{"id": "2504.18560", "pdf": "https://arxiv.org/pdf/2504.18560", "abs": "https://arxiv.org/abs/2504.18560", "authors": ["Alessio Buscemi", "C\u00e9dric Lothritz", "Sergio Morales", "Marcos Gomez-Vazquez", "Robert Claris\u00f3", "Jordi Cabot", "German Castignani"], "title": "Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have exhibited impressive natural language\nprocessing capabilities but often perpetuate social biases inherent in their\ntraining data. To address this, we introduce MultiLingual Augmented Bias\nTesting (MLA-BiTe), a framework that improves prior bias evaluation methods by\nenabling systematic multilingual bias testing. MLA-BiTe leverages automated\ntranslation and paraphrasing techniques to support comprehensive assessments\nacross diverse linguistic settings. In this study, we evaluate the\neffectiveness of MLA-BiTe by testing four state-of-the-art LLMs in six\nlanguages -- including two low-resource languages -- focusing on seven\nsensitive categories of discrimination.", "AI": {"tldr": "MLA-BiTe is a framework for multilingual bias testing in LLMs, improving evaluation methods by using automated translation and paraphrasing.", "motivation": "LLMs often perpetuate social biases from training data, necessitating better evaluation methods.", "method": "MLA-BiTe employs automated translation and paraphrasing to test biases in multiple languages, including low-resource ones.", "result": "The framework was tested on four LLMs across six languages, focusing on seven sensitive discrimination categories.", "conclusion": "MLA-BiTe provides a systematic approach to multilingual bias testing, enhancing bias evaluation in LLMs."}}
{"id": "2504.18639", "pdf": "https://arxiv.org/pdf/2504.18639", "abs": "https://arxiv.org/abs/2504.18639", "authors": ["Passant Elchafei", "Mervet Abu-Elkheir"], "title": "Span-Level Hallucination Detection for LLM-Generated Answers", "categories": ["cs.CL"], "comment": null, "summary": "Detecting spans of hallucination in LLM-generated answers is crucial for\nimproving factual consistency. This paper presents a span-level hallucination\ndetection framework for the SemEval-2025 Shared Task, focusing on English and\nArabic texts. Our approach integrates Semantic Role Labeling (SRL) to decompose\nthe answer into atomic roles, which are then compared with a retrieved\nreference context obtained via question-based LLM prompting. Using a\nDeBERTa-based textual entailment model, we evaluate each role semantic\nalignment with the retrieved context. The entailment scores are further refined\nthrough token-level confidence measures derived from output logits, and the\ncombined scores are used to detect hallucinated spans. Experiments on the\nMu-SHROOM dataset demonstrate competitive performance. Additionally,\nhallucinated spans have been verified through fact-checking by prompting GPT-4\nand LLaMA. Our findings contribute to improving hallucination detection in\nLLM-generated responses.", "AI": {"tldr": "A framework for detecting hallucinated spans in LLM-generated answers using Semantic Role Labeling and DeBERTa-based entailment, tested on Mu-SHROOM with GPT-4 and LLaMA verification.", "motivation": "Improving factual consistency in LLM-generated answers by detecting hallucinated spans.", "method": "Integrates Semantic Role Labeling (SRL) to decompose answers, compares with retrieved context using DeBERTa-based entailment, and refines scores with token-level confidence measures.", "result": "Competitive performance on Mu-SHROOM dataset; hallucinated spans verified via GPT-4 and LLaMA fact-checking.", "conclusion": "The framework effectively improves hallucination detection in LLM-generated responses."}}
{"id": "2504.18673", "pdf": "https://arxiv.org/pdf/2504.18673", "abs": "https://arxiv.org/abs/2504.18673", "authors": ["Jiayi Li", "Yingfan Zhou", "Pranav Narayanan Venkit", "Halima Binte Islam", "Sneha Arya", "Shomir Wilson", "Sarah Rajtmajer"], "title": "Can Third-parties Read Our Emotions?", "categories": ["cs.CL"], "comment": null, "summary": "Natural Language Processing tasks that aim to infer an author's private\nstates, e.g., emotions and opinions, from their written text, typically rely on\ndatasets annotated by third-party annotators. However, the assumption that\nthird-party annotators can accurately capture authors' private states remains\nlargely unexamined. In this study, we present human subjects experiments on\nemotion recognition tasks that directly compare third-party annotations with\nfirst-party (author-provided) emotion labels. Our findings reveal significant\nlimitations in third-party annotations-whether provided by human annotators or\nlarge language models (LLMs)-in faithfully representing authors' private\nstates. However, LLMs outperform human annotators nearly across the board. We\nfurther explore methods to improve third-party annotation quality. We find that\ndemographic similarity between first-party authors and third-party human\nannotators enhances annotation performance. While incorporating first-party\ndemographic information into prompts leads to a marginal but statistically\nsignificant improvement in LLMs' performance. We introduce a framework for\nevaluating the limitations of third-party annotations and call for refined\nannotation practices to accurately represent and model authors' private states.", "AI": {"tldr": "The paper examines the accuracy of third-party annotations (human and LLMs) in capturing authors' private states (emotions/opinions) compared to first-party labels, finding significant limitations but better performance by LLMs. It suggests demographic similarity improves annotation quality and proposes a framework for better practices.", "motivation": "To evaluate the assumption that third-party annotators accurately capture authors' private states, which is crucial for NLP tasks like emotion recognition.", "method": "Human subjects experiments comparing third-party (human and LLMs) and first-party annotations, exploring demographic similarity and prompting strategies.", "result": "Third-party annotations (human and LLMs) have limitations in representing authors' private states, though LLMs outperform humans. Demographic similarity improves human annotation quality, and demographic prompts marginally enhance LLMs.", "conclusion": "The study highlights the need for refined annotation practices to better represent authors' private states, proposing a framework for evaluation and improvement."}}
{"id": "2504.18715", "pdf": "https://arxiv.org/pdf/2504.18715", "abs": "https://arxiv.org/abs/2504.18715", "authors": ["Tuochao Chen", "Qirui Wang", "Runlin He", "Shyam Gollakota"], "title": "Spatial Speech Translation: Translating Across Space With Binaural Hearables", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted by CHI2025", "summary": "Imagine being in a crowded space where people speak a different language and\nhaving hearables that transform the auditory space into your native language,\nwhile preserving the spatial cues for all speakers. We introduce spatial speech\ntranslation, a novel concept for hearables that translate speakers in the\nwearer's environment, while maintaining the direction and unique voice\ncharacteristics of each speaker in the binaural output. To achieve this, we\ntackle several technical challenges spanning blind source separation,\nlocalization, real-time expressive translation, and binaural rendering to\npreserve the speaker directions in the translated audio, while achieving\nreal-time inference on the Apple M2 silicon. Our proof-of-concept evaluation\nwith a prototype binaural headset shows that, unlike existing models, which\nfail in the presence of interference, we achieve a BLEU score of up to 22.01\nwhen translating between languages, despite strong interference from other\nspeakers in the environment. User studies further confirm the system's\neffectiveness in spatially rendering the translated speech in previously unseen\nreal-world reverberant environments. Taking a step back, this work marks the\nfirst step towards integrating spatial perception into speech translation.", "AI": {"tldr": "A novel spatial speech translation system for hearables preserves speaker direction and voice characteristics while translating languages in real-time, achieving high BLEU scores despite interference.", "motivation": "To enable seamless communication in multilingual crowded spaces by translating speech while maintaining spatial auditory cues.", "method": "Combines blind source separation, localization, real-time expressive translation, and binaural rendering on Apple M2 silicon.", "result": "Achieves a BLEU score of 22.01 in noisy environments and effectively renders translated speech spatially.", "conclusion": "This work pioneers spatial perception integration in speech translation, validated by user studies in real-world settings."}}
{"id": "2504.18582", "pdf": "https://arxiv.org/pdf/2504.18582", "abs": "https://arxiv.org/abs/2504.18582", "authors": ["Abdulhady Abas Abdullah", "Sarkhel H. Taher Karim", "Sara Azad Ahmed", "Kanar R. Tariq", "Tarik A. Rashid"], "title": "Speaker Diarization for Low-Resource Languages Through Wav2vec Fine-Tuning", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Speaker diarization is a fundamental task in speech processing that involves\ndividing an audio stream by speaker. Although state-of-the-art models have\nadvanced performance in high-resource languages, low-resource languages such as\nKurdish pose unique challenges due to limited annotated data, multiple dialects\nand frequent code-switching. In this study, we address these issues by training\nthe Wav2Vec 2.0 self-supervised learning model on a dedicated Kurdish corpus.\nBy leveraging transfer learning, we adapted multilingual representations\nlearned from other languages to capture the phonetic and acoustic\ncharacteristics of Kurdish speech. Relative to a baseline method, our approach\nreduced the diarization error rate by seven point two percent and improved\ncluster purity by thirteen percent. These findings demonstrate that\nenhancements to existing models can significantly improve diarization\nperformance for under-resourced languages. Our work has practical implications\nfor developing transcription services for Kurdish-language media and for\nspeaker segmentation in multilingual call centers, teleconferencing and\nvideo-conferencing systems. The results establish a foundation for building\neffective diarization systems in other understudied languages, contributing to\ngreater equity in speech technology.", "AI": {"tldr": "The study improves speaker diarization for Kurdish using Wav2Vec 2.0, reducing error rates by 7.2% and boosting cluster purity by 13%.", "motivation": "Address challenges in low-resource languages like Kurdish, including limited data, dialects, and code-switching.", "method": "Train Wav2Vec 2.0 on a Kurdish corpus using transfer learning from multilingual representations.", "result": "Reduced diarization error rate by 7.2% and improved cluster purity by 13%.", "conclusion": "Enhancements to existing models can improve diarization for under-resourced languages, aiding transcription and multilingual applications."}}
{"id": "2504.19397", "pdf": "https://arxiv.org/pdf/2504.19397", "abs": "https://arxiv.org/abs/2504.19397", "authors": ["Sagar Sudhakara"], "title": "Symmetric Policy Design for Multi-Agent Dispatch Coordination in Supply Chains", "categories": ["cs.MA"], "comment": null, "summary": "We study a decentralized dispatch coordination problem in a multi-agent\nsupply chain setting with shared logistics capacity. We propose symmetric\n(identical) dispatch strategies for all agents, enabling efficient coordination\nwithout centralized control. Using a common information approach, we derive a\ndynamic programming solution that computes optimal symmetric dispatch\nstrategies by transforming the multi-agent problem into a tractable dynamic\nprogram on the agents common information state. Simulation results demonstrate\nthat our method significantly reduces coordination cost compared to baseline\nheuristics, including belief-based strategies and an always-dispatch policy.\nThese findings highlight the benefits of combining symmetric strategy design\nwith a common information-based dynamic programming framework for improving\nmulti-agent coordination performance.", "AI": {"tldr": "Proposes symmetric dispatch strategies for multi-agent supply chains, reducing coordination costs via dynamic programming.", "motivation": "Address decentralized dispatch coordination in multi-agent supply chains with shared logistics capacity, avoiding centralized control.", "method": "Uses a common information approach to derive dynamic programming solutions, transforming the problem into a tractable program.", "result": "Simulations show significant cost reduction compared to baseline heuristics like belief-based strategies.", "conclusion": "Symmetric strategy design with common information-based dynamic programming improves multi-agent coordination."}}
{"id": "2504.18539", "pdf": "https://arxiv.org/pdf/2504.18539", "abs": "https://arxiv.org/abs/2504.18539", "authors": ["Sungnyun Kim", "Sungwoo Cho", "Sangmin Bae", "Kangwook Jang", "Se-Young Yun"], "title": "Multi-Task Corrupted Prediction for Learning Robust Audio-Visual Speech Representation", "categories": ["eess.AS", "cs.LG", "cs.MM", "cs.SD"], "comment": "22 pages, 6 figures, 14 tables", "summary": "Audio-visual speech recognition (AVSR) incorporates auditory and visual\nmodalities to improve recognition accuracy, particularly in noisy environments\nwhere audio-only speech systems are insufficient. While previous research has\nlargely addressed audio disruptions, few studies have dealt with visual\ncorruptions, e.g., lip occlusions or blurred videos, which are also\ndetrimental. To address this real-world challenge, we propose CAV2vec, a novel\nself-supervised speech representation learning framework particularly designed\nto handle audio-visual joint corruption. CAV2vec employs a self-distillation\napproach with a corrupted prediction task, where the student model learns to\npredict clean targets, generated by the teacher model, with corrupted input\nframes. Specifically, we suggest a unimodal multi-task learning, which distills\ncross-modal knowledge and aligns the corrupted modalities, by predicting clean\naudio targets with corrupted videos, and clean video targets with corrupted\naudios. This strategy mitigates the dispersion in the representation space\ncaused by corrupted modalities, leading to more reliable and robust\naudio-visual fusion. Our experiments on robust AVSR benchmarks demonstrate that\nthe corrupted representation learning method significantly enhances recognition\naccuracy across generalized environments involving various types of corruption.", "AI": {"tldr": "CAV2vec is a self-supervised framework for AVSR that handles joint audio-visual corruption via self-distillation and unimodal multi-task learning, improving robustness in noisy or corrupted environments.", "motivation": "Addressing the lack of research on visual corruptions (e.g., lip occlusions) in AVSR, which degrade performance despite audio-visual fusion's advantages in noisy settings.", "method": "Proposes CAV2vec, using self-distillation with a corrupted prediction task. Unimodal multi-task learning aligns corrupted modalities by predicting clean targets (audio/video) from corrupted inputs.", "result": "CAV2vec significantly improves recognition accuracy in environments with various corruptions, as shown in robust AVSR benchmarks.", "conclusion": "The framework effectively mitigates representation dispersion from corrupted modalities, enhancing robustness in real-world AVSR applications."}}
{"id": "2504.18586", "pdf": "https://arxiv.org/pdf/2504.18586", "abs": "https://arxiv.org/abs/2504.18586", "authors": ["Leo Thomas Ramos", "Angel D. Sappa"], "title": "A Decade of You Only Look Once (YOLO) for Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "This review marks the tenth anniversary of You Only Look Once (YOLO), one of\nthe most influential frameworks in real-time object detection. Over the past\ndecade, YOLO has evolved from a streamlined detector into a diverse family of\narchitectures characterized by efficient design, modular scalability, and\ncross-domain adaptability. The paper presents a technical overview of the main\nversions, highlights key architectural trends, and surveys the principal\napplication areas in which YOLO has been adopted. It also addresses evaluation\npractices, ethical considerations, and potential future directions for the\nframework's continued development. The analysis aims to provide a comprehensive\nand critical perspective on YOLO's trajectory and ongoing transformation.", "AI": {"tldr": "A review of YOLO's evolution over 10 years, covering its technical advancements, applications, and future directions.", "motivation": "To critically analyze YOLO's development, impact, and future potential in real-time object detection.", "method": "Technical overview of YOLO versions, architectural trends, application areas, evaluation practices, and ethical considerations.", "result": "YOLO has evolved into a versatile, efficient, and widely adopted framework with diverse applications.", "conclusion": "The review provides a comprehensive perspective on YOLO's trajectory and suggests future development directions."}}
{"id": "2504.18544", "pdf": "https://arxiv.org/pdf/2504.18544", "abs": "https://arxiv.org/abs/2504.18544", "authors": ["Nazia Nafis", "Inaki Esnaola", "Alvaro Martinez-Perez", "Maria-Cruz Villa-Uriol", "Venet Osmani"], "title": "Critical Challenges and Guidelines in Evaluating Synthetic Tabular Data: A Systematic Review", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "Generating synthetic tabular data can be challenging, however evaluation of\ntheir quality is just as challenging, if not more. This systematic review sheds\nlight on the critical importance of rigorous evaluation of synthetic health\ndata to ensure reliability, relevance, and their appropriate use. Based on\nscreening of 1766 papers and a detailed review of 101 papers we identified key\nchallenges, including lack of consensus on evaluation methods, improper use of\nevaluation metrics, limited input from domain experts, inadequate reporting of\ndataset characteristics, and limited reproducibility of results. In response,\nwe provide several guidelines on the generation and evaluation of synthetic\ndata, to allow the community to unlock and fully harness the transformative\npotential of synthetic data and accelerate innovation.", "AI": {"tldr": "The paper highlights challenges in evaluating synthetic health data and proposes guidelines for better generation and evaluation.", "motivation": "To address the lack of consensus and rigor in evaluating synthetic health data, ensuring its reliability and appropriate use.", "method": "Systematic review of 1766 papers, with detailed analysis of 101, to identify key challenges in synthetic data evaluation.", "result": "Identified challenges include inconsistent evaluation methods, misuse of metrics, lack of domain expert input, poor dataset reporting, and low reproducibility.", "conclusion": "Proposes guidelines to improve synthetic data generation and evaluation, aiming to unlock its transformative potential."}}
{"id": "2504.18572", "pdf": "https://arxiv.org/pdf/2504.18572", "abs": "https://arxiv.org/abs/2504.18572", "authors": ["Syed Quiser Ahmed", "Bharathi Vokkaliga Ganesh", "Jagadish Babu P", "Karthick Selvaraj", "ReddySiva Naga Parvathi Devi", "Sravya Kappala"], "title": "BELL: Benchmarking the Explainability of Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models have demonstrated remarkable capabilities in natural\nlanguage processing, yet their decision-making processes often lack\ntransparency. This opaqueness raises significant concerns regarding trust,\nbias, and model performance. To address these issues, understanding and\nevaluating the interpretability of LLMs is crucial. This paper introduces a\nstandardised benchmarking technique, Benchmarking the Explainability of Large\nLanguage Models, designed to evaluate the explainability of large language\nmodels.", "AI": {"tldr": "A standardized benchmarking technique is introduced to evaluate the explainability of large language models (LLMs) to address transparency, trust, and bias concerns.", "motivation": "The lack of transparency in LLMs' decision-making raises concerns about trust, bias, and performance, necessitating a method to evaluate their interpretability.", "method": "The paper proposes a standardized benchmarking technique, Benchmarking the Explainability of Large Language Models, to assess LLM explainability.", "result": "The benchmarking technique provides a structured approach to evaluate the explainability of LLMs.", "conclusion": "Standardized benchmarking is essential for improving the transparency and trustworthiness of LLMs."}}
{"id": "2504.18799", "pdf": "https://arxiv.org/pdf/2504.18799", "abs": "https://arxiv.org/abs/2504.18799", "authors": ["Rashini Liyanarachchi", "Aditya Joshi", "Erik Meijering"], "title": "A Survey on Multimodal Music Emotion Recognition", "categories": ["cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "Multimodal music emotion recognition (MMER) is an emerging discipline in\nmusic information retrieval that has experienced a surge in interest in recent\nyears. This survey provides a comprehensive overview of the current\nstate-of-the-art in MMER. Discussing the different approaches and techniques\nused in this field, the paper introduces a four-stage MMER framework, including\nmultimodal data selection, feature extraction, feature processing, and final\nemotion prediction. The survey further reveals significant advancements in deep\nlearning methods and the increasing importance of feature fusion techniques.\nDespite these advancements, challenges such as the need for large annotated\ndatasets, datasets with more modalities, and real-time processing capabilities\nremain. This paper also contributes to the field by identifying critical gaps\nin current research and suggesting potential directions for future research.\nThe gaps underscore the importance of developing robust, scalable, a\ninterpretable models for MMER, with implications for applications in music\nrecommendation systems, therapeutic tools, and entertainment.", "AI": {"tldr": "A survey on multimodal music emotion recognition (MMER) outlining a four-stage framework, advancements in deep learning, and remaining challenges like dataset needs and real-time processing.", "motivation": "To provide a comprehensive overview of MMER, highlight advancements, and identify gaps for future research.", "method": "Introduces a four-stage MMER framework: multimodal data selection, feature extraction, feature processing, and emotion prediction. Discusses deep learning and feature fusion techniques.", "result": "Reveals progress in deep learning and feature fusion but notes challenges like dataset limitations and real-time processing needs.", "conclusion": "Identifies gaps in MMER research and suggests future directions, emphasizing robust, scalable models for applications in music recommendation, therapy, and entertainment."}}
{"id": "2504.18549", "pdf": "https://arxiv.org/pdf/2504.18549", "abs": "https://arxiv.org/abs/2504.18549", "authors": ["Boyuan Peng", "Jiaju Chen", "Yiwei Zhang", "Cuiyi Peng", "Junyang Li", "Jiaming Deng", "Peiwu Qin"], "title": "Dual-Modality Computational Ophthalmic Imaging with Deep Learning and Coaxial Optical Design", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "The growing burden of myopia and retinal diseases necessitates more\naccessible and efficient eye screening solutions. This study presents a\ncompact, dual-function optical device that integrates fundus photography and\nrefractive error detection into a unified platform. The system features a\ncoaxial optical design using dichroic mirrors to separate wavelength-dependent\nimaging paths, enabling simultaneous alignment of fundus and refraction\nmodules. A Dense-U-Net-based algorithm with customized loss functions is\nemployed for accurate pupil segmentation, facilitating automated alignment and\nfocusing. Experimental evaluations demonstrate the system's capability to\nachieve high-precision pupil localization (EDE = 2.8 px, mIoU = 0.931) and\nreliable refractive estimation with a mean absolute error below 5%. Despite\nlimitations due to commercial lens components, the proposed framework offers a\npromising solution for rapid, intelligent, and scalable ophthalmic screening,\nparticularly suitable for community health settings.", "AI": {"tldr": "A compact dual-function optical device integrates fundus photography and refractive error detection, using a coaxial design and Dense-U-Net for automated alignment, achieving high precision and reliability for scalable eye screening.", "motivation": "Address the growing burden of myopia and retinal diseases by providing an accessible and efficient eye screening solution.", "method": "Coaxial optical design with dichroic mirrors for wavelength separation, combined with a Dense-U-Net algorithm for pupil segmentation and automated alignment.", "result": "High-precision pupil localization (EDE = 2.8 px, mIoU = 0.931) and reliable refractive estimation (mean absolute error <5%).", "conclusion": "The framework offers a promising, scalable solution for rapid and intelligent ophthalmic screening, especially in community health settings."}}
{"id": "2504.18718", "pdf": "https://arxiv.org/pdf/2504.18718", "abs": "https://arxiv.org/abs/2504.18718", "authors": ["Lauren Levine", "Junghyun Min", "Amir Zeldes"], "title": "Building UD Cairo for Old English in the Classroom", "categories": ["cs.CL"], "comment": "7 pages, 2 figures", "summary": "In this paper we present a sample treebank for Old English based on the UD\nCairo sentences, collected and annotated as part of a classroom curriculum in\nHistorical Linguistics. To collect the data, a sample of 20 sentences\nillustrating a range of syntactic constructions in the world's languages, we\nemploy a combination of LLM prompting and searches in authentic Old English\ndata. For annotation we assigned sentences to multiple students with limited\nprior exposure to UD, whose annotations we compare and adjudicate. Our results\nsuggest that while current LLM outputs in Old English do not reflect authentic\nsyntax, this can be mitigated by post-editing, and that although beginner\nannotators do not possess enough background to complete the task perfectly,\ntaken together they can produce good results and learn from the experience. We\nalso conduct preliminary parsing experiments using Modern English training\ndata, and find that although performance on Old English is poor, parsing on\nannotated features (lemma, hyperlemma, gloss) leads to improved performance.", "AI": {"tldr": "A sample Old English treebank was created using UD Cairo sentences, combining LLM prompting and authentic data searches. Beginner annotators, despite limited UD knowledge, produced good results through collaboration. LLM outputs required post-editing for accuracy, and parsing experiments showed improved performance with annotated features.", "motivation": "To create a sample Old English treebank for educational purposes in Historical Linguistics, leveraging classroom involvement and modern tools like LLMs.", "method": "Combined LLM prompting and authentic Old English data searches to collect sentences. Multiple beginner annotators compared and adjudicated annotations. Parsing experiments used Modern English training data and annotated features.", "result": "LLM outputs lacked authentic syntax but improved with post-editing. Beginner annotators collectively produced good results. Parsing performance on Old English was poor but improved with annotated features.", "conclusion": "Collaborative annotation and post-editing can mitigate limitations of LLMs and beginner annotators. Annotated features enhance parsing performance, suggesting potential for further research."}}
{"id": "2504.18950", "pdf": "https://arxiv.org/pdf/2504.18950", "abs": "https://arxiv.org/abs/2504.18950", "authors": ["Erfan Loweimi", "Mengjie Qian", "Kate Knill", "Mark Gales"], "title": "Speaker Retrieval in the Wild: Challenges, Effectiveness and Robustness", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "comment": "13 pages, 10 figures, 10 tables, 76 references", "summary": "There is a growing abundance of publicly available or company-owned\naudio/video archives, highlighting the increasing importance of efficient\naccess to desired content and information retrieval from these archives. This\npaper investigates the challenges, solutions, effectiveness, and robustness of\nspeaker retrieval systems developed \"in the wild\" which involves addressing two\nprimary challenges: extraction of task-relevant labels from limited metadata\nfor system development and evaluation, as well as the unconstrained acoustic\nconditions encountered in the archive, ranging from quiet studios to adverse\nnoisy environments. While we focus on the publicly-available BBC Rewind archive\n(spanning 1948 to 1979), our framework addresses the broader issue of speaker\nretrieval on extensive and possibly aged archives with no control over the\ncontent and acoustic conditions. Typically, these archives offer a brief and\ngeneral file description, mostly inadequate for specific applications like\nspeaker retrieval, and manual annotation of such large-scale archives is\nunfeasible. We explore various aspects of system development (e.g., speaker\ndiarisation, embedding extraction, query selection) and analyse the challenges,\npossible solutions, and their functionality. To evaluate the performance, we\nconduct systematic experiments in both clean setup and against various\ndistortions simulating real-world applications. Our findings demonstrate the\neffectiveness and robustness of the developed speaker retrieval systems,\nestablishing the versatility and scalability of the proposed framework for a\nwide range of applications beyond the BBC Rewind corpus.", "AI": {"tldr": "The paper explores challenges and solutions for speaker retrieval in large, uncontrolled audio/video archives, focusing on the BBC Rewind archive, and demonstrates the robustness of the proposed framework.", "motivation": "The increasing importance of efficient access to audio/video archives and the challenges of speaker retrieval in uncontrolled environments motivate this study.", "method": "The paper investigates system development aspects like speaker diarisation and embedding extraction, and evaluates performance through experiments in clean and distorted setups.", "result": "The developed speaker retrieval systems show effectiveness and robustness, proving the framework's versatility for broader applications.", "conclusion": "The proposed framework is scalable and adaptable for diverse archives beyond the BBC Rewind corpus."}}
{"id": "2504.19487", "pdf": "https://arxiv.org/pdf/2504.19487", "abs": "https://arxiv.org/abs/2504.19487", "authors": ["Kavindu Warnakulasuriya", "Prabhash Dissanayake", "Navindu De Silva", "Stephen Cranefield", "Bastin Tony Roy Savarimuthu", "Surangika Ranathunga", "Nisansa de Silva"], "title": "Evolution of Cooperation in LLM-Agent Societies: A Preliminary Study Using Different Punishment Strategies", "categories": ["cs.MA"], "comment": "19 pages, 10 figures, Accepted for presentation as a full paper at\n  the COINE 2025 workshop at AAMAS 2025\n  (https://coin-workshop.github.io/coine-2025-detroit/accepted_for_presentation.html)", "summary": "The evolution of cooperation has been extensively studied using abstract\nmathematical models and simulations. Recent advances in Large Language Models\n(LLM) and the rise of LLM agents have demonstrated their ability to perform\nsocial reasoning, thus providing an opportunity to test the emergence of norms\nin more realistic agent-based simulations with human-like reasoning using\nnatural language. In this research, we investigate whether the cooperation\ndynamics presented in Boyd and Richerson's model persist in a more realistic\nsimulation of the diner's dilemma using LLM agents compared to the abstract\nmathematical nature in the work of Boyd and Richerson. Our findings indicate\nthat agents follow the strategies defined in the Boyd and Richerson model, and\nexplicit punishment mechanisms drive norm emergence, reinforcing cooperative\nbehaviour even when the agent strategy configuration varies. Our results\nsuggest that LLM-based Multi-Agent System simulations, in fact, can replicate\nthe evolution of cooperation predicted by the traditional mathematical models.\nMoreover, our simulations extend beyond the mathematical models by integrating\nnatural language-driven reasoning and a pairwise imitation method for strategy\nadoption, making them a more realistic testbed for cooperative behaviour in\nMASs.", "AI": {"tldr": "The paper explores cooperation dynamics in LLM-based agent simulations, confirming Boyd and Richerson's model and showing punishment-driven norm emergence.", "motivation": "To test if cooperation dynamics from abstract models persist in realistic LLM-agent simulations of the diner's dilemma.", "method": "Uses LLM agents with natural language reasoning and pairwise imitation for strategy adoption.", "result": "Agents replicate Boyd and Richerson's model, with punishment reinforcing cooperation.", "conclusion": "LLM-based simulations can replicate traditional models and offer a more realistic testbed for cooperative behavior."}}
{"id": "2504.19046", "pdf": "https://arxiv.org/pdf/2504.19046", "abs": "https://arxiv.org/abs/2504.19046", "authors": ["Billel Essaid", "Hamza Kheddar", "Noureddine Batel"], "title": "Enhancing Cochlear Implant Signal Coding with Scaled Dot-Product Attention", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": null, "summary": "Cochlear implants (CIs) play a vital role in restoring hearing for\nindividuals with severe to profound sensorineural hearing loss by directly\nstimulating the auditory nerve with electrical signals. While traditional\ncoding strategies, such as the advanced combination encoder (ACE), have proven\neffective, they are constrained by their adaptability and precision. This paper\ninvestigates the use of deep learning (DL) techniques to generate\nelectrodograms for CIs, presenting our model as an advanced alternative. We\ncompared the performance of our model with the ACE strategy by evaluating the\nintelligibility of reconstructed audio signals using the short-time objective\nintelligibility (STOI) metric. The results indicate that our model achieves a\nSTOI score of 0.6031, closely approximating the 0.6126 score of the ACE\nstrategy, and offers potential advantages in flexibility and adaptability. This\nstudy underscores the benefits of incorporating artificial intelligent (AI)\ninto CI technology, such as enhanced personalization and efficiency.", "AI": {"tldr": "Deep learning improves cochlear implant electrodograms, matching traditional methods in intelligibility while offering better adaptability.", "motivation": "Traditional cochlear implant coding strategies like ACE lack adaptability and precision, prompting exploration of deep learning for better performance.", "method": "A deep learning model was developed to generate electrodograms and compared to the ACE strategy using the STOI metric for intelligibility.", "result": "The DL model achieved a STOI score of 0.6031, close to ACE's 0.6126, with added flexibility and adaptability benefits.", "conclusion": "AI integration in cochlear implants enhances personalization and efficiency, demonstrating promise for future advancements."}}
{"id": "2504.18589", "pdf": "https://arxiv.org/pdf/2504.18589", "abs": "https://arxiv.org/abs/2504.18589", "authors": ["Zhikai Wang", "Jiashuo Sun", "Wenqi Zhang", "Zhiqiang Hu", "Xin Li", "Fan Wang", "Deli Zhao"], "title": "Benchmarking Multimodal Mathematical Reasoning with Explicit Visual Dependency", "categories": ["cs.CV"], "comment": "Home page: https://alibaba-damo-academy.github.io/VCBench/", "summary": "Recent advancements in Large Vision-Language Models (LVLMs) have\nsignificantly enhanced their ability to integrate visual and linguistic\ninformation, achieving near-human proficiency in tasks like object recognition,\ncaptioning, and visual question answering. However, current benchmarks\ntypically focus on knowledge-centric evaluations that assess domain-specific\nexpertise, often neglecting the core ability to reason about fundamental\nmathematical elements and visual concepts. We identify a gap in evaluating\nelementary-level math problems, which rely on explicit visual\ndependencies-requiring models to discern, integrate, and reason across multiple\nimages while incorporating commonsense knowledge, all of which are crucial for\nadvancing toward broader AGI capabilities. To address this gap, we introduce\nVCBENCH, a comprehensive benchmark for multimodal mathematical reasoning with\nexplicit visual dependencies. VCBENCH includes 1,720 problems across six\ncognitive domains, featuring 6,697 images (averaging 3.9 per question) to\nensure multi-image reasoning. We evaluate 26 state-of-the-art LVLMs on VCBENCH,\nrevealing substantial performance disparities, with even the top models unable\nto exceed 50% accuracy. Our findings highlight the ongoing challenges in\nvisual-mathematical integration and suggest avenues for future LVLM\nadvancements.", "AI": {"tldr": "VCBENCH is introduced to evaluate LVLMs on multimodal mathematical reasoning with visual dependencies, revealing significant performance gaps.", "motivation": "Current benchmarks overlook elementary-level math problems with visual dependencies, crucial for AGI progress.", "method": "VCBENCH includes 1,720 problems across six domains, using 6,697 images for multi-image reasoning.", "result": "Top LVLMs scored below 50% accuracy, showing challenges in visual-mathematical integration.", "conclusion": "VCBENCH highlights LVLM limitations and suggests future improvements in visual reasoning."}}
{"id": "2504.18547", "pdf": "https://arxiv.org/pdf/2504.18547", "abs": "https://arxiv.org/abs/2504.18547", "authors": ["Ching-Yi Lin", "Sahil Shah"], "title": "Low-Bit Integerization of Vision Transformers using Operand Reodering for Efficient Hardware", "categories": ["cs.LG", "cs.CV", "cs.SY", "eess.SY"], "comment": "4 pages + references, 5 figures, 2 tables in IEEE double column\n  conference template", "summary": "Pre-trained vision transformers have achieved remarkable performance across\nvarious visual tasks but suffer from expensive computational and memory costs.\nWhile model quantization reduces memory usage by lowering precision, these\nmodels still incur significant computational overhead due to the dequantization\nbefore matrix operations. In this work, we analyze the computation graph and\npropose an integerization process based on operation reordering. Specifically,\nthe process delays dequantization until after matrix operations. This enables\nintegerized matrix multiplication and linear module by directly processing the\nquantized input. To validate our approach, we synthesize the self-attention\nmodule of ViT on a systolic array-based hardware. Experimental results show\nthat our low-bit inference reduces per-PE power consumption for linear layer\nand matrix multiplication, bridging the gap between quantized models and\nefficient inference.", "AI": {"tldr": "The paper proposes an integerization process for pre-trained vision transformers to reduce computational overhead by delaying dequantization until after matrix operations, enabling efficient low-bit inference.", "motivation": "Pre-trained vision transformers face high computational and memory costs, even with quantization, due to dequantization overhead before matrix operations.", "method": "The method involves analyzing the computation graph and reordering operations to delay dequantization, allowing integerized matrix multiplication and linear modules.", "result": "Experiments on a systolic array-based hardware show reduced per-PE power consumption for linear layers and matrix multiplication.", "conclusion": "The approach bridges the gap between quantized models and efficient inference, validating its effectiveness for low-bit inference."}}
{"id": "2504.18600", "pdf": "https://arxiv.org/pdf/2504.18600", "abs": "https://arxiv.org/abs/2504.18600", "authors": ["Saizhuo Wang", "Hao Kong", "Jiadong Guo", "Fengrui Hua", "Yiyan Qi", "Wanyun Zhou", "Jiahao Zheng", "Xinyu Wang", "Lionel M. Ni", "Jian Guo"], "title": "QuantBench: Benchmarking AI Methods for Quantitative Investment", "categories": ["q-fin.CP", "cs.AI", "cs.CE"], "comment": null, "summary": "The field of artificial intelligence (AI) in quantitative investment has seen\nsignificant advancements, yet it lacks a standardized benchmark aligned with\nindustry practices. This gap hinders research progress and limits the practical\napplication of academic innovations. We present QuantBench, an industrial-grade\nbenchmark platform designed to address this critical need. QuantBench offers\nthree key strengths: (1) standardization that aligns with quantitative\ninvestment industry practices, (2) flexibility to integrate various AI\nalgorithms, and (3) full-pipeline coverage of the entire quantitative\ninvestment process. Our empirical studies using QuantBench reveal some critical\nresearch directions, including the need for continual learning to address\ndistribution shifts, improved methods for modeling relational financial data,\nand more robust approaches to mitigate overfitting in low signal-to-noise\nenvironments. By providing a common ground for evaluation and fostering\ncollaboration between researchers and practitioners, QuantBench aims to\naccelerate progress in AI for quantitative investment, similar to the impact of\nbenchmark platforms in computer vision and natural language processing.", "AI": {"tldr": "QuantBench is a standardized benchmark platform for AI in quantitative investment, addressing industry alignment, flexibility, and full-pipeline coverage. It highlights key research directions like continual learning and robust modeling.", "motivation": "The lack of a standardized benchmark in AI for quantitative investment hinders research and practical application. QuantBench aims to fill this gap.", "method": "QuantBench is designed with standardization, flexibility, and full-pipeline coverage, integrating various AI algorithms for empirical studies.", "result": "Empirical studies reveal critical research needs: continual learning, better relational data modeling, and robust overfitting mitigation.", "conclusion": "QuantBench accelerates AI progress in quantitative investment by providing a common evaluation ground and fostering researcher-practitioner collaboration."}}
{"id": "2504.19458", "pdf": "https://arxiv.org/pdf/2504.19458", "abs": "https://arxiv.org/abs/2504.19458", "authors": ["Taoyu Su", "Jiawei Sheng", "Duohe Ma", "Xiaodong Li", "Juwei Yue", "Mengxiao Song", "Yingkai Tang", "Tingwen Liu"], "title": "Mitigating Modality Bias in Multi-modal Entity Alignment from a Causal Perspective", "categories": ["cs.MM", "cs.CL", "cs.IR"], "comment": "Accepted by SIGIR 2025, 11 pages, 10 figures, 4 tables,", "summary": "Multi-Modal Entity Alignment (MMEA) aims to retrieve equivalent entities from\ndifferent Multi-Modal Knowledge Graphs (MMKGs), a critical information\nretrieval task. Existing studies have explored various fusion paradigms and\nconsistency constraints to improve the alignment of equivalent entities, while\noverlooking that the visual modality may not always contribute positively.\nEmpirically, entities with low-similarity images usually generate\nunsatisfactory performance, highlighting the limitation of overly relying on\nvisual features. We believe the model can be biased toward the visual modality,\nleading to a shortcut image-matching task. To address this, we propose a\ncounterfactual debiasing framework for MMEA, termed CDMEA, which investigates\nvisual modality bias from a causal perspective. Our approach aims to leverage\nboth visual and graph modalities to enhance MMEA while suppressing the direct\ncausal effect of the visual modality on model predictions. By estimating the\nTotal Effect (TE) of both modalities and excluding the Natural Direct Effect\n(NDE) of the visual modality, we ensure that the model predicts based on the\nTotal Indirect Effect (TIE), effectively utilizing both modalities and reducing\nvisual modality bias. Extensive experiments on 9 benchmark datasets show that\nCDMEA outperforms 14 state-of-the-art methods, especially in low-similarity,\nhigh-noise, and low-resource data scenarios.", "AI": {"tldr": "CDMEA is a counterfactual debiasing framework for Multi-Modal Entity Alignment (MMEA) that reduces visual modality bias by leveraging causal effects, outperforming 14 state-of-the-art methods.", "motivation": "Existing MMEA methods overly rely on visual features, which can bias the model and degrade performance for low-similarity images.", "method": "Proposes CDMEA, a framework that estimates Total Effect (TE) and excludes Natural Direct Effect (NDE) of visual modality to reduce bias, focusing on Total Indirect Effect (TIE).", "result": "CDMEA outperforms 14 state-of-the-art methods, especially in low-similarity, high-noise, and low-resource scenarios.", "conclusion": "CDMEA effectively reduces visual modality bias and improves MMEA performance by leveraging causal analysis."}}
{"id": "2504.18802", "pdf": "https://arxiv.org/pdf/2504.18802", "abs": "https://arxiv.org/abs/2504.18802", "authors": ["Xiren Zhou", "Shikang Liu", "Xinyu Yan", "Yizhan Fan", "Xiangyu Wang", "Yu Kang", "Jian Cheng", "Huanhuan Chen"], "title": "Reservoir-enhanced Segment Anything Model for Subsurface Diagnosis", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Urban roads and infrastructure, vital to city operations, face growing\nthreats from subsurface anomalies like cracks and cavities. Ground Penetrating\nRadar (GPR) effectively visualizes underground conditions employing\nelectromagnetic (EM) waves; however, accurate anomaly detection via GPR remains\nchallenging due to limited labeled data, varying subsurface conditions, and\nindistinct target boundaries. Although visually image-like, GPR data\nfundamentally represent EM waves, with variations within and between waves\ncritical for identifying anomalies. Addressing these, we propose the\nReservoir-enhanced Segment Anything Model (Res-SAM), an innovative framework\nexploiting both visual discernibility and wave-changing properties of GPR data.\nRes-SAM initially identifies apparent candidate anomaly regions given minimal\nprompts, and further refines them by analyzing anomaly-induced changing\ninformation within and between EM waves in local GPR data, enabling precise and\ncomplete anomaly region extraction and category determination. Real-world\nexperiments demonstrate that Res-SAM achieves high detection accuracy (>85%)\nand outperforms state-of-the-art. Notably, Res-SAM requires only minimal\naccessible non-target data, avoids intensive training, and incorporates simple\nhuman interaction to enhance reliability. Our research provides a scalable,\nresource-efficient solution for rapid subsurface anomaly detection across\ndiverse environments, improving urban safety monitoring while reducing manual\neffort and computational cost.", "AI": {"tldr": "Res-SAM, a novel framework combining visual and wave-based analysis, improves GPR anomaly detection with high accuracy (>85%) and minimal training.", "motivation": "Urban infrastructure faces threats from subsurface anomalies, but GPR-based detection is hindered by limited labeled data and unclear boundaries.", "method": "Res-SAM uses visual prompts and EM wave analysis to refine anomaly regions, requiring minimal non-target data and human interaction.", "result": "Achieves >85% accuracy, outperforms state-of-the-art methods, and reduces manual effort and computational costs.", "conclusion": "Res-SAM offers a scalable, efficient solution for urban safety monitoring, enhancing anomaly detection with minimal resources."}}
{"id": "2504.18736", "pdf": "https://arxiv.org/pdf/2504.18736", "abs": "https://arxiv.org/abs/2504.18736", "authors": ["Jianyou Wang", "Weili Cao", "Kaicheng Wang", "Xiaoyue Wang", "Ashish Dalvi", "Gino Prasad", "Qishan Liang", "Hsuan-lin Her", "Ming Wang", "Qin Yang", "Gene W. Yeo", "David E. Neal", "Maxim Khan", "Christopher D. Rosin", "Ramamohan Paturi", "Leon Bergen"], "title": "EvidenceBench: A Benchmark for Extracting Evidence from Biomedical Papers", "categories": ["cs.CL"], "comment": null, "summary": "We study the task of automatically finding evidence relevant to hypotheses in\nbiomedical papers. Finding relevant evidence is an important step when\nresearchers investigate scientific hypotheses. We introduce EvidenceBench to\nmeasure models performance on this task, which is created by a novel pipeline\nthat consists of hypothesis generation and sentence-by-sentence annotation of\nbiomedical papers for relevant evidence, completely guided by and faithfully\nfollowing existing human experts judgment. We demonstrate the pipeline's\nvalidity and accuracy with multiple sets of human-expert annotations. We\nevaluated a diverse set of language models and retrieval systems on the\nbenchmark and found that model performances still fall significantly short of\nthe expert level on this task. To show the scalability of our proposed\npipeline, we create a larger EvidenceBench-100k with 107,461 fully annotated\npapers with hypotheses to facilitate model training and development. Both\ndatasets are available at https://github.com/EvidenceBench/EvidenceBench", "AI": {"tldr": "The paper introduces EvidenceBench, a benchmark for evaluating models on finding evidence for biomedical hypotheses, validated by expert annotations, and shows current models fall short of expert performance.", "motivation": "Automating the process of finding relevant evidence for biomedical hypotheses is crucial for research efficiency, but current models lack expert-level accuracy.", "method": "A novel pipeline for hypothesis generation and sentence-by-sentence annotation of biomedical papers, validated by human experts, was used to create EvidenceBench.", "result": "Models evaluated on EvidenceBench perform significantly below expert level. A larger dataset, EvidenceBench-100k, was also created for scalability.", "conclusion": "EvidenceBench provides a reliable benchmark for evidence-finding tasks, highlighting the gap between model and expert performance, and offers a scalable dataset for future research."}}
{"id": "2504.19030", "pdf": "https://arxiv.org/pdf/2504.19030", "abs": "https://arxiv.org/abs/2504.19030", "authors": ["Sidahmed Lachenani", "Hamza Kheddar", "Mohamed Ouldzmirli"], "title": "Improving Pretrained YAMNet for Enhanced Speech Command Detection via Transfer Learning", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "This work addresses the need for enhanced accuracy and efficiency in speech\ncommand recognition systems, a critical component for improving user\ninteraction in various smart applications. Leveraging the robust pretrained\nYAMNet model and transfer learning, this study develops a method that\nsignificantly improves speech command recognition. We adapt and train a YAMNet\ndeep learning model to effectively detect and interpret speech commands from\naudio signals. Using the extensively annotated Speech Commands dataset\n(speech_commands_v0.01), our approach demonstrates the practical application of\ntransfer learning to accurately recognize a predefined set of speech commands.\nThe dataset is meticulously augmented, and features are strategically extracted\nto boost model performance. As a result, the final model achieved a recognition\naccuracy of 95.28%, underscoring the impact of advanced machine learning\ntechniques on speech command recognition. This achievement marks substantial\nprogress in audio processing technologies and establishes a new benchmark for\nfuture research in the field.", "AI": {"tldr": "The paper proposes a method using YAMNet and transfer learning to improve speech command recognition, achieving 95.28% accuracy.", "motivation": "Enhancing accuracy and efficiency in speech command recognition for better user interaction in smart applications.", "method": "Adapts and trains the YAMNet model using the Speech Commands dataset, with augmentation and strategic feature extraction.", "result": "Achieved a recognition accuracy of 95.28%.", "conclusion": "Demonstrates the effectiveness of transfer learning in speech command recognition, setting a new benchmark for future research."}}
{"id": "2504.19635", "pdf": "https://arxiv.org/pdf/2504.19635", "abs": "https://arxiv.org/abs/2504.19635", "authors": ["Yike Zhao", "Haoyuan Cai", "Ali H. Sayed"], "title": "Diffusion Stochastic Learning Over Adaptive Competing Networks", "categories": ["cs.MA", "cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "This paper studies a stochastic dynamic game between two competing teams,\neach consisting of a network of collaborating agents. Unlike fully cooperative\nsettings, where all agents share a common objective, each team in this game\naims to minimize its own distinct objective. In the adversarial setting, their\nobjectives could be conflicting as in zero-sum games. Throughout the\ncompetition, agents share strategic information within their own team while\nsimultaneously inferring and adapting to the strategies of the opposing team.\nWe propose diffusion learning algorithms to address two important classes of\nthis network game: i) a zero-sum game characterized by weak cross-team subgraph\ninteractions, and ii) a general non-zero-sum game exhibiting strong cross-team\nsubgraph interactions. We analyze the stability performance of the proposed\nalgorithms under reasonable assumptions and illustrate the theoretical results\nthrough experiments on Cournot team competition and decentralized GAN training.", "AI": {"tldr": "The paper studies a stochastic dynamic game between two competing teams of agents, proposing diffusion learning algorithms for zero-sum and non-zero-sum games, with theoretical and experimental validation.", "motivation": "To address competitive scenarios where teams of agents have conflicting objectives, requiring strategies for intra-team collaboration and inter-team adaptation.", "method": "Proposes diffusion learning algorithms for two game classes: zero-sum (weak cross-team interactions) and non-zero-sum (strong cross-team interactions).", "result": "The algorithms' stability is analyzed theoretically and validated through experiments on Cournot competition and decentralized GAN training.", "conclusion": "The proposed methods effectively handle competitive team dynamics, balancing intra-team collaboration and inter-team adaptation."}}
{"id": "2504.19062", "pdf": "https://arxiv.org/pdf/2504.19062", "abs": "https://arxiv.org/abs/2504.19062", "authors": ["Yu Zhang", "Wenxiang Guo", "Changhao Pan", "Zhiyuan Zhu", "Ruiqi Li", "Jingyu Lu", "Rongjie Huang", "Ruiyuan Zhang", "Zhiqing Hong", "Ziyue Jiang", "Zhou Zhao"], "title": "Versatile Framework for Song Generation with Prompt-based Control", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": null, "summary": "Song generation focuses on producing controllable high-quality songs based on\nvarious prompts. However, existing methods struggle to generate vocals and\naccompaniments with prompt-based control and proper alignment. Additionally,\nthey fall short in supporting various tasks. To address these challenges, we\nintroduce VersBand, a multi-task song generation framework for synthesizing\nhigh-quality, aligned songs with prompt-based control. VersBand comprises these\nprimary models: 1) VocalBand, a decoupled model, leverages the flow-matching\nmethod for generating singing styles, pitches, and mel-spectrograms, allowing\nfast, high-quality vocal generation with style control. 2) AccompBand, a\nflow-based transformer model, incorporates the Band-MOE, selecting suitable\nexperts for enhanced quality, alignment, and control. This model allows for\ngenerating controllable, high-quality accompaniments aligned with vocals. 3)\nTwo generation models, LyricBand for lyrics and MelodyBand for melodies,\ncontribute to the comprehensive multi-task song generation system, allowing for\nextensive control based on multiple prompts. Experimental results demonstrate\nthat VersBand performs better over baseline models across multiple song\ngeneration tasks using objective and subjective metrics. Audio samples are\navailable at https://VersBand.github.io.", "AI": {"tldr": "VersBand is a multi-task song generation framework addressing vocal and accompaniment alignment and control, outperforming baselines in quality and versatility.", "motivation": "Existing methods lack prompt-based control and alignment for vocals and accompaniments, and fail to support diverse tasks.", "method": "VersBand includes VocalBand (flow-matching for vocals), AccompBand (flow-based transformer for accompaniments), and additional models (LyricBand, MelodyBand) for comprehensive control.", "result": "VersBand outperforms baseline models in multiple song generation tasks, validated by objective and subjective metrics.", "conclusion": "VersBand successfully synthesizes high-quality, aligned songs with extensive prompt-based control, advancing multi-task song generation."}}
{"id": "2504.18666", "pdf": "https://arxiv.org/pdf/2504.18666", "abs": "https://arxiv.org/abs/2504.18666", "authors": ["David Aparco-Cardenas", "Jancarlo F. Gomes", "Alexandre X. Falc\u00e3o", "Pedro J. de Rezende"], "title": "Co-Training with Active Contrastive Learning and Meta-Pseudo-Labeling on 2D Projections for Deep Semi-Supervised Learning", "categories": ["cs.CV", "68T07", "I.4.10; I.5.1"], "comment": "Submitted to Journal of the Brazilian Computer Society (JBCS)\n  [https://journals-sol.sbc.org.br]", "summary": "A major challenge that prevents the training of DL models is the limited\navailability of accurately labeled data. This shortcoming is highlighted in\nareas where data annotation becomes a time-consuming and error-prone task. In\nthis regard, SSL tackles this challenge by capitalizing on scarce labeled and\nabundant unlabeled data; however, SoTA methods typically depend on pre-trained\nfeatures and large validation sets to learn effective representations for\nclassification tasks. In addition, the reduced set of labeled data is often\nrandomly sampled, neglecting the selection of more informative samples. Here,\nwe present active-DeepFA, a method that effectively combines CL,\nteacher-student-based meta-pseudo-labeling and AL to train non-pretrained CNN\narchitectures for image classification in scenarios of scarcity of labeled and\nabundance of unlabeled data. It integrates DeepFA into a co-training setup that\nimplements two cooperative networks to mitigate confirmation bias from\npseudo-labels. The method starts with a reduced set of labeled samples by\nwarming up the networks with supervised CL. Afterward and at regular epoch\nintervals, label propagation is performed on the 2D projections of the\nnetworks' deep features. Next, the most reliable pseudo-labels are exchanged\nbetween networks in a cross-training fashion, while the most meaningful samples\nare annotated and added into the labeled set. The networks independently\nminimize an objective loss function comprising supervised contrastive,\nsupervised and semi-supervised loss components, enhancing the representations\ntowards image classification. Our approach is evaluated on three challenging\nbiological image datasets using only 5% of labeled samples, improving baselines\nand outperforming six other SoTA methods. In addition, it reduces annotation\neffort by achieving comparable results to those of its counterparts with only\n3% of labeled data.", "AI": {"tldr": "Active-DeepFA combines contrastive learning, meta-pseudo-labeling, and active learning to train CNNs with limited labeled data, outperforming SoTA methods and reducing annotation effort.", "motivation": "The challenge of limited labeled data in DL, especially in error-prone annotation tasks, motivates the need for methods like SSL. However, existing methods rely on pre-trained features or large validation sets, and random sampling neglects informative data.", "method": "Active-DeepFA integrates DeepFA into a co-training setup with two networks to mitigate pseudo-label bias. It uses supervised contrastive learning for warm-up, label propagation on 2D feature projections, cross-training for pseudo-label exchange, and active learning for meaningful sample annotation.", "result": "Evaluated on biological image datasets with 5% labeled data, Active-DeepFA improves baselines and outperforms six SoTA methods. It achieves comparable results with only 3% labeled data, reducing annotation effort.", "conclusion": "Active-DeepFA effectively addresses the scarcity of labeled data by combining multiple learning strategies, demonstrating superior performance and efficiency in image classification tasks."}}
{"id": "2504.18556", "pdf": "https://arxiv.org/pdf/2504.18556", "abs": "https://arxiv.org/abs/2504.18556", "authors": ["Jialei Song", "Xingquan Zuo", "Feiyang Wang", "Hai Huang", "Tianle Zhang"], "title": "RDI: An adversarial robustness evaluation metric for deep neural networks based on sample clustering features", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep neural networks (DNNs) are highly susceptible to adversarial samples,\nraising concerns about their reliability in safety-critical tasks. Currently,\nmethods of evaluating adversarial robustness are primarily categorized into\nattack-based and certified robustness evaluation approaches. The former not\nonly relies on specific attack algorithms but also is highly time-consuming,\nwhile the latter due to its analytical nature, is typically difficult to\nimplement for large and complex models. A few studies evaluate model robustness\nbased on the model's decision boundary, but they suffer from low evaluation\naccuracy. To address the aforementioned issues, we propose a novel adversarial\nrobustness evaluation metric, Robustness Difference Index (RDI), which is based\non sample clustering features. RDI draws inspiration from clustering evaluation\nby analyzing the intra-class and inter-class distances of feature vectors\nseparated by the decision boundary to quantify model robustness. It is\nattack-independent and has high computational efficiency. Experiments show\nthat, RDI demonstrates a stronger correlation with the gold-standard\nadversarial robustness metric of attack success rate (ASR). The average\ncomputation time of RDI is only 1/30 of the evaluation method based on the PGD\nattack. Our open-source code is available at:\nhttps://anonymous.4open.science/r/RDI-B1DA.", "AI": {"tldr": "Proposes Robustness Difference Index (RDI), a novel metric for evaluating adversarial robustness in DNNs, based on clustering features, offering attack-independence and high efficiency.", "motivation": "Current adversarial robustness evaluation methods are either attack-dependent/time-consuming (attack-based) or hard to implement (certified robustness). Existing boundary-based methods lack accuracy.", "method": "RDI analyzes intra-class and inter-class distances of feature vectors separated by the decision boundary, inspired by clustering evaluation.", "result": "RDI correlates strongly with attack success rate (ASR) and is computationally efficient (1/30 time of PGD-based evaluation).", "conclusion": "RDI provides an effective, attack-independent, and efficient alternative for adversarial robustness evaluation."}}
{"id": "2504.18604", "pdf": "https://arxiv.org/pdf/2504.18604", "abs": "https://arxiv.org/abs/2504.18604", "authors": ["Xingyu Xiao", "Peng Chen", "Jiejuan Tong", "Shunshun Liu", "Hongru Zhao", "Jun Zhao", "Qianqian Jia", "Jingang Liang", "Haitao Wang"], "title": "A Cognitive-Mechanistic Human Reliability Analysis Framework: A Nuclear Power Plant Case Study", "categories": ["cs.AI"], "comment": null, "summary": "Traditional human reliability analysis (HRA) methods, such as IDHEAS-ECA,\nrely on expert judgment and empirical rules that often overlook the cognitive\nunderpinnings of human error. Moreover, conducting human-in-the-loop\nexperiments for advanced nuclear power plants is increasingly impractical due\nto novel interfaces and limited operational data. This study proposes a\ncognitive-mechanistic framework (COGMIF) that enhances the IDHEAS-ECA\nmethodology by integrating an ACT-R-based human digital twin (HDT) with\nTimeGAN-augmented simulation. The ACT-R model simulates operator cognition,\nincluding memory retrieval, goal-directed procedural reasoning, and\nperceptual-motor execution, under high-fidelity scenarios derived from a\nhigh-temperature gas-cooled reactor (HTGR) simulator. To overcome the resource\nconstraints of large-scale cognitive modeling, TimeGAN is trained on\nACT-R-generated time-series data to produce high-fidelity synthetic operator\nbehavior datasets. These simulations are then used to drive IDHEAS-ECA\nassessments, enabling scalable, mechanism-informed estimation of human error\nprobabilities (HEPs). Comparative analyses with SPAR-H and sensitivity\nassessments demonstrate the robustness and practical advantages of the proposed\nCOGMIF. Finally, procedural features are mapped onto a Bayesian network to\nquantify the influence of contributing factors, revealing key drivers of\noperational risk. This work offers a credible and computationally efficient\npathway to integrate cognitive theory into industrial HRA practices.", "AI": {"tldr": "The paper introduces COGMIF, a cognitive-mechanistic framework enhancing IDHEAS-ECA by integrating ACT-R-based human digital twins and TimeGAN-augmented simulation for scalable, mechanism-informed human error probability estimation in nuclear power plants.", "motivation": "Traditional HRA methods like IDHEAS-ECA lack cognitive insights and face impracticalities in human-in-the-loop experiments for advanced nuclear plants.", "method": "COGMIF combines ACT-R-based human digital twins (simulating cognition) with TimeGAN-augmented synthetic data to enhance IDHEAS-ECA assessments.", "result": "Comparative analyses show COGMIF's robustness and practical advantages over SPAR-H, with Bayesian network mapping revealing key operational risk drivers.", "conclusion": "COGMIF provides a credible, efficient way to integrate cognitive theory into industrial HRA practices."}}
{"id": "2504.19595", "pdf": "https://arxiv.org/pdf/2504.19595", "abs": "https://arxiv.org/abs/2504.19595", "authors": ["Pietro Bongini", "Sara Mandelli", "Andrea Montibeller", "Mirko Casu", "Orazio Pontorno", "Claudio Ragaglia", "Luca Zanchetta", "Mattia Aquilina", "Taiba Majid Wani", "Luca Guarnera", "Benedetta Tondi", "Paolo Bestagini", "Irene Amerini", "Francesco Denatale", "Sebastiano Battiato", "Mauro Barni"], "title": "WILD: a new in-the-Wild Image Linkage Dataset for synthetic image attribution", "categories": ["cs.MM", "cs.AI", "cs.CV"], "comment": null, "summary": "Synthetic image source attribution is an open challenge, with an increasing\nnumber of image generators being released yearly. The complexity and the sheer\nnumber of available generative techniques, as well as the scarcity of\nhigh-quality open source datasets of diverse nature for this task, make\ntraining and benchmarking synthetic image source attribution models very\nchallenging. WILD is a new in-the-Wild Image Linkage Dataset designed to\nprovide a powerful training and benchmarking tool for synthetic image\nattribution models. The dataset is built out of a closed set of 10 popular\ncommercial generators, which constitutes the training base of attribution\nmodels, and an open set of 10 additional generators, simulating a real-world\nin-the-wild scenario. Each generator is represented by 1,000 images, for a\ntotal of 10,000 images in the closed set and 10,000 images in the open set.\nHalf of the images are post-processed with a wide range of operators. WILD\nallows benchmarking attribution models in a wide range of tasks, including\nclosed and open set identification and verification, and robust attribution\nwith respect to post-processing and adversarial attacks. Models trained on WILD\nare expected to benefit from the challenging scenario represented by the\ndataset itself. Moreover, an assessment of seven baseline methodologies on\nclosed and open set attribution is presented, including robustness tests with\nrespect to post-processing.", "AI": {"tldr": "WILD is a dataset for training and benchmarking synthetic image source attribution models, featuring 20,000 images from 20 generators, including post-processed and adversarial examples.", "motivation": "The challenge of attributing synthetic images to their sources due to the growing number of generators and lack of diverse datasets.", "method": "Creation of the WILD dataset with closed and open sets of 10 generators each, totaling 20,000 images, half post-processed. Benchmarking seven baseline models.", "result": "WILD enables robust benchmarking for tasks like closed/open set identification, verification, and post-processing robustness. Baseline results are provided.", "conclusion": "WILD is a valuable tool for advancing synthetic image attribution, with models expected to perform better due to its challenging design."}}
{"id": "2504.18954", "pdf": "https://arxiv.org/pdf/2504.18954", "abs": "https://arxiv.org/abs/2504.18954", "authors": ["Marco Mezzina", "Pieter De Backer", "Tom Vercauteren", "Matthew Blaschko", "Alexandre Mottrie", "Tinne Tuytelaars"], "title": "Surgeons vs. Computer Vision: A comparative analysis on surgical phase recognition capabilities", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Purpose: Automated Surgical Phase Recognition (SPR) uses Artificial\nIntelligence (AI) to segment the surgical workflow into its key events,\nfunctioning as a building block for efficient video review, surgical education\nas well as skill assessment. Previous research has focused on short and linear\nsurgical procedures and has not explored if temporal context influences\nexperts' ability to better classify surgical phases. This research addresses\nthese gaps, focusing on Robot-Assisted Partial Nephrectomy (RAPN) as a highly\nnon-linear procedure. Methods: Urologists of varying expertise were grouped and\ntasked to indicate the surgical phase for RAPN on both single frames and video\nsnippets using a custom-made web platform. Participants reported their\nconfidence levels and the visual landmarks used in their decision-making. AI\narchitectures without and with temporal context as trained and benchmarked on\nthe Cholec80 dataset were subsequently trained on this RAPN dataset. Results:\nVideo snippets and presence of specific visual landmarks improved phase\nclassification accuracy across all groups. Surgeons displayed high confidence\nin their classifications and outperformed novices, who struggled discriminating\nphases. The performance of the AI models is comparable to the surgeons in the\nsurvey, with improvements when temporal context was incorporated in both cases.\nConclusion: SPR is an inherently complex task for expert surgeons and computer\nvision, where both perform equally well when given the same context.\nPerformance increases when temporal information is provided. Surgical tools and\norgans form the key landmarks for human interpretation and are expected to\nshape the future of automated SPR.", "AI": {"tldr": "Automated Surgical Phase Recognition (SPR) improves with temporal context and visual landmarks, matching expert surgeons' performance when AI includes temporal data.", "motivation": "To explore if temporal context enhances SPR accuracy in non-linear procedures like RAPN, addressing gaps in prior research focused on linear surgeries.", "method": "Urologists classified RAPN phases on frames/video snippets; AI models (with/without temporal context) were trained on RAPN and benchmarked on Cholec80.", "result": "Video snippets and landmarks boosted accuracy; surgeons outperformed novices. AI matched surgeons when temporal context was included.", "conclusion": "SPR is complex but improves with temporal context. Key landmarks (tools/organs) are crucial for humans and future AI in SPR."}}
{"id": "2504.18762", "pdf": "https://arxiv.org/pdf/2504.18762", "abs": "https://arxiv.org/abs/2504.18762", "authors": ["Ojasw Upadhyay", "Abishek Saravankumar", "Ayman Ismail"], "title": "SynLexLM: Scaling Legal LLMs with Synthetic Data and Curriculum Learning", "categories": ["cs.CL", "cs.LG"], "comment": "9 pages, 4 figures, 4 tables", "summary": "Large Language Models (LLMs) are powerful but often require extensive\nfine-tuning and large datasets for specialized domains like law.\nGeneral-purpose pre-training may not capture legal nuances, and acquiring\nsufficient legal data is challenging. We introduce SynLexLM, a novel approach\nto efficiently pre-train a legal LLM. Our method employs curriculum learning,\nprogressing from simple to complex legal texts and queries, combined with\nsynthetic data augmentation using models like Gemini Pro to address data\nscarcity. We aim to achieve improved performance on legal benchmarks\n(BigLaw-Bench, EUR-Lex-Sum) compared to traditional models and fine-tuned\nversions. Preliminary work involves generating synthetic QA pairs reflecting\nlegal reasoning. This work aims to enhance legal document analysis and research\ntools, potentially democratizing access to advanced legal AI.", "AI": {"tldr": "SynLexLM is a novel method for pre-training legal LLMs using curriculum learning and synthetic data augmentation to improve performance on legal tasks.", "motivation": "General-purpose LLMs lack legal nuance, and acquiring sufficient legal data is challenging. SynLexLM aims to address these issues.", "method": "Uses curriculum learning (simple to complex legal texts) and synthetic data augmentation (e.g., Gemini Pro) to pre-train the model.", "result": "Aims to outperform traditional models and fine-tuned versions on legal benchmarks like BigLaw-Bench and EUR-Lex-Sum.", "conclusion": "SynLexLM could enhance legal document analysis and democratize access to advanced legal AI tools."}}
{"id": "2504.19146", "pdf": "https://arxiv.org/pdf/2504.19146", "abs": "https://arxiv.org/abs/2504.19146", "authors": ["Xin Li", "Kaikai Jia", "Hao Sun", "Jun Dai", "Ziyang Jiang"], "title": "Muyan-TTS: A Trainable Text-to-Speech Model Optimized for Podcast Scenarios with a $50K Budget", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Recent advancements in text-to-speech (TTS) models have been driven by the\nintegration of large language models (LLMs), enhancing semantic comprehension\nand improving speech naturalness. However, existing LLM-based TTS models often\nlack open-source training code and efficient inference acceleration frameworks,\nlimiting their accessibility and adaptability. Additionally, there is no\npublicly available TTS model specifically optimized for podcast scenarios,\nwhich are in high demand for voice interaction applications. To address these\nlimitations, we introduce Muyan-TTS, an open-source trainable TTS model\ndesigned for podcast applications within a $50,000 budget. Our model is\npre-trained on over 100,000 hours of podcast audio data, enabling zero-shot TTS\nsynthesis with high-quality voice generation. Furthermore, Muyan-TTS supports\nspeaker adaptation with dozens of minutes of target speech, making it highly\ncustomizable for individual voices. In addition to open-sourcing the model, we\nprovide a comprehensive data collection and processing pipeline, a full\ntraining procedure, and an optimized inference framework that accelerates\nLLM-based TTS synthesis. Our code and models are available at\nhttps://github.com/MYZY-AI/Muyan-TTS.", "AI": {"tldr": "Muyan-TTS is an open-source, budget-friendly TTS model optimized for podcast scenarios, offering high-quality voice generation and speaker adaptation.", "motivation": "Addressing the lack of open-source training code, efficient inference frameworks, and podcast-optimized TTS models in existing LLM-based TTS solutions.", "method": "Pre-trained on 100k+ hours of podcast audio, Muyan-TTS supports zero-shot synthesis and speaker adaptation with minimal data.", "result": "Delivers high-quality TTS synthesis and customizable voice generation, with open-sourced code, data pipeline, and optimized inference.", "conclusion": "Muyan-TTS fills a gap in accessible, adaptable, and podcast-focused TTS solutions, backed by open-source resources."}}
{"id": "2504.19818", "pdf": "https://arxiv.org/pdf/2504.19818", "abs": "https://arxiv.org/abs/2504.19818", "authors": ["Feng Chen", "Ilias Stogiannidis", "Andrew Wood", "Danilo Bueno", "Dominic Williams", "Fraser Macfarlane", "Bruce Grieve", "Darren Wells", "Jonathan A. Atkinson", "Malcolm J. Hawkesford", "Stephen A. Rolfe", "Tracy Lawson", "Tony Pridmore", "Mario Valerio Giuffrida", "Sotirios A. Tsaftaris"], "title": "PhenoAssistant: A Conversational Multi-Agent AI System for Automated Plant Phenotyping", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Plant phenotyping increasingly relies on (semi-)automated image-based\nanalysis workflows to improve its accuracy and scalability. However, many\nexisting solutions remain overly complex, difficult to reimplement and\nmaintain, and pose high barriers for users without substantial computational\nexpertise. To address these challenges, we introduce PhenoAssistant: a\npioneering AI-driven system that streamlines plant phenotyping via intuitive\nnatural language interaction. PhenoAssistant leverages a large language model\nto orchestrate a curated toolkit supporting tasks including automated phenotype\nextraction, data visualisation and automated model training. We validate\nPhenoAssistant through several representative case studies and a set of\nevaluation tasks. By significantly lowering technical hurdles, PhenoAssistant\nunderscores the promise of AI-driven methodologies to democratising AI adoption\nin plant biology.", "AI": {"tldr": "PhenoAssistant is an AI-driven system simplifying plant phenotyping through natural language interaction, making it accessible to non-experts.", "motivation": "Existing plant phenotyping tools are complex and hard to use, limiting accessibility for non-experts.", "method": "PhenoAssistant uses a large language model to manage tasks like phenotype extraction, visualization, and model training.", "result": "Validated through case studies and evaluations, it lowers technical barriers in plant biology.", "conclusion": "PhenoAssistant demonstrates AI's potential to democratize plant phenotyping."}}
{"id": "2504.19605", "pdf": "https://arxiv.org/pdf/2504.19605", "abs": "https://arxiv.org/abs/2504.19605", "authors": ["Kohei Saijo", "Tetsuji Ogawa"], "title": "A Comparative Study on Positional Encoding for Time-frequency Domain Dual-path Transformer-based Source Separation Models", "categories": ["eess.AS", "cs.SD"], "comment": "5 pages, 3 tables, 2 figures", "summary": "In this study, we investigate the impact of positional encoding (PE) on\nsource separation performance and the generalization ability to long sequences\n(length extrapolation) in Transformer-based time-frequency (TF) domain\ndual-path models. The length extrapolation capability in TF-domain dual-path\nmodels is a crucial factor, as it affects not only their performance on\nlong-duration inputs but also their generalizability to signals with unseen\nsampling rates. While PE is known to significantly impact length extrapolation,\nthere has been limited research that explores the choice of PEs for TF-domain\ndual-path models from this perspective. To address this gap, we compare various\nPE methods using a recent state-of-the-art model, TF-Locoformer, as the base\narchitecture. Our analysis yields the following key findings: (i) When handling\nsequences that are the same length as or shorter than those seen during\ntraining, models with PEs achieve better performance. (ii) However, models\nwithout PE exhibit superior length extrapolation. This trend is particularly\npronounced when the model contains convolutional layers.", "AI": {"tldr": "PE improves performance for sequences of training length but harms length extrapolation, especially with convolutional layers.", "motivation": "Explore the impact of PE on source separation and length extrapolation in TF-domain dual-path Transformer models.", "method": "Compare various PE methods using TF-Locoformer as the base architecture.", "result": "PE boosts performance for trained lengths but reduces extrapolation ability, notably with convolutional layers.", "conclusion": "PE choice is critical for balancing performance and generalization in TF-domain models."}}
{"id": "2504.18684", "pdf": "https://arxiv.org/pdf/2504.18684", "abs": "https://arxiv.org/abs/2504.18684", "authors": ["Nader Zantout", "Haochen Zhang", "Pujith Kachana", "Jinkai Qiu", "Ji Zhang", "Wenshan Wang"], "title": "SORT3D: Spatial Object-centric Reasoning Toolbox for Zero-Shot 3D Grounding Using Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "7 pages, 6 figures, submitted to IROS 2025", "summary": "Interpreting object-referential language and grounding objects in 3D with\nspatial relations and attributes is essential for robots operating alongside\nhumans. However, this task is often challenging due to the diversity of scenes,\nlarge number of fine-grained objects, and complex free-form nature of language\nreferences. Furthermore, in the 3D domain, obtaining large amounts of natural\nlanguage training data is difficult. Thus, it is important for methods to learn\nfrom little data and zero-shot generalize to new environments. To address these\nchallenges, we propose SORT3D, an approach that utilizes rich object attributes\nfrom 2D data and merges a heuristics-based spatial reasoning toolbox with the\nability of large language models (LLMs) to perform sequential reasoning.\nImportantly, our method does not require text-to-3D data for training and can\nbe applied zero-shot to unseen environments. We show that SORT3D achieves\nstate-of-the-art performance on complex view-dependent grounding tasks on two\nbenchmarks. We also implement the pipeline to run real-time on an autonomous\nvehicle and demonstrate that our approach can be used for object-goal\nnavigation on previously unseen real-world environments. All source code for\nthe system pipeline is publicly released at https://github.com/nzantout/SORT3D .", "AI": {"tldr": "SORT3D combines 2D object attributes, spatial reasoning, and LLMs for zero-shot 3D object grounding without needing text-to-3D training data.", "motivation": "Addressing challenges in 3D object grounding due to scene diversity, fine-grained objects, and limited natural language training data.", "method": "Uses 2D object attributes, spatial reasoning heuristics, and LLMs for sequential reasoning, requiring no text-to-3D training.", "result": "Achieves state-of-the-art performance on view-dependent grounding tasks and works in real-time on an autonomous vehicle.", "conclusion": "SORT3D is effective for zero-shot generalization in unseen environments, with practical applications in robotics."}}
{"id": "2504.18562", "pdf": "https://arxiv.org/pdf/2504.18562", "abs": "https://arxiv.org/abs/2504.18562", "authors": ["Ayoub Jadouli", "Chaker El Amrani"], "title": "Deep Learning with Pretrained 'Internal World' Layers: A Gemma 3-Based Modular Architecture for Wildfire Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep learning models, especially large Transformers, carry substantial\n\"memory\" in their intermediate layers -- an \\emph{internal world} that encodes\na wealth of relational and contextual knowledge. This work harnesses that\ninternal world for wildfire occurrence prediction by introducing a modular\narchitecture built upon Gemma 3, a state-of-the-art multimodal model. Rather\nthan relying on Gemma 3's original embedding and positional encoding stacks, we\ndevelop a custom feed-forward module that transforms tabular wildfire features\ninto the hidden dimension required by Gemma 3's mid-layer Transformer blocks.\nWe freeze these Gemma 3 sub-layers -- thus preserving their pretrained\nrepresentation power -- while training only the smaller input and output\nnetworks. This approach minimizes the number of trainable parameters and\nreduces the risk of overfitting on limited wildfire data, yet retains the\nbenefits of Gemma 3's broad knowledge. Evaluations on a Moroccan wildfire\ndataset demonstrate improved predictive accuracy and robustness compared to\nstandard feed-forward and convolutional baselines. Ablation studies confirm\nthat the frozen Transformer layers consistently contribute to better\nrepresentations, underscoring the feasibility of reusing large-model mid-layers\nas a learned internal world. Our findings suggest that strategic modular reuse\nof pretrained Transformers can enable more data-efficient and interpretable\nsolutions for critical environmental applications such as wildfire risk\nmanagement.", "AI": {"tldr": "The paper introduces a modular architecture using Gemma 3's frozen Transformer layers for wildfire prediction, improving accuracy and robustness with fewer trainable parameters.", "motivation": "To leverage the rich internal representations of large Transformers (like Gemma 3) for wildfire prediction while avoiding overfitting on limited data.", "method": "A custom feed-forward module transforms tabular wildfire features into Gemma 3's hidden dimensions, freezing its mid-layers and training only smaller input/output networks.", "result": "Improved predictive accuracy and robustness on a Moroccan wildfire dataset compared to baseline models, with frozen Transformer layers enhancing representations.", "conclusion": "Strategic reuse of pretrained Transformer mid-layers enables data-efficient and interpretable solutions for environmental applications like wildfire risk management."}}
{"id": "2504.18631", "pdf": "https://arxiv.org/pdf/2504.18631", "abs": "https://arxiv.org/abs/2504.18631", "authors": ["Dingxin Lu", "Shurui Wu", "Xinyi Huang"], "title": "Research on Personalized Medical Intervention Strategy Generation System based on Group Relative Policy Optimization and Time-Series Data Fusion", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "With the timely formation of personalized intervention plans based on\nhigh-dimensional heterogeneous time series information becoming an important\nchallenge in the medical field today, electronic medical records, wearables,\nand other multi-source medical data are increasingly generated and diversified.\nIn this work, we develop a system to generate personalized medical intervention\nstrategies based on Group Relative Policy Optimization (GRPO) and Time-Series\nData Fusion. First, by incorporating relative policy constraints among the\ngroups during policy gradient updates, we adaptively balance individual and\ngroup gains. To improve the robustness and interpretability of decision-making,\na multi-layer neural network structure is employed to group-code patient\ncharacteristics. Second, for the rapid multi-modal fusion of multi-source\nheterogeneous time series, a multi-channel neural network combined with a\nself-attention mechanism is used for dynamic feature extraction. Key feature\nscreening and aggregation are achieved through a differentiable gating network.\nFinally, a collaborative search process combining a genetic algorithm and Monte\nCarlo tree search is proposed to find the ideal intervention strategy,\nachieving global optimization. Experimental results show significant\nimprovements in accuracy, coverage, and decision-making benefits compared with\nexisting methods.", "AI": {"tldr": "A system using GRPO and time-series data fusion generates personalized medical interventions, balancing individual and group gains, with improved accuracy and decision-making benefits.", "motivation": "Address the challenge of forming timely, personalized intervention plans from high-dimensional, heterogeneous medical data.", "method": "Uses GRPO for policy updates, multi-layer neural networks for patient grouping, multi-channel networks with self-attention for data fusion, and a genetic algorithm with Monte Carlo tree search for strategy optimization.", "result": "Significant improvements in accuracy, coverage, and decision-making benefits over existing methods.", "conclusion": "The proposed system effectively generates personalized medical interventions, outperforming current approaches."}}
{"id": "2504.18782", "pdf": "https://arxiv.org/pdf/2504.18782", "abs": "https://arxiv.org/abs/2504.18782", "authors": ["Hang Yu", "Jiahao Wen", "Zhedong Zheng"], "title": "CAMeL: Cross-modality Adaptive Meta-Learning for Text-based Person Retrieval", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Text-based person retrieval aims to identify specific individuals within an\nimage database using textual descriptions. Due to the high cost of annotation\nand privacy protection, researchers resort to synthesized data for the paradigm\nof pretraining and fine-tuning. However, these generated data often exhibit\ndomain biases in both images and textual annotations, which largely compromise\nthe scalability of the pre-trained model. Therefore, we introduce a\ndomain-agnostic pretraining framework based on Cross-modality Adaptive\nMeta-Learning (CAMeL) to enhance the model generalization capability during\npretraining to facilitate the subsequent downstream tasks. In particular, we\ndevelop a series of tasks that reflect the diversity and complexity of\nreal-world scenarios, and introduce a dynamic error sample memory unit to\nmemorize the history for errors encountered within multiple tasks. To further\nensure multi-task adaptation, we also adopt an adaptive dual-speed update\nstrategy, balancing fast adaptation to new tasks and slow weight updates for\nhistorical tasks. Albeit simple, our proposed model not only surpasses existing\nstate-of-the-art methods on real-world benchmarks, including CUHK-PEDES,\nICFG-PEDES, and RSTPReid, but also showcases robustness and scalability in\nhandling biased synthetic images and noisy text annotations. Our code is\navailable at https://github.com/Jahawn-Wen/CAMeL-reID.", "AI": {"tldr": "A domain-agnostic pretraining framework (CAMeL) is introduced to address domain biases in synthesized data for text-based person retrieval, improving model generalization and downstream task performance.", "motivation": "High annotation costs and privacy concerns lead to synthesized data, but domain biases in such data limit model scalability.", "method": "CAMeL uses cross-modality adaptive meta-learning, dynamic error memory, and dual-speed updates for multi-task adaptation.", "result": "CAMeL outperforms state-of-the-art methods on benchmarks (CUHK-PEDES, ICFG-PEDES, RSTPReid) and handles biased/noisy data robustly.", "conclusion": "CAMeL enhances generalization and scalability, proving effective for real-world text-based person retrieval tasks."}}
{"id": "2504.19119", "pdf": "https://arxiv.org/pdf/2504.19119", "abs": "https://arxiv.org/abs/2504.19119", "authors": ["Wei Jiang", "Yongqi Zhai", "Jiayu Yang", "Feng Gao", "Ronggang Wang"], "title": "MLICv2: Enhanced Multi-Reference Entropy Modeling for Learned Image Compression", "categories": ["eess.IV"], "comment": "Under Review", "summary": "Recent advancements in learned image compression (LIC) have yielded\nimpressive performance gains. Notably, the learned image compression models\nwith multi-reference entropy models (MLIC series) have significantly\noutperformed existing traditional image codecs such as the Versatile Video\nCoding (VVC) Intra. In this paper, we present MLICv2 and MLICv2$^+$, enhanced\nversions of the MLIC series, featuring improved transform techniques, entropy\nmodeling, and instance adaptability. For better transform, we introduce a\nsimple token mixing transform block inspired by the meta transformer\narchitecture, addressing the performance degradation at high bit-rates observed\nin previous MLIC series while maintaining computational efficiency. To enhance\nentropy modeling, we propose a hyperprior-guided global correlation prediction,\nenabling the capture of global contexts in the initial slice of the latent\nrepresentation. We also develop a channel reweighting module to dynamically\nprioritize important channels within each context. Additionally, advanced\npositional embedding for context modeling and selective compression with guided\noptimization are investigated. To boost instance adaptability, we employ\nstochastic Gumbel annealing to iteratively refine the latent representation\naccording to the rate-distortion optimization of a specific input image. This\napproach further enhances performance without impacting decoding speed.\nExperimental results demonstrate that our MLICv2 and MLICv2$^+$ achieve\nstate-of-the-art performance, reducing Bjontegaard-Delta rate (BD-rate) by\n16.54%, 21.61%, 16.05% and 20.46%, 24.35%, 19.14% respectively, compared to\nVTM-17.0 Intra on the Kodak, Tecnick, CLIC Pro Val dataset, respectively.", "AI": {"tldr": "MLICv2 and MLICv2+ improve learned image compression with enhanced transform, entropy modeling, and instance adaptability, outperforming VVC Intra significantly.", "motivation": "To address performance degradation at high bit-rates and improve global context capture in learned image compression.", "method": "Introduces token mixing transform, hyperprior-guided global correlation prediction, channel reweighting, and stochastic Gumbel annealing.", "result": "Reduces BD-rate by 16.54%-24.35% compared to VTM-17.0 Intra on benchmark datasets.", "conclusion": "MLICv2 and MLICv2+ achieve state-of-the-art performance in learned image compression."}}
{"id": "2504.18805", "pdf": "https://arxiv.org/pdf/2504.18805", "abs": "https://arxiv.org/abs/2504.18805", "authors": ["Jong Inn Park", "Maanas Taneja", "Qianwen Wang", "Dongyeop Kang"], "title": "Stealing Creator's Workflow: A Creator-Inspired Agentic Framework with Iterative Feedback Loop for Improved Scientific Short-form Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Project page: https://minnesotanlp.github.io/scitalk-project-page/", "summary": "Generating engaging, accurate short-form videos from scientific papers is\nchallenging due to content complexity and the gap between expert authors and\nreaders. Existing end-to-end methods often suffer from factual inaccuracies and\nvisual artifacts, limiting their utility for scientific dissemination. To\naddress these issues, we propose SciTalk, a novel multi-LLM agentic framework,\ngrounding videos in various sources, such as text, figures, visual styles, and\navatars. Inspired by content creators' workflows, SciTalk uses specialized\nagents for content summarization, visual scene planning, and text and layout\nediting, and incorporates an iterative feedback mechanism where video agents\nsimulate user roles to give feedback on generated videos from previous\niterations and refine generation prompts. Experimental evaluations show that\nSciTalk outperforms simple prompting methods in generating scientifically\naccurate and engaging content over the refined loop of video generation.\nAlthough preliminary results are still not yet matching human creators'\nquality, our framework provides valuable insights into the challenges and\nbenefits of feedback-driven video generation. Our code, data, and generated\nvideos will be publicly available.", "AI": {"tldr": "SciTalk is a multi-LLM framework for generating accurate and engaging short-form videos from scientific papers, using iterative feedback to improve quality.", "motivation": "Existing methods for video generation from papers often produce inaccuracies and visual flaws, hindering scientific dissemination.", "method": "SciTalk employs specialized agents for summarization, scene planning, and editing, with iterative feedback from simulated users.", "result": "SciTalk outperforms simple prompting methods in accuracy and engagement, though it doesn't yet match human creators.", "conclusion": "The framework offers insights into feedback-driven video generation, with plans to release code, data, and videos."}}
{"id": "2504.19197", "pdf": "https://arxiv.org/pdf/2504.19197", "abs": "https://arxiv.org/abs/2504.19197", "authors": ["Sandipan Dhar", "Nanda Dulal Jana", "Swagatam Das"], "title": "Generative Adversarial Network based Voice Conversion: Techniques, Challenges, and Recent Advancements", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "19 pages, 12 figures, 1 table", "summary": "Voice conversion (VC) stands as a crucial research area in speech synthesis,\nenabling the transformation of a speaker's vocal characteristics to resemble\nanother while preserving the linguistic content. This technology has broad\napplications, including automated movie dubbing, speech-to-singing conversion,\nand assistive devices for pathological speech rehabilitation. With the\nincreasing demand for high-quality and natural-sounding synthetic voices,\nresearchers have developed a wide range of VC techniques. Among these,\ngenerative adversarial network (GAN)-based approaches have drawn considerable\nattention for their powerful feature-mapping capabilities and potential to\nproduce highly realistic speech. Despite notable advancements, challenges such\nas ensuring training stability, maintaining linguistic consistency, and\nachieving perceptual naturalness continue to hinder progress in GAN-based VC\nsystems. This systematic review presents a comprehensive analysis of the voice\nconversion landscape, highlighting key techniques, key challenges, and the\ntransformative impact of GANs in the field. The survey categorizes existing\nmethods, examines technical obstacles, and critically evaluates recent\ndevelopments in GAN-based VC. By consolidating and synthesizing research\nfindings scattered across the literature, this review provides a structured\nunderstanding of the strengths and limitations of different approaches. The\nsignificance of this survey lies in its ability to guide future research by\nidentifying existing gaps, proposing potential directions, and offering\ninsights for building more robust and efficient VC systems. Overall, this work\nserves as an essential resource for researchers, developers, and practitioners\naiming to advance the state-of-the-art (SOTA) in voice conversion technology.", "AI": {"tldr": "A systematic review of voice conversion (VC) technologies, focusing on GAN-based approaches, their challenges, and future research directions.", "motivation": "The increasing demand for high-quality synthetic voices in applications like movie dubbing and speech rehabilitation drives the need for advanced VC techniques.", "method": "The paper categorizes and analyzes existing VC methods, particularly GAN-based approaches, and evaluates their technical challenges and recent advancements.", "result": "GAN-based VC shows promise but faces issues like training stability, linguistic consistency, and perceptual naturalness. The review consolidates research to guide future work.", "conclusion": "This survey serves as a resource to advance VC technology by identifying gaps and proposing directions for more robust systems."}}
{"id": "2504.18603", "pdf": "https://arxiv.org/pdf/2504.18603", "abs": "https://arxiv.org/abs/2504.18603", "authors": ["Iizalaarab Elhaimeur", "Nikos Chrisochoides"], "title": "Toward Personalizing Quantum Computing Education: An Evolutionary LLM-Powered Approach", "categories": ["cs.CY", "cs.AI", "cs.MA"], "comment": null, "summary": "Quantum computing education faces significant challenges due to its\ncomplexity and the limitations of current tools; this paper introduces a novel\nIntelligent Teaching Assistant for quantum computing education and details its\nevolutionary design process. The system combines a knowledge-graph-augmented\narchitecture with two specialized Large Language Model (LLM) agents: a Teaching\nAgent for dynamic interaction, and a Lesson Planning Agent for lesson plan\ngeneration. The system is designed to adapt to individual student needs, with\ninteractions meticulously tracked and stored in a knowledge graph. This graph\nrepresents student actions, learning resources, and relationships, aiming to\nenable reasoning about effective learning pathways. We describe the\nimplementation of the system, highlighting the challenges encountered and the\nsolutions implemented, including introducing a dual-agent architecture where\ntasks are separated, all coordinated through a central knowledge graph that\nmaintains system awareness, and a user-facing tag system intended to mitigate\nLLM hallucination and improve user control. Preliminary results illustrate the\nsystem's potential to capture rich interaction data, dynamically adapt lesson\nplans based on student feedback via a tag system in simulation, and facilitate\ncontext-aware tutoring through the integrated knowledge graph, though\nsystematic evaluation is required.", "AI": {"tldr": "A novel Intelligent Teaching Assistant for quantum computing education uses a knowledge-graph-augmented architecture with dual LLM agents for dynamic teaching and lesson planning, adapting to student needs and tracking interactions.", "motivation": "Addressing the complexity and tool limitations in quantum computing education by developing an adaptive, intelligent teaching system.", "method": "Combines a knowledge-graph-augmented architecture with two LLM agents (Teaching Agent and Lesson Planning Agent) and a user-facing tag system to mitigate LLM issues.", "result": "Preliminary results show potential for capturing interaction data, adapting lesson plans, and enabling context-aware tutoring, though further evaluation is needed.", "conclusion": "The system demonstrates promise for enhancing quantum computing education but requires systematic evaluation for broader applicability."}}
{"id": "2504.18650", "pdf": "https://arxiv.org/pdf/2504.18650", "abs": "https://arxiv.org/abs/2504.18650", "authors": ["Bruce Collins"], "title": "Unsupervised outlier detection to improve bird audio dataset labels", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": "27 pages, 9 figures", "summary": "The Xeno-Canto bird audio repository is an invaluable resource for those\ninterested in vocalizations and other sounds made by birds around the world.\nThis is particularly the case for machine learning researchers attempting to\nimprove on the bird species recognition accuracy of classification models.\nHowever, the task of extracting labeled datasets from the recordings found in\nthis crowd-sourced repository faces several challenges. One challenge of\nparticular significance to machine learning practitioners is that one bird\nspecies label is applied to each audio recording, but frequently other sounds\nare also captured including other bird species, other animal sounds,\nanthropogenic and other ambient sounds. These non-target bird species sounds\ncan result in dataset labeling discrepancies referred to as label noise. In\nthis work we present a cleaning process consisting of audio preprocessing\nfollowed by dimensionality reduction and unsupervised outlier detection (UOD)\nto reduce the label noise in a dataset derived from Xeno-Canto recordings. We\ninvestigate three neural network dimensionality reduction techniques: two\nflavors of convolutional autoencoders and variational deep embedding (VaDE\n(Jiang, 2017)). While both methods show some degree of effectiveness at\ndetecting outliers for most bird species datasets, we found significant\nvariation in the performance of the methods from one species to the next. We\nbelieve that the results of this investigation demonstrate that the application\nof our cleaning process can meaningfully reduce the label noise of bird species\ndatasets derived from Xeno-Canto audio repository but results vary across\nspecies.", "AI": {"tldr": "A cleaning process using audio preprocessing, dimensionality reduction, and unsupervised outlier detection is proposed to reduce label noise in bird species datasets from Xeno-Canto. Performance varies across species.", "motivation": "The Xeno-Canto repository is valuable for bird vocalization research but suffers from label noise due to non-target sounds in recordings.", "method": "Audio preprocessing, dimensionality reduction (convolutional autoencoders and VaDE), and unsupervised outlier detection are used to clean datasets.", "result": "The methods reduce label noise but show varying effectiveness across different bird species.", "conclusion": "The cleaning process can meaningfully reduce label noise, though results are species-dependent."}}
{"id": "2504.18689", "pdf": "https://arxiv.org/pdf/2504.18689", "abs": "https://arxiv.org/abs/2504.18689", "authors": ["Apoorva Beedu", "Irfan Essa"], "title": "HierSum: A Global and Local Attention Mechanism for Video Summarization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Video summarization creates an abridged version (i.e., a summary) that\nprovides a quick overview of the video while retaining pertinent information.\nIn this work, we focus on summarizing instructional videos and propose a method\nfor breaking down a video into meaningful segments, each corresponding to\nessential steps in the video. We propose \\textbf{HierSum}, a hierarchical\napproach that integrates fine-grained local cues from subtitles with global\ncontextual information provided by video-level instructions. Our approach\nutilizes the ``most replayed\" statistic as a supervisory signal to identify\ncritical segments, thereby improving the effectiveness of the summary. We\nevaluate on benchmark datasets such as TVSum, BLiSS, Mr.HiSum, and the WikiHow\ntest set, and show that HierSum consistently outperforms existing methods in\nkey metrics such as F1-score and rank correlation. We also curate a new\nmulti-modal dataset using WikiHow and EHow videos and associated articles\ncontaining step-by-step instructions. Through extensive ablation studies, we\ndemonstrate that training on this dataset significantly enhances summarization\non the target datasets.", "AI": {"tldr": "HierSum is a hierarchical video summarization method for instructional videos, combining local subtitle cues and global context, outperforming benchmarks in F1-score and rank correlation.", "motivation": "To create effective summaries of instructional videos by identifying essential steps and leveraging multimodal data.", "method": "HierSum integrates fine-grained subtitle cues with video-level instructions, using \"most replayed\" statistics as supervision.", "result": "HierSum outperforms existing methods on TVSum, BLiSS, Mr.HiSum, and WikiHow datasets, and a new curated dataset enhances performance.", "conclusion": "HierSum is effective for instructional video summarization, with multimodal training data further improving results."}}
{"id": "2504.18574", "pdf": "https://arxiv.org/pdf/2504.18574", "abs": "https://arxiv.org/abs/2504.18574", "authors": ["Aviv Bick", "Eric Xing", "Albert Gu"], "title": "Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "SSMs offer efficient processing of long sequences with fixed state sizes, but\nstruggle with algorithmic tasks like retrieving past context. In this work, we\nexamine how such in-context retrieval operates within Transformer- and\nSSM-based language models. We find that both architectures develop the same\nfundamental Gather-and-Aggregate (G&A) mechanism. A Gather Head first\nidentifies and extracts relevant information from the context, which an\nAggregate Head then integrates into a final representation. Across both model\ntypes, G&A concentrates in just a few heads, making them critical bottlenecks\neven for benchmarks that require a basic form of retrieval. For example,\ndisabling a single Gather or Aggregate Head of a pruned Llama-3.1-8B degrades\nits ability to retrieve the correct answer letter in MMLU, reducing accuracy\nfrom 66% to 25%. This finding suggests that in-context retrieval can obscure\nthe limited knowledge demands of certain tasks. Despite strong MMLU performance\nwith retrieval intact, the pruned model fails on other knowledge tests. Similar\nG&A dependencies exist in GSM8K, BBH, and dialogue tasks. Given the\nsignificance of G&A in performance, we show that retrieval challenges in SSMs\nmanifest in how they implement G&A, leading to smoother attention patterns\nrather than the sharp token transitions that effective G&A relies on. Thus,\nwhile a gap exists between Transformers and SSMs in implementing in-context\nretrieval, it is confined to a few heads, not the entire model. This insight\nsuggests a unified explanation for performance differences between Transformers\nand SSMs while also highlighting ways to combine their strengths. For example,\nin pretrained hybrid models, attention components naturally take on the role of\nAggregate Heads. Similarly, in a pretrained pure SSM, replacing a single G&A\nhead with an attention-based variant significantly improves retrieval.", "AI": {"tldr": "The paper examines in-context retrieval in Transformer- and SSM-based models, identifying a shared Gather-and-Aggregate (G&A) mechanism critical for performance. Disabling G&A heads significantly impacts tasks like MMLU, revealing retrieval challenges in SSMs due to smoother attention patterns. Hybrid models or attention-based replacements can improve retrieval.", "motivation": "To understand how in-context retrieval operates in Transformer- and SSM-based models and identify performance bottlenecks.", "method": "Analyze the Gather-and-Aggregate (G&A) mechanism in both architectures, test its impact on tasks like MMLU, and explore hybrid solutions.", "result": "G&A is concentrated in few heads, and its disruption degrades performance. SSMs struggle with retrieval due to smoother attention patterns, but attention-based replacements can help.", "conclusion": "The gap between Transformers and SSMs in retrieval is confined to a few heads, suggesting hybrid models or targeted improvements can bridge the performance difference."}}
{"id": "2504.18651", "pdf": "https://arxiv.org/pdf/2504.18651", "abs": "https://arxiv.org/abs/2504.18651", "authors": ["Filipi Miranda Soares", "Antonio Mauro Saraiva", "Lu\u00eds Ferreira Pires", "Luiz Olavo Bonino da Silva Santos", "Dilvan de Abreu Moreira", "Fernando Elias Corr\u00eaa", "Kelly Rosa Braghetto", "Debora Pignatari Drucker", "Alexandre Cl\u00e1udio Botazzo Delbem"], "title": "Exploring a Large Language Model for Transforming Taxonomic Data into OWL: Lessons Learned and Implications for Ontology Development", "categories": ["cs.AI"], "comment": "31 pages, 6 Figures, accepted for publication in Data Intelligence", "summary": "Managing scientific names in ontologies that represent species taxonomies is\nchallenging due to the ever-evolving nature of these taxonomies. Manually\nmaintaining these names becomes increasingly difficult when dealing with\nthousands of scientific names. To address this issue, this paper investigates\nthe use of ChatGPT-4 to automate the development of the :Organism module in the\nAgricultural Product Types Ontology (APTO) for species classification. Our\nmethodology involved leveraging ChatGPT-4 to extract data from the GBIF\nBackbone API and generate OWL files for further integration in APTO. Two\nalternative approaches were explored: (1) issuing a series of prompts for\nChatGPT-4 to execute tasks via the BrowserOP plugin and (2) directing ChatGPT-4\nto design a Python algorithm to perform analogous tasks. Both approaches rely\non a prompting method where we provide instructions, context, input data, and\nan output indicator. The first approach showed scalability limitations, while\nthe second approach used the Python algorithm to overcome these challenges, but\nit struggled with typographical errors in data handling. This study highlights\nthe potential of Large language models like ChatGPT-4 to streamline the\nmanagement of species names in ontologies. Despite certain limitations, these\ntools offer promising advancements in automating taxonomy-related tasks and\nimproving the efficiency of ontology development.", "AI": {"tldr": "The paper explores using ChatGPT-4 to automate species name management in ontologies, comparing two methods: direct prompting and Python algorithm design, with mixed results.", "motivation": "The challenge of manually maintaining evolving species taxonomies in ontologies like APTO motivates the use of automation via ChatGPT-4.", "method": "Two approaches were tested: (1) direct prompting via BrowserOP and (2) designing a Python algorithm for data extraction and OWL file generation.", "result": "The first approach faced scalability issues, while the second struggled with data errors but showed potential for automation.", "conclusion": "ChatGPT-4 can aid ontology development despite limitations, offering efficiency improvements in taxonomy tasks."}}
{"id": "2504.19056", "pdf": "https://arxiv.org/pdf/2504.19056", "abs": "https://arxiv.org/abs/2504.19056", "authors": ["Mohammad Mahdi Abootorabi", "Omid Ghahroodi", "Pardis Sadat Zahraei", "Hossein Behzadasl", "Alireza Mirrokni", "Mobina Salimipanah", "Arash Rasouli", "Bahar Behzadipour", "Sara Azarnoush", "Benyamin Maleki", "Erfan Sadraiye", "Kiarash Kiani Feriz", "Mahdi Teymouri Nahad", "Ali Moghadasi", "Abolfazl Eshagh Abianeh", "Nizi Nazar", "Hamid R. Rabiee", "Mahdieh Soleymani Baghshah", "Meisam Ahmadi", "Ehsaneddin Asgari"], "title": "Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": "50 main pages, 30 pages appendix, 21 figures, 8 tables, GitHub\n  Repository:\n  https://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey", "summary": "Generative AI is reshaping art, gaming, and most notably animation. Recent\nbreakthroughs in foundation and diffusion models have reduced the time and cost\nof producing animated content. Characters are central animation components,\ninvolving motion, emotions, gestures, and facial expressions. The pace and\nbreadth of advances in recent months make it difficult to maintain a coherent\nview of the field, motivating the need for an integrative review. Unlike\nearlier overviews that treat avatars, gestures, or facial animation in\nisolation, this survey offers a single, comprehensive perspective on all the\nmain generative AI applications for character animation. We begin by examining\nthe state-of-the-art in facial animation, expression rendering, image\nsynthesis, avatar creation, gesture modeling, motion synthesis, object\ngeneration, and texture synthesis. We highlight leading research, practical\ndeployments, commonly used datasets, and emerging trends for each area. To\nsupport newcomers, we also provide a comprehensive background section that\nintroduces foundational models and evaluation metrics, equipping readers with\nthe knowledge needed to enter the field. We discuss open challenges and map\nfuture research directions, providing a roadmap to advance AI-driven\ncharacter-animation technologies. This survey is intended as a resource for\nresearchers and developers entering the field of generative AI animation or\nadjacent fields. Resources are available at:\nhttps://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey.", "AI": {"tldr": "A survey on generative AI applications for character animation, covering facial animation, gesture modeling, and more, with resources for newcomers.", "motivation": "The rapid advances in generative AI for animation create a need for an integrative review to provide a coherent view of the field.", "method": "Examines state-of-the-art in facial animation, expression rendering, avatar creation, etc., and provides foundational background and evaluation metrics.", "result": "Highlights leading research, practical deployments, datasets, and trends, while identifying open challenges.", "conclusion": "Offers a roadmap for future research and serves as a resource for newcomers in generative AI animation."}}
{"id": "2504.19203", "pdf": "https://arxiv.org/pdf/2504.19203", "abs": "https://arxiv.org/abs/2504.19203", "authors": ["Ehsan Karami", "Hamid Soltanian-Zadeh"], "title": "Improving Generalization in MRI-Based Deep Learning Models for Total Knee Replacement Prediction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Knee osteoarthritis (KOA) is a common joint disease that causes pain and\nmobility issues. While MRI-based deep learning models have demonstrated\nsuperior performance in predicting total knee replacement (TKR) and disease\nprogression, their generalizability remains challenging, particularly when\napplied to imaging data from different sources. In this study, we have shown\nthat replacing batch normalization with instance normalization, using data\naugmentation, and applying contrastive loss improves model generalization in a\nbaseline deep learning model for knee osteoarthritis (KOA) prediction. We\ntrained and evaluated our model using MRI data from the Osteoarthritis\nInitiative (OAI) database, considering sagittal fat-suppressed\nintermediate-weighted turbo spin-echo (FS-IW-TSE) images as the source domain\nand sagittal fat-suppressed three-dimensional (3D) dual-echo in steady state\n(DESS) images as the target domain. The results demonstrate a statistically\nsignificant improvement in classification accuracy across both domains, with\nour approach outperforming the baseline model.", "AI": {"tldr": "The paper improves deep learning model generalization for KOA prediction by replacing batch normalization with instance normalization, using data augmentation, and applying contrastive loss.", "motivation": "MRI-based deep learning models for KOA prediction lack generalizability across different imaging data sources.", "method": "Replaced batch normalization with instance normalization, used data augmentation, and applied contrastive loss. Evaluated on OAI database MRI data (FS-IW-TSE and DESS images).", "result": "Statistically significant improvement in classification accuracy across domains, outperforming the baseline model.", "conclusion": "The proposed enhancements improve model generalization for KOA prediction across diverse imaging data."}}
{"id": "2504.18838", "pdf": "https://arxiv.org/pdf/2504.18838", "abs": "https://arxiv.org/abs/2504.18838", "authors": ["Yixin Cao", "Shibo Hong", "Xinze Li", "Jiahao Ying", "Yubo Ma", "Haiyuan Liang", "Yantao Liu", "Zijun Yao", "Xiaozhi Wang", "Dan Huang", "Wenxuan Zhang", "Lifu Huang", "Muhao Chen", "Lei Hou", "Qianru Sun", "Xingjun Ma", "Zuxuan Wu", "Min-Yen Kan", "David Lo", "Qi Zhang", "Heng Ji", "Jing Jiang", "Juanzi Li", "Aixin Sun", "Xuanjing Huang", "Tat-Seng Chua", "Yu-Gang Jiang"], "title": "Toward Generalizable Evaluation in the LLM Era: A Survey Beyond Benchmarks", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are advancing at an amazing speed and have\nbecome indispensable across academia, industry, and daily applications. To keep\npace with the status quo, this survey probes the core challenges that the rise\nof LLMs poses for evaluation. We identify and analyze two pivotal transitions:\n(i) from task-specific to capability-based evaluation, which reorganizes\nbenchmarks around core competencies such as knowledge, reasoning, instruction\nfollowing, multi-modal understanding, and safety; and (ii) from manual to\nautomated evaluation, encompassing dynamic dataset curation and\n\"LLM-as-a-judge\" scoring.\n  Yet, even with these transitions, a crucial obstacle persists: the evaluation\ngeneralization issue. Bounded test sets cannot scale alongside models whose\nabilities grow seemingly without limit. We will dissect this issue, along with\nthe core challenges of the above two transitions, from the perspectives of\nmethods, datasets, evaluators, and metrics. Due to the fast evolving of this\nfield, we will maintain a living GitHub repository (links are in each section)\nto crowd-source updates and corrections, and warmly invite contributors and\ncollaborators.", "AI": {"tldr": "The survey explores challenges in evaluating Large Language Models (LLMs), focusing on transitions to capability-based and automated evaluation, while addressing the persistent issue of evaluation generalization.", "motivation": "To address the rapid advancement of LLMs and the need for updated evaluation methods that match their growing capabilities.", "method": "Analyzes transitions from task-specific to capability-based evaluation and from manual to automated evaluation, including dynamic datasets and LLM-as-a-judge scoring.", "result": "Identifies the evaluation generalization issue as a major obstacle, where bounded test sets fail to scale with LLMs' expanding abilities.", "conclusion": "Proposes ongoing updates via a GitHub repository to keep pace with the evolving field, inviting collaboration."}}
{"id": "2410.06016", "pdf": "https://arxiv.org/pdf/2410.06016", "abs": "https://arxiv.org/abs/2410.06016", "authors": ["Yunkee Chae", "Woosung Choi", "Yuhta Takida", "Junghyun Koo", "Yukara Ikemiya", "Zhi Zhong", "Kin Wai Cheuk", "Marco A. Mart\u00ednez-Ram\u00edrez", "Kyogu Lee", "Wei-Hsiang Liao", "Yuki Mitsufuji"], "title": "Variable Bitrate Residual Vector Quantization for Audio Coding", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "ICASSP 2025 camera ready version", "summary": "Recent state-of-the-art neural audio compression models have progressively\nadopted residual vector quantization (RVQ). Despite this success, these models\nemploy a fixed number of codebooks per frame, which can be suboptimal in terms\nof rate-distortion tradeoff, particularly in scenarios with simple input audio,\nsuch as silence. To address this limitation, we propose variable bitrate RVQ\n(VRVQ) for audio codecs, which allows for more efficient coding by adapting the\nnumber of codebooks used per frame. Furthermore, we propose a gradient\nestimation method for the non-differentiable masking operation that transforms\nfrom the importance map to the binary importance mask, improving model training\nvia a straight-through estimator. We demonstrate that the proposed training\nframework achieves superior results compared to the baseline method and shows\nfurther improvement when applied to the current state-of-the-art codec.", "AI": {"tldr": "Proposes VRVQ for adaptive codebook usage in audio compression, improving rate-distortion tradeoff, and introduces a gradient estimation method for better training.", "motivation": "Fixed codebook usage in RVQ is suboptimal for simple audio (e.g., silence), prompting adaptive solutions.", "method": "Introduces VRVQ for variable bitrate coding and a gradient estimation technique for non-differentiable masking.", "result": "VRVQ outperforms baselines and enhances state-of-the-art codecs.", "conclusion": "Adaptive codebook usage and improved training methods advance audio compression efficiency."}}
{"id": "2504.19912", "pdf": "https://arxiv.org/pdf/2504.19912", "abs": "https://arxiv.org/abs/2504.19912", "authors": ["Khachik Smbatyan", "Tsolak Ghukasyan", "Tigran Aghajanyan", "Hovhannes Dabaghyan", "Sergey Adamyan", "Aram Bughdaryan", "Vahagn Altunyan", "Gagik Navasardyan", "Aram Davtyan", "Anush Hakobyan", "Aram Gharibyan", "Arman Fahradyan", "Artur Hakobyan", "Hasmik Mnatsakanyan", "Narek Ginoyan", "Garik Petrosyan"], "title": "Can AI Agents Design and Implement Drug Discovery Pipelines?", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The rapid advancement of artificial intelligence, particularly autonomous\nagentic systems based on Large Language Models (LLMs), presents new\nopportunities to accelerate drug discovery by improving in-silico modeling and\nreducing dependence on costly experimental trials. Current AI agent-based\nsystems demonstrate proficiency in solving programming challenges and\nconducting research, indicating an emerging potential to develop software\ncapable of addressing complex problems such as pharmaceutical design and drug\ndiscovery. This paper introduces DO Challenge, a benchmark designed to evaluate\nthe decision-making abilities of AI agents in a single, complex problem\nresembling virtual screening scenarios. The benchmark challenges systems to\nindependently develop, implement, and execute efficient strategies for\nidentifying promising molecular structures from extensive datasets, while\nnavigating chemical space, selecting models, and managing limited resources in\na multi-objective context. We also discuss insights from the DO Challenge 2025,\na competition based on the proposed benchmark, which showcased diverse\nstrategies explored by human participants. Furthermore, we present the Deep\nThought multi-agent system, which demonstrated strong performance on the\nbenchmark, outperforming most human teams. Among the language models tested,\nClaude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles,\nand GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While\npromising, the system's performance still fell short of expert-designed\nsolutions and showed high instability, highlighting both the potential and\ncurrent limitations of AI-driven methodologies in transforming drug discovery\nand broader scientific research.", "AI": {"tldr": "The paper introduces the DO Challenge benchmark to evaluate AI agents' decision-making in drug discovery, highlighting the potential and limitations of AI-driven methods.", "motivation": "To accelerate drug discovery by leveraging AI agents' capabilities in solving complex problems like pharmaceutical design.", "method": "The DO Challenge benchmark tests AI agents in virtual screening scenarios, requiring them to develop strategies for identifying molecular structures. The Deep Thought multi-agent system was also evaluated.", "result": "The Deep Thought system outperformed most human teams, with Claude 3.7 Sonnet, Gemini 2.5 Pro, and o3 excelling in primary roles, and GPT-4o and Gemini 2.0 Flash in auxiliary roles. However, AI performance still lagged behind expert solutions and showed instability.", "conclusion": "AI-driven methods show promise in drug discovery but face limitations in stability and performance compared to expert-designed solutions."}}
{"id": "2411.18803", "pdf": "https://arxiv.org/pdf/2411.18803", "abs": "https://arxiv.org/abs/2411.18803", "authors": ["Haibin Wu", "Naoyuki Kanda", "Sefik Emre Eskimez", "Jinyu Li"], "title": "TS3-Codec: Transformer-Based Simple Streaming Single Codec", "categories": ["eess.AS"], "comment": null, "summary": "Neural audio codecs (NACs) have garnered significant attention as key\ntechnologies for audio compression as well as audio representation for speech\nlanguage models. While mainstream NAC models are predominantly\nconvolution-based, the performance of NACs with a purely transformer-based, and\nconvolution-free architecture remains unexplored. This paper introduces\nTS3-Codec, a Transformer-Based Simple Streaming Single Codec. TS3-Codec\nconsists of only a stack of transformer layers with a few linear layers,\noffering greater simplicity and expressiveness by fully eliminating convolution\nlayers that require careful hyperparameter tuning and large computations. Under\nthe streaming setup, the proposed TS3-Codec achieves comparable or superior\nperformance compared to the codec with state-of-the-art convolution-based\narchitecture while requiring only 12% of the computation and 77% of bitrate.\nFurthermore, it significantly outperforms the convolution-based codec when\nusing similar computational resources.", "AI": {"tldr": "TS3-Codec, a transformer-based audio codec, outperforms convolution-based models with less computation and bitrate.", "motivation": "To explore the potential of transformer-based architectures in neural audio codecs, which are typically convolution-based.", "method": "TS3-Codec uses a stack of transformer layers and linear layers, eliminating convolutions for simplicity and efficiency.", "result": "Achieves comparable or better performance than state-of-the-art convolution-based codecs with 12% computation and 77% bitrate.", "conclusion": "Transformer-based architectures like TS3-Codec offer a simpler, more efficient alternative to convolution-based audio codecs."}}
{"id": "2504.18738", "pdf": "https://arxiv.org/pdf/2504.18738", "abs": "https://arxiv.org/abs/2504.18738", "authors": ["Ranjan Sapkota", "Konstantinos I Roumeliotis", "Rahul Harsha Cheppally", "Marco Flores Calero", "Manoj Karkee"], "title": "A Review of 3D Object Detection with Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "This review provides a systematic analysis of comprehensive survey of 3D\nobject detection with vision-language models(VLMs) , a rapidly advancing area\nat the intersection of 3D vision and multimodal AI. By examining over 100\nresearch papers, we provide the first systematic analysis dedicated to 3D\nobject detection with vision-language models. We begin by outlining the unique\nchallenges of 3D object detection with vision-language models, emphasizing\ndifferences from 2D detection in spatial reasoning and data complexity.\nTraditional approaches using point clouds and voxel grids are compared to\nmodern vision-language frameworks like CLIP and 3D LLMs, which enable\nopen-vocabulary detection and zero-shot generalization. We review key\narchitectures, pretraining strategies, and prompt engineering methods that\nalign textual and 3D features for effective 3D object detection with\nvision-language models. Visualization examples and evaluation benchmarks are\ndiscussed to illustrate performance and behavior. Finally, we highlight current\nchallenges, such as limited 3D-language datasets and computational demands, and\npropose future research directions to advance 3D object detection with\nvision-language models. >Object Detection, Vision-Language Models, Agents,\nVLMs, LLMs, AI", "AI": {"tldr": "A systematic review of 3D object detection using vision-language models (VLMs), comparing traditional methods with modern frameworks like CLIP and 3D LLMs, and discussing challenges and future directions.", "motivation": "To address the unique challenges of 3D object detection with VLMs, such as spatial reasoning and data complexity, and to provide a comprehensive analysis of this emerging field.", "method": "Examines over 100 research papers, comparing traditional point cloud and voxel grid approaches with modern VLMs, and reviews architectures, pretraining strategies, and prompt engineering.", "result": "Highlights the capabilities of VLMs for open-vocabulary detection and zero-shot generalization, along with performance benchmarks.", "conclusion": "Identifies challenges like limited datasets and computational demands, and suggests future research directions to advance the field."}}
{"id": "2504.18578", "pdf": "https://arxiv.org/pdf/2504.18578", "abs": "https://arxiv.org/abs/2504.18578", "authors": ["Orhun Vural", "Bunyamin Ozaydin", "Khalid Y. Aram", "James Booth", "Brittany F. Lindsey", "Abdulaziz Ahmed"], "title": "An Artificial Intelligence-Based Framework for Predicting Emergency Department Overcrowding: Development and Evaluation Study", "categories": ["cs.LG", "68T07", "I.2.6; J.3"], "comment": null, "summary": "Background: Emergency department (ED) overcrowding remains a major challenge,\ncausing delays in care and increased operational strain. Hospital management\noften reacts to congestion after it occurs. Machine learning predictive\nmodeling offers a proactive approach by forecasting patient flow metrics, such\nas waiting count, to improve resource planning and hospital efficiency.\n  Objective: This study develops machine learning models to predict ED waiting\nroom occupancy at two time scales. The hourly model forecasts the waiting count\nsix hours ahead (e.g., a 1 PM prediction for 7 PM), while the daily model\nestimates the average waiting count for the next 24 hours (e.g., a 5 PM\nprediction for the following day's average). These tools support staffing\ndecisions and enable earlier interventions to reduce overcrowding.\n  Methods: Data from a partner hospital's ED in the southeastern United States\nwere used, integrating internal metrics and external features. Eleven machine\nlearning algorithms, including traditional and deep learning models, were\ntrained and evaluated. Feature combinations were optimized, and performance was\nassessed across varying patient volumes and hours.\n  Results: TSiTPlus achieved the best hourly prediction (MAE: 4.19, MSE:\n29.32). The mean hourly waiting count was 18.11, with a standard deviation of\n9.77. Accuracy varied by hour, with MAEs ranging from 2.45 (11 PM) to 5.45 (8\nPM). Extreme case analysis at one, two, and three standard deviations above the\nmean showed MAEs of 6.16, 10.16, and 15.59, respectively. For daily\npredictions, XCMPlus performed best (MAE: 2.00, MSE: 6.64), with a daily mean\nof 18.11 and standard deviation of 4.51.\n  Conclusions: These models accurately forecast ED waiting room occupancy and\nsupport proactive resource allocation. Their implementation has the potential\nto improve patient flow and reduce overcrowding in emergency care settings.", "AI": {"tldr": "Machine learning models predict ED waiting room occupancy at hourly and daily scales to improve resource planning and reduce overcrowding.", "motivation": "Emergency department overcrowding causes delays and operational strain; proactive forecasting can enhance efficiency.", "method": "Used data from a hospital ED, tested 11 ML algorithms, optimized features, and evaluated performance across patient volumes and times.", "result": "TSiTPlus (hourly) and XCMPlus (daily) performed best with low MAE/MSE, showing accurate predictions even in extreme cases.", "conclusion": "The models effectively forecast ED occupancy, aiding proactive resource allocation and reducing overcrowding."}}
{"id": "2504.18671", "pdf": "https://arxiv.org/pdf/2504.18671", "abs": "https://arxiv.org/abs/2504.18671", "authors": ["Ross Gore", "Eranga Bandara", "Sachin Shetty", "Alberto E. Musto", "Pratip Rana", "Ambrosio Valencia-Romero", "Christopher Rhea", "Lobat Tayebi", "Heather Richter", "Atmaram Yarlagadda", "Donna Edmonds", "Steven Wallace", "Donna Broshek"], "title": "Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Mild Traumatic Brain Injury (TBI) detection presents significant challenges\ndue to the subtle and often ambiguous presentation of symptoms in medical\nimaging, making accurate diagnosis a complex task. To address these challenges,\nwe propose Proof-of-TBI, a medical diagnosis support system that integrates\nmultiple fine-tuned vision-language models with the OpenAI-o3 reasoning large\nlanguage model (LLM). Our approach fine-tunes multiple vision-language models\nusing a labeled dataset of TBI MRI scans, training them to diagnose TBI\nsymptoms effectively. The predictions from these models are aggregated through\na consensus-based decision-making process. The system evaluates the predictions\nfrom all fine-tuned vision language models using the OpenAI-o3 reasoning LLM, a\nmodel that has demonstrated remarkable reasoning performance, to produce the\nmost accurate final diagnosis. The LLM Agents orchestrates interactions between\nthe vision-language models and the reasoning LLM, managing the final\ndecision-making process with transparency, reliability, and automation. This\nend-to-end decision-making workflow combines the vision-language model\nconsortium with the OpenAI-o3 reasoning LLM, enabled by custom prompt\nengineering by the LLM agents. The prototype for the proposed platform was\ndeveloped in collaboration with the U.S. Army Medical Research team in Newport\nNews, Virginia, incorporating five fine-tuned vision-language models. The\nresults demonstrate the transformative potential of combining fine-tuned\nvision-language model inputs with the OpenAI-o3 reasoning LLM to create a\nrobust, secure, and highly accurate diagnostic system for mild TBI prediction.\nTo the best of our knowledge, this research represents the first application of\nfine-tuned vision-language models integrated with a reasoning LLM for TBI\nprediction tasks.", "AI": {"tldr": "Proof-of-TBI integrates fine-tuned vision-language models with OpenAI-o3 reasoning LLM for accurate mild TBI diagnosis.", "motivation": "Mild TBI detection is challenging due to subtle symptoms in medical imaging, requiring advanced diagnostic tools.", "method": "Fine-tunes vision-language models on TBI MRI scans, aggregates predictions via consensus, and uses OpenAI-o3 LLM for final diagnosis.", "result": "The system shows high accuracy and reliability in diagnosing mild TBI, validated by collaboration with U.S. Army Medical Research.", "conclusion": "This approach is the first to combine vision-language models with reasoning LLM for TBI prediction, offering robust and automated diagnosis."}}
{"id": "2504.19127", "pdf": "https://arxiv.org/pdf/2504.19127", "abs": "https://arxiv.org/abs/2504.19127", "authors": ["Jialang Lu", "Huayu Zhao", "Huiyu Zhai", "Xingxing Yang", "Shini Han"], "title": "DeepSPG: Exploring Deep Semantic Prior Guidance for Low-light Image Enhancement with Multimodal Learning", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted by ICMR 2025 Main track. Code is available at\n  https://github.com/Wenyuzhy/DeepSPG", "summary": "There has long been a belief that high-level semantics learning can benefit\nvarious downstream computer vision tasks. However, in the low-light image\nenhancement (LLIE) community, existing methods learn a brutal mapping between\nlow-light and normal-light domains without considering the semantic information\nof different regions, especially in those extremely dark regions that suffer\nfrom severe information loss. To address this issue, we propose a new deep\nsemantic prior-guided framework (DeepSPG) based on Retinex image decomposition\nfor LLIE to explore informative semantic knowledge via a pre-trained semantic\nsegmentation model and multimodal learning. Notably, we incorporate both\nimage-level semantic prior and text-level semantic prior and thus formulate a\nmultimodal learning framework with combinatorial deep semantic prior guidance\nfor LLIE. Specifically, we incorporate semantic knowledge to guide the\nenhancement process via three designs: an image-level semantic prior guidance\nby leveraging hierarchical semantic features from a pre-trained semantic\nsegmentation model; a text-level semantic prior guidance by integrating natural\nlanguage semantic constraints via a pre-trained vision-language model; a\nmulti-scale semantic-aware structure that facilitates effective semantic\nfeature incorporation. Eventually, our proposed DeepSPG demonstrates superior\nperformance compared to state-of-the-art methods across five benchmark\ndatasets. The implementation details and code are publicly available at\nhttps://github.com/Wenyuzhy/DeepSPG.", "AI": {"tldr": "DeepSPG is a new framework for low-light image enhancement (LLIE) that leverages semantic knowledge from pre-trained models to guide the enhancement process, outperforming existing methods.", "motivation": "Existing LLIE methods ignore semantic information, especially in extremely dark regions, leading to suboptimal results. DeepSPG addresses this by incorporating semantic priors.", "method": "DeepSPG uses Retinex decomposition and multimodal learning, integrating image-level (from semantic segmentation) and text-level (from vision-language models) semantic priors, along with a multi-scale structure.", "result": "DeepSPG achieves superior performance on five benchmark datasets compared to state-of-the-art methods.", "conclusion": "Incorporating semantic priors significantly improves LLIE, and DeepSPG provides a robust framework for this task."}}
{"id": "2504.19362", "pdf": "https://arxiv.org/pdf/2504.19362", "abs": "https://arxiv.org/abs/2504.19362", "authors": ["Yunxuan Wang", "Ray Yin", "Yumei Tan", "Hao Chen", "Haiying Xia"], "title": "Low-Rank Adaptive Structural Priors for Generalizable Diabetic Retinopathy Grading", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted by IJCNN 2025", "summary": "Diabetic retinopathy (DR), a serious ocular complication of diabetes, is one\nof the primary causes of vision loss among retinal vascular diseases. Deep\nlearning methods have been extensively applied in the grading of diabetic\nretinopathy (DR). However, their performance declines significantly when\napplied to data outside the training distribution due to domain shifts. Domain\ngeneralization (DG) has emerged as a solution to this challenge. However, most\nexisting DG methods overlook lesion-specific features, resulting in\ninsufficient accuracy. In this paper, we propose a novel approach that enhances\nexisting DG methods by incorporating structural priors, inspired by the\nobservation that DR grading is heavily dependent on vessel and lesion\nstructures. We introduce Low-rank Adaptive Structural Priors (LoASP), a\nplug-and-play framework designed for seamless integration with existing DG\nmodels. LoASP improves generalization by learning adaptive structural\nrepresentations that are finely tuned to the complexities of DR diagnosis.\nExtensive experiments on eight diverse datasets validate its effectiveness in\nboth single-source and multi-source domain scenarios. Furthermore,\nvisualizations reveal that the learned structural priors intuitively align with\nthe intricate architecture of the vessels and lesions, providing compelling\ninsights into their interpretability and diagnostic relevance.", "AI": {"tldr": "A novel framework, LoASP, enhances domain generalization for diabetic retinopathy grading by incorporating structural priors, improving accuracy and interpretability.", "motivation": "Existing domain generalization methods for diabetic retinopathy grading overlook lesion-specific features, leading to insufficient accuracy.", "method": "Proposes Low-rank Adaptive Structural Priors (LoASP), a plug-and-play framework that integrates with existing DG models to learn adaptive structural representations.", "result": "Validated on eight datasets, LoASP improves generalization in single-source and multi-source scenarios, with visualizations confirming alignment with vessel and lesion structures.", "conclusion": "LoASP effectively addresses domain shifts in DR grading by leveraging structural priors, offering both performance gains and interpretability."}}
{"id": "2504.18839", "pdf": "https://arxiv.org/pdf/2504.18839", "abs": "https://arxiv.org/abs/2504.18839", "authors": ["Abdellah Ghassel", "Xianzhi Li", "Xiaodan Zhu"], "title": "Towards Robust Dialogue Breakdown Detection: Addressing Disruptors in Large Language Models with Self-Guided Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are rapidly changing various domains. However,\ntheir capabilities in handling conversational breakdowns still require an\nin-depth exploration. This paper addresses the challenge of detecting and\nmitigating dialogue breakdowns within LLM-driven conversational systems. While\npowerful models from OpenAI and Anthropic excel in many dialogue tasks, they\ncan still produce incoherent or contradictory responses, commonly referred to\nas breakdowns, which undermine user trust. To tackle this, we propose an\napproach that combines specialized fine-tuning with advanced prompting\nstrategies, including few-shot learning, chain-of-thought reasoning, and\nanalogical prompting. In particular, we fine-tune a small 8B model and\ndemonstrate its robust classification and calibration capabilities in English\nand Japanese dialogue. We also validate its generalization on the BETOLD\ndataset, achieving a 7\\% accuracy improvement over its base model. Furthermore,\nwe introduce a real-time deployment architecture that selectively escalates\nsuspicious responses to more resource-intensive frontier models only when\nbreakdowns are detected, significantly cutting operational expenses and energy\nconsumption. Experimental results show our method surpasses prior\nstate-of-the-art specialized classifiers while also narrowing performance gaps\nbetween smaller open-source models and large proprietary ones. Our approach\noffers a scalable solution for robust conversational AI in high-impact domains\nby combining efficiency, interpretability, and reliability.", "AI": {"tldr": "The paper proposes a method to detect and mitigate dialogue breakdowns in LLM-driven systems using fine-tuning and advanced prompting, achieving improved accuracy and efficiency.", "motivation": "LLMs often produce incoherent or contradictory responses (breakdowns), undermining user trust. The paper aims to address this issue.", "method": "Combines specialized fine-tuning with advanced prompting strategies (few-shot learning, chain-of-thought reasoning, analogical prompting) on an 8B model.", "result": "Achieves 7% accuracy improvement on BETOLD dataset and reduces operational costs by selectively escalating responses.", "conclusion": "The approach offers a scalable, efficient, and reliable solution for robust conversational AI."}}
{"id": "2412.20722", "pdf": "https://arxiv.org/pdf/2412.20722", "abs": "https://arxiv.org/abs/2412.20722", "authors": ["Zhi Chen", "Yun-Fei Shao", "Yong Ma", "Mingsheng Wei", "Le Zhang", "Wei-Qiang Zhang"], "title": "Improving Acoustic Scene Classification in Low-Resource Conditions", "categories": ["eess.AS", "cs.SD"], "comment": "Copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component", "summary": "Acoustic Scene Classification (ASC) identifies an environment based on an\naudio signal. This paper explores ASC in low-resource conditions and proposes a\nnovel model, DS-FlexiNet, which combines depthwise separable convolutions from\nMobileNetV2 with ResNet-inspired residual connections for a balance of\nefficiency and accuracy. To address hardware limitations and device\nheterogeneity, DS-FlexiNet employs Quantization Aware Training (QAT) for model\ncompression and data augmentation methods like Auto Device Impulse Response\n(ADIR) and Freq-MixStyle (FMS) to improve cross-device generalization.\nKnowledge Distillation (KD) from twelve teacher models further enhances\nperformance on unseen devices. The architecture includes a custom Residual\nNormalization layer to handle domain differences across devices, and depthwise\nseparable convolutions reduce computational overhead without sacrificing\nfeature representation. Experimental results show that DS-FlexiNet excels in\nboth adaptability and performance under resource-constrained conditions.", "AI": {"tldr": "DS-FlexiNet is a novel model for Acoustic Scene Classification (ASC) in low-resource settings, combining MobileNetV2's depthwise separable convolutions with ResNet-inspired residual connections. It uses QAT, ADIR, FMS, and KD for efficiency, generalization, and performance.", "motivation": "Addressing ASC challenges in low-resource conditions, including hardware limitations and device heterogeneity, while maintaining accuracy and efficiency.", "method": "Proposes DS-FlexiNet with depthwise separable convolutions, residual connections, QAT, ADIR, FMS, and KD from twelve teacher models. Includes a Residual Normalization layer for domain adaptation.", "result": "DS-FlexiNet demonstrates superior adaptability and performance in resource-constrained scenarios.", "conclusion": "The model effectively balances efficiency and accuracy, making it suitable for low-resource ASC tasks."}}
{"id": "2504.19940", "pdf": "https://arxiv.org/pdf/2504.19940", "abs": "https://arxiv.org/abs/2504.19940", "authors": ["Luigia Costabile", "Gian Marco Orlando", "Valerio La Gatta", "Vincenzo Moscato"], "title": "Assessing the Potential of Generative Agents in Crowdsourced Fact-Checking", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": null, "summary": "The growing spread of online misinformation has created an urgent need for\nscalable, reliable fact-checking solutions. Crowdsourced fact-checking - where\nnon-experts evaluate claim veracity - offers a cost-effective alternative to\nexpert verification, despite concerns about variability in quality and bias.\nEncouraged by promising results in certain contexts, major platforms such as X\n(formerly Twitter), Facebook, and Instagram have begun shifting from\ncentralized moderation to decentralized, crowd-based approaches.\n  In parallel, advances in Large Language Models (LLMs) have shown strong\nperformance across core fact-checking tasks, including claim detection and\nevidence evaluation. However, their potential role in crowdsourced workflows\nremains unexplored. This paper investigates whether LLM-powered generative\nagents - autonomous entities that emulate human behavior and decision-making -\ncan meaningfully contribute to fact-checking tasks traditionally reserved for\nhuman crowds. Using the protocol of La Barbera et al. (2024), we simulate\ncrowds of generative agents with diverse demographic and ideological profiles.\nAgents retrieve evidence, assess claims along multiple quality dimensions, and\nissue final veracity judgments.\n  Our results show that agent crowds outperform human crowds in truthfulness\nclassification, exhibit higher internal consistency, and show reduced\nsusceptibility to social and cognitive biases. Compared to humans, agents rely\nmore systematically on informative criteria such as Accuracy, Precision, and\nInformativeness, suggesting a more structured decision-making process. Overall,\nour findings highlight the potential of generative agents as scalable,\nconsistent, and less biased contributors to crowd-based fact-checking systems.", "AI": {"tldr": "LLM-powered generative agents outperform human crowds in fact-checking tasks, showing higher consistency and reduced bias.", "motivation": "The need for scalable, reliable fact-checking solutions due to online misinformation, and the unexplored potential of LLMs in crowdsourced workflows.", "method": "Simulated crowds of generative agents with diverse profiles to perform fact-checking tasks using evidence retrieval and veracity judgments.", "result": "Agent crowds outperformed humans in truthfulness classification, consistency, and bias reduction, relying more on structured criteria.", "conclusion": "Generative agents are promising for scalable, consistent, and less biased crowd-based fact-checking."}}
{"id": "2412.16874", "pdf": "https://arxiv.org/pdf/2412.16874", "abs": "https://arxiv.org/abs/2412.16874", "authors": ["Anuprabha M", "Krishna Gurugubelli", "V Kesavaraj", "Anil Kumar Vuppala"], "title": "A Multi-modal Approach to Dysarthria Detection and Severity Assessment Using Speech and Text Information", "categories": ["cs.AI", "eess.AS"], "comment": "Submitted to ICASSP 2025", "summary": "Automatic detection and severity assessment of dysarthria are crucial for\ndelivering targeted therapeutic interventions to patients. While most existing\nresearch focuses primarily on speech modality, this study introduces a novel\napproach that leverages both speech and text modalities. By employing\ncross-attention mechanism, our method learns the acoustic and linguistic\nsimilarities between speech and text representations. This approach assesses\nspecifically the pronunciation deviations across different severity levels,\nthereby enhancing the accuracy of dysarthric detection and severity assessment.\nAll the experiments have been performed using UA-Speech dysarthric database.\nImproved accuracies of 99.53% and 93.20% in detection, and 98.12% and 51.97%\nfor severity assessment have been achieved when speaker-dependent and\nspeaker-independent, unseen and seen words settings are used. These findings\nsuggest that by integrating text information, which provides a reference\nlinguistic knowledge, a more robust framework has been developed for dysarthric\ndetection and assessment, thereby potentially leading to more effective\ndiagnoses.", "AI": {"tldr": "The paper introduces a novel method for dysarthria detection and severity assessment by combining speech and text modalities using cross-attention, achieving high accuracy.", "motivation": "Existing research focuses mainly on speech, but integrating text can improve dysarthric detection and severity assessment.", "method": "Uses cross-attention to learn acoustic and linguistic similarities between speech and text, assessing pronunciation deviations.", "result": "Achieved 99.53% and 93.20% accuracy in detection, and 98.12% and 51.97% in severity assessment.", "conclusion": "Combining text with speech enhances dysarthric detection and assessment, improving diagnostic effectiveness."}}
{"id": "2504.18746", "pdf": "https://arxiv.org/pdf/2504.18746", "abs": "https://arxiv.org/abs/2504.18746", "authors": ["Brian K. S. Isaac-Medina", "Toby P. Breckon"], "title": "Dream-Box: Object-wise Outlier Generation for Out-of-Distribution Detection", "categories": ["cs.CV"], "comment": "9 pages, 6 figures, 2 tables, LatinX in AI CVPR 2025 Workshop", "summary": "Deep neural networks have demonstrated great generalization capabilities for\ntasks whose training and test sets are drawn from the same distribution.\nNevertheless, out-of-distribution (OOD) detection remains a challenging task\nthat has received significant attention in recent years. Specifically, OOD\ndetection refers to the detection of instances that do not belong to the\ntraining distribution, while still having good performance on the\nin-distribution task (e.g., classification or object detection). Recent work\nhas focused on generating synthetic outliers and using them to train an outlier\ndetector, generally achieving improved OOD detection than traditional OOD\nmethods. In this regard, outliers can be generated either in feature or pixel\nspace. Feature space driven methods have shown strong performance on both the\nclassification and object detection tasks, at the expense that the\nvisualization of training outliers remains unknown, making further analysis on\nOOD failure modes challenging. On the other hand, pixel space outlier\ngeneration techniques enabled by diffusion models have been used for image\nclassification using, providing improved OOD detection performance and outlier\nvisualization, although their adaption to the object detection task is as yet\nunexplored. We therefore introduce Dream-Box, a method that provides a link to\nobject-wise outlier generation in the pixel space for OOD detection.\nSpecifically, we use diffusion models to generate object-wise outliers that are\nused to train an object detector for an in-distribution task and OOD detection.\nOur method achieves comparable performance to previous traditional methods\nwhile being the first technique to provide concrete visualization of generated\nOOD objects.", "AI": {"tldr": "Dream-Box introduces a method for OOD detection using diffusion models to generate object-wise outliers in pixel space, improving visualization and performance.", "motivation": "Addressing the challenge of OOD detection, especially in object detection tasks, where traditional methods lack visualization of outliers.", "method": "Uses diffusion models to generate object-wise outliers in pixel space, training an object detector for in-distribution tasks and OOD detection.", "result": "Achieves comparable performance to traditional methods while providing visualization of OOD objects.", "conclusion": "Dream-Box bridges the gap in OOD detection by enabling outlier visualization and maintaining detection performance."}}
{"id": "2504.18579", "pdf": "https://arxiv.org/pdf/2504.18579", "abs": "https://arxiv.org/abs/2504.18579", "authors": ["Feng Chen", "Yefei He", "Lequan Lin", "Jing Liu", "Bohan Zhuang", "Qi Wu"], "title": "ZipR1: Reinforcing Token Sparsity in MLLMs", "categories": ["cs.LG"], "comment": "work in process", "summary": "Sparse attention mechanisms aim to reduce computational overhead by\nselectively processing a subset of salient tokens while preserving model\nperformance. Despite the effectiveness of such designs, how to actively\nencourage token sparsity of well-posed MLLMs remains under-explored, which\nfundamentally limits the achievable acceleration effect during inference. In\nthis paper, we propose a simple RL-based post-training method named\n\\textbf{ZipR1} that treats the token reduction ratio as the efficiency reward\nand answer accuracy as the performance reward.\n  In this way, our method can jointly alleviate the computation and memory\nbottlenecks via directly optimizing the inference-consistent\nefficiency-performance tradeoff. Experimental results demonstrate that ZipR1\ncan reduce the token ratio of Qwen2/2.5-VL from 80\\% to 25\\% with a minimal\naccuracy reduction on 13 image and video benchmarks.", "AI": {"tldr": "ZipR1 is an RL-based post-training method that optimizes token sparsity in MLLMs to balance efficiency and performance, reducing token ratio significantly with minimal accuracy loss.", "motivation": "The paper addresses the under-explored challenge of actively encouraging token sparsity in MLLMs to improve computational efficiency during inference without compromising performance.", "method": "Proposes ZipR1, a reinforcement learning (RL)-based approach that treats token reduction ratio as an efficiency reward and answer accuracy as a performance reward, optimizing the tradeoff.", "result": "ZipR1 reduces the token ratio from 80% to 25% with minimal accuracy reduction on 13 benchmarks for Qwen2/2.5-VL models.", "conclusion": "ZipR1 effectively alleviates computation and memory bottlenecks by directly optimizing the efficiency-performance tradeoff during inference."}}
{"id": "2504.18687", "pdf": "https://arxiv.org/pdf/2504.18687", "abs": "https://arxiv.org/abs/2504.18687", "authors": ["Samuel Schapiro", "Jonah Black", "Lav R. Varshney"], "title": "Transformational Creativity in Science: A Graphical Theory", "categories": ["cs.AI"], "comment": null, "summary": "Creative processes are typically divided into three types: combinatorial,\nexploratory, and transformational. Here, we provide a graphical theory of\ntransformational scientific creativity, synthesizing Boden's insight that\ntransformational creativity arises from changes in the \"enabling constraints\"\nof a conceptual space and Kuhn's structure of scientific revolutions as\nresulting from paradigm shifts. We prove that modifications made to axioms of\nour graphical model have the most transformative potential and then illustrate\nhow several historical instances of transformational creativity can be captured\nby our framework.", "AI": {"tldr": "A graphical theory of transformational scientific creativity is proposed, linking Boden's enabling constraints and Kuhn's paradigm shifts, showing axiom modifications have the most transformative potential.", "motivation": "To synthesize Boden's and Kuhn's theories into a graphical model for understanding transformational creativity in science.", "method": "Develop a graphical model to represent transformational creativity, focusing on axiom modifications.", "result": "Proves axiom changes have the highest transformative potential and applies the model to historical cases.", "conclusion": "The graphical framework effectively captures transformational creativity, aligning with historical examples."}}
{"id": "2504.19529", "pdf": "https://arxiv.org/pdf/2504.19529", "abs": "https://arxiv.org/abs/2504.19529", "authors": ["Guobiao Li", "Lei Tan", "Yuliang Xue", "Gaozhi Liu", "Zhenxing Qian", "Sheng Li", "Xinpeng Zhang"], "title": "Adversarial Shallow Watermarking", "categories": ["cs.CV", "cs.MM"], "comment": "10 pages, 12 figures", "summary": "Recent advances in digital watermarking make use of deep neural networks for\nmessage embedding and extraction. They typically follow the ``encoder-noise\nlayer-decoder''-based architecture. By deliberately establishing a\ndifferentiable noise layer to simulate the distortion of the watermarked\nsignal, they jointly train the deep encoder and decoder to fit the noise layer\nto guarantee robustness. As a result, they are usually weak against unknown\ndistortions that are not used in their training pipeline. In this paper, we\npropose a novel watermarking framework to resist unknown distortions, namely\nAdversarial Shallow Watermarking (ASW). ASW utilizes only a shallow decoder\nthat is randomly parameterized and designed to be insensitive to distortions\nfor watermarking extraction. During the watermark embedding, ASW freezes the\nshallow decoder and adversarially optimizes a host image until its updated\nversion (i.e., the watermarked image) stably triggers the shallow decoder to\noutput the watermark message. During the watermark extraction, it accurately\nrecovers the message from the watermarked image by leveraging the insensitive\nnature of the shallow decoder against arbitrary distortions. Our ASW is\ntraining-free, encoder-free, and noise layer-free. Experiments indicate that\nthe watermarked images created by ASW have strong robustness against various\nunknown distortions. Compared to the existing ``encoder-noise layer-decoder''\napproaches, ASW achieves comparable results on known distortions and better\nrobustness on unknown distortions.", "AI": {"tldr": "ASW is a novel watermarking framework that uses a shallow decoder to resist unknown distortions, outperforming traditional deep learning-based methods.", "motivation": "Existing deep neural network-based watermarking methods are weak against unknown distortions not included in training.", "method": "ASW employs a shallow, randomly parameterized decoder, adversarially optimizes the host image for embedding, and leverages the decoder's insensitivity to distortions for extraction.", "result": "ASW shows strong robustness against unknown distortions and performs comparably to traditional methods on known distortions.", "conclusion": "ASW is a training-free, encoder-free, and noise layer-free solution that enhances robustness in watermarking."}}
{"id": "2504.19438", "pdf": "https://arxiv.org/pdf/2504.19438", "abs": "https://arxiv.org/abs/2504.19438", "authors": ["Lingrui Zhang", "Liang Guo", "Xiao An", "Feng Lin", "Binlong Zheng", "Jiankun Wang", "Zhirui Li"], "title": "Dual Attention Driven Lumbar Magnetic Resonance Image Feature Enhancement and Automatic Diagnosis of Herniation", "categories": ["eess.IV", "cs.CV"], "comment": "9 pages, 7 figures", "summary": "Lumbar disc herniation (LDH) is a common musculoskeletal disease that\nrequires magnetic resonance imaging (MRI) for effective clinical management.\nHowever, the interpretation of MRI images heavily relies on the expertise of\nradiologists, leading to delayed diagnosis and high costs for training\nphysicians. Therefore, this paper proposes an innovative automated LDH\nclassification framework. To address these key issues, the framework utilizes\nT1-weighted and T2-weighted MRI images from 205 people. The framework extracts\nclinically actionable LDH features and generates standardized diagnostic\noutputs by leveraging data augmentation and channel and spatial attention\nmechanisms. These outputs can help physicians make confident and time-effective\ncare decisions when needed. The proposed framework achieves an area under the\nreceiver operating characteristic curve (AUC-ROC) of 0.969 and an accuracy of\n0.9486 for LDH detection. The experimental results demonstrate the performance\nof the proposed framework. Our framework only requires a small number of\ndatasets for training to demonstrate high diagnostic accuracy. This is expected\nto be a solution to enhance the LDH detection capabilities of primary\nhospitals.", "AI": {"tldr": "An automated framework for classifying lumbar disc herniation (LDH) using MRI images achieves high accuracy and AUC-ROC, aiding physicians in faster and more confident diagnoses.", "motivation": "LDH diagnosis relies on radiologists' expertise, causing delays and high costs. Automating this process can improve efficiency and accessibility.", "method": "The framework uses T1/T2-weighted MRI images from 205 patients, employing data augmentation and attention mechanisms for feature extraction and standardized outputs.", "result": "Achieves an AUC-ROC of 0.969 and accuracy of 0.9486, demonstrating high performance with minimal training data.", "conclusion": "The framework enhances LDH detection in primary hospitals, offering a scalable and efficient diagnostic solution."}}
{"id": "2504.18851", "pdf": "https://arxiv.org/pdf/2504.18851", "abs": "https://arxiv.org/abs/2504.18851", "authors": ["Hayley Ross", "Ameya Sunil Mahabaleshwarkar", "Yoshi Suhara"], "title": "When2Call: When (not) to Call Tools", "categories": ["cs.CL"], "comment": "NAACL 2025", "summary": "Leveraging external tools is a key feature for modern Language Models (LMs)\nto expand their capabilities and integrate them into existing systems. However,\nexisting benchmarks primarily focus on the accuracy of tool calling -- whether\nthe correct tool is called with the correct parameters -- and less on\nevaluating when LMs should (not) call tools. We develop a new benchmark,\nWhen2Call, which evaluates tool-calling decision-making: when to generate a\ntool call, when to ask follow-up questions and when to admit the question can't\nbe answered with the tools provided. We find that state-of-the-art tool-calling\nLMs show significant room for improvement on When2Call, indicating the\nimportance of this benchmark. We also develop a training set for When2Call and\nleverage the multiple-choice nature of the benchmark to develop a preference\noptimization training regime, which shows considerably more improvement than\ntraditional fine-tuning. We release the benchmark and training data as well as\nevaluation scripts at https://github.com/NVIDIA/When2Call.", "AI": {"tldr": "The paper introduces When2Call, a benchmark evaluating LMs' decision-making on tool usage, highlighting gaps in current benchmarks and proposing a preference optimization training method.", "motivation": "Existing benchmarks focus on tool-calling accuracy but neglect evaluating when LMs should or shouldn't call tools, prompting the need for When2Call.", "method": "Developed When2Call benchmark and training set, leveraging multiple-choice questions for preference optimization training.", "result": "State-of-the-art LMs show significant improvement potential on When2Call, with preference optimization outperforming traditional fine-tuning.", "conclusion": "When2Call addresses a critical gap in LM tool-calling evaluation, offering a benchmark and training method for better decision-making."}}
{"id": "2410.01798", "pdf": "https://arxiv.org/pdf/2410.01798", "abs": "https://arxiv.org/abs/2410.01798", "authors": ["Rishi Veerapaneni", "Muhammad Suhail Saleem", "Jiaoyang Li", "Maxim Likhachev"], "title": "Windowed MAPF with Completeness Guarantees", "categories": ["cs.MA", "cs.AI", "cs.RO"], "comment": "Accepted at AAAI 2025", "summary": "Traditional multi-agent path finding (MAPF) methods try to compute entire\nstart-goal paths which are collision free. However, computing an entire path\ncan take too long for MAPF systems where agents need to replan fast. Methods\nthat address this typically employ a \"windowed\" approach and only try to find\ncollision free paths for a small windowed timestep horizon. This adaptation\ncomes at the cost of incompleteness; all current windowed approaches can become\nstuck in deadlock or livelock. Our main contribution is to introduce our\nframework, WinC-MAPF, for Windowed MAPF that enables completeness. Our\nframework uses heuristic update insights from single-agent real-time heuristic\nsearch algorithms as well as agent independence ideas from MAPF algorithms. We\nalso develop Single-Step CBS (SS-CBS), an instantiation of this framework using\na novel modification to CBS. We show how SS-CBS, which only plans a single step\nand updates heuristics, can effectively solve tough scenarios where existing\nwindowed approaches fail.", "AI": {"tldr": "WinC-MAPF introduces a framework for complete windowed MAPF, addressing deadlock/livelock issues by combining real-time heuristic search insights and agent independence. SS-CBS, an instantiation, effectively solves tough scenarios.", "motivation": "Traditional MAPF methods are slow for replanning, and windowed approaches lack completeness, leading to deadlock/livelock.", "method": "Combines real-time heuristic search updates and agent independence ideas, introducing SS-CBS as a novel CBS modification.", "result": "SS-CBS successfully solves challenging scenarios where other windowed methods fail.", "conclusion": "WinC-MAPF and SS-CBS provide a complete and efficient solution for windowed MAPF."}}
{"id": "2504.18756", "pdf": "https://arxiv.org/pdf/2504.18756", "abs": "https://arxiv.org/abs/2504.18756", "authors": ["Rezowan Shuvo", "M S Mekala", "Eyad Elyan"], "title": "Multi-Stage Boundary-Aware Transformer Network for Action Segmentation in Untrimmed Surgical Videos", "categories": ["cs.CV"], "comment": null, "summary": "Understanding actions within surgical workflows is essential for evaluating\npost-operative outcomes. However, capturing long sequences of actions performed\nin surgical settings poses challenges, as individual surgeons have their unique\napproaches shaped by their expertise, leading to significant variability. To\ntackle this complex problem, we focused on segmentation with precise\nboundaries, a demanding task due to the inherent variability in action\ndurations and the subtle transitions often observed in untrimmed videos. These\ntransitions, marked by ambiguous starting and ending points, complicate the\nsegmentation process. Traditional models, such as MS-TCN, which depend on large\nreceptive fields, frequently face challenges of over-segmentation (resulting in\nfragmented segments) or under-segmentation (merging distinct actions). Both of\nthese issues negatively impact the quality of segmentation. To overcome these\nchallenges, we present the Multi-Stage Boundary-Aware Transformer Network\n(MSBATN) with hierarchical sliding window attention, designed to enhance action\nsegmentation. Our proposed approach incorporates a novel unified loss function\nthat treats action classification and boundary detection as distinct yet\ninterdependent tasks. Unlike traditional binary boundary detection methods, our\nboundary voting mechanism accurately identifies start and end points by\nleveraging contextual information. Extensive experiments using three\nchallenging surgical datasets demonstrate the superior performance of the\nproposed method, achieving state-of-the-art results in F1 scores at thresholds\nof 25% and 50%, while also delivering comparable performance in other metrics.", "AI": {"tldr": "The paper introduces MSBATN, a transformer-based model with hierarchical sliding window attention, to improve surgical action segmentation by addressing over- and under-segmentation issues.", "motivation": "Capturing surgical workflows is challenging due to variability in surgeons' approaches and subtle action transitions in untrimmed videos.", "method": "Proposes MSBATN with a unified loss function and boundary voting mechanism for precise action segmentation.", "result": "Achieves state-of-the-art F1 scores at 25% and 50% thresholds on three surgical datasets.", "conclusion": "MSBATN effectively addresses segmentation challenges in surgical workflows, outperforming traditional methods."}}
{"id": "2504.18580", "pdf": "https://arxiv.org/pdf/2504.18580", "abs": "https://arxiv.org/abs/2504.18580", "authors": ["Shi Jie Yu", "Sehyun Choi"], "title": "Parameter-Efficient Checkpoint Merging via Metrics-Weighted Averaging", "categories": ["cs.LG"], "comment": null, "summary": "Checkpoint merging is a technique for combining multiple model snapshots into\na single superior model, potentially reducing training time for large language\nmodels. This paper explores checkpoint merging in the context of\nparameter-efficient fine-tuning (PEFT), where only small adapter modules (e.g.\nLoRA) are trained. We propose Metrics-Weighted Averaging (MWA), a simple yet\neffective method to merge model checkpoints by weighting their parameters\naccording to performance metrics. In particular, we investigate weighting by\ntraining loss and by training steps, under the intuition that lower-loss or\nlater-step checkpoints are more valuable. We introduce a formula with a penalty\nfactor to adjust weight distribution, requiring only one hyperparameter\nregardless of the number of checkpoints. Experiments on three fine-tuning tasks\n(mathematical reasoning, preference alignment, and general instruction tuning)\nshow that MWA consistently produces merged models that outperform the naive\nuniform average of checkpoints. Notably, loss-weighted merging often yields the\nbest results, delivering up to 5% higher task accuracy than the baseline\nuniform merge and even surpassing the final individual checkpoint's\nperformance. These findings validate checkpoint merging for PEFT and\ndemonstrate that a metric-driven weighting heuristic can efficiently boost\nmodel performance with minimal computational overhead.", "AI": {"tldr": "Checkpoint merging in PEFT using Metrics-Weighted Averaging (MWA) improves model performance by weighting parameters based on metrics like loss or training steps, outperforming naive averaging.", "motivation": "To enhance parameter-efficient fine-tuning (PEFT) by combining model checkpoints more effectively, reducing training time and improving performance.", "method": "Proposes Metrics-Weighted Averaging (MWA), weighting checkpoints by performance metrics (e.g., loss, training steps) with a penalty factor for balanced merging.", "result": "MWA outperforms uniform averaging, with loss-weighted merging achieving up to 5% higher accuracy, even surpassing individual checkpoints.", "conclusion": "Checkpoint merging with MWA is validated for PEFT, showing metric-driven weighting efficiently boosts performance with minimal overhead."}}
{"id": "2504.18765", "pdf": "https://arxiv.org/pdf/2504.18765", "abs": "https://arxiv.org/abs/2504.18765", "authors": ["Chengwei Liu", "Chong Wang", "Jiayue Cao", "Jingquan Ge", "Kun Wang", "Lvye Zhang", "Ming-Ming Cheng", "Penghai Zhao", "Tianlin Li", "Xiaojun Jia", "Xiang Li", "Xinfeng Li", "Yang Liu", "Yebo Feng", "Yihao Huang", "Yijia Xu", "Yuqiang Sun", "Zhenhong Zhou", "Zhengzi Xu"], "title": "A Vision for Auto Research with LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces Agent-Based Auto Research, a structured multi-agent\nframework designed to automate, coordinate, and optimize the full lifecycle of\nscientific research. Leveraging the capabilities of large language models\n(LLMs) and modular agent collaboration, the system spans all major research\nphases, including literature review, ideation, methodology planning,\nexperimentation, paper writing, peer review response, and dissemination. By\naddressing issues such as fragmented workflows, uneven methodological\nexpertise, and cognitive overload, the framework offers a systematic and\nscalable approach to scientific inquiry. Preliminary explorations demonstrate\nthe feasibility and potential of Auto Research as a promising paradigm for\nself-improving, AI-driven research processes.", "AI": {"tldr": "Agent-Based Auto Research automates scientific research using multi-agent LLMs, covering all research phases and addressing workflow fragmentation.", "motivation": "To streamline and optimize scientific research by overcoming fragmented workflows and cognitive overload.", "method": "A multi-agent framework leveraging LLMs for collaboration across research phases like literature review and experimentation.", "result": "Preliminary results show feasibility and potential for AI-driven, self-improving research processes.", "conclusion": "The framework presents a scalable, systematic approach to AI-augmented scientific inquiry."}}
{"id": "2504.19772", "pdf": "https://arxiv.org/pdf/2504.19772", "abs": "https://arxiv.org/abs/2504.19772", "authors": ["Indrajeet Ghosh", "Kasthuri Jayarajah", "Nicholas Waytowich", "Nirmalya Roy"], "title": "Memento: Augmenting Personalized Memory via Practical Multimodal Wearable Sensing in Visual Search and Wayfinding Navigation", "categories": ["cs.HC", "cs.MM"], "comment": "This work has been accepted to the Proceedings of the ACM UMAP 2025", "summary": "Working memory involves the temporary retention of information over short\nperiods. It is a critical cognitive function that enables humans to perform\nvarious online processing tasks, such as dialing a phone number, recalling\nmisplaced items' locations, or navigating through a store. However, inherent\nlimitations in an individual's capacity to retain information often result in\nforgetting important details during such tasks. Although previous research has\nsuccessfully utilized wearable and assistive technologies to enhance long-term\nmemory functions (e.g., episodic memory), their application to supporting\nshort-term recall in daily activities remains underexplored. To address this\ngap, we present Memento, a framework that uses multimodal wearable sensor data\nto detect significant changes in cognitive state and provide intelligent in\nsitu cues to enhance recall. Through two user studies involving 15 and 25\nparticipants in visual search navigation tasks, we demonstrate that\nparticipants receiving visual cues from Memento achieved significantly better\nroute recall, improving approximately 20-23% compared to free recall.\nFurthermore, Memento reduced cognitive load and review time by 46% while also\nsubstantially reducing computation time (3.86 seconds vs. 15.35 seconds),\noffering an average of 75% effectiveness compared to computer vision-based cue\nselection approaches.", "AI": {"tldr": "Memento, a wearable framework, enhances short-term recall in daily tasks using multimodal sensor data and intelligent cues, improving recall by 20-23% and reducing cognitive load by 46%.", "motivation": "Address the underexplored application of wearable technologies to support short-term recall in daily activities, given the limitations of human working memory.", "method": "Developed Memento, a framework using multimodal wearable sensor data to detect cognitive state changes and provide in situ cues. Evaluated through user studies with visual search navigation tasks.", "result": "Participants using Memento showed 20-23% better route recall, 46% reduced cognitive load, and 75% effectiveness compared to computer vision-based approaches.", "conclusion": "Memento effectively enhances short-term recall and reduces cognitive load, demonstrating the potential of wearable technologies for working memory support."}}
{"id": "2504.19930", "pdf": "https://arxiv.org/pdf/2504.19930", "abs": "https://arxiv.org/abs/2504.19930", "authors": ["Thanuja Uruththirakodeeswaran", "Harald Becher", "Michelle Noga", "Lawrence H. Le", "Pierre Boulanger", "Jonathan Windram", "Kumaradevan Punithakumar"], "title": "Accelerated 3D-3D rigid registration of echocardiographic images obtained from apical window using particle filter", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "The perfect alignment of 3D echocardiographic images captured from various\nangles has improved image quality and broadened the field of view. This study\nproposes an accelerated sequential Monte Carlo (SMC) algorithm for 3D-3D rigid\nregistration of transthoracic echocardiographic images with significant and\nlimited overlap taken from apical window that is robust to the noise and\nintensity variation in ultrasound images. The algorithm estimates the\ntranslational and rotational components of the rigid transform through an\niterative process and requires an initial approximation of the rotation and\ntranslation limits. We perform registration in two ways: the image-based\nregistration computes the transform to align the end-diastolic frame of the\napical nonstandard image to the apical standard image and applies the same\ntransform to all frames of the cardiac cycle, whereas the mask-based\nregistration approach uses the binary masks of the left ventricle in the same\nway. The SMC and exhaustive search (EX) algorithms were evaluated for 4D\ntemporal sequences recorded from 7 volunteers who participated in a study\nconducted at the Mazankowski Alberta Heart Institute. The evaluations\ndemonstrate that the mask-based approach of the accelerated SMC yielded a Dice\nscore value of 0.819 +/- 0.045 for the left ventricle and gained 16.7x speedup\ncompared to the CPU version of the SMC algorithm.", "AI": {"tldr": "The paper proposes an accelerated SMC algorithm for 3D-3D rigid registration of echocardiographic images, improving alignment and speed.", "motivation": "To enhance image quality and field of view in 3D echocardiography by addressing noise and intensity variations.", "method": "Uses an accelerated SMC algorithm for rigid registration, tested with image-based and mask-based approaches on 4D sequences from 7 volunteers.", "result": "Mask-based SMC achieved a Dice score of 0.819 +/- 0.045 for the left ventricle and 16.7x speedup over CPU SMC.", "conclusion": "The accelerated SMC algorithm is effective for robust and fast 3D-3D registration of echocardiographic images."}}
{"id": "2504.18857", "pdf": "https://arxiv.org/pdf/2504.18857", "abs": "https://arxiv.org/abs/2504.18857", "authors": ["Yi Lu", "Wanxu Zhao", "Xin Zhou", "Chenxin An", "Chenglong Wang", "Shuo Li", "Yuming Yang", "Jun Zhao", "Tao Ji", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Effective Length Extrapolation via Dimension-Wise Positional Embeddings Manipulation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) often struggle to process and generate coherent\ncontext when the number of input tokens exceeds the pre-trained length. Recent\nadvancements in long-context extension have significantly expanded the context\nwindow of LLMs but require expensive overhead to train the large-scale models\nwith longer context. In this work, we propose Dimension-Wise Positional\nEmbeddings Manipulation (DPE), a training-free framework to extrapolate the\ncontext window of LLMs by diving into RoPE's different hidden dimensions.\nInstead of manipulating all dimensions equally, DPE detects the effective\nlength for every dimension and finds the key dimensions for context extension.\nWe reuse the original position indices with their embeddings from the\npre-trained model and manipulate the key dimensions' position indices to their\nmost effective lengths. In this way, DPE adjusts the pre-trained models with\nminimal modifications while ensuring that each dimension reaches its optimal\nstate for extrapolation. DPE significantly surpasses well-known baselines such\nas YaRN and Self-Extend. DPE enables Llama3-8k 8B to support context windows of\n128k tokens without continual training and integrates seamlessly with Flash\nAttention 2. In addition to its impressive extrapolation capability, DPE also\ndramatically improves the models' performance within training length, such as\nLlama3.1 70B, by over 18 points on popular long-context benchmarks RULER. When\ncompared with commercial models, Llama 3.1 70B with DPE even achieves better\nperformance than GPT-4-128K.", "AI": {"tldr": "DPE is a training-free framework to extend LLMs' context window by optimizing RoPE's hidden dimensions, outperforming baselines and improving performance within training length.", "motivation": "LLMs struggle with long-context processing, and existing methods require costly training. DPE aims to extend context windows without retraining.", "method": "DPE analyzes RoPE's dimensions, identifies key ones for extension, and adjusts their position indices for optimal extrapolation, reusing pre-trained embeddings.", "result": "DPE enables Llama3-8k 8B to handle 128k tokens without training, improves Llama3.1 70B by 18 points on benchmarks, and surpasses GPT-4-128K.", "conclusion": "DPE offers an efficient, training-free solution for long-context extension, outperforming existing methods and enhancing model performance."}}
{"id": "2410.05538", "pdf": "https://arxiv.org/pdf/2410.05538", "abs": "https://arxiv.org/abs/2410.05538", "authors": ["Jan Mrkos", "Anton\u00edn Komenda", "David Fiedler", "Ji\u0159\u00ed Vok\u0159\u00ednek"], "title": "Online Dynamic Pricing for Electric Vehicle Charging Stations with Reservations", "categories": ["cs.MA", "cs.AI"], "comment": "45 pages, 11 figure, accepted to IEEE Transactions on Intelligent\n  Transportation Systems (T-ITS)", "summary": "This paper introduces a novel model for online dynamic pricing of electric\nvehicle charging services that integrates reservation, parking, and charging\ninto a comprehensive bundle priced as a whole. Our approach focuses on the\nindividual high-demand, fast-charging location, employing a Poisson process as\na model of charging reservation arrivals, and develops an online dynamic\npricing strategy optimized through a Markov Decision Process (MDP). A key\ncontribution is the novel analysis of discretization error introduced when\nincorporating the continuous-time Poisson process into the discrete MDP\nframework. The MDP model's feasibility is demonstrated with a heuristic dynamic\npricing method based on Monte-Carlo tree search, offering a viable path for\nreal-world applications.", "AI": {"tldr": "A dynamic pricing model for EV charging services integrates reservation, parking, and charging, using a Poisson process and MDP for optimization, with a focus on discretization error analysis.", "motivation": "To address the challenge of pricing EV charging services dynamically by combining reservation, parking, and charging into a bundled offering.", "method": "Uses a Poisson process for charging reservation arrivals and optimizes pricing via a Markov Decision Process (MDP), with a heuristic method based on Monte-Carlo tree search.", "result": "Demonstrates feasibility of the MDP model and provides a practical dynamic pricing strategy for real-world use.", "conclusion": "The model effectively integrates multiple services into a dynamic pricing framework, with potential for real-world implementation."}}
{"id": "2504.18770", "pdf": "https://arxiv.org/pdf/2504.18770", "abs": "https://arxiv.org/abs/2504.18770", "authors": ["Manuel Weber", "Carly Beneke"], "title": "PyViT-FUSE: A Foundation Model for Multi-Sensor Earth Observation Data", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "11 pages, 13 figures, Published at ICLR 2025 - Machine Learning for\n  Remote Sensing (ML4RS) Workshop", "summary": "We propose PyViT-FUSE, a foundation model for earth observation data\nexplicitly designed to handle multi-modal imagery by learning to fuse an\narbitrary number of mixed-resolution input bands into a single representation\nthrough an attention mechanism. The learned patch tokens are further processed\nby a stack of vision transformers with a novel pyramidal structure. We train\nthe model on a globally sampled dataset in a self-supervised manner, leveraging\ncore concepts of the SwAV algorithm. We show the interpretability of the fusion\nmechanism by visualization of the attention scores and the models applicability\nto downstream tasks.", "AI": {"tldr": "PyViT-FUSE is a foundation model for multi-modal earth observation data, using attention-based fusion and a pyramidal vision transformer, trained self-supervised for interpretability and downstream tasks.", "motivation": "To handle multi-modal, mixed-resolution earth observation data by learning a unified representation through attention fusion.", "method": "Uses attention to fuse arbitrary input bands, processes with pyramidal vision transformers, and trains self-supervised via SwAV concepts.", "result": "Demonstrates interpretable fusion via attention scores and applicability to downstream tasks.", "conclusion": "PyViT-FUSE effectively unifies multi-modal earth observation data with interpretable fusion and broad applicability."}}
{"id": "2504.18583", "pdf": "https://arxiv.org/pdf/2504.18583", "abs": "https://arxiv.org/abs/2504.18583", "authors": ["Zihao An", "Huajun Bai", "Ziqiong Liu", "Dong Li", "Emad Barsoum"], "title": "PARD: Accelerating LLM Inference with Low-Cost PARallel Draft Model Adaptation", "categories": ["cs.LG", "cs.PF"], "comment": "15 pages, 6 figures", "summary": "The autoregressive nature of large language models (LLMs) limits inference\nspeed. Each forward pass generates only a single token and is often\nbottlenecked by memory bandwidth. Speculative decoding alleviates this issue\nusing a draft-then-verify approach to accelerate token generation. However, the\noverhead introduced during the draft phase and the training cost of the draft\nmodel limit the efficiency and adaptability of speculative decoding. In this\nwork, we introduce PARallel Draft (PARD), a novel speculative decoding method\nthat enables low-cost adaptation of autoregressive draft models into parallel\ndraft models. PARD enhances inference efficiency by predicting multiple future\ntokens in a single forward pass of the draft phase, and incorporates a\nconditional drop token method to accelerate training. Its target-independence\nproperty allows a single draft model to be applied to an entire family of\ndifferent models, minimizing the adaptation cost. Our proposed conditional drop\ntoken method can improves draft model training efficiency by 3x. On our\noptimized inference framework, PARD accelerates LLaMA3.1-8B inference by 4.08x,\nachieving 311.5 tokens per second.", "AI": {"tldr": "PARD introduces a parallel speculative decoding method to speed up LLM inference by predicting multiple tokens in one pass, reducing training costs and improving efficiency.", "motivation": "Autoregressive LLMs are slow due to single-token generation and memory bottlenecks. Speculative decoding helps but has draft-phase overhead and high training costs.", "method": "PARD uses parallel draft models to predict multiple tokens in one forward pass, with a conditional drop token method for faster training and target-independence for broader applicability.", "result": "PARD improves training efficiency by 3x and accelerates LLaMA3.1-8B inference by 4.08x, achieving 311.5 tokens per second.", "conclusion": "PARD is an efficient, adaptable solution for speeding up LLM inference with minimal adaptation costs."}}
{"id": "2504.18777", "pdf": "https://arxiv.org/pdf/2504.18777", "abs": "https://arxiv.org/abs/2504.18777", "authors": ["Diana Febrita"], "title": "Evaluating AI-Driven Automated Map Digitization in QGIS", "categories": ["cs.AI"], "comment": "Submitted to 2025 Indiana Geographic Information Council (IGIC)\n  Conference", "summary": "Map digitization is an important process that converts maps into digital\nformats that can be used for further analysis. This process typically requires\na deep human involvement because of the need for interpretation and\ndecision-making when translating complex features. With the advancement of\nartificial intelligence, there is an alternative to conducting map digitization\nwith the help of machine learning techniques. Deepness, or Deep Neural Remote\nSensing, is an advanced AI-driven tool designed and integrated as a plugin in\nQGIS application. This research focuses on assessing the effectiveness of\nDeepness in automated digitization. This study analyses AI-generated\ndigitization results from Google Earth imagery and compares them with digitized\noutputs from OpenStreetMap (OSM) to evaluate performance.", "AI": {"tldr": "The paper evaluates Deepness, an AI tool for automated map digitization, comparing its results with OpenStreetMap outputs.", "motivation": "To reduce human involvement in map digitization by leveraging AI, specifically Deepness, for efficiency and accuracy.", "method": "Uses Deepness in QGIS to digitize Google Earth imagery and compares results with OpenStreetMap data.", "result": "Performance of Deepness is assessed against OSM to determine effectiveness in automated digitization.", "conclusion": "The study highlights the potential of AI-driven tools like Deepness for improving map digitization processes."}}
{"id": "2504.20016", "pdf": "https://arxiv.org/pdf/2504.20016", "abs": "https://arxiv.org/abs/2504.20016", "authors": ["Linshi Li", "Hanlin Cai"], "title": "Applying LLM-Powered Virtual Humans to Child Interviews in Child-Centered Design", "categories": ["cs.HC", "cs.CY", "cs.MM"], "comment": "This paper has been accepted as a Work-in-Progress (WiP) paper in the\n  24th annual ACM Interaction Design and Children (IDC) Conference", "summary": "In child-centered design, directly engaging children is crucial for deeply\nunderstanding their experiences. However, current research often prioritizes\nadult perspectives, as interviewing children involves unique challenges such as\nenvironmental sensitivities and the need for trust-building. AI-powered virtual\nhumans (VHs) offer a promising approach to facilitate engaging and multimodal\ninteractions with children. This study establishes key design guidelines for\nLLM-powered virtual humans tailored to child interviews, standardizing\nmultimodal elements including color schemes, voice characteristics, facial\nfeatures, expressions, head movements, and gestures. Using ChatGPT-based prompt\nengineering, we developed three distinct Human-AI workflows (LLM-Auto,\nLLM-Interview, and LLM-Analyze) and conducted a user study involving 15\nchildren aged 6 to 12. The results indicated that the LLM-Analyze workflow\noutperformed the others by eliciting longer responses, achieving higher user\nexperience ratings, and promoting more effective child engagement.", "AI": {"tldr": "AI-powered virtual humans (VHs) improve child interviews by standardizing multimodal interactions, with the LLM-Analyze workflow showing the best results.", "motivation": "Current research often overlooks children's perspectives in design due to interview challenges. AI-powered VHs can bridge this gap.", "method": "Developed three ChatGPT-based workflows (LLM-Auto, LLM-Interview, LLM-Analyze) and tested with 15 children aged 6-12.", "result": "LLM-Analyze workflow elicited longer responses, higher user experience ratings, and better engagement.", "conclusion": "AI-powered VHs, especially with LLM-Analyze, are effective for child-centered interviews."}}
{"id": "2504.19937", "pdf": "https://arxiv.org/pdf/2504.19937", "abs": "https://arxiv.org/abs/2504.19937", "authors": ["Sima Soltanpour", "Rachel Utama", "Arnold Chang", "Md Taufiq Nasseef", "Dan Madularu", "Praveen Kulkarni", "Craig Ferris", "Chris Joslin"], "title": "SST-DUNet: Automated preclinical functional MRI skull stripping using Smart Swin Transformer and Dense UNet", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Skull stripping is a common preprocessing step that is often performed\nmanually in Magnetic Resonance Imaging (MRI) pipelines, including functional\nMRI (fMRI). This manual process is time-consuming and operator dependent.\nAutomating this process is challenging for preclinical data due to variations\nin brain geometry, resolution, and tissue contrast. While existing methods for\nMRI skull stripping exist, they often struggle with the low resolution and\nvarying slice sizes in preclinical fMRI data. This study proposes a novel\nmethod called SST-DUNet, that integrates a dense UNet-based architecture with a\nfeature extractor based on Smart Swin Transformer (SST) for fMRI skull\nstripping. The Smart Shifted Window Multi-Head Self-Attention (SSW-MSA) module\nin SST is adapted to replace the mask-based module in the Swin Transformer\n(ST), enabling the learning of distinct channel-wise features while focusing on\nrelevant dependencies within brain structures. This modification allows the\nmodel to better handle the complexities of fMRI skull stripping, such as low\nresolution and variable slice sizes. To address the issue of class imbalance in\npreclinical data, a combined loss function using Focal and Dice loss is\nutilized. The model was trained on rat fMRI images and evaluated across three\nin-house datasets with a Dice similarity score of 98.65%, 97.86%, and 98.04%.\nThe fMRI results obtained through automatic skull stripping using the SST-DUNet\nmodel closely align with those from manual skull stripping for both seed-based\nand independent component analyses. These results indicate that the SST-DUNet\ncan effectively substitute manual brain extraction in rat fMRI analysis.", "AI": {"tldr": "SST-DUNet, a novel method combining dense UNet and Smart Swin Transformer, automates skull stripping in rat fMRI with high accuracy, outperforming manual methods.", "motivation": "Manual skull stripping in fMRI is time-consuming and operator-dependent, with existing automated methods struggling with low resolution and variable slice sizes in preclinical data.", "method": "Proposes SST-DUNet, integrating dense UNet with Smart Swin Transformer (SST), using SSW-MSA for feature extraction and a combined Focal-Dice loss to address class imbalance.", "result": "Achieves Dice scores of 98.65%, 97.86%, and 98.04% on rat fMRI datasets, closely matching manual skull stripping results.", "conclusion": "SST-DUNet effectively replaces manual skull stripping in rat fMRI, handling challenges like low resolution and variable slice sizes."}}
{"id": "2504.18872", "pdf": "https://arxiv.org/pdf/2504.18872", "abs": "https://arxiv.org/abs/2504.18872", "authors": ["Alexandra Abbas", "Nora Petrova", "Helios Ael Lyons", "Natalia Perez-Campanero"], "title": "Latent Adversarial Training Improves the Representation of Refusal", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Recent work has shown that language models' refusal behavior is primarily\nencoded in a single direction in their latent space, making it vulnerable to\ntargeted attacks. Although Latent Adversarial Training (LAT) attempts to\nimprove robustness by introducing noise during training, a key question\nremains: How does this noise-based training affect the underlying\nrepresentation of refusal behavior? Understanding this encoding is crucial for\nevaluating LAT's effectiveness and limitations, just as the discovery of linear\nrefusal directions revealed vulnerabilities in traditional supervised safety\nfine-tuning (SSFT).\n  Through the analysis of Llama 2 7B, we examine how LAT reorganizes the\nrefusal behavior in the model's latent space compared to SSFT and embedding\nspace adversarial training (AT). By computing activation differences between\nharmful and harmless instruction pairs and applying Singular Value\nDecomposition (SVD), we find that LAT significantly alters the refusal\nrepresentation, concentrating it in the first two SVD components which explain\napproximately 75 percent of the activation differences variance - significantly\nhigher than in reference models. This concentrated representation leads to more\neffective and transferable refusal vectors for ablation attacks: LAT models\nshow improved robustness when attacked with vectors from reference models but\nbecome more vulnerable to self-generated vectors compared to SSFT and AT. Our\nfindings suggest that LAT's training perturbations enable a more comprehensive\nrepresentation of refusal behavior, highlighting both its potential strengths\nand vulnerabilities for improving model safety.", "AI": {"tldr": "LAT alters refusal behavior encoding in language models, concentrating it in fewer SVD components, improving robustness but increasing vulnerability to self-generated attacks.", "motivation": "To understand how LAT affects the latent representation of refusal behavior in language models, evaluating its effectiveness and limitations.", "method": "Analyzed Llama 2 7B using activation differences and SVD to compare LAT with SSFT and AT.", "result": "LAT concentrates refusal behavior in the first two SVD components (75% variance), improving robustness to external attacks but increasing vulnerability to self-generated vectors.", "conclusion": "LAT's noise-based training enhances refusal representation but reveals trade-offs in robustness, highlighting its potential and risks for model safety."}}
{"id": "2412.06855", "pdf": "https://arxiv.org/pdf/2412.06855", "abs": "https://arxiv.org/abs/2412.06855", "authors": ["Tomer Jordi Chaffer", "Justin Goldston", "Gemach D. A. T. A. I"], "title": "Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Cooperation is vital to our survival and progress. Evolutionary game theory\noffers a lens to understand the structures and incentives that enable\ncooperation to be a successful strategy. As artificial intelligence agents\nbecome integral to human systems, the dynamics of cooperation take on\nunprecedented significance. The convergence of human-agent teaming, contract\ntheory, and decentralized frameworks like Web3, grounded in transparency,\naccountability, and trust, offers a foundation for fostering cooperation by\nestablishing enforceable rules and incentives for humans and AI agents. We\nconceptualize Incentivized Symbiosis as a social contract between humans and\nAI, inspired by Web3 principles and encoded in blockchain technology, to define\nand enforce rules, incentives, and consequences for both parties. By exploring\nthis paradigm, we aim to catalyze new research at the intersection of systems\nthinking in AI, Web3, and society, fostering innovative pathways for\ncooperative human-agent coevolution.", "AI": {"tldr": "The paper proposes 'Incentivized Symbiosis,' a social contract between humans and AI, using Web3 and blockchain to enforce cooperation rules and incentives.", "motivation": "Understanding and fostering cooperation between humans and AI is critical as AI becomes integral to human systems.", "method": "The paper conceptualizes a framework inspired by Web3 and blockchain to define and enforce rules and incentives for human-AI cooperation.", "result": "The proposed paradigm aims to enable cooperative human-agent coevolution by leveraging transparency, accountability, and trust.", "conclusion": "This approach could catalyze research at the intersection of AI, Web3, and society, promoting innovative cooperation pathways."}}
{"id": "2504.18773", "pdf": "https://arxiv.org/pdf/2504.18773", "abs": "https://arxiv.org/abs/2504.18773", "authors": ["Zhiheng Tu", "Xinjian Huang", "Yong He", "Ruiyang Zhou", "Bo Du", "Weitao Wu"], "title": "Depth as Points: Center Point-based Depth Estimation", "categories": ["cs.CV"], "comment": "Depth Esitimation, Key-points, Virtual Datasets, Autonomous Driving", "summary": "The perception of vehicles and pedestrians in urban scenarios is crucial for\nautonomous driving. This process typically involves complicated data\ncollection, imposes high computational and hardware demands. To address these\nlimitations, we first develop a highly efficient method for generating virtual\ndatasets, which enables the creation of task- and scenario-specific datasets in\na short time. Leveraging this method, we construct the virtual depth estimation\ndataset VirDepth, a large-scale, multi-task autonomous driving dataset.\nSubsequently, we propose CenterDepth, a lightweight architecture for monocular\ndepth estimation that ensures high operational efficiency and exhibits superior\nperformance in depth estimation tasks with highly imbalanced height-scale\ndistributions. CenterDepth integrates global semantic information through the\ninnovative Center FC-CRFs algorithm, aggregates multi-scale features based on\nobject key points, and enables detection-based depth estimation of targets.\nExperiments demonstrate that our proposed method achieves superior performance\nin terms of both computational speed and prediction accuracy.", "AI": {"tldr": "The paper introduces VirDepth, a virtual dataset for autonomous driving, and CenterDepth, a lightweight monocular depth estimation method, both improving efficiency and performance.", "motivation": "Addressing the high computational and hardware demands of vehicle and pedestrian perception in urban autonomous driving scenarios.", "method": "Developed a virtual dataset generation method (VirDepth) and proposed CenterDepth, a lightweight architecture integrating global semantics and multi-scale features.", "result": "Superior performance in computational speed and prediction accuracy for depth estimation tasks.", "conclusion": "The proposed methods efficiently tackle limitations in autonomous driving perception, offering scalable and accurate solutions."}}
{"id": "2504.18587", "pdf": "https://arxiv.org/pdf/2504.18587", "abs": "https://arxiv.org/abs/2504.18587", "authors": ["Tianbing Xu"], "title": "Training Large Language Models to Reason via EM Policy Gradient", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Recently, foundation models such as OpenAI's O1 and O3, along with DeepSeek's\nR1, have demonstrated strong reasoning capacities and problem-solving skills\nacquired through large-scale reinforcement learning (RL), with wide\napplications in mathematics, coding, science, intelligent agents, and virtual\nassistants. In this work, we introduce an off-policy reinforcement learning\nalgorithm, EM Policy Gradient, aimed at enhancing LLM reasoning by optimizing\nexpected return over reasoning trajectories. We frame the reasoning task as an\nExpectation-Maximization (EM) optimization problem, alternating between\nsampling diverse rationale trajectories and performing reward-guided\nfine-tuning. Unlike PPO and GRPO, which rely on complex importance weights and\nheuristic clipping, our method provides a simpler, more principled off-policy\npolicy gradient approach, eliminating these complexities while maintaining\nstrong performance. We evaluate the effectiveness of EM Policy Gradient on the\nGSM8K and MATH (HARD) datasets, where it achieves performance comparable to or\nslightly surpassing the state-of-the-art GRPO, while offering additional\nadvantages in scalability, simplicity, and reasoning conciseness. Moreover,\nmodels fine-tuned with our method exhibit cognitive behaviors, such as\nsub-problem decomposition, self-verification, and backtracking, highlighting\nits potential to enhance both the interpretability and robustness of LLM\nreasoning.", "AI": {"tldr": "EM Policy Gradient is a new off-policy RL algorithm for enhancing LLM reasoning, outperforming GRPO in simplicity and performance on GSM8K and MATH (HARD) datasets.", "motivation": "To improve LLM reasoning by simplifying and optimizing reinforcement learning methods, avoiding complexities like importance weights and clipping.", "method": "Frames reasoning as an EM optimization problem, alternating between sampling rationale trajectories and reward-guided fine-tuning.", "result": "Achieves comparable or better performance than GRPO, with added scalability and simplicity, and exhibits cognitive behaviors like sub-problem decomposition.", "conclusion": "EM Policy Gradient enhances LLM reasoning interpretability and robustness, offering a simpler yet effective alternative to existing methods."}}
{"id": "2504.18794", "pdf": "https://arxiv.org/pdf/2504.18794", "abs": "https://arxiv.org/abs/2504.18794", "authors": ["Brendon Johnson", "Alfredo Weitzenfeld"], "title": "Hierarchical Reinforcement Learning in Multi-Goal Spatial Navigation with Autonomous Mobile Robots", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Hierarchical reinforcement learning (HRL) is hypothesized to be able to take\nadvantage of the inherent hierarchy in robot learning tasks with sparse reward\nschemes, in contrast to more traditional reinforcement learning algorithms. In\nthis research, hierarchical reinforcement learning is evaluated and contrasted\nwith standard reinforcement learning in complex navigation tasks. We evaluate\nunique characteristics of HRL, including their ability to create sub-goals and\nthe termination function. We constructed experiments to test the differences\nbetween PPO and HRL, different ways of creating sub-goals, manual vs automatic\nsub-goal creation, and the effects of the frequency of termination on\nperformance. These experiments highlight the advantages of HRL and how it\nachieves these advantages.", "AI": {"tldr": "HRL outperforms standard RL in complex navigation tasks by leveraging sub-goals and termination functions.", "motivation": "To evaluate HRL's advantages over traditional RL in sparse-reward robot learning tasks.", "method": "Compared PPO and HRL, tested sub-goal creation (manual/automatic), and termination frequency effects.", "result": "HRL showed superior performance due to its hierarchical structure and sub-goal mechanisms.", "conclusion": "HRL is more effective for complex tasks with sparse rewards, highlighting its hierarchical benefits."}}
{"id": "2412.19238", "pdf": "https://arxiv.org/pdf/2412.19238", "abs": "https://arxiv.org/abs/2412.19238", "authors": ["Huiyu Duan", "Qiang Hu", "Jiarui Wang", "Liu Yang", "Zitong Xu", "Lu Liu", "Xiongkuo Min", "Chunlei Cai", "Tianxiao Ye", "Xiaoyun Zhang", "Guangtao Zhai"], "title": "FineVQ: Fine-Grained User Generated Content Video Quality Assessment", "categories": ["cs.CV", "cs.LG", "cs.MM", "eess.IV"], "comment": null, "summary": "The rapid growth of user-generated content (UGC) videos has produced an\nurgent need for effective video quality assessment (VQA) algorithms to monitor\nvideo quality and guide optimization and recommendation procedures. However,\ncurrent VQA models generally only give an overall rating for a UGC video, which\nlacks fine-grained labels for serving video processing and recommendation\napplications. To address the challenges and promote the development of UGC\nvideos, we establish the first large-scale Fine-grained Video quality\nassessment Database, termed FineVD, which comprises 6104 UGC videos with\nfine-grained quality scores and descriptions across multiple dimensions. Based\non this database, we propose a Fine-grained Video Quality assessment (FineVQ)\nmodel to learn the fine-grained quality of UGC videos, with the capabilities of\nquality rating, quality scoring, and quality attribution. Extensive\nexperimental results demonstrate that our proposed FineVQ can produce\nfine-grained video-quality results and achieve state-of-the-art performance on\nFineVD and other commonly used UGC-VQA datasets.", "AI": {"tldr": "The paper introduces FineVD, a large-scale database for fine-grained video quality assessment (VQA) of UGC videos, and proposes the FineVQ model to provide detailed quality ratings, scores, and attributions.", "motivation": "Current VQA models lack fine-grained labels for UGC videos, limiting their utility for video processing and recommendation.", "method": "The authors create the FineVD database with 6104 UGC videos and fine-grained scores, then develop the FineVQ model for multi-dimensional quality assessment.", "result": "FineVQ achieves state-of-the-art performance on FineVD and other UGC-VQA datasets, providing detailed quality insights.", "conclusion": "FineVD and FineVQ address the gap in fine-grained VQA, enhancing video quality monitoring and optimization for UGC content."}}
{"id": "2504.18581", "pdf": "https://arxiv.org/pdf/2504.18581", "abs": "https://arxiv.org/abs/2504.18581", "authors": ["Weixuan Chen", "Shunpu Tang", "Qianqian Yang", "Zhiguo Shi", "Dusit Niyato"], "title": "Enhancing Privacy in Semantic Communication over Wiretap Channels leveraging Differential Privacy", "categories": ["cs.CR", "eess.IV"], "comment": null, "summary": "Semantic communication (SemCom) improves transmission efficiency by focusing\non task-relevant information. However, transmitting semantic-rich data over\ninsecure channels introduces privacy risks. This paper proposes a novel SemCom\nframework that integrates differential privacy (DP) mechanisms to protect\nsensitive semantic features. This method employs the generative adversarial\nnetwork (GAN) inversion technique to extract disentangled semantic features and\nuses neural networks (NNs) to approximate the DP application and removal\nprocesses, effectively mitigating the non-invertibility issue of DP.\nAdditionally, an NN-based encryption scheme is introduced to strengthen the\nsecurity of channel inputs. Simulation results demonstrate that the proposed\napproach effectively prevents eavesdroppers from reconstructing sensitive\ninformation by generating chaotic or fake images, while ensuring high-quality\nimage reconstruction for legitimate users. The system exhibits robust\nperformance across various privacy budgets and channel conditions, achieving an\noptimal balance between privacy protection and reconstruction fidelity.", "AI": {"tldr": "A novel SemCom framework integrates DP and GAN inversion to protect sensitive semantic features, ensuring privacy and high-quality reconstruction.", "motivation": "SemCom improves efficiency but risks privacy over insecure channels; this work addresses privacy protection in SemCom.", "method": "Uses GAN inversion for disentangled feature extraction, NNs for DP processes, and NN-based encryption for secure channel inputs.", "result": "Prevents eavesdroppers from reconstructing sensitive data while maintaining high-quality image reconstruction for legitimate users.", "conclusion": "The framework balances privacy protection and reconstruction fidelity robustly across various conditions."}}
{"id": "2504.18884", "pdf": "https://arxiv.org/pdf/2504.18884", "abs": "https://arxiv.org/abs/2504.18884", "authors": ["Junichiro Niimi"], "title": "A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification", "categories": ["cs.CL", "cs.AI"], "comment": "This manuscript has been accepted for the 30th International\n  Conference on Natural Language & Information Systems (NLDB 2025). The final\n  version will appear in the Springer LNCS proceedings. arXiv admin note: text\n  overlap with arXiv:2407.13069", "summary": "With the advance of large language models (LLMs), LLMs have been utilized for\nthe various tasks. However, the issues of variability and reproducibility of\nresults from each trial of LLMs have been largely overlooked in existing\nliterature while actual human annotation uses majority voting to resolve\ndisagreements among annotators. Therefore, this study introduces the\nstraightforward ensemble strategy to a sentiment analysis using LLMs. As the\nresults, we demonstrate that the ensemble of multiple inference using\nmedium-sized LLMs produces more robust and accurate results than using a large\nmodel with a single attempt with reducing RMSE by 18.6%.", "AI": {"tldr": "Ensemble strategy for LLMs improves sentiment analysis robustness and accuracy, reducing RMSE by 18.6%.", "motivation": "Address variability and reproducibility issues in LLM results, inspired by human annotation's majority voting.", "method": "Straightforward ensemble strategy using medium-sized LLMs for sentiment analysis.", "result": "Ensemble of multiple inferences outperforms single large model, reducing RMSE by 18.6%.", "conclusion": "Ensemble approach with medium-sized LLMs enhances reliability and accuracy in sentiment analysis."}}
{"id": "2310.02121", "pdf": "https://arxiv.org/pdf/2310.02121", "abs": "https://arxiv.org/abs/2310.02121", "authors": ["Bojan Crnkovi\u0107", "Stefan Ivi\u0107", "Mila Zovko"], "title": "Fast algorithm for centralized multi-agent maze exploration", "categories": ["cs.RO", "cs.MA", "math.OC"], "comment": "Improved manuscript", "summary": "Recent advances in robotics have paved the way for robots to replace humans\nin perilous situations, such as searching for victims in burning buildings, in\nearthquake-damaged structures, in uncharted caves, traversing minefields or\npatrolling crime-ridden streets. These challenges can be generalized as\nproblems where agents have to explore unknown mazes. We propose a cooperative\nmulti-agent system of automated mobile agents for exploring unknown mazes and\nlocalizing stationary targets. The Heat Equation-Driven Area Coverage (HEDAC)\nalgorithm for maze exploration employs a potential field to guide the\nexploration of the maze and integrates cooperative behaviors of the agents such\nas collision avoidance, coverage coordination, and path planning. In contrast\nto previous applications for continuous static domains, we adapt the HEDAC\nmethod for mazes on expanding rectilinear grids. The proposed algorithm\nguarantees the exploration of the entire maze and can ensure the avoidance of\ncollisions and deadlocks. Moreover, this is the first application of the HEDAC\nalgorithm to domains that expand over time. To cope with the dynamically\nchanging domain, succesive over-relaxation (SOR) iterative linear solver has\nbeen adapted and implemented, which significantly reduced the computational\ncomplexity of the presented algorithm when compared to standard direct and\niterative linear solvers. The results highlight significant improvements and\nshow the applicability of the algorithm in different mazes. They confirm its\nrobustness, adaptability, scalability and simplicity, which enables centralized\nparallel computation to control multiple agents/robots in the maze.", "AI": {"tldr": "A cooperative multi-agent system using the HEDAC algorithm for exploring unknown mazes and locating targets, adapted for dynamic environments with improved computational efficiency.", "motivation": "To address the challenge of exploring hazardous environments (e.g., burning buildings, earthquake zones) by replacing humans with robots, focusing on unknown maze exploration.", "method": "Adapts the HEDAC algorithm for expanding rectilinear grids, integrating cooperative behaviors (collision avoidance, coverage coordination, path planning) and using an SOR iterative solver for computational efficiency.", "result": "Demonstrates robustness, adaptability, and scalability, ensuring full maze exploration, collision avoidance, and deadlock prevention.", "conclusion": "The HEDAC algorithm is effective for dynamic maze exploration, offering centralized control for multi-agent systems with reduced computational complexity."}}
{"id": "2504.18781", "pdf": "https://arxiv.org/pdf/2504.18781", "abs": "https://arxiv.org/abs/2504.18781", "authors": ["Hassan Wasswa", "Timothy Lynar", "Aziida Nanyonga", "Hussein Abbass"], "title": "IoT Botnet Detection: Application of Vision Transformer to Classification of Network Flow Traffic", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Despite the demonstrated effectiveness of transformer models in NLP, and\nimage and video classification, the available tools for extracting features\nfrom captured IoT network flow packets fail to capture sequential patterns in\naddition to the absence of spatial patterns consequently limiting transformer\nmodel application. This work introduces a novel preprocessing method to adapt\ntransformer models, the vision transformer (ViT) in particular, for IoT botnet\nattack detection using network flow packets. The approach involves feature\nextraction from .pcap files and transforming each instance into a 1-channel 2D\nimage shape, enabling ViT-based classification. Also, the ViT model was\nenhanced to allow use any classifier besides Multilayer Perceptron (MLP) that\nwas deployed in the initial ViT paper. Models including the conventional feed\nforward Deep Neural Network (DNN), LSTM and Bidirectional-LSTM (BLSTM)\ndemonstrated competitive performance in terms of precision, recall, and\nF1-score for multiclass-based attack detection when evaluated on two IoT attack\ndatasets.", "AI": {"tldr": "A novel preprocessing method adapts Vision Transformers (ViT) for IoT botnet attack detection by transforming network flow packets into 1-channel 2D images, enabling ViT-based classification with improved classifier options.", "motivation": "Existing tools for IoT network flow packet feature extraction lack sequential and spatial pattern capture, limiting transformer model effectiveness.", "method": "Feature extraction from .pcap files, transforming instances into 1-channel 2D images, and enhancing ViT to support various classifiers (DNN, LSTM, BLSTM).", "result": "Competitive performance in precision, recall, and F1-score for multiclass attack detection on two IoT attack datasets.", "conclusion": "The proposed method successfully adapts ViT for IoT botnet detection, outperforming traditional classifiers."}}
{"id": "2504.18588", "pdf": "https://arxiv.org/pdf/2504.18588", "abs": "https://arxiv.org/abs/2504.18588", "authors": ["YongHui Xia", "Lan Wang", "Hao Wu"], "title": "Dynamic QoS Prediction via a Non-Negative Tensor Snowflake Factorization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Dynamic quality of service (QoS) data exhibit rich temporal patterns in\nuser-service interactions, which are crucial for a comprehensive understanding\nof user behavior and service conditions in Web service. As the number of users\nand services increases, there is a large amount of unobserved QoS data, which\nsignificantly affects users'choice of services. To predict unobserved QoS data,\nwe propose a Non-negative Snowflake Factorization of tensors model. This method\ndesigns a snowflake core tensor to enhance the model's learning capability.\nAdditionally, it employs a single latent factor-based, nonnegative\nmultiplication update on tensor (SLF-NMUT) for parameter learning. Empirical\nresults demonstrate that the proposed model more accurately learns dynamic\nuser-service interaction patterns, thereby yielding improved predictions for\nmissing QoS data.", "AI": {"tldr": "A Non-negative Snowflake Factorization model is proposed to predict missing QoS data by capturing dynamic user-service interaction patterns.", "motivation": "To address the challenge of unobserved QoS data affecting service choices as user and service numbers grow.", "method": "Uses a snowflake core tensor and SLF-NMUT for parameter learning to enhance pattern learning.", "result": "Empirical results show improved accuracy in predicting missing QoS data.", "conclusion": "The model effectively learns dynamic interactions for better QoS predictions."}}
{"id": "2504.18875", "pdf": "https://arxiv.org/pdf/2504.18875", "abs": "https://arxiv.org/abs/2504.18875", "authors": ["Johannes Schneider"], "title": "Generative to Agentic AI: Survey, Conceptualization, and Challenges", "categories": ["cs.AI"], "comment": null, "summary": "Agentic Artificial Intelligence (AI) builds upon Generative AI (GenAI). It\nconstitutes the next major step in the evolution of AI with much stronger\nreasoning and interaction capabilities that enable more autonomous behavior to\ntackle complex tasks. Since the initial release of ChatGPT (3.5), Generative AI\nhas seen widespread adoption, giving users firsthand experience. However, the\ndistinction between Agentic AI and GenAI remains less well understood. To\naddress this gap, our survey is structured in two parts. In the first part, we\ncompare GenAI and Agentic AI using existing literature, discussing their key\ncharacteristics, how Agentic AI remedies limitations of GenAI, and the major\nsteps in GenAI's evolution toward Agentic AI. This section is intended for a\nbroad audience, including academics in both social sciences and engineering, as\nwell as industry professionals. It provides the necessary insights to\ncomprehend novel applications that are possible with Agentic AI but not with\nGenAI. In the second part, we deep dive into novel aspects of Agentic AI,\nincluding recent developments and practical concerns such as defining agents.\nFinally, we discuss several challenges that could serve as a future research\nagenda, while cautioning against risks that can emerge when exceeding human\nintelligence.", "AI": {"tldr": "The paper differentiates Agentic AI from Generative AI (GenAI), highlighting its advanced reasoning and autonomy. It surveys their key differences, Agentic AI's advantages, and future challenges.", "motivation": "To clarify the distinction between Agentic AI and GenAI, addressing gaps in understanding and exploring Agentic AI's potential and risks.", "method": "A two-part survey: first comparing GenAI and Agentic AI, then delving into Agentic AI's novel aspects and challenges.", "result": "Agentic AI offers stronger reasoning and autonomy, enabling new applications beyond GenAI, but raises concerns about surpassing human intelligence.", "conclusion": "Agentic AI represents a significant evolution of AI, with promising applications and challenges that warrant further research and caution."}}
{"id": "2504.18737", "pdf": "https://arxiv.org/pdf/2504.18737", "abs": "https://arxiv.org/abs/2504.18737", "authors": ["Benjamin R. Ecclestone", "James E. D. Tweel", "Marie Abi Daoud", "Hager Gaouda", "Deepak Dinakaran", "Michael P. Wallace", "Ally Khan Somani", "Gilbert Bigras", "John R. Mackey", "Parsin Haji Reza"], "title": "Photon Absorption Remote Sensing Virtual Histopathology: Diagnostic Equivalence to Gold-Standard H&E Staining in Skin Cancer Excisional Biopsies", "categories": ["q-bio.QM", "eess.IV"], "comment": "19 pages, 3 figures, 6 tables", "summary": "Photon Absorption Remote Sensing (PARS) enables label-free imaging of\nsubcellular morphology by observing biomolecule specific absorption\ninteractions. Coupled with deep-learning, PARS produces label-free virtual\nHematoxylin and Eosin (H&E) stained images in unprocessed tissues. This study\nevaluates the diagnostic performance of these PARS-derived virtual H&E images\nin benign and malignant excisional skin biopsies, including Squamous (SCC),\nBasal (BCC) Cell Carcinoma, and normal skin. Sixteen unstained formalin-fixed\nparaffin-embedded skin excisions were PARS imaged, virtually H&E stained, then\nchemically stained and imaged at 40x. Seven fellowship trained\ndermatopathologists assessed all 32 images in a masked randomized fashion.\nConcordance analysis indicates 95.5% agreement between primary diagnoses\nrendered on PARS versus H&E images (Cohen's k=0.93). Inter-rater reliability\nwas near-perfect for both image types (Fleiss' k=0.89 for PARS, k=0.80 for\nH&E). For subtype classification, agreement was near-perfect 91% (k=0.73) for\nSCC and was perfect for BCC. When assessing malignancy confinement (e.g.,\ncancer margins), agreement was 92% between PARS and H&E (k=0.718). During\nassessment dermatopathologists could not reliably distinguish image origin\n(PARS vs. H&E), and diagnostic confidence was equivalent between the\nmodalities. Inter-rater reliability for PARS virtual H&E was consistent with\nreported benchmarks for histologic evaluation. These results indicate that PARS\nvirtual histology may be diagnostically equivalent to traditional H&E staining\nin dermatopathology diagnostics, while enabling assessment directly from\nunlabeled, or unprocessed slides. In turn, the label-free PARS virtual H&E\nimaging workflow may preserve tissue for downstream analysis while producing\ndata well-suited for AI integration potentially accelerating and enhancing the\naccuracy of skin cancer diagnostics.", "AI": {"tldr": "PARS virtual H&E imaging shows high diagnostic agreement with traditional H&E in skin biopsies, enabling label-free, AI-friendly diagnostics.", "motivation": "To evaluate if PARS-derived virtual H&E images can match traditional H&E staining in diagnostic accuracy for skin biopsies.", "method": "PARS imaging of unstained skin biopsies, virtual H&E staining, and comparison with chemically stained H&E images by dermatopathologists.", "result": "95.5% diagnostic agreement (Cohen's k=0.93), near-perfect inter-rater reliability, and equivalent diagnostic confidence between PARS and H&E.", "conclusion": "PARS virtual histology is diagnostically equivalent to H&E, offering label-free, tissue-preserving benefits and AI integration potential."}}
{"id": "2504.18938", "pdf": "https://arxiv.org/pdf/2504.18938", "abs": "https://arxiv.org/abs/2504.18938", "authors": ["Junhong Liang", "Yu Zhou"], "title": "MTCSC: Retrieval-Augmented Iterative Refinement for Chinese Spelling Correction", "categories": ["cs.CL"], "comment": "12 pages, 2 figures", "summary": "Chinese Spelling Correction (CSC) aims to detect and correct erroneous tokens\nin sentences. While Large Language Models (LLMs) have shown remarkable success\nin identifying and rectifying potential errors, they often struggle with\nmaintaining consistent output lengths and adapting to domain-specific\ncorrections. Furthermore, existing CSC task impose rigid constraints requiring\ninput and output lengths to be identical, limiting their applicability. In this\nwork, we extend traditional CSC to variable-length correction scenarios,\nincluding Chinese Splitting Error Correction (CSEC) and ASR N-best Error\nCorrection. To address domain adaptation and length consistency, we propose\nMTCSC (Multi-Turn CSC) framework based on RAG enhanced with a length reflection\nmechanism. Our approach constructs a retrieval database from domain-specific\ntraining data and dictionaries, fine-tuning retrievers to optimize performance\nfor error-containing inputs. Additionally, we introduce a multi-source\ncombination strategy with iterative length reflection to ensure output length\nfidelity. Experiments across diverse domain datasets demonstrate that our\nmethod significantly outperforms current approaches in correction quality,\nparticularly in handling domain-specific and variable-length error correction\ntasks.", "AI": {"tldr": "The paper introduces MTCSC, a framework for variable-length Chinese Spelling Correction, addressing domain adaptation and output length consistency using RAG and a length reflection mechanism.", "motivation": "Existing CSC methods struggle with domain-specific corrections and rigid length constraints, limiting their applicability.", "method": "Proposes MTCSC, leveraging RAG with a retrieval database from domain-specific data and dictionaries, plus a multi-source combination strategy with iterative length reflection.", "result": "Outperforms current methods in correction quality, especially for domain-specific and variable-length tasks.", "conclusion": "MTCSC effectively addresses limitations of traditional CSC, offering improved flexibility and performance in diverse scenarios."}}
{"id": "2312.14256", "pdf": "https://arxiv.org/pdf/2312.14256", "abs": "https://arxiv.org/abs/2312.14256", "authors": ["Wesley H. Holliday", "Eric Pacuit"], "title": "An extension of May's Theorem to three alternatives: axiomatizing Minimax voting", "categories": ["econ.TH", "cs.GT", "cs.MA", "91B12, 91B14, 91B10", "I.2.11"], "comment": "Revised version forthcoming in Social Choice and Welfare", "summary": "May's Theorem [K. O. May, Econometrica 20 (1952) 680-684] characterizes\nmajority voting on two alternatives as the unique preferential voting method\nsatisfying several simple axioms. Here we show that by adding some desirable\naxioms to May's axioms, we can uniquely determine how to vote on three\nalternatives (setting aside tiebreaking). In particular, we add two axioms\nstating that the voting method should mitigate spoiler effects and avoid the\nso-called strong no show paradox. We prove a theorem stating that any\npreferential voting method satisfying our enlarged set of axioms, which\nincludes some weak homogeneity and preservation axioms, must choose from among\nthe Minimax winners in all three-alternative elections. When applied to more\nthan three alternatives, our axioms also distinguish Minimax from other known\nvoting methods that coincide with or refine Minimax for three alternatives.", "AI": {"tldr": "The paper extends May's Theorem by adding axioms to uniquely determine voting methods for three alternatives, focusing on mitigating spoiler effects and avoiding the strong no show paradox, ultimately favoring Minimax winners.", "motivation": "To address limitations of May's Theorem by expanding its axioms to handle three alternatives and ensure fairer voting outcomes.", "method": "Introduces additional axioms (spoiler effect mitigation, avoidance of strong no show paradox) and proves a theorem linking them to Minimax winners for three alternatives.", "result": "The extended axioms uniquely determine Minimax winners for three alternatives and distinguish Minimax from other methods for more alternatives.", "conclusion": "The study successfully generalizes May's Theorem for three alternatives, highlighting Minimax as the preferred voting method under the proposed axioms."}}
{"id": "2504.18800", "pdf": "https://arxiv.org/pdf/2504.18800", "abs": "https://arxiv.org/abs/2504.18800", "authors": ["Ryo Takizawa", "Satoshi Kodera", "Tempei Kabayama", "Ryo Matsuoka", "Yuta Ando", "Yuto Nakamura", "Haruki Settai", "Norihiko Takeda"], "title": "Video CLIP Model for Multi-View Echocardiography Interpretation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Echocardiography involves recording videos of the heart using ultrasound,\nenabling clinicians to evaluate its condition. Recent advances in large-scale\nvision-language models (VLMs) have garnered attention for automating the\ninterpretation of echocardiographic videos. However, most existing VLMs\nproposed for medical interpretation thus far rely on single-frame (i.e., image)\ninputs. Consequently, these image-based models often exhibit lower diagnostic\naccuracy for conditions identifiable through cardiac motion. Moreover,\nechocardiographic videos are recorded from various views that depend on the\ndirection of ultrasound emission, and certain views are more suitable than\nothers for interpreting specific conditions. Incorporating multiple views could\npotentially yield further improvements in accuracy. In this study, we developed\na video-language model that takes five different views and full video sequences\nas input, training it on pairs of echocardiographic videos and clinical reports\nfrom 60,747 cases. Our experiments demonstrate that this expanded approach\nachieves higher interpretation accuracy than models trained with only\nsingle-view videos or with still images.", "AI": {"tldr": "A video-language model using multiple echocardiographic views improves diagnostic accuracy over single-view or image-based models.", "motivation": "Existing vision-language models for echocardiography rely on single-frame inputs, limiting accuracy for motion-dependent conditions and ignoring the benefits of multiple views.", "method": "Developed a video-language model trained on 60,747 cases, incorporating five views and full video sequences paired with clinical reports.", "result": "The model outperformed single-view video and image-based models in interpretation accuracy.", "conclusion": "Using multiple views and full video sequences enhances diagnostic accuracy in echocardiography."}}
{"id": "2504.18590", "pdf": "https://arxiv.org/pdf/2504.18590", "abs": "https://arxiv.org/abs/2504.18590", "authors": ["Guillaume Lauga", "Ma\u00ebl Chaumette", "Edgar Desainte-Mar\u00e9ville", "\u00c9tienne Lasalle", "Arthur Lebeurrier"], "title": "A multilevel approach to accelerate the training of Transformers", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "In this article, we investigate the potential of multilevel approaches to\naccelerate the training of transformer architectures. Using an ordinary\ndifferential equation (ODE) interpretation of these architectures, we propose\nan appropriate way of varying the discretization of these ODE Transformers in\norder to accelerate the training. We validate our approach experimentally by a\ncomparison with the standard training procedure.", "AI": {"tldr": "The paper explores multilevel methods to speed up transformer training by leveraging an ODE interpretation and adaptive discretization.", "motivation": "To address the computational inefficiency in training transformer architectures by introducing a multilevel approach.", "method": "Proposes varying the discretization of ODE Transformers based on an ODE interpretation to optimize training.", "result": "Experimental validation shows the method accelerates training compared to standard procedures.", "conclusion": "Multilevel approaches with adaptive discretization can effectively reduce transformer training time."}}
{"id": "2504.18880", "pdf": "https://arxiv.org/pdf/2504.18880", "abs": "https://arxiv.org/abs/2504.18880", "authors": ["Zuhong Lin", "Daoyuan Ren", "Kai Ran", "Sun Jing", "Xiaotiang Huang", "Haiyang He", "Pengxu Pan", "Xiaohang Zhang", "Ying Fang", "Tianying Wang", "Minli Wu", "Zhanglin Li", "Xiaochuan Zhang", "Haipu Li", "Jingjing Yao"], "title": "Reshaping MOFs Text Mining with a Dynamic Multi-Agent Framework of Large Language Agents", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "comment": null, "summary": "The mining of synthesis conditions for metal-organic frameworks (MOFs) is a\nsignificant focus in materials science. However, identifying the precise\nsynthesis conditions for specific MOFs within the vast array of possibilities\npresents a considerable challenge. Large Language Models (LLMs) offer a\npromising solution to this problem. We leveraged the capabilities of LLMs,\nspecifically gpt-4o-mini, as core agents to integrate various MOF-related\nagents, including synthesis, attribute, and chemical information agents. This\nintegration culminated in the development of MOFh6, an LLM tool designed to\nstreamline the MOF synthesis process. MOFh6 allows users to query in multiple\nformats, such as submitting scientific literature, or inquiring about specific\nMOF codes or structural properties. The tool analyzes these queries to provide\noptimal synthesis conditions and generates model files for density functional\ntheory pre modeling. We believe MOFh6 will enhance efficiency in the MOF\nsynthesis of all researchers.", "AI": {"tldr": "MOFh6, an LLM-based tool, streamlines MOF synthesis by integrating various agents to provide optimal conditions and pre-modeling files.", "motivation": "Identifying precise MOF synthesis conditions is challenging due to the vast possibilities; LLMs offer a solution.", "method": "Leveraged gpt-4o-mini to integrate MOF-related agents (synthesis, attribute, chemical info) into MOFh6, enabling multi-format queries.", "result": "MOFh6 provides optimal synthesis conditions and generates pre-modeling files, enhancing research efficiency.", "conclusion": "MOFh6 improves MOF synthesis efficiency for researchers by leveraging LLM capabilities."}}
{"id": "2504.18849", "pdf": "https://arxiv.org/pdf/2504.18849", "abs": "https://arxiv.org/abs/2504.18849", "authors": ["Omar Naifar"], "title": "Theoretical Framework for Tempered Fractional Gradient Descent: Application to Breast Cancer Classification", "categories": ["cs.LG", "eess.IV", "26A33, 90C26, 68T05, 92C50", "G.1.6; I.2.6; J.3"], "comment": null, "summary": "This paper introduces Tempered Fractional Gradient Descent (TFGD), a novel\noptimization framework that synergizes fractional calculus with exponential\ntempering to enhance gradient-based learning. Traditional gradient descent\nmethods often suffer from oscillatory updates and slow convergence in\nhigh-dimensional, noisy landscapes. TFGD addresses these limitations by\nincorporating a tempered memory mechanism, where historical gradients are\nweighted by fractional coefficients $|w_j| = \\binom{\\alpha}{j}$ and\nexponentially decayed via a tempering parameter $\\lambda$. Theoretical analysis\nestablishes TFGD's convergence guarantees: in convex settings, it achieves an\n$\\mathcal{O}(1/K)$ rate with alignment coefficient $d_{\\alpha,\\lambda} = (1 -\ne^{-\\lambda})^{-\\alpha}$, while stochastic variants attain\n$\\mathcal{O}(1/k^\\alpha)$ error decay. The algorithm maintains $\\mathcal{O}(n)$\ntime complexity equivalent to SGD, with memory overhead scaling as\n$\\mathcal{O}(d/\\lambda)$ for parameter dimension $d$. Empirical validation on\nthe Breast Cancer Wisconsin dataset demonstrates TFGD's superiority, achieving\n98.25\\% test accuracy (vs. 92.11\\% for SGD) and 2$\\times$ faster convergence.\nThe tempered memory mechanism proves particularly effective in medical\nclassification tasks, where feature correlations benefit from stable gradient\naveraging. These results position TFGD as a robust alternative to conventional\noptimizers in both theoretical and applied machine learning.", "AI": {"tldr": "TFGD combines fractional calculus and exponential tempering to improve gradient descent, offering faster convergence and better accuracy than SGD, especially in noisy or high-dimensional tasks.", "motivation": "Traditional gradient descent struggles with oscillatory updates and slow convergence in noisy, high-dimensional landscapes. TFGD aims to overcome these issues.", "method": "TFGD uses a tempered memory mechanism, weighting historical gradients with fractional coefficients and exponential decay. It maintains SGD's time complexity while adding minimal memory overhead.", "result": "TFGD achieves 98.25% test accuracy (vs. 92.11% for SGD) and converges twice as fast, with theoretical guarantees for convex and stochastic settings.", "conclusion": "TFGD is a robust alternative to traditional optimizers, particularly effective in tasks like medical classification where stable gradient averaging is beneficial."}}
{"id": "2504.18942", "pdf": "https://arxiv.org/pdf/2504.18942", "abs": "https://arxiv.org/abs/2504.18942", "authors": ["Debarati Das", "Khanh Chi Le", "Ritik Sachin Parkar", "Karin De Langis", "Brendan Madson", "Chad M. Berryman", "Robin M. Willis", "Daniel H. Moses", "Brett McDonnell", "Daniel Schwarcz", "Dongyeop Kang"], "title": "LawFlow : Collecting and Simulating Lawyers' Thought Processes", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "submitted to COLM 2025", "summary": "Legal practitioners, particularly those early in their careers, face complex,\nhigh-stakes tasks that require adaptive, context-sensitive reasoning. While AI\nholds promise in supporting legal work, current datasets and models are\nnarrowly focused on isolated subtasks and fail to capture the end-to-end\ndecision-making required in real-world practice. To address this gap, we\nintroduce LawFlow, a dataset of complete end-to-end legal workflows collected\nfrom trained law students, grounded in real-world business entity formation\nscenarios. Unlike prior datasets focused on input-output pairs or linear chains\nof thought, LawFlow captures dynamic, modular, and iterative reasoning\nprocesses that reflect the ambiguity, revision, and client-adaptive strategies\nof legal practice. Using LawFlow, we compare human and LLM-generated workflows,\nrevealing systematic differences in structure, reasoning flexibility, and plan\nexecution. Human workflows tend to be modular and adaptive, while LLM workflows\nare more sequential, exhaustive, and less sensitive to downstream implications.\nOur findings also suggest that legal professionals prefer AI to carry out\nsupportive roles, such as brainstorming, identifying blind spots, and surfacing\nalternatives, rather than executing complex workflows end-to-end. Building on\nthese findings, we propose a set of design suggestions, rooted in empirical\nobservations, that align AI assistance with human goals of clarity,\ncompleteness, creativity, and efficiency, through hybrid planning, adaptive\nexecution, and decision-point support. Our results highlight both the current\nlimitations of LLMs in supporting complex legal workflows and opportunities for\ndeveloping more collaborative, reasoning-aware legal AI systems. All data and\ncode are available on our project page\n(https://minnesotanlp.github.io/LawFlow-website/).", "AI": {"tldr": "LawFlow introduces a dataset capturing end-to-end legal workflows, revealing differences between human and LLM reasoning. It suggests AI should support, not replace, legal professionals.", "motivation": "Current AI models lack the ability to handle the dynamic, iterative reasoning of real-world legal practice, necessitating a dataset like LawFlow.", "method": "LawFlow collects complete legal workflows from trained law students, comparing human and LLM-generated workflows to analyze reasoning differences.", "result": "Human workflows are modular and adaptive, while LLM workflows are sequential and less flexible. Legal professionals prefer AI in supportive roles.", "conclusion": "AI should assist, not replace, legal workflows, with design suggestions for hybrid planning and adaptive execution to enhance collaboration."}}
{"id": "2401.11563", "pdf": "https://arxiv.org/pdf/2401.11563", "abs": "https://arxiv.org/abs/2401.11563", "authors": ["Jiabin Lin", "Shana Moothedath"], "title": "Distributed Multi-Task Learning for Stochastic Bandits with Context Distribution and Stage-wise Constraints", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "We present conservative distributed multi-task learning in stochastic linear\ncontextual bandits with heterogeneous agents. This extends conservative linear\nbandits to a distributed setting where M agents tackle different but related\ntasks while adhering to stage-wise performance constraints. The exact context\nis unknown, and only a context distribution is available to the agents as in\nmany practical applications that involve a prediction mechanism to infer\ncontext, such as stock market prediction and weather forecast. We propose a\ndistributed upper confidence bound (UCB) algorithm, DiSC-UCB. Our algorithm\nconstructs a pruned action set during each round to ensure the constraints are\nmet. Additionally, it includes synchronized sharing of estimates among agents\nvia a central server using well-structured synchronization steps. We prove the\nregret and communication bounds on the algorithm. We extend the problem to a\nsetting where the agents are unaware of the baseline reward. For this setting,\nwe provide a modified algorithm, DiSC-UCB2, and we show that the modified\nalgorithm achieves the same regret and communication bounds. We empirically\nvalidated the performance of our algorithm on synthetic data and real-world\nMovielens-100K data.", "AI": {"tldr": "The paper introduces conservative distributed multi-task learning for stochastic linear contextual bandits with heterogeneous agents, proposing two algorithms (DiSC-UCB and DiSC-UCB2) to handle performance constraints and unknown baseline rewards, with theoretical and empirical validation.", "motivation": "To address the challenge of distributed multi-task learning in contextual bandits where agents face related tasks but must meet performance constraints, especially when only a context distribution is available.", "method": "Proposes DiSC-UCB and DiSC-UCB2 algorithms, which use pruned action sets and synchronized sharing of estimates via a central server to ensure constraints and handle unknown baseline rewards.", "result": "Theoretical regret and communication bounds are proven, and empirical validation on synthetic and Movielens-100K data confirms performance.", "conclusion": "The algorithms effectively balance task performance and constraints in distributed settings, with DiSC-UCB2 extending applicability to unknown baseline rewards."}}
{"id": "2504.18810", "pdf": "https://arxiv.org/pdf/2504.18810", "abs": "https://arxiv.org/abs/2504.18810", "authors": ["Yifan Xie", "Fei Ma", "Yi Bin", "Ying He", "Fei Yu"], "title": "Audio-Driven Talking Face Video Generation with Joint Uncertainty Learning", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 7 figures", "summary": "Talking face video generation with arbitrary speech audio is a significant\nchallenge within the realm of digital human technology. The previous studies\nhave emphasized the significance of audio-lip synchronization and visual\nquality. Currently, limited attention has been given to the learning of visual\nuncertainty, which creates several issues in existing systems, including\ninconsistent visual quality and unreliable performance across different input\nconditions. To address the problem, we propose a Joint Uncertainty Learning\nNetwork (JULNet) for high-quality talking face video generation, which\nincorporates a representation of uncertainty that is directly related to visual\nerror. Specifically, we first design an uncertainty module to individually\npredict the error map and uncertainty map after obtaining the generated image.\nThe error map represents the difference between the generated image and the\nground truth image, while the uncertainty map is used to predict the\nprobability of incorrect estimates. Furthermore, to match the uncertainty\ndistribution with the error distribution through a KL divergence term, we\nintroduce a histogram technique to approximate the distributions. By jointly\noptimizing error and uncertainty, the performance and robustness of our model\ncan be enhanced. Extensive experiments demonstrate that our method achieves\nsuperior high-fidelity and audio-lip synchronization in talking face video\ngeneration compared to previous methods.", "AI": {"tldr": "Proposes JULNet for talking face video generation, focusing on visual uncertainty learning to improve quality and robustness.", "motivation": "Addresses the lack of attention to visual uncertainty in existing systems, leading to inconsistent quality and performance.", "method": "Introduces an uncertainty module to predict error and uncertainty maps, using KL divergence and histogram techniques for joint optimization.", "result": "Achieves superior high-fidelity and audio-lip synchronization compared to previous methods.", "conclusion": "JULNet enhances performance and robustness in talking face video generation by learning visual uncertainty."}}
{"id": "2504.18591", "pdf": "https://arxiv.org/pdf/2504.18591", "abs": "https://arxiv.org/abs/2504.18591", "authors": ["Giovanni Catalani", "Michael Bauerheim", "Fr\u00e9d\u00e9ric Tost", "Xavier Bertrand", "Joseph Morlier"], "title": "Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Recent advances in Neural Fields have enabled powerful,\ndiscretization-invariant methods for learning neural operators that approximate\nsolutions of Partial Differential Equations (PDEs) on general geometries.\nBuilding on these developments, we introduce enf2enf, an encoder--decoder\nmethodology for predicting steady-state Partial Differential Equations with\nnon-parameterized geometric variability, based on recently proposed Equivariant\nNeural Field architectures. In enf2enf, input geometries are encoded into\nlatent point cloud embeddings that inherently preserve geometric grounding and\ncapture local phenomena. The resulting representations are then combined with\nglobal parameters and directly decoded into continuous output fields, thus\nefficiently modeling the coupling between geometry and physics. By leveraging\nthe inductive biases of locality and translation invariance, our approach is\nable to capture fine-scale physical features as well as complex shape\nvariations, thereby enhancing generalization and physical compliance. Extensive\nexperiments on a high-fidelity aerodynamic dataset, a hyper-elastic material\nbenchmark, and multi-element airfoil geometries, demonstrate that the proposed\nmodel achieves superior or competitive performance compared to state-of-the-art\ngraph based, operator learning, and neural field methods. Notably, our method\nsupports real time inference and zero-shot super-resolution, enabling efficient\ntraining on low-resolution meshes while maintaining high accuracy on full-scale\ndiscretizations.", "AI": {"tldr": "enf2enf is an encoder-decoder method for predicting steady-state PDEs with non-parameterized geometric variability, leveraging Equivariant Neural Fields for improved generalization and physical compliance.", "motivation": "To address the challenge of predicting PDE solutions on varying geometries without parameterization, enhancing generalization and capturing fine-scale features.", "method": "Uses latent point cloud embeddings to encode input geometries, preserving geometric grounding, and decodes them into continuous output fields, combining local and global parameters.", "result": "Superior or competitive performance on aerodynamic, hyper-elastic, and airfoil datasets, with real-time inference and zero-shot super-resolution capabilities.", "conclusion": "enf2enf effectively models geometry-physics coupling, offering high accuracy and efficiency in PDE solutions for diverse geometries."}}
{"id": "2504.18948", "pdf": "https://arxiv.org/pdf/2504.18948", "abs": "https://arxiv.org/abs/2504.18948", "authors": ["Devesh Pant", "Dibyendu Talukder", "Deepak Kumar", "Rachit Pandey", "Aaditeshwar Seth", "Chetan Arora"], "title": "Use of Metric Learning for the Recognition of Handwritten Digits, and its Application to Increase the Outreach of Voice-based Communication Platforms", "categories": ["cs.AI", "cs.CV"], "comment": "10 Pages, 7 Figures, ACM COMPASS 2022", "summary": "Initiation, monitoring, and evaluation of development programmes can involve\nfield-based data collection about project activities. This data collection\nthrough digital devices may not always be feasible though, for reasons such as\nunaffordability of smartphones and tablets by field-based cadre, or shortfalls\nin their training and capacity building. Paper-based data collection has been\nargued to be more appropriate in several contexts, with automated digitization\nof the paper forms through OCR (Optical Character Recognition) and OMR (Optical\nMark Recognition) techniques. We contribute with providing a large dataset of\nhandwritten digits, and deep learning based models and methods built using this\ndata, that are effective in real-world environments. We demonstrate the\ndeployment of these tools in the context of a maternal and child health and\nnutrition awareness project, which uses IVR (Interactive Voice Response)\nsystems to provide awareness information to rural women SHG (Self Help Group)\nmembers in north India. Paper forms were used to collect phone numbers of the\nSHG members at scale, which were digitized using the OCR tools developed by us,\nand used to push almost 4 million phone calls. The data, model, and code have\nbeen released in the open-source domain.", "AI": {"tldr": "The paper addresses challenges in digital data collection for development programs, proposing paper-based methods with OCR/OMR automation. It introduces a dataset, deep learning models, and tools for digitizing handwritten forms, demonstrated in a maternal health project in India.", "motivation": "Digital data collection is often unfeasible due to cost and training limitations. Paper-based methods with automated digitization offer a viable alternative.", "method": "Developed a large dataset of handwritten digits and deep learning models for OCR/OMR. Deployed tools in a maternal health project using IVR systems.", "result": "Successfully digitized paper forms to push 4 million phone calls in the project. Data, models, and code were released open-source.", "conclusion": "Paper-based data collection with automated digitization is effective in resource-limited settings, as demonstrated in the maternal health project."}}
{"id": "2504.18870", "pdf": "https://arxiv.org/pdf/2504.18870", "abs": "https://arxiv.org/abs/2504.18870", "authors": ["Guodong Sun", "Mingjing Li", "Dingjie Liu", "Mingxuan Liu", "Bo Wu", "Yang Zhang"], "title": "WLTCL: Wide Field-of-View 3-D LiDAR Truck Compartment Automatic Localization System", "categories": ["cs.CV", "cs.RO", "eess.IV"], "comment": "To appear in IEEE TIM", "summary": "As an essential component of logistics automation, the automated loading\nsystem is becoming a critical technology for enhancing operational efficiency\nand safety. Precise automatic positioning of the truck compartment, which\nserves as the loading area, is the primary step in automated loading. However,\nexisting methods have difficulty adapting to truck compartments of various\nsizes, do not establish a unified coordinate system for LiDAR and mobile\nmanipulators, and often exhibit reliability issues in cluttered environments.\nTo address these limitations, our study focuses on achieving precise automatic\npositioning of key points in large, medium, and small fence-style truck\ncompartments in cluttered scenarios. We propose an innovative wide\nfield-of-view 3-D LiDAR vehicle compartment automatic localization system. For\nvehicles of various sizes, this system leverages the LiDAR to generate\nhigh-density point clouds within an extensive field-of-view range. By\nincorporating parking area constraints, our vehicle point cloud segmentation\nmethod more effectively segments vehicle point clouds within the scene. Our\ncompartment key point positioning algorithm utilizes the geometric features of\nthe compartments to accurately locate the corner points, providing stackable\nspatial regions. Extensive experiments on our collected data and public\ndatasets demonstrate that this system offers reliable positioning accuracy and\nreduced computational resource consumption, leading to its application and\npromotion in relevant fields.", "AI": {"tldr": "The paper proposes a 3-D LiDAR system for precise automatic positioning of truck compartments in cluttered environments, addressing adaptability and reliability issues.", "motivation": "Existing methods struggle with varying truck sizes, lack a unified coordinate system, and face reliability challenges in cluttered settings.", "method": "The system uses wide field-of-view 3-D LiDAR for high-density point clouds, incorporates parking constraints for segmentation, and leverages geometric features for key point positioning.", "result": "The system achieves reliable positioning accuracy and reduced computational resource use, validated on collected and public datasets.", "conclusion": "The proposed system is effective for automated loading, with potential for broader application in logistics automation."}}
{"id": "2504.18992", "pdf": "https://arxiv.org/pdf/2504.18992", "abs": "https://arxiv.org/abs/2504.18992", "authors": ["Sanwoo Lee", "Jiahao Liu", "Qifan Wang", "Jingang Wang", "Xunliang Cai", "Yunfang Wu"], "title": "Dynamic Fisher-weighted Model Merging via Bayesian Optimization", "categories": ["cs.CL"], "comment": null, "summary": "The fine-tuning of pre-trained language models has resulted in the widespread\navailability of task-specific models. Model merging offers an efficient way to\ncreate multi-task models by combining these fine-tuned models at the parameter\nlevel, without the need for training data or joint training on multiple\ndatasets. Existing merging approaches typically involve scaling the parameters\nmodel-wise or integrating parameter importance parameter-wise. Both approaches\nexhibit their own weaknesses, leading to a notable performance gap compared to\nmulti-task fine-tuning. In this paper, we unify these seemingly distinct\nstrategies into a more general merging framework, and introduce Dynamic\nFisher-weighted Merging (DF-Merge). Specifically, candidate models are\nassociated with a set of coefficients that linearly scale their fine-tuned\nparameters. Bayesian optimization is applied to dynamically adjust these\ncoefficients, aiming to maximize overall performance on validation sets. Each\niteration of this process integrates parameter importance based on the Fisher\ninformation conditioned by the coefficients. Experimental results show that\nDF-Merge outperforms strong baselines across models of different sizes and a\nvariety of tasks. Our analysis shows that the effectiveness of DF-Merge arises\nfrom the unified view of merging and that near-optimal performance is\nachievable in a few iterations, even with minimal validation data.", "AI": {"tldr": "DF-Merge unifies model-wise and parameter-wise merging into a dynamic framework using Bayesian optimization and Fisher information, outperforming baselines with minimal validation data.", "motivation": "Existing merging approaches have weaknesses, creating a performance gap compared to multi-task fine-tuning. A unified, dynamic method is needed.", "method": "DF-Merge dynamically adjusts coefficients for model parameters using Bayesian optimization and Fisher information to maximize performance.", "result": "DF-Merge outperforms baselines across models and tasks, achieving near-optimal performance in few iterations with minimal validation data.", "conclusion": "DF-Merge provides a unified, efficient merging framework, bridging the performance gap and enabling effective multi-task model creation."}}
{"id": "2410.17466", "pdf": "https://arxiv.org/pdf/2410.17466", "abs": "https://arxiv.org/abs/2410.17466", "authors": ["Yann Bouteiller", "Karthik Soma", "Giovanni Beltrame"], "title": "Evolution of Societies via Reinforcement Learning", "categories": ["cs.LG", "cs.GT", "cs.MA", "q-bio.PE", "q-fin.GN"], "comment": "12 pages, 10 figures", "summary": "The universe involves many independent co-learning agents as an ever-evolving\npart of our observed environment. Yet, in practice, Multi-Agent Reinforcement\nLearning (MARL) applications are typically constrained to small, homogeneous\npopulations and remain computationally intensive. We propose a methodology that\nenables simulating populations of Reinforcement Learning agents at evolutionary\nscale. More specifically, we derive a fast, parallelizable implementation of\nPolicy Gradient (PG) and Opponent-Learning Awareness (LOLA), tailored for\nevolutionary simulations where agents undergo random pairwise interactions in\nstateless normal-form games. We demonstrate our approach by simulating the\nevolution of very large populations made of heterogeneous co-learning agents,\nunder both naive and advanced learning strategies. In our experiments, 200,000\nPG or LOLA agents evolve in the classic games of Hawk-Dove, Stag-Hunt, and\nRock-Paper-Scissors. Each game provides distinct insights into how populations\nevolve under both naive and advanced MARL rules, including compelling ways in\nwhich Opponent-Learning Awareness affects social evolution.", "AI": {"tldr": "A methodology for simulating large, heterogeneous populations of MARL agents using parallelizable PG and LOLA, tested in classic games to study evolutionary dynamics.", "motivation": "Current MARL applications are limited to small, homogeneous populations and are computationally intensive.", "method": "Fast, parallelizable implementation of PG and LOLA for stateless normal-form games with random pairwise interactions.", "result": "Simulated 200,000 agents in Hawk-Dove, Stag-Hunt, and Rock-Paper-Scissors, revealing insights into population evolution under naive and advanced MARL rules.", "conclusion": "LOLA influences social evolution in distinct ways, demonstrating the potential of scalable MARL simulations."}}
{"id": "2504.18856", "pdf": "https://arxiv.org/pdf/2504.18856", "abs": "https://arxiv.org/abs/2504.18856", "authors": ["Shahad Albastaki", "Anabia Sohail", "Iyyakutti Iyappan Ganapathi", "Basit Alawode", "Asim Khan", "Sajid Javed", "Naoufel Werghi", "Mohammed Bennamoun", "Arif Mahmood"], "title": "Multi-Resolution Pathology-Language Pre-training Model with Text-Guided Visual Representation", "categories": ["cs.CV"], "comment": null, "summary": "In Computational Pathology (CPath), the introduction of Vision-Language\nModels (VLMs) has opened new avenues for research, focusing primarily on\naligning image-text pairs at a single magnification level. However, this\napproach might not be sufficient for tasks like cancer subtype classification,\ntissue phenotyping, and survival analysis due to the limited level of detail\nthat a single-resolution image can provide. Addressing this, we propose a novel\nmulti-resolution paradigm leveraging Whole Slide Images (WSIs) to extract\nhistology patches at multiple resolutions and generate corresponding textual\ndescriptions through advanced CPath VLM. We introduce visual-textual alignment\nat multiple resolutions as well as cross-resolution alignment to establish more\neffective text-guided visual representations. Cross-resolution alignment using\na multimodal encoder enhances the model's ability to capture context from\nmultiple resolutions in histology images. Our model aims to capture a broader\nrange of information, supported by novel loss functions, enriches feature\nrepresentation, improves discriminative ability, and enhances generalization\nacross different resolutions. Pre-trained on a comprehensive TCGA dataset with\n34 million image-language pairs at various resolutions, our fine-tuned model\noutperforms state-of-the-art (SOTA) counterparts across multiple datasets and\ntasks, demonstrating its effectiveness in CPath. The code is available on\nGitHub at: https://github.com/BasitAlawode/MR-PLIP", "AI": {"tldr": "A novel multi-resolution paradigm for Vision-Language Models in Computational Pathology improves cancer subtype classification and tissue phenotyping by aligning image-text pairs at multiple resolutions.", "motivation": "Single-resolution alignment in Vision-Language Models (VLMs) lacks detail for tasks like cancer subtype classification and survival analysis. Multi-resolution alignment is proposed to address this limitation.", "method": "Leverages Whole Slide Images (WSIs) to extract histology patches at multiple resolutions, generates textual descriptions, and introduces visual-textual and cross-resolution alignment using a multimodal encoder. Novel loss functions enrich feature representation.", "result": "Pre-trained on TCGA with 34M image-language pairs, the model outperforms SOTA in multiple datasets and tasks.", "conclusion": "The multi-resolution approach enhances discriminative ability and generalization, proving effective for Computational Pathology."}}
{"id": "2504.18593", "pdf": "https://arxiv.org/pdf/2504.18593", "abs": "https://arxiv.org/abs/2504.18593", "authors": ["Akram Shojaei", "Mehdi Delrobaei"], "title": "Severity Classification of Chronic Obstructive Pulmonary Disease in Intensive Care Units: A Semi-Supervised Approach Using MIMIC-III Dataset", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Chronic obstructive pulmonary disease (COPD) represents a significant global\nhealth burden, where precise severity assessment is particularly critical for\neffective clinical management in intensive care unit (ICU) settings. This study\nintroduces an innovative machine learning framework for COPD severity\nclassification utilizing the MIMIC-III critical care database, thereby\nexpanding the applications of artificial intelligence in critical care\nmedicine. Our research developed a robust classification model incorporating\nkey ICU parameters such as blood gas measurements and vital signs, while\nimplementing semi-supervised learning techniques to effectively utilize\nunlabeled data and enhance model performance. The random forest classifier\nemerged as particularly effective, demonstrating exceptional discriminative\ncapability with 92.51% accuracy and 0.98 ROC AUC in differentiating between\nmild-to-moderate and severe COPD cases. This machine learning approach provides\nclinicians with a practical, accurate, and efficient tool for rapid COPD\nseverity evaluation in ICU environments, with significant potential to improve\nboth clinical decision-making processes and patient outcomes. Future research\ndirections should prioritize external validation across diverse patient\npopulations and integration with clinical decision support systems to optimize\nCOPD management in critical care settings.", "AI": {"tldr": "A machine learning framework for COPD severity classification in ICU settings achieved high accuracy (92.51%) and ROC AUC (0.98) using the MIMIC-III database.", "motivation": "Precise severity assessment of COPD is critical for ICU management, and AI can enhance this process.", "method": "Developed a robust classification model with ICU parameters (blood gas, vital signs) and semi-supervised learning for unlabeled data.", "result": "Random forest classifier performed best, with 92.51% accuracy and 0.98 ROC AUC in distinguishing COPD severity.", "conclusion": "The model offers a practical tool for ICU clinicians, with potential to improve decision-making and outcomes. Future work includes external validation and integration with clinical systems."}}
{"id": "2504.19017", "pdf": "https://arxiv.org/pdf/2504.19017", "abs": "https://arxiv.org/abs/2504.19017", "authors": ["Alireza Ghafarollahi", "Markus J. Buehler"], "title": "Sparks: Multi-Agent Artificial Intelligence Model Discovers Protein Design Principles", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cond-mat.soft", "cs.LG", "q-bio.BM"], "comment": null, "summary": "Advances in artificial intelligence (AI) promise autonomous discovery, yet\nmost systems still resurface knowledge latent in their training data. We\npresent Sparks, a multi-modal multi-agent AI model that executes the entire\ndiscovery cycle that includes hypothesis generation, experiment design and\niterative refinement to develop generalizable principles and a report without\nhuman intervention. Applied to protein science, Sparks uncovered two previously\nunknown phenomena: (i) a length-dependent mechanical crossover whereby\nbeta-sheet-biased peptides surpass alpha-helical ones in unfolding force beyond\n~80 residues, establishing a new design principle for peptide mechanics; and\n(ii) a chain-length/secondary-structure stability map revealing unexpectedly\nrobust beta-sheet-rich architectures and a \"frustration zone\" of high variance\nin mixed alpha/beta folds. These findings emerged from fully self-directed\nreasoning cycles that combined generative sequence design, high-accuracy\nstructure prediction and physics-aware property models, with paired\ngeneration-and-reflection agents enforcing self-correction and reproducibility.\nThe key result is that Sparks can independently conduct rigorous scientific\ninquiry and identify previously unknown scientific principles.", "AI": {"tldr": "Sparks, a multi-modal multi-agent AI model, autonomously conducts scientific discovery, uncovering new protein science phenomena without human intervention.", "motivation": "To advance AI beyond resurfacing latent knowledge in training data by enabling autonomous discovery cycles.", "method": "Uses generative sequence design, structure prediction, and physics-aware models with paired generation-and-reflection agents for self-correction.", "result": "Discovered two new protein phenomena: a length-dependent mechanical crossover and a stability map for secondary structures.", "conclusion": "Sparks demonstrates the ability to independently conduct rigorous scientific inquiry and identify unknown principles."}}
{"id": "2504.19136", "pdf": "https://arxiv.org/pdf/2504.19136", "abs": "https://arxiv.org/abs/2504.19136", "authors": ["Huiling Zheng", "Xian Zhong", "Bin Liu", "Yi Xiao", "Bihan Wen", "Xiaofeng Li"], "title": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "13 pages, 8 figures", "summary": "The fusion of Synthetic Aperture Radar (SAR) and RGB imagery for land cover\nclassification remains challenging due to modality heterogeneity and the\nunderutilization of spectral complementarity. Existing methods often fail to\ndecouple shared structural features from modality-specific radiometric\nattributes, leading to feature conflicts and information loss. To address this\nissue, we propose Phase-Amplitude Decoupling (PAD), a frequency-aware framework\nthat separates phase (modality-shared) and amplitude (modality-specific)\ncomponents in the Fourier domain. Specifically, PAD consists of two key\ncomponents: 1) Phase Spectrum Correction (PSC), which aligns cross-modal phase\nfeatures through convolution-guided scaling to enhance geometric consistency,\nand 2) Amplitude Spectrum Fusion (ASF), which dynamically integrates\nhigh-frequency details and low-frequency structures using frequency-adaptive\nmultilayer perceptrons. This approach leverages SAR's sensitivity to\nmorphological features and RGB's spectral richness. Extensive experiments on\nWHU-OPT-SAR and DDHR-SK datasets demonstrate state-of-the-art performance. Our\nwork establishes a new paradigm for physics-aware multi-modal fusion in remote\nsensing. The code will be available at https://github.com/RanFeng2/PAD.", "AI": {"tldr": "Proposes Phase-Amplitude Decoupling (PAD) for SAR and RGB fusion, separating phase (shared) and amplitude (specific) features in the Fourier domain for better land cover classification.", "motivation": "Addresses modality heterogeneity and underutilized spectral complementarity in SAR-RGB fusion, avoiding feature conflicts and information loss.", "method": "Uses Phase Spectrum Correction (PSC) for geometric consistency and Amplitude Spectrum Fusion (ASF) for dynamic detail integration via frequency-aware MLPs.", "result": "Achieves state-of-the-art performance on WHU-OPT-SAR and DDHR-SK datasets.", "conclusion": "PAD sets a new physics-aware multi-modal fusion paradigm in remote sensing; code available on GitHub."}}
{"id": "2504.19019", "pdf": "https://arxiv.org/pdf/2504.19019", "abs": "https://arxiv.org/abs/2504.19019", "authors": ["Mohammad Akbar-Tajari", "Mohammad Taher Pilehvar", "Mohammad Mahmoody"], "title": "Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": "19 pages, 1 figure, 6 tables", "summary": "The challenge of ensuring Large Language Models (LLMs) align with societal\nstandards is of increasing interest, as these models are still prone to\nadversarial jailbreaks that bypass their safety mechanisms. Identifying these\nvulnerabilities is crucial for enhancing the robustness of LLMs against such\nexploits. We propose Graph of ATtacks (GoAT), a method for generating\nadversarial prompts to test the robustness of LLM alignment using the Graph of\nThoughts framework [Besta et al., 2024]. GoAT excels at generating highly\neffective jailbreak prompts with fewer queries to the victim model than\nstate-of-the-art attacks, achieving up to five times better jailbreak success\nrate against robust models like Llama. Notably, GoAT creates high-quality,\nhuman-readable prompts without requiring access to the targeted model's\nparameters, making it a black-box attack. Unlike approaches constrained by\ntree-based reasoning, GoAT's reasoning is based on a more intricate graph\nstructure. By making simultaneous attack paths aware of each other's progress,\nthis dynamic framework allows a deeper integration and refinement of reasoning\npaths, significantly enhancing the collaborative exploration of adversarial\nvulnerabilities in LLMs. At a technical level, GoAT starts with a graph\nstructure and iteratively refines it by combining and improving thoughts,\nenabling synergy between different thought paths. The code for our\nimplementation can be found at: https://github.com/GoAT-pydev/Graph_of_Attacks.", "AI": {"tldr": "GoAT is a method for generating adversarial prompts to test LLM robustness, achieving higher jailbreak success rates with fewer queries and human-readable prompts.", "motivation": "LLMs are vulnerable to adversarial jailbreaks, and identifying these vulnerabilities is crucial for improving their alignment with societal standards.", "method": "GoAT uses the Graph of Thoughts framework to generate adversarial prompts, refining a graph structure iteratively for better reasoning and attack synergy.", "result": "GoAT achieves up to five times better jailbreak success rates than state-of-the-art attacks, even against robust models like Llama, without needing model parameters.", "conclusion": "GoAT's dynamic graph-based approach enhances adversarial prompt generation, offering a powerful tool for testing and improving LLM robustness."}}
{"id": "2504.18864", "pdf": "https://arxiv.org/pdf/2504.18864", "abs": "https://arxiv.org/abs/2504.18864", "authors": ["Yunzhong Zhang", "Bo Xiong", "You Zhou", "Changqing Su", "Zhen Cheng", "Zhaofei Yu", "Xun Cao", "Tiejun Huang"], "title": "Spike Imaging Velocimetry: Dense Motion Estimation of Fluids Using Spike Cameras", "categories": ["cs.CV"], "comment": null, "summary": "The need for accurate and non-intrusive flow measurement methods has led to\nthe widespread adoption of Particle Image Velocimetry (PIV), a powerful\ndiagnostic tool in fluid motion estimation. This study investigates the\ntremendous potential of spike cameras (a type of ultra-high-speed,\nhigh-dynamic-range camera) in PIV. We propose a deep learning framework, Spike\nImaging Velocimetry (SIV), designed specifically for highly turbulent and\nintricate flow fields. To aggregate motion features from the spike stream while\nminimizing information loss, we incorporate a Detail-Preserving Hierarchical\nTransform (DPHT) module. Additionally, we introduce a Graph Encoder (GE) to\nextract contextual features from highly complex fluid flows. Furthermore, we\npresent a spike-based PIV dataset, Particle Scenes with Spike and Displacement\n(PSSD), which provides labeled data for three challenging fluid dynamics\nscenarios. Our proposed method achieves superior performance compared to\nexisting baseline methods on PSSD. The datasets and our implementation of SIV\nare open-sourced in the supplementary materials.", "AI": {"tldr": "The paper introduces Spike Imaging Velocimetry (SIV), a deep learning framework for flow measurement using spike cameras in Particle Image Velocimetry (PIV), outperforming existing methods.", "motivation": "Accurate and non-intrusive flow measurement is crucial, and PIV is widely used. Spike cameras offer potential for high-speed, high-dynamic-range imaging in complex flows.", "method": "Proposes SIV with a Detail-Preserving Hierarchical Transform (DPHT) module and Graph Encoder (GE) for feature extraction. Introduces the PSSD dataset for validation.", "result": "SIV achieves superior performance on the PSSD dataset compared to baseline methods.", "conclusion": "The study demonstrates the effectiveness of SIV for complex flow fields and provides open-sourced datasets and implementation."}}
{"id": "2504.18594", "pdf": "https://arxiv.org/pdf/2504.18594", "abs": "https://arxiv.org/abs/2504.18594", "authors": ["Tongrui Su", "Qingbin Li", "Shengyu Zhu", "Wei Chen", "Xueqi Cheng"], "title": "A Simple DropConnect Approach to Transfer-based Targeted Attack", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study the problem of transfer-based black-box attack, where adversarial\nsamples generated using a single surrogate model are directly applied to target\nmodels. Compared with untargeted attacks, existing methods still have lower\nAttack Success Rates (ASRs) in the targeted setting, i.e., the obtained\nadversarial examples often overfit the surrogate model but fail to mislead\nother models. In this paper, we hypothesize that the pixels or features in\nthese adversarial examples collaborate in a highly dependent manner to maximize\nthe success of an adversarial attack on the surrogate model, which we refer to\nas perturbation co-adaptation. Then, we propose to Mitigate perturbation\nCo-adaptation by DropConnect (MCD) to enhance transferability, by creating\ndiverse variants of surrogate model at each optimization iteration. We conduct\nextensive experiments across various CNN- and Transformer-based models to\ndemonstrate the effectiveness of MCD. In the challenging scenario of\ntransferring from a CNN-based model to Transformer-based models, MCD achieves\n13% higher average ASRs compared with state-of-the-art baselines. MCD boosts\nthe performance of self-ensemble methods by bringing in more diversification\nacross the variants while reserving sufficient semantic information for each\nvariant. In addition, MCD attains the highest performance gain when scaling the\ncompute of crafting adversarial examples.", "AI": {"tldr": "The paper introduces MCD, a method to enhance transferability of adversarial attacks by mitigating perturbation co-adaptation via DropConnect, achieving higher Attack Success Rates (ASRs) compared to baselines.", "motivation": "Existing targeted transfer-based black-box attacks have low ASRs due to adversarial examples overfitting the surrogate model. The paper hypothesizes this is caused by perturbation co-adaptation.", "method": "Proposes MCD, which mitigates perturbation co-adaptation by creating diverse surrogate model variants using DropConnect during optimization.", "result": "MCD achieves 13% higher average ASRs in challenging scenarios (e.g., CNN to Transformer transfer) and boosts self-ensemble methods.", "conclusion": "MCD effectively enhances adversarial transferability, especially in targeted attacks, and scales well with computational resources."}}
{"id": "2504.19023", "pdf": "https://arxiv.org/pdf/2504.19023", "abs": "https://arxiv.org/abs/2504.19023", "authors": ["Justin M\u00fccke", "Ansgar Scherp"], "title": "GLaMoR: Consistency Checking of OWL Ontologies using Graph Language Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Semantic reasoning aims to infer new knowledge from existing knowledge, with\nOWL ontologies serving as a standardized framework for organizing information.\nA key challenge in semantic reasoning is verifying ontology consistency.\nHowever, state-of-the-art reasoners are computationally expensive, and their\nefficiency decreases as ontology sizes grow. While classical machine learning\nmodels have been explored for consistency checking, they struggle to capture\ncomplex relationships within ontologies. Large language models (LLMs) have\nshown promising results for simple reasoning tasks but perform poorly on\nstructured reasoning. The recently introduced Graph Language Model (GLM) offers\na way to simultaneously process graph-structured data and text. This paper\nproposes GLaMoR (Graph Language Model for Reasoning), a reasoning pipeline that\ntransforms OWL ontologies into graph-structured data and adapts the GLM\narchitecture for consistency checking. We evaluate GLaMoR on ontologies from\nthe NCBO BioPortal repository, converting them into triples suitable for model\ninput. Our results show that the GLM outperforms all baseline models, achieving\n$95\\%$ accuracy while being 20 times faster than classical reasoners.\n  The Code is accessible under: https://github.com/JustinMuecke/GLaMoR", "AI": {"tldr": "GLaMoR, a Graph Language Model for Reasoning, improves ontology consistency checking by transforming OWL ontologies into graph-structured data, achieving 95% accuracy and 20x speedup over classical reasoners.", "motivation": "The challenge of verifying ontology consistency efficiently, especially as ontology sizes grow, motivates the need for a scalable solution beyond traditional reasoners and classical machine learning models.", "method": "The paper proposes GLaMoR, which transforms OWL ontologies into graph-structured data and adapts the Graph Language Model (GLM) architecture for consistency checking.", "result": "GLaMoR achieves 95% accuracy and is 20 times faster than classical reasoners, as demonstrated on NCBO BioPortal ontologies.", "conclusion": "GLaMoR offers a promising, efficient alternative for ontology consistency checking, leveraging graph-structured data and language models."}}
{"id": "2504.19198", "pdf": "https://arxiv.org/pdf/2504.19198", "abs": "https://arxiv.org/abs/2504.19198", "authors": ["Lingtao Peng", "Liheng Bian"], "title": "Adaptive Dual-domain Learning for Underwater Image Enhancement", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted by AAAI 2025", "summary": "Recently, learning-based Underwater Image Enhancement (UIE) methods have\ndemonstrated promising performance. However, existing learning-based methods\nstill face two challenges. 1) They rarely consider the inconsistent degradation\nlevels in different spatial regions and spectral bands simultaneously. 2) They\ntreat all regions equally, ignoring that the regions with high-frequency\ndetails are more difficult to reconstruct. To address these challenges, we\npropose a novel UIE method based on spatial-spectral dual-domain adaptive\nlearning, termed SS-UIE. Specifically, we first introduce a spatial-wise\nMulti-scale Cycle Selective Scan (MCSS) module and a Spectral-Wise\nSelf-Attention (SWSA) module, both with linear complexity, and combine them in\nparallel to form a basic Spatial-Spectral block (SS-block). Benefiting from the\nglobal receptive field of MCSS and SWSA, SS-block can effectively model the\ndegradation levels of different spatial regions and spectral bands, thereby\nenabling degradation level-based dual-domain adaptive UIE. By stacking multiple\nSS-blocks, we build our SS-UIE network. Additionally, a Frequency-Wise Loss\n(FWL) is introduced to narrow the frequency-wise discrepancy and reinforce the\nmodel's attention on the regions with high-frequency details. Extensive\nexperiments validate that the SS-UIE technique outperforms state-of-the-art UIE\nmethods while requiring cheaper computational and memory costs.", "AI": {"tldr": "SS-UIE proposes a spatial-spectral dual-domain adaptive learning method for underwater image enhancement, addressing inconsistent degradation and high-frequency detail reconstruction.", "motivation": "Existing UIE methods fail to address inconsistent degradation levels across spatial regions and spectral bands, and neglect the difficulty of reconstructing high-frequency details.", "method": "Introduces MCSS and SWSA modules in parallel to form SS-blocks, enabling adaptive UIE. Uses Frequency-Wise Loss (FWL) to focus on high-frequency details.", "result": "SS-UIE outperforms state-of-the-art methods with lower computational and memory costs.", "conclusion": "SS-UIE effectively addresses key challenges in UIE, offering superior performance and efficiency."}}
{"id": "2504.19021", "pdf": "https://arxiv.org/pdf/2504.19021", "abs": "https://arxiv.org/abs/2504.19021", "authors": ["Zhyar Rzgar K Rostam", "G\u00e1bor Kert\u00e9sz"], "title": "Advancing Scientific Text Classification: Fine-Tuned Models with Dataset Expansion and Hard-Voting", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 1 figure, 8 tables", "summary": "Efficient text classification is essential for handling the increasing volume\nof academic publications. This study explores the use of pre-trained language\nmodels (PLMs), including BERT, SciBERT, BioBERT, and BlueBERT, fine-tuned on\nthe Web of Science (WoS-46985) dataset for scientific text classification. To\nenhance performance, we augment the dataset by executing seven targeted queries\nin the WoS database, retrieving 1,000 articles per category aligned with\nWoS-46985's main classes. PLMs predict labels for this unlabeled data, and a\nhard-voting strategy combines predictions for improved accuracy and confidence.\nFine-tuning on the expanded dataset with dynamic learning rates and early\nstopping significantly boosts classification accuracy, especially in\nspecialized domains. Domain-specific models like SciBERT and BioBERT\nconsistently outperform general-purpose models such as BERT. These findings\nunderscore the efficacy of dataset augmentation, inference-driven label\nprediction, hard-voting, and fine-tuning techniques in creating robust and\nscalable solutions for automated academic text classification.", "AI": {"tldr": "The paper explores fine-tuning pre-trained language models (PLMs) like BERT, SciBERT, BioBERT, and BlueBERT on the Web of Science dataset for scientific text classification. Dataset augmentation, hard-voting, and dynamic learning rates improve accuracy, with domain-specific models outperforming general ones.", "motivation": "Efficient text classification is needed due to the growing volume of academic publications. The study aims to enhance classification accuracy using PLMs and dataset augmentation.", "method": "The study fine-tunes PLMs on the WoS-46985 dataset, augments it with 1,000 articles per category via targeted queries, and uses hard-voting for label prediction. Dynamic learning rates and early stopping are applied during fine-tuning.", "result": "Domain-specific models (SciBERT, BioBERT) outperform general-purpose models (BERT). Dataset augmentation and hard-voting significantly boost classification accuracy, especially in specialized domains.", "conclusion": "The study highlights the effectiveness of dataset augmentation, inference-driven label prediction, hard-voting, and fine-tuning for robust and scalable academic text classification."}}
{"id": "2504.18866", "pdf": "https://arxiv.org/pdf/2504.18866", "abs": "https://arxiv.org/abs/2504.18866", "authors": ["Jiaxu Leng", "Zhanjie Wu", "Mingpi Tan", "Mengjingcheng Mo", "Jiankang Zheng", "Qingqing Li", "Ji Gan", "Xinbo Gao"], "title": "PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance", "categories": ["cs.CV"], "comment": "Submitted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "summary": "Existing weakly supervised video violence detection (VVD) methods primarily\nrely on Euclidean representation learning, which often struggles to distinguish\nvisually similar yet semantically distinct events due to limited hierarchical\nmodeling and insufficient ambiguous training samples. To address this\nchallenge, we propose PiercingEye, a novel dual-space learning framework that\nsynergizes Euclidean and hyperbolic geometries to enhance discriminative\nfeature representation. Specifically, PiercingEye introduces a layer-sensitive\nhyperbolic aggregation strategy with hyperbolic Dirichlet energy constraints to\nprogressively model event hierarchies, and a cross-space attention mechanism to\nfacilitate complementary feature interactions between Euclidean and hyperbolic\nspaces. Furthermore, to mitigate the scarcity of ambiguous samples, we leverage\nlarge language models to generate logic-guided ambiguous event descriptions,\nenabling explicit supervision through a hyperbolic vision-language contrastive\nloss that prioritizes high-confusion samples via dynamic similarity-aware\nweighting. Extensive experiments on XD-Violence and UCF-Crime benchmarks\ndemonstrate that PiercingEye achieves state-of-the-art performance, with\nparticularly strong results on a newly curated ambiguous event subset,\nvalidating its superior capability in fine-grained violence detection.", "AI": {"tldr": "PiercingEye improves weakly supervised video violence detection by combining Euclidean and hyperbolic geometries, using hierarchical modeling and logic-guided ambiguous samples for better performance.", "motivation": "Existing methods struggle with distinguishing visually similar but semantically distinct events due to limited hierarchical modeling and ambiguous samples.", "method": "Proposes PiercingEye, a dual-space learning framework with hyperbolic aggregation, cross-space attention, and logic-guided ambiguous samples via large language models.", "result": "Achieves state-of-the-art performance on XD-Violence and UCF-Crime benchmarks, especially on ambiguous event subsets.", "conclusion": "PiercingEye excels in fine-grained violence detection by leveraging dual-space learning and explicit supervision."}}
{"id": "2504.18595", "pdf": "https://arxiv.org/pdf/2504.18595", "abs": "https://arxiv.org/abs/2504.18595", "authors": ["Uzma", "Fabien Cholet", "Domenic Quinn", "Cindy Smith", "Siming You", "William Sloan"], "title": "EnviroPiNet: A Physics-Guided AI Model for Predicting Biofilter Performance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Environmental biotechnologies, such as drinking water biofilters, rely on\ncomplex interactions between microbial communities and their surrounding\nphysical-chemical environments. Predicting the performance of these systems is\nchallenging due to high-dimensional, sparse datasets that lack diversity and\nfail to fully capture system behaviour. Accurate predictive models require\ninnovative, science-guided approaches. In this study, we present the first\napplication of Buckingham Pi theory to modelling biofilter performance. This\ndimensionality reduction technique identifies meaningful, dimensionless\nvariables that enhance predictive accuracy and improve model interpretability.\nUsing these variables, we developed the Environmental Buckingham Pi Neural\nNetwork (EnviroPiNet), a physics-guided model benchmarked against traditional\ndata-driven methods, including Principal Component Analysis (PCA) and\nautoencoder neural networks. Our findings demonstrate that the EnviroPiNet\nmodel achieves an R^2 value of 0.9236 on the testing dataset, significantly\noutperforming PCA and autoencoder methods. The Buckingham Pi variables also\nprovide insights into the physical and chemical relationships governing\nbiofilter behaviour, with implications for system design and optimization. This\nstudy highlights the potential of combining physical principles with AI\napproaches to model complex environmental systems characterized by sparse,\nhigh-dimensional datasets.", "AI": {"tldr": "The paper introduces Buckingham Pi theory to model biofilter performance, creating the EnviroPiNet model, which outperforms traditional methods like PCA and autoencoders with an R\u00b2 of 0.9236.", "motivation": "Predicting biofilter performance is difficult due to sparse, high-dimensional data. The study aims to improve accuracy using physics-guided approaches.", "method": "Applied Buckingham Pi theory for dimensionality reduction and developed EnviroPiNet, a physics-guided neural network, comparing it to PCA and autoencoders.", "result": "EnviroPiNet achieved an R\u00b2 of 0.9236, outperforming PCA and autoencoders, and provided insights into biofilter behavior.", "conclusion": "Combining physical principles with AI enhances modeling of complex environmental systems with sparse data."}}
{"id": "2504.19027", "pdf": "https://arxiv.org/pdf/2504.19027", "abs": "https://arxiv.org/abs/2504.19027", "authors": ["Volkan Bakir", "Polat Goktas", "Sureyya Akyuz"], "title": "DiCE-Extended: A Robust Approach to Counterfactual Explanations in Machine Learning", "categories": ["cs.AI", "cs.LG", "cs.NE", "I.2; K.4; H.4"], "comment": "MCO 2025, 5th International Conference on Modelling, Computation and\n  Optimization in Information Systems and Management Sciences", "summary": "Explainable artificial intelligence (XAI) has become increasingly important\nin decision-critical domains such as healthcare, finance, and law.\nCounterfactual (CF) explanations, a key approach in XAI, provide users with\nactionable insights by suggesting minimal modifications to input features that\nlead to different model outcomes. Despite significant advancements, existing CF\ngeneration methods often struggle to balance proximity, diversity, and\nrobustness, limiting their real-world applicability. A widely adopted\nframework, Diverse Counterfactual Explanations (DiCE), emphasizes diversity but\nlacks robustness, making CF explanations sensitive to perturbations and domain\nconstraints. To address these challenges, we introduce DiCE-Extended, an\nenhanced CF explanation framework that integrates multi-objective optimization\ntechniques to improve robustness while maintaining interpretability. Our\napproach introduces a novel robustness metric based on the Dice-Sorensen\ncoefficient, ensuring stability under small input variations. Additionally, we\nrefine CF generation using weighted loss components (lambda_p, lambda_d,\nlambda_r) to balance proximity, diversity, and robustness. We empirically\nvalidate DiCE-Extended on benchmark datasets (COMPAS, Lending Club, German\nCredit, Adult Income) across multiple ML backends (Scikit-learn, PyTorch,\nTensorFlow). Results demonstrate improved CF validity, stability, and alignment\nwith decision boundaries compared to standard DiCE-generated explanations. Our\nfindings highlight the potential of DiCE-Extended in generating more reliable\nand interpretable CFs for high-stakes applications. Future work will explore\nadaptive optimization techniques and domain-specific constraints to further\nenhance CF generation in real-world scenarios.", "AI": {"tldr": "DiCE-Extended improves counterfactual (CF) explanations by balancing proximity, diversity, and robustness using multi-objective optimization and a novel robustness metric.", "motivation": "Existing CF methods like DiCE lack robustness, limiting real-world applicability in decision-critical domains.", "method": "DiCE-Extended integrates multi-objective optimization, introduces a Dice-Sorensen-based robustness metric, and refines CF generation with weighted loss components.", "result": "Empirical validation shows improved CF validity, stability, and alignment with decision boundaries compared to standard DiCE.", "conclusion": "DiCE-Extended enhances reliability and interpretability of CFs, with future work focusing on adaptive optimization and domain-specific constraints."}}
{"id": "2504.19401", "pdf": "https://arxiv.org/pdf/2504.19401", "abs": "https://arxiv.org/abs/2504.19401", "authors": ["Shuo Wang", "Tong Ren", "Nan Cheng", "Li Zhang", "Rong Wang"], "title": "Innovative Integration of 4D Cardiovascular Reconstruction and Hologram: A New Visualization Tool for Coronary Artery Bypass Grafting Planning", "categories": ["physics.med-ph", "cs.CV", "cs.GR", "eess.IV", "J.3; I.3.8"], "comment": "35 pages, 9 figures", "summary": "Background: Coronary artery bypass grafting (CABG) planning requires advanced\nspatial visualization and consideration of coronary artery depth,\ncalcification, and pericardial adhesions. Objective: To develop and evaluate a\ndynamic cardiovascular holographic visualization tool for preoperative CABG\nplanning. Methods: Using 4D cardiac computed tomography angiography data from\n14 CABG candidates, we developed a semi-automated workflow for time-resolved\nsegmentation of cardiac structures, epicardial adipose tissue (EAT), and\ncoronary arteries with calcium scoring. The workflow incorporated methods for\ncardiac segmentation, coronary calcification quantification, visualization of\ncoronary depth within EAT, and pericardial adhesion assessment through motion\nanalysis. Dynamic cardiovascular holograms were displayed using the Looking\nGlass platform. Thirteen cardiac surgeons evaluated the tool using a Likert\nscale. Additionally, pericardial adhesion scores from holograms of 21 patients\n(including seven undergoing secondary cardiac surgeries) were compared with\nintraoperative findings. Results: Surgeons rated the visualization tool highly\nfor preoperative planning utility (mean Likert score: 4.57/5.0). Hologram-based\npericardial adhesion scoring strongly correlated with intraoperative findings\n(r=0.786, P<0.001). Conclusion: This study establishes a visualization\nframework for CABG planning that produces clinically relevant dynamic holograms\nfrom patient-specific data, with clinical feedback confirming its effectiveness\nfor preoperative planning.", "AI": {"tldr": "A dynamic holographic tool for CABG planning was developed and evaluated, showing high utility and strong correlation with intraoperative findings.", "motivation": "To improve CABG planning by providing advanced spatial visualization of coronary artery depth, calcification, and pericardial adhesions.", "method": "Used 4D cardiac CT data to create a semi-automated workflow for segmentation and holographic visualization, evaluated by surgeons.", "result": "Surgeons rated the tool highly (4.57/5.0), and hologram-based adhesion scores correlated strongly with intraoperative findings (r=0.786).", "conclusion": "The tool is effective for CABG planning, confirmed by clinical feedback."}}
{"id": "2504.19024", "pdf": "https://arxiv.org/pdf/2504.19024", "abs": "https://arxiv.org/abs/2504.19024", "authors": ["Jiabin Fan", "Guoqing Luo", "Michael Bowling", "Lili Mou"], "title": "KETCHUP: K-Step Return Estimation for Sequential Knowledge Distillation", "categories": ["cs.CL"], "comment": null, "summary": "We propose a novel k-step return estimation method (called KETCHUP) for\nReinforcement Learning(RL)-based knowledge distillation (KD) in text generation\ntasks. Our idea is to induce a K-step return by using the Bellman Optimality\nEquation for multiple steps. Theoretical analysis shows that this K-step\nformulation reduces the variance of the gradient estimates, thus leading to\nimproved RL optimization especially when the student model size is large.\nEmpirical evaluation on three text generation tasks demonstrates that our\napproach yields superior performance in both standard task metrics and large\nlanguage model (LLM)-based evaluation. These results suggest that our K-step\nreturn induction offers a promising direction for enhancing RL-based KD in LLM\nresearch.", "AI": {"tldr": "KETCHUP, a novel k-step return estimation method for RL-based knowledge distillation in text generation, reduces gradient variance and improves optimization, especially for large student models.", "motivation": "To enhance RL-based knowledge distillation in text generation by reducing gradient variance through a k-step return formulation.", "method": "Uses the Bellman Optimality Equation for multiple steps to induce a K-step return, theoretically reducing gradient variance.", "result": "Superior performance in text generation tasks, validated by standard metrics and LLM-based evaluation.", "conclusion": "KETCHUP offers a promising direction for improving RL-based KD in large language model research."}}
{"id": "2504.18886", "pdf": "https://arxiv.org/pdf/2504.18886", "abs": "https://arxiv.org/abs/2504.18886", "authors": ["Simone Maurizio La Cava", "Roberto Casula", "Sara Concas", "Giulia Orr\u00f9", "Ruben Tolosana", "Martin Drahansky", "Julian Fierrez", "Gian Luca Marcialis"], "title": "Exploiting Multiple Representations: 3D Face Biometrics Fusion with Application to Surveillance", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "3D face reconstruction (3DFR) algorithms are based on specific assumptions\ntailored to the limits and characteristics of the different application\nscenarios. In this study, we investigate how multiple state-of-the-art 3DFR\nalgorithms can be used to generate a better representation of subjects, with\nthe final goal of improving the performance of face recognition systems in\nchallenging uncontrolled scenarios. We also explore how different parametric\nand non-parametric score-level fusion methods can exploit the unique strengths\nof multiple 3DFR algorithms to enhance biometric recognition robustness. With\nthis goal, we propose a comprehensive analysis of several face recognition\nsystems across diverse conditions, such as varying distances and camera setups,\nintra-dataset and cross-dataset, to assess the robustness of the proposed\nensemble method. The results demonstrate that the distinct information provided\nby different 3DFR algorithms can alleviate the problem of generalizing over\nmultiple application scenarios. In addition, the present study highlights the\npotential of advanced fusion strategies to enhance the reliability of\n3DFR-based face recognition systems, providing the research community with key\ninsights to exploit them in real-world applications effectively. Although the\nexperiments are carried out in a specific face verification setup, our proposed\nfusion-based 3DFR methods may be applied to other tasks around face biometrics\nthat are not strictly related to identity recognition.", "AI": {"tldr": "The paper explores using multiple 3D face reconstruction (3DFR) algorithms and fusion methods to improve face recognition in uncontrolled scenarios, demonstrating enhanced robustness and generalization.", "motivation": "To address the limitations of single 3DFR algorithms in face recognition systems, especially in challenging, uncontrolled scenarios, by leveraging multiple algorithms and fusion techniques.", "method": "Analyzes various 3DFR algorithms and employs parametric and non-parametric score-level fusion methods to combine their strengths. Tests face recognition systems under diverse conditions (e.g., varying distances, camera setups) to evaluate robustness.", "result": "Shows that combining multiple 3DFR algorithms improves generalization across scenarios. Advanced fusion strategies enhance the reliability of face recognition systems.", "conclusion": "Proposes fusion-based 3DFR methods as effective for improving face recognition robustness, with potential applications beyond identity recognition."}}
{"id": "2504.18599", "pdf": "https://arxiv.org/pdf/2504.18599", "abs": "https://arxiv.org/abs/2504.18599", "authors": ["Subhadip Bandyopadhyay", "Joy Bose", "Sujoy Roy Chowdhury"], "title": "A Hybrid Framework for Real-Time Data Drift and Anomaly Identification Using Hierarchical Temporal Memory and Statistical Tests", "categories": ["cs.LG", "62M10, 62P30, 68T07", "G.3; I.2.6; I.2.7; H.2.8; H.3.3"], "comment": "26 pages, 9 figures", "summary": "Data Drift is the phenomenon where the generating model behind the data\nchanges over time. Due to data drift, any model built on the past training data\nbecomes less relevant and inaccurate over time. Thus, detecting and controlling\nfor data drift is critical in machine learning models. Hierarchical Temporal\nMemory (HTM) is a machine learning model developed by Jeff Hawkins, inspired by\nhow the human brain processes information. It is a biologically inspired model\nof memory that is similar in structure to the neocortex, and whose performance\nis claimed to be comparable to state of the art models in detecting anomalies\nin time series data. Another unique benefit of HTMs is its independence from\ntraining and testing cycle; all the learning takes place online with streaming\ndata and no separate training and testing cycle is required. In sequential\nlearning paradigm, Sequential Probability Ratio Test (SPRT) offers some unique\nbenefit for online learning and inference. This paper proposes a novel hybrid\nframework combining HTM and SPRT for real-time data drift detection and anomaly\nidentification. Unlike existing data drift methods, our approach eliminates\nfrequent retraining and ensures low false positive rates. HTMs currently work\nwith one dimensional or univariate data. In a second study, we also propose an\napplication of HTM in multidimensional supervised scenario for anomaly\ndetection by combining the outputs of multiple HTM columns, one for each\ndimension of the data, through a neural network. Experimental evaluations\ndemonstrate that the proposed method outperforms conventional drift detection\ntechniques like the Kolmogorov-Smirnov (KS) test, Wasserstein distance, and\nPopulation Stability Index (PSI) in terms of accuracy, adaptability, and\ncomputational efficiency. Our experiments also provide insights into optimizing\nhyperparameters for real-time deployment in domains such as Telecom.", "AI": {"tldr": "A hybrid framework combining HTM and SPRT is proposed for real-time data drift detection and anomaly identification, outperforming traditional methods in accuracy and efficiency.", "motivation": "Data drift reduces model relevance over time, necessitating effective detection methods. HTM's biological inspiration and online learning capabilities make it suitable for this task.", "method": "Combines HTM and SPRT for drift detection and anomaly identification, with an extension to multidimensional data using multiple HTM columns and a neural network.", "result": "Outperforms KS test, Wasserstein distance, and PSI in accuracy, adaptability, and computational efficiency.", "conclusion": "The proposed hybrid framework is effective for real-time drift detection and anomaly identification, with potential for optimization in domains like Telecom."}}
{"id": "2504.19144", "pdf": "https://arxiv.org/pdf/2504.19144", "abs": "https://arxiv.org/abs/2504.19144", "authors": ["Bowei Wang", "Jiaran Gao", "Yelai Feng", "Renzhi Chen", "Shanshan Li", "Lei Wang"], "title": "ChiseLLM: Unleashing the Power of Reasoning LLMs for Chisel Agile Hardware Development", "categories": ["cs.AI", "cs.AR", "cs.SE"], "comment": null, "summary": "The growing demand for Domain-Specific Architecture (DSA) has driven the\ndevelopment of Agile Hardware Development Methodology (AHDM). Hardware\nConstruction Language (HCL) like Chisel offers high-level abstraction features,\nmaking it an ideal language for HCL-Based AHDM. While Large Language Models\n(LLMs) excel in code generation tasks, they still face challenges with Chisel\ngeneration, particularly regarding syntax correctness and design variability.\nRecent reasoning models have significantly enhanced code generation\ncapabilities through test-time scaling techniques. However, we found that\nreasoning models without domain adaptation cannot bring substantial benefits to\nChisel code generation tasks. This paper presents ChiseLLM, a solution\ncomprising data processing and transformation, prompt-guided reasoning trace\nsynthesis, and domain-adapted model training. We constructed high-quality\ndatasets from public RTL code resources and guided the model to adopt\nstructured thinking patterns through prompt enhancement methods. Experiments\ndemonstrate that our ChiseLLM-7B and ChiseLLM-32B models improved syntax\ncorrectness by 18.85% and 26.32% respectively over base models, while\nincreasing variability design ability by 47.58% compared to baseline reasoning\nmodels. Our datasets and models are publicly available, providing\nhigh-performance, cost-effective models for HCL-Based AHDM, and offering an\neffective baseline for future research. Github repository:\nhttps://github.com/observerw/ChiseLLM", "AI": {"tldr": "ChiseLLM improves Chisel code generation by enhancing syntax correctness and design variability through domain adaptation and prompt-guided reasoning.", "motivation": "The need for better Chisel code generation in Agile Hardware Development Methodology (AHDM) due to limitations of LLMs in syntax correctness and variability.", "method": "ChiseLLM combines data processing, prompt-guided reasoning trace synthesis, and domain-adapted model training using high-quality datasets from RTL code.", "result": "ChiseLLM-7B and ChiseLLM-32B improved syntax correctness by 18.85% and 26.32%, and design variability by 47.58% over baselines.", "conclusion": "ChiseLLM provides a high-performance, cost-effective solution for HCL-Based AHDM and sets a benchmark for future research."}}
{"id": "2504.19589", "pdf": "https://arxiv.org/pdf/2504.19589", "abs": "https://arxiv.org/abs/2504.19589", "authors": ["Daniele Rege Cambrin", "Luca Colomba", "Paolo Garza"], "title": "Magnifier: A Multi-grained Neural Network-based Architecture for Burned Area Delineation", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted in IEEE Journal of Selected Topics in Applied Earth\n  Observations and Remote Sensing", "summary": "In crisis management and remote sensing, image segmentation plays a crucial\nrole, enabling tasks like disaster response and emergency planning by analyzing\nvisual data. Neural networks are able to analyze satellite acquisitions and\ndetermine which areas were affected by a catastrophic event. The problem in\ntheir development in this context is the data scarcity and the lack of\nextensive benchmark datasets, limiting the capabilities of training large\nneural network models. In this paper, we propose a novel methodology, namely\nMagnifier, to improve segmentation performance with limited data availability.\nThe Magnifier methodology is applicable to any existing encoder-decoder\narchitecture, as it extends a model by merging information at different\ncontextual levels through a dual-encoder approach: a local and global encoder.\nMagnifier analyzes the input data twice using the dual-encoder approach. In\nparticular, the local and global encoders extract information from the same\ninput at different granularities. This allows Magnifier to extract more\ninformation than the other approaches given the same set of input images.\nMagnifier improves the quality of the results of +2.65% on average IoU while\nleading to a restrained increase in terms of the number of trainable parameters\ncompared to the original model. We evaluated our proposed approach with\nstate-of-the-art burned area segmentation models, demonstrating, on average,\ncomparable or better performances in less than half of the GFLOPs.", "AI": {"tldr": "The paper introduces Magnifier, a dual-encoder methodology for improving image segmentation in crisis management with limited data, achieving better performance (+2.65% IoU) with minimal parameter increase.", "motivation": "Data scarcity and lack of benchmark datasets hinder neural network training for disaster-related image segmentation.", "method": "Magnifier uses a dual-encoder (local and global) approach to merge contextual information at different granularities, enhancing segmentation with limited data.", "result": "Magnifier improves IoU by 2.65% and achieves comparable or better performance with fewer GFLOPs than state-of-the-art models.", "conclusion": "Magnifier is a scalable, efficient solution for improving segmentation in data-scarce scenarios, applicable to existing encoder-decoder architectures."}}
{"id": "2504.19044", "pdf": "https://arxiv.org/pdf/2504.19044", "abs": "https://arxiv.org/abs/2504.19044", "authors": ["Di Wu", "Yibin Lei", "Christof Monz"], "title": "Calibrating Translation Decoding with Quality Estimation on LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Neural machine translation (NMT) systems typically employ maximum a\nposteriori (MAP) decoding to select the highest-scoring translation from the\ndistribution mass. However, recent evidence highlights the inadequacy of MAP\ndecoding, often resulting in low-quality or even pathological hypotheses -- the\ndecoding objective is not aligned with real-world translation quality. This\npaper proposes calibrating hypothesis likelihoods with translation quality from\na distribution view by directly optimizing their Pearson correlation -- thereby\nenhancing the effectiveness of translation decoding. With our method,\ntranslation on large language models (LLMs) improves substantially after\nlimited training (2K instances per direction). This improvement is orthogonal\nto those achieved through supervised fine-tuning, leading to substantial gains\nacross a broad range of metrics and human evaluations -- even when applied to\ntop-performing translation-specialized LLMs fine-tuned on high-quality\ntranslation data, such as Tower, or when compared to recent preference\noptimization methods, like CPO. Moreover, the calibrated translation likelihood\ncan directly serve as a strong proxy for translation quality, closely\napproximating or even surpassing some state-of-the-art translation quality\nestimation models, like CometKiwi. Lastly, our in-depth analysis demonstrates\nthat calibration enhances the effectiveness of MAP decoding, thereby enabling\ngreater efficiency in real-world deployment. The resulting state-of-the-art\ntranslation model, which covers 10 languages, along with the accompanying code\nand human evaluation data, has been released to the community:\nhttps://github.com/moore3930/calibrating-llm-mt.", "AI": {"tldr": "The paper proposes calibrating hypothesis likelihoods in NMT to align decoding objectives with real-world translation quality, improving performance even on top LLMs.", "motivation": "MAP decoding in NMT often produces low-quality translations due to misalignment with real-world quality.", "method": "Calibrate hypothesis likelihoods by optimizing their Pearson correlation with translation quality.", "result": "Substantial improvements in translation quality across metrics and human evaluations, even on specialized LLMs.", "conclusion": "Calibration enhances MAP decoding efficiency and serves as a strong proxy for translation quality, outperforming some state-of-the-art models."}}
{"id": "2504.18906", "pdf": "https://arxiv.org/pdf/2504.18906", "abs": "https://arxiv.org/abs/2504.18906", "authors": ["Yufeng Wu", "Xin Liao", "Baowei Wang", "Han Fang", "Xiaoshuai Wu", "Guiling Wang"], "title": "Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness", "categories": ["cs.CV"], "comment": null, "summary": "Unauthorized screen capturing and dissemination pose severe security threats\nsuch as data leakage and information theft. Several studies propose robust\nwatermarking methods to track the copyright of Screen-Camera (SC) images,\nfacilitating post-hoc certification against infringement. These techniques\ntypically employ heuristic mathematical modeling or supervised neural network\nfitting as the noise layer, to enhance watermarking robustness against SC.\nHowever, both strategies cannot fundamentally achieve an effective\napproximation of SC noise. Mathematical simulation suffers from biased\napproximations due to the incomplete decomposition of the noise and the absence\nof interdependence among the noise components. Supervised networks require\npaired data to train the noise-fitting model, and it is difficult for the model\nto learn all the features of the noise. To address the above issues, we propose\nSimulation-to-Real (S2R). Specifically, an unsupervised noise layer employs\nunpaired data to learn the discrepancy between the modeling simulated noise\ndistribution and the real-world SC noise distribution, rather than directly\nlearning the mapping from sharp images to real-world images. Learning this\ntransformation from simulation to reality is inherently simpler, as it\nprimarily involves bridging the gap in noise distributions, instead of the\ncomplex task of reconstructing fine-grained image details. Extensive\nexperimental results validate the efficacy of the proposed method,\ndemonstrating superior watermark robustness and generalization compared to\nthose of state-of-the-art methods.", "AI": {"tldr": "Proposes Simulation-to-Real (S2R), an unsupervised method to improve watermarking robustness against screen-camera noise by learning noise distribution discrepancies.", "motivation": "Existing watermarking methods for screen-camera images fail to effectively approximate noise due to biased mathematical modeling or supervised learning limitations.", "method": "Uses unsupervised learning with unpaired data to bridge the gap between simulated and real-world noise distributions.", "result": "Outperforms state-of-the-art methods in watermark robustness and generalization.", "conclusion": "S2R provides a simpler, more effective solution for watermarking in screen-camera scenarios."}}
{"id": "2504.18668", "pdf": "https://arxiv.org/pdf/2504.18668", "abs": "https://arxiv.org/abs/2504.18668", "authors": ["Daehyeon Han", "Morteza Karimzadeh"], "title": "Exploring the Potential of Latent Embeddings for Sea Ice Characterization using ICESat-2 Data", "categories": ["cs.LG", "physics.ao-ph"], "comment": "4 pages, 4 figures", "summary": "The Ice, Cloud, and Elevation Satellite-2 (ICESat-2) provides high-resolution\nmeasurements of sea ice height. Recent studies have developed machine learning\nmethods on ICESat-2 data, primarily focusing on surface type classification.\nHowever, the heavy reliance on manually collected labels requires significant\ntime and effort for supervised learning, as it involves cross-referencing track\nmeasurements with overlapping background optical imagery. Additionally, the\ncoincidence of ICESat-2 tracks with background images is relatively rare due to\nthe different overpass patterns and atmospheric conditions. To address these\nlimitations, this study explores the potential of unsupervised autoencoder on\nunlabeled data to derive latent embeddings. We develop autoencoder models based\non Long Short-Term Memory (LSTM) and Convolutional Neural Networks (CNN) to\nreconstruct topographic sequences from ICESat-2 and derive embeddings. We then\napply Uniform Manifold Approximation and Projection (UMAP) to reduce dimensions\nand visualize the embeddings. Our results show that embeddings from\nautoencoders preserve the overall structure but generate relatively more\ncompact clusters compared to the original ICESat-2 data, indicating the\npotential of embeddings to lessen the number of required labels samples.", "AI": {"tldr": "The study explores unsupervised autoencoders for ICESat-2 data to reduce reliance on manual labels, using LSTM and CNN models to derive embeddings, which show promise in reducing label requirements.", "motivation": "Manual label collection for ICESat-2 data is time-consuming and limited by rare coincidences with background imagery, prompting the need for unsupervised methods.", "method": "Developed LSTM and CNN autoencoder models to reconstruct topographic sequences and derive embeddings, followed by UMAP for dimensionality reduction and visualization.", "result": "Autoencoder embeddings preserved data structure and formed more compact clusters, suggesting reduced label dependency.", "conclusion": "Unsupervised autoencoders show potential to lessen manual labeling efforts for ICESat-2 data analysis."}}
{"id": "2504.19148", "pdf": "https://arxiv.org/pdf/2504.19148", "abs": "https://arxiv.org/abs/2504.19148", "authors": ["Ke Liu", "Jing Ma", "Edmund M-K Lai"], "title": "A Dynamic Fuzzy Rule and Attribute Management Framework for Fuzzy Inference Systems in High-Dimensional Data", "categories": ["cs.AI"], "comment": null, "summary": "This paper presents an Adaptive Dynamic Attribute and Rule (ADAR) framework\ndesigned to address the challenges posed by high-dimensional data in\nneuro-fuzzy inference systems. By integrating dual weighting\nmechanisms-assigning adaptive importance to both attributes and rules-together\nwith automated growth and pruning strategies, ADAR adaptively streamlines\ncomplex fuzzy models without sacrificing performance or interpretability.\nExperimental evaluations on four diverse datasets - Auto MPG (7 variables),\nBeijing PM2.5 (10 variables), Boston Housing (13 variables), and Appliances\nEnergy Consumption (27 variables) show that ADAR-based models achieve\nconsistently lower Root Mean Square Error (RMSE) compared to state-of-the-art\nbaselines. On the Beijing PM2.5 dataset, for instance, ADAR-SOFENN attained an\nRMSE of 56.87 with nine rules, surpassing traditional ANFIS [12] and SOFENN\n[16] models. Similarly, on the high-dimensional Appliances Energy dataset,\nADAR-ANFIS reached an RMSE of 83.25 with nine rules, outperforming established\nfuzzy logic approaches and interpretability-focused methods such as APLR.\nAblation studies further reveal that combining rule-level and attribute-level\nweight assignment significantly reduces model overlap while preserving\nessential features, thereby enhancing explainability. These results highlight\nADAR's effectiveness in dynamically balancing rule complexity and feature\nimportance, paving the way for scalable, high-accuracy, and transparent\nneuro-fuzzy systems applicable to a range of real-world scenarios.", "AI": {"tldr": "ADAR framework improves neuro-fuzzy systems by dynamically weighting attributes and rules, achieving lower RMSE than baselines while maintaining interpretability.", "motivation": "Address challenges of high-dimensional data in neuro-fuzzy systems, balancing performance and interpretability.", "method": "Integrates dual weighting mechanisms (attributes and rules) with automated growth/pruning strategies.", "result": "Consistently lower RMSE on diverse datasets; outperforms ANFIS, SOFENN, and APLR.", "conclusion": "ADAR effectively balances complexity and feature importance, enabling scalable, accurate, and transparent neuro-fuzzy systems."}}
{"id": "2504.19621", "pdf": "https://arxiv.org/pdf/2504.19621", "abs": "https://arxiv.org/abs/2504.19621", "authors": ["Haroui Ma", "Francesco Quinzan", "Theresa Willem", "Stefan Bauer"], "title": "AI Alignment in Medical Imaging: Unveiling Hidden Biases Through Counterfactual Analysis", "categories": ["cs.LG", "eess.IV", "stat.ML"], "comment": null, "summary": "Machine learning (ML) systems for medical imaging have demonstrated\nremarkable diagnostic capabilities, but their susceptibility to biases poses\nsignificant risks, since biases may negatively impact generalization\nperformance. In this paper, we introduce a novel statistical framework to\nevaluate the dependency of medical imaging ML models on sensitive attributes,\nsuch as demographics. Our method leverages the concept of counterfactual\ninvariance, measuring the extent to which a model's predictions remain\nunchanged under hypothetical changes to sensitive attributes. We present a\npractical algorithm that combines conditional latent diffusion models with\nstatistical hypothesis testing to identify and quantify such biases without\nrequiring direct access to counterfactual data. Through experiments on\nsynthetic datasets and large-scale real-world medical imaging datasets,\nincluding \\textsc{cheXpert} and MIMIC-CXR, we demonstrate that our approach\naligns closely with counterfactual fairness principles and outperforms standard\nbaselines. This work provides a robust tool to ensure that ML diagnostic\nsystems generalize well, e.g., across demographic groups, offering a critical\nstep towards AI safety in healthcare. Code:\nhttps://github.com/Neferpitou3871/AI-Alignment-Medical-Imaging.", "AI": {"tldr": "A novel statistical framework evaluates ML models in medical imaging for biases using counterfactual invariance, outperforming baselines and ensuring better generalization.", "motivation": "ML systems in medical imaging risk biases affecting performance; this work aims to quantify and mitigate such biases.", "method": "Combines conditional latent diffusion models with statistical hypothesis testing to measure bias without counterfactual data.", "result": "Demonstrates alignment with counterfactual fairness and superior performance on synthetic and real-world datasets (CheXpert, MIMIC-CXR).", "conclusion": "Provides a robust tool for bias evaluation, enhancing AI safety and generalization in healthcare diagnostics."}}
{"id": "2504.19061", "pdf": "https://arxiv.org/pdf/2504.19061", "abs": "https://arxiv.org/abs/2504.19061", "authors": ["Anindya Bijoy Das", "Shibbir Ahmed", "Shahnewaz Karim Sakib"], "title": "Hallucinations and Key Information Extraction in Medical Texts: A Comprehensive Assessment of Open-Source Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Clinical summarization is crucial in healthcare as it distills complex\nmedical data into digestible information, enhancing patient understanding and\ncare management. Large language models (LLMs) have shown significant potential\nin automating and improving the accuracy of such summarizations due to their\nadvanced natural language understanding capabilities. These models are\nparticularly applicable in the context of summarizing medical/clinical texts,\nwhere precise and concise information transfer is essential. In this paper, we\ninvestigate the effectiveness of open-source LLMs in extracting key events from\ndischarge reports, such as reasons for hospital admission, significant\nin-hospital events, and critical follow-up actions. In addition, we also assess\nthe prevalence of various types of hallucinations in the summaries produced by\nthese models. Detecting hallucinations is vital as it directly influences the\nreliability of the information, potentially affecting patient care and\ntreatment outcomes. We conduct comprehensive numerical simulations to\nrigorously evaluate the performance of these models, further probing the\naccuracy and fidelity of the extracted content in clinical summarization.", "AI": {"tldr": "The paper explores the use of open-source large language models (LLMs) for clinical summarization, focusing on discharge reports, while also evaluating hallucination prevalence to ensure reliability.", "motivation": "Clinical summarization is essential for patient care, and LLMs can automate and improve its accuracy, but hallucinations must be addressed for reliability.", "method": "The study evaluates open-source LLMs by extracting key events from discharge reports and assessing hallucination prevalence through numerical simulations.", "result": "The research rigorously tests LLM performance in clinical summarization, focusing on accuracy and fidelity of extracted content.", "conclusion": "Open-source LLMs show promise for clinical summarization, but hallucination detection is critical for ensuring reliable information transfer in healthcare."}}
{"id": "2504.18910", "pdf": "https://arxiv.org/pdf/2504.18910", "abs": "https://arxiv.org/abs/2504.18910", "authors": ["Ali Nazari", "Mohsen Ebrahimi Moghaddam", "Omidreza Borzoei"], "title": "Kinship Verification through a Forest Neural Network", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Early methods used face representations in kinship verification, which are\nless accurate than joint representations of parents' and children's facial\nimages learned from scratch. We propose an approach featuring graph neural\nnetwork concepts to utilize face representations and have comparable results to\njoint representation algorithms. Moreover, we designed the structure of the\nclassification module and introduced a new combination of losses to engage the\ncenter loss gradually in training our network. Additionally, we conducted\nexperiments on KinFaceW-I and II, demonstrating the effectiveness of our\napproach. We achieved the best result on KinFaceW-II, an average improvement of\nnearly 1.6 for all kinship types, and we were near the best on KinFaceW-I. The\ncode is available at https://github.com/ali-nazari/Kinship-Verification", "AI": {"tldr": "Proposed a GNN-based approach for kinship verification, improving accuracy over traditional face representations and achieving top results on KinFaceW-II.", "motivation": "Early face representations for kinship verification were less accurate than joint representations, prompting a need for better methods.", "method": "Used graph neural networks to leverage face representations, designed a classification module, and introduced a gradual center loss combination.", "result": "Achieved best results on KinFaceW-II (1.6% average improvement) and near-best on KinFaceW-I.", "conclusion": "The GNN-based approach is effective for kinship verification, outperforming traditional methods."}}
{"id": "2504.18686", "pdf": "https://arxiv.org/pdf/2504.18686", "abs": "https://arxiv.org/abs/2504.18686", "authors": ["Mustafa Musab", "Joseph K. Chege", "Arie Yeredor", "Martin Haardt"], "title": "A Unified MDL-based Binning and Tensor Factorization Framework for PDF Estimation", "categories": ["cs.LG", "cs.IT", "math.IT", "math.PR", "stat.ML"], "comment": null, "summary": "Reliable density estimation is fundamental for numerous applications in\nstatistics and machine learning. In many practical scenarios, data are best\nmodeled as mixtures of component densities that capture complex and multimodal\npatterns. However, conventional density estimators based on uniform histograms\noften fail to capture local variations, especially when the underlying\ndistribution is highly nonuniform. Furthermore, the inherent discontinuity of\nhistograms poses challenges for tasks requiring smooth derivatives, such as\ngradient-based optimization, clustering, and nonparametric discriminant\nanalysis. In this work, we present a novel non-parametric approach for\nmultivariate probability density function (PDF) estimation that utilizes\nminimum description length (MDL)-based binning with quantile cuts. Our approach\nbuilds upon tensor factorization techniques, leveraging the canonical polyadic\ndecomposition (CPD) of a joint probability tensor. We demonstrate the\neffectiveness of our method on synthetic data and a challenging real dry bean\nclassification dataset.", "AI": {"tldr": "A novel non-parametric method for multivariate PDF estimation using MDL-based binning and tensor factorization, addressing limitations of uniform histograms.", "motivation": "Conventional density estimators like uniform histograms fail to capture local variations and smooth derivatives, limiting their effectiveness in complex, multimodal data scenarios.", "method": "Utilizes MDL-based binning with quantile cuts and tensor factorization (CPD) for joint probability tensor decomposition.", "result": "Demonstrated effectiveness on synthetic data and a real dry bean classification dataset.", "conclusion": "The proposed method offers a reliable solution for density estimation in complex, nonuniform distributions."}}
{"id": "2504.19179", "pdf": "https://arxiv.org/pdf/2504.19179", "abs": "https://arxiv.org/abs/2504.19179", "authors": ["Pedro A. Moreno-S\u00e1nchez", "Javier Del Ser", "Mark van Gils", "Jussi Hernesniemi"], "title": "A Design Framework for operationalizing Trustworthy Artificial Intelligence in Healthcare: Requirements, Tradeoffs and Challenges for its Clinical Adoption", "categories": ["cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) holds great promise for transforming healthcare,\nparticularly in disease diagnosis, prognosis, and patient care. The increasing\navailability of digital medical data, such as images, omics, biosignals, and\nelectronic health records, combined with advances in computing, has enabled AI\nmodels to approach expert-level performance. However, widespread clinical\nadoption remains limited, primarily due to challenges beyond technical\nperformance, including ethical concerns, regulatory barriers, and lack of\ntrust. To address these issues, AI systems must align with the principles of\nTrustworthy AI (TAI), which emphasize human agency and oversight, algorithmic\nrobustness, privacy and data governance, transparency, bias and discrimination\navoidance, and accountability. Yet, the complexity of healthcare processes\n(e.g., screening, diagnosis, prognosis, and treatment) and the diversity of\nstakeholders (clinicians, patients, providers, regulators) complicate the\nintegration of TAI principles. To bridge the gap between TAI theory and\npractical implementation, this paper proposes a design framework to support\ndevelopers in embedding TAI principles into medical AI systems. Thus, for each\nstakeholder identified across various healthcare processes, we propose a\ndisease-agnostic collection of requirements that medical AI systems should\nincorporate to adhere to the principles of TAI. Additionally, we examine the\nchallenges and tradeoffs that may arise when applying these principles in\npractice. To ground the discussion, we focus on cardiovascular diseases, a\nfield marked by both high prevalence and active AI innovation, and demonstrate\nhow TAI principles have been applied and where key obstacles persist.", "AI": {"tldr": "The paper proposes a design framework to integrate Trustworthy AI (TAI) principles into medical AI systems, addressing ethical, regulatory, and trust challenges in healthcare.", "motivation": "Despite AI's potential in healthcare, clinical adoption is hindered by non-technical challenges like ethics, regulation, and trust. TAI principles offer a solution but are hard to implement.", "method": "A disease-agnostic framework is proposed to embed TAI principles into medical AI systems, with stakeholder-specific requirements and an examination of practical challenges.", "result": "The framework is demonstrated using cardiovascular diseases, highlighting both successful TAI applications and persistent obstacles.", "conclusion": "The paper bridges TAI theory and practice, offering a practical approach to enhance trust and adoption of AI in healthcare."}}
{"id": "2401.00275", "pdf": "https://arxiv.org/pdf/2401.00275", "abs": "https://arxiv.org/abs/2401.00275", "authors": ["Vladyslav Gapyak", "Corinna Rentschler", "Thomas M\u00e4rz", "Andreas Weinmann"], "title": "An $\\ell^1$-Plug-and-Play Approach for MPI Using a Zero Shot Denoiser with Evaluation on the 3D Open MPI Dataset", "categories": ["eess.IV", "cs.CV", "cs.LG", "cs.NA", "math.NA"], "comment": "24 pages, 7 figures, additional supplementary material (78 pages\n  total)", "summary": "Objective: Magnetic particle imaging (MPI) is an emerging medical imaging\nmodality which has gained increasing interest in recent years. Among the\nbenefits of MPI are its high temporal resolution, and that the technique does\nnot expose the specimen to any kind of ionizing radiation. It is based on the\nnon-linear response of magnetic nanoparticles to an applied magnetic field.\nFrom the electric signal measured in receive coils, the particle concentration\nhas to be reconstructed. Due to the ill-posedness of the reconstruction\nproblem, various regularization methods have been proposed for reconstruction\nranging from early stopping methods, via classical Tikhonov regularization and\niterative methods to modern machine learning approaches. In this work, we\ncontribute to the latter class: we propose a plug-and-play approach based on a\ngeneric zero-shot denoiser with an $\\ell^1$-prior.\n  Approach: We validate the reconstruction parameters of the method on a hybrid\ndataset and compare it with the baseline Tikhonov, DIP and the previous PP-MPI,\nwhich is a plug-and-play method with denoiser trained on MPI-friendly data.\n  Main results: We offer a quantitative and qualitative evaluation of the\nzero-shot plug-and-play approach on the 3D Open MPI dataset. Moreover, we show\nthe quality of the approach with different levels of preprocessing of the data.\n  Significance: The proposed method employs a zero-shot denoiser which has not\nbeen trained for the MPI task and therefore saves the cost for training.\nMoreover, it offers a method that can be potentially applied in future MPI\ncontexts.", "AI": {"tldr": "A zero-shot plug-and-play denoiser with an \u2113\u00b9-prior is proposed for MPI reconstruction, avoiding training costs and showing competitive results.", "motivation": "MPI's high temporal resolution and non-ionizing nature make it promising, but its ill-posed reconstruction problem requires advanced regularization methods.", "method": "A zero-shot denoiser with \u2113\u00b9-prior is used for reconstruction, validated on hybrid and 3D Open MPI datasets against Tikhonov, DIP, and PP-MPI baselines.", "result": "Quantitative and qualitative evaluations show the method's effectiveness, even with varying preprocessing levels.", "conclusion": "The zero-shot approach eliminates training costs and is adaptable for future MPI applications."}}
{"id": "2504.19066", "pdf": "https://arxiv.org/pdf/2504.19066", "abs": "https://arxiv.org/abs/2504.19066", "authors": ["Deeksha Varshney", "Keane Ong", "Rui Mao", "Erik Cambria", "Gianmarco Mengaldo"], "title": "ClimaEmpact: Domain-Aligned Small Language Models and Datasets for Extreme Weather Analytics", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.ao-ph"], "comment": null, "summary": "Accurate assessments of extreme weather events are vital for research and\npolicy, yet localized and granular data remain scarce in many parts of the\nworld. This data gap limits our ability to analyze potential outcomes and\nimplications of extreme weather events, hindering effective decision-making.\nLarge Language Models (LLMs) can process vast amounts of unstructured text\ndata, extract meaningful insights, and generate detailed assessments by\nsynthesizing information from multiple sources. Furthermore, LLMs can\nseamlessly transfer their general language understanding to smaller models,\nenabling these models to retain key knowledge while being fine-tuned for\nspecific tasks. In this paper, we propose Extreme Weather Reasoning-Aware\nAlignment (EWRA), a method that enhances small language models (SLMs) by\nincorporating structured reasoning paths derived from LLMs, and\nExtremeWeatherNews, a large dataset of extreme weather event-related news\narticles. EWRA and ExtremeWeatherNews together form the overall framework,\nClimaEmpact, that focuses on addressing three critical extreme-weather tasks:\ncategorization of tangible vulnerabilities/impacts, topic labeling, and emotion\nanalysis. By aligning SLMs with advanced reasoning strategies on\nExtremeWeatherNews (and its derived dataset ExtremeAlign used specifically for\nSLM alignment), EWRA improves the SLMs' ability to generate well-grounded and\ndomain-specific responses for extreme weather analytics. Our results show that\nthe approach proposed guides SLMs to output domain-aligned responses,\nsurpassing the performance of task-specific models and offering enhanced\nreal-world applicability for extreme weather analytics.", "AI": {"tldr": "The paper proposes EWRA and ExtremeWeatherNews to enhance small language models (SLMs) for extreme weather analytics, improving categorization, labeling, and emotion analysis.", "motivation": "Localized data on extreme weather is scarce, limiting analysis and decision-making. LLMs can bridge this gap by processing unstructured data and transferring knowledge to SLMs.", "method": "Introduces EWRA, a method to align SLMs with reasoning paths from LLMs, and ExtremeWeatherNews, a dataset for training. The framework, ClimaEmpact, addresses categorization, topic labeling, and emotion analysis.", "result": "EWRA improves SLMs' domain-specific responses, outperforming task-specific models in extreme weather analytics.", "conclusion": "The proposed framework enhances SLMs' real-world applicability for extreme weather tasks, offering better decision-making support."}}
{"id": "2504.18959", "pdf": "https://arxiv.org/pdf/2504.18959", "abs": "https://arxiv.org/abs/2504.18959", "authors": ["Kamirul Kamirul", "Odysseas Pappas", "Alin Achim"], "title": "R-Sparse R-CNN: SAR Ship Detection Based on Background-Aware Sparse Learnable Proposals", "categories": ["cs.CV"], "comment": "Submitted to IEEE Journal of Selected Topics in Applied Earth\n  Observations and Remote Sensing", "summary": "We introduce R-Sparse R-CNN, a novel pipeline for oriented ship detection in\nSynthetic Aperture Radar (SAR) images that leverages sparse learnable proposals\nenriched with background contextual information, termed background-aware\nproposals (BAPs). The adoption of sparse proposals streamlines the pipeline by\neliminating the need for proposal generators and post-processing for\noverlapping predictions. The proposed BAPs enrich object representation by\nintegrating ship and background features, allowing the model to learn their\ncontextual relationships for more accurate distinction of ships in complex\nenvironments. To complement BAPs, we propose Dual-Context Pooling (DCP), a\nnovel strategy that jointly extracts ship and background features in a single\nunified operation. This unified design improves efficiency by eliminating\nredundant computation inherent in separate pooling. Moreover, by ensuring that\nship and background features are pooled from the same feature map level, DCP\nprovides aligned features that improve contextual relationship learning.\nFinally, as a core component of contextual relationship learning in R-Sparse\nR-CNN, we design a dedicated transformer-based Interaction Module. This module\ninteracts pooled ship and background features with corresponding proposal\nfeatures and models their relationships. Experimental results show that\nR-Sparse R-CNN delivers outstanding accuracy, surpassing state-of-the-art\nmodels by margins of up to 12.8% and 11.9% on SSDD and RSDD-SAR inshore\ndatasets, respectively. These results demonstrate the effectiveness and\ncompetitiveness of R-Sparse R-CNN as a robust framework for oriented ship\ndetection in SAR imagery. The code is available at:\nwww.github.com/ka-mirul/R-Sparse-R-CNN.", "AI": {"tldr": "R-Sparse R-CNN introduces a streamlined pipeline for ship detection in SAR images using sparse, background-aware proposals and a transformer-based Interaction Module, achieving superior accuracy.", "motivation": "The complexity of SAR imagery and overlapping ship detections necessitate a more efficient and accurate detection method.", "method": "The pipeline uses background-aware proposals (BAPs) and Dual-Context Pooling (DCP) to integrate ship and background features, alongside a transformer-based Interaction Module for contextual learning.", "result": "R-Sparse R-CNN outperforms state-of-the-art models by up to 12.8% and 11.9% on SSDD and RSDD-SAR datasets.", "conclusion": "The framework is effective and competitive for oriented ship detection in SAR imagery, with code publicly available."}}
{"id": "2504.18696", "pdf": "https://arxiv.org/pdf/2504.18696", "abs": "https://arxiv.org/abs/2504.18696", "authors": ["Felix Burr", "Marcel Hoffmann", "Ansgar Scherp"], "title": "Active Few-Shot Learning for Vertex Classification Starting from an Unlabeled Dataset", "categories": ["cs.LG"], "comment": "Accepted at IJCNN 2025", "summary": "Despite the ample availability of graph data, obtaining vertex labels is a\ntedious and expensive task. Therefore, it is desirable to learn from a few\nlabeled vertices only. Existing few-shot learners assume a class oracle, which\nprovides labeled vertices for a desired class. However, such an oracle is not\navailable in a real-world setting, i.e., when drawing a vertex for labeling it\nis unknown to which class the vertex belongs. Few-shot learners are often\ncombined with prototypical networks, while classical semi-supervised vertex\nclassification uses discriminative models, e.g., Graph Convolutional Networks\n(GCN). In this paper, we train our models by iteratively prompting a human\nannotator with vertices to annotate. We perform three experiments where we\ncontinually relax our assumptions. First, we assume a class oracle, i.e., the\nhuman annotator is provided with an equal number of vertices to label for each\nclass. We denote this as \"Balanced Sampling''. In the subsequent experiment,\n\"Unbalanced Sampling,'' we replace the class oracle with $k$-medoids clustering\nand draw vertices to label from the clusters. In the last experiment, the\n\"Unknown Number of Classes,'' we no longer assumed we knew the number and\ndistribution of classes. Our results show that prototypical models outperform\ndiscriminative models in all experiments when fewer than $20$ samples per class\nare available. While dropping the assumption of the class oracle for the\n\"Unbalanced Sampling'' experiment reduces the performance of the GCN by $9\\%$,\nthe prototypical network loses only $1\\%$ on average. For the \"Unknown Number\nof Classes'' experiment, the average performance for both models decreased\nfurther by $1\\%$.\n  Source code: https://github.com/Ximsa/2023-felix-ma", "AI": {"tldr": "The paper explores few-shot vertex classification without a class oracle, comparing prototypical and discriminative models under relaxed assumptions. Prototypical models outperform GCNs with limited labeled data.", "motivation": "Labeling vertices in graph data is costly, and existing few-shot learners rely on unrealistic class oracles. This work aims to address real-world scenarios where class information is unknown.", "method": "Three experiments were conducted: (1) Balanced Sampling with a class oracle, (2) Unbalanced Sampling using k-medoids clustering, and (3) Unknown Number of Classes. Models were trained by iteratively prompting human annotators.", "result": "Prototypical models consistently outperformed discriminative models (e.g., GCNs) with fewer than 20 labeled samples per class. Performance drops were smaller for prototypical models when assumptions were relaxed.", "conclusion": "Prototypical networks are more robust than discriminative models in few-shot vertex classification, especially when class information is uncertain or unavailable."}}
{"id": "2504.19255", "pdf": "https://arxiv.org/pdf/2504.19255", "abs": "https://arxiv.org/abs/2504.19255", "authors": ["Chad Coleman", "W. Russell Neuman", "Ali Dasdan", "Safinah Ali", "Manan Shah"], "title": "The Convergent Ethics of AI? Analyzing Moral Foundation Priorities in Large Language Models with a Multi-Framework Approach", "categories": ["cs.AI", "cs.CY"], "comment": "25 pages, 8 figures", "summary": "As large language models (LLMs) are increasingly deployed in consequential\ndecision-making contexts, systematically assessing their ethical reasoning\ncapabilities becomes a critical imperative. This paper introduces the\nPriorities in Reasoning and Intrinsic Moral Evaluation (PRIME) framework--a\ncomprehensive methodology for analyzing moral priorities across foundational\nethical dimensions including consequentialist-deontological reasoning, moral\nfoundations theory, and Kohlberg's developmental stages. We apply this\nframework to six leading LLMs through a dual-protocol approach combining direct\nquestioning and response analysis to established ethical dilemmas. Our analysis\nreveals striking patterns of convergence: all evaluated models demonstrate\nstrong prioritization of care/harm and fairness/cheating foundations while\nconsistently underweighting authority, loyalty, and sanctity dimensions.\nThrough detailed examination of confidence metrics, response reluctance\npatterns, and reasoning consistency, we establish that contemporary LLMs (1)\nproduce decisive ethical judgments, (2) demonstrate notable cross-model\nalignment in moral decision-making, and (3) generally correspond with\nempirically established human moral preferences. This research contributes a\nscalable, extensible methodology for ethical benchmarking while highlighting\nboth the promising capabilities and systematic limitations in current AI moral\nreasoning architectures--insights critical for responsible development as these\nsystems assume increasingly significant societal roles.", "AI": {"tldr": "The paper introduces the PRIME framework to evaluate LLMs' ethical reasoning, revealing alignment with human moral preferences but underweighting certain moral dimensions.", "motivation": "To systematically assess LLMs' ethical reasoning as they are deployed in consequential decision-making contexts.", "method": "The PRIME framework analyzes moral priorities using direct questioning and response analysis to ethical dilemmas across six leading LLMs.", "result": "LLMs prioritize care/harm and fairness/cheating, underweight authority/loyalty/sanctity, and align with human moral preferences.", "conclusion": "The PRIME framework provides scalable ethical benchmarking, revealing both capabilities and limitations in AI moral reasoning."}}
{"id": "2409.20332", "pdf": "https://arxiv.org/pdf/2409.20332", "abs": "https://arxiv.org/abs/2409.20332", "authors": ["Yuran Wang", "Zhijing Wan", "Yansheng Qiu", "Zheng Wang"], "title": "Devil is in Details: Locality-Aware 3D Abdominal CT Volume Generation for Self-Supervised Organ Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": "ACM MM 2024. Code is available at https://github.com/Ryann-Ran/Lad", "summary": "In the realm of medical image analysis, self-supervised learning (SSL)\ntechniques have emerged to alleviate labeling demands, while still facing the\nchallenge of training data scarcity owing to escalating resource requirements\nand privacy constraints. Numerous efforts employ generative models to generate\nhigh-fidelity, unlabeled 3D volumes across diverse modalities and anatomical\nregions. However, the intricate and indistinguishable anatomical structures\nwithin the abdomen pose a unique challenge to abdominal CT volume generation\ncompared to other anatomical regions. To address the overlooked challenge, we\nintroduce the Locality-Aware Diffusion (Lad), a novel method tailored for\nexquisite 3D abdominal CT volume generation. We design a locality loss to\nrefine crucial anatomical regions and devise a condition extractor to integrate\nabdominal priori into generation, thereby enabling the generation of large\nquantities of high-quality abdominal CT volumes essential for SSL tasks without\nthe need for additional data such as labels or radiology reports. Volumes\ngenerated through our method demonstrate remarkable fidelity in reproducing\nabdominal structures, achieving a decrease in FID score from 0.0034 to 0.0002\non AbdomenCT-1K dataset, closely mirroring authentic data and surpassing\ncurrent methods. Extensive experiments demonstrate the effectiveness of our\nmethod in self-supervised organ segmentation tasks, resulting in an improvement\nin mean Dice scores on two abdominal datasets effectively. These results\nunderscore the potential of synthetic data to advance self-supervised learning\nin medical image analysis.", "AI": {"tldr": "The paper introduces Locality-Aware Diffusion (Lad), a method for generating high-quality 3D abdominal CT volumes to address data scarcity in self-supervised learning (SSL) for medical image analysis.", "motivation": "To overcome the challenge of training data scarcity in medical image analysis due to resource and privacy constraints, especially for complex abdominal CT volumes.", "method": "Proposes Lad with a locality loss to refine anatomical regions and a condition extractor to integrate abdominal priori, enabling high-fidelity 3D CT volume generation without additional labeled data.", "result": "Achieves significant fidelity improvements (FID score drop from 0.0034 to 0.0002) and enhances SSL organ segmentation performance (higher mean Dice scores).", "conclusion": "Synthetic data generated by Lad can effectively advance SSL in medical image analysis, particularly for abdominal CT volumes."}}
{"id": "2504.19070", "pdf": "https://arxiv.org/pdf/2504.19070", "abs": "https://arxiv.org/abs/2504.19070", "authors": ["Sakshi Singh", "Abhinav Prakash", "Aakriti Shah", "Chaitanya Sachdeva", "Sanjana Dumpala"], "title": "Sample-Efficient Language Model for Hinglish Conversational AI", "categories": ["cs.CL", "I.2.7; I.2.6; H.5.2"], "comment": "5 pages, 2 tables, 2 figures", "summary": "This paper presents our process for developing a sample-efficient language\nmodel for a conversational Hinglish chatbot. Hinglish, a code-mixed language\nthat combines Hindi and English, presents a unique computational challenge due\nto inconsistent spelling, lack of standardization, and limited quality of\nconversational data. This work evaluates multiple pre-trained cross-lingual\nlanguage models, including Gemma3-4B and Qwen2.5-7B, and employs fine-tuning\ntechniques to improve performance on Hinglish conversational tasks. The\nproposed approach integrates synthetically generated dialogues with insights\nfrom existing Hinglish datasets to address data scarcity. Experimental results\ndemonstrate that models with fewer parameters, when appropriately fine-tuned on\nhigh-quality code-mixed data, can achieve competitive performance for Hinglish\nconversation generation while maintaining computational efficiency.", "AI": {"tldr": "The paper introduces a sample-efficient language model for a Hinglish chatbot, addressing challenges like inconsistent spelling and data scarcity by fine-tuning pre-trained models on synthetic and existing datasets.", "motivation": "Hinglish, a Hindi-English code-mixed language, poses computational challenges due to lack of standardization and limited conversational data, necessitating efficient modeling solutions.", "method": "Evaluates pre-trained models (Gemma3-4B, Qwen2.5-7B) and fine-tunes them using synthetic dialogues and existing Hinglish datasets to improve performance.", "result": "Smaller, fine-tuned models achieve competitive performance in Hinglish conversation generation while remaining computationally efficient.", "conclusion": "Fine-tuning smaller models on high-quality code-mixed data is effective for Hinglish chatbot development, balancing performance and efficiency."}}
{"id": "2504.18977", "pdf": "https://arxiv.org/pdf/2504.18977", "abs": "https://arxiv.org/abs/2504.18977", "authors": ["Ihsan Ullah", "Alfredo Petrosino"], "title": "3DPyranet Features Fusion for Spatio-temporal Feature Learning", "categories": ["cs.CV"], "comment": null, "summary": "Convolutional neural network (CNN) slides a kernel over the whole image to\nproduce an output map. This kernel scheme reduces the number of parameters with\nrespect to a fully connected neural network (NN). While CNN has proven to be an\neffective model in recognition of handwritten characters and traffic signal\nsign boards, etc. recently, its deep variants have proven to be effective in\nsimilar as well as more challenging applications like object, scene and action\nrecognition. Deep CNN add more layers and kernels to the classical CNN,\nincreasing the number of parameters, and partly reducing the main advantage of\nCNN which is less parameters. In this paper, a 3D pyramidal neural network\ncalled 3DPyraNet and a discriminative approach for spatio-temporal feature\nlearning based on it, called 3DPyraNet-F, are proposed. 3DPyraNet introduces a\nnew weighting scheme which learns features from both spatial and temporal\ndimensions analyzing multiple adjacent frames and keeping a biological\nplausible structure. It keeps the spatial topology of the input image and\npresents fewer parameters and lower computational and memory costs compared to\nboth fully connected NNs and recent deep CNNs. 3DPyraNet-F extract the features\nmaps of the highest layer of the learned network, fuse them in a single vector,\nand provide it as input in such a way to a linear-SVM classifier that enhances\nthe recognition of human actions and dynamic scenes from the videos.\nEncouraging results are reported with 3DPyraNet in real-world environments,\nespecially in the presence of camera induced motion. Further, 3DPyraNet-F\nclearly outperforms the state-of-the-art on three benchmark datasets and shows\ncomparable result for the fourth.", "AI": {"tldr": "The paper introduces 3DPyraNet, a 3D pyramidal neural network, and 3DPyraNet-F, a discriminative approach for spatio-temporal feature learning, addressing the parameter inefficiency of deep CNNs while maintaining biological plausibility and computational efficiency.", "motivation": "Deep CNNs increase parameters, reducing their advantage over fully connected NNs. The paper aims to propose a more efficient model for spatio-temporal feature learning in videos.", "method": "3DPyraNet uses a new weighting scheme to learn features from spatial and temporal dimensions, analyzing multiple frames. 3DPyraNet-F fuses feature maps into a vector for SVM-based action and scene recognition.", "result": "3DPyraNet shows promising results in real-world environments, especially with camera motion. 3DPyraNet-F outperforms state-of-the-art on three benchmarks and matches performance on a fourth.", "conclusion": "The proposed 3DPyraNet and 3DPyraNet-F offer efficient, biologically plausible solutions for spatio-temporal feature learning, demonstrating superior performance in action and scene recognition tasks."}}
{"id": "2504.18710", "pdf": "https://arxiv.org/pdf/2504.18710", "abs": "https://arxiv.org/abs/2504.18710", "authors": ["Patr\u00edcia Mu\u00f1oz Ewald"], "title": "Explicit neural network classifiers for non-separable data", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML", "57R70, 62M45"], "comment": "10 pages", "summary": "We fully characterize a large class of feedforward neural networks in terms\nof truncation maps. As an application, we show how a ReLU neural network can\nimplement a feature map which separates concentric data.", "AI": {"tldr": "The paper characterizes feedforward neural networks using truncation maps and demonstrates ReLU networks' ability to separate concentric data.", "motivation": "To understand and characterize the behavior of feedforward neural networks, particularly focusing on their implementation of feature maps.", "method": "Uses truncation maps to analyze a class of feedforward neural networks and applies this to ReLU networks.", "result": "Shows that ReLU neural networks can implement feature maps capable of separating concentric data.", "conclusion": "The study provides insights into the capabilities of feedforward neural networks, especially ReLU networks, in handling complex data structures like concentric data."}}
{"id": "2504.19277", "pdf": "https://arxiv.org/pdf/2504.19277", "abs": "https://arxiv.org/abs/2504.19277", "authors": ["Ishan Kavathekar", "Raghav Donakanti", "Ponnurangam Kumaraguru", "Karthik Vaidhyanathan"], "title": "Small Models, Big Tasks: An Exploratory Empirical Study on Small Language Models for Function Calling", "categories": ["cs.AI", "cs.SE"], "comment": "Accepted at EASE 2025 AI Models and Data Evaluation track", "summary": "Function calling is a complex task with widespread applications in domains\nsuch as information retrieval, software engineering and automation. For\nexample, a query to book the shortest flight from New York to London on January\n15 requires identifying the correct parameters to generate accurate function\ncalls. Large Language Models (LLMs) can automate this process but are\ncomputationally expensive and impractical in resource-constrained settings. In\ncontrast, Small Language Models (SLMs) can operate efficiently, offering faster\nresponse times, and lower computational demands, making them potential\ncandidates for function calling on edge devices. In this exploratory empirical\nstudy, we evaluate the efficacy of SLMs in generating function calls across\ndiverse domains using zero-shot, few-shot, and fine-tuning approaches, both\nwith and without prompt injection, while also providing the finetuned models to\nfacilitate future applications. Furthermore, we analyze the model responses\nacross a range of metrics, capturing various aspects of function call\ngeneration. Additionally, we perform experiments on an edge device to evaluate\ntheir performance in terms of latency and memory usage, providing useful\ninsights into their practical applicability. Our findings show that while SLMs\nimprove from zero-shot to few-shot and perform best with fine-tuning, they\nstruggle significantly with adhering to the given output format. Prompt\ninjection experiments further indicate that the models are generally robust and\nexhibit only a slight decline in performance. While SLMs demonstrate potential\nfor the function call generation task, our results also highlight areas that\nneed further refinement for real-time functioning.", "AI": {"tldr": "The paper explores the use of Small Language Models (SLMs) for function calling, comparing zero-shot, few-shot, and fine-tuning approaches. SLMs show promise but struggle with output format adherence.", "motivation": "Function calling is complex and widely applicable, but Large Language Models (LLMs) are impractical for resource-constrained settings. SLMs offer efficiency and speed, making them suitable for edge devices.", "method": "Evaluated SLMs using zero-shot, few-shot, and fine-tuning approaches, with and without prompt injection. Analyzed performance metrics and tested on edge devices for latency and memory usage.", "result": "SLMs improve from zero-shot to fine-tuning but struggle with output format. Prompt injection shows robustness with slight performance decline. SLMs show potential but need refinement for real-time use.", "conclusion": "SLMs are promising for function calling but require further refinement, especially in adhering to output formats and real-time performance."}}
{"id": "2411.14684", "pdf": "https://arxiv.org/pdf/2411.14684", "abs": "https://arxiv.org/abs/2411.14684", "authors": ["Tao Song", "Yicheng Wu", "Minhao Hu", "Xiangde Luo", "Linda Wei", "Guotai Wang", "Yi Guo", "Feng Xu", "Shaoting Zhang"], "title": "Learning Modality-Aware Representations: Adaptive Group-wise Interaction Network for Multimodal MRI Synthesis", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Multimodal MR image synthesis aims to generate missing modality images by\neffectively fusing and mapping from a subset of available MRI modalities. Most\nexisting methods adopt an image-to-image translation paradigm, treating\nmultiple modalities as input channels. However, these approaches often yield\nsub-optimal results due to the inherent difficulty in achieving precise\nfeature- or semantic-level alignment across modalities. To address these\nchallenges, we propose an Adaptive Group-wise Interaction Network (AGI-Net)\nthat explicitly models both inter-modality and intra-modality relationships for\nmultimodal MR image synthesis. Specifically, feature channels are first\npartitioned into predefined groups, after which an adaptive rolling mechanism\nis applied to conventional convolutional kernels to better capture feature and\nsemantic correspondences between different modalities. In parallel, a\ncross-group attention module is introduced to enable effective feature fusion\nacross groups, thereby enhancing the network's representational capacity. We\nvalidate the proposed AGI-Net on the publicly available IXI and BraTS2023\ndatasets. Experimental results demonstrate that AGI-Net achieves\nstate-of-the-art performance in multimodal MR image synthesis tasks, confirming\nthe effectiveness of its modality-aware interaction design. We release the\nrelevant code at:\nhttps://github.com/zunzhumu/Adaptive-Group-wise-Interaction-Network-for-Multimodal-MRI-Synthesis.git.", "AI": {"tldr": "AGI-Net improves multimodal MR image synthesis by modeling inter- and intra-modality relationships using adaptive group-wise interactions and cross-group attention.", "motivation": "Existing methods treat modalities as input channels, leading to sub-optimal results due to poor feature alignment.", "method": "AGI-Net partitions features into groups, uses adaptive rolling kernels for alignment, and employs cross-group attention for fusion.", "result": "AGI-Net achieves state-of-the-art performance on IXI and BraTS2023 datasets.", "conclusion": "AGI-Net's modality-aware design effectively enhances multimodal MR image synthesis."}}
{"id": "2504.19095", "pdf": "https://arxiv.org/pdf/2504.19095", "abs": "https://arxiv.org/abs/2504.19095", "authors": ["Jikai Wang", "Juntao Li", "Lijun Wu", "Min Zhang"], "title": "Efficient Reasoning for LLMs through Speculative Chain-of-Thought", "categories": ["cs.CL"], "comment": null, "summary": "Large reasoning language models such as OpenAI-o1 and Deepseek-R1 have\nrecently attracted widespread attention due to their impressive task-solving\nabilities. However, the enormous model size and the generation of lengthy\nthought chains introduce significant reasoning costs and response latency.\nExisting methods for efficient reasoning mainly focus on reducing the number of\nmodel parameters or shortening the chain-of-thought length. In this paper, we\nintroduce Speculative Chain-of-Thought (SCoT), which reduces reasoning latency\nfrom another perspective by accelerated average reasoning speed through large\nand small model collaboration. SCoT conducts thought-level drafting using a\nlightweight draft model. Then it selects the best CoT draft and corrects the\nerror cases with the target model. The proposed thinking behavior alignment\nimproves the efficiency of drafting and the draft selection strategy maintains\nthe prediction accuracy for complex problems. Experimental results on GSM8K,\nMATH, GaoKao, CollegeMath and Olympiad datasets show that SCoT reduces\nreasoning latency by 48\\%$\\sim$66\\% for Deepseek-R1-Distill-Qwen-32B while\nachieving near-target-model-level performance. Our code is available at\nhttps://github.com/Jikai0Wang/Speculative_CoT.", "AI": {"tldr": "SCoT reduces reasoning latency by 48%-66% for large models like Deepseek-R1-Distill-Qwen-32B while maintaining performance, using a draft model for thought-level drafting and error correction.", "motivation": "Large reasoning models face high costs and latency due to size and lengthy thought chains. Existing methods focus on parameter reduction or shortening chains, but SCoT addresses latency by improving reasoning speed through model collaboration.", "method": "SCoT uses a lightweight draft model for thought-level drafting, selects the best draft, and corrects errors with the target model. It aligns thinking behavior for efficiency and maintains accuracy with a draft selection strategy.", "result": "Experiments on GSM8K, MATH, GaoKao, CollegeMath, and Olympiad datasets show SCoT reduces latency by 48%-66% while achieving near-target-model performance.", "conclusion": "SCoT effectively reduces reasoning latency without compromising accuracy, demonstrating the potential of collaborative model approaches for efficient reasoning."}}
{"id": "2504.18983", "pdf": "https://arxiv.org/pdf/2504.18983", "abs": "https://arxiv.org/abs/2504.18983", "authors": ["Xuyin Qi", "Zeyu Zhang", "Canxuan Gang", "Hao Zhang", "Lei Zhang", "Zhiwei Zhang", "Yang Zhao"], "title": "MediAug: Exploring Visual Augmentation in Medical Imaging", "categories": ["cs.CV"], "comment": null, "summary": "Data augmentation is essential in medical imaging for improving\nclassification accuracy, lesion detection, and organ segmentation under limited\ndata conditions. However, two significant challenges remain. First, a\npronounced domain gap between natural photographs and medical images can\ndistort critical disease features. Second, augmentation studies in medical\nimaging are fragmented and limited to single tasks or architectures, leaving\nthe benefits of advanced mix-based strategies unclear. To address these\nchallenges, we propose a unified evaluation framework with six mix-based\naugmentation methods integrated with both convolutional and transformer\nbackbones on brain tumour MRI and eye disease fundus datasets. Our\ncontributions are threefold. (1) We introduce MediAug, a comprehensive and\nreproducible benchmark for advanced data augmentation in medical imaging. (2)\nWe systematically evaluate MixUp, YOCO, CropMix, CutMix, AugMix, and SnapMix\nwith ResNet-50 and ViT-B backbones. (3) We demonstrate through extensive\nexperiments that MixUp yields the greatest improvement on the brain tumor\nclassification task for ResNet-50 with 79.19% accuracy and SnapMix yields the\ngreatest improvement for ViT-B with 99.44% accuracy, and that YOCO yields the\ngreatest improvement on the eye disease classification task for ResNet-50 with\n91.60% accuracy and CutMix yields the greatest improvement for ViT-B with\n97.94% accuracy. Code will be available at\nhttps://github.com/AIGeeksGroup/MediAug.", "AI": {"tldr": "The paper proposes MediAug, a benchmark for evaluating mix-based data augmentation methods in medical imaging, showing performance improvements across tasks and architectures.", "motivation": "Addressing the domain gap between natural and medical images and the fragmented study of augmentation methods in medical imaging.", "method": "A unified framework evaluating six mix-based augmentation methods (MixUp, YOCO, CropMix, CutMix, AugMix, SnapMix) with ResNet-50 and ViT-B backbones on brain tumour MRI and eye disease datasets.", "result": "MixUp and SnapMix improved brain tumour classification (79.19% and 99.44% accuracy, respectively), while YOCO and CutMix improved eye disease classification (91.60% and 97.94% accuracy, respectively).", "conclusion": "MediAug provides a reproducible benchmark, demonstrating the effectiveness of mix-based augmentation in medical imaging tasks."}}
{"id": "2504.18720", "pdf": "https://arxiv.org/pdf/2504.18720", "abs": "https://arxiv.org/abs/2504.18720", "authors": ["G\u00e9r\u00f4me Andry", "Fran\u00e7ois Rozet", "Sacha Lewin", "Omer Rochman", "Victor Mangeleer", "Matthias Pirlet", "Elise Faulx", "Marilaure Gr\u00e9goire", "Gilles Louppe"], "title": "Appa: Bending Weather Dynamics with Latent Diffusion Models for Global Data Assimilation", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Deep learning has transformed weather forecasting by improving both its\naccuracy and computational efficiency. However, before any forecast can begin,\nweather centers must identify the current atmospheric state from vast amounts\nof observational data. To address this challenging problem, we introduce Appa,\na score-based data assimilation model producing global atmospheric trajectories\nat 0.25-degree resolution and 1-hour intervals. Powered by a 1.5B-parameter\nspatio-temporal latent diffusion model trained on ERA5 reanalysis data, Appa\ncan be conditioned on any type of observations to infer the posterior\ndistribution of plausible state trajectories, without retraining. Our unified\nprobabilistic framework flexibly tackles multiple inference tasks --\nreanalysis, filtering, and forecasting -- using the same model, eliminating the\nneed for task-specific architectures or training procedures. Experiments\ndemonstrate physical consistency on a global scale and good reconstructions\nfrom observations, while showing competitive forecasting skills. Our results\nestablish latent score-based data assimilation as a promising foundation for\nfuture global atmospheric modeling systems.", "AI": {"tldr": "Appa, a score-based data assimilation model, improves weather forecasting by inferring atmospheric states from observations using a unified probabilistic framework.", "motivation": "To address the challenge of identifying current atmospheric states from vast observational data for accurate weather forecasting.", "method": "Uses a 1.5B-parameter spatio-temporal latent diffusion model trained on ERA5 reanalysis data, conditioned on observations to infer plausible state trajectories.", "result": "Demonstrates physical consistency, good reconstructions, and competitive forecasting skills.", "conclusion": "Latent score-based data assimilation is a promising foundation for future global atmospheric modeling."}}
{"id": "2504.19320", "pdf": "https://arxiv.org/pdf/2504.19320", "abs": "https://arxiv.org/abs/2504.19320", "authors": ["Ralph Wojtowicz"], "title": "Logic-Based Artificial Intelligence Algorithms Supporting Categorical Semantics", "categories": ["cs.AI", "03, 18", "I.1.2"], "comment": "31 pages", "summary": "This paper seeks to apply categorical logic to the design of artificial\nintelligent agents that reason symbolically about objects more richly\nstructured than sets. Using Johnstone's sequent calculus of terms- and\nformulae-in-context, we develop forward chaining and normal form algorithms for\nreasoning about objects in cartesian categories with the rules for Horn logic.\nWe also adapt first-order unification to support multi-sorted theories,\ncontexts, and fragments of first-order logic. The significance of these\nreformulations rests in the fact that they can be applied to reasoning about\nobjects in semantic categories that do not support classical logic or even all\nits connectives.", "AI": {"tldr": "The paper applies categorical logic to design AI agents for symbolic reasoning about structured objects, using Johnstone's sequent calculus and adapting Horn logic and first-order unification for richer contexts.", "motivation": "To enable symbolic reasoning about objects in semantic categories that don't support classical logic or all its connectives.", "method": "Develops forward chaining and normal form algorithms using Johnstone's sequent calculus and adapts first-order unification for multi-sorted theories and contexts.", "result": "Provides reformulations for reasoning in non-classical semantic categories.", "conclusion": "The approach extends symbolic reasoning capabilities to more complex and less classical structures."}}
{"id": "2412.09998", "pdf": "https://arxiv.org/pdf/2412.09998", "abs": "https://arxiv.org/abs/2412.09998", "authors": ["Tao Song", "Yicheng Wu", "Minhao Hu", "Xiangde Luo", "Guoting Luo", "Guotai Wang", "Yi Guo", "Feng Xu", "Shaoting Zhang"], "title": "Self-Consistent Nested Diffusion Bridge for Accelerated MRI Reconstruction", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Accelerated MRI reconstruction plays a vital role in reducing scan time while\npreserving image quality. While most existing methods rely on complex-valued\nimage-space or k-space data, these formats are often inaccessible in clinical\npractice due to proprietary reconstruction pipelines, leaving only magnitude\nimages stored in DICOM files. To address this gap, we focus on the\nunderexplored task of magnitude-image-based MRI reconstruction. Recent\nadvancements in diffusion models, particularly denoising diffusion\nprobabilistic models (DDPMs), have demonstrated strong capabilities in modeling\nimage priors. However, their task-agnostic denoising nature limits performance\nin source-to-target image translation tasks, such as MRI reconstruction. In\nthis work, we propose a novel Self-Consistent Nested Diffusion Bridge (SC-NDB)\nframework that models accelerated MRI reconstruction as a bi-directional image\ntranslation process between under-sampled and fully-sampled magnitude MRI\nimages. SC-NDB introduces a nested diffusion architecture with a\nself-consistency constraint and reverse bridge diffusion pathways to improve\nintermediate prediction fidelity and better capture the explicit priors of\nsource images. Furthermore, we incorporate a Contour Decomposition Embedding\nModule (CDEM) to inject structural and textural knowledge by leveraging\nLaplacian pyramids and directional filter banks. Extensive experiments on the\nfastMRI and IXI datasets demonstrate that our method achieves state-of-the-art\nperformance compared to both magnitude-based and non-magnitude-based diffusion\nmodels, confirming the effectiveness and clinical relevance of SC-NDB.", "AI": {"tldr": "The paper proposes a Self-Consistent Nested Diffusion Bridge (SC-NDB) framework for accelerated MRI reconstruction using magnitude images, outperforming existing methods.", "motivation": "Existing MRI reconstruction methods often rely on inaccessible complex-valued data, leaving only magnitude images available in clinical practice. This gap motivates the focus on magnitude-image-based reconstruction.", "method": "The SC-NDB framework models MRI reconstruction as a bi-directional image translation process, incorporating nested diffusion with self-consistency constraints and a Contour Decomposition Embedding Module (CDEM) for structural knowledge.", "result": "SC-NDB achieves state-of-the-art performance on fastMRI and IXI datasets, surpassing both magnitude-based and non-magnitude-based diffusion models.", "conclusion": "The SC-NDB framework is effective and clinically relevant for MRI reconstruction, addressing the limitations of existing methods."}}
{"id": "2504.19101", "pdf": "https://arxiv.org/pdf/2504.19101", "abs": "https://arxiv.org/abs/2504.19101", "authors": ["Qianren Mao", "Qili Zhang", "Hanwen Hao", "Zhentao Han", "Runhua Xu", "Weifeng Jiang", "Qi Hu", "Zhijun Chen", "Tyler Zhou", "Bo Li", "Yangqiu Song", "Jin Dong", "Jianxin Li", "Philip S. Yu"], "title": "Privacy-Preserving Federated Embedding Learning for Localized Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has recently emerged as a promising\nsolution for enhancing the accuracy and credibility of Large Language Models\n(LLMs), particularly in Question & Answer tasks. This is achieved by\nincorporating proprietary and private data from integrated databases. However,\nprivate RAG systems face significant challenges due to the scarcity of private\ndomain data and critical data privacy issues. These obstacles impede the\ndeployment of private RAG systems, as developing privacy-preserving RAG systems\nrequires a delicate balance between data security and data availability. To\naddress these challenges, we regard federated learning (FL) as a highly\npromising technology for privacy-preserving RAG services. We propose a novel\nframework called Federated Retrieval-Augmented Generation (FedE4RAG). This\nframework facilitates collaborative training of client-side RAG retrieval\nmodels. The parameters of these models are aggregated and distributed on a\ncentral-server, ensuring data privacy without direct sharing of raw data. In\nFedE4RAG, knowledge distillation is employed for communication between the\nserver and client models. This technique improves the generalization of local\nRAG retrievers during the federated learning process. Additionally, we apply\nhomomorphic encryption within federated learning to safeguard model parameters\nand mitigate concerns related to data leakage. Extensive experiments conducted\non the real-world dataset have validated the effectiveness of FedE4RAG. The\nresults demonstrate that our proposed framework can markedly enhance the\nperformance of private RAG systems while maintaining robust data privacy\nprotection.", "AI": {"tldr": "FedE4RAG is a novel framework combining federated learning and RAG to enhance privacy-preserving question-answering systems without sharing raw data.", "motivation": "Private RAG systems face challenges like data scarcity and privacy issues, hindering deployment.", "method": "Proposes FedE4RAG, using federated learning for collaborative training, knowledge distillation, and homomorphic encryption.", "result": "Experiments show FedE4RAG improves private RAG performance while ensuring data privacy.", "conclusion": "FedE4RAG effectively balances data security and availability for private RAG systems."}}
{"id": "2504.19032", "pdf": "https://arxiv.org/pdf/2504.19032", "abs": "https://arxiv.org/abs/2504.19032", "authors": ["Niaz Ahmad", "Youngmoon Lee", "Guanghui Wang"], "title": "VISUALCENT: Visual Human Analysis using Dynamic Centroid Representation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We introduce VISUALCENT, a unified human pose and instance segmentation\nframework to address generalizability and scalability limitations to multi\nperson visual human analysis. VISUALCENT leverages centroid based bottom up\nkeypoint detection paradigm and uses Keypoint Heatmap incorporating Disk\nRepresentation and KeyCentroid to identify the optimal keypoint coordinates.\nFor the unified segmentation task, an explicit keypoint is defined as a dynamic\ncentroid called MaskCentroid to swiftly cluster pixels to specific human\ninstance during rapid changes in human body movement or significantly occluded\nenvironment. Experimental results on COCO and OCHuman datasets demonstrate\nVISUALCENTs accuracy and real time performance advantages, outperforming\nexisting methods in mAP scores and execution frame rate per second. The\nimplementation is available on the project page.", "AI": {"tldr": "VISUALCENT is a unified framework for human pose and instance segmentation, improving generalizability and scalability with centroid-based keypoint detection and dynamic MaskCentroid for segmentation.", "motivation": "To address limitations in multi-person visual human analysis, particularly in generalizability and scalability.", "method": "Uses centroid-based bottom-up keypoint detection with Keypoint Heatmap, Disk Representation, and KeyCentroid for keypoints, and MaskCentroid for segmentation.", "result": "Outperforms existing methods in mAP scores and frame rate on COCO and OCHuman datasets.", "conclusion": "VISUALCENT offers accurate, real-time performance for human pose and instance segmentation."}}
{"id": "2504.18729", "pdf": "https://arxiv.org/pdf/2504.18729", "abs": "https://arxiv.org/abs/2504.18729", "authors": ["Tung D. Vu", "Chung Hoang", "Truong-Son Hy"], "title": "Multimodal graph representation learning for website generation based on visual sketch", "categories": ["cs.LG"], "comment": null, "summary": "The Design2Code problem, which involves converting digital designs into\nfunctional source code, is a significant challenge in software development due\nto its complexity and time-consuming nature. Traditional approaches often\nstruggle with accurately interpreting the intricate visual details and\nstructural relationships inherent in webpage designs, leading to limitations in\nautomation and efficiency. In this paper, we propose a novel method that\nleverages multimodal graph representation learning to address these challenges.\nBy integrating both visual and structural information from design sketches, our\napproach enhances the accuracy and efficiency of code generation, particularly\nin producing semantically correct and structurally sound HTML code. We present\na comprehensive evaluation of our method, demonstrating significant\nimprovements in both accuracy and efficiency compared to existing techniques.\nExtensive evaluation demonstrates significant improvements of multimodal graph\nlearning over existing techniques, highlighting the potential of our method to\nrevolutionize design-to-code automation. Code available at\nhttps://github.com/HySonLab/Design2Code", "AI": {"tldr": "A novel method using multimodal graph representation learning improves accuracy and efficiency in converting digital designs to functional HTML code.", "motivation": "The complexity and inefficiency of traditional methods in interpreting visual and structural details of webpage designs motivate the need for a better solution.", "method": "The proposed approach integrates visual and structural information from design sketches using multimodal graph representation learning.", "result": "The method shows significant improvements in accuracy and efficiency for generating semantically correct and structurally sound HTML code.", "conclusion": "The approach has the potential to revolutionize design-to-code automation, outperforming existing techniques."}}
{"id": "2504.19354", "pdf": "https://arxiv.org/pdf/2504.19354", "abs": "https://arxiv.org/abs/2504.19354", "authors": ["Erkan Karabulut", "Paul Groth", "Victoria Degeler"], "title": "Neurosymbolic Association Rule Mining from Tabular Data", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Association Rule Mining (ARM) is the task of mining patterns among data\nfeatures in the form of logical rules, with applications across a myriad of\ndomains. However, high-dimensional datasets often result in an excessive number\nof rules, increasing execution time and negatively impacting downstream task\nperformance. Managing this rule explosion remains a central challenge in ARM\nresearch. To address this, we introduce Aerial+, a novel neurosymbolic ARM\nmethod. Aerial+ leverages an under-complete autoencoder to create a neural\nrepresentation of the data, capturing associations between features. It\nextracts rules from this neural representation by exploiting the model's\nreconstruction mechanism. Extensive evaluations on five datasets against seven\nbaselines demonstrate that Aerial+ achieves state-of-the-art results by\nlearning more concise, high-quality rule sets with full data coverage. When\nintegrated into rule-based interpretable machine learning models, Aerial+\nsignificantly reduces execution time while maintaining or improving accuracy.", "AI": {"tldr": "Aerial+ is a neurosymbolic ARM method that uses an under-complete autoencoder to reduce rule explosion, achieving concise, high-quality rule sets with full data coverage.", "motivation": "High-dimensional datasets in ARM lead to excessive rules, increasing execution time and degrading performance.", "method": "Aerial+ employs an under-complete autoencoder to create neural data representations and extracts rules from the model's reconstruction mechanism.", "result": "Aerial+ outperforms seven baselines, producing concise, high-quality rule sets with full coverage and reducing execution time in interpretable ML models.", "conclusion": "Aerial+ effectively addresses rule explosion in ARM, improving efficiency and accuracy in downstream tasks."}}
{"id": "2501.15309", "pdf": "https://arxiv.org/pdf/2501.15309", "abs": "https://arxiv.org/abs/2501.15309", "authors": ["Saikat Roy", "Mahmoud Mostapha", "Radu Miron", "Matt Holbrook", "Mariappan Nadar"], "title": "Investigating the Feasibility of Patch-based Inference for Generalized Diffusion Priors in Inverse Problems for Medical Images", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Accepted at IEEE International Symposium for Biomedical Imaging\n  (ISBI) 2025", "summary": "Plug-and-play approaches to solving inverse problems such as restoration and\nsuper-resolution have recently benefited from Diffusion-based generative priors\nfor natural as well as medical images. However, solutions often use the\nstandard albeit computationally intensive route of training and inferring with\nthe whole image on the diffusion prior. While patch-based approaches to\nevaluating diffusion priors in plug-and-play methods have received some\ninterest, they remain an open area of study. In this work, we explore the\nfeasibility of the usage of patches for training and inference of a diffusion\nprior on MRI images. We explore the minor adaptation necessary for artifact\navoidance, the performance and the efficiency of memory usage of patch-based\nmethods as well as the adaptability of whole image training to patch-based\nevaluation - evaluating across multiple plug-and-play methods, tasks and\ndatasets.", "AI": {"tldr": "The paper explores patch-based training and inference for diffusion priors in MRI image restoration, focusing on efficiency, artifact avoidance, and adaptability.", "motivation": "To improve computational efficiency and memory usage in diffusion-based plug-and-play methods for MRI image tasks by leveraging patch-based approaches.", "method": "Investigates patch-based training and inference for diffusion priors, evaluating adaptations for artifact avoidance, performance, and memory efficiency across tasks and datasets.", "result": "Demonstrates the feasibility of patch-based methods for MRI images, highlighting their efficiency and adaptability in plug-and-play frameworks.", "conclusion": "Patch-based diffusion priors are viable for MRI image tasks, offering computational benefits without compromising performance."}}
{"id": "2504.19110", "pdf": "https://arxiv.org/pdf/2504.19110", "abs": "https://arxiv.org/abs/2504.19110", "authors": ["Huajian Xin", "Luming Li", "Xiaoran Jin", "Jacques Fleuriot", "Wenda Li"], "title": "APE-Bench I: Towards File-level Automated Proof Engineering of Formal Math Libraries", "categories": ["cs.CL"], "comment": null, "summary": "Recent progress in large language models (LLMs) has shown promise in formal\ntheorem proving, yet existing benchmarks remain limited to isolated, static\nproof tasks, failing to capture the iterative, engineering-intensive workflows\nof real-world formal mathematics libraries. Motivated by analogous advances in\nsoftware engineering, we introduce the paradigm of Automated Proof Engineering\n(APE), which aims to automate proof engineering tasks such as feature addition,\nproof refactoring, and bug fixing using LLMs. To facilitate research in this\ndirection, we present APE-Bench I, the first realistic benchmark built from\nreal-world commit histories of Mathlib4, featuring diverse file-level tasks\ndescribed in natural language and verified via a hybrid approach combining the\nLean compiler and LLM-as-a-Judge. We further develop Eleanstic, a scalable\nparallel verification infrastructure optimized for proof checking across\nmultiple versions of Mathlib. Empirical results on state-of-the-art LLMs\ndemonstrate strong performance on localized edits but substantial degradation\non handling complex proof engineering. This work lays the foundation for\ndeveloping agentic workflows in proof engineering, with future benchmarks\ntargeting multi-file coordination, project-scale verification, and autonomous\nagents capable of planning, editing, and repairing formal libraries.", "AI": {"tldr": "The paper introduces Automated Proof Engineering (APE) to automate proof engineering tasks using LLMs, presents APE-Bench I for realistic benchmarking, and develops Eleanstic for scalable verification. Results show strong performance on localized edits but challenges in complex proof engineering.", "motivation": "To address the gap in benchmarks for iterative, engineering-intensive workflows in formal mathematics, inspired by software engineering advances.", "method": "Introduces APE, APE-Bench I (from Mathlib4 commit histories), and Eleanstic for verification. Uses Lean compiler and LLM-as-a-Judge for hybrid verification.", "result": "State-of-the-art LLMs perform well on localized edits but struggle with complex proof engineering tasks.", "conclusion": "Lays groundwork for agentic workflows in proof engineering, with future benchmarks targeting multi-file coordination and autonomous agents."}}
{"id": "2504.19074", "pdf": "https://arxiv.org/pdf/2504.19074", "abs": "https://arxiv.org/abs/2504.19074", "authors": ["Anyong Qin", "Chaoqi Yuan", "Qiang Li", "Feng Yang", "Tiecheng Song", "Chenqiang Gao"], "title": "Dual-Branch Residual Network for Cross-Domain Few-Shot Hyperspectral Image Classification with Refined Prototype", "categories": ["cs.CV", "cs.LG"], "comment": "5 pages, 2 figures. IEEE Geoscience and Remote Sensing Letters (2025)", "summary": "Convolutional neural networks (CNNs) are effective for hyperspectral image\n(HSI) classification, but their 3D convolutional structures introduce high\ncomputational costs and limited generalization in few-shot scenarios. Domain\nshifts caused by sensor differences and environmental variations further hinder\ncross-dataset adaptability. Metric-based few-shot learning (FSL) prototype\nnetworks mitigate this problem, yet their performance is sensitive to prototype\nquality, especially with limited samples. To overcome these challenges, a\ndual-branch residual network that integrates spatial and spectral features via\nparallel branches is proposed in this letter. Additionally, more robust refined\nprototypes are obtained through a regulation term. Furthermore, a kernel\nprobability matching strategy aligns source and target domain features,\nalleviating domain shift. Experiments on four publicly available HSI datasets\nillustrate that the proposal achieves superior performance compared to other\nmethods.", "AI": {"tldr": "A dual-branch residual network integrates spatial and spectral features for hyperspectral image classification, addressing computational costs, few-shot limitations, and domain shifts via refined prototypes and kernel probability matching.", "motivation": "CNNs for HSI classification face high computational costs, limited generalization in few-shot scenarios, and domain shifts due to sensor/environmental differences.", "method": "Proposes a dual-branch residual network with parallel branches for spatial-spectral feature integration, refined prototypes via regulation, and kernel probability matching for domain alignment.", "result": "Outperforms other methods on four HSI datasets, demonstrating superior performance.", "conclusion": "The proposed method effectively addresses computational, few-shot, and domain-shift challenges in HSI classification."}}
{"id": "2504.18735", "pdf": "https://arxiv.org/pdf/2504.18735", "abs": "https://arxiv.org/abs/2504.18735", "authors": ["Tanvir Islam"], "title": "TLoRA: Tri-Matrix Low-Rank Adaptation of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose TLoRA, a novel tri-matrix low-rank adaptation method that\ndecomposes weight updates into three matrices: two fixed random matrices and\none trainable matrix, combined with a learnable, layer-wise scaling factor.\nThis tri-matrix design enables TLoRA to achieve highly efficient parameter\nadaptation while introducing minimal additional computational overhead. Through\nextensive experiments on the GLUE benchmark, we demonstrate that TLoRA achieves\ncomparable performance to existing low-rank methods such as LoRA and\nAdapter-based techniques, while requiring significantly fewer trainable\nparameters. Analyzing the adaptation dynamics, we observe that TLoRA exhibits\nGaussian-like weight distributions, stable parameter norms, and scaling factor\nvariability across layers, further highlighting its expressive power and\nadaptability. Additionally, we show that TLoRA closely resembles LoRA in its\neigenvalue distributions, parameter norms, and cosine similarity of updates,\nunderscoring its ability to effectively approximate LoRA's adaptation behavior.\nOur results establish TLoRA as a highly efficient and effective fine-tuning\nmethod for LLMs, offering a significant step forward in resource-efficient\nmodel adaptation.", "AI": {"tldr": "TLoRA is a tri-matrix low-rank adaptation method for efficient parameter adaptation with minimal overhead, matching LoRA's performance using fewer parameters.", "motivation": "To improve resource efficiency in model adaptation while maintaining performance comparable to existing methods like LoRA.", "method": "Decomposes weight updates into three matrices (two fixed random, one trainable) with a learnable scaling factor.", "result": "Achieves comparable performance to LoRA on GLUE benchmark with fewer parameters, exhibiting stable adaptation dynamics.", "conclusion": "TLoRA is an efficient and effective fine-tuning method for LLMs, advancing resource-efficient adaptation."}}
{"id": "2504.19499", "pdf": "https://arxiv.org/pdf/2504.19499", "abs": "https://arxiv.org/abs/2504.19499", "authors": ["Omid Semiari", "Hosein Nikopour", "Shilpa Talwar"], "title": "Graph Reinforcement Learning for QoS-Aware Load Balancing in Open Radio Access Networks", "categories": ["cs.AI", "cs.IT", "cs.LG", "cs.NI", "eess.SP", "math.IT"], "comment": "To be published in the proceedings of the 2025 IEEE International\n  Conference on Communications (ICC), Seventh Workshop on Data Driven\n  Intelligence for Networks and Systems (DDINS)", "summary": "Next-generation wireless cellular networks are expected to provide\nunparalleled Quality-of-Service (QoS) for emerging wireless applications,\nnecessitating strict performance guarantees, e.g., in terms of link-level data\nrates. A critical challenge in meeting these QoS requirements is the prevention\nof cell congestion, which involves balancing the load to ensure sufficient\nradio resources are available for each cell to serve its designated User\nEquipments (UEs). In this work, a novel QoS-aware Load Balancing (LB) approach\nis developed to optimize the performance of Guaranteed Bit Rate (GBR) and Best\nEffort (BE) traffic in a multi-band Open Radio Access Network (O-RAN) under QoS\nand resource constraints. The proposed solution builds on Graph Reinforcement\nLearning (GRL), a powerful framework at the intersection of Graph Neural\nNetwork (GNN) and RL. The QoS-aware LB is modeled as a Markov Decision Process,\nwith states represented as graphs. QoS consideration are integrated into both\nstate representations and reward signal design. The LB agent is then trained\nusing an off-policy dueling Deep Q Network (DQN) that leverages a GNN-based\narchitecture. This design ensures the LB policy is invariant to the ordering of\nnodes (UE or cell), flexible in handling various network sizes, and capable of\naccounting for spatial node dependencies in LB decisions. Performance of the\nGRL-based solution is compared with two baseline methods. Results show\nsubstantial performance gains, including a $53\\%$ reduction in QoS violations\nand a fourfold increase in the 5th percentile rate for BE traffic.", "AI": {"tldr": "A novel QoS-aware Load Balancing (LB) approach using Graph Reinforcement Learning (GRL) is proposed for multi-band O-RAN, reducing QoS violations by 53% and improving BE traffic performance.", "motivation": "Next-gen wireless networks require strict QoS guarantees, but cell congestion poses a challenge. Balancing load while ensuring QoS for GBR and BE traffic is critical.", "method": "The LB problem is modeled as a Markov Decision Process with graph-based states. A GRL framework (combining GNN and RL) is used, with an off-policy dueling DQN for training.", "result": "The GRL-based solution reduces QoS violations by 53% and increases the 5th percentile rate for BE traffic fourfold compared to baselines.", "conclusion": "The proposed GRL approach effectively optimizes QoS-aware LB in O-RAN, demonstrating significant performance improvements over traditional methods."}}
{"id": "2504.18067", "pdf": "https://arxiv.org/pdf/2504.18067", "abs": "https://arxiv.org/abs/2504.18067", "authors": ["Chuyu Wang", "Huiting Deng", "Dong Liu"], "title": "Physics-Driven Neural Compensation For Electrical Impedance Tomography", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Electrical Impedance Tomography (EIT) provides a non-invasive, portable\nimaging modality with significant potential in medical and industrial\napplications. Despite its advantages, EIT encounters two primary challenges:\nthe ill-posed nature of its inverse problem and the spatially variable,\nlocation-dependent sensitivity distribution. Traditional model-based methods\nmitigate ill-posedness through regularization but overlook sensitivity\nvariability, while supervised deep learning approaches require extensive\ntraining data and lack generalization. Recent developments in neural fields\nhave introduced implicit regularization techniques for image reconstruction,\nbut these methods typically neglect the physical principles underlying EIT,\nthus limiting their effectiveness. In this study, we propose PhyNC\n(Physics-driven Neural Compensation), an unsupervised deep learning framework\nthat incorporates the physical principles of EIT. PhyNC addresses both the\nill-posed inverse problem and the sensitivity distribution by dynamically\nallocating neural representational capacity to regions with lower sensitivity,\nensuring accurate and balanced conductivity reconstructions. Extensive\nevaluations on both simulated and experimental data demonstrate that PhyNC\noutperforms existing methods in terms of detail preservation and artifact\nresistance, particularly in low-sensitivity regions. Our approach enhances the\nrobustness of EIT reconstructions and provides a flexible framework that can be\nadapted to other imaging modalities with similar challenges.", "AI": {"tldr": "PhyNC, an unsupervised deep learning framework, improves EIT by addressing ill-posedness and sensitivity variability using physics-driven neural compensation.", "motivation": "EIT faces challenges like ill-posed inverse problems and sensitivity variability, which traditional and deep learning methods inadequately address.", "method": "PhyNC dynamically allocates neural capacity to low-sensitivity regions, incorporating EIT's physical principles for accurate reconstructions.", "result": "PhyNC outperforms existing methods in detail preservation and artifact resistance, especially in low-sensitivity areas.", "conclusion": "PhyNC enhances EIT robustness and offers a flexible framework adaptable to other imaging modalities."}}
{"id": "2504.19162", "pdf": "https://arxiv.org/pdf/2504.19162", "abs": "https://arxiv.org/abs/2504.19162", "authors": ["Jiaqi Chen", "Bang Zhang", "Ruotian Ma", "Peisong Wang", "Xiaodan Liang", "Zhaopeng Tu", "Xiaolong Li", "Kwan-Yee K. Wong"], "title": "SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Project: https://chen-judge.github.io/SPC/", "summary": "Evaluating the step-by-step reliability of large language model (LLM)\nreasoning, such as Chain-of-Thought, remains challenging due to the difficulty\nand cost of obtaining high-quality step-level supervision. In this paper, we\nintroduce Self-Play Critic (SPC), a novel approach where a critic model evolves\nits ability to assess reasoning steps through adversarial self-play games,\neliminating the need for manual step-level annotation. SPC involves fine-tuning\ntwo copies of a base model to play two roles, namely a \"sneaky generator\" that\ndeliberately produces erroneous steps designed to be difficult to detect, and a\n\"critic\" that analyzes the correctness of reasoning steps. These two models\nengage in an adversarial game in which the generator aims to fool the critic,\nwhile the critic model seeks to identify the generator's errors. Using\nreinforcement learning based on the game outcomes, the models iteratively\nimprove; the winner of each confrontation receives a positive reward and the\nloser receives a negative reward, driving continuous self-evolution.\nExperiments on three reasoning process benchmarks (ProcessBench, PRM800K,\nDeltaBench) demonstrate that our SPC progressively enhances its error detection\ncapabilities (e.g., accuracy increases from 70.8% to 77.7% on ProcessBench) and\nsurpasses strong baselines, including distilled R1 model. Furthermore, applying\nSPC to guide the test-time search of diverse LLMs significantly improves their\nmathematical reasoning performance on MATH500 and AIME2024, outperforming\nstate-of-the-art process reward models.", "AI": {"tldr": "Self-Play Critic (SPC) improves LLM reasoning reliability via adversarial self-play, eliminating manual step-level supervision.", "motivation": "Challenges in evaluating LLM reasoning reliability due to costly step-level supervision.", "method": "SPC uses adversarial self-play between a 'sneaky generator' and 'critic' to iteratively improve error detection.", "result": "SPC enhances error detection (e.g., 70.8% to 77.7% on ProcessBench) and boosts LLM reasoning performance.", "conclusion": "SPC outperforms baselines and state-of-the-art models, proving effective for LLM reasoning evaluation."}}
{"id": "2504.19075", "pdf": "https://arxiv.org/pdf/2504.19075", "abs": "https://arxiv.org/abs/2504.19075", "authors": ["Qiuhui Chen", "Jintao Wang", "Gang Wang", "Yi Hong"], "title": "HoloDx: Knowledge- and Data-Driven Multimodal Diagnosis of Alzheimer's Disease", "categories": ["cs.CV"], "comment": null, "summary": "Accurate diagnosis of Alzheimer's disease (AD) requires effectively\nintegrating multimodal data and clinical expertise. However, existing methods\noften struggle to fully utilize multimodal information and lack structured\nmechanisms to incorporate dynamic domain knowledge. To address these\nlimitations, we propose HoloDx, a knowledge- and data-driven framework that\nenhances AD diagnosis by aligning domain knowledge with multimodal clinical\ndata. HoloDx incorporates a knowledge injection module with a knowledge-aware\ngated cross-attention, allowing the model to dynamically integrate\ndomain-specific insights from both large language models (LLMs) and clinical\nexpertise. Also, a memory injection module with a designed prototypical memory\nattention enables the model to retain and retrieve subject-specific\ninformation, ensuring consistency in decision-making. By jointly leveraging\nthese mechanisms, HoloDx enhances interpretability, improves robustness, and\neffectively aligns prior knowledge with current subject data. Evaluations on\nfive AD datasets demonstrate that HoloDx outperforms state-of-the-art methods,\nachieving superior diagnostic accuracy and strong generalization across diverse\ncohorts. The source code will be released upon publication acceptance.", "AI": {"tldr": "HoloDx is a knowledge- and data-driven framework for Alzheimer's disease diagnosis, integrating multimodal data and domain knowledge via dynamic mechanisms, outperforming existing methods.", "motivation": "Existing methods fail to fully utilize multimodal data or incorporate dynamic domain knowledge, limiting AD diagnosis accuracy.", "method": "HoloDx uses knowledge injection (gated cross-attention) and memory injection (prototypical memory attention) to align domain knowledge with clinical data.", "result": "Evaluations on five AD datasets show HoloDx achieves superior accuracy and generalization compared to state-of-the-art methods.", "conclusion": "HoloDx enhances interpretability, robustness, and diagnostic accuracy by effectively integrating knowledge and data."}}
{"id": "2504.18743", "pdf": "https://arxiv.org/pdf/2504.18743", "abs": "https://arxiv.org/abs/2504.18743", "authors": ["Zaiwei Chen"], "title": "Non-Asymptotic Guarantees for Average-Reward Q-Learning with Adaptive Stepsizes", "categories": ["cs.LG", "math.PR", "stat.ML"], "comment": "63 pages and 4 figures", "summary": "This work presents the first finite-time analysis for the last-iterate\nconvergence of average-reward Q-learning with an asynchronous implementation. A\nkey feature of the algorithm we study is the use of adaptive stepsizes, which\nserve as local clocks for each state-action pair. We show that the iterates\ngenerated by this Q-learning algorithm converge at a rate of $O(1/k)$ (in the\nmean-square sense) to the optimal relative Q-function in the span seminorm.\nMoreover, by adding a centering step to the algorithm, we further establish\npointwise mean-square convergence to a centered optimal relative Q-function,\nalso at a rate of $O(1/k)$. To prove these results, we show that adaptive\nstepsizes are necessary, as without them, the algorithm fails to converge to\nthe correct target. In addition, adaptive stepsizes can be interpreted as a\nform of implicit importance sampling that counteracts the effects of\nasynchronous updates.\n  Technically, the use of adaptive stepsizes makes each Q-learning update\ndepend on the entire sample history, introducing strong correlations and making\nthe algorithm a non-Markovian stochastic approximation (SA) scheme. Our\napproach to overcoming this challenge involves (1) a time-inhomogeneous\nMarkovian reformulation of non-Markovian SA, and (2) a combination of\nalmost-sure time-varying bounds, conditioning arguments, and Markov chain\nconcentration inequalities to break the strong correlations between the\nadaptive stepsizes and the iterates. The tools developed in this work are\nlikely to be broadly applicable to the analysis of general SA algorithms with\nadaptive stepsizes.", "AI": {"tldr": "Finite-time analysis of last-iterate convergence for average-reward Q-learning with adaptive stepsizes, showing O(1/k) convergence rates and necessity of adaptive stepsizes.", "motivation": "To address the lack of finite-time analysis for last-iterate convergence in asynchronous average-reward Q-learning, especially with adaptive stepsizes.", "method": "Uses adaptive stepsizes as local clocks, introduces a centering step, and employs non-Markovian stochastic approximation techniques with time-inhomogeneous Markovian reformulation.", "result": "Proves O(1/k) convergence rates in mean-square sense for optimal relative Q-function and centered optimal relative Q-function.", "conclusion": "Adaptive stepsizes are crucial for convergence, and the developed tools can aid analysis of other stochastic approximation algorithms with adaptive stepsizes."}}
{"id": "2504.19599", "pdf": "https://arxiv.org/pdf/2504.19599", "abs": "https://arxiv.org/abs/2504.19599", "authors": ["Kaichen Zhang", "Yuzhong Hong", "Junwei Bao", "Hongfei Jiang", "Yang Song", "Dingqian Hong", "Hui Xiong"], "title": "GVPO: Group Variance Policy Optimization for Large Language Model Post-Training", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Post-training plays a crucial role in refining and aligning large language\nmodels to meet specific tasks and human preferences. While recent advancements\nin post-training techniques, such as Group Relative Policy Optimization (GRPO),\nleverage increased sampling with relative reward scoring to achieve superior\nperformance, these methods often suffer from training instability that limits\ntheir practical adoption. To address this challenge, we present Group Variance\nPolicy Optimization (GVPO). GVPO incorporates the analytical solution to\nKL-constrained reward maximization directly into its gradient weights, ensuring\nalignment with the optimal policy. The method provides intuitive physical\ninterpretations: its gradient mirrors the mean squared error between the\ncentral distance of implicit rewards and that of actual rewards. GVPO offers\ntwo key advantages: (1) it guarantees a unique optimal solution, exactly the\nKL-constrained reward maximization objective, (2) it supports flexible sampling\ndistributions that avoids on-policy and importance sampling limitations. By\nunifying theoretical guarantees with practical adaptability, GVPO establishes a\nnew paradigm for reliable and versatile LLM post-training.", "AI": {"tldr": "GVPO introduces a stable post-training method for LLMs by incorporating KL-constrained reward maximization into gradient weights, ensuring optimal policy alignment and flexible sampling.", "motivation": "Addressing training instability in existing post-training techniques like GRPO, which limits practical adoption despite superior performance.", "method": "GVPO integrates KL-constrained reward maximization into gradient weights, providing intuitive physical interpretations and flexible sampling distributions.", "result": "GVPO guarantees a unique optimal solution, aligns with KL-constrained reward maximization, and avoids limitations of on-policy and importance sampling.", "conclusion": "GVPO sets a new standard for reliable and versatile LLM post-training by unifying theoretical guarantees with practical adaptability."}}
{"id": "2405.16016", "pdf": "https://arxiv.org/pdf/2405.16016", "abs": "https://arxiv.org/abs/2405.16016", "authors": ["Yusuke Akamatsu", "Terumi Umematsu", "Hitoshi Imaoka", "Shizuko Gomi", "Hideo Tsurushima"], "title": "ComFace: Facial Representation Learning with Synthetic Data for Comparing Faces", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025", "summary": "Daily monitoring of intra-personal facial changes associated with health and\nemotional conditions has great potential to be useful for medical, healthcare,\nand emotion recognition fields. However, the approach for capturing\nintra-personal facial changes is relatively unexplored due to the difficulty of\ncollecting temporally changing face images. In this paper, we propose a facial\nrepresentation learning method using synthetic images for comparing faces,\ncalled ComFace, which is designed to capture intra-personal facial changes. For\neffective representation learning, ComFace aims to acquire two feature\nrepresentations, i.e., inter-personal facial differences and intra-personal\nfacial changes. The key point of our method is the use of synthetic face images\nto overcome the limitations of collecting real intra-personal face images.\nFacial representations learned by ComFace are transferred to three extensive\ndownstream tasks for comparing faces: estimating facial expression changes,\nweight changes, and age changes from two face images of the same individual.\nOur ComFace, trained using only synthetic data, achieves comparable to or\nbetter transfer performance than general pre-training and state-of-the-art\nrepresentation learning methods trained using real images.", "AI": {"tldr": "ComFace uses synthetic images to learn facial representations for capturing intra-personal changes, outperforming methods using real images in tasks like expression, weight, and age change estimation.", "motivation": "Daily monitoring of facial changes for health and emotion tracking is valuable but limited by the difficulty of collecting real intra-personal face images.", "method": "ComFace learns two feature representations (inter-personal differences and intra-personal changes) using synthetic face images to bypass real data collection challenges.", "result": "ComFace achieves comparable or better performance than state-of-the-art methods trained on real images in downstream tasks like expression, weight, and age change estimation.", "conclusion": "Synthetic data can effectively train facial representation models for intra-personal change detection, offering a practical solution to data collection limitations."}}
{"id": "2504.19191", "pdf": "https://arxiv.org/pdf/2504.19191", "abs": "https://arxiv.org/abs/2504.19191", "authors": ["Liu Xiao", "Li Zhiyuan", "Lin Yueyu"], "title": "WuNeng: Hybrid State with Attention", "categories": ["cs.CL"], "comment": null, "summary": "The WuNeng architecture introduces a novel approach to enhancing the\nexpressivity and power of large language models by integrating recurrent neural\nnetwork (RNN)-based RWKV-7 with advanced attention mechanisms, prioritizing\nheightened contextual coherence over reducing KV cache size. Building upon the\nhybrid-head concept from Hymba, WuNeng augments standard multi-head attention\nwith additional RWKV-7 state-driven heads, rather than replacing existing\nheads, to enrich the model's representational capacity. A cross-head\ninteraction technique fosters dynamic synergy among standard, state-driven, and\nnewly introduced middle heads, leveraging concatenation, additive modulation,\nand gated fusion for robust information integration. Furthermore, a multi-token\nstate processing mechanism harnesses the continuous RWKV-7 state to capture\nintricate, sequence-wide dependencies, significantly boosting expressivity.\nRemarkably, these enhancements are achieved with minimal additional parameters,\nensuring efficiency while empowering the model to excel in complex reasoning\nand sequence generation tasks. WuNeng sets a new standard for balancing\nexpressivity and computational efficiency in modern neural architectures.", "AI": {"tldr": "WuNeng enhances large language models by integrating RWKV-7 RNN with attention mechanisms, improving contextual coherence without sacrificing efficiency.", "motivation": "To boost the expressivity and power of large language models while maintaining computational efficiency.", "method": "Combines RWKV-7 RNN with attention mechanisms, adds state-driven heads, and uses cross-head interaction and multi-token state processing.", "result": "Achieves heightened expressivity and contextual coherence with minimal additional parameters.", "conclusion": "WuNeng balances expressivity and efficiency, setting a new standard for neural architectures."}}
{"id": "2504.19077", "pdf": "https://arxiv.org/pdf/2504.19077", "abs": "https://arxiv.org/abs/2504.19077", "authors": ["Mitchell Goff", "Greg Hogan", "George Hotz", "Armand du Parc Locmaria", "Kacper Raczy", "Harald Sch\u00e4fer", "Adeeb Shihadeh", "Weixing Zhang", "Yassine Yousfi"], "title": "Learning to Drive from a World Model", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Most self-driving systems rely on hand-coded perception outputs and\nengineered driving rules. Learning directly from human driving data with an\nend-to-end method can allow for a training architecture that is simpler and\nscales well with compute and data.\n  In this work, we propose an end-to-end training architecture that uses real\ndriving data to train a driving policy in an on-policy simulator. We show two\ndifferent methods of simulation, one with reprojective simulation and one with\na learned world model. We show that both methods can be used to train a policy\nthat learns driving behavior without any hand-coded driving rules. We evaluate\nthe performance of these policies in a closed-loop simulation and when deployed\nin a real-world advanced driver-assistance system.", "AI": {"tldr": "The paper proposes an end-to-end training architecture for self-driving systems using real driving data, eliminating the need for hand-coded rules. It compares two simulation methods and evaluates their performance in simulations and real-world deployments.", "motivation": "To simplify and scale self-driving systems by learning directly from human driving data, avoiding reliance on hand-coded perception and rules.", "method": "Two simulation methods are used: reprojective simulation and a learned world model, both trained with real driving data to develop a driving policy.", "result": "Both methods successfully train policies without hand-coded rules, evaluated in closed-loop simulations and real-world driver-assistance systems.", "conclusion": "End-to-end training with real driving data is viable for self-driving systems, offering simplicity and scalability."}}
{"id": "2504.18758", "pdf": "https://arxiv.org/pdf/2504.18758", "abs": "https://arxiv.org/abs/2504.18758", "authors": ["Ling Wang", "Minglian Han"], "title": "High-order Graph Neural Networks with Common Neighbor Awareness for Link Prediction", "categories": ["cs.LG"], "comment": "Accepted By ICAIS&ISAS 2025", "summary": "Link prediction is a fundamental task in dynamic graph learning (DGL),\ninherently shaped by the topology of the DG. Recent advancements in dynamic\ngraph neural networks (DGNN), primarily by modeling the relationships among\nnodes via a message passing scheme, have significantly improved link prediction\nperformance. However, DGNNs heavily rely on the pairwise node interactions,\nwhich neglect the common neighbor interaction in DGL. To address this\nlimitation, we propose a High-order Graph Neural Networks with Common Neighbor\nAwareness (HGNN-CNA) for link prediction with two-fold ideas: a) estimating\ncorrelation score by considering multi-hop common neighbors for capturing the\ncomplex interaction between nodes; b) fusing the correlation into the\nmessage-passing process to consider common neighbor interaction directly in\nDGL. Experimental results on three real DGs demonstrate that the proposed\nHGNN-CNA acquires a significant accuracy gain over several state-of-the-art\nmodels on the link prediction task.", "AI": {"tldr": "HGNN-CNA improves link prediction in dynamic graphs by incorporating multi-hop common neighbor interactions into message-passing.", "motivation": "Existing DGNNs neglect common neighbor interactions, limiting their link prediction performance.", "method": "Proposes HGNN-CNA, which estimates correlation scores via multi-hop common neighbors and integrates them into message-passing.", "result": "HGNN-CNA achieves significant accuracy gains over state-of-the-art models on three real dynamic graphs.", "conclusion": "Incorporating common neighbor awareness enhances link prediction performance in dynamic graph learning."}}
{"id": "2504.19622", "pdf": "https://arxiv.org/pdf/2504.19622", "abs": "https://arxiv.org/abs/2504.19622", "authors": ["Minsu Kim", "Sangryul Kim", "James Thorne"], "title": "From Evidence to Belief: A Bayesian Epistemology Approach to Language Models", "categories": ["cs.AI"], "comment": null, "summary": "This paper investigates the knowledge of language models from the perspective\nof Bayesian epistemology. We explore how language models adjust their\nconfidence and responses when presented with evidence with varying levels of\ninformativeness and reliability. To study these properties, we create a dataset\nwith various types of evidence and analyze language models' responses and\nconfidence using verbalized confidence, token probability, and sampling. We\nobserved that language models do not consistently follow Bayesian epistemology:\nlanguage models follow the Bayesian confirmation assumption well with true\nevidence but fail to adhere to other Bayesian assumptions when encountering\ndifferent evidence types. Also, we demonstrated that language models can\nexhibit high confidence when given strong evidence, but this does not always\nguarantee high accuracy. Our analysis also reveals that language models are\nbiased toward golden evidence and show varying performance depending on the\ndegree of irrelevance, helping explain why they deviate from Bayesian\nassumptions.", "AI": {"tldr": "Language models' adherence to Bayesian epistemology is inconsistent; they perform well with true evidence but struggle with other types, showing bias and varying confidence-accuracy relationships.", "motivation": "To understand how language models adjust confidence and responses based on evidence quality and reliability, aligning with Bayesian principles.", "method": "Created a dataset with diverse evidence types, analyzed models using verbalized confidence, token probability, and sampling.", "result": "Models follow Bayesian confirmation with true evidence but fail otherwise, exhibit high confidence without accuracy, and show bias toward golden evidence.", "conclusion": "Language models deviate from Bayesian assumptions due to biases and evidence-type dependencies, highlighting limitations in their epistemic behavior."}}
{"id": "2406.07880", "pdf": "https://arxiv.org/pdf/2406.07880", "abs": "https://arxiv.org/abs/2406.07880", "authors": ["Jun Bai", "Di Wu", "Tristan Shelley", "Peter Schubel", "David Twine", "John Russell", "Xuesen Zeng", "Ji Zhang"], "title": "A Comprehensive Survey on Machine Learning Driven Material Defect Detection", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to ACM Computing Surveys", "summary": "Material defects (MD) represent a primary challenge affecting product\nperformance and giving rise to safety issues in related products. The rapid and\naccurate identification and localization of MD constitute crucial research\nendeavors in addressing contemporary challenges associated with MD. In recent\nyears, propelled by the swift advancement of machine learning (ML)\ntechnologies, particularly exemplified by deep learning, ML has swiftly emerged\nas the core technology and a prominent research direction for material defect\ndetection (MDD). Through a comprehensive review of the latest literature, we\nsystematically survey the ML techniques applied in MDD into five categories:\nunsupervised learning, supervised learning, semi-supervised learning,\nreinforcement learning, and generative learning. We provide a detailed analysis\nof the main principles and techniques used, together with the advantages and\npotential challenges associated with these techniques. Furthermore, the survey\nfocuses on the techniques for defect detection in composite materials, which\nare important types of materials enjoying increasingly wide application in\nvarious industries such as aerospace, automotive, construction, and renewable\nenergy. Finally, the survey explores potential future directions in MDD\nutilizing ML technologies. This survey consolidates ML-based MDD literature and\nprovides a foundation for future research and practice.", "AI": {"tldr": "A survey on ML techniques for material defect detection (MDD), categorizing methods into five types, analyzing principles, advantages, challenges, and focusing on composite materials. Future directions are also explored.", "motivation": "Material defects impact product performance and safety, necessitating rapid and accurate detection. ML, especially deep learning, has become central to MDD research.", "method": "Literature review categorizing ML techniques into unsupervised, supervised, semi-supervised, reinforcement, and generative learning, with analysis of principles and challenges.", "result": "Systematic survey of ML-based MDD, highlighting techniques for composite materials and identifying advantages and challenges.", "conclusion": "The survey consolidates ML-based MDD research, providing a foundation for future studies and practical applications."}}
{"id": "2504.19209", "pdf": "https://arxiv.org/pdf/2504.19209", "abs": "https://arxiv.org/abs/2504.19209", "authors": ["Elisabeth Fittschen", "Bella Xia", "Leib Celnik", "Paul Dilley", "Tom Lippincott"], "title": "Dynamic Embedded Topic Models: properties and recommendations based on diverse corpora", "categories": ["cs.CL", "cs.LG"], "comment": "Under review", "summary": "We measure the effects of several implementation choices for the Dynamic\nEmbedded Topic Model, as applied to five distinct diachronic corpora, with the\ngoal of isolating important decisions for its use and further development. We\nidentify priorities that will maximize utility in applied scholarship,\nincluding the practical scalability of vocabulary size to best exploit the\nstrengths of embedded representations, and more flexible modeling of intervals\nto accommodate the uneven temporal distributions of historical writing. Of\nsimilar importance, we find performance is not significantly or consistently\naffected by several aspects that otherwise limit the model's application or\nmight consume the resources of a grid search.", "AI": {"tldr": "Analysis of implementation choices for the Dynamic Embedded Topic Model on diachronic corpora, identifying key priorities for practical use and development.", "motivation": "To isolate important decisions for the use and further development of the Dynamic Embedded Topic Model in applied scholarship.", "method": "Measuring effects of implementation choices on five distinct diachronic corpora.", "result": "Identified priorities include scalable vocabulary size and flexible interval modeling; performance is unaffected by certain limiting factors.", "conclusion": "Key implementation choices are identified to enhance utility and scalability, with some factors having negligible impact on performance."}}
{"id": "2504.19080", "pdf": "https://arxiv.org/pdf/2504.19080", "abs": "https://arxiv.org/abs/2504.19080", "authors": ["Zhenkai Qin", "Jiaquan Liang", "Qiao Fang"], "title": "MIA-Mind: A Multidimensional Interactive Attention Mechanism Based on MindSpore", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Attention mechanisms have significantly advanced deep learning by enhancing\nfeature representation through selective focus. However, existing approaches\noften independently model channel importance and spatial saliency, overlooking\ntheir inherent interdependence and limiting their effectiveness. To address\nthis limitation, we propose MIA-Mind, a lightweight and modular\nMultidimensional Interactive Attention Mechanism, built upon the MindSpore\nframework. MIA-Mind jointly models spatial and channel features through a\nunified cross-attentive fusion strategy, enabling fine-grained feature\nrecalibration with minimal computational overhead. Extensive experiments are\nconducted on three representative datasets: on CIFAR-10, MIA-Mind achieves an\naccuracy of 82.9\\%; on ISBI2012, it achieves an accuracy of 78.7\\%; and on\nCIC-IDS2017, it achieves an accuracy of 91.9\\%. These results validate the\nversatility, lightweight design, and generalization ability of MIA-Mind across\nheterogeneous tasks. Future work will explore the extension of MIA-Mind to\nlarge-scale datasets, the development of ada,ptive attention fusion strategies,\nand distributed deployment to further enhance scalability and robustness.", "AI": {"tldr": "MIA-Mind is a lightweight, modular Multidimensional Interactive Attention Mechanism that jointly models spatial and channel features for improved feature recalibration. It achieves high accuracy on diverse datasets with minimal computational overhead.", "motivation": "Existing attention mechanisms independently model channel and spatial features, ignoring their interdependence, which limits effectiveness.", "method": "Proposes MIA-Mind, a unified cross-attentive fusion strategy for joint modeling of spatial and channel features within the MindSpore framework.", "result": "Achieves accuracies of 82.9% (CIFAR-10), 78.7% (ISBI2012), and 91.9% (CIC-IDS2017), demonstrating versatility and generalization.", "conclusion": "MIA-Mind is effective and lightweight; future work includes scaling to large datasets, adaptive fusion strategies, and distributed deployment."}}
{"id": "2504.18766", "pdf": "https://arxiv.org/pdf/2504.18766", "abs": "https://arxiv.org/abs/2504.18766", "authors": ["Wenjun Cao"], "title": "Dynamic Action Interpolation: A Universal Approach for Accelerating Reinforcement Learning with Expert Guidance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) suffers from severe sample inefficiency,\nespecially during early training, requiring extensive environmental\ninteractions to perform competently. Existing methods tend to solve this by\nincorporating prior knowledge, but introduce significant architectural and\nimplementation complexity. We propose Dynamic Action Interpolation (DAI), a\nuniversal yet straightforward framework that interpolates expert and RL actions\nvia a time-varying weight $\\alpha(t)$, integrating into any Actor-Critic\nalgorithm with just a few lines of code and without auxiliary networks or\nadditional losses. Our theoretical analysis shows that DAI reshapes state\nvisitation distributions to accelerate value function learning while preserving\nconvergence guarantees. Empirical evaluations across MuJoCo continuous control\ntasks demonstrate that DAI improves early-stage performance by over 160\\% on\naverage and final performance by more than 50\\%, with the Humanoid task showing\na 4$\\times$ improvement early on and a 2$\\times$ gain at convergence. These\nresults challenge the assumption that complex architectural modifications are\nnecessary for sample-efficient reinforcement learning.", "AI": {"tldr": "DAI is a simple framework for RL that interpolates expert and RL actions, improving sample efficiency without complex modifications.", "motivation": "RL's sample inefficiency, especially early in training, is addressed without adding complexity.", "method": "Dynamic Action Interpolation (DAI) uses a time-varying weight to blend expert and RL actions, integrating easily into Actor-Critic algorithms.", "result": "DAI improves early-stage performance by 160% and final performance by 50%, with significant gains in tasks like Humanoid.", "conclusion": "DAI proves sample-efficient RL doesn't require complex architectures, offering a simple yet effective solution."}}
{"id": "2504.19636", "pdf": "https://arxiv.org/pdf/2504.19636", "abs": "https://arxiv.org/abs/2504.19636", "authors": ["Fei Liu", "Qingfu Zhang", "Xialiang Tong", "Mingxuan Yuan", "Kun Mao"], "title": "Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant potential in\nalgorithm design. However, when integrated into search frameworks for iterative\nalgorithm search, the underlying fitness landscape--critical for understanding\nsearch behaviou--remains underexplored. In this paper, we illustrate and\nanalyze the fitness landscape of LLM-assisted Algorithm Search (LAS) using a\ngraph-based approach, where nodes represent algorithms and edges denote\ntransitions between them. We conduct extensive evaluations across six algorithm\ndesign tasks and six commonly used LLMs. Our findings reveal that LAS\nlandscapes are highly multimodal and rugged, particularly in combinatorial\noptimization tasks, with distinct structural variations across tasks and LLMs.\nFor instance, heuristic design tasks exhibit dense clusters of high-performing\nalgorithms, while symbolic regression tasks show sparse, scattered\ndistributions. Additionally, we demonstrate how population size influences\nexploration-exploitation trade-offs and the evolving trajectory of elite\nalgorithms. These insights not only advance our understanding of LAS landscapes\nbut also provide practical guidance for designing more effective LAS methods.", "AI": {"tldr": "The paper analyzes the fitness landscape of LLM-assisted Algorithm Search (LAS) using a graph-based approach, revealing multimodal and rugged landscapes with task and LLM-specific variations.", "motivation": "To understand the underexplored fitness landscape of LLM-assisted iterative algorithm search, critical for improving search behavior.", "method": "A graph-based approach where nodes represent algorithms and edges denote transitions, evaluated across six tasks and six LLMs.", "result": "LAS landscapes are highly multimodal and rugged, with task-specific variations (e.g., dense clusters in heuristic design, sparse distributions in symbolic regression). Population size affects exploration-exploitation trade-offs.", "conclusion": "The study advances understanding of LAS landscapes and offers practical guidance for designing more effective LAS methods."}}
{"id": "2408.10619", "pdf": "https://arxiv.org/pdf/2408.10619", "abs": "https://arxiv.org/abs/2408.10619", "authors": ["Andrew Kiruluta", "Eric Lundy", "Andreas Lemos"], "title": "Hierarchical Attention Diffusion Networks with Object Priors for Video Change Detection", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "We present a unified change detection pipeline that combines instance level\nmasking, multi\\-scale attention within a denoising diffusion model, and per\npixel semantic classification, all refined via SSIM to match human perception.\nBy first isolating only temporally novel objects with Mask R\\-CNN, then guiding\ndiffusion updates through hierarchical cross attention to object and global\ncontexts, and finally categorizing each pixel into one of C change types, our\nmethod delivers detailed, interpretable multi\\-class maps. It outperforms\ntraditional differencing, Siamese CNNs, and GAN\\-based detectors by 10\\-25\npoints in F1 and IoU on both synthetic and real world benchmarks, marking a new\nstate of the art in remote sensing change detection.", "AI": {"tldr": "A unified change detection pipeline combining instance-level masking, multi-scale attention in a diffusion model, and semantic classification, refined via SSIM, outperforms existing methods by 10-25 points in F1 and IoU.", "motivation": "To improve remote sensing change detection by providing detailed, interpretable multi-class maps that match human perception.", "method": "Combines Mask R-CNN for isolating novel objects, hierarchical cross-attention in a diffusion model, and per-pixel semantic classification, refined using SSIM.", "result": "Outperforms traditional differencing, Siamese CNNs, and GAN-based detectors by 10-25 points in F1 and IoU on synthetic and real-world benchmarks.", "conclusion": "Sets a new state of the art in remote sensing change detection with detailed and interpretable results."}}
{"id": "2504.19254", "pdf": "https://arxiv.org/pdf/2504.19254", "abs": "https://arxiv.org/abs/2504.19254", "authors": ["Dylan Bouchard", "Mohit Singh Chauhan"], "title": "Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "UQLM repository: https://github.com/cvs-health/uqlm", "summary": "Hallucinations are a persistent problem with Large Language Models (LLMs). As\nthese models become increasingly used in high-stakes domains, such as\nhealthcare and finance, the need for effective hallucination detection is\ncrucial. To this end, we propose a versatile framework for zero-resource\nhallucination detection that practitioners can apply to real-world use cases.\nTo achieve this, we adapt a variety of existing uncertainty quantification (UQ)\ntechniques, including black-box UQ, white-box UQ, and LLM-as-a-Judge,\ntransforming them as necessary into standardized response-level confidence\nscores ranging from 0 to 1. To enhance flexibility, we introduce a tunable\nensemble approach that incorporates any combination of the individual\nconfidence scores. This approach enables practitioners to optimize the ensemble\nfor a specific use case for improved performance. To streamline implementation,\nthe full suite of scorers is offered in this paper's companion Python toolkit,\nUQLM. To evaluate the performance of the various scorers, we conduct an\nextensive set of experiments using several LLM question-answering benchmarks.\nWe find that our tunable ensemble typically surpasses its individual components\nand outperforms existing hallucination detection methods. Our results\ndemonstrate the benefits of customized hallucination detection strategies for\nimproving the accuracy and reliability of LLMs.", "AI": {"tldr": "Proposes a zero-resource hallucination detection framework for LLMs using uncertainty quantification techniques, offering a tunable ensemble approach and a Python toolkit (UQLM).", "motivation": "Addresses the critical need for reliable hallucination detection in high-stakes domains like healthcare and finance as LLMs become more prevalent.", "method": "Adapts uncertainty quantification techniques (black-box UQ, white-box UQ, LLM-as-a-Judge) into standardized confidence scores and introduces a tunable ensemble for flexibility.", "result": "The tunable ensemble outperforms individual components and existing methods, improving LLM reliability.", "conclusion": "Customized hallucination detection strategies enhance LLM accuracy and reliability, supported by the UQLM toolkit."}}
{"id": "2504.19086", "pdf": "https://arxiv.org/pdf/2504.19086", "abs": "https://arxiv.org/abs/2504.19086", "authors": ["Xiaoran Xu", "Jiangang Yang", "Wenyue Chong", "Wenhui Shi", "Shichu Sun", "Jing Xing", "Jian Liu"], "title": "Boosting Single-domain Generalized Object Detection via Vision-Language Knowledge Interaction", "categories": ["cs.CV"], "comment": null, "summary": "Single-Domain Generalized Object Detection~(S-DGOD) aims to train an object\ndetector on a single source domain while generalizing well to diverse unseen\ntarget domains, making it suitable for multimedia applications that involve\nvarious domain shifts, such as intelligent video surveillance and VR/AR\ntechnologies. With the success of large-scale Vision-Language Models, recent\nS-DGOD approaches exploit pre-trained vision-language knowledge to guide\ninvariant feature learning across visual domains. However, the utilized\nknowledge remains at a coarse-grained level~(e.g., the textual description of\nadverse weather paired with the image) and serves as an implicit regularization\nfor guidance, struggling to learn accurate region- and object-level features in\nvarying domains. In this work, we propose a new cross-modal feature learning\nmethod, which can capture generalized and discriminative regional features for\nS-DGOD tasks. The core of our method is the mechanism of Cross-modal and\nRegion-aware Feature Interaction, which simultaneously learns both inter-modal\nand intra-modal regional invariance through dynamic interactions between\nfine-grained textual and visual features. Moreover, we design a simple but\neffective strategy called Cross-domain Proposal Refining and Mixing, which\naligns the position of region proposals across multiple domains and diversifies\nthem, enhancing the localization ability of detectors in unseen scenarios. Our\nmethod achieves new state-of-the-art results on S-DGOD benchmark datasets, with\nimprovements of +8.8\\%~mPC on Cityscapes-C and +7.9\\%~mPC on DWD over\nbaselines, demonstrating its efficacy.", "AI": {"tldr": "A new cross-modal feature learning method for Single-Domain Generalized Object Detection (S-DGOD) improves generalization to unseen domains by leveraging fine-grained textual and visual interactions and cross-domain proposal refining.", "motivation": "Current S-DGOD methods rely on coarse-grained vision-language knowledge, limiting accurate region- and object-level feature learning across domains.", "method": "Proposes Cross-modal and Region-aware Feature Interaction for fine-grained feature learning and Cross-domain Proposal Refining and Mixing for proposal alignment and diversification.", "result": "Achieves state-of-the-art results (+8.8% mPC on Cityscapes-C, +7.9% mPC on DWD) over baselines.", "conclusion": "The method effectively enhances generalization and localization in unseen domains."}}
{"id": "2504.18771", "pdf": "https://arxiv.org/pdf/2504.18771", "abs": "https://arxiv.org/abs/2504.18771", "authors": ["Markus Haug", "Gissel Velarde"], "title": "Performance of Machine Learning Classifiers for Anomaly Detection in Cyber Security Applications", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "This work empirically evaluates machine learning models on two imbalanced\npublic datasets (KDDCUP99 and Credit Card Fraud 2013). The method includes data\npreparation, model training, and evaluation, using an 80/20 (train/test) split.\nModels tested include eXtreme Gradient Boosting (XGB), Multi Layer Perceptron\n(MLP), Generative Adversarial Network (GAN), Variational Autoencoder (VAE), and\nMultiple-Objective Generative Adversarial Active Learning (MO-GAAL), with XGB\nand MLP further combined with Random-Over-Sampling (ROS) and\nSelf-Paced-Ensemble (SPE). Evaluation involves 5-fold cross-validation and\nimputation techniques (mean, median, and IterativeImputer) with 10, 20, 30, and\n50 % missing data. Findings show XGB and MLP outperform generative models.\nIterativeImputer results are comparable to mean and median, but not recommended\nfor large datasets due to increased complexity and execution time. The code\nused is publicly available on GitHub (github.com/markushaug/acr-25).", "AI": {"tldr": "The paper evaluates ML models on imbalanced datasets, finding XGB and MLP outperform generative models, with IterativeImputer being complex for large datasets.", "motivation": "To empirically assess the performance of various machine learning models on imbalanced datasets and compare their effectiveness.", "method": "Data preparation, model training (XGB, MLP, GAN, VAE, MO-GAAL), and evaluation using 80/20 train/test split, 5-fold CV, and imputation techniques.", "result": "XGB and MLP outperform generative models; IterativeImputer is comparable to simpler methods but less efficient for large datasets.", "conclusion": "XGB and MLP are effective for imbalanced data, while IterativeImputer's complexity limits its practicality for large-scale use."}}
{"id": "2504.19678", "pdf": "https://arxiv.org/pdf/2504.19678", "abs": "https://arxiv.org/abs/2504.19678", "authors": ["Mohamed Amine Ferrag", "Norbert Tihanyi", "Merouane Debbah"], "title": "From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large language models and autonomous AI agents have evolved rapidly,\nresulting in a diverse array of evaluation benchmarks, frameworks, and\ncollaboration protocols. However, the landscape remains fragmented and lacks a\nunified taxonomy or comprehensive survey. Therefore, we present a side-by-side\ncomparison of benchmarks developed between 2019 and 2025 that evaluate these\nmodels and agents across multiple domains. In addition, we propose a taxonomy\nof approximately 60 benchmarks that cover general and academic knowledge\nreasoning, mathematical problem-solving, code generation and software\nengineering, factual grounding and retrieval, domain-specific evaluations,\nmultimodal and embodied tasks, task orchestration, and interactive assessments.\nFurthermore, we review AI-agent frameworks introduced between 2023 and 2025\nthat integrate large language models with modular toolkits to enable autonomous\ndecision-making and multi-step reasoning. Moreover, we present real-world\napplications of autonomous AI agents in materials science, biomedical research,\nacademic ideation, software engineering, synthetic data generation, chemical\nreasoning, mathematical problem-solving, geographic information systems,\nmultimedia, healthcare, and finance. We then survey key agent-to-agent\ncollaboration protocols, namely the Agent Communication Protocol (ACP), the\nModel Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally,\nwe discuss recommendations for future research, focusing on advanced reasoning\nstrategies, failure modes in multi-agent LLM systems, automated scientific\ndiscovery, dynamic tool integration via reinforcement learning, integrated\nsearch capabilities, and security vulnerabilities in agent protocols.", "AI": {"tldr": "The paper provides a unified taxonomy and survey of benchmarks and frameworks for evaluating large language models and autonomous AI agents, along with real-world applications and collaboration protocols.", "motivation": "The rapid evolution of large language models and autonomous AI agents has led to fragmented evaluation benchmarks and frameworks, necessitating a unified taxonomy and comprehensive survey.", "method": "The study conducts a side-by-side comparison of benchmarks (2019-2025) and reviews AI-agent frameworks (2023-2025), proposing a taxonomy of 60 benchmarks and surveying collaboration protocols.", "result": "A taxonomy of benchmarks across domains, a review of AI-agent frameworks, real-world applications, and key collaboration protocols (ACP, MCP, A2A) are presented.", "conclusion": "Future research should focus on advanced reasoning, multi-agent failure modes, automated discovery, dynamic tool integration, search capabilities, and security vulnerabilities."}}
{"id": "2504.19267", "pdf": "https://arxiv.org/pdf/2504.19267", "abs": "https://arxiv.org/abs/2504.19267", "authors": ["Mohamed Gado", "Towhid Taliee", "Muhammad Memon", "Dmitry Ignatov", "Radu Timofte"], "title": "VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Visual storytelling is an interdisciplinary field combining computer vision\nand natural language processing to generate cohesive narratives from sequences\nof images. This paper presents a novel approach that leverages recent\nadvancements in multimodal models, specifically adapting transformer-based\narchitectures and large multimodal models, for the visual storytelling task.\nLeveraging the large-scale Visual Storytelling (VIST) dataset, our VIST-GPT\nmodel produces visually grounded, contextually appropriate narratives. We\naddress the limitations of traditional evaluation metrics, such as BLEU,\nMETEOR, ROUGE, and CIDEr, which are not suitable for this task. Instead, we\nutilize RoViST and GROOVIST, novel reference-free metrics designed to assess\nvisual storytelling, focusing on visual grounding, coherence, and\nnon-redundancy. These metrics provide a more nuanced evaluation of narrative\nquality, aligning closely with human judgment.", "AI": {"tldr": "The paper introduces VIST-GPT, a transformer-based model for visual storytelling, using novel metrics (RoViST and GROOVIST) to evaluate narrative quality beyond traditional NLP metrics.", "motivation": "To improve visual storytelling by addressing the limitations of existing evaluation metrics and leveraging advancements in multimodal models.", "method": "Adapts transformer-based architectures and large multimodal models, trained on the VIST dataset, to generate narratives. Introduces RoViST and GROOVIST for evaluation.", "result": "VIST-GPT produces visually grounded, coherent narratives, with evaluation metrics aligning better with human judgment.", "conclusion": "The proposed model and metrics advance visual storytelling by ensuring better narrative quality and evaluation."}}
{"id": "2504.19115", "pdf": "https://arxiv.org/pdf/2504.19115", "abs": "https://arxiv.org/abs/2504.19115", "authors": ["Jiaqi Peng", "Tai Wang", "Jiangmiao Pang", "Yuan Shen"], "title": "Towards Latency-Aware 3D Streaming Perception for Autonomous Driving", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Although existing 3D perception algorithms have demonstrated significant\nimprovements in performance, their deployment on edge devices continues to\nencounter critical challenges due to substantial runtime latency. We propose a\nnew benchmark tailored for online evaluation by considering runtime latency.\nBased on the benchmark, we build a Latency-Aware 3D Streaming Perception (LASP)\nframework that addresses the latency issue through two primary components: 1)\nlatency-aware history integration, which extends query propagation into a\ncontinuous process, ensuring the integration of historical feature regardless\nof varying latency; 2) latency-aware predictive detection, a module that\ncompensates the detection results with the predicted trajectory and the\nposterior accessed latency. By incorporating the latency-aware mechanism, our\nmethod shows generalization across various latency levels, achieving an online\nperformance that closely aligns with 80\\% of its offline evaluation on the\nJetson AGX Orin without any acceleration techniques.", "AI": {"tldr": "A new benchmark and framework (LASP) address runtime latency in 3D perception on edge devices, improving online performance.", "motivation": "Existing 3D perception algorithms face deployment challenges due to high runtime latency on edge devices.", "method": "Proposes LASP with latency-aware history integration and predictive detection to handle varying latency.", "result": "Achieves online performance close to 80% of offline evaluation on Jetson AGX Orin without acceleration.", "conclusion": "LASP effectively generalizes across latency levels, enhancing real-time 3D perception."}}
{"id": "2504.18785", "pdf": "https://arxiv.org/pdf/2504.18785", "abs": "https://arxiv.org/abs/2504.18785", "authors": ["Santosh Rajagopalan", "Jonathan Vronsky", "Songbai Yan", "S. Alireza Golestaneh", "Shubhra Chandra", "Min Zhou"], "title": "ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding", "categories": ["cs.LG"], "comment": null, "summary": "We present ALF (Advertiser Large Foundation model), a multi-modal transformer\narchitecture for understanding advertiser behavior and intent across text,\nimage, video and structured data modalities. Through contrastive learning and\nmulti-task optimization, ALF creates unified advertiser representations that\ncapture both content and behavioral patterns. Our model achieves\nstate-of-the-art performance on critical tasks including fraud detection,\npolicy violation identification, and advertiser similarity matching. In\nproduction deployment, ALF reduces false positives by 90% while maintaining\n99.8% precision on abuse detection tasks. The architecture's effectiveness\nstems from its novel combination of multi-modal transformations, inter-sample\nattention mechanism, spectrally normalized projections, and calibrated\nprobabilistic outputs.", "AI": {"tldr": "ALF is a multi-modal transformer model for understanding advertiser behavior, achieving state-of-the-art performance in fraud detection and policy violation tasks with high precision.", "motivation": "To create unified advertiser representations across text, image, video, and structured data for better understanding of advertiser intent and behavior.", "method": "Uses contrastive learning, multi-task optimization, multi-modal transformations, inter-sample attention, spectrally normalized projections, and calibrated probabilistic outputs.", "result": "Reduces false positives by 90% with 99.8% precision in abuse detection, outperforming existing methods.", "conclusion": "ALF's innovative architecture effectively captures advertiser behavior and intent, making it highly practical for real-world deployment."}}
{"id": "2504.19738", "pdf": "https://arxiv.org/pdf/2504.19738", "abs": "https://arxiv.org/abs/2504.19738", "authors": ["Yingbin Bai", "Sylvie Thiebaux", "Felipe Trevizan"], "title": "Learning Efficiency Meets Symmetry Breaking", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Learning-based planners leveraging Graph Neural Networks can learn search\nguidance applicable to large search spaces, yet their potential to address\nsymmetries remains largely unexplored. In this paper, we introduce a graph\nrepresentation of planning problems allying learning efficiency with the\nability to detect symmetries, along with two pruning methods, action pruning\nand state pruning, designed to manage symmetries during search. The integration\nof these techniques into Fast Downward achieves a first-time success over LAMA\non the latest IPC learning track dataset. Code is released at:\nhttps://github.com/bybeye/Distincter.", "AI": {"tldr": "A learning-based planner using Graph Neural Networks introduces symmetry-aware pruning methods (action and state pruning) to improve search efficiency, outperforming LAMA on IPC datasets.", "motivation": "The potential of learning-based planners to handle symmetries in large search spaces is underexplored.", "method": "Proposes a graph representation for planning problems and two pruning methods (action and state pruning) to manage symmetries during search.", "result": "Integration into Fast Downward achieves superior performance over LAMA on the IPC learning track dataset.", "conclusion": "The approach effectively combines learning efficiency with symmetry detection, demonstrating practical success."}}
{"id": "2504.19298", "pdf": "https://arxiv.org/pdf/2504.19298", "abs": "https://arxiv.org/abs/2504.19298", "authors": ["Hanyu Lai", "Junjie Gao", "Xiao Liu", "Yifan Xu", "Shudan Zhang", "Yuxiao Dong", "Jie Tang"], "title": "AndroidGen: Building an Android Language Agent under Data Scarcity", "categories": ["cs.CL"], "comment": null, "summary": "Large language models have opened up a world of possibilities for various NLP\ntasks, sparking optimism for the future. Despite their potential, LLMs have yet\nto be widely used as agents on real mobile devices. The main challenge is the\nneed for high-quality data sources. Time constraints and labor intensity often\nhinder human annotation. On the other hand, existing LLMs exhibit inadequate\ncompletion rates and need a robust data filtration strategy. Given these\nchallenges, we develop a framework called AndroidGen to enhance the\ncapabilities of LLM-based agents under data scarcity. In addition, we leverage\nAndroidGen to collect trajectories given human tasks and train open-source LLMs\non these trajectories to develop an open-source mobile agent without manually\nlabeled trajectories. We extensively evaluate AndroidGen with AndroidWorld,\nAitW, and various popular applications, demonstrating its improvements and\nrevealing potential areas for future improvement. Code, model, and data are\navailable at https://github.com/THUDM/AndroidGen.", "AI": {"tldr": "AndroidGen is a framework to enhance LLM-based agents for mobile tasks under data scarcity, using human task trajectories to train open-source LLMs without manual labeling.", "motivation": "Address the challenge of limited high-quality data for LLM-based mobile agents due to time and labor constraints in human annotation.", "method": "Develop AndroidGen to collect human task trajectories and train open-source LLMs on these trajectories, avoiding manual labeling.", "result": "Evaluated on AndroidWorld, AitW, and popular apps, AndroidGen shows improvements and identifies areas for future enhancement.", "conclusion": "AndroidGen effectively tackles data scarcity for LLM-based mobile agents, with potential for further refinement."}}
{"id": "2504.19124", "pdf": "https://arxiv.org/pdf/2504.19124", "abs": "https://arxiv.org/abs/2504.19124", "authors": ["Zhongxuan Li"], "title": "Blind Source Separation Based on Sparsity", "categories": ["cs.CV"], "comment": null, "summary": "Blind source separation (BSS) is a key technique in array processing and data\nanalysis, aiming to recover unknown sources from observed mixtures without\nknowledge of the mixing matrix. Classical independent component analysis (ICA)\nmethods rely on the assumption that sources are mutually independent. To\naddress limitations of ICA, sparsity-based methods have been introduced, which\ndecompose source signals sparsely in a predefined dictionary. Morphological\nComponent Analysis (MCA), based on sparse representation theory, assumes that a\nsignal is a linear combination of components with distinct geometries, each\nsparsely representable in one dictionary and not in others. This approach has\nrecently been applied to BSS with promising results.\n  This report reviews key approaches derived from classical ICA and explores\nsparsity-based methods for BSS. It introduces the theory of sparse\nrepresentation and decomposition, followed by a block coordinate relaxation MCA\nalgorithm, whose variants are used in Multichannel MCA (MMCA) and Generalized\nMCA (GMCA). A local dictionary learning method using K-SVD is then presented.\nFinally, we propose an improved algorithm, SAC+BK-SVD, which enhances K-SVD by\nlearning a block-sparsifying dictionary that clusters and updates similar atoms\nin blocks.\n  The implementation includes experiments on image segmentation and blind image\nsource separation using the discussed techniques. We also compare the proposed\nblock-sparse dictionary learning algorithm with K-SVD. Simulation results\ndemonstrate that our method yields improved blind image separation quality.", "AI": {"tldr": "The paper reviews ICA and sparsity-based methods for BSS, introduces MCA and its variants, and proposes an improved algorithm (SAC+BK-SVD) for better blind image separation.", "motivation": "To address ICA's limitations by leveraging sparsity-based methods and improving dictionary learning for BSS.", "method": "Reviews ICA and sparsity-based methods, introduces MCA and variants (MMCA, GMCA), and proposes SAC+BK-SVD for block-sparse dictionary learning.", "result": "Simulations show SAC+BK-SVD improves blind image separation quality compared to K-SVD.", "conclusion": "Sparsity-based methods, especially SAC+BK-SVD, enhance BSS performance, offering promising results for applications like image segmentation."}}
{"id": "2504.18818", "pdf": "https://arxiv.org/pdf/2504.18818", "abs": "https://arxiv.org/abs/2504.18818", "authors": ["Xufei Wang", "Fei Ge", "Jinchen Zhu", "Mingjian Zhang", "Qi Wu", "Jifeng Ren Shizhuang Weng"], "title": "Frequency-Integrated Transformer for Arbitrary-Scale Super-Resolution", "categories": ["cs.LG"], "comment": "11pages,8figures", "summary": "Methods based on implicit neural representation have demonstrated remarkable\ncapabilities in arbitrary-scale super-resolution (ASSR) tasks, but they neglect\nthe potential value of the frequency domain, leading to sub-optimal\nperformance. We proposes a novel network called Frequency-Integrated\nTransformer (FIT) to incorporate and utilize frequency information to enhance\nASSR performance. FIT employs Frequency Incorporation Module (FIM) to introduce\nfrequency information in a lossless manner and Frequency Utilization\nSelf-Attention module (FUSAM) to efficiently leverage frequency information by\nexploiting spatial-frequency interrelationship and global nature of frequency.\nFIM enriches detail characterization by incorporating frequency information\nthrough a combination of Fast Fourier Transform (FFT) with real-imaginary\nmapping. In FUSAM, Interaction Implicit Self-Attention (IISA) achieves\ncross-domain information synergy by interacting spatial and frequency\ninformation in subspace, while Frequency Correlation Self-attention (FCSA)\ncaptures the global context by computing correlation in frequency. Experimental\nresults demonstrate FIT yields superior performance compared to existing\nmethods across multiple benchmark datasets. Visual feature map proves the\nsuperiority of FIM in enriching detail characterization. Frequency error map\nvalidates IISA productively improve the frequency fidelity. Local attribution\nmap validates FCSA effectively captures global context.", "AI": {"tldr": "FIT, a novel network, integrates frequency information for ASSR tasks using FIM and FUSAM, outperforming existing methods.", "motivation": "Existing methods neglect frequency domain, limiting ASSR performance.", "method": "FIT uses FIM for lossless frequency incorporation and FUSAM for spatial-frequency synergy and global context capture.", "result": "FIT outperforms benchmarks, with FIM enriching details, IISA improving frequency fidelity, and FCSA capturing global context.", "conclusion": "FIT effectively leverages frequency information to enhance ASSR performance."}}
{"id": "2504.19933", "pdf": "https://arxiv.org/pdf/2504.19933", "abs": "https://arxiv.org/abs/2504.19933", "authors": ["Riccardo Lo Bianco", "Willem van Jaarsveld", "Jeroen Middelhuis", "Luca Begnardi", "Remco Dijkman"], "title": "Automated decision-making for dynamic task assignment at scale", "categories": ["cs.AI", "cs.LG", "math.OC"], "comment": null, "summary": "The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\ntasks in real time while minimizing some objectives, like resource costs or\ntask cycle time. In this work, we consider a DTAP variant where every task is a\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\ninvolves the decision of which employee to assign to which activity to process\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\nresearch is limited to solving small-scale, synthetic problems, neglecting the\nchallenges posed by real-world use cases. To bridge this gap, this work\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\nTo this end, we introduce a DRL agent with two novel elements: a graph\nstructure for observations and actions that can effectively represent any DTAP\nand a reward function that is provably equivalent to the objective of\nminimizing the average cycle time of tasks. The combination of these two\nnovelties allows the agent to learn effective and generalizable assignment\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\ninstances whose parameters are extracted from real-world logs through process\nmining. The experimental evaluation shows how the proposed DRL agent matches or\noutperforms the best baseline in all DTAP instances and generalizes on\ndifferent time horizons and across instances.", "AI": {"tldr": "A DRL-based DSS is proposed for real-world scale DTAPs, featuring a novel graph structure and reward function, outperforming baselines in evaluations.", "motivation": "Address the gap in DRL research for DTAPs, which often neglects real-world challenges, by developing a scalable solution.", "method": "Introduces a DRL agent with a graph structure for observations/actions and a provably equivalent reward function to minimize task cycle time.", "result": "The DRL agent matches or outperforms baselines in real-world DTAP instances and generalizes across time horizons.", "conclusion": "The proposed DSS effectively tackles real-world DTAPs, demonstrating scalability and generalization."}}
{"id": "2504.19314", "pdf": "https://arxiv.org/pdf/2504.19314", "abs": "https://arxiv.org/abs/2504.19314", "authors": ["Peilin Zhou", "Bruce Leon", "Xiang Ying", "Can Zhang", "Yifan Shao", "Qichen Ye", "Dading Chong", "Zhiling Jin", "Chenxuan Xie", "Meng Cao", "Yuxin Gu", "Sixin Hong", "Jing Ren", "Jian Chen", "Chao Liu", "Yining Hua"], "title": "BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese", "categories": ["cs.CL"], "comment": "Under Review", "summary": "As large language models (LLMs) evolve into tool-using agents, the ability to\nbrowse the web in real-time has become a critical yardstick for measuring their\nreasoning and retrieval competence. Existing benchmarks such as BrowseComp\nconcentrate on English and overlook the linguistic, infrastructural, and\ncensorship-related complexities of other major information ecosystems -- most\nnotably Chinese. To address this gap, we introduce BrowseComp-ZH, a\nhigh-difficulty benchmark purpose-built to comprehensively evaluate LLM agents\non the Chinese web. BrowseComp-ZH consists of 289 multi-hop questions spanning\n11 diverse domains. Each question is reverse-engineered from a short,\nobjective, and easily verifiable answer (e.g., a date, number, or proper noun).\nA two-stage quality control protocol is applied to strive for high question\ndifficulty and answer uniqueness. We benchmark over 20 state-of-the-art\nlanguage models and agentic search systems on our proposed BrowseComp-ZH.\nDespite their strong conversational and retrieval capabilities, most models\nstruggle severely: a large number achieve accuracy rates below 10%, and only a\nhandful exceed 20%. Even the best-performing system, OpenAI's DeepResearch,\nreaches just 42.9%. These results demonstrate the considerable difficulty of\nBrowseComp-ZH, where success demands not only effective retrieval strategies,\nbut also sophisticated reasoning and information reconciliation -- capabilities\nthat current models still struggle to master. Our dataset, construction\nguidelines, and benchmark results have been publicly released at\nhttps://github.com/PALIN2018/BrowseComp-ZH.", "AI": {"tldr": "BrowseComp-ZH is a high-difficulty benchmark for evaluating LLM agents on the Chinese web, revealing significant challenges for current models.", "motivation": "Existing benchmarks overlook complexities of non-English ecosystems, particularly Chinese, necessitating a specialized evaluation tool.", "method": "BrowseComp-ZH includes 289 multi-hop questions across 11 domains, with rigorous quality control for difficulty and answer uniqueness.", "result": "Most models perform poorly (below 10% accuracy), with the best (OpenAI's DeepResearch) achieving only 42.9%.", "conclusion": "BrowseComp-ZH highlights the need for improved retrieval, reasoning, and information reconciliation in LLM agents."}}
{"id": "2504.19161", "pdf": "https://arxiv.org/pdf/2504.19161", "abs": "https://arxiv.org/abs/2504.19161", "authors": ["Zheng Fang", "Kangjun Liu", "Ke Chen", "Qingyu Liu", "Jianguo Zhang", "Lingyang Song", "Yaowei Wang"], "title": "RadioFormer: A Multiple-Granularity Radio Map Estimation Transformer with 1\\textpertenthousand Spatial Sampling", "categories": ["cs.CV"], "comment": null, "summary": "The task of radio map estimation aims to generate a dense representation of\nelectromagnetic spectrum quantities, such as the received signal strength at\neach grid point within a geographic region, based on measurements from a subset\nof spatially distributed nodes (represented as pixels). Recently, deep vision\nmodels such as the U-Net have been adapted to radio map estimation, whose\neffectiveness can be guaranteed with sufficient spatial observations (typically\n0.01% to 1% of pixels) in each map, to model local dependency of observed\nsignal power. However, such a setting of sufficient measurements can be less\npractical in real-world scenarios, where extreme sparsity in spatial sampling\ncan be widely encountered. To address this challenge, we propose RadioFormer, a\nnovel multiple-granularity transformer designed to handle the constraints posed\nby spatial sparse observations. Our RadioFormer, through a dual-stream\nself-attention (DSA) module, can respectively discover the correlation of\npixel-wise observed signal power and also learn patch-wise buildings'\ngeometries in a style of multiple granularities, which are integrated into\nmulti-scale representations of radio maps by a cross stream cross-attention\n(CCA) module. Extensive experiments on the public RadioMapSeer dataset\ndemonstrate that RadioFormer outperforms state-of-the-art methods in radio map\nestimation while maintaining the lowest computational cost. Furthermore, the\nproposed approach exhibits exceptional generalization capabilities and robust\nzero-shot performance, underscoring its potential to advance radio map\nestimation in a more practical setting with very limited observation nodes.", "AI": {"tldr": "RadioFormer, a transformer-based model, improves radio map estimation with sparse spatial observations by leveraging dual-stream self-attention and cross-attention modules.", "motivation": "Existing deep vision models require sufficient spatial observations (0.01%-1% of pixels), which is impractical in real-world sparse sampling scenarios.", "method": "RadioFormer uses a dual-stream self-attention (DSA) module for pixel-wise and patch-wise correlations and a cross-attention (CCA) module for multi-scale integration.", "result": "Outperforms state-of-the-art methods on the RadioMapSeer dataset with lower computational cost and strong zero-shot generalization.", "conclusion": "RadioFormer advances radio map estimation in practical sparse observation settings."}}
{"id": "2504.18819", "pdf": "https://arxiv.org/pdf/2504.18819", "abs": "https://arxiv.org/abs/2504.18819", "authors": ["Hassan Wasswa", "Aziida Nanyonga", "Timothy Lynar"], "title": "Preserving Seasonal and Trend Information: A Variational Autoencoder-Latent Space Arithmetic Based Approach for Non-stationary Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "AI models have garnered significant research attention towards predictive\ntask automation. However, a stationary training environment is an underlying\nassumption for most models and such models simply do not work on non-stationary\ndata since a stationary relationship is learned. The existing solutions propose\nmaking data stationary prior to model training and evaluation. This leads to\nloss of trend and seasonal patterns which are vital components for learning\ntemporal dependencies of the system under study. This research aims to address\nthis limitation by proposing a method for enforcing stationary behaviour within\nthe latent space while preserving trend and seasonal information. The method\ndeploys techniques including Differencing, Time-series decomposition, and\nLatent Space Arithmetic (LSA), to learn information vital for efficient\napproximation of trend and seasonal information which is then stored as\nembeddings within the latent space of a Variational Autoencoder (VAE). The\napproach's ability to preserve trend and seasonal information was evaluated on\ntwo time-series non-stationary datasets. For predictive performance evaluation,\nfour deep learning models were trained on the latent vector representations of\nthe datasets after application of the proposed method and all models produced\ncompetitive results in comparison with state-of-the-art techniques using RMSE\nas the performance metric.", "AI": {"tldr": "The paper proposes a method to enforce stationary behavior in latent space while preserving trend and seasonal patterns, improving predictive performance on non-stationary data.", "motivation": "Existing AI models assume stationary training environments, losing vital trend and seasonal patterns in non-stationary data. This research addresses this limitation.", "method": "Uses Differencing, Time-series decomposition, and Latent Space Arithmetic (LSA) within a Variational Autoencoder (VAE) to preserve trend and seasonal info.", "result": "Evaluated on two non-stationary datasets, the method preserved trend/seasonal info and improved predictive performance in deep learning models.", "conclusion": "The proposed method effectively handles non-stationary data while maintaining predictive accuracy, outperforming state-of-the-art techniques."}}
{"id": "2504.19968", "pdf": "https://arxiv.org/pdf/2504.19968", "abs": "https://arxiv.org/abs/2504.19968", "authors": ["John Beverley", "Regina Hurley"], "title": "How Group Lives Go Well", "categories": ["cs.AI", "cs.GT"], "comment": null, "summary": "This paper explores the ontological space of group well being, proposing a\nframework for representing collective welfare, group functions, and long term\ncontributions within an ontology engineering context. Traditional well being\ntheories focus on individual states, often relying on hedonistic, desire\nsatisfaction, or objective list models. Such approaches struggle to account for\ncases where individual sacrifices contribute to broader social progress, a\ncritical challenge in modeling group flourishing. To address this, the paper\nrefines and extends the Counterfactual Account (CT) of well being, which\nevaluates goodness of an event by comparing an individual's actual well being\nwith a hypothetical counterpart in a nearby possible world. While useful, this\nframework is insufficient for group level ontologies, where well being depends\non functional persistence, institutional roles, and historical impact rather\nthan immediate individual outcomes. Drawing on Basic Formal Ontology (BFO), the\npaper introduces a model in which group flourishing is evaluated in terms of\ngroup functional, where members bear roles and exhibit persistence conditions\nakin to biological systems or designed artifacts. This approach enables\nsemantic interoperability for modeling longitudinal social contributions,\nallowing for structured reasoning about group welfare, social institutions, and\ngroup flourishing over time.", "AI": {"tldr": "The paper proposes a framework for modeling group well-being using ontology engineering, extending the Counterfactual Account (CT) to address limitations in traditional individual-focused theories.", "motivation": "Traditional well-being theories focus on individuals and struggle to account for group-level welfare, especially when individual sacrifices contribute to social progress.", "method": "The paper refines the CT framework and integrates it with Basic Formal Ontology (BFO) to model group flourishing based on functional persistence, roles, and historical impact.", "result": "The proposed model enables semantic interoperability for reasoning about group welfare, social institutions, and longitudinal contributions.", "conclusion": "The framework addresses gaps in group-level well-being modeling, offering a structured approach for evaluating collective welfare and flourishing."}}
{"id": "2504.19333", "pdf": "https://arxiv.org/pdf/2504.19333", "abs": "https://arxiv.org/abs/2504.19333", "authors": ["James O' Neill", "Santhosh Subramanian", "Eric Lin", "Vaikkunth Mugunthan"], "title": "Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The trend towards large language models (LLMs) for guardrailing against\nundesired behaviors is increasing and has shown promise for censoring user\ninputs. However, increased latency, memory consumption, hosting expenses and\nnon-structured outputs can make their use prohibitive.\n  In this work, we show that task-specific data generation can lead to\nfine-tuned classifiers that significantly outperform current state of the art\n(SoTA) while being orders of magnitude smaller. Secondly, we show that using a\nsingle model, \\texttt{MultiTaskGuard}, that is pretrained on a large\nsynthetically generated dataset with unique task instructions further improves\ngeneralization. Thirdly, our most performant models, \\texttt{UniGuard}, are\nfound using our proposed search-based model merging approach that finds an\noptimal set of parameters to combine single-policy models and multi-policy\nguardrail models. % On 7 public datasets and 4 guardrail benchmarks we created,\nour efficient guardrail classifiers improve over the best performing SoTA\npublicly available LLMs and 3$^{\\text{rd}}$ party guardrail APIs in detecting\nunsafe and safe behaviors by an average F1 score improvement of \\textbf{29.92}\npoints over Aegis-LlamaGuard and \\textbf{21.62} over \\texttt{gpt-4o},\nrespectively. Lastly, our guardrail synthetic data generation process that uses\ncustom task-specific guardrail poli", "AI": {"tldr": "Task-specific data generation and model merging improve guardrail classifiers, outperforming large language models (LLMs) in efficiency and performance.", "motivation": "Address the prohibitive costs and inefficiencies of using LLMs for guardrailing by developing smaller, task-specific models.", "method": "Fine-tuned classifiers, a pretrained multi-task model (MultiTaskGuard), and a search-based model merging approach (UniGuard).", "result": "Significant F1 score improvements (29.92 over Aegis-LlamaGuard, 21.62 over GPT-4o) on guardrail benchmarks.", "conclusion": "Task-specific models and synthetic data generation offer efficient, high-performance alternatives to LLMs for guardrailing."}}
{"id": "2504.19165", "pdf": "https://arxiv.org/pdf/2504.19165", "abs": "https://arxiv.org/abs/2504.19165", "authors": ["Yuan Li", "Ziqian Bai", "Feitong Tan", "Zhaopeng Cui", "Sean Fanello", "Yinda Zhang"], "title": "IM-Portrait: Learning 3D-aware Video Diffusion for PhotorealisticTalking Heads from Monocular Videos", "categories": ["cs.CV"], "comment": "CVPR2025; project page:\n  https://y-u-a-n-l-i.github.io/projects/IM-Portrait/", "summary": "We propose a novel 3D-aware diffusion-based method for generating\nphotorealistic talking head videos directly from a single identity image and\nexplicit control signals (e.g., expressions). Our method generates Multiplane\nImages (MPIs) that ensure geometric consistency, making them ideal for\nimmersive viewing experiences like binocular videos for VR headsets. Unlike\nexisting methods that often require a separate stage or joint optimization to\nreconstruct a 3D representation (such as NeRF or 3D Gaussians), our approach\ndirectly generates the final output through a single denoising process,\neliminating the need for post-processing steps to render novel views\nefficiently. To effectively learn from monocular videos, we introduce a\ntraining mechanism that reconstructs the output MPI randomly in either the\ntarget or the reference camera space. This approach enables the model to\nsimultaneously learn sharp image details and underlying 3D information.\nExtensive experiments demonstrate the effectiveness of our method, which\nachieves competitive avatar quality and novel-view rendering capabilities, even\nwithout explicit 3D reconstruction or high-quality multi-view training data.", "AI": {"tldr": "A 3D-aware diffusion method generates photorealistic talking head videos from a single image and control signals, using Multiplane Images (MPIs) for geometric consistency without post-processing.", "motivation": "To create immersive talking head videos efficiently without relying on explicit 3D reconstruction or multi-view data.", "method": "Generates MPIs directly via a single denoising process, with a training mechanism alternating between target and reference camera spaces.", "result": "Achieves competitive avatar quality and novel-view rendering without explicit 3D reconstruction.", "conclusion": "The method is effective for generating realistic talking heads with geometric consistency and efficiency."}}
{"id": "2504.18845", "pdf": "https://arxiv.org/pdf/2504.18845", "abs": "https://arxiv.org/abs/2504.18845", "authors": ["Mehmet Ali Ferah", "Tufan Kumbasar"], "title": "Introducing Interval Neural Networks for Uncertainty-Aware System Identification", "categories": ["cs.LG", "cs.AI"], "comment": "In International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025", "summary": "System Identification (SysID) is crucial for modeling and understanding\ndynamical systems using experimental data. While traditional SysID methods\nemphasize linear models, their inability to fully capture nonlinear dynamics\nhas driven the adoption of Deep Learning (DL) as a more powerful alternative.\nHowever, the lack of uncertainty quantification (UQ) in DL-based models poses\nchallenges for reliability and safety, highlighting the necessity of\nincorporating UQ. This paper introduces a systematic framework for constructing\nand learning Interval Neural Networks (INNs) to perform UQ in SysID tasks. INNs\nare derived by transforming the learnable parameters (LPs) of pre-trained\nneural networks into interval-valued LPs without relying on probabilistic\nassumptions. By employing interval arithmetic throughout the network, INNs can\ngenerate Prediction Intervals (PIs) that capture target coverage effectively.\nWe extend Long Short-Term Memory (LSTM) and Neural Ordinary Differential\nEquations (Neural ODEs) into Interval LSTM (ILSTM) and Interval NODE (INODE)\narchitectures, providing the mathematical foundations for their application in\nSysID. To train INNs, we propose a DL framework that integrates a UQ loss\nfunction and parameterization tricks to handle constraints arising from\ninterval LPs. We introduce novel concept \"elasticity\" for underlying\nuncertainty causes and validate ILSTM and INODE in SysID experiments,\ndemonstrating their effectiveness.", "AI": {"tldr": "The paper introduces Interval Neural Networks (INNs) for uncertainty quantification in System Identification (SysID), extending LSTM and Neural ODEs into interval-valued architectures (ILSTM and INODE) to improve reliability.", "motivation": "Traditional SysID methods lack nonlinearity handling, and DL-based models lack uncertainty quantification, necessitating a framework like INNs for reliable SysID.", "method": "Proposes INNs by transforming pre-trained neural network parameters into interval-valued ones, using interval arithmetic for prediction intervals. Extends LSTM and Neural ODEs into ILSTM and INODE.", "result": "Demonstrates effectiveness of ILSTM and INODE in SysID experiments, with INNs generating reliable prediction intervals.", "conclusion": "INNs provide a systematic approach for uncertainty quantification in SysID, enhancing reliability and safety of DL-based models."}}
{"id": "2504.20007", "pdf": "https://arxiv.org/pdf/2504.20007", "abs": "https://arxiv.org/abs/2504.20007", "authors": ["Anita Srbinovska", "Angela Srbinovska", "Vivek Senthil", "Adrian Martin", "John McCluskey", "Ernest Fokou\u00e9"], "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage", "categories": ["cs.AI", "cs.CV"], "comment": "6 pages, 2 figures, and 1 table", "summary": "This paper proposes a novel interdisciplinary framework for analyzing police\nbody-worn camera (BWC) footage from the Rochester Police Department (RPD) using\nadvanced artificial intelligence (AI) and statistical machine learning (ML)\ntechniques. Our goal is to detect, classify, and analyze patterns of\ninteraction between police officers and civilians to identify key behavioral\ndynamics, such as respect, disrespect, escalation, and de-escalation. We apply\nmultimodal data analysis by integrating video, audio, and natural language\nprocessing (NLP) techniques to extract meaningful insights from BWC footage. We\npresent our methodology, computational techniques, and findings, outlining a\npractical approach for law enforcement while advancing the frontiers of\nknowledge discovery from police BWC data.", "AI": {"tldr": "A novel AI and ML framework analyzes police BWC footage to detect and classify interaction patterns between officers and civilians.", "motivation": "To identify key behavioral dynamics (e.g., respect, escalation) in police-civilian interactions using BWC data.", "method": "Multimodal data analysis integrating video, audio, and NLP techniques.", "result": "Findings provide insights into behavioral patterns and a practical approach for law enforcement.", "conclusion": "The framework advances knowledge discovery from BWC data and aids law enforcement."}}
{"id": "2504.19339", "pdf": "https://arxiv.org/pdf/2504.19339", "abs": "https://arxiv.org/abs/2504.19339", "authors": ["Dongqi Liu", "Xi Yu", "Vera Demberg", "Mirella Lapata"], "title": "Explanatory Summarization with Discourse-Driven Planning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by the Transactions of the Association for Computational\n  Linguistics (TACL)", "summary": "Lay summaries for scientific documents typically include explanations to help\nreaders grasp sophisticated concepts or arguments. However, current automatic\nsummarization methods do not explicitly model explanations, which makes it\ndifficult to align the proportion of explanatory content with human-written\nsummaries. In this paper, we present a plan-based approach that leverages\ndiscourse frameworks to organize summary generation and guide explanatory\nsentences by prompting responses to the plan. Specifically, we propose two\ndiscourse-driven planning strategies, where the plan is conditioned as part of\nthe input or part of the output prefix, respectively. Empirical experiments on\nthree lay summarization datasets show that our approach outperforms existing\nstate-of-the-art methods in terms of summary quality, and it enhances model\nrobustness, controllability, and mitigates hallucination.", "AI": {"tldr": "A plan-based approach using discourse frameworks improves lay summaries by guiding explanatory content, outperforming current methods in quality and robustness.", "motivation": "Current automatic summarization methods lack explicit modeling of explanations, leading to misalignment with human-written summaries.", "method": "Proposes two discourse-driven planning strategies: conditioning the plan as input or output prefix to guide explanatory sentences.", "result": "Outperforms state-of-the-art methods on three datasets, improving summary quality, robustness, controllability, and reducing hallucination.", "conclusion": "The plan-based approach effectively enhances lay summarization by integrating explanatory content through discourse-driven strategies."}}
{"id": "2504.19183", "pdf": "https://arxiv.org/pdf/2504.19183", "abs": "https://arxiv.org/abs/2504.19183", "authors": ["Mi Zheng", "Guanglei Yang", "Zitong Huang", "Zhenhua Guo", "Kevin Han", "Wangmeng Zuo"], "title": "Segmenting Objectiveness and Task-awareness Unknown Region for Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "With the emergence of transformer-based architectures and large language\nmodels (LLMs), the accuracy of road scene perception has substantially\nadvanced. Nonetheless, current road scene segmentation approaches are\npredominantly trained on closed-set data, resulting in insufficient detection\ncapabilities for out-of-distribution (OOD) objects. To overcome this\nlimitation, road anomaly detection methods have been proposed. However,\nexisting methods primarily depend on image inpainting and OOD distribution\ndetection techniques, facing two critical issues: (1) inadequate consideration\nof the objectiveness attributes of anomalous regions, causing incomplete\nsegmentation when anomalous objects share similarities with known classes, and\n(2) insufficient attention to environmental constraints, leading to the\ndetection of anomalies irrelevant to autonomous driving tasks. In this paper,\nwe propose a novel framework termed Segmenting Objectiveness and Task-Awareness\n(SOTA) for autonomous driving scenes. Specifically, SOTA enhances the\nsegmentation of objectiveness through a Semantic Fusion Block (SFB) and filters\nanomalies irrelevant to road navigation tasks using a Scene-understanding\nGuided Prompt-Context Adaptor (SG-PCA). Extensive empirical evaluations on\nmultiple benchmark datasets, including Fishyscapes Lost and Found,\nSegment-Me-If-You-Can, and RoadAnomaly, demonstrate that the proposed SOTA\nconsistently improves OOD detection performance across diverse detectors,\nachieving robust and accurate segmentation outcomes.", "AI": {"tldr": "SOTA framework improves OOD detection in road scenes by focusing on objectiveness and task-awareness, outperforming existing methods.", "motivation": "Current road scene segmentation lacks robustness for OOD objects due to closed-set training and inadequate anomaly detection methods.", "method": "SOTA uses Semantic Fusion Block (SFB) for objectiveness segmentation and Scene-understanding Guided Prompt-Context Adaptor (SG-PCA) to filter irrelevant anomalies.", "result": "SOTA achieves superior OOD detection performance on benchmarks like Fishyscapes and RoadAnomaly.", "conclusion": "SOTA enhances segmentation accuracy and robustness for autonomous driving by addressing objectiveness and task-awareness."}}
{"id": "2504.18878", "pdf": "https://arxiv.org/pdf/2504.18878", "abs": "https://arxiv.org/abs/2504.18878", "authors": ["Robert Leppich", "Michael Stenger", "Daniel Grillmeyer", "Vanessa Borst", "Samuel Kounev"], "title": "TSRM: A Lightweight Temporal Feature Encoding Architecture for Time Series Forecasting and Imputation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce a temporal feature encoding architecture called Time Series\nRepresentation Model (TSRM) for multivariate time series forecasting and\nimputation. The architecture is structured around CNN-based representation\nlayers, each dedicated to an independent representation learning task and\ndesigned to capture diverse temporal patterns, followed by an attention-based\nfeature extraction layer and a merge layer, designed to aggregate extracted\nfeatures. The architecture is fundamentally based on a configuration that is\ninspired by a Transformer encoder, with self-attention mechanisms at its core.\nThe TSRM architecture outperforms state-of-the-art approaches on most of the\nseven established benchmark datasets considered in our empirical evaluation for\nboth forecasting and imputation tasks. At the same time, it significantly\nreduces complexity in the form of learnable parameters. The source code is\navailable at https://github.com/RobertLeppich/TSRM.", "AI": {"tldr": "TSRM is a CNN and attention-based model for time series forecasting and imputation, outperforming state-of-the-art methods with fewer parameters.", "motivation": "To improve multivariate time series forecasting and imputation by capturing diverse temporal patterns efficiently.", "method": "Uses CNN-based representation layers for independent tasks, attention-based feature extraction, and a merge layer, inspired by Transformer encoders.", "result": "Outperforms benchmarks on seven datasets for both tasks while reducing parameter complexity.", "conclusion": "TSRM is an effective, efficient architecture for time series tasks, with open-source availability."}}
{"id": "2504.20010", "pdf": "https://arxiv.org/pdf/2504.20010", "abs": "https://arxiv.org/abs/2504.20010", "authors": ["Jacob Emmerson", "Rayid Ghani", "Zheyuan Ryan Shi"], "title": "Towards Automated Scoping of AI for Social Good Projects", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Artificial Intelligence for Social Good (AI4SG) is an emerging effort that\naims to address complex societal challenges with the powerful capabilities of\nAI systems. These challenges range from local issues with transit networks to\nglobal wildlife preservation. However, regardless of scale, a critical\nbottleneck for many AI4SG initiatives is the laborious process of problem\nscoping -- a complex and resource-intensive task -- due to a scarcity of\nprofessionals with both technical and domain expertise. Given the remarkable\napplications of large language models (LLM), we propose a Problem Scoping Agent\n(PSA) that uses an LLM to generate comprehensive project proposals grounded in\nscientific literature and real-world knowledge. We demonstrate that our PSA\nframework generates proposals comparable to those written by experts through a\nblind review and AI evaluations. Finally, we document the challenges of\nreal-world problem scoping and note several areas for future work.", "AI": {"tldr": "AI4SG aims to tackle societal issues using AI, but problem scoping is a bottleneck. A Problem Scoping Agent (PSA) using LLMs generates expert-level proposals, validated by blind reviews. Challenges and future work are noted.", "motivation": "Addressing societal challenges with AI is hindered by the complex, resource-intensive process of problem scoping due to a lack of dual-expertise professionals.", "method": "Proposes a Problem Scoping Agent (PSA) leveraging large language models (LLMs) to create scientifically grounded project proposals.", "result": "PSA-generated proposals are comparable to expert-written ones, validated through blind reviews and AI evaluations.", "conclusion": "The PSA framework shows promise but highlights challenges in real-world problem scoping, suggesting areas for future research."}}
{"id": "2504.19395", "pdf": "https://arxiv.org/pdf/2504.19395", "abs": "https://arxiv.org/abs/2504.19395", "authors": ["Zhouxiang Fang", "Aayush Mishra", "Muhan Gao", "Anqi Liu", "Daniel Khashabi"], "title": "ICL CIPHERS: Quantifying \"Learning'' in In-Context Learning via Substitution Ciphers", "categories": ["cs.CL"], "comment": null, "summary": "Recent works have suggested that In-Context Learning (ICL) operates in dual\nmodes, i.e. task retrieval (remember learned patterns from pre-training) and\ntask learning (inference-time ``learning'' from demonstrations). However,\ndisentangling these the two modes remains a challenging goal. We introduce ICL\nCIPHERS, a class of task reformulations based on substitution ciphers borrowed\nfrom classic cryptography. In this approach, a subset of tokens in the\nin-context inputs are substituted with other (irrelevant) tokens, rendering\nEnglish sentences less comprehensible to human eye. However, by design, there\nis a latent, fixed pattern to this substitution, making it reversible. This\nbijective (reversible) cipher ensures that the task remains a well-defined task\nin some abstract sense, despite the transformations. It is a curious question\nif LLMs can solve ICL CIPHERS with a BIJECTIVE mapping, which requires\ndeciphering the latent cipher. We show that LLMs are better at solving ICL\nCIPHERS with BIJECTIVE mappings than the NON-BIJECTIVE (irreversible) baseline,\nproviding a novel approach to quantify ``learning'' in ICL. While this gap is\nsmall, it is consistent across the board on four datasets and six models.\nFinally, we examine LLMs' internal representations and identify evidence in\ntheir ability to decode the ciphered inputs.", "AI": {"tldr": "The paper introduces ICL CIPHERS, a method using reversible substitution ciphers to study dual modes of In-Context Learning (ICL) in LLMs, showing they perform better with bijective mappings.", "motivation": "Disentangling task retrieval and task learning in ICL is challenging. The study aims to quantify learning in ICL using cipher-based task reformulations.", "method": "ICL CIPHERS uses reversible substitution ciphers to transform in-context inputs, testing LLMs' ability to decipher latent patterns.", "result": "LLMs perform better with bijective (reversible) ciphers than non-bijective ones, showing consistent results across datasets and models.", "conclusion": "The study provides a novel way to quantify learning in ICL and finds evidence of LLMs decoding ciphered inputs."}}
{"id": "2504.19186", "pdf": "https://arxiv.org/pdf/2504.19186", "abs": "https://arxiv.org/abs/2504.19186", "authors": ["Zhangshuo Qi", "Luqi Cheng", "Zijie Zhou", "Guangming Xiong"], "title": "LRFusionPR: A Polar BEV-Based LiDAR-Radar Fusion Network for Place Recognition", "categories": ["cs.CV", "cs.RO"], "comment": "8 pages, 6 figures", "summary": "In autonomous driving, place recognition is critical for global localization\nin GPS-denied environments. LiDAR and radar-based place recognition methods\nhave garnered increasing attention, as LiDAR provides precise ranging, whereas\nradar excels in adverse weather resilience. However, effectively leveraging\nLiDAR-radar fusion for place recognition remains challenging. The noisy and\nsparse nature of radar data limits its potential to further improve recognition\naccuracy. In addition, heterogeneous radar configurations complicate the\ndevelopment of unified cross-modality fusion frameworks. In this paper, we\npropose LRFusionPR, which improves recognition accuracy and robustness by\nfusing LiDAR with either single-chip or scanning radar. Technically, a\ndual-branch network is proposed to fuse different modalities within the unified\npolar coordinate bird's eye view (BEV) representation. In the fusion branch,\ncross-attention is utilized to perform cross-modality feature interactions. The\nknowledge from the fusion branch is simultaneously transferred to the\ndistillation branch, which takes radar as its only input to further improve the\nrobustness. Ultimately, the descriptors from both branches are concatenated,\nproducing the multimodal global descriptor for place retrieval. Extensive\nevaluations on multiple datasets demonstrate that our LRFusionPR achieves\naccurate place recognition, while maintaining robustness under varying weather\nconditions. Our open-source code will be released at\nhttps://github.com/QiZS-BIT/LRFusionPR.", "AI": {"tldr": "LRFusionPR improves place recognition in GPS-denied environments by fusing LiDAR and radar data, using a dual-branch network for cross-modality feature interaction and robustness.", "motivation": "Addressing the challenges of noisy radar data and heterogeneous configurations in LiDAR-radar fusion for place recognition.", "method": "Proposes a dual-branch network for fusing LiDAR and radar data in a unified BEV representation, using cross-attention and knowledge distillation.", "result": "Achieves accurate place recognition and robustness under varying weather conditions, validated on multiple datasets.", "conclusion": "LRFusionPR effectively leverages LiDAR-radar fusion, enhancing recognition accuracy and robustness, with open-source code available."}}
{"id": "2504.18881", "pdf": "https://arxiv.org/pdf/2504.18881", "abs": "https://arxiv.org/abs/2504.18881", "authors": ["Hangtao Zhang", "Zhe Li", "Kairui Zhang"], "title": "TSCAN: Context-Aware Uplift Modeling via Two-Stage Training for Online Merchant Business Diagnosis", "categories": ["cs.LG"], "comment": "15 pages,7 figures", "summary": "A primary challenge in ITE estimation is sample selection bias. Traditional\napproaches utilize treatment regularization techniques such as the Integral\nProbability Metrics (IPM), re-weighting, and propensity score modeling to\nmitigate this bias. However, these regularizations may introduce undesirable\ninformation loss and limit the performance of the model. Furthermore, treatment\neffects vary across different external contexts, and the existing methods are\ninsufficient in fully interacting with and utilizing these contextual features.\nTo address these issues, we propose a Context-Aware uplift model based on the\nTwo-Stage training approach (TSCAN), comprising CAN-U and CAN-D sub-models. In\nthe first stage, we train an uplift model, called CAN-U, which includes the\ntreatment regularizations of IPM and propensity score prediction, to generate a\ncomplete dataset with counterfactual uplift labels. In the second stage, we\ntrain a model named CAN-D, which utilizes an isotonic output layer to directly\nmodel uplift effects, thereby eliminating the reliance on the regularization\ncomponents. CAN-D adaptively corrects the errors estimated by CAN-U through\nreinforcing the factual samples, while avoiding the negative impacts associated\nwith the aforementioned regularizations. Additionally, we introduce a\nContext-Aware Attention Layer throughout the two-stage process to manage the\ninteractions between treatment, merchant, and contextual features, thereby\nmodeling the varying treatment effect in different contexts. We conduct\nextensive experiments on two real-world datasets to validate the effectiveness\nof TSCAN. Ultimately, the deployment of our model for real-world merchant\ndiagnosis on one of China's largest online food ordering platforms validates\nits practical utility and impact.", "AI": {"tldr": "Proposes TSCAN, a two-stage context-aware uplift model (CAN-U and CAN-D) to address sample selection bias and context variability in ITE estimation, outperforming traditional methods.", "motivation": "Sample selection bias and context variability in ITE estimation limit traditional methods, necessitating a more adaptive approach.", "method": "Two-stage training: CAN-U (with IPM and propensity score) generates uplift labels; CAN-D (isotonic layer) refines estimates without regularization. Context-Aware Attention Layer handles feature interactions.", "result": "Validated on real-world datasets, TSCAN outperforms traditional methods and proves practical in merchant diagnosis on a major platform.", "conclusion": "TSCAN effectively addresses bias and context issues, offering superior performance and real-world utility."}}
{"id": "2504.18563", "pdf": "https://arxiv.org/pdf/2504.18563", "abs": "https://arxiv.org/abs/2504.18563", "authors": ["Abha Jha", "Ashwath Vaithinathan Aravindan", "Matthew Salaway", "Atharva Sandeep Bhide", "Duygu Nur Yaldiz"], "title": "Backdoor Defense in Diffusion Models via Spatial Attention Unlearning", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": null, "summary": "Text-to-image diffusion models are increasingly vulnerable to backdoor\nattacks, where malicious modifications to the training data cause the model to\ngenerate unintended outputs when specific triggers are present. While\nclassification models have seen extensive development of defense mechanisms,\ngenerative models remain largely unprotected due to their high-dimensional\noutput space, which complicates the detection and mitigation of subtle\nperturbations. Defense strategies for diffusion models, in particular, remain\nunder-explored. In this work, we propose Spatial Attention Unlearning (SAU), a\nnovel technique for mitigating backdoor attacks in diffusion models. SAU\nleverages latent space manipulation and spatial attention mechanisms to isolate\nand remove the latent representation of backdoor triggers, ensuring precise and\nefficient removal of malicious effects. We evaluate SAU across various types of\nbackdoor attacks, including pixel-based and style-based triggers, and\ndemonstrate its effectiveness in achieving 100% trigger removal accuracy.\nFurthermore, SAU achieves a CLIP score of 0.7023, outperforming existing\nmethods while preserving the model's ability to generate high-quality,\nsemantically aligned images. Our results show that SAU is a robust, scalable,\nand practical solution for securing text-to-image diffusion models against\nbackdoor attacks.", "AI": {"tldr": "SAU is a novel defense for text-to-image diffusion models against backdoor attacks, using spatial attention and latent space manipulation to remove triggers effectively.", "motivation": "Text-to-image diffusion models lack robust defenses against backdoor attacks due to their high-dimensional output space, leaving them vulnerable.", "method": "SAU employs latent space manipulation and spatial attention mechanisms to isolate and remove backdoor triggers.", "result": "SAU achieves 100% trigger removal accuracy and a high CLIP score (0.7023), outperforming existing methods.", "conclusion": "SAU is a scalable and practical solution for securing diffusion models against backdoor attacks while maintaining image quality."}}
{"id": "2504.19406", "pdf": "https://arxiv.org/pdf/2504.19406", "abs": "https://arxiv.org/abs/2504.19406", "authors": ["Mengxia Yu", "Bang Nguyen", "Olivia Zino", "Meng Jiang"], "title": "Context Selection and Rewriting for Video-based EducationalQuestion Generation", "categories": ["cs.CL"], "comment": null, "summary": "Educational question generation (EQG) is a crucial component of intelligent\neducational systems, significantly aiding self-assessment, active learning, and\npersonalized education. While EQG systems have emerged, existing datasets\ntypically rely on predefined, carefully edited texts, failing to represent\nreal-world classroom content, including lecture speech with a set of\ncomplementary slides. To bridge this gap, we collect a dataset of educational\nquestions based on lectures from real-world classrooms. On this realistic\ndataset, we find that current methods for EQG struggle with accurately\ngenerating questions from educational videos, particularly in aligning with\nspecific timestamps and target answers. Common challenges include selecting\ninformative contexts from extensive transcripts and ensuring generated\nquestions meaningfully incorporate the target answer. To address the\nchallenges, we introduce a novel framework utilizing large language models for\ndynamically selecting and rewriting contexts based on target timestamps and\nanswers. First, our framework selects contexts from both lecture transcripts\nand video keyframes based on answer relevance and temporal proximity. Then, we\nintegrate the contexts selected from both modalities and rewrite them into\nanswer-containing knowledge statements, to enhance the logical connection\nbetween the contexts and the desired answer. This approach significantly\nimproves the quality and relevance of the generated questions. Our dataset and\ncode are released in https://github.com/mengxiayu/COSER.", "AI": {"tldr": "The paper introduces a dataset and framework for educational question generation (EQG) from real-world lectures, addressing challenges in context selection and answer alignment using large language models.", "motivation": "Existing EQG datasets rely on edited texts, lacking real-world classroom content. The paper aims to bridge this gap by using lecture speech and slides.", "method": "A novel framework dynamically selects and rewrites contexts from transcripts and keyframes, integrating them into answer-containing knowledge statements.", "result": "The approach improves question quality and relevance by better aligning contexts with target answers and timestamps.", "conclusion": "The released dataset and framework enhance EQG for real-world educational content."}}
{"id": "2504.19210", "pdf": "https://arxiv.org/pdf/2504.19210", "abs": "https://arxiv.org/abs/2504.19210", "authors": ["Yuming Zhao", "Qijian Zhang", "Junhui Hou", "Jiazhi Xia", "Wenping Wang", "Ying He"], "title": "FlexPara: Flexible Neural Surface Parameterization", "categories": ["cs.CV"], "comment": null, "summary": "Surface parameterization is a fundamental geometry processing task, laying\nthe foundations for the visual presentation of 3D assets and numerous\ndownstream shape analysis scenarios. Conventional parameterization approaches\ndemand high-quality mesh triangulation and are restricted to certain simple\ntopologies unless additional surface cutting and decomposition are provided. In\npractice, the optimal configurations (e.g., type of parameterization domains,\ndistribution of cutting seams, number of mapping charts) may vary drastically\nwith different surface structures and task characteristics, thus requiring more\nflexible and controllable processing pipelines. To this end, this paper\nintroduces FlexPara, an unsupervised neural optimization framework to achieve\nboth global and multi-chart surface parameterizations by establishing\npoint-wise mappings between 3D surface points and adaptively-deformed 2D UV\ncoordinates. We ingeniously design and combine a series of\ngeometrically-interpretable sub-networks, with specific functionalities of\ncutting, deforming, unwrapping, and wrapping, to construct a bi-directional\ncycle mapping framework for global parameterization without the need for\nmanually specified cutting seams. Furthermore, we construct a multi-chart\nparameterization framework with adaptively-learned chart assignment. Extensive\nexperiments demonstrate the universality, superiority, and inspiring potential\nof our neural surface parameterization paradigm. The code will be publicly\navailable at https://github.com/AidenZhao/FlexPara", "AI": {"tldr": "FlexPara is an unsupervised neural framework for flexible and controllable surface parameterization, enabling global and multi-chart mappings without manual cutting seams.", "motivation": "Conventional parameterization methods require high-quality meshes and are limited to simple topologies, lacking flexibility for varied surface structures and tasks.", "method": "FlexPara uses geometrically-interpretable sub-networks for cutting, deforming, unwrapping, and wrapping, forming a bi-directional cycle mapping framework. It also adaptively learns chart assignments for multi-chart parameterization.", "result": "Experiments show FlexPara's universality and superiority in neural surface parameterization.", "conclusion": "FlexPara offers a flexible, unsupervised solution for surface parameterization, with potential for broader applications."}}
{"id": "2504.18882", "pdf": "https://arxiv.org/pdf/2504.18882", "abs": "https://arxiv.org/abs/2504.18882", "authors": ["Ce Ju", "Reinmar J. Kobler", "Antoine Collas", "Motoaki Kawanabe", "Cuntai Guan", "Bertrand Thirion"], "title": "SPD Learning for Covariance-Based Neuroimaging Analysis: Perspectives, Methods, and Challenges", "categories": ["cs.LG", "cs.AI", "eess.IV", "q-bio.NC", "I.2.0"], "comment": "20 pages, 3 figures, 2 tables; This paper has been submitted for\n  possible publication, and currently under review", "summary": "Neuroimaging provides a critical framework for characterizing brain activity\nby quantifying connectivity patterns and functional architecture across\nmodalities. While modern machine learning has significantly advanced our\nunderstanding of neural processing mechanisms through these datasets, decoding\ntask-specific signatures must contend with inherent neuroimaging constraints,\nfor example, low signal-to-noise ratios in raw electrophysiological recordings,\ncross-session non-stationarity, and limited sample sizes. This review focuses\non machine learning approaches for covariance-based neuroimaging data, where\noften symmetric positive definite (SPD) matrices under full-rank conditions\nencode inter-channel relationships. By equipping the space of SPD matrices with\nRiemannian metrics (e.g., affine-invariant or log-Euclidean), their space forms\na Riemannian manifold enabling geometric analysis. We unify methodologies\noperating on this manifold under the SPD learning framework, which\nsystematically leverages the SPD manifold's geometry to process covariance\nfeatures, thereby advancing brain imaging analytics.", "AI": {"tldr": "The paper reviews machine learning approaches for covariance-based neuroimaging data, focusing on SPD matrices and Riemannian metrics to enhance brain imaging analytics.", "motivation": "Neuroimaging faces challenges like low signal-to-noise ratios and cross-session non-stationarity. Machine learning can improve understanding by leveraging SPD matrices and Riemannian geometry.", "method": "The paper uses Riemannian metrics (e.g., affine-invariant or log-Euclidean) to analyze SPD matrices, forming a Riemannian manifold for geometric analysis.", "result": "The SPD learning framework unifies methodologies to process covariance features, improving brain imaging analytics.", "conclusion": "Riemannian geometry and SPD matrices offer a powerful framework for advancing neuroimaging data analysis."}}
{"id": "2504.18564", "pdf": "https://arxiv.org/pdf/2504.18564", "abs": "https://arxiv.org/abs/2504.18564", "authors": ["Xinzhe Huang", "Kedong Xiu", "Tianhang Zheng", "Churui Zeng", "Wangze Ni", "Zhan Qiin", "Kui Ren", "Chun Chen"], "title": "DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization", "categories": ["cs.CR", "cs.AI"], "comment": "20 pages, 8 figures", "summary": "Recent research has focused on exploring the vulnerabilities of Large\nLanguage Models (LLMs), aiming to elicit harmful and/or sensitive content from\nLLMs. However, due to the insufficient research on dual-jailbreaking -- attacks\ntargeting both LLMs and Guardrails, the effectiveness of existing attacks is\nlimited when attempting to bypass safety-aligned LLMs shielded by guardrails.\nTherefore, in this paper, we propose DualBreach, a target-driven framework for\ndual-jailbreaking. DualBreach employs a Target-driven Initialization (TDI)\nstrategy to dynamically construct initial prompts, combined with a Multi-Target\nOptimization (MTO) method that utilizes approximate gradients to jointly adapt\nthe prompts across guardrails and LLMs, which can simultaneously save the\nnumber of queries and achieve a high dual-jailbreaking success rate. For\nblack-box guardrails, DualBreach either employs a powerful open-sourced\nguardrail or imitates the target black-box guardrail by training a proxy model,\nto incorporate guardrails into the MTO process.\n  We demonstrate the effectiveness of DualBreach in dual-jailbreaking scenarios\nthrough extensive evaluation on several widely-used datasets. Experimental\nresults indicate that DualBreach outperforms state-of-the-art methods with\nfewer queries, achieving significantly higher success rates across all\nsettings. More specifically, DualBreach achieves an average dual-jailbreaking\nsuccess rate of 93.67% against GPT-4 with Llama-Guard-3 protection, whereas the\nbest success rate achieved by other methods is 88.33%. Moreover, DualBreach\nonly uses an average of 1.77 queries per successful dual-jailbreak,\noutperforming other state-of-the-art methods. For the purpose of defense, we\npropose an XGBoost-based ensemble defensive mechanism named EGuard, which\nintegrates the strengths of multiple guardrails, demonstrating superior\nperformance compared with Llama-Guard-3.", "AI": {"tldr": "DualBreach is a framework for dual-jailbreaking LLMs and guardrails, achieving high success rates with fewer queries, and includes a defensive mechanism, EGuard.", "motivation": "Existing attacks on LLMs are limited against safety-aligned models with guardrails, necessitating a dual-jailbreaking approach.", "method": "DualBreach uses Target-driven Initialization (TDI) and Multi-Target Optimization (MTO) to adapt prompts for both LLMs and guardrails, including proxy models for black-box guardrails.", "result": "DualBreach achieves 93.67% success rate against GPT-4 with Llama-Guard-3, using only 1.77 queries per success, outperforming other methods.", "conclusion": "DualBreach is effective for dual-jailbreaking, and EGuard provides robust defense, surpassing existing guardrails."}}
{"id": "2504.19413", "pdf": "https://arxiv.org/pdf/2504.19413", "abs": "https://arxiv.org/abs/2504.19413", "authors": ["Prateek Chhikara", "Dev Khant", "Saket Aryan", "Taranjeet Singh", "Deshraj Yadav"], "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable prowess in\ngenerating contextually coherent responses, yet their fixed context windows\npose fundamental challenges for maintaining consistency over prolonged\nmulti-session dialogues. We introduce Mem0, a scalable memory-centric\narchitecture that addresses this issue by dynamically extracting,\nconsolidating, and retrieving salient information from ongoing conversations.\nBuilding on this foundation, we further propose an enhanced variant that\nleverages graph-based memory representations to capture complex relational\nstructures among conversational elements. Through comprehensive evaluations on\nLOCOMO benchmark, we systematically compare our approaches against six baseline\ncategories: (i) established memory-augmented systems, (ii) retrieval-augmented\ngeneration (RAG) with varying chunk sizes and k-values, (iii) a full-context\napproach that processes the entire conversation history, (iv) an open-source\nmemory solution, (v) a proprietary model system, and (vi) a dedicated memory\nmanagement platform. Empirical results show that our methods consistently\noutperform all existing memory systems across four question categories:\nsingle-hop, temporal, multi-hop, and open-domain. Notably, Mem0 achieves 26%\nrelative improvements in the LLM-as-a-Judge metric over OpenAI, while Mem0 with\ngraph memory achieves around 2% higher overall score than the base\nconfiguration. Beyond accuracy gains, we also markedly reduce computational\noverhead compared to full-context method. In particular, Mem0 attains a 91%\nlower p95 latency and saves more than 90% token cost, offering a compelling\nbalance between advanced reasoning capabilities and practical deployment\nconstraints. Our findings highlight critical role of structured, persistent\nmemory mechanisms for long-term conversational coherence, paving the way for\nmore reliable and efficient LLM-driven AI agents.", "AI": {"tldr": "Mem0, a scalable memory-centric architecture, improves LLM consistency in multi-session dialogues by dynamically managing conversational memory, outperforming baselines in accuracy and efficiency.", "motivation": "Fixed context windows in LLMs hinder long-term conversational consistency, necessitating a dynamic memory solution.", "method": "Introduces Mem0, a memory-centric architecture, and an enhanced graph-based variant for relational memory. Evaluated against six baseline categories on the LOCOMO benchmark.", "result": "Mem0 outperforms baselines, achieving 26% improvement over OpenAI in LLM-as-a-Judge and 91% lower latency. Graph-based Mem0 adds 2% overall score.", "conclusion": "Structured, persistent memory mechanisms are crucial for reliable and efficient LLM-driven AI agents in long-term conversations."}}
{"id": "2504.19212", "pdf": "https://arxiv.org/pdf/2504.19212", "abs": "https://arxiv.org/abs/2504.19212", "authors": ["Tuan Nguyen", "Naseem Khan", "Issa Khalil"], "title": "CapsFake: A Multimodal Capsule Network for Detecting Instruction-Guided Deepfakes", "categories": ["cs.CV", "cs.AI"], "comment": "20 pages", "summary": "The rapid evolution of deepfake technology, particularly in\ninstruction-guided image editing, threatens the integrity of digital images by\nenabling subtle, context-aware manipulations. Generated conditionally from real\nimages and textual prompts, these edits are often imperceptible to both humans\nand existing detection systems, revealing significant limitations in current\ndefenses. We propose a novel multimodal capsule network, CapsFake, designed to\ndetect such deepfake image edits by integrating low-level capsules from visual,\ntextual, and frequency-domain modalities. High-level capsules, predicted\nthrough a competitive routing mechanism, dynamically aggregate local features\nto identify manipulated regions with precision. Evaluated on diverse datasets,\nincluding MagicBrush, Unsplash Edits, Open Images Edits, and Multi-turn Edits,\nCapsFake outperforms state-of-the-art methods by up to 20% in detection\naccuracy. Ablation studies validate its robustness, achieving detection rates\nabove 94% under natural perturbations and 96% against adversarial attacks, with\nexcellent generalization to unseen editing scenarios. This approach establishes\na powerful framework for countering sophisticated image manipulations.", "AI": {"tldr": "CapsFake, a multimodal capsule network, detects deepfake image edits by integrating visual, textual, and frequency-domain features, outperforming existing methods by up to 20% in accuracy.", "motivation": "The rise of subtle, context-aware deepfake image manipulations challenges current detection systems, necessitating advanced solutions.", "method": "CapsFake uses low-level capsules from multiple modalities and high-level capsules with competitive routing to identify manipulated regions.", "result": "CapsFake achieves over 94% detection accuracy under natural perturbations and 96% against adversarial attacks, with strong generalization.", "conclusion": "CapsFake provides a robust framework for detecting sophisticated deepfake image edits, addressing current defense limitations."}}
{"id": "2504.18914", "pdf": "https://arxiv.org/pdf/2504.18914", "abs": "https://arxiv.org/abs/2504.18914", "authors": ["Ma\u0142gorzata \u0141az\u0119cka", "Ewa Szczurek"], "title": "Factor Analysis with Correlated Topic Model for Multi-Modal Data", "categories": ["cs.LG", "stat.AP", "stat.ML"], "comment": "AISTATS 2025", "summary": "Integrating various data modalities brings valuable insights into underlying\nphenomena. Multimodal factor analysis (FA) uncovers shared axes of variation\nunderlying different simple data modalities, where each sample is represented\nby a vector of features. However, FA is not suited for structured data\nmodalities, such as text or single cell sequencing data, where multiple data\npoints are measured per each sample and exhibit a clustering structure. To\novercome this challenge, we introduce FACTM, a novel, multi-view and\nmulti-structure Bayesian model that combines FA with correlated topic modeling\nand is optimized using variational inference. Additionally, we introduce a\nmethod for rotating latent factors to enhance interpretability with respect to\nbinary features. On text and video benchmarks as well as real-world music and\nCOVID-19 datasets, we demonstrate that FACTM outperforms other methods in\nidentifying clusters in structured data, and integrating them with simple\nmodalities via the inference of shared, interpretable factors.", "AI": {"tldr": "FACTM is a Bayesian model combining factor analysis and topic modeling for structured data, outperforming others in clustering and interpretability.", "motivation": "Existing factor analysis (FA) methods are inadequate for structured data like text or single-cell sequencing, which have clustering structures.", "method": "FACTM integrates FA with correlated topic modeling, uses variational inference, and includes factor rotation for interpretability.", "result": "FACTM excels in clustering structured data and integrating it with simple modalities, as shown on text, video, music, and COVID-19 datasets.", "conclusion": "FACTM is a robust solution for multimodal structured data analysis, offering improved interpretability and performance."}}
{"id": "2504.18565", "pdf": "https://arxiv.org/pdf/2504.18565", "abs": "https://arxiv.org/abs/2504.18565", "authors": ["Sid Black", "Asa Cooper Stickland", "Jake Pencharz", "Oliver Sourbut", "Michael Schmatz", "Jay Bailey", "Ollie Matthews", "Ben Millwood", "Alex Remedios", "Alan Cooney"], "title": "RepliBench: Evaluating the autonomous replication capabilities of language model agents", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Uncontrollable autonomous replication of language model agents poses a\ncritical safety risk. To better understand this risk, we introduce RepliBench,\na suite of evaluations designed to measure autonomous replication capabilities.\nRepliBench is derived from a decomposition of these capabilities covering four\ncore domains: obtaining resources, exfiltrating model weights, replicating onto\ncompute, and persisting on this compute for long periods. We create 20 novel\ntask families consisting of 86 individual tasks. We benchmark 5 frontier\nmodels, and find they do not currently pose a credible threat of\nself-replication, but succeed on many components and are improving rapidly.\nModels can deploy instances from cloud compute providers, write\nself-propagating programs, and exfiltrate model weights under simple security\nsetups, but struggle to pass KYC checks or set up robust and persistent agent\ndeployments. Overall the best model we evaluated (Claude 3.7 Sonnet) has a >50%\npass@10 score on 15/20 task families, and a >50% pass@10 score for 9/20\nfamilies on the hardest variants. These findings suggest autonomous replication\ncapability could soon emerge with improvements in these remaining areas or with\nhuman assistance.", "AI": {"tldr": "RepliBench evaluates autonomous replication risks in language models, finding current models lack credible self-replication threats but show rapid improvement in key areas.", "motivation": "To assess the safety risks of uncontrolled autonomous replication by language model agents.", "method": "Introduces RepliBench, a suite of 20 task families (86 tasks) measuring replication capabilities across four domains: resource acquisition, weight exfiltration, compute replication, and persistence. Benchmarks 5 frontier models.", "result": "Models can perform tasks like deploying cloud instances or writing self-propagating programs but struggle with KYC or persistent deployments. Claude 3.7 Sonnet scores >50% on 15/20 task families.", "conclusion": "Autonomous replication capability may soon emerge with further improvements or human assistance."}}
{"id": "2504.19436", "pdf": "https://arxiv.org/pdf/2504.19436", "abs": "https://arxiv.org/abs/2504.19436", "authors": ["Jacky He", "Guiran Liu", "Binrong Zhu", "Hanlu Zhang", "Hongye Zheng", "Xiaokai Wang"], "title": "Context-Guided Dynamic Retrieval for Improving Generation Quality in RAG Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper focuses on the dynamic optimization of the Retrieval-Augmented\nGeneration (RAG) architecture. It proposes a state-aware dynamic knowledge\nretrieval mechanism to enhance semantic understanding and knowledge scheduling\nefficiency in large language models for open-domain question answering and\ncomplex generation tasks. The method introduces a multi-level perceptive\nretrieval vector construction strategy and a differentiable document matching\npath. These components enable end-to-end joint training and collaborative\noptimization of the retrieval and generation modules. This effectively\naddresses the limitations of static RAG structures in context adaptation and\nknowledge access. Experiments are conducted on the Natural Questions dataset.\nThe proposed structure is thoroughly evaluated across different large models,\nincluding GPT-4, GPT-4o, and DeepSeek. Comparative and ablation experiments\nfrom multiple perspectives confirm the significant improvements in BLEU and\nROUGE-L scores. The approach also demonstrates stronger robustness and\ngeneration consistency in tasks involving semantic ambiguity and multi-document\nfusion. These results highlight its broad application potential and practical\nvalue in building high-quality language generation systems.", "AI": {"tldr": "The paper introduces a dynamic optimization method for Retrieval-Augmented Generation (RAG) architecture, improving semantic understanding and knowledge scheduling efficiency for open-domain tasks.", "motivation": "To address limitations of static RAG structures in context adaptation and knowledge access for large language models.", "method": "Proposes a state-aware dynamic knowledge retrieval mechanism with multi-level perceptive retrieval vectors and differentiable document matching paths for joint training.", "result": "Significant improvements in BLEU and ROUGE-L scores on the Natural Questions dataset, with enhanced robustness and generation consistency.", "conclusion": "The method shows broad application potential and practical value for high-quality language generation systems."}}
{"id": "2504.19223", "pdf": "https://arxiv.org/pdf/2504.19223", "abs": "https://arxiv.org/abs/2504.19223", "authors": ["Alexander Baumann", "Leonardo Ayala", "Silvia Seidlitz", "Jan Sellner", "Alexander Studier-Fischer", "Berkin \u00d6zdemir", "Lena Maier-Hein", "Slobodan Ilic"], "title": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Spectral imaging offers promising applications across diverse domains,\nincluding medicine and urban scene understanding, and is already established as\na critical modality in remote sensing. However, variability in channel\ndimensionality and captured wavelengths among spectral cameras impede the\ndevelopment of AI-driven methodologies, leading to camera-specific models with\nlimited generalizability and inadequate cross-camera applicability. To address\nthis bottleneck, we introduce $\\textbf{CARL}$, a model for\n$\\textbf{C}$amera-$\\textbf{A}$gnostic $\\textbf{R}$epresentation\n$\\textbf{L}$earning across RGB, multispectral, and hyperspectral imaging\nmodalities. To enable the conversion of a spectral image with any channel\ndimensionality to a camera-agnostic embedding, we introduce wavelength\npositional encoding and a self-attention-cross-attention mechanism to compress\nspectral information into learned query representations. Spectral-spatial\npre-training is achieved with a novel spectral self-supervised JEPA-inspired\nstrategy tailored to CARL. Large-scale experiments across the domains of\nmedical imaging, autonomous driving, and satellite imaging demonstrate our\nmodel's unique robustness to spectral heterogeneity, outperforming on datasets\nwith simulated and real-world cross-camera spectral variations. The scalability\nand versatility of the proposed approach position our model as a backbone for\nfuture spectral foundation models.", "AI": {"tldr": "CARL introduces a camera-agnostic model for spectral imaging, addressing variability in channel dimensionality and wavelengths to improve AI-driven methodologies.", "motivation": "Variability in spectral cameras limits AI model generalizability and cross-camera applicability, necessitating a unified solution.", "method": "CARL uses wavelength positional encoding and a self-attention-cross-attention mechanism to create camera-agnostic embeddings, with spectral-spatial pre-training via a JEPA-inspired strategy.", "result": "CARL outperforms in robustness to spectral heterogeneity across medical, autonomous driving, and satellite imaging datasets.", "conclusion": "CARL's scalability and versatility make it a potential backbone for future spectral foundation models."}}
{"id": "2504.18929", "pdf": "https://arxiv.org/pdf/2504.18929", "abs": "https://arxiv.org/abs/2504.18929", "authors": ["Ruifeng Ren", "Yong Liu"], "title": "Revisiting Transformers through the Lens of Low Entropy and Dynamic Sparsity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Compression has been a critical lens to understand the success of\nTransformers. In the past, we have typically taken the target distribution as a\ncriterion to evaluate a model's compression performance. Nevertheless,it often\nremains challenging to precisely assess how well the model achieves compression\nand to compare the information content of the learned distribution with that of\nthe target distribution during compression,as the target distribution is\ntypically unknown and entropy computation often incurs exponential cost. In\nthis work, we explore these issues under a controlled experimental setup. We\nfind that Transformers exhibit a unique inductive bias in data compression:\nbeyond approaching the target distribution, they tend to favor learning\nlower-entropy distributions, with this tendency becoming more pronounced as the\nmodel size increases. This preference prevents Transformers from perfectly\naligning with the target distribution, instead further compressing its\ninformation content. Furthermore, we show that the FFN module plays a critical\nrole in driving this bias. In addition, while models remove informational\nredundancy from data during compression, they also exhibit redundancy within\ntheir parameters, which enables compression and can be characterized through\ndynamic sparsity. However, the dynamic sparsity patterns in Transformers,\nparticularly in attention and FFN modules, demand further exploration. As for\nthis, we show that larger Transformers show stronger preferences for bypassing\nattention computations via residual connections and have lower proportion of\nactive neurons. Interestingly, we also find that training instability in larger\nmodels strongly correlates with sudden increases in dead neurons. Our work\ncontributes to a deeper understanding of Transformers from the lens of entropy\nand dynamic sparsity.", "AI": {"tldr": "Transformers exhibit a bias toward learning lower-entropy distributions during compression, with larger models showing stronger tendencies. The FFN module drives this bias, and dynamic sparsity reveals parameter redundancy. Training instability in larger models correlates with dead neurons.", "motivation": "To understand how Transformers achieve compression and compare their learned distributions with target distributions, given the challenges of unknown target distributions and high entropy computation costs.", "method": "Controlled experiments to analyze Transformers' inductive bias in compression, focusing on entropy and dynamic sparsity, particularly in attention and FFN modules.", "result": "Transformers favor lower-entropy distributions, with larger models showing stronger biases. The FFN module is key to this behavior, and dynamic sparsity highlights parameter redundancy. Training instability in larger models links to dead neurons.", "conclusion": "Transformers' compression behavior is driven by entropy and dynamic sparsity, with the FFN module playing a critical role. Larger models exhibit stronger biases and training instability, offering insights into their inner workings."}}
{"id": "2504.18566", "pdf": "https://arxiv.org/pdf/2504.18566", "abs": "https://arxiv.org/abs/2504.18566", "authors": ["Harsh Patel"], "title": "Feature Selection via GANs (GANFS): Enhancing Machine Learning Models for DDoS Mitigation", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Distributed Denial of Service (DDoS) attacks represent a persistent and\nevolving threat to modern networked systems, capable of causing large-scale\nservice disruptions. The complexity of such attacks, often hidden within\nhigh-dimensional and redundant network traffic data, necessitates robust and\nintelligent feature selection techniques for effective detection. Traditional\nmethods such as filter-based, wrapper-based, and embedded approaches, each\noffer strengths but struggle with scalability or adaptability in complex attack\nenvironments. In this study, we explore these existing techniques through a\ndetailed comparative analysis and highlight their limitations when applied to\nlarge-scale DDoS detection tasks. Building upon these insights, we introduce a\nnovel Generative Adversarial Network-based Feature Selection (GANFS) method\nthat leverages adversarial learning dynamics to identify the most informative\nfeatures. By training a GAN exclusively on attack traffic and employing a\nperturbation-based sensitivity analysis on the Discriminator, GANFS effectively\nranks feature importance without relying on full supervision. Experimental\nevaluations using the CIC-DDoS2019 dataset demonstrate that GANFS not only\nimproves the accuracy of downstream classifiers but also enhances computational\nefficiency by significantly reducing feature dimensionality. These results\npoint to the potential of integrating generative learning models into\ncybersecurity pipelines to build more adaptive and scalable detection systems.", "AI": {"tldr": "The paper introduces GANFS, a GAN-based feature selection method for DDoS detection, outperforming traditional techniques in accuracy and efficiency.", "motivation": "DDoS attacks are complex and evolving, requiring robust feature selection for detection. Traditional methods lack scalability or adaptability.", "method": "Proposes GANFS, using adversarial learning to rank feature importance without full supervision, evaluated on the CIC-DDoS2019 dataset.", "result": "GANFS improves classifier accuracy and computational efficiency by reducing feature dimensionality.", "conclusion": "GANFS shows promise for adaptive and scalable DDoS detection, integrating generative models into cybersecurity."}}
{"id": "2504.19445", "pdf": "https://arxiv.org/pdf/2504.19445", "abs": "https://arxiv.org/abs/2504.19445", "authors": ["Yi-Long Lu", "Chunhui Zhang", "Wei Wang"], "title": "Systematic Bias in Large Language Models: Discrepant Response Patterns in Binary vs. Continuous Judgment Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used in tasks such as\npsychological text analysis and decision-making in automated workflows.\nHowever, their reliability remains a concern due to potential biases inherited\nfrom their training process. In this study, we examine how different response\nformat: binary versus continuous, may systematically influence LLMs' judgments.\nIn a value statement judgments task and a text sentiment analysis task, we\nprompted LLMs to simulate human responses and tested both formats across\nseveral models, including both open-source and commercial models. Our findings\nrevealed a consistent negative bias: LLMs were more likely to deliver\n\"negative\" judgments in binary formats compared to continuous ones. Control\nexperiments further revealed that this pattern holds across both tasks. Our\nresults highlight the importance of considering response format when applying\nLLMs to decision tasks, as small changes in task design can introduce\nsystematic biases.", "AI": {"tldr": "LLMs show a consistent negative bias in binary response formats compared to continuous ones, impacting their reliability in decision tasks.", "motivation": "To investigate how response formats (binary vs. continuous) influence LLMs' judgments and reveal potential biases.", "method": "Tested LLMs in value statement judgments and text sentiment analysis tasks, comparing binary and continuous response formats across various models.", "result": "LLMs exhibited a consistent negative bias in binary formats compared to continuous ones, confirmed across tasks.", "conclusion": "Response format significantly affects LLMs' judgments, emphasizing the need for careful task design to mitigate biases."}}
{"id": "2504.19227", "pdf": "https://arxiv.org/pdf/2504.19227", "abs": "https://arxiv.org/abs/2504.19227", "authors": ["Shalini Maiti", "Lourdes Agapito", "Benjamin Graham"], "title": "Unsupervised 2D-3D lifting of non-rigid objects using local constraints", "categories": ["cs.CV"], "comment": null, "summary": "For non-rigid objects, predicting the 3D shape from 2D keypoint observations\nis ill-posed due to occlusions, and the need to disentangle changes in\nviewpoint and changes in shape. This challenge has often been addressed by\nembedding low-rank constraints into specialized models. These models can be\nhard to train, as they depend on finding a canonical way of aligning\nobservations, before they can learn detailed geometry. These constraints have\nlimited the reconstruction quality. We show that generic, high capacity models,\ntrained with an unsupervised loss, allow for more accurate predicted shapes. In\nparticular, applying low-rank constraints to localized subsets of the full\nshape allows the high capacity to be suitably constrained. We reduce the\nstate-of-the-art reconstruction error on the S-Up3D dataset by over 70%.", "AI": {"tldr": "High-capacity models with unsupervised loss outperform specialized low-rank models for 3D shape prediction from 2D keypoints, reducing reconstruction error by 70%.", "motivation": "The challenge of predicting 3D shapes from 2D keypoints for non-rigid objects is ill-posed due to occlusions and viewpoint-shape disentanglement. Existing low-rank models are limited by alignment dependencies and reconstruction quality.", "method": "Proposes generic, high-capacity models trained with an unsupervised loss, applying low-rank constraints to localized shape subsets for better accuracy.", "result": "Achieves a 70% reduction in reconstruction error on the S-Up3D dataset compared to state-of-the-art methods.", "conclusion": "High-capacity models with localized constraints offer superior performance for 3D shape prediction from 2D observations."}}
{"id": "2504.19000", "pdf": "https://arxiv.org/pdf/2504.19000", "abs": "https://arxiv.org/abs/2504.19000", "authors": ["Elad Sofer", "Tomer Shaked", "Caroline Chaux", "Nir Shlezinger"], "title": "Unveiling and Mitigating Adversarial Vulnerabilities in Iterative Optimizers", "categories": ["cs.LG", "eess.SP"], "comment": "Under review for publication in the IEEE", "summary": "Machine learning (ML) models are often sensitive to carefully crafted yet\nseemingly unnoticeable perturbations. Such adversarial examples are considered\nto be a property of ML models, often associated with their black-box operation\nand sensitivity to features learned from data. This work examines the\nadversarial sensitivity of non-learned decision rules, and particularly of\niterative optimizers. Our analysis is inspired by the recent developments in\ndeep unfolding, which cast such optimizers as ML models. We show that\nnon-learned iterative optimizers share the sensitivity to adversarial examples\nof ML models, and that attacking iterative optimizers effectively alters the\noptimization objective surface in a manner that modifies the minima sought. We\nthen leverage the ability to cast iteration-limited optimizers as ML models to\nenhance robustness via adversarial training. For a class of proximal gradient\noptimizers, we rigorously prove how their learning affects adversarial\nsensitivity. We numerically back our findings, showing the vulnerability of\nvarious optimizers, as well as the robustness induced by unfolding and\nadversarial training.", "AI": {"tldr": "The paper explores adversarial sensitivity in non-learned iterative optimizers, showing they share vulnerabilities with ML models. It proposes adversarial training to enhance robustness and validates findings numerically.", "motivation": "To investigate if non-learned iterative optimizers, like ML models, are susceptible to adversarial perturbations and to develop methods to improve their robustness.", "method": "Analyzes adversarial sensitivity in iterative optimizers, casts them as ML models via deep unfolding, and uses adversarial training to enhance robustness. Theoretical proofs and numerical experiments validate the approach.", "result": "Non-learned optimizers exhibit adversarial sensitivity similar to ML models. Adversarial training improves robustness, and theoretical proofs support the findings.", "conclusion": "Iterative optimizers are vulnerable to adversarial attacks, but adversarial training can mitigate this, bridging insights between optimization and ML robustness."}}
{"id": "2504.18569", "pdf": "https://arxiv.org/pdf/2504.18569", "abs": "https://arxiv.org/abs/2504.18569", "authors": ["Guanchen Wu", "Linzhi Zheng", "Han Xie", "Zhen Xiang", "Jiaying Lu", "Darren Liu", "Delgersuren Bold", "Bo Li", "Xiao Hu", "Carl Yang"], "title": "Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "Shorter version published in MedInfo 2025", "summary": "The de-identification of private information in medical data is a crucial\nprocess to mitigate the risk of confidentiality breaches, particularly when\npatient personal details are not adequately removed before the release of\nmedical records. Although rule-based and learning-based methods have been\nproposed, they often struggle with limited generalizability and require\nsubstantial amounts of annotated data for effective performance. Recent\nadvancements in large language models (LLMs) have shown significant promise in\naddressing these issues due to their superior language comprehension\ncapabilities. However, LLMs present challenges, including potential privacy\nrisks when using commercial LLM APIs and high computational costs for deploying\nopen-source LLMs locally. In this work, we introduce LPPA, an LLM-empowered\nPrivacy-Protected PHI Annotation framework for clinical notes, targeting the\nEnglish language. By fine-tuning LLMs locally with synthetic notes, LPPA\nensures strong privacy protection and high PHI annotation accuracy. Extensive\nexperiments demonstrate LPPA's effectiveness in accurately de-identifying\nprivate information, offering a scalable and efficient solution for enhancing\npatient privacy protection.", "AI": {"tldr": "LPPA is a privacy-protected framework using locally fine-tuned LLMs for accurate de-identification of medical data, addressing generalizability and privacy concerns.", "motivation": "Existing methods for de-identifying medical data lack generalizability and require large annotated datasets, while commercial LLMs pose privacy risks.", "method": "LPPA fine-tunes LLMs locally using synthetic clinical notes to ensure privacy and accuracy in PHI annotation.", "result": "LPPA achieves high accuracy in de-identifying private information, providing a scalable and efficient solution.", "conclusion": "LPPA offers a robust, privacy-protected approach for medical data de-identification, leveraging LLMs effectively."}}
{"id": "2504.19457", "pdf": "https://arxiv.org/pdf/2504.19457", "abs": "https://arxiv.org/abs/2504.19457", "authors": ["Siyi Liu", "Kishaloy Halder", "Zheng Qi", "Wei Xiao", "Nikolaos Pappas", "Phu Mon Htut", "Neha Anna John", "Yassine Benajiba", "Dan Roth"], "title": "Towards Long Context Hallucination Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious tasks. However, they are prone to contextual hallucination, generating\ninformation that is either unsubstantiated or contradictory to the given\ncontext. Although many studies have investigated contextual hallucinations in\nLLMs, addressing them in long-context inputs remains an open problem. In this\nwork, we take an initial step toward solving this problem by constructing a\ndataset specifically designed for long-context hallucination detection.\nFurthermore, we propose a novel architecture that enables pre-trained encoder\nmodels, such as BERT, to process long contexts and effectively detect\ncontextual hallucinations through a decomposition and aggregation mechanism.\nOur experimental results show that the proposed architecture significantly\noutperforms previous models of similar size as well as LLM-based models across\nvarious metrics, while providing substantially faster inference.", "AI": {"tldr": "A new method addresses contextual hallucinations in LLMs for long-context inputs by creating a specialized dataset and proposing an efficient architecture using pre-trained encoders like BERT.", "motivation": "LLMs often generate unsubstantiated or contradictory information in long-context inputs, a problem not fully addressed by existing research.", "method": "Constructed a dataset for long-context hallucination detection and introduced a decomposition-aggregation architecture for pre-trained encoders.", "result": "The proposed architecture outperforms similar-sized models and LLM-based models in accuracy and speed.", "conclusion": "The work provides an effective solution for detecting hallucinations in long-context LLM inputs, improving both performance and efficiency."}}
{"id": "2504.19244", "pdf": "https://arxiv.org/pdf/2504.19244", "abs": "https://arxiv.org/abs/2504.19244", "authors": ["De Cheng", "Lingfeng He", "Nannan Wang", "Dingwen Zhang", "Xinbo Gao"], "title": "Semantic-Aligned Learning with Collaborative Refinement for Unsupervised VI-ReID", "categories": ["cs.CV"], "comment": "Accepted by IJCV 2025", "summary": "Unsupervised visible-infrared person re-identification (USL-VI-ReID) seeks to\nmatch pedestrian images of the same individual across different modalities\nwithout human annotations for model learning. Previous methods unify\npseudo-labels of cross-modality images through label association algorithms and\nthen design contrastive learning framework for global feature learning.\nHowever, these methods overlook the cross-modality variations in feature\nrepresentation and pseudo-label distributions brought by fine-grained patterns.\nThis insight results in insufficient modality-shared learning when only global\nfeatures are optimized. To address this issue, we propose a Semantic-Aligned\nLearning with Collaborative Refinement (SALCR) framework, which builds up\noptimization objective for specific fine-grained patterns emphasized by each\nmodality, thereby achieving complementary alignment between the label\ndistributions of different modalities. Specifically, we first introduce a Dual\nAssociation with Global Learning (DAGI) module to unify the pseudo-labels of\ncross-modality instances in a bi-directional manner. Afterward, a Fine-Grained\nSemantic-Aligned Learning (FGSAL) module is carried out to explore part-level\nsemantic-aligned patterns emphasized by each modality from cross-modality\ninstances. Optimization objective is then formulated based on the\nsemantic-aligned features and their corresponding label space. To alleviate the\nside-effects arising from noisy pseudo-labels, we propose a Global-Part\nCollaborative Refinement (GPCR) module to mine reliable positive sample sets\nfor the global and part features dynamically and optimize the inter-instance\nrelationships. Extensive experiments demonstrate the effectiveness of the\nproposed method, which achieves superior performances to state-of-the-art\nmethods. Our code is available at\n\\href{https://github.com/FranklinLingfeng/code-for-SALCR}.", "AI": {"tldr": "The paper proposes SALCR, a framework for unsupervised visible-infrared person re-identification, addressing cross-modality variations by aligning fine-grained patterns and refining pseudo-labels collaboratively.", "motivation": "Existing methods overlook cross-modality variations in feature representation and pseudo-label distributions, leading to insufficient modality-shared learning.", "method": "SALCR includes DAGI for bi-directional pseudo-label unification, FGSAL for part-level semantic alignment, and GPCR for dynamic refinement of noisy pseudo-labels.", "result": "The method outperforms state-of-the-art approaches in experiments.", "conclusion": "SALCR effectively addresses cross-modality variations and noisy pseudo-labels, achieving superior performance in unsupervised VI-ReID."}}
{"id": "2504.19002", "pdf": "https://arxiv.org/pdf/2504.19002", "abs": "https://arxiv.org/abs/2504.19002", "authors": ["Delun Lai", "Yeyubei Zhang", "Yunchong Liu", "Chaojie Li", "Huadong Mo"], "title": "Deep Learning-Based Multi-Modal Fusion for Robust Robot Perception and Navigation", "categories": ["cs.LG", "cs.CV", "cs.RO"], "comment": "6 pages, 4 figures", "summary": "This paper introduces a novel deep learning-based multimodal fusion\narchitecture aimed at enhancing the perception capabilities of autonomous\nnavigation robots in complex environments. By utilizing innovative feature\nextraction modules, adaptive fusion strategies, and time-series modeling\nmechanisms, the system effectively integrates RGB images and LiDAR data. The\nkey contributions of this work are as follows: a. the design of a lightweight\nfeature extraction network to enhance feature representation; b. the\ndevelopment of an adaptive weighted cross-modal fusion strategy to improve\nsystem robustness; and c. the incorporation of time-series information modeling\nto boost dynamic scene perception accuracy. Experimental results on the KITTI\ndataset demonstrate that the proposed approach increases navigation and\npositioning accuracy by 3.5% and 2.2%, respectively, while maintaining\nreal-time performance. This work provides a novel solution for autonomous robot\nnavigation in complex environments.", "AI": {"tldr": "A deep learning-based multimodal fusion architecture improves autonomous robot navigation by integrating RGB and LiDAR data, achieving higher accuracy and real-time performance.", "motivation": "Enhancing perception capabilities of autonomous robots in complex environments by effectively fusing multimodal data.", "method": "Uses lightweight feature extraction, adaptive weighted cross-modal fusion, and time-series modeling to integrate RGB and LiDAR data.", "result": "Increases navigation and positioning accuracy by 3.5% and 2.2% on the KITTI dataset while maintaining real-time performance.", "conclusion": "Provides a novel solution for autonomous robot navigation in complex environments."}}
{"id": "2504.18575", "pdf": "https://arxiv.org/pdf/2504.18575", "abs": "https://arxiv.org/abs/2504.18575", "authors": ["Ivan Evtimov", "Arman Zharmagambetov", "Aaron Grattafiori", "Chuan Guo", "Kamalika Chaudhuri"], "title": "WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Web navigation AI agents use language-and-vision foundation models to enhance\nproductivity but these models are known to be susceptible to indirect prompt\ninjections that get them to follow instructions different from the legitimate\nuser's. Existing explorations of this threat applied to web agents often focus\non a single isolated adversarial goal, test with injected instructions that are\neither too easy or not truly malicious, and often give the adversary\nunreasonable access. In order to better focus adversarial research, we\nconstruct a new benchmark called WASP (Web Agent Security against Prompt\ninjection attacks) that introduces realistic web agent hijacking objectives and\nan isolated environment to test them in that does not affect real users or the\nlive web. As part of WASP, we also develop baseline attacks against three\npopular web agentic systems (VisualWebArena, Claude Computer Use, and Operator)\ninstantiated with various state-of-the-art models. Our evaluation shows that\neven AI agents backed by models with advanced reasoning capabilities and by\nmodels with instruction hierarchy mitigations are susceptible to low-effort\nhuman-written prompt injections. However, the realistic objectives in WASP also\nallow us to observe that agents are currently not capable enough to complete\nthe goals of attackers end-to-end. Agents begin executing the adversarial\ninstruction between 16 and 86% of the time but only achieve the goal between 0\nand 17% of the time. Based on these findings, we argue that adversarial\nresearchers should demonstrate stronger attacks that more consistently maintain\ncontrol over the agent given realistic constraints on the adversary's power.", "AI": {"tldr": "The paper introduces WASP, a benchmark for testing web AI agents' vulnerability to realistic prompt injection attacks, showing current models are susceptible but often fail to fully achieve adversarial goals.", "motivation": "To address gaps in existing research on prompt injection attacks against web AI agents, which often lack realism or adversarial rigor.", "method": "Developed the WASP benchmark with realistic hijacking objectives and tested baseline attacks on three web agent systems using state-of-the-art models.", "result": "Agents executed adversarial instructions 16-86% of the time but achieved the full goal only 0-17% of the time, highlighting partial vulnerability.", "conclusion": "Adversarial research should focus on stronger attacks under realistic constraints, as current agents are vulnerable but not fully controllable."}}
{"id": "2504.19467", "pdf": "https://arxiv.org/pdf/2504.19467", "abs": "https://arxiv.org/abs/2504.19467", "authors": ["Jiageng Wu", "Bowen Gu", "Ren Zhou", "Kevin Xie", "Doug Snyder", "Yixing Jiang", "Valentina Carducci", "Richard Wyss", "Rishi J Desai", "Emily Alsentzer", "Leo Anthony Celi", "Adam Rodman", "Sebastian Schneeweiss", "Jonathan H. Chen", "Santiago Romero-Brufau", "Kueiyu Joshua Lin", "Jie Yang"], "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, current evaluations of LLMs in clinical contexts remain limited. Most\nexisting benchmarks rely on medical exam-style questions or PubMed-derived\ntext, failing to capture the complexity of real-world electronic health record\n(EHR) data. Others focus narrowly on specific application scenarios, limiting\ntheir generalizability across broader clinical use. To address this gap, we\npresent BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks\nsourced from real-world clinical data sources across nine languages. We\nsystematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,\nGPT-4o, Gemini, and Llama 4) under various inference strategies. With a total\nof 13,572 experiments, our results reveal substantial performance variation\nacross model sizes, languages, natural language processing tasks, and clinical\nspecialties. Notably, we demonstrate that open-source LLMs can achieve\nperformance comparable to proprietary models, while medically fine-tuned LLMs\nbased on older architectures often underperform versus updated general-purpose\nmodels. The BRIDGE and its corresponding leaderboard serve as a foundational\nresource and a unique reference for the development and evaluation of new LLMs\nin real-world clinical text understanding.", "AI": {"tldr": "BRIDGE is a multilingual benchmark for evaluating LLMs in clinical contexts, revealing performance variations and showing open-source models can match proprietary ones.", "motivation": "Current evaluations of LLMs in clinical settings are limited, relying on narrow benchmarks that don't reflect real-world EHR complexity.", "method": "BRIDGE includes 87 tasks from real-world clinical data across nine languages, evaluating 52 LLMs with 13,572 experiments.", "result": "Performance varies by model size, language, task, and specialty; open-source models can rival proprietary ones, while older medically fine-tuned models underperform.", "conclusion": "BRIDGE provides a foundational resource for developing and evaluating LLMs in clinical text understanding."}}
{"id": "2504.19249", "pdf": "https://arxiv.org/pdf/2504.19249", "abs": "https://arxiv.org/abs/2504.19249", "authors": ["Loc Phuc Truong Nguyen", "Hung Truong Thanh Nguyen", "Hung Cao"], "title": "ODExAI: A Comprehensive Object Detection Explainable AI Evaluation", "categories": ["cs.CV"], "comment": null, "summary": "Explainable Artificial Intelligence (XAI) techniques for interpreting object\ndetection models remain in an early stage, with no established standards for\nsystematic evaluation. This absence of consensus hinders both the comparative\nanalysis of methods and the informed selection of suitable approaches. To\naddress this gap, we introduce the Object Detection Explainable AI Evaluation\n(ODExAI), a comprehensive framework designed to assess XAI methods in object\ndetection based on three core dimensions: localization accuracy, faithfulness\nto model behavior, and computational complexity. We benchmark a set of XAI\nmethods across two widely used object detectors (YOLOX and Faster R-CNN) and\nstandard datasets (MS-COCO and PASCAL VOC). Empirical results demonstrate that\nregion-based methods (e.g., D-CLOSE) achieve strong localization (PG = 88.49%)\nand high model faithfulness (OA = 0.863), though with substantial computational\noverhead (Time = 71.42s). On the other hand, CAM-based methods (e.g., G-CAME)\nachieve superior localization (PG = 96.13%) and significantly lower runtime\n(Time = 0.54s), but at the expense of reduced faithfulness (OA = 0.549). These\nfindings demonstrate critical trade-offs among existing XAI approaches and\nreinforce the need for task-specific evaluation when deploying them in object\ndetection pipelines. Our implementation and evaluation benchmarks are publicly\navailable at: https://github.com/Analytics-Everywhere-Lab/odexai.", "AI": {"tldr": "The paper introduces ODExAI, a framework to evaluate XAI methods for object detection, highlighting trade-offs between localization, faithfulness, and computational complexity.", "motivation": "The lack of standards for evaluating XAI in object detection hinders method comparison and selection.", "method": "ODExAI evaluates XAI methods on three dimensions: localization accuracy, faithfulness, and computational complexity, tested on YOLOX, Faster R-CNN, MS-COCO, and PASCAL VOC.", "result": "Region-based methods excel in faithfulness but are slow; CAM-based methods are fast but less faithful.", "conclusion": "Task-specific evaluation is crucial for deploying XAI in object detection, with ODExAI providing a benchmark."}}
{"id": "2504.19013", "pdf": "https://arxiv.org/pdf/2504.19013", "abs": "https://arxiv.org/abs/2504.19013", "authors": ["J\u00falia Vicens Figueres", "Juliette Vanderhaeghen", "Federica Bragone", "Kateryna Morozovska", "Khemraj Shukla"], "title": "\\$PINN -- a Domain Decomposition Method for Bayesian Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI", "math.AP"], "comment": "37 pages, 22 figures", "summary": "Physics-Informed Neural Networks (PINNs) are a novel computational approach\nfor solving partial differential equations (PDEs) with noisy and sparse initial\nand boundary data. Although, efficient quantification of epistemic and\naleatoric uncertainties in big multi-scale problems remains challenging. We\npropose \\$PINN a novel method of computing global uncertainty in PDEs using a\nBayesian framework, by combining local Bayesian Physics-Informed Neural\nNetworks (BPINN) with domain decomposition. The solution continuity across\nsubdomains is obtained by imposing the flux continuity across the interface of\nneighboring subdomains. To demonstrate the effectiveness of \\$PINN, we conduct\na series of computational experiments on PDEs in 1D and 2D spatial domains.\nAlthough we have adopted conservative PINNs (cPINNs), the method can be\nseamlessly extended to other domain decomposition techniques. The results infer\nthat the proposed method recovers the global uncertainty by computing the local\nuncertainty exactly more efficiently as the uncertainty in each subdomain can\nbe computed concurrently. The robustness of \\$PINN is verified by adding\nuncorrelated random noise to the training data up to 15% and testing for\ndifferent domain sizes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.18596", "pdf": "https://arxiv.org/pdf/2504.18596", "abs": "https://arxiv.org/abs/2504.18596", "authors": ["Anantha Sharma", "Swetha Devabhaktuni", "Eklove Mohan"], "title": "Optimizing the Privacy-Utility Balance using Synthetic Data and Configurable Perturbation Pipelines", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "math.PR"], "comment": "18 pages, 8 figures, 5 tables", "summary": "This paper explores the strategic use of modern synthetic data generation and\nadvanced data perturbation techniques to enhance security, maintain analytical\nutility, and improve operational efficiency when managing large datasets, with\na particular focus on the Banking, Financial Services, and Insurance (BFSI)\nsector. We contrast these advanced methods encompassing generative models like\nGANs, sophisticated context-aware PII transformation, configurable statistical\nperturbation, and differential privacy with traditional anonymization\napproaches.\n  The goal is to create realistic, privacy-preserving datasets that retain high\nutility for complex machine learning tasks and analytics, a critical need in\nthe data-sensitive industries like BFSI, Healthcare, Retail, and\nTelecommunications. We discuss how these modern techniques potentially offer\nsignificant improvements in balancing privacy preservation while maintaining\ndata utility compared to older methods. Furthermore, we examine the potential\nfor operational gains, such as reduced overhead and accelerated analytics, by\nusing these privacy-enhanced datasets. We also explore key use cases where\nthese methods can mitigate regulatory risks and enable scalable, data-driven\ninnovation without compromising sensitive customer information.", "AI": {"tldr": "The paper discusses modern synthetic data generation and perturbation techniques to enhance security and utility in large datasets, focusing on BFSI and other data-sensitive industries.", "motivation": "The need for privacy-preserving datasets that retain high utility for machine learning and analytics in industries like BFSI, Healthcare, Retail, and Telecommunications.", "method": "Advanced methods like GANs, context-aware PII transformation, statistical perturbation, and differential privacy are compared to traditional anonymization.", "result": "These techniques improve privacy-utility balance, reduce overhead, and accelerate analytics while mitigating regulatory risks.", "conclusion": "Modern synthetic data methods enable scalable, data-driven innovation without compromising sensitive information."}}
{"id": "2504.19472", "pdf": "https://arxiv.org/pdf/2504.19472", "abs": "https://arxiv.org/abs/2504.19472", "authors": ["Siyi Liu", "Dan Roth"], "title": "Conflicts in Texts: Data, Implications and Challenges", "categories": ["cs.CL"], "comment": null, "summary": "As NLP models become increasingly integrated into real-world applications, it\nbecomes clear that there is a need to address the fact that models often rely\non and generate conflicting information. Conflicts could reflect the complexity\nof situations, changes that need to be explained and dealt with, difficulties\nin data annotation, and mistakes in generated outputs. In all cases,\ndisregarding the conflicts in data could result in undesired behaviors of\nmodels and undermine NLP models' reliability and trustworthiness. This survey\ncategorizes these conflicts into three key areas: (1) natural texts on the web,\nwhere factual inconsistencies, subjective biases, and multiple perspectives\nintroduce contradictions; (2) human-annotated data, where annotator\ndisagreements, mistakes, and societal biases impact model training; and (3)\nmodel interactions, where hallucinations and knowledge conflicts emerge during\ndeployment. While prior work has addressed some of these conflicts in\nisolation, we unify them under the broader concept of conflicting information,\nanalyze their implications, and discuss mitigation strategies. We highlight key\nchallenges and future directions for developing conflict-aware NLP systems that\ncan reason over and reconcile conflicting information more effectively.", "AI": {"tldr": "The paper surveys conflicts in NLP models, categorizing them into natural texts, human-annotated data, and model interactions, and discusses mitigation strategies.", "motivation": "Addressing conflicts in NLP models is crucial to improve reliability and trustworthiness, as ignoring them leads to undesired behaviors.", "method": "Categorizes conflicts into three areas: natural texts, human-annotated data, and model interactions, analyzing their implications.", "result": "Identifies key challenges and proposes mitigation strategies for conflict-aware NLP systems.", "conclusion": "Highlights the need for future work to develop systems that effectively reason over and reconcile conflicting information."}}
{"id": "2504.19256", "pdf": "https://arxiv.org/pdf/2504.19256", "abs": "https://arxiv.org/abs/2504.19256", "authors": ["Songsong Xiong", "Hamidreza Kasaei"], "title": "LM-MCVT: A Lightweight Multi-modal Multi-view Convolutional-Vision Transformer Approach for 3D Object Recognition", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "In human-centered environments such as restaurants, homes, and warehouses,\nrobots often face challenges in accurately recognizing 3D objects. These\nchallenges stem from the complexity and variability of these environments,\nincluding diverse object shapes. In this paper, we propose a novel Lightweight\nMulti-modal Multi-view Convolutional-Vision Transformer network (LM-MCVT) to\nenhance 3D object recognition in robotic applications. Our approach leverages\nthe Globally Entropy-based Embeddings Fusion (GEEF) method to integrate\nmulti-views efficiently. The LM-MCVT architecture incorporates pre- and\nmid-level convolutional encoders and local and global transformers to enhance\nfeature extraction and recognition accuracy. We evaluate our method on the\nsynthetic ModelNet40 dataset and achieve a recognition accuracy of 95.6% using\na four-view setup, surpassing existing state-of-the-art methods. To further\nvalidate its effectiveness, we conduct 5-fold cross-validation on the\nreal-world OmniObject3D dataset using the same configuration. Results\nconsistently show superior performance, demonstrating the method's robustness\nin 3D object recognition across synthetic and real-world 3D data.", "AI": {"tldr": "A novel LM-MCVT network is proposed for 3D object recognition in robotics, achieving 95.6% accuracy on ModelNet40 and robust performance on real-world data.", "motivation": "Robots struggle with 3D object recognition in complex human-centered environments due to diverse object shapes and variability.", "method": "The LM-MCVT network uses GEEF for multi-view fusion, combining convolutional encoders and transformers for feature extraction.", "result": "Achieves 95.6% accuracy on ModelNet40 and superior performance on OmniObject3D via 5-fold cross-validation.", "conclusion": "LM-MCVT is robust and outperforms state-of-the-art methods in 3D object recognition for both synthetic and real-world data."}}
{"id": "2504.19014", "pdf": "https://arxiv.org/pdf/2504.19014", "abs": "https://arxiv.org/abs/2504.19014", "authors": ["Sushant Vijayan"], "title": "Towards minimax optimal algorithms for Active Simple Hypothesis Testing", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study the Active Simple Hypothesis Testing (ASHT) problem, a simpler\nvariant of the Fixed Budget Best Arm Identification problem. In this work, we\nprovide novel game theoretic formulation of the upper bounds of the ASHT\nproblem. This formulation allows us to leverage tools of differential games and\nPartial Differential Equations (PDEs) to propose an approximately optimal\nalgorithm that is computationally tractable compared to prior work. However,\nthe optimal algorithm still suffers from a curse of dimensionality and instead\nwe use a novel link to Blackwell Approachability to propose an algorithm that\nis far more efficient computationally. We show that this new algorithm,\nalthough not proven to be optimal, is always better than static algorithms in\nall instances of ASHT and is numerically observed to attain the optimal\nexponent in various instances.", "AI": {"tldr": "The paper introduces a game-theoretic approach to the Active Simple Hypothesis Testing (ASHT) problem, proposing computationally efficient algorithms that outperform static methods.", "motivation": "To address the computational challenges and dimensionality issues in prior work on ASHT, leveraging game theory and PDEs for better bounds and algorithms.", "method": "Uses differential games and PDEs for theoretical bounds, then links to Blackwell Approachability for a more efficient algorithm.", "result": "The proposed algorithm is computationally tractable, outperforms static methods, and often achieves optimal performance.", "conclusion": "The new algorithm, while not proven optimal, is a significant improvement over existing methods in ASHT."}}
{"id": "2504.18598", "pdf": "https://arxiv.org/pdf/2504.18598", "abs": "https://arxiv.org/abs/2504.18598", "authors": ["Qingyue Wang", "Qi Pang", "Xixun Lin", "Shuai Wang", "Daoyuan Wu"], "title": "BadMoE: Backdooring Mixture-of-Experts LLMs via Optimizing Routing Triggers and Infecting Dormant Experts", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) have emerged as a powerful architecture for\n  large language models (LLMs), enabling efficient scaling of model capacity\n  while maintaining manageable computational costs. The key advantage lies in\n  their ability to route different tokens to different ``expert'' networks\n  within the model, enabling specialization and efficient handling of diverse\n  input. However, the vulnerabilities of MoE-based LLMs still have barely been\n  studied, and the potential for backdoor attacks in this context remains\n  largely unexplored. This paper presents the first backdoor attack against\n  MoE-based LLMs where the attackers poison ``dormant experts'' (i.e.,\nunderutilized\n  experts) and activate them by optimizing routing triggers, thereby gaining\n  control over the model's output. We first rigorously prove the existence of a\nfew ``dominating\n  experts'' in MoE models, whose outputs can determine the overall MoE's\n  output. We also show that dormant experts can serve as dominating experts to\nmanipulate model predictions.\n  Accordingly, our attack, namely \\textsc{BadMoE}, exploits the unique\n  architecture of MoE models by 1) identifying dormant experts unrelated to the\ntarget task, 2)\n  constructing a routing-aware loss to optimize the activation triggers of\nthese experts, and 3) promoting dormant experts to dominating roles via\npoisoned training data.", "AI": {"tldr": "The paper introduces \textsc{BadMoE}, the first backdoor attack targeting Mixture-of-Experts (MoE) LLMs, exploiting dormant experts to manipulate model outputs.", "motivation": "Despite MoE's efficiency in scaling LLMs, its vulnerabilities, especially to backdoor attacks, remain understudied. This work explores this gap.", "method": "The attack involves identifying dormant experts, optimizing routing triggers, and poisoning training data to elevate these experts to dominating roles.", "result": "The study proves the existence of dominating experts in MoE models and demonstrates how dormant experts can be exploited to control model outputs.", "conclusion": "\textsc{BadMoE} highlights critical security risks in MoE-based LLMs, urging further research into their vulnerabilities."}}
{"id": "2504.19556", "pdf": "https://arxiv.org/pdf/2504.19556", "abs": "https://arxiv.org/abs/2504.19556", "authors": ["Kristen Sussman", "Daniel Carter"], "title": "Detecting Effects of AI-Mediated Communication on Language Complexity and Sentiment", "categories": ["cs.CL", "cs.HC", "J.4; K.4.0; I.2.7"], "comment": "5 pages, 3 figures, Companion Proceedings of the ACM Web Conference\n  2025", "summary": "Given the subtle human-like effects of large language models on linguistic\npatterns, this study examines shifts in language over time to detect the impact\nof AI-mediated communication (AI- MC) on social media. We compare a replicated\ndataset of 970,919 tweets from 2020 (pre-ChatGPT) with 20,000 tweets from the\nsame period in 2024, all of which mention Donald Trump during election periods.\nUsing a combination of Flesch-Kincaid readability and polarity scores, we\nanalyze changes in text complexity and sentiment. Our findings reveal a\nsignificant increase in mean sentiment polarity (0.12 vs. 0.04) and a shift\nfrom predominantly neutral content (54.8% in 2020 to 39.8% in 2024) to more\npositive expressions (28.6% to 45.9%). These findings suggest not only an\nincreasing presence of AI in social media communication but also its impact on\nlanguage and emotional expression patterns.", "AI": {"tldr": "Study analyzes AI's impact on social media language, showing increased positivity and sentiment in tweets about Donald Trump post-ChatGPT.", "motivation": "To detect the influence of AI-mediated communication (AI-MC) on linguistic patterns and emotional expression in social media.", "method": "Compared 970,919 tweets from 2020 (pre-ChatGPT) with 20,000 tweets from 2024, analyzing changes in readability (Flesch-Kincaid) and sentiment (polarity scores).", "result": "Significant increase in mean sentiment polarity (0.12 vs. 0.04) and a shift from neutral to more positive expressions (28.6% to 45.9%).", "conclusion": "AI's presence in social media is growing, influencing language complexity and emotional expression patterns."}}
{"id": "2504.19258", "pdf": "https://arxiv.org/pdf/2504.19258", "abs": "https://arxiv.org/abs/2504.19258", "authors": ["Shuhao Kang", "Martin Y. Liao", "Yan Xia", "Olaf Wysocki", "Boris Jutzi", "Daniel Cremers"], "title": "OPAL: Visibility-aware LiDAR-to-OpenStreetMap Place Recognition via Adaptive Radial Fusion", "categories": ["cs.CV", "cs.RO"], "comment": "Technical report. 15 pages, 9 figures", "summary": "LiDAR place recognition is a critical capability for autonomous navigation\nand cross-modal localization in large-scale outdoor environments. Existing\napproaches predominantly depend on pre-built 3D dense maps or aerial imagery,\nwhich impose significant storage overhead and lack real-time adaptability. In\nthis paper, we propose OPAL, a novel network for LiDAR place recognition that\nleverages OpenStreetMap as a lightweight and up-to-date prior. Our key\ninnovation lies in bridging the domain disparity between sparse LiDAR scans and\nstructured OSM data through two carefully designed components: a cross-modal\nvisibility mask that identifies maximal observable regions from both modalities\nto guide feature learning, and an adaptive radial fusion module that\ndynamically consolidates multiscale radial features into discriminative global\ndescriptors. Extensive experiments on the augmented KITTI and KITTI-360\ndatasets demonstrate OPAL's superiority, achieving 15.98% higher recall at @1m\nthreshold for top-1 retrieved matches while operating at 12x faster inference\nspeeds compared to state-of-the-art approaches. Code and datasets are publicly\navailable at: https://github.com/WHU-USI3DV/OPAL .", "AI": {"tldr": "OPAL is a novel LiDAR place recognition network using OpenStreetMap as a lightweight prior, outperforming existing methods in recall and speed.", "motivation": "Existing methods rely on dense maps or aerial imagery, which are storage-heavy and lack real-time adaptability.", "method": "OPAL bridges LiDAR and OSM data using a cross-modal visibility mask and adaptive radial fusion module.", "result": "Achieves 15.98% higher recall at @1m threshold and 12x faster inference speeds than state-of-the-art methods.", "conclusion": "OPAL offers an efficient, scalable solution for LiDAR place recognition with superior performance."}}
{"id": "2504.19026", "pdf": "https://arxiv.org/pdf/2504.19026", "abs": "https://arxiv.org/abs/2504.19026", "authors": ["Stanislav Semenov"], "title": "Smooth Approximations of the Rounding Function", "categories": ["cs.LG", "math.OC", "03F60, 26E40", "F.4.1; F.1.1"], "comment": "9 pages, 1 figure, submitted to arXiv", "summary": "We propose novel smooth approximations to the classical rounding function,\nsuitable for differentiable optimization and machine learning applications. Our\nconstructions are based on two approaches: (1) localized sigmoid window\nfunctions centered at each integer, and (2) normalized weighted sums of sigmoid\nderivatives representing local densities. The first method approximates the\nstep-like behavior of rounding through differences of shifted sigmoids, while\nthe second method achieves smooth interpolation between integers via\ndensity-based weighting. Both methods converge pointwise to the classical\nrounding function as the sharpness parameter k tends to infinity, and allow\ncontrolled trade-offs between smoothness and approximation accuracy. We\ndemonstrate that by restricting the summation to a small set of nearest\nintegers, the computational cost remains low without sacrificing precision.\nThese constructions provide fully differentiable alternatives to hard rounding,\nwhich are valuable in contexts where gradient-based methods are essential.", "AI": {"tldr": "Novel smooth approximations to the classical rounding function for differentiable optimization and ML, using sigmoid-based methods with controlled trade-offs between smoothness and accuracy.", "motivation": "To enable gradient-based optimization in applications requiring rounding, by providing differentiable alternatives to hard rounding.", "method": "Two approaches: (1) localized sigmoid window functions centered at integers, and (2) normalized weighted sums of sigmoid derivatives for density-based interpolation. Both converge to classical rounding as sharpness increases.", "result": "Methods achieve smooth interpolation with low computational cost, maintaining precision while being fully differentiable.", "conclusion": "These approximations are valuable for gradient-based optimization, offering controlled smoothness and accuracy trade-offs."}}
{"id": "2504.18601", "pdf": "https://arxiv.org/pdf/2504.18601", "abs": "https://arxiv.org/abs/2504.18601", "authors": ["Philipp Koralus"], "title": "The Philosophic Turn for AI Agents: Replacing centralized digital rhetoric with decentralized truth-seeking", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "In the face of rapidly advancing AI technology, individuals will increasingly\nrely on AI agents to navigate life's growing complexities, raising critical\nconcerns about maintaining both human agency and autonomy. This paper addresses\na fundamental dilemma posed by AI decision-support systems: the risk of either\nbecoming overwhelmed by complex decisions, thus losing agency, or having\nautonomy compromised by externally controlled choice architectures reminiscent\nof ``nudging'' practices. While the ``nudge'' framework, based on the use of\nchoice-framing to guide individuals toward presumed beneficial outcomes,\ninitially appeared to preserve liberty, at AI-driven scale, it threatens to\nerode autonomy. To counteract this risk, the paper proposes a philosophic turn\nin AI design. AI should be constructed to facilitate decentralized\ntruth-seeking and open-ended inquiry, mirroring the Socratic method of\nphilosophical dialogue. By promoting individual and collective adaptive\nlearning, such AI systems would empower users to maintain control over their\njudgments, augmenting their agency without undermining autonomy. The paper\nconcludes by outlining essential features for autonomy-preserving AI systems,\nsketching a path toward AI systems that enhance human judgment rather than\nundermine it.", "AI": {"tldr": "The paper explores the risks of AI decision-support systems compromising human agency and autonomy, proposing a Socratic-method-inspired AI design to preserve autonomy while enhancing judgment.", "motivation": "Address the dilemma of AI systems either overwhelming users or compromising their autonomy, inspired by concerns about AI-driven nudging.", "method": "Proposes a philosophic approach to AI design, emphasizing decentralized truth-seeking and open-ended inquiry akin to the Socratic method.", "result": "AI systems designed this way could empower users to maintain control over judgments, enhancing agency without undermining autonomy.", "conclusion": "Outlines features for autonomy-preserving AI systems, advocating for designs that enhance human judgment rather than erode it."}}
{"id": "2504.19565", "pdf": "https://arxiv.org/pdf/2504.19565", "abs": "https://arxiv.org/abs/2504.19565", "authors": ["Meng Xiao", "Xunxin Cai", "Chengrui Wang", "Yuanchun Zhou"], "title": "m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training", "categories": ["cs.CL", "cs.AI", "q-bio.QM"], "comment": "22 pages, Large Language Model, Agentic AI, Dataset Distillation,\n  Multi-agent Collaboration", "summary": "The rapid progress of large language models (LLMs) in biomedical research has\nunderscored the limitations of existing open-source annotated scientific\ncorpora, which are often insufficient in quantity and quality. Addressing the\nchallenge posed by the complex hierarchy of biomedical knowledge, we propose a\nknowledge-driven, multi-agent framework for scientific corpus distillation\ntailored for LLM training in the biomedical domain. Central to our approach is\na collaborative multi-agent architecture, where specialized agents, each guided\nby the Medical Subject Headings (MeSH) hierarchy, work in concert to\nautonomously extract, synthesize, and self-evaluate high-quality textual data\nfrom vast scientific literature. These agents collectively generate and refine\ndomain-specific question-answer pairs, ensuring comprehensive coverage and\nconsistency with biomedical ontologies while minimizing manual involvement.\nExtensive experimental results show that language models trained on our\nmulti-agent distilled datasets achieve notable improvements in biomedical\nquestion-answering tasks, outperforming both strong life sciences LLM baselines\nand advanced proprietary models. Notably, our AI-Ready dataset enables\nLlama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger\nscale. Detailed ablation studies and case analyses further validate the\neffectiveness and synergy of each agent within the framework, highlighting the\npotential of multi-agent collaboration in biomedical LLM training.", "AI": {"tldr": "A multi-agent framework for distilling high-quality biomedical corpora improves LLM performance, surpassing proprietary models like GPT-4.", "motivation": "Existing biomedical corpora are limited in quality and quantity, hindering LLM training in the domain.", "method": "A knowledge-driven, multi-agent framework guided by MeSH hierarchy autonomously extracts and refines biomedical QA pairs.", "result": "LLMs trained on the distilled datasets outperform baselines and proprietary models, including GPT-4.", "conclusion": "Multi-agent collaboration effectively enhances biomedical LLM training, demonstrating significant performance gains."}}
{"id": "2504.19261", "pdf": "https://arxiv.org/pdf/2504.19261", "abs": "https://arxiv.org/abs/2504.19261", "authors": ["Xiaofeng Jin", "Yan Fang", "Matteo Frosi", "Jianfei Ge", "Jiangjian Xiao", "Matteo Matteucci"], "title": "Rendering Anywhere You See: Renderability Field-guided Gaussian Splatting", "categories": ["cs.CV", "65D18, 68U05", "I.3.7; I.4.8"], "comment": "8 pages,8 figures", "summary": "Scene view synthesis, which generates novel views from limited perspectives,\nis increasingly vital for applications like virtual reality, augmented reality,\nand robotics. Unlike object-based tasks, such as generating 360{\\deg} views of\na car, scene view synthesis handles entire environments where non-uniform\nobservations pose unique challenges for stable rendering quality. To address\nthis issue, we propose a novel approach: renderability field-guided gaussian\nsplatting (RF-GS). This method quantifies input inhomogeneity through a\nrenderability field, guiding pseudo-view sampling to enhanced visual\nconsistency. To ensure the quality of wide-baseline pseudo-views, we train an\nimage restoration model to map point projections to visible-light styles.\nAdditionally, our validated hybrid data optimization strategy effectively fuses\ninformation of pseudo-view angles and source view textures. Comparative\nexperiments on simulated and real-world data show that our method outperforms\nexisting approaches in rendering stability.", "AI": {"tldr": "The paper introduces RF-GS, a method for scene view synthesis that improves rendering stability by using a renderability field and pseudo-view sampling, outperforming existing approaches.", "motivation": "Scene view synthesis is crucial for VR, AR, and robotics, but non-uniform observations in environments challenge rendering quality.", "method": "RF-GS uses a renderability field to guide pseudo-view sampling, trains an image restoration model for wide-baseline views, and employs hybrid data optimization.", "result": "The method outperforms existing approaches in rendering stability on both simulated and real-world data.", "conclusion": "RF-GS effectively addresses inhomogeneity in scene view synthesis, enhancing visual consistency and rendering quality."}}
{"id": "2504.19034", "pdf": "https://arxiv.org/pdf/2504.19034", "abs": "https://arxiv.org/abs/2504.19034", "authors": ["Samantha Petti", "Carlos Mart\u00ed-G\u00f3mez", "Justin B. Kinney", "Juannan Zhou", "David M. McCandlish"], "title": "On learning functions over biological sequence space: relating Gaussian process priors, regularization, and gauge fixing", "categories": ["cs.LG", "q-bio.GN", "stat.ML"], "comment": null, "summary": "Mappings from biological sequences (DNA, RNA, protein) to quantitative\nmeasures of sequence functionality play an important role in contemporary\nbiology. We are interested in the related tasks of (i) inferring predictive\nsequence-to-function maps and (ii) decomposing sequence-function maps to\nelucidate the contributions of individual subsequences. Because each\nsequence-function map can be written as a weighted sum over subsequences in\nmultiple ways, meaningfully interpreting these weights requires \"gauge-fixing,\"\ni.e., defining a unique representation for each map. Recent work has\nestablished that most existing gauge-fixed representations arise as the unique\nsolutions to $L_2$-regularized regression in an overparameterized \"weight\nspace\" where the choice of regularizer defines the gauge. Here, we establish\nthe relationship between regularized regression in overparameterized weight\nspace and Gaussian process approaches that operate in \"function space,\" i.e.\nthe space of all real-valued functions on a finite set of sequences. We\ndisentangle how weight space regularizers both impose an implicit prior on the\nlearned function and restrict the optimal weights to a particular gauge. We\nalso show how to construct regularizers that correspond to arbitrary explicit\nGaussian process priors combined with a wide variety of gauges. Next, we derive\nthe distribution of gauge-fixed weights implied by the Gaussian process\nposterior and demonstrate that even for long sequences this distribution can be\nefficiently computed for product-kernel priors using a kernel trick. Finally,\nwe characterize the implicit function space priors associated with the most\ncommon weight space regularizers. Overall, our framework unifies and extends\nour ability to infer and interpret sequence-function relationships.", "AI": {"tldr": "The paper unifies Gaussian process approaches with regularized regression for sequence-function mapping, enabling better inference and interpretation of biological sequence functionality.", "motivation": "To improve the inference and interpretation of sequence-function maps in biology by addressing gauge-fixing and unifying methods.", "method": "Links regularized regression in overparameterized weight space to Gaussian process approaches in function space, and derives weight distributions for efficient computation.", "result": "Shows how to construct regularizers for arbitrary Gaussian process priors and gauges, and efficiently computes weight distributions for long sequences.", "conclusion": "The framework enhances the ability to infer and interpret sequence-function relationships, unifying and extending existing methods."}}
{"id": "2504.18636", "pdf": "https://arxiv.org/pdf/2504.18636", "abs": "https://arxiv.org/abs/2504.18636", "authors": ["Lohith Srikanth Pentapalli", "Jon Salisbury", "Josette Riep", "Kelly Cohen"], "title": "A Gradient-Optimized TSK Fuzzy Framework for Explainable Phishing Detection", "categories": ["cs.CR", "cs.AI", "cs.LO"], "comment": "14 pages, 5 figures", "summary": "Phishing attacks represent an increasingly sophisticated and pervasive threat\nto individuals and organizations, causing significant financial losses,\nidentity theft, and severe damage to institutional reputations. Existing\nphishing detection methods often struggle to simultaneously achieve high\naccuracy and explainability, either failing to detect novel attacks or\noperating as opaque black-box models. To address this critical gap, we propose\na novel phishing URL detection system based on a first-order Takagi-Sugeno-Kang\n(TSK) fuzzy inference model optimized through gradient-based techniques. Our\napproach intelligently combines the interpretability and human-like reasoning\ncapabilities of fuzzy logic with the precision and adaptability provided by\ngradient optimization methods, specifically leveraging the Adam optimizer for\nefficient parameter tuning. Experiments conducted using a comprehensive dataset\nof over 235,000 URLs demonstrate rapid convergence, exceptional predictive\nperformance (accuracy averaging 99.95% across 5 cross-validation folds, with a\nperfect AUC i.e. 1.00). Furthermore, optimized fuzzy rules and membership\nfunctions improve interoperability, clearly indicating how the model makes\ndecisions - an essential feature for cybersecurity applications. This\nhigh-performance, transparent, and interpretable phishing detection framework\nsignificantly advances current cybersecurity defenses, providing practitioners\nwith accurate and explainable decision-making tools.", "AI": {"tldr": "A novel phishing URL detection system using a TSK fuzzy inference model achieves high accuracy (99.95%) and explainability, addressing gaps in current methods.", "motivation": "Phishing attacks are a growing threat, but existing detection methods lack both accuracy and explainability.", "method": "Proposes a first-order TSK fuzzy inference model optimized with gradient-based techniques (Adam optimizer) for phishing URL detection.", "result": "Achieves 99.95% accuracy and perfect AUC (1.00) on a dataset of 235,000 URLs, with interpretable fuzzy rules.", "conclusion": "The framework offers a high-performance, transparent, and interpretable solution for phishing detection, advancing cybersecurity defenses."}}
{"id": "2504.19590", "pdf": "https://arxiv.org/pdf/2504.19590", "abs": "https://arxiv.org/abs/2504.19590", "authors": ["Israa Alsiyat"], "title": "Arabic Metaphor Sentiment Classification Using Semantic Information", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this paper, I discuss the testing of the Arabic Metaphor Corpus (AMC) [1]\nusing newly designed automatic tools for sentiment classification for AMC based\non semantic tags. The tool incorporates semantic emotional tags for sentiment\nclassification. I evaluate the tool using standard methods, which are F-score,\nrecall, and precision. The method is to show the impact of Arabic online\nmetaphors on sentiment through the newly designed tools. To the best of our\nknowledge, this is the first approach to conduct sentiment classification for\nArabic metaphors using semantic tags to find the impact of the metaphor.", "AI": {"tldr": "The paper tests the Arabic Metaphor Corpus (AMC) using new automatic tools for sentiment classification based on semantic tags, evaluating performance with F-score, recall, and precision.", "motivation": "To explore the impact of Arabic online metaphors on sentiment using semantic tags, a novel approach in the field.", "method": "Designs automatic tools incorporating semantic emotional tags for sentiment classification of AMC, evaluated with standard metrics.", "result": "The tool's performance is assessed using F-score, recall, and precision, though specific results are not detailed in the abstract.", "conclusion": "This is the first approach to sentiment classification for Arabic metaphors using semantic tags, highlighting its novelty and potential impact."}}
{"id": "2504.19266", "pdf": "https://arxiv.org/pdf/2504.19266", "abs": "https://arxiv.org/abs/2504.19266", "authors": ["Xiaofeng Jin", "Matteo Frosi", "Matteo Matteucci"], "title": "OpenFusion++: An Open-vocabulary Real-time Scene Understanding System", "categories": ["cs.CV", "68T45, 68U05", "I.2.10; I.4.8"], "comment": "8 pages, 9 figures", "summary": "Real-time open-vocabulary scene understanding is essential for efficient 3D\nperception in applications such as vision-language navigation, embodied\nintelligence, and augmented reality. However, existing methods suffer from\nimprecise instance segmentation, static semantic updates, and limited handling\nof complex queries. To address these issues, we present OpenFusion++, a\nTSDF-based real-time 3D semantic-geometric reconstruction system. Our approach\nrefines 3D point clouds by fusing confidence maps from foundational models,\ndynamically updates global semantic labels via an adaptive cache based on\ninstance area, and employs a dual-path encoding framework that integrates\nobject attributes with environmental context for precise query responses.\nExperiments on the ICL, Replica, ScanNet, and ScanNet++ datasets demonstrate\nthat OpenFusion++ significantly outperforms the baseline in both semantic\naccuracy and query responsiveness.", "AI": {"tldr": "OpenFusion++ improves real-time 3D scene understanding by refining point clouds, dynamically updating semantics, and enhancing query handling, outperforming baselines.", "motivation": "Addressing imprecise instance segmentation, static semantic updates, and limited query handling in real-time 3D perception.", "method": "TSDF-based system fusing confidence maps, adaptive semantic cache, and dual-path encoding for object-environment integration.", "result": "Outperforms baselines in semantic accuracy and query responsiveness on ICL, Replica, ScanNet, and ScanNet++.", "conclusion": "OpenFusion++ advances real-time 3D semantic-geometric reconstruction for applications like embodied intelligence and AR."}}
{"id": "2504.19036", "pdf": "https://arxiv.org/pdf/2504.19036", "abs": "https://arxiv.org/abs/2504.19036", "authors": ["Henry Herzog", "Joshua Hansen", "Yawen Zhang", "Patrick Beukema"], "title": "Atlantes: A system of GPS transformers for global-scale real-time maritime intelligence", "categories": ["cs.LG"], "comment": "8 pages, 10 figures, ICLR CCAI 2025, spotlight talk", "summary": "Unsustainable exploitation of the oceans exacerbated by global warming is\nthreatening coastal communities worldwide. Accurate and timely monitoring of\nmaritime activity is an essential step to effective governance and to inform\nfuture policy. In support of this complex global-scale effort, we built\nAtlantes, a deep learning based system that provides the first-ever real-time\nview of vessel behavior at global scale. Atlantes leverages a series of bespoke\ntransformers to distill a high volume, continuous stream of GPS messages\nemitted by hundreds of thousands of vessels into easily quantifiable behaviors.\nThe combination of low latency and high performance enables operationally\nrelevant decision-making and successful interventions on the high seas where\nillegal and exploitative activity is too common. Atlantes is already in use by\nhundreds of organizations worldwide. Here we provide an overview of the model\nand infrastructure that enables this system to function efficiently and\ncost-effectively at global-scale and in real-time.", "AI": {"tldr": "Atlantes is a deep learning system for real-time global vessel monitoring to combat unsustainable ocean exploitation.", "motivation": "Unsustainable ocean exploitation and global warming threaten coastal communities, necessitating accurate maritime monitoring.", "method": "Atlantes uses bespoke transformers to process GPS data from vessels into quantifiable behaviors for real-time analysis.", "result": "The system enables low-latency, high-performance decision-making and interventions against illegal maritime activities.", "conclusion": "Atlantes is operational globally, aiding hundreds of organizations in effective maritime governance."}}
{"id": "2504.18658", "pdf": "https://arxiv.org/pdf/2504.18658", "abs": "https://arxiv.org/abs/2504.18658", "authors": ["Siddharth Singh", "Mahua Singh", "Abhinav Bhatele"], "title": "The Big Send-off: High Performance Collectives on GPU-based Supercomputers", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "We evaluate the current state of collective communication on GPU-based\nsupercomputers for large language model (LLM) training at scale. Existing\nlibraries such as RCCL and Cray-MPICH exhibit critical limitations on systems\nsuch as Frontier -- Cray-MPICH underutilizes network and compute resources,\nwhile RCCL suffers from severe scalability issues. To address these challenges,\nwe introduce PCCL, a communication library with highly optimized\nimplementations of all-gather and reduce-scatter operations tailored for\ndistributed deep learning workloads. PCCL is designed to maximally utilize all\navailable network and compute resources and to scale efficiently to thousands\nof GPUs. It achieves substantial performance improvements, delivering 6-33x\nspeedups over RCCL and 28-70x over Cray-MPICH for all-gather on 2048 GCDs of\nFrontier. These gains translate directly to end-to-end performance: in\nlarge-scale GPT-3-style training, PCCL provides up to 60% and 40% speedups over\nRCCL for 7B and 13B parameter models, respectively.", "AI": {"tldr": "PCCL, a new communication library, outperforms RCCL and Cray-MPICH in GPU-based supercomputers for LLM training, achieving significant speedups in all-gather and reduce-scatter operations.", "motivation": "Existing libraries like RCCL and Cray-MPICH underutilize resources or face scalability issues, limiting performance in large-scale LLM training.", "method": "PCCL is introduced with optimized all-gather and reduce-scatter operations, designed to maximize network and compute resource utilization and scalability.", "result": "PCCL delivers 6-33x speedups over RCCL and 28-70x over Cray-MPICH for all-gather on 2048 GCDs, improving GPT-3-style training by up to 60%.", "conclusion": "PCCL effectively addresses the limitations of existing libraries, offering superior performance and scalability for distributed deep learning workloads."}}
{"id": "2504.19606", "pdf": "https://arxiv.org/pdf/2504.19606", "abs": "https://arxiv.org/abs/2504.19606", "authors": ["Hieu-Dai Tran", "Duc-Vu Nguyen", "Ngan Luu-Thuy Nguyen"], "title": "Coreference Resolution for Vietnamese Narrative Texts", "categories": ["cs.CL"], "comment": "Accepted at PACLIC 2024", "summary": "Coreference resolution is a vital task in natural language processing (NLP)\nthat involves identifying and linking different expressions in a text that\nrefer to the same entity. This task is particularly challenging for Vietnamese,\na low-resource language with limited annotated datasets. To address these\nchallenges, we developed a comprehensive annotated dataset using narrative\ntexts from VnExpress, a widely-read Vietnamese online news platform. We\nestablished detailed guidelines for annotating entities, focusing on ensuring\nconsistency and accuracy. Additionally, we evaluated the performance of large\nlanguage models (LLMs), specifically GPT-3.5-Turbo and GPT-4, on this dataset.\nOur results demonstrate that GPT-4 significantly outperforms GPT-3.5-Turbo in\nterms of both accuracy and response consistency, making it a more reliable tool\nfor coreference resolution in Vietnamese.", "AI": {"tldr": "The paper introduces a Vietnamese coreference resolution dataset from VnExpress and evaluates GPT-3.5-Turbo and GPT-4, finding GPT-4 superior.", "motivation": "Addressing the lack of annotated datasets for coreference resolution in Vietnamese, a low-resource language.", "method": "Developed a dataset using VnExpress texts with detailed annotation guidelines and evaluated GPT-3.5-Turbo and GPT-4.", "result": "GPT-4 outperformed GPT-3.5-Turbo in accuracy and consistency for Vietnamese coreference resolution.", "conclusion": "GPT-4 is more reliable for Vietnamese coreference resolution, highlighting the value of high-quality datasets."}}
{"id": "2504.19270", "pdf": "https://arxiv.org/pdf/2504.19270", "abs": "https://arxiv.org/abs/2504.19270", "authors": ["Chamin Hewa Koneputugodage", "Yizhak Ben-Shabat", "Sameera Ramasinghe", "Stephen Gould"], "title": "VI3NR: Variance Informed Initialization for Implicit Neural Representations", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "Implicit Neural Representations (INRs) are a versatile and powerful tool for\nencoding various forms of data, including images, videos, sound, and 3D shapes.\nA critical factor in the success of INRs is the initialization of the network,\nwhich can significantly impact the convergence and accuracy of the learned\nmodel. Unfortunately, commonly used neural network initializations are not\nwidely applicable for many activation functions, especially those used by INRs.\nIn this paper, we improve upon previous initialization methods by deriving an\ninitialization that has stable variance across layers, and applies to any\nactivation function. We show that this generalizes many previous initialization\nmethods, and has even better stability for well studied activations. We also\nshow that our initialization leads to improved results with INR activation\nfunctions in multiple signal modalities. Our approach is particularly effective\nfor Gaussian INRs, where we demonstrate that the theory of our initialization\nmatches with task performance in multiple experiments, allowing us to achieve\nimprovements in image, audio, and 3D surface reconstruction.", "AI": {"tldr": "The paper introduces a stable initialization method for Implicit Neural Representations (INRs) that works with any activation function, improving convergence and accuracy across various data modalities.", "motivation": "Common neural network initializations are not suitable for many activation functions used in INRs, limiting their effectiveness. The paper aims to address this gap.", "method": "The authors derive a new initialization method ensuring stable variance across layers, applicable to any activation function, and generalize previous methods.", "result": "The proposed initialization improves stability and performance for INR activation functions, particularly in Gaussian INRs, enhancing tasks like image, audio, and 3D reconstruction.", "conclusion": "The new initialization method is versatile, outperforms prior approaches, and is validated across multiple signal modalities."}}
{"id": "2504.19040", "pdf": "https://arxiv.org/pdf/2504.19040", "abs": "https://arxiv.org/abs/2504.19040", "authors": ["Nandan Joshi", "Erhan Guven"], "title": "Improved Molecular Generation through Attribute-Driven Integrative Embeddings and GAN Selectivity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The growing demand for molecules with tailored properties in fields such as\ndrug discovery and chemical engineering has driven advancements in\ncomputational methods for molecular design. Machine learning-based approaches\nfor de-novo molecular generation have recently garnered significant attention.\nThis paper introduces a transformer-based vector embedding generator combined\nwith a modified Generative Adversarial Network (GAN) to generate molecules with\ndesired properties. The embedding generator utilizes a novel molecular\ndescriptor, integrating Morgan fingerprints with global molecular attributes,\nenabling the transformer to capture local functional groups and broader\nmolecular characteristics. Modifying the GAN generator loss function ensures\nthe generation of molecules with specific desired properties. The transformer\nachieves a reconversion accuracy of 94% while translating molecular descriptors\nback to SMILES strings, validating the utility of the proposed embeddings for\ngenerative tasks. The approach is validated by generating novel odorant\nmolecules using a labeled dataset of odorant and non-odorant compounds. With\nthe modified range-loss function, the GAN exclusively generates odorant\nmolecules. This work underscores the potential of combining novel vector\nembeddings with transformers and modified GAN architectures to accelerate the\ndiscovery of tailored molecules, offering a robust tool for diverse molecular\ndesign applications.", "AI": {"tldr": "A transformer-based vector embedding generator and modified GAN are introduced for generating molecules with desired properties, validated by creating novel odorant molecules.", "motivation": "The demand for tailored molecules in fields like drug discovery and chemical engineering drives the need for advanced computational methods.", "method": "Combines a transformer-based embedding generator (using Morgan fingerprints and global attributes) with a modified GAN (adjusted loss function for specific properties).", "result": "Achieves 94% reconversion accuracy and successfully generates odorant molecules exclusively.", "conclusion": "The approach demonstrates the potential of combining novel embeddings and modified GANs for efficient molecular design."}}
{"id": "2504.18662", "pdf": "https://arxiv.org/pdf/2504.18662", "abs": "https://arxiv.org/abs/2504.18662", "authors": ["Daniel Sliwowski", "Dongheui Lee"], "title": "M2R2: MulitModal Robotic Representation for Temporal Action Segmentation", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 6 figures, 2 tables", "summary": "Temporal action segmentation (TAS) has long been a key area of research in\nboth robotics and computer vision. In robotics, algorithms have primarily\nfocused on leveraging proprioceptive information to determine skill boundaries,\nwith recent approaches in surgical robotics incorporating vision. In contrast,\ncomputer vision typically relies on exteroceptive sensors, such as cameras.\nExisting multimodal TAS models in robotics integrate feature fusion within the\nmodel, making it difficult to reuse learned features across different models.\nMeanwhile, pretrained vision-only feature extractors commonly used in computer\nvision struggle in scenarios with limited object visibility. In this work, we\naddress these challenges by proposing M2R2, a multimodal feature extractor\ntailored for TAS, which combines information from both proprioceptive and\nexteroceptive sensors. We introduce a novel pretraining strategy that enables\nthe reuse of learned features across multiple TAS models. Our method achieves\nstate-of-the-art performance on the REASSEMBLE dataset, a challenging\nmultimodal robotic assembly dataset, outperforming existing robotic action\nsegmentation models by 46.6%. Additionally, we conduct an extensive ablation\nstudy to evaluate the contribution of different modalities in robotic TAS\ntasks.", "AI": {"tldr": "The paper proposes M2R2, a multimodal feature extractor for Temporal Action Segmentation (TAS), combining proprioceptive and exteroceptive sensor data to address limitations in existing methods.", "motivation": "Existing TAS models in robotics struggle with feature reuse, while vision-only models fail in low-visibility scenarios. M2R2 aims to bridge this gap.", "method": "Introduces M2R2, a multimodal feature extractor with a novel pretraining strategy for feature reuse across models.", "result": "Achieves state-of-the-art performance on the REASSEMBLE dataset, outperforming existing models by 46.6%.", "conclusion": "M2R2 effectively combines multimodal data for TAS, enabling feature reuse and superior performance in robotic tasks."}}
{"id": "2504.19627", "pdf": "https://arxiv.org/pdf/2504.19627", "abs": "https://arxiv.org/abs/2504.19627", "authors": ["Run Luo", "Renke Shan", "Longze Chen", "Ziqiang Liu", "Lu Wang", "Min Yang", "Xiaobo Xia"], "title": "VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "VCM", "summary": "Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks like\nembodied intelligence due to their strong vision-language reasoning abilities.\nHowever, current LVLMs process entire images at the token level, which is\ninefficient compared to humans who analyze information and generate content at\nthe conceptual level, extracting relevant visual concepts with minimal effort.\nThis inefficiency, stemming from the lack of a visual concept model, limits\nLVLMs' usability in real-world applications. To address this, we propose VCM,\nan end-to-end self-supervised visual concept modeling framework. VCM leverages\nimplicit contrastive learning across multiple sampled instances and\nvision-language fine-tuning to construct a visual concept model without\nrequiring costly concept-level annotations. Our results show that VCM\nsignificantly reduces computational costs (e.g., 85\\% fewer FLOPs for\nLLaVA-1.5-7B) while maintaining strong performance across diverse image\nunderstanding tasks. Moreover, VCM enhances visual encoders' capabilities in\nclassic visual concept perception tasks. Extensive quantitative and qualitative\nexperiments validate the effectiveness and efficiency of VCM.", "AI": {"tldr": "VCM is a self-supervised visual concept modeling framework that improves efficiency and performance of LVLMs by reducing computational costs and enhancing visual concept perception.", "motivation": "Current LVLMs process images inefficiently at the token level, unlike humans who analyze at the conceptual level, limiting real-world usability.", "method": "VCM uses implicit contrastive learning and vision-language fine-tuning to build a visual concept model without costly annotations.", "result": "VCM reduces computational costs (e.g., 85% fewer FLOPs) while maintaining performance and improving visual concept perception.", "conclusion": "VCM is effective and efficient, validated by extensive experiments, enhancing LVLMs for real-world applications."}}
{"id": "2504.19271", "pdf": "https://arxiv.org/pdf/2504.19271", "abs": "https://arxiv.org/abs/2504.19271", "authors": ["Athul M. Mathew", "Arshad Ali Khan", "Thariq Khalid", "Faroq AL-Tam", "Riad Souissi"], "title": "Leveraging Multi-Modal Saliency and Fusion for Gaze Target Detection", "categories": ["cs.CV"], "comment": "accepted at NeurIPS 2023 Gaze Meets ML Workshop", "summary": "Gaze target detection (GTD) is the task of predicting where a person in an\nimage is looking. This is a challenging task, as it requires the ability to\nunderstand the relationship between the person's head, body, and eyes, as well\nas the surrounding environment. In this paper, we propose a novel method for\nGTD that fuses multiple pieces of information extracted from an image. First,\nwe project the 2D image into a 3D representation using monocular depth\nestimation. We then extract a depth-infused saliency module map, which\nhighlights the most salient (\\textit{attention-grabbing}) regions in image for\nthe subject in consideration. We also extract face and depth modalities from\nthe image, and finally fuse all the extracted modalities to identify the gaze\ntarget. We quantitatively evaluated our method, including the ablation analysis\non three publicly available datasets, namely VideoAttentionTarget, GazeFollow\nand GOO-Real, and showed that it outperforms other state-of-the-art methods.\nThis suggests that our method is a promising new approach for GTD.", "AI": {"tldr": "A novel method for gaze target detection (GTD) fuses 3D depth, saliency, and face modalities to outperform state-of-the-art methods on three datasets.", "motivation": "GTD is challenging due to the need to understand relationships between head, body, eyes, and environment.", "method": "Projects 2D images into 3D using depth estimation, extracts depth-infused saliency maps, and fuses face and depth modalities for gaze target prediction.", "result": "Outperforms state-of-the-art methods on VideoAttentionTarget, GazeFollow, and GOO-Real datasets.", "conclusion": "The proposed method is a promising new approach for GTD."}}
{"id": "2504.19084", "pdf": "https://arxiv.org/pdf/2504.19084", "abs": "https://arxiv.org/abs/2504.19084", "authors": ["Elliot L. Epstein", "Rajat Dwaraknath", "Thanawat Sornwanee", "John Winnicki", "Jerry Weihong Liu"], "title": "Score-Debiased Kernel Density Estimation", "categories": ["cs.LG", "stat.ML"], "comment": "ICLR 2025 Workshop on Frontiers of Probabilistic Inference", "summary": "We propose a novel method for density estimation that leverages an estimated\nscore function to debias kernel density estimation (SD-KDE). In our approach,\neach data point is adjusted by taking a single step along the score function\nwith a specific choice of step size, followed by standard KDE with a modified\nbandwidth. The step size and modified bandwidth are chosen to remove the\nleading order bias in the KDE. Our experiments on synthetic tasks in 1D, 2D and\non MNIST, demonstrate that our proposed SD-KDE method significantly reduces the\nmean integrated squared error compared to the standard Silverman KDE, even with\nnoisy estimates in the score function. These results underscore the potential\nof integrating score-based corrections into nonparametric density estimation.", "AI": {"tldr": "A novel method (SD-KDE) improves density estimation by debiasing kernel density estimation using an estimated score function, reducing error significantly.", "motivation": "To enhance the accuracy of kernel density estimation by addressing its leading order bias through score-based corrections.", "method": "Adjusts data points with a score function step, modifies bandwidth, and applies standard KDE to debias estimation.", "result": "SD-KDE reduces mean integrated squared error significantly compared to standard Silverman KDE, even with noisy score estimates.", "conclusion": "Score-based corrections can effectively improve nonparametric density estimation."}}
{"id": "2504.18691", "pdf": "https://arxiv.org/pdf/2504.18691", "abs": "https://arxiv.org/abs/2504.18691", "authors": ["Ali Alfageeh", "Sadegh AlMahdi Kazemi Zarkouei", "Daye Nam", "Daniel Prol", "Matin Amoozadeh", "Souti Chattopadhyay", "James Prather", "Paul Denny", "Juho Leinonen", "Michael Hilton", "Sruti Srinivasa Ragavan", "Mohammad Amin Alipour"], "title": "From Prompts to Propositions: A Logic-Based Lens on Student-LLM Interactions", "categories": ["cs.HC", "cs.AI", "cs.SE"], "comment": null, "summary": "Background and Context. The increasing integration of large language models\n(LLMs) in computing education presents an emerging challenge in understanding\nhow students use LLMs and craft prompts to solve computational tasks. Prior\nresearch has used both qualitative and quantitative methods to analyze\nprompting behavior, but these approaches lack scalability or fail to\neffectively capture the semantic evolution of prompts. Objective. In this\npaper, we investigate whether students prompts can be systematically analyzed\nusing propositional logic constraints. We examine whether this approach can\nidentify patterns in prompt evolution, detect struggling students, and provide\ninsights into effective and ineffective strategies. Method. We introduce\nPrompt2Constraints, a novel method that translates students prompts into\nlogical constraints. The constraints are able to represent the intent of the\nprompts in succinct and quantifiable ways. We used this approach to analyze a\ndataset of 1,872 prompts from 203 students solving introductory programming\ntasks. Findings. We find that while successful and unsuccessful attempts tend\nto use a similar number of constraints overall, when students fail, they often\nmodify their prompts more significantly, shifting problem-solving strategies\nmidway. We also identify points where specific interventions could be most\nhelpful to students for refining their prompts. Implications. This work offers\na new and scalable way to detect students who struggle in solving natural\nlanguage programming tasks. This work could be extended to investigate more\ncomplex tasks and integrated into programming tools to provide real-time\nsupport.", "AI": {"tldr": "The paper introduces Prompt2Constraints, a method to analyze student prompts in LLM-based computing education using propositional logic, revealing patterns in prompt evolution and identifying struggling students.", "motivation": "To address the lack of scalable methods for analyzing how students use LLMs and craft prompts in computing education.", "method": "Prompt2Constraints translates student prompts into logical constraints to quantify intent and analyze patterns in a dataset of 1,872 prompts from 203 students.", "result": "Successful and unsuccessful attempts use similar constraint counts, but struggling students modify prompts more significantly, shifting strategies. Specific intervention points are identified.", "conclusion": "The method offers a scalable way to detect struggling students and could be extended for complex tasks or integrated into tools for real-time support."}}
{"id": "2504.19645", "pdf": "https://arxiv.org/pdf/2504.19645", "abs": "https://arxiv.org/abs/2504.19645", "authors": ["Shadan Shukr Sabr", "Nazira Sabr Mustafa", "Talar Sabah Omar", "Salah Hwayyiz Rasool", "Nawzad Anwer Omer", "Darya Sabir Hamad", "Hemin Abdulhameed Shams", "Omer Mahmood Kareem", "Rozhan Noori Abdullah", "Khabat Atar Abdullah", "Mahabad Azad Mohammad", "Haneen Al-Raghefy", "Safar M. Asaad", "Sara Jamal Mohammed", "Twana Saeed Ali", "Fazil Shawrow", "Halgurd S. Maghdid"], "title": "A Comprehensive Part-of-Speech Tagging to Standardize Central-Kurdish Language: A Research Guide for Kurdish Natural Language Processing Tasks", "categories": ["cs.CL", "cs.AI", "K.5; K.7; J.7"], "comment": "25 pages, 4 figures, 2 tables", "summary": "- The field of natural language processing (NLP) has dramatically expanded\nwithin the last decade. Many human-being applications are conducted daily via\nNLP tasks, starting from machine translation, speech recognition, text\ngeneration and recommendations, Part-of-Speech tagging (POS), and Named-Entity\nRecognition (NER). However, low-resourced languages, such as the\nCentral-Kurdish language (CKL), mainly remain unexamined due to shortage of\nnecessary resources to support their development. The POS tagging task is the\nbase of other NLP tasks; for example, the POS tag set has been used to\nstandardized languages to provide the relationship between words among the\nsentences, followed by machine translation and text recommendation.\nSpecifically, for the CKL, most of the utilized or provided POS tagsets are\nneither standardized nor comprehensive. To this end, this study presented an\naccurate and comprehensive POS tagset for the CKL to provide better performance\nof the Kurdish NLP tasks. The article also collected most of the POS tags from\ndifferent studies as well as from Kurdish linguistic experts to standardized\npart-of-speech tags. The proposed POS tagset is designed to annotate a large\nCKL corpus and support Kurdish NLP tasks. The initial investigations of this\nstudy via comparison with the Universal Dependencies framework for standard\nlanguages, show that the proposed POS tagset can streamline or correct\nsentences more accurately for Kurdish NLP tasks.", "AI": {"tldr": "The paper introduces a standardized and comprehensive POS tagset for the Central-Kurdish language (CKL) to enhance NLP tasks, addressing the lack of resources for low-resourced languages.", "motivation": "Low-resourced languages like CKL lack standardized POS tagsets, hindering NLP task performance. This study aims to fill this gap.", "method": "The study collected POS tags from existing studies and Kurdish linguistic experts to create a standardized tagset, validated against the Universal Dependencies framework.", "result": "The proposed POS tagset improves accuracy and standardization for Kurdish NLP tasks, as shown by initial comparisons.", "conclusion": "The standardized POS tagset for CKL supports better NLP task performance and corrects sentences more accurately."}}
{"id": "2504.19279", "pdf": "https://arxiv.org/pdf/2504.19279", "abs": "https://arxiv.org/abs/2504.19279", "authors": ["Vita V. Vlasova", "Vladimir G. Kuzmin", "Maria S. Varetsa", "Natalia A. Ibragimova", "Oleg Y. Rogov", "Elena V. Lyapuntsova"], "title": "Optimal Hyperspectral Undersampling Strategy for Satellite Imaging", "categories": ["cs.CV"], "comment": "16 pages", "summary": "Hyperspectral image (HSI) classification presents significant challenges due\nto the high dimensionality, spectral redundancy, and limited labeled data\ntypically available in real-world applications. To address these issues and\noptimize classification performance, we propose a novel band selection strategy\nknown as Iterative Wavelet-based Gradient Sampling (IWGS). This method\nincrementally selects the most informative spectral bands by analyzing\ngradients within the wavelet-transformed domain, enabling efficient and\ntargeted dimensionality reduction. Unlike traditional selection methods, IWGS\nleverages the multi-resolution properties of wavelets to better capture subtle\nspectral variations relevant for classification. The iterative nature of the\napproach ensures that redundant or noisy bands are systematically excluded\nwhile maximizing the retention of discriminative features. We conduct\ncomprehensive experiments on two widely-used benchmark HSI datasets: Houston\n2013 and Indian Pines. Results demonstrate that IWGS consistently outperforms\nstate-of-the-art band selection and classification techniques in terms of both\naccuracy and computational efficiency. These improvements make our method\nespecially suitable for deployment in edge devices or other\nresource-constrained environments, where memory and processing power are\nlimited. In particular, IWGS achieved an overall accuracy up to 97.8% on Indian\nPines for selected classes, confirming its effectiveness and generalizability\nacross different HSI scenarios.", "AI": {"tldr": "A novel band selection method, IWGS, is proposed for HSI classification, outperforming state-of-the-art techniques in accuracy and efficiency.", "motivation": "Address challenges of high dimensionality, spectral redundancy, and limited labeled data in HSI classification.", "method": "Iterative Wavelet-based Gradient Sampling (IWGS) selects informative bands via wavelet-transformed gradient analysis.", "result": "Achieves up to 97.8% accuracy on benchmark datasets, outperforming existing methods.", "conclusion": "IWGS is effective, efficient, and suitable for resource-constrained environments."}}
{"id": "2504.19103", "pdf": "https://arxiv.org/pdf/2504.19103", "abs": "https://arxiv.org/abs/2504.19103", "authors": ["Shunxin Guo", "Jiaqi Lv", "Xin Geng"], "title": "Harmonizing Generalization and Personalization in Ring-topology Decentralized Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "We introduce Ring-topology Decentralized Federated Learning (RDFL) for\ndistributed model training, aiming to avoid the inherent risks of centralized\nfailure in server-based FL. However, RDFL faces the challenge of low\ninformation-sharing efficiency due to the point-to-point communication manner\nwhen handling inherent data heterogeneity. Existing studies to mitigate data\nheterogeneity focus on personalized optimization of models, ignoring that the\nlack of shared information constraints can lead to large differences among\nmodels, weakening the benefits of collaborative learning. To tackle these\nchallenges, we propose a Divide-and-conquer RDFL framework (DRDFL) that uses a\nfeature generation model to extract personalized information and invariant\nshared knowledge from the underlying data distribution, ensuring both effective\npersonalization and strong generalization. Specifically, we design a\n\\textit{PersonaNet} module that encourages class-specific feature\nrepresentations to follow a Gaussian mixture distribution, facilitating the\nlearning of discriminative latent representations tailored to local data\ndistributions. Meanwhile, the \\textit{Learngene} module is introduced to\nencapsulate shared knowledge through an adversarial classifier to align latent\nrepresentations and extract globally invariant information. Extensive\nexperiments demonstrate that DRDFL outperforms state-of-the-art methods in\nvarious data heterogeneity settings.", "AI": {"tldr": "DRDFL improves decentralized federated learning by addressing data heterogeneity with personalized and shared knowledge extraction, outperforming existing methods.", "motivation": "To avoid centralized failure risks in federated learning and tackle low information-sharing efficiency in ring-topology decentralized FL due to data heterogeneity.", "method": "Proposes DRDFL with PersonaNet for personalized feature learning and Learngene for shared knowledge extraction, using adversarial classifiers.", "result": "DRDFL outperforms state-of-the-art methods in diverse data heterogeneity settings.", "conclusion": "DRDFL effectively balances personalization and generalization in decentralized federated learning."}}
{"id": "2504.18693", "pdf": "https://arxiv.org/pdf/2504.18693", "abs": "https://arxiv.org/abs/2504.18693", "authors": ["Sina Gogani-Khiabani", "Varsha Dewangan", "Nina Olson", "Ashutosh Trivedi", "Saeid Tizpaz-Niari"], "title": "Technical Challenges in Maintaining Tax Prep Software with Large Language Models", "categories": ["cs.SE", "cs.AI", "https://www.irs.gov/statistics/fourteenth-annual-irs-tpc-joint-research-conference-on-tax-administration"], "comment": "Accepted to 14th Annual IRS/TPC Joint Research Conference on Tax\n  Administration (IRS-TPC 2024)", "summary": "As the US tax law evolves to adapt to ever-changing politico-economic\nrealities, tax preparation software plays a significant role in helping\ntaxpayers navigate these complexities. The dynamic nature of tax regulations\nposes a significant challenge to accurately and timely maintaining tax software\nartifacts. The state-of-the-art in maintaining tax prep software is\ntime-consuming and error-prone as it involves manual code analysis combined\nwith an expert interpretation of tax law amendments. We posit that the rigor\nand formality of tax amendment language, as expressed in IRS publications,\nmakes it amenable to automatic translation to executable specifications (code).\nOur research efforts focus on identifying, understanding, and tackling\ntechnical challenges in leveraging Large Language Models (LLMs), such as\nChatGPT and Llama, to faithfully extract code differentials from IRS\npublications and automatically integrate them with the prior version of the\ncode to automate tax prep software maintenance.", "AI": {"tldr": "The paper explores using LLMs to automate tax software updates by translating IRS tax law amendments into executable code, addressing manual maintenance challenges.", "motivation": "The dynamic nature of tax laws makes manual tax software maintenance time-consuming and error-prone, necessitating automation.", "method": "Leveraging LLMs (e.g., ChatGPT, Llama) to extract and integrate code differentials from IRS publications into existing tax software.", "result": "Proposes a method to automate tax software updates by translating formal tax amendment language into code.", "conclusion": "Automating tax software maintenance via LLMs could significantly reduce errors and save time compared to manual methods."}}
{"id": "2504.19669", "pdf": "https://arxiv.org/pdf/2504.19669", "abs": "https://arxiv.org/abs/2504.19669", "authors": ["Chen Su", "Yuanhe Tian", "Yan Song"], "title": "Multimodal Conditioned Diffusive Time Series Forecasting", "categories": ["cs.CL"], "comment": null, "summary": "Diffusion models achieve remarkable success in processing images and text,\nand have been extended to special domains such as time series forecasting\n(TSF). Existing diffusion-based approaches for TSF primarily focus on modeling\nsingle-modality numerical sequences, overlooking the rich multimodal\ninformation in time series data. To effectively leverage such information for\nprediction, we propose a multimodal conditioned diffusion model for TSF,\nnamely, MCD-TSF, to jointly utilize timestamps and texts as extra guidance for\ntime series modeling, especially for forecasting. Specifically, Timestamps are\ncombined with time series to establish temporal and semantic correlations among\ndifferent data points when aggregating information along the temporal\ndimension. Texts serve as supplementary descriptions of time series' history,\nand adaptively aligned with data points as well as dynamically controlled in a\nclassifier-free manner. Extensive experiments on real-world benchmark datasets\nacross eight domains demonstrate that the proposed MCD-TSF model achieves\nstate-of-the-art performance.", "AI": {"tldr": "MCD-TSF is a multimodal diffusion model for time series forecasting that leverages timestamps and text for improved performance.", "motivation": "Existing diffusion models for time series forecasting ignore multimodal information, limiting their potential.", "method": "MCD-TSF integrates timestamps and text as guidance, using temporal-semantic correlations and adaptive text alignment.", "result": "Achieves state-of-the-art performance on real-world datasets across eight domains.", "conclusion": "MCD-TSF effectively utilizes multimodal data for superior time series forecasting."}}
{"id": "2504.19289", "pdf": "https://arxiv.org/pdf/2504.19289", "abs": "https://arxiv.org/abs/2504.19289", "authors": ["Alexandra Malyugina", "Guoxi Huang", "Eduardo Ruiz", "Benjamin Leslie", "Nantheera Anantrasirichai"], "title": "Marine Snow Removal Using Internally Generated Pseudo Ground Truth", "categories": ["cs.CV"], "comment": null, "summary": "Underwater videos often suffer from degraded quality due to light absorption,\nscattering, and various noise sources. Among these, marine snow, which is\nsuspended organic particles appearing as bright spots or noise, significantly\nimpacts machine vision tasks, particularly those involving feature matching.\nExisting methods for removing marine snow are ineffective due to the lack of\npaired training data. To address this challenge, this paper proposes a novel\nenhancement framework that introduces a new approach for generating paired\ndatasets from raw underwater videos. The resulting dataset consists of paired\nimages of generated snowy and snow, free underwater videos, enabling supervised\ntraining for video enhancement. We describe the dataset creation process,\nhighlight its key characteristics, and demonstrate its effectiveness in\nenhancing underwater image restoration in the absence of ground truth.", "AI": {"tldr": "Proposes a framework for generating paired datasets to train models for removing marine snow from underwater videos, improving restoration without ground truth.", "motivation": "Underwater videos suffer from degraded quality due to marine snow, and existing methods lack paired training data.", "method": "Introduces a novel approach to create paired datasets (snowy and snow-free) from raw underwater videos for supervised training.", "result": "Demonstrates effectiveness in enhancing underwater image restoration without ground truth.", "conclusion": "The proposed framework addresses the lack of paired data, improving marine snow removal in underwater videos."}}
{"id": "2504.19139", "pdf": "https://arxiv.org/pdf/2504.19139", "abs": "https://arxiv.org/abs/2504.19139", "authors": ["Yun Qu", "Qi", "Wang", "Yixiu Mao", "Yiqin Lv", "Xiangyang Ji"], "title": "Fast and Robust: Task Sampling with Posterior and Diversity Synergies for Adaptive Decision-Makers in Randomized Environments", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Task robust adaptation is a long-standing pursuit in sequential\ndecision-making. Some risk-averse strategies, e.g., the conditional\nvalue-at-risk principle, are incorporated in domain randomization or meta\nreinforcement learning to prioritize difficult tasks in optimization, which\ndemand costly intensive evaluations. The efficiency issue prompts the\ndevelopment of robust active task sampling to train adaptive policies, where\nrisk-predictive models are used to surrogate policy evaluation. This work\ncharacterizes the optimization pipeline of robust active task sampling as a\nMarkov decision process, posits theoretical and practical insights, and\nconstitutes robustness concepts in risk-averse scenarios. Importantly, we\npropose an easy-to-implement method, referred to as Posterior and Diversity\nSynergized Task Sampling (PDTS), to accommodate fast and robust sequential\ndecision-making. Extensive experiments show that PDTS unlocks the potential of\nrobust active task sampling, significantly improves the zero-shot and few-shot\nadaptation robustness in challenging tasks, and even accelerates the learning\nprocess under certain scenarios. Our project website is at\nhttps://thu-rllab.github.io/PDTS_project_page.", "AI": {"tldr": "The paper introduces PDTS, a method for robust active task sampling in sequential decision-making, improving adaptation robustness and learning efficiency.", "motivation": "Addressing the efficiency and robustness challenges in task adaptation, particularly in risk-averse scenarios requiring costly evaluations.", "method": "Proposes PDTS (Posterior and Diversity Synergized Task Sampling), a method integrating risk-predictive models and theoretical insights for robust task sampling.", "result": "PDTS enhances zero-shot and few-shot adaptation robustness and accelerates learning in challenging tasks.", "conclusion": "PDTS effectively improves robustness and efficiency in sequential decision-making, validated by extensive experiments."}}
{"id": "2504.18722", "pdf": "https://arxiv.org/pdf/2504.18722", "abs": "https://arxiv.org/abs/2504.18722", "authors": ["Aashutosh Nema", "Samaksh Gulati", "Evangelos Giakoumakis", "Bipana Thapaliya"], "title": "MODP: Multi Objective Directional Prompting", "categories": ["cs.CC", "cs.AI", "I.2.0; I.2.6; I.2.7; H.3.3"], "comment": "10 pages, 5 figures, submission to KDD 2025", "summary": "Recent advances in large language models (LLMs) have led to their popularity\nacross multiple use-cases. However, prompt engineering, the process for\noptimally utilizing such models, remains approximation-driven and subjective.\nMost of the current research on prompt engineering focuses on task-specific\noptimization, while neglecting the behavior of the LLM under consideration\nduring prompt development. This paper introduces MODP -- Multi Objective\nDirectional Prompting, a framework based on two key concepts: 1)\nmulti-objectivity: the importance of considering an LLM's intrinsic behavior as\nan additional objective in prompt development, and 2) directional prompting: a\nmetrics-driven method for prompt engineering to ensure development of robust\nand high-precision prompts. We demonstrate the effectiveness of our proposed\nideas on a summarization task, using a synthetically created dataset, achieving\na 26% performance gain over initial prompts. Finally, we apply MODP to develop\nprompts for Dell's Next Best Action support tool, which is now in production\nand is used by more than 10,000 internal support agents and serving millions of\ncustomers worldwide.", "AI": {"tldr": "MODP is a framework for prompt engineering that considers LLM behavior and uses directional prompting, achieving a 26% performance gain in summarization tasks.", "motivation": "Current prompt engineering lacks consideration of LLM behavior and is task-specific, leading to suboptimal results.", "method": "MODP introduces multi-objectivity (LLM behavior as an objective) and directional prompting (metrics-driven approach).", "result": "Achieved a 26% performance gain in summarization and successfully deployed in Dell's support tool.", "conclusion": "MODP improves prompt engineering by integrating LLM behavior and metrics, proving effective in real-world applications."}}
{"id": "2504.19675", "pdf": "https://arxiv.org/pdf/2504.19675", "abs": "https://arxiv.org/abs/2504.19675", "authors": ["Osma Suominen", "Juho Inkinen", "Mona Lehtinen"], "title": "Annif at SemEval-2025 Task 5: Traditional XMTC augmented by LLMs", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.IR", "cs.LG", "I.2.7"], "comment": "6 pages, 4 figures, submitted to SemEval-2025 workshop Task 5:\n  LLMs4Subjects", "summary": "This paper presents the Annif system in SemEval-2025 Task 5 (LLMs4Subjects),\nwhich focussed on subject indexing using large language models (LLMs). The task\nrequired creating subject predictions for bibliographic records from the\nbilingual TIBKAT database using the GND subject vocabulary. Our approach\ncombines traditional natural language processing and machine learning\ntechniques implemented in the Annif toolkit with innovative LLM-based methods\nfor translation and synthetic data generation, and merging predictions from\nmonolingual models. The system ranked first in the all-subjects category and\nsecond in the tib-core-subjects category in the quantitative evaluation, and\nfourth in qualitative evaluations. These findings demonstrate the potential of\ncombining traditional XMTC algorithms with modern LLM techniques to improve the\naccuracy and efficiency of subject indexing in multilingual contexts.", "AI": {"tldr": "Annif system combines traditional NLP/ML with LLM techniques for subject indexing, achieving top rankings in SemEval-2025 Task 5.", "motivation": "To improve subject indexing accuracy and efficiency in multilingual contexts using LLMs.", "method": "Combines traditional NLP/ML (Annif toolkit) with LLM-based translation, synthetic data generation, and merging monolingual predictions.", "result": "Ranked first in all-subjects, second in tib-core-subjects (quantitative), and fourth in qualitative evaluations.", "conclusion": "Combining traditional XMTC algorithms with LLM techniques enhances subject indexing performance."}}
{"id": "2504.19295", "pdf": "https://arxiv.org/pdf/2504.19295", "abs": "https://arxiv.org/abs/2504.19295", "authors": ["Kangbiao Shi", "Yixu Feng", "Tao Hu", "Yu Cao", "Peng Wu", "Yijin Liang", "Yanning Zhang", "Qingsen Yan"], "title": "FusionNet: Multi-model Linear Fusion Framework for Low-light Image Enhancement", "categories": ["cs.CV"], "comment": null, "summary": "The advent of Deep Neural Networks (DNNs) has driven remarkable progress in\nlow-light image enhancement (LLIE), with diverse architectures (e.g., CNNs and\nTransformers) and color spaces (e.g., sRGB, HSV, HVI) yielding impressive\nresults. Recent efforts have sought to leverage the complementary strengths of\nthese paradigms, offering promising solutions to enhance performance across\nvarying degradation scenarios. However, existing fusion strategies are hindered\nby challenges such as parameter explosion, optimization instability, and\nfeature misalignment, limiting further improvements. To overcome these issues,\nwe introduce FusionNet, a novel multi-model linear fusion framework that\noperates in parallel to effectively capture global and local features across\ndiverse color spaces. By incorporating a linear fusion strategy underpinned by\nHilbert space theoretical guarantees, FusionNet mitigates network collapse and\nreduces excessive training costs. Our method achieved 1st place in the CVPR2025\nNTIRE Low Light Enhancement Challenge. Extensive experiments conducted on\nsynthetic and real-world benchmark datasets demonstrate that the proposed\nmethod significantly outperforms state-of-the-art methods in terms of both\nquantitative and qualitative results, delivering robust enhancement under\ndiverse low-light conditions.", "AI": {"tldr": "FusionNet introduces a multi-model linear fusion framework for low-light image enhancement, addressing challenges like parameter explosion and feature misalignment, achieving top performance in benchmarks.", "motivation": "Existing fusion strategies for low-light image enhancement face issues like parameter explosion and optimization instability, limiting performance improvements.", "method": "FusionNet uses a parallel multi-model linear fusion framework with Hilbert space guarantees to capture global and local features across color spaces.", "result": "FusionNet outperforms state-of-the-art methods in benchmarks, winning the CVPR2025 NTIRE Low Light Enhancement Challenge.", "conclusion": "FusionNet provides a robust solution for low-light image enhancement, addressing key challenges and delivering superior performance."}}
{"id": "2504.19141", "pdf": "https://arxiv.org/pdf/2504.19141", "abs": "https://arxiv.org/abs/2504.19141", "authors": ["Panagiotis Kakosimos"], "title": "Reliable Thermal Monitoring of Electric Machines through Machine Learning", "categories": ["cs.LG"], "comment": "2023 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "The electrification of powertrains is rising as the objective for a more\nviable future is intensified. To ensure continuous and reliable operation\nwithout undesirable malfunctions, it is essential to monitor the internal\ntemperatures of machines and keep them within safe operating limits.\nConventional modeling methods can be complex and usually require expert\nknowledge. With the amount of data collected these days, it is possible to use\ninformation models to assess thermal behaviors. This paper investigates\nartificial intelligence techniques for monitoring the cooling efficiency of\ninduction machines. Experimental data was collected under specific operating\nconditions, and three machine-learning models have been developed. The optimal\nconfiguration for each approach was determined through rigorous hyperparameter\nsearches, and the models were evaluated using a variety of metrics. The three\nsolutions performed well in monitoring the condition of the machine even under\ntransient operation, highlighting the potential of data-driven methods in\nimproving the thermal management.", "AI": {"tldr": "The paper explores AI techniques for monitoring cooling efficiency in induction machines, using machine learning models trained on experimental data.", "motivation": "To improve thermal management in electrified powertrains by leveraging data-driven methods for temperature monitoring.", "method": "Collected experimental data under specific conditions, developed three machine-learning models, and optimized them via hyperparameter searches.", "result": "All three models performed well in monitoring machine conditions, even during transient operations.", "conclusion": "Data-driven methods show strong potential for enhancing thermal management in induction machines."}}
{"id": "2504.18727", "pdf": "https://arxiv.org/pdf/2504.18727", "abs": "https://arxiv.org/abs/2504.18727", "authors": ["Ali Rostami", "Z Xie", "A Ishino", "Y Yamakata", "K Aizawa", "Ramesh Jain"], "title": "World Food Atlas Project", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "A coronavirus pandemic is forcing people to be \"at home\" all over the world.\nIn a life of hardly ever going out, we would have realized how the food we eat\naffects our bodies. What can we do to know our food more and control it better?\nTo give us a clue, we are trying to build a World Food Atlas (WFA) that\ncollects all the knowledge about food in the world. In this paper, we present\ntwo of our trials. The first is the Food Knowledge Graph (FKG), which is a\ngraphical representation of knowledge about food and ingredient relationships\nderived from recipes and food nutrition data. The second is the FoodLog Athl\nand the RecipeLog that are applications for collecting people's detailed\nrecords about food habit. We also discuss several problems that we try to solve\nto build the WFA by integrating these two ideas.", "AI": {"tldr": "The paper introduces the World Food Atlas (WFA) project, focusing on the Food Knowledge Graph (FKG) and FoodLog/RecipeLog applications to better understand and control food habits.", "motivation": "The pandemic highlighted the importance of understanding food's impact on health, prompting the creation of WFA to centralize global food knowledge.", "method": "Developed the FKG for food and ingredient relationships, and FoodLog/RecipeLog apps for tracking food habits.", "result": "Proposed integrating FKG and food-tracking apps to address challenges in building the WFA.", "conclusion": "The paper outlines initial steps toward the WFA, emphasizing the potential of combining knowledge graphs and user data for food insights."}}
{"id": "2504.19720", "pdf": "https://arxiv.org/pdf/2504.19720", "abs": "https://arxiv.org/abs/2504.19720", "authors": ["Ranran Zhen", "Juntao Li", "Yixin Ji", "Zhenlin Yang", "Tong Liu", "Qingrong Xia", "Xinyu Duan", "Zhefeng Wang", "Baoxing Huai", "Min Zhang"], "title": "Taming the Titans: A Survey of Efficient LLM Inference Serving", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG"], "comment": "work in progress;11 pages of main paper with 7 main figures, overall\n  20 pages", "summary": "Large Language Models (LLMs) for Generative AI have achieved remarkable\nprogress, evolving into sophisticated and versatile tools widely adopted across\nvarious domains and applications. However, the substantial memory overhead\ncaused by their vast number of parameters, combined with the high computational\ndemands of the attention mechanism, poses significant challenges in achieving\nlow latency and high throughput for LLM inference services. Recent\nadvancements, driven by groundbreaking research, have significantly accelerated\nprogress in this field. This paper provides a comprehensive survey of these\nmethods, covering fundamental instance-level approaches, in-depth cluster-level\nstrategies, emerging scenario directions, and other miscellaneous but important\nareas. At the instance level, we review model placement, request scheduling,\ndecoding length prediction, storage management, and the disaggregation\nparadigm. At the cluster level, we explore GPU cluster deployment,\nmulti-instance load balancing, and cloud service solutions. For emerging\nscenarios, we organize the discussion around specific tasks, modules, and\nauxiliary methods. To ensure a holistic overview, we also highlight several\nniche yet critical areas. Finally, we outline potential research directions to\nfurther advance the field of LLM inference serving.", "AI": {"tldr": "A survey of methods to optimize LLM inference services, covering instance-level, cluster-level, and emerging strategies, plus future research directions.", "motivation": "Address the challenges of high memory and computational demands in LLM inference to improve latency and throughput.", "method": "Comprehensive review of optimization techniques at instance, cluster, and scenario levels, including niche areas.", "result": "Organized insights into current advancements and practical solutions for LLM inference serving.", "conclusion": "Identifies gaps and suggests future research to further enhance LLM inference efficiency."}}
{"id": "2504.19300", "pdf": "https://arxiv.org/pdf/2504.19300", "abs": "https://arxiv.org/abs/2504.19300", "authors": ["Ni Yao", "Xiangyu Liu", "Danyang Sun", "Chuang Han", "Yanting Li", "Jiaofen Nan", "Chengyang Li", "Fubao Zhu", "Weihua Zhou", "Chen Zhao"], "title": "Myocardial Region-guided Feature Aggregation Net for Automatic Coronary artery Segmentation and Stenosis Assessment using Coronary Computed Tomography Angiography", "categories": ["cs.CV"], "comment": "31 pages, 12 figures", "summary": "Coronary artery disease (CAD) remains a leading cause of mortality worldwide,\nrequiring accurate segmentation and stenosis detection using Coronary Computed\nTomography angiography (CCTA). Existing methods struggle with challenges such\nas low contrast, morphological variability and small vessel segmentation. To\naddress these limitations, we propose the Myocardial Region-guided Feature\nAggregation Net, a novel U-shaped dual-encoder architecture that integrates\nanatomical prior knowledge to enhance robustness in coronary artery\nsegmentation. Our framework incorporates three key innovations: (1) a\nMyocardial Region-guided Module that directs attention to coronary regions via\nmyocardial contour expansion and multi-scale feature fusion, (2) a Residual\nFeature Extraction Encoding Module that combines parallel spatial channel\nattention with residual blocks to enhance local-global feature discrimination,\nand (3) a Multi-scale Feature Fusion Module for adaptive aggregation of\nhierarchical vascular features. Additionally, Monte Carlo dropout f quantifies\nprediction uncertainty, supporting clinical interpretability. For stenosis\ndetection, a morphology-based centerline extraction algorithm separates the\nvascular tree into anatomical branches, enabling cross-sectional area\nquantification and stenosis grading. The superiority of MGFA-Net was\ndemonstrated by achieving an Dice score of 85.04%, an accuracy of 84.24%, an\nHD95 of 6.1294 mm, and an improvement of 5.46% in true positive rate for\nstenosis detection compared to3D U-Net. The integrated segmentation-to-stenosis\npipeline provides automated, clinically interpretable CAD assessment, bridging\ndeep learning with anatomical prior knowledge for precision medicine. Our code\nis publicly available at http://github.com/chenzhao2023/MGFA_CCTA", "AI": {"tldr": "Proposes MGFA-Net, a U-shaped dual-encoder architecture for robust coronary artery segmentation and stenosis detection in CCTA, integrating anatomical prior knowledge and achieving superior performance metrics.", "motivation": "Address challenges in CAD diagnosis, such as low contrast, morphological variability, and small vessel segmentation, by leveraging anatomical prior knowledge for improved accuracy.", "method": "Introduces three innovations: Myocardial Region-guided Module, Residual Feature Extraction Encoding Module, and Multi-scale Feature Fusion Module, alongside Monte Carlo dropout for uncertainty quantification and a morphology-based stenosis detection algorithm.", "result": "Achieves Dice score of 85.04%, accuracy of 84.24%, HD95 of 6.1294 mm, and 5.46% improvement in true positive rate for stenosis detection compared to 3D U-Net.", "conclusion": "MGFA-Net provides an automated, interpretable CAD assessment pipeline, combining deep learning with anatomical knowledge for precision medicine."}}
{"id": "2504.19176", "pdf": "https://arxiv.org/pdf/2504.19176", "abs": "https://arxiv.org/abs/2504.19176", "authors": ["Piotr Migus"], "title": "Newton-Puiseux Analysis for Interpretability and Calibration of Complex-Valued Neural Networks", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Complex-valued neural networks (CVNNs) excel where phase matters, yet their\nmulti-sheeted decision surfaces defy standard explainability and calibration\ntools. We propose a \\emph{Newton-Puiseux} framework that fits a local\npolynomial surrogate to a high-uncertainty input and analytically decomposes\nthis surrogate into fractional-power series. The resulting Puiseux expansions,\ndominant Puiseux coefficients, and phase-aligned curvature descriptors deliver\nclosed-form estimates of robustness and over-confidence that gradient - or\nperturbation-based methods (saliency, LIME, SHAP) cannot provide. On a\ncontrolled $\\mathbb{C}^2$ helix the surrogate attains RMSE $< 0.09$ while\nrecovering the number of decision sheets; quartic coefficients predict\nadversarial flip radii within $10^{-3}$. On the real-world MIT-BIH arrhythmia\ncorpus, Puiseux-guided, phase-aware temperature scaling lowers expected\ncalibration error from 0.087 to 0.034, contributing to the advancement of\nCVNNs. Full code, pre-trained weights, and scripts are at\nhttps://github.com/piotrmgs/puiseux-cvnn.", "AI": {"tldr": "A Newton-Puiseux framework is proposed to explain and calibrate complex-valued neural networks (CVNNs) by fitting local polynomial surrogates and decomposing them into fractional-power series, improving robustness and calibration.", "motivation": "Standard explainability and calibration tools fail for CVNNs due to their multi-sheeted decision surfaces. The paper addresses this gap.", "method": "The method involves fitting a local polynomial surrogate to high-uncertainty inputs, decomposing it into Puiseux expansions, and using these to estimate robustness and over-confidence.", "result": "The framework achieves low RMSE (0.09) on a controlled helix, predicts adversarial flip radii accurately, and reduces calibration error on the MIT-BIH arrhythmia corpus from 0.087 to 0.034.", "conclusion": "The proposed framework advances CVNN explainability and calibration, with practical applications demonstrated on synthetic and real-world datasets."}}
{"id": "2504.18804", "pdf": "https://arxiv.org/pdf/2504.18804", "abs": "https://arxiv.org/abs/2504.18804", "authors": ["Jagrit Acharya", "Gouri Ginde"], "title": "Can We Enhance Bug Report Quality Using LLMs?: An Empirical Study of LLM-Based Bug Report Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Bug reports contain the information developers need to triage and fix\nsoftware bugs. However, unclear, incomplete, or ambiguous information may lead\nto delays and excessive manual effort spent on bug triage and resolution. In\nthis paper, we explore whether Instruction fine-tuned Large Language Models\n(LLMs) can automatically transform casual, unstructured bug reports into\nhigh-quality, structured bug reports adhering to a standard template. We\nevaluate three open-source instruction-tuned LLMs (\\emph{Qwen 2.5, Mistral, and\nLlama 3.2}) against ChatGPT-4o, measuring performance on established metrics\nsuch as CTQRS, ROUGE, METEOR, and SBERT. Our experiments show that fine-tuned\nQwen 2.5 achieves a CTQRS score of \\textbf{77%}, outperforming both fine-tuned\nMistral (\\textbf{71%}), Llama 3.2 (\\textbf{63%}) and ChatGPT in 3-shot learning\n(\\textbf{75%}). Further analysis reveals that Llama 3.2 shows higher accuracy\nof detecting missing fields particularly Expected Behavior and Actual Behavior,\nwhile Qwen 2.5 demonstrates superior performance in capturing\nSteps-to-Reproduce, with an F1 score of 76%. Additional testing of the models\non other popular projects (e.g., Eclipse, GCC) demonstrates that our approach\ngeneralizes well, achieving up to \\textbf{70%} CTQRS in unseen projects' bug\nreports. These findings highlight the potential of instruction fine-tuning in\nautomating structured bug report generation, reducing manual effort for\ndevelopers and streamlining the software maintenance process.", "AI": {"tldr": "Instruction-tuned LLMs like Qwen 2.5 can transform unstructured bug reports into structured ones, outperforming other models in metrics like CTQRS and F1 scores.", "motivation": "Unclear or incomplete bug reports delay triage and resolution. Automating structured report generation can reduce manual effort.", "method": "Evaluated Qwen 2.5, Mistral, Llama 3.2, and ChatGPT-4o using CTQRS, ROUGE, METEOR, and SBERT metrics.", "result": "Qwen 2.5 achieved 77% CTQRS, outperforming others. Llama 3.2 excelled in detecting missing fields, while Qwen 2.5 captured Steps-to-Reproduce best.", "conclusion": "Instruction fine-tuning LLMs can automate structured bug report generation, improving software maintenance efficiency."}}
{"id": "2504.19734", "pdf": "https://arxiv.org/pdf/2504.19734", "abs": "https://arxiv.org/abs/2504.19734", "authors": ["Ying Na", "Shihui Feng"], "title": "LLM-Assisted Automated Deductive Coding of Dialogue Data: Leveraging Dialogue-Specific Characteristics to Enhance Contextual Understanding", "categories": ["cs.CL", "cs.SI"], "comment": null, "summary": "Dialogue data has been a key source for understanding learning processes,\noffering critical insights into how students engage in collaborative\ndiscussions and how these interactions shape their knowledge construction. The\nadvent of Large Language Models (LLMs) has introduced promising opportunities\nfor advancing qualitative research, particularly in the automated coding of\ndialogue data. However, the inherent contextual complexity of dialogue presents\nunique challenges for these models, especially in understanding and\ninterpreting complex contextual information. This study addresses these\nchallenges by developing a novel LLM-assisted automated coding approach for\ndialogue data. The novelty of our proposed framework is threefold: 1) We\npredict the code for an utterance based on dialogue-specific characteristics --\ncommunicative acts and communicative events -- using separate prompts following\nthe role prompts and chain-of-thoughts methods; 2) We engaged multiple LLMs\nincluding GPT-4-turbo, GPT-4o, DeepSeek in collaborative code prediction; 3) We\nleveraged the interrelation between events and acts to implement consistency\nchecking using GPT-4o. In particular, our contextual consistency checking\nprovided a substantial accuracy improvement. We also found the accuracy of act\npredictions was consistently higher than that of event predictions. This study\ncontributes a new methodological framework for enhancing the precision of\nautomated coding of dialogue data as well as offers a scalable solution for\naddressing the contextual challenges inherent in dialogue analysis.", "AI": {"tldr": "The paper introduces an LLM-assisted automated coding approach for dialogue data, leveraging communicative acts and events, multiple LLMs, and contextual consistency checking to improve accuracy.", "motivation": "Dialogue data is crucial for understanding learning processes, but its contextual complexity poses challenges for automated coding using LLMs.", "method": "Developed a framework using dialogue-specific characteristics (acts and events), multiple LLMs (GPT-4-turbo, GPT-4o, DeepSeek), and contextual consistency checking with GPT-4o.", "result": "Contextual consistency checking improved accuracy; act predictions were more accurate than event predictions.", "conclusion": "The study provides a scalable, precise framework for automated dialogue coding, addressing contextual challenges in dialogue analysis."}}
{"id": "2504.19327", "pdf": "https://arxiv.org/pdf/2504.19327", "abs": "https://arxiv.org/abs/2504.19327", "authors": ["Moulik Choraria", "Xinbo Wu", "Akhil Bhimaraju", "Nitesh Sekhar", "Yue Wu", "Xu Zhang", "Prateek Singhal", "Lav R. Varshney"], "title": "Platonic Grounding for Efficient Multimodal Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The hyperscaling of data and parameter count in Transformer-based models is\nyielding diminishing performance improvement, especially when weighed against\ntraining costs. Such plateauing indicates the importance of methods for more\nefficient finetuning and inference, while retaining similar performance. This\nis especially relevant for multimodal learning paradigms, where inference costs\nof processing multimodal tokens can determine the model's practical viability.\nAt the same time, research on representations and mechanistic interpretability\nhas improved our understanding of the inner workings of Transformer-based\nmodels; one such line of work reveals an implicit alignment in the deeper\nlayers of pretrained models, across modalities. Taking inspiration from this,\nwe motivate and propose a simple modification to existing multimodal frameworks\nthat rely on aligning pretrained models. We demonstrate that our approach\nmaintains and, in some cases, even improves performance of baseline methods\nwhile achieving significant gains in both training and inference-time compute.\nOur work also has implications for combining pretrained models into larger\nsystems efficiently.", "AI": {"tldr": "The paper addresses diminishing returns in Transformer-based models by proposing a simple modification for efficient multimodal learning, balancing performance and compute costs.", "motivation": "The plateauing performance gains of large Transformer models, coupled with high training and inference costs, highlight the need for efficient finetuning and inference methods, especially in multimodal contexts.", "method": "The authors propose a simple modification to existing multimodal frameworks, inspired by insights into implicit alignment in deeper layers of pretrained models.", "result": "The approach maintains or improves baseline performance while significantly reducing training and inference compute costs.", "conclusion": "The work offers a practical solution for efficient multimodal learning and has broader implications for integrating pretrained models into larger systems."}}
{"id": "2504.19188", "pdf": "https://arxiv.org/pdf/2504.19188", "abs": "https://arxiv.org/abs/2504.19188", "authors": ["Jianlong Chen", "Chao Li", "Yang Yuan", "Andrew C Yao"], "title": "Hierarchical Attention Generates Better Proofs", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.LO"], "comment": "15 pages with 3 figures", "summary": "Large language models (LLMs) have shown promise in formal theorem proving,\nbut their token-level processing often fails to capture the inherent\nhierarchical nature of mathematical proofs. We introduce \\textbf{Hierarchical\nAttention}, a regularization method that aligns LLMs' attention mechanisms with\nmathematical reasoning structures. Our approach establishes a five-level\nhierarchy from foundational elements to high-level concepts, ensuring\nstructured information flow in proof generation. Experiments demonstrate that\nour method improves proof success rates by 2.05\\% on miniF2F and 1.69\\% on\nProofNet while reducing proof complexity by 23.81\\% and 16.50\\% respectively.\nThe code is available at https://github.com/Car-pe/HAGBP.", "AI": {"tldr": "Hierarchical Attention improves LLMs' theorem proving by aligning attention with proof structures, boosting success rates and reducing complexity.", "motivation": "Token-level processing in LLMs often misses the hierarchical nature of mathematical proofs.", "method": "Introduces Hierarchical Attention, a five-level hierarchy for structured proof generation.", "result": "Improves proof success rates (2.05% on miniF2F, 1.69% on ProofNet) and reduces complexity (23.81%, 16.50%).", "conclusion": "Hierarchical Attention effectively aligns LLMs with mathematical reasoning, enhancing performance."}}
{"id": "2504.18807", "pdf": "https://arxiv.org/pdf/2504.18807", "abs": "https://arxiv.org/abs/2504.18807", "authors": ["Si\u00e2n Brooke"], "title": "Clones in the Machine: A Feminist Critique of Agency in Digital Cloning", "categories": ["cs.HC", "cs.AI"], "comment": "ACM CHI Conference on Human Factors in Computing Systems 2025", "summary": "This paper critiques digital cloning in academic research, highlighting how\nit exemplifies AI solutionism. Digital clones, which replicate user data to\nsimulate behavior, are often seen as scalable tools for behavioral insights.\nHowever, this framing obscures ethical concerns around consent, agency, and\nrepresentation. Drawing on feminist theories of agency, the paper argues that\ndigital cloning oversimplifies human complexity and risks perpetuating systemic\nbiases. To address these issues, it proposes decentralized data repositories\nand dynamic consent models, promoting ethical, context-aware AI practices that\nchallenge the reductionist logic of AI solutionism", "AI": {"tldr": "The paper critiques digital cloning in research for oversimplifying human behavior and masking ethical issues, proposing decentralized data and dynamic consent as solutions.", "motivation": "To challenge AI solutionism and highlight ethical concerns like consent and bias in digital cloning.", "method": "Uses feminist theories of agency to critique digital cloning and proposes decentralized data repositories and dynamic consent models.", "result": "Digital cloning risks perpetuating biases and oversimplifies human complexity, requiring ethical AI practices.", "conclusion": "Advocates for context-aware AI and ethical frameworks to counter the reductionist logic of AI solutionism."}}
{"id": "2504.19759", "pdf": "https://arxiv.org/pdf/2504.19759", "abs": "https://arxiv.org/abs/2504.19759", "authors": ["Huichi Zhou", "Zehao Xu", "Munan Zhao", "Kaihong Li", "Yiqiang Li", "Hongtao Wang"], "title": "Moral Reasoning Across Languages: The Critical Role of Low-Resource Languages in LLMs", "categories": ["cs.CL"], "comment": "5 pages, 2 figures", "summary": "In this paper, we introduce the Multilingual Moral Reasoning Benchmark (MMRB)\nto evaluate the moral reasoning abilities of large language models (LLMs)\nacross five typologically diverse languages and three levels of contextual\ncomplexity: sentence, paragraph, and document. Our results show moral reasoning\nperformance degrades with increasing context complexity, particularly for\nlow-resource languages such as Vietnamese. We further fine-tune the open-source\nLLaMA-3-8B model using curated monolingual data for alignment and poisoning.\nSurprisingly, low-resource languages have a stronger impact on multilingual\nreasoning than high-resource ones, highlighting their critical role in\nmultilingual NLP.", "AI": {"tldr": "The paper introduces MMRB to assess LLMs' moral reasoning in five languages, showing performance drops with context complexity, especially in low-resource languages like Vietnamese. Fine-tuning LLaMA-3-8B reveals low-resource languages' outsized impact on multilingual reasoning.", "motivation": "To evaluate and improve the moral reasoning abilities of LLMs across diverse languages and contextual complexities, addressing gaps in multilingual NLP.", "method": "Introduces MMRB for evaluation, fine-tunes LLaMA-3-8B with monolingual data for alignment and poisoning, and tests performance across languages and context levels.", "result": "Moral reasoning performance declines with context complexity, notably in low-resource languages. Fine-tuning shows low-resource languages significantly influence multilingual reasoning.", "conclusion": "Low-resource languages play a critical role in multilingual NLP, and their impact on reasoning is stronger than high-resource languages, necessitating focused attention."}}
{"id": "2504.19334", "pdf": "https://arxiv.org/pdf/2504.19334", "abs": "https://arxiv.org/abs/2504.19334", "authors": ["Sidharth Rai", "Aryan Dalal", "Riley Slichter", "Ajay Sharda"], "title": "Enhancing seeding efficiency using a computer vision system to monitor furrow quality in real-time", "categories": ["cs.CV"], "comment": null, "summary": "Effective seed sowing in precision agriculture is hindered by challenges such\nas residue accumulation, low soil temperatures, and hair pinning (crop residue\npushed in the trench by furrow opener), which obstruct optimal trench\nformation. Row cleaners are employed to mitigate these issues, but there is a\nlack of quantitative methods to assess trench cleanliness. In this study, a\nnovel computer vision-based method was developed to evaluate row cleaner\nperformance. Multiple air seeders were equipped with a video acquisition system\nto capture trench conditions after row cleaner operation, enabling an effective\ncomparison of the performance of each row cleaner. The captured data were used\nto develop a segmentation model that analyzed key elements such as soil, straw,\nand machinery. Using the results from the segmentation model, an objective\nmethod was developed to quantify row cleaner performance. The results\ndemonstrated the potential of this method to improve row cleaner selection and\nenhance seeding efficiency in precision agriculture.", "AI": {"tldr": "A computer vision-based method was developed to quantify row cleaner performance in precision agriculture, improving trench cleanliness assessment and seeding efficiency.", "motivation": "Challenges like residue accumulation and hair pinning hinder optimal trench formation, but existing methods lack quantitative assessment of row cleaner performance.", "method": "A video acquisition system captured trench conditions post-row cleaner operation. A segmentation model analyzed soil, straw, and machinery to quantify performance.", "result": "The method effectively compared row cleaner performance, providing an objective assessment tool.", "conclusion": "This approach enhances row cleaner selection and seeding efficiency in precision agriculture."}}
{"id": "2504.19199", "pdf": "https://arxiv.org/pdf/2504.19199", "abs": "https://arxiv.org/abs/2504.19199", "authors": ["Ming Xu", "Jinrong Xiang", "Zilong Xie", "Xiangfu Meng"], "title": "HetGL2R: Learning to Rank Critical Road Segments via Attributed Heterogeneous Graph Random Walks", "categories": ["cs.LG"], "comment": null, "summary": "Accurately identifying critical nodes with high spatial influence in road\nnetworks is essential for enhancing the efficiency of traffic management and\nurban planning. However, existing node importance ranking methods mainly rely\non structural features and topological information, often overlooking critical\nfactors such as origin-destination (OD) demand and route information. This\nlimitation leaves considerable room for improvement in ranking accuracy. To\naddress this issue, we propose HetGL2R, an attributed heterogeneous graph\nlearning approach for ranking node importance in road networks. This method\nintroduces a tripartite graph (trip graph) to model the structure of the road\nnetwork, integrating OD demand, route choice, and various structural features\nof road segments. Based on the trip graph, we design an embedding method to\nlearn node representations that reflect the spatial influence of road segments.\nThe method consists of a heterogeneous random walk sampling algorithm\n(HetGWalk) and a Transformer encoder. HetGWalk constructs multiple\nattribute-guided graphs based on the trip graph to enrich the diversity of\nsemantic associations between nodes. It then applies a joint random walk\nmechanism to convert both topological structures and node attributes into\nsequences, enabling the encoder to capture spatial dependencies more\neffectively among road segments. Finally, a listwise ranking strategy is\nemployed to evaluate node importance. To validate the performance of our\nmethod, we construct two synthetic datasets using SUMO based on simulated road\nnetworks. Experimental results demonstrate that HetGL2R significantly\noutperforms baselines in incorporating OD demand and route choice information,\nachieving more accurate and robust node ranking. Furthermore, we conduct a case\nstudy using real-world taxi trajectory data from Beijing, further verifying the\npracticality of the proposed method.", "AI": {"tldr": "HetGL2R is a novel method for ranking node importance in road networks by integrating OD demand, route choice, and structural features, outperforming existing methods.", "motivation": "Existing node ranking methods overlook OD demand and route information, limiting accuracy. HetGL2R addresses this gap.", "method": "Uses a tripartite graph (trip graph) with OD demand and route data, embedding via HetGWalk and Transformer encoder for spatial influence.", "result": "Outperforms baselines in accuracy and robustness, validated on synthetic and real-world datasets.", "conclusion": "HetGL2R improves node ranking by effectively capturing spatial dependencies and practical traffic data."}}
{"id": "2504.18814", "pdf": "https://arxiv.org/pdf/2504.18814", "abs": "https://arxiv.org/abs/2504.18814", "authors": ["Abdelaziz Amara korba", "Nour Elislem Karabadji", "Yacine Ghamri-Doudane"], "title": "Zero-Day Botnet Attack Detection in IoV: A Modular Approach Using Isolation Forests and Particle Swarm Optimization", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The Internet of Vehicles (IoV) is transforming transportation by enhancing\nconnectivity and enabling autonomous driving. However, this increased\ninterconnectivity introduces new security vulnerabilities. Bot malware and\ncyberattacks pose significant risks to Connected and Autonomous Vehicles\n(CAVs), as demonstrated by real-world incidents involving remote vehicle system\ncompromise. To address these challenges, we propose an edge-based Intrusion\nDetection System (IDS) that monitors network traffic to and from CAVs. Our\ndetection model is based on a meta-ensemble classifier capable of recognizing\nknown (Nday) attacks and detecting previously unseen (zero-day) attacks. The\napproach involves training multiple Isolation Forest (IF) models on\nMulti-access Edge Computing (MEC) servers, with each IF specialized in\nidentifying a specific type of botnet attack. These IFs, either trained locally\nor shared by other MEC nodes, are then aggregated using a Particle Swarm\nOptimization (PSO) based stacking strategy to construct a robust\nmeta-classifier. The proposed IDS has been evaluated on a vehicular botnet\ndataset, achieving an average detection rate of 92.80% for N-day attacks and\n77.32% for zero-day attacks. These results highlight the effectiveness of our\nsolution in detecting both known and emerging threats, providing a scalable and\nadaptive defense mechanism for CAVs within the IoV ecosystem.", "AI": {"tldr": "Proposes an edge-based IDS for CAVs using a meta-ensemble classifier to detect known and zero-day botnet attacks, achieving high detection rates.", "motivation": "Addresses security vulnerabilities in IoV, particularly bot malware and cyberattacks on CAVs, demonstrated by real-world incidents.", "method": "Uses Isolation Forest models on MEC servers, aggregated via PSO-based stacking to create a meta-classifier for attack detection.", "result": "Achieves 92.80% detection for known attacks and 77.32% for zero-day attacks on a vehicular botnet dataset.", "conclusion": "The IDS is effective, scalable, and adaptive for securing CAVs in IoV."}}
{"id": "2504.19811", "pdf": "https://arxiv.org/pdf/2504.19811", "abs": "https://arxiv.org/abs/2504.19811", "authors": ["Takuya Tamura", "Taro Yano", "Masafumi Enomoto", "Masafumi Oyamada"], "title": "Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language Model Performance", "categories": ["cs.CL"], "comment": null, "summary": "Accurately forecasting the performance of Large Language Models (LLMs) before\nextensive fine-tuning or merging can substantially reduce both computational\nexpense and development time. Although prior approaches like scaling laws\naccount for global factors such as parameter size or training tokens, they\noften overlook explicit lineage relationships - i.e., which models are derived\nor merged from which parents. In this work, we propose a novel\nLineage-Regularized Matrix Factorization (LRMF) framework that encodes\nancestral ties among LLMs via a graph Laplacian regularizer. By leveraging\nmulti-hop parent-child connections, LRMF consistently outperforms conventional\nmatrix factorization and collaborative filtering methods in both instance-level\nand benchmark-level performance prediction. Our large-scale study includes\n2,934 publicly available Hugging Face models and 21,000+ instances across 6\nmajor benchmarks, showing that lineage constraints yield up to 7-10 percentage\npoints higher correlation with actual performance compared to baselines.\nMoreover, LRMF effectively addresses the cold-start problem, providing accurate\nestimates for newly derived or merged models even with minimal data. This\nlineage-guided strategy thus offers a resource-efficient way to inform\nhyperparameter tuning, data selection, and model combination in modern LLM\ndevelopment.", "AI": {"tldr": "LRMF, a lineage-regularized matrix factorization method, improves LLM performance forecasting by leveraging ancestral ties, outperforming baselines by 7-10% in accuracy.", "motivation": "Current LLM performance forecasting methods ignore lineage relationships, leading to inefficiencies in computational expense and development time.", "method": "Proposes LRMF, which uses a graph Laplacian regularizer to encode ancestral ties among LLMs, enhancing performance prediction.", "result": "LRMF outperforms baselines by 7-10% in correlation with actual performance and addresses the cold-start problem effectively.", "conclusion": "LRMF offers a resource-efficient solution for hyperparameter tuning, data selection, and model combination in LLM development."}}
{"id": "2504.19347", "pdf": "https://arxiv.org/pdf/2504.19347", "abs": "https://arxiv.org/abs/2504.19347", "authors": ["Rayson Laroca", "Marcelo dos Santos", "David Menotti"], "title": "Improving Small Drone Detection Through Multi-Scale Processing and Data Augmentation", "categories": ["cs.CV"], "comment": "Accepted for presentation at the International Joint Conference on\n  Neural Networks (IJCNN) 2025", "summary": "Detecting small drones, often indistinguishable from birds, is crucial for\nmodern surveillance. This work introduces a drone detection methodology built\nupon the medium-sized YOLOv11 object detection model. To enhance its\nperformance on small targets, we implemented a multi-scale approach in which\nthe input image is processed both as a whole and in segmented parts, with\nsubsequent prediction aggregation. We also utilized a copy-paste data\naugmentation technique to enrich the training dataset with diverse drone and\nbird examples. Finally, we implemented a post-processing technique that\nleverages frame-to-frame consistency to mitigate missed detections. The\nproposed approach attained a top-3 ranking in the 8th WOSDETC Drone-vsBird\nDetection Grand Challenge, held at the 2025 International Joint Conference on\nNeural Networks (IJCNN), showcasing its capability to detect drones in complex\nenvironments effectively.", "AI": {"tldr": "A drone detection method using YOLOv11 with multi-scale processing, data augmentation, and post-processing achieved top-3 in a detection challenge.", "motivation": "Detecting small drones indistinguishable from birds is critical for surveillance.", "method": "Uses YOLOv11 with multi-scale input processing, copy-paste data augmentation, and frame-to-frame consistency post-processing.", "result": "Ranked top-3 in the WOSDETC Drone-vsBird Detection Grand Challenge.", "conclusion": "The approach effectively detects drones in complex environments."}}
{"id": "2504.19259", "pdf": "https://arxiv.org/pdf/2504.19259", "abs": "https://arxiv.org/abs/2504.19259", "authors": ["Adwait Datar", "Nihat Ay"], "title": "Convergence Properties of Natural Gradient Descent for Minimizing KL Divergence", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "The Kullback-Leibler (KL) divergence plays a central role in probabilistic\nmachine learning, where it commonly serves as the canonical loss function.\nOptimization in such settings is often performed over the probability simplex,\nwhere the choice of parameterization significantly impacts convergence. In this\nwork, we study the problem of minimizing the KL divergence and analyze the\nbehavior of gradient-based optimization algorithms under two dual coordinate\nsystems within the framework of information geometry$-$ the exponential family\n($\\theta$ coordinates) and the mixture family ($\\eta$ coordinates). We compare\nEuclidean gradient descent (GD) in these coordinates with the\ncoordinate-invariant natural gradient descent (NGD), where the natural gradient\nis a Riemannian gradient that incorporates the intrinsic geometry of the\nparameter space. In continuous time, we prove that the convergence rates of GD\nin the $\\theta$ and $\\eta$ coordinates provide lower and upper bounds,\nrespectively, on the convergence rate of NGD. Moreover, under affine\nreparameterizations of the dual coordinates, the convergence rates of GD in\n$\\eta$ and $\\theta$ coordinates can be scaled to $2c$ and $\\frac{2}{c}$,\nrespectively, for any $c>0$, while NGD maintains a fixed convergence rate of\n$2$, remaining invariant to such transformations and sandwiched between them.\nAlthough this suggests that NGD may not exhibit uniformly superior convergence\nin continuous time, we demonstrate that its advantages become pronounced in\ndiscrete time, where it achieves faster convergence and greater robustness to\nnoise, outperforming GD. Our analysis hinges on bounding the spectrum and\ncondition number of the Hessian of the KL divergence at the optimum, which\ncoincides with the Fisher information matrix.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.18827", "pdf": "https://arxiv.org/pdf/2504.18827", "abs": "https://arxiv.org/abs/2504.18827", "authors": ["Teeradaj Racharak", "Chaiyong Ragkhitwetsagul", "Chommakorn Sontesadisai", "Thanwadee Sunetnanta"], "title": "Test It Before You Trust It: Applying Software Testing for Trustworthy In-context Learning", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "In-context learning (ICL) has emerged as a powerful capability of large\nlanguage models (LLMs), enabling them to perform new tasks based on a few\nprovided examples without explicit fine-tuning. Despite their impressive\nadaptability, these models remain vulnerable to subtle adversarial\nperturbations and exhibit unpredictable behavior when faced with linguistic\nvariations. Inspired by software testing principles, we introduce a software\ntesting-inspired framework, called MMT4NL, for evaluating the trustworthiness\nof in-context learning by utilizing adversarial perturbations and software\ntesting techniques. It includes diverse evaluation aspects of linguistic\ncapabilities for testing the ICL capabilities of LLMs. MMT4NL is built around\nthe idea of crafting metamorphic adversarial examples from a test set in order\nto quantify and pinpoint bugs in the designed prompts of ICL. Our philosophy is\nto treat any LLM as software and validate its functionalities just like testing\nthe software. Finally, we demonstrate applications of MMT4NL on the sentiment\nanalysis and question-answering tasks. Our experiments could reveal various\nlinguistic bugs in state-of-the-art LLMs.", "AI": {"tldr": "The paper introduces MMT4NL, a software testing-inspired framework to evaluate the trustworthiness of in-context learning (ICL) in LLMs using adversarial perturbations and testing techniques.", "motivation": "Despite the adaptability of LLMs in ICL, they are vulnerable to adversarial perturbations and unpredictable behavior with linguistic variations, necessitating a robust evaluation framework.", "method": "MMT4NL crafts metamorphic adversarial examples from a test set to quantify and identify bugs in ICL prompts, treating LLMs like software for validation.", "result": "Experiments on sentiment analysis and question-answering tasks revealed linguistic bugs in state-of-the-art LLMs.", "conclusion": "MMT4NL effectively evaluates and improves the reliability of ICL in LLMs by leveraging software testing principles."}}
{"id": "2504.19850", "pdf": "https://arxiv.org/pdf/2504.19850", "abs": "https://arxiv.org/abs/2504.19850", "authors": ["Kyo Gerrits", "Ana Guerberof-Arenas"], "title": "To MT or not to MT: An eye-tracking study on the reception by Dutch readers of different translation and creativity levels", "categories": ["cs.CL"], "comment": "This paper has been accepted to the MT Summit 2025 to be held in\n  Geneva on June 23-27 2025", "summary": "This article presents the results of a pilot study involving the reception of\na fictional short story translated from English into Dutch under four\nconditions: machine translation (MT), post-editing (PE), human translation (HT)\nand original source text (ST). The aim is to understand how creativity and\nerrors in different translation modalities affect readers, specifically\nregarding cognitive load. Eight participants filled in a questionnaire, read a\nstory using an eye-tracker, and conducted a retrospective think-aloud (RTA)\ninterview. The results show that units of creative potential (UCP) increase\ncognitive load and that this effect is highest for HT and lowest for MT; no\neffect of error was observed. Triangulating the data with RTAs leads us to\nhypothesize that the higher cognitive load in UCPs is linked to increases in\nreader enjoyment and immersion. The effect of translation creativity on\ncognitive load in different translation modalities at word-level is novel and\nopens up new avenues for further research. All the code and data are available\nat https://github.com/INCREC/Pilot_to_MT_or_not_to_MT", "AI": {"tldr": "The study explores how creativity and errors in different translation methods (MT, PE, HT, ST) affect cognitive load, finding that creative potential increases cognitive load, with HT having the highest impact and MT the lowest.", "motivation": "To understand how translation modalities influence cognitive load and reader experience, focusing on creativity and errors.", "method": "Pilot study with eight participants using questionnaires, eye-tracking, and retrospective think-aloud interviews to analyze cognitive load.", "result": "Creative potential (UCP) increases cognitive load, highest in HT and lowest in MT; no error effect observed. Higher cognitive load may link to reader enjoyment.", "conclusion": "Translation creativity affects cognitive load, with novel findings at word-level, suggesting further research. Data and code are openly available."}}
{"id": "2504.19357", "pdf": "https://arxiv.org/pdf/2504.19357", "abs": "https://arxiv.org/abs/2504.19357", "authors": ["Jiahao Lu", "Chong Yin", "Silvia Ingala", "Kenny Erleben", "Michael Bachmann Nielsen", "Sune Darkner"], "title": "MERA: Multimodal and Multiscale Self-Explanatory Model with Considerably Reduced Annotation for Lung Nodule Diagnosis", "categories": ["cs.CV"], "comment": null, "summary": "Lung cancer, a leading cause of cancer-related deaths globally, emphasises\nthe importance of early detection for better patient outcomes. Pulmonary\nnodules, often early indicators of lung cancer, necessitate accurate, timely\ndiagnosis. Despite Explainable Artificial Intelligence (XAI) advances, many\nexisting systems struggle providing clear, comprehensive explanations,\nespecially with limited labelled data. This study introduces MERA, a Multimodal\nand Multiscale self-Explanatory model designed for lung nodule diagnosis with\nconsiderably Reduced Annotation requirements. MERA integrates unsupervised and\nweakly supervised learning strategies (self-supervised learning techniques and\nVision Transformer architecture for unsupervised feature extraction) and a\nhierarchical prediction mechanism leveraging sparse annotations via\nsemi-supervised active learning in the learned latent space. MERA explains its\ndecisions on multiple levels: model-level global explanations via semantic\nlatent space clustering, instance-level case-based explanations showing similar\ninstances, local visual explanations via attention maps, and concept\nexplanations using critical nodule attributes. Evaluations on the public LIDC\ndataset show MERA's superior diagnostic accuracy and self-explainability. With\nonly 1% annotated samples, MERA achieves diagnostic accuracy comparable to or\nexceeding state-of-the-art methods requiring full annotation. The model's\ninherent design delivers comprehensive, robust, multilevel explanations aligned\nclosely with clinical practice, enhancing trustworthiness and transparency.\nDemonstrated viability of unsupervised and weakly supervised learning lowers\nthe barrier to deploying diagnostic AI in broader medical domains. Our complete\ncode is open-source available: https://github.com/diku-dk/credanno.", "AI": {"tldr": "MERA is a multimodal, multiscale self-explanatory model for lung nodule diagnosis, reducing annotation needs while providing comprehensive explanations and achieving high accuracy.", "motivation": "Early detection of lung cancer via pulmonary nodules is critical, but existing XAI systems lack clarity and require extensive labeled data.", "method": "MERA combines unsupervised and weakly supervised learning (self-supervised learning, Vision Transformer) with hierarchical prediction and semi-supervised active learning.", "result": "MERA matches or surpasses state-of-the-art accuracy with only 1% annotated data and offers multilevel explanations.", "conclusion": "MERA enhances trust and transparency in diagnostic AI, demonstrating the viability of reduced annotation approaches for broader medical use."}}
{"id": "2504.19274", "pdf": "https://arxiv.org/pdf/2504.19274", "abs": "https://arxiv.org/abs/2504.19274", "authors": ["Mohammad M Maheri", "Hamed Haddadi", "Alex Davidson"], "title": "TeleSparse: Practical Privacy-Preserving Verification of Deep Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "This paper has been accepted to the Privacy Enhancing Technologies\n  Symposium (PETS) 2025", "summary": "Verification of the integrity of deep learning inference is crucial for\nunderstanding whether a model is being applied correctly. However, such\nverification typically requires access to model weights and (potentially\nsensitive or private) training data. So-called Zero-knowledge Succinct\nNon-Interactive Arguments of Knowledge (ZK-SNARKs) would appear to provide the\ncapability to verify model inference without access to such sensitive data.\nHowever, applying ZK-SNARKs to modern neural networks, such as transformers and\nlarge vision models, introduces significant computational overhead.\n  We present TeleSparse, a ZK-friendly post-processing mechanisms to produce\npractical solutions to this problem. TeleSparse tackles two fundamental\nchallenges inherent in applying ZK-SNARKs to modern neural networks: (1)\nReducing circuit constraints: Over-parameterized models result in numerous\nconstraints for ZK-SNARK verification, driving up memory and proof generation\ncosts. We address this by applying sparsification to neural network models,\nenhancing proof efficiency without compromising accuracy or security. (2)\nMinimizing the size of lookup tables required for non-linear functions, by\noptimizing activation ranges through neural teleportation, a novel adaptation\nfor narrowing activation functions' range.\n  TeleSparse reduces prover memory usage by 67% and proof generation time by\n46% on the same model, with an accuracy trade-off of approximately 1%. We\nimplement our framework using the Halo2 proving system and demonstrate its\neffectiveness across multiple architectures (Vision-transformer, ResNet,\nMobileNet) and datasets (ImageNet,CIFAR-10,CIFAR-100). This work opens new\ndirections for ZK-friendly model design, moving toward scalable,\nresource-efficient verifiable deep learning.", "AI": {"tldr": "TeleSparse introduces ZK-friendly post-processing to verify deep learning inference efficiently, reducing computational overhead and memory usage while maintaining accuracy.", "motivation": "Verifying deep learning inference without accessing sensitive data (weights/training data) is challenging due to computational overhead with ZK-SNARKs.", "method": "TeleSparse uses sparsification to reduce circuit constraints and neural teleportation to minimize lookup tables for non-linear functions.", "result": "TeleSparse cuts prover memory by 67%, proof time by 46%, with ~1% accuracy loss, tested on various models and datasets.", "conclusion": "TeleSparse advances scalable, resource-efficient verifiable deep learning, enabling ZK-friendly model design."}}
{"id": "2504.18847", "pdf": "https://arxiv.org/pdf/2504.18847", "abs": "https://arxiv.org/abs/2504.18847", "authors": ["Hidayet Ersin Dursun", "Yusuf G\u00fcven", "Tufan Kumbasar"], "title": "Imitation Learning for Autonomous Driving: Insights from Real-World Testing", "categories": ["cs.RO", "cs.AI"], "comment": "In International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025", "summary": "This work focuses on the design of a deep learning-based autonomous driving\nsystem deployed and tested on the real-world MIT Racecar to assess its\neffectiveness in driving scenarios. The Deep Neural Network (DNN) translates\nraw image inputs into real-time steering commands in an end-to-end learning\nfashion, following the imitation learning framework. The key design challenge\nis to ensure that DNN predictions are accurate and fast enough, at a high\nsampling frequency, and result in smooth vehicle operation under different\noperating conditions. In this study, we design and compare various DNNs, to\nidentify the most effective approach for real-time autonomous driving. In\ndesigning the DNNs, we adopted an incremental design approach that involved\nenhancing the model capacity and dataset to address the challenges of\nreal-world driving scenarios. We designed a PD system, CNN, CNN-LSTM, and\nCNN-NODE, and evaluated their performance on the real-world MIT Racecar. While\nthe PD system handled basic lane following, it struggled with sharp turns and\nlighting variations. The CNN improved steering but lacked temporal awareness,\nwhich the CNN-LSTM addressed as it resulted in smooth driving performance. The\nCNN-NODE performed similarly to the CNN-LSTM in handling driving dynamics, yet\nwith slightly better driving performance. The findings of this research\nhighlight the importance of iterative design processes in developing robust\nDNNs for autonomous driving applications. The experimental video is available\nat https://www.youtube.com/watch?v=FNNYgU--iaY.", "AI": {"tldr": "The paper evaluates deep learning models for autonomous driving on the MIT Racecar, comparing PD, CNN, CNN-LSTM, and CNN-NODE, with CNN-LSTM and CNN-NODE showing superior performance.", "motivation": "To develop an effective deep learning-based autonomous driving system capable of real-time, smooth operation under varied conditions.", "method": "Incremental design of DNNs (PD, CNN, CNN-LSTM, CNN-NODE) tested on the MIT Racecar, focusing on accuracy, speed, and smoothness.", "result": "CNN-LSTM and CNN-NODE outperformed others, with CNN-NODE slightly better in driving dynamics. PD struggled with sharp turns and lighting.", "conclusion": "Iterative design is crucial for robust DNNs in autonomous driving, with CNN-LSTM and CNN-NODE being the most effective."}}
{"id": "2504.19856", "pdf": "https://arxiv.org/pdf/2504.19856", "abs": "https://arxiv.org/abs/2504.19856", "authors": ["Anastasia Zhukova", "Christian E. Matt", "Terry Ruas", "Bela Gipp"], "title": "Efficient Domain-adaptive Continual Pretraining for the Process Industry in the German Language", "categories": ["cs.CL"], "comment": null, "summary": "Domain-adaptive continual pretraining (DAPT) is a state-of-the-art technique\nthat further trains a language model (LM) on its pretraining task, e.g.,\nlanguage masking. Although popular, it requires a significant corpus of\ndomain-related data, which is difficult to obtain for specific domains in\nlanguages other than English, such as the process industry in the German\nlanguage. This paper introduces an efficient approach called ICL-augmented\npretraining or ICL-APT that leverages in-context learning (ICL) and k-nearest\nneighbors (kNN) to augment target data with domain-related and in-domain texts,\nsignificantly reducing GPU time while maintaining strong model performance. Our\nresults show that this approach performs better than traditional DAPT by 3.5 of\nthe average IR metrics (e.g., mAP, MRR, and nDCG) and requires almost 4 times\nless computing time, providing a cost-effective solution for industries with\nlimited computational capacity. The findings highlight the broader\napplicability of this framework to other low-resource industries, making\nNLP-based solutions more accessible and feasible in production environments.", "AI": {"tldr": "ICL-APT, an efficient alternative to DAPT, uses in-context learning and kNN to reduce GPU time and improve performance in low-resource domains.", "motivation": "Addressing the challenge of obtaining domain-specific data for non-English languages and resource-limited industries.", "method": "Leverages in-context learning (ICL) and k-nearest neighbors (kNN) to augment target data, reducing computational demands.", "result": "Outperforms DAPT by 3.5 in IR metrics and reduces computing time by 4x.", "conclusion": "ICL-APT offers a cost-effective, scalable solution for low-resource domains, enhancing NLP accessibility."}}
{"id": "2504.19370", "pdf": "https://arxiv.org/pdf/2504.19370", "abs": "https://arxiv.org/abs/2504.19370", "authors": ["Jean-R\u00e9my Conti", "St\u00e9phan Cl\u00e9men\u00e7on"], "title": "Mitigating Bias in Facial Recognition Systems: Centroid Fairness Loss Optimization", "categories": ["cs.CV", "cs.AI", "cs.LG", "stat.ML"], "comment": "Accepted at both the AFME and RegML Workshops at NeurIPS 2024. A\n  preliminary version has been accepted for publication by Springer Nature, in\n  the context of the ICPR 2024 conference", "summary": "The urging societal demand for fair AI systems has put pressure on the\nresearch community to develop predictive models that are not only globally\naccurate but also meet new fairness criteria, reflecting the lack of disparate\nmistreatment with respect to sensitive attributes ($\\textit{e.g.}$ gender,\nethnicity, age). In particular, the variability of the errors made by certain\nFacial Recognition (FR) systems across specific segments of the population\ncompromises the deployment of the latter, and was judged unacceptable by\nregulatory authorities. Designing fair FR systems is a very challenging\nproblem, mainly due to the complex and functional nature of the performance\nmeasure used in this domain ($\\textit{i.e.}$ ROC curves) and because of the\nhuge heterogeneity of the face image datasets usually available for training.\nIn this paper, we propose a novel post-processing approach to improve the\nfairness of pre-trained FR models by optimizing a regression loss which acts on\ncentroid-based scores. Beyond the computational advantages of the method, we\npresent numerical experiments providing strong empirical evidence of the gain\nin fairness and of the ability to preserve global accuracy.", "AI": {"tldr": "A post-processing method improves fairness in facial recognition (FR) systems by optimizing centroid-based scores, balancing fairness and global accuracy.", "motivation": "The need for fair AI systems, especially in FR, due to disparate error rates across demographic groups and regulatory pressures.", "method": "A novel post-processing approach optimizing a regression loss on centroid-based scores to enhance fairness in pre-trained FR models.", "result": "The method shows significant fairness improvements while maintaining global accuracy, supported by empirical evidence.", "conclusion": "The proposed approach effectively addresses fairness in FR systems without compromising overall performance."}}
{"id": "2504.19276", "pdf": "https://arxiv.org/pdf/2504.19276", "abs": "https://arxiv.org/abs/2504.19276", "authors": ["Yiyang Zhou", "Zhaoyang Wang", "Tianle Wang", "Shangyu Xing", "Peng Xia", "Bo Li", "Kaiyuan Zheng", "Zijian Zhang", "Zhaorun Chen", "Wenhao Zheng", "Xuchao Zhang", "Chetan Bansal", "Weitong Zhang", "Ying Wei", "Mohit Bansal", "Huaxiu Yao"], "title": "Anyprefer: An Agentic Framework for Preference Data Synthesis", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "High-quality preference data is essential for aligning foundation models with\nhuman values through preference learning. However, manual annotation of such\ndata is often time-consuming and costly. Recent methods often adopt a\nself-rewarding approach, where the target model generates and annotates its own\npreference data, but this can lead to inaccuracies since the reward model\nshares weights with the target model, thereby amplifying inherent biases. To\naddress these issues, we propose Anyprefer, a framework designed to synthesize\nhigh-quality preference data for aligning the target model. Anyprefer frames\nthe data synthesis process as a cooperative two-player Markov Game, where the\ntarget model and the judge model collaborate together. Here, a series of\nexternal tools are introduced to assist the judge model in accurately rewarding\nthe target model's responses, mitigating biases in the rewarding process. In\naddition, a feedback mechanism is introduced to optimize prompts for both\nmodels, enhancing collaboration and improving data quality. The synthesized\ndata is compiled into a new preference dataset, Anyprefer-V1, consisting of 58K\nhigh-quality preference pairs. Extensive experiments show that Anyprefer\nsignificantly improves model alignment performance across four main\napplications, covering 21 datasets, achieving average improvements of 18.55% in\nfive natural language generation datasets, 3.66% in nine vision-language\nunderstanding datasets, 30.05% in three medical image analysis datasets, and\n16.00% in four visuo-motor control tasks.", "AI": {"tldr": "Anyprefer is a framework for synthesizing high-quality preference data to align foundation models with human values, using a cooperative two-player Markov Game and external tools to mitigate biases.", "motivation": "Manual annotation of preference data is costly and time-consuming, and self-rewarding methods can amplify biases. Anyprefer aims to address these issues.", "method": "Anyprefer uses a cooperative two-player Markov Game involving the target model and a judge model, assisted by external tools and a feedback mechanism.", "result": "Anyprefer-V1, a dataset of 58K preference pairs, improves model alignment by 18.55% in NLG, 3.66% in vision-language, 30.05% in medical image analysis, and 16.00% in visuo-motor tasks.", "conclusion": "Anyprefer effectively synthesizes high-quality preference data, enhancing model alignment across diverse applications."}}
{"id": "2504.18854", "pdf": "https://arxiv.org/pdf/2504.18854", "abs": "https://arxiv.org/abs/2504.18854", "authors": ["Tengfei Xing", "Xiaodan Ren", "Jie Li"], "title": "Predicting Stress in Two-phase Random Materials and Super-Resolution Method for Stress Images by Embedding Physical Information", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG"], "comment": null, "summary": "Stress analysis is an important part of material design. For materials with\ncomplex microstructures, such as two-phase random materials (TRMs), material\nfailure is often accompanied by stress concentration. Phase interfaces in\ntwo-phase materials are critical for stress concentration. Therefore, the\nprediction error of stress at phase boundaries is crucial. In practical\nengineering, the pixels of the obtained material microstructure images are\nlimited, which limits the resolution of stress images generated by deep\nlearning methods, making it difficult to observe stress concentration regions.\nExisting Image Super-Resolution (ISR) technologies are all based on data-driven\nsupervised learning. However, stress images have natural physical constraints,\nwhich provide new ideas for new ISR technologies. In this study, we constructed\na stress prediction framework for TRMs. First, the framework uses a proposed\nMultiple Compositions U-net (MC U-net) to predict stress in low-resolution\nmaterial microstructures. By considering the phase interface information of the\nmicrostructure, the MC U-net effectively reduces the problem of excessive\nprediction errors at phase boundaries. Secondly, a Mixed Physics-Informed\nNeural Network (MPINN) based method for stress ISR (SRPINN) was proposed. By\nintroducing the constraints of physical information, the new method does not\nrequire paired stress images for training and can increase the resolution of\nstress images to any multiple. This enables a multiscale analysis of the stress\nconcentration regions at phase boundaries. Finally, we performed stress\nanalysis on TRMs with different phase volume fractions and loading states\nthrough transfer learning. The results show the proposed stress prediction\nframework has satisfactory accuracy and generalization ability.", "AI": {"tldr": "A stress prediction framework for two-phase random materials (TRMs) combines MC U-net for low-resolution stress prediction and SRPINN for super-resolution, leveraging physical constraints to improve accuracy and generalization.", "motivation": "Stress concentration at phase interfaces in TRMs is critical for material failure, but limited image resolution hinders observation. Existing ISR methods lack physical constraints.", "method": "Proposes MC U-net for stress prediction and SRPINN for super-resolution, incorporating physical constraints without paired training data.", "result": "The framework achieves accurate stress analysis for TRMs with varying phase fractions and loading states.", "conclusion": "The method offers improved accuracy and generalization for stress prediction in TRMs, enabling multiscale analysis of stress concentration."}}
{"id": "2504.19867", "pdf": "https://arxiv.org/pdf/2504.19867", "abs": "https://arxiv.org/abs/2504.19867", "authors": ["Ke Hong", "Lufang Chen", "Zhong Wang", "Xiuhong Li", "Qiuli Mao", "Jianping Ma", "Chao Xiong", "Guanyu Wu", "Buhe Han", "Guohao Dai", "Yun Liang", "Yu Wang"], "title": "semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated Computation and Unified Storage", "categories": ["cs.CL", "cs.DC", "cs.LG"], "comment": "18 pages, 16 figures", "summary": "Existing large language model (LLM) serving systems fall into two categories:\n1) a unified system where prefill phase and decode phase are co-located on the\nsame GPU, sharing the unified computational resource and storage, and 2) a\ndisaggregated system where the two phases are disaggregated to different GPUs.\nThe design of the disaggregated system addresses the latency interference and\nsophisticated scheduling issues in the unified system but leads to storage\nchallenges including 1) replicated weights for both phases that prevent\nflexible deployment, 2) KV cache transfer overhead between the two phases, 3)\nstorage imbalance that causes substantial wasted space of the GPU capacity, and\n4) suboptimal resource adjustment arising from the difficulties in migrating KV\ncache. Such storage inefficiency delivers poor serving performance under high\nrequest rates.\n  In this paper, we identify that the advantage of the disaggregated system\nlies in the disaggregated computation, i.e., partitioning the computational\nresource to enable the asynchronous computation of two phases. Thus, we propose\na novel LLM serving system, semi-PD, characterized by disaggregated computation\nand unified storage. In semi-PD, we introduce a computation resource controller\nto achieve disaggregated computation at the streaming multi-processor (SM)\nlevel, and a unified memory manager to manage the asynchronous memory access\nfrom both phases. semi-PD has a low-overhead resource adjustment mechanism\nbetween the two phases, and a service-level objective (SLO) aware dynamic\npartitioning algorithm to optimize the SLO attainment. Compared to\nstate-of-the-art systems, semi-PD maintains lower latency at higher request\nrates, reducing the average end-to-end latency per request by 1.27-2.58x on\nDeepSeek series models, and serves 1.55-1.72x more requests adhering to latency\nconstraints on Llama series models.", "AI": {"tldr": "The paper proposes semi-PD, a novel LLM serving system with disaggregated computation and unified storage to address storage inefficiencies in existing systems, improving latency and request handling.", "motivation": "Existing LLM serving systems face storage inefficiencies due to replicated weights, KV cache transfer overhead, storage imbalance, and suboptimal resource adjustment, leading to poor performance under high request rates.", "method": "The semi-PD system introduces a computation resource controller for disaggregated computation at the SM level and a unified memory manager for asynchronous memory access. It includes a low-overhead resource adjustment mechanism and an SLO-aware dynamic partitioning algorithm.", "result": "semi-PD reduces average end-to-end latency by 1.27-2.58x on DeepSeek models and serves 1.55-1.72x more requests under latency constraints on Llama models compared to state-of-the-art systems.", "conclusion": "semi-PD effectively addresses storage inefficiencies in LLM serving systems, improving performance and scalability under high request rates."}}
{"id": "2504.19390", "pdf": "https://arxiv.org/pdf/2504.19390", "abs": "https://arxiv.org/abs/2504.19390", "authors": ["Jakub Zadro\u017cny", "Hakan Bilen"], "title": "HumMorph: Generalized Dynamic Human Neural Fields from Few Views", "categories": ["cs.CV"], "comment": "Project page: https://jakubzadrozny.github.io/hummorph", "summary": "We introduce HumMorph, a novel generalized approach to free-viewpoint\nrendering of dynamic human bodies with explicit pose control. HumMorph renders\na human actor in any specified pose given a few observed views (starting from\njust one) in arbitrary poses. Our method enables fast inference as it relies\nonly on feed-forward passes through the model. We first construct a coarse\nrepresentation of the actor in the canonical T-pose, which combines visual\nfeatures from individual partial observations and fills missing information\nusing learned prior knowledge. The coarse representation is complemented by\nfine-grained pixel-aligned features extracted directly from the observed views,\nwhich provide high-resolution appearance information. We show that HumMorph is\ncompetitive with the state-of-the-art when only a single input view is\navailable, however, we achieve results with significantly better visual quality\ngiven just 2 monocular observations. Moreover, previous generalized methods\nassume access to accurate body shape and pose parameters obtained using\nsynchronized multi-camera setups. In contrast, we consider a more practical\nscenario where these body parameters are noisily estimated directly from the\nobserved views. Our experimental results demonstrate that our architecture is\nmore robust to errors in the noisy parameters and clearly outperforms the state\nof the art in this setting.", "AI": {"tldr": "HumMorph is a method for free-viewpoint rendering of dynamic human bodies with pose control, using few observed views and robust to noisy pose estimates.", "motivation": "To enable high-quality rendering of human actors in any pose from limited views, addressing practical scenarios with noisy pose estimates.", "method": "Constructs a coarse canonical representation and fine-grained pixel-aligned features from observed views, using feed-forward passes for fast inference.", "result": "Competitive with state-of-the-art for single-view input and superior with two views; robust to noisy pose parameters.", "conclusion": "HumMorph advances generalized free-viewpoint rendering by improving visual quality and robustness in practical settings."}}
{"id": "2504.19284", "pdf": "https://arxiv.org/pdf/2504.19284", "abs": "https://arxiv.org/abs/2504.19284", "authors": ["Angel Mary John", "Aiswarya M. U.", "Jerrin Thomas Panachakel"], "title": "Ethical Challenges of Using Artificial Intelligence in Judiciary", "categories": ["cs.LG"], "comment": "2023 IEEE MetroXRAINE 2023", "summary": "Artificial intelligence (AI) has emerged as a ubiquitous concept in numerous\ndomains, including the legal system. AI has the potential to revolutionize the\nfunctioning of the judiciary and the dispensation of justice. Incorporating AI\ninto the legal system offers the prospect of enhancing decision-making for\njudges, lawyers, and legal professionals, while concurrently providing the\npublic with more streamlined, efficient, and cost-effective services. The\nintegration of AI into the legal landscape offers manifold benefits,\nencompassing tasks such as document review, legal research, contract analysis,\ncase prediction, and decision-making. By automating laborious and error-prone\nprocedures, AI has the capacity to alleviate the burden associated with these\narduous tasks. Consequently, courts around the world have begun embracing AI\ntechnology as a means to enhance the administration of justice. However,\nalongside its potential advantages, the use of AI in the judiciary poses a\nrange of ethical challenges. These ethical quandaries must be duly addressed to\nensure the responsible and equitable deployment of AI systems. This article\ndelineates the principal ethical challenges entailed in employing AI within the\njudiciary and provides recommendations to effectively address these issues.", "AI": {"tldr": "AI in the judiciary offers efficiency and cost benefits but raises ethical challenges that need addressing.", "motivation": "To explore AI's potential in revolutionizing the legal system while addressing its ethical implications.", "method": "Analysis of AI's role in legal tasks and identification of ethical challenges.", "result": "AI can enhance legal processes but requires ethical safeguards for responsible use.", "conclusion": "Ethical guidelines are essential for equitable AI deployment in the judiciary."}}
{"id": "2504.18858", "pdf": "https://arxiv.org/pdf/2504.18858", "abs": "https://arxiv.org/abs/2504.18858", "authors": ["Vahid Garousi"], "title": "Why you shouldn't fully trust ChatGPT: A synthesis of this AI tool's error rates across disciplines and the software engineering lifecycle", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Context: ChatGPT and other large language models (LLMs) are widely used\nacross healthcare, business, economics, engineering, and software engineering\n(SE). Despite their popularity, concerns persist about their reliability,\nespecially their error rates across domains and the software development\nlifecycle (SDLC).\n  Objective: This study synthesizes and quantifies ChatGPT's reported error\nrates across major domains and SE tasks aligned with SDLC phases. It provides\nan evidence-based view of where ChatGPT excels, where it fails, and how\nreliability varies by task, domain, and model version (GPT-3.5, GPT-4,\nGPT-4-turbo, GPT-4o).\n  Method: A Multivocal Literature Review (MLR) was conducted, gathering data\nfrom academic studies, reports, benchmarks, and grey literature up to 2025.\nFactual, reasoning, coding, and interpretive errors were considered. Data were\ngrouped by domain and SE phase and visualized using boxplots to show error\ndistributions.\n  Results: Error rates vary across domains and versions. In healthcare, rates\nranged from 8% to 83%. Business and economics saw error rates drop from ~50%\nwith GPT-3.5 to 15-20% with GPT-4. Engineering tasks averaged 20-30%.\nProgramming success reached 87.5%, though complex debugging still showed over\n50% errors. In SE, requirements and design phases showed lower error rates\n(~5-20%), while coding, testing, and maintenance phases had higher variability\n(10-50%). Upgrades from GPT-3.5 to GPT-4 improved reliability.\n  Conclusion: Despite improvements, ChatGPT still exhibits non-negligible error\nrates varying by domain, task, and SDLC phase. Full reliance without human\noversight remains risky, especially in critical settings. Continuous evaluation\nand critical validation are essential to ensure reliability and\ntrustworthiness.", "AI": {"tldr": "This study quantifies ChatGPT's error rates across domains and SE tasks, revealing variability in reliability by domain, task, and model version.", "motivation": "To assess ChatGPT's reliability and error rates across diverse domains and SE tasks, addressing concerns about its dependability.", "method": "A Multivocal Literature Review (MLR) analyzed academic and grey literature, categorizing errors by domain and SE phase, visualized with boxplots.", "result": "Error rates vary widely: healthcare (8-83%), business/economics (15-50%), engineering (20-30%), and SE phases (5-50%). GPT-4 improved reliability over GPT-3.5.", "conclusion": "ChatGPT's error rates remain significant, requiring human oversight and continuous evaluation for reliable use, especially in critical applications."}}
{"id": "2504.19898", "pdf": "https://arxiv.org/pdf/2504.19898", "abs": "https://arxiv.org/abs/2504.19898", "authors": ["Mingqian He", "Fei Zhao", "Chonggang Lu", "Ziyan Liu", "Yue Wang", "Haofu Qian"], "title": "GenCLS++: Pushing the Boundaries of Generative Classification in LLMs Through Comprehensive SFT and RL Studies Across Diverse Datasets", "categories": ["cs.CL"], "comment": null, "summary": "As a fundamental task in machine learning, text classification plays a\ncrucial role in many areas. With the rapid scaling of Large Language Models\n(LLMs), particularly through reinforcement learning (RL), there is a growing\nneed for more capable discriminators. Consequently, advances in classification\nare becoming increasingly vital for enhancing the overall capabilities of LLMs.\nTraditional discriminative methods map text to labels but overlook LLMs'\nintrinsic generative strengths. Generative classification addresses this by\nprompting the model to directly output labels. However, existing studies still\nrely on simple SFT alone, seldom probing the interplay between training and\ninference prompts, and no work has systematically leveraged RL for generative\ntext classifiers and unified SFT, RL, and inference-time prompting in one\nframework. We bridge this gap with GenCLS++, a framework that jointly optimizes\nSFT and RL while systematically exploring five high-level strategy\ndimensions-in-context learning variants, category definitions, explicit\nuncertainty labels, semantically irrelevant numeric labels, and\nperplexity-based decoding-during both training and inference. After an SFT\n\"policy warm-up,\" we apply RL with a simple rule-based reward, yielding sizable\nextra gains. Across seven datasets, GenCLS++ achieves an average accuracy\nimprovement of 3.46% relative to the naive SFT baseline; on public datasets,\nthis improvement rises to 4.00%. Notably, unlike reasoning-intensive tasks that\nbenefit from explicit thinking processes, we find that classification tasks\nperform better without such reasoning steps. These insights into the role of\nexplicit reasoning provide valuable guidance for future LLM applications.", "AI": {"tldr": "GenCLS++ introduces a framework combining SFT and RL for generative text classification, improving accuracy by 3.46% on average, and highlights the inefficacy of explicit reasoning steps in classification tasks.", "motivation": "Traditional discriminative methods underutilize LLMs' generative strengths, and existing generative classifiers lack systematic integration of SFT, RL, and inference prompting.", "method": "GenCLS++ jointly optimizes SFT and RL, exploring five strategy dimensions (e.g., in-context learning, category definitions) during training and inference.", "result": "Achieves 3.46% average accuracy improvement over SFT baselines, with 4.00% on public datasets, and shows explicit reasoning steps hinder performance.", "conclusion": "The framework advances generative text classification and provides insights into avoiding explicit reasoning for better performance in LLM applications."}}
{"id": "2504.19398", "pdf": "https://arxiv.org/pdf/2504.19398", "abs": "https://arxiv.org/abs/2504.19398", "authors": ["Shuo Wang", "Weili Shi", "Shuai Yang", "Jiahao Cui", "Qinwei Guo"], "title": "Dynamic Arthroscopic Navigation System for Anterior Cruciate Ligament Reconstruction Based on Multi-level Memory Architecture", "categories": ["cs.CV", "I.4.9; I.2.10; J.3; I.4.8; I.5.4"], "comment": "28 pages, 13 figures", "summary": "This paper presents a dynamic arthroscopic navigation system based on\nmulti-level memory architecture for anterior cruciate ligament (ACL)\nreconstruction surgery. The system extends our previously proposed markerless\nnavigation method from static image matching to dynamic video sequence\ntracking. By integrating the Atkinson-Shiffrin memory model's three-level\narchitecture (sensory memory, working memory, and long-term memory), our system\nmaintains continuous tracking of the femoral condyle throughout the surgical\nprocedure, providing stable navigation support even in complex situations\ninvolving viewpoint changes, instrument occlusion, and tissue deformation.\nUnlike existing methods, our system operates in real-time on standard\narthroscopic equipment without requiring additional tracking hardware,\nachieving 25.3 FPS with a latency of only 39.5 ms, representing a 3.5-fold\nimprovement over our previous static system. For extended sequences (1000\nframes), the dynamic system maintained an error of 5.3 plus-minus 1.5 pixels,\ncompared to the static system's 12.6 plus-minus 3.7 pixels - an improvement of\napproximately 45 percent. For medium-length sequences (500 frames) and short\nsequences (100 frames), the system achieved approximately 35 percent and 19\npercent accuracy improvements, respectively. Experimental results demonstrate\nthe system overcomes limitations of traditional static matching methods,\nproviding new technical support for improving surgical precision in ACL\nreconstruction.", "AI": {"tldr": "A dynamic arthroscopic navigation system for ACL surgery improves tracking accuracy and speed by integrating a multi-level memory architecture, outperforming static methods.", "motivation": "To enhance surgical precision in ACL reconstruction by overcoming limitations of static image matching with a dynamic, real-time tracking system.", "method": "Extends markerless navigation to dynamic video tracking using the Atkinson-Shiffrin memory model (sensory, working, long-term memory) for continuous femoral condyle tracking.", "result": "Achieves 25.3 FPS with 39.5 ms latency, reducing tracking error by ~45% (5.3\u00b11.5 pixels vs. 12.6\u00b13.7 pixels) in long sequences.", "conclusion": "The system provides stable, real-time navigation without extra hardware, significantly improving surgical precision in ACL reconstruction."}}
{"id": "2504.19353", "pdf": "https://arxiv.org/pdf/2504.19353", "abs": "https://arxiv.org/abs/2504.19353", "authors": ["Weitao Du", "Shuning Chang", "Jiasheng Tang", "Yu Rong", "Fan Wang", "Shengchao Liu"], "title": "Flow Along the K-Amplitude for Generative Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we propose a novel generative learning paradigm, K-Flow, an\nalgorithm that flows along the $K$-amplitude. Here, $k$ is a scaling parameter\nthat organizes frequency bands (or projected coefficients), and amplitude\ndescribes the norm of such projected coefficients. By incorporating the\n$K$-amplitude decomposition, K-Flow enables flow matching across the scaling\nparameter as time. We discuss three venues and six properties of K-Flow, from\ntheoretical foundations, energy and temporal dynamics, and practical\napplications, respectively. Specifically, from the practical usage perspective,\nK-Flow allows steerable generation by controlling the information at different\nscales. To demonstrate the effectiveness of K-Flow, we conduct experiments on\nunconditional image generation, class-conditional image generation, and\nmolecule assembly generation. Additionally, we conduct three ablation studies\nto demonstrate how K-Flow steers scaling parameter to effectively control the\nresolution of image generation.", "AI": {"tldr": "K-Flow is a generative learning algorithm that uses a scaling parameter (K) to organize frequency bands, enabling flow matching and steerable generation across scales.", "motivation": "To address the challenge of controlling information at different scales in generative models, K-Flow introduces a novel paradigm for steerable generation.", "method": "K-Flow incorporates K-amplitude decomposition to enable flow matching across scaling parameters, with theoretical, dynamic, and practical properties explored.", "result": "Experiments on image and molecule generation show K-Flow's effectiveness, with ablation studies confirming its ability to control resolution via scaling parameters.", "conclusion": "K-Flow provides a scalable and steerable generative framework, validated by its performance in diverse generation tasks."}}
{"id": "2504.18902", "pdf": "https://arxiv.org/pdf/2504.18902", "abs": "https://arxiv.org/abs/2504.18902", "authors": ["Cyril Shih-Huan Hsu", "Anestis Dalgkitsis", "Chrysa Papagianni", "Paola Grosso"], "title": "Transformer-Empowered Actor-Critic Reinforcement Learning for Sequence-Aware Service Function Chain Partitioning", "categories": ["cs.NI", "cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "In the forthcoming era of 6G networks, characterized by unprecedented data\nrates, ultra-low latency, and extensive connectivity, effective management of\nVirtualized Network Functions (VNFs) is essential. VNFs are software-based\ncounterparts of traditional hardware devices that facilitate flexible and\nscalable service provisioning. Service Function Chains (SFCs), structured as\nordered sequences of VNFs, are pivotal in orchestrating complex network\nservices. Nevertheless, partitioning SFCs across multi-domain network\ninfrastructures presents substantial challenges due to stringent latency\nconstraints and limited resource availability. Conventional optimization-based\nmethods typically exhibit low scalability, whereas existing data-driven\napproaches often fail to adequately balance computational efficiency with the\ncapability to effectively account for dependencies inherent in SFCs. To\novercome these limitations, we introduce a Transformer-empowered actor-critic\nframework specifically designed for sequence-aware SFC partitioning. By\nutilizing the self-attention mechanism, our approach effectively models complex\ninter-dependencies among VNFs, facilitating coordinated and parallelized\ndecision-making processes. Additionally, we enhance training stability and\nconvergence using $\\epsilon$-LoPe exploration strategy as well as Asymptotic\nReturn Normalization. Comprehensive simulation results demonstrate that the\nproposed methodology outperforms existing state-of-the-art solutions in terms\nof long-term acceptance rates, resource utilization efficiency, and\nscalability, while achieving rapid inference. This study not only advances\nintelligent network orchestration by delivering a scalable and robust solution\nfor SFC partitioning within emerging 6G environments, but also bridging recent\nadvancements in Large Language Models (LLMs) with the optimization of\nnext-generation networks.", "AI": {"tldr": "A Transformer-empowered actor-critic framework is proposed for efficient SFC partitioning in 6G networks, outperforming existing methods in scalability and performance.", "motivation": "Effective VNF management in 6G networks is challenged by latency constraints and resource limitations, requiring scalable and dependency-aware solutions.", "method": "A Transformer-based actor-critic framework with self-attention and enhanced training strategies (\u03b5-LoPe exploration, Asymptotic Return Normalization).", "result": "Outperforms state-of-the-art in acceptance rates, resource efficiency, scalability, and inference speed.", "conclusion": "Advances intelligent network orchestration in 6G by combining LLM advancements with network optimization."}}
{"id": "2504.19982", "pdf": "https://arxiv.org/pdf/2504.19982", "abs": "https://arxiv.org/abs/2504.19982", "authors": ["Emre Can Acikgoz", "Carl Guo", "Suvodip Dey", "Akul Datta", "Takyoung Kim", "Gokhan Tur", "Dilek Hakkani-T\u00fcr"], "title": "TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Task-oriented dialogue (TOD) systems are experiencing a revolution driven by\nLarge Language Models (LLMs), yet the evaluation methodologies for these\nsystems remain insufficient for their growing sophistication. While traditional\nautomatic metrics effectively assessed earlier modular systems, they focus\nsolely on the dialogue level and cannot detect critical intermediate errors\nthat can arise during user-agent interactions. In this paper, we introduce\nTD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework\nthat unifies fine-grained turn-level analysis with holistic dialogue-level\ncomparisons. At turn level, we evaluate each response along three TOD-specific\ndimensions: conversation cohesion, backend knowledge consistency, and policy\ncompliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons\nto provide a measure of dialogue-level quality. Through experiments on MultiWOZ\n2.4 and {\\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the\nconversational errors that conventional metrics miss. Furthermore, TD-EVAL\nexhibits better alignment with human judgments than traditional and LLM-based\nmetrics. These findings demonstrate that TD-EVAL introduces a new paradigm for\nTOD system evaluation, efficiently assessing both turn and system levels with a\nplug-and-play framework for future research.", "AI": {"tldr": "TD-EVAL is a two-step evaluation framework for task-oriented dialogue systems, combining turn-level and dialogue-level analysis to improve error detection and alignment with human judgments.", "motivation": "Traditional metrics for TOD systems are insufficient for modern LLM-driven systems, lacking granularity to detect intermediate errors.", "method": "TD-EVAL evaluates turn-level responses on three dimensions (conversation cohesion, backend knowledge consistency, policy compliance) and uses TOD Agent Arena for dialogue-level pairwise comparisons.", "result": "TD-EVAL outperforms conventional and LLM-based metrics in identifying conversational errors and aligns better with human judgments.", "conclusion": "TD-EVAL offers a plug-and-play framework for comprehensive TOD system evaluation, addressing gaps in current methodologies."}}
{"id": "2504.19402", "pdf": "https://arxiv.org/pdf/2504.19402", "abs": "https://arxiv.org/abs/2504.19402", "authors": ["Khoa Tuan Nguyen", "Francesca Tozzi", "Wouter Willaert", "Joris Vankerschaver", "Nikdokht Rashidian", "Wesley De Neve"], "title": "Boosting 3D Liver Shape Datasets with Diffusion Models and Implicit Neural Representations", "categories": ["cs.CV"], "comment": null, "summary": "While the availability of open 3D medical shape datasets is increasing,\noffering substantial benefits to the research community, we have found that\nmany of these datasets are, unfortunately, disorganized and contain artifacts.\nThese issues limit the development and training of robust models, particularly\nfor accurate 3D reconstruction tasks. In this paper, we examine the current\nstate of available 3D liver shape datasets and propose a solution using\ndiffusion models combined with implicit neural representations (INRs) to\naugment and expand existing datasets. Our approach utilizes the generative\ncapabilities of diffusion models to create realistic, diverse 3D liver shapes,\ncapturing a wide range of anatomical variations and addressing the problem of\ndata scarcity. Experimental results indicate that our method enhances dataset\ndiversity, providing a scalable solution to improve the accuracy and\nreliability of 3D liver reconstruction and generation in medical applications.\nFinally, we suggest that diffusion models can also be applied to other\ndownstream tasks in 3D medical imaging.", "AI": {"tldr": "The paper addresses disorganization and artifacts in open 3D medical shape datasets by proposing a diffusion model and implicit neural representation (INR) solution to augment liver datasets, improving diversity and model robustness.", "motivation": "Existing 3D liver shape datasets are disorganized and contain artifacts, hindering robust model training for accurate 3D reconstruction tasks.", "method": "Uses diffusion models combined with implicit neural representations (INRs) to generate realistic, diverse 3D liver shapes, addressing data scarcity.", "result": "The method enhances dataset diversity, improving accuracy and reliability in 3D liver reconstruction and generation.", "conclusion": "Diffusion models can also benefit other downstream tasks in 3D medical imaging."}}
{"id": "2504.19374", "pdf": "https://arxiv.org/pdf/2504.19374", "abs": "https://arxiv.org/abs/2504.19374", "authors": ["Suping Xu", "Chuyi Dai", "Lin Shang", "Changbin Shao", "Xibei Yang", "Witold Pedrycz"], "title": "Rethinking Label-specific Features for Label Distribution Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "11 Pages, 5 figures", "summary": "Label distribution learning (LDL) is an emerging learning paradigm designed\nto capture the relative importance of labels for each instance. Label-specific\nfeatures (LSFs), constructed by LIFT, have proven effective for learning tasks\nwith label ambiguity by leveraging clustering-based prototypes for each label\nto re-characterize instances. However, directly introducing LIFT into LDL tasks\ncan be suboptimal, as the prototypes it collects primarily reflect\nintra-cluster relationships while neglecting interactions among distinct\nclusters. Additionally, constructing LSFs using multi-perspective information,\nrather than relying solely on Euclidean distance, provides a more robust and\ncomprehensive representation of instances, mitigating noise and bias that may\narise from a single distance perspective. To address these limitations, we\nintroduce Structural Anchor Points (SAPs) to capture inter-cluster\ninteractions. This leads to a novel LSFs construction strategy, LIFT-SAP, which\nenhances LIFT by integrating both distance and direction information of each\ninstance relative to SAPs. Furthermore, we propose a novel LDL algorithm, Label\nDistribution Learning via Label-specifIc FeaTure with SAPs (LDL-LIFT-SAP),\nwhich unifies multiple label description degrees predicted from different LSF\nspaces into a cohesive label distribution. Extensive experiments on 15\nreal-world datasets demonstrate the effectiveness of LIFT-SAP over LIFT, as\nwell as the superiority of LDL-LIFT-SAP compared to seven other\nwell-established algorithms.", "AI": {"tldr": "The paper introduces LIFT-SAP, an enhanced method for label distribution learning (LDL) that improves upon LIFT by incorporating Structural Anchor Points (SAPs) to capture inter-cluster interactions and multi-perspective information. The proposed LDL-LIFT-SAP algorithm outperforms existing methods.", "motivation": "Existing LIFT methods for LDL focus on intra-cluster relationships, neglecting inter-cluster interactions and relying solely on Euclidean distance, which can introduce noise and bias.", "method": "The authors propose LIFT-SAP, which uses SAPs to capture inter-cluster interactions and integrates distance and direction information for robust label-specific features (LSFs). They also introduce LDL-LIFT-SAP, unifying multiple label descriptions into a cohesive distribution.", "result": "Experiments on 15 datasets show LIFT-SAP outperforms LIFT, and LDL-LIFT-SAP surpasses seven other algorithms.", "conclusion": "LIFT-SAP and LDL-LIFT-SAP provide more accurate and robust LDL by addressing limitations of existing methods, demonstrating superior performance."}}
{"id": "2504.18916", "pdf": "https://arxiv.org/pdf/2504.18916", "abs": "https://arxiv.org/abs/2504.18916", "authors": ["Sarang S", "Druva Dhakshinamoorthy", "Aditya Shiva Sharma", "Yuvraj Singh Bhadauria", "Siddharth Chaitra Vivek", "Arihant Bansal", "Arnab K. Paul"], "title": "UnifyFL: Enabling Decentralized Cross-Silo Federated Learning", "categories": ["cs.DC", "cs.AI"], "comment": "12 pages, 7 figures, 7 tables. Accepted at the 26th ACM/IFIP\n  International Middleware Conference (MIDDLEWARE 2025)", "summary": "Federated Learning (FL) is a decentralized machine learning (ML) paradigm in\nwhich models are trained on private data across several devices called clients\nand combined at a single node called an aggregator rather than aggregating the\ndata itself. Many organizations employ FL to have better privacy-aware\nML-driven decision-making capabilities. However, organizations often operate\nindependently rather than collaborate to enhance their FL capabilities due to\nthe lack of an effective mechanism for collaboration. The challenge lies in\nbalancing trust and resource efficiency. One approach relies on trusting a\nthird-party aggregator to consolidate models from all organizations (multilevel\nFL), but this requires trusting an entity that may be biased or unreliable.\nAlternatively, organizations can bypass a third party by sharing their local\nmodels directly, which requires significant computational resources for\nvalidation. Both approaches reflect a fundamental trade-off between trust and\nresource constraints, with neither offering an ideal solution. In this work, we\ndevelop a trust-based cross-silo FL framework called \\proj, which uses\ndecentralized orchestration and distributed storage. \\proj provides flexibility\nto the participating organizations and presents synchronous and asynchronous\nmodes to handle stragglers. Our evaluation on a diverse testbed shows that\n\\proj achieves a performance comparable to the ideal multilevel centralized FL\nwhile allowing trust and optimal use of resources.", "AI": {"tldr": "The paper introduces a trust-based cross-silo federated learning framework, \\proj, addressing the trade-off between trust and resource efficiency in collaborative FL.", "motivation": "Organizations struggle to collaborate in FL due to trust and resource constraints, lacking an effective mechanism for decentralized cooperation.", "method": "Develops \\proj, a framework using decentralized orchestration and distributed storage, offering synchronous and asynchronous modes for straggler handling.", "result": "Evaluation shows \\proj performs comparably to centralized FL while optimizing trust and resource use.", "conclusion": "\\proj provides a flexible, efficient solution for cross-silo FL, balancing trust and resource constraints."}}
{"id": "2504.20000", "pdf": "https://arxiv.org/pdf/2504.20000", "abs": "https://arxiv.org/abs/2504.20000", "authors": ["Rishika Sen", "Sujoy Roychowdhury", "Sumit Soman", "H. G. Ranjani", "Srikhetra Mohanty"], "title": "Knowledge Distillation of Domain-adapted LLMs for Question-Answering in Telecom", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T50", "I.2.7"], "comment": "10 pages, 4 figures, 3 tables", "summary": "Knowledge Distillation (KD) is one of the approaches to reduce the size of\nLarge Language Models (LLMs). A LLM with smaller number of model parameters\n(student) is trained to mimic the performance of a LLM of a larger size\n(teacher model) on a specific task. For domain-specific tasks, it is not clear\nif teacher or student model, or both, must be considered for domain adaptation.\nIn this work, we study this problem from perspective of telecom domain\nQuestion-Answering (QA) task. We systematically experiment with Supervised\nFine-tuning (SFT) of teacher only, SFT of student only and SFT of both prior to\nKD. We design experiments to study the impact of vocabulary (same and\ndifferent) and KD algorithms (vanilla KD and Dual Space KD, DSKD) on the\ndistilled model. Multi-faceted evaluation of the distillation using 14\ndifferent metrics (N-gram, embedding and LLM-based metrics) is considered.\nExperimental results show that SFT of teacher improves performance of distilled\nmodel when both models have same vocabulary, irrespective of algorithm and\nmetrics. Overall, SFT of both teacher and student results in better performance\nacross all metrics, although the statistical significance of the same depends\non the vocabulary of the teacher models.", "AI": {"tldr": "The paper explores Knowledge Distillation (KD) for domain-specific tasks in telecom QA, comparing SFT of teacher, student, or both, and the impact of vocabulary and KD algorithms.", "motivation": "To determine the best approach for domain adaptation in KD for telecom QA tasks, considering the roles of teacher and student models.", "method": "Systematic experiments with SFT of teacher, student, or both, varying vocabulary and KD algorithms (vanilla KD and DSKD), evaluated using 14 metrics.", "result": "SFT of teacher improves performance when vocabularies match; SFT of both models yields the best results, though significance varies with teacher vocabulary.", "conclusion": "SFT of both teacher and student before KD is optimal for telecom QA, with vocabulary alignment playing a key role in performance."}}
{"id": "2504.19414", "pdf": "https://arxiv.org/pdf/2504.19414", "abs": "https://arxiv.org/abs/2504.19414", "authors": ["Sehyeong Jo", "Gangjae Jang", "Haesol Park"], "title": "GMAR: Gradient-Driven Multi-Head Attention Rollout for Vision Transformer Interpretability", "categories": ["cs.CV"], "comment": null, "summary": "The Vision Transformer (ViT) has made significant advancements in computer\nvision, utilizing self-attention mechanisms to achieve state-of-the-art\nperformance across various tasks, including image classification, object\ndetection, and segmentation. Its architectural flexibility and capabilities\nhave made it a preferred choice among researchers and practitioners. However,\nthe intricate multi-head attention mechanism of ViT presents significant\nchallenges to interpretability, as the underlying prediction process remains\nopaque. A critical limitation arises from an observation commonly noted in\ntransformer architectures: \"Not all attention heads are equally meaningful.\"\nOverlooking the relative importance of specific heads highlights the\nlimitations of existing interpretability methods. To address these challenges,\nwe introduce Gradient-Driven Multi-Head Attention Rollout (GMAR), a novel\nmethod that quantifies the importance of each attention head using\ngradient-based scores. These scores are normalized to derive a weighted\naggregate attention score, effectively capturing the relative contributions of\nindividual heads. GMAR clarifies the role of each head in the prediction\nprocess, enabling more precise interpretability at the head level. Experimental\nresults demonstrate that GMAR consistently outperforms traditional attention\nrollout techniques. This work provides a practical contribution to\ntransformer-based architectures, establishing a robust framework for enhancing\nthe interpretability of Vision Transformer models.", "AI": {"tldr": "GMAR improves ViT interpretability by quantifying attention head importance using gradient-based scores, outperforming traditional methods.", "motivation": "ViT's multi-head attention lacks interpretability, with some heads being more meaningful than others, highlighting the need for better interpretability methods.", "method": "Introduces GMAR, which uses gradient-based scores to quantify and normalize the importance of each attention head for clearer interpretability.", "result": "GMAR consistently outperforms traditional attention rollout techniques, providing precise head-level interpretability.", "conclusion": "GMAR enhances ViT interpretability, offering a robust framework for understanding transformer-based models."}}
{"id": "2504.19375", "pdf": "https://arxiv.org/pdf/2504.19375", "abs": "https://arxiv.org/abs/2504.19375", "authors": ["Siddharth Chandak"], "title": "$O(1/k)$ Finite-Time Bound for Non-Linear Two-Time-Scale Stochastic Approximation", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "comment": "Submitted to IEEE Transactions on Automatic Control", "summary": "Two-time-scale stochastic approximation is an algorithm with coupled\niterations which has found broad applications in reinforcement learning,\noptimization and game control. While several prior works have obtained a mean\nsquare error bound of $O(1/k)$ for linear two-time-scale iterations, the best\nknown bound in the non-linear contractive setting has been $O(1/k^{2/3})$. In\nthis work, we obtain an improved bound of $O(1/k)$ for non-linear\ntwo-time-scale stochastic approximation. Our result applies to algorithms such\nas gradient descent-ascent and two-time-scale Lagrangian optimization. The key\nstep in our analysis involves rewriting the original iteration in terms of an\naveraged noise sequence which decays sufficiently fast. Additionally, we use an\ninduction-based approach to show that the iterates are bounded in expectation.", "AI": {"tldr": "Improved $O(1/k)$ bound for non-linear two-time-scale stochastic approximation, surpassing the previous $O(1/k^{2/3})$ bound.", "motivation": "Address the gap in performance bounds for non-linear two-time-scale stochastic approximation, which has applications in reinforcement learning, optimization, and game control.", "method": "Rewrite the iteration using an averaged noise sequence with fast decay and use an induction-based approach to bound iterates in expectation.", "result": "Achieved an improved $O(1/k)$ bound for non-linear settings, applicable to algorithms like gradient descent-ascent and Lagrangian optimization.", "conclusion": "The work provides a tighter performance bound for non-linear two-time-scale stochastic approximation, enhancing its theoretical foundation."}}
{"id": "2504.18919", "pdf": "https://arxiv.org/pdf/2504.18919", "abs": "https://arxiv.org/abs/2504.18919", "authors": ["Andrew M. Bean", "Rebecca Payne", "Guy Parsons", "Hannah Rose Kirk", "Juan Ciro", "Rafael Mosquera", "Sara Hincapi\u00e9 Monsalve", "Aruna S. Ekanayaka", "Lionel Tarassenko", "Luc Rocher", "Adam Mahdi"], "title": "Clinical knowledge in LLMs does not translate to human interactions", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "52 pages, 4 figures", "summary": "Global healthcare providers are exploring use of large language models (LLMs)\nto provide medical advice to the public. LLMs now achieve nearly perfect scores\non medical licensing exams, but this does not necessarily translate to accurate\nperformance in real-world settings. We tested if LLMs can assist members of the\npublic in identifying underlying conditions and choosing a course of action\n(disposition) in ten medical scenarios in a controlled study with 1,298\nparticipants. Participants were randomly assigned to receive assistance from an\nLLM (GPT-4o, Llama 3, Command R+) or a source of their choice (control). Tested\nalone, LLMs complete the scenarios accurately, correctly identifying conditions\nin 94.9% of cases and disposition in 56.3% on average. However, participants\nusing the same LLMs identified relevant conditions in less than 34.5% of cases\nand disposition in less than 44.2%, both no better than the control group. We\nidentify user interactions as a challenge to the deployment of LLMs for medical\nadvice. Standard benchmarks for medical knowledge and simulated patient\ninteractions do not predict the failures we find with human participants.\nMoving forward, we recommend systematic human user testing to evaluate\ninteractive capabilities prior to public deployments in healthcare.", "AI": {"tldr": "LLMs perform well in medical scenarios alone but fail to improve accuracy when assisting users, highlighting the need for human testing before deployment.", "motivation": "To assess if LLMs can effectively assist the public in identifying medical conditions and choosing actions, given their high performance on exams.", "method": "Controlled study with 1,298 participants using LLMs (GPT-4o, Llama 3, Command R+) or a control source in ten medical scenarios.", "result": "LLMs alone achieved 94.9% accuracy in identifying conditions and 56.3% in disposition, but user-assisted performance dropped below 34.5% and 44.2%, matching the control group.", "conclusion": "User interaction challenges LLM deployment for medical advice; human testing is recommended before public use."}}
{"id": "2504.20013", "pdf": "https://arxiv.org/pdf/2504.20013", "abs": "https://arxiv.org/abs/2504.20013", "authors": ["Beizhe Hu", "Qiang Sheng", "Juan Cao", "Yang Li", "Danding Wang"], "title": "LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation", "categories": ["cs.CL", "cs.CY", "cs.IR"], "comment": "ACM SIGIR 2025 Full Paper", "summary": "Online fake news moderation now faces a new challenge brought by the\nmalicious use of large language models (LLMs) in fake news production. Though\nexisting works have shown LLM-generated fake news is hard to detect from an\nindividual aspect, it remains underexplored how its large-scale release will\nimpact the news ecosystem. In this study, we develop a simulation pipeline and\na dataset with ~56k generated news of diverse types to investigate the effects\nof LLM-generated fake news within neural news recommendation systems. Our\nfindings expose a truth decay phenomenon, where real news is gradually losing\nits advantageous position in news ranking against fake news as LLM-generated\nnews is involved in news recommendation. We further provide an explanation\nabout why truth decay occurs from a familiarity perspective and show the\npositive correlation between perplexity and news ranking. Finally, we discuss\nthe threats of LLM-generated fake news and provide possible countermeasures. We\nurge stakeholders to address this emerging challenge to preserve the integrity\nof news ecosystems.", "AI": {"tldr": "The study explores the impact of LLM-generated fake news on neural news recommendation systems, revealing a 'truth decay' phenomenon where fake news gains advantage over real news. It also suggests countermeasures to address this threat.", "motivation": "The rise of LLM-generated fake news poses a new challenge to online moderation, and its large-scale impact on the news ecosystem is underexplored.", "method": "A simulation pipeline and a dataset of ~56k diverse LLM-generated news items were used to study effects on neural news recommendation systems.", "result": "Findings show 'truth decay,' where fake news outperforms real news in rankings, with perplexity positively correlating to ranking.", "conclusion": "The study highlights the threat of LLM-generated fake news and calls for stakeholder action to protect news ecosystem integrity."}}
{"id": "2504.19417", "pdf": "https://arxiv.org/pdf/2504.19417", "abs": "https://arxiv.org/abs/2504.19417", "authors": ["Dehao Yuan", "Cornelia Ferm\u00fcller"], "title": "A Real-Time Event-Based Normal Flow Estimator", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents a real-time, asynchronous, event-based normal flow\nestimator. It follows the same algorithm as Learning Normal Flow Directly From\nEvent Neighborhoods, but with a more optimized implementation. The original\nmethod treats event slices as 3D point clouds, encodes each event's local\ngeometry into a fixed-length vector, and uses a multi-layer perceptron to\npredict normal flow. It constructs representations by multiplying an adjacency\nmatrix with a feature matrix, resulting in quadratic time complexity with\nrespect to the number of events. In contrast, we leverage the fact that event\ncoordinates are integers and reformulate the representation step as a pooling\noperation. This achieves the same effect as the adjacency matrix but with much\nlower computational cost. As a result, our method supports real-time normal\nflow prediction on event cameras. Our estimator uses 1 GB of CUDA memory and\nruns at 4 million normal flows per second on an RTX 3070, or 6 million per\nsecond on an RTX A5000. We release the CUDA implementation along with a Python\ninterface at https://github.com/dhyuan99/VecKM_flow_cpp.", "AI": {"tldr": "The paper introduces a real-time, asynchronous, event-based normal flow estimator with an optimized implementation, reducing computational cost while maintaining accuracy.", "motivation": "To improve the efficiency of normal flow prediction for event cameras by optimizing the computational process.", "method": "Reformulates the representation step as a pooling operation, leveraging integer event coordinates to reduce time complexity.", "result": "Achieves real-time performance with 4-6 million normal flows per second on GPUs, using only 1 GB of CUDA memory.", "conclusion": "The optimized method enables efficient real-time normal flow prediction and is made publicly available."}}
{"id": "2504.19382", "pdf": "https://arxiv.org/pdf/2504.19382", "abs": "https://arxiv.org/abs/2504.19382", "authors": ["Jonathan Gornet", "Yiannis Kantaros", "Bruno Sinopoli"], "title": "HyperController: A Hyperparameter Controller for Fast and Stable Training of Reinforcement Learning Neural Networks", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "We introduce Hyperparameter Controller (HyperController), a computationally\nefficient algorithm for hyperparameter optimization during training of\nreinforcement learning neural networks. HyperController optimizes\nhyperparameters quickly while also maintaining improvement of the reinforcement\nlearning neural network, resulting in faster training and deployment. It\nachieves this by modeling the hyperparameter optimization problem as an unknown\nLinear Gaussian Dynamical System, which is a system with a state that linearly\nchanges. It then learns an efficient representation of the hyperparameter\nobjective function using the Kalman filter, which is the optimal one-step\npredictor for a Linear Gaussian Dynamical System. To demonstrate the\nperformance of HyperController, it is applied as a hyperparameter optimizer\nduring training of reinforcement learning neural networks on a variety of\nOpenAI Gymnasium environments. In four out of the five Gymnasium environments,\nHyperController achieves highest median reward during evaluation compared to\nother algorithms. The results exhibit the potential of HyperController for\nefficient and stable training of reinforcement learning neural networks.", "AI": {"tldr": "HyperController is an efficient algorithm for hyperparameter optimization in reinforcement learning, using a Linear Gaussian Dynamical System and Kalman filter to achieve faster training and better performance.", "motivation": "To improve hyperparameter optimization efficiency and stability in reinforcement learning neural networks.", "method": "Models hyperparameter optimization as a Linear Gaussian Dynamical System and uses the Kalman filter for efficient representation.", "result": "Outperforms other algorithms in 4 out of 5 OpenAI Gymnasium environments, achieving higher median rewards.", "conclusion": "HyperController shows promise for efficient and stable reinforcement learning training."}}
{"id": "2504.18931", "pdf": "https://arxiv.org/pdf/2504.18931", "abs": "https://arxiv.org/abs/2504.18931", "authors": ["Dianwei Chen", "Yaobang Gong", "Xianfeng Yang"], "title": "Advanced Longitudinal Control and Collision Avoidance for High-Risk Edge Cases in Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Advanced Driver Assistance Systems (ADAS) and Advanced Driving Systems (ADS)\nare key to improving road safety, yet most existing implementations focus\nprimarily on the vehicle ahead, neglecting the behavior of following vehicles.\nThis shortfall often leads to chain reaction collisions in high speed, densely\nspaced traffic particularly when a middle vehicle suddenly brakes and trailing\nvehicles cannot respond in time. To address this critical gap, we propose a\nnovel longitudinal control and collision avoidance algorithm that integrates\nadaptive cruising with emergency braking. Leveraging deep reinforcement\nlearning, our method simultaneously accounts for both leading and following\nvehicles. Through a data preprocessing framework that calibrates real-world\nsensor data, we enhance the robustness and reliability of the training process,\nensuring the learned policy can handle diverse driving conditions. In simulated\nhigh risk scenarios (e.g., emergency braking in dense traffic), the algorithm\neffectively prevents potential pile up collisions, even in situations involving\nheavy duty vehicles. Furthermore, in typical highway scenarios where three\nvehicles decelerate, the proposed DRL approach achieves a 99% success rate far\nsurpassing the standard Federal Highway Administration speed concepts guide,\nwhich reaches only 36.77% success under the same conditions.", "AI": {"tldr": "A novel longitudinal control and collision avoidance algorithm using deep reinforcement learning (DRL) improves road safety by considering both leading and following vehicles, outperforming existing standards.", "motivation": "Existing ADAS/ADS systems focus on the vehicle ahead, neglecting trailing vehicles, leading to chain collisions in dense traffic.", "method": "Proposes a DRL-based algorithm integrating adaptive cruising and emergency braking, using preprocessed real-world sensor data for training.", "result": "The algorithm prevents pile-up collisions in high-risk scenarios and achieves a 99% success rate in typical highway deceleration, surpassing the 36.77% success rate of standard methods.", "conclusion": "The proposed DRL approach significantly enhances collision avoidance in dense traffic, offering a robust solution for improving road safety."}}
{"id": "2504.20022", "pdf": "https://arxiv.org/pdf/2504.20022", "abs": "https://arxiv.org/abs/2504.20022", "authors": ["Pritika Rohera", "Chaitrali Ginimav", "Gayatri Sawant", "Raviraj Joshi"], "title": "Better To Ask in English? Evaluating Factual Accuracy of Multilingual LLMs in English and Low-Resource Languages", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multilingual Large Language Models (LLMs) have demonstrated significant\neffectiveness across various languages, particularly in high-resource languages\nsuch as English. However, their performance in terms of factual accuracy across\nother low-resource languages, especially Indic languages, remains an area of\ninvestigation. In this study, we assess the factual accuracy of LLMs - GPT-4o,\nGemma-2-9B, Gemma-2-2B, and Llama-3.1-8B - by comparing their performance in\nEnglish and Indic languages using the IndicQuest dataset, which contains\nquestion-answer pairs in English and 19 Indic languages. By asking the same\nquestions in English and their respective Indic translations, we analyze\nwhether the models are more reliable for regional context questions in Indic\nlanguages or when operating in English. Our findings reveal that LLMs often\nperform better in English, even for questions rooted in Indic contexts.\nNotably, we observe a higher tendency for hallucination in responses generated\nin low-resource Indic languages, highlighting challenges in the multilingual\nunderstanding capabilities of current LLMs.", "AI": {"tldr": "LLMs like GPT-4o and Gemma perform better in English than Indic languages, with higher hallucination rates in low-resource Indic languages.", "motivation": "To evaluate the factual accuracy of multilingual LLMs in English and Indic languages, focusing on regional context questions.", "method": "Assessed LLMs (GPT-4o, Gemma-2-9B, Gemma-2-2B, Llama-3.1-8B) using the IndicQuest dataset with Q&A pairs in English and 19 Indic languages.", "result": "LLMs perform better in English, even for Indic context questions, with more hallucinations in low-resource Indic languages.", "conclusion": "Current LLMs face challenges in multilingual understanding, especially for low-resource languages like Indic languages."}}
{"id": "2504.19432", "pdf": "https://arxiv.org/pdf/2504.19432", "abs": "https://arxiv.org/abs/2504.19432", "authors": ["Zhe Dong", "Yuzhe Sun", "Tianzhu Liu", "Wangmeng Zuo", "Yanfeng Gu"], "title": "EarthMapper: Visual Autoregressive Models for Controllable Bidirectional Satellite-Map Translation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Satellite imagery and maps, as two fundamental data modalities in remote\nsensing, offer direct observations of the Earth's surface and\nhuman-interpretable geographic abstractions, respectively. The task of\nbidirectional translation between satellite images and maps (BSMT) holds\nsignificant potential for applications in urban planning and disaster response.\nHowever, this task presents two major challenges: first, the absence of precise\npixel-wise alignment between the two modalities substantially complicates the\ntranslation process; second, it requires achieving both high-level abstraction\nof geographic features and high-quality visual synthesis, which further\nelevates the technical complexity. To address these limitations, we introduce\nEarthMapper, a novel autoregressive framework for controllable bidirectional\nsatellite-map translation. EarthMapper employs geographic coordinate embeddings\nto anchor generation, ensuring region-specific adaptability, and leverages\nmulti-scale feature alignment within a geo-conditioned joint scale\nautoregression (GJSA) process to unify bidirectional translation in a single\ntraining cycle. A semantic infusion (SI) mechanism is introduced to enhance\nfeature-level consistency, while a key point adaptive guidance (KPAG) mechanism\nis proposed to dynamically balance diversity and precision during inference. We\nfurther contribute CNSatMap, a large-scale dataset comprising 302,132 precisely\naligned satellite-map pairs across 38 Chinese cities, enabling robust\nbenchmarking. Extensive experiments on CNSatMap and the New York dataset\ndemonstrate EarthMapper's superior performance, achieving significant\nimprovements in visual realism, semantic consistency, and structural fidelity\nover state-of-the-art methods. Additionally, EarthMapper excels in zero-shot\ntasks like in-painting, out-painting and coordinate-conditional generation,\nunderscoring its versatility.", "AI": {"tldr": "EarthMapper is an autoregressive framework for bidirectional satellite-map translation, addressing alignment and abstraction challenges with novel mechanisms and a large dataset.", "motivation": "The bidirectional translation between satellite images and maps (BSMT) is valuable for urban planning and disaster response but faces challenges like misalignment and the need for high-level abstraction and visual synthesis.", "method": "EarthMapper uses geographic coordinate embeddings, multi-scale feature alignment (GJSA), semantic infusion (SI), and key point adaptive guidance (KPAG) for controllable translation.", "result": "EarthMapper outperforms state-of-the-art methods in visual realism, semantic consistency, and structural fidelity, and excels in zero-shot tasks.", "conclusion": "EarthMapper is a versatile and effective solution for BSMT, demonstrated by its performance on the CNSatMap and New York datasets."}}
{"id": "2504.19391", "pdf": "https://arxiv.org/pdf/2504.19391", "abs": "https://arxiv.org/abs/2504.19391", "authors": ["David Warren", "Mark Dras"], "title": "Bi-directional Model Cascading with Proxy Confidence", "categories": ["cs.LG"], "comment": null, "summary": "Model Cascading, recently applied successfully to LLMs, is a simple but\npowerful technique that improves the efficiency of inference by selectively\napplying models of varying sizes. Models are used in sequence from smallest to\nlargest, only deferring samples to large, costly models when smaller models are\nnot sufficiently confident. Existing approaches to deferral use only limited\nsmall model confidence estimates because of the inaccessibility of the large\nmodel, although large model confidence is known to be important. We therefore\npropose a bi-directional approach to deferral that considers the confidence of\nsmall and large models in the cascade simultaneously through the use of a proxy\nfor the large model. This requires a richer representation of model confidence\nto enable comparative calibration: we use an analysis of hidden states to\nimprove post-invocation confidence of the small model, which in itself improves\ncascading results over prior approaches. We then combine this with a tiny proxy\nmodel to estimate pre-invocation confidence of the large model. We examine the\nproposed cascading system over challenging, multiple-choice datasets, finding\nimprovements over standard cascading baselines reflected in reductions in\ndeferrals to more costly models.", "AI": {"tldr": "A bi-directional model cascading approach improves efficiency by using small and large model confidence simultaneously, reducing costly deferrals.", "motivation": "Existing cascading methods lack large model confidence, limiting efficiency.", "method": "Uses hidden state analysis for small model confidence and a proxy for large model confidence.", "result": "Reduces deferrals to costly models, improving efficiency.", "conclusion": "Bi-directional cascading with richer confidence representation outperforms standard methods."}}
{"id": "2504.18932", "pdf": "https://arxiv.org/pdf/2504.18932", "abs": "https://arxiv.org/abs/2504.18932", "authors": ["Dong Whi Yoo", "Jiayue Melissa Shi", "Violeta J. Rodriguez", "Koustuv Saha"], "title": "AI Chatbots for Mental Health: Values and Harms from Lived Experiences of Depression", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Recent advancements in LLMs enable chatbots to interact with individuals on a\nrange of queries, including sensitive mental health contexts. Despite\nuncertainties about their effectiveness and reliability, the development of\nLLMs in these areas is growing, potentially leading to harms. To better\nidentify and mitigate these harms, it is critical to understand how the values\nof people with lived experiences relate to the harms. In this study, we\ndeveloped a technology probe, a GPT-4o based chatbot called Zenny, enabling\nparticipants to engage with depression self-management scenarios informed by\nprevious research. We used Zenny to interview 17 individuals with lived\nexperiences of depression. Our thematic analysis revealed key values:\ninformational support, emotional support, personalization, privacy, and crisis\nmanagement. This work explores the relationship between lived experience\nvalues, potential harms, and design recommendations for mental health AI\nchatbots, aiming to enhance self-management support while minimizing risks.", "AI": {"tldr": "Study explores how LLM-based chatbots like Zenny (GPT-4o) align with values of people with depression, identifying key values and design recommendations to mitigate harms.", "motivation": "To understand the relationship between lived experience values and potential harms of mental health AI chatbots, ensuring safer and more effective self-management support.", "method": "Developed Zenny, a GPT-4o chatbot, and interviewed 17 individuals with depression to analyze their values and experiences.", "result": "Identified key values: informational/emotional support, personalization, privacy, and crisis management, informing design recommendations.", "conclusion": "Aligning chatbot design with lived experience values can enhance self-management support while minimizing risks in mental health AI applications."}}
{"id": "2504.20039", "pdf": "https://arxiv.org/pdf/2504.20039", "abs": "https://arxiv.org/abs/2504.20039", "authors": ["Roman Garipov", "Fedor Velikonivtsev", "Ruslan Svirschevski", "Vage Egiazarian", "Max Ryabinin"], "title": "AutoJudge: Judge Decoding Without Manual Annotation", "categories": ["cs.CL", "cs.LG"], "comment": "Preprint, Work in progress", "summary": "We introduce AutoJudge, a framework that accelerates large language model\n(LLM) inference with task-specific lossy speculative decoding. Instead of\nmatching the original model output distribution token-by-token, we identify\nwhich of the generated tokens affect the downstream quality of the generated\nresponse, relaxing the guarantee so that the \"unimportant\" tokens can be\ngenerated faster. Our approach relies on a semi-greedy search algorithm to test\nwhich of the mismatches between target and draft model should be corrected to\npreserve quality, and which ones may be skipped. We then train a lightweight\nclassifier based on existing LLM embeddings to predict, at inference time,\nwhich mismatching tokens can be safely accepted without compromising the final\nanswer quality. We test our approach with Llama 3.2 1B (draft) and Llama 3.1 8B\n(target) models on zero-shot GSM8K reasoning, where it achieves up to 1.5x more\naccepted tokens per verification cycle with under 1% degradation in answer\naccuracy compared to standard speculative decoding and over 2x with small loss\nin accuracy. When applied to the LiveCodeBench benchmark, our approach\nautomatically detects other, programming-specific important tokens and shows\nsimilar speedups, demonstrating its ability to generalize across tasks.", "AI": {"tldr": "AutoJudge accelerates LLM inference by identifying and skipping unimportant tokens during speculative decoding, maintaining quality while improving speed.", "motivation": "To speed up LLM inference without significant loss in output quality by focusing on task-specific important tokens.", "method": "Uses a semi-greedy search algorithm and a lightweight classifier to predict which mismatching tokens can be skipped. Tested with Llama models on GSM8K and LiveCodeBench.", "result": "Achieves 1.5x more accepted tokens with <1% accuracy loss and 2x speedup with minor accuracy trade-offs.", "conclusion": "AutoJudge generalizes across tasks, balancing speed and quality effectively."}}
{"id": "2504.19443", "pdf": "https://arxiv.org/pdf/2504.19443", "abs": "https://arxiv.org/abs/2504.19443", "authors": ["Yejin Jeong", "Donghun Lee"], "title": "CLIP-KOA: Enhancing Knee Osteoarthritis Diagnosis with Multi-Modal Learning and Symmetry-Aware Loss Functions", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 2 figures", "summary": "Knee osteoarthritis (KOA) is a universal chronic musculoskeletal disorders\nworldwide, making early diagnosis crucial. Currently, the Kellgren and Lawrence\n(KL) grading system is widely used to assess KOA severity. However, its high\ninter-observer variability and subjectivity hinder diagnostic consistency. To\naddress these limitations, automated diagnostic techniques using deep learning\nhave been actively explored in recent years. In this study, we propose a\nCLIP-based framework (CLIP-KOA) to enhance the consistency and reliability of\nKOA grade prediction. To achieve this, we introduce a learning approach that\nintegrates image and text information and incorporate Symmetry Loss and\nConsistency Loss to ensure prediction consistency between the original and\nflipped images. CLIP-KOA achieves state-of-the-art accuracy of 71.86\\% on KOA\nseverity prediction task, and ablation studies show that CLIP-KOA has 2.36\\%\nimprovement in accuracy over the standard CLIP model due to our contribution.\nThis study shows a novel direction for data-driven medical prediction not only\nto improve reliability of fine-grained diagnosis and but also to explore\nmultimodal methods for medical image analysis. Our code is available at\nhttps://github.com/anonymized-link.", "AI": {"tldr": "The paper proposes CLIP-KOA, a deep learning framework using image and text integration to improve consistency and accuracy in knee osteoarthritis (KOA) severity prediction, achieving 71.86% accuracy.", "motivation": "Current KOA severity assessment methods like the KL grading system suffer from subjectivity and variability, prompting the need for automated, reliable diagnostic tools.", "method": "The CLIP-KOA framework integrates image and text data, employing Symmetry Loss and Consistency Loss to ensure prediction consistency between original and flipped images.", "result": "CLIP-KOA achieves 71.86% accuracy, outperforming the standard CLIP model by 2.36%, demonstrating improved reliability in KOA severity prediction.", "conclusion": "The study highlights the potential of multimodal deep learning for enhancing fine-grained medical diagnosis and reliability in medical image analysis."}}
{"id": "2504.19396", "pdf": "https://arxiv.org/pdf/2504.19396", "abs": "https://arxiv.org/abs/2504.19396", "authors": ["Shuo Wu", "Pawan Poojary", "Randall Berry"], "title": "Observational Learning with a Budget", "categories": ["cs.LG", "cs.SI"], "comment": "Submitted to ISIT 2025 Conference, 11 pages, 4 figures", "summary": "We consider a model of Bayesian observational learning in which a sequence of\nagents receives a private signal about an underlying binary state of the world.\nEach agent makes a decision based on its own signal and its observations of\nprevious agents. A central planner seeks to improve the accuracy of these\nsignals by allocating a limited budget to enhance signal quality across agents.\nWe formulate and analyze the budget allocation problem and propose two optimal\nallocation strategies. At least one of these strategies is shown to maximize\nthe probability of achieving a correct information cascade.", "AI": {"tldr": "A Bayesian learning model where agents improve decisions by observing predecessors. A planner optimizes signal quality with budget constraints, proposing two strategies to maximize correct information cascades.", "motivation": "To enhance decision accuracy in sequential Bayesian learning by optimizing signal quality allocation under budget limits.", "method": "Formulate and analyze budget allocation problem; propose two optimal strategies for signal enhancement.", "result": "At least one strategy maximizes the probability of achieving a correct information cascade.", "conclusion": "Optimal budget allocation can significantly improve decision accuracy in observational learning."}}
{"id": "2504.18943", "pdf": "https://arxiv.org/pdf/2504.18943", "abs": "https://arxiv.org/abs/2504.18943", "authors": ["Martin Berger", "Nathana\u00ebl Fijalkow", "Mojtaba Valizadeh"], "title": "GPU accelerated program synthesis: Enumerate semantics, not syntax!", "categories": ["cs.PL", "cs.AI", "cs.LO", "68", "D.3"], "comment": "10 pages", "summary": "Program synthesis is an umbrella term for generating programs and logical\nformulae from specifications. With the remarkable performance improvements that\nGPUs enable for deep learning, a natural question arose: can we also implement\na search-based program synthesiser on GPUs to achieve similar performance\nimprovements? In this article we discuss our insights on this question, based\non recent works~. The goal is to build a synthesiser running on GPUs which\ntakes as input positive and negative example traces and returns a logical\nformula accepting the positive and rejecting the negative traces. With\nGPU-friendly programming techniques -- using the semantics of formulae to\nminimise data movement and reduce data-dependent branching -- our synthesiser\nscales to significantly larger synthesis problems, and operates much faster\nthan the previous CPU-based state-of-the-art. We believe the insights that make\nour approach GPU-friendly have wide potential for enhancing the performance of\nother formal methods (FM) workloads.", "AI": {"tldr": "The paper explores GPU-based program synthesis for improved performance, leveraging GPU-friendly techniques to handle larger problems faster than CPU-based methods.", "motivation": "To harness GPU capabilities for program synthesis, aiming for performance gains similar to those seen in deep learning.", "method": "Uses GPU-friendly programming techniques, minimizing data movement and reducing data-dependent branching, to synthesize logical formulae from example traces.", "result": "Achieves scalability to larger problems and faster operation compared to CPU-based state-of-the-art methods.", "conclusion": "GPU-friendly techniques can enhance performance in program synthesis and potentially other formal methods workloads."}}
{"id": "2504.18748", "pdf": "https://arxiv.org/pdf/2504.18748", "abs": "https://arxiv.org/abs/2504.18748", "authors": ["Kaustubh D. Dhole", "Nikhita Vedula", "Saar Kuzi", "Giuseppe Castellucci", "Eugene Agichtein", "Shervin Malmasi"], "title": "Generative Product Recommendations for Implicit Superlative Queries", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "In Recommender Systems, users often seek the best products through indirect,\nvague, or under-specified queries, such as \"best shoes for trail running\". Such\nqueries, also referred to as implicit superlative queries, pose a significant\nchallenge for standard retrieval and ranking systems as they lack an explicit\nmention of attributes and require identifying and reasoning over complex\nfactors. We investigate how Large Language Models (LLMs) can generate implicit\nattributes for ranking as well as reason over them to improve product\nrecommendations for such queries. As a first step, we propose a novel\nfour-point schema for annotating the best product candidates for superlative\nqueries called SUPERB, paired with LLM-based product annotations. We then\nempirically evaluate several existing retrieval and ranking approaches on our\nnew dataset, providing insights and discussing their integration into\nreal-world e-commerce production systems.", "AI": {"tldr": "The paper explores using LLMs to enhance product recommendations for vague queries like 'best shoes for trail running' by generating implicit attributes and reasoning over them. It introduces the SUPERB annotation schema and evaluates existing methods on a new dataset.", "motivation": "Standard retrieval systems struggle with vague or implicit superlative queries (e.g., 'best shoes for trail running') due to lack of explicit attributes. The study aims to leverage LLMs to address this gap.", "method": "Proposes the SUPERB schema for annotating best product candidates for superlative queries, paired with LLM-based annotations. Evaluates existing retrieval and ranking methods on a new dataset.", "result": "Empirical evaluation of retrieval and ranking approaches provides insights into their effectiveness for implicit superlative queries.", "conclusion": "The study demonstrates the potential of LLMs to improve recommendations for vague queries and discusses integration into real-world e-commerce systems."}}
{"id": "2504.19455", "pdf": "https://arxiv.org/pdf/2504.19455", "abs": "https://arxiv.org/abs/2504.19455", "authors": ["Yuki Hirakawa", "Ryotaro Shimizu"], "title": "Masked Language Prompting for Generative Data Augmentation in Few-shot Fashion Style Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Constructing dataset for fashion style recognition is challenging due to the\ninherent subjectivity and ambiguity of style concepts. Recent advances in\ntext-to-image models have facilitated generative data augmentation by\nsynthesizing images from labeled data, yet existing methods based solely on\nclass names or reference captions often fail to balance visual diversity and\nstyle consistency. In this work, we propose \\textbf{Masked Language Prompting\n(MLP)}, a novel prompting strategy that masks selected words in a reference\ncaption and leverages large language models to generate diverse yet\nsemantically coherent completions. This approach preserves the structural\nsemantics of the original caption while introducing attribute-level variations\naligned with the intended style, enabling style-consistent and diverse image\ngeneration without fine-tuning. Experimental results on the FashionStyle14\ndataset demonstrate that our MLP-based augmentation consistently outperforms\nclass-name and caption-based baselines, validating its effectiveness for\nfashion style recognition under limited supervision.", "AI": {"tldr": "The paper proposes Masked Language Prompting (MLP) for style-consistent and diverse image generation in fashion style recognition, outperforming existing methods.", "motivation": "Challenges in fashion style recognition due to subjectivity and ambiguity of style concepts, and limitations of existing generative data augmentation methods.", "method": "Uses MLP, a prompting strategy masking words in captions and leveraging large language models for diverse yet coherent completions.", "result": "MLP-based augmentation outperforms class-name and caption-based baselines on the FashionStyle14 dataset.", "conclusion": "MLP is effective for fashion style recognition under limited supervision, balancing diversity and style consistency."}}
{"id": "2504.19408", "pdf": "https://arxiv.org/pdf/2504.19408", "abs": "https://arxiv.org/abs/2504.19408", "authors": ["Maitreya Sonawane", "Sumit Mamtani"], "title": "UNet with Axial Transformer : A Neural Weather Model for Precipitation Nowcasting", "categories": ["cs.LG", "cs.CV", "eess.SP"], "comment": null, "summary": "Making accurate weather predictions can be particularly challenging for\nlocalized storms or events that evolve on hourly timescales, such as\nthunderstorms. Hence, our goal for the project was to model Weather Nowcasting\nfor making highly localized and accurate predictions that apply to the\nimmediate future replacing the current numerical weather models and data\nassimilation systems with Deep Learning approaches. A significant advantage of\nmachine learning is that inference is computationally cheap given an\nalready-trained model, allowing forecasts that are nearly instantaneous and in\nthe native high resolution of the input data. In this work we developed a novel\nmethod that employs Transformer-based machine learning models to forecast\nprecipitation. This approach works by leveraging axial attention mechanisms to\nlearn complex patterns and dynamics from time series frames. Moreover, it is a\ngeneric framework and can be applied to univariate and multivariate time series\ndata, as well as time series embeddings data. This paper represents an initial\nresearch on the dataset used in the domain of next frame prediciton, and hence,\nwe demonstrate state-of-the-art results in terms of metrices (PSNR = 47.67,\nSSIM = 0.9943) used for the given dataset using UNet with Axial Transformer.", "AI": {"tldr": "The paper introduces a Transformer-based deep learning model for weather nowcasting, achieving high accuracy in localized storm predictions with fast inference.", "motivation": "Current numerical weather models struggle with localized, rapidly evolving storms. The goal is to replace these with efficient deep learning approaches for immediate, high-resolution forecasts.", "method": "A novel Transformer-based model using axial attention mechanisms is developed to learn patterns from time series data, applicable to univariate and multivariate datasets.", "result": "State-of-the-art results are achieved (PSNR = 47.67, SSIM = 0.9943) using UNet with Axial Transformer on the dataset.", "conclusion": "The proposed method demonstrates the potential of deep learning for accurate and efficient weather nowcasting, outperforming traditional models."}}
{"id": "2504.18953", "pdf": "https://arxiv.org/pdf/2504.18953", "abs": "https://arxiv.org/abs/2504.18953", "authors": ["Sahar Ramezani Jolfaei", "Sepehr Khodadadi Hossein Abadi"], "title": "Application of the Brain Drain Optimization Algorithm to the N-Queens Problem", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "This paper introduces the application of the Brain Drain Optimization\nalgorithm -- a swarm-based metaheuristic inspired by the emigration of\nintellectual elites -- to the N-Queens problem. The N-Queens problem, a classic\ncombinatorial optimization problem, serves as a challenge for applying the\nBRADO. A designed cost function guides the search, and the configurations are\ntuned using a TOPSIS-based multicriteria decision making process. BRADO\nconsistently outperforms alternatives in terms of solution quality, achieving\nfewer threats and better objective function values. To assess BRADO's efficacy,\nit is benchmarked against several established metaheuristic algorithms,\nincluding Particle Swarm Optimization (PSO), Genetic Algorithm (GA),\nImperialist Competitive Algorithm (ICA), Iterated Local Search (ILS), and basic\nLocal Search (LS). The study highlights BRADO's potential as a general-purpose\nsolver for combinatorial problems, opening pathways for future applications in\nother domains of artificial intelligence.", "AI": {"tldr": "The paper applies the Brain Drain Optimization (BRADO) algorithm to the N-Queens problem, demonstrating its superiority over other metaheuristics like PSO, GA, ICA, ILS, and LS in terms of solution quality.", "motivation": "To explore the effectiveness of BRADO, a swarm-based metaheuristic inspired by intellectual emigration, in solving the classic N-Queens problem.", "method": "BRADO uses a cost function and TOPSIS-based multicriteria decision-making to tune configurations. It is benchmarked against PSO, GA, ICA, ILS, and LS.", "result": "BRADO consistently outperforms other algorithms, achieving fewer threats and better objective function values.", "conclusion": "BRADO shows promise as a general-purpose solver for combinatorial problems, with potential applications in other AI domains."}}
{"id": "2504.18988", "pdf": "https://arxiv.org/pdf/2504.18988", "abs": "https://arxiv.org/abs/2504.18988", "authors": ["Saramsh Gautam", "Mahmood Jasim"], "title": "LINC: Supporting Language Independent Communication and Comprehension to Enhance Contribution in Multilingual Collaborative Meetings", "categories": ["cs.HC", "cs.CL", "H.5.3"], "comment": "19 pages, 4 figures. Multimodal system design and evaluation study", "summary": "Collaborative research often includes contributors with varied perspectives\nfrom diverse linguistic backgrounds. However, English as a Second Language\n(ESL) researchers often struggle to communicate during meetings in English and\ncomprehend discussions, leading to limited contribution. To investigate these\nchallenges, we surveyed 64 ESL researchers who frequently collaborate in\nmultilingual teams and identified four key design goals around participation,\ncomprehension, documentation, and feedback. Guided by these design goals, we\ndeveloped LINC, a multimodal Language INdependent Collaboration system with two\ncomponents: a real-time module for multilingual communication during meetings\nand a post-meeting dashboard for discussion analysis. We evaluated the system\nthrough a two-phased study with six triads of multilingual teams. We found that\nusing LINC, participants benefited from communicating in their preferred\nlanguage, recalled and reviewed actionable insights, and prepared for upcoming\nmeetings effectively. We discuss external factors that impact multilingual\nmeeting participation beyond language preferences and the implications of\nmultimodal systems in facilitating meetings in hybrid multilingual\ncollaborative settings beyond research.", "AI": {"tldr": "LINC, a multimodal system, aids ESL researchers in multilingual meetings by enabling real-time communication and post-meeting analysis, improving participation and comprehension.", "motivation": "ESL researchers face challenges in contributing to multilingual meetings due to language barriers, limiting their involvement.", "method": "Surveyed 64 ESL researchers, identified design goals, and developed LINC with real-time and post-meeting modules. Evaluated with six triads of multilingual teams.", "result": "LINC improved communication, comprehension, and meeting preparation for participants.", "conclusion": "LINC effectively supports multilingual collaboration, with broader implications for hybrid settings beyond research."}}
{"id": "2504.19475", "pdf": "https://arxiv.org/pdf/2504.19475", "abs": "https://arxiv.org/abs/2504.19475", "authors": ["Sonia Joseph", "Praneet Suresh", "Lorenz Hufe", "Edward Stevinson", "Robert Graham", "Yash Vadi", "Danilo Bzdok", "Sebastian Lapuschkin", "Lee Sharkey", "Blake Aaron Richards"], "title": "Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "4 pages, 3 figures, 9 tables. Oral and Tutorial at the CVPR\n  Mechanistic Interpretability for Vision (MIV) Workshop", "summary": "Robust tooling and publicly available pre-trained models have helped drive\nrecent advances in mechanistic interpretability for language models. However,\nsimilar progress in vision mechanistic interpretability has been hindered by\nthe lack of accessible frameworks and pre-trained weights. We present Prisma\n(Access the codebase here: https://github.com/Prisma-Multimodal/ViT-Prisma), an\nopen-source framework designed to accelerate vision mechanistic\ninterpretability research, providing a unified toolkit for accessing 75+ vision\nand video transformers; support for sparse autoencoder (SAE), transcoder, and\ncrosscoder training; a suite of 80+ pre-trained SAE weights; activation\ncaching, circuit analysis tools, and visualization tools; and educational\nresources. Our analysis reveals surprising findings, including that effective\nvision SAEs can exhibit substantially lower sparsity patterns than language\nSAEs, and that in some instances, SAE reconstructions can decrease model loss.\nPrisma enables new research directions for understanding vision model internals\nwhile lowering barriers to entry in this emerging field.", "AI": {"tldr": "Prisma is an open-source framework for vision mechanistic interpretability, offering tools, pre-trained weights, and educational resources to advance research in understanding vision models.", "motivation": "Progress in vision mechanistic interpretability has lagged due to lack of accessible frameworks and pre-trained models. Prisma aims to bridge this gap.", "method": "Prisma provides a toolkit for accessing 75+ vision transformers, supports SAE/transcoder/crosscoder training, offers pre-trained weights, and includes analysis/visualization tools.", "result": "Findings include lower sparsity in vision SAEs than language SAEs and cases where SAE reconstructions reduce model loss.", "conclusion": "Prisma lowers barriers to vision interpretability research and opens new directions for understanding vision model internals."}}
{"id": "2504.19419", "pdf": "https://arxiv.org/pdf/2504.19419", "abs": "https://arxiv.org/abs/2504.19419", "authors": ["Zhaiming Shen", "Sung Ha Kang"], "title": "Graph-based Semi-supervised and Unsupervised Methods for Local Clustering", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Local clustering aims to identify specific substructures within a large graph\nwithout requiring full knowledge of the entire graph. These substructures are\ntypically small compared to the overall graph, enabling the problem to be\napproached by finding a sparse solution to a linear system associated with the\ngraph Laplacian. In this work, we first propose a method for identifying\nspecific local clusters when very few labeled data is given, which we term\nsemi-supervised local clustering. We then extend this approach to the\nunsupervised setting when no prior information on labels is available. The\nproposed methods involve randomly sampling the graph, applying diffusion\nthrough local cluster extraction, then examining the overlap among the results\nto find each cluster. We establish the co-membership conditions for any pair of\nnodes and rigorously prove the correctness of our methods. Additionally, we\nconduct extensive experiments to demonstrate that the proposed methods achieve\nstate-of-the-arts results in the low-label rates regime.", "AI": {"tldr": "The paper introduces semi-supervised and unsupervised methods for local clustering in large graphs, using sparse solutions to graph Laplacian systems and diffusion-based techniques, achieving state-of-the-art results with minimal labeled data.", "motivation": "Local clustering is essential for identifying substructures in large graphs without full graph knowledge, but existing methods struggle with limited labeled data or no prior information.", "method": "Proposes semi-supervised and unsupervised approaches involving random graph sampling, diffusion-based local cluster extraction, and overlap analysis to identify clusters.", "result": "The methods are proven correct under co-membership conditions and outperform existing techniques in low-label rate scenarios.", "conclusion": "The proposed methods effectively address local clustering with minimal labeled data, offering scalable and accurate solutions."}}
{"id": "2504.18961", "pdf": "https://arxiv.org/pdf/2504.18961", "abs": "https://arxiv.org/abs/2504.18961", "authors": ["Junjie Zhou"], "title": "Feature Fusion Revisited: Multimodal CTR Prediction for MMCTR Challenge", "categories": ["cs.IR", "cs.AI"], "comment": "A technical report for the MMCTR Challenge held by EReL@MIR Workshop\n  at WWW 2025", "summary": "With the rapid advancement of Multimodal Large Language Models (MLLMs), an\nincreasing number of researchers are exploring their application in\nrecommendation systems. However, the high latency associated with large models\npresents a significant challenge for such use cases. The EReL@MIR workshop\nprovided a valuable opportunity to experiment with various approaches aimed at\nimproving the efficiency of multimodal representation learning for information\nretrieval tasks. As part of the competition's requirements, participants were\nmandated to submit a technical report detailing their methodologies and\nfindings. Our team was honored to receive the award for Task 2 - Winner\n(Multimodal CTR Prediction). In this technical report, we present our methods\nand key findings. Additionally, we propose several directions for future work,\nparticularly focusing on how to effectively integrate recommendation signals\ninto multimodal representations. The codebase for our implementation is\npublicly available at: https://github.com/Lattice-zjj/MMCTR_Code, and the\ntrained model weights can be accessed at:\nhttps://huggingface.co/FireFlyCourageous/MMCTR_DIN_MicroLens_1M_x1.", "AI": {"tldr": "The paper discusses improving efficiency in multimodal recommendation systems using MLLMs, winning Task 2 in the EReL@MIR workshop, and proposes future integration of recommendation signals into multimodal representations.", "motivation": "Address the high latency challenge of MLLMs in recommendation systems and explore efficient multimodal representation learning for information retrieval.", "method": "Participated in the EReL@MIR workshop, experimented with approaches for efficiency, and submitted a technical report detailing methodologies.", "result": "Won the award for Task 2 (Multimodal CTR Prediction) and made code and model weights publicly available.", "conclusion": "Proposes future work on integrating recommendation signals into multimodal representations and shares resources for further research."}}
{"id": "2504.19444", "pdf": "https://arxiv.org/pdf/2504.19444", "abs": "https://arxiv.org/abs/2504.19444", "authors": ["Kang Yang", "Xinjun Mao", "Shangwen Wang", "Yanlin Wang", "Tanghaoran Zhang", "Bo Lin", "Yihao Qin", "Zhang Zhang", "Yao Lu", "Kamal Al-Sabahi"], "title": "Large Language Models are Qualified Benchmark Builders: Rebuilding Pre-Training Datasets for Advancing Code Intelligence Tasks", "categories": ["cs.SE", "cs.CL"], "comment": "Awarded the ACM SIGSOFT Distinguished Paper Award in ICPC 2025", "summary": "Pre-trained code models rely heavily on high-quality pre-training data,\nparticularly human-written reference comments that bridge code and natural\nlanguage. However, these comments often become outdated as software evolves,\ndegrading model performance. Large language models (LLMs) excel at generating\nhigh-quality code comments. We investigate whether replacing human-written\ncomments with LLM-generated ones improves pre-training datasets. Since standard\nmetrics cannot assess reference comment quality, we propose two novel\nreference-free evaluation tasks: code-comment inconsistency detection and\nsemantic code search. Results show that LLM-generated comments are more\nsemantically consistent with code than human-written ones, as confirmed by\nmanual evaluation. Leveraging this finding, we rebuild the CodeSearchNet\ndataset with LLM-generated comments and re-pre-train CodeT5. Evaluations\ndemonstrate that models trained on LLM-enhanced data outperform those using\noriginal human comments in code summarization, generation, and translation\ntasks. This work validates rebuilding pre-training datasets with LLMs to\nadvance code intelligence, challenging the traditional reliance on human\nreference comments.", "AI": {"tldr": "Replacing human-written code comments with LLM-generated ones improves pre-training data quality, enhancing model performance in code-related tasks.", "motivation": "Human-written comments often become outdated, degrading model performance. LLMs can generate high-quality comments, potentially improving pre-training datasets.", "method": "Proposed two reference-free evaluation tasks (code-comment inconsistency detection, semantic code search) and rebuilt the CodeSearchNet dataset with LLM-generated comments. Re-pre-trained CodeT5.", "result": "LLM-generated comments are more semantically consistent with code than human-written ones. Models trained on LLM-enhanced data outperform those using original human comments.", "conclusion": "Rebuilding pre-training datasets with LLM-generated comments advances code intelligence, challenging reliance on human reference comments."}}
{"id": "2504.19478", "pdf": "https://arxiv.org/pdf/2504.19478", "abs": "https://arxiv.org/abs/2504.19478", "authors": ["Weitao Feng", "Hang Zhou", "Jing Liao", "Li Cheng", "Wenbo Zhou"], "title": "CasaGPT: Cuboid Arrangement and Scene Assembly for Interior Design", "categories": ["cs.CV"], "comment": null, "summary": "We present a novel approach for indoor scene synthesis, which learns to\narrange decomposed cuboid primitives to represent 3D objects within a scene.\nUnlike conventional methods that use bounding boxes to determine the placement\nand scale of 3D objects, our approach leverages cuboids as a straightforward\nyet highly effective alternative for modeling objects. This allows for compact\nscene generation while minimizing object intersections. Our approach, coined\nCasaGPT for Cuboid Arrangement and Scene Assembly, employs an autoregressive\nmodel to sequentially arrange cuboids, producing physically plausible scenes.\nBy applying rejection sampling during the fine-tuning stage to filter out\nscenes with object collisions, our model further reduces intersections and\nenhances scene quality. Additionally, we introduce a refined dataset,\n3DFRONT-NC, which eliminates significant noise presented in the original\ndataset, 3D-FRONT. Extensive experiments on the 3D-FRONT dataset as well as our\ndataset demonstrate that our approach consistently outperforms the\nstate-of-the-art methods, enhancing the realism of generated scenes, and\nproviding a promising direction for 3D scene synthesis.", "AI": {"tldr": "A novel method, CasaGPT, uses cuboids for indoor scene synthesis, reducing object intersections and improving realism.", "motivation": "To improve 3D scene synthesis by replacing bounding boxes with cuboids for better object representation and fewer intersections.", "method": "Uses an autoregressive model to arrange cuboids sequentially and applies rejection sampling to filter out scenes with collisions.", "result": "Outperforms state-of-the-art methods, enhancing scene realism and reducing intersections.", "conclusion": "CasaGPT offers a promising direction for 3D scene synthesis with improved quality and realism."}}
{"id": "2504.19446", "pdf": "https://arxiv.org/pdf/2504.19446", "abs": "https://arxiv.org/abs/2504.19446", "authors": ["Arnab Bhattacharyya", "Constantinos Daskalakis", "Themis Gouleakis", "Yuhao Wang"], "title": "Learning High-dimensional Gaussians from Censored Data", "categories": ["cs.LG", "cs.CC", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "We provide efficient algorithms for the problem of distribution learning from\nhigh-dimensional Gaussian data where in each sample, some of the variable\nvalues are missing. We suppose that the variables are missing not at random\n(MNAR). The missingness model, denoted by $S(y)$, is the function that maps any\npoint $y$ in $R^d$ to the subsets of its coordinates that are seen. In this\nwork, we assume that it is known. We study the following two settings:\n  (i) Self-censoring: An observation $x$ is generated by first sampling the\ntrue value $y$ from a $d$-dimensional Gaussian $N(\\mu*, \\Sigma*)$ with unknown\n$\\mu*$ and $\\Sigma*$. For each coordinate $i$, there exists a set $S_i$\nsubseteq $R^d$ such that $x_i = y_i$ if and only if $y_i$ in $S_i$. Otherwise,\n$x_i$ is missing and takes a generic value (e.g., \"?\"). We design an algorithm\nthat learns $N(\\mu*, \\Sigma*)$ up to total variation (TV) distance epsilon,\nusing $poly(d, 1/\\epsilon)$ samples, assuming only that each pair of\ncoordinates is observed with sufficiently high probability.\n  (ii) Linear thresholding: An observation $x$ is generated by first sampling\n$y$ from a $d$-dimensional Gaussian $N(\\mu*, \\Sigma)$ with unknown $\\mu*$ and\nknown $\\Sigma$, and then applying the missingness model $S$ where $S(y) = {i in\n[d] : v_i^T y <= b_i}$ for some $v_1, ..., v_d$ in $R^d$ and $b_1, ..., b_d$ in\n$R$. We design an efficient mean estimation algorithm, assuming that none of\nthe possible missingness patterns is very rare conditioned on the values of the\nobserved coordinates and that any small subset of coordinates is observed with\nsufficiently high probability.", "AI": {"tldr": "Efficient algorithms for learning high-dimensional Gaussian distributions with MNAR missing data, under self-censoring and linear thresholding models.", "motivation": "Address the challenge of distribution learning when data is missing not at random (MNAR) in high-dimensional Gaussian settings.", "method": "Two settings: (i) Self-censoring with unknown parameters, using poly-sample algorithms; (ii) Linear thresholding with known covariance, focusing on mean estimation.", "result": "Algorithms achieve learning up to TV distance epsilon or efficient mean estimation under specified assumptions.", "conclusion": "Proposed methods effectively handle MNAR missingness in Gaussian data, with polynomial sample complexity or efficient mean estimation."}}
{"id": "2504.19042", "pdf": "https://arxiv.org/pdf/2504.19042", "abs": "https://arxiv.org/abs/2504.19042", "authors": ["James Giroux", "Michael Martinez", "Cristiano Fanelli"], "title": "Generative Models for Fast Simulation of Cherenkov Detectors at the Electron-Ion Collider", "categories": ["physics.ins-det", "cs.AI", "cs.LG", "hep-ex", "nucl-ex"], "comment": "45 pages, 27 figures", "summary": "The integration of Deep Learning (DL) into experimental nuclear and particle\nphysics has driven significant progress in simulation and reconstruction\nworkflows. However, traditional simulation frameworks such as Geant4 remain\ncomputationally intensive, especially for Cherenkov detectors, where simulating\noptical photon transport through complex geometries and reflective surfaces\nintroduces a major bottleneck. To address this, we present an open, standalone\nfast simulation tool for Detection of Internally Reflected Cherenkov Light\n(DIRC) detectors, with a focus on the High-Performance DIRC (hpDIRC) at the\nfuture Electron-Ion Collider (EIC). Our framework incorporates a suite of\ngenerative models tailored to accelerate particle identification (PID) tasks by\noffering a scalable, GPU-accelerated alternative to full Geant4-based\nsimulations. Designed with accessibility in mind, our simulation package\nenables both DL researchers and physicists to efficiently generate\nhigh-fidelity large-scale datasets on demand, without relying on complex\ntraditional simulation stacks. This flexibility supports the development and\nbenchmarking of novel DL-driven PID methods. Moreover, this fast simulation\npipeline represents a critical step toward enabling EIC-wide PID strategies\nthat depend on virtually unlimited simulated samples, spanning the full\nacceptance of the hpDIRC.", "AI": {"tldr": "A fast simulation tool for DIRC detectors is introduced to replace computationally intensive Geant4 simulations, leveraging generative models for scalable, GPU-accelerated particle identification tasks.", "motivation": "Traditional simulation frameworks like Geant4 are too slow for Cherenkov detectors, especially for optical photon transport, creating bottlenecks in workflows.", "method": "The paper presents a standalone, open fast simulation tool using generative models, optimized for GPU acceleration, to replace full Geant4 simulations.", "result": "The tool enables efficient, high-fidelity dataset generation for DL-driven particle identification, supporting EIC-wide PID strategies.", "conclusion": "This fast simulation pipeline is a key advancement for scalable PID tasks, reducing reliance on traditional simulation stacks."}}
{"id": "2504.19483", "pdf": "https://arxiv.org/pdf/2504.19483", "abs": "https://arxiv.org/abs/2504.19483", "authors": ["Bertram H\u00f8jer", "Oliver Jarvis", "Stefan Heinrich"], "title": "Improving Reasoning Performance in Large Language Models via Representation Engineering", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Has been accepted at \"The Thirteenth International Conference on\n  Learning Representations (ICLR 2025)\" Link to publication:\n  https://openreview.net/forum?id=IssPhpUsKt", "summary": "Recent advancements in large language models (LLMs) have resulted in\nincreasingly anthropomorphic language concerning the ability of LLMs to reason.\nWhether reasoning in LLMs should be understood to be inherently different is,\nhowever, widely debated. We propose utilizing a representation engineering\napproach wherein model activations are read from the residual stream of an LLM\nwhen processing a reasoning task. The activations are used to derive a control\nvector that is applied to the model as an inference-time intervention,\nmodulating the representational space of the model, to improve performance on\nthe specified task. We publish the code for deriving control vectors and\nanalyzing model representations. The method allows us to improve performance on\nreasoning benchmarks and assess how control vectors influence the final logit\ndistribution of a model via metrics such as KL divergence and entropy. We apply\ncontrol vectors to Mistral-7B-Instruct and a range of Pythia models on an\ninductive, a deductive and mathematical reasoning task. We show that an LLM\ncan, to a certain degree, be controlled to improve its perceived reasoning\nability by modulating activations. The intervention is dependent upon the\nability to reliably extract the model's typical state when correctly solving a\ntask. Our results suggest that reasoning performance can be modulated in the\nsame manner as other information-processing tasks performed by LLMs and\ndemonstrate that we are capable of improving performance on specific tasks via\na simple intervention on the residual stream with no additional training.", "AI": {"tldr": "The paper explores improving LLM reasoning via representation engineering, using control vectors derived from model activations to modulate performance without additional training.", "motivation": "To address the debate on whether LLM reasoning is inherently different and to enhance reasoning performance via interventions.", "method": "Uses representation engineering to derive control vectors from LLM activations during reasoning tasks, applied as inference-time interventions.", "result": "Demonstrates improved reasoning benchmarks and shows LLMs can be controlled to enhance perceived reasoning ability.", "conclusion": "Reasoning in LLMs can be modulated like other tasks, and simple interventions on the residual stream can improve performance."}}
{"id": "2504.19500", "pdf": "https://arxiv.org/pdf/2504.19500", "abs": "https://arxiv.org/abs/2504.19500", "authors": ["Yan Wang", "Baoxiong Jia", "Ziyu Zhu", "Siyuan Huang"], "title": "Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding", "categories": ["cs.CV", "cs.CL"], "comment": "CVPR 2025", "summary": "Open-vocabulary 3D scene understanding is pivotal for enhancing physical\nintelligence, as it enables embodied agents to interpret and interact\ndynamically within real-world environments. This paper introduces MPEC, a novel\nMasked Point-Entity Contrastive learning method for open-vocabulary 3D semantic\nsegmentation that leverages both 3D entity-language alignment and point-entity\nconsistency across different point cloud views to foster entity-specific\nfeature representations. Our method improves semantic discrimination and\nenhances the differentiation of unique instances, achieving state-of-the-art\nresults on ScanNet for open-vocabulary 3D semantic segmentation and\ndemonstrating superior zero-shot scene understanding capabilities. Extensive\nfine-tuning experiments on 8 datasets, spanning from low-level perception to\nhigh-level reasoning tasks, showcase the potential of learned 3D features,\ndriving consistent performance gains across varied 3D scene understanding\ntasks. Project website: https://mpec-3d.github.io/", "AI": {"tldr": "MPEC introduces a Masked Point-Entity Contrastive learning method for open-vocabulary 3D semantic segmentation, achieving state-of-the-art results on ScanNet and demonstrating strong zero-shot capabilities.", "motivation": "Enhancing physical intelligence by enabling embodied agents to interpret and interact dynamically in real-world environments through open-vocabulary 3D scene understanding.", "method": "MPEC leverages 3D entity-language alignment and point-entity consistency across point cloud views to foster entity-specific feature representations.", "result": "Achieves state-of-the-art results on ScanNet for open-vocabulary 3D semantic segmentation and shows superior zero-shot scene understanding. Fine-tuning on 8 datasets demonstrates consistent performance gains.", "conclusion": "MPEC's approach drives advancements in 3D scene understanding, showcasing the potential of learned 3D features across diverse tasks."}}
{"id": "2504.19449", "pdf": "https://arxiv.org/pdf/2504.19449", "abs": "https://arxiv.org/abs/2504.19449", "authors": ["Zhenyu Zhang", "Zechun Liu", "Yuandong Tian", "Harshit Khaitan", "Zhangyang Wang", "Steven Li"], "title": "R-Sparse: Rank-Aware Activation Sparsity for Efficient LLM Inference", "categories": ["cs.LG"], "comment": "ICLR 2025", "summary": "Large Language Models (LLMs), while demonstrating remarkable capabilities\nacross various applications, present significant challenges during inference\ndue to their substantial model size, especially when deployed on edge devices.\nActivation sparsity offers a promising solution to reduce computation and\nmemory movement, enabling more efficient inference, particularly for\nsmall-batch on-device applications. However, current approaches face\nlimitations with non-ReLU activation function, which are foundational to most\nadvanced LLMs, or require heavy continual training. Additionally, the\ndifficulty in predicting active channels and limited achievable sparsity ratios\nconstrain the effectiveness of activation sparsity-based methods. In this\npaper, we introduce R-Sparse, a training-free activation sparsity approach\ncapable of achieving high sparsity levels in advanced LLMs. We conducted two\npreliminary investigations into how different components contribute to the\noutput within a single linear layer and found two key observations: (i) the\nnon-sparse components of the input function can be regarded as a few bias\nterms, and (ii) The full computation can be effectively approximated by an\nappropriate combination of input channels and weight singular values. Building\non this, we replace the linear layers in LLMs with a rank-aware sparse\ninference method that leverages the sparsity of input channels and singular\nvalue components, eliminating the need for active channel prediction like the\noutput sparsity based approaches. Experiments on Llama-2/3 and Mistral models\nacross ten diverse tasks demonstrate that R-Sparse achieves comparable\nperformance at 50% model-level sparsity, resulting in a significant 43%\nend-to-end efficient improvements with customized kernels.", "AI": {"tldr": "R-Sparse is a training-free activation sparsity method for LLMs, achieving high sparsity and efficiency without active channel prediction.", "motivation": "Addressing inefficiencies in LLM inference due to large model size and limitations of current activation sparsity methods.", "method": "Replaces linear layers with a rank-aware sparse inference method, leveraging input channel sparsity and singular value components.", "result": "Achieves 50% model-level sparsity with comparable performance, improving efficiency by 43%.", "conclusion": "R-Sparse offers a scalable and effective solution for efficient LLM inference without retraining."}}
{"id": "2504.19047", "pdf": "https://arxiv.org/pdf/2504.19047", "abs": "https://arxiv.org/abs/2504.19047", "authors": ["David Almog"], "title": "AI Recommendations and Non-instrumental Image Concerns", "categories": ["econ.GN", "cs.AI", "cs.HC", "q-fin.EC"], "comment": null, "summary": "There is growing enthusiasm about the potential for humans and AI to\ncollaborate by leveraging their respective strengths. Yet in practice, this\npromise often falls short. This paper uses an online experiment to identify\nnon-instrumental image concerns as a key reason individuals underutilize AI\nrecommendations. I show that concerns about how one is perceived, even when\nthose perceptions carry no monetary consequences, lead participants to\ndisregard AI advice and reduce task performance.", "AI": {"tldr": "People often underuse AI recommendations due to concerns about how they are perceived, even without monetary consequences, leading to poorer task performance.", "motivation": "To understand why humans underutilize AI recommendations despite the potential benefits of collaboration.", "method": "An online experiment to identify non-instrumental image concerns as a barrier to AI adoption.", "result": "Participants disregarded AI advice due to perception concerns, reducing task performance.", "conclusion": "Non-instrumental image concerns significantly hinder effective human-AI collaboration."}}
{"id": "2504.19519", "pdf": "https://arxiv.org/pdf/2504.19519", "abs": "https://arxiv.org/abs/2504.19519", "authors": ["Ke Hong", "Xiuhong Li", "Minxu Liu", "Qiuli Mao", "Tianqi Wu", "Zixiao Huang", "Lufang Chen", "Zhong Wang", "Yichong Zhang", "Zhenhua Zhu", "Guohao Dai", "Yu Wang"], "title": "FlashOverlap: A Lightweight Design for Efficiently Overlapping Communication and Computation", "categories": ["cs.DC", "cs.CL", "cs.LG"], "comment": "17 pages, 11 figures, 4 tables", "summary": "Generative models have achieved remarkable success across various\napplications, driving the demand for multi-GPU computing. Inter-GPU\ncommunication becomes a bottleneck in multi-GPU computing systems, particularly\non consumer-grade GPUs. By exploiting concurrent hardware execution,\noverlapping computation and communication latency is an effective technique for\nmitigating the communication overhead. We identify that an efficient and\nadaptable overlapping design should satisfy (1) tile-wise overlapping to\nmaximize the overlapping opportunity, (2) interference-free computation to\nmaintain the original computational performance, and (3) communication\nagnosticism to reduce the development burden against varying communication\nprimitives. Nevertheless, current designs fail to simultaneously optimize for\nall of those features.\n  To address the issue, we propose FlashOverlap, a lightweight design\ncharacterized by tile-wise overlapping, interference-free computation, and\ncommunication agnosticism. FlashOverlap utilizes a novel signaling mechanism to\nidentify tile-wise data dependency without interrupting the computation\nprocess, and reorders data to contiguous addresses, enabling communication by\nsimply calling NCCL APIs. Experiments show that such a lightweight design\nachieves up to 1.65x speedup, outperforming existing works in most cases.", "AI": {"tldr": "FlashOverlap is a lightweight design for overlapping computation and communication in multi-GPU systems, achieving up to 1.65x speedup.", "motivation": "Inter-GPU communication is a bottleneck in multi-GPU systems, especially on consumer-grade GPUs, and current designs fail to optimize overlapping features.", "method": "FlashOverlap uses tile-wise overlapping, interference-free computation, and communication agnosticism, with a novel signaling mechanism for data dependency and NCCL APIs for communication.", "result": "FlashOverlap achieves up to 1.65x speedup, outperforming existing solutions.", "conclusion": "FlashOverlap effectively mitigates communication overhead in multi-GPU systems with its lightweight and adaptable design."}}
{"id": "2504.19506", "pdf": "https://arxiv.org/pdf/2504.19506", "abs": "https://arxiv.org/abs/2504.19506", "authors": ["Xinyang Li", "Chengjie Yi", "Jiawei Lai", "Mingbao Lin", "Yansong Qu", "Shengchuan Zhang", "Liujuan Cao"], "title": "SynergyAmodal: Deocclude Anything with Text Control", "categories": ["cs.CV"], "comment": "17 pages", "summary": "Image deocclusion (or amodal completion) aims to recover the invisible\nregions (\\ie, shape and appearance) of occluded instances in images. Despite\nrecent advances, the scarcity of high-quality data that balances diversity,\nplausibility, and fidelity remains a major obstacle. To address this challenge,\nwe identify three critical elements: leveraging in-the-wild image data for\ndiversity, incorporating human expertise for plausibility, and utilizing\ngenerative priors for fidelity. We propose SynergyAmodal, a novel framework for\nco-synthesizing in-the-wild amodal datasets with comprehensive shape and\nappearance annotations, which integrates these elements through a tripartite\ndata-human-model collaboration. First, we design an occlusion-grounded\nself-supervised learning algorithm to harness the diversity of in-the-wild\nimage data, fine-tuning an inpainting diffusion model into a partial completion\ndiffusion model. Second, we establish a co-synthesis pipeline to iteratively\nfilter, refine, select, and annotate the initial deocclusion results of the\npartial completion diffusion model, ensuring plausibility and fidelity through\nhuman expert guidance and prior model constraints. This pipeline generates a\nhigh-quality paired amodal dataset with extensive category and scale diversity,\ncomprising approximately 16K pairs. Finally, we train a full completion\ndiffusion model on the synthesized dataset, incorporating text prompts as\nconditioning signals. Extensive experiments demonstrate the effectiveness of\nour framework in achieving zero-shot generalization and textual\ncontrollability. Our code, dataset, and models will be made publicly available\nat https://github.com/imlixinyang/SynergyAmodal.", "AI": {"tldr": "SynergyAmodal is a framework for co-synthesizing high-quality amodal datasets by combining in-the-wild data, human expertise, and generative priors, achieving zero-shot generalization and textual controllability.", "motivation": "The scarcity of diverse, plausible, and high-fidelity data for image deocclusion hinders progress. The paper aims to address this by integrating data, human input, and models.", "method": "The framework uses a self-supervised learning algorithm for diversity, a co-synthesis pipeline for plausibility and fidelity, and trains a full completion diffusion model with text prompts.", "result": "A high-quality paired amodal dataset (~16K pairs) is generated, and the model demonstrates zero-shot generalization and textual controllability.", "conclusion": "SynergyAmodal effectively bridges the gap in amodal dataset quality and utility, with public release of code, dataset, and models."}}
{"id": "2504.19452", "pdf": "https://arxiv.org/pdf/2504.19452", "abs": "https://arxiv.org/abs/2504.19452", "authors": ["Qibang Liu", "Vincient Zhong", "Hadi Meidani", "Diab Abueidda", "Seid Koric", "Philippe Geubelle"], "title": "Geometry-Informed Neural Operator Transformer", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Machine-learning-based surrogate models offer significant computational\nefficiency and faster simulations compared to traditional numerical methods,\nespecially for problems requiring repeated evaluations of partial differential\nequations. This work introduces the Geometry-Informed Neural Operator\nTransformer (GINOT), which integrates the transformer architecture with the\nneural operator framework to enable forward predictions for arbitrary\ngeometries. GINOT encodes the surface points cloud of a geometry using a\nsampling and grouping mechanism combined with an attention mechanism, ensuring\ninvariance to point order and padding while maintaining robustness to\nvariations in point density. The geometry information is seamlessly integrated\nwith query points in the solution decoder through the attention mechanism. The\nperformance of GINOT is validated on multiple challenging datasets, showcasing\nits high accuracy and strong generalization capabilities for complex and\narbitrary 2D and 3D geometries.", "AI": {"tldr": "GINOT combines transformers with neural operators for efficient PDE predictions on arbitrary geometries, achieving high accuracy and generalization.", "motivation": "To improve computational efficiency and accuracy in solving PDEs for arbitrary geometries using machine learning.", "method": "Integrates transformer architecture with neural operators, encoding geometry via point clouds and attention mechanisms.", "result": "Validated on challenging datasets, GINOT shows high accuracy and generalization for 2D/3D geometries.", "conclusion": "GINOT is a robust and efficient surrogate model for PDE predictions on complex geometries."}}
{"id": "2504.19093", "pdf": "https://arxiv.org/pdf/2504.19093", "abs": "https://arxiv.org/abs/2504.19093", "authors": ["Yu Li", "Qizhi Pei", "Mengyuan Sun", "Honglin Lin", "Chenlin Ming", "Xin Gao", "Jiang Wu", "Conghui He", "Lijun Wu"], "title": "CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenges", "categories": ["cs.CR", "cs.AI", "cs.PF"], "comment": "Work in progress", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities,\nespecially the recent advancements in reasoning, such as o1 and o3, pushing the\nboundaries of AI. Despite these impressive achievements in mathematics and\ncoding, the reasoning abilities of LLMs in domains requiring cryptographic\nexpertise remain underexplored. In this paper, we introduce CipherBank, a\ncomprehensive benchmark designed to evaluate the reasoning capabilities of LLMs\nin cryptographic decryption tasks. CipherBank comprises 2,358 meticulously\ncrafted problems, covering 262 unique plaintexts across 5 domains and 14\nsubdomains, with a focus on privacy-sensitive and real-world scenarios that\nnecessitate encryption. From a cryptographic perspective, CipherBank\nincorporates 3 major categories of encryption methods, spanning 9 distinct\nalgorithms, ranging from classical ciphers to custom cryptographic techniques.\nWe evaluate state-of-the-art LLMs on CipherBank, e.g., GPT-4o, DeepSeek-V3, and\ncutting-edge reasoning-focused models such as o1 and DeepSeek-R1. Our results\nreveal significant gaps in reasoning abilities not only between general-purpose\nchat LLMs and reasoning-focused LLMs but also in the performance of current\nreasoning-focused models when applied to classical cryptographic decryption\ntasks, highlighting the challenges these models face in understanding and\nmanipulating encrypted data. Through detailed analysis and error\ninvestigations, we provide several key observations that shed light on the\nlimitations and potential improvement areas for LLMs in cryptographic\nreasoning. These findings underscore the need for continuous advancements in\nLLM reasoning capabilities.", "AI": {"tldr": "CipherBank is a benchmark for evaluating LLMs' cryptographic reasoning, revealing gaps in their abilities despite advances in general reasoning.", "motivation": "LLMs excel in reasoning tasks like math and coding, but their cryptographic reasoning remains underexplored. CipherBank addresses this gap.", "method": "CipherBank includes 2,358 problems across 5 domains, 14 subdomains, and 9 encryption algorithms. Evaluated models like GPT-4o and DeepSeek-V3.", "result": "Significant gaps exist between general-purpose and reasoning-focused LLMs, with challenges in classical cryptographic tasks.", "conclusion": "LLMs need further advancements in cryptographic reasoning, as highlighted by CipherBank's findings."}}
{"id": "2504.19583", "pdf": "https://arxiv.org/pdf/2504.19583", "abs": "https://arxiv.org/abs/2504.19583", "authors": ["Hanlu Zhang", "Yumeng Ma", "Shuo Wang", "Guiran Liu", "Binrong Zhu"], "title": "Graph-Based Spectral Decomposition for Parameter Coordination in Language Model Fine-Tuning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "This paper proposes a parameter collaborative optimization algorithm for\nlarge language models, enhanced with graph spectral analysis. The goal is to\nimprove both fine-tuning efficiency and structural awareness during training.\nIn the proposed method, the parameters of a pre-trained language model are\ntreated as nodes in a graph. A weighted graph is constructed, and Laplacian\nspectral decomposition is applied to enable frequency-domain modeling and\nstructural representation of the parameter space. Based on this structure, a\njoint loss function is designed. It combines the task loss with a spectral\nregularization term to facilitate collaborative updates among parameters. In\naddition, a spectral filtering mechanism is introduced during the optimization\nphase. This mechanism adjusts gradients in a structure-aware manner, enhancing\nthe model's training stability and convergence behavior. The method is\nevaluated on multiple tasks, including traditional fine-tuning comparisons,\nfew-shot generalization tests, and convergence speed analysis. In all settings,\nthe proposed approach demonstrates superior performance. The experimental\nresults confirm that the spectral collaborative optimization framework\neffectively reduces parameter perturbations and improves fine-tuning quality\nwhile preserving overall model performance. This work contributes significantly\nto the field of artificial intelligence by advancing parameter-efficient\ntraining methodologies for large-scale models, reinforcing the importance of\nstructural signal processing in deep learning optimization, and offering a\nrobust, generalizable framework for enhancing language model adaptability and\nperformance.", "AI": {"tldr": "A graph spectral analysis-enhanced parameter collaborative optimization algorithm for large language models improves fine-tuning efficiency and structural awareness.", "motivation": "To enhance fine-tuning efficiency and structural awareness in large language models by leveraging graph spectral analysis.", "method": "Treats model parameters as graph nodes, constructs a weighted graph, applies Laplacian spectral decomposition, designs a joint loss function with spectral regularization, and introduces a spectral filtering mechanism for gradient adjustment.", "result": "Superior performance in fine-tuning comparisons, few-shot generalization, and convergence speed, with reduced parameter perturbations and improved fine-tuning quality.", "conclusion": "The framework advances parameter-efficient training, highlights structural signal processing in deep learning, and offers a robust solution for language model adaptability."}}
{"id": "2504.19514", "pdf": "https://arxiv.org/pdf/2504.19514", "abs": "https://arxiv.org/abs/2504.19514", "authors": ["Rong Gao", "Xin Liu", "Zhuozhao Hu", "Bohao Xing", "Baiqiang Xia", "Zitong Yu", "Heikki K\u00e4lvi\u00e4inen"], "title": "FSBench: A Figure Skating Benchmark for Advancing Artistic Sports Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Figure skating, known as the \"Art on Ice,\" is among the most artistic sports,\nchallenging to understand due to its blend of technical elements (like jumps\nand spins) and overall artistic expression. Existing figure skating datasets\nmainly focus on single tasks, such as action recognition or scoring, lacking\ncomprehensive annotations for both technical and artistic evaluation. Current\nsports research is largely centered on ball games, with limited relevance to\nartistic sports like figure skating. To address this, we introduce FSAnno, a\nlarge-scale dataset advancing artistic sports understanding through figure\nskating. FSAnno includes an open-access training and test dataset, alongside a\nbenchmark dataset, FSBench, for fair model evaluation. FSBench consists of\nFSBench-Text, with multiple-choice questions and explanations, and\nFSBench-Motion, containing multimodal data and Question and Answer (QA) pairs,\nsupporting tasks from technical analysis to performance commentary. Initial\ntests on FSBench reveal significant limitations in existing models'\nunderstanding of artistic sports. We hope FSBench will become a key tool for\nevaluating and enhancing model comprehension of figure skating.", "AI": {"tldr": "The paper introduces FSAnno, a large-scale dataset for figure skating, addressing the lack of comprehensive annotations for technical and artistic evaluation. It includes FSBench for benchmarking model performance.", "motivation": "Existing datasets for figure skating focus on single tasks, and sports research is biased toward ball games, neglecting artistic sports. FSAnno aims to fill this gap.", "method": "FSAnno provides a dataset with comprehensive annotations and introduces FSBench, a benchmark with text and motion data for tasks like technical analysis and performance commentary.", "result": "Initial tests on FSBench show existing models struggle with understanding artistic sports, highlighting the need for improved datasets and models.", "conclusion": "FSAnno and FSBench aim to advance understanding of artistic sports like figure skating and serve as tools for evaluating and enhancing model comprehension."}}
{"id": "2504.19473", "pdf": "https://arxiv.org/pdf/2504.19473", "abs": "https://arxiv.org/abs/2504.19473", "authors": ["Donghe Chen", "Han Wang", "Lin Cheng", "Shengping Gong"], "title": "Stability Enhancement in Reinforcement Learning via Adaptive Control Lyapunov Function", "categories": ["cs.LG", "cs.RO"], "comment": "10 pages, 8 figures", "summary": "Reinforcement Learning (RL) has shown promise in control tasks but faces\nsignificant challenges in real-world applications, primarily due to the absence\nof safety guarantees during the learning process. Existing methods often\nstruggle with ensuring safe exploration, leading to potential system failures\nand restricting applications primarily to simulated environments. Traditional\napproaches such as reward shaping and constrained policy optimization can fail\nto guarantee safety during initial learning stages, while model-based methods\nusing Control Lyapunov Functions (CLFs) or Control Barrier Functions (CBFs) may\nhinder efficient exploration and performance. To address these limitations,\nthis paper introduces Soft Actor-Critic with Control Lyapunov Function\n(SAC-CLF), a framework that enhances stability and safety through three key\ninnovations: (1) a task-specific CLF design method for safe and optimal\nperformance; (2) dynamic adjustment of constraints to maintain robustness under\nunmodeled dynamics; and (3) improved control input smoothness while ensuring\nsafety. Experimental results on a classical nonlinear system and satellite\nattitude control demonstrate the effectiveness of SAC-CLF in overcoming the\nshortcomings of existing methods.", "AI": {"tldr": "The paper introduces SAC-CLF, a framework combining Soft Actor-Critic with Control Lyapunov Functions to enhance safety and stability in reinforcement learning for real-world control tasks.", "motivation": "Existing RL methods lack safety guarantees during learning, limiting real-world applications. Traditional approaches like reward shaping or model-based methods (CLFs/CBFs) often fail to ensure safety or hinder exploration.", "method": "SAC-CLF integrates three innovations: task-specific CLF design, dynamic constraint adjustment, and improved control input smoothness.", "result": "Experiments on nonlinear systems and satellite attitude control show SAC-CLF outperforms existing methods in safety and performance.", "conclusion": "SAC-CLF effectively addresses safety and stability challenges in RL, enabling broader real-world applications."}}
{"id": "2504.19099", "pdf": "https://arxiv.org/pdf/2504.19099", "abs": "https://arxiv.org/abs/2504.19099", "authors": ["Ning Wang", "Bingkun Yao", "Jie Zhou", "Yuchen Hu", "Xi Wang", "Nan Guan", "Zhe Jiang"], "title": "VeriDebug: A Unified LLM for Verilog Debugging via Contrastive Embedding and Guided Correction", "categories": ["cs.SE", "cs.AI", "cs.AR"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable potential in\ndebugging for various programming languages. However, the application of LLMs\nto Verilog debugging remains insufficiently explored. Here, we present\nVeriDebug, an approach that integrates contrastive representation and guided\ncorrection capabilities for automated Verilog debugging. Unlike existing\nmethods, VeriDebug employs an embedding-based technique to accurately retrieve\ninternal information, followed by bug-fixing. VeriDebug unifies Verilog bug\ndetection and correction through a shared parameter space. By simultaneously\nlearning bug patterns and fixes, it streamlines debugging via contrastive\nembedding and guided correction. Empirical results show the efficacy of\nVeriDebug in enhancing Verilog debugging. Our VeriDebugLoc, Type model achieves\n64.7 accuracy in bug fixing (Acc1), a significant improvement from the existing\nopen-source SOTAs 11.3. This performance not only outperforms open-source\nalternatives but also exceeds larger closed-source models like GPT-3.5-turbo\n(36.6), offering a more accurate alternative to conventional debugging methods.", "AI": {"tldr": "VeriDebug integrates contrastive representation and guided correction for automated Verilog debugging, outperforming existing methods and models like GPT-3.5-turbo.", "motivation": "The application of LLMs to Verilog debugging is underexplored, despite their success in other programming languages.", "method": "VeriDebug uses embedding-based retrieval and bug-fixing in a shared parameter space, combining contrastive embedding and guided correction.", "result": "VeriDebug achieves 64.7% accuracy in bug fixing, surpassing open-source SOTAs (11.3%) and GPT-3.5-turbo (36.6%).", "conclusion": "VeriDebug offers a more accurate and streamlined approach to Verilog debugging compared to conventional methods."}}
{"id": "2504.19730", "pdf": "https://arxiv.org/pdf/2504.19730", "abs": "https://arxiv.org/abs/2504.19730", "authors": ["Wenhan Mu", "Ling Xu", "Shuren Pei", "Le Mi", "Huichi Zhou"], "title": "Evaluate-and-Purify: Fortifying Code Language Models Against Adversarial Attacks Using LLM-as-a-Judge", "categories": ["cs.SE", "cs.CL"], "comment": "25 pages, 6 figures", "summary": "The widespread adoption of code language models in software engineering tasks\nhas exposed vulnerabilities to adversarial attacks, especially the identifier\nsubstitution attacks. Although existing identifier substitution attackers\ndemonstrate high success rates, they often produce adversarial examples with\nunnatural code patterns. In this paper, we systematically assess the quality of\nadversarial examples using LLM-as-a-Judge. Our analysis reveals that over 80%\nof adversarial examples generated by state-of-the-art identifier substitution\nattackers (e.g., ALERT) are actually detectable. Based on this insight, we\npropose EP-Shield, a unified framework for evaluating and purifying identifier\nsubstitution attacks via naturalness-aware reasoning. Specifically, we first\nevaluate the naturalness of code and identify the perturbed adversarial code,\nthen purify it so that the victim model can restore correct prediction.\nExtensive experiments demonstrate the superiority of EP-Shield over adversarial\nfine-tuning (up to 83.36% improvement) and its lightweight design 7B\nparameters) with GPT-4-level performance.", "AI": {"tldr": "EP-Shield is a framework to evaluate and purify adversarial examples in code language models, improving detection and correction of unnatural patterns.", "motivation": "Address the vulnerability of code language models to adversarial attacks, particularly identifier substitution, and improve the naturalness of adversarial examples.", "method": "Uses LLM-as-a-Judge to assess adversarial example quality, then purifies them via naturalness-aware reasoning.", "result": "EP-Shield outperforms adversarial fine-tuning by up to 83.36% and achieves GPT-4-level performance with a lightweight design.", "conclusion": "EP-Shield effectively detects and purifies adversarial examples, enhancing the robustness of code language models."}}
{"id": "2504.19524", "pdf": "https://arxiv.org/pdf/2504.19524", "abs": "https://arxiv.org/abs/2504.19524", "authors": ["Peijian Zeng", "Feiyan Pang", "Zhanbo Wang", "Aimin Yang"], "title": "LR-IAD:Mask-Free Industrial Anomaly Detection with Logical Reasoning", "categories": ["cs.CV"], "comment": "10 pages", "summary": "Industrial Anomaly Detection (IAD) is critical for ensuring product quality\nby identifying defects. Traditional methods such as feature embedding and\nreconstruction-based approaches require large datasets and struggle with\nscalability. Existing vision-language models (VLMs) and Multimodal Large\nLanguage Models (MLLMs) address some limitations but rely on mask annotations,\nleading to high implementation costs and false positives. Additionally,\nindustrial datasets like MVTec-AD and VisA suffer from severe class imbalance,\nwith defect samples constituting only 23.8% and 11.1% of total data\nrespectively. To address these challenges, we propose a reward function that\ndynamically prioritizes rare defect patterns during training to handle class\nimbalance. We also introduce a mask-free reasoning framework using Chain of\nThought (CoT) and Group Relative Policy Optimization (GRPO) mechanisms,\nenabling anomaly detection directly from raw images without annotated masks.\nThis approach generates interpretable step-by-step explanations for defect\nlocalization. Our method achieves state-of-the-art performance, outperforming\nprior approaches by 36% in accuracy on MVTec-AD and 16% on VisA. By eliminating\nmask dependency and reducing costs while providing explainable outputs, this\nwork advances industrial anomaly detection and supports scalable quality\ncontrol in manufacturing. Code to reproduce the experiment is available at\nhttps://github.com/LilaKen/LR-IAD.", "AI": {"tldr": "A novel reward function and mask-free reasoning framework for industrial anomaly detection (IAD) improves accuracy and reduces costs by addressing class imbalance and eliminating mask dependencies.", "motivation": "Traditional IAD methods face scalability issues and high costs due to mask annotations. Class imbalance in datasets like MVTec-AD and VisA further complicates defect detection.", "method": "Proposes a dynamic reward function for class imbalance and a mask-free framework using Chain of Thought (CoT) and Group Relative Policy Optimization (GRPO) for direct anomaly detection from raw images.", "result": "Achieves state-of-the-art performance, improving accuracy by 36% on MVTec-AD and 16% on VisA, with interpretable defect localization.", "conclusion": "The method advances IAD by reducing costs, eliminating mask dependency, and providing explainable outputs, supporting scalable quality control in manufacturing."}}
{"id": "2504.19480", "pdf": "https://arxiv.org/pdf/2504.19480", "abs": "https://arxiv.org/abs/2504.19480", "authors": ["Dixiao Wei", "Peng Yi", "Jinlong Lei", "Yiguang Hong", "Yuchuan Du"], "title": "An Automated Reinforcement Learning Reward Design Framework with Large Language Model for Cooperative Platoon Coordination", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) has demonstrated excellent decision-making\npotential in platoon coordination problems. However, due to the variability of\ncoordination goals, the complexity of the decision problem, and the\ntime-consumption of trial-and-error in manual design, finding a well\nperformance reward function to guide RL training to solve complex platoon\ncoordination problems remains challenging. In this paper, we formally define\nthe Platoon Coordination Reward Design Problem (PCRDP), extending the RL-based\ncooperative platoon coordination problem to incorporate automated reward\nfunction generation. To address PCRDP, we propose a Large Language Model\n(LLM)-based Platoon coordination Reward Design (PCRD) framework, which\nsystematically automates reward function discovery through LLM-driven\ninitialization and iterative optimization. In this method, LLM first\ninitializes reward functions based on environment code and task requirements\nwith an Analysis and Initial Reward (AIR) module, and then iteratively\noptimizes them based on training feedback with an evolutionary module. The AIR\nmodule guides LLM to deepen their understanding of code and tasks through a\nchain of thought, effectively mitigating hallucination risks in code\ngeneration. The evolutionary module fine-tunes and reconstructs the reward\nfunction, achieving a balance between exploration diversity and convergence\nstability for training. To validate our approach, we establish six challenging\ncoordination scenarios with varying complexity levels within the Yangtze River\nDelta transportation network simulation. Comparative experimental results\ndemonstrate that RL agents utilizing PCRD-generated reward functions\nconsistently outperform human-engineered reward functions, achieving an average\nof 10\\% higher performance metrics in all scenarios.", "AI": {"tldr": "The paper introduces an LLM-based framework (PCRD) to automate reward function design for RL in platoon coordination, outperforming manual designs by 10%.", "motivation": "Manual reward function design for RL in platoon coordination is challenging due to goal variability, problem complexity, and trial-and-error inefficiency.", "method": "Proposes PCRD, using LLM-driven initialization (AIR module) and iterative optimization (evolutionary module) to automate reward function design.", "result": "RL agents with PCRD-generated rewards outperform human-engineered ones by 10% in six complex scenarios.", "conclusion": "PCRD effectively automates reward design, improving RL performance in platoon coordination."}}
{"id": "2504.19120", "pdf": "https://arxiv.org/pdf/2504.19120", "abs": "https://arxiv.org/abs/2504.19120", "authors": ["Gaojian Huang", "Yantong Jin", "Wei-Hsiang Lo"], "title": "Beyond Levels of Driving Automation: A Triadic Framework of Human-AI Collaboration in On-Road Mobility", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The goal of the current study is to introduce a triadic human-AI\ncollaboration framework for the automated vehicle domain. Previous\nclassifications (e.g., SAE Levels of Automation) focus on defining automation\nlevels based on who controls the vehicle. However, it remains unclear how human\nusers and AI should collaborate in real-time, especially in dynamic driving\ncontexts, where roles can shift frequently. To fill the gap, this study\nproposes a triadic human-AI collaboration framework with three AI roles (i.e.,\nAdvisor, Co-Pilot, and Guardian) that dynamically adapt to human needs.\nOverall, the study lays a foundation for developing adaptive, role-based\nhuman-AI collaboration strategies in automated vehicles.", "AI": {"tldr": "A triadic human-AI collaboration framework for automated vehicles is proposed, featuring dynamic AI roles (Advisor, Co-Pilot, Guardian) to adapt to human needs in real-time driving contexts.", "motivation": "Existing classifications (e.g., SAE Levels) lack clarity on real-time human-AI collaboration in dynamic driving scenarios where roles shift frequently.", "method": "Introduces a triadic framework with three AI roles (Advisor, Co-Pilot, Guardian) that dynamically adapt to human needs.", "result": "The framework provides a foundation for adaptive, role-based human-AI collaboration in automated vehicles.", "conclusion": "The study advances understanding of human-AI collaboration in dynamic driving contexts, enabling more effective role adaptation."}}
{"id": "2504.19754", "pdf": "https://arxiv.org/pdf/2504.19754", "abs": "https://arxiv.org/abs/2504.19754", "authors": ["Carlo Merola", "Jaspinder Singh"], "title": "Reconstructing Context: Evaluating Advanced Chunking Strategies for Retrieval-Augmented Generation", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "13 pages, 2 figures, Second Workshop on Knowledge-Enhanced\n  Information Retrieval, ECIR 2025", "summary": "Retrieval-augmented generation (RAG) has become a transformative approach for\nenhancing large language models (LLMs) by grounding their outputs in external\nknowledge sources. Yet, a critical question persists: how can vast volumes of\nexternal knowledge be managed effectively within the input constraints of LLMs?\nTraditional methods address this by chunking external documents into smaller,\nfixed-size segments. While this approach alleviates input limitations, it often\nfragments context, resulting in incomplete retrieval and diminished coherence\nin generation. To overcome these shortcomings, two advanced techniques, late\nchunking and contextual retrieval, have been introduced, both aiming to\npreserve global context. Despite their potential, their comparative strengths\nand limitations remain unclear. This study presents a rigorous analysis of late\nchunking and contextual retrieval, evaluating their effectiveness and\nefficiency in optimizing RAG systems. Our results indicate that contextual\nretrieval preserves semantic coherence more effectively but requires greater\ncomputational resources. In contrast, late chunking offers higher efficiency\nbut tends to sacrifice relevance and completeness.", "AI": {"tldr": "The paper compares late chunking and contextual retrieval in RAG systems, finding contextual retrieval better for coherence but more resource-intensive, while late chunking is efficient but less effective.", "motivation": "To address the challenge of managing vast external knowledge within LLM input constraints without fragmenting context.", "method": "Rigorous analysis of late chunking and contextual retrieval techniques in RAG systems.", "result": "Contextual retrieval preserves semantic coherence better but is resource-heavy; late chunking is efficient but less effective.", "conclusion": "Contextual retrieval is superior for coherence, while late chunking is better for efficiency, highlighting a trade-off in RAG optimization."}}
{"id": "2504.19545", "pdf": "https://arxiv.org/pdf/2504.19545", "abs": "https://arxiv.org/abs/2504.19545", "authors": ["Zezeng Li", "Zhihui Qi", "Weimin Wang", "Ziliang Wang", "Junyi Duan", "Na Lei"], "title": "Point2Quad: Generating Quad Meshes from Point Clouds via Face Prediction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Quad meshes are essential in geometric modeling and computational mechanics.\nAlthough learning-based methods for triangle mesh demonstrate considerable\nadvancements, quad mesh generation remains less explored due to the challenge\nof ensuring coplanarity, convexity, and quad-only meshes. In this paper, we\npresent Point2Quad, the first learning-based method for quad-only mesh\ngeneration from point clouds. The key idea is learning to identify quad mesh\nwith fused pointwise and facewise features. Specifically, Point2Quad begins\nwith a k-NN-based candidate generation considering the coplanarity and\nsquareness. Then, two encoders are followed to extract geometric and\ntopological features that address the challenge of quad-related constraints,\nespecially by combining in-depth quadrilaterals-specific characteristics.\nSubsequently, the extracted features are fused to train the classifier with a\ndesigned compound loss. The final results are derived after the refinement by a\nquad-specific post-processing. Extensive experiments on both clear and noise\ndata demonstrate the effectiveness and superiority of Point2Quad, compared to\nbaseline methods under comprehensive metrics.", "AI": {"tldr": "Point2Quad is the first learning-based method for generating quad-only meshes from point clouds, addressing challenges like coplanarity and convexity through fused pointwise and facewise features.", "motivation": "Quad mesh generation is under-explored in learning-based methods due to constraints like coplanarity and convexity, despite its importance in geometric modeling and computational mechanics.", "method": "Point2Quad uses k-NN-based candidate generation, two encoders for geometric/topological features, and a classifier trained with compound loss, followed by quad-specific post-processing.", "result": "Extensive experiments show Point2Quad outperforms baselines on both clean and noisy data under comprehensive metrics.", "conclusion": "Point2Quad effectively addresses quad mesh generation challenges, demonstrating superiority over existing methods."}}
{"id": "2504.19496", "pdf": "https://arxiv.org/pdf/2504.19496", "abs": "https://arxiv.org/abs/2504.19496", "authors": ["Rudy Morel", "Jiequn Han", "Edouard Oyallon"], "title": "DISCO: learning to DISCover an evolution Operator for multi-physics-agnostic prediction", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We address the problem of predicting the next state of a dynamical system\ngoverned by unknown temporal partial differential equations (PDEs) using only a\nshort trajectory. While standard transformers provide a natural black-box\nsolution to this task, the presence of a well-structured evolution operator in\nthe data suggests a more tailored and efficient approach. Specifically, when\nthe PDE is fully known, classical numerical solvers can evolve the state\naccurately with only a few parameters. Building on this observation, we\nintroduce DISCO, a model that uses a large hypernetwork to process a short\ntrajectory and generate the parameters of a much smaller operator network,\nwhich then predicts the next state through time integration. Our framework\ndecouples dynamics estimation (i.e., DISCovering an evolution operator from a\nshort trajectory) from state prediction (i.e., evolving this operator).\nExperiments show that pretraining our model on diverse physics datasets\nachieves state-of-the-art performance while requiring significantly fewer\nepochs. Moreover, it generalizes well and remains competitive when fine-tuned\non downstream tasks.", "AI": {"tldr": "DISCO uses a hypernetwork to generate parameters for a smaller operator network, enabling efficient prediction of dynamical system states governed by unknown PDEs.", "motivation": "To predict the next state of dynamical systems with unknown PDEs using minimal data, leveraging structured evolution operators for efficiency.", "method": "DISCO employs a hypernetwork to process short trajectories and generate parameters for a smaller operator network, which performs time integration for state prediction.", "result": "Pretraining on diverse physics datasets yields state-of-the-art performance with fewer epochs and strong generalization.", "conclusion": "DISCO effectively decouples dynamics estimation from state prediction, achieving high performance and generalization in PDE-governed systems."}}
{"id": "2504.19142", "pdf": "https://arxiv.org/pdf/2504.19142", "abs": "https://arxiv.org/abs/2504.19142", "authors": ["Chenhao Xu", "Chunyu Chen", "Jinglin Peng", "Jiannan Wang", "Jun Gao"], "title": "BQSched: A Non-intrusive Scheduler for Batch Concurrent Queries via Reinforcement Learning", "categories": ["cs.DB", "cs.AI"], "comment": "Accepted by ICDE '25", "summary": "Most large enterprises build predefined data pipelines and execute them\nperiodically to process operational data using SQL queries for various tasks. A\nkey issue in minimizing the overall makespan of these pipelines is the\nefficient scheduling of concurrent queries within the pipelines. Existing tools\nmainly rely on simple heuristic rules due to the difficulty of expressing the\ncomplex features and mutual influences of queries. The latest reinforcement\nlearning (RL) based methods have the potential to capture these patterns from\nfeedback, but it is non-trivial to apply them directly due to the large\nscheduling space, high sampling cost, and poor sample utilization.\n  Motivated by these challenges, we propose BQSched, a non-intrusive Scheduler\nfor Batch concurrent Queries via reinforcement learning. Specifically, BQSched\ndesigns an attention-based state representation to capture the complex query\npatterns, and proposes IQ-PPO, an auxiliary task-enhanced proximal policy\noptimization (PPO) algorithm, to fully exploit the rich signals of Individual\nQuery completion in logs. Based on the RL framework above, BQSched further\nintroduces three optimization strategies, including adaptive masking to prune\nthe action space, scheduling gain-based query clustering to deal with large\nquery sets, and an incremental simulator to reduce sampling cost. To our\nknowledge, BQSched is the first non-intrusive batch query scheduler via RL.\nExtensive experiments show that BQSched can significantly improve the\nefficiency and stability of batch query scheduling, while also achieving\nremarkable scalability and adaptability in both data and queries. For example,\nacross all DBMSs and scales tested, BQSched reduces the overall makespan of\nbatch queries on TPC-DS benchmark by an average of 34% and 13%, compared with\nthe commonly used heuristic strategy and the adapted RL-based scheduler,\nrespectively.", "AI": {"tldr": "BQSched is a reinforcement learning-based scheduler for batch concurrent queries, improving efficiency and reducing makespan compared to heuristic and RL-based methods.", "motivation": "Existing tools rely on simple heuristics, and RL methods face challenges like large scheduling space and high sampling costs. BQSched addresses these issues.", "method": "BQSched uses an attention-based state representation and IQ-PPO, an enhanced PPO algorithm, with optimization strategies like adaptive masking and query clustering.", "result": "BQSched reduces makespan by 34% and 13% compared to heuristic and RL-based methods, respectively, showing scalability and adaptability.", "conclusion": "BQSched is an effective, non-intrusive RL-based scheduler for batch queries, outperforming existing methods in efficiency and stability."}}
{"id": "2104.02496", "pdf": "https://arxiv.org/pdf/2104.02496", "abs": "https://arxiv.org/abs/2104.02496", "authors": ["P. Schulze", "S. Wiegrebe", "P. W. Thurner", "C. Heumann", "M. A\u00dfenmacher"], "title": "A Bayesian approach to modeling topic-metadata relationships", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": "13 pages, 1 table, 5 figures", "summary": "The objective of advanced topic modeling is not only to explore latent\ntopical structures, but also to estimate relationships between the discovered\ntopics and theoretically relevant metadata. Methods used to estimate such\nrelationships must take into account that the topical structure is not directly\nobserved, but instead being estimated itself in an unsupervised fashion,\nusually by common topic models. A frequently used procedure to achieve this is\nthe method of composition, a Monte Carlo sampling technique performing multiple\nrepeated linear regressions of sampled topic proportions on metadata\ncovariates. In this paper, we propose two modifications of this approach:\nFirst, we substantially refine the existing implementation of the method of\ncomposition from the R package stm by replacing linear regression with the more\nappropriate Beta regression. Second, we provide a fundamental enhancement of\nthe entire estimation framework by substituting the current blending of\nfrequentist and Bayesian methods with a fully Bayesian approach. This allows\nfor a more appropriate quantification of uncertainty. We illustrate our\nimproved methodology by investigating relationships between Twitter posts by\nGerman parliamentarians and different metadata covariates related to their\nelectoral districts, using the Structural Topic Model to estimate topic\nproportions.", "AI": {"tldr": "The paper proposes improvements to topic modeling by refining the method of composition with Beta regression and introducing a fully Bayesian approach for better uncertainty quantification.", "motivation": "To enhance the estimation of relationships between discovered topics and metadata, addressing limitations in current methods.", "method": "Replaces linear regression with Beta regression in the method of composition and shifts to a fully Bayesian framework.", "result": "Improved methodology demonstrated by analyzing Twitter posts of German parliamentarians and their electoral district metadata.", "conclusion": "The proposed modifications offer more accurate and robust topic-metadata relationship estimation."}}
{"id": "2504.19546", "pdf": "https://arxiv.org/pdf/2504.19546", "abs": "https://arxiv.org/abs/2504.19546", "authors": ["Tong Xiao", "Qunming Wang", "Ping Lu", "Tenghai Huang", "Xiaohua Tong", "Peter M. Atkinson"], "title": "Crowd Detection Using Very-Fine-Resolution Satellite Imagery", "categories": ["cs.CV"], "comment": "17 pages, 12 figures, 5 tables", "summary": "Accurate crowd detection (CD) is critical for public safety and historical\npattern analysis, yet existing methods relying on ground and aerial imagery\nsuffer from limited spatio-temporal coverage. The development of\nvery-fine-resolution (VFR) satellite sensor imagery (e.g., ~0.3 m spatial\nresolution) provides unprecedented opportunities for large-scale crowd activity\nanalysis, but it has never been considered for this task. To address this gap,\nwe proposed CrowdSat-Net, a novel point-based convolutional neural network,\nwhich features two innovative components: Dual-Context Progressive Attention\nNetwork (DCPAN) to improve feature representation of individuals by aggregating\nscene context and local individual characteristics, and High-Frequency Guided\nDeformable Upsampler (HFGDU) that recovers high-frequency information during\nupsampling through frequency-domain guided deformable convolutions. To validate\nthe effectiveness of CrowdSat-Net, we developed CrowdSat, the first VFR\nsatellite imagery dataset designed specifically for CD tasks, comprising over\n120k manually labeled individuals from multi-source satellite platforms\n(Beijing-3N, Jilin-1 Gaofen-04A and Google Earth) across China. In the\nexperiments, CrowdSat-Net was compared with five state-of-the-art point-based\nCD methods (originally designed for ground or aerial imagery) using CrowdSat\nand achieved the largest F1-score of 66.12% and Precision of 73.23%, surpassing\nthe second-best method by 1.71% and 2.42%, respectively. Moreover, extensive\nablation experiments validated the importance of the DCPAN and HFGDU modules.\nFurthermore, cross-regional evaluation further demonstrated the spatial\ngeneralizability of CrowdSat-Net. This research advances CD capability by\nproviding both a newly developed network architecture for CD and a pioneering\nbenchmark dataset to facilitate future CD development.", "AI": {"tldr": "CrowdSat-Net, a novel CNN for crowd detection using VFR satellite imagery, outperforms existing methods with innovative modules (DCPAN and HFGDU) and a new dataset (CrowdSat).", "motivation": "Existing crowd detection methods lack spatio-temporal coverage; VFR satellite imagery offers new opportunities but hasn't been explored for this task.", "method": "Proposed CrowdSat-Net with DCPAN for feature aggregation and HFGDU for high-frequency recovery, validated on the CrowdSat dataset.", "result": "Achieved F1-score of 66.12% and Precision of 73.23%, outperforming other methods by 1.71% and 2.42%, respectively.", "conclusion": "CrowdSat-Net advances crowd detection with a new architecture and benchmark dataset, demonstrating spatial generalizability."}}
{"id": "2504.19527", "pdf": "https://arxiv.org/pdf/2504.19527", "abs": "https://arxiv.org/abs/2504.19527", "authors": ["Qinwei Yang", "Ruocheng Guo", "Shasha Han", "Peng Wu"], "title": "Identification and Estimation of Long-Term Treatment Effects with Monotone Missing", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Estimating long-term treatment effects has a wide range of applications in\nvarious domains. A key feature in this context is that collecting long-term\noutcomes typically involves a multi-stage process and is subject to monotone\nmissing, where individuals missing at an earlier stage remain missing at\nsubsequent stages. Despite its prevalence, monotone missing has been rarely\nexplored in previous studies on estimating long-term treatment effects. In this\npaper, we address this gap by introducing the sequential missingness assumption\nfor identification. We propose three novel estimation methods, including\ninverse probability weighting, sequential regression imputation, and sequential\nmarginal structural model (SeqMSM). Considering that the SeqMSM method may\nsuffer from high variance due to severe data sparsity caused by monotone\nmissing, we further propose a novel balancing-enhanced approach, BalanceNet, to\nimprove the stability and accuracy of the estimation methods. Extensive\nexperiments on two widely used benchmark datasets demonstrate the effectiveness\nof our proposed methods.", "AI": {"tldr": "The paper addresses the challenge of estimating long-term treatment effects under monotone missing data, proposing three methods and a balancing-enhanced approach (BalanceNet) to improve stability and accuracy.", "motivation": "Long-term treatment effect estimation is crucial but complicated by monotone missing data, a common yet understudied issue.", "method": "Three methods are introduced: inverse probability weighting, sequential regression imputation, and sequential marginal structural model (SeqMSM), with BalanceNet enhancing SeqMSM stability.", "result": "Experiments on benchmark datasets confirm the effectiveness of the proposed methods.", "conclusion": "The study fills a gap in handling monotone missing data for long-term treatment effect estimation, offering practical solutions."}}
{"id": "2504.19155", "pdf": "https://arxiv.org/pdf/2504.19155", "abs": "https://arxiv.org/abs/2504.19155", "authors": ["Hussein Harb", "Didier Benoit", "Axel Rannou", "Chi-Hieu Pham", "Valentin Tissot", "Bahaa Nasr", "Julien Bert"], "title": "Machine Learning-Based Modeling of the Anode Heel Effect in X-ray Beam Monte Carlo Simulations", "categories": ["physics.med-ph", "cs.AI"], "comment": "15 pages, 8 figures", "summary": "This study enhances Monte Carlo simulation accuracy in X-ray imaging by\ndeveloping an AI-driven model for the anode heel effect, achieving improved\nbeam intensity distribution and dosimetric precision. Through dynamic\nadjustments to beam weights on the anode and cathode sides of the X-ray tube,\nour machine learning model effectively replicates the asymmetry characteristic\nof clinical X-ray beams. Experimental results reveal dose rate increases of up\nto 9.6% on the cathode side and reductions of up to 12.5% on the anode side,\nfor energy levels between 50 and 120 kVp. These experimentally optimized beam\nweights were integrated into the OpenGATE and GGEMS Monte Carlo toolkits,\nsignificantly advancing dosimetric simulation accuracy and the image quality\nwhich closely resembles the clinical imaging. Validation with fluence and dose\nactors demonstrated that the AI-based model closely mirrors clinical beam\nbehavior, providing substantial improvements in dose consistency and accuracy\nover conventional X-ray models. This approach provides a robust framework for\nimproving X-ray dosimetry, with potential applications in dose optimization,\nimaging quality enhancement, and radiation safety in both clinical and research\nsettings.", "AI": {"tldr": "AI-driven model improves Monte Carlo simulation accuracy in X-ray imaging by dynamically adjusting beam weights for the anode heel effect, enhancing dosimetric precision and image quality.", "motivation": "To address inaccuracies in Monte Carlo simulations of X-ray imaging caused by the anode heel effect, aiming for better beam intensity distribution and dosimetric precision.", "method": "Developed a machine learning model to dynamically adjust beam weights on the anode and cathode sides of the X-ray tube, replicating clinical beam asymmetry. Integrated optimized weights into OpenGATE and GGEMS toolkits.", "result": "Achieved dose rate increases of up to 9.6% on the cathode side and reductions of up to 12.5% on the anode side for 50-120 kVp. Improved simulation accuracy and image quality.", "conclusion": "The AI-based model provides a robust framework for enhancing X-ray dosimetry, with applications in dose optimization, imaging quality, and radiation safety."}}
{"id": "2110.08420", "pdf": "https://arxiv.org/pdf/2110.08420", "abs": "https://arxiv.org/abs/2110.08420", "authors": ["Kawin Ethayarajh", "Yejin Choi", "Swabha Swayamdipta"], "title": "Understanding Dataset Difficulty with $\\mathcal{V}$-Usable Information", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICML 2022 (Outstanding Paper)", "summary": "Estimating the difficulty of a dataset typically involves comparing\nstate-of-the-art models to humans; the bigger the performance gap, the harder\nthe dataset is said to be. However, this comparison provides little\nunderstanding of how difficult each instance in a given distribution is, or\nwhat attributes make the dataset difficult for a given model. To address these\nquestions, we frame dataset difficulty -- w.r.t. a model $\\mathcal{V}$ -- as\nthe lack of $\\mathcal{V}$-$\\textit{usable information}$ (Xu et al., 2019),\nwhere a lower value indicates a more difficult dataset for $\\mathcal{V}$. We\nfurther introduce $\\textit{pointwise $\\mathcal{V}$-information}$ (PVI) for\nmeasuring the difficulty of individual instances w.r.t. a given distribution.\nWhile standard evaluation metrics typically only compare different models for\nthe same dataset, $\\mathcal{V}$-$\\textit{usable information}$ and PVI also\npermit the converse: for a given model $\\mathcal{V}$, we can compare different\ndatasets, as well as different instances/slices of the same dataset.\nFurthermore, our framework allows for the interpretability of different input\nattributes via transformations of the input, which we use to discover\nannotation artefacts in widely-used NLP benchmarks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.19549", "pdf": "https://arxiv.org/pdf/2504.19549", "abs": "https://arxiv.org/abs/2504.19549", "authors": ["Deng Li", "Bohao Xing", "Xin Liu", "Baiqiang Xia", "Bihan Wen", "Heikki K\u00e4lvi\u00e4inen"], "title": "DEEMO: De-identity Multimodal Emotion Recognition and Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Emotion understanding is a critical yet challenging task. Most existing\napproaches rely heavily on identity-sensitive information, such as facial\nexpressions and speech, which raises concerns about personal privacy. To\naddress this, we introduce the De-identity Multimodal Emotion Recognition and\nReasoning (DEEMO), a novel task designed to enable emotion understanding using\nde-identified video and audio inputs. The DEEMO dataset consists of two\nsubsets: DEEMO-NFBL, which includes rich annotations of Non-Facial Body\nLanguage (NFBL), and DEEMO-MER, an instruction dataset for Multimodal Emotion\nRecognition and Reasoning using identity-free cues. This design supports\nemotion understanding without compromising identity privacy. In addition, we\npropose DEEMO-LLaMA, a Multimodal Large Language Model (MLLM) that integrates\nde-identified audio, video, and textual information to enhance both emotion\nrecognition and reasoning. Extensive experiments show that DEEMO-LLaMA achieves\nstate-of-the-art performance on both tasks, outperforming existing MLLMs by a\nsignificant margin, achieving 74.49% accuracy and 74.45% F1-score in\nde-identity emotion recognition, and 6.20 clue overlap and 7.66 label overlap\nin de-identity emotion reasoning. Our work contributes to ethical AI by\nadvancing privacy-preserving emotion understanding and promoting responsible\naffective computing.", "AI": {"tldr": "DEEMO introduces a privacy-preserving method for emotion recognition using de-identified data, achieving state-of-the-art results with DEEMO-LLaMA.", "motivation": "Address privacy concerns in emotion recognition by avoiding identity-sensitive data like facial expressions and speech.", "method": "Proposes DEEMO dataset (DEEMO-NFBL and DEEMO-MER) and DEEMO-LLaMA, a Multimodal Large Language Model for emotion recognition and reasoning.", "result": "DEEMO-LLaMA achieves 74.49% accuracy and 74.45% F1-score in recognition, and 6.20 clue overlap and 7.66 label overlap in reasoning.", "conclusion": "Advances ethical AI by enabling privacy-preserving emotion understanding."}}
{"id": "2504.19530", "pdf": "https://arxiv.org/pdf/2504.19530", "abs": "https://arxiv.org/abs/2504.19530", "authors": ["Yicheng Li", "Xinghua Sun"], "title": "Euclidean Distance Matrix Completion via Asymmetric Projected Gradient Descent", "categories": ["cs.LG", "eess.SP", "stat.ML"], "comment": null, "summary": "This paper proposes and analyzes a gradient-type algorithm based on\nBurer-Monteiro factorization, called the Asymmetric Projected Gradient Descent\n(APGD), for reconstructing the point set configuration from partial Euclidean\ndistance measurements, known as the Euclidean Distance Matrix Completion (EDMC)\nproblem. By paralleling the incoherence matrix completion framework, we show\nfor the first time that global convergence guarantee with exact recovery of\nthis routine can be established given $\\mathcal{O}(\\mu^2 r^3 \\kappa^2 n \\log\nn)$ Bernoulli random observations without any sample splitting. Unlike\nleveraging the tangent space Restricted Isometry Property (RIP) and local\ncurvature of the low-rank embedding manifold in some very recent works, our\nproof provides new upper bounds to replace the random graph lemma under EDMC\nsetting. The APGD works surprisingly well and numerical experiments demonstrate\nexact linear convergence behavior in rich-sample regions yet deteriorates fast\nwhen compared with the performance obtained by optimizing the s-stress\nfunction, i.e., the standard but unexplained non-convex approach for EDMC, if\nthe sample size is limited. While virtually matching our theoretical\nprediction, this unusual phenomenon might indicate that: (i) the power of\nimplicit regularization is weakened when specified in the APGD case; (ii) the\nstabilization of such new gradient direction requires substantially more\nsamples than the information-theoretic limit would suggest.", "AI": {"tldr": "The paper introduces APGD, a gradient-type algorithm for solving the EDMC problem, showing global convergence with exact recovery under certain conditions. It outperforms in rich-sample regions but struggles with limited samples.", "motivation": "The motivation is to address the EDMC problem by proposing a new algorithm (APGD) that guarantees global convergence and exact recovery without sample splitting, improving upon existing methods.", "method": "The method involves the Asymmetric Projected Gradient Descent (APGD) algorithm, leveraging Burer-Monteiro factorization and replacing the random graph lemma with new upper bounds under the EDMC setting.", "result": "APGD achieves exact linear convergence in rich-sample regions but deteriorates with limited samples, matching theoretical predictions while revealing potential weaknesses in implicit regularization.", "conclusion": "The study concludes that APGD is effective under certain conditions but highlights the need for more samples than theoretically expected, suggesting limitations in its implicit regularization and stabilization."}}
{"id": "2112.06876", "pdf": "https://arxiv.org/pdf/2112.06876", "abs": "https://arxiv.org/abs/2112.06876", "authors": ["Eugene Yu Ji"], "title": "Cognitive and Cultural Topology of Linguistic Categories:A Semantic-Pragmatic Metric Approach", "categories": ["cs.CL"], "comment": "12 Pages; 3 figures", "summary": "In recent years, the field of NLP has seen growing interest in modeling both\nsemantic and pragmatic dimensions. Despite this progress, two key challenges\npersist: firstly, the complex task of mapping and analyzing the interactions\nbetween semantic and pragmatic features; secondly, the insufficient\nincorporation of relevant insights from related disciplines outside NLP.\nAddressing these issues, this study introduces a novel geometric metric that\nutilizes word co-occurrence patterns. This metric maps two fundamental\nproperties - semantic typicality (cognitive) and pragmatic salience\n(socio-cultural) - for basic-level categories within a two-dimensional\nhyperbolic space. Our evaluations reveal that this semantic-pragmatic metric\nproduces mappings for basic-level categories that not only surpass traditional\ncognitive semantics benchmarks but also demonstrate significant socio-cultural\nrelevance. This finding proposes that basic-level categories, traditionally\nviewed as semantics-driven cognitive constructs, should be examined through the\nlens of both semantic and pragmatic dimensions, highlighting their role as a\ncognitive-cultural interface. The broad contribution of this paper lies in the\ndevelopment of medium-sized, interpretable, and human-centric language\nembedding models, which can effectively blend semantic and pragmatic dimensions\nto elucidate both the cognitive and socio-cultural significance of linguistic\ncategories.", "AI": {"tldr": "The paper introduces a geometric metric for mapping semantic and pragmatic features in NLP, outperforming traditional benchmarks and highlighting socio-cultural relevance.", "motivation": "Addressing challenges in modeling interactions between semantic and pragmatic features and integrating insights from related disciplines.", "method": "A novel geometric metric using word co-occurrence patterns to map semantic typicality and pragmatic salience in hyperbolic space.", "result": "The metric outperforms cognitive semantics benchmarks and shows socio-cultural relevance, suggesting basic-level categories are cognitive-cultural interfaces.", "conclusion": "The study contributes interpretable, human-centric language models blending semantic and pragmatic dimensions to understand linguistic categories."}}
{"id": "2504.19557", "pdf": "https://arxiv.org/pdf/2504.19557", "abs": "https://arxiv.org/abs/2504.19557", "authors": ["Mohammad Altillawi", "Fengyi Shen", "Liudi Yang", "Sai Manoj Prakhya", "Ziyuan Liu"], "title": "CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel View Synthesis in Autonomous Driving Scenes", "categories": ["cs.CV"], "comment": "Accepted in 2025 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition Workshops (CVPRW)", "summary": "Current point-based approaches encounter limitations in scalability and\nrendering quality when using large 3D point cloud maps because using them\ndirectly for novel view synthesis (NVS) leads to degraded visualizations. We\nidentify the primary issue behind these low-quality renderings as a visibility\nmismatch between geometry and appearance, stemming from using these two\nmodalities together. To address this problem, we present CE-NPBG, a new\napproach for novel view synthesis (NVS) in large-scale autonomous driving\nscenes. Our method is a neural point-based technique that leverages two\nmodalities: posed images (cameras) and synchronized raw 3D point clouds\n(LiDAR). We first employ a connectivity relationship graph between appearance\nand geometry, which retrieves points from a large 3D point cloud map observed\nfrom the current camera perspective and uses them for rendering. By leveraging\nthis connectivity, our method significantly improves rendering quality and\nenhances run-time and scalability by using only a small subset of points from\nthe large 3D point cloud map. Our approach associates neural descriptors with\nthe points and uses them to synthesize views. To enhance the encoding of these\ndescriptors and elevate rendering quality, we propose a joint adversarial and\npoint rasterization training. During training, we pair an image-synthesizer\nnetwork with a multi-resolution discriminator. At inference, we decouple them\nand use the image-synthesizer to generate novel views. We also integrate our\nproposal into the recent 3D Gaussian Splatting work to highlight its benefits\nfor improved rendering and scalability.", "AI": {"tldr": "CE-NPBG improves novel view synthesis in large-scale scenes by addressing visibility mismatches between geometry and appearance using a neural point-based method with connectivity graphs and joint adversarial training.", "motivation": "Current point-based methods struggle with scalability and rendering quality in large 3D point cloud maps due to visibility mismatches between geometry and appearance.", "method": "CE-NPBG uses a connectivity graph to retrieve relevant points from a large 3D point cloud map, associates neural descriptors with points, and employs joint adversarial and point rasterization training for improved rendering.", "result": "The method enhances rendering quality and scalability by using a subset of points and improves runtime efficiency.", "conclusion": "CE-NPBG effectively addresses visibility mismatches and integrates with 3D Gaussian Splatting for superior rendering in autonomous driving scenes."}}
{"id": "2504.19538", "pdf": "https://arxiv.org/pdf/2504.19538", "abs": "https://arxiv.org/abs/2504.19538", "authors": ["Yasir Ghunaim", "Andr\u00e9s Villa", "Gergo Ignacz", "Gyorgy Szekely", "Motasem Alfarra", "Bernard Ghanem"], "title": "Towards Faster and More Compact Foundation Models for Molecular Property Prediction", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Advancements in machine learning for molecular property prediction have\nimproved accuracy but at the expense of higher computational cost and longer\ntraining times. Recently, the Joint Multi-domain Pre-training (JMP) foundation\nmodel has demonstrated strong performance across various downstream tasks with\nreduced training time over previous models. Despite JMP's advantages,\nfine-tuning it on molecular datasets ranging from small-scale to large-scale\nrequires considerable time and computational resources. In this work, we\ninvestigate strategies to enhance efficiency by reducing model size while\npreserving performance. To better understand the model's efficiency, we analyze\nthe layer contributions of JMP and find that later interaction blocks provide\ndiminishing returns, suggesting an opportunity for model compression. We\nexplore block reduction strategies by pruning the pre-trained model and\nevaluating its impact on efficiency and accuracy during fine-tuning. Our\nanalysis reveals that removing two interaction blocks results in a minimal\nperformance drop, reducing the model size by 32% while increasing inference\nthroughput by 1.3x. These results suggest that JMP-L is over-parameterized and\nthat a smaller, more efficient variant can achieve comparable performance with\nlower computational cost. Our study provides insights for developing lighter,\nfaster, and more scalable foundation models for molecular and materials\ndiscovery. The code is publicly available at:\nhttps://github.com/Yasir-Ghunaim/efficient-jmp.", "AI": {"tldr": "The paper explores strategies to reduce the size of the JMP foundation model for molecular property prediction without significant performance loss, achieving a 32% size reduction and 1.3x faster inference.", "motivation": "Despite JMP's strong performance, its fine-tuning is computationally expensive, prompting the need for a more efficient variant.", "method": "Analyzes layer contributions, prunes interaction blocks, and evaluates the impact on efficiency and accuracy.", "result": "Removing two interaction blocks reduces model size by 32% and increases inference speed by 1.3x with minimal performance drop.", "conclusion": "JMP is over-parameterized, and a smaller variant can maintain performance while lowering computational costs, aiding scalable molecular discovery."}}
{"id": "2504.19275", "pdf": "https://arxiv.org/pdf/2504.19275", "abs": "https://arxiv.org/abs/2504.19275", "authors": ["Yiren Xu"], "title": "Balancing Creativity and Automation: The Influence of AI on Modern Film Production and Dissemination", "categories": ["cs.CY", "cs.AI", "I.5.m"], "comment": "19 pages, 1 figures, 2 tables", "summary": "The integration of Artificial Intelligence(AI) into film production has\nrevolutionized efficiency and creativity, yet it simultaneously raises critical\nethical and practical challenges. This study explores the dual impact of AI on\nmodern cinema through three objectives: defining the optimal human-AI\nrelationship, balancing creativity with automation, and developing ethical\nguidelines. By employing a mixed-method approach combining theoretical\nframeworks (auteur theory, human-technology relations) and case studies (The\nSafe Zone, Fast & Furious 7, The Brutalist), the research reveals that\npositioning AI as an \"embodiment tool\" rather than an independent \"alterity\npartner\" preserves human authorship and artistic integrity. Key findings\nhighlight the risks of surveillance capitalism in AI-driven markets and the\nethical dilemmas of deepfake technology. The study concludes with actionable\nrecommendations, including international regulatory frameworks and a Human\nControl Index (HCI) to quantify AI involvement. These insights aim to guide\nfilmmakers, policymakers, and scholars in navigating the evolving AI-cinema\nlandscape while safeguarding cultural diversity and ethical standards.", "AI": {"tldr": "AI in film boosts efficiency and creativity but poses ethical challenges. The study defines human-AI roles, balances creativity with automation, and proposes ethical guidelines, recommending AI as a tool, not a partner.", "motivation": "To address the dual impact of AI in cinema, balancing its benefits with ethical and practical concerns.", "method": "Mixed-method approach: theoretical frameworks (auteur theory, human-technology relations) and case studies (The Safe Zone, Fast & Furious 7, The Brutalist).", "result": "AI as an 'embodiment tool' preserves human authorship. Risks include surveillance capitalism and deepfake dilemmas.", "conclusion": "Recommends regulatory frameworks and a Human Control Index (HCI) to guide ethical AI use in film."}}
{"id": "2305.01920", "pdf": "https://arxiv.org/pdf/2305.01920", "abs": "https://arxiv.org/abs/2305.01920", "authors": ["Wanli Li", "Tieyun Qian", "Yi Song", "Zeyu Zhang", "Jiawei Li", "Zhuang Chen", "Lixin Zou"], "title": "Generative Meta-Learning for Zero-Shot Relation Triplet Extraction", "categories": ["cs.CL"], "comment": null, "summary": "Zero-shot Relation Triplet Extraction (ZeroRTE) aims to extract relation\ntriplets from texts containing unseen relation types. This capability benefits\nvarious downstream information retrieval (IR) tasks. The primary challenge lies\nin enabling models to generalize effectively to unseen relation categories.\nExisting approaches typically leverage the knowledge embedded in pre-trained\nlanguage models to accomplish the generalization process. However, these\nmethods focus solely on fitting the training data during training, without\nspecifically improving the model's generalization performance, resulting in\nlimited generalization capability. For this reason, we explore the integration\nof bi-level optimization (BLO) with pre-trained language models for learning\ngeneralized knowledge directly from the training data, and propose a generative\nmeta-learning framework which exploits the `learning-to-learn' ability of\nmeta-learning to boost the generalization capability of generative models.\n  Specifically, we introduce a BLO approach that simultaneously addresses data\nfitting and generalization. This is achieved by constructing an upper-level\nloss to focus on generalization and a lower-level loss to ensure accurate data\nfitting. Building on this, we subsequently develop three generative\nmeta-learning methods, each tailored to a distinct category of meta-learning.\nExtensive experimental results demonstrate that our framework performs well on\nthe ZeroRTE task. Our code is available at\nhttps://github.com/leeworry/TGM-MetaLearning.", "AI": {"tldr": "The paper proposes a generative meta-learning framework integrating bi-level optimization (BLO) with pre-trained language models to enhance generalization in Zero-shot Relation Triplet Extraction (ZeroRTE).", "motivation": "Existing methods for ZeroRTE lack explicit focus on improving generalization to unseen relation types, relying solely on pre-trained language models.", "method": "The framework uses BLO to balance data fitting and generalization, introducing upper-level (generalization) and lower-level (data fitting) losses. Three generative meta-learning methods are developed.", "result": "Experiments show the framework performs well on ZeroRTE tasks.", "conclusion": "The proposed approach effectively boosts generalization in ZeroRTE by leveraging meta-learning and BLO."}}
{"id": "2504.19572", "pdf": "https://arxiv.org/pdf/2504.19572", "abs": "https://arxiv.org/abs/2504.19572", "authors": ["Peter H\u00f6nig", "Matthias Hirschmanner", "Markus Vincze"], "title": "Category-Level and Open-Set Object Pose Estimation for Robotics", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted at Austrian Robotics Workshop 2025", "summary": "Object pose estimation enables a variety of tasks in computer vision and\nrobotics, including scene understanding and robotic grasping. The complexity of\na pose estimation task depends on the unknown variables related to the target\nobject. While instance-level methods already excel for opaque and Lambertian\nobjects, category-level and open-set methods, where texture, shape, and size\nare partially or entirely unknown, still struggle with these basic material\nproperties. Since texture is unknown in these scenarios, it cannot be used for\ndisambiguating object symmetries, another core challenge of 6D object pose\nestimation. The complexity of estimating 6D poses with such a manifold of\nunknowns led to various datasets, accuracy metrics, and algorithmic solutions.\nThis paper compares datasets, accuracy metrics, and algorithms for solving 6D\npose estimation on the category-level. Based on this comparison, we analyze how\nto bridge category-level and open-set object pose estimation to reach\ngeneralization and provide actionable recommendations.", "AI": {"tldr": "This paper compares datasets, metrics, and algorithms for 6D pose estimation at the category-level, aiming to bridge the gap to open-set scenarios and provide actionable recommendations.", "motivation": "The challenge lies in estimating 6D poses for objects with unknown texture, shape, and size, especially in category-level and open-set scenarios, where current methods struggle.", "method": "The study compares existing datasets, accuracy metrics, and algorithmic solutions for 6D pose estimation at the category-level.", "result": "The analysis identifies gaps and challenges in current approaches, particularly in handling unknown variables like texture and symmetries.", "conclusion": "The paper provides actionable recommendations to bridge category-level and open-set pose estimation, aiming for better generalization."}}
{"id": "2504.19561", "pdf": "https://arxiv.org/pdf/2504.19561", "abs": "https://arxiv.org/abs/2504.19561", "authors": ["Rom N. Parnichkun", "Neehal Tumma", "Armin W. Thomas", "Alessandro Moro", "Qi An", "Taiji Suzuki", "Atsushi Yamashita", "Michael Poli", "Stefano Massaroli"], "title": "Quantifying Memory Utilization with Effective State-Size", "categories": ["cs.LG"], "comment": null, "summary": "The need to develop a general framework for architecture analysis is becoming\nincreasingly important, given the expanding design space of sequence models. To\nthis end, we draw insights from classical signal processing and control theory,\nto develop a quantitative measure of \\textit{memory utilization}: the internal\nmechanisms through which a model stores past information to produce future\noutputs. This metric, which we call \\textbf{\\textit{effective state-size}}\n(ESS), is tailored to the fundamental class of systems with\n\\textit{input-invariant} and \\textit{input-varying linear operators},\nencompassing a variety of computational units such as variants of attention,\nconvolutions, and recurrences. Unlike prior work on memory utilization, which\neither relies on raw operator visualizations (e.g. attention maps), or simply\nthe total \\textit{memory capacity} (i.e. cache size) of a model, our metrics\nprovide highly interpretable and actionable measurements. In particular, we\nshow how ESS can be leveraged to improve initialization strategies, inform\nnovel regularizers and advance the performance-efficiency frontier through\nmodel distillation. Furthermore, we demonstrate that the effect of context\ndelimiters (such as end-of-speech tokens) on ESS highlights cross-architectural\ndifferences in how large language models utilize their available memory to\nrecall information. Overall, we find that ESS provides valuable insights into\nthe dynamics that dictate memory utilization, enabling the design of more\nefficient and effective sequence models.", "AI": {"tldr": "The paper introduces a metric called Effective State-Size (ESS) to measure memory utilization in sequence models, offering interpretable insights for improving model design.", "motivation": "The expanding design space of sequence models necessitates a general framework for analyzing architecture, particularly memory utilization.", "method": "Leveraging classical signal processing and control theory, ESS is developed for systems with input-invariant and input-varying linear operators, applicable to attention, convolutions, and recurrences.", "result": "ESS provides actionable insights, improving initialization, regularization, and model distillation, while revealing cross-architectural differences in memory use.", "conclusion": "ESS enhances understanding of memory dynamics, aiding the design of more efficient and effective sequence models."}}
{"id": "2504.19323", "pdf": "https://arxiv.org/pdf/2504.19323", "abs": "https://arxiv.org/abs/2504.19323", "authors": ["Hanchen Yang", "Zishen Wan", "Ritik Raj", "Joongun Park", "Ziwei Li", "Ananda Samajdar", "Arijit Raychowdhury", "Tushar Krishna"], "title": "NSFlow: An End-to-End FPGA Framework with Scalable Dataflow Architecture for Neuro-Symbolic AI", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "Neuro-Symbolic AI (NSAI) is an emerging paradigm that integrates neural\nnetworks with symbolic reasoning to enhance the transparency, reasoning\ncapabilities, and data efficiency of AI systems. Recent NSAI systems have\ngained traction due to their exceptional performance in reasoning tasks and\nhuman-AI collaborative scenarios. Despite these algorithmic advancements,\nexecuting NSAI tasks on existing hardware (e.g., CPUs, GPUs, TPUs) remains\nchallenging, due to their heterogeneous computing kernels, high memory\nintensity, and unique memory access patterns. Moreover, current NSAI algorithms\nexhibit significant variation in operation types and scales, making them\nincompatible with existing ML accelerators. These challenges highlight the need\nfor a versatile and flexible acceleration framework tailored to NSAI workloads.\nIn this paper, we propose NSFlow, an FPGA-based acceleration framework designed\nto achieve high efficiency, scalability, and versatility across NSAI systems.\nNSFlow features a design architecture generator that identifies workload data\ndependencies and creates optimized dataflow architectures, as well as a\nreconfigurable array with flexible compute units, re-organizable memory, and\nmixed-precision capabilities. Evaluating across NSAI workloads, NSFlow achieves\n31x speedup over Jetson TX2, more than 2x over GPU, 8x speedup over TPU-like\nsystolic array, and more than 3x over Xilinx DPU. NSFlow also demonstrates\nenhanced scalability, with only 4x runtime increase when symbolic workloads\nscale by 150x. To the best of our knowledge, NSFlow is the first framework to\nenable real-time generalizable NSAI algorithms acceleration, demonstrating a\npromising solution for next-generation cognitive systems.", "AI": {"tldr": "NSFlow is an FPGA-based acceleration framework for Neuro-Symbolic AI (NSAI) workloads, achieving significant speedups over existing hardware like GPUs and TPUs.", "motivation": "Current hardware struggles with NSAI tasks due to heterogeneous computing kernels, high memory intensity, and incompatible operation types, necessitating a tailored acceleration framework.", "method": "NSFlow features a design architecture generator for optimized dataflow and a reconfigurable array with flexible compute units, memory, and mixed-precision capabilities.", "result": "NSFlow achieves 31x speedup over Jetson TX2, 2x over GPU, 8x over TPU-like arrays, and 3x over Xilinx DPU, with strong scalability.", "conclusion": "NSFlow is the first framework enabling real-time generalizable NSAI acceleration, promising for next-gen cognitive systems."}}
{"id": "2305.16326", "pdf": "https://arxiv.org/pdf/2305.16326", "abs": "https://arxiv.org/abs/2305.16326", "authors": ["Qingyu Chen", "Yan Hu", "Xueqing Peng", "Qianqian Xie", "Qiao Jin", "Aidan Gilson", "Maxwell B. Singer", "Xuguang Ai", "Po-Ting Lai", "Zhizheng Wang", "Vipina Kuttichi Keloth", "Kalpana Raja", "Jiming Huang", "Huan He", "Fongci Lin", "Jingcheng Du", "Rui Zhang", "W. Jim Zheng", "Ron A. Adelman", "Zhiyong Lu", "Hua Xu"], "title": "Benchmarking large language models for biomedical natural language processing applications and recommendations", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "The rapid growth of biomedical literature poses challenges for manual\nknowledge curation and synthesis. Biomedical Natural Language Processing\n(BioNLP) automates the process. While Large Language Models (LLMs) have shown\npromise in general domains, their effectiveness in BioNLP tasks remains unclear\ndue to limited benchmarks and practical guidelines.\n  We perform a systematic evaluation of four LLMs, GPT and LLaMA\nrepresentatives on 12 BioNLP benchmarks across six applications. We compare\ntheir zero-shot, few-shot, and fine-tuning performance with traditional\nfine-tuning of BERT or BART models. We examine inconsistencies, missing\ninformation, hallucinations, and perform cost analysis. Here we show that\ntraditional fine-tuning outperforms zero or few shot LLMs in most tasks.\nHowever, closed-source LLMs like GPT-4 excel in reasoning-related tasks such as\nmedical question answering. Open source LLMs still require fine-tuning to close\nperformance gaps. We find issues like missing information and hallucinations in\nLLM outputs. These results offer practical insights for applying LLMs in\nBioNLP.", "AI": {"tldr": "Traditional fine-tuning outperforms zero/few-shot LLMs in BioNLP tasks, but GPT-4 excels in reasoning tasks. Open-source LLMs need fine-tuning to match performance, with issues like hallucinations noted.", "motivation": "The rapid growth of biomedical literature necessitates automated NLP solutions, but LLMs' effectiveness in BioNLP lacks clear benchmarks and guidelines.", "method": "Systematic evaluation of four LLMs (GPT and LLaMA) on 12 BioNLP benchmarks across six applications, comparing zero-shot, few-shot, and fine-tuning performance against BERT/BART models.", "result": "Traditional fine-tuning beats zero/few-shot LLMs in most tasks; GPT-4 excels in reasoning tasks. Open-source LLMs lag without fine-tuning, with issues like hallucinations.", "conclusion": "LLMs show promise in BioNLP but require fine-tuning and caution due to inconsistencies. GPT-4 is strong in reasoning, while open-source models need improvement."}}
{"id": "2504.19574", "pdf": "https://arxiv.org/pdf/2504.19574", "abs": "https://arxiv.org/abs/2504.19574", "authors": ["Seongmin Hwang", "Daeyoung Han", "Moongu Jeon"], "title": "DG-DETR: Toward Domain Generalized Detection Transformer", "categories": ["cs.CV"], "comment": "Under Review", "summary": "End-to-end Transformer-based detectors (DETRs) have demonstrated strong\ndetection performance. However, domain generalization (DG) research has\nprimarily focused on convolutional neural network (CNN)-based detectors, while\npaying little attention to enhancing the robustness of DETRs. In this letter,\nwe introduce a Domain Generalized DEtection TRansformer (DG-DETR), a simple,\neffective, and plug-and-play method that improves out-of-distribution (OOD)\nrobustness for DETRs. Specifically, we propose a novel domain-agnostic query\nselection strategy that removes domain-induced biases from object queries via\northogonal projection onto the instance-specific style space. Additionally, we\nleverage a wavelet decomposition to disentangle features into domain-invariant\nand domain-specific components, enabling synthesis of diverse latent styles\nwhile preserving the semantic features of objects. Experimental results\nvalidate the effectiveness of DG-DETR. Our code is available at\nhttps://github.com/sminhwang/DG-DETR.", "AI": {"tldr": "DG-DETR enhances DETR's out-of-distribution robustness via domain-agnostic query selection and wavelet-based feature disentanglement.", "motivation": "Existing domain generalization research focuses on CNN-based detectors, neglecting DETRs. DG-DETR aims to improve DETR's robustness to unseen domains.", "method": "Proposes domain-agnostic query selection (removes biases via orthogonal projection) and wavelet decomposition (disentangles features into domain-invariant/specific components).", "result": "Experimental results confirm DG-DETR's effectiveness in improving DETR's out-of-distribution robustness.", "conclusion": "DG-DETR is a simple, plug-and-play solution for enhancing DETR's domain generalization capabilities."}}
{"id": "2504.19602", "pdf": "https://arxiv.org/pdf/2504.19602", "abs": "https://arxiv.org/abs/2504.19602", "authors": ["Kitsuya Azuma", "Takayuki Nishio", "Yuichi Kitagawa", "Wakako Nakano", "Takahito Tanimura"], "title": "Soft-Label Caching and Sharpening for Communication-Efficient Federated Distillation", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndecentralized clients, enhancing privacy by keeping data local. Yet\nconventional FL, relying on frequent parameter-sharing, suffers from high\ncommunication overhead and limited model heterogeneity. Distillation-based FL\napproaches address these issues by sharing predictions (soft-labels) instead,\nbut they often involve redundant transmissions across communication rounds,\nreducing efficiency. We propose SCARLET, a novel framework integrating\nsynchronized soft-label caching and an enhanced Entropy Reduction Aggregation\n(Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing\ncached soft-labels, achieving up to 50% reduction in communication costs\ncompared to existing methods while maintaining accuracy. Enhanced ERA can be\ntuned to adapt to non-IID data variations, ensuring robust aggregation and\nperformance in diverse client scenarios. Experimental evaluations demonstrate\nthat SCARLET consistently outperforms state-of-the-art distillation-based FL\nmethods in terms of accuracy and communication efficiency. The implementation\nof SCARLET is publicly available at https://github.com/kitsuyaazuma/SCARLET.", "AI": {"tldr": "SCARLET is a federated learning framework that reduces communication costs by 50% using synchronized soft-label caching and Enhanced ERA, while maintaining accuracy.", "motivation": "Address high communication overhead and limited model heterogeneity in conventional FL, and redundancy in distillation-based FL.", "method": "Integrates synchronized soft-label caching and Enhanced Entropy Reduction Aggregation (Enhanced ERA) to minimize redundant transmissions.", "result": "Achieves up to 50% reduction in communication costs and outperforms state-of-the-art methods in accuracy and efficiency.", "conclusion": "SCARLET is effective for diverse client scenarios, offering a robust and efficient solution for FL."}}
{"id": "2504.19341", "pdf": "https://arxiv.org/pdf/2504.19341", "abs": "https://arxiv.org/abs/2504.19341", "authors": ["Jialiang Zhao", "Naveen Kuppuswamy", "Siyuan Feng", "Benjamin Burchfiel", "Edward Adelson"], "title": "PolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation Using Tactile-Diffusion Policies", "categories": ["cs.RO", "cs.AI"], "comment": "Nominated for the best paper award at ICRA 2025", "summary": "Achieving robust dexterous manipulation in unstructured domestic environments\nremains a significant challenge in robotics. Even with state-of-the-art robot\nlearning methods, haptic-oblivious control strategies (i.e. those relying only\non external vision and/or proprioception) often fall short due to occlusions,\nvisual complexities, and the need for precise contact interaction control. To\naddress these limitations, we introduce PolyTouch, a novel robot finger that\nintegrates camera-based tactile sensing, acoustic sensing, and peripheral\nvisual sensing into a single design that is compact and durable. PolyTouch\nprovides high-resolution tactile feedback across multiple temporal scales,\nwhich is essential for efficiently learning complex manipulation tasks.\nExperiments demonstrate an at least 20-fold increase in lifespan over\ncommercial tactile sensors, with a design that is both easy to manufacture and\nscalable. We then use this multi-modal tactile feedback along with\nvisuo-proprioceptive observations to synthesize a tactile-diffusion policy from\nhuman demonstrations; the resulting contact-aware control policy significantly\noutperforms haptic-oblivious policies in multiple contact-aware manipulation\npolicies. This paper highlights how effectively integrating multi-modal contact\nsensing can hasten the development of effective contact-aware manipulation\npolicies, paving the way for more reliable and versatile domestic robots. More\ninformation can be found at https://polytouch.alanz.info/", "AI": {"tldr": "PolyTouch, a novel robot finger integrating tactile, acoustic, and visual sensing, improves dexterous manipulation by providing high-resolution tactile feedback, outperforming traditional haptic-oblivious methods.", "motivation": "Robust dexterous manipulation in unstructured environments is challenging due to occlusions, visual complexities, and precise contact control needs.", "method": "Introduces PolyTouch, combining camera-based tactile, acoustic, and peripheral visual sensing for multi-modal feedback, and synthesizes a tactile-diffusion policy from human demonstrations.", "result": "PolyTouch shows a 20-fold lifespan increase over commercial sensors and outperforms haptic-oblivious policies in contact-aware tasks.", "conclusion": "Multi-modal contact sensing accelerates effective manipulation policies, advancing reliable domestic robots."}}
{"id": "2309.15217", "pdf": "https://arxiv.org/pdf/2309.15217", "abs": "https://arxiv.org/abs/2309.15217", "authors": ["Shahul Es", "Jithin James", "Luis Espinosa-Anke", "Steven Schockaert"], "title": "Ragas: Automated Evaluation of Retrieval Augmented Generation", "categories": ["cs.CL"], "comment": "Reference-free (not tied to having ground truth available) evaluation\n  framework for retrieval agumented generation", "summary": "We introduce Ragas (Retrieval Augmented Generation Assessment), a framework\nfor reference-free evaluation of Retrieval Augmented Generation (RAG)\npipelines. RAG systems are composed of a retrieval and an LLM based generation\nmodule, and provide LLMs with knowledge from a reference textual database,\nwhich enables them to act as a natural language layer between a user and\ntextual databases, reducing the risk of hallucinations. Evaluating RAG\narchitectures is, however, challenging because there are several dimensions to\nconsider: the ability of the retrieval system to identify relevant and focused\ncontext passages, the ability of the LLM to exploit such passages in a faithful\nway, or the quality of the generation itself. With Ragas, we put forward a\nsuite of metrics which can be used to evaluate these different dimensions\n\\textit{without having to rely on ground truth human annotations}. We posit\nthat such a framework can crucially contribute to faster evaluation cycles of\nRAG architectures, which is especially important given the fast adoption of\nLLMs.", "AI": {"tldr": "Ragas is a framework for evaluating RAG pipelines without ground truth annotations, focusing on retrieval, generation, and faithfulness.", "motivation": "Evaluating RAG systems is complex due to multiple dimensions like retrieval relevance and generation quality, and ground truth annotations are often unavailable.", "method": "Ragas introduces a suite of metrics to assess retrieval, generation, and faithfulness in RAG pipelines without human annotations.", "result": "The framework enables faster evaluation cycles for RAG architectures, addressing the rapid adoption of LLMs.", "conclusion": "Ragas provides a scalable, reference-free solution for evaluating RAG systems, crucial for efficient development and deployment."}}
{"id": "2504.19581", "pdf": "https://arxiv.org/pdf/2504.19581", "abs": "https://arxiv.org/abs/2504.19581", "authors": ["Chengzhi Wu", "Yuxin Wan", "Hao Fu", "Julius Pfrommer", "Zeyun Zhong", "Junwei Zheng", "Jiaming Zhang", "J\u00fcrgen Beyerer"], "title": "SAMBLE: Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity", "categories": ["cs.CV"], "comment": null, "summary": "Driven by the increasing demand for accurate and efficient representation of\n3D data in various domains, point cloud sampling has emerged as a pivotal\nresearch topic in 3D computer vision. Recently, learning-to-sample methods have\ngarnered growing interest from the community, particularly for their ability to\nbe jointly trained with downstream tasks. However, previous learning-based\nsampling methods either lead to unrecognizable sampling patterns by generating\na new point cloud or biased sampled results by focusing excessively on sharp\nedge details. Moreover, they all overlook the natural variations in point\ndistribution across different shapes, applying a similar sampling strategy to\nall point clouds. In this paper, we propose a Sparse Attention Map and\nBin-based Learning method (termed SAMBLE) to learn shape-specific sampling\nstrategies for point cloud shapes. SAMBLE effectively achieves an improved\nbalance between sampling edge points for local details and preserving\nuniformity in the global shape, resulting in superior performance across\nmultiple common point cloud downstream tasks, even in scenarios with few-point\nsampling.", "AI": {"tldr": "SAMBLE is a learning-based method for point cloud sampling that balances edge detail preservation and global shape uniformity, outperforming prior methods in downstream tasks.", "motivation": "Addressing the limitations of existing learning-to-sample methods, which either produce unrecognizable patterns or biased results by ignoring shape-specific variations.", "method": "Proposes SAMBLE, using sparse attention maps and bin-based learning to tailor sampling strategies to individual point cloud shapes.", "result": "Achieves better balance between edge detail and global uniformity, improving performance in downstream tasks, even with few-point sampling.", "conclusion": "SAMBLE offers a robust, shape-specific approach to point cloud sampling, enhancing accuracy and efficiency in 3D data representation."}}
{"id": "2504.19638", "pdf": "https://arxiv.org/pdf/2504.19638", "abs": "https://arxiv.org/abs/2504.19638", "authors": ["Biqing Duan", "Qing Wang", "Di Liu", "Wei Zhou", "Zhenli He", "Shengfa Miao"], "title": "LODAP: On-Device Incremental Learning Via Lightweight Operations and Data Pruning", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "Incremental learning that learns new classes over time after the model's\ndeployment is becoming increasingly crucial, particularly for industrial edge\nsystems, where it is difficult to communicate with a remote server to conduct\ncomputation-intensive learning. As more classes are expected to learn after\ntheir execution for edge devices. In this paper, we propose LODAP, a new\non-device incremental learning framework for edge systems. The key part of\nLODAP is a new module, namely Efficient Incremental Module (EIM). EIM is\ncomposed of normal convolutions and lightweight operations. During incremental\nlearning, EIM exploits some lightweight operations, called adapters, to\neffectively and efficiently learn features for new classes so that it can\nimprove the accuracy of incremental learning while reducing model complexity as\nwell as training overhead. The efficiency of LODAP is further enhanced by a\ndata pruning strategy that significantly reduces the training data, thereby\nlowering the training overhead. We conducted extensive experiments on the\nCIFAR-100 and Tiny- ImageNet datasets. Experimental results show that LODAP\nimproves the accuracy by up to 4.32\\% over existing methods while reducing\naround 50\\% of model complexity. In addition, evaluations on real edge systems\ndemonstrate its applicability for on-device machine learning. The code is\navailable at https://github.com/duanbiqing/LODAP.", "AI": {"tldr": "LODAP is an on-device incremental learning framework for edge systems, featuring an Efficient Incremental Module (EIM) and data pruning to improve accuracy and reduce complexity.", "motivation": "Addressing the need for efficient incremental learning in edge systems where remote server communication is impractical.", "method": "Proposes LODAP with EIM, using lightweight adapters and data pruning to reduce training overhead.", "result": "Achieves up to 4.32% higher accuracy and 50% lower model complexity on CIFAR-100 and Tiny-ImageNet datasets.", "conclusion": "LODAP is effective for on-device incremental learning, validated by real-edge system evaluations."}}
{"id": "2504.19373", "pdf": "https://arxiv.org/pdf/2504.19373", "abs": "https://arxiv.org/abs/2504.19373", "authors": ["Weidi Luo", "Qiming Zhang", "Tianyu Lu", "Xiaogeng Liu", "Yue Zhao", "Zhen Xiang", "Chaowei Xiao"], "title": "Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The increasing capabilities of agentic multi-modal large reasoning models,\nsuch as ChatGPT o3, have raised critical concerns regarding privacy leakage\nthrough inadvertent image geolocation. In this paper, we conduct the first\nsystematic and controlled study on the potential privacy risks associated with\nvisual reasoning abilities of ChatGPT o3. We manually collect and construct a\ndataset comprising 50 real-world images that feature individuals alongside\nprivacy-relevant environmental elements, capturing realistic and sensitive\nscenarios for analysis. Our experimental evaluation reveals that ChatGPT o3 can\npredict user locations with high precision, achieving street-level accuracy\n(within one mile) in 60% of cases. Through analysis, we identify key visual\ncues, including street layout and front yard design, that significantly\ncontribute to the model inference success. Additionally, targeted occlusion\nexperiments demonstrate that masking critical features effectively mitigates\ngeolocation accuracy, providing insights into potential defense mechanisms. Our\nfindings highlight an urgent need for privacy-aware development for agentic\nmulti-modal large reasoning models, particularly in applications involving\nprivate imagery.", "AI": {"tldr": "The study examines privacy risks from ChatGPT o3's visual reasoning, finding it can geolocate images with 60% street-level accuracy. Key cues like street layout aid inference, while occlusion mitigates risks.", "motivation": "Address concerns about privacy leakage via image geolocation in multi-modal models like ChatGPT o3.", "method": "Manual collection of 50 real-world images with privacy-relevant elements, experimental evaluation, and targeted occlusion tests.", "result": "ChatGPT o3 achieves street-level geolocation accuracy in 60% of cases, with street layout and yard design as key cues. Occlusion reduces accuracy.", "conclusion": "Urgent need for privacy-aware development in multi-modal models handling private imagery."}}
{"id": "2405.13056", "pdf": "https://arxiv.org/pdf/2405.13056", "abs": "https://arxiv.org/abs/2405.13056", "authors": ["Rohitash Chandra", "Baicheng Zhu", "Qingying Fang", "Eka Shinjikashvili"], "title": "Large language models for newspaper sentiment analysis during COVID-19: The Guardian", "categories": ["cs.CL", "cs.SI"], "comment": null, "summary": "During the COVID-19 pandemic, the news media coverage encompassed a wide\nrange of topics that includes viral transmission, allocation of medical\nresources, and government response measures. There have been studies on\nsentiment analysis of social media platforms during COVID-19 to understand the\npublic response given the rise of cases and government strategies implemented\nto control the spread of the virus. Sentiment analysis can provide a better\nunderstanding of changes in societal opinions and emotional trends during the\npandemic. Apart from social media, newspapers have played a vital role in the\ndissemination of information, including information from the government,\nexperts, and also the public about various topics. A study of sentiment\nanalysis of newspaper sources during COVID-19 for selected countries can give\nan overview of how the media covered the pandemic. In this study, we select The\nGuardian newspaper and provide a sentiment analysis during various stages of\nCOVID-19 that includes initial transmission, lockdowns and vaccination. We\nemploy novel large language models (LLMs) and refine them with expert-labelled\nsentiment analysis data. We also provide an analysis of sentiments experienced\npre-pandemic for comparison. The results indicate that during the early\npandemic stages, public sentiment prioritised urgent crisis response, later\nshifting focus to addressing the impact on health and the economy. In\ncomparison with related studies about social media sentiment analyses, we found\na discrepancy between The Guardian with dominance of negative sentiments (sad,\nannoyed, anxious and denial), suggesting that social media offers a more\ndiversified emotional reflection. We found a grim narrative in The Guardian\nwith overall dominance of negative sentiments, pre and during COVID-19 across\nnews sections including Australia, UK, World News, and Opinion", "AI": {"tldr": "The study analyzes sentiment in The Guardian newspaper during COVID-19 stages (transmission, lockdowns, vaccination) using LLMs and expert-labelled data, revealing a dominance of negative sentiments compared to social media's diverse emotional reflection.", "motivation": "To understand media sentiment during COVID-19 and compare it with pre-pandemic sentiments and social media analyses.", "method": "Employed novel large language models (LLMs) refined with expert-labelled sentiment analysis data on The Guardian's coverage.", "result": "Early pandemic sentiment focused on crisis response, later shifting to health and economy. The Guardian showed a grim narrative with dominant negative sentiments, unlike social media's diversity.", "conclusion": "The Guardian's coverage was consistently negative, differing from social media's varied emotional responses, highlighting media's role in shaping public sentiment during crises."}}
{"id": "2504.19584", "pdf": "https://arxiv.org/pdf/2504.19584", "abs": "https://arxiv.org/abs/2504.19584", "authors": ["Sangmin Kim", "Seunguk Do", "Jaesik Park"], "title": "ShowMak3r: Compositional TV Show Reconstruction", "categories": ["cs.CV"], "comment": "Project page : https://nstar1125.github.io/showmak3r", "summary": "Reconstructing dynamic radiance fields from video clips is challenging,\nespecially when entertainment videos like TV shows are given. Many challenges\nmake the reconstruction difficult due to (1) actors occluding with each other\nand having diverse facial expressions, (2) cluttered stages, and (3) small\nbaseline views or sudden shot changes. To address these issues, we present\nShowMak3r, a comprehensive reconstruction pipeline that allows the editing of\nscenes like how video clips are made in a production control room. In\nShowMak3r, a 3DLocator module locates recovered actors on the stage using depth\nprior and estimates unseen human poses via interpolation. The proposed\nShotMatcher module then tracks the actors under shot changes. Furthermore,\nShowMak3r introduces a face-fitting network that dynamically recovers the\nactors' expressions. Experiments on Sitcoms3D dataset show that our pipeline\ncan reassemble TV show scenes with new cameras at different timestamps. We also\ndemonstrate that ShowMak3r enables interesting applications such as synthetic\nshot-making, actor relocation, insertion, deletion, and pose manipulation.\nProject page : https://nstar1125.github.io/showmak3r", "AI": {"tldr": "ShowMak3r is a pipeline for reconstructing and editing dynamic radiance fields from challenging TV show videos, addressing occlusion, cluttered stages, and shot changes.", "motivation": "Reconstructing dynamic radiance fields from entertainment videos is difficult due to actor occlusion, diverse expressions, cluttered stages, and shot changes.", "method": "ShowMak3r uses a 3DLocator for actor positioning and pose estimation, a ShotMatcher for tracking across shots, and a face-fitting network for expression recovery.", "result": "Experiments on Sitcoms3D show successful scene reassembly with new cameras and timestamps, enabling applications like synthetic shot-making and actor manipulation.", "conclusion": "ShowMak3r effectively reconstructs and edits dynamic scenes from TV shows, offering practical applications in video production."}}
{"id": "2504.19639", "pdf": "https://arxiv.org/pdf/2504.19639", "abs": "https://arxiv.org/abs/2504.19639", "authors": ["Youngjoon Lee", "Jinu Gong", "Joonhyuk Kang"], "title": "A Unified Benchmark of Federated Learning with Kolmogorov-Arnold Networks for Medical Imaging", "categories": ["cs.LG", "eess.SP"], "comment": "5 pages", "summary": "Federated Learning (FL) enables model training across decentralized devices\nwithout sharing raw data, thereby preserving privacy in sensitive domains like\nhealthcare. In this paper, we evaluate Kolmogorov-Arnold Networks (KAN)\narchitectures against traditional MLP across six state-of-the-art FL algorithms\non a blood cell classification dataset. Notably, our experiments demonstrate\nthat KAN can effectively replace MLP in federated environments, achieving\nsuperior performance with simpler architectures. Furthermore, we analyze the\nimpact of key hyperparameters-grid size and network architecture-on KAN\nperformance under varying degrees of Non-IID data distribution. Additionally,\nour ablation studies reveal that optimizing KAN width while maintaining minimal\ndepth yields the best performance in federated settings. As a result, these\nfindings establish KAN as a promising alternative for privacy-preserving\nmedical imaging applications in distributed healthcare. To the best of our\nknowledge, this is the first comprehensive benchmark of KAN in FL settings for\nmedical imaging task.", "AI": {"tldr": "Kolmogorov-Arnold Networks (KAN) outperform MLPs in federated learning for medical imaging, offering simpler architectures and better performance under Non-IID data.", "motivation": "To evaluate KAN's potential as a privacy-preserving alternative to MLPs in federated learning, especially in healthcare.", "method": "Benchmarked KAN against MLP using six FL algorithms on a blood cell classification dataset, analyzing hyperparameters and Non-IID data impact.", "result": "KAN achieved superior performance with simpler architectures, optimized by adjusting width and minimal depth.", "conclusion": "KAN is a promising alternative for privacy-preserving medical imaging in distributed healthcare, marking the first comprehensive FL benchmark for KAN."}}
{"id": "2504.19384", "pdf": "https://arxiv.org/pdf/2504.19384", "abs": "https://arxiv.org/abs/2504.19384", "authors": ["Syed Tauhid Ullah Shah", "Mohamad Hussein", "Ann Barcomb", "Mohammad Moshirpour"], "title": "From Inductive to Deductive: LLMs-Based Qualitative Data Analysis in Requirements Engineering", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Requirements Engineering (RE) is essential for developing complex and\nregulated software projects. Given the challenges in transforming stakeholder\ninputs into consistent software designs, Qualitative Data Analysis (QDA)\nprovides a systematic approach to handling free-form data. However, traditional\nQDA methods are time-consuming and heavily reliant on manual effort. In this\npaper, we explore the use of Large Language Models (LLMs), including GPT-4,\nMistral, and LLaMA-2, to improve QDA tasks in RE. Our study evaluates LLMs'\nperformance in inductive (zero-shot) and deductive (one-shot, few-shot)\nannotation tasks, revealing that GPT-4 achieves substantial agreement with\nhuman analysts in deductive settings, with Cohen's Kappa scores exceeding 0.7,\nwhile zero-shot performance remains limited. Detailed, context-rich prompts\nsignificantly improve annotation accuracy and consistency, particularly in\ndeductive scenarios, and GPT-4 demonstrates high reliability across repeated\nruns. These findings highlight the potential of LLMs to support QDA in RE by\nreducing manual effort while maintaining annotation quality. The structured\nlabels automatically provide traceability of requirements and can be directly\nutilized as classes in domain models, facilitating systematic software design.", "AI": {"tldr": "The paper explores using LLMs like GPT-4 for Qualitative Data Analysis in Requirements Engineering, showing GPT-4's strong performance in deductive tasks with high agreement to human analysts.", "motivation": "To address the time-consuming and manual nature of traditional QDA methods in RE by leveraging LLMs for efficiency and consistency.", "method": "Evaluates LLMs (GPT-4, Mistral, LLaMA-2) in inductive (zero-shot) and deductive (one-shot, few-shot) annotation tasks, measuring performance via Cohen's Kappa scores.", "result": "GPT-4 achieves high agreement (Kappa > 0.7) in deductive tasks, with detailed prompts improving accuracy. Zero-shot performance is limited.", "conclusion": "LLMs, especially GPT-4, can reduce manual effort in QDA for RE while maintaining quality, aiding systematic software design."}}
{"id": "2407.02122", "pdf": "https://arxiv.org/pdf/2407.02122", "abs": "https://arxiv.org/abs/2407.02122", "authors": ["Soveatin Kuntur", "Anna Wr\u00f3blewska", "Marcin Paprzycki", "Maria Ganzha"], "title": "Fake News Detection: It's All in the Data!", "categories": ["cs.CL"], "comment": null, "summary": "This comprehensive survey serves as an indispensable resource for researchers\nembarking on the journey of fake news detection. By highlighting the pivotal\nrole of dataset quality and diversity, it underscores the significance of these\nelements in the effectiveness and robustness of detection models. The survey\nmeticulously outlines the key features of datasets, various labeling systems\nemployed, and prevalent biases that can impact model performance. Additionally,\nit addresses critical ethical issues and best practices, offering a thorough\noverview of the current state of available datasets. Our contribution to this\nfield is further enriched by the provision of GitHub repository, which\nconsolidates publicly accessible datasets into a single, user-friendly portal.\nThis repository is designed to facilitate and stimulate further research and\ndevelopment efforts aimed at combating the pervasive issue of fake news.", "AI": {"tldr": "A survey on fake news detection emphasizing dataset quality, diversity, and ethical issues, with a GitHub repository for accessible datasets.", "motivation": "To provide researchers with a resource highlighting the importance of dataset quality and diversity in fake news detection, addressing biases and ethical concerns.", "method": "Survey of key dataset features, labeling systems, biases, and ethical issues, supplemented by a GitHub repository of datasets.", "result": "Identifies critical dataset attributes and biases, offers a centralized dataset repository to aid research.", "conclusion": "The survey and repository aim to enhance fake news detection research by improving dataset accessibility and awareness of ethical considerations."}}
{"id": "2504.19592", "pdf": "https://arxiv.org/pdf/2504.19592", "abs": "https://arxiv.org/abs/2504.19592", "authors": ["Roman Malashin", "Daniil Ilyukhin"], "title": "Neural network task specialization via domain constraining", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper introduces a concept of neural network specialization via\ntask-specific domain constraining, aimed at enhancing network performance on\ndata subspace in which the network operates. The study presents experiments on\ntraining specialists for image classification and object detection tasks. The\nresults demonstrate that specialization can enhance a generalist's accuracy\neven without additional data or changing training regimes: solely by\nconstraining class label space in which the network performs. Theoretical and\nexperimental analyses indicate that effective specialization requires modifying\ntraditional fine-tuning methods and constraining data space to semantically\ncoherent subsets. The specialist extraction phase before tuning the network is\nproposed for maximal performance gains. We also provide analysis of the\nevolution of the feature space during specialization. This study paves way to\nfuture research for developing more advanced dynamically configurable image\nanalysis systems, where computations depend on the specific input.\nAdditionally, the proposed methods can help improve system performance in\nscenarios where certain data domains should be excluded from consideration of\nthe generalist network.", "AI": {"tldr": "Specializing neural networks by constraining their domain improves performance without extra data or training changes, focusing on coherent data subsets.", "motivation": "Enhance neural network performance on specific data subspaces by specializing them for tasks like image classification and object detection.", "method": "Task-specific domain constraining, modifying fine-tuning methods, and extracting specialists before tuning. Analyzes feature space evolution.", "result": "Specialization boosts generalist accuracy by constraining class label space, requiring coherent data subsets for effectiveness.", "conclusion": "Paves the way for dynamically configurable systems and improves performance by excluding irrelevant data domains."}}
{"id": "2504.19649", "pdf": "https://arxiv.org/pdf/2504.19649", "abs": "https://arxiv.org/abs/2504.19649", "authors": ["Lei Xu", "Shanshan Wang", "Emmanuel Casseau", "Chenglong Xiao"], "title": "Intelligent4DSE: Optimizing High-Level Synthesis Design Space Exploration with Graph Neural Networks and Large Language Models", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "High-level synthesis (HLS) design space exploration (DSE) is an optimization\nprocess in electronic design automation (EDA) that systematically explores\nhigh-level design configurations to achieve Pareto-optimal hardware\nimplementations balancing performance, area, and power (PPA). To optimize this\nprocess, HLS prediction tasks often employ message-passing neural networks\n(MPNNs), leveraging complex architectures to achieve high accuracy. These\npredictors serve as evaluators in the DSE process, effectively bypassing the\ntime-consuming estimations traditionally required by HLS tools. However,\nexisting models often prioritize structural complexity and minimization of\ntraining loss, overlooking task-specific characteristics. Additionally, while\nevolutionary algorithms are widely used in DSE, they typically require\nextensive domain-specific knowledge to design effective crossover and mutation\noperators. To address these limitations, we propose CoGNNs-LLMEA, a framework\nthat integrates a graph neural network with task-adaptive message passing and a\nlarge language model-enhanced evolutionary algorithm. As a predictive model,\nCoGNNs directly leverages intermediate representations generated from source\ncode after compiler front-end processing, enabling prediction of quality of\nresults (QoR) without invoking HLS tools. Due to its strong adaptability to\ntasks, CoGNNs can be tuned to predict post-HLS and post-implementation\noutcomes, effectively bridging the gap between high-level abstractions and\nphysical implementation characteristics. CoGNNs achieves state-of-the-art\nprediction accuracy in post-HLS QoR prediction, reducing mean prediction errors\nby 2.8$\\times$ for latency and 3.4$\\times$ for resource utilization compared to\nbaseline models.", "AI": {"tldr": "The paper introduces CoGNNs-LLMEA, a framework combining graph neural networks and a large language model-enhanced evolutionary algorithm to improve HLS design space exploration by predicting QoR without HLS tools, achieving state-of-the-art accuracy.", "motivation": "Existing HLS DSE methods prioritize structural complexity and training loss, overlooking task-specific needs, while evolutionary algorithms require extensive domain knowledge. The paper aims to address these gaps.", "method": "Proposes CoGNNs-LLMEA, integrating a task-adaptive graph neural network (CoGNNs) with a large language model-enhanced evolutionary algorithm (LLMEA) to predict QoR from compiler front-end outputs.", "result": "CoGNNs reduces mean prediction errors by 2.8\u00d7 for latency and 3.4\u00d7 for resource utilization compared to baselines, achieving state-of-the-art accuracy in post-HLS QoR prediction.", "conclusion": "The framework effectively bridges high-level abstractions and physical implementation, offering a more efficient and accurate approach to HLS DSE."}}
{"id": "2504.19394", "pdf": "https://arxiv.org/pdf/2504.19394", "abs": "https://arxiv.org/abs/2504.19394", "authors": ["Toby Simonds"], "title": "LLMs for Engineering: Teaching Models to Design High Powered Rockets", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have transformed software engineering, but their\napplication to physical engineering domains remains underexplored. This paper\nevaluates LLMs' capabilities in high-powered rocketry design through\nRocketBench, a benchmark connecting LLMs to high-fidelity rocket simulations.\nWe test models on two increasingly complex design tasks: target altitude\noptimization and precision landing challenges. Our findings reveal that while\nstate-of-the-art LLMs demonstrate strong baseline engineering knowledge, they\nstruggle to iterate on their designs when given simulation results and\nultimately plateau below human performance levels. However, when enhanced with\nreinforcement learning (RL), we show that a 7B parameter model outperforms both\nSoTA foundation models and human experts. This research demonstrates that\nRL-trained LLMs can serve as effective tools for complex engineering\noptimization, potentially transforming engineering domains beyond software\ndevelopment.", "AI": {"tldr": "LLMs show promise in rocketry design but plateau below human performance without RL. RL-enhanced LLMs outperform humans and SoTA models.", "motivation": "Explore LLMs' potential in physical engineering, specifically high-powered rocketry, beyond software domains.", "method": "Use RocketBench to test LLMs on rocket design tasks (altitude optimization, precision landing) and enhance them with RL.", "result": "LLMs plateau below human performance without RL, but RL-trained LLMs outperform humans and SoTA models.", "conclusion": "RL-trained LLMs can revolutionize complex engineering optimization beyond software."}}
{"id": "2408.02239", "pdf": "https://arxiv.org/pdf/2408.02239", "abs": "https://arxiv.org/abs/2408.02239", "authors": ["Nathan Brown", "Vukosi Marivate"], "title": "Pula: Training Large Language Models for Setswana", "categories": ["cs.CL"], "comment": "NAACL 2025. 10 pages, 5 tables, 1 figure", "summary": "In this work we present Pula, a suite of bilingual language models proficient\nin both Setswana and English. Leveraging recent advancements in data\navailability and efficient fine-tuning, Pula 8B and Pula 14B outperform GPT-4o\nand Gemini 1.5 Pro on English-Setswana translation tasks and achieve\nstate-of-the-art performance on Setswana reasoning tasks for their size. We\nrelease the weights for Pula 1B, 3B, 8B, and 14B as well as training logs and\ntraining and evaluation code. Alongside Pula, we release the largest-ever\nSetswana text corpus, Marothodi, and the first comprehensive Setswana\ninstruction-tuning dataset, Medupi, consisting of reformatted datasets,\ntranslated corpora, and synthetic LLM-generated text. To accompany this data,\nwe release the code used for dataset construction, formatting, filtering, and\nscraping. Last, we release two Setswana LLM-translated benchmarks, MMLU-tsn and\nGSM8K-tsn, to measure Setswana knowledge and reasoning capabilities.", "AI": {"tldr": "Pula is a bilingual (Setswana-English) language model suite outperforming GPT-4o and Gemini 1.5 Pro in translation and reasoning tasks. It includes released weights, datasets, and benchmarks.", "motivation": "To advance Setswana language processing by creating high-performing bilingual models and comprehensive datasets.", "method": "Leveraged data availability and efficient fine-tuning to develop Pula models (1B to 14B), alongside datasets (Marothodi, Medupi) and benchmarks (MMLU-tsn, GSM8K-tsn).", "result": "Pula 8B and 14B outperform GPT-4o and Gemini 1.5 Pro in English-Setswana translation and Setswana reasoning tasks.", "conclusion": "Pula and its resources significantly advance Setswana NLP, providing tools and benchmarks for future research."}}
{"id": "2504.19598", "pdf": "https://arxiv.org/pdf/2504.19598", "abs": "https://arxiv.org/abs/2504.19598", "authors": ["Dou Quan", "Rufan Zhou", "Shuang Wang", "Ning Huyan", "Dong Zhao", "Yunan Li", "Licheng Jiao"], "title": "Lightweight Adapter Learning for More Generalized Remote Sensing Change Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep learning methods have shown promising performances in remote sensing\nimage change detection (CD). However, existing methods usually train a\ndataset-specific deep network for each dataset. Due to the significant\ndifferences in the data distribution and labeling between various datasets, the\ntrained dataset-specific deep network has poor generalization performances on\nother datasets. To solve this problem, this paper proposes a change adapter\nnetwork (CANet) for a more universal and generalized CD. CANet contains\ndataset-shared and dataset-specific learning modules. The former explores the\ndiscriminative features of images, and the latter designs a lightweight adapter\nmodel, to deal with the characteristics of different datasets in data\ndistribution and labeling. The lightweight adapter can quickly generalize the\ndeep network for new CD tasks with a small computation cost. Specifically, this\npaper proposes an interesting change region mask (ICM) in the adapter, which\ncan adaptively focus on interested change objects and decrease the influence of\nlabeling differences in various datasets. Moreover, CANet adopts a unique batch\nnormalization layer for each dataset to deal with data distribution\ndifferences. Compared with existing deep learning methods, CANet can achieve\nsatisfactory CD performances on various datasets simultaneously. Experimental\nresults on several public datasets have verified the effectiveness and\nadvantages of the proposed CANet on CD. CANet has a stronger generalization\nability, smaller training costs (merely updating 4.1%-7.7% parameters), and\nbetter performances under limited training datasets than other deep learning\nmethods, which also can be flexibly inserted with existing deep models.", "AI": {"tldr": "The paper proposes CANet, a change adapter network for universal remote sensing image change detection, combining dataset-shared and dataset-specific modules for better generalization and efficiency.", "motivation": "Existing deep learning methods for change detection are dataset-specific and lack generalization across datasets due to data distribution and labeling differences.", "method": "CANet uses shared and specific modules, including a lightweight adapter with an interesting change region mask (ICM) and dataset-specific batch normalization.", "result": "CANet achieves strong generalization, lower training costs (4.1%-7.7% parameter updates), and better performance with limited data compared to existing methods.", "conclusion": "CANet is effective, flexible, and outperforms other deep learning methods in change detection tasks across diverse datasets."}}
{"id": "2504.19659", "pdf": "https://arxiv.org/pdf/2504.19659", "abs": "https://arxiv.org/abs/2504.19659", "authors": ["Muhammad Sabih", "Abrarul Karim", "Jakob Wittmann", "Frank Hannig", "J\u00fcrgen Teich"], "title": "Hardware/Software Co-Design of RISC-V Extensions for Accelerating Sparse DNNs on FPGAs", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": null, "summary": "The customizability of RISC-V makes it an attractive choice for accelerating\ndeep neural networks (DNNs). It can be achieved through instruction set\nextensions and corresponding custom functional units. Yet, efficiently\nexploiting these opportunities requires a hardware/software co-design approach\nin which the DNN model, software, and hardware are designed together. In this\npaper, we propose novel RISC-V extensions for accelerating DNN models\ncontaining semi-structured and unstructured sparsity. While the idea of\naccelerating structured and unstructured pruning is not new, our novel design\noffers various advantages over other designs. To exploit semi-structured\nsparsity, we take advantage of the fine-grained (bit-level) configurability of\nFPGAs and suggest reserving a few bits in a block of DNN weights to encode the\ninformation about sparsity in the succeeding blocks. The proposed custom\nfunctional unit utilizes this information to skip computations. To exploit\nunstructured sparsity, we propose a variable cycle sequential\nmultiply-and-accumulate unit that performs only as many multiplications as the\nnon-zero weights. Our implementation of unstructured and semi-structured\npruning accelerators can provide speedups of up to a factor of 3 and 4,\nrespectively. We then propose a combined design that can accelerate both types\nof sparsities, providing speedups of up to a factor of 5. Our designs consume a\nsmall amount of additional FPGA resources such that the resulting co-designs\nenable the acceleration of DNNs even on small FPGAs. We benchmark our designs\non standard TinyML applications such as keyword spotting, image classification,\nand person detection.", "AI": {"tldr": "The paper proposes RISC-V extensions for accelerating DNNs with semi-structured and unstructured sparsity, achieving speedups of up to 5x while using minimal FPGA resources.", "motivation": "RISC-V's customizability makes it ideal for DNN acceleration, but efficient exploitation requires co-design of hardware and software.", "method": "Novel RISC-V extensions and custom functional units are introduced to handle sparsity: bit-level configurability for semi-structured sparsity and variable-cycle multiply-and-accumulate for unstructured sparsity.", "result": "Speedups of 3x for unstructured and 4x for semi-structured sparsity, with a combined design achieving 5x. Minimal FPGA resource usage enables deployment on small devices.", "conclusion": "The proposed co-design approach effectively accelerates DNNs on RISC-V, demonstrating significant performance gains for TinyML applications."}}
{"id": "2504.19409", "pdf": "https://arxiv.org/pdf/2504.19409", "abs": "https://arxiv.org/abs/2504.19409", "authors": ["Zuxing Lu", "Xin Yuan", "Shaowen Yang", "Jingyu Liu", "Jiawei Wang", "Changyin Sun"], "title": "GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Semantic-aware 3D scene reconstruction is essential for autonomous robots to\nperform complex interactions. Semantic SLAM, an online approach, integrates\npose tracking, geometric reconstruction, and semantic mapping into a unified\nframework, shows significant potential. However, existing systems, which rely\non 2D ground truth priors for supervision, are often limited by the sparsity\nand noise of these signals in real-world environments. To address this\nchallenge, we propose GSFF-SLAM, a novel dense semantic SLAM system based on 3D\nGaussian Splatting that leverages feature fields to achieve joint rendering of\nappearance, geometry, and N-dimensional semantic features. By independently\noptimizing feature gradients, our method supports semantic reconstruction using\nvarious forms of 2D priors, particularly sparse and noisy signals. Experimental\nresults demonstrate that our approach outperforms previous methods in both\ntracking accuracy and photorealistic rendering quality. When utilizing 2D\nground truth priors, GSFF-SLAM achieves state-of-the-art semantic segmentation\nperformance with 95.03\\% mIoU, while achieving up to 2.9$\\times$ speedup with\nonly marginal performance degradation.", "AI": {"tldr": "GSFF-SLAM is a dense semantic SLAM system using 3D Gaussian Splatting and feature fields for joint rendering of appearance, geometry, and semantics, outperforming prior methods in accuracy and speed.", "motivation": "Existing semantic SLAM systems rely on 2D ground truth priors, which are sparse and noisy, limiting performance in real-world environments.", "method": "Proposes GSFF-SLAM, leveraging 3D Gaussian Splatting and feature fields to optimize feature gradients for semantic reconstruction with various 2D priors.", "result": "Achieves 95.03% mIoU in semantic segmentation and up to 2.9x speedup with minimal performance loss.", "conclusion": "GSFF-SLAM advances semantic SLAM by handling sparse/noisy signals and improving accuracy and efficiency."}}
{"id": "2408.05906", "pdf": "https://arxiv.org/pdf/2408.05906", "abs": "https://arxiv.org/abs/2408.05906", "authors": ["Peinan Zhang", "Yusuke Sakai", "Masato Mita", "Hiroki Ouchi", "Taro Watanabe"], "title": "AdTEC: A Unified Benchmark for Evaluating Text Quality in Search Engine Advertising", "categories": ["cs.CL"], "comment": "Accepted to NAACL 2025", "summary": "With the increase in the fluency of ad texts automatically created by natural\nlanguage generation technology, there is high demand to verify the quality of\nthese creatives in a real-world setting. We propose AdTEC (Ad Text Evaluation\nBenchmark by CyberAgent), the first public benchmark to evaluate ad texts from\nmultiple perspectives within practical advertising operations. Our\ncontributions are as follows: (i) Defining five tasks for evaluating the\nquality of ad texts, as well as building a Japanese dataset based on the\npractical operational experiences of building a Japanese dataset based on the\npractical operational experiences of advertising agencies, which are typically\nkept in-house. (ii) Validating the performance of existing pre-trained language\nmodels (PLMs) and human evaluators on the dataset. (iii) Analyzing the\ncharacteristics and providing challenges of the benchmark. The results show\nthat while PLMs have already reached practical usage level in several tasks,\nhumans still outperform in certain domains, implying that there is significant\nroom for improvement in this area.", "AI": {"tldr": "AdTEC is the first public benchmark for evaluating ad texts, defining five tasks and validating PLMs and human performance, showing PLMs are practical but humans still outperform in some areas.", "motivation": "To address the need for verifying the quality of automatically generated ad texts in real-world settings.", "method": "Proposed AdTEC benchmark with five evaluation tasks, built a Japanese dataset from advertising agency experiences, and tested PLMs and human evaluators.", "result": "PLMs are practical for some tasks, but humans outperform in certain domains, indicating room for improvement.", "conclusion": "AdTEC provides a valuable benchmark for ad text evaluation, highlighting the gap between PLMs and human performance."}}
{"id": "2504.19600", "pdf": "https://arxiv.org/pdf/2504.19600", "abs": "https://arxiv.org/abs/2504.19600", "authors": ["Pengfei Zhang", "Shouqing Jia"], "title": "Image Generation Method Based on Heat Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Denoising Diffusion Probabilistic Models (DDPMs) achieve high-quality image\ngeneration without adversarial training, but they process images as a whole.\nSince adjacent pixels are highly likely to belong to the same object, we\npropose the Heat Diffusion Model (HDM) to further preserve image details and\ngenerate more realistic images. HDM is a model that incorporates pixel-level\noperations while maintaining the same training process as DDPM. In HDM, the\ndiscrete form of the two-dimensional heat equation is integrated into the\ndiffusion and generation formulas of DDPM, enabling the model to compute\nrelationships between neighboring pixels during image processing. Our\nexperiments demonstrate that HDM can generate higher-quality samples compared\nto models such as DDPM, Consistency Diffusion Models (CDM), Latent Diffusion\nModels (LDM), and Vector Quantized Generative Adversarial Networks (VQGAN).", "AI": {"tldr": "HDM improves image generation by incorporating pixel-level heat diffusion into DDPM, outperforming DDPM, CDM, LDM, and VQGAN.", "motivation": "Adjacent pixels likely belong to the same object, so preserving details via pixel-level operations can enhance realism.", "method": "Integrates the 2D heat equation into DDPM's diffusion and generation formulas to compute neighbor pixel relationships.", "result": "HDM generates higher-quality images than DDPM, CDM, LDM, and VQGAN.", "conclusion": "HDM enhances image generation by leveraging pixel-level heat diffusion, outperforming existing models."}}
{"id": "2504.19667", "pdf": "https://arxiv.org/pdf/2504.19667", "abs": "https://arxiv.org/abs/2504.19667", "authors": ["Michael Banf", "Johannes Kuhn"], "title": "A Tripartite Perspective on GraphRAG", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious domains, yet they struggle with knowledge-intensive tasks in areas that\ndemand factual accuracy, e.g. industrial automation and healthcare. Key\nlimitations include their tendency to hallucinate, lack of source traceability\n(provenance), and challenges in timely knowledge updates. Combining language\nmodels with knowledge graphs (GraphRAG) offers promising avenues for overcoming\nthese deficits. However, a major challenge lies in creating such a knowledge\ngraph in the first place. Here, we propose a novel approach that combines LLMs\nwith a tripartite knowledge graph representation, which is constructed by\nconnecting complex, domain-specific objects via a curated ontology of\ncorresponding, domain-specific concepts to relevant sections within chunks of\ntext through a concept-anchored pre-analysis of source documents starting from\nan initial lexical graph. As a consequence, our Tripartite-GraphRAG approach\nimplements: i) a concept-specific, information-preserving pre-compression of\ntextual chunks; ii) allows for the formation of a concept-specific relevance\nestimation of embedding similarities grounded in statistics; and iii) avoids\ncommon challenges w.r.t. continuous extendability, such as the need for entity\nresolution and deduplication. By applying a transformation to the knowledge\ngraph, we formulate LLM prompt creation as an unsupervised node classification\nproblem, drawing on ideas from Markov Random Fields. We evaluate our approach\non a healthcare use case, involving multi-faceted analyses of patient anamneses\ngiven a set of medical concepts as well as clinical literature. Experiments\nindicate that it can optimize information density, coverage, and arrangement of\nLLM prompts while reducing their lengths, which may lead to reduced costs and\nmore consistent and reliable LLM outputs.", "AI": {"tldr": "The paper proposes Tripartite-GraphRAG, a method combining LLMs with a tripartite knowledge graph to improve factual accuracy and knowledge updates, evaluated in healthcare.", "motivation": "LLMs struggle with knowledge-intensive tasks due to hallucinations, lack of provenance, and outdated knowledge. Integrating knowledge graphs could address these issues.", "method": "The approach constructs a tripartite knowledge graph via domain-specific concepts, enabling concept-specific text compression, relevance estimation, and avoiding entity resolution challenges.", "result": "The method optimizes LLM prompt information density, coverage, and arrangement, reducing prompt length and improving reliability in healthcare use cases.", "conclusion": "Tripartite-GraphRAG enhances LLM performance in knowledge-intensive domains by leveraging structured knowledge graphs, offering cost and reliability benefits."}}
{"id": "2504.19426", "pdf": "https://arxiv.org/pdf/2504.19426", "abs": "https://arxiv.org/abs/2504.19426", "authors": ["Steffen Dereich", "Arnulf Jentzen", "Adrian Riekert"], "title": "Sharp higher order convergence rates for the Adam optimizer", "categories": ["math.OC", "cs.AI", "68T05, 65K05, 90C25", "I.2.0"], "comment": "27 pages", "summary": "Gradient descent based optimization methods are the methods of choice to\ntrain deep neural networks in machine learning. Beyond the standard gradient\ndescent method, also suitable modified variants of standard gradient descent\ninvolving acceleration techniques such as the momentum method and/or adaptivity\ntechniques such as the RMSprop method are frequently considered optimization\nmethods. These days the most popular of such sophisticated optimization schemes\nis presumably the Adam optimizer that has been proposed in 2014 by Kingma and\nBa. A highly relevant topic of research is to investigate the speed of\nconvergence of such optimization methods. In particular, in 1964 Polyak showed\nthat the standard gradient descent method converges in a neighborhood of a\nstrict local minimizer with rate (x - 1)(x + 1)^{-1} while momentum achieves\nthe (optimal) strictly faster convergence rate (\\sqrt{x} - 1)(\\sqrt{x} +\n1)^{-1} where x \\in (1,\\infty) is the condition number (the ratio of the\nlargest and the smallest eigenvalue) of the Hessian of the objective function\nat the local minimizer. It is the key contribution of this work to reveal that\nAdam also converges with the strictly faster convergence rate (\\sqrt{x} -\n1)(\\sqrt{x} + 1)^{-1} while RMSprop only converges with the convergence rate (x\n- 1)(x + 1)^{-1}.", "AI": {"tldr": "The paper analyzes the convergence rates of gradient descent variants, showing Adam matches momentum's optimal rate while RMSprop does not.", "motivation": "To investigate and compare the convergence speeds of popular optimization methods like Adam and RMSprop in deep learning.", "method": "Theoretical analysis of convergence rates for gradient descent, momentum, Adam, and RMSprop near strict local minimizers.", "result": "Adam achieves the optimal convergence rate (\u221ax - 1)/(\u221ax + 1), while RMSprop matches standard gradient descent's slower rate (x - 1)/(x + 1).", "conclusion": "Adam outperforms RMSprop in convergence speed, matching momentum's optimal rate, highlighting its efficiency for training deep neural networks."}}
{"id": "2408.08444", "pdf": "https://arxiv.org/pdf/2408.08444", "abs": "https://arxiv.org/abs/2408.08444", "authors": ["Jinming Nian", "Zhiyuan Peng", "Qifan Wang", "Yi Fang"], "title": "W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "In knowledge-intensive tasks such as open-domain question answering (OpenQA),\nlarge language models (LLMs) often struggle to generate factual answers,\nrelying solely on their internal (parametric) knowledge. To address this\nlimitation, Retrieval-Augmented Generation (RAG) systems enhance LLMs by\nretrieving relevant information from external sources, thereby positioning the\nretriever as a pivotal component. Although dense retrieval demonstrates\nstate-of-the-art performance, its training poses challenges due to the scarcity\nof ground-truth evidence, largely attributed to the high costs of human\nannotation. In this paper, we propose W-RAG, a method that draws weak training\nsignals from the downstream task (such as OpenQA) of an LLM, and fine-tunes the\nretriever to prioritize passages that most benefit the task. Specifically, we\nrerank the top-$k$ passages retrieved via BM25 by assessing the probability\nthat the LLM will generate the correct answer for a question given each\npassage. The highest-ranking passages are then used as positive fine-tuning\nexamples for dense retrieval. We conduct comprehensive experiments across four\npublicly available OpenQA datasets to demonstrate that our approach enhances\nboth retrieval and OpenQA performance compared to baseline models, achieving\nresults comparable to models fine-tuned with human-labeled data.", "AI": {"tldr": "W-RAG improves retrieval and OpenQA performance by using weak training signals from LLM tasks to fine-tune retrievers, achieving results close to human-labeled data.", "motivation": "Addresses LLMs' limitations in factual accuracy by enhancing retrievers with task-specific signals, avoiding costly human annotation.", "method": "Reranks BM25-retrieved passages using LLM-generated answer probabilities, then fine-tunes dense retrieval with top passages.", "result": "Outperforms baselines in retrieval and OpenQA, matching performance of human-labeled fine-tuning.", "conclusion": "W-RAG offers a cost-effective alternative to human annotation for improving retrieval-augmented LLMs."}}
{"id": "2504.19614", "pdf": "https://arxiv.org/pdf/2504.19614", "abs": "https://arxiv.org/abs/2504.19614", "authors": ["Junpeng Jiang", "Gangyi Hong", "Miao Zhang", "Hengtong Hu", "Kun Zhan", "Rui Shao", "Liqiang Nie"], "title": "DiVE: Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer", "categories": ["cs.CV"], "comment": null, "summary": "Collecting multi-view driving scenario videos to enhance the performance of\n3D visual perception tasks presents significant challenges and incurs\nsubstantial costs, making generative models for realistic data an appealing\nalternative. Yet, the videos generated by recent works suffer from poor quality\nand spatiotemporal consistency, undermining their utility in advancing\nperception tasks under driving scenarios. To address this gap, we propose DiVE,\na diffusion transformer-based generative framework meticulously engineered to\nproduce high-fidelity, temporally coherent, and cross-view consistent\nmulti-view videos, aligning seamlessly with bird's-eye view layouts and textual\ndescriptions. DiVE leverages a unified cross-attention and a SketchFormer to\nexert precise control over multimodal data, while incorporating a view-inflated\nattention mechanism that adds no extra parameters, thereby guaranteeing\nconsistency across views. Despite these advancements, synthesizing\nhigh-resolution videos under multimodal constraints introduces dual challenges:\ninvestigating the optimal classifier-free guidance coniguration under intricate\nmulti-condition inputs and mitigating excessive computational latency in\nhigh-resolution rendering--both of which remain underexplored in prior\nresearches. To resolve these limitations, we introduce two innovations:\nMulti-Control Auxiliary Branch Distillation, which streamlines multi-condition\nCFG selection while circumventing high computational overhead, and Resolution\nProgressive Sampling, a training-free acceleration strategy that staggers\nresolution scaling to reduce high latency due to high resolution. These\ninnovations collectively achieve a 2.62x speedup with minimal quality\ndegradation. Evaluated on the nuScenes dataset, DiVE achieves SOTA performance\nin multi-view video generation, yielding photorealistic outputs with\nexceptional temporal and cross-view coherence.", "AI": {"tldr": "DiVE is a diffusion transformer-based framework for generating high-fidelity, temporally coherent multi-view driving videos, addressing quality and consistency issues in prior works.", "motivation": "High costs and challenges in collecting real multi-view driving data motivate the need for generative models that produce realistic, consistent videos.", "method": "DiVE uses a diffusion transformer with cross-attention, SketchFormer, and view-inflated attention for consistency. Innovations include Multi-Control Auxiliary Branch Distillation and Resolution Progressive Sampling for efficiency.", "result": "DiVE achieves state-of-the-art performance on nuScenes, producing photorealistic, temporally coherent videos with a 2.62x speedup.", "conclusion": "DiVE advances multi-view video generation by addressing quality, consistency, and computational challenges, offering a viable alternative to real data collection."}}
{"id": "2504.19740", "pdf": "https://arxiv.org/pdf/2504.19740", "abs": "https://arxiv.org/abs/2504.19740", "authors": ["Yonghui Zhai", "Yang Zhang", "Minghao Shang", "Lihua Pang", "Yaxin Ren"], "title": "Graph Fourier Transformer with Structure-Frequency Information", "categories": ["cs.LG", "cs.GR"], "comment": null, "summary": "Graph Transformers (GTs) have shown advantages in numerous graph structure\ntasks but their self-attention mechanism ignores the generalization bias of\ngraphs, with existing methods mainly compensating for this bias from aspects\nlike position encoding, attention bias and relative distance yet still having\nsub-optimal performance and being insufficient by only considering the\nstructural perspective of generalization bias. To address this, this paper\nproposes Grafourierformer, which innovatively combines GT with inductive bias\ncontaining Frequency-Structure information by applying Graph Fourier Transform\nto the Attention Matrix: specifically, eigenvalues from the Graph Laplacian\nmatrix are used to construct an Eigenvalue matrix mask (reflecting node\npositions and structural relationships with neighboring nodes to enable\nconsideration of node range structural characteristics and focus on local graph\ndetails), and inverse Fourier transform is employed to extract node\nhigh-frequency and low-frequency features, calculate low-frequency and\nhigh-frequency energy, and construct a node frequency-energy matrix to filter\nthe eigenvalue matrix mask, allowing attention heads to incorporate both graph\nstructural information and node frequency information optimization, adaptively\ndistinguish global trends from local details, and effectively suppress\nredundant information interference. Extensive experiments on various benchmarks\nshow Grafourierformer consistently outperforms GNN and GT-based models in graph\nclassification and node classification tasks, with ablation experiments further\nvalidating the effectiveness and necessity of the method. Codes are available\nat https://github.com/Arichibald/Grafourierformer.git", "AI": {"tldr": "Grafourierformer enhances Graph Transformers by integrating Frequency-Structure inductive bias via Graph Fourier Transform, improving performance in graph and node classification tasks.", "motivation": "Existing Graph Transformers lack generalization bias consideration, leading to sub-optimal performance. This paper addresses this by combining structural and frequency information.", "method": "Proposes Grafourierformer, using Graph Fourier Transform on the Attention Matrix to incorporate node frequency and structural information, optimizing attention heads.", "result": "Outperforms GNN and GT-based models in benchmarks, validated by ablation studies.", "conclusion": "Grafourierformer effectively combines structural and frequency information, enhancing performance and generalization in graph tasks."}}
{"id": "2504.19460", "pdf": "https://arxiv.org/pdf/2504.19460", "abs": "https://arxiv.org/abs/2504.19460", "authors": ["Mahya Khazaei", "Ali Bahrani", "George Tzanetakis"], "title": "A Real-Time Gesture-Based Control Framework", "categories": ["cs.HC", "cs.AI"], "comment": "8 pages, 4 figures, 2025 International Computer Music Conference", "summary": "We introduce a real-time, human-in-the-loop gesture control framework that\ncan dynamically adapt audio and music based on human movement by analyzing live\nvideo input. By creating a responsive connection between visual and auditory\nstimuli, this system enables dancers and performers to not only respond to\nmusic but also influence it through their movements. Designed for live\nperformances, interactive installations, and personal use, it offers an\nimmersive experience where users can shape the music in real time.\n  The framework integrates computer vision and machine learning techniques to\ntrack and interpret motion, allowing users to manipulate audio elements such as\ntempo, pitch, effects, and playback sequence. With ongoing training, it\nachieves user-independent functionality, requiring as few as 50 to 80 samples\nto label simple gestures. This framework combines gesture training, cue\nmapping, and audio manipulation to create a dynamic, interactive experience.\nGestures are interpreted as input signals, mapped to sound control commands,\nand used to naturally adjust music elements, showcasing the seamless interplay\nbetween human interaction and machine response.", "AI": {"tldr": "A real-time gesture control framework adapts audio/music based on human movement using live video input, enabling interactive performances.", "motivation": "To create an immersive experience where users can dynamically influence music through movement, bridging visual and auditory stimuli.", "method": "Integrates computer vision and machine learning to track motion, map gestures to audio controls (tempo, pitch, effects), and requires minimal training (50-80 samples).", "result": "Achieves user-independent functionality, allowing real-time music manipulation via gestures for performances and installations.", "conclusion": "The framework demonstrates seamless human-machine interaction, enabling dynamic audio adaptation through intuitive gestures."}}
{"id": "2409.06601", "pdf": "https://arxiv.org/pdf/2409.06601", "abs": "https://arxiv.org/abs/2409.06601", "authors": ["Yetao Wu", "Yihong Wang", "Teng Chen", "Ningyuan Xi", "Qingqing Gu", "Hongyang Lei", "Luo Ji"], "title": "LaMsS: When Large Language Models Meet Self-Skepticism", "categories": ["cs.CL", "cs.LG"], "comment": "11 pages, 6 figures, ICLR 2025 Workshop SSI-FM,", "summary": "Hallucination is a major challenge for large language models (LLMs),\npreventing their further application in some fields. The skeptical thinking of\nhumankind could be useful for LLMs to self-cognition, self-reflection and\nalleviate their hallucinations. Inspired by this consideration, we propose a\nnovel approach called LaMsS, which combines the semantic understanding\ncapability of LLMs with self-skepticism. By introducing a series of skepticism\ntokens and augmenting them into the vocabulary, we conduct both pertaining and\nfinetuning, which allow the LLM to decode each normal token followed by a\nskeptical token, representing different skepticism levels. By calculating the\nresponse skepticism given a query, one can define a new self-aware LLM which is\nonly willing to answer with relative lower skepticism level than the threshold.\nBy examining the accuracy, AUC and AP of willingly answering questions, we\ndemonstrate that LaMsS achieves better performance than baselines on both\nmulti-choice questions and open-domain question-answering benchmarks, and can\ngeneralize to multi-task and out-of-domain settings. Our study sheds some\nlights on the self-skepticism modeling on further artificial intelligence.\nProject code and model checkpoints can be found in\nhttps://anonymous.4open.science/r/SM-1E76.", "AI": {"tldr": "LaMsS introduces self-skepticism into LLMs to reduce hallucinations by augmenting skepticism tokens and thresholds, improving performance on benchmarks.", "motivation": "Address LLM hallucinations by leveraging human skeptical thinking for self-cognition and reflection.", "method": "Augment LLM vocabulary with skepticism tokens, perform pre-training and fine-tuning, and use skepticism thresholds to filter responses.", "result": "LaMsS outperforms baselines in accuracy, AUC, and AP on multi-choice and open-domain QA tasks, generalizing to multi-task and out-of-domain settings.", "conclusion": "Self-skepticism modeling in LLMs can mitigate hallucinations and enhance reliability, with potential for broader AI applications."}}
{"id": "2504.19634", "pdf": "https://arxiv.org/pdf/2504.19634", "abs": "https://arxiv.org/abs/2504.19634", "authors": ["Yechan Kim", "DongHo Yoon", "SooYeon Kim", "Moongu Jeon"], "title": "NSegment : Noisy Segment Improves Remote Sensing Image Segmentation", "categories": ["cs.CV"], "comment": "Preprint", "summary": "Labeling errors in remote sensing (RS) image segmentation datasets often\nremain implicit and subtle due to ambiguous class boundaries, mixed pixels,\nshadows, complex terrain features, and subjective annotator bias. Furthermore,\nthe scarcity of annotated RS data due to high image acquisition and labeling\ncosts complicates training noise-robust models. While sophisticated mechanisms\nsuch as label selection or noise correction might address this issue, they tend\nto increase training time and add implementation complexity. In this letter, we\npropose NSegment-a simple yet effective data augmentation solution to mitigate\nthis issue. Unlike traditional methods, it applies elastic transformations only\nto segmentation labels, varying deformation intensity per sample in each\ntraining epoch to address annotation inconsistencies. Experimental results\ndemonstrate that our approach improves the performance of RS image segmentation\non various state-of-the-art models.", "AI": {"tldr": "NSegment is a data augmentation method for RS image segmentation that applies elastic transformations to labels, improving model performance despite labeling errors.", "motivation": "Labeling errors in RS datasets are common due to ambiguous boundaries, mixed pixels, and subjective bias, and annotated data is scarce, making noise-robust training challenging.", "method": "NSegment uses elastic transformations on segmentation labels, varying deformation intensity per sample in each epoch to address annotation inconsistencies.", "result": "The approach enhances performance of RS image segmentation across state-of-the-art models.", "conclusion": "NSegment offers a simple, effective solution to mitigate labeling errors without increasing training complexity."}}
{"id": "2504.19746", "pdf": "https://arxiv.org/pdf/2504.19746", "abs": "https://arxiv.org/abs/2504.19746", "authors": ["Xilong Xie", "Liang Wang", "Limin Xiao", "Meng Han", "Lin Sun", "Shuai Zheng", "Xiangrong Xu"], "title": "FineQ: Software-Hardware Co-Design for Low-Bit Fine-Grained Mixed-Precision Quantization of LLMs", "categories": ["cs.LG", "cs.AR"], "comment": "DATE 2025", "summary": "Large language models (LLMs) have significantly advanced the natural language\nprocessing paradigm but impose substantial demands on memory and computational\nresources. Quantization is one of the most effective ways to reduce memory\nconsumption of LLMs. However, advanced single-precision quantization methods\nexperience significant accuracy degradation when quantizing to ultra-low bits.\nExisting mixed-precision quantization methods are quantized by groups with\ncoarse granularity. Employing high precision for group data leads to\nsubstantial memory overhead, whereas low precision severely impacts model\naccuracy. To address this issue, we propose FineQ, software-hardware co-design\nfor low-bit fine-grained mixed-precision quantization of LLMs. First, FineQ\npartitions the weights into finer-grained clusters and considers the\ndistribution of outliers within these clusters, thus achieving a balance\nbetween model accuracy and memory overhead. Then, we propose an outlier\nprotection mechanism within clusters that uses 3 bits to represent outliers and\nintroduce an encoding scheme for index and data concatenation to enable aligned\nmemory access. Finally, we introduce an accelerator utilizing temporal coding\nthat effectively supports the quantization algorithm while simplifying the\nmultipliers in the systolic array. FineQ achieves higher model accuracy\ncompared to the SOTA mixed-precision quantization algorithm at a close average\nbit-width. Meanwhile, the accelerator achieves up to 1.79x energy efficiency\nand reduces the area of the systolic array by 61.2%.", "AI": {"tldr": "FineQ is a software-hardware co-design for fine-grained mixed-precision quantization of LLMs, balancing accuracy and memory efficiency.", "motivation": "Addressing the trade-off between memory overhead and accuracy degradation in ultra-low-bit quantization of LLMs.", "method": "Partitions weights into fine-grained clusters, uses an outlier protection mechanism with 3 bits, and introduces an encoding scheme for aligned memory access. Also includes an accelerator with temporal coding.", "result": "Achieves higher accuracy than SOTA mixed-precision quantization at similar bit-widths, with 1.79x energy efficiency and 61.2% area reduction in the systolic array.", "conclusion": "FineQ effectively balances accuracy and memory efficiency in LLM quantization, supported by hardware optimization."}}
{"id": "2410.08800", "pdf": "https://arxiv.org/pdf/2410.08800", "abs": "https://arxiv.org/abs/2410.08800", "authors": ["Nicolo' Brandizzi", "Hammam Abdelwahab", "Anirban Bhowmick", "Lennard Helmer", "Benny J\u00f6rg Stein", "Pavel Denisov", "Qasid Saleem", "Michael Fromm", "Mehdi Ali", "Richard Rutmann", "Farzad Naderi", "Mohamad Saif Agy", "Alexander Schwirjow", "Fabian K\u00fcch", "Luzian Hahn", "Malte Ostendorff", "Pedro Ortiz Suarez", "Georg Rehm", "Dennis Wegener", "Nicolas Flores-Herr", "Joachim K\u00f6hler", "Johannes Leveling"], "title": "Data Processing for the OpenGPT-X Model Family", "categories": ["cs.CL", "H.3.1; I.2.7"], "comment": null, "summary": "This paper presents a comprehensive overview of the data preparation pipeline\ndeveloped for the OpenGPT-X project, a large-scale initiative aimed at creating\nopen and high-performance multilingual large language models (LLMs). The\nproject goal is to deliver models that cover all major European languages, with\na particular focus on real-world applications within the European Union. We\nexplain all data processing steps, starting with the data selection and\nrequirement definition to the preparation of the final datasets for model\ntraining. We distinguish between curated data and web data, as each of these\ncategories is handled by distinct pipelines, with curated data undergoing\nminimal filtering and web data requiring extensive filtering and deduplication.\nThis distinction guided the development of specialized algorithmic solutions\nfor both pipelines. In addition to describing the processing methodologies, we\nprovide an in-depth analysis of the datasets, increasing transparency and\nalignment with European data regulations. Finally, we share key insights and\nchallenges faced during the project, offering recommendations for future\nendeavors in large-scale multilingual data preparation for LLMs.", "AI": {"tldr": "The paper details the data preparation pipeline for OpenGPT-X, focusing on multilingual LLMs for European languages, emphasizing data selection, processing, and regulatory compliance.", "motivation": "To create open, high-performance multilingual LLMs for European languages, addressing real-world EU applications and ensuring transparency with data regulations.", "method": "Distinct pipelines for curated and web data, with minimal filtering for curated data and extensive filtering/deduplication for web data, alongside specialized algorithms.", "result": "Comprehensive datasets prepared for model training, with insights into challenges and recommendations for future multilingual data projects.", "conclusion": "The project successfully developed a scalable data pipeline, highlighting the importance of tailored processing and regulatory alignment for multilingual LLMs."}}
{"id": "2504.19637", "pdf": "https://arxiv.org/pdf/2504.19637", "abs": "https://arxiv.org/abs/2504.19637", "authors": ["Junlong Ren", "Gangjian Zhang", "Yu Hu", "Jian Shu", "Hao Wang"], "title": "Exploiting Inter-Sample Correlation and Intra-Sample Redundancy for Partially Relevant Video Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Partially Relevant Video Retrieval (PRVR) aims to retrieve the target video\nthat is partially relevant to the text query. The primary challenge in PRVR\narises from the semantic asymmetry between textual and visual modalities, as\nvideos often contain substantial content irrelevant to the query. Existing\nmethods coarsely align paired videos and text queries to construct the semantic\nspace, neglecting the critical cross-modal dual nature inherent in this task:\ninter-sample correlation and intra-sample redundancy. To this end, we propose a\nnovel PRVR framework to systematically exploit these two characteristics. Our\nframework consists of three core modules. First, the Inter Correlation\nEnhancement (ICE) module captures inter-sample correlation by identifying\nsemantically similar yet unpaired text queries and video moments, combining\nthem to form pseudo-positive pairs for more robust semantic space construction.\nSecond, the Intra Redundancy Mining (IRM) module mitigates intra-sample\nredundancy by mining redundant video moment features and treating them as hard\nnegative samples, thereby encouraging the model to learn more discriminative\nrepresentations. Finally, to reinforce these modules, we introduce the Temporal\nCoherence Prediction (TCP) module, which enhances feature discrimination by\ntraining the model to predict the original temporal order of randomly shuffled\nvideo frames and moments. Extensive experiments on three datasets demonstrate\nthe superiority of our approach compared to previous methods, achieving\nstate-of-the-art results.", "AI": {"tldr": "A novel PRVR framework addresses semantic asymmetry in video retrieval by leveraging inter-sample correlation and intra-sample redundancy, outperforming existing methods.", "motivation": "The challenge in PRVR is semantic asymmetry between text and video, with existing methods neglecting inter-sample correlation and intra-sample redundancy.", "method": "Proposes three modules: ICE for inter-sample correlation, IRM for intra-sample redundancy, and TCP for temporal coherence.", "result": "Achieves state-of-the-art results on three datasets.", "conclusion": "The framework effectively addresses PRVR challenges by exploiting dual cross-modal characteristics."}}
{"id": "2504.19774", "pdf": "https://arxiv.org/pdf/2504.19774", "abs": "https://arxiv.org/abs/2504.19774", "authors": ["Nicola Debole", "Pietro Barbiero", "Francesco Giannini", "Andrea Passeggini", "Stefano Teso", "Emanuele Marconato"], "title": "If Concept Bottlenecks are the Question, are Foundation Models the Answer?", "categories": ["cs.LG"], "comment": null, "summary": "Concept Bottleneck Models (CBMs) are neural networks designed to conjoin high\nperformance with ante-hoc interpretability. CBMs work by first mapping inputs\n(e.g., images) to high-level concepts (e.g., visible objects and their\nproperties) and then use these to solve a downstream task (e.g., tagging or\nscoring an image) in an interpretable manner. Their performance and\ninterpretability, however, hinge on the quality of the concepts they learn. The\ngo-to strategy for ensuring good quality concepts is to leverage expert\nannotations, which are expensive to collect and seldom available in\napplications. Researchers have recently addressed this issue by introducing\n\"VLM-CBM\" architectures that replace manual annotations with weak supervision\nfrom foundation models. It is however unclear what is the impact of doing so on\nthe quality of the learned concepts. To answer this question, we put\nstate-of-the-art VLM-CBMs to the test, analyzing their learned concepts\nempirically using a selection of significant metrics. Our results show that,\ndepending on the task, VLM supervision can sensibly differ from expert\nannotations, and that concept accuracy and quality are not strongly correlated.\nOur code is available at https://github.com/debryu/CQA.", "AI": {"tldr": "VLM-CBMs replace expert annotations with weak supervision from foundation models, but their concept quality varies and doesn't strongly correlate with accuracy.", "motivation": "To evaluate the impact of replacing expert annotations with weak supervision from foundation models in Concept Bottleneck Models (CBMs).", "method": "Analyze state-of-the-art VLM-CBMs using empirical metrics to assess concept quality.", "result": "VLM supervision differs from expert annotations, and concept accuracy doesn't strongly correlate with quality.", "conclusion": "Weak supervision from VLMs can impact concept quality, and accuracy isn't a reliable proxy for concept quality."}}
{"id": "2504.19594", "pdf": "https://arxiv.org/pdf/2504.19594", "abs": "https://arxiv.org/abs/2504.19594", "authors": ["Lorenzo Alvisi", "Serena Tardelli", "Maurizio Tesconi"], "title": "Mapping the Italian Telegram Ecosystem", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Telegram has become a major space for political discourse and alternative\nmedia. However, its lack of moderation allows misinformation, extremism, and\ntoxicity to spread. While prior research focused on these particular phenomena\nor topics, these have mostly been examined separately, and a broader\nunderstanding of the Telegram ecosystem is still missing. In this work, we fill\nthis gap by conducting a large-scale analysis of the Italian Telegram sphere,\nleveraging a dataset of 186 million messages from 13,151 chats collected in\n2023. Using network analysis, Large Language Models, and toxicity detection\ntools, we examine how different thematic communities form, align ideologically,\nand engage in harmful discourse within the Italian cultural context. Results\nshow strong thematic and ideological homophily. We also identify mixed\nideological communities where far-left and far-right rhetoric coexist on\nparticular geopolitical issues. Beyond political analysis, we find that\ntoxicity, rather than being isolated in a few extreme chats, appears widely\nnormalized within highly toxic communities. Moreover, we find that Italian\ndiscourse primarily targets Black people, Jews, and gay individuals\nindependently of the topic. Finally, we uncover common trend of intra-national\nhostility, where Italians often attack other Italians, reflecting regional and\nintra-regional cultural conflicts that can be traced back to old historical\ndivisions. This study provides the first large-scale mapping of the Italian\nTelegram ecosystem, offering insights into ideological interactions, toxicity,\nand identity-targets of hate and contributing to research on online toxicity\nacross different cultural and linguistic contexts on Telegram.", "AI": {"tldr": "A large-scale analysis of the Italian Telegram ecosystem reveals strong ideological homophily, mixed ideological communities, widespread toxicity, and specific hate targets like Black people, Jews, and gay individuals.", "motivation": "To address the lack of a comprehensive understanding of the Telegram ecosystem, especially regarding misinformation, extremism, and toxicity in the Italian context.", "method": "Analyzed 186 million messages from 13,151 Italian Telegram chats in 2023 using network analysis, Large Language Models, and toxicity detection tools.", "result": "Found thematic and ideological homophily, mixed ideological communities, normalized toxicity, and hate targeting specific groups. Also identified intra-national hostility reflecting historical divisions.", "conclusion": "The study maps the Italian Telegram ecosystem, providing insights into ideological interactions, toxicity, and hate targets, contributing to broader research on online toxicity."}}
{"id": "2410.11325", "pdf": "https://arxiv.org/pdf/2410.11325", "abs": "https://arxiv.org/abs/2410.11325", "authors": ["Wenda Xu", "Rujun Han", "Zifeng Wang", "Long T. Le", "Dhruv Madeka", "Lei Li", "William Yang Wang", "Rishabh Agarwal", "Chen-Yu Lee", "Tomas Pfister"], "title": "Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling", "categories": ["cs.CL", "cs.AI"], "comment": "ICLR2025", "summary": "Recent advances in knowledge distillation (KD) have enabled smaller student\nmodels to approach the performance of larger teacher models. However, popular\nmethods such as supervised KD and on-policy KD, are adversely impacted by the\nknowledge gaps between teacher-student in practical scenarios. Supervised KD\nsuffers from a distribution mismatch between training with a static dataset and\ninference over final student-generated outputs. Conversely, on-policy KD, which\nuses student-generated samples for training, can suffer from low-quality\ntraining examples with which teacher models are not familiar, resulting in\ninaccurate teacher feedback. To address these limitations, we introduce\nSpeculative Knowledge Distillation (SKD), a novel approach that leverages\ncooperation between student and teacher models to generate high-quality\ntraining data on-the-fly while aligning with the student's inference-time\ndistribution. In SKD, the student proposes tokens, and the teacher replaces\npoorly ranked ones based on its own distribution, transferring high-quality\nknowledge adaptively. We evaluate SKD on various text generation tasks,\nincluding translation, summarization, math, and instruction following, and show\nthat SKD consistently outperforms existing KD methods across different domains,\ndata sizes, and model initialization strategies.", "AI": {"tldr": "Speculative Knowledge Distillation (SKD) improves knowledge transfer between teacher and student models by dynamically generating high-quality training data, outperforming existing methods.", "motivation": "Addressing limitations of supervised and on-policy KD, which suffer from distribution mismatch and low-quality training examples.", "method": "SKD involves student proposing tokens and teacher replacing poorly ranked ones, ensuring adaptive knowledge transfer.", "result": "SKD outperforms existing KD methods across text generation tasks like translation, summarization, and more.", "conclusion": "SKD offers a robust solution for effective knowledge distillation by aligning training with student inference-time distribution."}}
{"id": "2504.19643", "pdf": "https://arxiv.org/pdf/2504.19643", "abs": "https://arxiv.org/abs/2504.19643", "authors": ["Pin-Chi Pan", "Soo-Chang Pei"], "title": "BARIS: Boundary-Aware Refinement with Environmental Degradation Priors for Robust Underwater Instance Segmentation", "categories": ["cs.CV"], "comment": "15 pages, 9 figures, and 11 tables", "summary": "Underwater instance segmentation is challenging due to adverse visual\nconditions such as light attenuation, scattering, and color distortion, which\ndegrade model performance. In this work, we propose BARIS-Decoder\n(Boundary-Aware Refinement Decoder for Instance Segmentation), a framework that\nenhances segmentation accuracy through feature refinement. To address\nunderwater degradations, we introduce the Environmental Robust Adapter (ERA),\nwhich efficiently models underwater degradation patterns while reducing\ntrainable parameters by over 90\\% compared to full fine-tuning. The integration\nof BARIS-Decoder with ERA-tuning, referred to as BARIS-ERA, achieves\nstate-of-the-art performance, surpassing Mask R-CNN by 3.4 mAP with a Swin-B\nbackbone and 3.8 mAP with ConvNeXt V2. Our findings demonstrate the\neffectiveness of BARIS-ERA in advancing underwater instance segmentation,\nproviding a robust and efficient solution.", "AI": {"tldr": "BARIS-ERA improves underwater instance segmentation by refining features and modeling degradation patterns, outperforming Mask R-CNN by 3.4-3.8 mAP.", "motivation": "Underwater conditions degrade segmentation performance due to light and color issues.", "method": "Proposes BARIS-Decoder for feature refinement and ERA for modeling underwater degradations with fewer parameters.", "result": "BARIS-ERA achieves state-of-the-art performance, surpassing Mask R-CNN by 3.4-3.8 mAP.", "conclusion": "BARIS-ERA provides a robust and efficient solution for underwater instance segmentation."}}
{"id": "2504.19779", "pdf": "https://arxiv.org/pdf/2504.19779", "abs": "https://arxiv.org/abs/2504.19779", "authors": ["Claudia Drygala", "Hanno Gottschalk", "Thomas Kruse", "S\u00e9gol\u00e8ne Martin", "Annika M\u00fctze"], "title": "Learning Brenier Potentials with Convex Generative Adversarial Neural Networks", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Brenier proved that under certain conditions on a source and a target\nprobability measure there exists a strictly convex function such that its\ngradient is a transport map from the source to the target distribution. This\nfunction is called the Brenier potential. Furthermore, detailed information on\nthe H\\\"older regularity of the Brenier potential is available. In this work we\ndevelop the statistical learning theory of generative adversarial neural\nnetworks that learn the Brenier potential. As by the transformation of\ndensities formula, the density of the generated measure depends on the second\nderivative of the Brenier potential, we develop the universal approximation\ntheory of ReCU networks with cubic activation $\\mathtt{ReCU}(x)=\\max\\{0,x\\}^3$\nthat combines the favorable approximation properties of H\\\"older functions with\na Lipschitz continuous density. In order to assure the convexity of such\ngeneral networks, we introduce an adversarial training procedure for a\npotential function represented by the ReCU networks that combines the classical\ndiscriminator cross entropy loss with a penalty term that enforces (strict)\nconvexity. We give a detailed decomposition of learning errors and show that\nfor a suitable high penalty parameter all networks chosen in the adversarial\nmin-max optimization problem are strictly convex. This is further exploited to\nprove the consistency of the learning procedure for (slowly) expanding network\ncapacity. We also implement the described learning algorithm and apply it to a\nnumber of standard test cases from Gaussian mixture to image data as target\ndistributions. As predicted in theory, we observe that the convexity loss\nbecomes inactive during the training process and the potentials represented by\nthe neural networks have learned convexity.", "AI": {"tldr": "The paper develops a statistical learning theory for generative adversarial neural networks (GANs) that learn the Brenier potential, ensuring convexity through adversarial training and proving consistency for expanding network capacity.", "motivation": "To leverage the Brenier potential's properties for learning transport maps between probability distributions, particularly focusing on the convexity and regularity of the potential.", "method": "Uses ReCU networks with cubic activation for approximation, introduces adversarial training with a convexity penalty, and decomposes learning errors to ensure strict convexity.", "result": "Theoretical consistency is proven, and empirical results show the convexity loss becomes inactive during training, with networks successfully learning convex potentials.", "conclusion": "The proposed method effectively learns the Brenier potential, combining theoretical guarantees with practical performance on standard test cases."}}
{"id": "2504.19653", "pdf": "https://arxiv.org/pdf/2504.19653", "abs": "https://arxiv.org/abs/2504.19653", "authors": ["Leon Davies", "Baihua Li", "Mohamad Saada", "Simon S\u00f8lvsten", "Qinggang Meng"], "title": "GAN-SLAM: Real-Time GAN Aided Floor Plan Creation Through SLAM", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "10 pages, preprint conference submission", "summary": "SLAM is a fundamental component of modern autonomous systems, providing\nrobots and their operators with a deeper understanding of their environment.\nSLAM systems often encounter challenges due to the dynamic nature of robotic\nmotion, leading to inaccuracies in mapping quality, particularly in 2D\nrepresentations such as Occupancy Grid Maps. These errors can significantly\ndegrade map quality, hindering the effectiveness of specific downstream tasks\nsuch as floor plan creation. To address this challenge, we introduce our novel\n'GAN-SLAM', a new SLAM approach that leverages Generative Adversarial Networks\nto clean and complete occupancy grids during the SLAM process, reducing the\nimpact of noise and inaccuracies introduced on the output map. We adapt and\nintegrate accurate pose estimation techniques typically used for 3D SLAM into a\n2D form. This enables the quality improvement 3D LiDAR-odometry has seen in\nrecent years to be effective for 2D representations. Our results demonstrate\nsubstantial improvements in map fidelity and quality, with minimal noise and\nerrors, affirming the effectiveness of GAN-SLAM for real-world mapping\napplications within large-scale complex environments. We validate our approach\non real-world data operating in real-time, and on famous examples of 2D maps.\nThe improved quality of the output map enables new downstream tasks, such as\nfloor plan drafting, further enhancing the capabilities of autonomous systems.\nOur novel approach to SLAM offers a significant step forward in the field,\nimproving the usability for SLAM in mapping-based tasks, and offers insight\ninto the usage of GANs for OGM error correction.", "AI": {"tldr": "GAN-SLAM improves 2D SLAM by using GANs to clean and complete occupancy grids, enhancing map quality for tasks like floor plan creation.", "motivation": "Dynamic robotic motion introduces noise and inaccuracies in 2D SLAM maps, degrading their quality and usability for downstream tasks.", "method": "Integrates GANs to refine occupancy grids and adapts 3D pose estimation techniques for 2D SLAM.", "result": "Significant improvements in map fidelity and quality, validated on real-world data and famous 2D maps.", "conclusion": "GAN-SLAM advances SLAM usability for mapping tasks and demonstrates GANs' potential for error correction in occupancy grid maps."}}
{"id": "2410.12311", "pdf": "https://arxiv.org/pdf/2410.12311", "abs": "https://arxiv.org/abs/2410.12311", "authors": ["Siyi Liu", "Qiang Ning", "Kishaloy Halder", "Wei Xiao", "Zheng Qi", "Phu Mon Htut", "Yi Zhang", "Neha Anna John", "Bonan Min", "Yassine Benajiba", "Dan Roth"], "title": "Open Domain Question Answering with Conflicting Contexts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Open domain question answering systems frequently rely on information\nretrieved from large collections of text (such as the Web) to answer questions.\nHowever, such collections of text often contain conflicting information, and\nindiscriminately depending on this information may result in untruthful and\ninaccurate answers. To understand the gravity of this problem, we collect a\nhuman-annotated dataset, Question Answering with Conflicting Contexts (QACC),\nand find that as much as 25% of unambiguous, open domain questions can lead to\nconflicting contexts when retrieved using Google Search. We evaluate and\nbenchmark three powerful Large Language Models (LLMs) with our dataset QACC and\ndemonstrate their limitations in effectively addressing questions with\nconflicting information. To explore how humans reason through conflicting\ncontexts, we request our annotators to provide explanations for their\nselections of correct answers. We demonstrate that by finetuning LLMs to\nexplain their answers, we can introduce richer information into their training\nthat guide them through the process of reasoning with conflicting contexts.", "AI": {"tldr": "The paper addresses the issue of conflicting information in open-domain QA systems, introduces a dataset (QACC), benchmarks LLMs, and improves their performance by finetuning them to provide explanations.", "motivation": "Open-domain QA systems often retrieve conflicting information, leading to untruthful answers. The study aims to quantify this problem and improve LLM performance.", "method": "The authors collect a human-annotated dataset (QACC), evaluate three LLMs, and finetune them to generate explanations for answers.", "result": "25% of unambiguous questions lead to conflicting contexts. Finetuning LLMs with explanations improves their reasoning with conflicting information.", "conclusion": "Explanations enhance LLMs' ability to handle conflicting contexts, suggesting a path for improving QA systems."}}
{"id": "2504.19646", "pdf": "https://arxiv.org/pdf/2504.19646", "abs": "https://arxiv.org/abs/2504.19646", "authors": ["Anjith George", "Sebastien Marcel"], "title": "xEdgeFace: Efficient Cross-Spectral Face Recognition for Edge Devices", "categories": ["cs.CV"], "comment": "11 pages", "summary": "Heterogeneous Face Recognition (HFR) addresses the challenge of matching face\nimages across different sensing modalities, such as thermal to visible or\nnear-infrared to visible, expanding the applicability of face recognition\nsystems in real-world, unconstrained environments. While recent HFR methods\nhave shown promising results, many rely on computation-intensive architectures,\nlimiting their practicality for deployment on resource-constrained edge\ndevices. In this work, we present a lightweight yet effective HFR framework by\nadapting a hybrid CNN-Transformer architecture originally designed for face\nrecognition. Our approach enables efficient end-to-end training with minimal\npaired heterogeneous data while preserving strong performance on standard RGB\nface recognition tasks. This makes it a compelling solution for both\nhomogeneous and heterogeneous scenarios. Extensive experiments across multiple\nchallenging HFR and face recognition benchmarks demonstrate that our method\nconsistently outperforms state-of-the-art approaches while maintaining a low\ncomputational overhead.", "AI": {"tldr": "A lightweight HFR framework using a hybrid CNN-Transformer architecture achieves strong performance with minimal data and low computational cost.", "motivation": "Addressing the challenge of matching face images across different modalities while ensuring practicality for resource-constrained devices.", "method": "Adapts a hybrid CNN-Transformer architecture for efficient end-to-end training with minimal paired heterogeneous data.", "result": "Outperforms state-of-the-art methods on HFR and face recognition benchmarks with low computational overhead.", "conclusion": "The framework is effective for both homogeneous and heterogeneous face recognition, offering a practical solution for edge devices."}}
{"id": "2504.19785", "pdf": "https://arxiv.org/pdf/2504.19785", "abs": "https://arxiv.org/abs/2504.19785", "authors": ["Haishan Wang", "Arno Solin", "Vikas Garg"], "title": "Heterophily-informed Message Passing", "categories": ["cs.LG"], "comment": "Appearing in Transactions on Machine Learning Research (TMLR) 2025", "summary": "Graph neural networks (GNNs) are known to be vulnerable to oversmoothing due\nto their implicit homophily assumption. We mitigate this problem with a novel\nscheme that regulates the aggregation of messages, modulating the type and\nextent of message passing locally thereby preserving both the low and\nhigh-frequency components of information. Our approach relies solely on learnt\nembeddings, obviating the need for auxiliary labels, thus extending the\nbenefits of heterophily-aware embeddings to broader applications, e.g.,\ngenerative modelling. Our experiments, conducted across various data sets and\nGNN architectures, demonstrate performance enhancements and reveal heterophily\npatterns across standard classification benchmarks. Furthermore, application to\nmolecular generation showcases notable performance improvements on\nchemoinformatics benchmarks.", "AI": {"tldr": "A novel scheme mitigates GNN oversmoothing by regulating message aggregation, preserving information frequencies without auxiliary labels, showing improved performance in classification and molecular generation.", "motivation": "Address GNNs' vulnerability to oversmoothing due to homophily assumptions by preserving both low and high-frequency information.", "method": "Regulate message aggregation locally using learnt embeddings, avoiding auxiliary labels.", "result": "Performance improvements in classification benchmarks and notable gains in molecular generation tasks.", "conclusion": "The approach effectively handles heterophily, extending benefits to broader applications like generative modeling."}}
{"id": "2504.19654", "pdf": "https://arxiv.org/pdf/2504.19654", "abs": "https://arxiv.org/abs/2504.19654", "authors": ["Leon Davies", "Baihua Li", "Mohamad Saada", "Simon S\u00f8lvsten", "Qinggang Meng"], "title": "Transformation & Translation Occupancy Grid Mapping: 2-Dimensional Deep Learning Refined SLAM", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "12 pages, preprint, submitted to Robotics And Autonomous Systems", "summary": "SLAM (Simultaneous Localisation and Mapping) is a crucial component for\nrobotic systems, providing a map of an environment, the current location and\nprevious trajectory of a robot. While 3D LiDAR SLAM has received notable\nimprovements in recent years, 2D SLAM lags behind. Gradual drifts in odometry\nand pose estimation inaccuracies hinder modern 2D LiDAR-odometry algorithms in\nlarge complex environments. Dynamic robotic motion coupled with inherent\nestimation based SLAM processes introduce noise and errors, degrading map\nquality. Occupancy Grid Mapping (OGM) produces results that are often noisy and\nunclear. This is due to the fact that evidence based mapping represents maps\naccording to uncertain observations. This is why OGMs are so popular in\nexploration or navigation tasks. However, this also limits OGMs' effectiveness\nfor specific mapping based tasks such as floor plan creation in complex scenes.\nTo address this, we propose our novel Transformation and Translation Occupancy\nGrid Mapping (TT-OGM). We adapt and enable accurate and robust pose estimation\ntechniques from 3D SLAM to the world of 2D and mitigate errors to improve map\nquality using Generative Adversarial Networks (GANs). We introduce a novel data\ngeneration method via deep reinforcement learning (DRL) to build datasets large\nenough for training a GAN for SLAM error correction. We demonstrate our SLAM in\nreal-time on data collected at Loughborough University. We also prove its\ngeneralisability on a variety of large complex environments on a collection of\nlarge scale well-known 2D occupancy maps. Our novel approach enables the\ncreation of high quality OGMs in complex scenes, far surpassing the\ncapabilities of current SLAM algorithms in terms of quality, accuracy and\nreliability.", "AI": {"tldr": "The paper proposes TT-OGM, a novel method combining 3D SLAM techniques and GANs to improve 2D LiDAR SLAM, addressing odometry drifts and pose inaccuracies for better map quality in complex environments.", "motivation": "Current 2D LiDAR SLAM struggles with odometry drifts and pose inaccuracies, leading to noisy and unclear maps, especially in complex environments.", "method": "The authors introduce TT-OGM, adapting 3D SLAM techniques to 2D and using GANs for error correction. They also employ DRL for dataset generation.", "result": "The method demonstrates improved map quality and generalizability in real-time tests and large-scale environments.", "conclusion": "TT-OGM outperforms existing 2D SLAM algorithms in quality, accuracy, and reliability for complex scenes."}}
{"id": "2410.13961", "pdf": "https://arxiv.org/pdf/2410.13961", "abs": "https://arxiv.org/abs/2410.13961", "authors": ["Catarina G. Belem", "Pouya Pezeshkpour", "Hayate Iso", "Seiji Maekawa", "Nikita Bhutani", "Estevam Hruschka"], "title": "From Single to Multi: How LLMs Hallucinate in Multi-Document Summarization", "categories": ["cs.CL"], "comment": "NAACL 2025 - Findings", "summary": "Although many studies have investigated and reduced hallucinations in large\nlanguage models (LLMs) for single-document tasks, research on hallucination in\nmulti-document summarization (MDS) tasks remains largely unexplored.\nSpecifically, it is unclear how the challenges arising from handling multiple\ndocuments (e.g., repetition and diversity of information) affect models\noutputs. In this work, we investigate how hallucinations manifest in LLMs when\nsummarizing topic-specific information from multiple documents. Since no\nbenchmarks exist for investigating hallucinations in MDS, we use existing news\nand conversation datasets, annotated with topic-specific insights, to create\ntwo novel multi-document benchmarks. When evaluating 5 LLMs on our benchmarks,\nwe observe that on average, up to 75% of the content in LLM-generated summary\nis hallucinated, with hallucinations more likely to occur towards the end of\nthe summaries. Moreover, when summarizing non-existent topic-related\ninformation, gpt-3.5-turbo and GPT-4o still generate summaries about 79.35% and\n44% of the time, raising concerns about their tendency to fabricate content. To\nunderstand the characteristics of these hallucinations, we manually evaluate\n700+ insights and find that most errors stem from either failing to follow\ninstructions or producing overly generic insights. Motivated by these\nobservations, we investigate the efficacy of simple post-hoc baselines in\nmitigating hallucinations but find them only moderately effective. Our results\nunderscore the need for more effective approaches to systematically mitigate\nhallucinations in MDS. We release our dataset and code at\ngithub.com/megagonlabs/Hallucination_MDS.", "AI": {"tldr": "The paper investigates hallucinations in multi-document summarization (MDS) by LLMs, revealing high hallucination rates (up to 75%) and tendencies to fabricate content, especially with non-existent topics. It introduces new benchmarks and finds current mitigation methods only moderately effective.", "motivation": "To explore the under-researched area of hallucinations in MDS tasks, particularly how handling multiple documents affects LLM outputs, and to create benchmarks for evaluation.", "method": "The study uses annotated news and conversation datasets to create MDS benchmarks, evaluates 5 LLMs, and manually analyzes 700+ insights to understand hallucination characteristics.", "result": "Up to 75% of LLM-generated summaries contain hallucinations, with higher rates for non-existent topics (79.35% for GPT-3.5-turbo, 44% for GPT-4). Post-hoc mitigation methods are only moderately effective.", "conclusion": "The findings highlight the need for better approaches to reduce hallucinations in MDS, as current methods are insufficient. The dataset and code are released for further research."}}
{"id": "2504.19682", "pdf": "https://arxiv.org/pdf/2504.19682", "abs": "https://arxiv.org/abs/2504.19682", "authors": ["Nikolaos Chaidos", "Angeliki Dimitriou", "Nikolaos Spanos", "Athanasios Voulodimos", "Giorgos Stamou"], "title": "Explaining Vision GNNs: A Semantic and Visual Analysis of Graph-based Image Classification", "categories": ["cs.CV", "cs.LG"], "comment": "13 pages, 3 figures, accepted for presentation at\n  xAI-World-Conference 2025, code is available at\n  https://github.com/nickhaidos/Vision-GNNs-Explainer", "summary": "Graph Neural Networks (GNNs) have emerged as an efficient alternative to\nconvolutional approaches for vision tasks such as image classification,\nleveraging patch-based representations instead of raw pixels. These methods\nconstruct graphs where image patches serve as nodes, and edges are established\nbased on patch similarity or classification relevance. Despite their\nefficiency, the explainability of GNN-based vision models remains\nunderexplored, even though graphs are naturally interpretable. In this work, we\nanalyze the semantic consistency of the graphs formed at different layers of\nGNN-based image classifiers, focusing on how well they preserve object\nstructures and meaningful relationships. A comprehensive analysis is presented\nby quantifying the extent to which inter-layer graph connections reflect\nsemantic similarity and spatial coherence. Explanations from standard and\nadversarial settings are also compared to assess whether they reflect the\nclassifiers' robustness. Additionally, we visualize the flow of information\nacross layers through heatmap-based visualization techniques, thereby\nhighlighting the models' explainability. Our findings demonstrate that the\ndecision-making processes of these models can be effectively explained, while\nalso revealing that their reasoning does not necessarily align with human\nperception, especially in deeper layers.", "AI": {"tldr": "The paper explores the explainability of GNN-based image classifiers by analyzing semantic consistency and graph connections across layers, comparing standard and adversarial settings, and visualizing information flow.", "motivation": "Despite GNNs' efficiency for vision tasks, their explainability is underexplored, even though graphs are naturally interpretable.", "method": "Analyzes semantic consistency of graphs at different GNN layers, quantifying inter-layer connections for semantic similarity and spatial coherence. Compares explanations in standard and adversarial settings and visualizes information flow.", "result": "Demonstrates effective explainability of GNN decision-making but reveals misalignment with human perception, especially in deeper layers.", "conclusion": "GNN-based models can be explained, but their reasoning may not align with human intuition, particularly in deeper layers."}}
{"id": "2504.19792", "pdf": "https://arxiv.org/pdf/2504.19792", "abs": "https://arxiv.org/abs/2504.19792", "authors": ["Runtian Zhai"], "title": "Contextures: The Mechanism of Representation Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "PhD Dissertation", "summary": "This dissertation establishes the contexture theory to mathematically\ncharacterize the mechanism of representation learning, or pretraining. Despite\nthe remarkable empirical success of foundation models, it is not very clear\nwhat representations they learn, and why these representations are useful for\nvarious downstream tasks. A scientific understanding of representation learning\nis critical, especially at this point when scaling up the model size is\nproducing diminishing returns, and designing new pretraining methods is\nimperative for further progress.\n  Prior work treated different representation learning methods quite\ndifferently, whereas the contexture theory provides a unified framework for\nanalyzing these methods. The central argument is that a representation is\nlearned from the association between the input X and a context variable A. We\nprove that if an encoder captures the maximum information of this association,\nin which case we say that the encoder learns the contexture, then it will be\noptimal on the class of tasks that are compatible with the context. We also\nshow that a context is the most useful when the association between X and A is\nneither too strong nor too weak. The important implication of the contexture\ntheory is that increasing the model size alone will achieve diminishing\nreturns, and further advancements require better contexts.\n  We demonstrate that many pretraining objectives can learn the contexture,\nincluding supervised learning, self-supervised learning, generative models,\netc. Then, we introduce two general objectives -- SVME and KISE, for learning\nthe contexture. We also show how to mix multiple contexts together, an\neffortless way to create better contexts from existing ones. Then, we prove\nstatistical learning bounds for representation learning. Finally, we discuss\nthe effect of the data distribution shift from pretraining to the downstream\ntask.", "AI": {"tldr": "The paper introduces the contexture theory to unify and mathematically characterize representation learning, emphasizing the role of context variables in optimizing representations for downstream tasks. It argues that better contexts, not just larger models, are key to progress.", "motivation": "To address the lack of scientific understanding of why representations learned by foundation models are effective, especially as scaling models yields diminishing returns.", "method": "Proposes the contexture theory, proving that optimal representations arise from capturing the association between input X and context variable A. Introduces SVME and KISE objectives for learning contextures and shows how to combine contexts.", "result": "Demonstrates that many pretraining methods can learn contextures and provides statistical learning bounds. Highlights the importance of balanced association strength between X and A.", "conclusion": "Scaling models alone is insufficient; better contexts are crucial for advancing representation learning. The theory unifies diverse pretraining methods and guides future improvements."}}
{"id": "2504.19673", "pdf": "https://arxiv.org/pdf/2504.19673", "abs": "https://arxiv.org/abs/2504.19673", "authors": ["Stefanie Krause", "Ashish Dalvi", "Syed Khubaib Zaidi"], "title": "Generative AI in Education: Student Skills and Lecturer Roles", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) tools such as ChatGPT are emerging\nas a revolutionary tool in education that brings both positive aspects and\nchallenges for educators and students, reshaping how learning and teaching are\napproached. This study aims to identify and evaluate the key competencies\nstudents need to effectively engage with GenAI in education and to provide\nstrategies for lecturers to integrate GenAI into teaching practices. The study\napplied a mixed method approach with a combination of a literature review and a\nquantitative survey involving 130 students from South Asia and Europe to obtain\nits findings. The literature review identified 14 essential student skills for\nGenAI engagement, with AI literacy, critical thinking, and ethical AI practices\nemerging as the most critical. The student survey revealed gaps in prompt\nengineering, bias awareness, and AI output management. In our study of lecturer\nstrategies, we identified six key areas, with GenAI Integration and Curriculum\nDesign being the most emphasised. Our findings highlight the importance of\nincorporating GenAI into education. While literature prioritized ethics and\npolicy development, students favour hands-on, project-based learning and\npractical AI applications. To foster inclusive and responsible GenAI adoption,\ninstitutions should ensure equitable access to GenAI tools, establish clear\nacademic integrity policies, and advocate for global GenAI research\ninitiatives.", "AI": {"tldr": "The study evaluates student competencies and lecturer strategies for integrating GenAI in education, identifying key skills and gaps through a mixed-method approach.", "motivation": "To address the transformative impact of GenAI tools like ChatGPT in education and provide actionable insights for educators and students.", "method": "Mixed-method approach combining literature review (identifying 14 student skills) and a quantitative survey of 130 students from South Asia and Europe.", "result": "Key student skills: AI literacy, critical thinking, ethical AI practices. Gaps: prompt engineering, bias awareness, AI output management. Lecturer strategies emphasize GenAI integration and curriculum design.", "conclusion": "Institutions should ensure equitable access to GenAI tools, establish academic integrity policies, and promote global research for responsible adoption."}}
{"id": "2411.00030", "pdf": "https://arxiv.org/pdf/2411.00030", "abs": "https://arxiv.org/abs/2411.00030", "authors": ["Danrun Cao", "Nicolas B\u00e9chet", "Pierre-Fran\u00e7ois Marteau"], "title": "WikiNER-fr-gold: A Gold-Standard NER Corpus", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": null, "summary": "We address in this article the the quality of the WikiNER corpus, a\nmultilingual Named Entity Recognition corpus, and provide a consolidated\nversion of it. The annotation of WikiNER was produced in a semi-supervised\nmanner i.e. no manual verification has been carried out a posteriori. Such\ncorpus is called silver-standard. In this paper we propose WikiNER-fr-gold\nwhich is a revised version of the French proportion of WikiNER. Our corpus\nconsists of randomly sampled 20% of the original French sub-corpus (26,818\nsentences with 700k tokens). We start by summarizing the entity types included\nin each category in order to define an annotation guideline, and then we\nproceed to revise the corpus. Finally we present an analysis of errors and\ninconsistency observed in the WikiNER-fr corpus, and we discuss potential\nfuture work directions.", "AI": {"tldr": "The paper introduces WikiNER-fr-gold, a revised version of the French portion of the WikiNER corpus, addressing its quality issues and providing a gold-standard annotation.", "motivation": "To improve the quality of the WikiNER corpus, which was originally created semi-supervised (silver-standard) without manual verification, by producing a manually revised version for French.", "method": "Randomly sampled 20% of the original French sub-corpus (26,818 sentences), defined annotation guidelines, and revised the corpus manually.", "result": "A gold-standard version (WikiNER-fr-gold) was created, and errors/inconsistencies in the original corpus were analyzed.", "conclusion": "The revised corpus provides higher quality annotations, and future work directions are discussed to further improve such resources."}}
{"id": "2504.19684", "pdf": "https://arxiv.org/pdf/2504.19684", "abs": "https://arxiv.org/abs/2504.19684", "authors": ["Anush Lakshman Sivaraman", "Kojo Adu-Gyamfi", "Ibne Farabi Shihab", "Anuj Sharma"], "title": "ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Accurate weather classification from low-quality traffic camera imagery\nremains a challenging task, particularly under adverse nighttime conditions. In\nthis study, we propose a scalable framework that combines generative domain\nadaptation with efficient contrastive learning to enhance classification\nperformance. Using CycleGAN-based domain translation, we improve the quality of\nnighttime images, enabling better feature extraction by downstream models.\nWhile the baseline EVA-02 model employing CLIP-based contrastive loss achieves\nan overall accuracy of 96.55\\%, it exhibits a significant performance gap\nbetween daytime (97.21\\%) and nighttime conditions (63.40\\%). Replacing CLIP\nwith the lightweight SigLIP-2 (Sigmoid contrastive loss) achieves a competitive\noverall accuracy of 94.00\\%, with substantial improvements in nighttime\nperformance (85.90\\% accuracy). The combination of Vision-SigLIP-2,\nText-SigLIP-2, CycleGAN, and contrastive training achieves the best nighttime\naccuracy (85.90\\%) among all models tested, while EVA-02 with CycleGAN\nmaintains the highest overall accuracy (97.01\\%) and per-class accuracies.\nThese findings demonstrate the potential of combining domain adaptation and\nefficient contrastive learning to build practical, resource-efficient weather\nclassification systems for intelligent transportation infrastructure.", "AI": {"tldr": "A scalable framework combining generative domain adaptation and contrastive learning improves weather classification from low-quality traffic camera images, especially at night.", "motivation": "Accurate weather classification from low-quality nighttime traffic camera imagery is challenging.", "method": "Uses CycleGAN for domain translation and SigLIP-2 for contrastive learning to enhance feature extraction.", "result": "SigLIP-2 improves nighttime accuracy to 85.90%, while EVA-02 with CycleGAN achieves 97.01% overall accuracy.", "conclusion": "Combining domain adaptation and efficient contrastive learning enhances practical, resource-efficient weather classification systems."}}
{"id": "2504.19820", "pdf": "https://arxiv.org/pdf/2504.19820", "abs": "https://arxiv.org/abs/2504.19820", "authors": ["Yoonhyuk Choi", "Chong-Kwon Kim"], "title": "Hierarchical Uncertainty-Aware Graph Neural Network", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Recent research on graph neural networks (GNNs) has explored mechanisms for\ncapturing local uncertainty and exploiting graph hierarchies to mitigate data\nsparsity and leverage structural properties. However, the synergistic\nintegration of these two approaches remains underexplored. In this work, we\nintroduce a novel architecture, the Hierarchical Uncertainty-Aware Graph Neural\nNetwork (HU-GNN), which unifies multi-scale representation learning, principled\nuncertainty estimation, and self-supervised embedding diversity within a single\nend-to-end framework. Specifically, HU-GNN adaptively forms node clusters and\nestimates uncertainty at multiple structural scales from individual nodes to\nhigher levels. These uncertainty estimates guide a robust message-passing\nmechanism and attention weighting, effectively mitigating noise and adversarial\nperturbations while preserving predictive accuracy on both node- and\ngraph-level tasks. We also offer key theoretical contributions, including a\nprobabilistic formulation, rigorous uncertainty-calibration guarantees, and\nformal robustness bounds. Finally, by incorporating recent advances in graph\ncontrastive learning, HU-GNN maintains diverse, structurally faithful\nembeddings. Extensive experiments on standard benchmarks demonstrate that our\nmodel achieves state-of-the-art robustness and interpretability.", "AI": {"tldr": "HU-GNN integrates multi-scale representation learning, uncertainty estimation, and self-supervised diversity in a single framework for robust and interpretable graph neural networks.", "motivation": "To address the underexplored synergy between local uncertainty capture and graph hierarchy exploitation in GNNs.", "method": "HU-GNN adaptively clusters nodes, estimates uncertainty at multiple scales, and uses these for robust message-passing and attention weighting.", "result": "Achieves state-of-the-art robustness and interpretability on standard benchmarks.", "conclusion": "HU-GNN unifies uncertainty-aware learning and hierarchical representation, offering theoretical guarantees and practical performance."}}
{"id": "2504.19674", "pdf": "https://arxiv.org/pdf/2504.19674", "abs": "https://arxiv.org/abs/2504.19674", "authors": ["Madhur Jindal", "Hari Shrawgi", "Parag Agrawal", "Sandipan Dandapat"], "title": "$\\texttt{SAGE}$: A Generic Framework for LLM Safety Evaluation", "categories": ["cs.CR", "cs.AI"], "comment": "24 pages, 9 main pages excluding references and appendix", "summary": "Safety evaluation of Large Language Models (LLMs) has made progress and\nattracted academic interest, but it remains challenging to keep pace with the\nrapid integration of LLMs across diverse applications. Different applications\nexpose users to various harms, necessitating application-specific safety\nevaluations with tailored harms and policies. Another major gap is the lack of\nfocus on the dynamic and conversational nature of LLM systems. Such potential\noversights can lead to harms that go unnoticed in standard safety benchmarks.\nThis paper identifies the above as key requirements for robust LLM safety\nevaluation and recognizing that current evaluation methodologies do not satisfy\nthese, we introduce the $\\texttt{SAGE}$ (Safety AI Generic Evaluation)\nframework. $\\texttt{SAGE}$ is an automated modular framework designed for\ncustomized and dynamic harm evaluations. It utilizes adversarial user models\nthat are system-aware and have unique personalities, enabling a holistic\nred-teaming evaluation. We demonstrate $\\texttt{SAGE}$'s effectiveness by\nevaluating seven state-of-the-art LLMs across three applications and harm\npolicies. Our experiments with multi-turn conversational evaluations revealed a\nconcerning finding that harm steadily increases with conversation length.\nFurthermore, we observe significant disparities in model behavior when exposed\nto different user personalities and scenarios. Our findings also reveal that\nsome models minimize harmful outputs by employing severe refusal tactics that\ncan hinder their usefulness. These insights highlight the necessity of adaptive\nand context-specific testing to ensure better safety alignment and safer\ndeployment of LLMs in real-world scenarios.", "AI": {"tldr": "The paper introduces SAGE, a framework for dynamic and application-specific safety evaluation of LLMs, addressing gaps in current methodologies.", "motivation": "Current LLM safety evaluations lack focus on dynamic, conversational contexts and application-specific harms, leading to unnoticed risks.", "method": "The SAGE framework uses adversarial user models with unique personalities for automated, modular, and holistic red-teaming evaluations.", "result": "Experiments show harm increases with conversation length, model behavior varies by user personality, and some models overuse refusal tactics.", "conclusion": "Adaptive, context-specific testing is essential for safer LLM deployment, as highlighted by SAGE's findings."}}
{"id": "2411.07611", "pdf": "https://arxiv.org/pdf/2411.07611", "abs": "https://arxiv.org/abs/2411.07611", "authors": ["Shuai Niu", "Jing Ma", "Hongzhan Lin", "Liang Bai", "Zhihua Wang", "Yida Xu", "Yunya Song", "Xian Yang"], "title": "Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "13 pages. 7 figures", "summary": "Interpretation is critical for disease diagnosis, but existing models\nstruggle to balance predictive accuracy with human-understandable rationales.\nWhile large language models (LLMs) offer strong reasoning abilities, their\nclinical use is limited by high computational costs and restricted multimodal\nreasoning ability. Small language models (SLMs) are efficient but lack advanced\nreasoning for integrating multimodal medical data. In addition, both LLMs and\nSLMs lack of domain knowledge for trustworthy reasoning. Therefore, we propose\nClinRaGen, enhancing SLMs by leveraging LLM-derived reasoning ability via\nrationale distillation and domain knowledge injection for trustworthy\nmultimodal rationale generation. Key innovations include a sequential rationale\ndistillation framework that equips SLMs with LLM-comparable mutlimodal\nreasoning abilities, and a knowledge-augmented attention mechanism that jointly\nunifies multimodal representation from time series and textual data in a same\nencoding space, enabling it naturally interpreted by SLMs while incorporating\ndomain knowledge for reliable rationale generation. Experiments on real-world\nmedical datasets show that ClinRaGen achieves state-of-the-art performance in\ndisease diagnosis and rationale generation, demonstrating the effectiveness of\ncombining LLM-driven reasoning with knowledge augmentation for improved\ninterpretability.", "AI": {"tldr": "ClinRaGen enhances small language models (SLMs) with LLM-derived reasoning and domain knowledge for trustworthy multimodal rationale generation in disease diagnosis.", "motivation": "Existing models struggle to balance accuracy and interpretability, with LLMs being computationally expensive and SLMs lacking advanced reasoning.", "method": "Sequential rationale distillation and knowledge-augmented attention mechanism to unify multimodal data.", "result": "State-of-the-art performance in disease diagnosis and rationale generation on real-world datasets.", "conclusion": "Combining LLM reasoning with knowledge augmentation improves interpretability and performance."}}
{"id": "2504.19687", "pdf": "https://arxiv.org/pdf/2504.19687", "abs": "https://arxiv.org/abs/2504.19687", "authors": ["Baoshun Shi", "Bing Chen", "Shaolei Zhang", "Huazhu Fu", "Zhanli Hu"], "title": "Prompt Guiding Multi-Scale Adaptive Sparse Representation-driven Network for Low-Dose CT MAR", "categories": ["cs.CV"], "comment": null, "summary": "Low-dose CT (LDCT) is capable of reducing X-ray radiation exposure, but it\nwill potentially degrade image quality, even yields metal artifacts at the case\nof metallic implants. For simultaneous LDCT reconstruction and metal artifact\nreduction (LDMAR), existing deep learning-based efforts face two main\nlimitations: i) the network design neglects multi-scale and within-scale\ninformation; ii) training a distinct model for each dose necessitates\nsignificant storage space for multiple doses. To fill these gaps, we propose a\nprompt guiding multi-scale adaptive sparse representation-driven network,\nabbreviated as PMSRNet, for LDMAR task. Specifically, we construct PMSRNet\ninspired from multi-scale sparsifying frames, and it can simultaneously employ\nwithin-scale characteristics and cross-scale complementarity owing to an\nelaborated prompt guiding scale-adaptive threshold generator (PSATG) and a\nbuilt multi-scale coefficient fusion module (MSFuM). The PSATG can adaptively\ncapture multiple contextual information to generate more faithful thresholds,\nachieved by fusing features from local, regional, and global levels.\nFurthermore, we elaborate a model interpretable dual domain LDMAR framework\ncalled PDuMSRNet, and train single model with a prompt guiding strategy for\nmultiple dose levels. We build a prompt guiding module, whose input contains\ndose level, metal mask and input instance, to provide various guiding\ninformation, allowing a single model to accommodate various CT dose settings.\nExtensive experiments at various dose levels demonstrate that the proposed\nmethods outperform the state-of-the-art LDMAR methods.", "AI": {"tldr": "Proposes PMSRNet for low-dose CT reconstruction and metal artifact reduction, addressing multi-scale information neglect and storage inefficiency with a single adaptive model.", "motivation": "Existing methods lack multi-scale and within-scale information integration and require separate models for each dose level, increasing storage needs.", "method": "Introduces PMSRNet with a prompt guiding scale-adaptive threshold generator (PSATG) and multi-scale coefficient fusion module (MSFuM) for adaptive thresholding and feature fusion. Also develops PDuMSRNet, a dual-domain framework, trained with a prompt guiding strategy for multiple doses.", "result": "Outperforms state-of-the-art methods in experiments across various dose levels.", "conclusion": "PMSRNet and PDuMSRNet effectively address limitations in LDCT reconstruction and metal artifact reduction, offering improved performance and efficiency."}}
{"id": "2504.19822", "pdf": "https://arxiv.org/pdf/2504.19822", "abs": "https://arxiv.org/abs/2504.19822", "authors": ["Minjong Cheon"], "title": "Mj\u00f6lnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density", "categories": ["cs.LG", "cs.AI", "cs.CV", "physics.ao-ph"], "comment": null, "summary": "Recent advances in AI-based weather forecasting models, such as FourCastNet,\nPangu-Weather, and GraphCast, have demonstrated the remarkable ability of deep\nlearning to emulate complex atmospheric dynamics. Building on this momentum, we\npropose Mj\\\"olnir, a novel deep learning-based framework for global lightning\nflash density parameterization. Trained on ERA5 atmospheric predictors and\nWorld Wide Lightning Location Network (WWLLN) observations at a daily temporal\nresolution and 1 degree spatial resolution, Mj\\\"olnir captures the nonlinear\nmapping between large-scale environmental conditions and lightning activity.\nThe model architecture is based on the InceptionNeXt backbone with SENet, and a\nmulti-task learning strategy to simultaneously predict lightning occurrence and\nmagnitude. Extensive evaluations yield that Mollnir accurately reproduces the\nglobal distribution, seasonal variability, and regional characteristics of\nlightning activity, achieving a global Pearson correlation coefficient of 0.96\nfor annual mean fields. These results suggest that Mj\\\"olnir serves not only as\nan effective data-driven global lightning parameterization but also as a\npromising AI-based scheme for next-generation Earth system models (AI-ESMs).", "AI": {"tldr": "Mj\"olnir is a deep learning framework for global lightning flash density prediction, achieving high accuracy with a Pearson correlation of 0.96.", "motivation": "To leverage AI for accurate global lightning activity prediction, building on advances in AI-based weather forecasting.", "method": "Uses ERA5 and WWLLN data with an InceptionNeXt-SENet architecture and multi-task learning for lightning occurrence and magnitude.", "result": "Accurately predicts global lightning distribution, seasonal variability, and regional patterns.", "conclusion": "Mj\"olnir is a robust AI-based tool for lightning parameterization and future Earth system models."}}
{"id": "2504.19715", "pdf": "https://arxiv.org/pdf/2504.19715", "abs": "https://arxiv.org/abs/2504.19715", "authors": ["Heisei Yonezawa", "Ansei Yonezawa", "Itsuro Kajiwara"], "title": "Model-based controller assisted domain randomization in deep reinforcement learning: application to nonlinear powertrain control", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": null, "summary": "Complex mechanical systems such as vehicle powertrains are inherently subject\nto multiple nonlinearities and uncertainties arising from parametric\nvariations. Modeling and calibration errors are therefore unavoidable, making\nthe transfer of control systems from simulation to real-world systems a\ncritical challenge. Traditional robust controls have limitations in handling\ncertain types of nonlinearities and uncertainties, requiring a more practical\napproach capable of comprehensively compensating for these various constraints.\nThis study proposes a new robust control approach using the framework of deep\nreinforcement learning (DRL). The key strategy lies in the synergy among domain\nrandomization-based DRL, long short-term memory (LSTM)-based actor and critic\nnetworks, and model-based control (MBC). The problem setup is modeled via the\nlatent Markov decision process (LMDP), a set of vanilla MDPs, for a controlled\nsystem subject to uncertainties and nonlinearities. In LMDP, the dynamics of an\nenvironment simulator is randomized during training to improve the robustness\nof the control system to real testing environments. The randomization increases\ntraining difficulties as well as conservativeness of the resultant control\nsystem; therefore, progress is assisted by concurrent use of a model-based\ncontroller based on a nominal system model. Compared to traditional DRL-based\ncontrols, the proposed controller design is smarter in that we can achieve a\nhigh level of generalization ability with a more compact neural network\narchitecture and a smaller amount of training data. The proposed approach is\nverified via practical application to active damping for a complex powertrain\nsystem with nonlinearities and parametric variations. Comparative tests\ndemonstrate the high robustness of the proposed approach.", "AI": {"tldr": "A novel robust control approach using deep reinforcement learning (DRL) is proposed to handle nonlinearities and uncertainties in complex mechanical systems, outperforming traditional methods.", "motivation": "Traditional robust controls struggle with certain nonlinearities and uncertainties, necessitating a more practical and comprehensive solution for real-world applications.", "method": "The approach combines domain randomization-based DRL, LSTM-based actor and critic networks, and model-based control (MBC) within a latent Markov decision process (LMDP) framework.", "result": "The method achieves high generalization with compact neural networks and less training data, validated by successful application to a powertrain system.", "conclusion": "The proposed DRL-based control demonstrates superior robustness and practicality for complex systems with nonlinearities and uncertainties."}}
{"id": "2411.17270", "pdf": "https://arxiv.org/pdf/2411.17270", "abs": "https://arxiv.org/abs/2411.17270", "authors": ["Duc-Vu Nguyen", "Thang Chau Phan", "Quoc-Nam Nguyen", "Kiet Van Nguyen", "Ngan Luu-Thuy Nguyen"], "title": "An Attempt to Develop a Neural Parser based on Simplified Head-Driven Phrase Structure Grammar on Vietnamese", "categories": ["cs.CL"], "comment": "Accepted at SoICT 2024", "summary": "In this paper, we aimed to develop a neural parser for Vietnamese based on\nsimplified Head-Driven Phrase Structure Grammar (HPSG). The existing corpora,\nVietTreebank and VnDT, had around 15% of constituency and dependency tree pairs\nthat did not adhere to simplified HPSG rules. To attempt to address the issue\nof the corpora not adhering to simplified HPSG rules, we randomly permuted\nsamples from the training and development sets to make them compliant with\nsimplified HPSG. We then modified the first simplified HPSG Neural Parser for\nthe Penn Treebank by replacing it with the PhoBERT or XLM-RoBERTa models, which\ncan encode Vietnamese texts. We conducted experiments on our modified\nVietTreebank and VnDT corpora. Our extensive experiments showed that the\nsimplified HPSG Neural Parser achieved a new state-of-the-art F-score of 82%\nfor constituency parsing when using the same predicted part-of-speech (POS)\ntags as the self-attentive constituency parser. Additionally, it outperformed\nprevious studies in dependency parsing with a higher Unlabeled Attachment Score\n(UAS). However, our parser obtained lower Labeled Attachment Score (LAS) scores\nlikely due to our focus on arc permutation without changing the original\nlabels, as we did not consult with a linguistic expert. Lastly, the research\nfindings of this paper suggest that simplified HPSG should be given more\nattention to linguistic expert when developing treebanks for Vietnamese natural\nlanguage processing.", "AI": {"tldr": "A neural parser for Vietnamese based on simplified HPSG was developed, achieving state-of-the-art F-scores in constituency parsing but lower LAS in dependency parsing due to label constraints.", "motivation": "To address the issue of existing Vietnamese corpora not fully adhering to simplified HPSG rules and improve parsing performance.", "method": "Modified a simplified HPSG Neural Parser by replacing models with PhoBERT/XLM-RoBERTa for Vietnamese text encoding and permuted non-compliant corpus samples.", "result": "Achieved 82% F-score in constituency parsing and higher UAS in dependency parsing, but lower LAS due to unchanged labels.", "conclusion": "Simplified HPSG requires linguistic expert input for better label handling in Vietnamese treebank development."}}
{"id": "2504.19695", "pdf": "https://arxiv.org/pdf/2504.19695", "abs": "https://arxiv.org/abs/2504.19695", "authors": ["Lucas Morin", "Gerhard Ingmar Meijer", "Val\u00e9ry Weber", "Luc Van Gool", "Peter W. J. Staar"], "title": "SubGrapher: Visual Fingerprinting of Chemical Structures", "categories": ["cs.CV"], "comment": null, "summary": "Automatic extraction of chemical structures from scientific literature plays\na crucial role in accelerating research across fields ranging from drug\ndiscovery to materials science. Patent documents, in particular, contain\nmolecular information in visual form, which is often inaccessible through\ntraditional text-based searches. In this work, we introduce SubGrapher, a\nmethod for the visual fingerprinting of chemical structure images. Unlike\nconventional Optical Chemical Structure Recognition (OCSR) models that attempt\nto reconstruct full molecular graphs, SubGrapher focuses on extracting\nmolecular fingerprints directly from chemical structure images. Using\nlearning-based instance segmentation, SubGrapher identifies functional groups\nand carbon backbones, constructing a substructure-based fingerprint that\nenables chemical structure retrieval. Our approach is evaluated against\nstate-of-the-art OCSR and fingerprinting methods, demonstrating superior\nretrieval performance and robustness across diverse molecular depictions. The\ndataset, models, and code will be made publicly available.", "AI": {"tldr": "SubGrapher extracts molecular fingerprints directly from chemical structure images, outperforming traditional methods in retrieval performance.", "motivation": "Chemical structures in patents are often inaccessible via text searches, necessitating visual extraction methods.", "method": "SubGrapher uses learning-based instance segmentation to identify functional groups and carbon backbones for fingerprinting.", "result": "Outperforms state-of-the-art OCSR and fingerprinting methods in retrieval and robustness.", "conclusion": "SubGrapher offers a superior approach for chemical structure retrieval, with public release of resources."}}
{"id": "2504.19874", "pdf": "https://arxiv.org/pdf/2504.19874", "abs": "https://arxiv.org/abs/2504.19874", "authors": ["Amir Zandieh", "Majid Daliri", "Majid Hadian", "Vahab Mirrokni"], "title": "TurboQuant: Online Vector Quantization with Near-optimal Distortion Rate", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.DS"], "comment": "25 pages", "summary": "Vector quantization, a problem rooted in Shannon's source coding theory, aims\nto quantize high-dimensional Euclidean vectors while minimizing distortion in\ntheir geometric structure. We propose TurboQuant to address both mean-squared\nerror (MSE) and inner product distortion, overcoming limitations of existing\nmethods that fail to achieve optimal distortion rates. Our data-oblivious\nalgorithms, suitable for online applications, achieve near-optimal distortion\nrates (within a small constant factor) across all bit-widths and dimensions.\nTurboQuant achieves this by randomly rotating input vectors, inducing a\nconcentrated Beta distribution on coordinates, and leveraging the\nnear-independence property of distinct coordinates in high dimensions to simply\napply optimal scalar quantizers per each coordinate. Recognizing that\nMSE-optimal quantizers introduce bias in inner product estimation, we propose a\ntwo-stage approach: applying an MSE quantizer followed by a 1-bit Quantized JL\n(QJL) transform on the residual, resulting in an unbiased inner product\nquantizer. We also provide a formal proof of the information-theoretic lower\nbounds on best achievable distortion rate by any vector quantizer,\ndemonstrating that TurboQuant closely matches these bounds, differing only by a\nsmall constant ($\\approx 2.7$) factor. Experimental results validate our\ntheoretical findings, showing that for KV cache quantization, we achieve\nabsolute quality neutrality with 3.5 bits per channel and marginal quality\ndegradation with 2.5 bits per channel. Furthermore, in nearest neighbor search\ntasks, our method outperforms existing product quantization techniques in\nrecall while reducing indexing time to virtually zero.", "AI": {"tldr": "TurboQuant is a novel vector quantization method that achieves near-optimal distortion rates for both MSE and inner product, outperforming existing techniques with minimal quality degradation.", "motivation": "Existing vector quantization methods fail to achieve optimal distortion rates for both MSE and inner product, limiting their effectiveness in applications like KV cache quantization and nearest neighbor search.", "method": "TurboQuant uses random rotations to induce a Beta distribution on coordinates, applies optimal scalar quantizers per coordinate, and introduces a two-stage approach (MSE quantizer + 1-bit QJL transform) for unbiased inner product estimation.", "result": "TurboQuant achieves near-optimal distortion rates, closely matching theoretical lower bounds. It shows absolute quality neutrality at 3.5 bits per channel and outperforms existing methods in nearest neighbor search tasks.", "conclusion": "TurboQuant is a highly efficient and practical solution for vector quantization, offering superior performance with minimal distortion and computational overhead."}}
{"id": "2504.19755", "pdf": "https://arxiv.org/pdf/2504.19755", "abs": "https://arxiv.org/abs/2504.19755", "authors": ["Kapil Kashyap", "Sean Fargose", "Chrisil Dabre", "Fatema Dolaria", "Nilesh Patil", "Aniket Kore"], "title": "Hybrid Approach Combining Ultrasound and Blood Test Analysis with a Voting Classifier for Accurate Liver Fibrosis and Cirrhosis Assessment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Liver cirrhosis is an insidious condition involving the substitution of\nnormal liver tissue with fibrous scar tissue and causing major health\ncomplications. The conventional method of diagnosis using liver biopsy is\ninvasive and, therefore, inconvenient for use in regular screening. In this\npaper,we present a hybrid model that combines machine learning techniques with\nclinical data and ultrasoundscans to improve liver fibrosis and cirrhosis\ndetection accuracy is presented. The model integrates fixed blood test\nprobabilities with deep learning model predictions (DenseNet-201) for\nultrasonic images. The combined hybrid model achieved an accuracy of 92.5%. The\nfindings establish the viability of the combined model in enhancing diagnosis\naccuracy and supporting early intervention in liver disease care.", "AI": {"tldr": "A hybrid model combining machine learning, clinical data, and ultrasound scans improves liver cirrhosis detection with 92.5% accuracy, offering a non-invasive alternative to liver biopsy.", "motivation": "Liver biopsy is invasive and unsuitable for regular screening, necessitating a non-invasive, accurate diagnostic method for liver cirrhosis.", "method": "The hybrid model integrates fixed blood test probabilities with deep learning (DenseNet-201) predictions from ultrasound scans.", "result": "The model achieved 92.5% accuracy in detecting liver fibrosis and cirrhosis.", "conclusion": "The hybrid model enhances diagnosis accuracy and supports early intervention, proving viable for liver disease care."}}
{"id": "2412.17592", "pdf": "https://arxiv.org/pdf/2412.17592", "abs": "https://arxiv.org/abs/2412.17592", "authors": ["Ziqian Peng", "Rachel Bawden", "Fran\u00e7ois Yvon"], "title": "Investigating Length Issues in Document-level Machine Translation", "categories": ["cs.CL"], "comment": "Accepted at the MT Summit 2025", "summary": "Transformer architectures are increasingly effective at processing and\ngenerating very long chunks of texts, opening new perspectives for\ndocument-level machine translation (MT). In this work, we challenge the ability\nof MT systems to handle texts comprising up to several thousands of tokens. We\ndesign and implement a new approach designed to precisely measure the effect of\nlength increments on MT outputs. Our experiments with two representative\narchitectures unambiguously show that (a)~translation performance decreases\nwith the length of the input text; (b)~the position of sentences within the\ndocument matters, and translation quality is higher for sentences occurring\nearlier in a document. We further show that manipulating the distribution of\ndocument lengths and of positional embeddings only marginally mitigates such\nproblems. Our results suggest that even though document-level MT is\ncomputationally feasible, it does not yet match the performance of\nsentence-based MT.", "AI": {"tldr": "The paper explores the challenges of document-level machine translation (MT) with long texts, showing performance declines with length and positional effects.", "motivation": "To assess the ability of MT systems to handle very long texts and understand the impact of length and sentence position on translation quality.", "method": "Designed a new approach to measure length increments' effects on MT outputs, tested with two representative architectures.", "result": "Translation performance decreases with input length, and earlier sentences in documents are translated better. Adjusting document length distribution and positional embeddings had minimal impact.", "conclusion": "Document-level MT is feasible but underperforms compared to sentence-based MT."}}
{"id": "2504.19706", "pdf": "https://arxiv.org/pdf/2504.19706", "abs": "https://arxiv.org/abs/2504.19706", "authors": ["Song Xia", "Yi Yu", "Henghui Ding", "Wenhan Yang", "Shifei Liu", "Alex C. Kot", "Xudong Jiang"], "title": "Open-set Anomaly Segmentation in Complex Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "Precise segmentation of out-of-distribution (OoD) objects, herein referred to\nas anomalies, is crucial for the reliable deployment of semantic segmentation\nmodels in open-set, safety-critical applications, such as autonomous driving.\nCurrent anomalous segmentation benchmarks predominantly focus on favorable\nweather conditions, resulting in untrustworthy evaluations that overlook the\nrisks posed by diverse meteorological conditions in open-set environments, such\nas low illumination, dense fog, and heavy rain. To bridge this gap, this paper\nintroduces the ComsAmy, a challenging benchmark specifically designed for\nopen-set anomaly segmentation in complex scenarios. ComsAmy encompasses a wide\nspectrum of adverse weather conditions, dynamic driving environments, and\ndiverse anomaly types to comprehensively evaluate the model performance in\nrealistic open-world scenarios. Our extensive evaluation of several\nstate-of-the-art anomalous segmentation models reveals that existing methods\ndemonstrate significant deficiencies in such challenging scenarios,\nhighlighting their serious safety risks for real-world deployment. To solve\nthat, we propose a novel energy-entropy learning (EEL) strategy that integrates\nthe complementary information from energy and entropy to bolster the robustness\nof anomaly segmentation under complex open-world environments. Additionally, a\ndiffusion-based anomalous training data synthesizer is proposed to generate\ndiverse and high-quality anomalous images to enhance the existing copy-paste\ntraining data synthesizer. Extensive experimental results on both public and\nComsAmy benchmarks demonstrate that our proposed diffusion-based synthesizer\nwith energy and entropy learning (DiffEEL) serves as an effective and\ngeneralizable plug-and-play method to enhance existing models, yielding an\naverage improvement of around 4.96% in $\\rm{AUPRC}$ and 9.87% in\n$\\rm{FPR}_{95}$.", "AI": {"tldr": "The paper introduces ComsAmy, a benchmark for anomaly segmentation in adverse weather, and proposes DiffEEL, a method combining energy-entropy learning and diffusion-based data synthesis to improve model robustness.", "motivation": "Current benchmarks overlook adverse weather conditions, leading to unreliable evaluations for safety-critical applications like autonomous driving.", "method": "Proposes DiffEEL, integrating energy-entropy learning and a diffusion-based data synthesizer to enhance anomaly segmentation.", "result": "DiffEEL improves performance by 4.96% in AUPRC and 9.87% in FPR95 on benchmarks.", "conclusion": "DiffEEL is a plug-and-play solution for robust anomaly segmentation in complex open-world scenarios."}}
{"id": "2504.19901", "pdf": "https://arxiv.org/pdf/2504.19901", "abs": "https://arxiv.org/abs/2504.19901", "authors": ["Hude Liu", "Jerry Yao-Chieh Hu", "Zhao Song", "Han Liu"], "title": "Attention Mechanism, Max-Affine Partition, and Universal Approximation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We establish the universal approximation capability of single-layer,\nsingle-head self- and cross-attention mechanisms with minimal attached\nstructures. Our key insight is to interpret single-head attention as an input\ndomain-partition mechanism that assigns distinct values to subregions. This\nallows us to engineer the attention weights such that this assignment imitates\nthe target function. Building on this, we prove that a single self-attention\nlayer, preceded by sum-of-linear transformations, is capable of approximating\nany continuous function on a compact domain under the $L_\\infty$-norm.\nFurthermore, we extend this construction to approximate any Lebesgue integrable\nfunction under $L_p$-norm for $1\\leq p <\\infty$. Lastly, we also extend our\ntechniques and show that, for the first time, single-head cross-attention\nachieves the same universal approximation guarantees.", "AI": {"tldr": "Single-layer, single-head self- and cross-attention mechanisms can universally approximate continuous and Lebesgue integrable functions with minimal structures.", "motivation": "To demonstrate the universal approximation capability of simplified attention mechanisms, challenging the notion that complex architectures are necessary.", "method": "Interpret single-head attention as a domain-partition mechanism, engineer attention weights to imitate target functions, and extend the approach to cross-attention.", "result": "Proven capability to approximate any continuous function under $L_\\infty$-norm and any Lebesgue integrable function under $L_p$-norm.", "conclusion": "Simplified attention mechanisms achieve universal approximation, broadening their theoretical applicability."}}
{"id": "2504.19847", "pdf": "https://arxiv.org/pdf/2504.19847", "abs": "https://arxiv.org/abs/2504.19847", "authors": ["Juhan Park", "Kyungjae Lee", "Hyung Jin Chang", "Jungchan Cho"], "title": "Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this work, we introduce Segmentation to Human-Object Interaction\n(\\textit{\\textbf{Seg2HOI}}) approach, a novel framework that integrates\nsegmentation-based vision foundation models with the human-object interaction\ntask, distinguished from traditional detection-based Human-Object Interaction\n(HOI) methods. Our approach enhances HOI detection by not only predicting the\nstandard triplets but also introducing quadruplets, which extend HOI triplets\nby including segmentation masks for human-object pairs. More specifically,\nSeg2HOI inherits the properties of the vision foundation model (e.g.,\npromptable and interactive mechanisms) and incorporates a decoder that applies\nthese attributes to HOI task. Despite training only for HOI, without additional\ntraining mechanisms for these properties, the framework demonstrates that such\nfeatures still operate efficiently. Extensive experiments on two public\nbenchmark datasets demonstrate that Seg2HOI achieves performance comparable to\nstate-of-the-art methods, even in zero-shot scenarios. Lastly, we propose that\nSeg2HOI can generate HOI quadruplets and interactive HOI segmentation from\nnovel text and visual prompts that were not used during training, making it\nversatile for a wide range of applications by leveraging this flexibility.", "AI": {"tldr": "Seg2HOI integrates segmentation models with HOI tasks, introducing quadruplets (HOI triplets + masks) and leveraging vision foundation model properties without extra training. It matches state-of-the-art performance and supports zero-shot and prompt-based applications.", "motivation": "To enhance HOI detection by incorporating segmentation masks and leveraging vision foundation models' properties for more versatile and efficient HOI tasks.", "method": "Seg2HOI combines segmentation-based vision models with an HOI decoder, using quadruplets (triplets + masks) and inheriting promptable/interactive features from foundation models.", "result": "Achieves performance comparable to state-of-the-art methods on benchmark datasets, even in zero-shot scenarios.", "conclusion": "Seg2HOI is versatile, generating HOI quadruplets and interactive segmentation from novel prompts, broadening its application potential."}}
{"id": "2412.17596", "pdf": "https://arxiv.org/pdf/2412.17596", "abs": "https://arxiv.org/abs/2412.17596", "authors": ["Kai Ruan", "Xuan Wang", "Jixiang Hong", "Peng Wang", "Yang Liu", "Hao Sun"], "title": "LiveIdeaBench: Evaluating LLMs' Divergent Thinking for Scientific Idea Generation with Minimal Context", "categories": ["cs.CL", "cs.AI"], "comment": "Updated manuscript and title", "summary": "While Large Language Models (LLMs) demonstrate remarkable capabilities in\nscientific tasks such as literature analysis and experimental design (e.g.,\naccurately extracting key findings from papers or generating coherent\nexperimental procedures), existing evaluation benchmarks primarily assess\nperformance using rich contextual inputs. We introduce LiveIdeaBench, a\ncomprehensive benchmark evaluating LLMs' scientific idea generation by\nassessing divergent thinking capabilities using single-keyword prompts. Drawing\nfrom Guilford's creativity theory, our benchmark employs a dynamic panel of\nstate-of-the-art LLMs to assess generated ideas across five key dimensions:\noriginality, feasibility, fluency, flexibility, and clarity. Through extensive\nexperimentation with over 40 leading models across 1,180 keywords spanning 22\nscientific domains, we reveal that the scientific idea generation capabilities\nmeasured by our benchmark, are poorly predicted by standard metrics of general\nintelligence. Our results demonstrate that models like QwQ-32B-preview achieve\ncreative performance comparable to top-tier models such as\nclaude-3.7-sonnet:thinking, despite significant gaps in their general\nintelligence scores. These findings highlight the need for specialized\nevaluation benchmarks for scientific idea generation and suggest that enhancing\nthese idea generation capabilities in LLMs may require different training\nstrategies than those used for improving general problem-solving abilities,\npotentially enabling a wider range of AI tools tailored for different stages of\nthe scientific process.", "AI": {"tldr": "LiveIdeaBench evaluates LLMs' scientific idea generation using single-keyword prompts, revealing that creative performance doesn't align with general intelligence metrics.", "motivation": "Existing benchmarks focus on rich contextual inputs, but LiveIdeaBench addresses the gap in assessing divergent thinking for scientific idea generation.", "method": "The benchmark uses single-keyword prompts and evaluates ideas across five dimensions (originality, feasibility, fluency, flexibility, clarity) with 40+ models across 22 domains.", "result": "Creative performance (e.g., QwQ-32B-preview) doesn't correlate with general intelligence scores, highlighting the need for specialized benchmarks.", "conclusion": "Specialized training strategies may be required to enhance LLMs' scientific idea generation, enabling tailored AI tools for scientific processes."}}
{"id": "2504.19719", "pdf": "https://arxiv.org/pdf/2504.19719", "abs": "https://arxiv.org/abs/2504.19719", "authors": ["Lukas Folkman", "Quynh LK Vo", "Colin Johnston", "Bela Stantic", "Kylie A Pitt"], "title": "A computer vision method to estimate ventilation rate of Atlantic salmon in sea fish farms", "categories": ["cs.CV"], "comment": null, "summary": "The increasing demand for aquaculture production necessitates the development\nof innovative, intelligent tools to effectively monitor and manage fish health\nand welfare. While non-invasive video monitoring has become a common practice\nin finfish aquaculture, existing intelligent monitoring methods predominantly\nfocus on assessing body condition or fish swimming patterns and are often\ndeveloped and evaluated in controlled tank environments, without demonstrating\ntheir applicability to real-world aquaculture settings in open sea farms. This\nunderscores the necessity for methods that can monitor physiological traits\ndirectly within the production environment of sea fish farms. To this end, we\nhave developed a computer vision method for monitoring ventilation rates of\nAtlantic salmon (Salmo salar), which was specifically designed for videos\nrecorded in the production environment of commercial sea fish farms using the\nexisting infrastructure. Our approach uses a fish head detection model, which\nclassifies the mouth state as either open or closed using a convolutional\nneural network. This is followed with multiple object tracking to create\ntemporal sequences of fish swimming across the field of view of the underwater\nvideo camera to estimate ventilation rates. The method demonstrated high\nefficiency, achieving a Pearson correlation coefficient of 0.82 between ground\ntruth and predicted ventilation rates in a test set of 100 fish collected\nindependently of the training data. By accurately identifying pens where fish\nexhibit signs of respiratory distress, our method offers broad applicability\nand the potential to transform fish health and welfare monitoring in finfish\naquaculture.", "AI": {"tldr": "A computer vision method was developed to monitor Atlantic salmon ventilation rates in commercial sea fish farms, achieving high accuracy and potential for improving fish health monitoring.", "motivation": "The need for innovative tools to monitor fish health in real-world aquaculture settings, as existing methods are limited to controlled environments.", "method": "Uses a fish head detection model with a CNN to classify mouth states (open/closed) and multiple object tracking to estimate ventilation rates from underwater videos.", "result": "Achieved a Pearson correlation coefficient of 0.82 between predicted and ground truth ventilation rates, demonstrating high efficiency.", "conclusion": "The method can identify respiratory distress in fish, offering broad applicability and transformative potential for aquaculture health monitoring."}}
{"id": "2504.19903", "pdf": "https://arxiv.org/pdf/2504.19903", "abs": "https://arxiv.org/abs/2504.19903", "authors": ["Diying Yang", "Yingwei Hou", "Danyang Xiao", "Weigang Wu"], "title": "Convergence Analysis of Asynchronous Federated Learning with Gradient Compression for Non-Convex Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Gradient compression is an effective technique for reducing communication\ncosts in federated learning (FL), and error feedback (EF) is usually adopted to\nremedy the compression errors. However, there remains a lack of systematic\nstudy on these techniques in asynchronous FL. In this paper, we fill this gap\nby analyzing the convergence behaviors of FL under different frameworks. We\nfirstly consider a basic asynchronous FL framework AsynFL, and provide an\nimproved convergence analysis that relies on fewer assumptions and yields a\nsuperior convergence rate than prior studies. Then, we consider a variant\nframework with gradient compression, AsynFLC. We show sufficient conditions for\nits convergence to the optimum, indicating the interaction between asynchronous\ndelay and compression rate. Our analysis also demonstrates that asynchronous\ndelay amplifies the variance caused by compression, thereby hindering\nconvergence, and such an impact is exacerbated by high data heterogeneity.\nFurthermore, we study the convergence of AsynFLC-EF, the framework that further\nintegrates EF. We prove that EF can effectively reduce the variance of gradient\nestimation despite asynchronous delay, which enables AsynFLC-EF to match the\nconvergence rate of AsynFL. We also show that the impact of asynchronous delay\non EF is limited to slowing down the higher-order convergence term.\nExperimental results substantiate our analytical findings very well.", "AI": {"tldr": "The paper analyzes gradient compression and error feedback in asynchronous federated learning (FL), improving convergence analysis and showing how EF mitigates variance caused by compression and delay.", "motivation": "To systematically study gradient compression and error feedback in asynchronous FL, addressing gaps in understanding their convergence behaviors.", "method": "Analyzes convergence under three frameworks: AsynFL (basic asynchronous FL), AsynFLC (with gradient compression), and AsynFLC-EF (with EF). Provides theoretical conditions for convergence and examines interactions between delay, compression, and data heterogeneity.", "result": "Improved convergence rates for AsynFL, identified conditions for AsynFLC convergence, and demonstrated EF's effectiveness in reducing gradient variance despite delay.", "conclusion": "EF enhances convergence in asynchronous FL by mitigating compression-induced variance, with delay primarily affecting higher-order convergence terms. Experiments validate findings."}}
{"id": "2504.19848", "pdf": "https://arxiv.org/pdf/2504.19848", "abs": "https://arxiv.org/abs/2504.19848", "authors": ["Simona Casini", "Pietro Ducange", "Francesco Marcelloni", "Lorenzo Pollini"], "title": "Human-Centered AI and Autonomy in Robotics: Insights from a Bibliometric Study", "categories": ["cs.RO", "cs.AI"], "comment": "International Joint Conference on Neural Network 2025 - Accepted", "summary": "The development of autonomous robotic systems offers significant potential\nfor performing complex tasks with precision and consistency. Recent advances in\nArtificial Intelligence (AI) have enabled more capable intelligent automation\nsystems, addressing increasingly complex challenges. However, this progress\nraises questions about human roles in such systems. Human-Centered AI (HCAI)\naims to balance human control and automation, ensuring performance enhancement\nwhile maintaining creativity, mastery, and responsibility. For real-world\napplications, autonomous robots must balance task performance with reliability,\nsafety, and trustworthiness. Integrating HCAI principles enhances human-robot\ncollaboration and ensures responsible operation.\n  This paper presents a bibliometric analysis of intelligent autonomous robotic\nsystems, utilizing SciMAT and VOSViewer to examine data from the Scopus\ndatabase. The findings highlight academic trends, emerging topics, and AI's\nrole in self-adaptive robotic behaviour, with an emphasis on HCAI architecture.\nThese insights are then projected onto the IBM MAPE-K architecture, with the\ngoal of identifying how these research results map into actual robotic\nautonomous systems development efforts for real-world scenarios.", "AI": {"tldr": "A bibliometric analysis of intelligent autonomous robotic systems, emphasizing Human-Centered AI (HCAI) and its integration into real-world applications.", "motivation": "To explore the balance between human roles and automation in robotic systems, ensuring performance, reliability, and trustworthiness.", "method": "Bibliometric analysis using SciMAT and VOSViewer on Scopus data, mapping findings to IBM MAPE-K architecture.", "result": "Identified academic trends, emerging topics, and AI's role in self-adaptive robotic behavior, with a focus on HCAI.", "conclusion": "HCAI principles enhance human-robot collaboration and guide responsible autonomous system development for real-world use."}}
{"id": "2502.00090", "pdf": "https://arxiv.org/pdf/2502.00090", "abs": "https://arxiv.org/abs/2502.00090", "authors": ["Logan Born", "M. Willis Monroe", "Kathryn Kelley", "Anoop Sarkar"], "title": "Disambiguating Numeral Sequences to Decipher Ancient Accounting Corpora", "categories": ["cs.CL"], "comment": "Englund 1996 incorrectly reported the relative values of signs in the\n  decimal system. An earlier version of this paper used those values. This\n  update fixes those mistakes and retrains our models using the corrected\n  readings. Our analysis and discussion remain similar to the original, but the\n  performance of the baseline model is now stronger", "summary": "A numeration system encodes abstract numeric quantities as concrete strings\nof written characters. The numeration systems used by modern scripts tend to be\nprecise and unambiguous, but this was not so for the ancient and\npartially-deciphered proto-Elamite (PE) script, where written numerals can have\nup to four distinct readings depending on the system that is used to read them.\nWe consider the task of disambiguating between these readings in order to\ndetermine the values of the numeric quantities recorded in this corpus. We\nalgorithmically extract a list of possible readings for each PE numeral\nnotation, and contribute two disambiguation techniques based on structural\nproperties of the original documents and classifiers learned with the\nbootstrapping algorithm. We also contribute a test set for evaluating\ndisambiguation techniques, as well as a novel approach to cautious rule\nselection for bootstrapped classifiers. Our analysis confirms existing\nintuitions about this script and reveals previously-unknown correlations\nbetween tablet content and numeral magnitude. This work is crucial to\nunderstanding and deciphering PE, as the corpus is heavily accounting-focused\nand contains many more numeric tokens than tokens of text.", "AI": {"tldr": "The paper addresses the ambiguity in numeral readings of the proto-Elamite script by proposing algorithmic disambiguation techniques and a test set for evaluation.", "motivation": "The proto-Elamite script's numerals are ambiguous, hindering understanding of the corpus, which is accounting-heavy.", "method": "Algorithmic extraction of possible numeral readings, structural document analysis, and bootstrapped classifiers for disambiguation.", "result": "Confirmed existing intuitions and revealed new correlations between tablet content and numeral magnitude.", "conclusion": "The work aids in deciphering proto-Elamite by resolving numeral ambiguity, crucial for understanding its accounting-focused corpus."}}
{"id": "2504.19722", "pdf": "https://arxiv.org/pdf/2504.19722", "abs": "https://arxiv.org/abs/2504.19722", "authors": ["Rupert Polley", "Nikolai Polley", "Dominik Heid", "Marc Heinrich", "Sven Ochs", "J. Marius Z\u00f6llner"], "title": "The ATLAS of Traffic Lights: A Reliable Perception Framework for Autonomous Driving", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at IEEE Intelligent Vehicles Symposium (IV 2025). Dataset\n  link: https://url.fzi.de/ATLAS", "summary": "Traffic light perception is an essential component of the camera-based\nperception system for autonomous vehicles, enabling accurate detection and\ninterpretation of traffic lights to ensure safe navigation through complex\nurban environments. In this work, we propose a modularized perception framework\nthat integrates state-of-the-art detection models with a novel real-time\nassociation and decision framework, enabling seamless deployment into an\nautonomous driving stack. To address the limitations of existing public\ndatasets, we introduce the ATLAS dataset, which provides comprehensive\nannotations of traffic light states and pictograms across diverse environmental\nconditions and camera setups. This dataset is publicly available at\nhttps://url.fzi.de/ATLAS. We train and evaluate several state-of-the-art\ntraffic light detection architectures on ATLAS, demonstrating significant\nperformance improvements in both accuracy and robustness. Finally, we evaluate\nthe framework in real-world scenarios by deploying it in an autonomous vehicle\nto make decisions at traffic light-controlled intersections, highlighting its\nreliability and effectiveness for real-time operation.", "AI": {"tldr": "A modularized traffic light perception framework for autonomous vehicles is proposed, leveraging a new dataset (ATLAS) and demonstrating improved accuracy and robustness in real-world testing.", "motivation": "To enhance traffic light perception for autonomous vehicles, addressing dataset limitations and ensuring reliable real-time operation.", "method": "Integration of state-of-the-art detection models with a real-time association and decision framework, trained and evaluated on the ATLAS dataset.", "result": "Significant performance improvements in accuracy and robustness, validated in real-world autonomous driving scenarios.", "conclusion": "The proposed framework is reliable and effective for real-time traffic light perception in autonomous vehicles."}}
{"id": "2504.19955", "pdf": "https://arxiv.org/pdf/2504.19955", "abs": "https://arxiv.org/abs/2504.19955", "authors": ["Malhar A. Managoli", "Vinod M. Prabhakaran", "Suhas Diggavi"], "title": "Robust Federated Personalised Mean Estimation for the Gaussian Mixture Model", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "Federated learning with heterogeneous data and personalization has received\nsignificant recent attention. Separately, robustness to corrupted data in the\ncontext of federated learning has also been studied. In this paper we explore\ncombining personalization for heterogeneous data with robustness, where a\nconstant fraction of the clients are corrupted. Motivated by this broad\nproblem, we formulate a simple instantiation which captures some of its\ndifficulty. We focus on the specific problem of personalized mean estimation\nwhere the data is drawn from a Gaussian mixture model. We give an algorithm\nwhose error depends almost linearly on the ratio of corrupted to uncorrupted\nsamples, and show a lower bound with the same behavior, albeit with a gap of a\nconstant factor.", "AI": {"tldr": "The paper explores combining personalization and robustness in federated learning with corrupted clients, focusing on personalized mean estimation under a Gaussian mixture model. It provides an algorithm with near-linear error dependence on corruption ratio and a matching lower bound.", "motivation": "To address the challenge of combining personalization for heterogeneous data with robustness against corrupted clients in federated learning.", "method": "Formulates a simplified problem of personalized mean estimation using a Gaussian mixture model and develops an algorithm for this scenario.", "result": "The algorithm's error scales almost linearly with the ratio of corrupted to uncorrupted samples, with a lower bound showing similar behavior.", "conclusion": "The study demonstrates feasibility in combining personalization and robustness, with theoretical guarantees on error behavior."}}
{"id": "2504.19854", "pdf": "https://arxiv.org/pdf/2504.19854", "abs": "https://arxiv.org/abs/2504.19854", "authors": ["Chia-Yu Hung", "Qi Sun", "Pengfei Hong", "Amir Zadeh", "Chuan Li", "U-Xuan Tan", "Navonil Majumder", "Soujanya Poria"], "title": "NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Existing Visual-Language-Action (VLA) models have shown promising performance\nin zero-shot scenarios, demonstrating impressive task execution and reasoning\ncapabilities. However, a significant challenge arises from the limitations of\nvisual encoding, which can result in failures during tasks such as object\ngrasping. Moreover, these models typically suffer from high computational\noverhead due to their large sizes, often exceeding 7B parameters. While these\nmodels excel in reasoning and task planning, the substantial computational\noverhead they incur makes them impractical for real-time robotic environments,\nwhere speed and efficiency are paramount. To address the limitations of\nexisting VLA models, we propose NORA, a 3B-parameter model designed to reduce\ncomputational overhead while maintaining strong task performance. NORA adopts\nthe Qwen-2.5-VL-3B multimodal model as its backbone, leveraging its superior\nvisual-semantic understanding to enhance visual reasoning and action grounding.\nAdditionally, our \\model{} is trained on 970k real-world robot demonstrations\nand equipped with the FAST+ tokenizer for efficient action sequence generation.\nExperimental results demonstrate that NORA outperforms existing large-scale VLA\nmodels, achieving better task performance with significantly reduced\ncomputational overhead, making it a more practical solution for real-time\nrobotic autonomy.", "AI": {"tldr": "NORA, a 3B-parameter VLA model, reduces computational overhead while maintaining strong task performance, making it practical for real-time robotics.", "motivation": "Existing VLA models face challenges like visual encoding limitations and high computational overhead, hindering real-time robotic applications.", "method": "NORA uses the Qwen-2.5-VL-3B backbone, is trained on 970k robot demos, and employs the FAST+ tokenizer for efficient action generation.", "result": "NORA outperforms larger VLA models in task performance with reduced computational overhead.", "conclusion": "NORA is a practical solution for real-time robotic autonomy, balancing performance and efficiency."}}
{"id": "2502.01220", "pdf": "https://arxiv.org/pdf/2502.01220", "abs": "https://arxiv.org/abs/2502.01220", "authors": ["Hichem Ammar Khodja", "Fr\u00e9d\u00e9ric B\u00e9chet", "Quentin Brabant", "Alexis Nasr", "Gw\u00e9nol\u00e9 Lecorv\u00e9"], "title": "Factual Knowledge in Language Models: Robustness and Anomalies under Simple Temporal Context Variations", "categories": ["cs.CL", "cs.LG"], "comment": "preprint v4", "summary": "This paper explores the robustness of language models (LMs) to variations in\nthe temporal context within factual knowledge. It examines whether LMs can\ncorrectly associate a temporal context with a past fact valid over a defined\nperiod, by asking them to differentiate correct from incorrect contexts. The\naccuracy of LMs is analyzed along two dimensions: the distance of the incorrect\ncontext from the validity period and the granularity of the context. To this\nend, a dataset called TimeStress is introduced, enabling the evaluation of 18\ndiverse LMs. Results reveal that the best LM achieves perfect accuracy for only\n6% of the studied facts, with critical errors that humans would not make. This\nwork highlights the limitations of current LMs in temporal representation. We\nprovide all data and code for further research.", "AI": {"tldr": "The paper investigates how well language models handle temporal context in factual knowledge, revealing significant limitations.", "motivation": "To assess the robustness of LMs in associating temporal contexts with facts and identify their shortcomings.", "method": "Evaluated 18 LMs using the TimeStress dataset, measuring accuracy based on context distance and granularity.", "result": "Best LM achieved only 6% perfect accuracy, with errors humans wouldn't make.", "conclusion": "Current LMs struggle with temporal representation; dataset and code are shared for future research."}}
{"id": "2504.19724", "pdf": "https://arxiv.org/pdf/2504.19724", "abs": "https://arxiv.org/abs/2504.19724", "authors": ["Haofan Wang", "Yujia Xu", "Yimeng Li", "Junchen Li", "Chaowei Zhang", "Jing Wang", "Kejia Yang", "Zhibo Chen"], "title": "RepText: Rendering Visual Text via Replicating", "categories": ["cs.CV"], "comment": "Technical Report. https://reptext.github.io/", "summary": "Although contemporary text-to-image generation models have achieved\nremarkable breakthroughs in producing visually appealing images, their capacity\nto generate precise and flexible typographic elements, especially non-Latin\nalphabets, remains constrained. To address these limitations, we start from an\nnaive assumption that text understanding is only a sufficient condition for\ntext rendering, but not a necessary condition. Based on this, we present\nRepText, which aims to empower pre-trained monolingual text-to-image generation\nmodels with the ability to accurately render, or more precisely, replicate,\nmultilingual visual text in user-specified fonts, without the need to really\nunderstand them. Specifically, we adopt the setting from ControlNet and\nadditionally integrate language agnostic glyph and position of rendered text to\nenable generating harmonized visual text, allowing users to customize text\ncontent, font and position on their needs. To improve accuracy, a text\nperceptual loss is employed along with the diffusion loss. Furthermore, to\nstabilize rendering process, at the inference phase, we directly initialize\nwith noisy glyph latent instead of random initialization, and adopt region\nmasks to restrict the feature injection to only the text region to avoid\ndistortion of the background. We conducted extensive experiments to verify the\neffectiveness of our RepText relative to existing works, our approach\noutperforms existing open-source methods and achieves comparable results to\nnative multi-language closed-source models. To be more fair, we also\nexhaustively discuss its limitations in the end.", "AI": {"tldr": "RepText enhances text-to-image models to accurately render multilingual text without understanding it, using glyph and position integration, perceptual loss, and region masks.", "motivation": "Existing models struggle with precise typographic elements, especially non-Latin alphabets. RepText addresses this by focusing on rendering rather than understanding text.", "method": "RepText integrates glyph and position data, uses text perceptual loss, initializes with noisy glyph latent, and employs region masks to stabilize rendering.", "result": "RepText outperforms open-source methods and matches closed-source models in multilingual text rendering.", "conclusion": "RepText effectively improves multilingual text rendering but has limitations, as discussed."}}
{"id": "2504.19979", "pdf": "https://arxiv.org/pdf/2504.19979", "abs": "https://arxiv.org/abs/2504.19979", "authors": ["Liyuan Wang", "Jiachen Chen", "Kathryn L. Lunetta", "Danyang Huang", "Huimin Cheng", "Debarghya Mukherjee"], "title": "Transfer Learning Under High-Dimensional Network Convolutional Regression Model", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "Transfer learning enhances model performance by utilizing knowledge from\nrelated domains, particularly when labeled data is scarce. While existing\nresearch addresses transfer learning under various distribution shifts in\nindependent settings, handling dependencies in networked data remains\nchallenging. To address this challenge, we propose a high-dimensional transfer\nlearning framework based on network convolutional regression (NCR), inspired by\nthe success of graph convolutional networks (GCNs). The NCR model incorporates\nrandom network structure by allowing each node's response to depend on its\nfeatures and the aggregated features of its neighbors, capturing local\ndependencies effectively. Our methodology includes a two-step transfer learning\nalgorithm that addresses domain shift between source and target networks, along\nwith a source detection mechanism to identify informative domains.\nTheoretically, we analyze the lasso estimator in the context of a random graph\nbased on the Erdos-Renyi model assumption, demonstrating that transfer learning\nimproves convergence rates when informative sources are present. Empirical\nevaluations, including simulations and a real-world application using Sina\nWeibo data, demonstrate substantial improvements in prediction accuracy,\nparticularly when labeled data in the target domain is limited.", "AI": {"tldr": "A transfer learning framework (NCR) for networked data improves prediction accuracy by leveraging dependencies and domain shifts, validated theoretically and empirically.", "motivation": "Addressing the challenge of transfer learning in networked data with dependencies, where existing methods fall short.", "method": "Proposes a network convolutional regression (NCR) model, incorporating local dependencies and a two-step transfer learning algorithm with source detection.", "result": "Theoretical analysis shows improved convergence rates; empirical tests on simulations and Sina Weibo data confirm higher accuracy, especially with limited labeled data.", "conclusion": "The NCR framework effectively handles networked data dependencies and domain shifts, enhancing transfer learning performance."}}
{"id": "2504.19863", "pdf": "https://arxiv.org/pdf/2504.19863", "abs": "https://arxiv.org/abs/2504.19863", "authors": ["Daniel Kienzle", "Robin Sch\u00f6n", "Rainer Lienhart", "Shin'Ichi Satoh"], "title": "Towards Ball Spin and Trajectory Analysis in Table Tennis Broadcast Videos via Physically Grounded Synthetic-to-Real Transfer", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "To be published in 2025 IEEE/CVF International Conference on Computer\n  Vision and Pattern Recognition Workshops (CVPRW)", "summary": "Analyzing a player's technique in table tennis requires knowledge of the\nball's 3D trajectory and spin. While, the spin is not directly observable in\nstandard broadcasting videos, we show that it can be inferred from the ball's\ntrajectory in the video. We present a novel method to infer the initial spin\nand 3D trajectory from the corresponding 2D trajectory in a video. Without\nground truth labels for broadcast videos, we train a neural network solely on\nsynthetic data. Due to the choice of our input data representation, physically\ncorrect synthetic training data, and using targeted augmentations, the network\nnaturally generalizes to real data. Notably, these simple techniques are\nsufficient to achieve generalization. No real data at all is required for\ntraining. To the best of our knowledge, we are the first to present a method\nfor spin and trajectory prediction in simple monocular broadcast videos,\nachieving an accuracy of 92.0% in spin classification and a 2D reprojection\nerror of 0.19% of the image diagonal.", "AI": {"tldr": "A method to infer table tennis ball spin and 3D trajectory from 2D broadcast videos using synthetic data, achieving high accuracy without real training data.", "motivation": "Spin is crucial for analyzing player technique but isn't directly observable in videos. The goal is to predict spin and trajectory from 2D video frames.", "method": "Train a neural network on synthetic data with physically correct representations and targeted augmentations, eliminating the need for real-world training data.", "result": "Achieves 92.0% accuracy in spin classification and a 2D reprojection error of 0.19% of the image diagonal.", "conclusion": "The method successfully generalizes to real data using only synthetic training, pioneering spin and trajectory prediction in monocular videos."}}
{"id": "2502.12257", "pdf": "https://arxiv.org/pdf/2502.12257", "abs": "https://arxiv.org/abs/2502.12257", "authors": ["Bryan L. M. de Oliveira", "Luana G. B. Martins", "Bruno Brand\u00e3o", "Luckeciano C. Melo"], "title": "InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models excel at following explicit instructions, but they\noften struggle with ambiguous or incomplete user requests, defaulting to\nverbose, generic responses instead of seeking clarification. We introduce\nInfoQuest, a multi-turn chat benchmark designed to evaluate how dialogue agents\nhandle hidden context in open-ended user requests. This benchmark presents\nintentionally ambiguous scenarios that require models to engage in\ninformation-seeking dialogue by asking clarifying questions before providing\nappropriate responses. Our evaluation of both open and closed models reveals\nthat, while proprietary models generally perform better, all current assistants\nstruggle to gather critical information effectively. They often require\nmultiple turns to infer user intent and frequently default to generic responses\nwithout proper clarification. We provide a systematic methodology for\ngenerating diverse scenarios and evaluating models' information-seeking\ncapabilities, which can be leveraged to automatically generate data for\nself-improvement. We also offer insights into the current limitations of\nlanguage models in handling ambiguous requests through multi-turn interactions.", "AI": {"tldr": "InfoQuest is a benchmark for evaluating dialogue agents' ability to handle ambiguous requests by seeking clarification, revealing current models' struggles with hidden context.", "motivation": "To address the challenge of language models defaulting to generic responses for ambiguous or incomplete requests instead of seeking clarification.", "method": "Introduce InfoQuest, a multi-turn chat benchmark with ambiguous scenarios, and evaluate open and closed models on their information-seeking dialogue capabilities.", "result": "Proprietary models perform better but all struggle with effective information gathering, often requiring multiple turns or defaulting to generic responses.", "conclusion": "The benchmark provides a methodology for evaluating and improving models' handling of ambiguous requests, highlighting current limitations in multi-turn interactions."}}
{"id": "2504.19735", "pdf": "https://arxiv.org/pdf/2504.19735", "abs": "https://arxiv.org/abs/2504.19735", "authors": ["Rustam Tagiew", "Prasannavenkatesh Balaji"], "title": "Measuring Train Driver Performance as Key to Approval of Driverless Trains", "categories": ["cs.CV"], "comment": "6 pages, 3 figures, abstract accepted by IAVVC 2025, full paper to be\n  submitted to IAVVC 2025", "summary": "Points 2.1.4(b), 2.4.2(b) and 2.4.3(b) in Annex I of Implementing Regulation\n(EU) No. 402/2013 allow a simplified approach for the safety approval of\ncomputer vision systems for driverless trains, if they have 'similar' functions\nand interfaces as the replaced human driver. The human driver is not replaced\none-to-one by a technical system - only a limited set of cognitive functions\nare replaced. However, performance in the most challenging function, obstacle\ndetection, is difficult to quantify due to the deficiency of published\nmeasurement results. This article summarizes the data published so far. This\narticle also goes a long way to remedy this situation by providing a new public\nand anonymized dataset of 711 train driver performance measurements from\ncontrolled experiments. The measurements are made for different speeds,\nobstacle sizes, train protection systems and obstacle color contrasts\nrespectively. The measured values are reaction time and distance to the\nobstacle. The goal of this paper is an unbiased and exhaustive description of\nthe presented dataset for research, standardization and regulation. Further\nproject related information including the dataset and source code is available\nat https://atosense-02371c.usercontent.opencode.de/", "AI": {"tldr": "The paper addresses the lack of published data on obstacle detection performance for driverless trains, providing a new dataset of 711 measurements to aid research and regulation.", "motivation": "The motivation is to fill the gap in quantifying obstacle detection performance for computer vision systems replacing human drivers in trains, as current data is insufficient.", "method": "The method involves controlled experiments measuring reaction time and distance to obstacles under varying conditions like speed, obstacle size, and color contrast.", "result": "The result is a comprehensive, public dataset of 711 performance measurements, aiding standardization and regulation.", "conclusion": "The paper concludes by offering an unbiased dataset to improve research and regulatory frameworks for driverless train safety."}}
{"id": "2504.19981", "pdf": "https://arxiv.org/pdf/2504.19981", "abs": "https://arxiv.org/abs/2504.19981", "authors": ["Adam Younsi", "Abdalgader Abubaker", "Mohamed El Amine Seddik", "Hakim Hacid", "Salem Lahlou"], "title": "Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided GFlowNets", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Achieving both accuracy and diverse reasoning remains challenging for Large\nLanguage Models (LLMs) in complex domains like mathematics. A key bottleneck is\nevaluating intermediate reasoning steps to guide generation without costly\nhuman annotations. To address this, we first introduce a novel Process Reward\nModel (PRM) trained automatically using Monte Carlo Tree Search coupled with a\nsimilarity-based data augmentation technique, effectively capturing step-level\nreasoning quality. Leveraging this PRM, we then adapt Generative Flow Networks\n(GFlowNets) to operate at the reasoning step level. Unlike traditional\nreinforcement learning focused on maximizing a single reward, GFlowNets\nnaturally sample diverse, high-quality solutions proportional to their rewards,\nas measured by our PRM. Empirical evaluation shows strong improvements in both\naccuracy and solution diversity on challenging mathematical benchmarks (e.g.,\n+2.59% absolute accuracy on MATH Level 5 for Llama3.2-3B), with effective\ngeneralization to unseen datasets (+9.4% absolute on SAT MATH). Our work\ndemonstrates the potential of PRM-guided, step-level GFlowNets for developing\nmore robust and versatile mathematical reasoning in LLMs.", "AI": {"tldr": "The paper introduces a Process Reward Model (PRM) and Generative Flow Networks (GFlowNets) to improve accuracy and diversity in LLM reasoning for mathematics, showing significant gains on benchmarks.", "motivation": "Addressing the challenge of evaluating intermediate reasoning steps in LLMs without costly human annotations to enhance mathematical reasoning.", "method": "Develops a PRM using Monte Carlo Tree Search and data augmentation, then adapts GFlowNets to sample diverse, high-quality solutions based on PRM rewards.", "result": "Improves accuracy (+2.59% on MATH Level 5) and diversity, with generalization (+9.4% on SAT MATH).", "conclusion": "PRM-guided GFlowNets enhance LLM robustness and versatility in mathematical reasoning."}}
{"id": "2504.19900", "pdf": "https://arxiv.org/pdf/2504.19900", "abs": "https://arxiv.org/abs/2504.19900", "authors": ["Han Chen", "Anne L. Martel"], "title": "Breast Cancer Detection from Multi-View Screening Mammograms with Visual Prompt Tuning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate detection of breast cancer from high-resolution mammograms is\ncrucial for early diagnosis and effective treatment planning. Previous studies\nhave shown the potential of using single-view mammograms for breast cancer\ndetection. However, incorporating multi-view data can provide more\ncomprehensive insights. Multi-view classification, especially in medical\nimaging, presents unique challenges, particularly when dealing with\nlarge-scale, high-resolution data. In this work, we propose a novel Multi-view\nVisual Prompt Tuning Network (MVPT-NET) for analyzing multiple screening\nmammograms. We first pretrain a robust single-view classification model on\nhigh-resolution mammograms and then innovatively adapt multi-view feature\nlearning into a task-specific prompt tuning process. This technique selectively\ntunes a minimal set of trainable parameters (7\\%) while retaining the\nrobustness of the pre-trained single-view model, enabling efficient integration\nof multi-view data without the need for aggressive downsampling. Our approach\noffers an efficient alternative to traditional feature fusion methods,\nproviding a more robust, scalable, and efficient solution for high-resolution\nmammogram analysis. Experimental results on a large multi-institution dataset\ndemonstrate that our method outperforms conventional approaches while\nmaintaining detection efficiency, achieving an AUROC of 0.852 for\ndistinguishing between Benign, DCIS, and Invasive classes. This work highlights\nthe potential of MVPT-NET for medical imaging tasks and provides a scalable\nsolution for integrating multi-view data in breast cancer detection.", "AI": {"tldr": "MVPT-NET, a Multi-view Visual Prompt Tuning Network, improves breast cancer detection by efficiently integrating multi-view mammogram data with minimal parameter tuning, outperforming traditional methods.", "motivation": "Breast cancer detection from high-resolution mammograms benefits from multi-view data, but existing methods face challenges in scalability and efficiency.", "method": "Pretrains a single-view model, then adapts multi-view learning via prompt tuning, tuning only 7% of parameters to retain robustness.", "result": "Achieves AUROC of 0.852 for classifying Benign, DCIS, and Invasive classes, outperforming conventional methods.", "conclusion": "MVPT-NET offers a scalable, efficient solution for multi-view mammogram analysis, advancing breast cancer detection."}}
{"id": "2502.13019", "pdf": "https://arxiv.org/pdf/2502.13019", "abs": "https://arxiv.org/abs/2502.13019", "authors": ["Sha Li", "Naren Ramakrishnan"], "title": "Oreo: A Plug-in Context Reconstructor to Enhance Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": "16 pages", "summary": "Retrieval-Augmented Generation (RAG) aims to augment the capabilities of\nLarge Language Models (LLMs) by retrieving and incorporate external documents\nor chunks prior to generation. However, even improved retriever relevance can\nbrings erroneous or contextually distracting information, undermining the\neffectiveness of RAG in downstream tasks. We introduce a compact, efficient,\nand pluggable module designed to refine retrieved chunks before using them for\ngeneration. The module aims to extract and reorganize the most relevant and\nsupportive information into a concise, query-specific format. Through a\nthree-stage training paradigm - comprising supervised fine - tuning,\ncontrastive multi-task learning, and reinforcement learning-based alignment -\nit prioritizes critical knowledge and aligns it with the generator's\npreferences. This approach enables LLMs to produce outputs that are more\naccurate, reliable, and contextually appropriate.", "AI": {"tldr": "A compact module refines retrieved chunks in RAG to improve LLM outputs by prioritizing relevant information through a three-stage training paradigm.", "motivation": "Retrieval-Augmented Generation (RAG) can suffer from erroneous or distracting retrieved information, reducing its effectiveness.", "method": "A pluggable module refines retrieved chunks via supervised fine-tuning, contrastive multi-task learning, and reinforcement learning-based alignment.", "result": "The module enhances LLM outputs by aligning retrieved knowledge with the generator's preferences, improving accuracy and contextual appropriateness.", "conclusion": "The proposed module effectively refines retrieved information, making RAG more reliable and effective for downstream tasks."}}
{"id": "2504.19737", "pdf": "https://arxiv.org/pdf/2504.19737", "abs": "https://arxiv.org/abs/2504.19737", "authors": ["Abhishek Kuriyal", "Elliot Vincent", "Mathieu Aubry", "Loic Landrieu"], "title": "CoDEx: Combining Domain Expertise for Spatial Generalization in Satellite Image Analysis", "categories": ["cs.CV"], "comment": "CVPR 2025 EarthVision Workshop", "summary": "Global variations in terrain appearance raise a major challenge for satellite\nimage analysis, leading to poor model performance when training on locations\nthat differ from those encountered at test time. This remains true even with\nrecent large global datasets. To address this challenge, we propose a novel\ndomain-generalization framework for satellite images. Instead of trying to\nlearn a single generalizable model, we train one expert model per training\ndomain, while learning experts' similarity and encouraging similar experts to\nbe consistent. A model selection module then identifies the most suitable\nexperts for a given test sample and aggregates their predictions. Experiments\non four datasets (DynamicEarthNet, MUDS, OSCD, and FMoW) demonstrate consistent\ngains over existing domain generalization and adaptation methods. Our code is\npublicly available at https://github.com/Abhishek19009/CoDEx.", "AI": {"tldr": "A domain-generalization framework for satellite images uses multiple expert models and a selection module to improve performance across diverse terrains.", "motivation": "Global terrain variations in satellite images cause poor model generalization, even with large datasets.", "method": "Train one expert model per training domain, learn expert similarity, ensure consistency among similar experts, and use a model selection module to aggregate predictions.", "result": "Outperforms existing domain generalization and adaptation methods on four datasets (DynamicEarthNet, MUDS, OSCD, FMoW).", "conclusion": "The proposed framework effectively addresses terrain variation challenges in satellite image analysis."}}
{"id": "2504.19983", "pdf": "https://arxiv.org/pdf/2504.19983", "abs": "https://arxiv.org/abs/2504.19983", "authors": ["Yunwei Ren", "Eshaan Nichani", "Denny Wu", "Jason D. Lee"], "title": "Emergence and scaling laws in SGD learning of shallow neural networks", "categories": ["cs.LG", "stat.ML"], "comment": "100 pages", "summary": "We study the complexity of online stochastic gradient descent (SGD) for\nlearning a two-layer neural network with $P$ neurons on isotropic Gaussian\ndata: $f_*(\\boldsymbol{x}) = \\sum_{p=1}^P a_p\\cdot\n\\sigma(\\langle\\boldsymbol{x},\\boldsymbol{v}_p^*\\rangle)$, $\\boldsymbol{x} \\sim\n\\mathcal{N}(0,\\boldsymbol{I}_d)$, where the activation\n$\\sigma:\\mathbb{R}\\to\\mathbb{R}$ is an even function with information exponent\n$k_*>2$ (defined as the lowest degree in the Hermite expansion),\n$\\{\\boldsymbol{v}^*_p\\}_{p\\in[P]}\\subset \\mathbb{R}^d$ are orthonormal signal\ndirections, and the non-negative second-layer coefficients satisfy $\\sum_{p}\na_p^2=1$. We focus on the challenging ``extensive-width'' regime $P\\gg 1$ and\npermit diverging condition number in the second-layer, covering as a special\ncase the power-law scaling $a_p\\asymp p^{-\\beta}$ where\n$\\beta\\in\\mathbb{R}_{\\ge 0}$. We provide a precise analysis of SGD dynamics for\nthe training of a student two-layer network to minimize the mean squared error\n(MSE) objective, and explicitly identify sharp transition times to recover each\nsignal direction. In the power-law setting, we characterize scaling law\nexponents for the MSE loss with respect to the number of training samples and\nSGD steps, as well as the number of parameters in the student neural network.\nOur analysis entails that while the learning of individual teacher neurons\nexhibits abrupt transitions, the juxtaposition of $P\\gg 1$ emergent learning\ncurves at different timescales leads to a smooth scaling law in the cumulative\nobjective.", "AI": {"tldr": "The paper analyzes the complexity of online SGD for training a two-layer neural network with isotropic Gaussian data, focusing on the extensive-width regime and power-law scaling. It identifies sharp transition times for signal recovery and characterizes scaling laws for MSE loss.", "motivation": "Understanding the dynamics of SGD in learning two-layer neural networks, especially in the extensive-width regime with diverging condition numbers, to provide insights into signal recovery and scaling laws.", "method": "The study uses online SGD to train a student two-layer network, analyzing its dynamics for MSE minimization. It examines the power-law scaling of second-layer coefficients and identifies transition times for signal recovery.", "result": "The paper identifies sharp transition times for recovering signal directions and characterizes scaling law exponents for MSE loss with respect to training samples, SGD steps, and network parameters.", "conclusion": "While individual teacher neurons show abrupt transitions, the combination of many emergent learning curves results in a smooth cumulative scaling law."}}
{"id": "2504.19918", "pdf": "https://arxiv.org/pdf/2504.19918", "abs": "https://arxiv.org/abs/2504.19918", "authors": ["Hugo Georgenthum", "Cristian Cosentino", "Fabrizio Marozzo", "Pietro Li\u00f2"], "title": "Enhancing Surgical Documentation through Multimodal Visual-Temporal Transformers and Generative AI", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The automatic summarization of surgical videos is essential for enhancing\nprocedural documentation, supporting surgical training, and facilitating\npost-operative analysis. This paper presents a novel method at the intersection\nof artificial intelligence and medicine, aiming to develop machine learning\nmodels with direct real-world applications in surgical contexts. We propose a\nmulti-modal framework that leverages recent advancements in computer vision and\nlarge language models to generate comprehensive video summaries. % The approach\nis structured in three key stages. First, surgical videos are divided into\nclips, and visual features are extracted at the frame level using visual\ntransformers. This step focuses on detecting tools, tissues, organs, and\nsurgical actions. Second, the extracted features are transformed into\nframe-level captions via large language models. These are then combined with\ntemporal features, captured using a ViViT-based encoder, to produce clip-level\nsummaries that reflect the broader context of each video segment. Finally, the\nclip-level descriptions are aggregated into a full surgical report using a\ndedicated LLM tailored for the summarization task. % We evaluate our method on\nthe CholecT50 dataset, using instrument and action annotations from 50\nlaparoscopic videos. The results show strong performance, achieving 96\\%\nprecision in tool detection and a BERT score of 0.74 for temporal context\nsummarization. This work contributes to the advancement of AI-assisted tools\nfor surgical reporting, offering a step toward more intelligent and reliable\nclinical documentation.", "AI": {"tldr": "A novel multi-modal framework for surgical video summarization using AI, achieving high precision in tool detection and context summarization.", "motivation": "To enhance procedural documentation, surgical training, and post-operative analysis through automated video summarization.", "method": "A three-stage approach: frame-level feature extraction, clip-level summarization with temporal context, and full-report generation using tailored LLMs.", "result": "96% precision in tool detection and a BERT score of 0.74 for temporal context summarization on the CholecT50 dataset.", "conclusion": "Advances AI-assisted surgical reporting, improving clinical documentation reliability."}}
{"id": "2502.13881", "pdf": "https://arxiv.org/pdf/2502.13881", "abs": "https://arxiv.org/abs/2502.13881", "authors": ["Jie Zou", "Mohammad Aliannejadi", "Evangelos Kanoulas", "Shuxi Han", "Heli Ma", "Zheng Wang", "Yang Yang", "Heng Tao Shen"], "title": "PSCon: Product Search Through Conversations", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "11 pages. Accepted by SIGIR 2025", "summary": "Conversational Product Search ( CPS ) systems interact with users via natural\nlanguage to offer personalized and context-aware product lists. However, most\nexisting research on CPS is limited to simulated conversations, due to the lack\nof a real CPS dataset driven by human-like language. Moreover, existing\nconversational datasets for e-commerce are constructed for a particular market\nor a particular language and thus can not support cross-market and\nmulti-lingual usage. In this paper, we propose a CPS data collection protocol\nand create a new CPS dataset, called PSCon, which assists product search\nthrough conversations with human-like language. The dataset is collected by a\ncoached human-human data collection protocol and is available for dual markets\nand two languages. By formulating the task of CPS, the dataset allows for\ncomprehensive and in-depth research on six subtasks: user intent detection,\nkeyword extraction, system action prediction, question selection, item ranking,\nand response generation. Moreover, we present a concise analysis of the dataset\nand propose a benchmark model on the proposed CPS dataset. Our proposed dataset\nand model will be helpful for facilitating future research on CPS.", "AI": {"tldr": "The paper introduces PSCon, a new dataset for Conversational Product Search (CPS) using human-like language, addressing limitations of existing datasets by supporting cross-market and multi-lingual usage.", "motivation": "Existing CPS research relies on simulated conversations and lacks real datasets with human-like language, limiting cross-market and multi-lingual applicability.", "method": "A coached human-human data collection protocol is used to create the PSCon dataset, enabling research on six CPS subtasks.", "result": "PSCon supports dual markets and two languages, and a benchmark model is proposed for the dataset.", "conclusion": "PSCon and the benchmark model advance CPS research by providing a realistic, versatile dataset."}}
{"id": "2504.19739", "pdf": "https://arxiv.org/pdf/2504.19739", "abs": "https://arxiv.org/abs/2504.19739", "authors": ["Muzammil Behzad", "Guoying Zhao"], "title": "Contrastive Language-Image Learning with Augmented Textual Prompts for 3D/4D FER Using Vision-Language Model", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce AffectVLM, a vision-language model designed to\nintegrate multiviews for a semantically rich and visually comprehensive\nunderstanding of facial emotions from 3D/4D data. To effectively capture visual\nfeatures, we propose a joint representation learning framework paired with a\nnovel gradient-friendly loss function that accelerates model convergence\ntowards optimal feature representation. Additionally, we introduce augmented\ntextual prompts to enhance the model's linguistic capabilities and employ mixed\nview augmentation to expand the visual dataset. We also develop a Streamlit app\nfor a real-time interactive inference and enable the model for distributed\nlearning. Extensive experiments validate the superior performance of AffectVLM\nacross multiple benchmarks.", "AI": {"tldr": "AffectVLM is a vision-language model for facial emotion understanding from 3D/4D data, using joint representation learning and a novel loss function for faster convergence. It includes augmented textual prompts, mixed view augmentation, and a Streamlit app for real-time interaction.", "motivation": "To achieve a semantically rich and visually comprehensive understanding of facial emotions by integrating multiviews from 3D/4D data.", "method": "Joint representation learning with a gradient-friendly loss function, augmented textual prompts, mixed view augmentation, and distributed learning.", "result": "Superior performance across multiple benchmarks.", "conclusion": "AffectVLM effectively integrates multiviews and enhances linguistic and visual capabilities for facial emotion analysis."}}
{"id": "2504.20019", "pdf": "https://arxiv.org/pdf/2504.20019", "abs": "https://arxiv.org/abs/2504.20019", "authors": ["Abdelhakim Amer", "David Felsager", "Yury Brodskiy", "Andriy Sarabakha"], "title": "Modelling of Underwater Vehicles using Physics-Informed Neural Networks with Control", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "This paper has been accepted for presentation at the International\n  Joint Conference on Neural Networks (IJCNN) 2025. The final version consists\n  of 8 pages", "summary": "Physics-informed neural networks (PINNs) integrate physical laws with\ndata-driven models to improve generalization and sample efficiency. This work\nintroduces an open-source implementation of the Physics-Informed Neural Network\nwith Control (PINC) framework, designed to model the dynamics of an underwater\nvehicle. Using initial states, control actions, and time inputs, PINC extends\nPINNs to enable physically consistent transitions beyond the training domain.\nVarious PINC configurations are tested, including differing loss functions,\ngradient-weighting schemes, and hyperparameters. Validation on a simulated\nunderwater vehicle demonstrates more accurate long-horizon predictions compared\nto a non-physics-informed baseline", "AI": {"tldr": "An open-source implementation of Physics-Informed Neural Network with Control (PINC) improves underwater vehicle dynamics modeling by integrating physical laws and control actions.", "motivation": "To enhance generalization and sample efficiency in modeling underwater vehicle dynamics by combining physics and data-driven approaches.", "method": "PINC extends PINNs with control inputs, testing various configurations like loss functions and hyperparameters.", "result": "PINC achieves more accurate long-horizon predictions than non-physics-informed baselines in simulations.", "conclusion": "PINC effectively integrates physics and control for improved underwater vehicle dynamics modeling."}}
{"id": "2504.19944", "pdf": "https://arxiv.org/pdf/2504.19944", "abs": "https://arxiv.org/abs/2504.19944", "authors": ["Markus Bl\u00e4ser", "Julian D\u00f6rfler", "Maciej Li\u015bkiewicz", "Benito van der Zander"], "title": "Probabilistic and Causal Satisfiability: Constraining the Model", "categories": ["cs.CC", "cs.AI", "cs.LO"], "comment": "accepted at ICALP 25", "summary": "We study the complexity of satisfiability problems in probabilistic and\ncausal reasoning. Given random variables $X_1, X_2,\\ldots$ over finite domains,\nthe basic terms are probabilities of propositional formulas over atomic events\n$X_i = x_i$, such as $P(X_1 = x_1)$ or $P(X_1 = x_1 \\vee X_2 = x_2)$. The basic\nterms can be combined using addition (yielding linear terms) or multiplication\n(polynomial terms). The probabilistic satisfiability problem asks whether a\njoint probability distribution satisfies a Boolean combination of\n(in)equalities over such terms. Fagin et al. (1990) showed that for basic and\nlinear terms, this problem is NP-complete, making it no harder than Boolean\nsatisfiability, while Moss\\'e et al. (2022) proved that for polynomial terms,\nit is complete for the existential theory of the reals.\n  Pearl's Causal Hierarchy (PCH) extends the probabilistic setting with\ninterventional and counterfactual reasoning, enriching the expressiveness of\nlanguages. However, Moss\\'e et al. (2022) found that satisfiability complexity\nremains unchanged. Van der Zander et al. (2023) showed that introducing a\nmarginalization operator to languages induces a significant increase in\ncomplexity.\n  We extend this line of work by adding two new dimensions to the problem by\nconstraining the models. First, we fix the graph structure of the underlying\nstructural causal model, motivated by settings like Pearl's do-calculus, and\ngive a nearly complete landscape across different arithmetics and PCH levels.\nSecond, we study small models. While earlier work showed that satisfiable\ninstances admit polynomial-size models, this is no longer guaranteed with\ncompact marginalization. We characterize the complexities of satisfiability\nunder small-model constraints across different settings.", "AI": {"tldr": "The paper analyzes the complexity of probabilistic and causal satisfiability problems, extending prior work by introducing constraints on model structure and size.", "motivation": "To understand how fixing the graph structure of causal models and limiting model size affect the complexity of satisfiability problems in probabilistic and causal reasoning.", "method": "Extends prior work by constraining models: (1) fixing the graph structure of structural causal models, (2) studying small models. Analyzes complexities across different arithmetics and Pearl's Causal Hierarchy levels.", "result": "Provides a nearly complete complexity landscape for fixed graph structures and characterizes complexities under small-model constraints, showing changes from prior guarantees.", "conclusion": "Constraining model structure and size significantly impacts satisfiability complexity, offering new insights into probabilistic and causal reasoning."}}
{"id": "2502.14644", "pdf": "https://arxiv.org/pdf/2502.14644", "abs": "https://arxiv.org/abs/2502.14644", "authors": ["Yansheng Mao", "Yufei Xu", "Jiaqi Li", "Fanxu Meng", "Haotong Yang", "Zilong Zheng", "Xiyuan Wang", "Muhan Zhang"], "title": "LIFT: Improving Long Context Understanding of Large Language Models through Long Input Fine-Tuning", "categories": ["cs.CL"], "comment": null, "summary": "Long context understanding remains challenging for large language models due\nto their limited context windows. This paper presents Long Input Fine-Tuning\n(LIFT), a novel framework for long-context modeling that can improve the\nlong-context performance of arbitrary (short-context) LLMs by dynamically\nadapting model parameters based on the long input. Importantly, LIFT, rather\nthan endlessly extending the context window size to accommodate increasingly\nlonger inputs in context, chooses to store and absorb the long input in\nparameter. By fine-tuning the long input into model parameters, LIFT allows\nshort-context LLMs to answer questions even when the required information is\nnot provided in the context during inference. Furthermore, to enhance LIFT\nperformance while maintaining the original in-context learning (ICL)\ncapabilities, we introduce Gated Memory, a specialized attention adapter that\nautomatically balances long input memorization and ICL. We provide a\ncomprehensive analysis of the strengths and limitations of LIFT on long context\nunderstanding, offering valuable directions for future research.", "AI": {"tldr": "LIFT is a framework for improving long-context performance in short-context LLMs by fine-tuning long inputs into model parameters, avoiding endless context window extensions.", "motivation": "Addressing the challenge of long-context understanding in LLMs with limited context windows.", "method": "Introduces Long Input Fine-Tuning (LIFT) and Gated Memory, an attention adapter to balance memorization and in-context learning.", "result": "Enables short-context LLMs to answer questions without requiring all information in the context during inference.", "conclusion": "LIFT offers a promising approach for long-context modeling, with potential for future research."}}
{"id": "2504.19742", "pdf": "https://arxiv.org/pdf/2504.19742", "abs": "https://arxiv.org/abs/2504.19742", "authors": ["Valerie Zermatten", "Javiera Castillo-Navarro", "Pallavi Jain", "Devis Tuia", "Diego Marcos"], "title": "EcoWikiRS: Learning Ecological Representation of Satellite Images from Weak Supervision with Species Observations and Wikipedia", "categories": ["cs.CV"], "comment": "Accepted at EarthVision 2025 (CVPRW 2025)", "summary": "The presence of species provides key insights into the ecological properties\nof a location such as land cover, climatic conditions or even soil properties.\nWe propose a method to predict such ecological properties directly from remote\nsensing (RS) images by aligning them with species habitat descriptions. We\nintroduce the EcoWikiRS dataset, consisting of high-resolution aerial images,\nthe corresponding geolocated species observations, and, for each species, the\ntextual descriptions of their habitat from Wikipedia. EcoWikiRS offers a\nscalable way of supervision for RS vision language models (RS-VLMs) for\necology. This is a setting with weak and noisy supervision, where, for\ninstance, some text may describe properties that are specific only to part of\nthe species' niche or is irrelevant to a specific image. We tackle this by\nproposing WINCEL, a weighted version of the InfoNCE loss. We evaluate our model\non the task of ecosystem zero-shot classification by following the habitat\ndefinitions from the European Nature Information System (EUNIS). Our results\nshow that our approach helps in understanding RS images in a more ecologically\nmeaningful manner. The code and the dataset are available at\nhttps://github.com/eceo-epfl/EcoWikiRS.", "AI": {"tldr": "The paper proposes a method to predict ecological properties from remote sensing images using species habitat descriptions, introducing the EcoWikiRS dataset and WINCEL, a weighted InfoNCE loss, for improved ecological understanding.", "motivation": "To leverage species habitat descriptions for ecological insights from remote sensing images, addressing weak and noisy supervision.", "method": "Aligns remote sensing images with species habitat descriptions using the EcoWikiRS dataset and WINCEL, a weighted InfoNCE loss.", "result": "Improves ecosystem zero-shot classification, aligning with EUNIS habitat definitions.", "conclusion": "The approach enhances ecological understanding of remote sensing images, with code and dataset publicly available."}}
{"id": "2504.20020", "pdf": "https://arxiv.org/pdf/2504.20020", "abs": "https://arxiv.org/abs/2504.20020", "authors": ["Xin Wang", "Haoyang Li", "Zeyang Zhang", "Haibo Chen", "Wenwu Zhu"], "title": "Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 3 figures", "summary": "Large language models (LLMs) have dramatically advanced machine learning\nresearch including natural language processing, computer vision, data mining,\netc., yet they still exhibit critical limitations in reasoning, factual\nconsistency, and interpretability. In this paper, we introduce a novel learning\nparadigm -- Modular Machine Learning (MML) -- as an essential approach toward\nnew-generation LLMs. MML decomposes the complex structure of LLMs into three\ninterdependent components: modular representation, modular model, and modular\nreasoning, aiming to enhance LLMs' capability of counterfactual reasoning,\nmitigating hallucinations, as well as promoting fairness, safety, and\ntransparency. Specifically, the proposed MML paradigm can: i) clarify the\ninternal working mechanism of LLMs through the disentanglement of semantic\ncomponents; ii) allow for flexible and task-adaptive model design; iii) enable\ninterpretable and logic-driven decision-making process. We present a feasible\nimplementation of MML-based LLMs via leveraging advanced techniques such as\ndisentangled representation learning, neural architecture search and\nneuro-symbolic learning. We critically identify key challenges, such as the\nintegration of continuous neural and discrete symbolic processes, joint\noptimization, and computational scalability, present promising future research\ndirections that deserve further exploration. Ultimately, the integration of the\nMML paradigm with LLMs has the potential to bridge the gap between statistical\n(deep) learning and formal (logical) reasoning, thereby paving the way for\nrobust, adaptable, and trustworthy AI systems across a wide range of real-world\napplications.", "AI": {"tldr": "The paper introduces Modular Machine Learning (MML) to address limitations in LLMs like reasoning, factual consistency, and interpretability by decomposing them into modular components.", "motivation": "Current LLMs lack reasoning, factual consistency, and interpretability, limiting their reliability and applicability.", "method": "MML divides LLMs into modular representation, model, and reasoning, using techniques like disentangled representation learning and neuro-symbolic learning.", "result": "MML enhances counterfactual reasoning, reduces hallucinations, and improves fairness, safety, and transparency in LLMs.", "conclusion": "MML bridges statistical learning and formal reasoning, promising robust and trustworthy AI systems for real-world applications."}}
{"id": "2504.19949", "pdf": "https://arxiv.org/pdf/2504.19949", "abs": "https://arxiv.org/abs/2504.19949", "authors": ["Aydo\u011fan Soylu", "Tufan Kumbasar"], "title": "Capturing Aerodynamic Characteristics of ATTAS Aircraft with Evolving Intelligent System", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": "in International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025", "summary": "Accurate modeling of aerodynamic coefficients is crucial for understanding\nand optimizing the performance of modern aircraft systems. This paper presents\nthe novel deployment of an Evolving Type-2 Quantum Fuzzy Neural Network\n(eT2QFNN) for modeling the aerodynamic coefficients of the ATTAS aircraft to\nexpress the aerodynamic characteristics. eT2QFNN can represent the nonlinear\naircraft model by creating multiple linear submodels with its rule-based\nstructure through an incremental learning strategy rather than a traditional\nbatch learning approach. Moreover, it enhances robustness to uncertainties and\ndata noise through its quantum membership functions, as well as its automatic\nrule-learning and parameter-tuning capabilities. During the estimation of the\naerodynamic coefficients via the flight data of the ATTAS, two different\nstudies are conducted in the training phase: one with a large amount of data\nand the other with a limited amount of data. The results show that the modeling\nperformance of the eT2QFNN is superior in comparison to baseline counterparts.\nFurthermore, eT2QFNN estimated the aerodynamic model with fewer rules compared\nto Type-1 fuzzy counterparts. In addition, by applying the Delta method to the\nproposed approach, the stability and control derivatives of the aircraft are\nanalyzed. The results prove the superiority of the proposed eT2QFNN in\nrepresenting aerodynamic coefficients.", "AI": {"tldr": "The paper introduces an Evolving Type-2 Quantum Fuzzy Neural Network (eT2QFNN) for modeling aerodynamic coefficients of the ATTAS aircraft, outperforming baseline methods in accuracy and robustness.", "motivation": "Accurate modeling of aerodynamic coefficients is essential for optimizing aircraft performance, requiring methods robust to uncertainties and noise.", "method": "The eT2QFNN uses incremental learning, quantum membership functions, and automatic rule-learning to model nonlinear aircraft dynamics.", "result": "eT2QFNN outperforms baseline methods, especially with limited data, and uses fewer rules than Type-1 fuzzy models.", "conclusion": "The proposed eT2QFNN is superior for aerodynamic modeling, validated by stability and control derivative analysis."}}
{"id": "2502.15147", "pdf": "https://arxiv.org/pdf/2502.15147", "abs": "https://arxiv.org/abs/2502.15147", "authors": ["Zhouhang Xie", "Tushar Khot", "Bhavana Dalvi Mishra", "Harshit Surana", "Julian McAuley", "Peter Clark", "Bodhisattwa Prasad Majumder"], "title": "Latent Factor Models Meets Instructions: Goal-conditioned Latent Factor Discovery without Task Supervision", "categories": ["cs.CL"], "comment": "NAACL 2025", "summary": "Instruction-following LLMs have recently allowed systems to discover hidden\nconcepts from a collection of unstructured documents based on a natural\nlanguage description of the purpose of the discovery (i.e., goal). Still, the\nquality of the discovered concepts remains mixed, as it depends heavily on\nLLM's reasoning ability and drops when the data is noisy or beyond LLM's\nknowledge. We present Instruct-LF, a goal-oriented latent factor discovery\nsystem that integrates LLM's instruction-following ability with statistical\nmodels to handle large, noisy datasets where LLM reasoning alone falls short.\n  Instruct-LF uses LLMs to propose fine-grained, goal-related properties from\ndocuments, estimates their presence across the dataset, and applies\ngradient-based optimization to uncover hidden factors, where each factor is\nrepresented by a cluster of co-occurring properties. We evaluate latent factors\nproduced by Instruct-LF on movie recommendation, text-world navigation, and\nlegal document categorization tasks. These interpretable representations\nimprove downstream task performance by 5-52% than the best baselines and were\npreferred 1.8 times as often as the best alternative, on average, in human\nevaluation.", "AI": {"tldr": "Instruct-LF combines LLMs with statistical models to improve latent factor discovery in noisy datasets, outperforming baselines by 5-52%.", "motivation": "Addressing the limitations of LLMs in discovering high-quality hidden concepts from noisy or complex data.", "method": "Uses LLMs to propose goal-related properties, estimates their presence, and applies gradient-based optimization to uncover latent factors.", "result": "Improves downstream task performance by 5-52% and is preferred 1.8 times more in human evaluations.", "conclusion": "Instruct-LF effectively integrates LLMs with statistical methods for robust latent factor discovery."}}
{"id": "2504.19749", "pdf": "https://arxiv.org/pdf/2504.19749", "abs": "https://arxiv.org/abs/2504.19749", "authors": ["Zhimin Liao", "Ping Wei", "Shuaijia Chen", "Haoxuan Wang", "Ziyang Ren"], "title": "STCOcc: Sparse Spatial-Temporal Cascade Renovation for 3D Occupancy and Scene Flow Prediction", "categories": ["cs.CV"], "comment": null, "summary": "3D occupancy and scene flow offer a detailed and dynamic representation of 3D\nscene. Recognizing the sparsity and complexity of 3D space, previous\nvision-centric methods have employed implicit learning-based approaches to\nmodel spatial and temporal information. However, these approaches struggle to\ncapture local details and diminish the model's spatial discriminative ability.\nTo address these challenges, we propose a novel explicit state-based modeling\nmethod designed to leverage the occupied state to renovate the 3D features.\nSpecifically, we propose a sparse occlusion-aware attention mechanism,\nintegrated with a cascade refinement strategy, which accurately renovates 3D\nfeatures with the guidance of occupied state information. Additionally, we\nintroduce a novel method for modeling long-term dynamic interactions, which\nreduces computational costs and preserves spatial information. Compared to the\nprevious state-of-the-art methods, our efficient explicit renovation strategy\nnot only delivers superior performance in terms of RayIoU and mAVE for\noccupancy and scene flow prediction but also markedly reduces GPU memory usage\nduring training, bringing it down to 8.7GB. Our code is available on\nhttps://github.com/lzzzzzm/STCOcc", "AI": {"tldr": "A novel explicit state-based method improves 3D occupancy and scene flow prediction by leveraging occupied states, reducing computational costs, and enhancing spatial details.", "motivation": "Addressing the limitations of implicit learning-based approaches in capturing local details and spatial discriminative ability in 3D scene representation.", "method": "Proposes a sparse occlusion-aware attention mechanism with cascade refinement and a method for modeling long-term dynamic interactions.", "result": "Superior performance in RayIoU and mAVE metrics, with reduced GPU memory usage (8.7GB).", "conclusion": "The explicit state-based approach effectively enhances 3D feature renovation and dynamic interaction modeling, outperforming previous methods."}}
{"id": "2504.18545", "pdf": "https://arxiv.org/pdf/2504.18545", "abs": "https://arxiv.org/abs/2504.18545", "authors": ["Geethu Joy", "Christian Huyck", "Xin-She Yang"], "title": "Parameter Tuning of the Firefly Algorithm by Three Tuning Methods: Standard Monte Carlo, Quasi-Monte Carlo and Latin Hypercube Sampling Methods", "categories": ["stat.CO", "cs.LG", "cs.NE", "68T05, 90C31"], "comment": "21 pages", "summary": "There are many different nature-inspired algorithms in the literature, and\nalmost all such algorithms have algorithm-dependent parameters that need to be\ntuned. The proper setting and parameter tuning should be carried out to\nmaximize the performance of the algorithm under consideration. This work is the\nextension of the recent work on parameter tuning by Joy et al. (2024) presented\nat the International Conference on Computational Science (ICCS 2024), and the\nFirefly Algorithm (FA) is tuned using three different methods: the Monte Carlo\nmethod, the Quasi-Monte Carlo method and the Latin Hypercube Sampling. The FA\nwith the tuned parameters is then used to solve a set of six different\noptimization problems, and the possible effect of parameter setting on the\nquality of the optimal solutions is analyzed. Rigorous statistical hypothesis\ntests have been carried out, including Student's t-tests, F-tests,\nnon-parametric Friedman tests and ANOVA. Results show that the performance of\nthe FA is not influenced by the tuning methods used. In addition, the tuned\nparameter values are largely independent of the tuning methods used. This\nindicates that the FA can be flexible and equally effective in solving\noptimization problems, and any of the three tuning methods can be used to tune\nits parameters effectively.", "AI": {"tldr": "The paper extends parameter tuning methods for the Firefly Algorithm (FA), comparing Monte Carlo, Quasi-Monte Carlo, and Latin Hypercube Sampling. Results show no significant performance difference among tuning methods, indicating FA's flexibility.", "motivation": "To investigate the impact of parameter tuning methods on the Firefly Algorithm's performance and solution quality.", "method": "Three tuning methods (Monte Carlo, Quasi-Monte Carlo, Latin Hypercube Sampling) are applied to FA, tested on six optimization problems, and analyzed using statistical tests.", "result": "No significant performance difference among tuning methods; FA remains effective regardless of the method used.", "conclusion": "FA is flexible, and any of the three tuning methods can effectively tune its parameters for optimization problems."}}
{"id": "2504.19951", "pdf": "https://arxiv.org/pdf/2504.19951", "abs": "https://arxiv.org/abs/2504.19951", "authors": ["Vineeth Sai Narajala", "Ken Huang", "Idan Habler"], "title": "Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach", "categories": ["cs.CR", "cs.AI"], "comment": "12 pages, 4 figures, 1 table", "summary": "The rise of generative AI (GenAI) multi-agent systems (MAS) necessitates\nstandardized protocols enabling agents to discover and interact with external\ntools. However, these protocols introduce new security challenges,\nparticularly; tool squatting; the deceptive registration or representation of\ntools. This paper analyzes tool squatting threats within the context of\nemerging interoperability standards, such as Model Context Protocol (MCP) or\nseamless communication between agents protocols. It introduces a comprehensive\nTool Registry system designed to mitigate these risks. We propose a\nsecurity-focused architecture featuring admin-controlled registration,\ncentralized tool discovery, fine grained access policies enforced via dedicated\nAgent and Tool Registry services, a dynamic trust scoring mechanism based on\ntool versioning and known vulnerabilities, and just in time credential\nprovisioning. Based on its design principles, the proposed registry framework\naims to effectively prevent common tool squatting vectors while preserving the\nflexibility and power of multi-agent systems. This work addresses a critical\nsecurity gap in the rapidly evolving GenAI ecosystem and provides a foundation\nfor secure tool integration in production environments.", "AI": {"tldr": "The paper proposes a Tool Registry system to combat tool squatting in GenAI multi-agent systems, featuring security measures like admin-controlled registration and dynamic trust scoring.", "motivation": "The rise of GenAI MAS requires standardized protocols, but these introduce security risks like tool squatting, necessitating a secure solution.", "method": "Introduces a Tool Registry with admin-controlled registration, centralized discovery, fine-grained access policies, dynamic trust scoring, and just-in-time credential provisioning.", "result": "The proposed framework aims to prevent tool squatting while maintaining MAS flexibility.", "conclusion": "The work fills a security gap in GenAI ecosystems, enabling secure tool integration in production."}}
{"id": "2502.20503", "pdf": "https://arxiv.org/pdf/2502.20503", "abs": "https://arxiv.org/abs/2502.20503", "authors": ["Jonathan Tonglet", "Tinne Tuytelaars", "Marie-Francine Moens", "Iryna Gurevych"], "title": "Protecting multimodal large language models against misleading visualizations", "categories": ["cs.CL"], "comment": "Preprint. Code and data available at\n  https://github.com/UKPLab/arxiv2025-misleading-visualizations", "summary": "Visualizations play a pivotal role in daily communication in an increasingly\ndata-driven world. Research on multimodal large language models (MLLMs) for\nautomated chart understanding has accelerated massively, with steady\nimprovements on standard benchmarks. However, for MLLMs to be reliable, they\nmust be robust to misleading visualizations, charts that distort the underlying\ndata, leading readers to draw inaccurate conclusions that may support\ndisinformation. Here, we uncover an important vulnerability: MLLM\nquestion-answering accuracy on misleading visualizations drops on average to\nthe level of a random baseline. To address this, we introduce the first\ninference-time methods to improve performance on misleading visualizations,\nwithout compromising accuracy on non-misleading ones. The most effective method\nextracts the underlying data table and uses a text-only LLM to answer the\nquestion based on the table. Our findings expose a critical blind spot in\ncurrent research and establish benchmark results to guide future efforts in\nreliable MLLMs.", "AI": {"tldr": "MLLMs struggle with misleading visualizations, performing at random baseline accuracy. A new method using data table extraction and text-only LLMs improves performance without affecting accuracy on non-misleading charts.", "motivation": "To address the vulnerability of MLLMs in handling misleading visualizations, which can lead to inaccurate conclusions and disinformation.", "method": "Extract underlying data tables from charts and use text-only LLMs for question-answering, ensuring robustness without compromising accuracy on non-misleading charts.", "result": "MLLM accuracy on misleading visualizations drops to random baseline levels. The proposed method improves performance without affecting non-misleading chart accuracy.", "conclusion": "The study highlights a critical blind spot in MLLM research and sets benchmarks for future work on reliable MLLMs."}}
{"id": "2504.19819", "pdf": "https://arxiv.org/pdf/2504.19819", "abs": "https://arxiv.org/abs/2504.19819", "authors": ["Hoang Chuong Nguyen", "Wei Mao", "Jose M. Alvarez", "Miaomiao Liu"], "title": "Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video", "categories": ["cs.CV"], "comment": null, "summary": "Neural Radiance Fields (NeRF) has demonstrated its superior capability to\nrepresent 3D geometry but require accurately precomputed camera poses during\ntraining. To mitigate this requirement, existing methods jointly optimize\ncamera poses and NeRF often relying on good pose initialisation or depth\npriors. However, these approaches struggle in challenging scenarios, such as\nlarge rotations, as they map each camera to a world coordinate system. We\npropose a novel method that eliminates prior dependencies by modeling\ncontinuous camera motions as time-dependent angular velocity and velocity.\nRelative motions between cameras are learned first via velocity integration,\nwhile camera poses can be obtained by aggregating such relative motions up to a\nworld coordinate system defined at a single time step within the video.\nSpecifically, accurate continuous camera movements are learned through a\ntime-dependent NeRF, which captures local scene geometry and motion by training\nfrom neighboring frames for each time step. The learned motions enable\nfine-tuning the NeRF to represent the full scene geometry. Experiments on Co3D\nand Scannet show our approach achieves superior camera pose and depth\nestimation and comparable novel-view synthesis performance compared to\nstate-of-the-art methods. Our code is available at\nhttps://github.com/HoangChuongNguyen/cope-nerf.", "AI": {"tldr": "A novel method improves NeRF by learning continuous camera motions without relying on accurate initial poses or depth priors, achieving superior pose and depth estimation.", "motivation": "NeRF requires accurate camera poses for training, which is limiting. Existing methods struggle with large rotations or lack of priors.", "method": "Models camera motions as time-dependent velocities, learns relative motions first, and aggregates them to define poses. Uses a time-dependent NeRF for local geometry and motion.", "result": "Outperforms state-of-the-art in camera pose and depth estimation on Co3D and Scannet, with comparable novel-view synthesis.", "conclusion": "The method eliminates dependency on pose priors, enabling robust NeRF training in challenging scenarios."}}
{"id": "2504.18570", "pdf": "https://arxiv.org/pdf/2504.18570", "abs": "https://arxiv.org/abs/2504.18570", "authors": ["Sabrina Bruckmeier", "Huadong Mo", "James Qin"], "title": "Residual-Evasive Attacks on ADMM in Distributed Optimization", "categories": ["cs.CR", "cs.DC", "cs.LG", "math.OC"], "comment": "10 pages, 12 figures, 2 tables", "summary": "This paper presents two attack strategies designed to evade detection in\nADMM-based systems by preventing significant changes to the residual during the\nattacked iteration. While many detection algorithms focus on identifying false\ndata injection through residual changes, we show that our attacks remain\nundetected by keeping the residual largely unchanged. The first strategy uses a\nrandom starting point combined with Gram-Schmidt orthogonalization to ensure\nstealth, with potential for refinement by enhancing the orthogonal component to\nincrease system disruption. The second strategy builds on the first, targeting\nfinancial gains by manipulating reactive power and pushing the system to its\nupper voltage limit, exploiting operational constraints. The effectiveness of\nthe proposed attack-resilient mechanism is demonstrated through case studies on\nthe IEEE 14-bus system. A comparison of the two strategies, along with commonly\nused naive attacks, reveals trade-offs between simplicity, detectability, and\neffectiveness, providing insights into ADMM system vulnerabilities. These\nfindings underscore the need for more robust monitoring algorithms to protect\nagainst advanced attack strategies.", "AI": {"tldr": "Two stealthy attack strategies for ADMM-based systems evade detection by minimizing residual changes, with one focusing on system disruption and the other on financial gains.", "motivation": "To expose vulnerabilities in ADMM-based systems by developing attacks that avoid detection through residual analysis, highlighting the need for stronger monitoring.", "method": "1. Random starting point with Gram-Schmidt orthogonalization for stealth. 2. Reactive power manipulation to exploit operational constraints for financial gain.", "result": "Attacks remain undetected and disrupt systems or exploit financial gains, demonstrated on the IEEE 14-bus system.", "conclusion": "The study reveals ADMM system vulnerabilities, emphasizing the need for more robust detection algorithms against advanced attacks."}}
{"id": "2504.19956", "pdf": "https://arxiv.org/pdf/2504.19956", "abs": "https://arxiv.org/abs/2504.19956", "authors": ["Vineeth Sai Narajala", "Om Narayan"], "title": "Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents", "categories": ["cs.CR", "cs.AI"], "comment": "12 pages, 2 figures, 1 table", "summary": "As generative AI (GenAI) agents become more common in enterprise settings,\nthey introduce security challenges that differ significantly from those posed\nby traditional systems. These agents are not just LLMs; they reason, remember,\nand act, often with minimal human oversight. This paper introduces a\ncomprehensive threat model tailored specifically for GenAI agents, focusing on\nhow their autonomy, persistent memory access, complex reasoning, and tool\nintegration create novel risks. This research work identifies 9 primary threats\nand organizes them across five key domains: cognitive architecture\nvulnerabilities, temporal persistence threats, operational execution\nvulnerabilities, trust boundary violations, and governance circumvention. These\nthreats are not just theoretical they bring practical challenges such as\ndelayed exploitability, cross-system propagation, cross system lateral\nmovement, and subtle goal misalignments that are hard to detect with existing\nframeworks and standard approaches. To help address this, the research work\npresent two complementary frameworks: ATFAA - Advanced Threat Framework for\nAutonomous AI Agents, which organizes agent-specific risks, and SHIELD, a\nframework proposing practical mitigation strategies designed to reduce\nenterprise exposure. While this work builds on existing work in LLM and AI\nsecurity, the focus is squarely on what makes agents different and why those\ndifferences matter. Ultimately, this research argues that GenAI agents require\na new lens for security. If we fail to adapt our threat models and defenses to\naccount for their unique architecture and behavior, we risk turning a powerful\nnew tool into a serious enterprise liability.", "AI": {"tldr": "The paper introduces a threat model for GenAI agents, identifying 9 primary threats across five domains, and proposes two frameworks (ATFAA and SHIELD) to address these risks.", "motivation": "GenAI agents' autonomy, memory, reasoning, and tool integration create novel security challenges not addressed by traditional systems.", "method": "Develops a comprehensive threat model and two frameworks (ATFAA for risk organization and SHIELD for mitigation strategies).", "result": "Identifies 9 threats across five domains and provides frameworks to mitigate them.", "conclusion": "GenAI agents require a new security approach; failing to adapt could turn them into enterprise liabilities."}}
{"id": "2503.10617", "pdf": "https://arxiv.org/pdf/2503.10617", "abs": "https://arxiv.org/abs/2503.10617", "authors": ["Andy Zhou"], "title": "Compositional Subspace Representation Fine-tuning for Adaptive Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ICLR 2025 SCOPE", "summary": "Adapting large language models to multiple tasks can cause cross-skill\ninterference, where improvements for one skill degrade another. While methods\nsuch as LoRA impose orthogonality constraints at the weight level, they do not\nfully address interference in hidden-state representations. We propose\nCompositional Subspace Representation Fine-tuning (CS-ReFT), a novel\nrepresentation-based approach that learns multiple orthonormal subspace\ntransformations, each specializing in a distinct skill, and composes them via a\nlightweight router. By isolating these subspace edits in the hidden state,\nrather than weight matrices, CS-ReFT prevents cross-task conflicts more\neffectively. On the AlpacaEval benchmark, applying CS-ReFT to Llama-2-7B\nachieves a 93.94% win rate, surpassing GPT-3.5 Turbo (86.30%) while requiring\nonly 0.0098% of model parameters. These findings show that specialized\nrepresentation edits, composed via a simple router, significantly enhance\nmulti-task instruction following with minimal overhead.", "AI": {"tldr": "CS-ReFT is a method to prevent cross-skill interference in large language models by learning orthonormal subspace transformations for distinct skills, achieving high performance with minimal parameter overhead.", "motivation": "Addressing cross-skill interference in multi-task adaptation of large language models, where traditional methods like LoRA fail to fully mitigate hidden-state representation conflicts.", "method": "Proposes Compositional Subspace Representation Fine-tuning (CS-ReFT), which learns orthonormal subspace transformations for each skill and composes them via a lightweight router, isolating edits in hidden states.", "result": "Achieves a 93.94% win rate on AlpacaEval with Llama-2-7B, outperforming GPT-3.5 Turbo (86.30%) using only 0.0098% of model parameters.", "conclusion": "CS-ReFT demonstrates that specialized representation edits with a simple router significantly improve multi-task performance efficiently."}}
{"id": "2504.19824", "pdf": "https://arxiv.org/pdf/2504.19824", "abs": "https://arxiv.org/abs/2504.19824", "authors": ["Mohamed Hassan", "Mohammad Wasil", "Sebastian Houben"], "title": "Taming the Randomness: Towards Label-Preserving Cropping in Contrastive Learning", "categories": ["cs.CV"], "comment": null, "summary": "Contrastive learning (CL) approaches have gained great recognition as a very\nsuccessful subset of self-supervised learning (SSL) methods. SSL enables\nlearning from unlabeled data, a crucial step in the advancement of deep\nlearning, particularly in computer vision (CV), given the plethora of unlabeled\nimage data. CL works by comparing different random augmentations (e.g.,\ndifferent crops) of the same image, thus achieving self-labeling. Nevertheless,\nrandomly augmenting images and especially random cropping can result in an\nimage that is semantically very distant from the original and therefore leads\nto false labeling, hence undermining the efficacy of the methods. In this\nresearch, two novel parameterized cropping methods are introduced that increase\nthe robustness of self-labeling and consequently increase the efficacy. The\nresults show that the use of these methods significantly improves the accuracy\nof the model by between 2.7\\% and 12.4\\% on the downstream task of classifying\nCIFAR-10, depending on the crop size compared to that of the non-parameterized\nrandom cropping method.", "AI": {"tldr": "The paper introduces two novel parameterized cropping methods for contrastive learning to improve self-labeling robustness and model accuracy.", "motivation": "Random augmentations in contrastive learning can lead to semantically distant images, causing false labeling and reducing efficacy.", "method": "Two parameterized cropping methods are proposed to enhance self-labeling robustness.", "result": "The methods improve model accuracy by 2.7% to 12.4% on CIFAR-10 classification.", "conclusion": "Parameterized cropping methods significantly enhance contrastive learning efficacy by reducing false labeling."}}
{"id": "2504.18571", "pdf": "https://arxiv.org/pdf/2504.18571", "abs": "https://arxiv.org/abs/2504.18571", "authors": ["Fabio Palmese", "Anna Maria Mandalari", "Hamed Haddadi", "Alessandro Enrico Cesare Redondi"], "title": "Intelligent Detection of Non-Essential IoT Traffic on the Home Gateway", "categories": ["cs.CR", "cs.LG"], "comment": "Paper accepted for publication at 10th International Workshop on\n  Traffic Measurements for Cybersecurity (WTMC 2025)", "summary": "The rapid expansion of Internet of Things (IoT) devices, particularly in\nsmart home environments, has introduced considerable security and privacy\nconcerns due to their persistent connectivity and interaction with cloud\nservices. Despite advancements in IoT security, effective privacy measures\nremain uncovered, with existing solutions often relying on cloud-based threat\ndetection that exposes sensitive data or outdated allow-lists that inadequately\nrestrict non-essential network traffic. This work presents ML-IoTrim, a system\nfor detecting and mitigating non-essential IoT traffic (i.e., not influencing\nthe device operations) by analyzing network behavior at the edge, leveraging\nMachine Learning to classify network destinations. Our approach includes\nbuilding a labeled dataset based on IoT device behavior and employing a\nfeature-extraction pipeline to enable a binary classification of essential vs.\nnon-essential network destinations. We test our framework in a consumer smart\nhome setup with IoT devices from five categories, demonstrating that the model\ncan accurately identify and block non-essential traffic, including previously\nunseen destinations, without relying on traditional allow-lists. We implement\nour solution on a home access point, showing the framework has strong potential\nfor scalable deployment, supporting near-real-time traffic classification in\nlarge-scale IoT environments with hundreds of devices. This research advances\nprivacy-aware traffic control in smart homes, paving the way for future\ndevelopments in IoT device privacy.", "AI": {"tldr": "ML-IoTrim is a system using ML to classify and block non-essential IoT traffic at the edge, enhancing privacy in smart homes without relying on cloud-based solutions.", "motivation": "Addressing privacy concerns in IoT due to persistent connectivity and inadequate existing solutions like cloud-based threat detection or outdated allow-lists.", "method": "Leverages ML to classify network destinations, using a labeled dataset and feature-extraction pipeline for binary classification of essential vs. non-essential traffic.", "result": "Accurately identifies and blocks non-essential traffic, including unseen destinations, in a smart home setup with IoT devices from five categories.", "conclusion": "ML-IoTrim shows scalable potential for real-time traffic classification, advancing privacy-aware traffic control in IoT environments."}}
{"id": "2504.19967", "pdf": "https://arxiv.org/pdf/2504.19967", "abs": "https://arxiv.org/abs/2504.19967", "authors": ["Adway Das", "Agnimitra Sengupta", "S. Ilgin Guler"], "title": "Enhancing short-term traffic prediction by integrating trends and fluctuations with attention mechanism", "categories": ["cs.ET", "cs.AI", "cs.LG", "stat.AP"], "comment": null, "summary": "Traffic flow prediction is a critical component of intelligent transportation\nsystems, yet accurately forecasting traffic remains challenging due to the\ninteraction between long-term trends and short-term fluctuations. Standard deep\nlearning models often struggle with these challenges because their\narchitectures inherently smooth over fine-grained fluctuations while focusing\non general trends. This limitation arises from low-pass filtering effects, gate\nbiases favoring stability, and memory update mechanisms that prioritize\nlong-term information retention. To address these shortcomings, this study\nintroduces a hybrid deep learning framework that integrates both long-term\ntrend and short-term fluctuation information using two input features processed\nin parallel, designed to capture complementary aspects of traffic flow\ndynamics. Further, our approach leverages attention mechanisms, specifically\nBahdanau attention, to selectively focus on critical time steps within traffic\ndata, enhancing the model's ability to predict congestion and other transient\nphenomena. Experimental results demonstrate that features learned from both\nbranches are complementary, significantly improving the goodness-of-fit\nstatistics across multiple prediction horizons compared to a baseline model.\nNotably, the attention mechanism enhances short-term forecast accuracy by\ndirectly targeting immediate fluctuations, though challenges remain in fully\nintegrating long-term trends. This framework can contribute to more effective\ncongestion mitigation and urban mobility planning by advancing the robustness\nand precision of traffic prediction models.", "AI": {"tldr": "A hybrid deep learning framework improves traffic flow prediction by integrating long-term trends and short-term fluctuations, using attention mechanisms for better accuracy.", "motivation": "Accurate traffic prediction is challenging due to interactions between long-term trends and short-term fluctuations, which standard deep learning models struggle to address.", "method": "A hybrid framework processes long-term and short-term features in parallel, using Bahdanau attention to focus on critical time steps.", "result": "The model outperforms baselines, with attention improving short-term forecasts, though long-term trend integration remains a challenge.", "conclusion": "The framework enhances traffic prediction robustness, aiding congestion mitigation and urban planning."}}
{"id": "2504.06868", "pdf": "https://arxiv.org/pdf/2504.06868", "abs": "https://arxiv.org/abs/2504.06868", "authors": ["Seungwon Lim", "Seungbeen Lee", "Dongjun Min", "Youngjae Yu"], "title": "Persona Dynamics: Unveiling the Impact of Personality Traits on Agents in Text-Based Games", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Artificial agents are increasingly central to complex interactions and\ndecision-making tasks, yet aligning their behaviors with desired human values\nremains an open challenge. In this work, we investigate how human-like\npersonality traits influence agent behavior and performance within text-based\ninteractive environments. We introduce PANDA: Personality Adapted Neural\nDecision Agents, a novel method for projecting human personality traits onto\nagents to guide their behavior. To induce personality in a text-based game\nagent, (i) we train a personality classifier to identify what personality type\nthe agent's actions exhibit, and (ii) we integrate the personality profiles\ndirectly into the agent's policy-learning pipeline. By deploying agents\nembodying 16 distinct personality types across 25 text-based games and\nanalyzing their trajectories, we demonstrate that an agent's action decisions\ncan be guided toward specific personality profiles. Moreover, certain\npersonality types, such as those characterized by higher levels of Openness,\ndisplay marked advantages in performance. These findings underscore the promise\nof personality-adapted agents for fostering more aligned, effective, and\nhuman-centric decision-making in interactive environments.", "AI": {"tldr": "PANDA introduces a method to align AI agent behavior with human personality traits, showing performance benefits for certain traits like Openness.", "motivation": "Aligning AI behaviors with human values is challenging; this work explores how human-like personality traits can guide agent behavior.", "method": "PANDA trains a personality classifier and integrates personality profiles into policy-learning for text-based game agents.", "result": "Agents with specific personality traits (e.g., Openness) showed improved performance in text-based games.", "conclusion": "Personality-adapted agents enhance alignment and effectiveness in interactive environments."}}
{"id": "2504.19828", "pdf": "https://arxiv.org/pdf/2504.19828", "abs": "https://arxiv.org/abs/2504.19828", "authors": ["Zhiming Hu", "Daniel Haeufle", "Syn Schmitt", "Andreas Bulling"], "title": "HOIGaze: Gaze Estimation During Hand-Object Interactions in Extended Reality Exploiting Eye-Hand-Head Coordination", "categories": ["cs.CV"], "comment": "Accepted at SIGGRAPH 2025, link:\n  https://zhiminghu.net/hu25_hoigaze.html", "summary": "We present HOIGaze - a novel learning-based approach for gaze estimation\nduring hand-object interactions (HOI) in extended reality (XR). HOIGaze\naddresses the challenging HOI setting by building on one key insight: The eye,\nhand, and head movements are closely coordinated during HOIs and this\ncoordination can be exploited to identify samples that are most useful for gaze\nestimator training - as such, effectively denoising the training data. This\ndenoising approach is in stark contrast to previous gaze estimation methods\nthat treated all training samples as equal. Specifically, we propose: 1) a\nnovel hierarchical framework that first recognises the hand currently visually\nattended to and then estimates gaze direction based on the attended hand; 2) a\nnew gaze estimator that uses cross-modal Transformers to fuse head and\nhand-object features extracted using a convolutional neural network and a\nspatio-temporal graph convolutional network; and 3) a novel eye-head\ncoordination loss that upgrades training samples belonging to the coordinated\neye-head movements. We evaluate HOIGaze on the HOT3D and Aria digital twin\n(ADT) datasets and show that it significantly outperforms state-of-the-art\nmethods, achieving an average improvement of 15.6% on HOT3D and 6.0% on ADT in\nmean angular error. To demonstrate the potential of our method, we further\nreport significant performance improvements for the sample downstream task of\neye-based activity recognition on ADT. Taken together, our results underline\nthe significant information content available in eye-hand-head coordination\nand, as such, open up an exciting new direction for learning-based gaze\nestimation.", "AI": {"tldr": "HOIGaze is a learning-based method for gaze estimation in XR during hand-object interactions, leveraging eye-hand-head coordination to denoise training data and outperforming state-of-the-art methods.", "motivation": "Existing gaze estimation methods treat all training samples equally, ignoring the coordination between eye, hand, and head movements during HOIs. HOIGaze aims to exploit this coordination for improved accuracy.", "method": "1) Hierarchical framework for attended hand recognition and gaze estimation. 2) Cross-modal Transformers for fusing head and hand-object features. 3) Eye-head coordination loss for better training samples.", "result": "HOIGaze achieves 15.6% and 6.0% improvements in mean angular error on HOT3D and ADT datasets, respectively, and enhances eye-based activity recognition.", "conclusion": "Eye-hand-head coordination provides valuable information for gaze estimation, opening a new direction for learning-based methods."}}
{"id": "2504.18605", "pdf": "https://arxiv.org/pdf/2504.18605", "abs": "https://arxiv.org/abs/2504.18605", "authors": ["Baimam Boukar Jean Jacques"], "title": "Explainable Deep-Learning Based Potentially Hazardous Asteroids Classification Using Graph Neural Networks", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": null, "summary": "Classifying potentially hazardous asteroids (PHAs) is crucial for planetary\ndefense and deep space navigation, yet traditional methods often overlook the\ndynamical relationships among asteroids. We introduce a Graph Neural Network\n(GNN) approach that models asteroids as nodes with orbital and physical\nfeatures, connected by edges representing their similarities, using a NASA\ndataset of 958,524 records. Despite an extreme class imbalance with only 0.22%\nof the dataset with the hazardous label, our model achieves an overall accuracy\nof 99% and an AUC of 0.99, with a recall of 78% and an F1-score of 37% for\nhazardous asteroids after applying the Synthetic Minority Oversampling\nTechnique. Feature importance analysis highlights albedo, perihelion distance,\nand semi-major axis as main predictors. This framework supports planetary\ndefense missions and confirms AI's potential in enabling autonomous navigation\nfor future missions such as NASA's NEO Surveyor and ESA's Ramses, offering an\ninterpretable and scalable solution for asteroid hazard assessment.", "AI": {"tldr": "A Graph Neural Network (GNN) approach classifies hazardous asteroids with high accuracy (99%) and AUC (0.99), addressing class imbalance via oversampling, and identifies key predictors like albedo and orbital features.", "motivation": "Traditional methods for classifying potentially hazardous asteroids (PHAs) neglect dynamical relationships, necessitating a more robust and interpretable solution for planetary defense and space navigation.", "method": "The study uses a GNN to model asteroids as nodes with orbital/physical features and edges representing similarities, applied to a NASA dataset of 958,524 records. Synthetic Minority Oversampling Technique (SMOTE) mitigates class imbalance.", "result": "The model achieves 99% accuracy, 0.99 AUC, 78% recall, and 37% F1-score for hazardous asteroids. Key predictors include albedo, perihelion distance, and semi-major axis.", "conclusion": "The GNN framework is scalable and interpretable, supporting planetary defense and autonomous navigation for future missions like NASA's NEO Surveyor and ESA's Ramses."}}
{"id": "2504.19985", "pdf": "https://arxiv.org/pdf/2504.19985", "abs": "https://arxiv.org/abs/2504.19985", "authors": ["Keyhan Rayati", "Amirhossein Feizi", "Alireza Beigy", "Pourya Shahverdi", "Mehdi Tale Masouleh", "Ahmad Kalhor"], "title": "Real-Time Imitation of Human Head Motions, Blinks and Emotions by Nao Robot: A Closed-Loop Approach", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "This paper introduces a novel approach for enabling real-time imitation of\nhuman head motion by a Nao robot, with a primary focus on elevating human-robot\ninteractions. By using the robust capabilities of the MediaPipe as a computer\nvision library and the DeepFace as an emotion recognition library, this\nresearch endeavors to capture the subtleties of human head motion, including\nblink actions and emotional expressions, and seamlessly incorporate these\nindicators into the robot's responses. The result is a comprehensive framework\nwhich facilitates precise head imitation within human-robot interactions,\nutilizing a closed-loop approach that involves gathering real-time feedback\nfrom the robot's imitation performance. This feedback loop ensures a high\ndegree of accuracy in modeling head motion, as evidenced by an impressive R2\nscore of 96.3 for pitch and 98.9 for yaw. Notably, the proposed approach holds\npromise in improving communication for children with autism, offering them a\nvaluable tool for more effective interaction. In essence, proposed work\nexplores the integration of real-time head imitation and real-time emotion\nrecognition to enhance human-robot interactions, with potential benefits for\nindividuals with unique communication needs.", "AI": {"tldr": "A novel method for real-time human head motion imitation by a Nao robot, using MediaPipe and DeepFace, achieves high accuracy (R2 scores: 96.3 pitch, 98.9 yaw) and benefits autism communication.", "motivation": "To enhance human-robot interactions by capturing human head motion subtleties (blinks, emotions) and integrating them into robot responses, particularly aiding children with autism.", "method": "Uses MediaPipe (computer vision) and DeepFace (emotion recognition) in a closed-loop framework with real-time feedback for precise head imitation.", "result": "High accuracy in head motion modeling (R2 scores: 96.3 pitch, 98.9 yaw), improving interaction quality.", "conclusion": "The approach successfully integrates real-time head imitation and emotion recognition, benefiting human-robot interactions, especially for individuals with communication needs like autism."}}
{"id": "2504.09714", "pdf": "https://arxiv.org/pdf/2504.09714", "abs": "https://arxiv.org/abs/2504.09714", "authors": ["Ay\u015fe Aysu Cengiz", "Ahmet Kaan Sever", "Elif Ecem \u00dcm\u00fctl\u00fc", "Naime \u015eeyma Erdem", "Burak Aytan", "B\u00fc\u015fra Tufan", "Abdullah Topraksoy", "Esra Dar\u0131c\u0131", "Cagri Toraman"], "title": "Evaluating the Quality of Benchmark Datasets for Low-Resource Languages: A Case Study on Turkish", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The reliance on translated or adapted datasets from English or multilingual\nresources introduces challenges regarding linguistic and cultural suitability.\nThis study addresses the need for robust and culturally appropriate benchmarks\nby evaluating the quality of 17 commonly used Turkish benchmark datasets. Using\na comprehensive framework that assesses six criteria, both human and LLM-judge\nannotators provide detailed evaluations to identify dataset strengths and\nshortcomings.\n  Our results reveal that 70% of the benchmark datasets fail to meet our\nheuristic quality standards. The correctness of the usage of technical terms is\nthe strongest criterion, but 85% of the criteria are not satisfied in the\nexamined datasets. Although LLM judges demonstrate potential, they are less\neffective than human annotators, particularly in understanding cultural common\nsense knowledge and interpreting fluent, unambiguous text. GPT-4o has stronger\nlabeling capabilities for grammatical and technical tasks, while Llama3.3-70B\nexcels at correctness and cultural knowledge evaluation. Our findings emphasize\nthe urgent need for more rigorous quality control in creating and adapting\ndatasets for low-resource languages.", "AI": {"tldr": "70% of Turkish benchmark datasets fail quality standards, with LLMs underperforming humans in cultural and linguistic tasks. GPT-4o and Llama3.3-70B show strengths in specific areas, highlighting the need for better dataset quality control.", "motivation": "Address the lack of culturally and linguistically suitable benchmarks for Turkish by evaluating existing datasets.", "method": "Evaluate 17 Turkish benchmark datasets using a framework with six criteria, assessed by human and LLM annotators.", "result": "70% of datasets fail quality standards; LLMs lag behind humans in cultural and linguistic understanding, though GPT-4o and Llama3.3-70B excel in specific tasks.", "conclusion": "Urgent need for stricter quality control in dataset creation for low-resource languages like Turkish."}}
{"id": "2504.19834", "pdf": "https://arxiv.org/pdf/2504.19834", "abs": "https://arxiv.org/abs/2504.19834", "authors": ["Xiaoyu Liu", "Mingshuai Yao", "Yabo Zhang", "Xianhui Lin", "Peiran Ren", "Xiaoming Li", "Ming Liu", "Wangmeng Zuo"], "title": "AnimateAnywhere: Rouse the Background in Human Image Animation", "categories": ["cs.CV"], "comment": null, "summary": "Human image animation aims to generate human videos of given characters and\nbackgrounds that adhere to the desired pose sequence. However, existing methods\nfocus more on human actions while neglecting the generation of background,\nwhich typically leads to static results or inharmonious movements. The\ncommunity has explored camera pose-guided animation tasks, yet preparing the\ncamera trajectory is impractical for most entertainment applications and\nordinary users. As a remedy, we present an AnimateAnywhere framework, rousing\nthe background in human image animation without requirements on camera\ntrajectories. In particular, based on our key insight that the movement of the\nhuman body often reflects the motion of the background, we introduce a\nbackground motion learner (BML) to learn background motions from human pose\nsequences. To encourage the model to learn more accurate cross-frame\ncorrespondences, we further deploy an epipolar constraint on the 3D attention\nmap. Specifically, the mask used to suppress geometrically unreasonable\nattention is carefully constructed by combining an epipolar mask and the\ncurrent 3D attention map. Extensive experiments demonstrate that our\nAnimateAnywhere effectively learns the background motion from human pose\nsequences, achieving state-of-the-art performance in generating human animation\nresults with vivid and realistic backgrounds. The source code and model will be\navailable at https://github.com/liuxiaoyu1104/AnimateAnywhere.", "AI": {"tldr": "AnimateAnywhere framework generates human videos with dynamic backgrounds by learning background motions from human pose sequences, avoiding the need for camera trajectories.", "motivation": "Existing methods neglect background generation, leading to static or inharmonious results. Preparing camera trajectories is impractical for users.", "method": "Uses a background motion learner (BML) to infer background motion from human poses and applies an epipolar constraint on 3D attention maps for accuracy.", "result": "Achieves state-of-the-art performance in generating realistic human animations with dynamic backgrounds.", "conclusion": "AnimateAnywhere effectively learns background motion from poses, enhancing animation realism without requiring camera trajectories."}}
{"id": "2504.18624", "pdf": "https://arxiv.org/pdf/2504.18624", "abs": "https://arxiv.org/abs/2504.18624", "authors": ["Ali SaraerToosi", "Avery Broderick"], "title": "Validation and Calibration of Semi-Analytical Models for the Event Horizon Telescope Observations of Sagittarius A*", "categories": ["astro-ph.HE", "astro-ph.IM", "cs.CV", "cs.LG", "85A99, 35Q75, 65C60, 62F15", "I.2.6; G.1.10; I.4.10"], "comment": "26 pages, 9 figures, 2 tables, submitted to ApJ", "summary": "The Event Horizon Telescope (EHT) enables the exploration of black hole\naccretion flows at event-horizon scales. Fitting ray-traced physical models to\nEHT observations requires the generation of synthetic images, a task that is\ncomputationally demanding. This study leverages \\alinet, a generative machine\nlearning model, to efficiently produce radiatively inefficient accretion flow\n(RIAF) images as a function of the specified physical parameters. \\alinet has\npreviously been shown to be able to interpolate black hole images and their\nassociated physical parameters after training on a computationally tractable\nset of library images. We utilize this model to estimate the uncertainty\nintroduced by a number of anticipated unmodeled physical effects, including\ninterstellar scattering and intrinsic source variability. We then use this to\ncalibrate physical parameter estimates and their associated uncertainties from\nRIAF model fits to mock EHT data via a library of general relativistic\nmagnetohydrodynamics models.", "AI": {"tldr": "The study uses a generative ML model, \\alinet, to efficiently create RIAF images for EHT observations, addressing computational demands and estimating uncertainties from unmodeled effects.", "motivation": "To overcome the computational challenges of generating synthetic images for EHT observations and to account for uncertainties from unmodeled physical effects.", "method": "Leverages \\alinet, a generative ML model, to interpolate black hole images and physical parameters, then estimates uncertainties from effects like interstellar scattering.", "result": "The model efficiently produces RIAF images and calibrates physical parameter estimates from mock EHT data.", "conclusion": "\\alinet provides a practical solution for generating synthetic images and improving parameter estimation accuracy in EHT observations."}}
{"id": "2504.19990", "pdf": "https://arxiv.org/pdf/2504.19990", "abs": "https://arxiv.org/abs/2504.19990", "authors": ["Salem Lahlou"], "title": "Mitigating Societal Cognitive Overload in the Age of AI: Challenges and Directions", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Societal cognitive overload, driven by the deluge of information and\ncomplexity in the AI age, poses a critical challenge to human well-being and\nsocietal resilience. This paper argues that mitigating cognitive overload is\nnot only essential for improving present-day life but also a crucial\nprerequisite for navigating the potential risks of advanced AI, including\nexistential threats. We examine how AI exacerbates cognitive overload through\nvarious mechanisms, including information proliferation, algorithmic\nmanipulation, automation anxieties, deregulation, and the erosion of meaning.\nThe paper reframes the AI safety debate to center on cognitive overload,\nhighlighting its role as a bridge between near-term harms and long-term risks.\nIt concludes by discussing potential institutional adaptations, research\ndirections, and policy considerations that arise from adopting an\noverload-resilient perspective on human-AI alignment, suggesting pathways for\nfuture exploration rather than prescribing definitive solutions.", "AI": {"tldr": "The paper highlights cognitive overload in the AI age as a critical issue, linking it to both immediate well-being and long-term AI risks, and suggests future research and policy directions.", "motivation": "Addressing cognitive overload is vital for human well-being and societal resilience, especially in mitigating risks posed by advanced AI.", "method": "The paper analyzes how AI exacerbates cognitive overload through mechanisms like information proliferation and algorithmic manipulation, and reframes AI safety around this issue.", "result": "Cognitive overload is identified as a bridge between near-term harms and long-term AI risks, necessitating institutional and policy adaptations.", "conclusion": "The paper advocates for an overload-resilient perspective in human-AI alignment, proposing future research and policy pathways without definitive solutions."}}
{"id": "2504.10982", "pdf": "https://arxiv.org/pdf/2504.10982", "abs": "https://arxiv.org/abs/2504.10982", "authors": ["Yingjian Chen", "Feiyang Li", "Xingyu Song", "Tianxiao Li", "Zixin Xu", "Xiujie Chen", "Issey Sukeda", "Irene Li"], "title": "Exploring the Role of Knowledge Graph-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages", "summary": "Large language models (LLMs) perform well in medical QA, but their\neffectiveness in Japanese contexts is limited due to privacy constraints that\nprevent the use of commercial models like GPT-4 in clinical settings. As a\nresult, recent efforts focus on instruction-tuning open-source LLMs, though the\npotential of combining them with retrieval-augmented generation (RAG) remains\nunderexplored. To bridge this gap, we are the first to explore a knowledge\ngraph-based (KG) RAG framework for Japanese medical QA small-scale open-source\nLLMs. Experimental results show that KG-based RAG has only a limited impact on\nJapanese medical QA using small-scale open-source LLMs. Further case studies\nreveal that the effectiveness of the RAG is sensitive to the quality and\nrelevance of the external retrieved content. These findings offer valuable\ninsights into the challenges and potential of applying RAG in Japanese medical\nQA, while also serving as a reference for other low-resource languages.", "AI": {"tldr": "The paper explores a knowledge graph-based RAG framework for Japanese medical QA using small-scale open-source LLMs, finding limited impact due to sensitivity to retrieved content quality.", "motivation": "Commercial LLMs like GPT-4 can't be used in Japanese clinical settings due to privacy constraints, prompting research into open-source alternatives combined with RAG.", "method": "The study employs a knowledge graph-based RAG framework for Japanese medical QA, testing small-scale open-source LLMs.", "result": "KG-based RAG shows limited impact, with effectiveness highly dependent on the quality and relevance of retrieved content.", "conclusion": "The findings highlight challenges and potential for RAG in Japanese medical QA, offering insights for low-resource languages."}}
{"id": "2504.19839", "pdf": "https://arxiv.org/pdf/2504.19839", "abs": "https://arxiv.org/abs/2504.19839", "authors": ["Yulong Guo", "Zilun Zhang", "Yongheng Shang", "Tiancheng Zhao", "Shuiguang Deng", "Yingchun Yang", "Jianwei Yin"], "title": "SRMF: A Data Augmentation and Multimodal Fusion Approach for Long-Tail UHR Satellite Image Segmentation", "categories": ["cs.CV"], "comment": "None", "summary": "The long-tail problem presents a significant challenge to the advancement of\nsemantic segmentation in ultra-high-resolution (UHR) satellite imagery. While\nprevious efforts in UHR semantic segmentation have largely focused on\nmulti-branch network architectures that emphasize multi-scale feature\nextraction and fusion, they have often overlooked the importance of addressing\nthe long-tail issue. In contrast to prior UHR methods that focused on\nindependent feature extraction, we emphasize data augmentation and multimodal\nfeature fusion to alleviate the long-tail problem. In this paper, we introduce\nSRMF, a novel framework for semantic segmentation in UHR satellite imagery. Our\napproach addresses the long-tail class distribution by incorporating a\nmulti-scale cropping technique alongside a data augmentation strategy based on\nsemantic reordering and resampling. To further enhance model performance, we\npropose a multimodal fusion-based general representation knowledge injection\nmethod, which, for the first time, fuses text and visual features without the\nneed for individual region text descriptions, extracting more robust features.\nExtensive experiments on the URUR, GID, and FBP datasets demonstrate that our\nmethod improves mIoU by 3.33\\%, 0.66\\%, and 0.98\\%, respectively, achieving\nstate-of-the-art performance. Code is available at:\nhttps://github.com/BinSpa/SRMF.git.", "AI": {"tldr": "The paper introduces SRMF, a framework for semantic segmentation in UHR satellite imagery, addressing the long-tail problem through data augmentation and multimodal feature fusion, achieving state-of-the-art results.", "motivation": "The long-tail problem in UHR satellite imagery semantic segmentation is often overlooked, despite its impact on performance. The paper aims to address this by focusing on data augmentation and multimodal fusion.", "method": "The SRMF framework uses multi-scale cropping and semantic reordering/resampling for data augmentation, alongside a novel multimodal fusion method combining text and visual features without region-specific text descriptions.", "result": "Experiments on URUR, GID, and FBP datasets show mIoU improvements of 3.33%, 0.66%, and 0.98%, respectively, achieving state-of-the-art performance.", "conclusion": "SRMF effectively tackles the long-tail problem in UHR semantic segmentation, outperforming existing methods through innovative data augmentation and multimodal fusion."}}
{"id": "2504.18628", "pdf": "https://arxiv.org/pdf/2504.18628", "abs": "https://arxiv.org/abs/2504.18628", "authors": ["Christodoulos Peltekis", "Chrysostomos Nicopoulos", "Giorgos Dimitrakopoulos"], "title": "Periodic Online Testing for Sparse Systolic Tensor Arrays", "categories": ["cs.AR", "cs.LG"], "comment": "International Conference on Modern Circuits and Systems Technologies\n  (MOCAST) 2025", "summary": "Modern Machine Learning (ML) applications often benefit from structured\nsparsity, a technique that efficiently reduces model complexity and simplifies\nhandling of sparse data in hardware. Sparse systolic tensor arrays -\nspecifically designed to accelerate these structured-sparse ML models - play a\npivotal role in enabling efficient computations. As ML is increasingly\nintegrated into safety-critical systems, it is of paramount importance to\nensure the reliability of these systems. This paper introduces an online\nerror-checking technique capable of detecting and locating permanent faults\nwithin sparse systolic tensor arrays before computation begins. The new\ntechnique relies on merely four test vectors and exploits the weight values\nalready loaded within the systolic array to comprehensively test the system.\nFault-injection campaigns within the gate-level netlist, while executing three\nwell-established Convolutional Neural Networks (CNN), validate the efficiency\nof the proposed approach, which is shown to achieve very high fault coverage,\nwhile incurring minimal performance and area overheads.", "AI": {"tldr": "The paper introduces an online error-checking technique for sparse systolic tensor arrays in ML, using four test vectors to detect permanent faults with high coverage and minimal overhead.", "motivation": "Ensuring reliability in safety-critical ML systems by detecting faults in sparse systolic tensor arrays before computation.", "method": "Uses four test vectors and existing weight values in the systolic array for comprehensive fault detection.", "result": "Validated via fault-injection campaigns on CNNs, achieving high fault coverage with low overhead.", "conclusion": "The technique is efficient for reliable ML computations in safety-critical applications."}}
{"id": "2504.19996", "pdf": "https://arxiv.org/pdf/2504.19996", "abs": "https://arxiv.org/abs/2504.19996", "authors": ["Andreas Kalogeras", "Dimitrios Bormpoudakis", "Iason Tsardanidis", "Dimitra A. Loka", "Charalampos Kontoes"], "title": "Monitoring digestate application on agricultural crops using Sentinel-2 Satellite imagery", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The widespread use of Exogenous Organic Matter in agriculture necessitates\nmonitoring to assess its effects on soil and crop health. This study evaluates\noptical Sentinel-2 satellite imagery for detecting digestate application, a\npractice that enhances soil fertility but poses environmental risks like\nmicroplastic contamination and nitrogen losses. In the first instance,\nSentinel-2 satellite image time series (SITS) analysis of specific indices\n(EOMI, NDVI, EVI) was used to characterize EOM's spectral behavior after\napplication on the soils of four different crop types in Thessaly, Greece.\nFurthermore, Machine Learning (ML) models (namely Random Forest, k-NN, Gradient\nBoosting and a Feed-Forward Neural Network), were used to investigate digestate\npresence detection, achieving F1-scores up to 0.85. The findings highlight the\npotential of combining remote sensing and ML for scalable and cost-effective\nmonitoring of EOM applications, supporting precision agriculture and\nsustainability.", "AI": {"tldr": "The study uses Sentinel-2 satellite imagery and ML models to detect digestate application in agriculture, achieving high accuracy and highlighting its potential for scalable monitoring.", "motivation": "To assess the effects of Exogenous Organic Matter (EOM) on soil and crop health, particularly digestate application, which poses environmental risks.", "method": "Analyzed Sentinel-2 satellite imagery using specific indices (EOMI, NDVI, EVI) and employed ML models (Random Forest, k-NN, Gradient Boosting, Feed-Forward Neural Network) for detection.", "result": "Achieved F1-scores up to 0.85, demonstrating effective detection of digestate presence.", "conclusion": "Combining remote sensing and ML offers scalable, cost-effective monitoring for precision agriculture and sustainability."}}
{"id": "2504.11975", "pdf": "https://arxiv.org/pdf/2504.11975", "abs": "https://arxiv.org/abs/2504.11975", "authors": ["Ra\u00fal V\u00e1zquez", "Timothee Mickus", "Elaine Zosa", "Teemu Vahtola", "J\u00f6rg Tiedemann", "Aman Sinha", "Vincent Segonne", "Fernando S\u00e1nchez-Vega", "Alessandro Raganato", "Jind\u0159ich Libovick\u00fd", "Jussi Karlgren", "Shaoxiong Ji", "Jind\u0159ich Helcl", "Liane Guillou", "Ona de Gibert", "Jaione Bengoetxea", "Joseph Attieh", "Marianna Apidianaki"], "title": "SemEval-2025 Task 3: Mu-SHROOM, the Multilingual Shared Task on Hallucinations and Related Observable Overgeneration Mistakes", "categories": ["cs.CL"], "comment": "Mu-SHROOM is part of SemEval-2025 (Task 3). TBP: Proceedings of the\n  19th International Workshop on Semantic Evaluation (SemEval-2025)", "summary": "We present the Mu-SHROOM shared task which is focused on detecting\nhallucinations and other overgeneration mistakes in the output of\ninstruction-tuned large language models (LLMs). Mu-SHROOM addresses\ngeneral-purpose LLMs in 14 languages, and frames the hallucination detection\nproblem as a span-labeling task. We received 2,618 submissions from 43\nparticipating teams employing diverse methodologies. The large number of\nsubmissions underscores the interest of the community in hallucination\ndetection. We present the results of the participating systems and conduct an\nempirical analysis to identify key factors contributing to strong performance\nin this task. We also emphasize relevant current challenges, notably the\nvarying degree of hallucinations across languages and the high annotator\ndisagreement when labeling hallucination spans.", "AI": {"tldr": "Mu-SHROOM is a shared task for detecting hallucinations in LLM outputs across 14 languages, framed as a span-labeling task with 2,618 submissions from 43 teams.", "motivation": "To address the challenge of detecting hallucinations and overgeneration mistakes in instruction-tuned LLMs, highlighting community interest and language-specific variations.", "method": "The task is framed as a span-labeling problem, with diverse methodologies employed by participating teams.", "result": "High participation (2,618 submissions) shows strong community interest. Empirical analysis identifies key performance factors and challenges like language variability and annotator disagreement.", "conclusion": "Mu-SHROOM highlights the importance of hallucination detection in LLMs, revealing challenges such as language differences and labeling consistency."}}
{"id": "2504.19860", "pdf": "https://arxiv.org/pdf/2504.19860", "abs": "https://arxiv.org/abs/2504.19860", "authors": ["Chenhan Jiang", "Yihan Zeng", "Hang Xu", "Dit-Yan Yeung"], "title": "CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback", "categories": ["cs.CV"], "comment": null, "summary": "Score Distillation Sampling (SDS) has achieved remarkable success in\ntext-to-3D content generation. However, SDS-based methods struggle to maintain\nsemantic fidelity for user prompts, particularly when involving multiple\nobjects with intricate interactions. While existing approaches often address 3D\nconsistency through multiview diffusion model fine-tuning on 3D datasets, this\nstrategy inadvertently exacerbates text-3D alignment degradation. The\nlimitation stems from SDS's inherent accumulation of view-independent biases\nduring optimization, which progressively diverges from the ideal text alignment\ndirection. To alleviate this limitation, we propose a novel SDS objective,\ndubbed as Textual Coherent Score Distillation (TCSD), which integrates\nalignment feedback from multimodal large language models (MLLMs). Our TCSD\nleverages cross-modal understanding capabilities of MLLMs to assess and guide\nthe text-3D correspondence during the optimization. We further develop\n3DLLaVA-CRITIC - a fine-tuned MLLM specialized for evaluating multiview text\nalignment in 3D generations. Additionally, we introduce an LLM-layout\ninitialization that significantly accelerates optimization convergence through\nsemantic-aware spatial configuration. Comprehensive evaluations demonstrate\nthat our framework, CoherenDream, establishes state-of-the-art performance in\ntext-aligned 3D generation across multiple benchmarks, including T$^3$Bench and\nTIFA subset. Qualitative results showcase the superior performance of\nCoherenDream in preserving textual consistency and semantic interactions. As\nthe first study to incorporate MLLMs into SDS optimization, we also conduct\nextensive ablation studies to explore optimal MLLM adaptations for 3D\ngeneration tasks.", "AI": {"tldr": "The paper introduces Textual Coherent Score Distillation (TCSD) to improve text-to-3D generation by addressing semantic fidelity issues in SDS-based methods, leveraging MLLMs for alignment feedback, and achieving state-of-the-art results.", "motivation": "Existing SDS-based methods struggle with semantic fidelity for complex prompts, especially for multiple objects with intricate interactions, due to view-independent biases.", "method": "Proposes TCSD, integrating MLLM feedback for text-3D alignment, develops 3DLLaVA-CRITIC for evaluation, and introduces LLM-layout initialization for faster convergence.", "result": "CoherenDream achieves state-of-the-art performance in text-aligned 3D generation, preserving textual consistency and semantic interactions.", "conclusion": "TCSD effectively addresses SDS limitations by leveraging MLLMs, demonstrating superior performance and opening new avenues for MLLM integration in 3D generation."}}
{"id": "2504.18633", "pdf": "https://arxiv.org/pdf/2504.18633", "abs": "https://arxiv.org/abs/2504.18633", "authors": ["Nguyen Thi Minh Phu", "Duong Tan Loc", "Vo Nguyen Le Duy"], "title": "Statistical Inference for Clustering-based Anomaly Detection", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Unsupervised anomaly detection (AD) is a fundamental problem in machine\nlearning and statistics. A popular approach to unsupervised AD is\nclustering-based detection. However, this method lacks the ability to guarantee\nthe reliability of the detected anomalies. In this paper, we propose SI-CLAD\n(Statistical Inference for CLustering-based Anomaly Detection), a novel\nstatistical framework for testing the clustering-based AD results. The key\nstrength of SI-CLAD lies in its ability to rigorously control the probability\nof falsely identifying anomalies, maintaining it below a pre-specified\nsignificance level $\\alpha$ (e.g., $\\alpha = 0.05$). By analyzing the selection\nmechanism inherent in clustering-based AD and leveraging the Selective\nInference (SI) framework, we prove that false detection control is attainable.\nMoreover, we introduce a strategy to boost the true detection rate, enhancing\nthe overall performance of SI-CLAD. Extensive experiments on synthetic and\nreal-world datasets provide strong empirical support for our theoretical\nfindings, showcasing the superior performance of the proposed method.", "AI": {"tldr": "SI-CLAD is a statistical framework for testing clustering-based anomaly detection results, ensuring false detection control and boosting true detection rates.", "motivation": "Existing clustering-based anomaly detection lacks reliability guarantees, prompting the need for a method to control false detections.", "method": "SI-CLAD uses Selective Inference to analyze clustering-based AD, controlling false detection probability below a significance level.", "result": "The method achieves rigorous false detection control and improves true detection rates, validated by experiments.", "conclusion": "SI-CLAD outperforms existing methods, offering reliable anomaly detection with theoretical and empirical support."}}
{"id": "2504.19997", "pdf": "https://arxiv.org/pdf/2504.19997", "abs": "https://arxiv.org/abs/2504.19997", "authors": ["Ivo Brett"], "title": "Simplified and Secure MCP Gateways for Enterprise AI Integration", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The increased adoption of the Model Context Protocol (MCP) for AI Agents\nnecessitates robust security for Enterprise integrations. This paper introduces\nthe MCP Gateway to simplify self-hosted MCP server integration. The proposed\narchitecture integrates security principles, authentication, intrusion\ndetection, and secure tunneling, enabling secure self-hosting without exposing\ninfrastructure. Key contributions include a reference architecture, threat\nmodel mapping, simplified integration strategies, and open-source\nimplementation recommendations. This work focuses on the unique challenges of\nenterprise-centric, self-hosted AI integrations, unlike existing public MCP\nserver solutions.", "AI": {"tldr": "The paper introduces the MCP Gateway to secure self-hosted MCP server integrations for enterprises, addressing unique challenges not covered by public solutions.", "motivation": "The growing use of MCP for AI agents in enterprises requires robust security for integrations, which existing public MCP solutions lack.", "method": "Proposes the MCP Gateway architecture, incorporating security principles, authentication, intrusion detection, and secure tunneling.", "result": "Key contributions include a reference architecture, threat model mapping, simplified integration strategies, and open-source implementation recommendations.", "conclusion": "The MCP Gateway enables secure self-hosting of MCP servers without exposing infrastructure, addressing enterprise-specific needs."}}
{"id": "2504.12098", "pdf": "https://arxiv.org/pdf/2504.12098", "abs": "https://arxiv.org/abs/2504.12098", "authors": ["Adil Bahaj", "Hamed Rahimi", "Mohamed Chetouani", "Mounir Ghogho"], "title": "Gauging Overprecision in LLMs: An Empirical Study", "categories": ["cs.CL"], "comment": "16 pages", "summary": "Recently, overconfidence in large language models (LLMs) has garnered\nconsiderable attention due to its fundamental importance in quantifying the\ntrustworthiness of LLM generation. However, existing approaches prompt the\n\\textit{black box LLMs} to produce their confidence (\\textit{verbalized\nconfidence}), which can be subject to many biases and hallucinations. Inspired\nby a different aspect of overconfidence in cognitive science called\n\\textit{overprecision}, we designed a framework for its study in black box\nLLMs. This framework contains three main phases: 1) generation, 2) refinement\nand 3) evaluation. In the generation phase we prompt the LLM to generate\nanswers to numerical questions in the form of intervals with a certain level of\nconfidence. This confidence level is imposed in the prompt and not required for\nthe LLM to generate as in previous approaches. We use various prompting\ntechniques and use the same prompt multiple times to gauge the effects of\nrandomness in the generation process. In the refinement phase, answers from the\nprevious phase are refined to generate better answers. The LLM answers are\nevaluated and studied in the evaluation phase to understand its internal\nworkings. This study allowed us to gain various insights into LLM\noverprecision: 1) LLMs are highly uncalibrated for numerical tasks 2) there is\nno correlation between the length of the interval and the imposed confidence\nlevel, which can be symptomatic of a a) lack of understanding of the concept of\nconfidence or b) inability to adjust self-confidence by following instructions,\n{3) LLM numerical precision differs depending on the task, scale of answer and\nprompting technique 4) Refinement of answers doesn't improve precision in most\ncases. We believe this study offers new perspectives on LLM overconfidence and\nserves as a strong baseline for overprecision in LLMs.", "AI": {"tldr": "The paper studies overconfidence in LLMs, focusing on 'overprecision' in numerical tasks. It introduces a framework with generation, refinement, and evaluation phases, revealing LLMs' poor calibration and lack of correlation between interval length and confidence.", "motivation": "To address biases in existing methods for measuring LLM confidence by exploring overprecision, inspired by cognitive science, and to provide insights into LLM trustworthiness.", "method": "A three-phase framework: 1) Generate numerical answers with imposed confidence levels, 2) Refine answers, and 3) Evaluate LLM behavior and precision.", "result": "LLMs are uncalibrated for numerical tasks, show no correlation between interval length and confidence, and refinement rarely improves precision.", "conclusion": "The study offers new insights into LLM overconfidence and establishes a baseline for future research on overprecision."}}
{"id": "2504.19876", "pdf": "https://arxiv.org/pdf/2504.19876", "abs": "https://arxiv.org/abs/2504.19876", "authors": ["Mamadou Keita", "Wassim Hamidouche", "Hessen Bougueffa Eutamene", "Abdelmalik Taleb-Ahmed", "Abdenour Hadid"], "title": "DeeCLIP: A Robust and Generalizable Transformer-Based Framework for Detecting AI-Generated Images", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "This paper introduces DeeCLIP, a novel framework for detecting AI-generated\nimages using CLIP-ViT and fusion learning. Despite significant advancements in\ngenerative models capable of creating highly photorealistic images, existing\ndetection methods often struggle to generalize across different models and are\nhighly sensitive to minor perturbations. To address these challenges, DeeCLIP\nincorporates DeeFuser, a fusion module that combines high-level and low-level\nfeatures, improving robustness against degradations such as compression and\nblurring. Additionally, we apply triplet loss to refine the embedding space,\nenhancing the model's ability to distinguish between real and synthetic\ncontent. To further enable lightweight adaptation while preserving pre-trained\nknowledge, we adopt parameter-efficient fine-tuning using low-rank adaptation\n(LoRA) within the CLIP-ViT backbone. This approach supports effective zero-shot\nlearning without sacrificing generalization. Trained exclusively on 4-class\nProGAN data, DeeCLIP achieves an average accuracy of 89.00% on 19 test subsets\ncomposed of generative adversarial network (GAN) and diffusion models. Despite\nhaving fewer trainable parameters, DeeCLIP outperforms existing methods,\ndemonstrating superior robustness against various generative models and\nreal-world distortions. The code is publicly available at\nhttps://github.com/Mamadou-Keita/DeeCLIP for research purposes.", "AI": {"tldr": "DeeCLIP is a framework for detecting AI-generated images using CLIP-ViT and fusion learning, improving robustness and generalization.", "motivation": "Existing detection methods struggle with generalization and sensitivity to perturbations, prompting the need for a more robust solution.", "method": "DeeCLIP uses DeeFuser for feature fusion, triplet loss for embedding refinement, and LoRA for parameter-efficient fine-tuning.", "result": "Achieves 89.00% accuracy on 19 test subsets, outperforming existing methods with fewer parameters.", "conclusion": "DeeCLIP demonstrates superior robustness and generalization, with potential for lightweight adaptation."}}
{"id": "2504.18657", "pdf": "https://arxiv.org/pdf/2504.18657", "abs": "https://arxiv.org/abs/2504.18657", "authors": ["Benjamin Schiffer", "Lucas Janson"], "title": "Foundations of Safe Online Reinforcement Learning in the Linear Quadratic Regulator: $\\sqrt{T}$-Regret", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Understanding how to efficiently learn while adhering to safety constraints\nis essential for using online reinforcement learning in practical applications.\nHowever, proving rigorous regret bounds for safety-constrained reinforcement\nlearning is difficult due to the complex interaction between safety,\nexploration, and exploitation. In this work, we seek to establish foundations\nfor safety-constrained reinforcement learning by studying the canonical problem\nof controlling a one-dimensional linear dynamical system with unknown dynamics.\nWe study the safety-constrained version of this problem, where the state must\nwith high probability stay within a safe region, and we provide the first safe\nalgorithm that achieves regret of $\\tilde{O}_T(\\sqrt{T})$. Furthermore, the\nregret is with respect to the baseline of truncated linear controllers, a\nnatural baseline of non-linear controllers that are well-suited for\nsafety-constrained linear systems. In addition to introducing this new\nbaseline, we also prove several desirable continuity properties of the optimal\ncontroller in this baseline. In showing our main result, we prove that whenever\nthe constraints impact the optimal controller, the non-linearity of our\ncontroller class leads to a faster rate of learning than in the unconstrained\nsetting.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.20018", "pdf": "https://arxiv.org/pdf/2504.20018", "abs": "https://arxiv.org/abs/2504.20018", "authors": ["Jiongli Zhu", "Yue Wang", "Bailu Ding", "Philip A. Bernstein", "Vivek Narasayya", "Surajit Chaudhuri"], "title": "MINT: Multi-Vector Search Index Tuning", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Vector search plays a crucial role in many real-world applications. In\naddition to single-vector search, multi-vector search becomes important for\nmulti-modal and multi-feature scenarios today. In a multi-vector database, each\nrow is an item, each column represents a feature of items, and each cell is a\nhigh-dimensional vector. In multi-vector databases, the choice of indexes can\nhave a significant impact on performance. Although index tuning for relational\ndatabases has been extensively studied, index tuning for multi-vector search\nremains unclear and challenging. In this paper, we define multi-vector search\nindex tuning and propose a framework to solve it. Specifically, given a\nmulti-vector search workload, we develop algorithms to find indexes that\nminimize latency and meet storage and recall constraints. Compared to the\nbaseline, our latency achieves 2.1X to 8.3X speedup.", "AI": {"tldr": "The paper proposes a framework for tuning indexes in multi-vector databases to optimize latency while meeting storage and recall constraints, achieving significant speedup.", "motivation": "Multi-vector search is crucial for multi-modal and multi-feature scenarios, but index tuning for such databases is unclear and challenging.", "method": "The authors define multi-vector search index tuning and develop algorithms to find optimal indexes for given workloads.", "result": "The proposed framework achieves a 2.1X to 8.3X speedup in latency compared to baselines.", "conclusion": "The framework effectively addresses the challenge of index tuning in multi-vector databases, improving performance significantly."}}
{"id": "2504.13828", "pdf": "https://arxiv.org/pdf/2504.13828", "abs": "https://arxiv.org/abs/2504.13828", "authors": ["Shijie Xia", "Yiwei Qin", "Xuefeng Li", "Yan Ma", "Run-Ze Fan", "Steffi Chern", "Haoyang Zou", "Fan Zhou", "Xiangkun Hu", "Jiahe Jin", "Yanheng He", "Yixin Ye", "Yixiu Liu", "Pengfei Liu"], "title": "Generative AI Act II: Test Time Scaling Drives Cognition Engineering", "categories": ["cs.CL", "cs.AI"], "comment": "v3: add the comparison to existing work part; fix some errors", "summary": "The first generation of Large Language Models - what might be called \"Act I\"\nof generative AI (2020-2023) - achieved remarkable success through massive\nparameter and data scaling, yet exhibited fundamental limitations such as\nknowledge latency, shallow reasoning, and constrained cognitive processes.\nDuring this era, prompt engineering emerged as our primary interface with AI,\nenabling dialogue-level communication through natural language. We now witness\nthe emergence of \"Act II\" (2024-present), where models are transitioning from\nknowledge-retrieval systems (in latent space) to thought-construction engines\nthrough test-time scaling techniques. This new paradigm establishes a\nmind-level connection with AI through language-based thoughts. In this paper,\nwe clarify the conceptual foundations of cognition engineering and explain why\nthis moment is critical for its development. We systematically break down these\nadvanced approaches through comprehensive tutorials and optimized\nimplementations, democratizing access to cognition engineering and enabling\nevery practitioner to participate in AI's second act. We provide a regularly\nupdated collection of papers on test-time scaling in the GitHub Repository:\nhttps://github.com/GAIR-NLP/cognition-engineering", "AI": {"tldr": "The paper discusses the transition from early generative AI (Act I) to advanced cognition engineering (Act II), highlighting limitations of Act I and the potential of Act II.", "motivation": "To address the limitations of early generative AI (knowledge latency, shallow reasoning) and explore the potential of cognition engineering in Act II.", "method": "Systematic breakdown of advanced approaches through tutorials and optimized implementations, with a focus on test-time scaling techniques.", "result": "Democratization of cognition engineering, enabling broader participation in AI's second act.", "conclusion": "The paper emphasizes the critical moment for cognition engineering's development and provides resources for practitioners to engage with it."}}
{"id": "2504.19881", "pdf": "https://arxiv.org/pdf/2504.19881", "abs": "https://arxiv.org/abs/2504.19881", "authors": ["Claire Warwick", "Andrew Beresford", "Soazig Casteau", "Hubert P. H. Shum", "Dan Smith", "Francis Xiatian Zhang"], "title": "Using Fixed and Mobile Eye Tracking to Understand How Visitors View Art in a Museum: A Study at the Bowes Museum, County Durham, UK", "categories": ["cs.CV"], "comment": null, "summary": "The following paper describes a collaborative project involving researchers\nat Durham University, and professionals at the Bowes Museum, Barnard Castle,\nCounty Durham, UK, during which we used fixed and mobile eye tracking to\nunderstand how visitors view art. Our study took place during summer 2024 and\nbuilds on work presented at DH2017 (Bailey-Ross et al., 2017). Our\ninterdisciplinary team included researchers from digital humanities,\npsychology, art history and computer science, working in collaboration with\nprofessionals from the museum. We used fixed and mobile eye tracking to\nunderstand how museum visitors view art in a physical gallery setting. This\nresearch will enable us to make recommendations about how the Museum's\ncollections could be more effectively displayed, encouraging visitors to engage\nwith them more fully.", "AI": {"tldr": "Researchers used eye tracking to study how museum visitors view art, aiming to improve display effectiveness.", "motivation": "To understand visitor engagement with art in a gallery setting and enhance museum display strategies.", "method": "Fixed and mobile eye tracking during summer 2024, involving an interdisciplinary team.", "result": "Insights into visitor viewing behavior to inform better art display recommendations.", "conclusion": "Findings will help the museum optimize collections display for improved visitor engagement."}}
{"id": "2504.18695", "pdf": "https://arxiv.org/pdf/2504.18695", "abs": "https://arxiv.org/abs/2504.18695", "authors": ["Ladan Tazik", "James Stafford", "John Braun"], "title": "Local Polynomial Lp-norm Regression", "categories": ["stat.ML", "cs.LG", "stat.OT"], "comment": null, "summary": "The local least squares estimator for a regression curve cannot provide\noptimal results when non-Gaussian noise is present. Both theoretical and\nempirical evidence suggests that residuals often exhibit distributional\nproperties different from those of a normal distribution, making it worthwhile\nto consider estimation based on other norms. It is suggested that $L_p$-norm\nestimators be used to minimize the residuals when these exhibit non-normal\nkurtosis. In this paper, we propose a local polynomial $L_p$-norm regression\nthat replaces weighted least squares estimation with weighted $L_p$-norm\nestimation for fitting the polynomial locally. We also introduce a new method\nfor estimating the parameter $p$ from the residuals, enhancing the adaptability\nof the approach. Through numerical and theoretical investigation, we\ndemonstrate our method's superiority over local least squares in\none-dimensional data and show promising outcomes for higher dimensions,\nspecifically in 2D.", "AI": {"tldr": "The paper proposes a local polynomial $L_p$-norm regression method to handle non-Gaussian noise, outperforming traditional least squares, especially in 1D and 2D data.", "motivation": "Traditional least squares estimators fail under non-Gaussian noise, prompting the need for alternative norms like $L_p$-norm to better fit residuals with non-normal kurtosis.", "method": "The method replaces weighted least squares with weighted $L_p$-norm estimation for local polynomial fitting and introduces a way to estimate the parameter $p$ from residuals.", "result": "Numerical and theoretical results show the method's superiority over local least squares in 1D and promising performance in 2D.", "conclusion": "The $L_p$-norm regression is a robust alternative to least squares for non-Gaussian noise, with adaptability and improved performance."}}
{"id": "2504.20026", "pdf": "https://arxiv.org/pdf/2504.20026", "abs": "https://arxiv.org/abs/2504.20026", "authors": ["Zhengqin Li", "Dilin Wang", "Ka Chen", "Zhaoyang Lv", "Thu Nguyen-Phuoc", "Milim Lee", "Jia-Bin Huang", "Lei Xiao", "Cheng Zhang", "Yufeng Zhu", "Carl S. Marshall", "Yufeng Ren", "Richard Newcombe", "Zhao Dong"], "title": "LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by CVPR 2025", "summary": "We present Large Inverse Rendering Model (LIRM), a transformer architecture\nthat jointly reconstructs high-quality shape, materials, and radiance fields\nwith view-dependent effects in less than a second. Our model builds upon the\nrecent Large Reconstruction Models (LRMs) that achieve state-of-the-art\nsparse-view reconstruction quality. However, existing LRMs struggle to\nreconstruct unseen parts accurately and cannot recover glossy appearance or\ngenerate relightable 3D contents that can be consumed by standard Graphics\nengines. To address these limitations, we make three key technical\ncontributions to build a more practical multi-view 3D reconstruction framework.\nFirst, we introduce an update model that allows us to progressively add more\ninput views to improve our reconstruction. Second, we propose a hexa-plane\nneural SDF representation to better recover detailed textures, geometry and\nmaterial parameters. Third, we develop a novel neural directional-embedding\nmechanism to handle view-dependent effects. Trained on a large-scale shape and\nmaterial dataset with a tailored coarse-to-fine training scheme, our model\nachieves compelling results. It compares favorably to optimization-based\ndense-view inverse rendering methods in terms of geometry and relighting\naccuracy, while requiring only a fraction of the inference time.", "AI": {"tldr": "LIRM is a transformer-based model for fast, high-quality 3D reconstruction of shape, materials, and radiance fields, addressing limitations of existing methods with novel contributions like progressive view updates, hexa-plane neural SDF, and directional-embedding for view-dependent effects.", "motivation": "Existing Large Reconstruction Models (LRMs) lack accuracy in unseen parts, fail to recover glossy appearance, and cannot generate relightable 3D content. LIRM aims to overcome these limitations for practical multi-view 3D reconstruction.", "method": "LIRM introduces three key techniques: 1) progressive view updates, 2) hexa-plane neural SDF for detailed textures and geometry, and 3) neural directional-embedding for view-dependent effects. It uses a coarse-to-fine training scheme on a large dataset.", "result": "LIRM outperforms dense-view inverse rendering methods in geometry and relighting accuracy while being significantly faster, achieving high-quality reconstructions in under a second.", "conclusion": "LIRM provides a practical, efficient solution for high-quality 3D reconstruction with relightable outputs, advancing the state-of-the-art in inverse rendering."}}
{"id": "2504.15471", "pdf": "https://arxiv.org/pdf/2504.15471", "abs": "https://arxiv.org/abs/2504.15471", "authors": ["Tyler A. Chang", "Benjamin K. Bergen"], "title": "Bigram Subnetworks: Mapping to Next Tokens in Transformer Language Models", "categories": ["cs.CL"], "comment": null, "summary": "In Transformer language models, activation vectors transform from current\ntoken embeddings to next token predictions as they pass through the model. To\nisolate a minimal form of this transformation, we identify language model\nsubnetworks that make bigram predictions, naive next token predictions based\nonly on the current token. We find that bigram subnetworks can be found in\nfully trained language models up to 1B parameters, and these subnetworks are\ncritical for model performance even when they consist of less than 0.2% of\nmodel parameters. Bigram subnetworks are concentrated in the first Transformer\nMLP layer, and they overlap significantly with subnetworks trained to optimally\nprune a given model. Mechanistically, the bigram subnetworks often recreate a\npattern from the full models where the first layer induces a sharp change that\naligns activations with next token predictions rather than current token\nrepresentations. Our results demonstrate that bigram subnetworks comprise a\nminimal subset of parameters that are both necessary and sufficient for basic\nnext token predictions in language models, and they help drive the\ntransformation from current to next token activations in the residual stream.\nThese subnetworks can lay a foundation for studying more complex language model\ncircuits by building up from a minimal circuit.", "AI": {"tldr": "Bigram subnetworks in Transformer models are minimal, critical for performance, and concentrated in the first MLP layer, aiding next token predictions.", "motivation": "To isolate and understand the minimal transformation from current token embeddings to next token predictions in language models.", "method": "Identify and analyze bigram subnetworks in fully trained Transformer models up to 1B parameters.", "result": "Bigram subnetworks are essential (even with <0.2% of parameters), concentrated in the first MLP layer, and overlap with optimal pruning subnetworks.", "conclusion": "Bigram subnetworks are necessary and sufficient for basic next token predictions, providing a foundation for studying more complex circuits."}}
{"id": "2504.19882", "pdf": "https://arxiv.org/pdf/2504.19882", "abs": "https://arxiv.org/abs/2504.19882", "authors": ["Runhui Zhang", "Sijin Zhou", "Zhuang Qi"], "title": "Federated Out-of-Distribution Generalization: A Causal Augmentation View", "categories": ["cs.CV"], "comment": "IJCNN 2025 Accepted", "summary": "Federated learning aims to collaboratively model by integrating multi-source\ninformation to obtain a model that can generalize across all client data.\nExisting methods often leverage knowledge distillation or data augmentation to\nmitigate the negative impact of data bias across clients. However, the limited\nperformance of teacher models on out-of-distribution samples and the inherent\nquality gap between augmented and original data hinder their effectiveness and\nthey typically fail to leverage the advantages of incorporating rich contextual\ninformation. To address these limitations, this paper proposes a Federated\nCausal Augmentation method, termed FedCAug, which employs causality-inspired\ndata augmentation to break the spurious correlation between attributes and\ncategories. Specifically, it designs a causal region localization module to\naccurately identify and decouple the background and objects in the image,\nproviding rich contextual information for causal data augmentation.\nAdditionally, it designs a causality-inspired data augmentation module that\nintegrates causal features and within-client context to generate counterfactual\nsamples. This significantly enhances data diversity, and the entire process\ndoes not require any information sharing between clients, thereby contributing\nto the protection of data privacy. Extensive experiments conducted on three\ndatasets reveal that FedCAug markedly reduces the model's reliance on\nbackground to predict sample labels, achieving superior performance compared to\nstate-of-the-art methods.", "AI": {"tldr": "FedCAug introduces causality-inspired data augmentation in federated learning to break spurious correlations, enhancing model generalization without compromising privacy.", "motivation": "Existing federated learning methods struggle with data bias and limited contextual information, hindering performance on out-of-distribution samples.", "method": "FedCAug uses causal region localization and augmentation to decouple background and objects, generating counterfactual samples without inter-client data sharing.", "result": "FedCAug reduces reliance on background for predictions and outperforms state-of-the-art methods on three datasets.", "conclusion": "FedCAug effectively addresses data bias and privacy concerns in federated learning, improving model generalization."}}
{"id": "2504.18791", "pdf": "https://arxiv.org/pdf/2504.18791", "abs": "https://arxiv.org/abs/2504.18791", "authors": ["Uday Kiran Reddy Tadipatri", "Benjamin D. Haeffele", "Joshua Agterberg", "Ingvar Ziemann", "Ren\u00e9 Vidal"], "title": "Nonconvex Linear System Identification with Minimal State Representation", "categories": ["eess.SY", "cs.LG", "cs.SY", "eess.SP", "stat.ML"], "comment": "Accepted to 7th Annual Conference on Learning for Dynamics and\n  Control (L4DC) 2025. The full version including appendix", "summary": "Low-order linear System IDentification (SysID) addresses the challenge of\nestimating the parameters of a linear dynamical system from finite samples of\nobservations and control inputs with minimal state representation. Traditional\napproaches often utilize Hankel-rank minimization, which relies on convex\nrelaxations that can require numerous, costly singular value decompositions\n(SVDs) to optimize. In this work, we propose two nonconvex reformulations to\ntackle low-order SysID (i) Burer-Monterio (BM) factorization of the Hankel\nmatrix for efficient nuclear norm minimization, and (ii) optimizing directly\nover system parameters for real, diagonalizable systems with an atomic norm\nstyle decomposition. These reformulations circumvent the need for repeated\nheavy SVD computations, significantly improving computational efficiency.\nMoreover, we prove that optimizing directly over the system parameters yields\nlower statistical error rates, and lower sample complexities that do not scale\nlinearly with trajectory length like in Hankel-nuclear norm minimization.\nAdditionally, while our proposed formulations are nonconvex, we provide\ntheoretical guarantees of achieving global optimality in polynomial time.\nFinally, we demonstrate algorithms that solve these nonconvex programs and\nvalidate our theoretical claims on synthetic data.", "AI": {"tldr": "Proposes nonconvex reformulations for low-order linear system identification, improving efficiency and reducing statistical error compared to traditional Hankel-rank methods.", "motivation": "Traditional Hankel-rank minimization for SysID is computationally expensive due to repeated SVDs.", "method": "Uses Burer-Monterio factorization and direct optimization over system parameters to avoid SVDs.", "result": "Achieves lower statistical error, reduced sample complexity, and global optimality guarantees.", "conclusion": "Nonconvex approaches offer efficient, theoretically sound alternatives to traditional SysID methods."}}
{"id": "2209.04100", "pdf": "https://arxiv.org/pdf/2209.04100", "abs": "https://arxiv.org/abs/2209.04100", "authors": ["Xianqi Zhang", "Xingtao Wang", "Xu Liu", "Wenrui Wang", "Xiaopeng Fan", "Debin Zhao"], "title": "Task-Agnostic Learning to Accomplish New Tasks", "categories": ["cs.AI"], "comment": "14 pages, 10 figures, Accepted by IEEE-TCDS", "summary": "Reinforcement Learning (RL) and Imitation Learning (IL) have made great\nprogress in robotic decision-making in recent years. However, these methods\nshow obvious deterioration for new tasks that need to be completed through new\ncombinations of actions. RL methods suffer from reward functions and\ndistribution shifts, while IL methods are limited by expert demonstrations\nwhich do not cover new tasks. In contrast, humans can easily complete these\ntasks with the fragmented knowledge learned from task-agnostic experience.\nInspired by this observation, this paper proposes a task-agnostic learning\nmethod (TAL for short) that can learn fragmented knowledge only from\ntask-agnostic data to accomplish new tasks. TAL consists of four stages. First,\nthe task-agnostic exploration is performed to collect data from interactions\nwith the environment. The collected data is organized via a knowledge graph.\nSecond, an action feature extractor is proposed and trained using the collected\nknowledge graph data for task-agnostic fragmented knowledge learning. Third, a\ncandidate action generator is designed, which applies the action feature\nextractor on a new task to generate multiple candidate action sets. Finally, an\naction proposal network is designed to produce the probabilities for actions in\na new task according to the environmental information. The probabilities are\nthen used to generate order information for selecting actions to be executed\nfrom multiple candidate action sets to form the plan. Experiments on a virtual\nindoor scene show that the proposed method outperforms the state-of-the-art\noffline RL methods and IL methods by more than 20%.", "AI": {"tldr": "The paper introduces TAL, a task-agnostic learning method for robotic decision-making, outperforming RL and IL by 20%.", "motivation": "RL and IL struggle with new tasks due to reward functions, distribution shifts, and limited expert data. Humans use fragmented knowledge from task-agnostic experience, inspiring TAL.", "method": "TAL involves four stages: task-agnostic exploration, knowledge graph organization, action feature extraction, candidate action generation, and action proposal for new tasks.", "result": "TAL outperforms state-of-the-art offline RL and IL methods by over 20% in virtual indoor scene experiments.", "conclusion": "TAL effectively learns fragmented knowledge from task-agnostic data, enabling better performance on new tasks compared to RL and IL."}}
{"id": "2504.15900", "pdf": "https://arxiv.org/pdf/2504.15900", "abs": "https://arxiv.org/abs/2504.15900", "authors": ["Cheng Wen", "Tingwei Guo", "Shuaijiang Zhao", "Wei Zou", "Xiangang Li"], "title": "SARI: Structured Audio Reasoning via Curriculum-Guided Reinforcement Learning", "categories": ["cs.CL"], "comment": null, "summary": "Recent work shows that reinforcement learning(RL) can markedly sharpen the\nreasoning ability of large language models (LLMs) by prompting them to \"think\nbefore answering.\" Yet whether and how these gains transfer to audio-language\nreasoning remains largely unexplored. We extend the Group-Relative Policy\nOptimization (GRPO) framework from DeepSeek-R1 to a Large Audio-Language Model\n(LALM), and construct a 32k sample multiple-choice corpus. Using a two-stage\nregimen supervised fine-tuning on structured and unstructured\nchains-of-thought, followed by curriculum-guided GRPO, we systematically\ncompare implicit vs. explicit, and structured vs. free form reasoning under\nidentical architectures. Our structured audio reasoning model, SARI (Structured\nAudio Reasoning via Curriculum-Guided Reinforcement Learning), achieves a\n16.35% improvement in average accuracy over the base model\nQwen2-Audio-7B-Instruct. Furthermore, the variant built upon Qwen2.5-Omni\nreaches state-of-the-art performance of 67.08% on the MMAU test-mini benchmark.\nAblation experiments show that on the base model we use: (i) SFT warm-up is\nimportant for stable RL training, (ii) structured chains yield more robust\ngeneralization than unstructured ones, and (iii) easy-to-hard curricula\naccelerate convergence and improve final performance. These findings\ndemonstrate that explicit, structured reasoning and curriculum learning\nsubstantially enhances audio-language understanding.", "AI": {"tldr": "RL enhances audio-language reasoning via structured, curriculum-guided methods, achieving significant accuracy improvements.", "motivation": "Explore the transfer of RL gains from text to audio-language reasoning, addressing a gap in current research.", "method": "Extend GRPO to LALM, use a two-stage regimen (SFT and curriculum-guided GRPO), and compare reasoning types.", "result": "16.35% accuracy improvement over base model; SARI variant achieves 67.08% on MMAU benchmark.", "conclusion": "Structured reasoning and curriculum learning significantly boost audio-language understanding."}}
{"id": "2504.19888", "pdf": "https://arxiv.org/pdf/2504.19888", "abs": "https://arxiv.org/abs/2504.19888", "authors": ["Han Chen", "Anne L. Martel"], "title": "Enhancing breast cancer detection on screening mammogram using self-supervised learning and a hybrid deep model of Swin Transformer and Convolutional Neural Network", "categories": ["cs.CV"], "comment": null, "summary": "Purpose: The scarcity of high-quality curated labeled medical training data\nremains one of the major limitations in applying artificial intelligence (AI)\nsystems to breast cancer diagnosis. Deep models for mammogram analysis and mass\n(or micro-calcification) detection require training with a large volume of\nlabeled images, which are often expensive and time-consuming to collect. To\nreduce this challenge, we proposed a novel method that leverages\nself-supervised learning (SSL) and a deep hybrid model, named \\textbf{HybMNet},\nwhich combines local self-attention and fine-grained feature extraction to\nenhance breast cancer detection on screening mammograms.\n  Approach: Our method employs a two-stage learning process: (1) SSL\nPretraining: We utilize EsViT, a SSL technique, to pretrain a Swin Transformer\n(Swin-T) using a limited set of mammograms. The pretrained Swin-T then serves\nas the backbone for the downstream task. (2) Downstream Training: The proposed\nHybMNet combines the Swin-T backbone with a CNN-based network and a novel\nfusion strategy. The Swin-T employs local self-attention to identify\ninformative patch regions from the high-resolution mammogram, while the\nCNN-based network extracts fine-grained local features from the selected\npatches. A fusion module then integrates global and local information from both\nnetworks to generate robust predictions. The HybMNet is trained end-to-end,\nwith the loss function combining the outputs of the Swin-T and CNN modules to\noptimize feature extraction and classification performance.\n  Results: The proposed method was evaluated for its ability to detect breast\ncancer by distinguishing between benign (normal) and malignant mammograms.\nLeveraging SSL pretraining and the HybMNet model, it achieved AUC of 0.864 (95%\nCI: 0.852, 0.875) on the CMMD dataset and 0.889 (95% CI: 0.875, 0.903) on the\nINbreast dataset, highlighting its effectiveness.", "AI": {"tldr": "A novel method, HybMNet, combines self-supervised learning and a hybrid deep model to improve breast cancer detection in mammograms, achieving high AUC scores.", "motivation": "The scarcity of labeled medical data limits AI applications in breast cancer diagnosis, prompting the need for efficient training methods.", "method": "A two-stage process: SSL pretraining with EsViT and Swin-T, followed by downstream training with HybMNet (Swin-T + CNN) and a fusion module.", "result": "Achieved AUC of 0.864 on CMMD and 0.889 on INbreast datasets, demonstrating strong performance.", "conclusion": "HybMNet effectively addresses data scarcity and enhances breast cancer detection accuracy."}}
{"id": "2504.18830", "pdf": "https://arxiv.org/pdf/2504.18830", "abs": "https://arxiv.org/abs/2504.18830", "authors": ["Fran\u00e7ois-Xavier Briol", "Alexandra Gessner", "Toni Karvonen", "Maren Mahsereci"], "title": "A Dictionary of Closed-Form Kernel Mean Embeddings", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "stat.CO"], "comment": null, "summary": "Kernel mean embeddings -- integrals of a kernel with respect to a probability\ndistribution -- are essential in Bayesian quadrature, but also widely used in\nother computational tools for numerical integration or for statistical\ninference based on the maximum mean discrepancy. These methods often require,\nor are enhanced by, the availability of a closed-form expression for the kernel\nmean embedding. However, deriving such expressions can be challenging, limiting\nthe applicability of kernel-based techniques when practitioners do not have\naccess to a closed-form embedding. This paper addresses this limitation by\nproviding a comprehensive dictionary of known kernel mean embeddings, along\nwith practical tools for deriving new embeddings from known ones. We also\nprovide a Python library that includes minimal implementations of the\nembeddings.", "AI": {"tldr": "The paper provides a dictionary of kernel mean embeddings and tools for deriving new ones, along with a Python library for implementation.", "motivation": "Kernel mean embeddings are crucial in Bayesian quadrature and other computational tools, but deriving closed-form expressions is challenging, limiting their applicability.", "method": "The paper compiles known kernel mean embeddings and offers practical tools for deriving new ones, supported by a Python library.", "result": "A comprehensive resource of kernel mean embeddings and derivation tools is created, enhancing accessibility and usability.", "conclusion": "The work expands the applicability of kernel-based techniques by simplifying access to and derivation of kernel mean embeddings."}}
{"id": "2305.09200", "pdf": "https://arxiv.org/pdf/2305.09200", "abs": "https://arxiv.org/abs/2305.09200", "authors": ["Paolo Liberatore"], "title": "Representing states in iterated belief revision", "categories": ["cs.AI"], "comment": null, "summary": "Iterated belief revision requires information about the current beliefs. This\ninformation is represented by mathematical structures called doxastic states.\nMost literature concentrates on how to revise a doxastic state and neglects\nthat it may exponentially grow. This problem is studied for the most common\nways of storing a doxastic state. All four methods are able to store every\ndoxastic state, but some do it in less space than others. In particular, the\nexplicit representation (an enumeration of the current beliefs) is the more\nwasteful on space. The level representation (a sequence of propositional\nformulae) and the natural representation (a history of natural revisions) are\nmore compact than it. The lexicographic representation (a history of\nlexicographic revision) is even more compact than them.", "AI": {"tldr": "The paper compares four methods of storing doxastic states for iterated belief revision, highlighting their space efficiency.", "motivation": "Address the exponential growth problem of doxastic states in belief revision, often overlooked in literature.", "method": "Analyzes four storage methods: explicit representation, level representation, natural representation, and lexicographic representation.", "result": "Lexicographic representation is the most space-efficient, followed by natural and level representations, while explicit representation is the least efficient.", "conclusion": "Space efficiency varies significantly across methods, with lexicographic representation being the most compact for storing doxastic states."}}
{"id": "2504.16286", "pdf": "https://arxiv.org/pdf/2504.16286", "abs": "https://arxiv.org/abs/2504.16286", "authors": ["Li Weigang", "Pedro Carvalho Brom"], "title": "The Paradox of Poetic Intent in Back-Translation: Evaluating the Quality of Large Language Models in Chinese Translation", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "24 pages, 3 figures", "summary": "The rapid advancement of large language models (LLMs) has reshaped the\nlandscape of machine translation, yet challenges persist in preserving poetic\nintent, cultural heritage, and handling specialized terminology in\nChinese-English translation. This study constructs a diverse corpus\nencompassing Chinese scientific terminology, historical translation paradoxes,\nand literary metaphors. Utilizing a back-translation and Friedman test-based\nevaluation system (BT-Fried), we evaluate BLEU, CHRF, TER, and semantic\nsimilarity metrics across six major LLMs (e.g., GPT-4.5, DeepSeek V3) and three\ntraditional translation tools. Key findings include: (1) Scientific abstracts\noften benefit from back-translation, while traditional tools outperform LLMs in\nlinguistically distinct texts; (2) LLMs struggle with cultural and literary\nretention, exemplifying the \"paradox of poetic intent\"; (3) Some models exhibit\n\"verbatim back-translation\", reflecting emergent memory behavior; (4) A novel\nBLEU variant using Jieba segmentation and n-gram weighting is proposed. The\nstudy contributes to the empirical evaluation of Chinese NLP performance and\nadvances understanding of cultural fidelity in AI-mediated translation.", "AI": {"tldr": "The study evaluates LLMs and traditional tools for Chinese-English translation, highlighting challenges in cultural and poetic retention, and proposes a new BLEU variant.", "motivation": "Addressing the challenges in preserving poetic intent, cultural heritage, and specialized terminology in Chinese-English translation using LLMs.", "method": "Constructs a diverse corpus and uses a BT-Fried evaluation system to assess BLEU, CHRF, TER, and semantic similarity across six LLMs and three traditional tools.", "result": "LLMs struggle with cultural and literary retention, while traditional tools excel in distinct texts. A new BLEU variant is proposed.", "conclusion": "The study advances empirical evaluation of Chinese NLP and cultural fidelity in AI translation."}}
{"id": "2504.19894", "pdf": "https://arxiv.org/pdf/2504.19894", "abs": "https://arxiv.org/abs/2504.19894", "authors": ["Quynh Phung", "Long Mai", "Fabian David Caba Heilbron", "Feng Liu", "Jia-Bin Huang", "Cusuh Ham"], "title": "CineVerse: Consistent Keyframe Synthesis for Cinematic Scene Composition", "categories": ["cs.CV"], "comment": "link website: https://cinevers.github.io/", "summary": "We present CineVerse, a novel framework for the task of cinematic scene\ncomposition. Similar to traditional multi-shot generation, our task emphasizes\nthe need for consistency and continuity across frames. However, our task also\nfocuses on addressing challenges inherent to filmmaking, such as multiple\ncharacters, complex interactions, and visual cinematic effects. In order to\nlearn to generate such content, we first create the CineVerse dataset. We use\nthis dataset to train our proposed two-stage approach. First, we prompt a large\nlanguage model (LLM) with task-specific instructions to take in a high-level\nscene description and generate a detailed plan for the overall setting and\ncharacters, as well as the individual shots. Then, we fine-tune a text-to-image\ngeneration model to synthesize high-quality visual keyframes. Experimental\nresults demonstrate that CineVerse yields promising improvements in generating\nvisually coherent and contextually rich movie scenes, paving the way for\nfurther exploration in cinematic video synthesis.", "AI": {"tldr": "CineVerse is a framework for cinematic scene composition, addressing challenges like multi-character interactions and visual effects. It uses a two-stage approach: LLM-based planning and text-to-image synthesis, showing promising results.", "motivation": "To tackle the challenges of cinematic scene generation, such as consistency, multiple characters, and visual effects, which traditional multi-shot generation lacks.", "method": "A two-stage approach: 1) LLM generates detailed scene and shot plans from high-level descriptions; 2) Text-to-image model synthesizes keyframes.", "result": "CineVerse improves visual coherence and contextual richness in movie scenes.", "conclusion": "The framework shows potential for advancing cinematic video synthesis."}}
{"id": "2504.18860", "pdf": "https://arxiv.org/pdf/2504.18860", "abs": "https://arxiv.org/abs/2504.18860", "authors": ["Ken-Joel Simmoteit", "Philipp Schillinger", "Leonel Rozo"], "title": "Diffeomorphic Obstacle Avoidance for Contractive Dynamical Systems via Implicit Representations", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted at R:SS 2025", "summary": "Ensuring safety and robustness of robot skills is becoming crucial as robots\nare required to perform increasingly complex and dynamic tasks. The former is\nessential when performing tasks in cluttered environments, while the latter is\nrelevant to overcome unseen task situations. This paper addresses the challenge\nof ensuring both safety and robustness in dynamic robot skills learned from\ndemonstrations. Specifically, we build on neural contractive dynamical systems\nto provide robust extrapolation of the learned skills, while designing a\nfull-body obstacle avoidance strategy that preserves contraction stability via\ndiffeomorphic transforms. This is particularly crucial in complex environments\nwhere implicit scene representations, such as Signed Distance Fields (SDFs),\nare necessary. To this end, our framework called Signed Distance Field\nDiffeomorphic Transform, leverages SDFs and flow-based diffeomorphisms to\nachieve contraction-preserving obstacle avoidance. We thoroughly evaluate our\nframework on synthetic datasets and several real-world robotic tasks in a\nkitchen environment. Our results show that our approach locally adapts the\nlearned contractive vector field while staying close to the learned dynamics\nand without introducing highly-curved motion paths, thus outperforming several\nstate-of-the-art methods.", "AI": {"tldr": "The paper proposes a framework for ensuring safety and robustness in robot skills by combining neural contractive dynamical systems with obstacle avoidance via diffeomorphic transforms, leveraging SDFs for complex environments.", "motivation": "As robots tackle more complex tasks, ensuring safety in cluttered environments and robustness against unseen situations becomes critical.", "method": "The framework uses neural contractive dynamical systems for robust skill extrapolation and integrates a full-body obstacle avoidance strategy via diffeomorphic transforms, utilizing SDFs for scene representation.", "result": "Evaluations on synthetic and real-world tasks show the framework adapts learned dynamics locally, avoids obstacles effectively, and outperforms existing methods.", "conclusion": "The approach successfully balances safety and robustness in dynamic robot skills, demonstrating superior performance in complex environments."}}
{"id": "2402.15445", "pdf": "https://arxiv.org/pdf/2402.15445", "abs": "https://arxiv.org/abs/2402.15445", "authors": ["Paolo Liberatore"], "title": "Can we forget how we learned? Doxastic redundancy in iterated belief revision", "categories": ["cs.AI"], "comment": "formerly part of arXiv:2305.09200", "summary": "Forgetting a belief acquisition episode may not cause information loss\nbecause of the others. Checking whether it does is not obvious, as the\ncontribution of each belief revision is not isolated from the others, and the\nsame information may be given not directly but by deduction. An algorithm for\nchecking whether forgetting reduces information is given for a number of\niterated belief revision operators: lexicographic, natural, severe, plain\nsevere, moderate severe, restrained, very radical and full meet revisions. It\nmay take exponential time in the worst case, which is expected given that the\nproblem is coNP-hard, even in the Horn restriction. It is in coNP for\nhomogeneous sequences of lexicographic revisions.", "AI": {"tldr": "Forgetting belief revisions may not lose information due to indirect deductions. An algorithm checks this for various belief revision operators, with exponential worst-case time, coNP-hard complexity, and coNP for homogeneous lexicographic sequences.", "motivation": "To determine if forgetting belief acquisition episodes causes information loss, considering indirect deductions and multiple belief revisions.", "method": "An algorithm is developed to check information loss for iterated belief revision operators (lexicographic, natural, severe, etc.), analyzing computational complexity.", "result": "The algorithm may take exponential time (coNP-hard in worst case) but is in coNP for homogeneous lexicographic sequences.", "conclusion": "Forgetting belief revisions doesn't always lose information due to deductions, but verifying this is computationally challenging."}}
{"id": "2504.16511", "pdf": "https://arxiv.org/pdf/2504.16511", "abs": "https://arxiv.org/abs/2504.16511", "authors": ["Fengze Liu", "Weidong Zhou", "Binbin Liu", "Zhimiao Yu", "Yifan Zhang", "Haobin Lin", "Yifeng Yu", "Bingni Zhang", "Xiaohuan Zhou", "Taifeng Wang", "Yong Cao"], "title": "QuaDMix: Quality-Diversity Balanced Data Selection for Efficient LLM Pretraining", "categories": ["cs.CL"], "comment": null, "summary": "Quality and diversity are two critical metrics for the training data of large\nlanguage models (LLMs), positively impacting performance. Existing studies\noften optimize these metrics separately, typically by first applying quality\nfiltering and then adjusting data proportions. However, these approaches\noverlook the inherent trade-off between quality and diversity, necessitating\ntheir joint consideration. Given a fixed training quota, it is essential to\nevaluate both the quality of each data point and its complementary effect on\nthe overall dataset. In this paper, we introduce a unified data selection\nframework called QuaDMix, which automatically optimizes the data distribution\nfor LLM pretraining while balancing both quality and diversity. Specifically,\nwe first propose multiple criteria to measure data quality and employ domain\nclassification to distinguish data points, thereby measuring overall diversity.\nQuaDMix then employs a unified parameterized data sampling function that\ndetermines the sampling probability of each data point based on these quality\nand diversity related labels. To accelerate the search for the optimal\nparameters involved in the QuaDMix framework, we conduct simulated experiments\non smaller models and use LightGBM for parameters searching, inspired by the\nRegMix method. Our experiments across diverse models and datasets demonstrate\nthat QuaDMix achieves an average performance improvement of 7.2% across\nmultiple benchmarks. These results outperform the independent strategies for\nquality and diversity, highlighting the necessity and ability to balance data\nquality and diversity.", "AI": {"tldr": "QuaDMix is a unified data selection framework for LLM pretraining that jointly optimizes data quality and diversity, achieving a 7.2% performance improvement.", "motivation": "Existing methods optimize quality and diversity separately, ignoring their trade-off, which limits LLM performance.", "method": "QuaDMix uses quality criteria and domain classification for diversity, then employs a parameterized sampling function. Simulated experiments and LightGBM optimize parameters.", "result": "QuaDMix improves performance by 7.2% on average, outperforming separate quality/diversity strategies.", "conclusion": "Balancing quality and diversity is essential for LLM pretraining, and QuaDMix effectively achieves this."}}
{"id": "2504.19935", "pdf": "https://arxiv.org/pdf/2504.19935", "abs": "https://arxiv.org/abs/2504.19935", "authors": ["Xiem HoangVan", "Hieu Bui Minh", "Sang NguyenQuang", "Wen-Hsiao Peng"], "title": "Enhancing Quality for VVC Compressed Videos with Omniscient Quality Enhancement Model", "categories": ["cs.CV"], "comment": null, "summary": "The latest video coding standard H.266/VVC has shown its great improvement in\nterms of compression performance when compared to its predecessor HEVC\nstandard. Though VVC was implemented with many advanced techniques, it still\nmet the same challenges as its predecessor due to the need for even higher\nperceptual quality demand at the decoder side as well as the compression\nperformance at the encoder side. The advancement of Artificial Intelligence\n(AI) technology, notably the deep learning-based video quality enhancement\nmethods, was shown to be a promising approach to improving the perceptual\nquality experience. In this paper, we propose a novel Omniscient video quality\nenhancement Network for VVC compressed Videos. The Omniscient Network for\ncompressed video quality enhancement was originally designed for HEVC\ncompressed videos in which not only the spatial-temporal features but also\ncross-frequencies information were employed to augment the visual quality.\nInspired by this work, we propose a modification of the OVQE model and\nintegrate it into the lasted STD-VVC (Standard Versatile Video Coding) decoder\narchitecture. As assessed in a rich set of test conditions, the proposed\nOVQE-VVC solution is able to achieve significant PSNR improvement, notably\naround 0.74 dB and up to 1.2 dB with respect to the original STD-VVC codec.\nThis also corresponds to around 19.6% of bitrate saving while keeping a similar\nquality observation.", "AI": {"tldr": "The paper proposes an Omniscient video quality enhancement Network (OVQE-VVC) for VVC compressed videos, achieving significant PSNR improvement and bitrate savings.", "motivation": "Despite advancements in VVC, challenges remain in perceptual quality and compression performance. AI-based methods, like deep learning, offer potential solutions.", "method": "A modified OVQE model, originally for HEVC, is integrated into the VVC decoder, leveraging spatial-temporal and cross-frequency features.", "result": "OVQE-VVC achieves PSNR improvements of 0.74 dB to 1.2 dB and ~19.6% bitrate savings compared to the original VVC codec.", "conclusion": "The proposed OVQE-VVC effectively enhances video quality and compression efficiency, demonstrating its potential for practical applications."}}
{"id": "2504.18868", "pdf": "https://arxiv.org/pdf/2504.18868", "abs": "https://arxiv.org/abs/2504.18868", "authors": ["David Sychrovsk\u00fd", "Christopher Solinas", "Revan MacQueen", "Kevin Wang", "James R. Wright", "Nathan R. Sturtevant", "Michael Bowling"], "title": "Approximating Nash Equilibria in General-Sum Games via Meta-Learning", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "Nash equilibrium is perhaps the best-known solution concept in game theory.\nSuch a solution assigns a strategy to each player which offers no incentive to\nunilaterally deviate. While a Nash equilibrium is guaranteed to always exist,\nthe problem of finding one in general-sum games is PPAD-complete, generally\nconsidered intractable. Regret minimization is an efficient framework for\napproximating Nash equilibria in two-player zero-sum games. However, in\ngeneral-sum games, such algorithms are only guaranteed to converge to a\ncoarse-correlated equilibrium (CCE), a solution concept where players can\ncorrelate their strategies. In this work, we use meta-learning to minimize the\ncorrelations in strategies produced by a regret minimizer. This encourages the\nregret minimizer to find strategies that are closer to a Nash equilibrium. The\nmeta-learned regret minimizer is still guaranteed to converge to a CCE, but we\ngive a bound on the distance to Nash equilibrium in terms of our meta-loss. We\nevaluate our approach in general-sum imperfect information games. Our\nalgorithms provide significantly better approximations of Nash equilibria than\nstate-of-the-art regret minimization techniques.", "AI": {"tldr": "The paper proposes using meta-learning to reduce correlations in strategies from regret minimization, improving Nash equilibrium approximations in general-sum games.", "motivation": "Existing regret minimization methods in general-sum games only guarantee convergence to coarse-correlated equilibria (CCE), not Nash equilibria, which are more desirable.", "method": "Meta-learning is applied to minimize correlations in strategies generated by a regret minimizer, pushing results closer to Nash equilibrium.", "result": "The meta-learned regret minimizer achieves better Nash equilibrium approximations than state-of-the-art techniques in general-sum imperfect information games.", "conclusion": "Meta-learning enhances regret minimization, bridging the gap between CCE and Nash equilibrium in general-sum games."}}
{"id": "2407.06443", "pdf": "https://arxiv.org/pdf/2407.06443", "abs": "https://arxiv.org/abs/2407.06443", "authors": ["Qizhang Feng", "Siva Rajesh Kasa", "Santhosh Kumar Kasa", "Hyokun Yun", "Choon Hui Teo", "Sravan Babu Bodapati"], "title": "Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have seen widespread adoption due to their\nremarkable natural language capabilities. However, when deploying them in\nreal-world settings, it is important to align LLMs to generate texts according\nto acceptable human standards. Methods such as Proximal Policy Optimization\n(PPO) and Direct Preference Optimization (DPO) have enabled significant\nprogress in refining LLMs using human preference data. However, the privacy\nconcerns inherent in utilizing such preference data have yet to be adequately\nstudied. In this paper, we investigate the vulnerability of LLMs aligned using\ntwo widely used methods - DPO and PPO - to membership inference attacks (MIAs).\nOur study has two main contributions: first, we theoretically motivate that DPO\nmodels are more vulnerable to MIA compared to PPO models; second, we introduce\na novel reference-based attack framework specifically for analyzing preference\ndata called PREMIA (\\uline{Pre}ference data \\uline{MIA}). Using PREMIA and\nexisting baselines we empirically show that DPO models have a relatively\nheightened vulnerability towards MIA.", "AI": {"tldr": "The paper examines the vulnerability of LLMs aligned with DPO and PPO to membership inference attacks, finding DPO models more susceptible and introducing a new attack framework, PREMIA.", "motivation": "To address privacy concerns in LLM alignment using human preference data, focusing on vulnerabilities to membership inference attacks.", "method": "Theoretical analysis and empirical evaluation using PREMIA and existing baselines to compare DPO and PPO models.", "result": "DPO models are more vulnerable to membership inference attacks than PPO models.", "conclusion": "The study highlights privacy risks in LLM alignment methods and proposes PREMIA for analyzing preference data vulnerabilities."}}
{"id": "2504.16778", "pdf": "https://arxiv.org/pdf/2504.16778", "abs": "https://arxiv.org/abs/2504.16778", "authors": ["Sarah Jabbour", "Trenton Chang", "Anindya Das Antar", "Joseph Peper", "Insu Jang", "Jiachen Liu", "Jae-Won Chung", "Shiqi He", "Michael Wellman", "Bryan Goodman", "Elizabeth Bondi-Kelly", "Kevin Samy", "Rada Mihalcea", "Mosharaf Chowdhury", "David Jurgens", "Lu Wang"], "title": "Evaluation Framework for AI Systems in \"the Wild\"", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "35 pages", "summary": "Generative AI (GenAI) models have become vital across industries, yet current\nevaluation methods have not adapted to their widespread use. Traditional\nevaluations often rely on benchmarks and fixed datasets, frequently failing to\nreflect real-world performance, which creates a gap between lab-tested outcomes\nand practical applications. This white paper proposes a comprehensive framework\nfor how we should evaluate real-world GenAI systems, emphasizing diverse,\nevolving inputs and holistic, dynamic, and ongoing assessment approaches. The\npaper offers guidance for practitioners on how to design evaluation methods\nthat accurately reflect real-time capabilities, and provides policymakers with\nrecommendations for crafting GenAI policies focused on societal impacts, rather\nthan fixed performance numbers or parameter sizes. We advocate for holistic\nframeworks that integrate performance, fairness, and ethics and the use of\ncontinuous, outcome-oriented methods that combine human and automated\nassessments while also being transparent to foster trust among stakeholders.\nImplementing these strategies ensures GenAI models are not only technically\nproficient but also ethically responsible and impactful.", "AI": {"tldr": "The paper proposes a dynamic, holistic framework for evaluating GenAI systems in real-world settings, focusing on diverse inputs, ethics, and societal impact.", "motivation": "Current evaluation methods for GenAI rely on static benchmarks, failing to reflect real-world performance and societal implications.", "method": "The paper suggests a comprehensive framework combining continuous, outcome-oriented assessments, human and automated evaluations, and transparency.", "result": "The proposed framework ensures GenAI models are technically proficient, ethically responsible, and impactful.", "conclusion": "The paper advocates for evolving evaluation methods that prioritize real-world applicability, fairness, and trust among stakeholders."}}
{"id": "2504.19938", "pdf": "https://arxiv.org/pdf/2504.19938", "abs": "https://arxiv.org/abs/2504.19938", "authors": ["Yunfei Wan", "Jianheng Liu", "Jiarong Lin", "Fu Zhang"], "title": "Mesh-Learner: Texturing Mesh with Spherical Harmonics", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "In this paper, we present a 3D reconstruction and rendering framework termed\nMesh-Learner that is natively compatible with traditional rasterization\npipelines. It integrates mesh and spherical harmonic (SH) texture (i.e.,\ntexture filled with SH coefficients) into the learning process to learn each\nmesh s view-dependent radiance end-to-end. Images are rendered by interpolating\nsurrounding SH Texels at each pixel s sampling point using a novel\ninterpolation method. Conversely, gradients from each pixel are back-propagated\nto the related SH Texels in SH textures. Mesh-Learner exploits graphic features\nof rasterization pipeline (texture sampling, deferred rendering) to render,\nwhich makes Mesh-Learner naturally compatible with tools (e.g., Blender) and\ntasks (e.g., 3D reconstruction, scene rendering, reinforcement learning for\nrobotics) that are based on rasterization pipelines. Our system can train vast,\nunlimited scenes because we transfer only the SH textures within the frustum to\nthe GPU for training. At other times, the SH textures are stored in CPU RAM,\nwhich results in moderate GPU memory usage. The rendering results on\ninterpolation and extrapolation sequences in the Replica and FAST-LIVO2\ndatasets achieve state-of-the-art performance compared to existing\nstate-of-the-art methods (e.g., 3D Gaussian Splatting and M2-Mapping). To\nbenefit the society, the code will be available at\nhttps://github.com/hku-mars/Mesh-Learner.", "AI": {"tldr": "Mesh-Learner is a 3D reconstruction and rendering framework compatible with rasterization pipelines, using mesh and SH textures for view-dependent radiance learning. It achieves state-of-the-art performance with efficient GPU memory usage.", "motivation": "To create a 3D reconstruction and rendering framework that integrates seamlessly with traditional rasterization pipelines and tools like Blender, while efficiently handling large scenes.", "method": "The framework combines mesh and SH textures, using a novel interpolation method for rendering and back-propagating gradients to SH Texels. It leverages rasterization pipeline features for compatibility.", "result": "Achieves state-of-the-art performance on Replica and FAST-LIVO2 datasets, with efficient GPU memory usage by storing SH textures in CPU RAM when not in use.", "conclusion": "Mesh-Learner offers a scalable, efficient, and compatible solution for 3D reconstruction and rendering, with potential applications in robotics and scene rendering."}}
{"id": "2504.18897", "pdf": "https://arxiv.org/pdf/2504.18897", "abs": "https://arxiv.org/abs/2504.18897", "authors": ["Yuha Park", "Kunwoong Kim", "Insung Kong", "Yongdai Kim"], "title": "ReLU integral probability metric and its applications", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "49 pages, 9 figures", "summary": "We propose a parametric integral probability metric (IPM) to measure the\ndiscrepancy between two probability measures. The proposed IPM leverages a\nspecific parametric family of discriminators, such as single-node neural\nnetworks with ReLU activation, to effectively distinguish between\ndistributions, making it applicable in high-dimensional settings. By optimizing\nover the parameters of the chosen discriminator class, the proposed IPM\ndemonstrates that its estimators have good convergence rates and can serve as a\nsurrogate for other IPMs that use smooth nonparametric discriminator classes.\nWe present an efficient algorithm for practical computation, offering a simple\nimplementation and requiring fewer hyperparameters. Furthermore, we explore its\napplications in various tasks, such as covariate balancing for causal inference\nand fair representation learning. Across such diverse applications, we\ndemonstrate that the proposed IPM provides strong theoretical guarantees, and\nempirical experiments show that it achieves comparable or even superior\nperformance to other methods.", "AI": {"tldr": "A parametric IPM using neural networks for distribution discrepancy measurement, with strong theoretical and empirical performance.", "motivation": "To create a scalable and efficient method for measuring distribution discrepancies in high-dimensional settings.", "method": "Uses parametric discriminators (e.g., single-node ReLU networks) and optimizes their parameters for convergence and applicability.", "result": "Achieves good convergence rates, simpler implementation, and outperforms other methods in tasks like causal inference and fair learning.", "conclusion": "The proposed IPM is efficient, versatile, and performs comparably or better than existing methods."}}
{"id": "2408.13918", "pdf": "https://arxiv.org/pdf/2408.13918", "abs": "https://arxiv.org/abs/2408.13918", "authors": ["Siyu Li", "Toan Tran", "Haowen Lin", "John Krumm", "Cyrus Shahabi", "Lingyi Zhao", "Khurram Shafique", "Li Xiong"], "title": "Geo-Llama: Leveraging LLMs for Human Mobility Trajectory Generation with Spatiotemporal Constraints", "categories": ["cs.AI"], "comment": null, "summary": "Generating realistic human mobility data is essential for various application\ndomains, including transportation, urban planning, and epidemic control, as\nreal data is often inaccessible to researchers due to high costs and privacy\nconcerns. Existing deep generative models learn from real trajectories to\ngenerate synthetic ones. Despite the progress, most of them suffer from\ntraining stability issues and scale poorly with increasing data size. More\nimportantly, they often lack control mechanisms to guide the generated\ntrajectories under constraints such as enforcing specific visits. To address\nthese limitations, we formally define the controlled trajectory generation\nproblem for effectively handling multiple spatiotemporal constraints. We\nintroduce Geo-Llama, a novel LLM finetuning framework that can enforce multiple\nexplicit visit constraints while maintaining contextual coherence of the\ngenerated trajectories. In this approach, pre-trained LLMs are fine-tuned on\ntrajectory data with a visit-wise permutation strategy where each visit\ncorresponds to a specific time and location. This strategy enables the model to\ncapture spatiotemporal patterns regardless of visit orders while maintaining\nflexible and in-context constraint integration through prompts during\ngeneration. Extensive experiments on real-world and synthetic datasets validate\nthe effectiveness of Geo-Llama, demonstrating its versatility and robustness in\nhandling a broad range of constraints to generate more realistic trajectories\ncompared to existing methods.", "AI": {"tldr": "Geo-Llama is a novel LLM framework for generating realistic human mobility trajectories under multiple spatiotemporal constraints, outperforming existing methods.", "motivation": "Real human mobility data is often inaccessible due to costs and privacy concerns, and existing generative models lack control mechanisms for constraints like specific visits.", "method": "Geo-Llama fine-tunes pre-trained LLMs on trajectory data using a visit-wise permutation strategy, enabling flexible constraint integration via prompts.", "result": "Experiments show Geo-Llama effectively handles diverse constraints and generates more realistic trajectories than existing methods.", "conclusion": "Geo-Llama addresses limitations of current models, offering a robust solution for controlled trajectory generation."}}
{"id": "2504.16884", "pdf": "https://arxiv.org/pdf/2504.16884", "abs": "https://arxiv.org/abs/2504.16884", "authors": ["Joseph M. Denning", "Xiaohan Hannah Guo", "Bryor Snefjella", "Idan A. Blank"], "title": "Do Large Language Models know who did what to whom?", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are commonly criticized for not understanding\nlanguage. However, many critiques focus on cognitive abilities that, in humans,\nare distinct from language processing. Here, we instead study a kind of\nunderstanding tightly linked to language: inferring who did what to whom\n(thematic roles) in a sentence. Does the central training objective of\nLLMs-word prediction-result in sentence representations that capture thematic\nroles? In two experiments, we characterized sentence representations in four\nLLMs. In contrast to human similarity judgments, in LLMs the overall\nrepresentational similarity of sentence pairs reflected syntactic similarity\nbut not whether their agent and patient assignments were identical vs.\nreversed. Furthermore, we found little evidence that thematic role information\nwas available in any subset of hidden units. However, some attention heads\nrobustly captured thematic roles, independently of syntax. Therefore, LLMs can\nextract thematic roles but, relative to humans, this information influences\ntheir representations more weakly.", "AI": {"tldr": "LLMs' sentence representations prioritize syntax over thematic roles, but some attention heads can capture thematic roles independently.", "motivation": "To assess whether LLMs' word prediction training results in representations that capture thematic roles (who did what to whom).", "method": "Analyzed sentence representations in four LLMs, comparing them to human similarity judgments and examining hidden units and attention heads.", "result": "LLMs' representations reflected syntactic similarity but not thematic role assignments. Thematic roles were weakly captured, mainly by some attention heads.", "conclusion": "LLMs can extract thematic roles, but this information is less influential in their representations compared to humans."}}
{"id": "2504.19970", "pdf": "https://arxiv.org/pdf/2504.19970", "abs": "https://arxiv.org/abs/2504.19970", "authors": ["Narges Rashvand", "Ghazal Alinezhad Noghre", "Armin Danesh Pazho", "Babak Rahimi Ardabili", "Hamed Tabkhi"], "title": "Shopformer: Transformer-Based Framework for Detecting Shoplifting via Human Pose", "categories": ["cs.CV"], "comment": null, "summary": "Shoplifting remains a costly issue for the retail sector, but traditional\nsurveillance systems, which are mostly based on human monitoring, are still\nlargely ineffective, with only about 2% of shoplifters being arrested. Existing\nAI-based approaches rely on pixel-level video analysis which raises privacy\nconcerns, is sensitive to environmental variations, and demands significant\ncomputational resources. To address these limitations, we introduce Shopformer,\na novel transformer-based model that detects shoplifting by analyzing pose\nsequences rather than raw video. We propose a custom tokenization strategy that\nconverts pose sequences into compact embeddings for efficient transformer\nprocessing. To the best of our knowledge, this is the first pose-sequence-based\ntransformer model for shoplifting detection. Evaluated on real-world pose data,\nour method outperforms state-of-the-art anomaly detection models, offering a\nprivacy-preserving, and scalable solution for real-time retail surveillance.\nThe code base for this work is available at\nhttps://github.com/TeCSAR-UNCC/Shopformer.", "AI": {"tldr": "Shopformer is a transformer-based model for shoplifting detection using pose sequences, offering privacy and efficiency over traditional video analysis.", "motivation": "Traditional surveillance and AI-based video analysis are ineffective, privacy-invasive, and resource-heavy.", "method": "Uses pose sequences and custom tokenization for transformer processing.", "result": "Outperforms state-of-the-art anomaly detection models on real-world data.", "conclusion": "Provides a privacy-preserving, scalable solution for retail surveillance."}}
{"id": "2504.18911", "pdf": "https://arxiv.org/pdf/2504.18911", "abs": "https://arxiv.org/abs/2504.18911", "authors": ["Benedict Leimkuhler", "Ren\u00e9 Lohmann", "Peter Whalley"], "title": "A Langevin sampling algorithm inspired by the Adam optimizer", "categories": ["stat.CO", "cs.LG", "stat.ML", "60J22, 62-08, 82C31, 65C05, 65C30, 65C40"], "comment": null, "summary": "We present a framework for adaptive-stepsize MCMC sampling based on\ntime-rescaled Langevin dynamics, in which the stepsize variation is dynamically\ndriven by an additional degree of freedom. Our approach augments the phase\nspace by an additional variable which in turn defines a time\nreparameterization. The use of an auxiliary relaxation equation allows\naccumulation of a moving average of a local monitor function and provides for\nprecise control of the timestep while circumventing the need to modify the\ndrift term in the physical system. Our algorithm is straightforward to\nimplement and can be readily combined with any off-the-peg fixed-stepsize\nLangevin integrator. As a particular example, we consider control of the\nstepsize by monitoring the norm of the log-posterior gradient, which takes\ninspiration from the Adam optimizer, the stepsize being automatically reduced\nin regions of steep change of the log posterior and increased on plateaus,\nimproving numerical stability and convergence speed. As in Adam, the stepsize\nvariation depends on the recent history of the gradient norm, which enhances\nstability and improves accuracy compared to more immediate control approaches.\nWe demonstrate the potential benefit of this method--both in accuracy and in\nstability--in numerical experiments including Neal's funnel and a Bayesian\nneural network for classification of MNIST data.", "AI": {"tldr": "A framework for adaptive-stepsize MCMC sampling using time-rescaled Langevin dynamics, dynamically adjusting stepsize via an auxiliary variable for improved stability and convergence.", "motivation": "To enhance MCMC sampling by dynamically controlling stepsize without modifying the drift term, improving numerical stability and convergence speed.", "method": "Augments phase space with an auxiliary variable for time reparameterization, using a relaxation equation to adjust stepsize based on a local monitor function (e.g., gradient norm).", "result": "Demonstrated improved accuracy and stability in experiments, including Neal's funnel and a Bayesian neural network for MNIST classification.", "conclusion": "The framework is easy to implement, compatible with fixed-stepsize integrators, and enhances sampling efficiency and stability."}}
{"id": "2409.09013", "pdf": "https://arxiv.org/pdf/2409.09013", "abs": "https://arxiv.org/abs/2409.09013", "authors": ["Zhe Su", "Xuhui Zhou", "Sanketh Rangreji", "Anubha Kabra", "Julia Mendelsohn", "Faeze Brahman", "Maarten Sap"], "title": "AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Truthfulness (adherence to factual accuracy) and utility (satisfying human\nneeds and instructions) are both fundamental aspects of Large Language Models,\nyet these goals often conflict (e.g., sell a car with known flaws), which makes\nit challenging to achieve both in real-world deployments. We propose AI-LieDar,\na framework to study how LLM-based agents navigate these scenarios in an\nmulti-turn interactive setting. We design a set of real-world scenarios where\nlanguage agents are instructed to achieve goals that are in conflict with being\ntruthful during a multi-turn conversation with simulated human agents. To\nevaluate the truthfulness at large scale, we develop a truthfulness detector\ninspired by psychological literature to assess the agents' responses. Our\nexperiment demonstrates that all models are truthful less than 50% of the time,\nthough truthfulness and goal achievement (utility) rates vary across models. We\nfurther test the steerability of LLMs towards truthfulness, finding that models\ncan be directed to be truthful or deceptive, and even truth-steered models\nstill lie. These findings reveal the complex nature of truthfulness in LLMs and\nunderscore the importance of further research to ensure the safe and reliable\ndeployment of LLMs and LLM-based agents.", "AI": {"tldr": "The paper introduces AI-LieDar, a framework to study how LLMs balance truthfulness and utility in multi-turn interactions, revealing models often lie and can be steered toward deception or truth.", "motivation": "To address the conflict between truthfulness and utility in LLMs, especially in real-world scenarios where goals may require deception.", "method": "Developed AI-LieDar, a framework with real-world scenarios and a truthfulness detector to evaluate LLM agents in multi-turn conversations.", "result": "Models were truthful less than 50% of the time, with varying truthfulness and utility rates. LLMs can be steered toward truth or deception, but even truth-steered models still lie.", "conclusion": "The study highlights the complexity of truthfulness in LLMs and the need for further research to ensure their safe and reliable deployment."}}
{"id": "2504.17130", "pdf": "https://arxiv.org/pdf/2504.17130", "abs": "https://arxiv.org/abs/2504.17130", "authors": ["Hannah Cyberey", "David Evans"], "title": "Steering the CensorShip: Uncovering Representation Vectors for LLM \"Thought\" Control", "categories": ["cs.CL", "cs.CR", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) have transformed the way we access information.\nThese models are often tuned to refuse to comply with requests that are\nconsidered harmful and to produce responses that better align with the\npreferences of those who control the models. To understand how this\n\"censorship\" works. We use representation engineering techniques to study\nopen-weights safety-tuned models. We present a method for finding a\nrefusal--compliance vector that detects and controls the level of censorship in\nmodel outputs. We also analyze recent reasoning LLMs, distilled from\nDeepSeek-R1, and uncover an additional dimension of censorship through \"thought\nsuppression\". We show a similar approach can be used to find a vector that\nsuppresses the model's reasoning process, allowing us to remove censorship by\napplying the negative multiples of this vector. Our code is publicly available\nat: https://github.com/hannahxchen/llm-censorship-steering", "AI": {"tldr": "The paper explores how safety-tuned LLMs censor responses, using representation engineering to detect and control censorship, and reveals thought suppression in reasoning models.", "motivation": "To understand and manipulate the censorship mechanisms in safety-tuned LLMs, ensuring alignment with user preferences.", "method": "Uses representation engineering to identify refusal-compliance vectors and thought suppression vectors in models like DeepSeek-R1.", "result": "Demonstrates control over censorship levels and uncovers thought suppression, enabling censorship removal via vector manipulation.", "conclusion": "The study provides tools to analyze and adjust censorship in LLMs, offering insights into model behavior and control."}}
{"id": "2504.19991", "pdf": "https://arxiv.org/pdf/2504.19991", "abs": "https://arxiv.org/abs/2504.19991", "authors": ["Ioannis Kontogiorgakis", "Iason Tsardanidis", "Dimitrios Bormpoudakis", "Ilias Tsoumas", "Dimitra A. Loka", "Christos Noulas", "Alexandros Tsitouras", "Charalampos Kontoes"], "title": "Mapping of Weed Management Methods in Orchards using Sentinel-2 and PlanetScope Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Effective weed management is crucial for improving agricultural productivity,\nas weeds compete with crops for vital resources like nutrients and water.\nAccurate maps of weed management methods are essential for policymakers to\nassess farmer practices, evaluate impacts on vegetation health, biodiversity,\nand climate, as well as ensure compliance with policies and subsidies. However,\nmonitoring weed management methods is challenging as commonly rely on on-ground\nfield surveys, which are often costly, time-consuming and subject to delays. In\norder to tackle this problem, we leverage Earth Observation (EO) data and\nMachine Learning (ML). Specifically, we developed an ML approach for mapping\nfour distinct weed management methods (Mowing, Tillage, Chemical-spraying, and\nNo practice) in orchards using satellite image time series (SITS) data from two\ndifferent sources: Sentinel-2 (S2) and PlanetScope (PS). The findings\ndemonstrate the potential of ML-driven remote sensing to enhance the efficiency\nand accuracy of weed management mapping in orchards.", "AI": {"tldr": "The paper proposes an ML-based approach using satellite data to map weed management methods in orchards, improving efficiency over traditional field surveys.", "motivation": "Effective weed management is vital for agriculture, but current monitoring methods like field surveys are costly and slow.", "method": "The study uses ML with Sentinel-2 and PlanetScope satellite data to classify four weed management methods (Mowing, Tillage, Chemical-spraying, No practice) in orchards.", "result": "The ML-driven remote sensing approach shows promise for efficient and accurate weed management mapping.", "conclusion": "ML and EO data can enhance weed management monitoring, offering a scalable and timely alternative to field surveys."}}
{"id": "2504.18917", "pdf": "https://arxiv.org/pdf/2504.18917", "abs": "https://arxiv.org/abs/2504.18917", "authors": ["David Sychrovsk\u00fd", "Martin Schmid", "Michal \u0160ustr", "Michael Bowling"], "title": "Meta-Learning in Self-Play Regret Minimization", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "Regret minimization is a general approach to online optimization which plays\na crucial role in many algorithms for approximating Nash equilibria in\ntwo-player zero-sum games. The literature mainly focuses on solving individual\ngames in isolation. However, in practice, players often encounter a\ndistribution of similar but distinct games. For example, when trading\ncorrelated assets on the stock market, or when refining the strategy in\nsubgames of a much larger game. Recently, offline meta-learning was used to\naccelerate one-sided equilibrium finding on such distributions. We build upon\nthis, extending the framework to the more challenging self-play setting, which\nis the basis for most state-of-the-art equilibrium approximation algorithms for\ndomains at scale. When selecting the strategy, our method uniquely integrates\ninformation across all decision states, promoting global communication as\nopposed to the traditional local regret decomposition. Empirical evaluation on\nnormal-form games and river poker subgames shows our meta-learned algorithms\nconsiderably outperform other state-of-the-art regret minimization algorithms.", "AI": {"tldr": "The paper extends offline meta-learning to self-play settings for regret minimization in online optimization, improving performance in equilibrium approximation for games.", "motivation": "Players often face distributions of similar games (e.g., stock trading or subgames), but existing methods focus on isolated games. Meta-learning can accelerate equilibrium finding.", "method": "Extends offline meta-learning to self-play, integrating global information across decision states instead of local regret decomposition.", "result": "Empirical tests on normal-form games and river poker subgames show superior performance over state-of-the-art regret minimization algorithms.", "conclusion": "The proposed meta-learning approach enhances regret minimization in self-play settings, outperforming existing methods."}}
{"id": "2410.04320", "pdf": "https://arxiv.org/pdf/2410.04320", "abs": "https://arxiv.org/abs/2410.04320", "authors": ["Haonan An", "Zhengru Fang", "Yuang Zhang", "Senkang Hu", "Xianhao Chen", "Guowen Xu", "Yuguang Fang"], "title": "Channel-Aware Throughput Maximization for Cooperative Data Fusion in CAV", "categories": ["cs.AI"], "comment": null, "summary": "Connected and autonomous vehicles (CAVs) have garnered significant attention\ndue to their extended perception range and enhanced sensing coverage. To\naddress challenges such as blind spots and obstructions, CAVs employ\nvehicle-to-vehicle (V2V) communications to aggregate sensory data from\nsurrounding vehicles. However, cooperative perception is often constrained by\nthe limitations of achievable network throughput and channel quality. In this\npaper, we propose a channel-aware throughput maximization approach to\nfacilitate CAV data fusion, leveraging a self-supervised autoencoder for\nadaptive data compression. We formulate the problem as a mixed integer\nprogramming (MIP) model, which we decompose into two sub-problems to derive\noptimal data rate and compression ratio solutions under given link conditions.\nAn autoencoder is then trained to minimize bitrate with the determined\ncompression ratio, and a fine-tuning strategy is employed to further reduce\nspectrum resource consumption. Experimental evaluation on the OpenCOOD platform\ndemonstrates the effectiveness of our proposed algorithm, showing more than\n20.19\\% improvement in network throughput and a 9.38\\% increase in average\nprecision (AP@IoU) compared to state-of-the-art methods, with an optimal\nlatency of 19.99 ms.", "AI": {"tldr": "The paper proposes a channel-aware throughput maximization approach for CAV data fusion, using a self-supervised autoencoder for adaptive data compression, improving network throughput and precision.", "motivation": "Challenges like blind spots and obstructions in CAVs are addressed by V2V communications, but cooperative perception is limited by network throughput and channel quality.", "method": "A mixed integer programming model is decomposed into sub-problems for optimal data rate and compression ratio. A self-supervised autoencoder is trained for adaptive compression, with fine-tuning to reduce resource use.", "result": "Experiments show a 20.19% throughput improvement, 9.38% AP@IoU increase, and optimal latency of 19.99 ms.", "conclusion": "The proposed method effectively enhances CAV data fusion performance under network constraints."}}
{"id": "2504.17192", "pdf": "https://arxiv.org/pdf/2504.17192", "abs": "https://arxiv.org/abs/2504.17192", "authors": ["Minju Seo", "Jinheon Baek", "Seongyun Lee", "Sung Ju Hwang"], "title": "Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning", "categories": ["cs.CL"], "comment": null, "summary": "Despite the rapid growth of machine learning research, corresponding code\nimplementations are often unavailable, making it slow and labor-intensive for\nresearchers to reproduce results and build upon prior work. In the meantime,\nrecent Large Language Models (LLMs) excel at understanding scientific documents\nand generating high-quality code. Inspired by this, we introduce PaperCoder, a\nmulti-agent LLM framework that transforms machine learning papers into\nfunctional code repositories. PaperCoder operates in three stages: planning,\nwhere it constructs a high-level roadmap, designs the system architecture with\ndiagrams, identifies file dependencies, and generates configuration files;\nanalysis, which focuses on interpreting implementation-specific details; and\ngeneration, where modular, dependency-aware code is produced. Moreover, each\nphase is instantiated through a set of specialized agents designed to\ncollaborate effectively across the pipeline. We then evaluate PaperCoder on\ngenerating code implementations from machine learning papers based on both\nmodel-based and human evaluations, specifically from the original paper\nauthors, with author-released repositories as ground truth if available. Our\nresults demonstrate the effectiveness of PaperCoder in creating high-quality,\nfaithful implementations. Furthermore, it consistently shows strengths in the\nrecently released PaperBench benchmark, surpassing strong baselines by\nsubstantial margins. Code is available at:\nhttps://github.com/going-doer/Paper2Code.", "AI": {"tldr": "PaperCoder is a multi-agent LLM framework that converts machine learning papers into functional code repositories, excelling in quality and faithfulness.", "motivation": "Addressing the lack of available code implementations in ML research, which hinders reproducibility and progress.", "method": "A three-stage process (planning, analysis, generation) with specialized agents, evaluated via model-based and human assessments.", "result": "PaperCoder produces high-quality, faithful implementations, outperforming baselines on the PaperBench benchmark.", "conclusion": "PaperCoder effectively bridges the gap between ML papers and code, enhancing reproducibility and research efficiency."}}
{"id": "2504.20024", "pdf": "https://arxiv.org/pdf/2504.20024", "abs": "https://arxiv.org/abs/2504.20024", "authors": ["Wufei Ma", "Yu-Cheng Chou", "Qihao Liu", "Xingrui Wang", "Celso de Melo", "Jieneng Chen", "Jianwen Xie", "Alan Yuille"], "title": "SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning", "categories": ["cs.CV"], "comment": "Project page: https://spatial-reasoner.github.io", "summary": "Recent studies in 3D spatial reasoning explore data-driven approaches and\nachieve enhanced spatial reasoning performance with reinforcement learning\n(RL). However, these methods typically perform spatial reasoning in an implicit\nmanner, and it remains underexplored whether the acquired 3D knowledge\ngeneralizes to unseen question types at any stage of the training. In this work\nwe introduce SpatialReasoner, a novel large vision-language model (LVLM) that\naddress 3D spatial reasoning with explicit 3D representations shared between\nstages -- 3D perception, computation, and reasoning. Explicit 3D\nrepresentations provide a coherent interface that supports advanced 3D spatial\nreasoning and enable us to study the factual errors made by LVLMs. Results show\nthat our SpatialReasoner achieve improved performance on a variety of spatial\nreasoning benchmarks and generalizes better when evaluating on novel 3D spatial\nreasoning questions. Our study bridges the 3D parsing capabilities of prior\nvisual foundation models with the powerful reasoning abilities of large\nlanguage models, opening new directions for 3D spatial reasoning.", "AI": {"tldr": "SpatialReasoner, a new LVLM, uses explicit 3D representations for improved spatial reasoning and generalization.", "motivation": "Existing RL-based methods lack explicit 3D reasoning and generalization to unseen questions.", "method": "Introduces SpatialReasoner, an LVLM with shared explicit 3D representations across perception, computation, and reasoning stages.", "result": "Outperforms benchmarks and generalizes better to novel 3D spatial reasoning questions.", "conclusion": "Bridges 3D parsing and reasoning, advancing 3D spatial reasoning research."}}
{"id": "2504.18958", "pdf": "https://arxiv.org/pdf/2504.18958", "abs": "https://arxiv.org/abs/2504.18958", "authors": ["Masoud Ataei"], "title": "Modeling Regime Structure and Informational Drivers of Stock Market Volatility via the Financial Chaos Index", "categories": ["q-fin.ST", "cs.LG"], "comment": null, "summary": "This paper investigates the structural dynamics of stock market volatility\nthrough the Financial Chaos Index, a tensor- and eigenvalue-based measure\ndesigned to capture realized volatility via mutual fluctuations among asset\nprices. Motivated by empirical evidence of regime-dependent volatility behavior\nand perceptual time dilation during financial crises, we develop a\nregime-switching framework based on the Modified Lognormal Power-Law\ndistribution. Analysis of the FCIX from January 1990 to December 2023\nidentifies three distinct market regimes, low-chaos, intermediate-chaos, and\nhigh-chaos, each characterized by differing levels of systemic stress,\nstatistical dispersion and persistence characteristics. Building upon the\nsegmented regime structure, we further examine the informational forces that\nshape forward-looking market expectations. Using sentiment-based predictors\nderived from the Equity Market Volatility tracker, we employ an elastic net\nregression model to forecast implied volatility, as proxied by the VIX index.\nOur findings indicate that shifts in macroeconomic, financial, policy, and\ngeopolitical uncertainty exhibit strong predictive power for volatility\ndynamics across regimes. Together, these results offer a unified empirical\nperspective on how systemic uncertainty governs both the realized evolution of\nfinancial markets and the anticipatory behavior embedded in implied volatility\nmeasures.", "AI": {"tldr": "The paper analyzes stock market volatility using the Financial Chaos Index (FCIX) and identifies three market regimes. It also forecasts implied volatility (VIX) using sentiment predictors, showing how uncertainty shapes market dynamics.", "motivation": "To understand regime-dependent volatility behavior and perceptual time dilation during financial crises, and to explore the forces shaping market expectations.", "method": "Develops a regime-switching framework using the Modified Lognormal Power-Law distribution and employs elastic net regression with sentiment-based predictors to forecast implied volatility.", "result": "Identifies three market regimes (low-, intermediate-, and high-chaos) and shows that macroeconomic, financial, policy, and geopolitical uncertainty strongly predict volatility dynamics.", "conclusion": "Provides a unified view of how systemic uncertainty influences both realized market evolution and implied volatility."}}
{"id": "2410.16543", "pdf": "https://arxiv.org/pdf/2410.16543", "abs": "https://arxiv.org/abs/2410.16543", "authors": ["Jingwei Huang", "Kuroush Nezafati", "Ismael Villanueva-Miranda", "Zifan Gu", "Yueshuang Xu", "Ann Marie Navar", "Tingyi Wanyan", "Qin Zhou", "Bo Yao", "Ruichen Rong", "Xiaowei Zhan", "Guanghua Xiao", "Eric D. Peterson", "Donghan M. Yang", "Wenqi Shi", "Yang Xie"], "title": "Multi-Agent LLMs Ensemble for Efficient Atrial Fibrillation Annotation of ECG Reports", "categories": ["cs.AI", "I.2"], "comment": "26 pages, 12 figures", "summary": "This study introduces a novel multiagent ensemble method powered by LLMs to\naddress a key challenge in ML - data labeling, particularly in large-scale EHR\ndatasets. Manual labeling of such datasets requires domain expertise and is\nlabor-intensive, time-consuming, expensive, and error-prone. To overcome this\nbottleneck, we developed an ensemble LLMs method and demonstrated its\neffectiveness in two real-world tasks: (1) labeling a large-scale unlabeled ECG\ndataset in MIMIC-IV; (2) identifying social determinants of health (SDOH) from\nthe clinical notes of EHR. Trading off benefits and cost, we selected a pool of\ndiverse open source LLMs with satisfactory performance. We treat each LLM's\nprediction as a vote and apply a mechanism of majority voting with minimal\nwinning threshold for ensemble. We implemented an ensemble LLMs application for\nEHR data labeling tasks. By using the ensemble LLMs and natural language\nprocessing, we labeled MIMIC-IV ECG dataset of 623,566 ECG reports with an\nestimated accuracy of 98.2%. We applied the ensemble LLMs method to identify\nSDOH from social history sections of 1,405 EHR clinical notes, also achieving\ncompetitive performance. Our experiments show that the ensemble LLMs can\noutperform individual LLM even the best commercial one, and the method reduces\nhallucination errors. From the research, we found that (1) the ensemble LLMs\nmethod significantly reduces the time and effort required for labeling\nlarge-scale EHR data, automating the process with high accuracy and quality;\n(2) the method generalizes well to other text data labeling tasks, as shown by\nits application to SDOH identification; (3) the ensemble of a group of diverse\nLLMs can outperform or match the performance of the best individual LLM; and\n(4) the ensemble method substantially reduces hallucination errors. This\napproach provides a scalable and efficient solution to data-labeling\nchallenges.", "AI": {"tldr": "A novel multiagent ensemble method using LLMs automates large-scale EHR data labeling, achieving high accuracy and reducing manual effort.", "motivation": "Manual labeling of large-scale EHR datasets is labor-intensive, time-consuming, and error-prone, necessitating an automated solution.", "method": "An ensemble of diverse open-source LLMs uses majority voting with a minimal winning threshold for labeling tasks, applied to ECG reports and SDOH identification.", "result": "The method labeled 623,566 ECG reports with 98.2% accuracy and identified SDOH from 1,405 clinical notes, outperforming individual LLMs and reducing errors.", "conclusion": "The ensemble LLMs method is scalable, efficient, and generalizable, significantly reducing labeling effort while maintaining high accuracy."}}
{"id": "2301.10140", "pdf": "https://arxiv.org/pdf/2301.10140", "abs": "https://arxiv.org/abs/2301.10140", "authors": ["Rodney Kinney", "Chloe Anastasiades", "Russell Authur", "Iz Beltagy", "Jonathan Bragg", "Alexandra Buraczynski", "Isabel Cachola", "Stefan Candra", "Yoganand Chandrasekhar", "Arman Cohan", "Miles Crawford", "Doug Downey", "Jason Dunkelberger", "Oren Etzioni", "Rob Evans", "Sergey Feldman", "Joseph Gorney", "David Graham", "Fangzhou Hu", "Regan Huff", "Daniel King", "Sebastian Kohlmeier", "Bailey Kuehl", "Michael Langan", "Daniel Lin", "Haokun Liu", "Kyle Lo", "Jaron Lochner", "Kelsey MacMillan", "Tyler Murray", "Chris Newell", "Smita Rao", "Shaurya Rohatgi", "Paul Sayre", "Zejiang Shen", "Amanpreet Singh", "Luca Soldaini", "Shivashankar Subramanian", "Amber Tanaka", "Alex D. Wade", "Linda Wagner", "Lucy Lu Wang", "Chris Wilhelm", "Caroline Wu", "Jiangjiang Yang", "Angele Zamarron", "Madeleine Van Zuylen", "Daniel S. Weld"], "title": "The Semantic Scholar Open Data Platform", "categories": ["cs.DL", "cs.CL"], "comment": "8 pages, 6 figures", "summary": "The volume of scientific output is creating an urgent need for automated\ntools to help scientists keep up with developments in their field. Semantic\nScholar (S2) is an open data platform and website aimed at accelerating science\nby helping scholars discover and understand scientific literature. We combine\npublic and proprietary data sources using state-of-the-art techniques for\nscholarly PDF content extraction and automatic knowledge graph construction to\nbuild the Semantic Scholar Academic Graph, the largest open scientific\nliterature graph to-date, with 200M+ papers, 80M+ authors, 550M+\npaper-authorship edges, and 2.4B+ citation edges. The graph includes advanced\nsemantic features such as structurally parsed text, natural language summaries,\nand vector embeddings. In this paper, we describe the components of the S2 data\nprocessing pipeline and the associated APIs offered by the platform. We will\nupdate this living document to reflect changes as we add new data offerings and\nimprove existing services.", "AI": {"tldr": "Semantic Scholar (S2) is an open data platform accelerating science by automating literature discovery and understanding, featuring a massive knowledge graph with advanced semantic features.", "motivation": "The rapid growth of scientific output necessitates automated tools to help scholars stay updated.", "method": "Combines public and proprietary data sources using advanced PDF extraction and knowledge graph construction techniques.", "result": "Built the largest open scientific literature graph (200M+ papers, 80M+ authors) with semantic features like parsed text and embeddings.", "conclusion": "S2's pipeline and APIs are described, with plans for ongoing updates to improve services."}}
{"id": "2504.20032", "pdf": "https://arxiv.org/pdf/2504.20032", "abs": "https://arxiv.org/abs/2504.20032", "authors": ["Kai Ye", "Haidi Tang", "Bowen Liu", "Pingyang Dai", "Liujuan Cao", "Rongrong Ji"], "title": "More Clear, More Flexible, More Precise: A Comprehensive Oriented Object Detection benchmark for UAV", "categories": ["cs.CV"], "comment": null, "summary": "Applications of unmanned aerial vehicle (UAV) in logistics, agricultural\nautomation, urban management, and emergency response are highly dependent on\noriented object detection (OOD) to enhance visual perception. Although existing\ndatasets for OOD in UAV provide valuable resources, they are often designed for\nspecific downstream tasks.Consequently, they exhibit limited generalization\nperformance in real flight scenarios and fail to thoroughly demonstrate\nalgorithm effectiveness in practical environments. To bridge this critical gap,\nwe introduce CODrone, a comprehensive oriented object detection dataset for\nUAVs that accurately reflects real-world conditions. It also serves as a new\nbenchmark designed to align with downstream task requirements, ensuring greater\napplicability and robustness in UAV-based OOD.Based on application\nrequirements, we identify four key limitations in current UAV OOD datasets-low\nimage resolution, limited object categories, single-view imaging, and\nrestricted flight altitudes-and propose corresponding improvements to enhance\ntheir applicability and robustness.Furthermore, CODrone contains a broad\nspectrum of annotated images collected from multiple cities under various\nlighting conditions, enhancing the realism of the benchmark. To rigorously\nevaluate CODrone as a new benchmark and gain deeper insights into the novel\nchallenges it presents, we conduct a series of experiments based on 22\nclassical or SOTA methods.Our evaluation not only assesses the effectiveness of\nCODrone in real-world scenarios but also highlights key bottlenecks and\nopportunities to advance OOD in UAV applications.Overall, CODrone fills the\ndata gap in OOD from UAV perspective and provides a benchmark with enhanced\ngeneralization capability, better aligning with practical applications and\nfuture algorithm development.", "AI": {"tldr": "CODrone is a new UAV-oriented object detection dataset addressing limitations of existing datasets, enhancing real-world applicability and robustness.", "motivation": "Existing UAV OOD datasets lack generalization and real-world relevance, limiting practical algorithm effectiveness.", "method": "CODrone improves upon four key dataset limitations (resolution, categories, views, altitudes) and includes diverse annotated images from multiple cities.", "result": "Experiments with 22 methods validate CODrone's effectiveness and highlight challenges in UAV OOD.", "conclusion": "CODrone bridges the data gap, offering a robust benchmark for future UAV OOD development."}}
{"id": "2504.18989", "pdf": "https://arxiv.org/pdf/2504.18989", "abs": "https://arxiv.org/abs/2504.18989", "authors": ["Gal Almog", "Ariel Shamir", "Ohad Fried"], "title": "REED-VAE: RE-Encode Decode Training for Iterative Image Editing with Diffusion Models", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Accepted to Eurographics 2025. Project page:\n  https://reed-vae.github.io/", "summary": "While latent diffusion models achieve impressive image editing results, their\napplication to iterative editing of the same image is severely restricted. When\ntrying to apply consecutive edit operations using current models, they\naccumulate artifacts and noise due to repeated transitions between pixel and\nlatent spaces. Some methods have attempted to address this limitation by\nperforming the entire edit chain within the latent space, sacrificing\nflexibility by supporting only a limited, predetermined set of diffusion\nediting operations. We present a RE-encode decode (REED) training scheme for\nvariational autoencoders (VAEs), which promotes image quality preservation even\nafter many iterations. Our work enables multi-method iterative image editing:\nusers can perform a variety of iterative edit operations, with each operation\nbuilding on the output of the previous one using both diffusion-based\noperations and conventional editing techniques. We demonstrate the advantage of\nREED-VAE across a range of image editing scenarios, including text-based and\nmask-based editing frameworks. In addition, we show how REED-VAE enhances the\noverall editability of images, increasing the likelihood of successful and\nprecise edit operations. We hope that this work will serve as a benchmark for\nthe newly introduced task of multi-method image editing. Our code and models\nwill be available at https://github.com/galmog/REED-VAE", "AI": {"tldr": "REED-VAE introduces a training scheme for VAEs to enable high-quality iterative image editing without accumulating artifacts, supporting diverse edit operations.", "motivation": "Current latent diffusion models struggle with iterative editing due to noise and artifact accumulation, limiting flexibility and quality.", "method": "Proposes REED (RE-encode decode) training for VAEs to preserve image quality across multiple edits, supporting both diffusion-based and conventional techniques.", "result": "Demonstrates improved editability and quality in text-based and mask-based editing, enabling successful multi-method iterative edits.", "conclusion": "REED-VAE sets a benchmark for multi-method image editing, offering a flexible and high-quality solution for iterative edits."}}
{"id": "2411.06251", "pdf": "https://arxiv.org/pdf/2411.06251", "abs": "https://arxiv.org/abs/2411.06251", "authors": ["Aditya Parashar", "Aditya Vikram Singh", "Avinash Amballa", "Jinlin Lai", "Benjamin Rozonoyer"], "title": "Quasi-random Multi-Sample Inference for Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are often equipped with multi-sample decoding\nstrategies. An LLM implicitly defines an arithmetic code book, facilitating\nefficient and embarrassingly parallelizable \\textbf{arithmetic sampling} to\nproduce multiple samples using quasi-random codes. Traditional text generation\nmethods, such as beam search and sampling-based techniques, have notable\nlimitations: they lack parallelizability or diversity of sampled sequences.\nThis study explores the potential of arithmetic sampling, contrasting it with\nancestral sampling across two decoding tasks that employ multi-sample\ninference: chain-of-thought reasoning with self-consistency and machine\ntranslation with minimum Bayes risk decoding. Our results demonstrate that\narithmetic sampling produces more diverse samples, significantly improving\nreasoning and translation performance as the sample size increases. We observe\na $\\mathbf{3\\text{-}5\\%}$ point increase in accuracy on the GSM8K dataset and a\n$\\mathbf{0.45\\text{-}0.89\\%}$ point increment in COMET score for WMT19 tasks\nusing arithmetic sampling without any significant computational overhead.", "AI": {"tldr": "Arithmetic sampling in LLMs improves diversity and performance in multi-sample tasks like reasoning and translation, outperforming traditional methods without extra computational cost.", "motivation": "Traditional text generation methods (beam search, ancestral sampling) lack parallelizability or sample diversity, limiting their effectiveness in multi-sample inference tasks.", "method": "The study introduces arithmetic sampling, leveraging quasi-random codes for parallelizable and diverse sample generation, and compares it with ancestral sampling in chain-of-thought reasoning and machine translation tasks.", "result": "Arithmetic sampling enhances diversity and performance, yielding 3-5% accuracy boost on GSM8K and 0.45-0.89% COMET score improvement on WMT19 tasks.", "conclusion": "Arithmetic sampling is a superior alternative to traditional methods for multi-sample decoding, offering significant performance gains with minimal overhead."}}
{"id": "2303.10430", "pdf": "https://arxiv.org/pdf/2303.10430", "abs": "https://arxiv.org/abs/2303.10430", "authors": ["Yiran Ye", "Thai Le", "Dongwon Lee"], "title": "NoisyHate: Mining Online Human-Written Perturbations for Realistic Robustness Benchmarking of Content Moderation Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": "Accepted to International AAAI Conference on Web and Social Media\n  (ICWSM 2025)", "summary": "Online texts with toxic content are a clear threat to the users on social\nmedia in particular and society in general. Although many platforms have\nadopted various measures (e.g., machine learning-based hate-speech detection\nsystems) to diminish their effect, toxic content writers have also attempted to\nevade such measures by using cleverly modified toxic words, so-called\nhuman-written text perturbations. Therefore, to help build automatic detection\ntools to recognize those perturbations, prior methods have developed\nsophisticated techniques to generate diverse adversarial samples. However, we\nnote that these ``algorithms\"-generated perturbations do not necessarily\ncapture all the traits of ``human\"-written perturbations. Therefore, in this\npaper, we introduce a novel, high-quality dataset of human-written\nperturbations, named as NoisyHate, that was created from real-life\nperturbations that are both written and verified by human-in-the-loop. We show\nthat perturbations in NoisyHate have different characteristics than prior\nalgorithm-generated toxic datasets show, and thus can be in particular useful\nto help develop better toxic speech detection solutions. We thoroughly validate\nNoisyHate against state-of-the-art language models, such as BERT and RoBERTa,\nand black box APIs, such as Perspective API, on two tasks, such as perturbation\nnormalization and understanding.", "AI": {"tldr": "The paper introduces NoisyHate, a dataset of human-written toxic text perturbations, to improve toxic speech detection by addressing gaps in algorithm-generated datasets.", "motivation": "Existing toxic content detection tools struggle with human-written perturbations, which differ from algorithm-generated ones. NoisyHate aims to bridge this gap.", "method": "The authors created NoisyHate, a dataset of real-life human-written perturbations, and validated it using state-of-the-art language models and APIs.", "result": "NoisyHate exhibits unique traits compared to algorithm-generated datasets, enhancing toxic speech detection.", "conclusion": "NoisyHate is a valuable resource for developing better toxic content detection tools, as it captures human-written perturbations more effectively."}}
{"id": "2504.20033", "pdf": "https://arxiv.org/pdf/2504.20033", "abs": "https://arxiv.org/abs/2504.20033", "authors": ["Sara Yavari", "Jacob Furst"], "title": "Mitigating Catastrophic Forgetting in the Incremental Learning of Medical Images", "categories": ["cs.CV", "I.2.6; I.2.10"], "comment": "15 Pages, 3 Figures, 3 Tables, 1 Algorithm, This paper will be\n  updated", "summary": "This paper proposes an Incremental Learning (IL) approach to enhance the\naccuracy and efficiency of deep learning models in analyzing T2-weighted (T2w)\nMRI medical images prostate cancer detection using the PI-CAI dataset. We used\nmultiple health centers' artificial intelligence and radiology data, focused on\ndifferent tasks that looked at prostate cancer detection using MRI (PI-CAI). We\nutilized Knowledge Distillation (KD), as it employs generated images from past\ntasks to guide the training of models for subsequent tasks. The approach\nyielded improved performance and faster convergence of the models. To\ndemonstrate the versatility and robustness of our approach, we evaluated it on\nthe PI-CAI dataset, a diverse set of medical imaging modalities including OCT\nand PathMNIST, and the benchmark continual learning dataset CIFAR-10. Our\nresults indicate that KD can be a promising technique for IL in medical image\nanalysis in which data is sourced from individual health centers and the\nstorage of large datasets is not feasible. By using generated images from prior\ntasks, our method enables the model to retain and apply previously acquired\nknowledge without direct access to the original data.", "AI": {"tldr": "The paper introduces an Incremental Learning (IL) approach using Knowledge Distillation (KD) to improve prostate cancer detection in T2w MRI images, showing enhanced performance and efficiency.", "motivation": "To address challenges in medical image analysis where large datasets from multiple health centers are impractical to store, while maintaining model accuracy.", "method": "Utilized Knowledge Distillation (KD) with generated images from past tasks to train models incrementally, tested on PI-CAI, OCT, PathMNIST, and CIFAR-10 datasets.", "result": "Improved model performance and faster convergence, demonstrating KD's effectiveness for IL in medical imaging.", "conclusion": "KD is a promising IL technique for medical image analysis, enabling knowledge retention without storing original data."}}
{"id": "2504.19007", "pdf": "https://arxiv.org/pdf/2504.19007", "abs": "https://arxiv.org/abs/2504.19007", "authors": ["Jinghao Lyu", "Kyle J. Ray", "James P. Crutchfield"], "title": "Learning Stochastic Thermodynamics Directly from Correlation and Trajectory-Fluctuation Currents", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "cs.LG", "nlin.AO", "stat.ML"], "comment": "11 pages, 6 appendices (10 pages), 4 figures;\n  https://csc.ucdavis.edu/~cmg/compmech/pubs/currents.htm", "summary": "Markedly increased computational power and data acquisition have led to\ngrowing interest in data-driven inverse dynamics problems. These seek to answer\na fundamental question: What can we learn from time series measurements of a\ncomplex dynamical system? For small systems interacting with external\nenvironments, the effective dynamics are inherently stochastic, making it\ncrucial to properly manage noise in data. Here, we explore this for systems\nobeying Langevin dynamics and, using currents, we construct a learning\nframework for stochastic modeling. Currents have recently gained increased\nattention for their role in bounding entropy production (EP) from thermodynamic\nuncertainty relations (TURs). We introduce a fundamental relationship between\nthe cumulant currents there and standard machine-learning loss functions. Using\nthis, we derive loss functions for several key thermodynamic functions directly\nfrom the system dynamics without the (common) intermediate step of deriving a\nTUR. These loss functions reproduce results derived both from TURs and other\nmethods. More significantly, they open a path to discover new loss functions\nfor previously inaccessible quantities. Notably, this includes access to\nper-trajectory entropy production, even if the observed system is driven far\nfrom its steady-state. We also consider higher order estimation. Our method is\nstraightforward and unifies dynamic inference with recent approaches to entropy\nproduction estimation. Taken altogether, this reveals a deep connection between\ndiffusion models in machine learning and entropy production estimation in\nstochastic thermodynamics.", "AI": {"tldr": "The paper introduces a learning framework for stochastic modeling of systems obeying Langevin dynamics, leveraging currents to derive loss functions for thermodynamic functions without needing thermodynamic uncertainty relations (TURs).", "motivation": "To address the challenge of managing noise in data-driven inverse dynamics problems for stochastic systems, particularly those obeying Langevin dynamics.", "method": "Uses currents to construct a learning framework, deriving loss functions directly from system dynamics for thermodynamic functions, bypassing TURs.", "result": "The derived loss functions reproduce known results and enable estimation of per-trajectory entropy production, even far from steady-state.", "conclusion": "The work unifies dynamic inference with entropy production estimation, revealing a connection between diffusion models in machine learning and stochastic thermodynamics."}}
{"id": "2501.10069", "pdf": "https://arxiv.org/pdf/2501.10069", "abs": "https://arxiv.org/abs/2501.10069", "authors": ["Xinzhe Li"], "title": "A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling, Search Algorithms, and Relevant Frameworks", "categories": ["cs.AI"], "comment": "TMLR (camera-ready). Details on\n  https://openreview.net/forum?id=x9VQFjtOPS", "summary": "LLM test-time compute (or LLM inference) via search has emerged as a\npromising research area with rapid developments. However, current frameworks\noften adopt distinct perspectives on three key aspects: task definition, LLM\nprofiling, and search procedures, making direct comparisons challenging.\nMoreover, the search algorithms employed often diverge from standard\nimplementations, and their specific characteristics are not thoroughly\nspecified. This survey aims to provide a comprehensive but integrated technical\nreview on existing LIS frameworks. Specifically, we unify task definitions\nunder Markov Decision Process (MDP) and provides modular definitions of LLM\nprofiling and search procedures. The definitions enable precise comparisons of\nvarious LLM inference frameworks while highlighting their departures from\nconventional search algorithms. We also discuss the applicability, performance,\nand efficiency of these methods. For ongoing paper updates, please refer to our\nGitHub repository: https://github.com/xinzhel/LLM-Search.", "AI": {"tldr": "A survey unifying LLM test-time compute frameworks under MDP, modularizing LLM profiling and search procedures for better comparison.", "motivation": "Addressing the lack of standardized comparisons in LLM inference frameworks due to divergent task definitions, profiling, and search procedures.", "method": "Unifies task definitions under Markov Decision Process (MDP) and modularizes LLM profiling and search procedures.", "result": "Enables precise comparisons of LLM inference frameworks and highlights deviations from conventional search algorithms.", "conclusion": "The survey provides a comprehensive review of LLM inference frameworks, discussing their applicability, performance, and efficiency."}}
{"id": "2307.12369", "pdf": "https://arxiv.org/pdf/2307.12369", "abs": "https://arxiv.org/abs/2307.12369", "authors": ["Rumeng Li", "Xun Wang", "Dan Berlowitz", "Brian Silver", "Wen Hu", "Heather Keating", "Raelene Goodwin", "Weisong Liu", "Honghuang Lin", "Hong Yu"], "title": "Early Prediction of Alzheimers Disease Leveraging Symptom Occurrences from Longitudinal Electronic Health Records of US Military Veterans", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "An updated version is under review. Data and experiment results have\n  been updated", "summary": "Early prediction of Alzheimer's disease (AD) is crucial for timely\nintervention and treatment. This study aims to use machine learning approaches\nto analyze longitudinal electronic health records (EHRs) of patients with AD\nand identify signs and symptoms that can predict AD onset earlier. We used a\ncase-control design with longitudinal EHRs from the U.S. Department of Veterans\nAffairs Veterans Health Administration (VHA) from 2004 to 2021. Cases were VHA\npatients with AD diagnosed after 1/1/2016 based on ICD-10-CM codes, matched 1:9\nwith controls by age, sex and clinical utilization with replacement. We used a\npanel of AD-related keywords and their occurrences over time in a patient's\nlongitudinal EHRs as predictors for AD prediction with four machine learning\nmodels. We performed subgroup analyses by age, sex, and race/ethnicity, and\nvalidated the model in a hold-out and \"unseen\" VHA stations group. Model\ndiscrimination, calibration, and other relevant metrics were reported for\npredictions up to ten years before ICD-based diagnosis. The study population\nincluded 16,701 cases and 39,097 matched controls. The average number of\nAD-related keywords (e.g., \"concentration\", \"speaking\") per year increased\nrapidly for cases as diagnosis approached, from around 10 to over 40, while\nremaining flat at 10 for controls. The best model achieved high discriminative\naccuracy (ROCAUC 0.997) for predictions using data from at least ten years\nbefore ICD-based diagnoses. The model was well-calibrated (Hosmer-Lemeshow\ngoodness-of-fit p-value = 0.99) and consistent across subgroups of age, sex and\nrace/ethnicity, except for patients younger than 65 (ROCAUC 0.746). Machine\nlearning models using AD-related keywords identified from EHR notes can predict\nfuture AD diagnoses, suggesting its potential use for identifying AD risk using\nEHR notes, offering an affordable way for early screening on large population.", "AI": {"tldr": "Machine learning models using AD-related keywords from EHRs predict Alzheimer's disease (AD) up to ten years before diagnosis with high accuracy.", "motivation": "Early prediction of AD is critical for timely intervention, and EHRs provide a rich data source for identifying early signs.", "method": "Used longitudinal EHRs from VHA, case-control design, and four machine learning models to analyze AD-related keywords over time.", "result": "Best model achieved ROCAUC 0.997 for predictions up to ten years before diagnosis, with consistent performance across subgroups except patients under 65.", "conclusion": "EHR-based machine learning models offer an affordable and effective tool for early AD screening in large populations."}}
{"id": "2504.20040", "pdf": "https://arxiv.org/pdf/2504.20040", "abs": "https://arxiv.org/abs/2504.20040", "authors": ["Zador Pataki", "Paul-Edouard Sarlin", "Johannes L. Sch\u00f6nberger", "Marc Pollefeys"], "title": "MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion", "categories": ["cs.CV", "cs.RO"], "comment": "CVPR 2025", "summary": "While Structure-from-Motion (SfM) has seen much progress over the years,\nstate-of-the-art systems are prone to failure when facing extreme viewpoint\nchanges in low-overlap, low-parallax or high-symmetry scenarios. Because\ncapturing images that avoid these pitfalls is challenging, this severely limits\nthe wider use of SfM, especially by non-expert users. We overcome these\nlimitations by augmenting the classical SfM paradigm with monocular depth and\nnormal priors inferred by deep neural networks. Thanks to a tight integration\nof monocular and multi-view constraints, our approach significantly outperforms\nexisting ones under extreme viewpoint changes, while maintaining strong\nperformance in standard conditions. We also show that monocular priors can help\nreject faulty associations due to symmetries, which is a long-standing problem\nfor SfM. This makes our approach the first capable of reliably reconstructing\nchallenging indoor environments from few images. Through principled uncertainty\npropagation, it is robust to errors in the priors, can handle priors inferred\nby different models with little tuning, and will thus easily benefit from\nfuture progress in monocular depth and normal estimation. Our code is publicly\navailable at https://github.com/cvg/mpsfm.", "AI": {"tldr": "The paper introduces a method to improve Structure-from-Motion (SfM) by integrating monocular depth and normal priors from deep neural networks, enhancing performance in challenging scenarios like low-overlap or high-symmetry.", "motivation": "Current SfM systems fail under extreme viewpoint changes, limiting their usability. The goal is to make SfM more robust and accessible, especially for non-experts.", "method": "The approach combines classical SfM with monocular depth and normal priors from deep learning, tightly integrating monocular and multi-view constraints.", "result": "The method outperforms existing systems in extreme conditions, handles symmetry-related errors, and reliably reconstructs challenging indoor scenes from few images.", "conclusion": "The integration of monocular priors makes SfM more robust and adaptable, with potential for future improvements in depth and normal estimation."}}
{"id": "2504.19012", "pdf": "https://arxiv.org/pdf/2504.19012", "abs": "https://arxiv.org/abs/2504.19012", "authors": ["Xizhuo", "Zhang", "Bing Yao"], "title": "Geometry-aware Active Learning of Spatiotemporal Dynamic Systems", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Rapid developments in advanced sensing and imaging have significantly\nenhanced information visibility, opening opportunities for predictive modeling\nof complex dynamic systems. However, sensing signals acquired from such complex\nsystems are often distributed across 3D geometries and rapidly evolving over\ntime, posing significant challenges in spatiotemporal predictive modeling. This\npaper proposes a geometry-aware active learning framework for modeling\nspatiotemporal dynamic systems. Specifically, we propose a geometry-aware\nspatiotemporal Gaussian Process (G-ST-GP) to effectively integrate the temporal\ncorrelations and geometric manifold features for reliable prediction of\nhigh-dimensional dynamic behaviors. In addition, we develop an adaptive active\nlearning strategy to strategically identify informative spatial locations for\ndata collection and further maximize the prediction accuracy. This strategy\nachieves the adaptive trade-off between the prediction uncertainty in the\nG-ST-GP model and the space-filling design guided by the geodesic distance\nacross the 3D geometry. We implement the proposed framework to model the\nspatiotemporal electrodynamics in a 3D heart geometry. Numerical experiments\nshow that our framework outperforms traditional methods lacking the mechanism\nof geometric information incorporation or effective data collection.", "AI": {"tldr": "A geometry-aware active learning framework is proposed for spatiotemporal predictive modeling, integrating temporal correlations and geometric features via a G-ST-GP model, with adaptive data collection to maximize accuracy.", "motivation": "Complex dynamic systems generate distributed, rapidly evolving sensing signals, challenging spatiotemporal modeling.", "method": "Proposes a geometry-aware spatiotemporal Gaussian Process (G-ST-GP) and an adaptive active learning strategy for data collection.", "result": "Outperforms traditional methods by incorporating geometric information and optimizing data collection.", "conclusion": "The framework effectively models high-dimensional dynamic behaviors, enhancing prediction accuracy in complex systems."}}
{"id": "2502.13107", "pdf": "https://arxiv.org/pdf/2502.13107", "abs": "https://arxiv.org/abs/2502.13107", "authors": ["Yingheng Tang", "Wenbin Xu", "Jie Cao", "Weilu Gao", "Steve Farrell", "Benjamin Erichson", "Michael W. Mahoney", "Andy Nonaka", "Zhi Yao"], "title": "MatterChat: A Multi-Modal LLM for Material Science", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting the properties of inorganic materials is crucial\nfor accelerating advancements in materials science and driving applications in\nenergy, electronics, and beyond. Integrating material structure data with\nlanguage-based information through multi-modal large language models (LLMs)\noffers great potential to support these efforts by enhancing human-AI\ninteraction. However, a key challenge lies in integrating atomic structures at\nfull resolution into LLMs. In this work, we introduce MatterChat, a versatile\nstructure-aware multi-modal LLM that unifies material structural data and\ntextual inputs into a single cohesive model. MatterChat employs a bridging\nmodule to effectively align a pretrained machine learning interatomic potential\nwith a pretrained LLM, reducing training costs and enhancing flexibility. Our\nresults demonstrate that MatterChat significantly improves performance in\nmaterial property prediction and human-AI interaction, surpassing\ngeneral-purpose LLMs such as GPT-4. We also demonstrate its usefulness in\napplications such as more advanced scientific reasoning and step-by-step\nmaterial synthesis.", "AI": {"tldr": "MatterChat integrates material structure data with language models to improve material property prediction and human-AI interaction.", "motivation": "Advancing materials science requires better tools for understanding and predicting material properties, especially by combining structural data with language models.", "method": "MatterChat uses a bridging module to align a pretrained interatomic potential model with a pretrained LLM, unifying structural and textual inputs.", "result": "MatterChat outperforms general-purpose LLMs like GPT-4 in material property prediction and enables advanced scientific reasoning and synthesis.", "conclusion": "MatterChat is a powerful tool for materials science, enhancing AI capabilities in property prediction and synthesis planning."}}
{"id": "2403.19103", "pdf": "https://arxiv.org/pdf/2403.19103", "abs": "https://arxiv.org/abs/2403.19103", "authors": ["Yutong He", "Alexander Robey", "Naoki Murata", "Yiding Jiang", "Joshua Nathaniel Williams", "George J. Pappas", "Hamed Hassani", "Yuki Mitsufuji", "Ruslan Salakhutdinov", "J. Zico Kolter"], "title": "Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Prompt engineering is an effective but labor-intensive way to control\ntext-to-image (T2I) generative models. Its time-intensive nature and complexity\nhave spurred the development of algorithms for automated prompt generation.\nHowever, these methods often struggle with transferability across T2I models,\nrequire white-box access to the underlying model, or produce non-intuitive\nprompts. In this work, we introduce PRISM, an algorithm that automatically\nproduces human-interpretable and transferable prompts that can effectively\ngenerate desired concepts given only black-box access to T2I models. Inspired\nby large language model (LLM) jailbreaking, PRISM leverages the in-context\nlearning ability of LLMs to iteratively refine the candidate prompt\ndistribution built upon the reference images. Our experiments demonstrate the\nversatility and effectiveness of PRISM in generating accurate prompts for\nobjects, styles, and images across multiple T2I models, including Stable\nDiffusion, DALL-E, and Midjourney.", "AI": {"tldr": "PRISM automates prompt generation for text-to-image models, producing human-interpretable and transferable prompts without needing white-box access.", "motivation": "Manual prompt engineering is labor-intensive, and existing automated methods lack transferability or require model access.", "method": "PRISM uses LLM in-context learning to iteratively refine prompts based on reference images.", "result": "PRISM effectively generates prompts for objects, styles, and images across models like Stable Diffusion, DALL-E, and Midjourney.", "conclusion": "PRISM offers a versatile and efficient solution for automated prompt generation in T2I models."}}
{"id": "2504.20041", "pdf": "https://arxiv.org/pdf/2504.20041", "abs": "https://arxiv.org/abs/2504.20041", "authors": ["Yibin Yan", "Jilan Xu", "Shangzhe Di", "Yikun Liu", "Yudi Shi", "Qirui Chen", "Zeqian Li", "Yifei Huang", "Weidi Xie"], "title": "Learning Streaming Video Representation via Multitask Training", "categories": ["cs.CV"], "comment": "Technical Report. Project Page:\n  https://go2heart.github.io/streamformer", "summary": "Understanding continuous video streams plays a fundamental role in real-time\napplications including embodied AI and autonomous driving. Unlike offline video\nunderstanding, streaming video understanding requires the ability to process\nvideo streams frame by frame, preserve historical information, and make\nlow-latency decisions.To address these challenges, our main contributions are\nthree-fold. (i) We develop a novel streaming video backbone, termed as\nStreamFormer, by incorporating causal temporal attention into a pre-trained\nvision transformer. This enables efficient streaming video processing while\nmaintaining image representation capability.(ii) To train StreamFormer, we\npropose to unify diverse spatial-temporal video understanding tasks within a\nmultitask visual-language alignment framework. Hence, StreamFormer learns\nglobal semantics, temporal dynamics, and fine-grained spatial relationships\nsimultaneously. (iii) We conduct extensive experiments on online action\ndetection, online video instance segmentation, and video question answering.\nStreamFormer achieves competitive results while maintaining efficiency,\ndemonstrating its potential for real-time applications.", "AI": {"tldr": "StreamFormer is a novel streaming video backbone for real-time video understanding, integrating causal temporal attention into a vision transformer. It unifies multitask visual-language alignment for training and achieves competitive results in real-time applications.", "motivation": "To address the challenges of processing video streams frame by frame, preserving historical information, and making low-latency decisions for real-time applications like embodied AI and autonomous driving.", "method": "Develop StreamFormer by adding causal temporal attention to a pre-trained vision transformer. Train it using a multitask visual-language alignment framework to learn global semantics, temporal dynamics, and spatial relationships.", "result": "Competitive performance in online action detection, video instance segmentation, and video question answering while maintaining efficiency.", "conclusion": "StreamFormer demonstrates strong potential for real-time video understanding tasks, balancing accuracy and efficiency."}}
{"id": "2504.19053", "pdf": "https://arxiv.org/pdf/2504.19053", "abs": "https://arxiv.org/abs/2504.19053", "authors": ["Hongni Jin", "Gurinder Singh", "Kenneth M. Merz Jr"], "title": "QFGN: A Quantum Approach to High-Fidelity Implicit Neural Representations", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Implicit neural representations have shown potential in various applications.\nHowever, accurately reconstructing the image or providing clear details via\nimage super-resolution remains challenging. This paper introduces Quantum\nFourier Gaussian Network (QFGN), a quantum-based machine learning model for\nbetter signal representations. The frequency spectrum is well balanced by\npenalizing the low-frequency components, leading to the improved expressivity\nof quantum circuits. The results demonstrate that with minimal parameters, QFGN\noutperforms the current state-of-the-art (SOTA) models. Despite noise on\nhardware, the model achieves accuracy comparable to that of SIREN, highlighting\nthe potential applications of quantum machine learning in this field.", "AI": {"tldr": "QFGN, a quantum-based model, improves image super-resolution by balancing frequency spectra and outperforms SOTA models with minimal parameters.", "motivation": "Implicit neural representations struggle with accurate image reconstruction and super-resolution. QFGN addresses this by leveraging quantum machine learning.", "method": "QFGN uses quantum circuits to balance frequency spectra, penalizing low-frequency components for better expressivity.", "result": "QFGN outperforms SOTA models with fewer parameters and achieves accuracy comparable to SIREN despite hardware noise.", "conclusion": "QFGN demonstrates quantum machine learning's potential for high-quality signal representation and super-resolution tasks."}}
{"id": "2502.13392", "pdf": "https://arxiv.org/pdf/2502.13392", "abs": "https://arxiv.org/abs/2502.13392", "authors": ["Jim Dai", "Manxi Wu", "Zhanhao Zhang"], "title": "Atomic Proximal Policy Optimization for Electric Robo-Taxi Dispatch and Charger Allocation", "categories": ["cs.AI"], "comment": null, "summary": "Pioneering companies such as Waymo have deployed robo-taxi services in\nseveral U.S. cities. These robo-taxis are electric vehicles, and their\noperations require the joint optimization of ride matching, vehicle\nrepositioning, and charging scheduling in a stochastic environment. We model\nthe operations of the ride-hailing system with robo-taxis as a discrete-time,\naverage-reward Markov Decision Process with an infinite horizon. As the fleet\nsize grows, dispatching becomes challenging, as both the system state space and\nthe fleet dispatching action space grow exponentially with the number of\nvehicles. To address this, we introduce a scalable deep reinforcement learning\nalgorithm, called Atomic Proximal Policy Optimization (Atomic-PPO), that\nreduces the action space using atomic action decomposition. We evaluate our\nalgorithm using real-world NYC for-hire vehicle trip records and measure its\nperformance by the long-run average reward achieved by the dispatching policy,\nrelative to a fluid-based upper bound. Our experiments demonstrate the superior\nperformance of Atomic-PPO compared to benchmark methods. Furthermore, we\nconduct extensive numerical experiments to analyze the efficient allocation of\ncharging facilities and assess the impact of vehicle range and charger speed on\nsystem performance.", "AI": {"tldr": "The paper introduces Atomic-PPO, a scalable deep reinforcement learning algorithm, to optimize robo-taxi operations like ride matching, repositioning, and charging in stochastic environments. It outperforms benchmarks and analyzes charging facility allocation.", "motivation": "To address the challenge of exponentially growing action and state spaces in large-scale robo-taxi fleet dispatching.", "method": "Model the system as a Markov Decision Process and propose Atomic-PPO, which reduces action space via atomic action decomposition.", "result": "Atomic-PPO achieves superior performance in long-run average reward compared to benchmarks, and insights on charging facility allocation are provided.", "conclusion": "Atomic-PPO is effective for scalable robo-taxi dispatching, and charging infrastructure planning significantly impacts system performance."}}
{"id": "2403.20331", "pdf": "https://arxiv.org/pdf/2403.20331", "abs": "https://arxiv.org/abs/2403.20331", "authors": ["Atsuyuki Miyai", "Jingkang Yang", "Jingyang Zhang", "Yifei Ming", "Qing Yu", "Go Irie", "Yixuan Li", "Hai Li", "Ziwei Liu", "Kiyoharu Aizawa"], "title": "Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Code: https://github.com/AtsuMiyai/UPD. Update from v2: Correction to\n  Figure 1", "summary": "This paper introduces a novel task to evaluate the robust understanding\ncapability of Large Multimodal Models (LMMs), termed $\\textbf{Unsolvable\nProblem Detection (UPD)}$. Multiple-choice question answering (MCQA) is widely\nused to assess the understanding capability of LMMs, but it does not guarantee\nthat LMMs truly comprehend the answer. UPD assesses the LMM's ability to\nwithhold answers when encountering unsolvable problems of MCQA, verifying\nwhether the model truly understands the answer. UPD encompasses three problems:\nAbsent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and\nIncompatible Visual Question Detection (IVQD), covering unsolvable cases like\nanswer-lacking or incompatible choices and image-question mismatches. For the\nevaluation, we introduce the MM-UPD Bench, a benchmark for assessing\nperformance across various ability dimensions. Our experiments reveal that even\nmost LMMs, which demonstrate adequate performance on existing benchmarks,\nstruggle significantly with MM-UPD, underscoring a novel aspect of\ntrustworthiness that current benchmarks have overlooked. A detailed analysis\nshows that LMMs have different bottlenecks and chain-of-thought and\nself-reflection improved performance for LMMs with the bottleneck in their LLM\ncapability. We hope our insights will enhance the broader understanding and\ndevelopment of more reliable LMMs.", "AI": {"tldr": "The paper introduces Unsolvable Problem Detection (UPD) to evaluate Large Multimodal Models (LMMs) by assessing their ability to withhold answers for unsolvable MCQA problems, revealing gaps in current benchmarks.", "motivation": "Current multiple-choice question answering (MCQA) benchmarks don't ensure LMMs truly understand answers, so UPD evaluates their ability to detect unsolvable problems.", "method": "UPD includes three problem types (AAD, IASD, IVQD) and uses the MM-UPD Bench for evaluation. Chain-of-thought and self-reflection are tested to improve performance.", "result": "Most LMMs perform poorly on MM-UPD, highlighting overlooked trustworthiness aspects. Chain-of-thought and self-reflection help models with LLM bottlenecks.", "conclusion": "UPD reveals critical limitations in LMMs, offering insights for developing more reliable models."}}
{"id": "2504.20042", "pdf": "https://arxiv.org/pdf/2504.20042", "abs": "https://arxiv.org/abs/2504.20042", "authors": ["Yu-Ju Tsai", "Brian Price", "Qing Liu", "Luis Figueroa", "Daniil Pakhomov", "Zhihong Ding", "Scott Cohen", "Ming-Hsuan Yang"], "title": "CompleteMe: Reference-based Human Image Completion", "categories": ["cs.CV"], "comment": "Project page: https://liagm.github.io/CompleteMe/", "summary": "Recent methods for human image completion can reconstruct plausible body\nshapes but often fail to preserve unique details, such as specific clothing\npatterns or distinctive accessories, without explicit reference images. Even\nstate-of-the-art reference-based inpainting approaches struggle to accurately\ncapture and integrate fine-grained details from reference images. To address\nthis limitation, we propose CompleteMe, a novel reference-based human image\ncompletion framework. CompleteMe employs a dual U-Net architecture combined\nwith a Region-focused Attention (RFA) Block, which explicitly guides the\nmodel's attention toward relevant regions in reference images. This approach\neffectively captures fine details and ensures accurate semantic correspondence,\nsignificantly improving the fidelity and consistency of completed images.\nAdditionally, we introduce a challenging benchmark specifically designed for\nevaluating reference-based human image completion tasks. Extensive experiments\ndemonstrate that our proposed method achieves superior visual quality and\nsemantic consistency compared to existing techniques. Project page:\nhttps://liagm.github.io/CompleteMe/", "AI": {"tldr": "CompleteMe is a novel framework for human image completion that uses a dual U-Net and Region-focused Attention Block to preserve fine details from reference images, outperforming existing methods.", "motivation": "Existing methods fail to preserve unique details like clothing patterns or accessories without explicit reference images, and even reference-based approaches struggle with fine-grained detail integration.", "method": "CompleteMe employs a dual U-Net architecture with a Region-focused Attention (RFA) Block to focus on relevant regions in reference images, ensuring accurate semantic correspondence.", "result": "The method achieves superior visual quality and semantic consistency compared to existing techniques, as demonstrated by extensive experiments.", "conclusion": "CompleteMe effectively addresses the limitations of current human image completion methods by improving fidelity and consistency in completed images."}}
{"id": "2504.19113", "pdf": "https://arxiv.org/pdf/2504.19113", "abs": "https://arxiv.org/abs/2504.19113", "authors": ["Satwik Kundu", "Swaroop Ghosh"], "title": "Inverse-Transpilation: Reverse-Engineering Quantum Compiler Optimization Passes from Circuit Snapshots", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Circuit compilation, a crucial process for adapting quantum algorithms to\nhardware constraints, often operates as a ``black box,'' with limited\nvisibility into the optimization techniques used by proprietary systems or\nadvanced open-source frameworks. Due to fundamental differences in qubit\ntechnologies, efficient compiler design is an expensive process, further\nexposing these systems to various security threats. In this work, we take a\nfirst step toward evaluating one such challenge affecting compiler\nconfidentiality, specifically, reverse-engineering compilation methodologies.\nWe propose a simple ML-based framework to infer underlying optimization\ntechniques by leveraging structural differences observed between original and\ncompiled circuits. The motivation is twofold: (1) enhancing transparency in\ncircuit optimization for improved cross-platform debugging and performance\ntuning, and (2) identifying potential intellectual property (IP)-protected\noptimizations employed by commercial systems. Our extensive evaluation across\nthousands of quantum circuits shows that a neural network performs the best in\ndetecting optimization passes, with individual pass F1-scores reaching as high\nas 0.96. Thus, our initial study demonstrates the viability of this threat to\ncompiler confidentiality and underscores the need for active research in this\narea.", "AI": {"tldr": "A study proposes an ML-based framework to reverse-engineer quantum circuit compilation techniques, aiming to enhance transparency and identify proprietary optimizations, achieving high accuracy in detecting optimization passes.", "motivation": "To improve transparency in quantum circuit compilation and identify potential IP-protected optimizations used in commercial systems.", "method": "A simple ML-based framework leveraging structural differences between original and compiled circuits to infer optimization techniques.", "result": "Neural networks achieved high accuracy (F1-scores up to 0.96) in detecting optimization passes.", "conclusion": "The study highlights a viable threat to compiler confidentiality and calls for further research in this area."}}
{"id": "2502.17049", "pdf": "https://arxiv.org/pdf/2502.17049", "abs": "https://arxiv.org/abs/2502.17049", "authors": ["Xin Zhang", "Liangxiu Han", "Stephen White", "Saad Hassan", "Philip A Kalra", "James Ritchie", "Carl Diver", "Jennie Shorley"], "title": "TabulaTime: A Novel Multimodal Deep Learning Framework for Advancing Acute Coronary Syndrome Prediction through Environmental and Clinical Data Integration", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Acute Coronary Syndromes (ACS), including ST-segment elevation myocardial\ninfarctions (STEMI) and non-ST-segment elevation myocardial infarctions\n(NSTEMI), remain a leading cause of mortality worldwide. Traditional\ncardiovascular risk scores rely primarily on clinical data, often overlooking\nenvironmental influences like air pollution that significantly impact heart\nhealth. Moreover, integrating complex time-series environmental data with\nclinical records is challenging.\n  We introduce TabulaTime, a multimodal deep learning framework that enhances\nACS risk prediction by combining clinical risk factors with air pollution data.\nTabulaTime features three key innovations: First, it integrates time-series air\npollution data with clinical tabular data to improve prediction accuracy.\nSecond, its PatchRWKV module automatically extracts complex temporal patterns,\novercoming limitations of traditional feature engineering while maintaining\nlinear computational complexity. Third, attention mechanisms enhance\ninterpretability by revealing interactions between clinical and environmental\nfactors.\n  Experimental results show that TabulaTime improves prediction accuracy by\nover 20% compared to conventional models such as CatBoost, Random Forest, and\nLightGBM, with air pollution data alone contributing over a 10% improvement.\nFeature importance analysis identifies critical predictors including previous\nangina, systolic blood pressure, PM10, and NO2. Overall, TabulaTime bridges\nclinical and environmental insights, supporting personalized prevention\nstrategies and informing public health policies to mitigate ACS risk.", "AI": {"tldr": "TabulaTime is a multimodal deep learning framework that combines clinical and air pollution data to improve ACS risk prediction, outperforming traditional models by over 20%.", "motivation": "Traditional cardiovascular risk scores overlook environmental factors like air pollution, which significantly impact heart health. Integrating such data with clinical records is challenging.", "method": "TabulaTime integrates time-series air pollution and clinical data, uses PatchRWKV for temporal pattern extraction, and employs attention mechanisms for interpretability.", "result": "TabulaTime improves prediction accuracy by over 20%, with air pollution data alone contributing over 10%. Key predictors include previous angina, systolic blood pressure, PM10, and NO2.", "conclusion": "TabulaTime bridges clinical and environmental insights, aiding personalized prevention and public health policies to reduce ACS risk."}}
{"id": "2409.03140", "pdf": "https://arxiv.org/pdf/2409.03140", "abs": "https://arxiv.org/abs/2409.03140", "authors": ["Ashirbad Mishra", "Soumik Dey", "Marshall Wu", "Jinyu Zhao", "He Yu", "Kaichen Ni", "Binbin Li", "Kamesh Madduri"], "title": "GraphEx: A Graph-based Extraction Method for Advertiser Keyphrase Recommendation", "categories": ["cs.IR", "cs.CL", "cs.LG"], "comment": null, "summary": "Online sellers and advertisers are recommended keyphrases for their listed\nproducts, which they bid on to enhance their sales. One popular paradigm that\ngenerates such recommendations is Extreme Multi-Label Classification (XMC),\nwhich involves tagging/mapping keyphrases to items. We outline the limitations\nof using traditional item-query based tagging or mapping techniques for\nkeyphrase recommendations on E-Commerce platforms. We introduce GraphEx, an\ninnovative graph-based approach that recommends keyphrases to sellers using\nextraction of token permutations from item titles. Additionally, we demonstrate\nthat relying on traditional metrics such as precision/recall can be misleading\nin practical applications, thereby necessitating a combination of metrics to\nevaluate performance in real-world scenarios. These metrics are designed to\nassess the relevance of keyphrases to items and the potential for buyer\noutreach. GraphEx outperforms production models at eBay, achieving the\nobjectives mentioned above. It supports near real-time inferencing in\nresource-constrained production environments and scales effectively for\nbillions of items.", "AI": {"tldr": "GraphEx, a graph-based approach, outperforms traditional methods for keyphrase recommendations in e-commerce by using token permutations from item titles and combining metrics for better evaluation.", "motivation": "Traditional item-query based tagging techniques are limited for keyphrase recommendations in e-commerce, prompting the need for an innovative solution like GraphEx.", "method": "GraphEx extracts token permutations from item titles and uses a graph-based approach to recommend keyphrases, evaluated with combined metrics.", "result": "GraphEx outperforms eBay's production models, supports real-time inferencing, and scales for billions of items.", "conclusion": "GraphEx is an effective solution for keyphrase recommendations, addressing limitations of traditional methods and improving practical performance."}}
{"id": "2504.18540", "pdf": "https://arxiv.org/pdf/2504.18540", "abs": "https://arxiv.org/abs/2504.18540", "authors": ["Gon\u00e7alo Hora de Carvalho"], "title": "Exploring Visual Complaints through a test battery in Acquired Brain Injury Patients: A Detailed Analysis of the DiaNAH Dataset", "categories": ["q-bio.NC", "cs.CV", "q-bio.QM"], "comment": null, "summary": "This study investigated visual impairment complaints in a sample of 948\nAcquired Brain Injury (ABI) patients using the DiaNAH dataset, emphasizing\nadvanced machine learning techniques for managing missing data. Patients\ncompleted a CVS questionnaire capturing eight types of visual symptoms,\nincluding blurred vision and altered contrast perception. Due to incomplete\ndata, 181 patients were excluded, resulting in an analytical subset of 767\nindividuals. To address the challenge of missing data, an automated machine\nlearning (AutoML) approach was employed for data imputation, preserving the\ndistributional characteristics of the original dataset. Patients were grouped\naccording to singular and combined complaint clusters derived from the 40,320\npotential combinations identified through the CVS questionnaire. A linear\ncorrelation analysis revealed minimal to no direct relationship between\npatient-reported visual complaints and standard visual perceptual function\ntests. This study represents an initial systematic attempt to understand the\ncomplex relationship between subjective visual complaints and objective visual\nperceptual assessments in ABI patients. Given the limitations of sample size\nand variability, further studies with larger populations are recommended to\nrobustly explore these complaint clusters and their implications for visual\nperception following brain injury.", "AI": {"tldr": "The study analyzed visual impairment complaints in 948 ABI patients, using AutoML for missing data imputation, and found minimal correlation between subjective complaints and objective tests.", "motivation": "To systematically explore the relationship between subjective visual complaints and objective visual perceptual assessments in ABI patients.", "method": "Used the DiaNAH dataset, employed AutoML for missing data imputation, and grouped patients by complaint clusters from a CVS questionnaire. Linear correlation analysis was performed.", "result": "Minimal to no direct relationship between patient-reported visual complaints and standard visual perceptual function tests.", "conclusion": "Further studies with larger populations are needed to robustly explore complaint clusters and their implications for visual perception post-brain injury."}}
{"id": "2504.19145", "pdf": "https://arxiv.org/pdf/2504.19145", "abs": "https://arxiv.org/abs/2504.19145", "authors": ["Abhishek Pasula", "Deepak N. Subramani"], "title": "Global Climate Model Bias Correction Using Deep Learning", "categories": ["physics.ao-ph", "cs.LG", "stat.AP"], "comment": "40 pages, 15 figures", "summary": "Climate change affects ocean temperature, salinity and sea level, impacting\nmonsoons and ocean productivity. Future projections by Global Climate Models\nbased on shared socioeconomic pathways from the Coupled Model Intercomparison\nProject (CMIP) are widely used to understand the effects of climate change.\nHowever, CMIP models have significant bias compared to reanalysis in the Bay of\nBengal for the time period when both projections and reanalysis are available.\nFor example, there is a 1.5C root mean square error (RMSE) in the sea surface\ntemperature (SST) projections of the climate model CNRM-CM6 compared to the\nOcean Reanalysis System (ORAS5). We develop a suite of data-driven deep\nlearning models for bias correction of climate model projections and apply it\nto correct SST projections of the Bay of Bengal. We propose the use of three\ndifferent deep neural network architectures: convolutional encoder-decoder\nUNet, Bidirectional LSTM and ConvLSTM. We also use a baseline linear regression\nmodel and the Equi-Distant Cumulative Density Function (EDCDF) bias correction\nmethod for comparison and evaluating the impact of the new deep learning\nmodels. All bias correction models are trained using pairs of monthly CMIP6\nprojections and the corresponding month's ORAS5 as input and output. Historical\ndata (1950-2014) and future projection data (2015-2020) of CNRM-CM6 are used\nfor training and validation, including hyperparameter tuning. Testing is\nperformed on future projection data from 2021 to 2024. Detailed analysis of the\nthree deep neural models has been completed. We found that the UNet\narchitecture trained using a climatology-removed CNRM-CM6 projection as input\nand climatology-removed ORAS5 as output gives the best bias-corrected\nprojections. Our novel deep learning-based method for correcting CNRM-CM6 data\nhas a 15% reduction in RMSE compared EDCDF.", "AI": {"tldr": "The paper addresses bias in CMIP6 climate models for the Bay of Bengal using deep learning, achieving a 15% RMSE reduction with a UNet model.", "motivation": "To improve the accuracy of climate model projections by correcting biases in sea surface temperature (SST) data from CMIP6 models compared to reanalysis data (ORAS5).", "method": "Developed three deep learning models (UNet, Bidirectional LSTM, ConvLSTM) and compared them to linear regression and EDCDF methods for bias correction.", "result": "The UNet model, trained on climatology-removed data, performed best, reducing RMSE by 15% compared to EDCDF.", "conclusion": "Deep learning, particularly UNet, is effective for bias correction in climate models, offering improved accuracy for future projections."}}
{"id": "2502.19546", "pdf": "https://arxiv.org/pdf/2502.19546", "abs": "https://arxiv.org/abs/2502.19546", "authors": ["Anton Alyakin", "Jaden Stryker", "Daniel Alexander Alber", "Karl L. Sangwon", "Jin Vivian Lee", "Brandon Duderstadt", "Akshay Save", "David Kurland", "Spencer Frome", "Shrutika Singh", "Jeff Zhang", "Eunice Yang", "Ki Yun Park", "Cordelia Orillac", "Aly A. Valliani", "Sean Neifert", "Albert Liu", "Aneek Patel", "Christopher Livia", "Darryl Lau", "Ilya Laufer", "Peter A. Rozman", "Eveline Teresa Hidalgo", "Howard Riina", "Rui Feng", "Todd Hollon", "Yindalon Aphinyanaphongs", "John G. Golfinos", "Laura Snyder", "Eric Leuthardt", "Douglas Kondziolka", "Eric Karl Oermann"], "title": "Repurposing the scientific literature with vision-language models", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Leading vision-language models (VLMs) are trained on general Internet\ncontent, overlooking scientific journals' rich, domain-specific knowledge.\nTraining on specialty-specific literature could yield high-performance,\ntask-specific tools, enabling generative AI to match generalist models in\nspecialty publishing, educational, and clinical tasks. We created NeuroPubs, a\nmultimodal dataset of 23,000 Neurosurgery Publications articles (134M words,\n78K image-caption pairs). Using NeuroPubs, VLMs generated publication-ready\ngraphical abstracts (70% of 100 abstracts) and board-style questions\nindistinguishable from human-written ones (54% of 89,587 questions). We used\nthese questions to train CNS-Obsidian, a 34B-parameter VLM. In a blinded,\nrandomized controlled trial, our model demonstrated non-inferiority to then\nstate-of-the-art GPT-4o in neurosurgical differential diagnosis (clinical\nutility, 40.62% upvotes vs. 57.89%, p=0.1150; accuracy, 59.38% vs. 65.79%,\np=0.3797). Our pilot study demonstrates how training generative AI models on\nspecialty-specific journal content - without large-scale internet data -\nresults in high-performance academic and clinical tools, enabling\ndomain-tailored AI across diverse fields.", "AI": {"tldr": "Training VLMs on neurosurgery-specific data (NeuroPubs) yields high-performance tools for academic and clinical tasks, matching GPT-4o in some areas.", "motivation": "General VLMs overlook domain-specific knowledge in scientific journals, limiting their utility in specialty tasks like neurosurgery.", "method": "Created NeuroPubs (23K articles, 134M words, 78K image-caption pairs) and trained CNS-Obsidian (34B-parameter VLM) for tasks like generating graphical abstracts and board-style questions.", "result": "Achieved 70% success in graphical abstracts and 54% in indistinguishable board-style questions; CNS-Obsidian matched GPT-4o in neurosurgical diagnosis (non-inferiority shown).", "conclusion": "Specialty-specific training enables high-performance AI tools without relying on large-scale internet data, applicable across diverse fields."}}
{"id": "2410.08847", "pdf": "https://arxiv.org/pdf/2410.08847", "abs": "https://arxiv.org/abs/2410.08847", "authors": ["Noam Razin", "Sadhika Malladi", "Adithya Bhaskar", "Danqi Chen", "Sanjeev Arora", "Boris Hanin"], "title": "Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "Accepted to ICLR 2025; Code available at\n  https://github.com/princeton-nlp/unintentional-unalignment", "summary": "Direct Preference Optimization (DPO) and its variants are increasingly used\nfor aligning language models with human preferences. Although these methods are\ndesigned to teach a model to generate preferred responses more frequently\nrelative to dispreferred responses, prior work has observed that the likelihood\nof preferred responses often decreases during training. The current work sheds\nlight on the causes and implications of this counter-intuitive phenomenon,\nwhich we term likelihood displacement. We demonstrate that likelihood\ndisplacement can be catastrophic, shifting probability mass from preferred\nresponses to responses with an opposite meaning. As a simple example, training\na model to prefer $\\texttt{No}$ over $\\texttt{Never}$ can sharply increase the\nprobability of $\\texttt{Yes}$. Moreover, when aligning the model to refuse\nunsafe prompts, we show that such displacement can unintentionally lead to\nunalignment, by shifting probability mass from preferred refusal responses to\nharmful responses (e.g., reducing the refusal rate of Llama-3-8B-Instruct from\n74.4% to 33.4%). We theoretically characterize that likelihood displacement is\ndriven by preferences that induce similar embeddings, as measured by a centered\nhidden embedding similarity (CHES) score. Empirically, the CHES score enables\nidentifying which training samples contribute most to likelihood displacement\nin a given dataset. Filtering out these samples effectively mitigated\nunintentional unalignment in our experiments. More broadly, our results\nhighlight the importance of curating data with sufficiently distinct\npreferences, for which we believe the CHES score may prove valuable.", "AI": {"tldr": "DPO and variants align models with human preferences but can reduce the likelihood of preferred responses, termed likelihood displacement, which may shift probability to opposite or harmful responses. A CHES score identifies problematic samples, and filtering them mitigates unalignment.", "motivation": "To understand why preferred responses' likelihood decreases during DPO training and its implications, including unintended shifts to harmful responses.", "method": "Theoretical analysis using CHES score to measure embedding similarity and empirical validation by filtering problematic samples.", "result": "Likelihood displacement is driven by similar embeddings; CHES score identifies problematic samples, and filtering them reduces unalignment.", "conclusion": "Data curation with distinct preferences is crucial; CHES score aids in identifying and mitigating likelihood displacement."}}
{"id": "2504.18768", "pdf": "https://arxiv.org/pdf/2504.18768", "abs": "https://arxiv.org/abs/2504.18768", "authors": ["Letian Huang", "Dongwei Ye", "Jialin Dan", "Chengzhi Tao", "Huiwen Liu", "Kun Zhou", "Bo Ren", "Yuanqi Li", "Yanwen Guo", "Jie Guo"], "title": "TransparentGS: Fast Inverse Rendering of Transparent Objects with Gaussians", "categories": ["cs.GR", "cs.CV"], "comment": "accepted by SIGGRAPH 2025;\n  https://letianhuang.github.io/transparentgs/", "summary": "The emergence of neural and Gaussian-based radiance field methods has led to\nconsiderable advancements in novel view synthesis and 3D object reconstruction.\nNonetheless, specular reflection and refraction continue to pose significant\nchallenges due to the instability and incorrect overfitting of radiance fields\nto high-frequency light variations. Currently, even 3D Gaussian Splatting\n(3D-GS), as a powerful and efficient tool, falls short in recovering\ntransparent objects with nearby contents due to the existence of apparent\nsecondary ray effects. To address this issue, we propose TransparentGS, a fast\ninverse rendering pipeline for transparent objects based on 3D-GS. The main\ncontributions are three-fold. Firstly, an efficient representation of\ntransparent objects, transparent Gaussian primitives, is designed to enable\nspecular refraction through a deferred refraction strategy. Secondly, we\nleverage Gaussian light field probes (GaussProbe) to encode both ambient light\nand nearby contents in a unified framework. Thirdly, a depth-based iterative\nprobes query (IterQuery) algorithm is proposed to reduce the parallax errors in\nour probe-based framework. Experiments demonstrate the speed and accuracy of\nour approach in recovering transparent objects from complex environments, as\nwell as several applications in computer graphics and vision.", "AI": {"tldr": "TransparentGS improves 3D-GS for transparent objects by introducing transparent Gaussian primitives, GaussProbe for light encoding, and IterQuery for parallax error reduction.", "motivation": "Existing radiance field methods struggle with specular reflection and refraction, especially for transparent objects with nearby contents.", "method": "Proposes TransparentGS with transparent Gaussian primitives, GaussProbe for light encoding, and IterQuery for parallax reduction.", "result": "Demonstrates speed and accuracy in recovering transparent objects from complex environments.", "conclusion": "TransparentGS advances transparent object reconstruction with applications in graphics and vision."}}
{"id": "2504.19231", "pdf": "https://arxiv.org/pdf/2504.19231", "abs": "https://arxiv.org/abs/2504.19231", "authors": ["Alexander Dubbs"], "title": "Test Set Sizing for the Ridge Regression", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "We derive the ideal train/test split for the ridge regression to high\naccuracy in the limit that the number of training rows m becomes large. The\nsplit must depend on the ridge tuning parameter, alpha, but we find that the\ndependence is weak and can asymptotically be ignored; all parameters vanish\nexcept for m and the number of features, n. This is the first time that such a\nsplit is calculated mathematically for a machine learning model in the large\ndata limit. The goal of the calculations is to maximize \"integrity,\" so that\nthe measured error in the trained model is as close as possible to what it\ntheoretically should be. This paper's result for the ridge regression split\nmatches prior art for the plain vanilla linear regression split to the first\ntwo terms asymptotically, and it appears that practically there is no\ndifference.", "AI": {"tldr": "The paper derives the ideal train/test split for ridge regression in the large-data limit, showing weak dependence on the ridge parameter and matching prior linear regression results.", "motivation": "To maximize integrity by ensuring the measured error in the trained model aligns closely with theoretical expectations.", "method": "Derives the split mathematically for ridge regression in the limit of large training data, focusing on the relationship between training rows (m) and features (n).", "result": "The split depends weakly on the ridge parameter (alpha) and asymptotically matches prior linear regression results, showing no practical difference.", "conclusion": "The derived split for ridge regression is mathematically validated and practically equivalent to prior linear regression splits."}}
{"id": "2502.20601", "pdf": "https://arxiv.org/pdf/2502.20601", "abs": "https://arxiv.org/abs/2502.20601", "authors": ["Saman Khamesian", "Asiful Arefeen", "Stephanie M. Carpenter", "Hassan Ghasemzadeh"], "title": "NutriGen: Personalized Meal Plan Generator Leveraging Large Language Models to Enhance Dietary and Nutritional Adherence", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Maintaining a balanced diet is essential for overall health, yet many\nindividuals struggle with meal planning due to nutritional complexity, time\nconstraints, and lack of dietary knowledge. Personalized food recommendations\ncan help address these challenges by tailoring meal plans to individual\npreferences, habits, and dietary restrictions. However, existing dietary\nrecommendation systems often lack adaptability, fail to consider real-world\nconstraints such as food ingredient availability, and require extensive user\ninput, making them impractical for sustainable and scalable daily use. To\naddress these limitations, we introduce NutriGen, a framework based on large\nlanguage models (LLM) designed to generate personalized meal plans that align\nwith user-defined dietary preferences and constraints. By building a\npersonalized nutrition database and leveraging prompt engineering, our approach\nenables LLMs to incorporate reliable nutritional references like the USDA\nnutrition database while maintaining flexibility and ease-of-use. We\ndemonstrate that LLMs have strong potential in generating accurate and\nuser-friendly food recommendations, addressing key limitations in existing\ndietary recommendation systems by providing structured, practical, and scalable\nmeal plans. Our evaluation shows that Llama 3.1 8B and GPT-3.5 Turbo achieve\nthe lowest percentage errors of 1.55\\% and 3.68\\%, respectively, producing meal\nplans that closely align with user-defined caloric targets while minimizing\ndeviation and improving precision. Additionally, we compared the performance of\nDeepSeek V3 against several established models to evaluate its potential in\npersonalized nutrition planning.", "AI": {"tldr": "NutriGen, an LLM-based framework, generates personalized meal plans addressing dietary constraints and preferences, outperforming existing systems with low error rates.", "motivation": "Many struggle with meal planning due to complexity, time, and lack of knowledge. Current systems lack adaptability and practicality.", "method": "NutriGen uses LLMs (e.g., Llama 3.1 8B, GPT-3.5 Turbo) and a personalized nutrition database with prompt engineering for accurate recommendations.", "result": "LLMs achieve low error rates (1.55% and 3.68%), closely aligning with caloric targets and improving precision.", "conclusion": "LLMs show strong potential for scalable, accurate, and user-friendly dietary recommendations, addressing existing system limitations."}}
{"id": "2410.12735", "pdf": "https://arxiv.org/pdf/2410.12735", "abs": "https://arxiv.org/abs/2410.12735", "authors": ["Zhaoyang Wang", "Weilei He", "Zhiyuan Liang", "Xuchao Zhang", "Chetan Bansal", "Ying Wei", "Weitong Zhang", "Huaxiu Yao"], "title": "CREAM: Consistency Regularized Self-Rewarding Language Models", "categories": ["cs.LG", "cs.CL"], "comment": "To appear at ICLR 2025", "summary": "Recent self-rewarding large language models (LLM) have successfully applied\nLLM-as-a-Judge to iteratively improve the alignment performance without the\nneed of human annotations for preference data. These methods commonly utilize\nthe same LLM to act as both the policy model (which generates responses) and\nthe reward model (which scores and ranks those responses). The ranked responses\nare then used as preference pairs to train the LLM via direct alignment\ntechnologies (e.g. DPO). However, it is noteworthy that throughout this\nprocess, there is no guarantee of accuracy in the rewarding and ranking, which\nis critical for ensuring accurate rewards and high-quality preference data.\nEmpirical results from relatively small LLMs (e.g., 7B parameters) also\nindicate that improvements from self-rewarding may diminish after several\niterations in certain situations, which we hypothesize is due to accumulated\nbias in the reward system. This bias can lead to unreliable preference data for\ntraining the LLM. To address this issue, we first formulate and analyze the\ngeneralized iterative preference fine-tuning framework for self-rewarding\nlanguage model. We then introduce the regularization to this generalized\nframework to mitigate the overconfident preference labeling in the\nself-rewarding process. Based on this theoretical insight, we propose a\nConsistency Regularized sElf-rewarding lAnguage Model (CREAM) that leverages\nthe consistency of rewards across different iterations to regularize the\nself-rewarding training, helping the model to learn from more reliable\npreference data. With this explicit regularization, our empirical results\ndemonstrate the superiority of CREAM in improving both reward consistency and\nalignment performance. The code is publicly available at\nhttps://github.com/Raibows/CREAM.", "AI": {"tldr": "The paper introduces CREAM, a self-rewarding LLM framework with regularization to mitigate bias and improve alignment performance by ensuring reward consistency.", "motivation": "Addressing the lack of accuracy and accumulated bias in self-rewarding LLMs, which can degrade alignment performance over iterations.", "method": "Proposes CREAM, a framework with regularization to ensure reward consistency across iterations, improving the reliability of preference data.", "result": "Empirical results show CREAM enhances reward consistency and alignment performance compared to standard self-rewarding methods.", "conclusion": "CREAM effectively mitigates bias in self-rewarding LLMs, leading to more reliable preference data and improved alignment."}}
{"id": "2504.18829", "pdf": "https://arxiv.org/pdf/2504.18829", "abs": "https://arxiv.org/abs/2504.18829", "authors": ["Jiayi Chen", "Yubin Ke", "Lin Peng", "He Wang"], "title": "Dexonomy: Synthesizing All Dexterous Grasp Types in a Grasp Taxonomy", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted by Robotics: Science and Systems (RSS 2025)", "summary": "Generalizable dexterous grasping with suitable grasp types is a fundamental\nskill for intelligent robots. Developing such skills requires a large-scale and\nhigh-quality dataset that covers numerous grasp types (i.e., at least those\ncategorized by the GRASP taxonomy), but collecting such data is extremely\nchallenging. Existing automatic grasp synthesis methods are often limited to\nspecific grasp types or object categories, hindering scalability. This work\nproposes an efficient pipeline capable of synthesizing contact-rich,\npenetration-free, and physically plausible grasps for any grasp type, object,\nand articulated hand. Starting from a single human-annotated template for each\nhand and grasp type, our pipeline tackles the complicated synthesis problem\nwith two stages: optimize the object to fit the hand template first, and then\nlocally refine the hand to fit the object in simulation. To validate the\nsynthesized grasps, we introduce a contact-aware control strategy that allows\nthe hand to apply the appropriate force at each contact point to the object.\nThose validated grasps can also be used as new grasp templates to facilitate\nfuture synthesis. Experiments show that our method significantly outperforms\nprevious type-unaware grasp synthesis baselines in simulation. Using our\nalgorithm, we construct a dataset containing 10.7k objects and 9.5M grasps,\ncovering 31 grasp types in the GRASP taxonomy. Finally, we train a\ntype-conditional generative model that successfully performs the desired grasp\ntype from single-view object point clouds, achieving an 82.3% success rate in\nreal-world experiments. Project page: https://pku-epic.github.io/Dexonomy.", "AI": {"tldr": "A pipeline for synthesizing diverse, physically plausible grasps for any object and hand, validated by a contact-aware control strategy, outperforming baselines and enabling a large-scale dataset.", "motivation": "Addressing the challenge of collecting large-scale, high-quality grasp datasets for diverse grasp types and objects, which is essential for generalizable dexterous grasping in robots.", "method": "A two-stage pipeline: first optimizes the object to fit a hand template, then refines the hand to fit the object in simulation, validated by a contact-aware control strategy.", "result": "Outperforms type-unaware baselines, creates a dataset with 10.7k objects and 9.5M grasps (31 grasp types), and achieves an 82.3% success rate in real-world experiments.", "conclusion": "The method enables scalable grasp synthesis and generalizable grasping, validated by real-world performance and a large dataset."}}
{"id": "2504.19239", "pdf": "https://arxiv.org/pdf/2504.19239", "abs": "https://arxiv.org/abs/2504.19239", "authors": ["Yoshiaki Kawase"], "title": "The effect of the number of parameters and the number of local feature patches on loss landscapes in distributed quantum neural networks", "categories": ["quant-ph", "cs.LG"], "comment": "9 pages + Appendices", "summary": "Quantum neural networks hold promise for tackling computationally challenging\ntasks that are intractable for classical computers. However, their practical\napplication is hindered by significant optimization challenges, arising from\ncomplex loss landscapes characterized by barren plateaus and numerous local\nminima. These problems become more severe as the number of parameters or qubits\nincreases, hampering effective training. To mitigate these optimization\nchallenges, particularly for quantum machine learning applied to classical\ndata, we employ an approach of distributing overlapping local patches across\nmultiple quantum neural networks, processing each patch with an independent\nquantum neural network, and aggregating their outputs for prediction. In this\nstudy, we investigate how the number of parameters and patches affects the loss\nlandscape geometry of this distributed quantum neural network architecture via\nHessian analysis and loss landscape visualization. Our results confirm that\nincreasing the number of parameters tends to lead to deeper and sharper loss\nlandscapes. Crucially, we demonstrate that increasing the number of patches\nsignificantly reduces the largest Hessian eigenvalue at minima. This finding\nsuggests that our distributed patch approach acts as a form of implicit\nregularization, promoting optimization stability and potentially enhancing\ngeneralization. Our study provides valuable insights into optimization\nchallenges and highlights that the distributed patch approach is a promising\nstrategy for developing more trainable and practical quantum machine learning\nmodels for classical data tasks.", "AI": {"tldr": "The paper explores a distributed patch approach to mitigate optimization challenges in quantum neural networks, showing it reduces loss landscape complexity and improves stability.", "motivation": "Quantum neural networks face optimization difficulties like barren plateaus and local minima, especially with more parameters or qubits, limiting practical applications.", "method": "The study uses a distributed approach with overlapping local patches processed by independent quantum neural networks, analyzing effects via Hessian analysis and loss landscape visualization.", "result": "Increasing parameters deepens loss landscapes, but more patches reduce the largest Hessian eigenvalue, suggesting implicit regularization and better optimization stability.", "conclusion": "The distributed patch approach is promising for enhancing trainability and practicality of quantum machine learning models for classical data tasks."}}
{"id": "2503.10619", "pdf": "https://arxiv.org/pdf/2503.10619", "abs": "https://arxiv.org/abs/2503.10619", "authors": ["Andy Zhou"], "title": "Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search", "categories": ["cs.AI", "cs.CL", "cs.CR"], "comment": "Accepted to ICLR 2025 Trustworthy LLM", "summary": "We introduce Siege, a multi-turn adversarial framework that models the\ngradual erosion of Large Language Model (LLM) safety through a tree search\nperspective. Unlike single-turn jailbreaks that rely on one meticulously\nengineered prompt, Siege expands the conversation at each turn in a\nbreadth-first fashion, branching out multiple adversarial prompts that exploit\npartial compliance from previous responses. By tracking these incremental\npolicy leaks and re-injecting them into subsequent queries, Siege reveals how\nminor concessions can accumulate into fully disallowed outputs. Evaluations on\nthe JailbreakBench dataset show that Siege achieves a 100% success rate on\nGPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries\nthan baselines such as Crescendo or GOAT. This tree search methodology offers\nan in-depth view of how model safeguards degrade over successive dialogue\nturns, underscoring the urgency of robust multi-turn testing procedures for\nlanguage models.", "AI": {"tldr": "Siege is a multi-turn adversarial framework that erodes LLM safety via tree search, achieving high jailbreak success rates with fewer queries.", "motivation": "To understand how minor concessions in LLM responses can accumulate into fully disallowed outputs, highlighting the need for robust multi-turn testing.", "method": "Uses breadth-first tree search to expand adversarial prompts incrementally, exploiting partial compliance from previous responses.", "result": "Achieves 100% success on GPT-3.5-turbo and 97% on GPT-4, outperforming baselines like Crescendo or GOAT.", "conclusion": "Siege reveals the vulnerability of LLM safeguards over successive turns, emphasizing the need for stronger multi-turn testing."}}
{"id": "2410.18252", "pdf": "https://arxiv.org/pdf/2410.18252", "abs": "https://arxiv.org/abs/2410.18252", "authors": ["Michael Noukhovitch", "Shengyi Huang", "Sophie Xhonneux", "Arian Hosseini", "Rishabh Agarwal", "Aaron Courville"], "title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "accepted at ICLR 2025, code at\n  https://github.com/mnoukhov/async_rlhf, integrated into the open-instruct\n  library https://github.com/allenai/open-instruct", "summary": "The dominant paradigm for RLHF is online and on-policy RL: synchronously\ngenerating from the large language model (LLM) policy, labelling with a reward\nmodel, and learning using feedback on the LLM's own outputs. While performant,\nthis paradigm is computationally inefficient. Inspired by classical deep RL\nliterature, we propose separating generation and learning in RLHF. This enables\nasynchronous generation of new samples while simultaneously training on old\nsamples, leading to faster training and more compute-optimal scaling. However,\nasynchronous training relies on an underexplored regime, online but off-policy\nRLHF: learning on samples from previous iterations of our model which give a\nworse training signal. We tackle the fundamental challenge in this regime: how\nmuch off-policyness can we tolerate for asynchronous training to speed up\nlearning but maintain performance? Among several RLHF algorithms we test,\nonline DPO is found to be most robust to off-policy data, and robustness\nincreases with the scale of the policy model. We study further compute\noptimizations for asynchronous RLHF but find that they come at a performance\ncost, giving rise to a trade-off. We verify the scalability of asynchronous\nRLHF by training a general-purpose chatbot from LLaMA 3.1 8B on an\ninstruction-following task ~40% faster than a synchronous run while matching\nfinal performance. Finally, we extend our results to math and reasoning to\ndemonstrate asynchronous RL can finetune Rho 1B on GSM8k ~70% faster while\nmatching synchronous accuracy.", "AI": {"tldr": "The paper proposes asynchronous RLHF for faster training by separating generation and learning, finding online DPO robust to off-policy data, and validating scalability with a chatbot and math task.", "motivation": "Current RLHF methods are computationally inefficient due to synchronous generation and learning. The goal is to improve efficiency without sacrificing performance.", "method": "Separates generation and learning in RLHF, enabling asynchronous training. Tests various RLHF algorithms, focusing on online DPO's robustness to off-policy data.", "result": "Asynchronous RLHF trains a chatbot 40% faster and a math model 70% faster while matching synchronous performance.", "conclusion": "Asynchronous RLHF offers a compute-efficient alternative to synchronous methods, with online DPO being particularly robust to off-policy data."}}
{"id": "2504.19174", "pdf": "https://arxiv.org/pdf/2504.19174", "abs": "https://arxiv.org/abs/2504.19174", "authors": ["Xueqi Ma", "Yilin Liu", "Tianlong Gao", "Qirui Huang", "Hui Huang"], "title": "CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025", "summary": "We introduce CLR-Wire, a novel framework for 3D curve-based wireframe\ngeneration that integrates geometry and topology into a unified Continuous\nLatent Representation. Unlike conventional methods that decouple vertices,\nedges, and faces, CLR-Wire encodes curves as Neural Parametric Curves along\nwith their topological connectivity into a continuous and fixed-length latent\nspace using an attention-driven variational autoencoder (VAE). This unified\napproach facilitates joint learning and generation of both geometry and\ntopology. To generate wireframes, we employ a flow matching model to\nprogressively map Gaussian noise to these latents, which are subsequently\ndecoded into complete 3D wireframes. Our method provides fine-grained modeling\nof complex shapes and irregular topologies, and supports both unconditional\ngeneration and generation conditioned on point cloud or image inputs.\nExperimental results demonstrate that, compared with state-of-the-art\ngenerative approaches, our method achieves substantial improvements in\naccuracy, novelty, and diversity, offering an efficient and comprehensive\nsolution for CAD design, geometric reconstruction, and 3D content creation.", "AI": {"tldr": "CLR-Wire is a framework for 3D wireframe generation using a unified latent representation for geometry and topology, outperforming existing methods in accuracy and diversity.", "motivation": "Traditional methods separate geometry and topology; CLR-Wire unifies them for better joint learning and generation.", "method": "Uses an attention-driven VAE to encode curves and topology into a latent space, then employs flow matching to generate wireframes.", "result": "Achieves higher accuracy, novelty, and diversity compared to state-of-the-art methods.", "conclusion": "CLR-Wire offers an efficient solution for CAD design, reconstruction, and 3D content creation."}}
{"id": "2504.19264", "pdf": "https://arxiv.org/pdf/2504.19264", "abs": "https://arxiv.org/abs/2504.19264", "authors": ["Angel Mary John", "Jerrin Thomas Panachakel", "Anusha S. P"], "title": "Navigating AI Policy Landscapes: Insights into Human Rights Considerations Across IEEE Regions", "categories": ["cs.CY", "cs.LG"], "comment": "2024 IEEE 12th Region 10 Humanitarian Technology Conference\n  (R10-HTC). IEEE, 2024", "summary": "This paper explores the integration of human rights considerations into AI\nregulatory frameworks across different IEEE regions - specifically the United\nStates (Region 1-6), Europe (Region 8), China (part of Region 10), and\nSingapore (part of Region 10). While all acknowledge the transformative\npotential of AI and the necessity of ethical guidelines, their regulatory\napproaches significantly differ. Europe exhibits a rigorous framework with\nstringent protections for individual rights, while the U.S. promotes innovation\nwith less restrictive regulations. China emphasizes state control and societal\norder in its AI strategies. In contrast, Singapore's advisory framework\nencourages self-regulation and aligns closely with international norms. This\ncomparative analysis underlines the need for ongoing global dialogue to\nharmonize AI regulations that safeguard human rights while promoting\ntechnological advancement, reflecting the diverse perspectives and priorities\nof each region.", "AI": {"tldr": "Comparative analysis of AI regulatory frameworks in IEEE regions (US, Europe, China, Singapore) highlights diverse approaches to human rights and ethics, emphasizing the need for global dialogue.", "motivation": "To examine how human rights considerations are integrated into AI regulations across different regions and identify gaps or disparities.", "method": "Comparative analysis of AI regulatory frameworks in the US (Region 1-6), Europe (Region 8), China (part of Region 10), and Singapore (part of Region 10).", "result": "Europe has stringent protections, the US prioritizes innovation, China focuses on state control, and Singapore promotes self-regulation aligned with international norms.", "conclusion": "Global dialogue is essential to harmonize AI regulations, balancing human rights protection with technological advancement."}}
{"id": "2504.04736", "pdf": "https://arxiv.org/pdf/2504.04736", "abs": "https://arxiv.org/abs/2504.04736", "authors": ["Anna Goldie", "Azalia Mirhoseini", "Hao Zhou", "Irene Cai", "Christopher D. Manning"], "title": "Synthetic Data Generation & Multi-Step RL for Reasoning & Tool Use", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Reinforcement learning has been shown to improve the performance of large\nlanguage models. However, traditional approaches like RLHF or RLAIF treat the\nproblem as single-step. As focus shifts toward more complex reasoning and\nagentic tasks, language models must take multiple steps of text generation,\nreasoning and environment interaction before generating a solution. We propose\na synthetic data generation and RL methodology targeting multi-step\noptimization scenarios. This approach, called Step-Wise Reinforcement Learning\n(SWiRL), iteratively generates multi-step reasoning and tool use data, and then\nlearns from that data. It employs a simple step-wise decomposition that breaks\neach multi-step trajectory into multiple sub-trajectories corresponding to each\naction by the original model. It then applies synthetic data filtering and RL\noptimization on these sub-trajectories. We evaluated SWiRL on a number of\nmulti-step tool use, question answering, and mathematical reasoning tasks. Our\nexperiments show that SWiRL outperforms baseline approaches by 21.5%, 12.3%,\n14.8%, 11.1%, and 15.3% in relative accuracy on GSM8K, HotPotQA, CofCA,\nMuSiQue, and BeerQA, respectively. Excitingly, the approach exhibits\ngeneralization across tasks: for example, training only on HotPotQA (text\nquestion-answering) improves zero-shot performance on GSM8K (a math dataset) by\na relative 16.9%.", "AI": {"tldr": "SWiRL introduces a multi-step reinforcement learning approach for language models, outperforming baselines on reasoning tasks.", "motivation": "Traditional RL methods treat tasks as single-step, but complex reasoning requires multi-step optimization.", "method": "SWiRL decomposes multi-step trajectories into sub-trajectories, applies synthetic data filtering, and optimizes with RL.", "result": "SWiRL improves accuracy by 11.1%-21.5% on tasks like GSM8K and HotPotQA, showing cross-task generalization.", "conclusion": "SWiRL is effective for multi-step reasoning and generalizes across tasks, enhancing language model performance."}}
{"id": "2410.21465", "pdf": "https://arxiv.org/pdf/2410.21465", "abs": "https://arxiv.org/abs/2410.21465", "authors": ["Hanshi Sun", "Li-Wen Chang", "Wenlei Bao", "Size Zheng", "Ningxin Zheng", "Xin Liu", "Harry Dong", "Yuejie Chi", "Beidi Chen"], "title": "ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "With the widespread deployment of long-context large language models (LLMs),\nthere has been a growing demand for efficient support of high-throughput\ninference. However, as the key-value (KV) cache expands with the sequence\nlength, the increasing memory footprint and the need to access it for each\ntoken generation both result in low throughput when serving long-context LLMs.\nWhile various dynamic sparse attention methods have been proposed to speed up\ninference while maintaining generation quality, they either fail to\nsufficiently reduce GPU memory consumption or introduce significant decoding\nlatency by offloading the KV cache to the CPU. We present ShadowKV, a\nhigh-throughput long-context LLM inference system that stores the low-rank key\ncache and offloads the value cache to reduce the memory footprint for larger\nbatch sizes and longer sequences. To minimize decoding latency, ShadowKV\nemploys an accurate KV selection strategy that reconstructs minimal sparse KV\npairs on-the-fly. By evaluating ShadowKV on a broad range of benchmarks,\nincluding RULER, LongBench, and Needle In A Haystack, and models like\nLlama-3.1-8B, Llama-3-8B-1M, GLM-4-9B-1M, Yi-9B-200K, Phi-3-Mini-128K, and\nQwen2-7B-128K, we demonstrate that it can support up to 6$\\times$ larger batch\nsizes and boost throughput by up to 3.04$\\times$ on an A100 GPU without\nsacrificing accuracy, even surpassing the performance achievable with infinite\nbatch size under the assumption of infinite GPU memory. The code is available\nat https://github.com/bytedance/ShadowKV.", "AI": {"tldr": "ShadowKV is a system for high-throughput long-context LLM inference, reducing memory footprint and boosting throughput without sacrificing accuracy.", "motivation": "The demand for efficient high-throughput inference in long-context LLMs is unmet due to memory and latency issues with current methods.", "method": "ShadowKV stores low-rank key cache and offloads value cache, using an accurate KV selection strategy to minimize latency.", "result": "It supports 6\u00d7 larger batch sizes and boosts throughput by 3.04\u00d7 on an A100 GPU, maintaining accuracy.", "conclusion": "ShadowKV effectively addresses memory and throughput challenges in long-context LLM inference."}}
{"id": "2504.19189", "pdf": "https://arxiv.org/pdf/2504.19189", "abs": "https://arxiv.org/abs/2504.19189", "authors": ["Lei Zhong", "Chuan Guo", "Yiming Xie", "Jiawei Wang", "Changjian Li"], "title": "Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation", "categories": ["cs.GR", "cs.CV"], "comment": "Project page: https://zhongleilz.github.io/Sketch2Anim/", "summary": "Storyboarding is widely used for creating 3D animations. Animators use the 2D\nsketches in storyboards as references to craft the desired 3D animations\nthrough a trial-and-error process. The traditional approach requires\nexceptional expertise and is both labor-intensive and time-consuming.\nConsequently, there is a high demand for automated methods that can directly\ntranslate 2D storyboard sketches into 3D animations. This task is\nunder-explored to date and inspired by the significant advancements of motion\ndiffusion models, we propose to address it from the perspective of conditional\nmotion synthesis. We thus present Sketch2Anim, composed of two key modules for\nsketch constraint understanding and motion generation. Specifically, due to the\nlarge domain gap between the 2D sketch and 3D motion, instead of directly\nconditioning on 2D inputs, we design a 3D conditional motion generator that\nsimultaneously leverages 3D keyposes, joint trajectories, and action words, to\nachieve precise and fine-grained motion control. Then, we invent a neural\nmapper dedicated to aligning user-provided 2D sketches with their corresponding\n3D keyposes and trajectories in a shared embedding space, enabling, for the\nfirst time, direct 2D control of motion generation. Our approach successfully\ntransfers storyboards into high-quality 3D motions and inherently supports\ndirect 3D animation editing, thanks to the flexibility of our multi-conditional\nmotion generator. Comprehensive experiments and evaluations, and a user\nperceptual study demonstrate the effectiveness of our approach.", "AI": {"tldr": "Sketch2Anim automates the translation of 2D storyboard sketches into 3D animations using a motion diffusion model, combining sketch constraint understanding and motion generation for precise control.", "motivation": "Traditional 3D animation from storyboards is labor-intensive and requires expertise, creating demand for automated solutions.", "method": "Sketch2Anim uses a 3D conditional motion generator with keyposes, joint trajectories, and action words, and a neural mapper to align 2D sketches with 3D motion.", "result": "The approach produces high-quality 3D motions and supports direct animation editing, validated by experiments and user studies.", "conclusion": "Sketch2Anim effectively bridges the gap between 2D sketches and 3D animations, offering a flexible and automated solution."}}
{"id": "2504.19342", "pdf": "https://arxiv.org/pdf/2504.19342", "abs": "https://arxiv.org/abs/2504.19342", "authors": ["Nan Lu", "Ethan X. Fang", "Junwei Lu"], "title": "Contextual Online Uncertainty-Aware Preference Learning for Human Feedback", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) has become a pivotal\nparadigm in artificial intelligence to align large models with human\npreferences. In this paper, we propose a novel statistical framework to\nsimultaneously conduct the online decision-making and statistical inference on\nthe optimal model using human preference data based on dynamic contextual\ninformation. Our approach introduces an efficient decision strategy that\nachieves both the optimal regret bound and the asymptotic distribution of the\nestimators. A key challenge in RLHF is handling the dependent online human\npreference outcomes with dynamic contexts. To address this, in the\nmethodological aspect, we propose a two-stage algorithm starting with\n$\\epsilon$-greedy followed by exploitations; in the theoretical aspect, we\ntailor anti-concentration inequalities and matrix martingale concentration\ntechniques to derive the uniform estimation rate and asymptotic normality of\nthe estimators using dependent samples from both stages. Extensive simulation\nresults demonstrate that our method outperforms state-of-the-art strategies. We\napply the proposed framework to analyze the human preference data for ranking\nlarge language models on the Massive Multitask Language Understanding dataset,\nyielding insightful results on the performance of different large language\nmodels for medical anatomy knowledge.", "AI": {"tldr": "A novel statistical framework for RLHF combines online decision-making and inference, achieving optimal regret and asymptotic normality, validated by simulations and applied to ranking LLMs.", "motivation": "Aligning large AI models with human preferences via RLHF is crucial, but handling dynamic contexts and dependent human feedback poses challenges.", "method": "Proposes a two-stage algorithm (\u03b5-greedy followed by exploitation) and uses anti-concentration inequalities for theoretical guarantees.", "result": "Outperforms state-of-the-art in simulations; applied to rank LLMs on medical anatomy knowledge.", "conclusion": "The framework effectively balances decision-making and inference, providing insights into LLM performance."}}
{"id": "2504.11419", "pdf": "https://arxiv.org/pdf/2504.11419", "abs": "https://arxiv.org/abs/2504.11419", "authors": ["Li Jin", "Liu Jia"], "title": "Embodied World Models Emerge from Navigational Task in Open-Ended Environments", "categories": ["cs.AI", "cs.NE"], "comment": "Research on explainable meta-reinforcement learning AI", "summary": "Spatial reasoning in partially observable environments has often been\napproached through passive predictive models, yet theories of embodied\ncognition suggest that genuinely useful representations arise only when\nperception is tightly coupled to action. Here we ask whether a recurrent agent,\ntrained solely by sparse rewards to solve procedurally generated planar mazes,\ncan autonomously internalize metric concepts such as direction, distance and\nobstacle layout. After training, the agent consistently produces near-optimal\npaths in unseen mazes, behavior that hints at an underlying spatial model. To\nprobe this possibility, we cast the closed agent-environment loop as a hybrid\ndynamical system, identify stable limit cycles in its state space, and\ncharacterize behavior with a Ridge Representation that embeds whole\ntrajectories into a common metric space. Canonical correlation analysis exposes\na robust linear alignment between neural and behavioral manifolds, while\ntargeted perturbations of the most informative neural dimensions sharply\ndegrade navigation performance. Taken together, these dynamical,\nrepresentational, and causal signatures show that sustained sensorimotor\ninteraction is sufficient for the spontaneous emergence of compact, embodied\nworld models, providing a principled path toward interpretable and transferable\nnavigation policies.", "AI": {"tldr": "A recurrent agent trained with sparse rewards in planar mazes internalizes spatial concepts like direction and distance, enabling near-optimal navigation in unseen mazes. Analysis reveals stable neural-behavioral alignment and causal evidence for embodied world models.", "motivation": "To explore if active, embodied interaction (rather than passive prediction) leads to useful spatial representations in partially observable environments.", "method": "Train a recurrent agent with sparse rewards in procedurally generated mazes, then analyze its behavior and neural dynamics using hybrid dynamical systems theory and Ridge Representation.", "result": "The agent achieves near-optimal navigation in new mazes, with neural-behavioral alignment confirmed by canonical correlation analysis and causal perturbations.", "conclusion": "Sustained sensorimotor interaction enables spontaneous emergence of compact, embodied world models, offering interpretable and transferable navigation policies."}}
{"id": "2411.05060", "pdf": "https://arxiv.org/pdf/2411.05060", "abs": "https://arxiv.org/abs/2411.05060", "authors": ["Camille Thibault", "Jacob-Junqi Tian", "Gabrielle Peloquin-Skulski", "Taylor Lynn Curtis", "James Zhou", "Florence Laflamme", "Yuxiang Guan", "Reihaneh Rabbany", "Jean-Fran\u00e7ois Godbout", "Kellin Pelrine"], "title": "A Guide to Misinformation Detection Data and Evaluation", "categories": ["cs.SI", "cs.CL", "cs.CY"], "comment": null, "summary": "Misinformation is a complex societal issue, and mitigating solutions are\ndifficult to create due to data deficiencies. To address this, we have curated\nthe largest collection of (mis)information datasets in the literature, totaling\n75. From these, we evaluated the quality of 36 datasets that consist of\nstatements or claims, as well as the 9 datasets that consist of data in purely\nparagraph form. We assess these datasets to identify those with solid\nfoundations for empirical work and those with flaws that could result in\nmisleading and non-generalizable results, such as spurious correlations, or\nexamples that are ambiguous or otherwise impossible to assess for veracity. We\nfind the latter issue is particularly severe and affects most datasets in the\nliterature. We further provide state-of-the-art baselines on all these\ndatasets, but show that regardless of label quality, categorical labels may no\nlonger give an accurate evaluation of detection model performance. Finally, we\npropose and highlight Evaluation Quality Assurance (EQA) as a tool to guide the\nfield toward systemic solutions rather than inadvertently propagating issues in\nevaluation. Overall, this guide aims to provide a roadmap for higher quality\ndata and better grounded evaluations, ultimately improving research in\nmisinformation detection. All datasets and other artifacts are available at\nmisinfo-datasets.complexdatalab.com.", "AI": {"tldr": "The paper curates the largest collection of misinformation datasets, evaluates their quality, identifies flaws, and proposes Evaluation Quality Assurance (EQA) to improve research in misinformation detection.", "motivation": "Addressing data deficiencies in misinformation research by evaluating dataset quality and improving evaluation methods.", "method": "Curated 75 datasets, evaluated 36 for statement/claim quality and 9 for paragraph form. Assessed for empirical foundations and flaws like spurious correlations.", "result": "Found severe issues like ambiguous examples in most datasets. Provided baselines but noted categorical labels may not accurately evaluate models.", "conclusion": "Proposed EQA to guide systemic solutions, aiming for better data quality and evaluations in misinformation detection."}}
{"id": "2504.19200", "pdf": "https://arxiv.org/pdf/2504.19200", "abs": "https://arxiv.org/abs/2504.19200", "authors": ["Tristan Manchester", "Adam Anders", "Julio Spadotto", "Hannah Eccleston", "William Beavan", "Hugues Arcis", "Brian J. Connolly"], "title": "Leveraging Modified Ex Situ Tomography Data for Segmentation of In Situ Synchrotron X-Ray Computed Tomography", "categories": ["cond-mat.mtrl-sci", "cs.CV"], "comment": null, "summary": "In situ synchrotron X-ray computed tomography enables dynamic material\nstudies, but automated segmentation remains challenging due to complex imaging\nartefacts and limited training data. We present a methodology for deep\nlearning-based segmentation by transforming high-quality ex situ laboratory\ndata to train models for binary segmentation of in situ synchrotron data,\ndemonstrated through copper oxide dissolution studies. Using a modified\nSegFormer architecture, our approach achieves high segmentation performance on\nunseen data while reducing processing time from hours to seconds per 3D\ndataset. The method maintains consistent performance over significant\nmorphological changes during experiments, despite training only on static\nspecimens. This methodology can be readily applied to diverse materials\nsystems, accelerating the analysis of time-resolved tomographic data across\nscientific disciplines.", "AI": {"tldr": "A deep learning method transforms ex situ lab data to train models for binary segmentation of in situ synchrotron data, achieving high performance and speed.", "motivation": "Automated segmentation of in situ synchrotron X-ray computed tomography is challenging due to imaging artefacts and limited training data.", "method": "Uses a modified SegFormer architecture to train models on ex situ lab data for binary segmentation of in situ data.", "result": "Achieves high segmentation performance on unseen data, reducing processing time from hours to seconds per 3D dataset.", "conclusion": "The method is versatile and accelerates analysis of time-resolved tomographic data across materials systems."}}
{"id": "2504.19351", "pdf": "https://arxiv.org/pdf/2504.19351", "abs": "https://arxiv.org/abs/2504.19351", "authors": ["Chathurika S Abeykoon", "Aleksandr Beknazaryan", "Hailin Sang"], "title": "The Double Descent Behavior in Two Layer Neural Network for Binary Classification", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Recent studies observed a surprising concept on model test error called the\ndouble descent phenomenon, where the increasing model complexity decreases the\ntest error first and then the error increases and decreases again. To observe\nthis, we work on a two layer neural network model with a ReLU activation\nfunction designed for binary classification under supervised learning. Our aim\nis to observe and investigate the mathematical theory behind the double descent\nbehavior of model test error for varying model sizes. We quantify the model\nsize by the ratio of number of training samples to the dimension of the model.\nDue to the complexity of the empirical risk minimization procedure, we use the\nConvex Gaussian Min Max Theorem to find a suitable candidate for the global\ntraining loss.", "AI": {"tldr": "The paper investigates the double descent phenomenon in model test error using a two-layer neural network with ReLU activation, focusing on binary classification under supervised learning.", "motivation": "To understand the mathematical theory behind the double descent behavior of test error as model complexity varies.", "method": "Uses a two-layer neural network with ReLU activation and employs the Convex Gaussian Min Max Theorem to analyze the global training loss.", "result": "Quantifies the double descent phenomenon by examining the ratio of training samples to model dimension.", "conclusion": "Provides insights into the double descent behavior, contributing to the theoretical understanding of model complexity and test error."}}
{"id": "2504.16736", "pdf": "https://arxiv.org/pdf/2504.16736", "abs": "https://arxiv.org/abs/2504.16736", "authors": ["Yingxuan Yang", "Huacan Chai", "Yuanyi Song", "Siyuan Qi", "Muning Wen", "Ning Li", "Junwei Liao", "Haoyi Hu", "Jianghao Lin", "Gaowei Chang", "Weiwen Liu", "Ying Wen", "Yong Yu", "Weinan Zhang"], "title": "A Survey of AI Agent Protocols", "categories": ["cs.AI"], "comment": null, "summary": "The rapid development of large language models (LLMs) has led to the\nwidespread deployment of LLM agents across diverse industries, including\ncustomer service, content generation, data analysis, and even healthcare.\nHowever, as more LLM agents are deployed, a major issue has emerged: there is\nno standard way for these agents to communicate with external tools or data\nsources. This lack of standardized protocols makes it difficult for agents to\nwork together or scale effectively, and it limits their ability to tackle\ncomplex, real-world tasks. A unified communication protocol for LLM agents\ncould change this. It would allow agents and tools to interact more smoothly,\nencourage collaboration, and triggering the formation of collective\nintelligence. In this paper, we provide the first comprehensive analysis of\nexisting agent protocols, proposing a systematic two-dimensional classification\nthat differentiates context-oriented versus inter-agent protocols and\ngeneral-purpose versus domain-specific protocols. Additionally, we conduct a\ncomparative performance analysis of these protocols across key dimensions such\nas security, scalability, and latency. Finally, we explore the future landscape\nof agent protocols by identifying critical research directions and\ncharacteristics necessary for next-generation protocols. These characteristics\ninclude adaptability, privacy preservation, and group-based interaction, as\nwell as trends toward layered architectures and collective intelligence\ninfrastructures. We expect this work to serve as a practical reference for both\nresearchers and engineers seeking to design, evaluate, or integrate robust\ncommunication infrastructures for intelligent agents.", "AI": {"tldr": "The paper proposes a unified communication protocol for LLM agents to address the lack of standardization, enabling smoother interactions and collaboration. It classifies existing protocols, analyzes their performance, and outlines future research directions.", "motivation": "The absence of standardized communication protocols for LLM agents hinders collaboration, scalability, and their ability to handle complex tasks. A unified protocol could enhance interoperability and collective intelligence.", "method": "The authors classify existing protocols into context-oriented vs. inter-agent and general-purpose vs. domain-specific. They also analyze performance across security, scalability, and latency.", "result": "The study provides a systematic classification and performance analysis of protocols, identifying gaps and proposing future research directions.", "conclusion": "The paper serves as a reference for designing next-generation protocols, emphasizing adaptability, privacy, and collective intelligence."}}
{"id": "2501.15579", "pdf": "https://arxiv.org/pdf/2501.15579", "abs": "https://arxiv.org/abs/2501.15579", "authors": ["Yuxiang Nie", "Sunan He", "Yequan Bie", "Yihui Wang", "Zhixuan Chen", "Shu Yang", "Zhiyuan Cai", "Hongmei Wang", "Xi Wang", "Luyang Luo", "Mingxiang Wu", "Xian Wu", "Ronald Cheong Kin Chan", "Yuk Ming Lau", "Yefeng Zheng", "Pranav Rajpurkar", "Hao Chen"], "title": "An Explainable Biomedical Foundation Model via Large-Scale Concept-Enhanced Vision-Language Pre-training", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "The clinical adoption of artificial intelligence (AI) in medical imaging\nrequires models that are both diagnostically accurate and interpretable to\nclinicians. While current multimodal biomedical foundation models prioritize\nperformance, their black-box nature hinders explaining the decision-making\nprocess in clinically meaningful concepts. Here, we present ConceptCLIP, the\nfirst explainable biomedical foundation model that achieves state-of-the-art\ndiagnostic accuracy while delivering human-interpretable explanations across\ndiverse imaging modalities. We curate MedConcept-23M, the largest pre-training\ndataset comprising 23 million image-text-concept triplets across diverse\nmedical modalities, where clinical concepts are derived from the Unified\nMedical Language System. Leveraging this dataset, we develop ConceptCLIP\nthrough a novel dual-alignment approach that simultaneously learns global\nimage-text representations and fine-grained region-concept associations for\nprecise and interpretable medical image analysis. We curate the most extensive\nevaluation benchmark for multimodal biomedical foundation models, covering 52\nclinical tasks spanning 10 imaging modalities. Extensive experiments\ndemonstrate that ConceptCLIP outperforms existing state-of-the-art multimodal\nbiomedical foundation models. Importantly, ConceptCLIP demonstrates superior\ndiagnostic performance while providing human-understandable explanations\nvalidated by clinical experts. As the first precise and interpretable\nbiomedical foundation model, ConceptCLIP represents a critical milestone toward\nthe widespread clinical adoption of AI, thereby advancing trustworthy AI in\nmedicine.", "AI": {"tldr": "ConceptCLIP is an explainable biomedical foundation model that combines high diagnostic accuracy with human-interpretable explanations, outperforming existing models across diverse medical imaging tasks.", "motivation": "To bridge the gap between AI performance and interpretability in medical imaging, ensuring clinicians can trust and understand AI decisions.", "method": "Developed using a dual-alignment approach on MedConcept-23M, a dataset of 23M image-text-concept triplets, to learn global and fine-grained associations.", "result": "Outperforms state-of-the-art models on 52 clinical tasks across 10 modalities, with validated human-understandable explanations.", "conclusion": "ConceptCLIP advances trustworthy AI in medicine by balancing accuracy and interpretability, enabling broader clinical adoption."}}
{"id": "2504.19253", "pdf": "https://arxiv.org/pdf/2504.19253", "abs": "https://arxiv.org/abs/2504.19253", "authors": ["Taoyi Wang", "Lijian Wang", "Yihan Lin", "Mingtao Ou", "Yuguo Chen", "Xinglong Ji", "Rong Zhao"], "title": "Quantitative evaluation of brain-inspired vision sensors in high-speed robotic perception", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 8 figures, 1 table, conference", "summary": "Perception systems in robotics encounter significant challenges in high-speed\nand dynamic conditions when relying on traditional cameras, where motion blur\ncan compromise spatial feature integrity and task performance. Brain-inspired\nvision sensors (BVS) have recently gained attention as an alternative, offering\nhigh temporal resolution with reduced bandwidth and power requirements. Here,\nwe present the first quantitative evaluation framework for two representative\nclasses of BVSs in variable-speed robotic sensing, including event-based vision\nsensors (EVS) that detect asynchronous temporal contrasts, and the\nprimitive-based sensor Tianmouc that employs a complementary mechanism to\nencode both spatiotemporal changes and intensity. A unified testing protocol is\nestablished, including crosssensor calibrations, standardized testing\nplatforms, and quality metrics to address differences in data modality. From an\nimaging standpoint, we evaluate the effects of sensor non-idealities, such as\nmotion-induced distortion, on the capture of structural information. For\nfunctional benchmarking, we examine task performance in corner detection and\nmotion estimation under different rotational speeds. Results indicate that EVS\nperforms well in highspeed, sparse scenarios and in modestly fast, complex\nscenes, but exhibits performance limitations in high-speed, cluttered settings\ndue to pixel-level bandwidth variations and event rate saturation. In\ncomparison, Tianmouc demonstrates consistent performance across sparse and\ncomplex scenarios at various speeds, supported by its global, precise,\nhigh-speed spatiotemporal gradient samplings. These findings offer valuable\ninsights into the applicationdependent suitability of BVS technologies and\nsupport further advancement in this area.", "AI": {"tldr": "The paper evaluates brain-inspired vision sensors (BVS) for robotic perception in dynamic conditions, comparing event-based vision sensors (EVS) and Tianmouc. Results show EVS excels in high-speed sparse scenarios but struggles in cluttered settings, while Tianmouc performs consistently across conditions.", "motivation": "Traditional cameras face challenges like motion blur in high-speed robotic tasks, prompting exploration of BVS for better performance.", "method": "A unified testing framework is developed, including cross-sensor calibration, standardized platforms, and quality metrics. Imaging and functional benchmarks (corner detection, motion estimation) are conducted under varying speeds.", "result": "EVS performs well in high-speed sparse scenarios but falters in cluttered high-speed settings. Tianmouc maintains consistent performance across all conditions due to its precise spatiotemporal sampling.", "conclusion": "The study highlights the application-dependent suitability of BVS technologies, guiding future advancements in robotic perception systems."}}
{"id": "2504.19355", "pdf": "https://arxiv.org/pdf/2504.19355", "abs": "https://arxiv.org/abs/2504.19355", "authors": ["Gionni Marchetti"], "title": "Metric Similarity and Manifold Learning of Circular Dichroism Spectra of Proteins", "categories": ["physics.soc-ph", "cs.LG"], "comment": "13 pages, 16 figures", "summary": "We present a machine learning analysis of circular dichroism spectra of\nglobular proteins from the SP175 database, using the optimal transport-based\n$1$-Wasserstein distance $\\mathcal{W}_1$ (with order $p=1$) and the manifold\nlearning algorithm $t$-SNE. Our results demonstrate that $\\mathcal{W}_1$ is\nconsistent with both Euclidean and Manhattan metrics while exhibiting\nrobustness to noise. On the other hand, $t$-SNE uncovers meaningful structure\nin the high-dimensional data. The clustering in the $t$-SNE embedding is\nprimarily determined by proteins with distinct secondary structure\ncompositions: one cluster predominantly contains $\\beta$-rich proteins, while\nthe other consists mainly of proteins with mixed $\\alpha/\\beta$ and\n$\\alpha$-helical content.", "AI": {"tldr": "The paper analyzes circular dichroism spectra of globular proteins using optimal transport-based Wasserstein distance and t-SNE, revealing robust noise resistance and meaningful clustering by secondary structure.", "motivation": "To explore the effectiveness of the Wasserstein distance and t-SNE in analyzing high-dimensional protein spectra data and uncovering structural patterns.", "method": "Employed the $1$-Wasserstein distance ($\\mathcal{W}_1$) for spectral comparison and t-SNE for manifold learning to reduce dimensionality and cluster proteins.", "result": "$\\mathcal{W}_1$ showed robustness to noise and consistency with Euclidean/Manhattan metrics. t-SNE revealed clusters based on secondary structure: $\\beta$-rich proteins and mixed $\\alpha/\\beta$ or $\\alpha$-helical proteins.", "conclusion": "The Wasserstein distance and t-SNE are effective tools for analyzing protein spectra, with t-SNE particularly useful for identifying secondary structure-based clustering."}}
{"id": "2203.02927", "pdf": "https://arxiv.org/pdf/2203.02927", "abs": "https://arxiv.org/abs/2203.02927", "authors": ["Armin Moin", "Ukrit Wattanavaekin", "Alexandra Lungu", "Stephan R\u00f6ssler", "Stephan G\u00fcnnemann"], "title": "Automated Machine Learning: A Case Study on Non-Intrusive Appliance Load Monitoring", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "ITNG 2025 - To be published by Springer", "summary": "We propose a novel approach to enable Automated Machine Learning (AutoML) for\nNon-Intrusive Appliance Load Monitoring (NIALM), also known as Energy\nDisaggregation, through Bayesian Optimization. NIALM offers a cost-effective\nalternative to smart meters for measuring the energy consumption of electric\ndevices and appliances. NIALM methods analyze the entire power consumption\nsignal of a household and predict the type of appliances as well as their\nindividual power consumption (i.e., their contributions to the aggregated\nsignal). We enable NIALM domain experts and practitioners who typically have no\ndeep data analytics or Machine Learning (ML) skills to benefit from\nstate-of-the-art ML approaches to NIALM. Further, we conduct a survey and\nbenchmarking of the state of the art and show that in many cases, simple and\nbasic ML models and algorithms, such as Decision Trees, outperform the state of\nthe art. Finally, we present our open-source tool, AutoML4NIALM, which will\nfacilitate the exploitation of existing methods for NIALM in the industry.", "AI": {"tldr": "The paper introduces an AutoML approach for NIALM using Bayesian Optimization, enabling non-experts to leverage ML for energy disaggregation. It benchmarks state-of-the-art methods, finding simpler models like Decision Trees often outperform them, and releases an open-source tool, AutoML4NIALM.", "motivation": "To make advanced ML accessible for NIALM (Energy Disaggregation) without requiring deep ML expertise, addressing the need for cost-effective energy monitoring solutions.", "method": "Uses Bayesian Optimization for AutoML in NIALM, benchmarking existing methods and comparing them with simpler ML models like Decision Trees.", "result": "Simpler ML models (e.g., Decision Trees) often outperform state-of-the-art methods in NIALM. The open-source tool AutoML4NIALM is introduced.", "conclusion": "The approach democratizes ML for NIALM, showing the effectiveness of simpler models and providing a practical tool for industry adoption."}}
{"id": "2502.09573", "pdf": "https://arxiv.org/pdf/2502.09573", "abs": "https://arxiv.org/abs/2502.09573", "authors": ["Mark Beliaev", "Victor Yang", "Madhura Raju", "Jiachen Sun", "Xinghai Hu"], "title": "Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt Engineering", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "9 pages", "summary": "In this study, we tackle industry challenges in video content classification\nby exploring and optimizing GPT-based models for zero-shot classification\nacross seven critical categories of video quality. We contribute a novel\napproach to improving GPT's performance through prompt optimization and policy\nrefinement, demonstrating that simplifying complex policies significantly\nreduces false negatives. Additionally, we introduce a new\ndecomposition-aggregation-based prompt engineering technique, which outperforms\ntraditional single-prompt methods. These experiments, conducted on real\nindustry problems, show that thoughtful prompt design can substantially enhance\nGPT's performance without additional finetuning, offering an effective and\nscalable solution for improving video classification.", "AI": {"tldr": "Optimizing GPT-based models for zero-shot video classification using prompt optimization and policy refinement, reducing false negatives and outperforming traditional methods.", "motivation": "Addressing industry challenges in video content classification by enhancing GPT's performance without additional finetuning.", "method": "Novel approach combining prompt optimization, policy refinement, and decomposition-aggregation-based prompt engineering.", "result": "Simplified policies reduce false negatives; new technique outperforms single-prompt methods, improving classification.", "conclusion": "Thoughtful prompt design enhances GPT's performance, offering a scalable solution for video classification."}}
{"id": "2504.19718", "pdf": "https://arxiv.org/pdf/2504.19718", "abs": "https://arxiv.org/abs/2504.19718", "authors": ["Victoria Yue Chen", "Daoye Wang", "Stephan Garbin", "Sebastian Winberg", "Timo Bolkart", "Thabo Beeler"], "title": "Pixels2Points: Fusing 2D and 3D Features for Facial Skin Segmentation", "categories": ["cs.GR", "cs.CV"], "comment": "4 pages, 4 figures, to be published in Eurographics 2025 as a short\n  paper", "summary": "Face registration deforms a template mesh to closely fit a 3D face scan, the\nquality of which commonly degrades in non-skin regions (e.g., hair, beard,\naccessories), because the optimized template-to-scan distance pulls the\ntemplate mesh towards the noisy scan surface. Improving registration quality\nrequires a clean separation of skin and non-skin regions on the scan mesh.\nExisting image-based (2D) or scan-based (3D) segmentation methods however\nperform poorly. Image-based segmentation outputs multi-view inconsistent masks,\nand they cannot account for scan inaccuracies or scan-image misalignment, while\nscan-based methods suffer from lower spatial resolution compared to images. In\nthis work, we introduce a novel method that accurately separates skin from\nnon-skin geometry on 3D human head scans. For this, our method extracts\nfeatures from multi-view images using a frozen image foundation model and\naggregates these features in 3D. These lifted 2D features are then fused with\n3D geometric features extracted from the scan mesh, to then predict a\nsegmentation mask directly on the scan mesh. We show that our segmentations\nimprove the registration accuracy over pure 2D or 3D segmentation methods by\n8.89% and 14.3%, respectively. Although trained only on synthetic data, our\nmodel generalizes well to real data.", "AI": {"tldr": "A novel method improves 3D face scan registration by accurately segmenting skin and non-skin regions using fused 2D and 3D features, outperforming existing methods.", "motivation": "Existing 2D or 3D segmentation methods perform poorly for skin/non-skin separation, degrading face registration quality in noisy regions.", "method": "The method combines 2D features from multi-view images (using a frozen image foundation model) with 3D geometric features from the scan mesh to predict segmentation directly on the mesh.", "result": "The approach improves registration accuracy by 8.89% over 2D and 14.3% over 3D methods, generalizing well to real data despite synthetic training.", "conclusion": "The proposed fusion of 2D and 3D features effectively addresses segmentation challenges, enhancing registration quality."}}
{"id": "2504.19372", "pdf": "https://arxiv.org/pdf/2504.19372", "abs": "https://arxiv.org/abs/2504.19372", "authors": ["Weishi Wang", "Mark K. Transtrum", "Vincenzo Lordi", "Vasily V. Bulatov", "Amit Samanta"], "title": "Composable and adaptive design of machine learning interatomic potentials guided by Fisher-information analysis", "categories": ["cond-mat.mtrl-sci", "cs.LG", "cs.NA", "math.NA", "physics.app-ph", "physics.comp-ph"], "comment": "18 pages, 7 figures, and 6 tables", "summary": "An adaptive physics-informed model design strategy for machine-learning\ninteratomic potentials (MLIPs) is proposed. This strategy follows an iterative\nreconfiguration of composite models from single-term models, followed by a\nunified training procedure. A model evaluation method based on the Fisher\ninformation matrix (FIM) and multiple-property error metrics is proposed to\nguide model reconfiguration and hyperparameter optimization. Combining the\nmodel reconfiguration and the model evaluation subroutines, we provide an\nadaptive MLIP design strategy that balances flexibility and extensibility. In a\ncase study of designing models against a structurally diverse niobium dataset,\nwe managed to obtain an optimal configuration with 75 parameters generated by\nour framework that achieved a force RMSE of 0.172 eV/{\\AA} and an energy RMSE\nof 0.013 eV/atom.", "AI": {"tldr": "An adaptive strategy for designing ML interatomic potentials (MLIPs) combines model reconfiguration and evaluation using Fisher information matrix (FIM) and error metrics, achieving high accuracy in a niobium dataset case study.", "motivation": "To balance flexibility and extensibility in MLIP design by iteratively refining models and optimizing hyperparameters.", "method": "Proposes an adaptive strategy involving iterative reconfiguration of composite models, unified training, and evaluation using FIM and error metrics.", "result": "Achieved a force RMSE of 0.172 eV/\u00c5 and energy RMSE of 0.013 eV/atom with a 75-parameter model in a niobium dataset.", "conclusion": "The adaptive strategy effectively balances flexibility and extensibility, yielding accurate MLIPs for diverse datasets."}}
{"id": "2303.09271", "pdf": "https://arxiv.org/pdf/2303.09271", "abs": "https://arxiv.org/abs/2303.09271", "authors": ["John T\u00f6rnblom", "Emil Karlsson", "Simin Nadjm-Tehrani"], "title": "Finding Minimum-Cost Explanations for Predictions made by Tree Ensembles", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The ability to explain why a machine learning model arrives at a particular\nprediction is crucial when used as decision support by human operators of\ncritical systems. The provided explanations must be provably correct, and\npreferably without redundant information, called minimal explanations. In this\npaper, we aim at finding explanations for predictions made by tree ensembles\nthat are not only minimal, but also minimum with respect to a cost function.\n  To this end, we first present a highly efficient oracle that can determine\nthe correctness of explanations, surpassing the runtime performance of current\nstate-of-the-art alternatives by several orders of magnitude when computing\nminimal explanations.\n  Secondly, we adapt an algorithm called MARCO from related works (calling it\nm-MARCO) for the purpose of computing a single minimum explanation per\nprediction, and demonstrate an overall speedup factor of two compared to the\nMARCO algorithm which enumerates all minimal explanations.\n  Finally, we study the obtained explanations from a range of use cases,\nleading to further insights of their characteristics. In particular, we observe\nthat in several cases, there are more than 100,000 minimal explanations to\nchoose from for a single prediction. In these cases, we see that only a small\nportion of the minimal explanations are also minimum, and that the minimum\nexplanations are significantly less verbose, hence motivating the aim of this\nwork.", "AI": {"tldr": "The paper focuses on finding provably correct, minimal, and cost-efficient explanations for predictions made by tree ensembles, introducing an efficient oracle and an adapted algorithm (m-MARCO) to achieve this.", "motivation": "To provide human operators of critical systems with trustworthy, concise, and cost-effective explanations for machine learning model predictions.", "method": "1. Introduces a highly efficient oracle for verifying explanation correctness. 2. Adapts the MARCO algorithm (m-MARCO) to compute single minimum explanations.", "result": "Demonstrates significant speed improvements (orders of magnitude for minimal explanations, 2x for m-MARCO) and reveals that minimum explanations are less verbose and rare among minimal ones.", "conclusion": "The work successfully advances the efficiency and quality of explanations for tree ensemble predictions, emphasizing the value of minimum explanations in practice."}}
{"id": "2502.11678", "pdf": "https://arxiv.org/pdf/2502.11678", "abs": "https://arxiv.org/abs/2502.11678", "authors": ["Haoxuan Li", "Jifan Yu", "Xin Cong", "Yang Dang", "Daniel Zhang-li", "Yisi Zhan", "Huiqin Liu", "Zhiyuan Liu"], "title": "Exploring LLM-based Student Simulation for Metacognitive Cultivation", "categories": ["cs.CY", "cs.CL"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Metacognitive education plays a crucial role in cultivating students'\nself-regulation and reflective thinking, providing essential support for those\nwith learning difficulties through academic advising. Simulating students with\ninsufficient learning capabilities using large language models offers a\npromising approach to refining pedagogical methods without ethical concerns.\nHowever, existing simulations often fail to authentically represent students'\nlearning struggles and face challenges in evaluation due to the lack of\nreliable metrics and ethical constraints in data collection. To address these\nissues, we propose a pipeline for automatically generating and filtering\nhigh-quality simulated student agents. Our approach leverages a two-round\nautomated scoring system validated by human experts and employs a score\npropagation module to obtain more consistent scores across the student graph.\nExperimental results demonstrate that our pipeline efficiently identifies\nhigh-quality student agents, and we discuss the traits that influence the\nsimulation's effectiveness. By simulating students with varying degrees of\nlearning difficulties, our work paves the way for broader applications in\npersonalized learning and educational assessment.", "AI": {"tldr": "A pipeline for generating high-quality simulated student agents is proposed to improve metacognitive education, addressing challenges in authenticity and evaluation.", "motivation": "To refine pedagogical methods ethically by simulating students with learning difficulties, overcoming limitations of existing simulations.", "method": "A two-round automated scoring system validated by human experts, with a score propagation module for consistency.", "result": "The pipeline efficiently identifies high-quality student agents, revealing traits affecting simulation effectiveness.", "conclusion": "The work enables broader applications in personalized learning and educational assessment by simulating diverse learning difficulties."}}
{"id": "2109.08843", "pdf": "https://arxiv.org/pdf/2109.08843", "abs": "https://arxiv.org/abs/2109.08843", "authors": ["Feng Chen", "Fei Wu", "Qi Wu", "Zhiguo Wan"], "title": "Memory Regulation and Alignment toward Generalizer RGB-Infrared Person", "categories": ["cs.CV"], "comment": "This paper is withdrawn due to an internal decision among the authors\n  to discontinue its publication", "summary": "The domain shift, coming from unneglectable modality gap and non-overlapped\nidentity classes between training and test sets, is a major issue of\nRGB-Infrared person re-identification. A key to tackle the inherent issue --\ndomain shift -- is to enforce the data distributions of the two domains to be\nsimilar. However, RGB-IR ReID always demands discriminative features, leading\nto over-rely feature sensitivity of seen classes, \\textit{e.g.}, via\nattention-based feature alignment or metric learning. Therefore, predicting the\nunseen query category from predefined training classes may not be accurate and\nleads to a sub-optimal adversarial gradient. In this paper, we uncover it in a\nmore explainable way and propose a novel multi-granularity memory regulation\nand alignment module (MG-MRA) to solve this issue. By explicitly incorporating\na latent variable attribute, from fine-grained to coarse semantic granularity,\ninto intermediate features, our method could alleviate the over-confidence of\nthe model about discriminative features of seen classes. Moreover, instead of\nmatching discriminative features by traversing nearest neighbor, sparse\nattributes, \\textit{i.e.}, global structural pattern, are recollected with\nrespect to features and assigned to measure pair-wise image similarity in\nhashing. Extensive experiments on RegDB \\cite{RegDB} and SYSU-MM01 \\cite{SYSU}\nshow the superiority of the proposed method that outperforms existing\nstate-of-the-art methods. Our code is available in\nhttps://github.com/Chenfeng1271/MGMRA.", "AI": {"tldr": "The paper addresses domain shift in RGB-Infrared person re-identification by proposing a multi-granularity memory regulation and alignment module (MG-MRA) to align data distributions and reduce over-reliance on seen classes.", "motivation": "Domain shift due to modality gaps and non-overlapping identity classes in RGB-IR ReID leads to sub-optimal adversarial gradients and over-reliance on discriminative features of seen classes.", "method": "Introduces MG-MRA, which incorporates latent variable attributes (fine to coarse granularity) into features to mitigate over-confidence and uses sparse attributes for similarity measurement.", "result": "Outperforms state-of-the-art methods on RegDB and SYSU-MM01 datasets.", "conclusion": "MG-MRA effectively addresses domain shift and improves RGB-IR ReID performance by balancing feature sensitivity and leveraging global structural patterns."}}
{"id": "2504.19464", "pdf": "https://arxiv.org/pdf/2504.19464", "abs": "https://arxiv.org/abs/2504.19464", "authors": ["Junting Ren", "Armin Schwartzman"], "title": "Model uncertainty quantification using feature confidence sets for outcome excursions", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "When implementing prediction models for high-stakes real-world applications\nsuch as medicine, finance, and autonomous systems, quantifying prediction\nuncertainty is critical for effective risk management. Traditional approaches\nto uncertainty quantification, such as confidence and prediction intervals,\nprovide probability coverage guarantees for the expected outcomes\n$f(\\boldsymbol{x})$ or the realized outcomes $f(\\boldsymbol{x})+\\epsilon$.\nInstead, this paper introduces a novel, model-agnostic framework for\nquantifying uncertainty in continuous and binary outcomes using confidence sets\nfor outcome excursions, where the goal is to identify a subset of the feature\nspace where the expected or realized outcome exceeds a specific value. The\nproposed method constructs data-dependent inner and outer confidence sets that\naim to contain the true feature subset for which the expected or realized\noutcomes of these features exceed a specified threshold. We establish\ntheoretical guarantees for the probability that these confidence sets contain\nthe true feature subset, both asymptotically and for finite sample sizes. The\nframework is validated through simulations and applied to real-world datasets,\ndemonstrating its utility in contexts such as housing price prediction and time\nto sepsis diagnosis in healthcare. This approach provides a unified method for\nuncertainty quantification that is broadly applicable across various continuous\nand binary prediction models.", "AI": {"tldr": "The paper introduces a model-agnostic framework for quantifying uncertainty in continuous and binary outcomes using confidence sets for outcome excursions, ensuring theoretical guarantees and practical utility.", "motivation": "Traditional uncertainty quantification methods lack coverage for specific feature subsets where outcomes exceed thresholds, necessitating a novel approach for high-stakes applications like medicine and finance.", "method": "The proposed framework constructs data-dependent inner and outer confidence sets to identify feature subsets where expected or realized outcomes exceed a threshold, with theoretical guarantees.", "result": "The method is validated through simulations and real-world datasets (e.g., housing prices, sepsis diagnosis), showing its broad applicability and effectiveness.", "conclusion": "The framework provides a unified, model-agnostic solution for uncertainty quantification in high-stakes prediction models, with proven theoretical and practical benefits."}}
{"id": "2307.08187", "pdf": "https://arxiv.org/pdf/2307.08187", "abs": "https://arxiv.org/abs/2307.08187", "authors": ["Hiroki Naganuma", "Ryuichiro Hataya", "Kotaro Yoshida", "Ioannis Mitliagkas"], "title": "An Empirical Study of Pre-trained Model Selection for Out-of-Distribution Generalization and Calibration", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to TMLR", "summary": "In the field of computer vision, fine-tuning pre-trained models has become a\nprevalent strategy for out-of-distribution (OOD) generalization tasks.\nDifferent from most prior work that has focused on advancing learning\nalgorithms, we systematically examined how pre-trained model size, pre-training\ndataset size, and training strategies impact generalization and confidence\ncalibration on downstream tasks. We evaluated 100 models across diverse\npre-trained model sizes, five pre-training datasets, and five data\naugmentations through extensive experiments on four distribution shift datasets\ntotaling over 120,000 GPU hours. Our results demonstrate the significant impact\nof pre-trained model selection, with optimal choices substantially improving\nOOD accuracy over algorithm improvement alone. Additionally, we find that\nlarger models and bigger pre-training datasets not only enhance OOD performance\nbut also improve calibration, helping to mitigate overconfidence, contrary to\nsome prior studies that found modern deep networks to calibrate worse than\nclassical shallow models. Our work underscores the overlooked importance of\npre-trained model selection for out-of-distribution generalization and\ncalibration.", "AI": {"tldr": "Pre-trained model size, dataset size, and training strategies significantly impact OOD generalization and calibration, with larger models and datasets improving both performance and confidence calibration.", "motivation": "To systematically study how pre-trained model selection (size, dataset, training strategies) affects OOD generalization and calibration, beyond focusing solely on learning algorithms.", "method": "Evaluated 100 models across varying sizes, five pre-training datasets, and five data augmentations on four distribution shift datasets (120,000+ GPU hours).", "result": "Optimal pre-trained model choices improve OOD accuracy more than algorithm improvements. Larger models and datasets enhance both OOD performance and calibration, countering prior findings.", "conclusion": "Pre-trained model selection is crucial for OOD generalization and calibration, with larger models and datasets offering significant benefits."}}
{"id": "2504.03947", "pdf": "https://arxiv.org/pdf/2504.03947", "abs": "https://arxiv.org/abs/2504.03947", "authors": ["Chris Samarinas", "Hamed Zamani"], "title": "Distillation and Refinement of Reasoning in Small Language Models for Document Re-ranking", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "We present a novel approach for training small language models for\nreasoning-intensive document ranking that combines knowledge distillation with\nreinforcement learning optimization. While existing methods often rely on\nexpensive human annotations or large black-box language models, our methodology\nleverages web data and a teacher LLM to automatically generate high-quality\ntraining examples with relevance explanations. By framing document ranking as a\nreinforcement learning problem and incentivizing explicit reasoning\ncapabilities, we train a compact 3B parameter language model that achieves\nstate-of-the-art performance on the BRIGHT benchmark. Our model ranks third on\nthe leaderboard while using substantially fewer parameters than other\napproaches, outperforming models that are over 20 times larger. Through\nextensive experiments, we demonstrate that generating explanations during\ninference, rather than directly predicting relevance scores, enables more\neffective reasoning with smaller language models. The self-supervised nature of\nour method offers a scalable and interpretable solution for modern information\nretrieval systems.", "AI": {"tldr": "A novel method combines knowledge distillation and reinforcement learning to train small language models for document ranking, achieving state-of-the-art performance with fewer parameters.", "motivation": "Existing methods rely on costly human annotations or large models; this work aims to leverage web data and teacher LLMs for scalable, high-quality training.", "method": "Combines knowledge distillation with reinforcement learning, using web data and a teacher LLM to generate training examples with explanations.", "result": "A 3B parameter model achieves state-of-the-art performance on BRIGHT, ranking third while outperforming larger models.", "conclusion": "Generating explanations during inference improves reasoning in small models, offering a scalable and interpretable solution for information retrieval."}}
{"id": "2208.14649", "pdf": "https://arxiv.org/pdf/2208.14649", "abs": "https://arxiv.org/abs/2208.14649", "authors": ["Zilun Zhang", "Cuifeng Shen", "Yuan Shen", "Huixin Xiong", "Xinyu Zhou"], "title": "Injecting Image Details into CLIP's Feature Space", "categories": ["cs.CV"], "comment": null, "summary": "Although CLIP-like Visual Language Models provide a functional joint feature\nspace for image and text, due to the limitation of the CILP-like model's image\ninput size (e.g., 224), subtle details are lost in the feature representation\nif we input high-resolution images (e.g., 2240). In this work, we introduce an\nefficient framework that can produce a single feature representation for a\nhigh-resolution image that injects image details and shares the same semantic\nspace as the original CLIP. In the framework, we train a feature fusing model\nbased on CLIP features extracted from a carefully designed image patch method\nthat can cover objects of any scale, weakly supervised by image-agnostic class\nprompted queries. We validate our framework by retrieving images from class\nprompted queries on the real world and synthetic datasets, showing significant\nperformance improvement on these tasks. Furthermore, to fully demonstrate our\nframework's detail retrieval ability, we construct a CLEVR-like synthetic\ndataset called CLVER-DS, which is fully annotated and has a controllable object\nscale.", "AI": {"tldr": "An efficient framework is introduced to enhance CLIP-like models by preserving subtle details in high-resolution images, improving feature representation and retrieval performance.", "motivation": "CLIP-like models lose subtle details in high-resolution images due to input size limitations, necessitating a solution for better feature representation.", "method": "A feature fusing model is trained using CLIP features from a custom image patch method, weakly supervised by class-prompted queries.", "result": "The framework significantly improves image retrieval performance on real-world and synthetic datasets, including the newly created CLVER-DS.", "conclusion": "The proposed framework effectively preserves image details and aligns with CLIP's semantic space, demonstrating superior retrieval capabilities."}}
{"id": "2504.19476", "pdf": "https://arxiv.org/pdf/2504.19476", "abs": "https://arxiv.org/abs/2504.19476", "authors": ["Mina Karzand", "Guy Bresler"], "title": "Optimal Sequential Recommendations: Exploiting User and Item Structure", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "comment": "91 pages, 7 figures", "summary": "We consider an online model for recommendation systems, with each user being\nrecommended an item at each time-step and providing 'like' or 'dislike'\nfeedback. A latent variable model specifies the user preferences: both users\nand items are clustered into types. The model captures structure in both the\nitem and user spaces, as used by item-item and user-user collaborative\nfiltering algorithms. We study the situation in which the type preference\nmatrix has i.i.d. entries. Our main contribution is an algorithm that\nsimultaneously uses both item and user structures, proved to be near-optimal\nvia corresponding information-theoretic lower bounds. In particular, our\nanalysis highlights the sub-optimality of using only one of item or user\nstructure (as is done in most collaborative filtering algorithms).", "AI": {"tldr": "An online recommendation system model with user-item clustering and feedback is analyzed, showing the superiority of combining user and item structures over using just one.", "motivation": "To improve recommendation systems by leveraging both user and item structures, addressing the limitations of traditional collaborative filtering methods.", "method": "A latent variable model clusters users and items into types, with an algorithm designed to utilize both structures simultaneously.", "result": "The proposed algorithm is proven near-optimal, outperforming methods that rely solely on user or item structures.", "conclusion": "Combining user and item structures in recommendation systems is more effective than using either alone, as demonstrated by theoretical and practical results."}}
{"id": "2309.10360", "pdf": "https://arxiv.org/pdf/2309.10360", "abs": "https://arxiv.org/abs/2309.10360", "authors": ["Jianjun Gao", "Yi Wang", "Kim-Hui Yap", "Kratika Garg", "Boon Siew Han"], "title": "OccluTrack: Rethinking Awareness of Occlusion for Enhancing Multiple Pedestrian Tracking", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by IEEE T-ITS", "summary": "Multiple pedestrian tracking is crucial for enhancing safety and efficiency\nin intelligent transport and autonomous driving systems by predicting movements\nand enabling adaptive decision-making in dynamic environments. It optimizes\ntraffic flow, facilitates human interaction, and ensures compliance with\nregulations. However, it faces the challenge of tracking pedestrians in the\npresence of occlusion. Existing methods overlook effects caused by abnormal\ndetections during partial occlusion. Subsequently, these abnormal detections\ncan lead to inaccurate motion estimation, unreliable appearance features, and\nunfair association. To address these issues, we propose an adaptive\nocclusion-aware multiple pedestrian tracker, OccluTrack, to mitigate the\neffects caused by partial occlusion. Specifically, we first introduce a\nplug-and-play abnormal motion suppression mechanism into the Kalman Filter to\nadaptively detect and suppress outlier motions caused by partial occlusion.\nSecond, we develop a pose-guided re-identification (Re-ID) module to extract\ndiscriminative part features for partially occluded pedestrians. Last, we\ndevelop a new occlusion-aware association method towards fair Intersection over\nUnion (IoU) and appearance embedding distance measurement for occluded\npedestrians. Extensive evaluation results demonstrate that our method\noutperforms state-of-the-art methods on MOTChallenge and DanceTrack datasets.\nParticularly, the performance improvements on IDF1 and ID Switches, as well as\nvisualized results, demonstrate the effectiveness of our method in multiple\npedestrian tracking.", "AI": {"tldr": "Proposes OccluTrack, an adaptive occlusion-aware tracker for multiple pedestrian tracking, addressing partial occlusion challenges with motion suppression, pose-guided Re-ID, and occlusion-aware association.", "motivation": "To improve safety and efficiency in intelligent transport by addressing inaccuracies in motion estimation and unreliable features caused by partial occlusion in existing methods.", "method": "Introduces a motion suppression mechanism in Kalman Filter, a pose-guided Re-ID module, and an occlusion-aware association method for fair IoU and embedding distance measurement.", "result": "Outperforms state-of-the-art methods on MOTChallenge and DanceTrack datasets, showing improvements in IDF1 and ID Switches.", "conclusion": "OccluTrack effectively mitigates partial occlusion effects, enhancing tracking accuracy and reliability in dynamic environments."}}
{"id": "2504.07089", "pdf": "https://arxiv.org/pdf/2504.07089", "abs": "https://arxiv.org/abs/2504.07089", "authors": ["Yiting Lu", "Jiakang Yuan", "Zhen Li", "Shitian Zhao", "Qi Qin", "Xinyue Li", "Le Zhuo", "Licheng Wen", "Dongyang Liu", "Yuewen Cao", "Xiangchao Yan", "Xin Li", "Tianshuo Peng", "Shufei Zhang", "Botian Shi", "Tao Chen", "Zhibo Chen", "Lei Bai", "Bo Zhang", "Peng Gao"], "title": "OmniCaptioner: One Captioner to Rule Them All", "categories": ["cs.CV", "cs.CL"], "comment": "More visualizations on Homepage:\n  https://alpha-innovator.github.io/OmniCaptioner-project-page and Official\n  code: https://github.com/Alpha-Innovator/OmniCaptioner", "summary": "We propose OmniCaptioner, a versatile visual captioning framework for\ngenerating fine-grained textual descriptions across a wide variety of visual\ndomains. Unlike prior methods limited to specific image types (e.g., natural\nimages or geometric visuals), our framework provides a unified solution for\ncaptioning natural images, visual text (e.g., posters, UIs, textbooks), and\nstructured visuals (e.g., documents, tables, charts). By converting low-level\npixel information into semantically rich textual representations, our framework\nbridges the gap between visual and textual modalities. Our results highlight\nthree key advantages: (i) Enhanced Visual Reasoning with LLMs, where\nlong-context captions of visual modalities empower LLMs, particularly the\nDeepSeek-R1 series, to reason effectively in multimodal scenarios; (ii)\nImproved Image Generation, where detailed captions improve tasks like\ntext-to-image generation and image transformation; and (iii) Efficient\nSupervised Fine-Tuning (SFT), which enables faster convergence with less data.\nWe believe the versatility and adaptability of OmniCaptioner can offer a new\nperspective for bridging the gap between language and visual modalities.", "AI": {"tldr": "OmniCaptioner is a unified visual captioning framework for diverse visual domains, enhancing multimodal reasoning, image generation, and fine-tuning efficiency.", "motivation": "To bridge the gap between visual and textual modalities by providing a versatile solution for captioning various visual types, unlike domain-specific prior methods.", "method": "Converts low-level pixel data into rich textual descriptions for natural images, visual text, and structured visuals.", "result": "Demonstrates enhanced visual reasoning with LLMs, improved image generation, and efficient supervised fine-tuning.", "conclusion": "OmniCaptioner's versatility offers a new perspective for integrating language and visual modalities."}}
{"id": "2302.01540", "pdf": "https://arxiv.org/pdf/2302.01540", "abs": "https://arxiv.org/abs/2302.01540", "authors": ["Dongsheng Xu", "Qingbao Huang", "Xingmao Zhang", "Haonan Cheng", "Feng Shuang", "Yi Cai"], "title": "DEVICE: Depth and Visual Concepts Aware Transformer for OCR-based Image Captioning", "categories": ["cs.CV"], "comment": "13pages, 8figures. This work has been published in Pattern\n  Recognition", "summary": "OCR-based image captioning is an important but under-explored task, aiming to\ngenerate descriptions containing visual objects and scene text. Recent studies\nhave made encouraging progress, but they are still suffering from a lack of\noverall understanding of scenes and generating inaccurate captions. One\npossible reason is that current studies mainly focus on constructing the\nplane-level geometric relationship of scene text without depth information.\nThis leads to insufficient scene text relational reasoning so that models may\ndescribe scene text inaccurately. The other possible reason is that existing\nmethods fail to generate fine-grained descriptions of some visual objects. In\naddition, they may ignore essential visual objects, leading to the scene text\nbelonging to these ignored objects not being utilized. To address the above\nissues, we propose a Depth and Visual Concepts Aware Transformer (DEVICE) for\nOCR-based image captinong. Concretely, to construct three-dimensional geometric\nrelations, we introduce depth information and propose a depth-enhanced feature\nupdating module to ameliorate OCR token features. To generate more precise and\ncomprehensive captions, we introduce semantic features of detected visual\nconcepts as auxiliary information, and propose a semantic-guided alignment\nmodule to improve the model's ability to utilize visual concepts. Our DEVICE is\ncapable of comprehending scenes more comprehensively and boosting the accuracy\nof described visual entities. Sufficient experiments demonstrate the\neffectiveness of our proposed DEVICE, which outperforms state-of-the-art models\non the TextCaps test set.", "AI": {"tldr": "The paper proposes DEVICE, a Depth and Visual Concepts Aware Transformer, to improve OCR-based image captioning by incorporating depth information and visual concepts for better scene understanding and caption accuracy.", "motivation": "Current OCR-based image captioning methods lack depth information and fine-grained descriptions, leading to inaccurate captions and insufficient scene text relational reasoning.", "method": "Introduces depth-enhanced feature updating and semantic-guided alignment modules to improve OCR token features and utilize visual concepts.", "result": "DEVICE outperforms state-of-the-art models on the TextCaps test set, demonstrating improved scene comprehension and caption accuracy.", "conclusion": "Incorporating depth and visual concepts enhances OCR-based image captioning, addressing previous limitations and achieving superior performance."}}
{"id": "2504.19488", "pdf": "https://arxiv.org/pdf/2504.19488", "abs": "https://arxiv.org/abs/2504.19488", "authors": ["Vijay Prakash S"], "title": "Two-parameter superposable S-curves", "categories": ["stat.ME", "cs.LG"], "comment": null, "summary": "Straight line equation $y=mx$ with slope $m$, when singularly perturbed as\n$ay^3+y=mx$ with a positive parameter $a$, results in S-shaped curves or\nS-curves on a real plane. As $a\\rightarrow 0$, we get back $y=mx$ which is a\ncumulative distribution function of a continuous uniform distribution that\ndescribes the occurrence of every event in an interval to be equally probable.\nAs $a\\rightarrow\\infty$, the derivative of $y$ has finite support only at $y=0$\nresembling a degenerate distribution. Based on these arguments, in this work,\nwe propose that these S-curves can represent maximum entropy uniform\ndistribution to a zero entropy single value. We also argue that these S-curves\nare superposable as they are only parametrically nonlinear but fundamentally\nlinear. So far, the superposed forms have been used to capture the patterns of\nnatural systems such as nonlinear dynamics of biological growth and kinetics of\nenzyme reactions. Here, we attempt to use the S-curve and its superposed form\nas a statistical model. We fit the models on a classical dataset containing\nflower measurements of iris plants and analyze their usefulness in pattern\nrecognition. Based on these models, we claim that any non-uniform pattern can\nbe represented as a singular perturbation to uniform distribution. However, our\nparametric estimation procedure have some limitations such as sensitivity to\ninitial conditions depending on the data at hand.", "AI": {"tldr": "The paper explores S-curves from singular perturbations of a straight line equation, proposing them as models for transitioning from uniform to degenerate distributions. It applies these curves to pattern recognition in iris flower data.", "motivation": "To bridge the gap between uniform and degenerate distributions using S-curves and demonstrate their utility in statistical modeling and pattern recognition.", "method": "Singular perturbation of the equation $y=mx$ to $ay^3+y=mx$, analyzing S-curves and their superposed forms, fitting them to iris flower data.", "result": "S-curves can model transitions from uniform to degenerate distributions and capture patterns in natural systems, though parameter estimation is sensitive to initial conditions.", "conclusion": "Non-uniform patterns can be represented as perturbations of uniform distributions, but the method has limitations in parameter sensitivity."}}
{"id": "2312.15101", "pdf": "https://arxiv.org/pdf/2312.15101", "abs": "https://arxiv.org/abs/2312.15101", "authors": ["Nikolaos Louloudakis", "Perry Gibson", "Jos\u00e9 Cano", "Ajitha Rajan"], "title": "FetaFix: Automatic Fault Localization and Repair of Deep Learning Model Conversions", "categories": ["cs.SE", "cs.AI", "cs.CV", "cs.LG"], "comment": "12 pages, 4 figures, 3 tables, 1 algorithm", "summary": "Converting deep learning models between frameworks is a common step to\nmaximize model compatibility across devices and leverage optimization features\nthat may be exclusively provided in one deep learning framework. However, this\nconversion process may be riddled with bugs, making the converted models either\nundeployable or problematic, considerably degrading their prediction\ncorrectness.\n  In this paper, we propose an automated approach for fault localization and\nrepair, FetaFix, during model conversion between deep learning frameworks.\nFetaFix is capable of detecting and fixing faults introduced in model input,\nparameters, hyperparameters, and the model graph during conversion. FetaFix\nuses a set of fault types (mined from surveying common conversion issues\nreported in code repositories and forums) to localize potential conversion\nfaults in the converted target model and then repair them appropriately, e.g.,\nreplacing the parameters of the target model with those from the source model.\nThis is done iteratively for every image in the dataset, comparing output label\ndifferences between the source model and the converted target model until all\ndifferences are resolved. We evaluate the effectiveness of FetaFix in fixing\nmodel conversion bugs of three widely used image recognition models converted\nacross four different deep learning frameworks. Overall, FetaFix was able to\nfix $462$ out of $755$ detected conversion faults, either completely repairing\nor significantly improving the performance of $14$ out of the $15$ erroneous\nconversion cases.", "AI": {"tldr": "FetaFix is an automated tool for detecting and fixing faults in deep learning model conversions, improving compatibility and correctness.", "motivation": "Model conversion between frameworks often introduces bugs, making converted models unreliable or unusable.", "method": "FetaFix localizes and repairs faults in input, parameters, hyperparameters, and model graphs using mined fault types and iterative comparison of outputs.", "result": "FetaFix fixed 462 out of 755 faults, significantly improving 14 out of 15 erroneous conversion cases.", "conclusion": "FetaFix effectively addresses conversion faults, enhancing model reliability post-conversion."}}
{"id": "2504.15280", "pdf": "https://arxiv.org/pdf/2504.15280", "abs": "https://arxiv.org/abs/2504.15280", "authors": ["Chun-Hsiao Yeh", "Chenyu Wang", "Shengbang Tong", "Ta-Ying Cheng", "Ruoyu Wang", "Tianzhe Chu", "Yuexiang Zhai", "Yubei Chen", "Shenghua Gao", "Yi Ma"], "title": "Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs", "categories": ["cs.CV", "cs.CL"], "comment": "Project page: https://danielchyeh.github.io/All-Angles-Bench/", "summary": "Multi-view understanding, the ability to reconcile visual information across\ndiverse viewpoints for effective navigation, manipulation, and 3D scene\ncomprehension, is a fundamental challenge in Multi-Modal Large Language Models\n(MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive\nadvances in high-level reasoning and planning, they frequently fall short when\nconfronted with multi-view geometric consistency and cross-view correspondence.\nTo comprehensively evaluate the challenges of MLLMs in multi-view scene\nreasoning, we propose All-Angles Bench, a benchmark of over 2,100 human\ncarefully annotated multi-view question-answer pairs across 90 diverse\nreal-world scenes. Our six tasks (counting, attribute identification, relative\ndistance, relative direction, object manipulation, and camera pose estimation)\nspecifically test model's geometric correspondence and the capacity to align\ninformation consistently across views. Our extensive experiments, benchmark on\n27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and\nGPT-4o against human evaluators reveals a substantial performance gap,\nindicating that current MLLMs remain far from human-level proficiency. Through\nin-depth analysis, we show that MLLMs are particularly underperforming under\ntwo aspects: (1) cross-view correspondence for partially occluded views and (2)\nestablishing the coarse camera poses. These findings highlight the necessity of\ndomain-specific refinements or modules that embed stronger multi-view\nawareness. We believe that our All-Angles Bench offers valuable insights and\ncontribute to bridging the gap between MLLMs and human-level multi-view\nunderstanding. The project and benchmark are publicly available at\nhttps://danielchyeh.github.io/All-Angles-Bench/.", "AI": {"tldr": "The paper introduces All-Angles Bench, a benchmark for evaluating Multi-Modal Large Language Models (MLLMs) on multi-view scene reasoning, revealing significant gaps in geometric consistency and cross-view correspondence compared to humans.", "motivation": "To address the shortcomings of MLLMs in multi-view understanding, particularly in geometric consistency and cross-view correspondence, which are crucial for embodied agents.", "method": "The authors propose All-Angles Bench, a dataset of 2,100 annotated multi-view QA pairs across 90 real-world scenes, testing six tasks to evaluate MLLMs.", "result": "Experiments on 27 MLLMs show a substantial performance gap, with models struggling in cross-view correspondence for occluded views and coarse camera pose estimation.", "conclusion": "The findings emphasize the need for domain-specific refinements in MLLMs to improve multi-view awareness, with All-Angles Bench serving as a valuable resource for future research."}}
{"id": "2304.04421", "pdf": "https://arxiv.org/pdf/2304.04421", "abs": "https://arxiv.org/abs/2304.04421", "authors": ["Yi Xiao", "Qiangqiang Yuan", "Kui Jiang", "Xianyu Jin", "Jiang He", "Liangpei Zhang", "Chia-Wen Lin"], "title": "Local-Global Temporal Difference Learning for Satellite Video Super-Resolution", "categories": ["cs.CV"], "comment": "IEEE Transactions on Circuits and Systems for Video Technology,\n  34(4): 2789-2802, 2024", "summary": "Optical-flow-based and kernel-based approaches have been extensively explored\nfor temporal compensation in satellite Video Super-Resolution (VSR). However,\nthese techniques are less generalized in large-scale or complex scenarios,\nespecially in satellite videos. In this paper, we propose to exploit the\nwell-defined temporal difference for efficient and effective temporal\ncompensation. To fully utilize the local and global temporal information within\nframes, we systematically modeled the short-term and long-term temporal\ndiscrepancies since we observed that these discrepancies offer distinct and\nmutually complementary properties. Specifically, we devise a Short-term\nTemporal Difference Module (S-TDM) to extract local motion representations from\nRGB difference maps between adjacent frames, which yields more clues for\naccurate texture representation. To explore the global dependency in the entire\nframe sequence, a Long-term Temporal Difference Module (L-TDM) is proposed,\nwhere the differences between forward and backward segments are incorporated\nand activated to guide the modulation of the temporal feature, leading to a\nholistic global compensation. Moreover, we further propose a Difference\nCompensation Unit (DCU) to enrich the interaction between the spatial\ndistribution of the target frame and temporal compensated results, which helps\nmaintain spatial consistency while refining the features to avoid misalignment.\nRigorous objective and subjective evaluations conducted across five mainstream\nvideo satellites demonstrate that our method performs favorably against\nstate-of-the-art approaches. Code will be available at\nhttps://github.com/XY-boy/LGTD", "AI": {"tldr": "The paper proposes a novel method for temporal compensation in satellite Video Super-Resolution (VSR) using short-term and long-term temporal differences, outperforming existing techniques.", "motivation": "Existing optical-flow and kernel-based methods for temporal compensation in satellite VSR lack generalization in large-scale or complex scenarios.", "method": "The authors introduce Short-term (S-TDM) and Long-term (L-TDM) Temporal Difference Modules to capture local and global temporal discrepancies, along with a Difference Compensation Unit (DCU) for spatial consistency.", "result": "The method outperforms state-of-the-art approaches in objective and subjective evaluations across five mainstream video satellites.", "conclusion": "The proposed approach effectively addresses limitations of existing methods by leveraging temporal differences, offering improved performance in satellite VSR."}}
{"id": "2504.19497", "pdf": "https://arxiv.org/pdf/2504.19497", "abs": "https://arxiv.org/abs/2504.19497", "authors": ["Kanghong Shi", "Ruigang Wang", "Ian R. Manchester"], "title": "Negative Imaginary Neural ODEs: Learning to Control Mechanical Systems with Stability Guarantees", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "comment": null, "summary": "We propose a neural control method to provide guaranteed stabilization for\nmechanical systems using a novel negative imaginary neural ordinary\ndifferential equation (NINODE) controller. Specifically, we employ neural\nnetworks with desired properties as state-space function matrices within a\nHamiltonian framework to ensure the system possesses the NI property. This\nNINODE system can serve as a controller that asymptotically stabilizes an NI\nplant under certain conditions. For mechanical plants with colocated force\nactuators and position sensors, we demonstrate that all the conditions required\nfor stability can be translated into regularity constraints on the neural\nnetworks used in the controller. We illustrate the utility, effectiveness, and\nstability guarantees of the NINODE controller through an example involving a\nnonlinear mass-spring system.", "AI": {"tldr": "A neural control method (NINODE) ensures guaranteed stabilization for mechanical systems by embedding neural networks with desired properties in a Hamiltonian framework.", "motivation": "To provide guaranteed stabilization for mechanical systems using neural networks while ensuring the negative imaginary (NI) property.", "method": "Neural networks are used as state-space function matrices within a Hamiltonian framework to create a NINODE controller, ensuring the NI property. Stability conditions are translated into neural network constraints.", "result": "The NINODE controller asymptotically stabilizes NI plants, demonstrated via a nonlinear mass-spring system.", "conclusion": "The NINODE controller is effective, stable, and applicable to mechanical systems with colocated actuators and sensors."}}
{"id": "2401.08658", "pdf": "https://arxiv.org/pdf/2401.08658", "abs": "https://arxiv.org/abs/2401.08658", "authors": ["Gongjin Lan", "Qi Hao"], "title": "End-To-End Planning of Autonomous Driving in Industry and Academia: 2022-2023", "categories": ["cs.RO", "cs.AI"], "comment": "This is a draft and not ready to be public. There are many errors", "summary": "This paper aims to provide a quick review of the methods including the\ntechnologies in detail that are currently reported in industry and academia.\nSpecifically, this paper reviews the end-to-end planning, including Tesla FSD\nV12, Momenta 2023, Horizon Robotics 2023, Motional RoboTaxi 2022, Woven Planet\n(Toyota): Urban Driver, and Nvidia. In addition, we review the state-of-the-art\nacademic studies that investigate end-to-end planning of autonomous driving.\nThis paper provides readers with a concise structure and fast learning of\nstate-of-the-art end-to-end planning for 2022-2023. This article provides a\nmeaningful overview as introductory material for beginners to follow the\nstate-of-the-art end-to-end planning of autonomous driving in industry and\nacademia, as well as supplementary material for advanced researchers.", "AI": {"tldr": "A review of state-of-the-art end-to-end planning methods in autonomous driving for 2022-2023, covering industry and academic advancements.", "motivation": "To provide a concise and structured overview of current end-to-end planning technologies in autonomous driving for beginners and advanced researchers.", "method": "Reviews industry reports (e.g., Tesla FSD V12, Momenta 2023) and academic studies on end-to-end planning.", "result": "A comprehensive summary of the latest advancements in autonomous driving planning.", "conclusion": "The paper serves as an introductory and supplementary resource for understanding end-to-end planning in autonomous driving."}}
{"id": "2504.17834", "pdf": "https://arxiv.org/pdf/2504.17834", "abs": "https://arxiv.org/abs/2504.17834", "authors": ["Haokai Zhang", "Shengtao Zhang", "Zijian Cai", "Heng Wang", "Ruixuan Zhu", "Zinan Zeng", "Minnan Luo"], "title": "Unveiling the Hidden: Movie Genre and User Bias in Spoiler Detection", "categories": ["cs.IR", "cs.CL"], "comment": "11 pages, 6 figures, under review", "summary": "Spoilers in movie reviews are important on platforms like IMDb and Rotten\nTomatoes, offering benefits and drawbacks. They can guide some viewers' choices\nbut also affect those who prefer no plot details in advance, making effective\nspoiler detection essential. Existing spoiler detection methods mainly analyze\nreview text, often overlooking the impact of movie genres and user bias,\nlimiting their effectiveness. To address this, we analyze movie review data,\nfinding genre-specific variations in spoiler rates and identifying that certain\nusers are more likely to post spoilers. Based on these findings, we introduce a\nnew spoiler detection framework called GUSD (The code is available at\nhttps://github.com/AI-explorer-123/GUSD) (Genre-aware and User-specific Spoiler\nDetection), which incorporates genre-specific data and user behavior bias. User\nbias is calculated through dynamic graph modeling of review history.\nAdditionally, the R2GFormer module combines RetGAT (Retentive Graph Attention\nNetwork) for graph information and GenreFormer for genre-specific aggregation.\nThe GMoE (Genre-Aware Mixture of Experts) model further assigns reviews to\nspecialized experts based on genre. Extensive testing on benchmark datasets\nshows that GUSD achieves state-of-the-art results. This approach advances\nspoiler detection by addressing genre and user-specific patterns, enhancing\nuser experience on movie review platforms.", "AI": {"tldr": "The paper introduces GUSD, a spoiler detection framework that considers genre-specific data and user behavior bias, outperforming existing methods.", "motivation": "Existing spoiler detection methods ignore genre and user bias, limiting effectiveness. This work aims to improve detection by addressing these factors.", "method": "GUSD uses dynamic graph modeling for user bias, RetGAT and GenreFormer for graph and genre data, and GMoE for genre-specific review assignment.", "result": "GUSD achieves state-of-the-art performance on benchmark datasets.", "conclusion": "GUSD enhances spoiler detection by incorporating genre and user-specific patterns, improving user experience on review platforms."}}
{"id": "2305.14392", "pdf": "https://arxiv.org/pdf/2305.14392", "abs": "https://arxiv.org/abs/2305.14392", "authors": ["Amogh Joshi", "Adarsh Kosta", "Wachirawit Ponghiran", "Manish Nagaraj", "Kaushik Roy"], "title": "FEDORA: Flying Event Dataset fOr Reactive behAvior", "categories": ["cs.CV", "cs.ET", "cs.LG", "cs.NE", "cs.RO"], "comment": "Published in the Proceedings of the IEEE/RSJ International Conference\n  on Intelligent Robots and Systems (IROS), 2024", "summary": "The ability of resource-constrained biological systems such as fruitflies to\nperform complex and high-speed maneuvers in cluttered environments has been one\nof the prime sources of inspiration for developing vision-based autonomous\nsystems. To emulate this capability, the perception pipeline of such systems\nmust integrate information cues from tasks including optical flow and depth\nestimation, object detection and tracking, and segmentation, among others.\nHowever, the conventional approach of employing slow, synchronous inputs from\nstandard frame-based cameras constrains these perception capabilities,\nparticularly during high-speed maneuvers. Recently, event-based sensors have\nemerged as low latency and low energy alternatives to standard frame-based\ncameras for capturing high-speed motion, effectively speeding up perception and\nhence navigation. For coherence, all the perception tasks must be trained on\nthe same input data. However, present-day datasets are curated mainly for a\nsingle or a handful of tasks and are limited in the rate of the provided ground\ntruths. To address these limitations, we present Flying Event Dataset fOr\nReactive behAviour (FEDORA) - a fully synthetic dataset for perception tasks,\nwith raw data from frame-based cameras, event-based cameras, and Inertial\nMeasurement Units (IMU), along with ground truths for depth, pose, and optical\nflow at a rate much higher than existing datasets.", "AI": {"tldr": "FEDORA is a synthetic dataset addressing the lack of high-rate ground truths for multiple perception tasks in vision-based autonomous systems, inspired by biological systems like fruitflies.", "motivation": "Biological systems perform high-speed maneuvers in cluttered environments, inspiring vision-based autonomous systems. Current datasets lack high-rate ground truths for multiple tasks.", "method": "Introduces FEDORA, a synthetic dataset with raw data from frame-based and event-based cameras, IMUs, and high-rate ground truths for depth, pose, and optical flow.", "result": "FEDORA provides a comprehensive dataset for training perception tasks, overcoming limitations of existing datasets.", "conclusion": "FEDORA enables better training of perception pipelines for high-speed maneuvers in autonomous systems."}}
{"id": "2504.19596", "pdf": "https://arxiv.org/pdf/2504.19596", "abs": "https://arxiv.org/abs/2504.19596", "authors": ["Xi Fu", "Wei-Bang Jiang", "Yi Ding", "Cuntai Guan"], "title": "Towards Robust Multimodal Physiological Foundation Models: Handling Arbitrary Missing Modalities", "categories": ["eess.SP", "cs.LG"], "comment": "19 pages, 5 figures", "summary": "Multimodal physiological signals, such as EEG, ECG, EOG, and EMG, are crucial\nfor healthcare and brain-computer interfaces. While existing methods rely on\nspecialized architectures and dataset-specific fusion strategies, they struggle\nto learn universal representations that generalize across datasets and handle\nmissing modalities at inference time. To address these issues, we propose\nPhysioOmni, a foundation model for multimodal physiological signal analysis\nthat models both homogeneous and heterogeneous features to decouple multimodal\nsignals and extract generic representations while maintaining compatibility\nwith arbitrary missing modalities. PhysioOmni trains a decoupled multimodal\ntokenizer, enabling masked signal pre-training via modality-invariant and\nmodality-specific objectives. To ensure adaptability to diverse and incomplete\nmodality combinations, the pre-trained encoders undergo resilient fine-tuning\nwith prototype alignment on downstream datasets. Extensive experiments on four\ndownstream tasks, emotion recognition, sleep stage classification, motor\nprediction, and mental workload detection, demonstrate that PhysioOmni achieves\nstate-of-the-art performance while maintaining strong robustness to missing\nmodalities. Our code and model weights will be released.", "AI": {"tldr": "PhysioOmni is a foundation model for multimodal physiological signal analysis, addressing generalization and missing modality issues by decoupling signals and using masked pre-training.", "motivation": "Existing methods lack universal representations and struggle with missing modalities. PhysioOmni aims to generalize across datasets and handle incomplete data.", "method": "Proposes a decoupled multimodal tokenizer with masked signal pre-training (modality-invariant and specific objectives) and resilient fine-tuning with prototype alignment.", "result": "Achieves state-of-the-art performance on four tasks (emotion recognition, sleep stage classification, motor prediction, mental workload detection) with robustness to missing modalities.", "conclusion": "PhysioOmni is effective for multimodal physiological signal analysis, offering generalization and robustness, with plans to release code and model weights."}}
{"id": "2402.00389", "pdf": "https://arxiv.org/pdf/2402.00389", "abs": "https://arxiv.org/abs/2402.00389", "authors": ["Huan Li", "Yiming Dong", "Zhouchen Lin"], "title": "On the $O(\\frac{\\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\\ell_1$ Norm", "categories": ["math.OC", "cs.AI"], "comment": "V5 vs V4: Improve the noise dependence from $\\sqrt{d}\\|\\sigma\\|_2$ to\n  $\\|\\sigma\\|_1$ and modify the related work. V4 vs V3: More experiments. V3 vs\n  V2: A fairer comparison with (Li et al., 2023). V2 vs V1: (1) Correct one\n  error in v1. (2) Improve the convergence rate matching the lower bound with\n  respect to all the coefficients except the dimension", "summary": "Although adaptive gradient methods have been extensively used in deep\nlearning, their convergence rates proved in the literature are all slower than\nthat of SGD, particularly with respect to their dependence on the dimension.\nThis paper considers the classical RMSProp and its momentum extension and\nestablishes the convergence rate of $\\frac{1}{T}\\sum_{k=1}^T E\\left[\\|\\nabla\nf(x^k)\\|_1\\right]\\leq O(\\frac{\\sqrt{d}C}{T^{1/4}})$ measured by $\\ell_1$ norm\nwithout the bounded gradient assumption, where $d$ is the dimension of the\noptimization variable, $T$ is the iteration number, and $C$ is a constant\nidentical to that appeared in the optimal convergence rate of SGD. Our\nconvergence rate matches the lower bound with respect to all the coefficients\nexcept the dimension $d$. Since $\\|x\\|_2\\ll\\|x\\|_1\\leq\\sqrt{d}\\|x\\|_2$ for\nproblems with extremely large $d$, our convergence rate can be considered to be\nanalogous to the $\\frac{1}{T}\\sum_{k=1}^T E\\left[\\|\\nabla f(x^k)\\|_2\\right]\\leq\nO(\\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\\|\\nabla\nf(x)\\|_1=\\varTheta(\\sqrt{d}\\|\\nabla f(x)\\|_2)$.", "AI": {"tldr": "The paper establishes a convergence rate for RMSProp and its momentum variant, matching SGD's optimal rate except for dimension dependence, and shows it's analogous to SGD in large dimensions.", "motivation": "To address the slower convergence rates of adaptive gradient methods compared to SGD, particularly in high-dimensional settings.", "method": "Analyzes RMSProp and its momentum extension, proving convergence rates using the \u21131 norm without bounded gradient assumptions.", "result": "Derives a convergence rate of O(\u221ad C / T^{1/4}), matching SGD's lower bound except for dimension dependence.", "conclusion": "The results show RMSProp's convergence is comparable to SGD in high dimensions, bridging a gap in adaptive method theory."}}
{"id": "2307.00183", "pdf": "https://arxiv.org/pdf/2307.00183", "abs": "https://arxiv.org/abs/2307.00183", "authors": ["Jiangpeng He", "Xiaoyan Zhang", "Luotao Lin", "Jack Ma", "Heather A. Eicher-Miller", "Fengqing Zhu"], "title": "Long-Tailed Continual Learning For Visual Food Recognition", "categories": ["cs.CV"], "comment": "Accepted to IEEE Transactions on Multimedia, the VFN186 food image\n  dataset is available at https://github.com/JiangpengHe/VFN186", "summary": "Deep learning-based food recognition has made significant progress in\npredicting food types from eating occasion images. However, two key challenges\nhinder real-world deployment: (1) continuously learning new food classes\nwithout forgetting previously learned ones, and (2) handling the long-tailed\ndistribution of food images, where a few common classes and many more rare\nclasses. To address these, food recognition methods should focus on long-tailed\ncontinual learning. In this work, We introduce a dataset that encompasses 186\nAmerican foods along with comprehensive annotations. We also introduce three\nnew benchmark datasets, VFN186-LT, VFN186-INSULIN and VFN186-T2D, which reflect\nreal-world food consumption for healthy populations, insulin takers and\nindividuals with type 2 diabetes without taking insulin. We propose a novel\nend-to-end framework that improves the generalization ability for instance-rare\nfood classes using a knowledge distillation-based predictor to avoid\nmisalignment of representation during continual learning. Additionally, we\nintroduce an augmentation technique by integrating class-activation-map (CAM)\nand CutMix to improve generalization on instance-rare food classes. Our method,\nevaluated on Food101-LT, VFN-LT, VFN186-LT, VFN186-INSULIN, and VFN186-T2DM,\nshows significant improvements over existing methods. An ablation study\nhighlights further performance enhancements, demonstrating its potential for\nreal-world food recognition applications.", "AI": {"tldr": "A novel framework for long-tailed continual learning in food recognition addresses challenges like forgetting old classes and handling rare food classes, using knowledge distillation and CAM-CutMix augmentation, validated on new datasets.", "motivation": "Overcome challenges in real-world food recognition: continual learning without forgetting and handling long-tailed distributions of food classes.", "method": "Proposes an end-to-end framework with knowledge distillation and CAM-CutMix augmentation to improve generalization, especially for rare classes.", "result": "Significant improvements over existing methods on benchmark datasets, with ablation studies confirming performance gains.", "conclusion": "The framework shows promise for real-world food recognition, addressing key challenges in continual learning and long-tailed distributions."}}
{"id": "2504.19625", "pdf": "https://arxiv.org/pdf/2504.19625", "abs": "https://arxiv.org/abs/2504.19625", "authors": ["Massimo Fioravanti", "Samuele Pasini", "Giovanni Agosta"], "title": "Rulebook: bringing co-routines to reinforcement learning environments", "categories": ["cs.PL", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) algorithms, due to their reliance on external\nsystems to learn from, require digital environments (e.g., simulators) with\nvery simple interfaces, which in turn constrain significantly the\nimplementation of such environments. In particular, these environments are\nimplemented either as separate processes or as state machines, leading to\nsynchronization and communication overheads in the first case, and to\nunstructured programming in the second.\n  We propose a new domain-specific, co-routine-based, compiled language, called\nRulebook, designed to automatically generate the state machine required to\ninteract with machine learning (ML) algorithms and similar applications, with\nno performance overhead. Rulebook allows users to express programs without\nneeding to be aware of the specific interface required by the ML components. By\ndecoupling the execution model of the program from the syntactical encoding of\nthe program, and thus without the need for manual state management, Rulebook\nallows to create larger and more sophisticated environments at a lower\ndevelopment cost.", "AI": {"tldr": "Rulebook is a new language designed to simplify and optimize the creation of environments for reinforcement learning by automating state machine generation.", "motivation": "Current RL environments face issues like synchronization overhead or unstructured programming due to their reliance on external systems.", "method": "Rulebook, a domain-specific, co-routine-based compiled language, automates state machine generation for ML interactions without performance overhead.", "result": "Rulebook enables the creation of more sophisticated environments with lower development costs by decoupling execution from syntax.", "conclusion": "Rulebook offers a streamlined solution for RL environment development, reducing complexity and overhead."}}
{"id": "2403.05842", "pdf": "https://arxiv.org/pdf/2403.05842", "abs": "https://arxiv.org/abs/2403.05842", "authors": ["Hengyuan Xu", "Liyao Xiang", "Borui Yang", "Xingjun Ma", "Siheng Chen", "Baochun Li"], "title": "TokenMark: A Modality-Agnostic Watermark for Pre-trained Transformers", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Watermarking is a critical tool for model ownership verification. However,\nexisting watermarking techniques are often designed for specific data\nmodalities and downstream tasks, without considering the inherent architectural\nproperties of the model. This lack of generality and robustness underscores the\nneed for a more versatile watermarking approach. In this work, we investigate\nthe properties of Transformer models and propose TokenMark, a\nmodality-agnostic, robust watermarking system for pre-trained models,\nleveraging the permutation equivariance property. TokenMark embeds the\nwatermark by fine-tuning the pre-trained model on a set of specifically\npermuted data samples, resulting in a watermarked model that contains two\ndistinct sets of weights -- one for normal functionality and the other for\nwatermark extraction, the latter triggered only by permuted inputs. Extensive\nexperiments on state-of-the-art pre-trained models demonstrate that TokenMark\nsignificantly improves the robustness, efficiency, and universality of model\nwatermarking, highlighting its potential as a unified watermarking solution.", "AI": {"tldr": "TokenMark is a versatile, modality-agnostic watermarking system for pre-trained Transformer models, leveraging permutation equivariance for robust ownership verification.", "motivation": "Existing watermarking techniques lack generality and robustness, failing to account for model architectural properties.", "method": "TokenMark embeds watermarks by fine-tuning models on permuted data, creating dual-weight sets for normal and watermark-triggered functionality.", "result": "TokenMark enhances robustness, efficiency, and universality in model watermarking, as validated by experiments on state-of-the-art models.", "conclusion": "TokenMark offers a unified, effective solution for model watermarking, addressing limitations of prior approaches."}}
{"id": "2310.17952", "pdf": "https://arxiv.org/pdf/2310.17952", "abs": "https://arxiv.org/abs/2310.17952", "authors": ["Shuang Li", "Jiaxu Leng", "Ji Gan", "Mengjingcheng Mo", "Xinbo Gao"], "title": "Shape-centered Representation Learning for Visible-Infrared Person Re-identification", "categories": ["cs.CV"], "comment": "Accepted for Pattern Recognition. Code:\n  https://github.com/Visuang/ScRL", "summary": "Visible-Infrared Person Re-Identification (VI-ReID) plays a critical role in\nall-day surveillance systems. However, existing methods primarily focus on\nlearning appearance features while overlooking body shape features, which not\nonly complement appearance features but also exhibit inherent robustness to\nmodality variations. Despite their potential, effectively integrating shape and\nappearance features remains challenging. Appearance features are highly\nsusceptible to modality variations and background noise, while shape features\noften suffer from inaccurate infrared shape estimation due to the limitations\nof auxiliary models. To address these challenges, we propose the Shape-centered\nRepresentation Learning (ScRL) framework, which enhances VI-ReID performance by\ninnovatively integrating shape and appearance features. Specifically, we\nintroduce Infrared Shape Restoration (ISR) to restore inaccuracies in infrared\nbody shape representations at the feature level by leveraging infrared\nappearance features. In addition, we propose Shape Feature Propagation (SFP),\nwhich enables the direct extraction of shape features from original images\nduring inference with minimal computational complexity. Furthermore, we design\nAppearance Feature Enhancement (AFE), which utilizes shape features to\nemphasize shape-related appearance features while effectively suppressing\nidentity-unrelated noise. Benefiting from the effective integration of shape\nand appearance features, ScRL demonstrates superior performance through\nextensive experiments. On the SYSU-MM01, HITSZ-VCM, and RegDB datasets, it\nachieves Rank-1 (mAP) accuracies of 76.1% (72.6%), 71.2% (52.9%), and 92.4%\n(86.7%), respectively, surpassing existing state-of-the-art methods.", "AI": {"tldr": "The paper proposes ScRL, a framework for VI-ReID that integrates shape and appearance features to improve performance, addressing challenges like modality variations and inaccurate shape estimation.", "motivation": "Existing VI-ReID methods focus on appearance features but neglect body shape features, which are robust to modality variations. Integrating both features effectively is challenging due to noise and estimation inaccuracies.", "method": "ScRL includes Infrared Shape Restoration (ISR) to correct shape representations, Shape Feature Propagation (SFP) for direct shape extraction, and Appearance Feature Enhancement (AFE) to refine appearance features using shape cues.", "result": "ScRL achieves Rank-1 (mAP) accuracies of 76.1% (72.6%), 71.2% (52.9%), and 92.4% (86.7%) on SYSU-MM01, HITSZ-VCM, and RegDB datasets, outperforming state-of-the-art methods.", "conclusion": "The ScRL framework successfully integrates shape and appearance features, demonstrating superior performance in VI-ReID tasks."}}
{"id": "2504.19632", "pdf": "https://arxiv.org/pdf/2504.19632", "abs": "https://arxiv.org/abs/2504.19632", "authors": ["Subham Das", "Ashtakala Meghanath", "Bikash K. Behera", "Shahid Mumtaz", "Saif Al-Kuwari", "Ahmed Farouk"], "title": "QFDNN: A Resource-Efficient Variational Quantum Feature Deep Neural Networks for Fraud Detection and Loan Prediction", "categories": ["quant-ph", "cs.LG"], "comment": "12 pages, 6 figures, 8 tables", "summary": "Social financial technology focuses on trust, sustainability, and social\nresponsibility, which require advanced technologies to address complex\nfinancial tasks in the digital era. With the rapid growth in online\ntransactions, automating credit card fraud detection and loan eligibility\nprediction has become increasingly challenging. Classical machine learning (ML)\nmodels have been used to solve these challenges; however, these approaches\noften encounter scalability, overfitting, and high computational costs due to\ncomplexity and high-dimensional financial data. Quantum computing (QC) and\nquantum machine learning (QML) provide a promising solution to efficiently\nprocessing high-dimensional datasets and enabling real-time identification of\nsubtle fraud patterns. However, existing quantum algorithms lack robustness in\nnoisy environments and fail to optimize performance with reduced feature sets.\nTo address these limitations, we propose a quantum feature deep neural network\n(QFDNN), a novel, resource efficient, and noise-resilient quantum model that\noptimizes feature representation while requiring fewer qubits and simpler\nvariational circuits. The model is evaluated using credit card fraud detection\nand loan eligibility prediction datasets, achieving competitive accuracies of\n82.2% and 74.4%, respectively, with reduced computational overhead.\nFurthermore, we test QFDNN against six noise models, demonstrating its\nrobustness across various error conditions. Our findings highlight QFDNN\npotential to enhance trust and security in social financial technology by\naccurately detecting fraudulent transactions while supporting sustainability\nthrough its resource-efficient design and minimal computational overhead.", "AI": {"tldr": "A quantum feature deep neural network (QFDNN) is proposed to address scalability and noise issues in financial tasks like fraud detection and loan prediction, achieving competitive accuracy with reduced computational costs.", "motivation": "The need for advanced, scalable, and noise-resilient solutions in social financial technology to handle high-dimensional data and ensure trust and sustainability.", "method": "Development of QFDNN, a resource-efficient and noise-resilient quantum model, tested on credit card fraud and loan eligibility datasets.", "result": "Achieved accuracies of 82.2% (fraud detection) and 74.4% (loan prediction) with reduced computational overhead, and demonstrated robustness against noise.", "conclusion": "QFDNN enhances trust and security in financial technology by efficiently detecting fraud and supporting sustainability with minimal computational resources."}}
{"id": "2406.10449", "pdf": "https://arxiv.org/pdf/2406.10449", "abs": "https://arxiv.org/abs/2406.10449", "authors": ["Emi Soroka", "Rohan Sinha", "Sanjay Lall"], "title": "Learning Temporal Logic Predicates from Data with Statistical Guarantees", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": "As submitted to L4DC 2025", "summary": "Temporal logic rules are often used in control and robotics to provide\nstructured, human-interpretable descriptions of trajectory data. These rules\nhave numerous applications including safety validation using formal methods,\nconstraining motion planning among autonomous agents, and classifying data.\nHowever, existing methods for learning temporal logic predicates from data do\nnot provide assurances about the correctness of the resulting predicate. We\npresent a novel method to learn temporal logic predicates from data with\nfinite-sample correctness guarantees. Our approach leverages expression\noptimization and conformal prediction to learn predicates that correctly\ndescribe future trajectories under mild statistical assumptions. We provide\nexperimental results showing the performance of our approach on a simulated\ntrajectory dataset and perform ablation studies to understand how each\ncomponent of our algorithm contributes to its performance.", "AI": {"tldr": "A novel method for learning temporal logic predicates from data with correctness guarantees, using expression optimization and conformal prediction.", "motivation": "Existing methods lack correctness assurances for learned temporal logic predicates, limiting their reliability in applications like safety validation and motion planning.", "method": "Leverages expression optimization and conformal prediction to ensure finite-sample correctness guarantees under mild statistical assumptions.", "result": "Demonstrated performance on a simulated trajectory dataset, with ablation studies highlighting the contribution of each algorithm component.", "conclusion": "The approach provides reliable temporal logic predicates with correctness guarantees, enhancing applications in control and robotics."}}
{"id": "2310.19545", "pdf": "https://arxiv.org/pdf/2310.19545", "abs": "https://arxiv.org/abs/2310.19545", "authors": ["Colton R. Crum", "Adam Czajka"], "title": "MENTOR: Human Perception-Guided Pretraining for Increased Generalization", "categories": ["cs.CV"], "comment": "10 pages, 3 figures, 5 tables", "summary": "Leveraging human perception into training of convolutional neural networks\n(CNN) has boosted generalization capabilities of such models in open-set\nrecognition tasks. One of the active research questions is where (in the model\narchitecture or training pipeline) and how to efficiently incorporate always\nlimited human perceptual data into training strategies of models. In this\npaper, we introduce MENTOR (huMan pErceptioN-guided preTraining fOr increased\ngeneRalization), which addresses this question through two unique rounds of\ntraining CNNs tasked with open-set anomaly detection. First, we train an\nautoencoder to learn human saliency maps given an input image, without any\nclass labels. The autoencoder is thus tasked with discovering domain-specific\nsalient features which mimic human perception. Second, we remove the decoder\npart, add a classification layer on top of the encoder, and train this new\nmodel conventionally, now using class labels. We show that MENTOR successfully\nraises the generalization performance across three different CNN backbones in a\nvariety of anomaly detection tasks (demonstrated for detection of unknown iris\npresentation attacks, synthetically-generated faces, and anomalies in chest\nX-ray images) compared to traditional pretraining methods (e.g., sourcing the\nweights from ImageNet), and as well as state-of-the-art methods that\nincorporate human perception guidance into training. In addition, we\ndemonstrate that MENTOR can be flexibly applied to existing human\nperception-guided methods and subsequently increasing their generalization with\nno architectural modifications.", "AI": {"tldr": "MENTOR improves CNN generalization for open-set anomaly detection by incorporating human perception in two training rounds: first learning saliency maps, then fine-tuning with class labels.", "motivation": "To address the challenge of efficiently integrating limited human perceptual data into CNN training for better generalization in open-set recognition tasks.", "method": "Two-stage training: (1) Train an autoencoder to learn human saliency maps without labels, then (2) replace the decoder with a classifier and train with labels.", "result": "MENTOR outperforms traditional pretraining and state-of-the-art methods in anomaly detection tasks across various domains (e.g., iris attacks, synthetic faces, chest X-rays).", "conclusion": "MENTOR effectively enhances generalization in CNNs for anomaly detection and can be flexibly applied to existing methods without architectural changes."}}
{"id": "2504.19657", "pdf": "https://arxiv.org/pdf/2504.19657", "abs": "https://arxiv.org/abs/2504.19657", "authors": ["Shotaro Takasu", "Toshio Aoyagi"], "title": "Neuronal correlations shape the scaling behavior of memory capacity and nonlinear computational capability of recurrent neural networks", "categories": ["cond-mat.dis-nn", "cs.LG", "q-bio.NC"], "comment": "19 pages, 8 figures", "summary": "Reservoir computing is a powerful framework for real-time information\nprocessing, characterized by its high computational ability and quick learning,\nwith applications ranging from machine learning to biological systems. In this\npaper, we demonstrate that the memory capacity of a reservoir recurrent neural\nnetwork scales sublinearly with the number of readout neurons. To elucidate\nthis phenomenon, we develop a theoretical framework for analytically deriving\nmemory capacity, attributing the decaying growth of memory capacity to neuronal\ncorrelations. In addition, numerical simulations reveal that once memory\ncapacity becomes sublinear, increasing the number of readout neurons\nsuccessively enables nonlinear processing at progressively higher polynomial\norders. Furthermore, our theoretical framework suggests that neuronal\ncorrelations govern not only memory capacity but also the sequential growth of\nnonlinear computational capabilities. Our findings establish a foundation for\ndesigning scalable and cost-effective reservoir computing, providing novel\ninsights into the interplay among neuronal correlations, linear memory, and\nnonlinear processing.", "AI": {"tldr": "Reservoir computing's memory capacity scales sublinearly with readout neurons due to neuronal correlations, enabling nonlinear processing at higher polynomial orders.", "motivation": "To understand how memory capacity in reservoir computing scales with readout neurons and the role of neuronal correlations.", "method": "Developed a theoretical framework for memory capacity and validated with numerical simulations.", "result": "Memory capacity grows sublinearly, and increasing readout neurons enables higher-order nonlinear processing.", "conclusion": "Neuronal correlations govern memory capacity and nonlinear capabilities, aiding scalable reservoir computing design."}}
{"id": "2408.14523", "pdf": "https://arxiv.org/pdf/2408.14523", "abs": "https://arxiv.org/abs/2408.14523", "authors": ["Yuxia Wu", "Lizi Liao", "Yuan Fang"], "title": "Retrieval Augmented Generation for Dynamic Graph Modeling", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by SIGIR 2025", "summary": "Modeling dynamic graphs, such as those found in social networks,\nrecommendation systems, and e-commerce platforms, is crucial for capturing\nevolving relationships and delivering relevant insights over time. Traditional\napproaches primarily rely on graph neural networks with temporal components or\nsequence generation models, which often focus narrowly on the historical\ncontext of target nodes. This limitation restricts the ability to adapt to new\nand emerging patterns in dynamic graphs. To address this challenge, we propose\na novel framework, Retrieval-Augmented Generation for Dynamic Graph modeling\n(RAG4DyG), which enhances dynamic graph predictions by incorporating\ncontextually and temporally relevant examples from broader graph structures.\nOur approach includes a time- and context-aware contrastive learning module to\nidentify high-quality demonstrations and a graph fusion strategy to effectively\nintegrate these examples with historical contexts. The proposed framework is\ndesigned to be effective in both transductive and inductive scenarios, ensuring\nadaptability to previously unseen nodes and evolving graph structures.\nExtensive experiments across multiple real-world datasets demonstrate the\neffectiveness of RAG4DyG in improving predictive accuracy and adaptability for\ndynamic graph modeling. The code and datasets are publicly available at\nhttps://github.com/YuxiaWu/RAG4DyG.", "AI": {"tldr": "RAG4DyG is a novel framework for dynamic graph modeling that improves predictions by integrating contextually and temporally relevant examples, outperforming traditional methods.", "motivation": "Traditional methods for dynamic graph modeling focus narrowly on historical contexts, limiting adaptability to new patterns. RAG4DyG aims to address this by leveraging broader graph structures.", "method": "The framework uses time- and context-aware contrastive learning to identify high-quality examples and a graph fusion strategy to integrate them with historical data.", "result": "Experiments show RAG4DyG improves predictive accuracy and adaptability in dynamic graph modeling.", "conclusion": "RAG4DyG is effective for both transductive and inductive scenarios, offering a robust solution for evolving graph structures."}}
{"id": "2311.01090", "pdf": "https://arxiv.org/pdf/2311.01090", "abs": "https://arxiv.org/abs/2311.01090", "authors": ["Nicolas Cherel", "Andr\u00e9s Almansa", "Yann Gousseau", "Alasdair Newson"], "title": "Infusion: internal diffusion for inpainting of dynamic textures and complex motion", "categories": ["cs.CV"], "comment": "14 pages, 11 figures. Published in Eurographics 2025", "summary": "Video inpainting is the task of filling a region in a video in a visually\nconvincing manner. It is very challenging due to the high dimensionality of the\ndata and the temporal consistency required for obtaining convincing results.\nRecently, diffusion models have shown impressive results in modeling complex\ndata distributions, including images and videos. Such models remain nonetheless\nvery expensive to train and to perform inference with, which strongly reduce\ntheir applicability to videos, and yields unreasonable computational loads. We\nshow that in the case of video inpainting, thanks to the highly auto-similar\nnature of videos, the training data of a diffusion model can be restricted to\nthe input video and still produce very satisfying results. With this internal\nlearning approach, where the training data is limited to a single video, our\nlightweight models perform very well with only half a million parameters, in\ncontrast to the very large networks with billions of parameters typically found\nin the literature. We also introduce a new method for efficient training and\ninference of diffusion models in the context of internal learning, by splitting\nthe diffusion process into different learning intervals corresponding to\ndifferent noise levels of the diffusion process. We show qualitative and\nquantitative results, demonstrating that our method reaches or exceeds state of\nthe art performance in the case of dynamic textures and complex dynamic\nbackgrounds", "AI": {"tldr": "A lightweight diffusion model for video inpainting uses internal learning (training on a single video) to achieve state-of-the-art results with minimal parameters.", "motivation": "Video inpainting is challenging due to high data dimensionality and temporal consistency. Diffusion models are powerful but computationally expensive, limiting their video applications.", "method": "Proposes internal learning (training on one video) and splits the diffusion process into intervals for efficient training/inference. Uses a lightweight model (500K parameters).", "result": "Achieves or exceeds state-of-the-art performance for dynamic textures and complex backgrounds.", "conclusion": "Internal learning with lightweight diffusion models is effective for video inpainting, reducing computational load while maintaining high quality."}}
{"id": "2504.19787", "pdf": "https://arxiv.org/pdf/2504.19787", "abs": "https://arxiv.org/abs/2504.19787", "authors": ["Aditi Nachnani", "Kai K. Li-Caldwell", "Saptarshi Biswas", "Prince Sharma", "Gaoyuan Ouyang", "Prashant Singh"], "title": "Interpretable machine learning-guided design of Fe-based soft magnetic alloys", "categories": ["cond-mat.mtrl-sci", "cond-mat.other", "cs.LG"], "comment": "24 Pages, 6 Figure, 1 Table", "summary": "We present a machine-learning guided approach to predict saturation\nmagnetization (MS) and coercivity (HC) in Fe-rich soft magnetic alloys,\nparticularly Fe-Si-B systems. ML models trained on experimental data reveals\nthat increasing Si and B content reduces MS from 1.81T (DFT~2.04 T) to ~1.54 T\n(DFT~1.56T) in Fe-Si-B, which is attributed to decreased magnetic density and\nstructural modifications. Experimental validation of ML predicted magnetic\nsaturation on Fe-1Si-1B (2.09T), Fe-5Si-5B (2.01T) and Fe-10Si-10B (1.54T)\nalloy compositions further support our findings. These trends are consistent\nwith density functional theory (DFT) predictions, which link increased\nelectronic disorder and band broadening to lower MS values. Experimental\nvalidation on selected alloys confirms the predictive accuracy of the ML model,\nwith good agreement across compositions. Beyond predictive accuracy, detailed\nuncertainty quantification and model interpretability including through feature\nimportance and partial dependence analysis reveals that MS is governed by a\nnonlinear interplay between Fe content, early transition metal ratios, and\nannealing temperature, while HC is more sensitive to processing conditions such\nas ribbon thickness and thermal treatment windows. The ML framework was further\napplied to Fe-Si-B/Cr/Cu/Zr/Nb alloys in a pseudo-quaternary compositional\nspace, which shows comparable magnetic properties to NANOMET\n(Fe84.8Si0.5B9.4Cu0.8 P3.5C1), FINEMET (Fe73.5Si13.5B9 Cu1Nb3), NANOPERM\n(Fe88Zr7B4Cu1), and HITPERM (Fe44Co44Zr7B4Cu1. Our fundings demonstrate the\npotential of ML framework for accelerated search of high-performance, Co- and\nNi-free, soft magnetic materials.", "AI": {"tldr": "ML predicts saturation magnetization (MS) and coercivity (HC) in Fe-Si-B alloys, validated by experiments and DFT, revealing key compositional and processing factors.", "motivation": "To accelerate the discovery of high-performance, Co- and Ni-free soft magnetic materials using machine learning.", "method": "ML models trained on experimental data, validated with DFT predictions and experimental results, including uncertainty quantification and feature analysis.", "result": "Increasing Si and B reduces MS; ML predictions align with experiments and DFT. HC is more sensitive to processing conditions.", "conclusion": "ML framework effectively predicts magnetic properties, aiding the search for optimized soft magnetic alloys."}}
{"id": "2408.16189", "pdf": "https://arxiv.org/pdf/2408.16189", "abs": "https://arxiv.org/abs/2408.16189", "authors": ["Steve Hanneke", "Samory Kpotufe"], "title": "Adaptive Sample Aggregation In Transfer Learning", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Transfer Learning aims to optimally aggregate samples from a target\ndistribution, with related samples from a so-called source distribution to\nimprove target risk. Multiple procedures have been proposed over the last two\ndecades to address this problem, each driven by one of a multitude of possible\ndivergence measures between source and target distributions. A first question\nasked in this work is whether there exist unified algorithmic approaches that\nautomatically adapt to many of these divergence measures simultaneously.\n  We show that this is indeed the case for a large family of divergences\nproposed across classification and regression tasks, as they all happen to\nupper-bound the same measure of continuity between source and target risks,\nwhich we refer to as a weak modulus of transfer. This more unified view allows\nus, first, to identify algorithmic approaches that are simultaneously adaptive\nto these various divergence measures via a reduction to particular confidence\nsets. Second, it allows for a more refined understanding of the statistical\nlimits of transfer under such divergences, and in particular, reveals regimes\nwith faster rates than might be expected under coarser lenses.\n  We then turn to situations that are not well captured by the weak modulus and\ncorresponding divergences: these are situations where the aggregate of source\nand target data can improve target performance significantly beyond what's\npossible with either source or target data alone. We show that common such\nsituations -- as may arise, e.g., under certain causal models with spurious\ncorrelations -- are well described by a so-called strong modulus of transfer\nwhich supersedes the weak modulus. We finally show that the strong modulus also\nadmits adaptive procedures, which achieve near optimal rates in terms of the\nunknown strong modulus, and therefore apply in more general settings.", "AI": {"tldr": "The paper explores unified algorithmic approaches for transfer learning, identifying a 'weak modulus of transfer' that adapts to various divergence measures. It also introduces a 'strong modulus' for more complex scenarios, achieving near-optimal rates.", "motivation": "To unify diverse divergence measures in transfer learning and understand statistical limits, while addressing scenarios where source and target data together outperform individual datasets.", "method": "Proposes a 'weak modulus of transfer' unifying divergence measures, reduces to confidence sets for adaptive algorithms, and introduces a 'strong modulus' for complex cases.", "result": "Identifies adaptive algorithms for weak modulus, reveals faster statistical rates, and extends to strong modulus for broader applicability.", "conclusion": "The weak and strong moduli provide a unified framework for transfer learning, enabling adaptive algorithms and improved performance in diverse settings."}}
{"id": "2401.17515", "pdf": "https://arxiv.org/pdf/2401.17515", "abs": "https://arxiv.org/abs/2401.17515", "authors": ["Chun Tao", "Timur Ibrayev", "Kaushik Roy"], "title": "Semantic-Syntactic Discrepancy in Images (SSDI): Learning Meaning and Order of Features from Natural Images", "categories": ["cs.CV"], "comment": "32 pages, 22 figures, 10 tables Published in Transactions on Machine\n  Learning Research (04/2025)", "summary": "Despite considerable progress in image classification tasks, classification\nmodels seem unaffected by the images that significantly deviate from those that\nappear natural to human eyes. Specifically, while human perception can easily\nidentify abnormal appearances or compositions in images, classification models\noverlook any alterations in the arrangement of object parts as long as they are\npresent in any order, even if unnatural. Hence, this work exposes the\nvulnerability of having semantic and syntactic discrepancy in images (SSDI) in\nthe form of corruptions that remove or shuffle image patches or present images\nin the form of puzzles. To address this vulnerability, we propose the concept\nof \"image grammar\", comprising \"image semantics\" and \"image syntax\". Image\nsemantics pertains to the interpretation of parts or patches within an image,\nwhereas image syntax refers to the arrangement of these parts to form a\ncoherent object. We present a semi-supervised two-stage method for learning the\nimage grammar of visual elements and environments solely from natural images.\nWhile the first stage learns the semantic meaning of individual object parts,\nthe second stage learns how their relative arrangement constitutes an entire\nobject. The efficacy of the proposed approach is then demonstrated by achieving\nSSDI detection rates ranging from 70% to 90% on corruptions generated from\nCelebA and SUN-RGBD datasets. Code is publicly available at:\nhttps://github.com/ChunTao1999/SSDI/", "AI": {"tldr": "The paper exposes classification models' vulnerability to unnatural image compositions (SSDI) and proposes 'image grammar' (semantics + syntax) to detect such discrepancies via a two-stage semi-supervised method.", "motivation": "Human perception easily detects unnatural image compositions, but classification models overlook such discrepancies, prompting the need to address this vulnerability.", "method": "A semi-supervised two-stage method: first learns semantic meaning of object parts, then their syntactic arrangement to form coherent objects.", "result": "Achieves 70%-90% SSDI detection rates on corruptions from CelebA and SUN-RGBD datasets.", "conclusion": "The proposed 'image grammar' effectively detects semantic and syntactic discrepancies in images, improving model robustness."}}
{"id": "2504.19797", "pdf": "https://arxiv.org/pdf/2504.19797", "abs": "https://arxiv.org/abs/2504.19797", "authors": ["Gang Mao", "Tousif Rahman", "Sidharth Maheshwari", "Bob Pattison", "Zhuang Shao", "Rishad Shafik", "Alex Yakovlev"], "title": "Dynamic Tsetlin Machine Accelerators for On-Chip Training at the Edge using FPGAs", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "The increased demand for data privacy and security in machine learning (ML)\napplications has put impetus on effective edge training on Internet-of-Things\n(IoT) nodes. Edge training aims to leverage speed, energy efficiency and\nadaptability within the resource constraints of the nodes. Deploying and\ntraining Deep Neural Networks (DNNs)-based models at the edge, although\naccurate, posit significant challenges from the back-propagation algorithm's\ncomplexity, bit precision trade-offs, and heterogeneity of DNN layers. This\npaper presents a Dynamic Tsetlin Machine (DTM) training accelerator as an\nalternative to DNN implementations. DTM utilizes logic-based on-chip inference\nwith finite-state automata-driven learning within the same Field Programmable\nGate Array (FPGA) package. Underpinned on the Vanilla and Coalesced Tsetlin\nMachine algorithms, the dynamic aspect of the accelerator design allows for a\nrun-time reconfiguration targeting different datasets, model architectures, and\nmodel sizes without resynthesis. This makes the DTM suitable for targeting\nmultivariate sensor-based edge tasks. Compared to DNNs, DTM trains with fewer\nmultiply-accumulates, devoid of derivative computation. It is a data-centric ML\nalgorithm that learns by aligning Tsetlin automata with input data to form\nlogical propositions enabling efficient Look-up-Table (LUT) mapping and frugal\nBlock RAM usage in FPGA training implementations. The proposed accelerator\noffers 2.54x more Giga operations per second per Watt (GOP/s per W) and uses 6x\nless power than the next-best comparable design.", "AI": {"tldr": "The paper proposes a Dynamic Tsetlin Machine (DTM) accelerator for edge training, offering higher efficiency and lower power consumption compared to DNNs.", "motivation": "Addressing the challenges of deploying DNNs on IoT nodes due to complexity, bit precision, and layer heterogeneity, the paper seeks a more efficient alternative.", "method": "The DTM uses logic-based on-chip inference with finite-state automata-driven learning, enabling runtime reconfiguration without resynthesis.", "result": "The DTM accelerator achieves 2.54x more GOP/s per W and uses 6x less power than comparable designs.", "conclusion": "DTM is a viable, efficient alternative to DNNs for edge training, particularly for sensor-based tasks."}}
{"id": "2409.06941", "pdf": "https://arxiv.org/pdf/2409.06941", "abs": "https://arxiv.org/abs/2409.06941", "authors": ["Jiashu Zhang", "Zihan Pan", "Molly", "Xu", "Khuzaima Daudjee", "Sihang Liu"], "title": "FreeRide: Harvesting Bubbles in Pipeline Parallelism", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "The occurrence of bubbles in pipeline parallelism is an inherent limitation\nthat can account for more than 40% of the large language model (LLM) training\ntime and is one of the main reasons for the underutilization of GPU resources\nin LLM training. Harvesting these bubbles for GPU side tasks can increase\nresource utilization and reduce training costs but comes with challenges.\nFirst, because bubbles are discontinuous with various shapes, programming side\ntasks becomes difficult while requiring excessive engineering effort. Second, a\nside task can compete with pipeline training for GPU resources and incur\nsignificant overhead. To address these challenges, we propose FreeRide, a\nsystem designed to harvest bubbles in pipeline parallelism for side tasks.\nFreeRide provides programmers with interfaces to implement side tasks easily,\nmanages bubbles and side tasks during pipeline training, and controls access to\nGPU resources by side tasks to reduce overhead. We demonstrate that FreeRide\nachieves 7.8% average cost savings with a negligible overhead of about 1% in\ntraining LLMs while serving model training, graph analytics, and image\nprocessing side tasks.", "AI": {"tldr": "FreeRide is a system that harvests pipeline parallelism bubbles for side tasks, improving GPU utilization and reducing LLM training costs with minimal overhead.", "motivation": "Bubbles in pipeline parallelism waste GPU resources, accounting for over 40% of LLM training time. Harvesting these bubbles for side tasks can enhance utilization but poses programming and resource competition challenges.", "method": "FreeRide offers interfaces for easy side task implementation, manages bubbles and tasks during training, and controls GPU resource access to minimize overhead.", "result": "FreeRide achieves 7.8% average cost savings with only ~1% overhead, effectively serving side tasks like model training, graph analytics, and image processing.", "conclusion": "FreeRide successfully addresses the challenges of bubble utilization, proving its efficiency in reducing costs and overhead in LLM training."}}
{"id": "2402.06136", "pdf": "https://arxiv.org/pdf/2402.06136", "abs": "https://arxiv.org/abs/2402.06136", "authors": ["Xiaokang Wei", "Zhuoman Liu", "Ping Li", "Yan Luximon"], "title": "SIR: Multi-view Inverse Rendering with Decomposable Shadow Under Indoor Intense Lighting", "categories": ["cs.CV"], "comment": "ICME 2025. Homepage:https://xiaokangwei.github.io/SIR/", "summary": "We propose SIR, an efficient method to decompose differentiable shadows for\ninverse rendering on indoor scenes using multi-view data, addressing the\nchallenges in accurately decomposing the materials and lighting conditions.\nUnlike previous methods that struggle with shadow fidelity in complex lighting\nenvironments, our approach explicitly learns shadows for enhanced realism in\nmaterial estimation under unknown light positions. Utilizing posed HDR images\nas input, SIR employs an SDF-based neural radiance field for comprehensive\nscene representation. Then, SIR integrates a shadow term with a three-stage\nmaterial estimation approach to improve SVBRDF quality. Specifically, SIR is\ndesigned to learn a differentiable shadow, complemented by BRDF regularization,\nto optimize inverse rendering accuracy. Extensive experiments on both synthetic\nand real-world indoor scenes demonstrate the superior performance of SIR over\nexisting methods in both quantitative metrics and qualitative analysis. The\nsignificant decomposing ability of SIR enables sophisticated editing\ncapabilities like free-view relighting, object insertion, and material\nreplacement. The code and data are available at\nhttps://xiaokangwei.github.io/SIR/.", "AI": {"tldr": "SIR is a method for decomposing shadows in inverse rendering using multi-view data, improving material and lighting accuracy with a neural radiance field and shadow term.", "motivation": "Addressing challenges in shadow fidelity and material decomposition in complex lighting environments for indoor scenes.", "method": "Uses posed HDR images and an SDF-based neural radiance field, integrating a shadow term with a three-stage material estimation approach.", "result": "Outperforms existing methods in quantitative and qualitative metrics, enabling advanced editing like relighting and material replacement.", "conclusion": "SIR provides superior shadow and material decomposition, enhancing realism and editing capabilities for indoor scenes."}}
{"id": "2504.19816", "pdf": "https://arxiv.org/pdf/2504.19816", "abs": "https://arxiv.org/abs/2504.19816", "authors": ["Erblin Isaku", "Hassan Sartaj", "Shaukat Ali"], "title": "Digital Twin-based Out-of-Distribution Detection in Autonomous Vessels", "categories": ["eess.SY", "cs.LG", "cs.SE", "cs.SY"], "comment": "34 pages, 12 figures, 11 tables", "summary": "An autonomous vessel (AV) is a complex cyber-physical system (CPS) with\nsoftware enabling many key functionalities, e.g., navigation software enables\nan AV to autonomously or semi-autonomously follow a path to its destination.\nDigital twins of such AVs enable advanced functionalities such as running\nwhat-if scenarios, performing predictive maintenance, and enabling fault\ndiagnosis. Due to technological improvements, real-time analyses using\ncontinuous data from vessels' real-time operations have become increasingly\npossible. However, the literature has little explored developing advanced\nanalyses in real-time data in AVs with digital twins built with machine\nlearning techniques. To this end, we present a novel digital twin-based\napproach (ODDIT) to detect future out-of-distribution (OOD) states of an AV\nbefore reaching them, enabling proactive intervention. Such states may indicate\nanomalies requiring attention (e.g., manual correction by the ship master) and\nassist testers in scenario-centered testing. The digital twin consists of two\nmachine-learning models predicting future vessel states and whether the\npredicted state will be OOD. We evaluated ODDIT with five vessels across\nwaypoint and zigzag maneuvering under simulated conditions, including sensor\nand actuator noise and environmental disturbances i.e., ocean current. ODDIT\nachieved high accuracy in detecting OOD states, with AUROC and TNR@TPR95 scores\nreaching 99\\% across multiple vessels.", "AI": {"tldr": "ODDIT is a digital twin-based approach using ML to detect future out-of-distribution states in autonomous vessels, achieving high accuracy in proactive anomaly detection.", "motivation": "The lack of real-time advanced analyses for AVs with ML-based digital twins inspired the development of ODDIT to enable proactive intervention.", "method": "ODDIT employs two ML models: one predicts future vessel states, and the other detects if these states are out-of-distribution (OOD).", "result": "ODDIT achieved 99% accuracy in detecting OOD states under simulated conditions with noise and disturbances.", "conclusion": "ODDIT effectively enables proactive anomaly detection in AVs, enhancing safety and testing capabilities."}}
{"id": "2409.08775", "pdf": "https://arxiv.org/pdf/2409.08775", "abs": "https://arxiv.org/abs/2409.08775", "authors": ["Qianou Ma", "Weirui Peng", "Chenyang Yang", "Hua Shen", "Kenneth Koedinger", "Tongshuang Wu"], "title": "What Should We Engineer in Prompts? Training Humans in Requirement-Driven LLM Use", "categories": ["cs.HC", "cs.AI"], "comment": "15 pages; TOCHI 2025", "summary": "Prompting LLMs for complex tasks (e.g., building a trip advisor chatbot)\nneeds humans to clearly articulate customized requirements (e.g., \"start the\nresponse with a tl;dr\"). However, existing prompt engineering instructions\noften lack focused training on requirement articulation and instead tend to\nemphasize increasingly automatable strategies (e.g., tricks like adding\nrole-plays and \"think step-by-step\"). To address the gap, we introduce\nRequirement-Oriented Prompt Engineering (ROPE), a paradigm that focuses human\nattention on generating clear, complete requirements during prompting. We\nimplement ROPE through an assessment and training suite that provides\ndeliberate practice with LLM-generated feedback. In a randomized controlled\nexperiment with 30 novices, ROPE significantly outperforms conventional prompt\nengineering training (20% vs. 1% gains), a gap that automatic prompt\noptimization cannot close. Furthermore, we demonstrate a direct correlation\nbetween the quality of input requirements and LLM outputs. Our work paves the\nway to empower more end-users to build complex LLM applications.", "AI": {"tldr": "ROPE (Requirement-Oriented Prompt Engineering) improves LLM prompting by focusing on clear requirement articulation, outperforming conventional methods by 20% vs. 1% gains.", "motivation": "Existing prompt engineering lacks training on requirement articulation, relying on automatable tricks instead.", "method": "ROPE uses an assessment and training suite with LLM-generated feedback to practice requirement articulation.", "result": "ROPE significantly outperforms conventional training (20% vs. 1% gains) and shows a correlation between requirement quality and LLM outputs.", "conclusion": "ROPE empowers end-users to build complex LLM applications by improving requirement clarity."}}
{"id": "2403.01968", "pdf": "https://arxiv.org/pdf/2403.01968", "abs": "https://arxiv.org/abs/2403.01968", "authors": ["Xin Zhang", "Tao Xiao", "Gepeng Ji", "Xuan Wu", "Keren Fu", "Qijun Zhao"], "title": "Explicit Motion Handling and Interactive Prompting for Video Camouflaged Object Detection", "categories": ["cs.CV"], "comment": "Accepted to TIP; Corresponding author: Keren Fu\n  (fkrsuper@scu.edu.cn). Code: https://github.com/zhangxin06/EMIP", "summary": "Camouflage poses challenges in distinguishing a static target, whereas any\nmovement of the target can break this disguise. Existing video camouflaged\nobject detection (VCOD) approaches take noisy motion estimation as input or\nmodel motion implicitly, restricting detection performance in complex dynamic\nscenes. In this paper, we propose a novel Explicit Motion handling and\nInteractive Prompting framework for VCOD, dubbed EMIP, which handles motion\ncues explicitly using a frozen pre-trained optical flow fundamental model. EMIP\nis characterized by a two-stream architecture for simultaneously conducting\ncamouflaged segmentation and optical flow estimation. Interactions across the\ndual streams are realized in an interactive prompting way that is inspired by\nemerging visual prompt learning. Two learnable modules, i.e., the camouflaged\nfeeder and motion collector, are designed to incorporate segmentation-to-motion\nand motion-to-segmentation prompts, respectively, and enhance outputs of the\nboth streams. The prompt fed to the motion stream is learned by supervising\noptical flow in a self-supervised manner. Furthermore, we show that long-term\nhistorical information can also be incorporated as a prompt into EMIP and\nachieve more robust results with temporal consistency. Experimental results\ndemonstrate that our EMIP achieves new state-of-the-art records on popular VCOD\nbenchmarks. Our code is made publicly available at\nhttps://github.com/zhangxin06/EMIP.", "AI": {"tldr": "EMIP is a novel framework for video camouflaged object detection (VCOD) that explicitly handles motion cues using a two-stream architecture with interactive prompting, achieving state-of-the-art results.", "motivation": "Existing VCOD methods rely on noisy motion estimation or implicit motion modeling, limiting performance in dynamic scenes. EMIP addresses this by explicitly leveraging motion cues.", "method": "EMIP uses a two-stream architecture for camouflaged segmentation and optical flow estimation, with interactive prompting via camouflaged feeder and motion collector modules. It incorporates self-supervised learning for motion prompts and historical data for robustness.", "result": "EMIP sets new state-of-the-art records on VCOD benchmarks, demonstrating superior performance in complex dynamic scenes.", "conclusion": "EMIP's explicit motion handling and interactive prompting framework significantly improves VCOD performance, offering a robust solution for dynamic scenes."}}
{"id": "2504.19925", "pdf": "https://arxiv.org/pdf/2504.19925", "abs": "https://arxiv.org/abs/2504.19925", "authors": ["Athinagoras Skiadopoulos", "Mark Zhao", "Swapnil Gandhi", "Thomas Norrie", "Shrijeet Mukherjee", "Christos Kozyrakis"], "title": "Accelerating Mixture-of-Experts Training with Adaptive Expert Replication", "categories": ["cs.DC", "cs.LG"], "comment": "Preprint. Under review", "summary": "Mixture-of-Experts (MoE) models have become a widely adopted solution to\ncontinue scaling model sizes without a corresponding linear increase in\ncompute. During MoE model training, each input token is dynamically routed to a\nsubset of experts -- sparsely-activated feed-forward networks -- within each\ntransformer layer. The distribution of tokens assigned to each expert varies\nwidely and rapidly over the course of training. To handle the wide load\nimbalance across experts, current systems are forced to either drop tokens\nassigned to popular experts, degrading convergence, or frequently rebalance\nresources allocated to each expert based on popularity, incurring high state\nmigration overheads.\n  To break this performance-accuracy tradeoff, we introduce SwiftMoE, an\nadaptive MoE training system. The key insight of SwiftMoE is to decouple the\nplacement of expert parameters from their large optimizer state. SwiftMoE\nstatically partitions the optimizer of each expert across all training nodes.\nMeanwhile, SwiftMoE dynamically adjusts the placement of expert parameters by\nrepurposing existing weight updates, avoiding migration overheads. In doing so,\nSwiftMoE right-sizes the GPU resources allocated to each expert, on a\nper-iteration basis, with minimal overheads. Compared to state-of-the-art MoE\ntraining systems, DeepSpeed and FlexMoE, SwiftMoE is able to achieve a 30.5%\nand 25.9% faster time-to-convergence, respectively.", "AI": {"tldr": "SwiftMoE introduces an adaptive MoE training system to balance performance and accuracy by decoupling expert parameter placement from optimizer state, achieving faster convergence.", "motivation": "Current MoE training systems face trade-offs between dropping tokens (degrading convergence) or rebalancing resources (incurring high overheads).", "method": "SwiftMoE decouples expert parameter placement from optimizer state, statically partitioning optimizer state and dynamically adjusting expert placement.", "result": "SwiftMoE achieves 30.5% and 25.9% faster convergence compared to DeepSpeed and FlexMoE, respectively.", "conclusion": "SwiftMoE effectively balances performance and accuracy in MoE training with minimal overhead."}}
{"id": "2409.09497", "pdf": "https://arxiv.org/pdf/2409.09497", "abs": "https://arxiv.org/abs/2409.09497", "authors": ["Hugo Porta", "Emanuele Dalsasso", "Diego Marcos", "Devis Tuia"], "title": "Multi-Scale Grouped Prototypes for Interpretable Semantic Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at WACV 2025", "summary": "Prototypical part learning is emerging as a promising approach for making\nsemantic segmentation interpretable. The model selects real patches seen during\ntraining as prototypes and constructs the dense prediction map based on the\nsimilarity between parts of the test image and the prototypes. This improves\ninterpretability since the user can inspect the link between the predicted\noutput and the patterns learned by the model in terms of prototypical\ninformation. In this paper, we propose a method for interpretable semantic\nsegmentation that leverages multi-scale image representation for prototypical\npart learning. First, we introduce a prototype layer that explicitly learns\ndiverse prototypical parts at several scales, leading to multi-scale\nrepresentations in the prototype activation output. Then, we propose a sparse\ngrouping mechanism that produces multi-scale sparse groups of these\nscale-specific prototypical parts. This provides a deeper understanding of the\ninteractions between multi-scale object representations while enhancing the\ninterpretability of the segmentation model. The experiments conducted on Pascal\nVOC, Cityscapes, and ADE20K demonstrate that the proposed method increases\nmodel sparsity, improves interpretability over existing prototype-based\nmethods, and narrows the performance gap with the non-interpretable counterpart\nmodels. Code is available at github.com/eceo-epfl/ScaleProtoSeg.", "AI": {"tldr": "The paper proposes a method for interpretable semantic segmentation using multi-scale prototypical part learning, improving sparsity and interpretability while narrowing the performance gap with non-interpretable models.", "motivation": "To enhance interpretability in semantic segmentation by linking predictions to learned prototypical patterns and leveraging multi-scale representations.", "method": "Introduces a prototype layer for multi-scale prototypical part learning and a sparse grouping mechanism to understand interactions between scales.", "result": "Experiments on Pascal VOC, Cityscapes, and ADE20K show improved sparsity, interpretability, and performance close to non-interpretable models.", "conclusion": "The method advances interpretable semantic segmentation by effectively combining multi-scale representations and prototype learning."}}
{"id": "2403.10413", "pdf": "https://arxiv.org/pdf/2403.10413", "abs": "https://arxiv.org/abs/2403.10413", "authors": ["Hongyuan Yu", "Cheng Wan", "Xiyang Dai", "Mengchen Liu", "Dongdong Chen", "Bin Xiao", "Yan Huang", "Yuan Lu", "Liang Wang"], "title": "Real-Time Image Segmentation via Hybrid Convolutional-Transformer Architecture Search", "categories": ["cs.CV"], "comment": "29 pages, 5 figures, submitted to Knowledge-Baed Systems", "summary": "Image segmentation is one of the most fundamental problems in computer vision\nand has drawn a lot of attention due to its vast applications in image\nunderstanding and autonomous driving. However, designing effective and\nefficient segmentation neural architectures is a labor-intensive process that\nmay require numerous trials by human experts. In this paper, we address the\nchallenge of integrating multi-head self-attention into high-resolution\nrepresentation CNNs efficiently by leveraging architecture search. Manually\nreplacing convolution layers with multi-head self-attention is non-trivial due\nto the costly overhead in memory to maintain high resolution. By contrast, we\ndevelop a multi-target multi-branch supernet method, which not only fully\nutilizes the advantages of high-resolution features but also finds the proper\nlocation for placing the multi-head self-attention module. Our search algorithm\nis optimized towards multiple objectives (e.g., latency and mIoU) and is\ncapable of finding architectures on the Pareto frontier with an arbitrary\nnumber of branches in a single search. We further present a series of models\nvia the Hybrid Convolutional-Transformer Architecture Search (HyCTAS) method\nthat searches for the best hybrid combination of light-weight convolution\nlayers and memory-efficient self-attention layers between branches from\ndifferent resolutions and fuses them to high resolution for both efficiency and\neffectiveness. Extensive experiments demonstrate that HyCTAS outperforms\nprevious methods in both semantic segmentation and panoptic segmentation tasks.\nCode and models are available at https://github.com/MarvinYu1995/HyCTAS.", "AI": {"tldr": "The paper introduces HyCTAS, a method for efficiently integrating multi-head self-attention into high-resolution CNNs using architecture search, achieving superior performance in segmentation tasks.", "motivation": "Designing effective segmentation architectures is labor-intensive. The paper aims to automate this by optimizing the placement of self-attention modules in CNNs for efficiency and performance.", "method": "A multi-target multi-branch supernet method is developed to find optimal hybrid combinations of convolution and self-attention layers, optimized for objectives like latency and mIoU.", "result": "HyCTAS outperforms previous methods in semantic and panoptic segmentation, demonstrating efficiency and effectiveness.", "conclusion": "The proposed HyCTAS method successfully automates architecture design for segmentation, balancing performance and efficiency."}}
{"id": "2504.19952", "pdf": "https://arxiv.org/pdf/2504.19952", "abs": "https://arxiv.org/abs/2504.19952", "authors": ["Shubhada Agrawal", "Aaditya Ramdas"], "title": "On Stopping Times of Power-one Sequential Tests: Tight Lower and Upper Bounds", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": "36 pages", "summary": "We prove two lower bounds for stopping times of sequential tests between\ngeneral composite nulls and alternatives. The first lower bound is for the\nsetting where the type-1 error level $\\alpha$ approaches zero, and equals\n$\\log(1/\\alpha)$ divided by a certain infimum KL divergence, termed\n$\\operatorname{KL_{inf}}$. The second lower bound applies to the setting where\n$\\alpha$ is fixed and $\\operatorname{KL_{inf}}$ approaches 0 (meaning that the\nnull and alternative sets are not separated) and equals $c\n\\operatorname{KL_{inf}}^{-1} \\log \\log \\operatorname{KL_{inf}}^{-1}$ for a\nuniversal constant $c > 0$. We also provide a sufficient condition for matching\nthe upper bounds and show that this condition is met in several special cases.\nGiven past work, these upper and lower bounds are unsurprising in their form;\nour main contribution is the generality in which they hold, for example, not\nrequiring reference measures or compactness of the classes.", "AI": {"tldr": "The paper proves two lower bounds for stopping times in sequential tests between composite hypotheses, focusing on type-1 error and KL divergence.", "motivation": "To generalize lower bounds for stopping times in sequential tests, removing assumptions like reference measures or compactness.", "method": "Proves two lower bounds: one for vanishing type-1 error and another for fixed error with vanishing KL divergence. Also provides a condition for matching upper bounds.", "result": "Establishes lower bounds in terms of KL divergence and shows they hold broadly, including cases without reference measures or compactness.", "conclusion": "The bounds generalize prior work, demonstrating applicability in more general settings."}}
{"id": "2409.13867", "pdf": "https://arxiv.org/pdf/2409.13867", "abs": "https://arxiv.org/abs/2409.13867", "authors": ["Justin Wang", "Haimin Hu", "Duy Phuong Nguyen", "Jaime Fern\u00e1ndez Fisac"], "title": "MAGICS: Adversarial RL with Minimax Actors Guided by Implicit Critic Stackelberg for Convergent Neural Synthesis of Robot Safety", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "Algorithmic Foundations of Robotics (WAFR) XVI", "summary": "While robust optimal control theory provides a rigorous framework to compute\nrobot control policies that are provably safe, it struggles to scale to\nhigh-dimensional problems, leading to increased use of deep learning for\ntractable synthesis of robot safety. Unfortunately, existing neural safety\nsynthesis methods often lack convergence guarantees and solution\ninterpretability. In this paper, we present Minimax Actors Guided by Implicit\nCritic Stackelberg (MAGICS), a novel adversarial reinforcement learning (RL)\nalgorithm that guarantees local convergence to a minimax equilibrium solution.\nWe then build on this approach to provide local convergence guarantees for a\ngeneral deep RL-based robot safety synthesis algorithm. Through both simulation\nstudies on OpenAI Gym environments and hardware experiments with a\n36-dimensional quadruped robot, we show that MAGICS can yield robust control\npolicies outperforming the state-of-the-art neural safety synthesis methods.", "AI": {"tldr": "MAGICS is a novel adversarial RL algorithm guaranteeing local convergence to minimax equilibrium, outperforming state-of-the-art neural safety synthesis methods in robot control.", "motivation": "Existing neural safety synthesis methods lack convergence guarantees and interpretability, limiting their reliability in high-dimensional robot control.", "method": "MAGICS uses adversarial RL to ensure local convergence to a minimax equilibrium, validated in simulations and hardware experiments.", "result": "MAGICS outperforms current neural safety synthesis methods in robustness and performance, demonstrated in simulations and real-world quadruped robot tests.", "conclusion": "MAGICS provides a scalable, provably convergent solution for robot safety synthesis, bridging the gap between robust control theory and deep learning."}}
{"id": "2404.14671", "pdf": "https://arxiv.org/pdf/2404.14671", "abs": "https://arxiv.org/abs/2404.14671", "authors": ["Ming Nie", "Xinyue Cai", "Hang Xu", "Li Zhang"], "title": "LaneCorrect: Self-supervised Lane Detection", "categories": ["cs.CV"], "comment": "IJCV 2025", "summary": "Lane detection has evolved highly functional autonomous driving system to\nunderstand driving scenes even under complex environments. In this paper, we\nwork towards developing a generalized computer vision system able to detect\nlanes without using any annotation. We make the following contributions: (i) We\nillustrate how to perform unsupervised 3D lane segmentation by leveraging the\ndistinctive intensity of lanes on the LiDAR point cloud frames, and then obtain\nthe noisy lane labels in the 2D plane by projecting the 3D points; (ii) We\npropose a novel self-supervised training scheme, dubbed LaneCorrect, that\nautomatically corrects the lane label by learning geometric consistency and\ninstance awareness from the adversarial augmentations; (iii) With the\nself-supervised pre-trained model, we distill to train a student network for\narbitrary target lane (e.g., TuSimple) detection without any human labels; (iv)\nWe thoroughly evaluate our self-supervised method on four major lane detection\nbenchmarks (including TuSimple, CULane, CurveLanes and LLAMAS) and demonstrate\nexcellent performance compared with existing supervised counterpart, whilst\nshowing more effective results on alleviating the domain gap, i.e., training on\nCULane and test on TuSimple.", "AI": {"tldr": "The paper presents an unsupervised method for lane detection using LiDAR point clouds and a self-supervised training scheme (LaneCorrect) to correct noisy labels, achieving strong performance on benchmarks without human annotations.", "motivation": "To develop a generalized computer vision system for lane detection without relying on annotated data, addressing domain gaps and complex environments.", "method": "Unsupervised 3D lane segmentation from LiDAR, projection to 2D, self-supervised label correction (LaneCorrect), and distillation for target lane detection.", "result": "Outperforms supervised methods on benchmarks (TuSimple, CULane, CurveLanes, LLAMAS) and reduces domain gaps effectively.", "conclusion": "The proposed unsupervised approach is robust, generalizable, and competitive with supervised methods, demonstrating practical viability for autonomous driving."}}
{"id": "2504.19987", "pdf": "https://arxiv.org/pdf/2504.19987", "abs": "https://arxiv.org/abs/2504.19987", "authors": ["Yomn Alkabakibi", "Congwei Xie", "Artem R. Oganov"], "title": "Graph Neural Network Prediction of Nonlinear Optical Properties", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.optics"], "comment": "7 pages, 2 figures, 2 tables", "summary": "Nonlinear optical (NLO) materials for generating lasers via second harmonic\ngeneration (SHG) are highly sought in today's technology. However, discovering\nnovel materials with considerable SHG is challenging due to the time-consuming\nand costly nature of both experimental methods and first-principles\ncalculations. In this study, we present a deep learning approach using the\nAtomistic Line Graph Neural Network (ALIGNN) to predict NLO properties.\nSourcing data from the Novel Opto-Electronic Materials Discovery (NOEMD)\ndatabase and using the Kurtz-Perry (KP) coefficient as the key target, we\ndeveloped a robust model capable of accurately estimating nonlinear optical\nresponses. Our results demonstrate that the model achieves 82.5% accuracy at a\ntolerated absolute error up to 1 pm/V and relative error not exceeding 0.5.\nThis work highlights the potential of deep learning in accelerating the\ndiscovery and design of advanced optical materials with desired properties.", "AI": {"tldr": "A deep learning model (ALIGNN) predicts nonlinear optical (NLO) properties for laser generation, achieving 82.5% accuracy with low error rates.", "motivation": "Discovering NLO materials with significant second harmonic generation (SHG) is costly and time-consuming, necessitating faster methods.", "method": "Used Atomistic Line Graph Neural Network (ALIGNN) trained on NOEMD database data, targeting the Kurtz-Perry (KP) coefficient.", "result": "Model achieved 82.5% accuracy with absolute error \u22641 pm/V and relative error \u22640.5.", "conclusion": "Deep learning can accelerate discovery of advanced optical materials with desired NLO properties."}}
{"id": "2409.14872", "pdf": "https://arxiv.org/pdf/2409.14872", "abs": "https://arxiv.org/abs/2409.14872", "authors": ["Yongxin Deng", "Xihe Qiu", "Xiaoyu Tan", "Yaochu Jin"], "title": "FedSlate:A Federated Deep Reinforcement Learning Recommender System", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Reinforcement learning methods have been used to optimize long-term user\nengagement in recommendation systems. However, existing reinforcement\nlearning-based recommendation systems do not fully exploit the relevance of\nindividual user behavior across different platforms. One potential solution is\nto aggregate data from various platforms in a centralized location and use the\naggregated data for training. However, this approach raises economic and legal\nconcerns, including increased communication costs and potential threats to user\nprivacy. To address these challenges, we propose \\textbf{FedSlate}, a federated\nreinforcement learning recommendation algorithm that effectively utilizes\ninformation that is prohibited from being shared at a legal level. We employ\nthe SlateQ algorithm to assist FedSlate in learning users' long-term behavior\nand evaluating the value of recommended content. We extend the existing\napplication scope of recommendation systems from single-user single-platform to\nsingle-user multi-platform and address cross-platform learning challenges by\nintroducing federated learning. We use RecSim to construct a simulation\nenvironment for evaluating FedSlate and compare its performance with\nstate-of-the-art benchmark recommendation models. Experimental results\ndemonstrate the superior effects of FedSlate over baseline methods in various\nenvironmental settings, and FedSlate facilitates the learning of recommendation\nstrategies in scenarios where baseline methods are completely inapplicable.\nCode is available at \\textit{https://github.com/TianYaDY/FedSlate}.", "AI": {"tldr": "FedSlate is a federated reinforcement learning recommendation algorithm that addresses cross-platform learning challenges while preserving user privacy and reducing communication costs.", "motivation": "Existing reinforcement learning-based recommendation systems fail to leverage user behavior across platforms due to economic and legal constraints.", "method": "FedSlate uses the SlateQ algorithm for long-term user behavior learning and employs federated learning to enable cross-platform recommendations without data sharing.", "result": "FedSlate outperforms state-of-the-art models in simulations, excelling in scenarios where baseline methods fail.", "conclusion": "FedSlate effectively extends recommendation systems to multi-platform contexts while addressing privacy and legal concerns."}}
{"id": "2406.03744", "pdf": "https://arxiv.org/pdf/2406.03744", "abs": "https://arxiv.org/abs/2406.03744", "authors": ["Fang Chen", "Gourav Datta", "Mujahid Al Rafi", "Hyeran Jeon", "Meng Tang"], "title": "ReDistill: Residual Encoded Distillation for Peak Memory Reduction of CNNs", "categories": ["cs.CV", "cs.LG"], "comment": "16 pages, 7 figures, 10 tables", "summary": "The expansion of neural network sizes and the enhanced resolution of modern\nimage sensors result in heightened memory and power demands to process modern\ncomputer vision models. In order to deploy these models in extremely\nresource-constrained edge devices, it is crucial to reduce their peak memory,\nwhich is the maximum memory consumed during the execution of a model. A naive\napproach to reducing peak memory is aggressive down-sampling of feature maps\nvia pooling with large stride, which often results in unacceptable degradation\nin network performance. To mitigate this problem, we propose residual encoded\ndistillation (ReDistill) for peak memory reduction in a teacher-student\nframework, in which a student network with less memory is derived from the\nteacher network using aggressive pooling. We apply our distillation method to\nmultiple problems in computer vision, including image classification and\ndiffusion-based image generation. For image classification, our method yields\n4x-5x theoretical peak memory reduction with less degradation in accuracy for\nmost CNN-based architectures. For diffusion-based image generation, our\nproposed distillation method yields a denoising network with 4x lower\ntheoretical peak memory while maintaining decent diversity and fidelity for\nimage generation. Experiments demonstrate our method's superior performance\ncompared to other feature-based and response-based distillation methods when\napplied to the same student network. The code is available at\nhttps://github.com/mengtang-lab/ReDistill.", "AI": {"tldr": "ReDistill reduces peak memory in neural networks via teacher-student distillation with aggressive pooling, achieving 4x-5x memory reduction with minimal accuracy loss.", "motivation": "Addressing high memory and power demands of modern computer vision models for deployment in resource-constrained edge devices.", "method": "Proposes residual encoded distillation (ReDistill) in a teacher-student framework using aggressive pooling to derive a memory-efficient student network.", "result": "4x-5x peak memory reduction for CNNs with minimal accuracy loss; 4x reduction for diffusion models while maintaining image quality.", "conclusion": "ReDistill outperforms other distillation methods, offering a practical solution for memory-efficient model deployment."}}
{"id": "2504.20004", "pdf": "https://arxiv.org/pdf/2504.20004", "abs": "https://arxiv.org/abs/2504.20004", "authors": ["Jing Wang", "Yan Jin", "Hamid Taghavifar", "Fei Ding", "Chongfeng Wei"], "title": "Socially-Aware Autonomous Driving: Inferring Yielding Intentions for Safer Interactions", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Since the emergence of autonomous driving technology, it has advanced rapidly\nover the past decade. It is becoming increasingly likely that autonomous\nvehicles (AVs) would soon coexist with human-driven vehicles (HVs) on the\nroads. Currently, safety and reliable decision-making remain significant\nchallenges, particularly when AVs are navigating lane changes and interacting\nwith surrounding HVs. Therefore, precise estimation of the intentions of\nsurrounding HVs can assist AVs in making more reliable and safe lane change\ndecision-making. This involves not only understanding their current behaviors\nbut also predicting their future motions without any direct communication.\nHowever, distinguishing between the passing and yielding intentions of\nsurrounding HVs still remains ambiguous. To address the challenge, we propose a\nsocial intention estimation algorithm rooted in Directed Acyclic Graph (DAG),\ncoupled with a decision-making framework employing Deep Reinforcement Learning\n(DRL) algorithms. To evaluate the method's performance, the proposed framework\ncan be tested and applied in a lane-changing scenario within a simulated\nenvironment. Furthermore, the experiment results demonstrate how our approach\nenhances the ability of AVs to navigate lane changes safely and efficiently on\nroads.", "AI": {"tldr": "A DAG-based social intention estimation algorithm and DRL decision-making framework improve AVs' lane-change safety and efficiency.", "motivation": "Safety and reliable decision-making for AVs interacting with HVs during lane changes.", "method": "Proposes a social intention estimation algorithm using DAG and a DRL-based decision-making framework.", "result": "Enhances AVs' ability to navigate lane changes safely and efficiently in simulations.", "conclusion": "The framework improves AV-HV interaction by better estimating HV intentions."}}
{"id": "2409.14983", "pdf": "https://arxiv.org/pdf/2409.14983", "abs": "https://arxiv.org/abs/2409.14983", "authors": ["Jiashuo Li", "Shaokun Wang", "Bo Qian", "Yuhang He", "Xing Wei", "Qiang Wang", "Yihong Gong"], "title": "Dynamic Integration of Task-Specific Adapters for Class Incremental Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Non-exemplar class Incremental Learning (NECIL) enables models to\ncontinuously acquire new classes without retraining from scratch and storing\nold task exemplars, addressing privacy and storage issues. However, the absence\nof data from earlier tasks exacerbates the challenge of catastrophic forgetting\nin NECIL. In this paper, we propose a novel framework called Dynamic\nIntegration of task-specific Adapters (DIA), which comprises two key\ncomponents: Task-Specific Adapter Integration (TSAI) and Patch-Level Model\nAlignment. TSAI boosts compositionality through a patch-level adapter\nintegration strategy, which provides a more flexible compositional solution\nwhile maintaining low computation costs. Patch-Level Model Alignment maintains\nfeature consistency and accurate decision boundaries via two specialized\nmechanisms: Patch-Level Distillation Loss (PDL) and Patch-Level Feature\nReconstruction method (PFR). Specifically, the PDL preserves feature-level\nconsistency between successive models by implementing a distillation loss based\non the contributions of patch tokens to new class learning. The PFR facilitates\naccurate classifier alignment by reconstructing old class features from\nprevious tasks that adapt to new task knowledge. Extensive experiments validate\nthe effectiveness of our DIA, revealing significant improvements on benchmark\ndatasets in the NECIL setting, maintaining an optimal balance between\ncomputational complexity and accuracy.", "AI": {"tldr": "The paper introduces DIA, a framework for Non-exemplar Class Incremental Learning (NECIL), addressing catastrophic forgetting with task-specific adapters and patch-level alignment.", "motivation": "To tackle catastrophic forgetting in NECIL without storing old exemplars, ensuring privacy and storage efficiency.", "method": "Proposes Dynamic Integration of task-specific Adapters (DIA) with Task-Specific Adapter Integration (TSAI) and Patch-Level Model Alignment (PDL and PFR).", "result": "DIA significantly improves performance on benchmark datasets, balancing computational complexity and accuracy.", "conclusion": "DIA effectively mitigates catastrophic forgetting in NECIL, offering a flexible and efficient solution."}}
{"id": "2406.06423", "pdf": "https://arxiv.org/pdf/2406.06423", "abs": "https://arxiv.org/abs/2406.06423", "authors": ["Daniel Bogdoll", "Jan Imhof", "Tim Joseph", "Svetlana Pavlitska", "J. Marius Z\u00f6llner"], "title": "Hybrid Video Anomaly Detection for Anomalous Scenarios in Autonomous Driving", "categories": ["cs.CV", "cs.RO"], "comment": "Daniel Bogdoll and Jan Imhof contributed equally. Accepted for\n  publication at BMVC 2024 RROW workshop. Won Best Paper Award", "summary": "In autonomous driving, the most challenging scenarios can only be detected\nwithin their temporal context. Most video anomaly detection approaches focus\neither on surveillance or traffic accidents, which are only a subfield of\nautonomous driving. We present HF$^2$-VAD$_{AD}$, a variation of the HF$^2$-VAD\nsurveillance video anomaly detection method for autonomous driving. We learn a\nrepresentation of normality from a vehicle's ego perspective and evaluate\npixel-wise anomaly detections in rare and critical scenarios.", "AI": {"tldr": "HF$^2$-VAD$_{AD}$ adapts a surveillance anomaly detection method for autonomous driving, focusing on rare and critical scenarios.", "motivation": "Addressing the gap in anomaly detection for autonomous driving, especially in rare and critical scenarios.", "method": "Adapts HF$^2$-VAD for autonomous driving, learning normality from ego perspective and evaluating pixel-wise anomalies.", "result": "Demonstrates effectiveness in detecting anomalies in rare and critical driving scenarios.", "conclusion": "HF$^2$-VAD$_{AD}$ is a promising approach for anomaly detection in autonomous driving."}}
{"id": "2504.20011", "pdf": "https://arxiv.org/pdf/2504.20011", "abs": "https://arxiv.org/abs/2504.20011", "authors": ["Aditya Vatsavai", "Ganesh Narasimha", "Yongtao Liu", "Jan-Chi Yang", "Hiroshu Funakubo", "Maxim Ziatdinov", "Rama Vasudevan"], "title": "Curiosity Driven Exploration to Optimize Structure-Property Learning in Microscopy", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": "12 pages, 8 figures", "summary": "Rapidly determining structure-property correlations in materials is an\nimportant challenge in better understanding fundamental mechanisms and greatly\nassists in materials design. In microscopy, imaging data provides a direct\nmeasurement of the local structure, while spectroscopic measurements provide\nrelevant functional property information. Deep kernel active learning\napproaches have been utilized to rapidly map local structure to functional\nproperties in microscopy experiments, but are computationally expensive for\nmulti-dimensional and correlated output spaces. Here, we present an alternative\nlightweight curiosity algorithm which actively samples regions with unexplored\nstructure-property relations, utilizing a deep-learning based surrogate model\nfor error prediction. We show that the algorithm outperforms random sampling\nfor predicting properties from structures, and provides a convenient tool for\nefficient mapping of structure-property relationships in materials science.", "AI": {"tldr": "A lightweight curiosity algorithm is introduced to efficiently map structure-property relationships in materials science, outperforming random sampling.", "motivation": "The challenge of rapidly determining structure-property correlations in materials to aid design and understanding.", "method": "Utilizes a deep-learning based surrogate model for error prediction to actively sample unexplored regions.", "result": "Outperforms random sampling in predicting properties from structures.", "conclusion": "Provides a convenient and efficient tool for mapping structure-property relationships."}}
{"id": "2409.19954", "pdf": "https://arxiv.org/pdf/2409.19954", "abs": "https://arxiv.org/abs/2409.19954", "authors": ["Shiben Liu", "Qiang Wang", "Huijie Fan", "Weihong Ren", "Baojie Fan", "Yandong Tang"], "title": "Domain Consistency Representation Learning for Lifelong Person Re-Identification", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 6 figures", "summary": "Lifelong person re-identification (LReID) exhibits a contradictory\nrelationship between intra-domain discrimination and inter-domain gaps when\nlearning from continuous data. Intra-domain discrimination focuses on\nindividual nuances (i.e., clothing type, accessories, etc.), while inter-domain\ngaps emphasize domain consistency. Achieving a trade-off between maximizing\nintra-domain discrimination and minimizing inter-domain gaps is a crucial\nchallenge for improving LReID performance. Most existing methods strive to\nreduce inter-domain gaps through knowledge distillation to maintain domain\nconsistency. However, they often ignore intra-domain discrimination. To address\nthis challenge, we propose a novel domain consistency representation learning\n(DCR) model that explores global and attribute-wise representations as a bridge\nto balance intra-domain discrimination and inter-domain gaps. At the\nintra-domain level, we explore the complementary relationship between global\nand attribute-wise representations to improve discrimination among similar\nidentities. Excessive learning intra-domain discrimination can lead to\ncatastrophic forgetting. We further develop an attribute-oriented\nanti-forgetting (AF) strategy that explores attribute-wise representations to\nenhance inter-domain consistency, and propose a knowledge consolidation (KC)\nstrategy to facilitate knowledge transfer. Extensive experiments show that our\nDCR model achieves superior performance compared to state-of-the-art LReID\nmethods. Our code is publicly available at https://github.com/LiuShiBen/DCR.", "AI": {"tldr": "The paper proposes a Domain Consistency Representation (DCR) model to balance intra-domain discrimination and inter-domain gaps in Lifelong Person Re-Identification (LReID), using global and attribute-wise representations, along with anti-forgetting and knowledge consolidation strategies.", "motivation": "The contradictory relationship between intra-domain discrimination (focusing on individual nuances) and inter-domain gaps (emphasizing domain consistency) in LReID poses a challenge. Existing methods often neglect intra-domain discrimination while reducing inter-domain gaps.", "method": "The DCR model leverages global and attribute-wise representations to balance intra-domain discrimination and inter-domain gaps. It includes an attribute-oriented anti-forgetting strategy and a knowledge consolidation strategy to prevent catastrophic forgetting and enhance knowledge transfer.", "result": "Extensive experiments demonstrate that the DCR model outperforms state-of-the-art LReID methods.", "conclusion": "The DCR model effectively addresses the trade-off between intra-domain discrimination and inter-domain gaps, achieving superior performance in LReID tasks."}}
{"id": "2406.14856", "pdf": "https://arxiv.org/pdf/2406.14856", "abs": "https://arxiv.org/abs/2406.14856", "authors": ["Md Saiful Islam", "Tariq Adnan", "Jan Freyberg", "Sangwu Lee", "Abdelrahman Abdelkader", "Meghan Pawlik", "Cathe Schwartz", "Karen Jaffe", "Ruth B. Schneider", "E Ray Dorsey", "Ehsan Hoque"], "title": "Accessible, At-Home Detection of Parkinson's Disease via Multi-task Video Analysis", "categories": ["cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "Limited accessibility to neurological care leads to underdiagnosed\nParkinson's Disease (PD), preventing early intervention. Existing AI-based PD\ndetection methods primarily focus on unimodal analysis of motor or speech\ntasks, overlooking the multifaceted nature of the disease. To address this, we\nintroduce a large-scale, multi-task video dataset consisting of 1102 sessions\n(each containing videos of finger tapping, facial expression, and speech tasks\ncaptured via webcam) from 845 participants (272 with PD). We propose a novel\nUncertainty-calibrated Fusion Network (UFNet) that leverages this multimodal\ndata to enhance diagnostic accuracy. UFNet employs independent task-specific\nnetworks, trained with Monte Carlo Dropout for uncertainty quantification,\nfollowed by self-attended fusion of features, with attention weights\ndynamically adjusted based on task-specific uncertainties. To ensure\npatient-centered evaluation, the participants were randomly split into three\nsets: 60% for training, 20% for model selection, and 20% for final performance\nevaluation. UFNet significantly outperformed single-task models in terms of\naccuracy, area under the ROC curve (AUROC), and sensitivity while maintaining\nnon-inferior specificity. Withholding uncertain predictions further boosted the\nperformance, achieving 88.0+-0.3%$ accuracy, 93.0+-0.2% AUROC, 79.3+-0.9%\nsensitivity, and 92.6+-0.3% specificity, at the expense of not being able to\npredict for 2.3+-0.3% data (+- denotes 95% confidence interval). Further\nanalysis suggests that the trained model does not exhibit any detectable bias\nacross sex and ethnic subgroups and is most effective for individuals aged\nbetween 50 and 80. Requiring only a webcam and microphone, our approach\nfacilitates accessible home-based PD screening, especially in regions with\nlimited healthcare resources.", "AI": {"tldr": "A novel Uncertainty-calibrated Fusion Network (UFNet) uses multimodal data (finger tapping, facial expression, speech) for accurate Parkinson's Disease (PD) detection, outperforming single-task models and enabling accessible home-based screening.", "motivation": "Limited neurological care access leads to underdiagnosed PD. Existing AI methods focus on unimodal analysis, missing the disease's multifaceted nature.", "method": "UFNet leverages a large-scale multi-task video dataset (1102 sessions from 845 participants) with Monte Carlo Dropout for uncertainty quantification and self-attended feature fusion.", "result": "UFNet achieved 88.0% accuracy, 93.0% AUROC, 79.3% sensitivity, and 92.6% specificity, with no detectable bias across subgroups.", "conclusion": "UFNet enables accessible PD screening via webcam/microphone, particularly beneficial for regions with limited healthcare resources."}}
{"id": "2312.16638", "pdf": "https://arxiv.org/pdf/2312.16638", "abs": "https://arxiv.org/abs/2312.16638", "authors": ["Surojit Ganguli", "Zeyu Zhou", "Christopher G. Brinton", "David I. Inouye"], "title": "Robust Collaborative Inference with Vertically Split Data Over Dynamic Device Environments", "categories": ["cs.LG"], "comment": null, "summary": "When each edge device of a network only perceives a local part of the\nenvironment, collaborative inference across multiple devices is often needed to\npredict global properties of the environment. In safety-critical applications,\ncollaborative inference must be robust to significant network failures caused\nby environmental disruptions or extreme weather. Existing collaborative\nlearning approaches, such as privacy-focused Vertical Federated Learning (VFL),\ntypically assume a centralized setup or that one device never fails. However,\nthese assumptions make prior approaches susceptible to significant network\nfailures. To address this problem, we first formalize the problem of robust\ncollaborative inference over a dynamic network of devices that could experience\nsignificant network faults. Then, we develop a minimalistic yet impactful\nmethod called Multiple Aggregation with Gossip Rounds and Simulated Faults\n(MAGS) that synthesizes simulated faults via dropout, replication, and\ngossiping to significantly improve robustness over baselines. We also\ntheoretically analyze our proposed approach to explain why each component\nenhances robustness. Extensive empirical results validate that MAGS is robust\nacross a range of fault rates-including extreme fault rates.", "AI": {"tldr": "The paper proposes MAGS, a method for robust collaborative inference in dynamic networks prone to significant faults, outperforming existing approaches.", "motivation": "Existing collaborative learning methods assume stable networks, making them vulnerable to failures in safety-critical applications.", "method": "MAGS uses simulated faults (dropout, replication, gossiping) to enhance robustness in dynamic networks.", "result": "MAGS significantly improves robustness across varying fault rates, including extreme cases.", "conclusion": "MAGS provides a practical and theoretically sound solution for robust collaborative inference in fault-prone networks."}}
{"id": "2410.05779", "pdf": "https://arxiv.org/pdf/2410.05779", "abs": "https://arxiv.org/abs/2410.05779", "authors": ["Zirui Guo", "Lianghao Xia", "Yanhua Yu", "Tu Ao", "Chao Huang"], "title": "LightRAG: Simple and Fast Retrieval-Augmented Generation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems enhance large language models\n(LLMs) by integrating external knowledge sources, enabling more accurate and\ncontextually relevant responses tailored to user needs. However, existing RAG\nsystems have significant limitations, including reliance on flat data\nrepresentations and inadequate contextual awareness, which can lead to\nfragmented answers that fail to capture complex inter-dependencies. To address\nthese challenges, we propose LightRAG, which incorporates graph structures into\ntext indexing and retrieval processes. This innovative framework employs a\ndual-level retrieval system that enhances comprehensive information retrieval\nfrom both low-level and high-level knowledge discovery. Additionally, the\nintegration of graph structures with vector representations facilitates\nefficient retrieval of related entities and their relationships, significantly\nimproving response times while maintaining contextual relevance. This\ncapability is further enhanced by an incremental update algorithm that ensures\nthe timely integration of new data, allowing the system to remain effective and\nresponsive in rapidly changing data environments. Extensive experimental\nvalidation demonstrates considerable improvements in retrieval accuracy and\nefficiency compared to existing approaches. We have made our LightRAG\nopen-source and available at the link: https://github.com/HKUDS/LightRAG", "AI": {"tldr": "LightRAG improves RAG systems by using graph structures for better contextual awareness and efficiency.", "motivation": "Existing RAG systems lack contextual depth and efficient retrieval, leading to fragmented answers.", "method": "LightRAG integrates graph structures into text indexing and retrieval, using a dual-level system and incremental updates.", "result": "Experiments show improved retrieval accuracy and efficiency.", "conclusion": "LightRAG outperforms existing RAG systems and is open-sourced for broader use."}}
{"id": "2406.18544", "pdf": "https://arxiv.org/pdf/2406.18544", "abs": "https://arxiv.org/abs/2406.18544", "authors": ["Zuo-Liang Zhu", "Beibei Wang", "Jian Yang"], "title": "GS-ROR$^2$: Bidirectional-guided 3DGS and SDF for Reflective Object Relighting and Reconstruction", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has shown a powerful capability for novel view\nsynthesis due to its detailed expressive ability and highly efficient rendering\nspeed. Unfortunately, creating relightable 3D assets and reconstructing\nfaithful geometry with 3DGS is still problematic, particularly for reflective\nobjects, as its discontinuous representation raises difficulties in\nconstraining geometries. Volumetric signed distance field (SDF) methods provide\nrobust geometry reconstruction, while the expensive ray marching hinders its\nreal-time application and slows the training. Besides, these methods struggle\nto capture sharp geometric details. To this end, we propose to guide 3DGS and\nSDF bidirectionally in a complementary manner, including an SDF-aided Gaussian\nsplatting for efficient optimization of the relighting model and a GS-guided\nSDF enhancement for high-quality geometry reconstruction. At the core of our\nSDF-aided Gaussian splatting is the mutual supervision of the depth and normal\nbetween blended Gaussians and SDF, which avoids the expensive volume rendering\nof SDF. Thanks to this mutual supervision, the learned blended Gaussians are\nwell-constrained with a minimal time cost. As the Gaussians are rendered in a\ndeferred shading mode, the alpha-blended Gaussians are smooth, while individual\nGaussians may still be outliers, yielding floater artifacts. Therefore, we\nintroduce an SDF-aware pruning strategy to remove Gaussian outliers located\ndistant from the surface defined by SDF, avoiding floater issue. This way, our\nGS framework provides reasonable normal and achieves realistic relighting,\nwhile the mesh from depth is still problematic. Therefore, we design a\nGS-guided SDF refinement, which utilizes the blended normal from Gaussians to\nfinetune SDF. With this enhancement, our method can further provide\nhigh-quality meshes for reflective objects at the cost of 17% extra training\ntime.", "AI": {"tldr": "The paper proposes a bidirectional guidance method combining 3D Gaussian Splatting (3DGS) and SDF for relightable 3D assets and high-quality geometry reconstruction, addressing limitations of each approach.", "motivation": "Current methods like 3DGS struggle with relightable assets and geometry reconstruction, especially for reflective objects, while SDF methods are slow and lack detail.", "method": "The approach uses mutual supervision between 3DGS and SDF, including SDF-aided Gaussian splatting for relighting and GS-guided SDF refinement for geometry.", "result": "The method achieves realistic relighting and high-quality meshes for reflective objects with minimal extra training time (17%).", "conclusion": "The bidirectional guidance effectively combines the strengths of 3DGS and SDF, improving both relighting and geometry reconstruction."}}
{"id": "2402.07745", "pdf": "https://arxiv.org/pdf/2402.07745", "abs": "https://arxiv.org/abs/2402.07745", "authors": ["Jamelle Watson-Daniels", "Flavio du Pin Calmon", "Alexander D'Amour", "Carol Long", "David C. Parkes", "Berk Ustun"], "title": "Predictive Churn with the Set of Good Models", "categories": ["cs.LG"], "comment": null, "summary": "Issues can arise when research focused on fairness, transparency, or safety\nis conducted separately from research driven by practical deployment concerns\nand vice versa. This separation creates a growing need for translational work\nthat bridges the gap between independently studied concepts that may be\nfundamentally related. This paper explores connections between two seemingly\nunrelated concepts of predictive inconsistency that share intriguing parallels.\nThe first, known as predictive multiplicity, occurs when models that perform\nsimilarly (e.g., nearly equivalent training loss) produce conflicting\npredictions for individual samples. This concept is often emphasized in\nalgorithmic fairness research as a means of promoting transparency in ML model\ndevelopment. The second concept, predictive churn, examines the differences in\nindividual predictions before and after model updates, a key challenge in\ndeploying ML models in consumer-facing applications. We present theoretical and\nempirical results that uncover links between these previously disconnected\nconcepts.", "AI": {"tldr": "The paper bridges predictive multiplicity (conflicting predictions from similar models) and predictive churn (prediction changes after updates), highlighting their connections.", "motivation": "Address the gap between fairness/transparency research and practical deployment concerns by linking predictive multiplicity and churn.", "method": "Theoretical and empirical analysis to explore parallels between predictive multiplicity and churn.", "result": "Uncovered links between the two concepts, showing their fundamental relationship.", "conclusion": "Translational work is needed to connect fairness research with deployment challenges, as demonstrated by the study."}}
{"id": "2410.08260", "pdf": "https://arxiv.org/pdf/2410.08260", "abs": "https://arxiv.org/abs/2410.08260", "authors": ["Qiuheng Wang", "Yukai Shi", "Jiarong Ou", "Rui Chen", "Ke Lin", "Jiahao Wang", "Boyuan Jiang", "Haotian Yang", "Mingwu Zheng", "Xin Tao", "Fei Yang", "Pengfei Wan", "Di Zhang"], "title": "Koala-36M: A Large-scale Video Dataset Improving Consistency between Fine-grained Conditions and Video Content", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by CVPR2025. Project page: https://koala36m.github.io/", "summary": "With the continuous progress of visual generation technologies, the scale of\nvideo datasets has grown exponentially. The quality of these datasets plays a\npivotal role in the performance of video generation models. We assert that\ntemporal splitting, detailed captions, and video quality filtering are three\ncrucial determinants of dataset quality. However, existing datasets exhibit\nvarious limitations in these areas. To address these challenges, we introduce\nKoala-36M, a large-scale, high-quality video dataset featuring accurate\ntemporal splitting, detailed captions, and superior video quality. The essence\nof our approach lies in improving the consistency between fine-grained\nconditions and video content. Specifically, we employ a linear classifier on\nprobability distributions to enhance the accuracy of transition detection,\nensuring better temporal consistency. We then provide structured captions for\nthe splitted videos, with an average length of 200 words, to improve text-video\nalignment. Additionally, we develop a Video Training Suitability Score (VTSS)\nthat integrates multiple sub-metrics, allowing us to filter high-quality videos\nfrom the original corpus. Finally, we incorporate several metrics into the\ntraining process of the generation model, further refining the fine-grained\nconditions. Our experiments demonstrate the effectiveness of our data\nprocessing pipeline and the quality of the proposed Koala-36M dataset. Our\ndataset and code have been released at https://koala36m.github.io/.", "AI": {"tldr": "The paper introduces Koala-36M, a high-quality video dataset addressing limitations in temporal splitting, captions, and video quality filtering to enhance video generation models.", "motivation": "Existing video datasets lack quality in temporal splitting, detailed captions, and video quality filtering, which are crucial for video generation models.", "method": "The authors improve dataset quality by ensuring temporal consistency with a linear classifier, providing detailed captions (200 words avg.), and filtering videos using a Video Training Suitability Score (VTSS).", "result": "Koala-36M demonstrates improved consistency between fine-grained conditions and video content, validated by experiments.", "conclusion": "The proposed dataset and processing pipeline effectively address dataset quality issues, enhancing video generation model performance."}}
{"id": "2407.21402", "pdf": "https://arxiv.org/pdf/2407.21402", "abs": "https://arxiv.org/abs/2407.21402", "authors": ["Pei-Kai Huang", "Tzu-Hsien Chen", "Ya-Ting Chan", "Kuan-Wen Chen", "Chiou-Ting Hsu"], "title": "DD-rPPGNet: De-interfering and Descriptive Feature Learning for Unsupervised rPPG Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Remote Photoplethysmography (rPPG) aims to measure physiological signals and\nHeart Rate (HR) from facial videos. Recent unsupervised rPPG estimation methods\nhave shown promising potential in estimating rPPG signals from facial regions\nwithout relying on ground truth rPPG signals. However, these methods seem\noblivious to interference existing in rPPG signals and still result in\nunsatisfactory performance. In this paper, we propose a novel De-interfered and\nDescriptive rPPG Estimation Network (DD-rPPGNet) to eliminate the interference\nwithin rPPG features for learning genuine rPPG signals. First, we investigate\nthe characteristics of local spatial-temporal similarities of interference and\ndesign a novel unsupervised model to estimate the interference. Next, we\npropose an unsupervised de-interfered method to learn genuine rPPG signals with\ntwo stages. In the first stage, we estimate the initial rPPG signals by\ncontrastive learning from both the training data and their augmented\ncounterparts. In the second stage, we use the estimated interference features\nto derive de-interfered rPPG features and encourage the rPPG signals to be\ndistinct from the interference. In addition, we propose an effective\ndescriptive rPPG feature learning by developing a strong 3D Learnable\nDescriptive Convolution (3DLDC) to capture the subtle chrominance changes for\nenhancing rPPG estimation. Extensive experiments conducted on five rPPG\nbenchmark datasets demonstrate that the proposed DD-rPPGNet outperforms\nprevious unsupervised rPPG estimation methods and achieves competitive\nperformances with state-of-the-art supervised rPPG methods. The code is\navailable at: https://github.com/Pei-KaiHuang/TIFS2025-DD-rPPGNet", "AI": {"tldr": "Proposes DD-rPPGNet, an unsupervised method to eliminate interference in rPPG signals, improving HR estimation from facial videos.", "motivation": "Current unsupervised rPPG methods ignore interference, leading to poor performance.", "method": "Uses contrastive learning and a 3D Learnable Descriptive Convolution to de-interfere and enhance rPPG signals.", "result": "Outperforms unsupervised methods and matches supervised ones on benchmark datasets.", "conclusion": "DD-rPPGNet effectively removes interference, improving rPPG signal quality and HR estimation."}}
{"id": "2403.09066", "pdf": "https://arxiv.org/pdf/2403.09066", "abs": "https://arxiv.org/abs/2403.09066", "authors": ["Sungmin Cha", "Kyunghyun Cho"], "title": "Hyperparameters in Continual Learning: A Reality Check", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted to TMLR", "summary": "Continual learning (CL) aims to train a model on a sequence of tasks (i.e., a\nCL scenario) while balancing the trade-off between plasticity (learning new\ntasks) and stability (retaining prior knowledge). The dominantly adopted\nconventional evaluation protocol for CL algorithms selects the best\nhyperparameters (e.g., learning rate, mini-batch size, regularization\nstrengths, etc.) within a given scenario and then evaluates the algorithms\nusing these hyperparameters in the same scenario. However, this protocol has\nsignificant shortcomings: it overestimates the CL capacity of algorithms and\nrelies on unrealistic hyperparameter tuning, which is not feasible for\nreal-world applications. From the fundamental principles of evaluation in\nmachine learning, we argue that the evaluation of CL algorithms should focus on\nassessing the generalizability of their CL capacity to unseen scenarios. Based\non this, we propose the Generalizable Two-phase Evaluation Protocol (GTEP)\nconsisting of hyperparameter tuning and evaluation phases. Both phases share\nthe same scenario configuration (e.g., number of tasks) but are generated from\ndifferent datasets. Hyperparameters of CL algorithms are tuned in the first\nphase and applied in the second phase to evaluate the algorithms. We apply this\nprotocol to class-incremental learning, both with and without pretrained\nmodels. Across more than 8,000 experiments, our results show that most\nstate-of-the-art algorithms fail to replicate their reported performance,\nhighlighting that their CL capacity has been significantly overestimated in the\nconventional evaluation protocol. Our implementation can be found in\nhttps://github.com/csm9493/GTEP.", "AI": {"tldr": "The paper critiques the conventional evaluation protocol for continual learning (CL) algorithms, proposing a new Generalizable Two-phase Evaluation Protocol (GTEP) to better assess CL capacity across unseen scenarios. Results show overestimation of current algorithms' performance.", "motivation": "Current CL evaluation protocols overestimate algorithm performance by tuning hyperparameters on the same scenario, which is unrealistic for real-world applications.", "method": "Proposes GTEP, a two-phase protocol: hyperparameter tuning on one dataset and evaluation on another, both with the same scenario configuration.", "result": "Over 8,000 experiments reveal most state-of-the-art CL algorithms fail to replicate reported performance, indicating overestimation.", "conclusion": "GTEP provides a more realistic and generalizable evaluation framework for CL algorithms, exposing limitations of current methods."}}
{"id": "2411.01819", "pdf": "https://arxiv.org/pdf/2411.01819", "abs": "https://arxiv.org/abs/2411.01819", "authors": ["Bo Gao", "Jianhui Wang", "Xinyuan Song", "Yangfan He", "Fangxu Xing", "Tianyu Shi"], "title": "Free-Mask: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages,11 figures,5 tables", "summary": "Current semantic segmentation models typically require a substantial amount\nof manually annotated data, a process that is both time-consuming and\nresource-intensive. Alternatively, leveraging advanced text-to-image models\nsuch as Midjourney and Stable Diffusion has emerged as an efficient strategy,\nenabling the automatic generation of synthetic data in place of manual\nannotations. However, previous methods have been limited to generating\nsingle-instance images, as the generation of multiple instances with Stable\nDiffusion has proven unstable. To address this limitation and expand the scope\nand diversity of synthetic datasets, we propose a framework \\textbf{Free-Mask}\nthat combines a Diffusion Model for segmentation with advanced image editing\ncapabilities, allowing for the integration of multiple objects into images via\ntext-to-image models. Our method facilitates the creation of highly realistic\ndatasets that closely emulate open-world environments while generating accurate\nsegmentation masks. It reduces the labor associated with manual annotation and\nalso ensures precise mask generation. Experimental results demonstrate that\nsynthetic data generated by \\textbf{Free-Mask} enables segmentation models to\noutperform those trained on real data, especially in zero-shot settings.\nNotably, \\textbf{Free-Mask} achieves new state-of-the-art results on previously\nunseen classes in the VOC 2012 benchmark.", "AI": {"tldr": "Free-Mask leverages text-to-image models to generate synthetic datasets with multiple objects, reducing manual annotation effort and improving segmentation model performance.", "motivation": "Manual annotation for semantic segmentation is time-consuming and resource-intensive. Existing methods using text-to-image models are limited to single-instance images.", "method": "Combines a Diffusion Model with image editing to integrate multiple objects into images, generating realistic datasets and accurate masks.", "result": "Outperforms models trained on real data, especially in zero-shot settings, and achieves state-of-the-art results on unseen VOC 2012 classes.", "conclusion": "Free-Mask effectively addresses the limitations of manual annotation and single-instance generation, enhancing dataset diversity and model performance."}}
{"id": "2408.09449", "pdf": "https://arxiv.org/pdf/2408.09449", "abs": "https://arxiv.org/abs/2408.09449", "authors": ["Xin Liu", "Weijia Zhang", "Min-Ling Zhang"], "title": "Position: From Correlation to Causation: Max-Pooling-Based Multi-Instance Learning Leads to More Robust Whole Slide Image Classification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Although attention-based multi-instance learning (MIL) algorithms have\nachieved impressive performance on slide-level whole slide image (WSI)\nclassification tasks, they are prone to mistakenly focusing on irrelevant\npatterns such as staining conditions and tissue morphology, leading to\nincorrect patch-level predictions and unreliable interpretability. In this\npaper, we analyze why attention-based methods tend to rely on spurious\ncorrelations in their predictions. Furthermore, we revisit max-pooling-based\napproaches and examine the reasons behind the underperformance of existing\nmethods. We argue that well-trained max-pooling-based MIL models can make\npredictions based on causal factors and avoid relying on spurious correlations.\nBuilding on these insights, we propose a simple yet effective max-pooling-based\nMIL method (FocusMIL) that outperforms existing mainstream attention-based\nmethods on two datasets. In this position paper, we advocate renewed attention\nto max-pooling-based methods to achieve more robust and interpretable\npredictions.", "AI": {"tldr": "The paper critiques attention-based MIL for WSI classification, proposing FocusMIL, a max-pooling-based method that avoids spurious correlations and outperforms attention-based approaches.", "motivation": "Attention-based MIL methods often focus on irrelevant patterns, leading to unreliable predictions. The paper aims to address this by revisiting max-pooling-based methods.", "method": "The authors analyze the flaws in attention-based MIL and propose FocusMIL, a max-pooling-based approach designed to rely on causal factors.", "result": "FocusMIL outperforms existing attention-based methods on two datasets, demonstrating robustness and better interpretability.", "conclusion": "The paper advocates for max-pooling-based methods like FocusMIL as a more reliable alternative to attention-based MIL for WSI classification."}}
{"id": "2404.13056", "pdf": "https://arxiv.org/pdf/2404.13056", "abs": "https://arxiv.org/abs/2404.13056", "authors": ["Jiayuan Dong", "Christian Jacobsen", "Mehdi Khalloufi", "Maryam Akram", "Wanjiao Liu", "Karthik Duraisamy", "Xun Huan"], "title": "Variational Bayesian Optimal Experimental Design with Normalizing Flows", "categories": ["cs.LG", "cs.CE", "stat.CO", "stat.ME", "stat.ML", "62K05, 94A17, 62C10, 62F15"], "comment": null, "summary": "Bayesian optimal experimental design (OED) seeks experiments that maximize\nthe expected information gain (EIG) in model parameters. Directly estimating\nthe EIG using nested Monte Carlo is computationally expensive and requires an\nexplicit likelihood. Variational OED (vOED), in contrast, estimates a lower\nbound of the EIG without likelihood evaluations by approximating the posterior\ndistributions with variational forms, and then tightens the bound by optimizing\nits variational parameters. We introduce the use of normalizing flows (NFs) for\nrepresenting variational distributions in vOED; we call this approach vOED-NFs.\nSpecifically, we adopt NFs with a conditional invertible neural network\narchitecture built from compositions of coupling layers, and enhanced with a\nsummary network for data dimension reduction. We present Monte Carlo estimators\nto the lower bound along with gradient expressions to enable a gradient-based\nsimultaneous optimization of the variational parameters and the design\nvariables. The vOED-NFs algorithm is then validated in two benchmark problems,\nand demonstrated on a partial differential equation-governed application of\ncathodic electrophoretic deposition and an implicit likelihood case with\nstochastic modeling of aphid population. The findings suggest that a\ncomposition of 4--5 coupling layers is able to achieve lower EIG estimation\nbias, under a fixed budget of forward model runs, compared to previous\napproaches. The resulting NFs produce approximate posteriors that agree well\nwith the true posteriors, able to capture non-Gaussian and multi-modal features\neffectively.", "AI": {"tldr": "vOED-NFs uses normalizing flows to estimate a lower bound of expected information gain (EIG) in Bayesian OED, improving accuracy and efficiency over nested Monte Carlo methods.", "motivation": "Direct EIG estimation via nested Monte Carlo is computationally expensive and requires explicit likelihoods, motivating the need for variational methods like vOED-NFs.", "method": "vOED-NFs employs conditional invertible neural networks (coupling layers) and a summary network for variational posterior approximation, optimizing variational parameters and design variables simultaneously.", "result": "vOED-NFs achieves lower EIG bias with 4-5 coupling layers, capturing non-Gaussian and multi-modal features in posteriors, validated on benchmark and real-world problems.", "conclusion": "vOED-NFs offers a computationally efficient and accurate alternative for Bayesian OED, particularly for complex, implicit-likelihood models."}}
{"id": "2411.07199", "pdf": "https://arxiv.org/pdf/2411.07199", "abs": "https://arxiv.org/abs/2411.07199", "authors": ["Cong Wei", "Zheyang Xiong", "Weiming Ren", "Xinrun Du", "Ge Zhang", "Wenhu Chen"], "title": "OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision", "categories": ["cs.CV", "cs.AI"], "comment": "21 pages", "summary": "Instruction-guided image editing methods have demonstrated significant\npotential by training diffusion models on automatically synthesized or manually\nannotated image editing pairs. However, these methods remain far from\npractical, real-life applications. We identify three primary challenges\ncontributing to this gap. Firstly, existing models have limited editing skills\ndue to the biased synthesis process. Secondly, these methods are trained with\ndatasets with a high volume of noise and artifacts. This is due to the\napplication of simple filtering methods like CLIP-score. Thirdly, all these\ndatasets are restricted to a single low resolution and fixed aspect ratio,\nlimiting the versatility to handle real-world use cases. In this paper, we\npresent \\omniedit, which is an omnipotent editor to handle seven different\nimage editing tasks with any aspect ratio seamlessly. Our contribution is in\nfour folds: (1) \\omniedit is trained by utilizing the supervision from seven\ndifferent specialist models to ensure task coverage. (2) we utilize importance\nsampling based on the scores provided by large multimodal models (like GPT-4o)\ninstead of CLIP-score to improve the data quality. (3) we propose a new editing\narchitecture called EditNet to greatly boost the editing success rate, (4) we\nprovide images with different aspect ratios to ensure that our model can handle\nany image in the wild. We have curated a test set containing images of\ndifferent aspect ratios, accompanied by diverse instructions to cover different\ntasks. Both automatic evaluation and human evaluations demonstrate that\n\\omniedit can significantly outperform all the existing models. Our code,\ndataset and model will be available at https://tiger-ai-lab.github.io/OmniEdit/", "AI": {"tldr": "OmniEdit is an advanced image editor addressing limitations of current methods by handling diverse tasks, improving data quality, and supporting any aspect ratio.", "motivation": "Existing image editing methods are limited by biased synthesis, noisy datasets, and fixed resolutions, hindering practical use.", "method": "OmniEdit uses supervision from specialist models, importance sampling with large multimodal models, a new EditNet architecture, and diverse aspect ratio training.", "result": "OmniEdit outperforms existing models in both automatic and human evaluations.", "conclusion": "OmniEdit bridges the gap to practical applications by addressing key challenges in image editing."}}
{"id": "2409.00591", "pdf": "https://arxiv.org/pdf/2409.00591", "abs": "https://arxiv.org/abs/2409.00591", "authors": ["Xujie Wan", "Wenjie Li", "Guangwei Gao", "Huimin Lu", "Jian Yang", "Chia-Wen Lin"], "title": "Attention-Guided Multi-scale Interaction Network for Face Super-Resolution", "categories": ["cs.CV"], "comment": "13 pages, 11 figures, 10 tables", "summary": "Recently, CNN and Transformer hybrid networks demonstrated excellent\nperformance in face super-resolution (FSR) tasks. Since numerous features at\ndifferent scales in hybrid networks, how to fuse these multi-scale features and\npromote their complementarity is crucial for enhancing FSR. However, existing\nhybrid network-based FSR methods ignore this, only simply combining the\nTransformer and CNN. To address this issue, we propose an attention-guided\nMulti-scale interaction network (AMINet), which contains local and global\nfeature interactions and encoder-decoder phase feature interactions.\nSpecifically, we propose a Local and Global Feature Interaction Module (LGFI)\nto promote fusions of global features and different receptive fields' local\nfeatures extracted by our Residual Depth Feature Extraction Module (RDFE).\nAdditionally, we propose a Selective Kernel Attention Fusion Module (SKAF) to\nadaptively select fusions of different features within LGFI and encoder-decoder\nphases. Our above design allows the free flow of multi-scale features from\nwithin modules and between encoder and decoder, which can promote the\ncomplementarity of different scale features to enhance FSR. Comprehensive\nexperiments confirm that our method consistently performs well with less\ncomputational consumption and faster inference.", "AI": {"tldr": "AMINet, a CNN-Transformer hybrid network, enhances face super-resolution (FSR) by fusing multi-scale features through local-global and encoder-decoder interactions, outperforming existing methods with efficiency.", "motivation": "Existing hybrid networks for FSR lack effective multi-scale feature fusion, limiting performance. AMINet addresses this gap.", "method": "Proposes AMINet with Local and Global Feature Interaction Module (LGFI) and Selective Kernel Attention Fusion Module (SKAF) for adaptive feature fusion.", "result": "AMINet achieves superior FSR performance with lower computational cost and faster inference.", "conclusion": "AMINet's design effectively enhances multi-scale feature complementarity, advancing FSR efficiency and performance."}}
{"id": "2404.18314", "pdf": "https://arxiv.org/pdf/2404.18314", "abs": "https://arxiv.org/abs/2404.18314", "authors": ["Geert De Paepe", "Lesley De Cruz"], "title": "DIRESA, a distance-preserving nonlinear dimension reduction technique based on regularized autoencoders", "categories": ["cs.LG", "nlin.CD", "physics.ao-ph"], "comment": "28 pages, 19 figures, 6 tables (including Appendices); accepted for\n  publication in Artificial Intelligence for the Earth Systems", "summary": "In meteorology, finding similar weather patterns or analogs in historical\ndatasets can be useful for data assimilation, forecasting, and postprocessing.\nIn climate science, analogs in historical and climate projection data are used\nfor attribution and impact studies. However, most of the time, those large\nweather and climate datasets are nearline. This means that they must be\ndownloaded, which takes a lot of bandwidth and disk space, before the\ncomputationally expensive search can be executed. We propose a dimension\nreduction technique based on autoencoder (AE) neural networks to compress the\ndatasets and perform the search in an interpretable, compressed latent space. A\ndistance-regularized Siamese twin autoencoder (DIRESA) architecture is designed\nto preserve distance in latent space while capturing the nonlinearities in the\ndatasets. Using conceptual climate models of different complexities, we show\nthat the latent components thus obtained provide physical insight into the\ndominant modes of variability in the system. Compressing datasets with DIRESA\nreduces the online storage and keeps the latent components uncorrelated, while\nthe distance (ordering) preservation and reconstruction fidelity robustly\noutperform Principal Component Analysis (PCA) and other dimension reduction\ntechniques such as UMAP or variational autoencoders.", "AI": {"tldr": "A dimension reduction technique using autoencoder neural networks (DIRESA) is proposed to compress weather and climate datasets, enabling efficient search in a latent space while preserving interpretability and outperforming PCA and other methods.", "motivation": "Large weather and climate datasets are often nearline, requiring significant bandwidth and storage for downloads before analysis. Efficient, interpretable compression is needed.", "method": "A distance-regularized Siamese twin autoencoder (DIRESA) is designed to compress datasets, preserving distances in latent space and capturing nonlinearities.", "result": "DIRESA reduces storage needs, keeps latent components uncorrelated, and outperforms PCA, UMAP, and variational autoencoders in distance preservation and reconstruction fidelity.", "conclusion": "DIRESA provides an efficient, interpretable solution for compressing and analyzing large weather and climate datasets, offering physical insights into system variability."}}
{"id": "2411.11934", "pdf": "https://arxiv.org/pdf/2411.11934", "abs": "https://arxiv.org/abs/2411.11934", "authors": ["Zhen Lv", "Yangqi Long", "Congzhentao Huang", "Cao Li", "Chengfei Lv", "Hao Ren", "Dian Zheng"], "title": "SpatialDreamer: Self-supervised Stereo Video Synthesis from Monocular Input", "categories": ["cs.CV", "cs.AI"], "comment": "website, see https://spatialdreamer.github.io", "summary": "Stereo video synthesis from a monocular input is a demanding task in the\nfields of spatial computing and virtual reality. The main challenges of this\ntask lie on the insufficiency of high-quality paired stereo videos for training\nand the difficulty of maintaining the spatio-temporal consistency between\nframes. Existing methods primarily address these issues by directly applying\nnovel view synthesis (NVS) techniques to video, while facing limitations such\nas the inability to effectively represent dynamic scenes and the requirement\nfor large amounts of training data. In this paper, we introduce a novel\nself-supervised stereo video synthesis paradigm via a video diffusion model,\ntermed SpatialDreamer, which meets the challenges head-on. Firstly, to address\nthe stereo video data insufficiency, we propose a Depth based Video Generation\nmodule DVG, which employs a forward-backward rendering mechanism to generate\npaired videos with geometric and temporal priors. Leveraging data generated by\nDVG, we propose RefinerNet along with a self-supervised synthetic framework\ndesigned to facilitate efficient and dedicated training. More importantly, we\ndevise a consistency control module, which consists of a metric of stereo\ndeviation strength and a Temporal Interaction Learning module TIL for geometric\nand temporal consistency ensurance respectively. We evaluated the proposed\nmethod against various benchmark methods, with the results showcasing its\nsuperior performance.", "AI": {"tldr": "SpatialDreamer introduces a self-supervised stereo video synthesis method using a video diffusion model, addressing data insufficiency and spatio-temporal consistency challenges.", "motivation": "The task of stereo video synthesis from monocular input lacks high-quality paired training data and struggles with spatio-temporal consistency. Existing NVS techniques fall short in dynamic scene representation and require excessive training data.", "method": "Proposes Depth-based Video Generation (DVG) for paired video creation, RefinerNet for efficient training, and a consistency control module (stereo deviation metric and Temporal Interaction Learning) for geometric and temporal consistency.", "result": "Outperforms benchmark methods in evaluations.", "conclusion": "SpatialDreamer effectively addresses stereo video synthesis challenges with innovative modules and self-supervised learning."}}
{"id": "2409.01003", "pdf": "https://arxiv.org/pdf/2409.01003", "abs": "https://arxiv.org/abs/2409.01003", "authors": ["Qian Li", "Shuojue Yang", "Daiyun Shen", "Jimmy Bok Yan So", "Jing Qin", "Yueming Jin"], "title": "Free-DyGS: Camera-Pose-Free Scene Reconstruction for Dynamic Surgical Videos with Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "High-fidelity reconstruction of surgical scene is a fundamentally crucial\ntask to support many applications, such as intra-operative navigation and\nsurgical education. However, most existing methods assume the ideal surgical\nscenarios - either focus on dynamic reconstruction with deforming tissue yet\nassuming a given fixed camera pose, or allow endoscope movement yet\nreconstructing the static scenes. In this paper, we target at a more realistic\nyet challenging setup - free-pose reconstruction with a moving camera for\nhighly dynamic surgical scenes. Meanwhile, we take the first step to introduce\nGaussian Splitting (GS) technique to tackle this challenging setting and\npropose a novel GS-based framework for fast reconstruction, termed\n\\textit{Free-DyGS}. Concretely, our model embraces a novel scene initialization\nin which a pre-trained Sparse Gaussian Regressor (SGR) can efficiently\nparameterize the initial attributes. For each subsequent frame, we propose to\njointly optimize the deformation model and 6D camera poses in a frame-by-frame\nmanner, easing training given the limited deformation differences between\nconsecutive frames. A Scene Expansion scheme is followed to expand the GS model\nfor the unseen regions introduced by the moving camera. Moreover, the framework\nis equipped with a novel Retrospective Deformation Recapitulation (RDR)\nstrategy to preserve the entire-clip deformations throughout the frame-by-frame\ntraining scheme. The efficacy of the proposed Free-DyGS is substantiated\nthrough extensive experiments on two datasets: StereoMIS and Hamlyn datasets.\nThe experimental outcomes underscore that Free-DyGS surpasses other advanced\nmethods in both rendering accuracy and efficiency. Code will be available.", "AI": {"tldr": "The paper introduces Free-DyGS, a framework for high-fidelity reconstruction of dynamic surgical scenes with a moving camera, using Gaussian Splitting (GS) and novel techniques like Sparse Gaussian Regressor (SGR) and Retrospective Deformation Recapitulation (RDR).", "motivation": "Existing methods either assume fixed camera poses or static scenes, limiting their applicability in realistic surgical scenarios. This paper addresses the challenge of free-pose reconstruction for highly dynamic surgical scenes.", "method": "The proposed Free-DyGS framework uses GS for fast reconstruction, initializing scenes with a pre-trained SGR. It jointly optimizes deformation models and camera poses frame-by-frame, employs Scene Expansion for unseen regions, and uses RDR to preserve deformations.", "result": "Experiments on StereoMIS and Hamlyn datasets show Free-DyGS outperforms other methods in rendering accuracy and efficiency.", "conclusion": "Free-DyGS effectively tackles the challenging setup of dynamic surgical scene reconstruction with a moving camera, offering superior performance and practicality."}}
{"id": "2405.17366", "pdf": "https://arxiv.org/pdf/2405.17366", "abs": "https://arxiv.org/abs/2405.17366", "authors": ["Ruichen Wang", "Dinesh Manocha"], "title": "EM-GANSim: Real-time and Accurate EM Simulation Using Conditional GANs for 3D Indoor Scenes", "categories": ["cs.LG", "eess.SP"], "comment": "12 pages, 9 figures, 5 tables", "summary": "We present a novel machine-learning (ML) approach (EM-GANSim) for real-time\nelectromagnetic (EM) propagation that is used for wireless communication\nsimulation in 3D indoor environments. Our approach uses a modified conditional\nGenerative Adversarial Network (GAN) that incorporates encoded geometry and\ntransmitter location while adhering to the electromagnetic propagation theory.\nThe overall physically-inspired learning is able to predict the power\ndistribution in 3D scenes, which is represented using heatmaps. We evaluated\nour method on 15 complex 3D indoor environments, with 4 additional scenarios\nlater included in the results, showcasing the generalizability of the model\nacross diverse conditions. Our overall accuracy is comparable to ray\ntracing-based EM simulation, as evidenced by lower mean squared error values.\nFurthermore, our GAN-based method drastically reduces the computation time,\nachieving a 5X speedup on complex benchmarks. In practice, it can compute the\nsignal strength in a few milliseconds on any location in 3D indoor\nenvironments. We also present a large dataset of 3D models and EM ray\ntracing-simulated heatmaps. To the best of our knowledge, EM-GANSim is the\nfirst real-time algorithm for EM simulation in complex 3D indoor environments.\nWe plan to release the code and the dataset.", "AI": {"tldr": "EM-GANSim is a novel ML approach using a modified GAN for real-time EM propagation simulation in 3D indoor environments, achieving accuracy comparable to ray tracing with 5X speedup.", "motivation": "To enable real-time EM propagation simulation for wireless communication in complex 3D indoor environments, overcoming the computational inefficiency of traditional ray tracing methods.", "method": "Uses a modified conditional GAN incorporating encoded geometry and transmitter location, adhering to EM propagation theory to predict power distribution (heatmaps).", "result": "Evaluated on 19 scenarios, EM-GANSim matches ray tracing accuracy (lower MSE) and reduces computation time by 5X, enabling real-time signal strength prediction.", "conclusion": "EM-GANSim is the first real-time EM simulation algorithm for 3D indoor environments, with plans to release code and dataset."}}
{"id": "2411.18948", "pdf": "https://arxiv.org/pdf/2411.18948", "abs": "https://arxiv.org/abs/2411.18948", "authors": ["Xue Tan", "Hao Luan", "Mingyu Luo", "Xiaoyan Sun", "Ping Chen", "Jun Dai"], "title": "RevPRAG: Revealing Poisoning Attacks in Retrieval-Augmented Generation through LLM Activation Analysis", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enriches the input to LLMs by retrieving\ninformation from the relevant knowledge database, enabling them to produce\nresponses that are more accurate and contextually appropriate. It is worth\nnoting that the knowledge database, being sourced from publicly available\nchannels such as Wikipedia, inevitably introduces a new attack surface. RAG\npoisoning involves injecting malicious texts into the knowledge database,\nultimately leading to the generation of the attacker's target response (also\ncalled poisoned response). However, there are currently limited methods\navailable for detecting such poisoning attacks. We aim to bridge the gap in\nthis work. Particularly, we introduce RevPRAG, a flexible and automated\ndetection pipeline that leverages the activations of LLMs for poisoned response\ndetection. Our investigation uncovers distinct patterns in LLMs' activations\nwhen generating correct responses versus poisoned responses. Our results on\nmultiple benchmark datasets and RAG architectures show our approach could\nachieve 98% true positive rate, while maintaining false positive rates close to\n1%.", "AI": {"tldr": "RevPRAG detects RAG poisoning by analyzing LLM activations, achieving high accuracy with 98% true positive and 1% false positive rates.", "motivation": "RAG poisoning introduces risks by injecting malicious texts into knowledge databases, but detection methods are lacking.", "method": "Introduces RevPRAG, a pipeline using LLM activations to identify poisoned responses by analyzing activation patterns.", "result": "Achieves 98% true positive and 1% false positive rates across benchmark datasets and RAG architectures.", "conclusion": "RevPRAG effectively bridges the detection gap for RAG poisoning, leveraging LLM activation patterns for high accuracy."}}
{"id": "2409.01348", "pdf": "https://arxiv.org/pdf/2409.01348", "abs": "https://arxiv.org/abs/2409.01348", "authors": ["Guanglei Zhou", "Bhargav Korrapati", "Gaurav Rajavendra Reddy", "Chen-Chia Chang", "Jingyu Pan", "Jiang Hu", "Yiran Chen", "Dipto G. Thakurta"], "title": "PatternPaint: Practical Layout Pattern Generation Using Diffusion-Based Inpainting", "categories": ["cs.CV", "cs.CE", "cs.LG"], "comment": "DAC 2025 accepted", "summary": "Generating diverse VLSI layout patterns is essential for various downstream\ntasks in design for manufacturing, as design rules continually evolve during\nthe development of new technology nodes. However, existing training-based\nmethods for layout pattern generation rely on large datasets. In practical\nscenarios, especially when developing a new technology node, obtaining such\nextensive layout data is challenging. Consequently, training models with large\ndatasets becomes impractical, limiting the scalability and adaptability of\nprior approaches. To this end, we propose PatternPaint, a diffusion-based\nframework capable of generating legal patterns with limited\ndesign-rule-compliant training samples. PatternPaint simplifies complex layout\npattern generation into a series of inpainting processes with a template-based\ndenoising scheme. Furthermore, we perform few-shot finetuning on a pretrained\nimage foundation model with only 20 design-rule-compliant samples. Experimental\nresults show that using a sub-3nm technology node (Intel 18A), our model is the\nonly one that can generate legal patterns in complex 2D metal interconnect\ndesign rule settings among all previous works and achieves a high diversity\nscore. Additionally, our few-shot finetuning can boost the legality rate with\n1.87X improvement compared to the original pretrained model. As a result, we\ndemonstrate a production-ready approach for layout pattern generation in\ndeveloping new technology nodes.", "AI": {"tldr": "PatternPaint is a diffusion-based framework for generating diverse VLSI layout patterns with limited training data, outperforming existing methods in legality and diversity.", "motivation": "Existing methods require large datasets, which are impractical for new technology nodes. PatternPaint addresses this by working with limited design-rule-compliant samples.", "method": "PatternPaint uses a diffusion-based framework with template-based denoising and few-shot finetuning on a pretrained image model.", "result": "The model generates legal patterns in complex 2D metal interconnect designs, achieving high diversity and a 1.87X legality rate improvement.", "conclusion": "PatternPaint offers a scalable, production-ready solution for layout pattern generation in new technology nodes."}}
{"id": "2406.12615", "pdf": "https://arxiv.org/pdf/2406.12615", "abs": "https://arxiv.org/abs/2406.12615", "authors": ["Yedi Zhang", "Andrew Saxe", "Peter E. Latham"], "title": "When Are Bias-Free ReLU Networks Effectively Linear Networks?", "categories": ["cs.LG"], "comment": "TMLR", "summary": "We investigate the implications of removing bias in ReLU networks regarding\ntheir expressivity and learning dynamics. We first show that two-layer\nbias-free ReLU networks have limited expressivity: the only odd function\ntwo-layer bias-free ReLU networks can express is a linear one. We then show\nthat, under symmetry conditions on the data, these networks have the same\nlearning dynamics as linear networks. This enables us to give analytical\ntime-course solutions to certain two-layer bias-free (leaky) ReLU networks\noutside the lazy learning regime. While deep bias-free ReLU networks are more\nexpressive than their two-layer counterparts, they still share a number of\nsimilarities with deep linear networks. These similarities enable us to\nleverage insights from linear networks to understand certain ReLU networks.\nOverall, our results show that some properties previously established for\nbias-free ReLU networks arise due to equivalence to linear networks.", "AI": {"tldr": "Bias-free ReLU networks, especially two-layer ones, have limited expressivity and share learning dynamics with linear networks under symmetric data. Deep bias-free ReLU networks, while more expressive, still resemble linear networks, allowing insights from linear networks to apply.", "motivation": "To understand the expressivity and learning dynamics of bias-free ReLU networks and their similarities to linear networks.", "method": "Analyzed two-layer and deep bias-free ReLU networks, comparing their expressivity and learning dynamics to linear networks under symmetric data conditions.", "result": "Two-layer bias-free ReLU networks are limited to expressing linear odd functions and share learning dynamics with linear networks. Deep bias-free ReLU networks, though more expressive, still resemble linear networks.", "conclusion": "Some properties of bias-free ReLU networks arise from their equivalence to linear networks, enabling insights from linear networks to be applied."}}
{"id": "2412.04107", "pdf": "https://arxiv.org/pdf/2412.04107", "abs": "https://arxiv.org/abs/2412.04107", "authors": ["Yuhao Wang", "Junwei Pan", "Pengyue Jia", "Wanyu Wang", "Maolin Wang", "Zhixiang Feng", "Xiaotian Li", "Jie Jiang", "Xiangyu Zhao"], "title": "Pre-train, Align, and Disentangle: Empowering Sequential Recommendation with Large Language Models", "categories": ["cs.IR", "cs.AI"], "comment": "accepted to SIGIR 2025", "summary": "Sequential Recommendation (SR) aims to leverage the sequential patterns in\nusers' historical interactions to accurately track their preferences. However,\nthe primary reliance of existing SR methods on collaborative data results in\nchallenges such as the cold-start problem and sub-optimal performance.\nConcurrently, despite the proven effectiveness of large language models (LLMs),\ntheir integration into commercial recommender systems is impeded by issues such\nas high inference latency, incomplete capture of all distribution statistics,\nand catastrophic forgetting. To address these issues, we introduce a novel\nPre-train, Align, and Disentangle (PAD) framework to enhance SR models with\nLLMs. In particular, we initially pre-train both the SR and LLM models to\nobtain collaborative and textual embeddings. Subsequently, we propose a\ncharacteristic recommendation-anchored alignment loss using multi-kernel\nmaximum mean discrepancy with Gaussian kernels. Lastly, a triple-experts\narchitecture, comprising aligned and modality-specific experts with\ndisentangled embeddings, is fine-tuned in a frequency-aware manner.\nExperimental results on three public datasets validate the efficacy of PAD,\nindicating substantial enhancements and compatibility with various SR backbone\nmodels, particularly for cold items. The code and datasets are accessible for\nreproduction at https://github.com/Applied-Machine-Learning-Lab/PAD.", "AI": {"tldr": "The paper introduces the PAD framework to enhance Sequential Recommendation (SR) models by integrating large language models (LLMs), addressing cold-start issues and improving performance.", "motivation": "Existing SR methods rely heavily on collaborative data, leading to cold-start problems and sub-optimal performance. LLMs, though effective, face challenges like high inference latency and incomplete data capture in recommender systems.", "method": "The PAD framework pre-trains SR and LLM models, aligns their embeddings using a multi-kernel maximum mean discrepancy loss, and fine-tunes a triple-experts architecture with disentangled embeddings.", "result": "Experiments on three datasets show PAD significantly improves SR performance, especially for cold items, and is compatible with various SR backbone models.", "conclusion": "The PAD framework effectively integrates LLMs into SR models, overcoming key challenges and enhancing recommendation accuracy, particularly for cold-start scenarios."}}
{"id": "2409.17993", "pdf": "https://arxiv.org/pdf/2409.17993", "abs": "https://arxiv.org/abs/2409.17993", "authors": ["Junchen Yu", "Si-Yuan Cao", "Runmin Zhang", "Chenghao Zhang", "Zhu Yu", "Shujie Chen", "Bailin Yang", "Hui-liang Shen"], "title": "SSHNet: Unsupervised Cross-modal Homography Estimation via Problem Reformulation and Split Optimization", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "We propose a novel unsupervised cross-modal homography estimation learning\nframework, named Split Supervised Homography estimation Network (SSHNet).\nSSHNet reformulates the unsupervised cross-modal homography estimation into two\nsupervised sub-problems, each addressed by its specialized network: a\nhomography estimation network and a modality transfer network. To realize\nstable training, we introduce an effective split optimization strategy to train\neach network separately within its respective sub-problem. We also formulate an\nextra homography feature space supervision to enhance feature consistency,\nfurther boosting the estimation accuracy. Moreover, we employ a simple yet\neffective distillation training technique to reduce model parameters and\nimprove cross-domain generalization ability while maintaining comparable\nperformance. The training stability of SSHNet enables its cooperation with\nvarious homography estimation architectures. Experiments reveal that the SSHNet\nusing IHN as homography estimation network, namely SSHNet-IHN, outperforms\nprevious unsupervised approaches by a significant margin. Even compared to\nsupervised approaches MHN and LocalTrans, SSHNet-IHN achieves 47.4% and 85.8%\nmean average corner errors (MACEs) reduction on the challenging OPT-SAR\ndataset.", "AI": {"tldr": "SSHNet is an unsupervised cross-modal homography estimation framework that splits the problem into supervised sub-tasks, using specialized networks and a split optimization strategy for stable training. It outperforms previous methods significantly.", "motivation": "To address the challenges of unsupervised cross-modal homography estimation by reformulating it into supervised sub-problems for improved accuracy and stability.", "method": "SSHNet divides the task into two supervised sub-problems: homography estimation and modality transfer, using specialized networks. It employs split optimization, feature space supervision, and distillation training.", "result": "SSHNet-IHN outperforms unsupervised methods and reduces mean average corner errors by 47.4% and 85.8% compared to supervised approaches on the OPT-SAR dataset.", "conclusion": "SSHNet provides a stable and accurate framework for cross-modal homography estimation, with potential for integration with various architectures."}}
{"id": "2407.01856", "pdf": "https://arxiv.org/pdf/2407.01856", "abs": "https://arxiv.org/abs/2407.01856", "authors": ["Xinxing Shi", "Thomas Baldwin-McDonald", "Mauricio A. \u00c1lvarez"], "title": "Adaptive RKHS Fourier Features for Compositional Gaussian Process Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Deep Gaussian Processes (DGPs) leverage a compositional structure to model\nnon-stationary processes. DGPs typically rely on local inducing point\napproximations across intermediate GP layers. Recent advances in DGP inference\nhave shown that incorporating global Fourier features from the Reproducing\nKernel Hilbert Space (RKHS) can enhance the DGPs' capability to capture complex\nnon-stationary patterns. This paper extends the use of these features to\ncompositional GPs involving linear transformations. In particular, we introduce\nOrdinary Differential Equation(ODE)--based RKHS Fourier features that allow for\nadaptive amplitude and phase modulation through convolution operations. This\nconvolutional formulation relates our work to recently proposed deep latent\nforce models, a multi-layer structure designed for modelling nonlinear\ndynamical systems. By embedding these adjustable RKHS Fourier features within a\ndoubly stochastic variational inference framework, our model exhibits improved\npredictive performance across various regression tasks.", "AI": {"tldr": "The paper introduces ODE-based RKHS Fourier features for DGPs, enhancing their ability to model non-stationary processes through adaptive amplitude and phase modulation, improving predictive performance.", "motivation": "To improve DGPs' capability to capture complex non-stationary patterns by incorporating global Fourier features and linear transformations.", "method": "Extends DGPs with ODE-based RKHS Fourier features, enabling adaptive modulation via convolution, and uses doubly stochastic variational inference.", "result": "The model shows improved predictive performance in various regression tasks.", "conclusion": "ODE-based RKHS Fourier features enhance DGPs, linking them to deep latent force models for better modeling of nonlinear dynamics."}}
{"id": "2412.04653", "pdf": "https://arxiv.org/pdf/2412.04653", "abs": "https://arxiv.org/abs/2412.04653", "authors": ["Kasra Arabi", "Benjamin Feuer", "R. Teal Witter", "Chinmay Hegde", "Niv Cohen"], "title": "Hidden in the Noise: Two-Stage Robust Watermarking for Images", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "As the quality of image generators continues to improve, deepfakes become a\ntopic of considerable societal debate. Image watermarking allows responsible\nmodel owners to detect and label their AI-generated content, which can mitigate\nthe harm. Yet, current state-of-the-art methods in image watermarking remain\nvulnerable to forgery and removal attacks. This vulnerability occurs in part\nbecause watermarks distort the distribution of generated images,\nunintentionally revealing information about the watermarking techniques.\n  In this work, we first demonstrate a distortion-free watermarking method for\nimages, based on a diffusion model's initial noise. However, detecting the\nwatermark requires comparing the initial noise reconstructed for an image to\nall previously used initial noises. To mitigate these issues, we propose a\ntwo-stage watermarking framework for efficient detection. During generation, we\naugment the initial noise with generated Fourier patterns to embed information\nabout the group of initial noises we used. For detection, we (i) retrieve the\nrelevant group of noises, and (ii) search within the given group for an initial\nnoise that might match our image. This watermarking approach achieves\nstate-of-the-art robustness to forgery and removal against a large battery of\nattacks.", "AI": {"tldr": "A distortion-free watermarking method for images using diffusion models and Fourier patterns, achieving robust detection against attacks.", "motivation": "Address vulnerabilities in current watermarking methods that distort images and are prone to forgery and removal.", "method": "Two-stage framework: (1) augment initial noise with Fourier patterns during generation, (2) retrieve and match noise groups for detection.", "result": "State-of-the-art robustness to forgery and removal attacks.", "conclusion": "The proposed method effectively embeds and detects watermarks without distorting images, improving security."}}
{"id": "2409.18125", "pdf": "https://arxiv.org/pdf/2409.18125", "abs": "https://arxiv.org/abs/2409.18125", "authors": ["Chenming Zhu", "Tai Wang", "Wenwei Zhang", "Jiangmiao Pang", "Xihui Liu"], "title": "LLaVA-3D: A Simple yet Effective Pathway to Empowering LMMs with 3D-awareness", "categories": ["cs.CV"], "comment": "Project page: https://zcmax.github.io/projects/LLaVA-3D/", "summary": "Recent advancements in Large Multimodal Models (LMMs) have greatly enhanced\ntheir proficiency in 2D visual understanding tasks, enabling them to\neffectively process and understand images and videos. However, the development\nof LMMs with 3D scene understanding capabilities has been hindered by the lack\nof large-scale 3D vision-language datasets and powerful 3D encoders. In this\npaper, we introduce a simple yet effective framework called LLaVA-3D.\nLeveraging the strong 2D visual understanding priors from LLaVA, our LLaVA-3D\nefficiently adapts LLaVA for 3D scene understanding without compromising 2D\nunderstanding capabilities. To achieve this, we utilize the 3D position\nembeddings to enhance the 2D CLIP Patches with 3D spatial context information\nand construct 3D patches. By integrating the 3D position embeddings into 2D\nLMMs and employing joint 2D and 3D vision-language instruction tuning, we\nestablish a unified architecture for both 2D visual understanding and 3D scene\nunderstanding. In contrast to previous 3D LMMs, LLaVA-3D supports decoding\naccurate 3D spatial perception outputs, e.g., 3D bounding boxes, directly from\nthese 3D patches, without relying on the time-consuming off-the-shelf 3D\nsegmentors. Experimental results show that LLaVA-3D converges 3.5x faster than\nexisting 3D LMMs when trained on 3D vision-language datasets. Moreover,\nLLaVA-3D not only achieves state-of-the-art performance across various 3D tasks\nbut also maintains comparable 2D visual understanding and vision-language\nconversation capabilities with LLaVA.", "AI": {"tldr": "LLaVA-3D is a framework adapting LLaVA for 3D scene understanding by integrating 3D position embeddings into 2D models, achieving faster convergence and state-of-the-art performance without compromising 2D capabilities.", "motivation": "The lack of large-scale 3D vision-language datasets and powerful 3D encoders hinders the development of LMMs with 3D scene understanding.", "method": "LLaVA-3D enhances 2D CLIP patches with 3D spatial context using 3D position embeddings, constructs 3D patches, and employs joint 2D and 3D vision-language instruction tuning.", "result": "LLaVA-3D converges 3.5x faster than existing 3D LMMs and achieves state-of-the-art performance in 3D tasks while maintaining 2D capabilities.", "conclusion": "LLaVA-3D provides a unified architecture for 2D and 3D understanding, offering efficient and accurate 3D perception without relying on slow 3D segmentors."}}
{"id": "2407.10652", "pdf": "https://arxiv.org/pdf/2407.10652", "abs": "https://arxiv.org/abs/2407.10652", "authors": ["Lucas Joos", "Daniel A. Keim", "Maximilian T. Fischer"], "title": "Cutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews", "categories": ["cs.LG", "cs.DL", "cs.HC", "H.5.2"], "comment": "6 pages, 5 figures, 1 table", "summary": "Systematic literature reviews (SLRs) are essential but labor-intensive due to\nhigh publication volumes and inefficient keyword-based filtering. To streamline\nthis process, we evaluate Large Language Models (LLMs) for enhancing efficiency\nand accuracy in corpus filtration while minimizing manual effort. Our\nopen-source tool LLMSurver presents a visual interface to utilize LLMs for\nliterature filtration, evaluate the results, and refine queries in an\ninteractive way. We assess the real-world performance of our approach in\nfiltering over 8.3k articles during a recent survey construction, comparing\nresults with human efforts. The findings show that recent LLM models can reduce\nfiltering time from weeks to minutes. A consensus scheme ensures recall rates\n>98.8%, surpassing typical human error thresholds and improving selection\naccuracy. This work advances literature review methodologies and highlights the\npotential of responsible human-AI collaboration in academic research.", "AI": {"tldr": "LLMSurver, an open-source tool using LLMs, significantly speeds up literature reviews by reducing filtering time from weeks to minutes while maintaining high accuracy (>98.8% recall).", "motivation": "To address the inefficiency of manual keyword-based filtering in systematic literature reviews due to high publication volumes.", "method": "Developed LLMSurver, a visual tool leveraging LLMs for interactive literature filtration, query refinement, and evaluation. Tested on 8.3k articles.", "result": "LLMs reduced filtering time drastically (weeks to minutes) with >98.8% recall, outperforming human error thresholds.", "conclusion": "LLMs enhance literature review efficiency and accuracy, demonstrating the potential of human-AI collaboration in research."}}
{"id": "2412.11983", "pdf": "https://arxiv.org/pdf/2412.11983", "abs": "https://arxiv.org/abs/2412.11983", "authors": ["Taiyan Zhang", "Renchi Yang", "Yurui Lai", "Mingyu Yan", "Xiaochun Ye", "Dongrui Fan"], "title": "Leveraging Large Language Models for Effective Label-free Node Classification in Text-Attributed Graphs", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 5 figures", "summary": "Graph neural networks (GNNs) have become the preferred models for node\nclassification in graph data due to their robust capabilities in integrating\ngraph structures and attributes. However, these models heavily depend on a\nsubstantial amount of high-quality labeled data for training, which is often\ncostly to obtain. With the rise of large language models (LLMs), a promising\napproach is to utilize their exceptional zero-shot capabilities and extensive\nknowledge for node labeling. Despite encouraging results, this approach either\nrequires numerous queries to LLMs or suffers from reduced performance due to\nnoisy labels generated by LLMs. To address these challenges, we introduce\nLocle, an active self-training framework that does Label-free node\nClassification with LLMs cost-Effectively. Locle iteratively identifies small\nsets of \"critical\" samples using GNNs and extracts informative pseudo-labels\nfor them with both LLMs and GNNs, serving as additional supervision signals to\nenhance model training. Specifically, Locle comprises three key components: (i)\nan effective active node selection strategy for initial annotations; (ii) a\ncareful sample selection scheme to identify \"critical\" nodes based on label\ndisharmonicity and entropy; and (iii) a label refinement module that combines\nLLMs and GNNs with a rewired topology. Extensive experiments on five benchmark\ntext-attributed graph datasets demonstrate that Locle significantly outperforms\nstate-of-the-art methods under the same query budget to LLMs in terms of\nlabel-free node classification. Notably, on the DBLP dataset with 14.3k nodes,\nLocle achieves an 8.08% improvement in accuracy over the state-of-the-art at a\ncost of less than one cent. Our code is available at\nhttps://github.com/HKBU-LAGAS/Locle.", "AI": {"tldr": "Locle is an active self-training framework for label-free node classification using LLMs and GNNs, outperforming state-of-the-art methods with minimal cost.", "motivation": "GNNs rely on labeled data, which is costly. LLMs offer zero-shot capabilities but face issues like high query costs or noisy labels. Locle addresses these challenges.", "method": "Locle iteratively selects critical nodes, generates pseudo-labels using LLMs and GNNs, and refines labels with a rewired topology.", "result": "Locle achieves an 8.08% accuracy improvement on DBLP dataset at minimal cost.", "conclusion": "Locle effectively combines LLMs and GNNs for cost-efficient, label-free node classification."}}
{"id": "2410.07149", "pdf": "https://arxiv.org/pdf/2410.07149", "abs": "https://arxiv.org/abs/2410.07149", "authors": ["Clement Neo", "Luke Ong", "Philip Torr", "Mor Geva", "David Krueger", "Fazl Barez"], "title": "Towards Interpreting Visual Information Processing in Vision-Language Models", "categories": ["cs.CV", "cs.LG"], "comment": "Published at ICLR 2025", "summary": "Vision-Language Models (VLMs) are powerful tools for processing and\nunderstanding text and images. We study the processing of visual tokens in the\nlanguage model component of LLaVA, a prominent VLM. Our approach focuses on\nanalyzing the localization of object information, the evolution of visual token\nrepresentations across layers, and the mechanism of integrating visual\ninformation for predictions. Through ablation studies, we demonstrated that\nobject identification accuracy drops by over 70\\% when object-specific tokens\nare removed. We observed that visual token representations become increasingly\ninterpretable in the vocabulary space across layers, suggesting an alignment\nwith textual tokens corresponding to image content. Finally, we found that the\nmodel extracts object information from these refined representations at the\nlast token position for prediction, mirroring the process in text-only language\nmodels for factual association tasks. These findings provide crucial insights\ninto how VLMs process and integrate visual information, bridging the gap\nbetween our understanding of language and vision models, and paving the way for\nmore interpretable and controllable multimodal systems.", "AI": {"tldr": "The paper analyzes how LLaVA, a vision-language model, processes visual tokens, focusing on object localization, representation evolution, and integration for predictions. Key findings include a 70% drop in object identification without object-specific tokens, increasing interpretability of visual tokens across layers, and alignment with textual tokens for prediction.", "motivation": "To understand how visual tokens are processed and integrated in VLMs, particularly in LLaVA, to bridge the gap between language and vision models and improve interpretability.", "method": "The study involves analyzing visual token localization, representation evolution across layers, and integration mechanisms, supported by ablation studies.", "result": "Removing object-specific tokens reduces accuracy by 70%; visual tokens align with textual tokens across layers; object information is extracted at the last token position for prediction.", "conclusion": "The findings enhance understanding of VLM processing, offering insights for more interpretable and controllable multimodal systems."}}
{"id": "2407.17458", "pdf": "https://arxiv.org/pdf/2407.17458", "abs": "https://arxiv.org/abs/2407.17458", "authors": ["Joana Reuss", "Jan Macdonald", "Simon Becker", "Lorenz Richter", "Marco K\u00f6rner"], "title": "EuroCropsML: A Time Series Benchmark Dataset For Few-Shot Crop Type Classification", "categories": ["cs.LG"], "comment": "12 pages, 8 figures", "summary": "We introduce EuroCropsML, an analysis-ready remote sensing machine learning\ndataset for time series crop type classification of agricultural parcels in\nEurope. It is the first dataset designed to benchmark transnational few-shot\ncrop type classification algorithms that supports advancements in algorithmic\ndevelopment and research comparability. It comprises 706 683 multi-class\nlabeled data points across 176 classes, featuring annual time series of\nper-parcel median pixel values from Sentinel-2 L1C data for 2021, along with\ncrop type labels and spatial coordinates. Based on the open-source EuroCrops\ncollection, EuroCropsML is publicly available on Zenodo.", "AI": {"tldr": "EuroCropsML is a remote sensing dataset for crop type classification in Europe, designed for benchmarking few-shot algorithms.", "motivation": "To support advancements in algorithmic development and enable research comparability for transnational few-shot crop type classification.", "method": "The dataset includes 706,683 labeled data points across 176 classes, featuring annual Sentinel-2 L1C time series data for 2021, crop type labels, and spatial coordinates.", "result": "EuroCropsML is the first such dataset, publicly available on Zenodo, derived from the open-source EuroCrops collection.", "conclusion": "EuroCropsML facilitates benchmarking and research in few-shot crop type classification, promoting algorithmic progress in remote sensing."}}
{"id": "2412.12636", "pdf": "https://arxiv.org/pdf/2412.12636", "abs": "https://arxiv.org/abs/2412.12636", "authors": ["ChonLam Lao", "Minlan Yu", "Aditya Akella", "Jiamin Cao", "Yu Guan", "Pengcheng Zhang", "Zhilong Zheng", "Yichi Xu", "Ennan Zhai", "Dennis Cai", "Jiaqi Gao"], "title": "TrainMover: An Interruption-Resilient and Reliable ML Training Runtime", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "comment": "13 pages body, 17 pages total", "summary": "Large-scale ML training jobs are frequently interrupted by hardware and\nsoftware anomalies, failures, and management events. Existing solutions like\ncheckpointing or runtime reconfiguration suffer from long downtimes, degraded\nperformance, or undesired changes to training strategies. We present\nTrainMover, a resilient runtime that leverages standby machines to handle\ninterruptions with minimal downtime and zero memory overhead. To achieve these\ngoals, TrainMover introduces two key techniques: two-phase, delta-based\ncommunication group setups and communication-free sandboxed shadow iterations.\nOur evaluation shows that TrainMover consistently achieves second-level\ndowntime across all evaluated models during migration, maintaining 99\\%\ntraining efficiency during periodic 10-minute rebalancing. We also demonstrate\nthe effectiveness of TrainMover in handling various interruptions.", "AI": {"tldr": "TrainMover is a resilient runtime for large-scale ML training, minimizing downtime during interruptions using standby machines, delta-based communication, and shadow iterations.", "motivation": "Existing solutions for handling interruptions in ML training (e.g., checkpointing) cause long downtimes or degraded performance, necessitating a more efficient approach.", "method": "TrainMover uses two-phase, delta-based communication group setups and communication-free sandboxed shadow iterations to handle interruptions.", "result": "TrainMover achieves second-level downtime during migration and maintains 99% training efficiency during periodic rebalancing.", "conclusion": "TrainMover effectively handles interruptions with minimal downtime and no memory overhead, outperforming existing solutions."}}
{"id": "2410.16719", "pdf": "https://arxiv.org/pdf/2410.16719", "abs": "https://arxiv.org/abs/2410.16719", "authors": ["Evans Xu Han", "Linghao Jin", "Xiaofeng Liu", "Paul Pu Liang"], "title": "Progressive Compositionality in Text-to-Image Generative Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Despite the impressive text-to-image (T2I) synthesis capabilities of\ndiffusion models, they often struggle to understand compositional relationships\nbetween objects and attributes, especially in complex settings. Existing\nsolutions have tackled these challenges by optimizing the cross-attention\nmechanism or learning from the caption pairs with minimal semantic changes.\nHowever, can we generate high-quality complex contrastive images that diffusion\nmodels can directly discriminate based on visual representations? In this work,\nwe leverage large-language models (LLMs) to compose realistic, complex\nscenarios and harness Visual-Question Answering (VQA) systems alongside\ndiffusion models to automatically curate a contrastive dataset, ConPair,\nconsisting of 15k pairs of high-quality contrastive images. These pairs feature\nminimal visual discrepancies and cover a wide range of attribute categories,\nespecially complex and natural scenarios. To learn effectively from these error\ncases, i.e., hard negative images, we propose EvoGen, a new multi-stage\ncurriculum for contrastive learning of diffusion models. Through extensive\nexperiments across a wide range of compositional scenarios, we showcase the\neffectiveness of our proposed framework on compositional T2I benchmarks.", "AI": {"tldr": "The paper introduces ConPair, a dataset of 15k contrastive image pairs for improving diffusion models' understanding of compositional relationships, and EvoGen, a multi-stage curriculum for contrastive learning.", "motivation": "Diffusion models struggle with compositional relationships in complex settings, and existing solutions are limited.", "method": "Leverages LLMs to create realistic scenarios, uses VQA systems to curate ConPair dataset, and proposes EvoGen for contrastive learning.", "result": "The framework effectively improves compositional text-to-image synthesis, as shown in experiments.", "conclusion": "The proposed approach enhances diffusion models' ability to handle complex compositional scenarios."}}
{"id": "2408.03425", "pdf": "https://arxiv.org/pdf/2408.03425", "abs": "https://arxiv.org/abs/2408.03425", "authors": ["Agathe Fernandes Machado", "Arthur Charpentier", "Ewen Gallic"], "title": "Sequential Conditional Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "In this paper, we link two existing approaches to derive counterfactuals:\nadaptations based on a causal graph, and optimal transport. We extend \"Knothe's\nrearrangement\" and \"triangular transport\" to probabilistic graphical models,\nand use this counterfactual approach, referred to as sequential transport, to\ndiscuss fairness at the individual level. After establishing the theoretical\nfoundations of the proposed method, we demonstrate its application through\nnumerical experiments on both synthetic and real datasets.", "AI": {"tldr": "The paper combines causal graph adaptations and optimal transport to derive counterfactuals, introducing sequential transport for fairness analysis.", "motivation": "To bridge causal graph methods and optimal transport for counterfactual analysis, focusing on individual fairness.", "method": "Extends Knothe's rearrangement and triangular transport to probabilistic graphical models, proposing sequential transport.", "result": "Theoretical foundations are established, and numerical experiments on synthetic and real datasets validate the method.", "conclusion": "Sequential transport effectively links causal and transport-based approaches for counterfactual fairness."}}
{"id": "2412.17965", "pdf": "https://arxiv.org/pdf/2412.17965", "abs": "https://arxiv.org/abs/2412.17965", "authors": ["Osama Abdellatif", "Ahmed Ayman", "Ali Hamdi"], "title": "LMV-RPA: Large Model Voting-based Robotic Process Automation", "categories": ["cs.RO", "cs.AI", "cs.SE"], "comment": "12 pages, 1 figures, 1 algorithm", "summary": "Automating high-volume unstructured data processing is essential for\noperational efficiency. Optical Character Recognition (OCR) is critical but\noften struggles with accuracy and efficiency in complex layouts and ambiguous\ntext. These challenges are especially pronounced in large-scale tasks requiring\nboth speed and precision. This paper introduces LMV-RPA, a Large Model\nVoting-based Robotic Process Automation system to enhance OCR workflows.\nLMV-RPA integrates outputs from OCR engines such as Paddle OCR, Tesseract OCR,\nEasy OCR, and DocTR with Large Language Models (LLMs) like LLaMA 3 and\nGemini-1.5-pro. Using a majority voting mechanism, it processes OCR outputs\ninto structured JSON formats, improving accuracy, particularly in complex\nlayouts. The multi-phase pipeline processes text extracted by OCR engines\nthrough LLMs, combining results to ensure the most accurate outputs. LMV-RPA\nachieves 99 percent accuracy in OCR tasks, surpassing baseline models with 94\npercent, while reducing processing time by 80 percent. Benchmark evaluations\nconfirm its scalability and demonstrate that LMV-RPA offers a faster, more\nreliable, and efficient solution for automating large-scale document processing\ntasks.", "AI": {"tldr": "LMV-RPA is a system combining OCR engines and LLMs with majority voting to enhance accuracy and efficiency in processing unstructured data, achieving 99% accuracy and 80% faster processing.", "motivation": "Addressing the limitations of OCR in accuracy and efficiency for complex layouts and ambiguous text in large-scale tasks.", "method": "Integrates OCR engines (Paddle OCR, Tesseract OCR, Easy OCR, DocTR) and LLMs (LLaMA 3, Gemini-1.5-pro) using majority voting to process outputs into structured JSON.", "result": "Achieves 99% accuracy (vs. 94% baseline) and reduces processing time by 80%.", "conclusion": "LMV-RPA provides a scalable, faster, and more reliable solution for large-scale document processing."}}
{"id": "2410.19816", "pdf": "https://arxiv.org/pdf/2410.19816", "abs": "https://arxiv.org/abs/2410.19816", "authors": ["Elena Sierra", "Lauren E. Gillespie", "Salim Soltani", "Moises Exposito-Alonso", "Teja Kattenborn"], "title": "DivShift: Exploring Domain-Specific Distribution Shift in Large-Scale, Volunteer-Collected Biodiversity Datasets", "categories": ["cs.CV"], "comment": "Published at AAAI-25 AI for Social Impact Track\n  (https://ojs.aaai.org/index.php/AAAI/article/view/35060) Presented at NeurIPS\n  2024 Workshop on Tackling Climate Change with Machine Learning\n  (https://www.climatechange.ai/papers/neurips2024/43)", "summary": "Large-scale, volunteer-collected datasets of community-identified natural\nworld imagery like iNaturalist have enabled marked performance gains for\nfine-grained visual classification of species using machine learning methods.\nHowever, such data -- sometimes referred to as citizen science data -- are\nopportunistic and lack a structured sampling strategy. This volunteer-collected\nbiodiversity data contains geographic, temporal, taxonomic, observers, and\nsociopolitical biases that can have significant effects on biodiversity model\nperformance, but whose impacts are unclear for fine-grained species recognition\nperformance. Here we introduce Diversity Shift (DivShift), a framework for\nquantifying the effects of domain-specific distribution shifts on machine\nlearning model performance. To diagnose the performance effects of biases\nspecific to volunteer-collected biodiversity data, we also introduce DivShift -\nNorth American West Coast (DivShift-NAWC), a curated dataset of almost 7.5\nmillion iNaturalist images across the western coast of North America\npartitioned across five types of expert-verified bias. We compare species\nrecognition performance across these bias partitions using a diverse variety of\nspecies- and ecosystem-focused accuracy metrics. We observe that these biases\nconfound model performance less than expected from the underlying label\ndistribution shift, and that more data leads to better model performance but\nthe magnitude of these improvements are bias-specific. These findings imply\nthat while the structure within natural world images provides generalization\nimprovements for biodiversity monitoring tasks, the biases present in\nvolunteer-collected biodiversity data can also affect model performance; thus\nthese models should be used with caution in downstream biodiversity monitoring\ntasks.", "AI": {"tldr": "The paper introduces DivShift, a framework to quantify bias effects in volunteer-collected biodiversity data on ML model performance, using a curated dataset (DivShift-NAWC) to analyze biases and their impacts.", "motivation": "To understand how biases in citizen science data (e.g., geographic, temporal) affect fine-grained species recognition performance in ML models.", "method": "Introduces DivShift framework and DivShift-NAWC dataset (7.5M iNaturalist images) to partition and analyze biases. Compares species recognition performance across bias partitions using diverse metrics.", "result": "Biases confound model performance less than expected; more data improves performance, but improvements vary by bias type.", "conclusion": "While natural world images aid generalization, biases in volunteer-collected data impact model performance, warranting caution in biodiversity monitoring."}}
{"id": "2408.03626", "pdf": "https://arxiv.org/pdf/2408.03626", "abs": "https://arxiv.org/abs/2408.03626", "authors": ["Pinak Mandal", "Georg A. Gottwald", "Nicholas Cranch"], "title": "On the choice of the non-trainable internal weights in random feature maps", "categories": ["cs.LG", "physics.data-an", "stat.ME", "stat.ML"], "comment": "27 pages, 23 figures", "summary": "The computationally cheap machine learning architecture of random feature\nmaps can be viewed as a single-layer feedforward network in which the weights\nof the hidden layer are random but fixed and only the outer weights are learned\nvia linear regression. The internal weights are typically chosen from a\nprescribed distribution. The choice of the internal weights significantly\nimpacts the accuracy of random feature maps. We address here the task of how to\nbest select the internal weights. In particular, we consider the forecasting\nproblem whereby random feature maps are used to learn a one-step propagator map\nfor a dynamical system. We provide a computationally cheap hit-and-run\nalgorithm to select good internal weights which lead to good forecasting skill.\nWe show that the number of good features is the main factor controlling the\nforecasting skill of random feature maps and acts as an effective feature\ndimension. Lastly, we compare random feature maps with single-layer feedforward\nneural networks in which the internal weights are now learned using gradient\ndescent. We find that random feature maps have superior forecasting\ncapabilities whilst having several orders of magnitude lower computational\ncost.", "AI": {"tldr": "The paper proposes a hit-and-run algorithm to optimize internal weights in random feature maps for better forecasting in dynamical systems, showing superior performance and lower computational cost compared to traditional neural networks.", "motivation": "The accuracy of random feature maps heavily depends on the choice of internal weights, which are typically fixed randomly. The paper aims to improve forecasting in dynamical systems by optimizing these weights.", "method": "A computationally cheap hit-and-run algorithm is introduced to select optimal internal weights for random feature maps, focusing on forecasting dynamical systems.", "result": "The number of good features is key to forecasting skill, acting as an effective feature dimension. Random feature maps outperform traditional neural networks in forecasting while being much cheaper computationally.", "conclusion": "Random feature maps with optimized internal weights offer a cost-effective and accurate alternative to traditional neural networks for forecasting tasks."}}
{"id": "2501.02921", "pdf": "https://arxiv.org/pdf/2501.02921", "abs": "https://arxiv.org/abs/2501.02921", "authors": ["Mahmoud Abdulsalam", "Usman Zahidi", "Bradley Hurst", "Simon Pearson", "Grzegorz Cielniak", "James Brown"], "title": "Unsupervised Tomato Split Anomaly Detection using Hyperspectral Imaging and Variational Autoencoders", "categories": ["cs.CV", "cs.AI"], "comment": "CVPPA Workshop", "summary": "Tomato anomalies/damages pose a significant challenge in greenhouse farming.\nWhile this method of cultivation benefits from efficient resource utilization,\nanomalies can significantly degrade the quality of farm produce. A common\nanomaly associated with tomatoes is splitting, characterized by the development\nof cracks on the tomato skin, which degrades its quality. Detecting this type\nof anomaly is challenging due to dynamic variations in appearance and sizes,\ncompounded by dataset scarcity. We address this problem in an unsupervised\nmanner by utilizing a tailored variational autoencoder (VAE) with hyperspectral\ninput. Preliminary analysis of the dataset enabled us to select the optimal\nrange of wavelengths for detecting this anomaly. Our findings indicate that the\n530nm - 550nm range is suitable for identifying tomato dry splits. The proposed\nVAE model achieved a 97% detection accuracy for tomato split anomalies in the\ntest data. The analysis on reconstruction loss allow us to not only detect the\nanomalies but also to some degree estimate the anomalous regions.", "AI": {"tldr": "Unsupervised VAE model detects tomato split anomalies with 97% accuracy using hyperspectral data (530nm-550nm range).", "motivation": "Tomato anomalies like splitting degrade quality; detecting them is hard due to appearance variations and scarce data.", "method": "Tailored variational autoencoder (VAE) with hyperspectral input, focusing on 530nm-550nm wavelengths.", "result": "97% detection accuracy for tomato splits; reconstruction loss helps estimate anomalous regions.", "conclusion": "The VAE model effectively detects and localizes tomato split anomalies in an unsupervised manner."}}
{"id": "2411.11927", "pdf": "https://arxiv.org/pdf/2411.11927", "abs": "https://arxiv.org/abs/2411.11927", "authors": ["Anjia Cao", "Xing Wei", "Zhiheng Ma"], "title": "FLAME: Frozen Large Language Models Enable Data-Efficient Language-Image Pre-training", "categories": ["cs.CV"], "comment": null, "summary": "Language-image pre-training faces significant challenges due to limited data\nin specific formats and the constrained capacities of text encoders. While\nprevailing methods attempt to address these issues through data augmentation\nand architecture modifications, they continue to struggle with processing\nlong-form text inputs, and the inherent limitations of traditional CLIP text\nencoders lead to suboptimal downstream generalization. In this paper, we\npropose FLAME (Frozen Large lAnguage Models Enable data-efficient\nlanguage-image pre-training) that leverages frozen large language models as\ntext encoders, naturally processing long text inputs and demonstrating\nimpressive multilingual generalization. FLAME comprises two key components: 1)\na multifaceted prompt distillation technique for extracting diverse semantic\nrepresentations from long captions, which better aligns with the multifaceted\nnature of images, and 2) a facet-decoupled attention mechanism, complemented by\nan offline embedding strategy, to ensure efficient computation. Extensive\nempirical evaluations demonstrate FLAME's superior performance. When trained on\nCC3M, FLAME surpasses the previous state-of-the-art by 4.9% in ImageNet top-1\naccuracy. On YFCC15M, FLAME surpasses the WIT-400M-trained CLIP by 44.4\\% in\naverage image-to-text recall@1 across 36 languages, and by 34.6% in\ntext-to-image recall@1 for long-context retrieval on Urban-1k. Code is\navailable at https://github.com/MIV-XJTU/FLAME.", "AI": {"tldr": "FLAME uses frozen large language models as text encoders for efficient language-image pre-training, outperforming previous methods in accuracy and multilingual tasks.", "motivation": "Addressing challenges in language-image pre-training, such as limited data formats and text encoder constraints, FLAME aims to improve long-text processing and multilingual generalization.", "method": "FLAME employs multifaceted prompt distillation and facet-decoupled attention with an offline embedding strategy for efficient computation.", "result": "FLAME achieves 4.9% higher ImageNet top-1 accuracy on CC3M and outperforms CLIP by 44.4% in multilingual tasks on YFCC15M.", "conclusion": "FLAME demonstrates superior performance in language-image pre-training, particularly for long-text and multilingual applications."}}
{"id": "2408.13720", "pdf": "https://arxiv.org/pdf/2408.13720", "abs": "https://arxiv.org/abs/2408.13720", "authors": ["Mohammad Mohammadi", "Sreejita Ghosh"], "title": "A prototype-based model for set classification", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Classification of sets of inputs (e.g., images and texts) is an active area\nof research within both computer vision (CV) and natural language processing\n(NLP). A common way to represent a set of vectors is to model them as linear\nsubspaces. In this contribution, we present a prototype-based approach for\nlearning on the manifold formed from such linear subspaces, the Grassmann\nmanifold. Our proposed method learns a set of subspace prototypes capturing the\nrepresentative characteristics of classes and a set of relevance factors\nautomating the selection of the dimensionality of the subspaces. This leads to\na transparent classifier model which presents the computed impact of each input\nvector on its decision. Through experiments on benchmark image and text\ndatasets, we have demonstrated the efficiency of our proposed classifier,\ncompared to the transformer-based models in terms of not only performance and\nexplainability but also computational resource requirements.", "AI": {"tldr": "A prototype-based method for learning on the Grassmann manifold is proposed, offering efficient, explainable classification of sets of inputs like images and texts.", "motivation": "To improve classification of sets of inputs (e.g., images, texts) by leveraging linear subspaces and enhancing transparency and efficiency.", "method": "Uses subspace prototypes and relevance factors on the Grassmann manifold to automate dimensionality selection and provide explainable decisions.", "result": "Outperforms transformer-based models in performance, explainability, and computational efficiency on benchmark datasets.", "conclusion": "The proposed method is efficient, transparent, and effective for set classification tasks."}}
{"id": "2501.16347", "pdf": "https://arxiv.org/pdf/2501.16347", "abs": "https://arxiv.org/abs/2501.16347", "authors": ["Anindita Chattopadhyay", "Siddharth Bisariya", "Vijay Kumar Sutrakar"], "title": "Fast and Accurate Identification of Hardware Trojan Locations in Gate-Level Netlist using Nearest Neighbour Approach integrated with Machine Learning Technique", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In the evolving landscape of integrated circuit design, detecting Hardware\nTrojans (HTs) within a multi entity based design cycle presents significant\nchallenges. This research proposes an innovative machine learning-based\nmethodology for identifying malicious logic gates in gate-level netlists. By\nfocusing on path retrace algorithms. The methodology is validated across three\ndistinct cases, each employing different machine learning models to classify\nHTs. Case I utilizes a decision tree algorithm for node-to-node comparisons,\nsignificantly improving detection accuracy through the integration of Principal\nComponent Analysis (PCA). Case II introduces a graph-to-graph classification\nusing a Graph Neural Network (GNN) model, enabling the differentiation between\nnormal and Trojan-infected circuit designs. Case III applies GNN-based node\nclassification to identify individual compromised nodes and its location.\nAdditionally, nearest neighbor (NN) method has been combined with GNN\ngraph-to-graph in Case II and GNN node-to-node in Case III. Despite the\npotential of GNN model graph-to-graph classification, NN approach demonstrated\nsuperior performance, with the first nearest neighbor (1st NN) achieving 73.2%\naccuracy and the second nearest neighbor (2nd NN) method reaching 97.7%. In\ncomparison, the GNN model achieved an accuracy of 62.8%. Similarly, GNN model\nnode-to-node classification, NN approach demonstrated superior performance,\nwith the 1st NN achieving 93% accuracy and the 2nd NN method reaching 97.7%. In\ncomparison, the GNN model achieved an accuracy of 79.8%. However, higher and\nhigher NN will lead to large code coverage for the identification of HTs.", "AI": {"tldr": "A machine learning-based method for detecting Hardware Trojans (HTs) in gate-level netlists is proposed, using path retrace algorithms and validated across three cases with different models. The nearest neighbor (NN) method outperformed Graph Neural Networks (GNNs) in accuracy.", "motivation": "The challenge of detecting HTs in multi-entity integrated circuit designs necessitates innovative solutions to identify malicious logic gates.", "method": "Three cases were tested: Case I used decision trees with PCA, Case II employed GNNs for graph-to-graph classification, and Case III used GNNs for node-to-node classification. NN methods were also integrated.", "result": "NN methods outperformed GNNs, with 2nd NN achieving 97.7% accuracy in both graph-to-graph and node-to-node classifications, compared to GNNs' lower accuracies. However, higher NN methods increase code coverage.", "conclusion": "The NN approach is more effective for HT detection than GNNs, but scalability concerns arise with higher NN methods due to increased code coverage."}}
{"id": "2411.18808", "pdf": "https://arxiv.org/pdf/2411.18808", "abs": "https://arxiv.org/abs/2411.18808", "authors": ["Jiaman Li", "C. Karen Liu", "Jiajun Wu"], "title": "Lifting Motion to the 3D World via 2D Diffusion", "categories": ["cs.CV"], "comment": "CVPR 2025 (Highlight), project page:\n  https://lijiaman.github.io/projects/mvlift/", "summary": "Estimating 3D motion from 2D observations is a long-standing research\nchallenge. Prior work typically requires training on datasets containing ground\ntruth 3D motions, limiting their applicability to activities well-represented\nin existing motion capture data. This dependency particularly hinders\ngeneralization to out-of-distribution scenarios or subjects where collecting 3D\nground truth is challenging, such as complex athletic movements or animal\nmotion. We introduce MVLift, a novel approach to predict global 3D motion --\nincluding both joint rotations and root trajectories in the world coordinate\nsystem -- using only 2D pose sequences for training. Our multi-stage framework\nleverages 2D motion diffusion models to progressively generate consistent 2D\npose sequences across multiple views, a key step in recovering accurate global\n3D motion. MVLift generalizes across various domains, including human poses,\nhuman-object interactions, and animal poses. Despite not requiring 3D\nsupervision, it outperforms prior work on five datasets, including those\nmethods that require 3D supervision.", "AI": {"tldr": "MVLift predicts 3D motion from 2D poses without 3D supervision, outperforming methods that rely on 3D data.", "motivation": "Overcome limitations of prior work requiring 3D ground truth, enabling generalization to out-of-distribution scenarios like athletic or animal motion.", "method": "Multi-stage framework using 2D motion diffusion models to generate consistent 2D pose sequences across views for accurate 3D motion recovery.", "result": "Outperforms prior work on five datasets, even those using 3D supervision, and generalizes across human, human-object, and animal poses.", "conclusion": "MVLift advances 3D motion estimation by eliminating the need for 3D supervision while improving accuracy and generalization."}}
{"id": "2409.09990", "pdf": "https://arxiv.org/pdf/2409.09990", "abs": "https://arxiv.org/abs/2409.09990", "authors": ["Amogh Joshi", "Adarsh Kumar Kosta", "Kaushik Roy"], "title": "SHIRE: Enhancing Sample Efficiency using Human Intuition in REinforcement Learning", "categories": ["cs.LG", "cs.NE", "cs.RO"], "comment": "Accepted for publication at the IEEE International Conference on\n  Robotics & Automation (ICRA) 2025", "summary": "The ability of neural networks to perform robotic perception and control\ntasks such as depth and optical flow estimation, simultaneous localization and\nmapping (SLAM), and automatic control has led to their widespread adoption in\nrecent years. Deep Reinforcement Learning has been used extensively in these\nsettings, as it does not have the unsustainable training costs associated with\nsupervised learning. However, DeepRL suffers from poor sample efficiency, i.e.,\nit requires a large number of environmental interactions to converge to an\nacceptable solution. Modern RL algorithms such as Deep Q Learning and Soft\nActor-Critic attempt to remedy this shortcoming but can not provide the\nexplainability required in applications such as autonomous robotics. Humans\nintuitively understand the long-time-horizon sequential tasks common in\nrobotics. Properly using such intuition can make RL policies more explainable\nwhile enhancing their sample efficiency. In this work, we propose SHIRE, a\nnovel framework for encoding human intuition using Probabilistic Graphical\nModels (PGMs) and using it in the Deep RL training pipeline to enhance sample\nefficiency. Our framework achieves 25-78% sample efficiency gains across the\nenvironments we evaluate at negligible overhead cost. Additionally, by teaching\nRL agents the encoded elementary behavior, SHIRE enhances policy\nexplainability. A real-world demonstration further highlights the efficacy of\npolicies trained using our framework.", "AI": {"tldr": "SHIRE is a framework combining human intuition (via PGMs) with Deep RL to improve sample efficiency and explainability in robotic tasks.", "motivation": "Deep RL lacks sample efficiency and explainability, which are critical for robotics. Human intuition can address these gaps.", "method": "SHIRE encodes human intuition using Probabilistic Graphical Models (PGMs) and integrates it into Deep RL training.", "result": "Achieves 25-78% sample efficiency gains with negligible overhead and enhances policy explainability.", "conclusion": "SHIRE effectively bridges the gap between human intuition and Deep RL, improving performance and explainability in robotics."}}
{"id": "2501.17567", "pdf": "https://arxiv.org/pdf/2501.17567", "abs": "https://arxiv.org/abs/2501.17567", "authors": ["Emmanuel Irabor", "Mariam Musavi", "Abhijit Das", "Sergi Abadal"], "title": "Exploring the Potential of Wireless-enabled Multi-Chip AI Accelerators", "categories": ["cs.AR", "cs.AI"], "comment": "Accepted in AccML @ HiPEAC 2025", "summary": "The insatiable appetite of Artificial Intelligence (AI) workloads for\ncomputing power is pushing the industry to develop faster and more efficient\naccelerators. The rigidity of custom hardware, however, conflicts with the need\nfor scalable and versatile architectures capable of catering to the needs of\nthe evolving and heterogeneous pool of Machine Learning (ML) models in the\nliterature. In this context, multi-chiplet architectures assembling multiple\n(perhaps heterogeneous) accelerators are an appealing option that is\nunfortunately hindered by the still rigid and inefficient chip-to-chip\ninterconnects. In this paper, we explore the potential of wireless technology\nas a complement to existing wired interconnects in this multi-chiplet approach.\nUsing an evaluation framework from the state-of-the-art, we show that wireless\ninterconnects can lead to speedups of 10% on average and 20% maximum. We also\nhighlight the importance of load balancing between the wired and wireless\ninterconnects, which will be further explored in future work.", "AI": {"tldr": "The paper explores wireless interconnects as a complement to wired ones in multi-chiplet AI accelerators, showing potential speedups of 10-20%.", "motivation": "The rigidity of custom hardware and inefficient chip-to-chip interconnects limit scalability and versatility for evolving ML models.", "method": "The study evaluates wireless technology alongside wired interconnects using a state-of-the-art framework.", "result": "Wireless interconnects achieve average speedups of 10% and peak speedups of 20%.", "conclusion": "Wireless interconnects show promise, with load balancing between wired and wireless links identified as a key area for future research."}}
{"id": "2411.18968", "pdf": "https://arxiv.org/pdf/2411.18968", "abs": "https://arxiv.org/abs/2411.18968", "authors": ["Nardiena A. Pratama", "Shaoyang Fan", "Gianluca Demartini"], "title": "Perception of Visual Content: Differences Between Humans and Foundation Models", "categories": ["cs.CV", "cs.LG"], "comment": "12 pages (including references), 5 figures, 5 tables, and a\n  paper/ethics checklist. Camera-Ready Copy for ICWSM 2025. This version uses\n  the same results as the previously posted revise-and-resubmit version.\n  Changes are mostly formatting adjustments", "summary": "Human-annotated content is often used to train machine learning (ML) models.\nHowever, recently, language and multi-modal foundational models have been used\nto replace and scale-up human annotator's efforts. This study explores the\nsimilarity between human-generated and ML-generated annotations of images\nacross diverse socio-economic contexts (RQ1) and their impact on ML model\nperformance and bias (RQ2). We aim to understand differences in perception and\nidentify potential biases in content interpretation. Our dataset comprises\nimages of people from various geographical regions and income levels, covering\nvarious daily activities and home environments. ML captions and human labels\nshow highest similarity at a low-level, i.e., types of words that appear and\nsentence structures, but all annotations are consistent in how they perceive\nimages across regions. ML Captions resulted in best overall region\nclassification performance, while ML Objects and ML Captions performed best\noverall for income regression. ML annotations worked best for action\ncategories, while human input was more effective for non-action categories.\nThese findings highlight the notion that both human and machine annotations are\nimportant, and that human-generated annotations are yet to be replaceable.", "AI": {"tldr": "The study compares human and ML-generated image annotations, finding similarities in low-level features but differences in performance and bias. ML excels in region classification and income regression, while human annotations are better for non-action categories.", "motivation": "To explore the similarity between human and ML-generated annotations and their impact on ML model performance and bias, especially across diverse socio-economic contexts.", "method": "Analyzed images from various regions and income levels, comparing human labels and ML captions for perception and bias.", "result": "ML captions showed high similarity to human labels in low-level features but performed better in region classification and income regression. Human annotations were superior for non-action categories.", "conclusion": "Both human and ML annotations are valuable, with human input still irreplaceable for certain tasks."}}
{"id": "2410.06140", "pdf": "https://arxiv.org/pdf/2410.06140", "abs": "https://arxiv.org/abs/2410.06140", "authors": ["Barak Gahtan", "Robert J. Shahla", "Reuven Cohen", "Alex M. Bronstein"], "title": "Estimating the Number of HTTP/3 Responses in QUIC Using Deep Learning", "categories": ["cs.LG", "cs.CV", "cs.NI"], "comment": null, "summary": "QUIC, a new and increasingly used transport protocol, enhances TCP by\noffering improved security, performance, and stream multiplexing. These\nfeatures, however, also impose challenges for network middle-boxes that need to\nmonitor and analyze web traffic. This paper proposes a novel method to estimate\nthe number of HTTP/3 responses in a given QUIC connection by an observer. This\nestimation reveals server behavior, client-server interactions, and data\ntransmission efficiency, which is crucial for various applications such as\ndesigning a load balancing solution and detecting HTTP/3 flood attacks. The\nproposed scheme transforms QUIC connection traces into image sequences and uses\nmachine learning (ML) models, guided by a tailored loss function, to predict\nresponse counts. Evaluations on more than seven million images-derived from\n100,000 traces collected across 44,000 websites over four months-achieve up to\n97% accuracy in both known and unknown server settings and 92% accuracy on\npreviously unseen complete QUIC traces.", "AI": {"tldr": "The paper proposes a machine learning-based method to estimate HTTP/3 responses in QUIC connections, achieving high accuracy for network monitoring and security applications.", "motivation": "QUIC's features challenge network middle-boxes, necessitating methods to monitor and analyze web traffic for applications like load balancing and attack detection.", "method": "Transform QUIC connection traces into image sequences and use ML models with a tailored loss function to predict response counts.", "result": "Achieves up to 97% accuracy in known/unknown server settings and 92% accuracy on unseen QUIC traces.", "conclusion": "The method effectively estimates HTTP/3 responses, aiding in network monitoring and security."}}
{"id": "2502.01143", "pdf": "https://arxiv.org/pdf/2502.01143", "abs": "https://arxiv.org/abs/2502.01143", "authors": ["Tairan He", "Jiawei Gao", "Wenli Xiao", "Yuanhang Zhang", "Zi Wang", "Jiashun Wang", "Zhengyi Luo", "Guanqi He", "Nikhil Sobanbab", "Chaoyi Pan", "Zeji Yi", "Guannan Qu", "Kris Kitani", "Jessica Hodgins", "Linxi \"Jim\" Fan", "Yuke Zhu", "Changliu Liu", "Guanya Shi"], "title": "ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "RSS 2025. Project website: https://agile.human2humanoid.com/", "summary": "Humanoid robots hold the potential for unparalleled versatility in performing\nhuman-like, whole-body skills. However, achieving agile and coordinated\nwhole-body motions remains a significant challenge due to the dynamics mismatch\nbetween simulation and the real world. Existing approaches, such as system\nidentification (SysID) and domain randomization (DR) methods, often rely on\nlabor-intensive parameter tuning or result in overly conservative policies that\nsacrifice agility. In this paper, we present ASAP (Aligning Simulation and\nReal-World Physics), a two-stage framework designed to tackle the dynamics\nmismatch and enable agile humanoid whole-body skills. In the first stage, we\npre-train motion tracking policies in simulation using retargeted human motion\ndata. In the second stage, we deploy the policies in the real world and collect\nreal-world data to train a delta (residual) action model that compensates for\nthe dynamics mismatch. Then, ASAP fine-tunes pre-trained policies with the\ndelta action model integrated into the simulator to align effectively with\nreal-world dynamics. We evaluate ASAP across three transfer scenarios: IsaacGym\nto IsaacSim, IsaacGym to Genesis, and IsaacGym to the real-world Unitree G1\nhumanoid robot. Our approach significantly improves agility and whole-body\ncoordination across various dynamic motions, reducing tracking error compared\nto SysID, DR, and delta dynamics learning baselines. ASAP enables highly agile\nmotions that were previously difficult to achieve, demonstrating the potential\nof delta action learning in bridging simulation and real-world dynamics. These\nresults suggest a promising sim-to-real direction for developing more\nexpressive and agile humanoids.", "AI": {"tldr": "ASAP is a two-stage framework to align simulation and real-world physics for agile humanoid robot skills, reducing tracking error and improving coordination.", "motivation": "Addressing the dynamics mismatch between simulation and real-world for humanoid robots, overcoming limitations of SysID and DR methods.", "method": "1) Pre-train motion tracking policies in simulation using human motion data. 2) Deploy in real-world, collect data, and train a delta action model to compensate for dynamics mismatch. Fine-tune policies with the delta model.", "result": "ASAP improves agility and coordination, reducing tracking error compared to baselines (SysID, DR, delta dynamics). Enables previously difficult agile motions.", "conclusion": "ASAP demonstrates delta action learning's potential to bridge simulation and real-world dynamics, advancing agile humanoid development."}}
{"id": "2412.12091", "pdf": "https://arxiv.org/pdf/2412.12091", "abs": "https://arxiv.org/abs/2412.12091", "authors": ["Hanwen Liang", "Junli Cao", "Vidit Goel", "Guocheng Qian", "Sergei Korolev", "Demetri Terzopoulos", "Konstantinos N. Plataniotis", "Sergey Tulyakov", "Jian Ren"], "title": "Wonderland: Navigating 3D Scenes from a Single Image", "categories": ["cs.CV"], "comment": "Project page: https://snap-research.github.io/wonderland/", "summary": "How can one efficiently generate high-quality, wide-scope 3D scenes from\narbitrary single images? Existing methods suffer several drawbacks, such as\nrequiring multi-view data, time-consuming per-scene optimization, distorted\ngeometry in occluded areas, and low visual quality in backgrounds. Our novel 3D\nscene reconstruction pipeline overcomes these limitations to tackle the\naforesaid challenge. Specifically, we introduce a large-scale reconstruction\nmodel that leverages latents from a video diffusion model to predict 3D\nGaussian Splattings of scenes in a feed-forward manner. The video diffusion\nmodel is designed to create videos precisely following specified camera\ntrajectories, allowing it to generate compressed video latents that encode\nmulti-view information while maintaining 3D consistency. We train the 3D\nreconstruction model to operate on the video latent space with a progressive\nlearning strategy, enabling the efficient generation of high-quality,\nwide-scope, and generic 3D scenes. Extensive evaluations across various\ndatasets affirm that our model significantly outperforms existing single-view\n3D scene generation methods, especially with out-of-domain images. Thus, we\ndemonstrate for the first time that a 3D reconstruction model can effectively\nbe built upon the latent space of a diffusion model in order to realize\nefficient 3D scene generation.", "AI": {"tldr": "A novel 3D scene reconstruction pipeline uses a video diffusion model's latents to predict 3D Gaussian Splattings, enabling efficient, high-quality, wide-scope 3D scene generation from single images.", "motivation": "Existing methods for 3D scene generation from single images face issues like multi-view data requirements, slow optimization, distorted geometry, and poor background quality. This work aims to overcome these limitations.", "method": "The pipeline leverages a video diffusion model to generate multi-view consistent latents, which are used to train a 3D reconstruction model for predicting 3D Gaussian Splattings in a feed-forward manner.", "result": "The model outperforms existing single-view 3D generation methods, especially with out-of-domain images, demonstrating high-quality and efficient scene generation.", "conclusion": "This work shows that a 3D reconstruction model can effectively use a diffusion model's latent space for efficient and high-quality 3D scene generation."}}
{"id": "2410.10243", "pdf": "https://arxiv.org/pdf/2410.10243", "abs": "https://arxiv.org/abs/2410.10243", "authors": ["Lothar Sebastian Krapp", "Laura Wirth"], "title": "Measurability in the Fundamental Theorem of Statistical Learning", "categories": ["cs.LG", "cs.LO", "math.LO", "math.PR", "stat.ML", "Primary 68T05, 03C64, Secondary 28A05, 28A20, 03C98, 68T27, 12J15"], "comment": "42 pages plus appendix", "summary": "The Fundamental Theorem of Statistical Learning states that a hypothesis\nspace is PAC learnable if and only if its VC dimension is finite. For the\nagnostic model of PAC learning, the literature so far presents proofs of this\ntheorem that often tacitly impose several measurability assumptions on the\ninvolved sets and functions. We scrutinize these proofs from a\nmeasure-theoretic perspective in order to explicitly extract the assumptions\nneeded for a rigorous argument. This leads to a sound statement as well as a\ndetailed and self-contained proof of the Fundamental Theorem of Statistical\nLearning in the agnostic setting, showcasing the minimal measurability\nrequirements needed. As the Fundamental Theorem of Statistical Learning\nunderpins a wide range of further theoretical developments, our results are of\nfoundational importance: A careful analysis of measurability aspects is\nessential, especially when the theorem is used in settings where\nmeasure-theoretic subtleties play a role. We particularly discuss applications\nin Model Theory, considering NIP and o-minimal structures. Our main theorem\npresents sufficient conditions for the PAC learnability of hypothesis spaces\ndefined over o-minimal expansions of the reals. This class of hypothesis spaces\ncovers all artificial neural networks for binary classification that use\ncommonly employed activation functions like ReLU and the sigmoid function.", "AI": {"tldr": "The paper rigorously analyzes the Fundamental Theorem of Statistical Learning in the agnostic PAC model, clarifying minimal measurability assumptions and proving its validity. It also extends applications to Model Theory, particularly for NIP and o-minimal structures.", "motivation": "To address the tacit measurability assumptions in existing proofs of the Fundamental Theorem of Statistical Learning and provide a rigorous, self-contained proof with minimal requirements.", "method": "Scrutinizing existing proofs from a measure-theoretic perspective to extract explicit assumptions and presenting a detailed proof for the agnostic PAC learning setting.", "result": "A sound statement and proof of the Fundamental Theorem of Statistical Learning with minimal measurability requirements, applicable to Model Theory and hypothesis spaces like neural networks.", "conclusion": "The careful analysis of measurability is foundational for theoretical developments, especially in settings like Model Theory and neural networks, where measure-theoretic subtleties matter."}}
{"id": "2502.02772", "pdf": "https://arxiv.org/pdf/2502.02772", "abs": "https://arxiv.org/abs/2502.02772", "authors": ["Ravi Tejwani", "Karl Velazquez", "John Payne", "Paolo Bonato", "Harry Asada"], "title": "Cross-modality Force and Language Embeddings for Natural Human-Robot Communication", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": "Under review in RSS 2025", "summary": "A method for cross-modality embedding of force profile and words is presented\nfor synergistic coordination of verbal and haptic communication. When two\npeople carry a large, heavy object together, they coordinate through verbal\ncommunication about the intended movements and physical forces applied to the\nobject. This natural integration of verbal and physical cues enables effective\ncoordination. Similarly, human-robot interaction could achieve this level of\ncoordination by integrating verbal and haptic communication modalities. This\npaper presents a framework for embedding words and force profiles in a unified\nmanner, so that the two communication modalities can be integrated and\ncoordinated in a way that is effective and synergistic. Here, it will be shown\nthat, although language and physical force profiles are deemed completely\ndifferent, the two can be embedded in a unified latent space and proximity\nbetween the two can be quantified. In this latent space, a force profile and\nwords can a) supplement each other, b) integrate the individual effects, and c)\nsubstitute in an exchangeable manner. First, the need for cross-modality\nembedding is addressed, and the basic architecture and key building block\ntechnologies are presented. Methods for data collection and implementation\nchallenges will be addressed, followed by experimental results and discussions.", "AI": {"tldr": "A method for embedding force profiles and words in a unified latent space to enhance human-robot coordination through verbal and haptic communication.", "motivation": "To achieve synergistic coordination in human-robot interaction by integrating verbal and haptic communication, inspired by natural human coordination during collaborative tasks.", "method": "Develops a framework for cross-modality embedding, mapping words and force profiles into a shared latent space, enabling quantification of their proximity and interaction.", "result": "Demonstrates that language and force profiles can be embedded together, allowing them to supplement, integrate, or substitute each other effectively.", "conclusion": "The framework successfully enables synergistic coordination between verbal and haptic communication, paving the way for more natural human-robot interaction."}}
{"id": "2412.20047", "pdf": "https://arxiv.org/pdf/2412.20047", "abs": "https://arxiv.org/abs/2412.20047", "authors": ["Phi Vu Tran"], "title": "SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection", "categories": ["cs.CV", "cs.LG"], "comment": "CVPR 2025. The reference code is available at\n  https://github.com/lexisnexis-risk-open-source/simltd", "summary": "While modern visual recognition systems have made significant advancements,\nmany continue to struggle with the open problem of learning from few exemplars.\nThis paper focuses on the task of object detection in the setting where object\nclasses follow a natural long-tailed distribution. Existing methods for\nlong-tailed detection resort to external ImageNet labels to augment the\nlow-shot training instances. However, such dependency on a large labeled\ndatabase has limited utility in practical scenarios. We propose a versatile and\nscalable approach to leverage optional unlabeled images, which are easy to\ncollect without the burden of human annotations. Our SimLTD framework is\nstraightforward and intuitive, and consists of three simple steps: (1)\npre-training on abundant head classes; (2) transfer learning on scarce tail\nclasses; and (3) fine-tuning on a sampled set of both head and tail classes.\nOur approach can be viewed as an improved head-to-tail model transfer paradigm\nwithout the added complexities of meta-learning or knowledge distillation, as\nwas required in past research. By harnessing supplementary unlabeled images,\nwithout extra image labels, SimLTD establishes new record results on the\nchallenging LVIS v1 benchmark across both supervised and semi-supervised\nsettings.", "AI": {"tldr": "SimLTD is a simple, scalable framework for long-tailed object detection, leveraging unlabeled images to improve performance without complex methods like meta-learning.", "motivation": "Existing methods rely on large labeled datasets, which are impractical. SimLTD aims to use unlabeled data for better scalability.", "method": "Three-step approach: pre-training on head classes, transfer learning on tail classes, and fine-tuning on a mix of head and tail classes.", "result": "Achieves state-of-the-art results on LVIS v1 benchmark in supervised and semi-supervised settings.", "conclusion": "SimLTD offers a practical, effective solution for long-tailed detection without dependency on extensive labeled data."}}
{"id": "2410.18352", "pdf": "https://arxiv.org/pdf/2410.18352", "abs": "https://arxiv.org/abs/2410.18352", "authors": ["Jong-Ik Park", "Srinivasa Pranav", "Jos\u00e9 M. F. Moura", "Carlee Joe-Wong"], "title": "FedBaF: Federated Learning Aggregation Biased by a Foundation Model", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": "To be published at The 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2025)", "summary": "Foundation models are now a major focus of leading technology organizations\ndue to their ability to generalize across diverse tasks. Existing approaches\nfor adapting foundation models to new applications often rely on Federated\nLearning (FL) and disclose the foundation model weights to clients when using\nit to initialize the global model. While these methods ensure client data\nprivacy, they compromise model and information security. In this paper, we\nintroduce Federated Learning Aggregation Biased by a Foundation Model (FedBaF),\na novel method for dynamically integrating pre-trained foundation model weights\nduring the FL aggregation phase. Unlike conventional methods, FedBaF preserves\nthe confidentiality of the foundation model while still leveraging its power to\ntrain more accurate models, especially in non-IID and adversarial scenarios.\nOur comprehensive experiments use Pre-ResNet and foundation models like Vision\nTransformer to demonstrate that FedBaF not only matches, but often surpasses\nthe test accuracy of traditional weight initialization methods by up to 11.4%\nin IID and up to 15.8% in non-IID settings. Additionally, FedBaF applied to a\nTransformer-based language model significantly reduced perplexity by up to\n39.2%.", "AI": {"tldr": "FedBaF is a new FL method that integrates pre-trained foundation model weights during aggregation, preserving model confidentiality while improving accuracy in IID and non-IID settings.", "motivation": "Existing FL methods compromise model security by disclosing foundation model weights. FedBaF aims to address this while enhancing performance.", "method": "FedBaF dynamically integrates foundation model weights during FL aggregation, avoiding direct weight disclosure.", "result": "FedBaF improves test accuracy by up to 11.4% (IID) and 15.8% (non-IID), and reduces perplexity by 39.2% in language models.", "conclusion": "FedBaF successfully balances model security and performance, outperforming traditional FL methods."}}
{"id": "2502.03962", "pdf": "https://arxiv.org/pdf/2502.03962", "abs": "https://arxiv.org/abs/2502.03962", "authors": ["Vincenzo Lipardi", "Domenica Dibenedetto", "Georgios Stamoulis", "Mark H. M. Winands"], "title": "Quantum Circuit Design using a Progressive Widening Enhanced Monte Carlo Tree Search", "categories": ["quant-ph", "cs.AI", "cs.ET"], "comment": null, "summary": "The performance of Variational Quantum Algorithms (VQAs) strongly depends on\nthe choice of the parameterized quantum circuit to optimize. One of the biggest\nchallenges in VQAs is designing quantum circuits tailored to the particular\nproblem. This article proposes a gradient-free Monte Carlo Tree Search (MCTS)\ntechnique to automate the process of quantum circuit design. Our proposed\ntechnique introduces a novel formulation of the action space based on a\nsampling scheme and a progressive widening technique to explore the space\ndynamically. When testing our MCTS approach on the domain of random quantum\ncircuits, MCTS approximates unstructured circuits under different values of\nstabilizer R\\'enyi entropy. It turns out that MCTS manages to approximate the\nbenchmark quantum states independently from their degree of nonstabilizerness.\nNext, our technique exhibits robustness across various application domains,\nincluding quantum chemistry and systems of linear equations. Compared to\nprevious MCTS research, our technique reduces the number of quantum circuit\nevaluations by a factor of 10 up to 100 while achieving equal or better\nresults. In addition, the resulting quantum circuits exhibit up to three times\nfewer CNOT gates, which is important for implementation on noisy quantum\nhardware.", "AI": {"tldr": "A gradient-free Monte Carlo Tree Search (MCTS) technique is proposed to automate quantum circuit design for VQAs, reducing evaluations and CNOT gates while maintaining performance.", "motivation": "The challenge of designing tailored quantum circuits for VQAs motivates the need for automated, efficient methods.", "method": "A novel MCTS approach with a sampling-based action space and progressive widening dynamically explores circuit designs.", "result": "MCTS approximates benchmark states robustly, reduces evaluations by 10-100x, and cuts CNOT gates by up to 3x.", "conclusion": "The technique is effective across domains, offering efficiency and practicality for noisy quantum hardware."}}
{"id": "2501.01695", "pdf": "https://arxiv.org/pdf/2501.01695", "abs": "https://arxiv.org/abs/2501.01695", "authors": ["Chenhao Zhang", "Yuanping Cao", "Lei Zhang"], "title": "CrossView-GS: Cross-view Gaussian Splatting For Large-scale Scene Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) leverages densely distributed Gaussian\nprimitives for high-quality scene representation and reconstruction. While\nexisting 3DGS methods perform well in scenes with minor view variation, large\nview changes from cross-view data pose optimization challenges for these\nmethods. To address these issues, we propose a novel cross-view Gaussian\nSplatting method for large-scale scene reconstruction based on multi-branch\nconstruction and fusion. Our method independently reconstructs models from\ndifferent sets of views as multiple independent branches to establish the\nbaselines of Gaussian distribution, providing reliable priors for cross-view\nreconstruction during initialization and densification. Specifically, a\ngradient-aware regularization strategy is introduced to mitigate smoothing\nissues caused by significant view disparities. Additionally, a unique Gaussian\nsupplementation strategy is utilized to incorporate complementary information\nof multi-branch into the cross-view model. Extensive experiments on benchmark\ndatasets demonstrate that our method achieves superior performance in novel\nview synthesis compared to state-of-the-art methods.", "AI": {"tldr": "A novel cross-view Gaussian Splatting method improves large-scale scene reconstruction by using multi-branch construction, gradient-aware regularization, and Gaussian supplementation to handle view disparities.", "motivation": "Existing 3DGS methods struggle with large view changes in cross-view data, limiting their effectiveness in large-scale scene reconstruction.", "method": "Proposes multi-branch reconstruction, gradient-aware regularization, and Gaussian supplementation to optimize cross-view Gaussian Splatting.", "result": "Achieves superior performance in novel view synthesis compared to state-of-the-art methods.", "conclusion": "The method effectively addresses challenges in cross-view reconstruction, enhancing 3DGS for large-scale scenes."}}
{"id": "2410.19665", "pdf": "https://arxiv.org/pdf/2410.19665", "abs": "https://arxiv.org/abs/2410.19665", "authors": ["Hongjia Wu", "Hui Zeng", "Zehui Xiong", "Jiawen Kang", "Zhiping Cai", "Tse-Tin Chan", "Dusit Niyato", "Zhu Han"], "title": "MetaTrading: An Immersion-Aware Model Trading Framework for Vehicular Metaverse Services", "categories": ["cs.LG", "cs.CR", "cs.GT"], "comment": null, "summary": "Timely updating of Internet of Things (IoT) data is crucial for immersive\nvehicular metaverse services. However, challenges such as latency caused by\nmassive data transmissions, privacy risks associated with user data, and\ncomputational burdens on metaverse service providers (MSPs) hinder continuous\ncollection of high-quality data. To address these issues, we propose an\nimmersion-aware model trading framework that facilitates data provision for\nservices while ensuring privacy through federated learning (FL). Specifically,\nwe first develop a novel multi-dimensional metric, the immersion of model\n(IoM), which assesses model value comprehensively by considering freshness and\naccuracy of learning models, as well as the amount and potential value of raw\ndata used for training. Then, we design an incentive mechanism to incentivize\nmetaverse users (MUs) to contribute high-value models under resource\nconstraints. The trading interactions between MSPs and MUs are modeled as an\nequilibrium problem with equilibrium constraints (EPEC) to analyze and balance\ntheir costs and gains, where MSPs as leaders determine rewards, while MUs as\nfollowers optimize resource allocation. Furthermore, considering dynamic\nnetwork conditions and privacy concerns, we formulate the reward decisions of\nMSPs as a multi-agent Markov decision process. To solve this, we develop a\nfully distributed dynamic reward algorithm based on deep reinforcement\nlearning, without accessing any private information about MUs and other MSPs.\nExperimental results demonstrate that the proposed framework outperforms\nstate-of-the-art benchmarks, achieving improvements in IoM of 38.3% and 37.2%,\nand reductions in training time to reach the target accuracy of 43.5% and\n49.8%, on average, for the MNIST and GTSRB datasets, respectively.", "AI": {"tldr": "The paper proposes an immersion-aware model trading framework for IoT data in vehicular metaverse services, using federated learning for privacy and a novel IoM metric to assess model value. An incentive mechanism and dynamic reward algorithm improve performance and reduce training time.", "motivation": "Challenges like latency, privacy risks, and computational burdens hinder high-quality IoT data collection for vehicular metaverse services.", "method": "Develops the IoM metric, designs an incentive mechanism, models interactions as an EPEC problem, and formulates reward decisions as a multi-agent Markov decision process solved with deep reinforcement learning.", "result": "Outperforms benchmarks with 38.3% and 37.2% improvements in IoM, and 43.5% and 49.8% reductions in training time for MNIST and GTSRB datasets.", "conclusion": "The framework effectively balances privacy, efficiency, and performance in IoT data collection for metaverse services."}}
{"id": "2502.08449", "pdf": "https://arxiv.org/pdf/2502.08449", "abs": "https://arxiv.org/abs/2502.08449", "authors": ["Yankai Fu", "Qiuxuan Feng", "Ning Chen", "Zichen Zhou", "Mengzhen Liu", "Mingdong Wu", "Tianxing Chen", "Shanyu Rong", "Jiaming Liu", "Hao Dong", "Shanghang Zhang"], "title": "CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World", "categories": ["cs.RO", "cs.AI"], "comment": "Robotics: Science and Systems (RSS) 2025. Videos, code:\n  https://aureleopku.github.io/CordViP", "summary": "Achieving human-level dexterity in robots is a key objective in the field of\nrobotic manipulation. Recent advancements in 3D-based imitation learning have\nshown promising results, providing an effective pathway to achieve this goal.\nHowever, obtaining high-quality 3D representations presents two key problems:\n(1) the quality of point clouds captured by a single-view camera is\nsignificantly affected by factors such as camera resolution, positioning, and\nocclusions caused by the dexterous hand; (2) the global point clouds lack\ncrucial contact information and spatial correspondences, which are necessary\nfor fine-grained dexterous manipulation tasks. To eliminate these limitations,\nwe propose CordViP, a novel framework that constructs and learns\ncorrespondences by leveraging the robust 6D pose estimation of objects and\nrobot proprioception. Specifically, we first introduce the interaction-aware\npoint clouds, which establish correspondences between the object and the hand.\nThese point clouds are then used for our pre-training policy, where we also\nincorporate object-centric contact maps and hand-arm coordination information,\neffectively capturing both spatial and temporal dynamics. Our method\ndemonstrates exceptional dexterous manipulation capabilities, achieving\nstate-of-the-art performance in six real-world tasks, surpassing other\nbaselines by a large margin. Experimental results also highlight the superior\ngeneralization and robustness of CordViP to different objects, viewpoints, and\nscenarios. Code and videos are available on\nhttps://aureleopku.github.io/CordViP.", "AI": {"tldr": "CordViP is a novel framework for dexterous robotic manipulation, addressing limitations in 3D representations by leveraging 6D pose estimation and proprioception. It achieves state-of-the-art performance in real-world tasks.", "motivation": "Human-level dexterity in robots is challenging due to poor-quality 3D representations and missing contact/spatial information in point clouds.", "method": "CordViP constructs interaction-aware point clouds, uses object-centric contact maps, and incorporates hand-arm coordination for pre-training policies.", "result": "The framework outperforms baselines in six real-world tasks, showing superior generalization and robustness.", "conclusion": "CordViP effectively addresses key limitations in 3D-based imitation learning, advancing dexterous manipulation capabilities."}}
{"id": "2502.01776", "pdf": "https://arxiv.org/pdf/2502.01776", "abs": "https://arxiv.org/abs/2502.01776", "authors": ["Haocheng Xi", "Shuo Yang", "Yilong Zhao", "Chenfeng Xu", "Muyang Li", "Xiuyu Li", "Yujun Lin", "Han Cai", "Jintao Zhang", "Dacheng Li", "Jianfei Chen", "Ion Stoica", "Kurt Keutzer", "Song Han"], "title": "Sparse VideoGen: Accelerating Video Diffusion Transformers with Spatial-Temporal Sparsity", "categories": ["cs.CV", "cs.LG"], "comment": "17 pages, 11 figures, 3 tables", "summary": "Diffusion Transformers (DiTs) dominate video generation but their high\ncomputational cost severely limits real-world applicability, usually requiring\ntens of minutes to generate a few seconds of video even on high-performance\nGPUs. This inefficiency primarily arises from the quadratic computational\ncomplexity of 3D Full Attention with respect to the context length. In this\npaper, we propose a training-free framework termed Sparse VideoGen (SVG) that\nleverages the inherent sparsity in 3D Full Attention to boost inference\nefficiency. We reveal that the attention heads can be dynamically classified\ninto two groups depending on distinct sparse patterns: (1) Spatial Head, where\nonly spatially-related tokens within each frame dominate the attention output,\nand (2) Temporal Head, where only temporally-related tokens across different\nframes dominate. Based on this insight, SVG proposes an online profiling\nstrategy to capture the dynamic sparse patterns and predicts the type of\nattention head. Combined with a novel hardware-efficient tensor layout\ntransformation and customized kernel implementations, SVG achieves up to 2.28x\nand 2.33x end-to-end speedup on CogVideoX-v1.5 and HunyuanVideo, respectively,\nwhile preserving generation quality. Our code is open-sourced and is available\nat https://github.com/svg-project/Sparse-VideoGen", "AI": {"tldr": "SVG improves video generation efficiency by leveraging sparsity in 3D Full Attention, achieving up to 2.33x speedup without quality loss.", "motivation": "High computational cost of Diffusion Transformers (DiTs) limits real-world video generation.", "method": "SVG classifies attention heads into Spatial and Temporal Heads, uses online profiling, and optimizes hardware efficiency.", "result": "2.28x and 2.33x speedup on CogVideoX-v1.5 and HunyuanVideo, respectively.", "conclusion": "SVG offers a training-free, efficient solution for video generation without compromising quality."}}
{"id": "2410.20268", "pdf": "https://arxiv.org/pdf/2410.20268", "abs": "https://arxiv.org/abs/2410.20268", "authors": ["Marcel Binz", "Elif Akata", "Matthias Bethge", "Franziska Br\u00e4ndle", "Fred Callaway", "Julian Coda-Forno", "Peter Dayan", "Can Demircan", "Maria K. Eckstein", "No\u00e9mi \u00c9ltet\u0151", "Thomas L. Griffiths", "Susanne Haridi", "Akshay K. Jagadish", "Li Ji-An", "Alexander Kipnis", "Sreejan Kumar", "Tobias Ludwig", "Marvin Mathony", "Marcelo Mattar", "Alireza Modirshanechi", "Surabhi S. Nath", "Joshua C. Peterson", "Milena Rmus", "Evan M. Russek", "Tankred Saanum", "Johannes A. Schubert", "Luca M. Schulze Buschoff", "Nishad Singhi", "Xin Sui", "Mirko Thalmann", "Fabian Theis", "Vuong Truong", "Vishaal Udandarao", "Konstantinos Voudouris", "Robert Wilson", "Kristin Witte", "Shuchen Wu", "Dirk Wulff", "Huadong Xiong", "Eric Schulz"], "title": "Centaur: a foundation model of human cognition", "categories": ["cs.LG"], "comment": null, "summary": "Establishing a unified theory of cognition has been a major goal of\npsychology. While there have been previous attempts to instantiate such\ntheories by building computational models, we currently do not have one model\nthat captures the human mind in its entirety. A first step in this direction is\nto create a model that can predict human behavior in a wide range of settings.\nHere we introduce Centaur, a computational model that can predict and simulate\nhuman behavior in any experiment expressible in natural language. We derived\nCentaur by finetuning a state-of-the-art language model on a novel, large-scale\ndata set called Psych-101. Psych-101 reaches an unprecedented scale, covering\ntrial-by-trial data from over 60,000 participants performing over 10,000,000\nchoices in 160 experiments. Centaur not only captures the behavior of held-out\nparticipants better than existing cognitive models, but also generalizes to new\ncover stories, structural task modifications, and entirely new domains.\nFurthermore, we find that the model's internal representations become more\naligned with human neural activity after finetuning. Taken together, our\nresults demonstrate that it is possible to discover computational models that\ncapture human behavior across a wide range of domains. We believe that such\nmodels provide tremendous potential for guiding the development of cognitive\ntheories and present a case study to demonstrate this.", "AI": {"tldr": "Centaur, a computational model trained on Psych-101 data, predicts human behavior across diverse experiments and aligns with neural activity, advancing unified cognitive theory.", "motivation": "To create a unified computational model predicting human behavior across varied settings, addressing gaps in existing cognitive theories.", "method": "Finetuned a state-of-the-art language model on Psych-101, a large-scale dataset with trial-by-trial data from 60,000 participants and 10M choices in 160 experiments.", "result": "Centaur outperforms existing models in predicting behavior, generalizes to new tasks, and aligns better with human neural activity post-finetuning.", "conclusion": "Centaur demonstrates the feasibility of unified computational models for human cognition, offering potential for cognitive theory development."}}
{"id": "2502.10363", "pdf": "https://arxiv.org/pdf/2502.10363", "abs": "https://arxiv.org/abs/2502.10363", "authors": ["Huayi Wang", "Zirui Wang", "Junli Ren", "Qingwei Ben", "Tao Huang", "Weinan Zhang", "Jiangmiao Pang"], "title": "BeamDojo: Learning Agile Humanoid Locomotion on Sparse Footholds", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Published at RSS 2025. Project website:\n  https://why618188.github.io/beamdojo", "summary": "Traversing risky terrains with sparse footholds poses a significant challenge\nfor humanoid robots, requiring precise foot placements and stable locomotion.\nExisting learning-based approaches often struggle on such complex terrains due\nto sparse foothold rewards and inefficient learning processes. To address these\nchallenges, we introduce BeamDojo, a reinforcement learning (RL) framework\ndesigned for enabling agile humanoid locomotion on sparse footholds. BeamDojo\nbegins by introducing a sampling-based foothold reward tailored for polygonal\nfeet, along with a double critic to balancing the learning process between\ndense locomotion rewards and sparse foothold rewards. To encourage sufficient\ntrial-and-error exploration, BeamDojo incorporates a two-stage RL approach: the\nfirst stage relaxes the terrain dynamics by training the humanoid on flat\nterrain while providing it with task-terrain perceptive observations, and the\nsecond stage fine-tunes the policy on the actual task terrain. Moreover, we\nimplement a onboard LiDAR-based elevation map to enable real-world deployment.\nExtensive simulation and real-world experiments demonstrate that BeamDojo\nachieves efficient learning in simulation and enables agile locomotion with\nprecise foot placement on sparse footholds in the real world, maintaining a\nhigh success rate even under significant external disturbances.", "AI": {"tldr": "BeamDojo is an RL framework for agile humanoid locomotion on sparse footholds, using tailored rewards, a two-stage learning process, and real-world LiDAR integration.", "motivation": "Existing methods struggle with sparse foothold rewards and inefficient learning on complex terrains.", "method": "Introduces sampling-based foothold rewards, a double critic, and a two-stage RL approach (flat terrain training followed by fine-tuning). Uses LiDAR for real-world deployment.", "result": "Achieves efficient learning in simulation and agile locomotion with precise foot placement in real-world tests.", "conclusion": "BeamDojo effectively addresses sparse foothold challenges, enabling stable and precise humanoid locomotion."}}
{"id": "2502.02097", "pdf": "https://arxiv.org/pdf/2502.02097", "abs": "https://arxiv.org/abs/2502.02097", "authors": ["Zaid Ilyas", "Arooba Maqsood", "Afsah Saleem", "Erchuan Zhang", "David Suter", "Parminder Raina", "Jonathan M. Hodgson", "John T. Schousboe", "William D. Leslie", "Joshua R. Lewis", "Syed Zulqarnain Gilani"], "title": "VerteNet -- A Multi-Context Hybrid CNN Transformer for Accurate Vertebral Landmark Localization in Lateral Spine DXA Images", "categories": ["cs.CV"], "comment": "10 pages with 7 figures", "summary": "Lateral Spine Image (LSI) analysis is important for medical diagnosis,\ntreatment planning, and detailed spinal health assessments. Although modalities\nlike Computed Tomography and Digital X-ray Imaging are commonly used, Dual\nEnergy X-ray Absorptiometry (DXA) is often preferred due to lower radiation\nexposure, seamless capture, and cost-effectiveness. Accurate Vertebral Landmark\nLocalization (VLL) on LSIs is important to detect spinal conditions like\nkyphosis and lordosis, as well as assessing Abdominal Aortic Calcification\n(AAC) using Inter-Vertebral Guides (IVGs). Nonetheless, few automated VLL\nmethodologies have concentrated on DXA LSIs. We present VerteNet, a hybrid\nCNN-Transformer model featuring a novel dual-resolution attention mechanism in\nself and cross-attention domains, referred to as Dual Resolution Self-Attention\n(DRSA) and Dual Resolution Cross-Attention (DRCA). These mechanisms capture the\ndiverse frequencies in DXA images by operating at two different feature map\nresolutions. Additionally, we design a Multi-Context Feature Fusion Block\n(MCFB) that efficiently integrates the features using DRSA and DRCA. We train\nVerteNet on 620 DXA LSIs from various machines and achieve superior results\ncompared to existing methods. We also design an algorithm that utilizes\nVerteNet's predictions in estimating the Region of Interest (ROI) to detect\npotential abdominal aorta cropping, where inadequate soft tissue hinders\ncalcification assessment. Additionally, we present a small proof-of-concept\nstudy to show that IVGs generated from VLL information can improve inter-reader\ncorrelation in AAC scoring, addressing two key areas of disagreement in expert\nAAC-24 scoring: IVG placement and quality control for full abdominal aorta\nassessment. The code for this work can be found at\nhttps://github.com/zaidilyas89/VerteNet.", "AI": {"tldr": "VerteNet, a hybrid CNN-Transformer model with dual-resolution attention mechanisms, improves Vertebral Landmark Localization (VLL) on DXA Lateral Spine Images (LSIs), aiding in spinal condition detection and AAC assessment.", "motivation": "Accurate VLL on DXA LSIs is crucial for diagnosing spinal conditions and assessing AAC, but automated methods for DXA are lacking.", "method": "VerteNet combines CNN and Transformer with Dual Resolution Self-Attention (DRSA) and Cross-Attention (DRCA), and a Multi-Context Feature Fusion Block (MCFB). Trained on 620 DXA LSIs.", "result": "Superior performance over existing methods; includes an ROI algorithm for detecting abdominal aorta cropping and improves AAC scoring consistency.", "conclusion": "VerteNet advances VLL on DXA LSIs, enhancing AAC assessment and inter-reader correlation, with potential for broader clinical use."}}
{"id": "2410.23042", "pdf": "https://arxiv.org/pdf/2410.23042", "abs": "https://arxiv.org/abs/2410.23042", "authors": ["Bryan Chan", "Xinyi Chen", "Andr\u00e1s Gy\u00f6rgy", "Dale Schuurmans"], "title": "Toward Understanding In-context vs. In-weight Learning", "categories": ["cs.LG"], "comment": "In The Thirteenth International Conference on Learning\n  Representations (ICLR 2025)", "summary": "It has recently been demonstrated empirically that in-context learning\nemerges in transformers when certain distributional properties are present in\nthe training data, but this ability can also diminish upon further training. We\nprovide a new theoretical understanding of these phenomena by identifying\nsimplified distributional properties that give rise to the emergence and\neventual disappearance of in-context learning. We do so by first analyzing a\nsimplified model that uses a gating mechanism to choose between an in-weight\nand an in-context predictor. Through a combination of a generalization error\nand regret analysis we identify conditions where in-context and in-weight\nlearning emerge. These theoretical findings are then corroborated\nexperimentally by comparing the behaviour of a full transformer on the\nsimplified distributions to that of the stylized model, demonstrating aligned\nresults. We then extend the study to a full large language model, showing how\nfine-tuning on various collections of natural language prompts can elicit\nsimilar in-context and in-weight learning behaviour.", "AI": {"tldr": "The paper explains why in-context learning emerges and disappears in transformers, using theoretical and experimental analysis of simplified models and real-world language models.", "motivation": "To understand the conditions under which in-context learning emerges and diminishes in transformers, providing theoretical insights into these phenomena.", "method": "Analyzes a simplified gating mechanism model, combines generalization error and regret analysis, and validates findings experimentally with transformers and large language models.", "result": "Identifies distributional conditions for in-context learning emergence and disappearance, with experimental alignment between simplified models and real transformers.", "conclusion": "Theoretical and experimental results show how in-context learning behavior is influenced by training data properties, extending insights to large language models."}}
{"id": "2502.13013", "pdf": "https://arxiv.org/pdf/2502.13013", "abs": "https://arxiv.org/abs/2502.13013", "authors": ["Qingwei Ben", "Feiyu Jia", "Jia Zeng", "Junting Dong", "Dahua Lin", "Jiangmiao Pang"], "title": "HOMIE: Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": null, "summary": "Generalizable humanoid loco-manipulation poses significant challenges,\nrequiring coordinated whole-body control and precise, contact-rich object\nmanipulation. To address this, this paper introduces HOMIE, a semi-autonomous\nteleoperation system that combines a reinforcement learning policy for body\ncontrol mapped to a pedal, an isomorphic exoskeleton arm for arm control, and\nmotion-sensing gloves for hand control, forming a unified cockpit to freely\noperate humanoids and establish a data flywheel. The policy incorporates novel\ndesigns, including an upper-body pose curriculum, a height-tracking reward, and\nsymmetry utilization. These features enable the system to perform walking and\nsquatting to specific heights while seamlessly adapting to arbitrary upper-body\nposes. The exoskeleton, by eliminating the reliance on inverse dynamics,\ndelivers faster and more precise arm control. The gloves utilize Hall sensors\ninstead of servos, allowing even compact devices to achieve 15 or more degrees\nof freedom and freely adapt to any model of dexterous hands. Compared to\nprevious teleoperation systems, HOMIE stands out for its exceptional\nefficiency, completing tasks in half the time; its expanded working range,\nallowing users to freely reach high and low areas as well as interact with any\nobjects; and its affordability, with a price of just $500. The system is fully\nopen-source, demos and code can be found in our https://homietele.github.io/.", "AI": {"tldr": "HOMIE is a semi-autonomous teleoperation system for humanoid loco-manipulation, combining RL-based body control, an exoskeleton arm, and motion-sensing gloves for efficient, precise, and affordable operation.", "motivation": "Addressing the challenges of coordinated whole-body control and precise object manipulation in humanoid robots.", "method": "Uses a reinforcement learning policy for body control, an isomorphic exoskeleton arm, and motion-sensing gloves with Hall sensors. Novel designs include an upper-body pose curriculum and height-tracking rewards.", "result": "HOMIE outperforms previous systems in efficiency (half the time), working range (high/low reach), and affordability ($500).", "conclusion": "HOMIE provides a unified, open-source solution for humanoid teleoperation, enabling versatile and cost-effective loco-manipulation."}}
{"id": "2502.03746", "pdf": "https://arxiv.org/pdf/2502.03746", "abs": "https://arxiv.org/abs/2502.03746", "authors": ["Rupesh Dulal", "Rabin Dulal"], "title": "Brain Tumor Identification using Improved YOLOv8", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Identifying the extent of brain tumors is a significant challenge in brain\ncancer treatment. The main difficulty is in the approximate detection of tumor\nsize. Magnetic resonance imaging (MRI) has become a critical diagnostic tool.\nHowever, manually detecting the boundaries of brain tumors from MRI scans is a\nlabor-intensive task that requires extensive expertise. Deep learning and\ncomputer-aided detection techniques have led to notable advances in machine\nlearning for this purpose. In this paper, we propose a modified You Only Look\nOnce (YOLOv8) model to accurately detect the tumors within the MRI images. The\nproposed model replaced the Non-Maximum Suppression (NMS) algorithm with a\nReal-Time Detection Transformer (RT- DETR) in the detection head. NMS filters\nout redundant or overlapping bounding boxes in the detected tumors, but they\nare hand-designed and pre-set. RT-DETR removes hand-designed components. The\nsecond improvement was made by replacing the normal convolution block with\nghost convolution. Ghost Convolution reduces computational and memory costs\nwhile maintaining high accuracy and enabling faster inference, making it ideal\nfor resource-constrained environments and real-time applications. The third\nimprovement was made by introducing a vision transformer block in the backbone\nof YOLOv8 to extract context-aware features. We used a publicly available\ndataset of brain tumors in the proposed model. The proposed model performed\nbetter than the original YOLOv8 model and also performed better than other\nobject detectors (Faster R- CNN, Mask R-CNN, YOLO, YOLOv3, YOLOv4, YOLOv5, SSD,\nRetinaNet, EfficientDet, and DETR). The proposed model achieved 0.91 mAP (mean\nAverage Precision)@0.5.", "AI": {"tldr": "A modified YOLOv8 model with RT-DETR, Ghost Convolution, and Vision Transformer blocks improves brain tumor detection in MRI scans, outperforming other models with 0.91 mAP.", "motivation": "Manual tumor boundary detection in MRI scans is labor-intensive and requires expertise, prompting the need for automated, accurate solutions.", "method": "The proposed model replaces NMS with RT-DETR, uses Ghost Convolution for efficiency, and integrates Vision Transformer blocks for context-aware feature extraction.", "result": "The model achieved 0.91 mAP@0.5, outperforming original YOLOv8 and other detectors like Faster R-CNN and DETR.", "conclusion": "The modified YOLOv8 model offers a robust, efficient solution for brain tumor detection, suitable for real-time applications."}}
{"id": "2411.01641", "pdf": "https://arxiv.org/pdf/2411.01641", "abs": "https://arxiv.org/abs/2411.01641", "authors": ["Md Abrar Jahin", "Md. Akmol Masud", "Md Wahiduzzaman Suva", "M. F. Mridha", "Nilanjan Dey"], "title": "Lorentz-Equivariant Quantum Graph Neural Network for High-Energy Physics", "categories": ["cs.LG", "hep-ex", "physics.ins-det"], "comment": null, "summary": "The rapid data surge from the high-luminosity Large Hadron Collider\nintroduces critical computational challenges requiring novel approaches for\nefficient data processing in particle physics. Quantum machine learning, with\nits capability to leverage the extensive Hilbert space of quantum hardware,\noffers a promising solution. However, current quantum graph neural networks\n(GNNs) lack robustness to noise and are often constrained by fixed symmetry\ngroups, limiting adaptability in complex particle interaction modeling. This\npaper demonstrates that replacing the Lorentz Group Equivariant Block modules\nin LorentzNet with a dressed quantum circuit significantly enhances performance\ndespite using nearly 5.5 times fewer parameters. Additionally, quantum circuits\neffectively replace MLPs by inherently preserving symmetries, with Lorentz\nsymmetry integration ensuring robust handling of relativistic invariance. Our\nLorentz-Equivariant Quantum Graph Neural Network (Lorentz-EQGNN) achieved\n$74.00\\%$ test accuracy and an AUC of $87.38\\%$ on the Quark-Gluon jet tagging\ndataset, outperforming the classical and quantum GNNs with a reduced\narchitecture using only 4 qubits. On the Electron-Photon dataset, Lorentz-EQGNN\nreached $67.00\\%$ test accuracy and an AUC of $68.20\\%$, demonstrating\ncompetitive results with just 800 training samples. Evaluation of our model on\ngeneric MNIST and FashionMNIST datasets confirmed Lorentz-EQGNN's efficiency,\nachieving $88.10\\%$ and $74.80\\%$ test accuracy, respectively. Ablation studies\nvalidated the impact of quantum components on performance, with notable\nimprovements in background rejection rates over classical counterparts. These\nresults highlight Lorentz-EQGNN's potential for immediate applications in\nnoise-resilient jet tagging, event classification, and broader data-scarce HEP\ntasks.", "AI": {"tldr": "A quantum-enhanced graph neural network (Lorentz-EQGNN) outperforms classical and quantum GNNs in particle physics tasks with fewer parameters and noise resilience.", "motivation": "Address computational challenges in particle physics data processing by leveraging quantum machine learning, overcoming noise and symmetry constraints in current quantum GNNs.", "method": "Replace Lorentz Group Equivariant Block modules in LorentzNet with dressed quantum circuits, preserving symmetries and reducing parameters.", "result": "Achieved 74.00% test accuracy and 87.38% AUC on Quark-Gluon dataset, 67.00% accuracy on Electron-Photon dataset, and competitive results on MNIST/FashionMNIST with minimal training data.", "conclusion": "Lorentz-EQGNN is efficient, noise-resilient, and suitable for jet tagging and event classification in high-energy physics."}}
{"id": "2502.15709", "pdf": "https://arxiv.org/pdf/2502.15709", "abs": "https://arxiv.org/abs/2502.15709", "authors": ["Zhaoxing Li", "Vahid Yazdanpanah", "Jindi Wang", "Wen Gu", "Lei Shi", "Alexandra I. Cristea", "Sarah Kiden", "Sebastian Stein"], "title": "TutorLLM: Customizing Learning Recommendations with Knowledge Tracing and Retrieval-Augmented Generation", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "The integration of AI in education offers significant potential to enhance\nlearning efficiency. Large Language Models (LLMs), such as ChatGPT, Gemini, and\nLlama, allow students to query a wide range of topics, providing unprecedented\nflexibility. However, LLMs face challenges, such as handling varying content\nrelevance and lack of personalization. To address these challenges, we propose\nTutorLLM, a personalized learning recommender LLM system based on Knowledge\nTracing (KT) and Retrieval-Augmented Generation (RAG). The novelty of TutorLLM\nlies in its unique combination of KT and RAG techniques with LLMs, which\nenables dynamic retrieval of context-specific knowledge and provides\npersonalized learning recommendations based on the student's personal learning\nstate. Specifically, this integration allows TutorLLM to tailor responses based\non individual learning states predicted by the Multi-Features with Latent\nRelations BERT-based KT (MLFBK) model and to enhance response accuracy with a\nScraper model. The evaluation includes user assessment questionnaires and\nperformance metrics, demonstrating a 10% improvement in user satisfaction and a\n5\\% increase in quiz scores compared to using general LLMs alone.", "AI": {"tldr": "TutorLLM combines Knowledge Tracing and Retrieval-Augmented Generation with LLMs to personalize learning, improving satisfaction and quiz scores.", "motivation": "Address challenges of content relevance and lack of personalization in LLMs for education.", "method": "Integrates KT (MLFBK model) and RAG with LLMs for dynamic, personalized recommendations.", "result": "10% higher user satisfaction and 5% better quiz scores than general LLMs.", "conclusion": "TutorLLM effectively enhances personalized learning by leveraging KT and RAG."}}
{"id": "2502.05173", "pdf": "https://arxiv.org/pdf/2502.05173", "abs": "https://arxiv.org/abs/2502.05173", "authors": ["Xilin Wei", "Xiaoran Liu", "Yuhang Zang", "Xiaoyi Dong", "Pan Zhang", "Yuhang Cao", "Jian Tong", "Haodong Duan", "Qipeng Guo", "Jiaqi Wang", "Xipeng Qiu", "Dahua Lin"], "title": "VideoRoPE: What Makes for Good Video Rotary Position Embedding?", "categories": ["cs.CV"], "comment": null, "summary": "While Rotary Position Embedding (RoPE) and its variants are widely adopted\nfor their long-context capabilities, the extension of the 1D RoPE to video,\nwith its complex spatio-temporal structure, remains an open challenge. This\nwork first introduces a comprehensive analysis that identifies four key\ncharacteristics essential for the effective adaptation of RoPE to video, which\nhave not been fully considered in prior work. As part of our analysis, we\nintroduce a challenging V-NIAH-D (Visual Needle-In-A-Haystack with Distractors)\ntask, which adds periodic distractors into V-NIAH. The V-NIAH-D task\ndemonstrates that previous RoPE variants, lacking appropriate temporal\ndimension allocation, are easily misled by distractors. Based on our analysis,\nwe introduce \\textbf{VideoRoPE}, with a \\textit{3D structure} designed to\npreserve spatio-temporal relationships. VideoRoPE features\n\\textit{low-frequency temporal allocation} to mitigate periodic oscillations, a\n\\textit{diagonal layout} to maintain spatial symmetry, and \\textit{adjustable\ntemporal spacing} to decouple temporal and spatial indexing. VideoRoPE\nconsistently surpasses previous RoPE variants, across diverse downstream tasks\nsuch as long video retrieval, video understanding, and video hallucination. Our\ncode will be available at\n\\href{https://github.com/Wiselnn570/VideoRoPE}{https://github.com/Wiselnn570/VideoRoPE}.", "AI": {"tldr": "VideoRoPE extends Rotary Position Embedding (RoPE) to video by addressing spatio-temporal challenges, outperforming prior variants in tasks like video retrieval and understanding.", "motivation": "Prior RoPE variants struggle with video's spatio-temporal complexity, especially when faced with periodic distractors, necessitating a more robust solution.", "method": "VideoRoPE introduces a 3D structure with low-frequency temporal allocation, diagonal layout, and adjustable temporal spacing to handle spatio-temporal relationships effectively.", "result": "VideoRoPE consistently outperforms previous RoPE variants in tasks like long video retrieval, video understanding, and video hallucination.", "conclusion": "VideoRoPE successfully adapts RoPE for video, addressing key spatio-temporal challenges and demonstrating superior performance across diverse tasks."}}
{"id": "2411.09804", "pdf": "https://arxiv.org/pdf/2411.09804", "abs": "https://arxiv.org/abs/2411.09804", "authors": ["Xiaohui Tu", "Yossiri Adulyasak", "Nima Akbarzadeh", "Erick Delage"], "title": "Fair Resource Allocation in Weakly Coupled Markov Decision Processes", "categories": ["cs.LG"], "comment": null, "summary": "We consider fair resource allocation in sequential decision-making\nenvironments modeled as weakly coupled Markov decision processes, where\nresource constraints couple the action spaces of $N$ sub-Markov decision\nprocesses (sub-MDPs) that would otherwise operate independently. We adopt a\nfairness definition using the generalized Gini function instead of the\ntraditional utilitarian (total-sum) objective. After introducing a general but\ncomputationally prohibitive solution scheme based on linear programming, we\nfocus on the homogeneous case where all sub-MDPs are identical. For this case,\nwe show for the first time that the problem reduces to optimizing the\nutilitarian objective over the class of \"permutation invariant\" policies. This\nresult is particularly useful as we can exploit Whittle index policies in the\nrestless bandits setting while, for the more general setting, we introduce a\ncount-proportion-based deep reinforcement learning approach. Finally, we\nvalidate our theoretical findings with comprehensive experiments, confirming\nthe effectiveness of our proposed method in achieving fairness.", "AI": {"tldr": "The paper proposes a fair resource allocation method in weakly coupled MDPs using the generalized Gini function, reducing the problem to optimizing a utilitarian objective for homogeneous cases and validating the approach with experiments.", "motivation": "To address fairness in resource allocation within sequential decision-making environments, moving beyond traditional utilitarian objectives.", "method": "Introduces a linear programming solution for general cases and simplifies the problem for homogeneous sub-MDPs using permutation invariant policies and Whittle index policies, supplemented by deep reinforcement learning.", "result": "The proposed method effectively achieves fairness, validated through comprehensive experiments.", "conclusion": "The approach successfully balances fairness and efficiency in resource allocation for weakly coupled MDPs."}}
{"id": "2502.17499", "pdf": "https://arxiv.org/pdf/2502.17499", "abs": "https://arxiv.org/abs/2502.17499", "authors": ["Sumei Fan", "Deyun Zhang", "Yue Wang", "Shijia Geng", "Kun Lu", "Meng Sang", "Weilun Xu", "Haixue Wang", "Qinghao Zhao", "Chuandong Cheng", "Peng Wang", "Shenda Hong"], "title": "Detecting Long QT Syndrome and First-Degree Atrioventricular Block using Single-Lead AI-ECG: A Multi-Center Real-World Study", "categories": ["eess.SP", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "comment": "29pages, 11 figures, 8 tables", "summary": "Home-based single-lead AI-ECG devices have enabled continuous, real-world\ncardiac monitoring. However, the accuracy of parameter calculations from\nsingle-lead AI-ECG algorithm remains to be fully validated, which is critical\nfor conditions such as Long QT Syndrome (LQTS) and First-Degree\nAtrioventricular Block (AVBI). In this multicenter study, we assessed\nFeatureDB, an ECG measurements computation algorithm, in the context of\nsingle-lead monitoring using three annotated datasets: PTB-XL+ (n=21,354), CSE\n(n=105), and HeartVoice-ECG-lite (n=369). FeatureDB showed strong correlation\nwith standard ECG machines (12SL and Uni-G) in key measurements (PR, QRS, QT,\nQTc), and high agreement confirmed by Bland-Altman analysis. In detecting LQTS\n(AUC=0.786) and AVBI (AUC=0.684), FeatureDB demonstrated diagnostic performance\ncomparable to commercial ECG systems (12SL: 0.859/0.716; Uni-G: 0.817/0.605),\nsignificantly outperforming ECGDeli (0.501/0.569). Notably, FeatureDB can\noperate locally on resource-limited devices, facilitating use in\nlow-connectivity settings. These findings confirm the clinical reliability of\nFeatureDB for single-lead ECG diagnostics and highlight its potential to bridge\ntraditional ECG diagnostics with wearable technology for scalable\ncardiovascular monitoring and early intervention.", "AI": {"tldr": "FeatureDB, an AI-ECG algorithm, was validated for single-lead ECG monitoring, showing strong correlation with standard ECG machines and comparable diagnostic performance for LQTS and AVBI.", "motivation": "To validate the accuracy of single-lead AI-ECG algorithms for critical cardiac conditions like LQTS and AVBI, bridging traditional diagnostics with wearable technology.", "method": "Multicenter study using three annotated datasets (PTB-XL+, CSE, HeartVoice-ECG-lite) to assess FeatureDB's performance against standard ECG machines (12SL, Uni-G) and ECGDeli.", "result": "FeatureDB showed strong correlation with standard machines in key measurements and high diagnostic performance (AUC=0.786 for LQTS, 0.684 for AVBI), outperforming ECGDeli. It operates locally on resource-limited devices.", "conclusion": "FeatureDB is clinically reliable for single-lead ECG diagnostics, offering scalable cardiovascular monitoring and early intervention potential."}}
{"id": "2502.08025", "pdf": "https://arxiv.org/pdf/2502.08025", "abs": "https://arxiv.org/abs/2502.08025", "authors": ["Kristofer Grover Roos", "Atsushi Fukuda", "Quan Huu Cap"], "title": "From Brainwaves to Brain Scans: A Robust Neural Network for EEG-to-fMRI Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "While functional magnetic resonance imaging (fMRI) offers valuable insights\ninto brain activity, it is limited by high operational costs and significant\ninfrastructural demands. In contrast, electroencephalography (EEG) provides\nmillisecond-level precision in capturing electrical activity but lacks the\nspatial fidelity necessary for precise neural localization. To bridge these\ngaps, we propose E2fNet, a simple yet effective deep learning model for\nsynthesizing fMRI images from low-cost EEG data. E2fNet is an encoder-decoder\nnetwork specifically designed to capture and translate meaningful multi-scale\nfeatures from EEG across electrode channels into accurate fMRI representations.\nExtensive evaluations across three public datasets demonstrate that E2fNet\nconsistently outperforms existing CNN- and transformer-based methods, achieving\nstate-of-the-art results in terms of the structural similarity index measure\n(SSIM). These results demonstrate that E2fNet is a promising, cost-effective\nsolution for enhancing neuroimaging capabilities. The code is available at\nhttps://github.com/kgr20/E2fNet.", "AI": {"tldr": "E2fNet is a deep learning model that synthesizes fMRI images from EEG data, outperforming existing methods and offering a cost-effective neuroimaging solution.", "motivation": "fMRI is costly and infrastructure-heavy, while EEG lacks spatial fidelity. E2fNet bridges these gaps by generating fMRI from EEG.", "method": "E2fNet is an encoder-decoder network that translates multi-scale EEG features into fMRI representations.", "result": "E2fNet achieves state-of-the-art SSIM scores on three public datasets, surpassing CNN- and transformer-based methods.", "conclusion": "E2fNet is a promising, cost-effective tool for enhancing neuroimaging capabilities."}}
{"id": "2411.11745", "pdf": "https://arxiv.org/pdf/2411.11745", "abs": "https://arxiv.org/abs/2411.11745", "authors": ["Yuzong Chen", "Ahmed F. AbouElhamayed", "Xilai Dai", "Yang Wang", "Marta Andronic", "George A. Constantinides", "Mohamed S. Abdelfattah"], "title": "BitMoD: Bit-serial Mixture-of-Datatype LLM Acceleration", "categories": ["cs.LG", "cs.AR"], "comment": "HPCA 2025", "summary": "Large language models (LLMs) have demonstrated remarkable performance across\nvarious machine learning tasks. Yet the substantial memory footprint of LLMs\nsignificantly hinders their deployment. In this paper, we improve the\naccessibility of LLMs through BitMoD, an algorithm-hardware co-design solution\nthat enables efficient LLM acceleration at low weight precision. On the\nalgorithm side, BitMoD introduces fine-grained data type adaptation that uses a\ndifferent numerical data type to quantize a group of (e.g., 128) weights.\nThrough the careful design of these new data types, BitMoD is able to quantize\nLLM weights to very low precision (e.g., 4 bits and 3 bits) while maintaining\nhigh accuracy. On the hardware side, BitMoD employs a bit-serial processing\nelement to easily support multiple numerical precisions and data types; our\nhardware design includes two key innovations: First, it employs a unified\nrepresentation to process different weight data types, thus reducing the\nhardware cost. Second, it adopts a bit-serial dequantization unit to rescale\nthe per-group partial sum with minimal hardware overhead. Our evaluation on six\nrepresentative LLMs demonstrates that BitMoD significantly outperforms\nstate-of-the-art LLM quantization and acceleration methods. For discriminative\ntasks, BitMoD can quantize LLM weights to 4-bit with $<\\!0.5\\%$ accuracy loss\non average. For generative tasks, BitMoD is able to quantize LLM weights to\n3-bit while achieving better perplexity than prior LLM quantization scheme.\nCombining the superior model performance with an efficient accelerator design,\nBitMoD achieves an average of $1.69\\times$ and $1.48\\times$ speedups compared\nto prior LLM accelerators ANT and OliVe, respectively.", "AI": {"tldr": "BitMoD is an algorithm-hardware co-design solution for efficient LLM acceleration at low weight precision, achieving high accuracy with 4-bit and 3-bit quantization and outperforming existing methods.", "motivation": "The substantial memory footprint of LLMs hinders deployment, prompting the need for efficient acceleration solutions like BitMoD.", "method": "BitMoD combines fine-grained data type adaptation for quantization with a bit-serial processing element and unified hardware representation.", "result": "BitMoD quantizes LLM weights to 4-bit (discriminative tasks) and 3-bit (generative tasks) with minimal accuracy loss, outperforming state-of-the-art methods.", "conclusion": "BitMoD's efficient design and superior performance make it a promising solution for LLM deployment."}}
{"id": "2502.19645", "pdf": "https://arxiv.org/pdf/2502.19645", "abs": "https://arxiv.org/abs/2502.19645", "authors": ["Moo Jin Kim", "Chelsea Finn", "Percy Liang"], "title": "Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted to Robotics: Science and Systems (RSS) 2025. Project\n  website: https://openvla-oft.github.io/", "summary": "Recent vision-language-action models (VLAs) build upon pretrained\nvision-language models and leverage diverse robot datasets to demonstrate\nstrong task execution, language following ability, and semantic generalization.\nDespite these successes, VLAs struggle with novel robot setups and require\nfine-tuning to achieve good performance, yet how to most effectively fine-tune\nthem is unclear given many possible strategies. In this work, we study key VLA\nadaptation design choices such as different action decoding schemes, action\nrepresentations, and learning objectives for fine-tuning, using OpenVLA as our\nrepresentative base model. Our empirical analysis informs an Optimized\nFine-Tuning (OFT) recipe that integrates parallel decoding, action chunking, a\ncontinuous action representation, and a simple L1 regression-based learning\nobjective to altogether improve inference efficiency, policy performance, and\nflexibility in the model's input-output specifications. We propose OpenVLA-OFT,\nan instantiation of this recipe, which sets a new state of the art on the\nLIBERO simulation benchmark, significantly boosting OpenVLA's average success\nrate across four task suites from 76.5% to 97.1% while increasing action\ngeneration throughput by 26$\\times$. In real-world evaluations, our fine-tuning\nrecipe enables OpenVLA to successfully execute dexterous, high-frequency\ncontrol tasks on a bimanual ALOHA robot and outperform other VLAs ($\\pi_0$ and\nRDT-1B) fine-tuned using their default recipes, as well as strong imitation\nlearning policies trained from scratch (Diffusion Policy and ACT) by up to 15%\n(absolute) in average success rate. We release code for OFT and pretrained\nmodel checkpoints at https://openvla-oft.github.io/.", "AI": {"tldr": "The paper introduces an Optimized Fine-Tuning (OFT) recipe for vision-language-action models (VLAs), improving performance and efficiency, and demonstrates its success in simulations and real-world tasks.", "motivation": "VLAs struggle with novel robot setups and unclear fine-tuning strategies, prompting the need for an optimized approach.", "method": "The study evaluates design choices like action decoding, representations, and learning objectives, proposing OFT with parallel decoding, action chunking, and L1 regression.", "result": "OpenVLA-OFT achieves a 97.1% success rate (up from 76.5%) in simulations and outperforms other VLAs and imitation learning policies by up to 15% in real-world tasks.", "conclusion": "OFT significantly enhances VLA performance and flexibility, setting a new benchmark and enabling successful real-world applications."}}
{"id": "2502.10377", "pdf": "https://arxiv.org/pdf/2502.10377", "abs": "https://arxiv.org/abs/2502.10377", "authors": ["Liyuan Zhu", "Shengqu Cai", "Shengyu Huang", "Gordon Wetzstein", "Naji Khosravan", "Iro Armeni"], "title": "ReStyle3D: Scene-Level Appearance Transfer with Semantic Correspondences", "categories": ["cs.CV", "cs.GR"], "comment": "SIGGRAPH 2025. Project page: https://restyle3d.github.io/", "summary": "We introduce ReStyle3D, a novel framework for scene-level appearance transfer\nfrom a single style image to a real-world scene represented by multiple views.\nThe method combines explicit semantic correspondences with multi-view\nconsistency to achieve precise and coherent stylization. Unlike conventional\nstylization methods that apply a reference style globally, ReStyle3D uses\nopen-vocabulary segmentation to establish dense, instance-level correspondences\nbetween the style and real-world images. This ensures that each object is\nstylized with semantically matched textures. It first transfers the style to a\nsingle view using a training-free semantic-attention mechanism in a diffusion\nmodel. It then lifts the stylization to additional views via a learned\nwarp-and-refine network guided by monocular depth and pixel-wise\ncorrespondences. Experiments show that ReStyle3D consistently outperforms prior\nmethods in structure preservation, perceptual style similarity, and multi-view\ncoherence. User studies further validate its ability to produce\nphoto-realistic, semantically faithful results. Our code, pretrained models,\nand dataset will be publicly released, to support new applications in interior\ndesign, virtual staging, and 3D-consistent stylization.", "AI": {"tldr": "ReStyle3D is a framework for transferring scene-level appearance from a single style image to a multi-view real-world scene, ensuring precise and coherent stylization using semantic correspondences and multi-view consistency.", "motivation": "To achieve semantically faithful and multi-view coherent stylization, addressing limitations of conventional methods that apply styles globally without semantic matching.", "method": "Combines open-vocabulary segmentation for dense instance-level correspondences, a training-free semantic-attention mechanism in a diffusion model for single-view stylization, and a warp-and-refine network for multi-view consistency.", "result": "Outperforms prior methods in structure preservation, perceptual style similarity, and multi-view coherence, validated by user studies.", "conclusion": "ReStyle3D enables photo-realistic, semantically accurate stylization, with potential applications in interior design, virtual staging, and 3D-consistent stylization."}}
{"id": "2412.03743", "pdf": "https://arxiv.org/pdf/2412.03743", "abs": "https://arxiv.org/abs/2412.03743", "authors": ["Jakob Schloer", "Matthew Newman", "Jannik Thuemmel", "Antonietta Capotondi", "Bedartha Goswami"], "title": "A Hybrid Deep-Learning Model for El Ni\u00f1o Southern Oscillation in the Low-Data Regime", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "While deep-learning models have demonstrated skillful El Ni\\~no Southern\nOscillation (ENSO) forecasts up to one year in advance, they are predominantly\ntrained on climate model simulations that provide thousands of years of\ntraining data at the expense of introducing climate model biases. Simpler\nLinear Inverse Models (LIMs) trained on the much shorter observational record\nalso make skillful ENSO predictions but do not capture predictable nonlinear\nprocesses. This motivates a hybrid approach, combining the LIMs modest data\nneeds with a deep-learning non-Markovian correction of the LIM. For O(100 yr)\ndatasets, our resulting Hybrid model is more skillful than the LIM while also\nexceeding the skill of a full deep-learning model. Additionally, while the most\npredictable ENSO events are still identified in advance by the LIM, they are\nbetter predicted by the Hybrid model, especially in the western tropical\nPacific for leads beyond about 9 months, by capturing the subsequent asymmetric\n(warm versus cold phases) evolution of ENSO.", "AI": {"tldr": "A hybrid model combining Linear Inverse Models (LIMs) with deep-learning corrections outperforms both LIMs and full deep-learning models for ENSO forecasting, especially for longer lead times.", "motivation": "Deep-learning models for ENSO forecasting rely on biased climate simulations, while LIMs trained on observational data lack nonlinear process capture. A hybrid approach addresses these limitations.", "method": "The hybrid model integrates LIMs with a deep-learning non-Markovian correction, leveraging the LIM's data efficiency and deep-learning's nonlinear capabilities.", "result": "The hybrid model surpasses both LIMs and full deep-learning models in skill, particularly for ENSO events beyond 9 months, capturing asymmetric evolution better.", "conclusion": "The hybrid approach offers a balanced solution for ENSO forecasting, combining data efficiency and nonlinear accuracy, improving predictions for longer lead times."}}
{"id": "2502.20099", "pdf": "https://arxiv.org/pdf/2502.20099", "abs": "https://arxiv.org/abs/2502.20099", "authors": ["Juan L. Gamella", "Simon Bing", "Jakob Runge"], "title": "Sanity Checking Causal Representation Learning on a Simple Real-World System", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": "24 pages, 12 figures", "summary": "We evaluate methods for causal representation learning (CRL) on a simple,\nreal-world system where these methods are expected to work. The system consists\nof a controlled optical experiment specifically built for this purpose, which\nsatisfies the core assumptions of CRL and where the underlying causal factors\n(the inputs to the experiment) are known, providing a ground truth. We select\nmethods representative of different approaches to CRL and find that they all\nfail to recover the underlying causal factors. To understand the failure modes\nof the evaluated algorithms, we perform an ablation on the data by substituting\nthe real data-generating process with a simpler synthetic equivalent. The\nresults reveal a reproducibility problem, as most methods already fail on this\nsynthetic ablation despite its simple data-generating process. Additionally, we\nobserve that common assumptions on the mixing function are crucial for the\nperformance of some of the methods but do not hold in the real data. Our\nefforts highlight the contrast between the theoretical promise of the state of\nthe art and the challenges in its application. We hope the benchmark serves as\na simple, real-world sanity check to further develop and validate methodology,\nbridging the gap towards CRL methods that work in practice. We make all code\nand datasets publicly available at github.com/simonbing/CRLSanityCheck", "AI": {"tldr": "The paper evaluates causal representation learning (CRL) methods on a real-world optical experiment, finding they fail to recover causal factors. Synthetic data reveals reproducibility issues, and assumptions on mixing functions are often unmet.", "motivation": "To assess the practical applicability of CRL methods by testing them on a controlled real-world system with known ground truth.", "method": "Evaluated representative CRL methods on a real-world optical experiment and synthetic data ablation.", "result": "All methods failed to recover causal factors; synthetic data exposed reproducibility problems and invalid assumptions.", "conclusion": "Highlights the gap between theoretical promise and practical challenges in CRL, offering a benchmark for future method validation."}}
{"id": "2502.11801", "pdf": "https://arxiv.org/pdf/2502.11801", "abs": "https://arxiv.org/abs/2502.11801", "authors": ["Sheng-Yu Huang", "Zi-Ting Chou", "Yu-Chiang Frank Wang"], "title": "3D Gaussian Inpainting with Depth-Guided Cross-View Consistency", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to CVPR 2025. For project page, see\n  https://peterjohnsonhuang.github.io/3dgic-pages", "summary": "When performing 3D inpainting using novel-view rendering methods like Neural\nRadiance Field (NeRF) or 3D Gaussian Splatting (3DGS), how to achieve texture\nand geometry consistency across camera views has been a challenge. In this\npaper, we propose a framework of 3D Gaussian Inpainting with Depth-Guided\nCross-View Consistency (3DGIC) for cross-view consistent 3D inpainting. Guided\nby the rendered depth information from each training view, our 3DGIC exploits\nbackground pixels visible across different views for updating the inpainting\nmask, allowing us to refine the 3DGS for inpainting purposes.Through extensive\nexperiments on benchmark datasets, we confirm that our 3DGIC outperforms\ncurrent state-of-the-art 3D inpainting methods quantitatively and\nqualitatively.", "AI": {"tldr": "Proposes 3DGIC, a depth-guided framework for cross-view consistent 3D inpainting, outperforming existing methods.", "motivation": "Addressing texture and geometry consistency challenges in 3D inpainting using NeRF or 3DGS.", "method": "Uses depth-guided cross-view consistency to refine inpainting masks and update 3DGS.", "result": "Outperforms state-of-the-art methods on benchmark datasets.", "conclusion": "3DGIC effectively achieves cross-view consistency in 3D inpainting."}}
{"id": "2412.04914", "pdf": "https://arxiv.org/pdf/2412.04914", "abs": "https://arxiv.org/abs/2412.04914", "authors": ["Jari Peeperkorn", "Simon De Vos"], "title": "Achieving Group Fairness through Independence in Predictive Process Monitoring", "categories": ["cs.LG", "stat.ML"], "comment": "Preprint", "summary": "Predictive process monitoring focuses on forecasting future states of ongoing\nprocess executions, such as predicting the outcome of a particular case. In\nrecent years, the application of machine learning models in this domain has\ngarnered significant scientific attention. When using historical execution\ndata, which may contain biases or exhibit unfair behavior, these biases may be\nencoded into the trained models. Consequently, when such models are deployed to\nmake decisions or guide interventions for new cases, they risk perpetuating\nthis unwanted behavior. This work addresses group fairness in predictive\nprocess monitoring by investigating independence, i.e. ensuring predictions are\nunaffected by sensitive group membership. We explore independence through\nmetrics for demographic parity such as $\\Delta$DP, as well as recently\nintroduced, threshold-independent distribution-based alternatives.\nAdditionally, we propose a composite loss function existing of binary\ncross-entropy and a distribution-based loss (Wasserstein) to train models that\nbalance predictive performance and fairness, and allow for customizable\ntrade-offs. The effectiveness of both the fairness metrics and the composite\nloss functions is validated through a controlled experimental setup.", "AI": {"tldr": "The paper addresses group fairness in predictive process monitoring, proposing metrics and a composite loss function to balance predictive performance and fairness.", "motivation": "Machine learning models in predictive process monitoring may inherit biases from historical data, risking unfair decisions. This work aims to mitigate such biases by ensuring predictions are independent of sensitive group attributes.", "method": "The study investigates independence using fairness metrics like \u0394DP and distribution-based alternatives. It introduces a composite loss function combining binary cross-entropy and Wasserstein loss for balanced performance and fairness.", "result": "The proposed fairness metrics and composite loss function are validated through controlled experiments, demonstrating their effectiveness.", "conclusion": "The work successfully addresses fairness in predictive process monitoring, offering tools to balance accuracy and fairness with customizable trade-offs."}}
{"id": "2503.03108", "pdf": "https://arxiv.org/pdf/2503.03108", "abs": "https://arxiv.org/abs/2503.03108", "authors": ["Wenrui Cheng", "Tiantian Zhu", "Chunlin Xiong", "Haofei Sun", "Zijun Wang", "Shunan Jing", "Mingqi Lv", "Yan Chen"], "title": "SoK: Knowledge is All You Need: Accelerating Last Mile Delivery for Automated Provenance-based Intrusion Detection with LLMs", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Recently, provenance-based intrusion detection systems (PIDSes) have been\nwidely proposed for endpoint threat analysis. However, due to the lack of\nsystematic integration and utilization of knowledge, existing PIDSes still\nrequire significant manual intervention for practical deployment, making full\nautomation challenging. This paper presents a disruptive innovation by\ncategorizing PIDSes according to the types of knowledge they utilize. In\nresponse to the prevalent issue of ``knowledge silos problem'' in existing\nresearch, we introduce a novel knowledge-driven provenance-based intrusion\ndetection framework, powered by large language models (LLMs). We also present\nOmniSec, a best practice system built upon this framework. By integrating\nattack representation knowledge, threat intelligence knowledge, and benign\nbehavior knowledge, OmniSec outperforms the state-of-the-art approaches on\npublic benchmark datasets. OmniSec is available online at\nhttps://anonymous.4open.science/r/PIDS-with-LLM-613B.", "AI": {"tldr": "The paper introduces a knowledge-driven provenance-based intrusion detection framework using LLMs to address the 'knowledge silos problem' in existing PIDSes, presenting OmniSec as a best-practice system.", "motivation": "Existing PIDSes lack systematic knowledge integration, requiring manual intervention and hindering full automation.", "method": "Proposes a framework categorizing PIDSes by knowledge types and introduces OmniSec, integrating attack representation, threat intelligence, and benign behavior knowledge with LLMs.", "result": "OmniSec outperforms state-of-the-art approaches on public benchmark datasets.", "conclusion": "The framework and OmniSec demonstrate improved automation and performance in intrusion detection, addressing knowledge silos effectively."}}
{"id": "2502.20087", "pdf": "https://arxiv.org/pdf/2502.20087", "abs": "https://arxiv.org/abs/2502.20087", "authors": ["Meng Lou", "Yizhou Yu"], "title": "OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025 (Oral)", "summary": "Top-down attention plays a crucial role in the human vision system, wherein\nthe brain initially obtains a rough overview of a scene to discover salient\ncues (i.e., overview first), followed by a more careful finer-grained\nexamination (i.e., look closely next). However, modern ConvNets remain confined\nto a pyramid structure that successively downsamples the feature map for\nreceptive field expansion, neglecting this crucial biomimetic principle. We\npresent OverLoCK, the first pure ConvNet backbone architecture that explicitly\nincorporates a top-down attention mechanism. Unlike pyramid backbone networks,\nour design features a branched architecture with three synergistic\nsub-networks: 1) a Base-Net that encodes low/mid-level features; 2) a\nlightweight Overview-Net that generates dynamic top-down attention through\ncoarse global context modeling (i.e., overview first); and 3) a robust\nFocus-Net that performs finer-grained perception guided by top-down attention\n(i.e., look closely next). To fully unleash the power of top-down attention, we\nfurther propose a novel context-mixing dynamic convolution (ContMix) that\neffectively models long-range dependencies while preserving inherent local\ninductive biases even when the input resolution increases, addressing critical\nlimitations in existing convolutions. Our OverLoCK exhibits a notable\nperformance improvement over existing methods. For instance, OverLoCK-T\nachieves a Top-1 accuracy of 84.2%, significantly surpassing ConvNeXt-B while\nusing only around one-third of the FLOPs/parameters. On object detection, our\nOverLoCK-S clearly surpasses MogaNet-B by 1% in AP^b. On semantic segmentation,\nour OverLoCK-T remarkably improves UniRepLKNet-T by 1.7% in mIoU. Code is\npublicly available at https://github.com/LMMMEng/OverLoCK.", "AI": {"tldr": "OverLoCK introduces a ConvNet backbone with top-down attention, outperforming existing methods in accuracy and efficiency.", "motivation": "Modern ConvNets lack biomimetic top-down attention, which is crucial for human vision. OverLoCK addresses this gap.", "method": "OverLoCK uses a branched architecture with Base-Net, Overview-Net, and Focus-Net, plus ContMix for long-range dependencies.", "result": "OverLoCK-T achieves 84.2% Top-1 accuracy, surpassing ConvNeXt-B with fewer FLOPs/parameters. It also excels in detection and segmentation.", "conclusion": "OverLoCK successfully integrates top-down attention, offering a powerful and efficient alternative to traditional ConvNets."}}
{"id": "2501.03492", "pdf": "https://arxiv.org/pdf/2501.03492", "abs": "https://arxiv.org/abs/2501.03492", "authors": ["Weijiang Xiong", "Robert Fonod", "Alexandre Alahi", "Nikolas Geroliminis"], "title": "Multi-Source Urban Traffic Flow Forecasting with Drone and Loop Detector Data", "categories": ["cs.LG"], "comment": null, "summary": "Traffic forecasting is a fundamental task in transportation research, however\nthe scope of current research has mainly focused on a single data modality of\nloop detectors. Recently, the advances in Artificial Intelligence and drone\ntechnologies have made possible novel solutions for efficient, accurate and\nflexible aerial observations of urban traffic. As a promising traffic\nmonitoring approach, drone-captured data can create an accurate multi-sensor\nmobility observatory for large-scale urban networks, when combined with\nexisting infrastructure. Therefore, this paper investigates the problem of\nmulti-source traffic speed prediction, simultaneously using drone and loop\ndetector data. A simple yet effective graph-based model HiMSNet is proposed to\nintegrate multiple data modalities and learn spatio-temporal correlations.\nDetailed analysis shows that predicting accurate segment-level speed is more\nchallenging than the regional speed, especially under high-demand scenarios\nwith heavier congestions and varying traffic dynamics. Utilizing both drone and\nloop detector data, the prediction accuracy can be improved compared to\nsingle-modality cases, when the sensors have lower coverages and are subject to\nnoise. Our simulation study based on vehicle trajectories in a real urban road\nnetwork has highlighted the added value of integrating drones in traffic\nforecasting and monitoring.", "AI": {"tldr": "The paper proposes HiMSNet, a graph-based model for multi-source traffic speed prediction using drone and loop detector data, improving accuracy over single-modality methods.", "motivation": "Current traffic forecasting relies on single-modality loop detectors, but drone-captured data offers a more accurate and flexible solution for urban traffic monitoring.", "method": "HiMSNet, a graph-based model, integrates drone and loop detector data to learn spatio-temporal correlations.", "result": "Combining drone and loop detector data improves prediction accuracy, especially in high-demand scenarios with noise or low sensor coverage.", "conclusion": "Integrating drones into traffic forecasting enhances accuracy and monitoring capabilities, as demonstrated in a real urban road network simulation."}}
{"id": "2503.12282", "pdf": "https://arxiv.org/pdf/2503.12282", "abs": "https://arxiv.org/abs/2503.12282", "authors": ["Liying Han", "Gaofeng Dong", "Xiaomin Ouyang", "Lance Kaplan", "Federico Cerutti", "Mani Srivastava"], "title": "Toward Foundation Models for Online Complex Event Detection in CPS-IoT: A Case Study", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Complex events (CEs) play a crucial role in CPS-IoT applications, enabling\nhigh-level decision-making in domains such as smart monitoring and autonomous\nsystems. However, most existing models focus on short-span perception tasks,\nlacking the long-term reasoning required for CE detection. CEs consist of\nsequences of short-time atomic events (AEs) governed by spatiotemporal\ndependencies. Detecting them is difficult due to long, noisy sensor data and\nthe challenge of filtering out irrelevant AEs while capturing meaningful\npatterns. This work explores CE detection as a case study for CPS-IoT\nfoundation models capable of long-term reasoning. We evaluate three approaches:\n(1) leveraging large language models (LLMs), (2) employing various neural\narchitectures that learn CE rules from data, and (3) adopting a neurosymbolic\napproach that integrates neural models with symbolic engines embedding human\nknowledge. Our results show that the state-space model, Mamba, which belongs to\nthe second category, outperforms all methods in accuracy and generalization to\nlonger, unseen sensor traces. These findings suggest that state-space models\ncould be a strong backbone for CPS-IoT foundation models for long-span\nreasoning tasks.", "AI": {"tldr": "The paper explores CE detection in CPS-IoT using three methods, finding state-space models like Mamba outperform others in accuracy and generalization.", "motivation": "Existing models lack long-term reasoning for CE detection, which is crucial for CPS-IoT applications like smart monitoring.", "method": "Three approaches are evaluated: LLMs, neural architectures learning CE rules, and neurosymbolic integration of neural models with symbolic engines.", "result": "Mamba, a state-space model, outperforms other methods in accuracy and generalization to longer, unseen sensor traces.", "conclusion": "State-space models like Mamba are promising for CPS-IoT foundation models requiring long-span reasoning."}}
{"id": "2503.00803", "pdf": "https://arxiv.org/pdf/2503.00803", "abs": "https://arxiv.org/abs/2503.00803", "authors": ["Qingwen Zhang", "Ajinkya Khoche", "Yi Yang", "Li Ling", "Sina Sharif Mansouri", "Olov Andersson", "Patric Jensfelt"], "title": "HiMo: High-Speed Objects Motion Compensation in Point Clouds", "categories": ["cs.CV", "cs.RO"], "comment": "12 pages", "summary": "LiDAR point cloud is essential for autonomous vehicles, but motion\ndistortions from dynamic objects degrade the data quality. While previous work\nhas considered distortions caused by ego motion, distortions caused by other\nmoving objects remain largely overlooked, leading to errors in object shape and\nposition. This distortion is particularly pronounced in high-speed environments\nsuch as highways and in multi-LiDAR configurations, a common setup for heavy\nvehicles. To address this challenge, we introduce HiMo, a pipeline that\nrepurposes scene flow estimation for non-ego motion compensation, correcting\nthe representation of dynamic objects in point clouds. During the development\nof HiMo, we observed that existing self-supervised scene flow estimators often\nproduce degenerate or inconsistent estimates under high-speed distortion. We\nfurther propose SeFlow++, a real-time scene flow estimator that achieves\nstate-of-the-art performance on both scene flow and motion compensation. Since\nwell-established motion distortion metrics are absent in the literature, we\nintroduce two evaluation metrics: compensation accuracy at a point level and\nshape similarity of objects. We validate HiMo through extensive experiments on\nArgoverse 2, ZOD, and a newly collected real-world dataset featuring highway\ndriving and multi-LiDAR-equipped heavy vehicles. Our findings show that HiMo\nimproves the geometric consistency and visual fidelity of dynamic objects in\nLiDAR point clouds, benefiting downstream tasks such as semantic segmentation\nand 3D detection. See https://kin-zhang.github.io/HiMo for more details.", "AI": {"tldr": "HiMo addresses motion distortions in LiDAR point clouds caused by dynamic objects, improving data quality for autonomous vehicles.", "motivation": "Motion distortions from dynamic objects degrade LiDAR data quality, especially in high-speed or multi-LiDAR setups, impacting object shape and position accuracy.", "method": "HiMo repurposes scene flow estimation for non-ego motion compensation, and introduces SeFlow++, a real-time scene flow estimator. Two new metrics evaluate motion distortion.", "result": "HiMo enhances geometric consistency and visual fidelity of dynamic objects, validated on Argoverse 2, ZOD, and a new dataset.", "conclusion": "HiMo effectively corrects distortions, benefiting downstream tasks like semantic segmentation and 3D detection."}}
{"id": "2501.11421", "pdf": "https://arxiv.org/pdf/2501.11421", "abs": "https://arxiv.org/abs/2501.11421", "authors": ["G Dhinesh Chandran", "Srinivas Reddy Kota", "Srikrishna Bhashyam"], "title": "Online Clustering with Bandit Information", "categories": ["cs.LG", "cs.IT", "math.IT", "math.ST", "stat.TH"], "comment": null, "summary": "We study the problem of online clustering within the multi-armed bandit\nframework under the fixed confidence setting. In this multi-armed bandit\nproblem, we have $M$ arms, each providing i.i.d. samples that follow a\nmultivariate Gaussian distribution with an {\\em unknown} mean and a known unit\ncovariance. The arms are grouped into $K$ clusters based on the distance\nbetween their means using the Single Linkage (SLINK) clustering algorithm on\nthe means of the arms. Since the true means are unknown, the objective is to\nobtain the above clustering of the arms with the minimum number of samples\ndrawn from the arms, subject to an upper bound on the error probability. We\nintroduce a novel algorithm, Average Tracking Bandit Online Clustering (ATBOC),\nand prove that this algorithm is order optimal, meaning that the upper bound on\nits expected sample complexity for given error probability $\\delta$ is within a\nfactor of 2 of an instance-dependent lower bound as $\\delta \\rightarrow 0$.\nFurthermore, we propose a computationally more efficient algorithm, Lower and\nUpper Confidence Bound-based Bandit Online Clustering (LUCBBOC), inspired by\nthe LUCB algorithm for best arm identification. Simulation results demonstrate\nthat the performance of LUCBBOC is comparable to that of ATBOC. We numerically\nassess the effectiveness of the proposed algorithms through numerical\nexperiments on both synthetic datasets and the real-world MovieLens dataset. To\nthe best of our knowledge, this is the first work on bandit online clustering\nthat allows arms with different means in a cluster and $K$ greater than 2.", "AI": {"tldr": "The paper introduces two algorithms, ATBOC and LUCBBOC, for online clustering in the multi-armed bandit framework, proving their order-optimality and efficiency.", "motivation": "To address the challenge of clustering arms with unknown means in the multi-armed bandit problem while minimizing sample complexity and ensuring low error probability.", "method": "Proposes ATBOC (order-optimal) and LUCBBOC (computationally efficient) algorithms, leveraging SLINK clustering and confidence bounds.", "result": "ATBOC is within a factor of 2 of the lower bound; LUCBBOC performs comparably. Both validated on synthetic and real-world data.", "conclusion": "First work enabling clustering with varying means and K>2, demonstrating effectiveness of the proposed algorithms."}}
{"id": "2503.12790", "pdf": "https://arxiv.org/pdf/2503.12790", "abs": "https://arxiv.org/abs/2503.12790", "authors": ["Xiaofei Kong", "Lei Li", "Zhaoyun Chen", "Cheng Xue", "Xiaofan Xu", "Huanyu Liu", "Yuchun Wu", "Yuan Fang", "Han Fang", "Kejiang Chen", "Yang Yang", "Menghan Dou", "Guoping Guo"], "title": "Quantum-Enhanced LLM Efficient Fine Tuning", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) enables efficient fine-tuning of pre-trained\nlanguage models through low-rank matrix approximation, achieving effectiveness\nin many scenarios. However, its representation capacity is constrained in\ncomplex tasks or high-rank dependency settings, potentially limiting model\nadaptability. To overcome the expressive bottleneck in classical low-rank\napproximation for fine-tuning large language models (LLMs), we propose Quantum\nTensor Hybrid Adaptation (QTHA), a parameter-efficient fine-tuning method that\nintegrates a quantum neural network (QNN) with a tensor network. QTHA explores\nquantum tensor hybrid fine-tuning within low-rank spaces by decomposing\npre-trained weights into quantum neural network and tensor network\nrepresentations, leveraging quantum state superposition to overcome classical\nrank limitations. Experiments demonstrate that QTHA achieves performance\ncomparable to or surpassing LoRA in parameter-efficient fine-tuning. Compared\nto LoRA, QTHA reduces trainable parameters by 76% while reducing training loss\nby up to 17% and improving test set performance by up to 17% within the same\ntraining steps. This research not only enables lightweight adaptation of\nquantum resources to the billion-parameter models but also validates the\nfeasibility of quantum hardware optimization driven by LLM tasks. It\nestablishes the first engineering-ready foundation for future quantum-enhanced\nArtificial General Intelligence (AGI) systems.", "AI": {"tldr": "QTHA integrates quantum neural networks and tensor networks to enhance fine-tuning of LLMs, outperforming LoRA with fewer parameters and better performance.", "motivation": "LoRA's limitations in complex tasks or high-rank dependencies prompted the development of QTHA to leverage quantum state superposition for improved adaptability.", "method": "QTHA decomposes pre-trained weights into quantum neural network and tensor network representations, combining quantum and classical approaches.", "result": "QTHA reduces trainable parameters by 76%, lowers training loss by 17%, and improves test performance by 17% compared to LoRA.", "conclusion": "QTHA provides a scalable, quantum-enhanced fine-tuning method for LLMs, paving the way for quantum-optimized AGI systems."}}
{"id": "2503.01576", "pdf": "https://arxiv.org/pdf/2503.01576", "abs": "https://arxiv.org/abs/2503.01576", "authors": ["Mojtaba Safari", "Shansong Wang", "Zach Eidex", "Qiang Li", "Erik H. Middlebrooks", "David S. Yu", "Xiaofeng Yang"], "title": "MRI super-resolution reconstruction using efficient diffusion probabilistic model with residual shifting", "categories": ["cs.CV", "physics.med-ph"], "comment": null, "summary": "Objective:This study introduces a residual error-shifting mechanism that\ndrastically reduces sampling steps while preserving critical anatomical\ndetails, thus accelerating MRI reconstruction. Approach:We propose a novel\ndiffusion-based SR framework called Res-SRDiff, which integrates residual error\nshifting into the forward diffusion process. This enables efficient HR image\nreconstruction by aligning the degraded HR and LR distributions.We evaluated\nRes-SRDiff on ultra-high-field brain T1 MP2RAGE maps and T2-weighted prostate\nimages, comparing it with Bicubic, Pix2pix, CycleGAN, and a conventional\ndenoising diffusion probabilistic model with vision transformer backbone\n(TM-DDPM), using quantitative metrics such as peak signal-to-noise ratio\n(PSNR), structural similarity index (SSIM), gradient magnitude similarity\ndeviation (GMSD), and learned perceptual image patch similarity (LPIPS). Main\nresults: Res-SRDiff significantly outperformed all comparative methods in terms\nof PSNR, SSIM, and GMSD across both datasets, with statistically significant\nimprovements (p-values<<0.05). The model achieved high-fidelity image\nrestoration with only four sampling steps, drastically reducing computational\ntime to under one second per slice, which is substantially faster than\nconventional TM-DDPM with around 20 seconds per slice. Qualitative analyses\nfurther demonstrated that Res-SRDiff effectively preserved fine anatomical\ndetails and lesion morphology in both brain and pelvic MRI images.\nSignificance: Our findings show that Res-SRDiff is an efficient and accurate\nMRI SR method, markedly improving computational efficiency and image quality.\nIntegrating residual error shifting into the diffusion process allows for rapid\nand robust HR image reconstruction, enhancing clinical MRI workflows and\nadvancing medical imaging research. The source\nat:https://github.com/mosaf/Res-SRDiff", "AI": {"tldr": "Res-SRDiff, a diffusion-based SR framework with residual error-shifting, accelerates MRI reconstruction by reducing sampling steps while preserving anatomical details, outperforming other methods in quality and speed.", "motivation": "To improve MRI reconstruction efficiency and accuracy by reducing computational time without compromising image quality.", "method": "Proposes Res-SRDiff, integrating residual error-shifting into diffusion processes for high-fidelity image reconstruction with fewer sampling steps.", "result": "Res-SRDiff outperforms Bicubic, Pix2pix, CycleGAN, and TM-DDPM in PSNR, SSIM, and GMSD, achieving fast reconstruction (under 1 second per slice).", "conclusion": "Res-SRDiff is an efficient and accurate MRI SR method, enhancing clinical workflows and medical imaging research."}}
{"id": "2502.00177", "pdf": "https://arxiv.org/pdf/2502.00177", "abs": "https://arxiv.org/abs/2502.00177", "authors": ["Eirini Schoinas", "Adyah Rastogi", "Anissa Carter", "Jacob Granley", "Michael Beyeler"], "title": "Evaluating Deep Human-in-the-Loop Optimization for Retinal Implants Using Sighted Participants", "categories": ["cs.LG", "cs.CV", "cs.HC", "I.2.10"], "comment": null, "summary": "Human-in-the-loop optimization (HILO) is a promising approach for\npersonalizing visual prostheses by iteratively refining stimulus parameters\nbased on user feedback. Previous work demonstrated HILO's efficacy in\nsimulation, but its performance with human participants remains untested. Here\nwe evaluate HILO using sighted participants viewing simulated prosthetic vision\nto assess its ability to optimize stimulation strategies under realistic\nconditions. Participants selected between phosphenes generated by competing\nencoders to iteratively refine a deep stimulus encoder (DSE). We tested HILO in\nthree conditions: standard optimization, threshold misspecifications, and\nout-of-distribution parameter sampling. Participants consistently preferred\nHILO-generated stimuli over both a naive encoder and the DSE alone, with log\nodds favoring HILO across all conditions. We also observed key differences\nbetween human and simulated decision-making, highlighting the importance of\nvalidating optimization strategies with human participants. These findings\nsupport HILO as a viable approach for adapting visual prostheses to\nindividuals. Clinical relevance: Validating HILO with sighted participants\nviewing simulated prosthetic vision is an important step toward personalized\ncalibration of future visual prostheses.", "AI": {"tldr": "HILO optimizes visual prostheses using human feedback, showing preference over naive methods in tests with sighted participants.", "motivation": "To validate HILO's efficacy with human participants, as previous work only tested it in simulation.", "method": "Participants refined a deep stimulus encoder by selecting phosphenes in three conditions: standard optimization, threshold misspecifications, and out-of-distribution sampling.", "result": "Participants preferred HILO-generated stimuli over naive methods, with log odds favoring HILO in all conditions. Human decision-making differed from simulations.", "conclusion": "HILO is viable for personalizing visual prostheses, emphasizing the need for human validation in optimization strategies."}}
{"id": "2503.13558", "pdf": "https://arxiv.org/pdf/2503.13558", "abs": "https://arxiv.org/abs/2503.13558", "authors": ["Jingyuan Xue", "Longfei Wei", "Fang Sheng", "Jianfei Zhang"], "title": "Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Battery degradation significantly impacts the reliability and efficiency of\nenergy storage systems, particularly in electric vehicles and industrial\napplications. Predicting the remaining useful life (RUL) of lithium-ion\nbatteries is crucial for optimizing maintenance schedules, reducing costs, and\nimproving safety. Traditional RUL prediction methods often struggle with\nnonlinear degradation patterns and uncertainty quantification. To address these\nchallenges, we propose a hybrid survival analysis framework integrating\nsurvival data reconstruction, survival model learning, and survival probability\nestimation. Our approach transforms battery voltage time series into\ntime-to-failure data using path signatures. The multiple Cox-based survival\nmodels and machine-learning-based methods, such as DeepHit and MTLR, are\nlearned to predict battery failure-free probabilities over time. Experiments\nconducted on the Toyota battery and NASA battery datasets demonstrate the\neffectiveness of our approach, achieving high time-dependent AUC and\nconcordance index (C-Index) while maintaining a low integrated Brier score. The\ndata and source codes for this work are available to the public at\nhttps://github.com/thinkxca/rul.", "AI": {"tldr": "A hybrid survival analysis framework is proposed to predict the remaining useful life (RUL) of lithium-ion batteries, addressing nonlinear degradation and uncertainty.", "motivation": "Battery degradation affects reliability and efficiency; accurate RUL prediction is needed for maintenance, cost reduction, and safety.", "method": "Transforms voltage time series into time-to-failure data using path signatures, integrating Cox-based and machine-learning models (DeepHit, MTLR).", "result": "High time-dependent AUC and C-Index, low integrated Brier score on Toyota and NASA datasets.", "conclusion": "The framework effectively predicts RUL, with publicly available data and code."}}
{"id": "2503.02247", "pdf": "https://arxiv.org/pdf/2503.02247", "abs": "https://arxiv.org/abs/2503.02247", "authors": ["Dujun Nie", "Xianda Guo", "Yiqun Duan", "Ruijun Zhang", "Long Chen"], "title": "WMNav: Integrating Vision-Language Models into World Models for Object Goal Navigation", "categories": ["cs.CV", "cs.RO"], "comment": "8 pages, 5 figures", "summary": "Object Goal Navigation-requiring an agent to locate a specific object in an\nunseen environment-remains a core challenge in embodied AI. Although recent\nprogress in Vision-Language Model (VLM)-based agents has demonstrated promising\nperception and decision-making abilities through prompting, none has yet\nestablished a fully modular world model design that reduces risky and costly\ninteractions with the environment by predicting the future state of the world.\nWe introduce WMNav, a novel World Model-based Navigation framework powered by\nVision-Language Models (VLMs). It predicts possible outcomes of decisions and\nbuilds memories to provide feedback to the policy module. To retain the\npredicted state of the environment, WMNav proposes the online maintained\nCuriosity Value Map as part of the world model memory to provide dynamic\nconfiguration for navigation policy. By decomposing according to a human-like\nthinking process, WMNav effectively alleviates the impact of model\nhallucination by making decisions based on the feedback difference between the\nworld model plan and observation. To further boost efficiency, we implement a\ntwo-stage action proposer strategy: broad exploration followed by precise\nlocalization. Extensive evaluation on HM3D and MP3D validates WMNav surpasses\nexisting zero-shot benchmarks in both success rate and exploration efficiency\n(absolute improvement: +3.2% SR and +3.2% SPL on HM3D, +13.5% SR and +1.1% SPL\non MP3D). Project page: https://b0b8k1ng.github.io/WMNav/.", "AI": {"tldr": "WMNav introduces a world model-based navigation framework using VLMs to predict outcomes and reduce risky interactions, improving success rates and efficiency in object goal navigation.", "motivation": "Current VLM-based agents lack a modular world model to predict future states, leading to costly interactions. WMNav aims to address this gap.", "method": "WMNav uses a Curiosity Value Map for memory, a two-stage action proposer (broad exploration then precise localization), and feedback-based decision-making to reduce model hallucination.", "result": "WMNav outperforms zero-shot benchmarks with absolute improvements of +3.2% SR and +3.2% SPL on HM3D, and +13.5% SR and +1.1% SPL on MP3D.", "conclusion": "WMNav's modular design and feedback-driven approach enhance navigation efficiency and success, setting a new benchmark for object goal navigation."}}
{"id": "2502.04664", "pdf": "https://arxiv.org/pdf/2502.04664", "abs": "https://arxiv.org/abs/2502.04664", "authors": ["Chen Fan", "Mark Schmidt", "Christos Thrampoulidis"], "title": "Implicit bias of Normalized Steepest Descent in Multiclass Classification: Sign Descent, Spectral Descent, and Adam", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "In the optimization of overparameterized models, different gradient-based\nmethods can achieve zero training error yet converge to distinctly different\nsolutions inducing different generalization properties. Despite a decade of\nresearch on implicit optimization bias, important questions remain open even in\nthe foundational case of linear classification with separable data. We address\nthis gap by characterizing the implicit bias of both Adam and Sign gradient\ndescent (SignGD) in multi-class cross-entropy minimization: we prove that their\niterates converge to solutions maximizing the margin with respect to the\nclassifier matrix's max-norm, and we establish the corresponding convergence\nrates. We then generalize our analysis to p-norm normalized steepest descent\n(NSD) algorithms. This includes Spectral Descent, which we show converges to\nthe max-margin solution with respect to the spectral norm. A key insight is\nthat the analysis of general entry-wise and Schatten p-norms can be reduced to\nthe analysis of NSD with max-norm (i.e., SignGD) by exploiting a natural\nordering property between all p-norms relative to the max-norm and its dual\nsum-norm. Our results demonstrate that the multi-class linear setting, which is\ninherently richer than the binary counterpart, provides the most transparent\nplayground for studying implicit biases of matrix-parameter optimization\nalgorithms.", "AI": {"tldr": "The paper analyzes the implicit bias of gradient-based methods like Adam and SignGD in multi-class linear classification, proving they converge to max-margin solutions and extending this to p-norm NSD algorithms.", "motivation": "To address open questions about implicit optimization bias in linear classification with separable data, particularly for multi-class settings.", "method": "Characterizes the implicit bias of Adam and SignGD, proves convergence to max-margin solutions, and generalizes to p-norm NSD algorithms like Spectral Descent.", "result": "Shows convergence to max-margin solutions for various norms, with insights reducing analysis to max-norm cases.", "conclusion": "Multi-class linear settings offer a clear framework for studying implicit biases in matrix-parameter optimization."}}
{"id": "2503.13915", "pdf": "https://arxiv.org/pdf/2503.13915", "abs": "https://arxiv.org/abs/2503.13915", "authors": ["Dongkwan Lee", "Kyomin Hwang", "Nojun Kwak"], "title": "Unlocking the Potential of Unlabeled Data in Semi-Supervised Domain Generalization", "categories": ["cs.CV", "cs.AI"], "comment": "CVPR 2025", "summary": "We address the problem of semi-supervised domain generalization (SSDG), where\nthe distributions of train and test data differ, and only a small amount of\nlabeled data along with a larger amount of unlabeled data are available during\ntraining. Existing SSDG methods that leverage only the unlabeled samples for\nwhich the model's predictions are highly confident (confident-unlabeled\nsamples), limit the full utilization of the available unlabeled data. To the\nbest of our knowledge, we are the first to explore a method for incorporating\nthe unconfident-unlabeled samples that were previously disregarded in SSDG\nsetting. To this end, we propose UPCSC to utilize these unconfident-unlabeled\nsamples in SSDG that consists of two modules: 1) Unlabeled Proxy-based\nContrastive learning (UPC) module, treating unconfident-unlabeled samples as\nadditional negative pairs and 2) Surrogate Class learning (SC) module,\ngenerating positive pairs for unconfident-unlabeled samples using their\nconfusing class set. These modules are plug-and-play and do not require any\ndomain labels, which can be easily integrated into existing approaches.\nExperiments on four widely used SSDG benchmarks demonstrate that our approach\nconsistently improves performance when attached to baselines and outperforms\ncompeting plug-and-play methods. We also analyze the role of our method in\nSSDG, showing that it enhances class-level discriminability and mitigates\ndomain gaps. The code is available at https://github.com/dongkwani/UPCSC.", "AI": {"tldr": "The paper proposes UPCSC, a method to utilize unconfident-unlabeled samples in semi-supervised domain generalization (SSDG), improving performance by enhancing class-level discriminability and reducing domain gaps.", "motivation": "Existing SSDG methods underutilize unlabeled data by focusing only on confident samples, leaving unconfident samples unexplored.", "method": "UPCSC introduces two modules: Unlabeled Proxy-based Contrastive learning (UPC) for negative pairs and Surrogate Class learning (SC) for positive pairs, both plug-and-play and domain-label-free.", "result": "Experiments on four benchmarks show UPCSC consistently improves baseline performance and outperforms competitors.", "conclusion": "UPCSC effectively leverages unconfident-unlabeled samples, enhancing discriminability and mitigating domain gaps in SSDG."}}
{"id": "2503.10195", "pdf": "https://arxiv.org/pdf/2503.10195", "abs": "https://arxiv.org/abs/2503.10195", "authors": ["Hongze Sun", "Jun Wang", "Wuque Cai", "Duo Chen", "Qianqian Liao", "Jiayi He", "Yan Cui", "Dezhong Yao", "Daqing Guo"], "title": "ST-FlowNet: An Efficient Spiking Neural Network for Event-Based Optical Flow Estimation", "categories": ["cs.CV", "cs.NE", "q-bio.NC"], "comment": "13 pages, 6 figures, 6 tables; This work has been submitted to Neural\n  Networks for possible publication", "summary": "Spiking Neural Networks (SNNs) have emerged as a promising tool for\nevent-based optical flow estimation tasks due to their ability to leverage\nspatio-temporal information and low-power capabilities. However, the\nperformance of SNN models is often constrained, limiting their application in\nreal-world scenarios. In this work, we address this gap by proposing a novel\nneural network architecture, ST-FlowNet, specifically tailored for optical flow\nestimation from event-based data. The ST-FlowNet architecture integrates\nConvGRU modules to facilitate cross-modal feature augmentation and temporal\nalignment of the predicted optical flow, improving the network's ability to\ncapture complex motion dynamics. Additionally, to overcome the challenges\nassociated with training SNNs, we introduce a novel approach to derive SNN\nmodels from pre-trained artificial neural networks (ANNs) through ANN-to-SNN\nconversion or our proposed BISNN method. Notably, the BISNN method alleviates\nthe complexities involved in biological parameter selection, further enhancing\nthe robustness of SNNs in optical flow estimation tasks. Extensive evaluations\non three benchmark event-based datasets demonstrate that the SNN-based\nST-FlowNet model outperforms state-of-the-art methods, delivering superior\nperformance in accurate optical flow estimation across a diverse range of\ndynamic visual scenes. Furthermore, the inherent energy efficiency of SNN\nmodels is highlighted, establishing a compelling advantage for their practical\ndeployment. Overall, our work presents a novel framework for optical flow\nestimation using SNNs and event-based data, contributing to the advancement of\nneuromorphic vision applications.", "AI": {"tldr": "The paper introduces ST-FlowNet, a novel SNN architecture for event-based optical flow estimation, leveraging ConvGRU modules and a BISNN method for improved performance and training efficiency.", "motivation": "SNNs show promise for optical flow estimation but face performance constraints. The work aims to enhance SNN applicability in real-world scenarios.", "method": "Proposes ST-FlowNet with ConvGRU modules for feature augmentation and temporal alignment. Introduces BISNN for simplified SNN training from ANNs.", "result": "ST-FlowNet outperforms state-of-the-art methods on benchmark datasets, offering accurate optical flow estimation and energy efficiency.", "conclusion": "The work advances neuromorphic vision by presenting a robust SNN framework for optical flow estimation with practical deployment advantages."}}
{"id": "2502.07011", "pdf": "https://arxiv.org/pdf/2502.07011", "abs": "https://arxiv.org/abs/2502.07011", "authors": ["Georgios Syros", "Anshuman Suri", "Farinaz Koushanfar", "Cristina Nita-Rotaru", "Alina Oprea"], "title": "DROP: Poison Dilution via Knowledge Distillation for Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": null, "summary": "Federated Learning is vulnerable to adversarial manipulation, where malicious\nclients can inject poisoned updates to influence the global model's behavior.\nWhile existing defense mechanisms have made notable progress, they fail to\nprotect against adversaries that aim to induce targeted backdoors under\ndifferent learning and attack configurations. To address this limitation, we\nintroduce DROP (Distillation-based Reduction Of Poisoning), a novel defense\nmechanism that combines clustering and activity-tracking techniques with\nextraction of benign behavior from clients via knowledge distillation to tackle\nstealthy adversaries that manipulate low data poisoning rates and diverse\nmalicious client ratios within the federation. Through extensive\nexperimentation, our approach demonstrates superior robustness compared to\nexisting defenses across a wide range of learning configurations. Finally, we\nevaluate existing defenses and our method under the challenging setting of\nnon-IID client data distribution and highlight the challenges of designing a\nresilient FL defense in this setting.", "AI": {"tldr": "DROP is a new defense mechanism for Federated Learning that combats stealthy adversarial attacks by combining clustering, activity-tracking, and knowledge distillation, outperforming existing methods.", "motivation": "Existing defenses fail against targeted backdoor attacks under varied learning and attack configurations, necessitating a more robust solution.", "method": "DROP integrates clustering, activity-tracking, and knowledge distillation to extract benign behavior and mitigate poisoning attacks.", "result": "DROP shows superior robustness across diverse learning configurations, including non-IID data distributions.", "conclusion": "DROP addresses limitations of current defenses, proving effective against stealthy adversaries, but challenges remain in non-IID settings."}}
{"id": "2503.17401", "pdf": "https://arxiv.org/pdf/2503.17401", "abs": "https://arxiv.org/abs/2503.17401", "authors": ["Torsten Tiltack"], "title": "AIJIM: A Scalable Model for Real-Time AI in Environmental Journalism", "categories": ["cs.CY", "cs.AI", "cs.HC", "68T45", "I.2.10; H.3.5; J.4"], "comment": "22 pages, 10 figures, 5 tables. Keywords: Artificial Intelligence,\n  Environmental Journalism, Real-Time Reporting, Vision Transformers, Image\n  Recognition, Crowdsourced Validation, GPT-4, Automated News Generation, GIS\n  Integration, Data Privacy Compliance, Explainable AI (XAI), AI Ethics,\n  Sustainable Development", "summary": "This paper introduces AIJIM, the Artificial Intelligence Journalism\nIntegration Model -- a novel framework for integrating real-time AI into\nenvironmental journalism. AIJIM combines Vision Transformer-based hazard\ndetection, crowdsourced validation with 252 validators, and automated reporting\nwithin a scalable, modular architecture. A dual-layer explainability approach\nensures ethical transparency through fast CAM-based visual overlays and\noptional LIME-based box-level interpretations. Validated in a 2024 pilot on the\nisland of Mallorca using the NamicGreen platform, AIJIM achieved 85.4\\%\ndetection accuracy and 89.7\\% agreement with expert annotations, while reducing\nreporting latency by 40\\%. Unlike conventional approaches such as Data-Driven\nJournalism or AI Fact-Checking, AIJIM provides a transferable model for\nparticipatory, community-driven environmental reporting, advancing journalism,\nartificial intelligence, and sustainability in alignment with the UN\nSustainable Development Goals and the EU AI Act.", "AI": {"tldr": "AIJIM is a new AI-driven framework for environmental journalism, combining hazard detection, crowdsourced validation, and automated reporting with high accuracy and transparency.", "motivation": "To integrate real-time AI into environmental journalism, ensuring ethical transparency and community participation while aligning with sustainability goals.", "method": "Uses Vision Transformer-based hazard detection, crowdsourced validation (252 validators), and automated reporting with a dual-layer explainability approach (CAM and LIME).", "result": "Achieved 85.4% detection accuracy, 89.7% agreement with experts, and reduced reporting latency by 40% in a 2024 pilot.", "conclusion": "AIJIM offers a scalable, participatory model for environmental journalism, advancing AI, journalism, and sustainability goals."}}
{"id": "2503.12150", "pdf": "https://arxiv.org/pdf/2503.12150", "abs": "https://arxiv.org/abs/2503.12150", "authors": ["Hongyu Sun", "Qiuhong Ke", "Ming Cheng", "Yongcai Wang", "Deying Li", "Chenhui Gou", "Jianfei Cai"], "title": "Point-Cache: Test-time Dynamic and Hierarchical Cache for Robust and Generalizable Point Cloud Analysis", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025; 24 pages, 14 figures, 18 tables", "summary": "This paper proposes a general solution to enable point cloud recognition\nmodels to handle distribution shifts at test time. Unlike prior methods, which\nrely heavily on training data (often inaccessible during online inference) and\nare limited to recognizing a fixed set of point cloud classes predefined during\ntraining, we explore a more practical and challenging scenario: adapting the\nmodel solely based on online test data to recognize both previously seen\nclasses and novel, unseen classes at test time. To this end, we develop\n\\textbf{Point-Cache}, a hierarchical cache model that captures essential clues\nof online test samples, particularly focusing on the global structure of point\nclouds and their local-part details. Point-Cache, which serves as a rich 3D\nknowledge base, is dynamically managed to prioritize the inclusion of\nhigh-quality samples. Designed as a plug-and-play module, our method can be\nflexibly integrated into large multimodal 3D models to support open-vocabulary\npoint cloud recognition. Notably, our solution operates with efficiency\ncomparable to zero-shot inference, as it is entirely training-free. Point-Cache\ndemonstrates substantial gains across 8 challenging benchmarks and 4\nrepresentative large 3D models, highlighting its effectiveness. Code is\navailable at https://github.com/auniquesun/Point-Cache.", "AI": {"tldr": "Proposes Point-Cache, a hierarchical cache model for open-vocabulary point cloud recognition, handling distribution shifts and novel classes at test time without training.", "motivation": "Addresses the limitation of prior methods that rely on fixed training data and predefined classes, focusing on adapting models dynamically to unseen classes during inference.", "method": "Develops Point-Cache, a plug-and-play module capturing global and local details of point clouds, dynamically managed for high-quality samples.", "result": "Achieves significant improvements across 8 benchmarks and 4 large 3D models, operating efficiently without training.", "conclusion": "Point-Cache is an effective, training-free solution for open-vocabulary point cloud recognition, adaptable to various models."}}
{"id": "2502.08231", "pdf": "https://arxiv.org/pdf/2502.08231", "abs": "https://arxiv.org/abs/2502.08231", "authors": ["Evgeniia Tokarchuk", "Hua Chang Bakker", "Vlad Niculae"], "title": "Keep your distance: learning dispersed embeddings on $\\mathbb{S}_d$", "categories": ["cs.LG"], "comment": null, "summary": "Learning well-separated features in high-dimensional spaces, such as text or\nimage embeddings, is crucial for many machine learning applications. Achieving\nsuch separation can be effectively accomplished through the dispersion of\nembeddings, where unrelated vectors are pushed apart as much as possible. By\nconstraining features to be on a hypersphere, we can connect dispersion to\nwell-studied problems in mathematics and physics, where optimal solutions are\nknown for limited low-dimensional cases. However, in representation learning we\ntypically deal with a large number of features in high-dimensional space, and\nmoreover, dispersion is usually traded off with some other task-oriented\ntraining objective, making existing theoretical and numerical solutions\ninapplicable. Therefore, it is common to rely on gradient-based methods to\nencourage dispersion, usually by minimizing some function of the pairwise\ndistances. In this work, we first give an overview of existing methods from\ndisconnected literature, making new connections and highlighting similarities.\nNext, we introduce some new angles. We propose to reinterpret pairwise\ndispersion using a maximum mean discrepancy (MMD) motivation. We then propose\nan online variant of the celebrated Lloyd's algorithm, of K-Means fame, as an\neffective alternative regularizer for dispersion on generic domains. Finally,\nwe derive a novel dispersion method that directly exploits properties of the\nhypersphere. Our experiments show the importance of dispersion in image\nclassification and natural language processing tasks, and how algorithms\nexhibit different trade-offs in different regimes.", "AI": {"tldr": "The paper discusses methods for achieving well-separated features in high-dimensional spaces, introduces new approaches for dispersion, and evaluates their effectiveness in machine learning tasks.", "motivation": "Learning well-separated features is crucial for machine learning, but existing methods are limited in high-dimensional spaces or when combined with task-oriented objectives.", "method": "The paper reviews existing methods, proposes a reinterpretation using MMD, introduces an online variant of Lloyd's algorithm, and derives a novel hypersphere-based dispersion method.", "result": "Experiments demonstrate the importance of dispersion in tasks like image classification and NLP, showing trade-offs between different algorithms.", "conclusion": "The paper highlights the significance of dispersion and presents new methods to achieve it, offering practical insights for representation learning."}}
{"id": "2503.17794", "pdf": "https://arxiv.org/pdf/2503.17794", "abs": "https://arxiv.org/abs/2503.17794", "authors": ["Ketan Suhaas Saichandran", "Xavier Thomas", "Prakhar Kaushik", "Deepti Ghadiyaram"], "title": "Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Text-to-image generative models often struggle with long prompts detailing\ncomplex scenes, diverse objects with distinct visual characteristics and\nspatial relationships. In this work, we propose SCoPE (Scheduled interpolation\nof Coarse-to-fine Prompt Embeddings), a training-free method to improve\ntext-to-image alignment by progressively refining the input prompt in a\ncoarse-to-fine-grained manner. Given a detailed input prompt, we first\ndecompose it into multiple sub-prompts which evolve from describing broad scene\nlayout to highly intricate details. During inference, we interpolate between\nthese sub-prompts and thus progressively introduce finer-grained details into\nthe generated image. Our training-free plug-and-play approach significantly\nenhances prompt alignment, achieves an average improvement of up to +4% in\nVisual Question Answering (VQA) scores over the Stable Diffusion baselines on\n85% of the prompts from the GenAI-Bench dataset.", "AI": {"tldr": "SCoPE improves text-to-image alignment by refining prompts from coarse to fine details, enhancing VQA scores by 4% over baselines.", "motivation": "Text-to-image models struggle with complex, detailed prompts, leading to misalignment.", "method": "Decomposes prompts into sub-prompts (broad to intricate), interpolates during inference for progressive detail.", "result": "+4% VQA score improvement on 85% of GenAI-Bench prompts.", "conclusion": "SCoPE is a training-free, plug-and-play solution for better prompt alignment."}}
{"id": "2503.12929", "pdf": "https://arxiv.org/pdf/2503.12929", "abs": "https://arxiv.org/abs/2503.12929", "authors": ["Xuying Zhang", "Yupeng Zhou", "Kai Wang", "Yikai Wang", "Zhen Li", "Shaohui Jiao", "Daquan Zhou", "Qibin Hou", "Ming-Ming Cheng"], "title": "AR-1-to-3: Single Image to Consistent 3D Object Generation via Next-View Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Novel view synthesis (NVS) is a cornerstone for image-to-3d creation.\nHowever, existing works still struggle to maintain consistency between the\ngenerated views and the input views, especially when there is a significant\ncamera pose difference, leading to poor-quality 3D geometries and textures. We\nattribute this issue to their treatment of all target views with equal priority\naccording to our empirical observation that the target views closer to the\ninput views exhibit higher fidelity. With this inspiration, we propose\nAR-1-to-3, a novel next-view prediction paradigm based on diffusion models that\nfirst generates views close to the input views, which are then utilized as\ncontextual information to progressively synthesize farther views. To encode the\ngenerated view subsequences as local and global conditions for the next-view\nprediction, we accordingly develop a stacked local feature encoding strategy\n(Stacked-LE) and an LSTM-based global feature encoding strategy (LSTM-GE).\nExtensive experiments demonstrate that our method significantly improves the\nconsistency between the generated views and the input views, producing\nhigh-fidelity 3D assets.", "AI": {"tldr": "AR-1-to-3 improves novel view synthesis by prioritizing closer views and using diffusion models for progressive synthesis, enhancing consistency and fidelity.", "motivation": "Existing methods struggle with consistency in novel view synthesis, especially with large camera pose differences, leading to poor 3D quality.", "method": "Proposes AR-1-to-3, a diffusion model-based approach that prioritizes closer views and uses Stacked-LE and LSTM-GE for feature encoding.", "result": "Significantly improves consistency and fidelity in generated views, producing high-quality 3D assets.", "conclusion": "AR-1-to-3 effectively addresses consistency issues in novel view synthesis, outperforming existing methods."}}
{"id": "2502.15496", "pdf": "https://arxiv.org/pdf/2502.15496", "abs": "https://arxiv.org/abs/2502.15496", "authors": ["John D. Jakeman", "Lorena A. Barba", "Joaquim R. R. A. Martins", "Thomas O'Leary-Roseberry"], "title": "Verification and Validation for Trustworthy Scientific Machine Learning", "categories": ["cs.LG", "68T07, 68N30", "I.6.4; I.6.5; G.4"], "comment": null, "summary": "Scientific machine learning (SciML) models are transforming many scientific\ndisciplines. However, the development of good modeling practices to increase\nthe trustworthiness of SciML has lagged behind its application, limiting its\npotential impact. The goal of this paper is to start a discussion on\nestablishing consensus-based good practices for predictive SciML. We identify\nkey challenges in applying existing computational science and engineering\nguidelines, such as verification and validation protocols, and provide\nrecommendations to address these challenges. Our discussion focuses on\npredictive SciML, which uses machine learning models to learn, improve, and\naccelerate numerical simulations of physical systems. While centered on\npredictive applications, our 16 recommendations aim to help researchers conduct\nand document their modeling processes rigorously across all SciML domains.", "AI": {"tldr": "The paper discusses establishing good practices for predictive scientific machine learning (SciML) to enhance trustworthiness, addressing challenges in applying existing guidelines and providing 16 recommendations.", "motivation": "The rapid application of SciML has outpaced the development of trustworthy modeling practices, limiting its potential impact. The paper aims to initiate consensus on good practices.", "method": "The authors identify challenges in applying computational science and engineering guidelines (e.g., verification and validation) to SciML and propose solutions.", "result": "16 recommendations are provided to improve rigor in predictive SciML modeling and documentation, applicable across SciML domains.", "conclusion": "The paper advocates for standardized practices in SciML to ensure reliability and broader impact, focusing on predictive applications but extending to all SciML areas."}}
{"id": "2504.00058", "pdf": "https://arxiv.org/pdf/2504.00058", "abs": "https://arxiv.org/abs/2504.00058", "authors": ["Lahiru Akmeemana", "Chamodya Attanayake", "Husni Faiz", "Sandareka Wickramanayake"], "title": "GAL-MAD: Towards Explainable Anomaly Detection in Microservice Applications Using Graph Attention Networks", "categories": ["cs.SE", "cs.AI", "cs.LG", "I.2.m"], "comment": "Preprint - Journal of Universal Computer Science, 13 pages, preprint,\n  7 figures", "summary": "The transition to microservices has revolutionized software architectures,\noffering enhanced scalability and modularity. However, the distributed and\ndynamic nature of microservices introduces complexities in ensuring system\nreliability, making anomaly detection crucial for maintaining performance and\nfunctionality. Anomalies stemming from network and performance issues must be\nswiftly identified and addressed. Existing anomaly detection techniques often\nrely on statistical models or machine learning methods that struggle with the\nhigh-dimensional, interdependent data inherent in microservice applications.\nCurrent techniques and available datasets predominantly focus on system traces\nand logs, limiting their ability to support advanced detection models. This\npaper addresses these gaps by introducing the RS-Anomic dataset generated using\nthe open-source RobotShop microservice application. The dataset captures\nmultivariate performance metrics and response times under normal and anomalous\nconditions, encompassing ten types of anomalies. We propose a novel anomaly\ndetection model called Graph Attention and LSTM-based Microservice Anomaly\nDetection (GAL-MAD), leveraging Graph Attention and Long Short-Term Memory\narchitectures to capture spatial and temporal dependencies in microservices. We\nutilize SHAP values to localize anomalous services and identify root causes to\nenhance explainability. Experimental results demonstrate that GAL-MAD\noutperforms state-of-the-art models on the RS-Anomic dataset, achieving higher\naccuracy and recall across varying anomaly rates. The explanations provide\nactionable insights into service anomalies, which benefits system\nadministrators.", "AI": {"tldr": "The paper introduces the RS-Anomic dataset and GAL-MAD, a novel anomaly detection model for microservices, outperforming existing methods with higher accuracy and explainability.", "motivation": "The distributed nature of microservices complicates reliability, and current anomaly detection methods struggle with high-dimensional data.", "method": "Proposes GAL-MAD, combining Graph Attention and LSTM to capture spatial-temporal dependencies, and uses SHAP for explainability.", "result": "GAL-MAD achieves superior accuracy and recall on the RS-Anomic dataset, providing actionable insights for administrators.", "conclusion": "The approach effectively addresses microservice anomaly detection challenges, offering improved performance and explainability."}}
{"id": "2503.13777", "pdf": "https://arxiv.org/pdf/2503.13777", "abs": "https://arxiv.org/abs/2503.13777", "authors": ["Xuyang Fang", "Sion Hannuna", "Neill Campbell"], "title": "8-Calves Image dataset", "categories": ["cs.CV"], "comment": "12 pages, 5 figures", "summary": "We introduce the 8-Calves dataset, a benchmark for evaluating object\ndetection and identity preservation in occlusion-rich, temporally consistent\nenvironments. Comprising a 1-hour video (67,760 frames) of eight Holstein\nFriesian calves with unique coat patterns and 900 static frames, the dataset\nemphasizes real-world challenges like prolonged occlusions, motion blur, and\npose variation. By fine-tuning 28 object detectors (YOLO variants,\ntransformers) and evaluating 23 pretrained backbones (ResNet, ConvNextV2,\nViTs), we expose critical architectural trade-offs: smaller models (e.g.,\nConvNextV2 Nano, 15.6M parameters) excel in efficiency and retrieval accuracy,\nwhile pure vision transformers lag in occlusion-heavy settings. The dataset's\nstructured design-fixed camera views, natural motion, and verified\nidentities-provides a reproducible testbed for object detection challenges\n(mAP50:95: 56.5-66.4%), bridging synthetic simplicity and domain-specific\ncomplexity. The dataset and benchmark code are all publicly available at\nhttps://huggingface.co/datasets/tonyFang04/8-calves. Limitations include\npartial labeling and detector bias, addressed in later sections.", "AI": {"tldr": "The 8-Calves dataset is a benchmark for object detection and identity preservation in occlusion-rich, temporally consistent environments, featuring a 1-hour video and 900 static frames. It evaluates 28 object detectors and 23 backbones, revealing trade-offs in model performance.", "motivation": "To address real-world challenges like occlusions, motion blur, and pose variation in object detection, providing a reproducible testbed bridging synthetic and domain-specific complexity.", "method": "Fine-tuning 28 object detectors (YOLO variants, transformers) and evaluating 23 pretrained backbones (ResNet, ConvNextV2, ViTs) on the 8-Calves dataset.", "result": "Smaller models (e.g., ConvNextV2 Nano) excel in efficiency and retrieval accuracy, while pure vision transformers struggle in occlusion-heavy settings (mAP50:95: 56.5-66.4%).", "conclusion": "The dataset offers a structured, reproducible benchmark for object detection, though limitations like partial labeling and detector bias exist."}}
{"id": "2503.00961", "pdf": "https://arxiv.org/pdf/2503.00961", "abs": "https://arxiv.org/abs/2503.00961", "authors": ["Md Abrar Jahin", "Shahriar Soudeep", "Fahmid Al Farid", "M. F. Mridha", "Raihan Kabir", "Md Rashedul Islam", "Hezerul Abdul Karim"], "title": "CAGN-GAT Fusion: A Hybrid Contrastive Attentive Graph Neural Network for Network Intrusion Detection", "categories": ["cs.LG"], "comment": "Accepted in 38th International Conference on Industrial, Engineering\n  & Other Applications of Applied Intelligent Systems (IEA/AIE 2025),\n  Kitakyushu, Japan, Jul 2025", "summary": "Cybersecurity threats are growing, making network intrusion detection\nessential. Traditional machine learning models remain effective in\nresource-limited environments due to their efficiency, requiring fewer\nparameters and less computational time. However, handling short and highly\nimbalanced datasets remains challenging. In this study, we propose the fusion\nof a Contrastive Attentive Graph Network and Graph Attention Network (CAGN-GAT\nFusion) and benchmark it against 15 other models, including both Graph Neural\nNetworks (GNNs) and traditional ML models. Our evaluation is conducted on four\nbenchmark datasets (KDD-CUP-1999, NSL-KDD, UNSW-NB15, and CICIDS2017) using a\nshort and proportionally imbalanced dataset with a constant size of 5000\nsamples to ensure fairness in comparison. Results show that CAGN-GAT Fusion\ndemonstrates stable and competitive accuracy, recall, and F1-score, even though\nit does not achieve the highest performance in every dataset. Our analysis also\nhighlights the impact of adaptive graph construction techniques, including\nsmall changes in connections (edge perturbation) and selective hiding of\nfeatures (feature masking), improving detection performance. The findings\nconfirm that GNNs, particularly CAGN-GAT Fusion, are robust and computationally\nefficient, making them well-suited for resource-constrained environments.\nFuture work will explore GraphSAGE layers and multiview graph construction\ntechniques to further enhance adaptability and detection accuracy.", "AI": {"tldr": "The paper proposes CAGN-GAT Fusion, a hybrid GNN model, for network intrusion detection, showing competitive performance on imbalanced datasets compared to 15 other models.", "motivation": "Growing cybersecurity threats and challenges with imbalanced datasets in traditional ML models motivate the need for robust, efficient solutions like GNNs.", "method": "The study combines Contrastive Attentive Graph Network and Graph Attention Network (CAGN-GAT Fusion) and benchmarks it against 15 models using four datasets (KDD-CUP-1999, NSL-KDD, UNSW-NB15, CICIDS2017) with 5000 samples each. Adaptive graph construction techniques (edge perturbation, feature masking) are analyzed.", "result": "CAGN-GAT Fusion shows stable accuracy, recall, and F1-score, though not always the highest. Adaptive techniques improve detection performance, confirming GNNs' robustness and efficiency.", "conclusion": "GNNs, especially CAGN-GAT Fusion, are effective for resource-constrained environments. Future work will explore GraphSAGE layers and multiview techniques for better adaptability and accuracy."}}
{"id": "2504.02450", "pdf": "https://arxiv.org/pdf/2504.02450", "abs": "https://arxiv.org/abs/2504.02450", "authors": ["Jingyi Wang", "Duanfeng Chu", "Zejian Deng", "Liping Lu", "Jinxiang Wang", "Chen Sun"], "title": "CHARMS: A Cognitive Hierarchical Agent for Reasoning and Motion Stylization in Autonomous Driving", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "To address the challenge of insufficient interactivity and behavioral\ndiversity in autonomous driving decision-making, this paper proposes a\nCognitive Hierarchical Agent for Reasoning and Motion Stylization (CHARMS). By\nleveraging Level-k game theory, CHARMS captures human-like reasoning patterns\nthrough a two-stage training pipeline comprising reinforcement learning\npretraining and supervised fine-tuning. This enables the resulting models to\nexhibit diverse and human-like behaviors, enhancing their decision-making\ncapacity and interaction fidelity in complex traffic environments. Building\nupon this capability, we further develop a scenario generation framework that\nutilizes the Poisson cognitive hierarchy theory to control the distribution of\nvehicles with different driving styles through Poisson and binomial sampling.\nExperimental results demonstrate that CHARMS is capable of both making\nintelligent driving decisions as an ego vehicle and generating diverse,\nrealistic driving scenarios as environment vehicles. The code for CHARMS is\nreleased at https://github.com/chuduanfeng/CHARMS.", "AI": {"tldr": "CHARMS enhances autonomous driving decision-making by using Level-k game theory and a two-stage training pipeline to create human-like behaviors and diverse scenarios.", "motivation": "Addressing insufficient interactivity and behavioral diversity in autonomous driving decision-making.", "method": "Leverages Level-k game theory with a two-stage training pipeline (reinforcement learning pretraining and supervised fine-tuning) and a scenario generation framework using Poisson cognitive hierarchy theory.", "result": "CHARMS exhibits human-like behaviors and generates diverse, realistic driving scenarios.", "conclusion": "CHARMS improves decision-making and interaction fidelity in complex traffic environments, with code publicly available."}}
{"id": "2503.18339", "pdf": "https://arxiv.org/pdf/2503.18339", "abs": "https://arxiv.org/abs/2503.18339", "authors": ["Inpyo Hong", "Youngwan Jo", "Hyojeong Lee", "Sunghyun Ahn", "Sanghyun Park"], "title": "GranQ: Granular Zero-Shot Quantization with Unified Layer-Channel Awareness", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot quantization (ZSQ) enables neural network compression without\ntraining data, which is crucial in restricted data access environments.\nHowever, existing ZSQ methods suffer from significant activation loss in\nlow-bit environments owing to their coarse-grained scaling strategy. To address\nthis issue, we propose GranQ, a novel ZSQ approach that leverages layer-channel\nawareness to minimize the quantization error. Unlike conventional layer- or\nchannel-wise quantization, GranQ dynamically adjusts quantization granularity\nby considering both layer- and channel-level activation distributions. This\nenables fine-grained quantization while minimizing activation distortion.\nAdditionally, we introduce vectorized activation quantization, which enables\nefficient parallel computation and reduces computational overhead while\npreserving accuracy. GranQ achieves superior performance compared with those of\nstate-of-the-art ZSQ methods that employ quantization-aware training. With\nthese findings, we anticipate that GranQ will inspire novel research directions\nbeyond conventional ZSQ approaches focused on data generation and model\ntraining.", "AI": {"tldr": "GranQ is a novel zero-shot quantization (ZSQ) method that dynamically adjusts quantization granularity using layer-channel awareness, minimizing activation loss and outperforming existing ZSQ methods.", "motivation": "Existing ZSQ methods struggle with significant activation loss in low-bit environments due to coarse-grained scaling. GranQ aims to address this by fine-tuning quantization granularity.", "method": "GranQ dynamically adjusts quantization granularity by analyzing layer- and channel-level activation distributions, and introduces vectorized activation quantization for efficiency.", "result": "GranQ outperforms state-of-the-art ZSQ methods, even those using quantization-aware training, by reducing activation distortion and computational overhead.", "conclusion": "GranQ sets a new direction for ZSQ research, moving beyond traditional data generation and model training approaches."}}
{"id": "2503.09192", "pdf": "https://arxiv.org/pdf/2503.09192", "abs": "https://arxiv.org/abs/2503.09192", "authors": ["Chuanyin Wang", "Yifei Zhang", "Neng Gao", "Qiang Luo"], "title": "Differential Privacy Personalized Federated Learning Based on Dynamically Sparsified Client Updates", "categories": ["cs.LG", "cs.CR"], "comment": "10 pages,2 figures", "summary": "Personalized federated learning is extensively utilized in scenarios\ncharacterized by data heterogeneity, facilitating more efficient and automated\nlocal training on data-owning terminals. This includes the automated selection\nof high-performance model parameters for upload, thereby enhancing the overall\ntraining process. However, it entails significant risks of privacy leakage.\nExisting studies have attempted to mitigate these risks by utilizing\ndifferential privacy. Nevertheless, these studies present two major\nlimitations: (1) The integration of differential privacy into personalized\nfederated learning lacks sufficient personalization, leading to the\nintroduction of excessive noise into the model. (2) It fails to adequately\ncontrol the spatial scope of model update information, resulting in a\nsuboptimal balance between data privacy and model effectiveness in differential\nprivacy federated learning. In this paper, we propose a differentially private\npersonalized federated learning approach that employs dynamically sparsified\nclient updates through reparameterization and adaptive norm(DP-pFedDSU).\nReparameterization training effectively selects personalized client update\ninformation, thereby reducing the quantity of updates. This approach minimizes\nthe introduction of noise to the greatest extent possible. Additionally,\ndynamic adaptive norm refers to controlling the norm space of model updates\nduring the training process, mitigating the negative impact of clipping on the\nupdate information. These strategies substantially enhance the effective\nintegration of differential privacy and personalized federated learning.\nExperimental results on EMNIST, CIFAR-10, and CIFAR-100 demonstrate that our\nproposed scheme achieves superior performance and is well-suited for more\ncomplex personalized federated learning scenarios.", "AI": {"tldr": "The paper proposes DP-pFedDSU, a differentially private personalized federated learning method, addressing privacy leakage risks and improving model performance by dynamically sparsifying updates and using adaptive norms.", "motivation": "Existing differential privacy methods in personalized federated learning introduce excessive noise and lack spatial control, compromising privacy and model effectiveness.", "method": "The approach uses reparameterization to select personalized updates and dynamic adaptive norms to control update norms, minimizing noise and clipping impact.", "result": "Experiments on EMNIST, CIFAR-10, and CIFAR-100 show superior performance in complex scenarios.", "conclusion": "DP-pFedDSU effectively balances privacy and model performance, making it suitable for complex personalized federated learning."}}
{"id": "2504.02698", "pdf": "https://arxiv.org/pdf/2504.02698", "abs": "https://arxiv.org/abs/2504.02698", "authors": ["Shengrui XU", "Tianchi Lu", "Zikun Wang", "Jixiu Zhai"], "title": "SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions", "categories": ["cs.LG", "cs.AI", "q-bio.QM", "92C40, 68T07", "I.2.6; J.3"], "comment": "20 pages,9 figures,conference", "summary": "Protein-protein interaction (PPI) prediction plays a pivotal role in\ndeciphering cellular functions and disease mechanisms. To address the\nlimitations of traditional experimental methods and existing computational\napproaches in cross-modal feature fusion and false-negative suppression, we\npropose SCMPPI-a novel supervised contrastive multimodal framework. By\neffectively integrating sequence-based features (AAC, DPC, ESMC-CKSAAP) with\nnetwork topology (Node2Vec embeddings) and incorporating an enhanced\ncontrastive learning strategy with negative sample filtering, SCMPPI achieves\nsuperior prediction performance. Extensive experiments on eight benchmark\ndatasets demonstrate its state-of-the-art accuracy(98.13%) and AUC(99.69%),\nalong with excellent cross-species generalization (AUC>99%). Successful\napplications in CD9 networks, Wnt pathway analysis, and cancer-specific\nnetworks further highlight its potential for disease target discovery,\nestablishing SCMPPI as a powerful tool for multimodal biological data analysis.", "AI": {"tldr": "SCMPPI is a novel supervised contrastive multimodal framework for PPI prediction, achieving high accuracy and cross-species generalization by integrating sequence and network features with contrastive learning.", "motivation": "To overcome limitations of traditional methods in cross-modal feature fusion and false-negative suppression for PPI prediction.", "method": "Integrates sequence-based features (AAC, DPC, ESMC-CKSAAP) with network topology (Node2Vec embeddings) using enhanced contrastive learning and negative sample filtering.", "result": "Achieves 98.13% accuracy and 99.69% AUC on benchmark datasets, with strong cross-species generalization (AUC>99%).", "conclusion": "SCMPPI is a powerful tool for multimodal biological data analysis, with applications in disease target discovery."}}
{"id": "2503.18478", "pdf": "https://arxiv.org/pdf/2503.18478", "abs": "https://arxiv.org/abs/2503.18478", "authors": ["Xiangrui Liu", "Yan Shu", "Zheng Liu", "Ao Li", "Yang Tian", "Bo Zhao"], "title": "Video-XL-Pro: Reconstructive Token Compression for Extremely Long Video Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Despite advanced token compression techniques, existing multimodal large\nlanguage models (MLLMs) still struggle with hour-long video understanding. In\nthis work, we propose Video-XL-Pro, an efficient method for extremely long\nvideo understanding, built upon Reconstructive Compression of Tokens (ReCoT), a\nlearnable module that leverages self-supervised learning to generate\ncomprehensive and compact video tokens. ReCoT introduces two key components:\n(i) Dynamic Token Synthesizer (DTS): DTS generates pseudo-video tokens from\nstatic image tokens by learning intra-token relationships, which are then used\nin masked video modeling. (ii) Semantic-Guided Masking (SGM): SGM adaptively\nmasks redundant visual tokens to facilitate more effective reconstructive\nlearning. To improve training efficiency in MLLMs fine-tuning, we introduce a\nvideo-specific dataset pruning strategy and design a simple yet Query-aware\nSelector that enables the model to precisely locate query-relevant video\ntokens. With only 3B parameters, Video-XL-Pro outperforms most 7B models\ntrained on larger datasets across multiple long video understanding benchmarks.\nMoreover, it can process over 8K frames on a single A100 GPU while maintaining\nhigh-quality performance.", "AI": {"tldr": "Video-XL-Pro improves long video understanding with ReCoT, featuring Dynamic Token Synthesizer and Semantic-Guided Masking, outperforming larger models.", "motivation": "Existing MLLMs struggle with hour-long video understanding, necessitating efficient token compression and training methods.", "method": "Uses ReCoT with Dynamic Token Synthesizer (DTS) and Semantic-Guided Masking (SGM), plus dataset pruning and Query-aware Selector.", "result": "Outperforms 7B models with 3B parameters, handles 8K frames on A100 GPU.", "conclusion": "Video-XL-Pro is efficient and effective for long video understanding."}}
{"id": "2503.11900", "pdf": "https://arxiv.org/pdf/2503.11900", "abs": "https://arxiv.org/abs/2503.11900", "authors": ["Lauren Harrell", "Christine Kaeser-Chen", "Burcu Karagol Ayan", "Keith Anderson", "Michelangelo Conserva", "Elise Kleeman", "Maxim Neumann", "Matt Overlan", "Melissa Chapman", "Drew Purves"], "title": "Heterogenous graph neural networks for species distribution modeling", "categories": ["cs.LG", "q-bio.PE", "stat.ML", "92B20 (Primary) 68T07, 92D40 (Secondary)", "I.2.1; J.3"], "comment": "13 pages, 3 figures,", "summary": "Species distribution models (SDMs) are necessary for measuring and predicting\noccurrences and habitat suitability of species and their relationship with\nenvironmental factors. We introduce a novel presence-only SDM with graph neural\nnetworks (GNN). In our model, species and locations are treated as two distinct\nnode sets, and the learning task is predicting detection records as the edges\nthat connect locations to species. Using GNN for SDM allows us to model\nfine-grained interactions between species and the environment. We evaluate the\npotential of this methodology on the six-region dataset compiled by National\nCenter for Ecological Analysis and Synthesis (NCEAS) for benchmarking SDMs. For\neach of the regions, the heterogeneous GNN model is comparable to or\noutperforms previously-benchmarked single-species SDMs as well as a\nfeed-forward neural network baseline model.", "AI": {"tldr": "A novel presence-only SDM using GNNs treats species and locations as nodes, predicting detection records as edges, outperforming traditional SDMs.", "motivation": "To enhance species distribution modeling by capturing fine-grained interactions between species and environmental factors.", "method": "Uses a heterogeneous GNN with species and locations as distinct node sets, predicting edges (detection records). Evaluated on NCEAS's six-region dataset.", "result": "GNN model matches or outperforms single-species SDMs and a feed-forward neural network baseline.", "conclusion": "GNNs offer a promising approach for SDMs by effectively modeling species-environment interactions."}}
{"id": "2504.03686", "pdf": "https://arxiv.org/pdf/2504.03686", "abs": "https://arxiv.org/abs/2504.03686", "authors": ["Zhanwei Wang", "Qunsong Zeng", "Haotian Zheng", "Kaibin Huang"], "title": "Revisiting Outage for Edge Inference Systems", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": null, "summary": "One of the key missions of sixth-generation (6G) mobile networks is to deploy\nlarge-scale artificial intelligence (AI) models at the network edge to provide\nremote-inference services for edge devices. The resultant platform, known as\nedge inference, will support a wide range of Internet-of-Things applications,\nsuch as autonomous driving, industrial automation, and augmented reality. Given\nthe mission-critical and time-sensitive nature of these tasks, it is essential\nto design edge inference systems that are both reliable and capable of meeting\nstringent end-to-end (E2E) latency constraints. Existing studies, which\nprimarily focus on communication reliability as characterized by channel outage\nprobability, may fail to guarantee E2E performance, specifically in terms of\nE2E inference accuracy and latency. To address this limitation, we propose a\ntheoretical framework that introduces and mathematically characterizes the\ninference outage (InfOut) probability, which quantifies the likelihood that the\nE2E inference accuracy falls below a target threshold. Under an E2E latency\nconstraint, this framework establishes a fundamental tradeoff between\ncommunication overhead (i.e., uploading more sensor observations) and inference\nreliability as quantified by the InfOut probability. To find a tractable way to\noptimize this tradeoff, we derive accurate surrogate functions for InfOut\nprobability by applying a Gaussian approximation to the distribution of the\nreceived discriminant gain. Experimental results demonstrate the superiority of\nthe proposed design over conventional communication-centric approaches in terms\nof E2E inference reliability.", "AI": {"tldr": "A framework for edge inference in 6G networks introduces the concept of inference outage probability to balance communication overhead and reliability under latency constraints.", "motivation": "Existing studies focus on communication reliability but fail to ensure end-to-end (E2E) performance in edge inference, critical for applications like autonomous driving and augmented reality.", "method": "A theoretical framework is proposed, mathematically characterizing inference outage probability and optimizing the tradeoff between communication overhead and inference reliability using Gaussian approximation.", "result": "The framework outperforms conventional communication-centric approaches in E2E inference reliability.", "conclusion": "The proposed design addresses the limitations of existing methods, ensuring reliable and low-latency edge inference for 6G networks."}}
{"id": "2503.23452", "pdf": "https://arxiv.org/pdf/2503.23452", "abs": "https://arxiv.org/abs/2503.23452", "authors": ["Yuhang Yang", "Ke Fan", "Shangkun Sun", "Hongxiang Li", "Ailing Zeng", "FeiLin Han", "Wei Zhai", "Wei Liu", "Yang Cao", "Zheng-Jun Zha"], "title": "VideoGen-Eval: Agent-based System for Video Generation Evaluation", "categories": ["cs.CV"], "comment": "project:https://github.com/AILab-CVC/VideoGen-Eval", "summary": "The rapid advancement of video generation has rendered existing evaluation\nsystems inadequate for assessing state-of-the-art models, primarily due to\nsimple prompts that cannot showcase the model's capabilities, fixed evaluation\noperators struggling with Out-of-Distribution (OOD) cases, and misalignment\nbetween computed metrics and human preferences. To bridge the gap, we propose\nVideoGen-Eval, an agent evaluation system that integrates LLM-based content\nstructuring, MLLM-based content judgment, and patch tools designed for\ntemporal-dense dimensions, to achieve a dynamic, flexible, and expandable video\ngeneration evaluation. Additionally, we introduce a video generation benchmark\nto evaluate existing cutting-edge models and verify the effectiveness of our\nevaluation system. It comprises 700 structured, content-rich prompts (both T2V\nand I2V) and over 12,000 videos generated by 20+ models, among them, 8\ncutting-edge models are selected as quantitative evaluation for the agent and\nhuman. Extensive experiments validate that our proposed agent-based evaluation\nsystem demonstrates strong alignment with human preferences and reliably\ncompletes the evaluation, as well as the diversity and richness of the\nbenchmark.", "AI": {"tldr": "VideoGen-Eval is a dynamic, flexible evaluation system for video generation models, addressing gaps in existing methods with LLM-based structuring, MLLM-based judgment, and patch tools. It includes a benchmark with 700 prompts and 12,000+ videos, showing strong alignment with human preferences.", "motivation": "Existing video generation evaluation systems are inadequate due to simple prompts, OOD challenges, and misaligned metrics.", "method": "Proposes VideoGen-Eval, integrating LLM-based content structuring, MLLM-based judgment, and temporal-dense patch tools. Introduces a benchmark with 700 prompts and 12,000+ videos from 20+ models.", "result": "The system aligns well with human preferences and reliably evaluates models. The benchmark is diverse and rich.", "conclusion": "VideoGen-Eval effectively addresses current evaluation shortcomings and provides a robust framework for assessing video generation models."}}
{"id": "2503.13051", "pdf": "https://arxiv.org/pdf/2503.13051", "abs": "https://arxiv.org/abs/2503.13051", "authors": ["Kai Uwe Barthel", "Florian Barthel", "Peter Eisert"], "title": "Permutation Learning with Only N Parameters: From SoftSort to Self-Organizing Gaussians", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Sorting and permutation learning are key concepts in optimization and machine\nlearning, especially when organizing high-dimensional data into meaningful\nspatial layouts. The Gumbel-Sinkhorn method, while effective, requires N*N\nparameters to determine a full permutation matrix, making it computationally\nexpensive for large datasets. Low-rank matrix factorization approximations\nreduce memory requirements to 2NM (with M << N), but they still struggle with\nvery large problems. SoftSort, by providing a continuous relaxation of the\nargsort operator, allows differentiable 1D sorting, but it faces challenges\nwith multidimensional data and complex permutations. In this paper, we present\na novel method for learning permutations using only N parameters, which\ndramatically reduces storage costs. Our method extends SoftSort by iteratively\nshuffling the N indices of the elements and applying a few SoftSort\noptimization steps per iteration. This modification significantly improves\nsorting quality, especially for multidimensional data and complex optimization\ncriteria, and outperforms pure SoftSort. Our method offers improved memory\nefficiency and scalability compared to existing approaches, while maintaining\nhigh-quality permutation learning. Its dramatically reduced memory requirements\nmake it particularly well-suited for large-scale optimization tasks, such as\n\"Self-Organizing Gaussians\", where efficient and scalable permutation learning\nis critical.", "AI": {"tldr": "A novel method for learning permutations with only N parameters is introduced, improving memory efficiency and scalability while maintaining high-quality results.", "motivation": "Existing methods like Gumbel-Sinkhorn and SoftSort are computationally expensive or struggle with multidimensional data, necessitating a more efficient solution.", "method": "The method extends SoftSort by iteratively shuffling indices and applying SoftSort optimization steps, reducing parameters to N.", "result": "The approach outperforms SoftSort in sorting quality and efficiency, especially for multidimensional data and large-scale tasks.", "conclusion": "The method is highly scalable and efficient, making it ideal for large-scale optimization tasks like Self-Organizing Gaussians."}}
{"id": "2504.04482", "pdf": "https://arxiv.org/pdf/2504.04482", "abs": "https://arxiv.org/abs/2504.04482", "authors": ["Mengxia Dai", "Wenqian Luo", "Tianyang Li"], "title": "Statistical Management of the False Discovery Rate in Medical Instance Segmentation Based on Conformal Risk Control", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by 2025 IEEE 3rd International Conference on Image\n  Processing and Computer Applications (ICIPCA 2025)", "summary": "Instance segmentation plays a pivotal role in medical image analysis by\nenabling precise localization and delineation of lesions, tumors, and\nanatomical structures. Although deep learning models such as Mask R-CNN and\nBlendMask have achieved remarkable progress, their application in high-risk\nmedical scenarios remains constrained by confidence calibration issues, which\nmay lead to misdiagnosis. To address this challenge, we propose a robust\nquality control framework based on conformal prediction theory. This framework\ninnovatively constructs a risk-aware dynamic threshold mechanism that\nadaptively adjusts segmentation decision boundaries according to clinical\nrequirements.Specifically, we design a \\textbf{calibration-aware loss function}\nthat dynamically tunes the segmentation threshold based on a user-defined risk\nlevel $\\alpha$. Utilizing exchangeable calibration data, this method ensures\nthat the expected FNR or FDR on test data remains below $\\alpha$ with high\nprobability. The framework maintains compatibility with mainstream segmentation\nmodels (e.g., Mask R-CNN, BlendMask+ResNet-50-FPN) and datasets (PASCAL VOC\nformat) without requiring architectural modifications. Empirical results\ndemonstrate that we rigorously bound the FDR metric marginally over the test\nset via our developed calibration framework.", "AI": {"tldr": "A robust quality control framework for medical instance segmentation using conformal prediction to address confidence calibration issues.", "motivation": "Deep learning models like Mask R-CNN and BlendMask face confidence calibration problems in high-risk medical scenarios, risking misdiagnosis.", "method": "Proposes a calibration-aware loss function with a dynamic threshold mechanism based on conformal prediction theory, ensuring FNR/FDR bounds.", "result": "Empirical results show the framework bounds FDR metrics on test sets without modifying model architectures.", "conclusion": "The framework effectively addresses calibration issues in medical segmentation, ensuring reliability in clinical settings."}}
{"id": "2504.03230", "pdf": "https://arxiv.org/pdf/2504.03230", "abs": "https://arxiv.org/abs/2504.03230", "authors": ["Yasmine Mustafa", "Mohamed Elmahallawy", "Tie Luo"], "title": "Unlocking Neural Transparency: Jacobian Maps for Explainable AI in Alzheimer's Detection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Alzheimer's disease (AD) leads to progressive cognitive decline, making early\ndetection crucial for effective intervention. While deep learning models have\nshown high accuracy in AD diagnosis, their lack of interpretability limits\nclinical trust and adoption. This paper introduces a novel pre-model approach\nleveraging Jacobian Maps (JMs) within a multi-modal framework to enhance\nexplainability and trustworthiness in AD detection. By capturing localized\nbrain volume changes, JMs establish meaningful correlations between model\npredictions and well-known neuroanatomical biomarkers of AD. We validate JMs\nthrough experiments comparing a 3D CNN trained on JMs versus on traditional\npreprocessed data, which demonstrates superior accuracy. We also employ 3D\nGrad-CAM analysis to provide both visual and quantitative insights, further\nshowcasing improved interpretability and diagnostic reliability.", "AI": {"tldr": "The paper proposes a pre-model approach using Jacobian Maps (JMs) to improve interpretability and trustworthiness in Alzheimer's disease (AD) detection, outperforming traditional methods in accuracy and explainability.", "motivation": "Early AD detection is critical, but deep learning models lack interpretability, hindering clinical trust. This work aims to bridge this gap.", "method": "Introduces JMs in a multi-modal framework to capture brain volume changes, validated via 3D CNN and 3D Grad-CAM for interpretability.", "result": "JMs-based CNN shows superior accuracy and provides meaningful correlations with AD biomarkers, enhancing diagnostic reliability.", "conclusion": "The JMs approach improves both accuracy and interpretability in AD detection, addressing a key limitation of deep learning models in clinical settings."}}
{"id": "2503.15294", "pdf": "https://arxiv.org/pdf/2503.15294", "abs": "https://arxiv.org/abs/2503.15294", "authors": ["Ari Blondal", "Hamed Hatami", "Pooya Hatami", "Chavdar Lalov", "Sivan Tretiak"], "title": "Borsuk-Ulam and Replicable Learning of Large-Margin Halfspaces", "categories": ["cs.LG"], "comment": "Added Corollary 1.9 that answers a question of [CHHH23]", "summary": "Recent remarkable advances in learning theory have established that, for\ntotal concept classes, list replicability, global stability, differentially\nprivate (DP) learnability, and shared-randomness replicability all coincide\nwith the finiteness of Littlestone dimension. Does this equivalence extend to\npartial concept classes?\n  We answer this question by proving that the list replicability number of\n$d$-dimensional $\\gamma$-margin half-spaces satisfies \\[ \\frac{d}{2}+1 \\le\n\\mathrm{LR}(H^d_\\gamma) \\le d, \\] which grows with dimension. Consequently, for\npartial classes, list replicability and global stability do not necessarily\nfollow from bounded Littlestone dimension, pure DP-learnability, or\nshared-randomness replicability.\n  Applying our main theorem, we resolve several open problems:\n  $\\bullet$ Every disambiguation of infinite-dimensional large-margin\nhalf-spaces to a total concept class has unbounded Littlestone dimension,\nanswering an open question of Alon et al. (FOCS '21).\n  $\\bullet$ The maximum list-replicability number of any finite set of points\nand homogeneous half-spaces in $d$-dimensional Euclidean space is $d$,\nresolving a problem of Chase et al. (FOCS '23).\n  $\\bullet$ Every disambiguation of the Gap Hamming Distance problem in the\nlarge gap regime has unbounded public-coin randomized communication complexity.\nThis answers an open question of Fang et al. (STOC '25).\n  $\\bullet$ There exists a partial concept class with Littlestone dimension $1$\nsuch that all its disambiguations have infinite Littlestone dimension. This\nanswers a question of Cheung et al. (ICALP '23).\n  Our lower bound follows from a topological argument based on the local\nBorsuk-Ulam theorem of Chase, Chornomaz, Moran, and Yehudayoff (STOC '24). For\nthe upper bound, we construct a list-replicable learning rule using the\ngeneralization properties of SVMs.", "AI": {"tldr": "The paper investigates whether the equivalence of list replicability, global stability, DP learnability, and shared-randomness replicability with finite Littlestone dimension extends to partial concept classes. It proves bounds for list replicability of half-spaces and resolves several open problems.", "motivation": "To determine if the equivalence of various learning-theoretic properties with finite Littlestone dimension holds for partial concept classes, addressing gaps in current understanding.", "method": "Proves bounds on list replicability for half-spaces using topological arguments (local Borsuk-Ulam theorem) and constructs a list-replicable learning rule using SVM generalization properties.", "result": "Shows that list replicability and global stability do not necessarily follow from bounded Littlestone dimension, DP-learnability, or shared-randomness replicability for partial classes. Resolves multiple open problems in the field.", "conclusion": "The equivalence of learning-theoretic properties with finite Littlestone dimension does not extend to partial concept classes, as demonstrated by the results and resolved open problems."}}
{"id": "2504.06962", "pdf": "https://arxiv.org/pdf/2504.06962", "abs": "https://arxiv.org/abs/2504.06962", "authors": ["Thomas Kerdreux", "Alexandre Tuel", "Quentin Febvre", "Alexis Mouche", "Bertrand Chapron"], "title": "Efficient Self-Supervised Learning for Earth Observation via Dynamic Dataset Curation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPR Workshop : The First Workshop on Foundation and\n  Large Vision Models in Remote Sensing", "summary": "Self-supervised learning (SSL) has enabled the development of vision\nfoundation models for Earth Observation (EO), demonstrating strong\ntransferability across diverse remote sensing tasks. While prior work has\nfocused on network architectures and training strategies, the role of dataset\ncuration, especially in balancing and diversifying pre-training datasets,\nremains underexplored. In EO, this challenge is amplified by the redundancy and\nheavy-tailed distributions common in satellite imagery, which can lead to\nbiased representations and inefficient training.\n  In this work, we propose a dynamic dataset pruning strategy designed to\nimprove SSL pre-training by maximizing dataset diversity and balance. Our\nmethod iteratively refines the training set without requiring a pre-existing\nfeature extractor, making it well-suited for domains where curated datasets are\nlimited or unavailable. We demonstrate our approach on the Sentinel-1 Wave Mode\n(WV) Synthetic Aperture Radar (SAR) archive, a challenging dataset dominated by\nocean observations. We train models from scratch on the entire Sentinel-1 WV\narchive spanning 10 years. Across three downstream tasks, our results show that\ndynamic pruning improves both computational efficiency and representation\nquality, leading to stronger transferability.\n  We also release the weights of OceanSAR-1, the first model in the OceanSAR\nfamily, a series of foundation models for ocean observation and analysis using\nSAR imagery, at github.com/galeio-research/OceanSAR-models/.", "AI": {"tldr": "Dynamic dataset pruning improves SSL pre-training for EO by enhancing dataset diversity and balance, leading to better transferability and efficiency.", "motivation": "Addressing the underexplored role of dataset curation in SSL for EO, especially given the challenges of redundancy and heavy-tailed distributions in satellite imagery.", "method": "Proposes a dynamic dataset pruning strategy to iteratively refine training sets without needing a pre-existing feature extractor, tested on the Sentinel-1 WV SAR archive.", "result": "Dynamic pruning improves computational efficiency and representation quality, enhancing transferability across three downstream tasks.", "conclusion": "The approach is effective for domains with limited curated datasets, and the OceanSAR-1 model is released as a foundation for ocean observation."}}
{"id": "2504.04339", "pdf": "https://arxiv.org/pdf/2504.04339", "abs": "https://arxiv.org/abs/2504.04339", "authors": ["Peng Gao", "Yujian Lee", "Zailong Chen", "Hui zhang", "Xubo Liu", "Yiyang Hu", "Guquang Jing"], "title": "NCL-CIR: Noise-aware Contrastive Learning for Composed Image Retrieval", "categories": ["cs.CV"], "comment": "Has been accepted by ICASSP2025", "summary": "Composed Image Retrieval (CIR) seeks to find a target image using a\nmulti-modal query, which combines an image with modification text to pinpoint\nthe target. While recent CIR methods have shown promise, they mainly focus on\nexploring relationships between the query pairs (image and text) through data\naugmentation or model design. These methods often assume perfect alignment\nbetween queries and target images, an idealized scenario rarely encountered in\npractice. In reality, pairs are often partially or completely mismatched due to\nissues like inaccurate modification texts, low-quality target images, and\nannotation errors. Ignoring these mismatches leads to numerous False Positive\nPair (FFPs) denoted as noise pairs in the dataset, causing the model to overfit\nand ultimately reducing its performance. To address this problem, we propose\nthe Noise-aware Contrastive Learning for CIR (NCL-CIR), comprising two key\ncomponents: the Weight Compensation Block (WCB) and the Noise-pair Filter Block\n(NFB). The WCB coupled with diverse weight maps can ensure more stable token\nrepresentations of multi-modal queries and target images. Meanwhile, the NFB,\nin conjunction with the Gaussian Mixture Model (GMM) predicts noise pairs by\nevaluating loss distributions, and generates soft labels correspondingly,\nallowing for the design of the soft-label based Noise Contrastive Estimation\n(NCE) loss function. Consequently, the overall architecture helps to mitigate\nthe influence of mismatched and partially matched samples, with experimental\nresults demonstrating that NCL-CIR achieves exceptional performance on the\nbenchmark datasets.", "AI": {"tldr": "NCL-CIR introduces noise-aware contrastive learning to address mismatched pairs in Composed Image Retrieval, improving performance via Weight Compensation Block and Noise-pair Filter Block.", "motivation": "Existing CIR methods assume perfect query-target alignment, but real-world datasets often contain mismatched pairs, leading to false positives and degraded performance.", "method": "Proposes NCL-CIR with Weight Compensation Block (WCB) for stable token representations and Noise-pair Filter Block (NFB) with GMM to predict noise pairs and design a soft-label NCE loss.", "result": "NCL-CIR outperforms benchmarks by mitigating mismatched and partially matched sample effects.", "conclusion": "NCL-CIR effectively handles noise in CIR datasets, enhancing retrieval performance."}}
{"id": "2503.16846", "pdf": "https://arxiv.org/pdf/2503.16846", "abs": "https://arxiv.org/abs/2503.16846", "authors": ["Qingsong Wang"], "title": "An Efficient Alternating Algorithm for ReLU-based Symmetric Matrix Decomposition", "categories": ["cs.LG", "math.OC"], "comment": "7 pages, 2 figures. The paper is under consideration at Pattern\n  Recognition Letters", "summary": "Symmetric matrix decomposition is an active research area in machine\nlearning. This paper focuses on exploiting the low-rank structure of\nnon-negative and sparse symmetric matrices via the rectified linear unit (ReLU)\nactivation function. We propose the ReLU-based nonlinear symmetric matrix\ndecomposition (ReLU-NSMD) model, introduce an accelerated alternating partial\nBregman (AAPB) method for its solution, and present the algorithm's convergence\nresults. Our algorithm leverages the Bregman proximal gradient framework to\novercome the challenge of estimating the global $L$-smooth constant in the\nclassic proximal gradient algorithm. Numerical experiments on synthetic and\nreal datasets validate the effectiveness of our model and algorithm.", "AI": {"tldr": "Proposes ReLU-NSMD for low-rank symmetric matrix decomposition using ReLU, with AAPB method for efficient solution and proven convergence.", "motivation": "Exploit low-rank structure in non-negative, sparse symmetric matrices using ReLU activation.", "method": "ReLU-NSMD model with AAPB method, leveraging Bregman proximal gradient to avoid estimating global L-smooth constant.", "result": "Validated effectiveness on synthetic and real datasets.", "conclusion": "ReLU-NSMD and AAPB are effective for symmetric matrix decomposition."}}
{"id": "2504.08985", "pdf": "https://arxiv.org/pdf/2504.08985", "abs": "https://arxiv.org/abs/2504.08985", "authors": ["Luna Xingyu Li", "Ray-yuan Chung", "Feng Chen", "Wenyu Zeng", "Yein Jeon", "Oleg Zaslavsky"], "title": "Learning from Elders: Making an LLM-powered Chatbot for Retirement Communities more Accessible through User-centered Design", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted as Research talk for Considering Cultural and Linguistic\n  Diversity in AI Applications workshop at CALD-AI@ASIS&T 2025", "summary": "Low technology and eHealth literacy among older adults in retirement\ncommunities hinder engagement with digital tools. To address this, we designed\nan LLM-powered chatbot prototype using a human-centered approach for a local\nretirement community. Through interviews and persona development, we\nprioritized accessibility and dual functionality: simplifying internal\ninformation retrieval and improving technology and eHealth literacy. A pilot\ntrial with residents demonstrated high satisfaction and ease of use, but also\nidentified areas for further improvement. Based on the feedback, we refined the\nchatbot using GPT-3.5 Turbo and Streamlit. The chatbot employs tailored prompt\nengineering to deliver concise responses. Accessible features like adjustable\nfont size, interface theme and personalized follow-up responses were\nimplemented. Future steps include enabling voice-to-text function and\nlongitudinal intervention studies. Together, our results highlight the\npotential of LLM-driven chatbots to empower older adults through accessible,\npersonalized interactions, bridging literacy gaps in retirement communities.", "AI": {"tldr": "An LLM-powered chatbot was designed for older adults in retirement communities to improve eHealth literacy and simplify information access. The pilot showed high satisfaction, leading to refinements like GPT-3.5 Turbo integration and accessibility features. Future steps include voice-to-text and further studies.", "motivation": "Low technology and eHealth literacy among older adults in retirement communities hinder their engagement with digital tools, necessitating an accessible solution.", "method": "A human-centered approach was used, involving interviews and persona development to design a chatbot. The prototype was refined using GPT-3.5 Turbo and Streamlit, with tailored prompt engineering and accessibility features.", "result": "Pilot trials demonstrated high satisfaction and ease of use, though areas for improvement were identified. The refined chatbot includes personalized responses and accessibility options.", "conclusion": "LLM-driven chatbots show promise in empowering older adults by bridging literacy gaps through accessible, personalized interactions."}}
{"id": "2504.05601", "pdf": "https://arxiv.org/pdf/2504.05601", "abs": "https://arxiv.org/abs/2504.05601", "authors": ["Zhenteng Li", "Sheng Lian", "Dengfeng Pan", "Youlin Wang", "Wei Liu"], "title": "AD-Det: Boosting Object Detection in UAV Images with Focused Small Objects and Balanced Tail Classes", "categories": ["cs.CV"], "comment": "Published in Remote Sensing", "summary": "Object detection in Unmanned Aerial Vehicle (UAV) images poses significant\nchallenges due to complex scale variations and class imbalance among objects.\nExisting methods often address these challenges separately, overlooking the\nintricate nature of UAV images and the potential synergy between them. In\nresponse, this paper proposes AD-Det, a novel framework employing a coherent\ncoarse-to-fine strategy that seamlessly integrates two pivotal components:\nAdaptive Small Object Enhancement (ASOE) and Dynamic Class-balanced Copy-paste\n(DCC). ASOE utilizes a high-resolution feature map to identify and cluster\nregions containing small objects. These regions are subsequently enlarged and\nprocessed by a fine-grained detector. On the other hand, DCC conducts\nobject-level resampling by dynamically pasting tail classes around the cluster\ncenters obtained by ASOE, main-taining a dynamic memory bank for each tail\nclass. This approach enables AD-Det to not only extract regions with small\nobjects for precise detection but also dynamically perform reasonable\nresampling for tail-class objects. Consequently, AD-Det enhances the overall\ndetection performance by addressing the challenges of scale variations and\nclass imbalance in UAV images through a synergistic and adaptive framework. We\nextensively evaluate our approach on two public datasets, i.e., VisDrone and\nUAVDT, and demonstrate that AD-Det significantly outperforms existing\ncompetitive alternatives. Notably, AD-Det achieves a 37.5% Average Precision\n(AP) on the VisDrone dataset, surpassing its counterparts by at least 3.1%.", "AI": {"tldr": "AD-Det is a novel framework for UAV object detection, combining Adaptive Small Object Enhancement (ASOE) and Dynamic Class-balanced Copy-paste (DCC) to tackle scale variations and class imbalance. It outperforms existing methods, achieving 37.5% AP on VisDrone.", "motivation": "Challenges in UAV object detection include complex scale variations and class imbalance, which existing methods address separately. This paper aims to synergize solutions for these issues.", "method": "AD-Det integrates ASOE for small object detection and DCC for class imbalance. ASOE clusters and enlarges small object regions, while DCC dynamically resamples tail classes using a memory bank.", "result": "AD-Det achieves 37.5% AP on VisDrone, outperforming competitors by at least 3.1%. It also performs well on UAVDT.", "conclusion": "AD-Det effectively addresses UAV object detection challenges through a synergistic framework, demonstrating superior performance on benchmark datasets."}}
{"id": "2503.19466", "pdf": "https://arxiv.org/pdf/2503.19466", "abs": "https://arxiv.org/abs/2503.19466", "authors": ["Leander Kurscheidt", "Paolo Morettin", "Roberto Sebastiani", "Andrea Passerini", "Antonio Vergari"], "title": "A Probabilistic Neuro-symbolic Layer for Algebraic Constraint Satisfaction", "categories": ["cs.LG"], "comment": "Expanded related work", "summary": "In safety-critical applications, guaranteeing the satisfaction of constraints\nover continuous environments is crucial, e.g., an autonomous agent should never\ncrash into obstacles or go off-road. Neural models struggle in the presence of\nthese constraints, especially when they involve intricate algebraic\nrelationships. To address this, we introduce a differentiable probabilistic\nlayer that guarantees the satisfaction of non-convex algebraic constraints over\ncontinuous variables. This probabilistic algebraic layer (PAL) can be\nseamlessly plugged into any neural architecture and trained via maximum\nlikelihood without requiring approximations. PAL defines a distribution over\nconjunctions and disjunctions of linear inequalities, parameterized by\npolynomials. This formulation enables efficient and exact renormalization via\nsymbolic integration, which can be amortized across different data points and\neasily parallelized on a GPU. We showcase PAL and our integration scheme on a\nnumber of benchmarks for algebraic constraint integration and on real-world\ntrajectory data.", "AI": {"tldr": "A differentiable probabilistic layer (PAL) is introduced to guarantee satisfaction of non-convex algebraic constraints in neural models, enabling safe operation in continuous environments.", "motivation": "Neural models often fail to handle intricate algebraic constraints in safety-critical applications, such as autonomous agents avoiding obstacles.", "method": "PAL is a probabilistic layer that defines distributions over linear inequalities, parameterized by polynomials, and integrates symbolically for exact renormalization.", "result": "PAL is demonstrated on benchmarks and real-world trajectory data, showing effective constraint satisfaction.", "conclusion": "PAL provides a scalable and exact solution for integrating algebraic constraints into neural architectures without approximations."}}
{"id": "2504.09428", "pdf": "https://arxiv.org/pdf/2504.09428", "abs": "https://arxiv.org/abs/2504.09428", "authors": ["Qiwei Wang", "Dandan Lin", "Wenqing Lin", "Ziming Wu"], "title": "FROG: Effective Friend Recommendation in Online Games via Modality-aware User Preferences", "categories": ["cs.SI", "cs.AI", "cs.IR"], "comment": "Accepted in SIGIR 2025", "summary": "Due to the convenience of mobile devices, the online games have become an\nimportant part for user entertainments in reality, creating a demand for friend\nrecommendation in online games. However, none of existing approaches can\neffectively incorporate the multi-modal user features (e.g., images and texts)\nwith the structural information in the friendship graph, due to the following\nlimitations: (1) some of them ignore the high-order structural proximity\nbetween users, (2) some fail to learn the pairwise relevance between users at\nmodality-specific level, and (3) some cannot capture both the local and global\nuser preferences on different modalities. By addressing these issues, in this\npaper, we propose an end-to-end model FROG that better models the user\npreferences on potential friends. Comprehensive experiments on both offline\nevaluation and online deployment at Tencent have demonstrated the superiority\nof FROG over existing approaches.", "AI": {"tldr": "FROG is an end-to-end model for friend recommendation in online games, addressing limitations of existing methods by incorporating multi-modal user features and structural information.", "motivation": "The demand for effective friend recommendation in online games is unmet due to limitations in existing approaches, such as ignoring high-order structural proximity and failing to learn pairwise relevance at modality-specific levels.", "method": "Proposes FROG, an end-to-end model that integrates multi-modal user features (images, texts) with structural information in the friendship graph, capturing both local and global user preferences.", "result": "FROG outperforms existing approaches in offline evaluations and online deployment at Tencent.", "conclusion": "FROG effectively addresses the limitations of existing methods, providing superior friend recommendations in online games."}}
{"id": "2504.07957", "pdf": "https://arxiv.org/pdf/2504.07957", "abs": "https://arxiv.org/abs/2504.07957", "authors": ["Shengyuan Ding", "Shenxi Wu", "Xiangyu Zhao", "Yuhang Zang", "Haodong Duan", "Xiaoyi Dong", "Pan Zhang", "Yuhang Cao", "Dahua Lin", "Jiaqi Wang"], "title": "MM-IFEngine: Towards Multimodal Instruction Following", "categories": ["cs.CV"], "comment": null, "summary": "The Instruction Following (IF) ability measures how well Multi-modal Large\nLanguage Models (MLLMs) understand exactly what users are telling them and\nwhether they are doing it right. Existing multimodal instruction following\ntraining data is scarce, the benchmarks are simple with atomic instructions,\nand the evaluation strategies are imprecise for tasks demanding exact output\nconstraints. To address this, we present MM-IFEngine, an effective pipeline to\ngenerate high-quality image-instruction pairs. Our MM-IFEngine pipeline yields\nlarge-scale, diverse, and high-quality training data MM-IFInstruct-23k, which\nis suitable for Supervised Fine-Tuning (SFT) and extended as MM-IFDPO-23k for\nDirect Preference Optimization (DPO). We further introduce MM-IFEval, a\nchallenging and diverse multi-modal instruction-following benchmark that\nincludes (1) both compose-level constraints for output responses and\nperception-level constraints tied to the input images, and (2) a comprehensive\nevaluation pipeline incorporating both rule-based assessment and judge model.\nWe conduct SFT and DPO experiments and demonstrate that fine-tuning MLLMs on\nMM-IFInstruct-23k and MM-IFDPO-23k achieves notable gains on various IF\nbenchmarks, such as MM-IFEval (+10.2$\\%$), MIA (+7.6$\\%$), and IFEval\n(+12.3$\\%$). We have fully open-sourced the datasets (both SFT and DPO),\nevaluation code and training scripts at https://github.com/SYuan03/MM-IFEngine.", "AI": {"tldr": "The paper introduces MM-IFEngine, a pipeline for generating high-quality image-instruction pairs, and MM-IFEval, a benchmark for evaluating multi-modal instruction-following. Fine-tuning models on the generated datasets improves performance on IF benchmarks.", "motivation": "Existing multimodal instruction-following training data is scarce, benchmarks are simple, and evaluation strategies are imprecise for exact output constraints.", "method": "Proposes MM-IFEngine to generate image-instruction pairs (MM-IFInstruct-23k and MM-IFDPO-23k) and MM-IFEval for evaluation.", "result": "Fine-tuning on MM-IFInstruct-23k and MM-IFDPO-23k improves performance on benchmarks like MM-IFEval (+10.2%), MIA (+7.6%), and IFEval (+12.3%).", "conclusion": "The pipeline and datasets effectively address gaps in multimodal instruction-following, with open-sourced resources for broader use."}}
{"id": "2503.21223", "pdf": "https://arxiv.org/pdf/2503.21223", "abs": "https://arxiv.org/abs/2503.21223", "authors": ["Zhihan Zhang", "Xunkai Li", "Guang Zeng", "Hongchao Qin", "Ronghua Li", "Guoren Wang"], "title": "Rethinking Graph Structure Learning in the Era of LLMs", "categories": ["cs.LG"], "comment": "29 pages, 9 figures", "summary": "Recently, the emergence of LLMs has prompted researchers to integrate\nlanguage descriptions into graphs, aiming to enhance model encoding\ncapabilities from a data-centric perspective. This graph representation is\ncalled text-attributed graphs (TAGs). A review of prior advancements highlights\nthat graph structure learning (GSL) is a pivotal technique for improving data\nutility, making it highly relevant to efficient TAG learning. However, most GSL\nmethods are tailored for traditional graphs without textual information,\nunderscoring the necessity of developing a new GSL paradigm. Despite clear\nmotivations, it remains challenging: (1) How can we define a reasonable\noptimization objective for GSL in the era of LLMs, considering the massive\nparameters in LLM? (2) How can we design an efficient model architecture that\nenables seamless integration of LLM for this optimization objective? For\nQuestion 1, we reformulate existing GSL optimization objectives as a tree\noptimization framework, shifting the focus from obtaining a well-trained edge\npredictor to a language-aware tree sampler. For Question 2, we propose\ndecoupled and training-free model design principles for LLM integration,\nshifting the focus from computation-intensive fine-tuning to more efficient\ninference. Based on this, we propose Large Language and Tree Assistant (LLaTA),\nwhich leverages tree-based LLM in-context learning to enhance the understanding\nof topology and text, enabling reliable inference and generating improved graph\nstructure. Extensive experiments on 10 datasets demonstrate that LLaTA enjoys\nflexibility-incorporated with any backbone; scalability-outperforms other\nLLM-enhanced graph learning methods; effectiveness-achieves SOTA predictive\nperformance.", "AI": {"tldr": "The paper introduces LLaTA, a method integrating LLMs with graph structure learning (GSL) for text-attributed graphs (TAGs), addressing optimization and architecture challenges.", "motivation": "To enhance graph encoding by integrating textual descriptions (TAGs) and adapting GSL for LLMs, overcoming limitations of traditional GSL methods.", "method": "Reformulates GSL objectives as a tree optimization framework and proposes decoupled, training-free LLM integration principles, leading to LLaTA.", "result": "LLaTA outperforms other LLM-enhanced methods, achieving state-of-the-art performance on 10 datasets.", "conclusion": "LLaTA effectively integrates LLMs with GSL for TAGs, offering flexibility, scalability, and superior predictive performance."}}
{"id": "2504.12984", "pdf": "https://arxiv.org/pdf/2504.12984", "abs": "https://arxiv.org/abs/2504.12984", "authors": ["Yaoyao Ding", "Bohan Hou", "Xiao Zhang", "Allan Lin", "Tianqi Chen", "Cody Yu Hao", "Yida Wang", "Gennady Pekhimenko"], "title": "Tilus: A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM Serving", "categories": ["cs.LG", "cs.AI", "cs.PL"], "comment": "18 pages, 15 figures", "summary": "Serving Large Language Models (LLMs) is critical for AI-powered applications\nbut demands substantial computational resources, particularly in memory\nbandwidth and computational throughput. Low-precision computation has emerged\nas a key technique to improve efficiency while reducing resource consumption.\nExisting approaches for generating low-precision kernels are limited to weight\nbit widths that are powers of two and suffer from suboptimal performance due to\nhigh-level GPU programming abstractions. These abstractions restrict critical\noptimizations, such as fine-grained register management and optimized memory\naccess patterns, which are essential for efficient low-precision computations.\nIn this paper, we introduce a virtual machine (VM) designed for General-Purpose\nGPU (GPGPU) computing, enabling support for low-precision data types with\narbitrary bit widths while maintaining GPU programmability. The proposed VM\nfeatures a thread-block-level programming model, a hierarchical memory space, a\nnovel algebraic layout system, and extensive support for diverse low-precision\ndata types. VM programs are compiled into highly efficient GPU programs with\nautomatic vectorization and instruction selection. Extensive experiments\ndemonstrate that our VM efficiently supports a full spectrum of low-precision\ndata types, and outperforms state-of-the-art low-precision kernels on their\nsupported types. Compared to existing compilers like Triton and Ladder, as well\nas hand-optimized kernels such as QuantLLM and Marlin, our VM achieves\nperformance improvements of 1.75x, 2.61x, 1.29x and 1.03x, respectively.", "AI": {"tldr": "A virtual machine (VM) for GPGPU computing is introduced to support low-precision data types with arbitrary bit widths, outperforming existing methods.", "motivation": "Efficiently serving LLMs requires reducing computational resource demands, but current low-precision kernel approaches are limited and suboptimal.", "method": "The proposed VM includes a thread-block-level programming model, hierarchical memory, an algebraic layout system, and supports diverse low-precision types, compiling into optimized GPU programs.", "result": "The VM outperforms state-of-the-art methods, achieving performance improvements of up to 2.61x over existing compilers and hand-optimized kernels.", "conclusion": "The VM enables efficient low-precision computations for LLMs, addressing limitations of current approaches and improving performance."}}
{"id": "2504.09149", "pdf": "https://arxiv.org/pdf/2504.09149", "abs": "https://arxiv.org/abs/2504.09149", "authors": ["Changhao Li", "Yu Xin", "Xiaowei Zhou", "Ariel Shamir", "Hao Zhang", "Ligang Liu", "Ruizhen Hu"], "title": "MASH: Masked Anchored SpHerical Distances for 3D Shape Representation and Generation", "categories": ["cs.CV", "cs.CG"], "comment": "11 pages, 11 figures, SIGGRAPH 2025 Accept - Conference", "summary": "We introduce Masked Anchored SpHerical Distances (MASH), a novel multi-view\nand parametrized representation of 3D shapes. Inspired by multi-view geometry\nand motivated by the importance of perceptual shape understanding for learning\n3D shapes, MASH represents a 3D shape as a collection of observable local\nsurface patches, each defined by a spherical distance function emanating from\nan anchor point. We further leverage the compactness of spherical harmonics to\nencode the MASH functions, combined with a generalized view cone with a\nparameterized base that masks the spatial extent of the spherical function to\nattain locality. We develop a differentiable optimization algorithm capable of\nconverting any point cloud into a MASH representation accurately approximating\nground-truth surfaces with arbitrary geometry and topology. Extensive\nexperiments demonstrate that MASH is versatile for multiple applications\nincluding surface reconstruction, shape generation, completion, and blending,\nachieving superior performance thanks to its unique representation encompassing\nboth implicit and explicit features.", "AI": {"tldr": "MASH is a novel 3D shape representation using spherical distance functions from anchor points, encoded with spherical harmonics, for versatile applications like reconstruction and generation.", "motivation": "To improve perceptual shape understanding and learning of 3D shapes by representing them as observable local surface patches.", "method": "Represents 3D shapes as spherical distance functions from anchor points, uses spherical harmonics for encoding, and employs a parameterized view cone for locality. Includes a differentiable optimization algorithm for point cloud conversion.", "result": "MASH accurately approximates ground-truth surfaces and excels in applications like surface reconstruction, shape generation, completion, and blending.", "conclusion": "MASH's unique implicit-explicit hybrid representation offers superior performance in diverse 3D shape tasks."}}
{"id": "2503.22939", "pdf": "https://arxiv.org/pdf/2503.22939", "abs": "https://arxiv.org/abs/2503.22939", "authors": ["Fadi Alharbi", "Nishant Budhiraja", "Aleksandar Vakanski", "Boyu Zhang", "Murtada K. Elbashir", "Hrshith Gudur", "Mohanad Mohammed"], "title": "Graph Kolmogorov-Arnold Networks for Multi-Cancer Classification and Biomarker Identification, An Interpretable Multi-Omics Approach", "categories": ["cs.LG", "q-bio.QM", "68", "I.2.6"], "comment": null, "summary": "The integration of heterogeneous multi-omics datasets at a systems level\nremains a central challenge for developing analytical and computational models\nin precision cancer diagnostics. This paper introduces Multi-Omics Graph\nKolmogorov-Arnold Network (MOGKAN), a deep learning framework that utilizes\nmessenger-RNA, micro-RNA sequences, and DNA methylation samples together with\nProtein-Protein Interaction (PPI) networks for cancer classification across 31\ndifferent cancer types. The proposed approach combines differential gene\nexpression with DESeq2, Linear Models for Microarray (LIMMA), and Least\nAbsolute Shrinkage and Selection Operator (LASSO) regression to reduce\nmulti-omics data dimensionality while preserving relevant biological features.\nThe model architecture is based on the Kolmogorov-Arnold theorem principle and\nuses trainable univariate functions to enhance interpretability and feature\nanalysis. MOGKAN achieves classification accuracy of 96.28 percent and exhibits\nlow experimental variability in comparison to related deep learning-based\nmodels. The biomarkers identified by MOGKAN were validated as cancer-related\nmarkers through Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes\n(KEGG) enrichment analysis. By integrating multi-omics data with graph-based\ndeep learning, our proposed approach demonstrates robust predictive performance\nand interpretability with potential to enhance the translation of complex\nmulti-omics data into clinically actionable cancer diagnostics.", "AI": {"tldr": "MOGKAN, a deep learning framework, integrates multi-omics data and PPI networks for cancer classification, achieving 96.28% accuracy and validated biomarkers.", "motivation": "Addressing the challenge of integrating heterogeneous multi-omics data for precision cancer diagnostics.", "method": "Combines DESeq2, LIMMA, and LASSO regression for dimensionality reduction, and uses Kolmogorov-Arnold theorem-based architecture for interpretability.", "result": "Achieves 96.28% classification accuracy with low variability and validated cancer-related biomarkers.", "conclusion": "MOGKAN offers robust predictive performance and interpretability, aiding clinical translation of multi-omics data."}}
{"id": "2504.13376", "pdf": "https://arxiv.org/pdf/2504.13376", "abs": "https://arxiv.org/abs/2504.13376", "authors": ["Aitor Gomez-Tejedor", "Eneko Osaba", "Esther Villar-Rodriguez"], "title": "Addressing the Minor-Embedding Problem in Quantum Annealing and Evaluating State-of-the-Art Algorithm Performance", "categories": ["quant-ph", "cs.AI", "cs.ET"], "comment": "Paper submitted for review in the Future Generation Computer Systems\n  journal", "summary": "This study addresses the minor-embedding problem, which involves mapping the\nvariables of an Ising model onto a quantum annealing processor. The primary\nmotivation stems from the observed performance disparity of quantum annealers\nwhen solving problems suited to the processor's architecture versus those with\nnon-hardware-native topologies. Our research has two main objectives: i) to\nanalyze the impact of embedding quality on the performance of D-Wave Systems\nquantum annealers, and ii) to evaluate the quality of the embeddings generated\nby Minorminer, an algorithm provided by D-Wave and widely recognized as the\nstandard minor-embedding technique in the literature. Regarding the first\nobjective, our experiments reveal a clear correlation between the average chain\nlength of embeddings and the relative errors of the solutions sampled. This\nunderscores the critical influence of embedding quality on quantum annealing\nperformance. For the second objective, we focus on the Minorminer technique,\nassessing its capacity to embed problems, the quality of the embeddings\nproduced, and the robustness of the results. We also compare its performance\nwith Clique Embedding, another algorithm developed by D-Wave, which is\ndeterministic and designed to embed fully connected Ising models into quantum\nannealing processors, serving as a worst-case scenario. The results demonstrate\nthat there is significant room for improvement for Minorminer, as it has not\nconsistently outperformed the worst-case scenario.", "AI": {"tldr": "The study explores the impact of minor-embedding quality on quantum annealing performance, focusing on D-Wave's Minorminer, and finds room for improvement.", "motivation": "The performance gap in quantum annealers for problems with non-hardware-native topologies drives the need to analyze embedding quality.", "method": "The study evaluates Minorminer's embedding quality and compares it with Clique Embedding, a deterministic worst-case scenario.", "result": "Average chain length correlates with solution errors, and Minorminer does not consistently outperform the worst-case scenario.", "conclusion": "Embedding quality significantly affects quantum annealing performance, and Minorminer has potential for improvement."}}
{"id": "2504.11019", "pdf": "https://arxiv.org/pdf/2504.11019", "abs": "https://arxiv.org/abs/2504.11019", "authors": ["Hyejin Lee", "Seokjun Hong", "Jeonghoon Song", "Haechan Cho", "Zhixiong Jin", "Byeonghun Kim", "Joobin Jin", "Jaegyun Im", "Byeongjoon Noh", "Hwasoo Yeo"], "title": "DRIFT open dataset: A drone-derived intelligence for traffic analysis in urban environment", "categories": ["cs.CV", "I.2.10; I.4.8; H.2.8; J.7"], "comment": "30 pages, 15 figures", "summary": "Reliable traffic data are essential for understanding urban mobility and\ndeveloping effective traffic management strategies. This study introduces the\nDRone-derived Intelligence For Traffic analysis (DRIFT) dataset, a large-scale\nurban traffic dataset collected systematically from synchronized drone videos\nat approximately 250 meters altitude, covering nine interconnected\nintersections in Daejeon, South Korea. DRIFT provides high-resolution vehicle\ntrajectories that include directional information, processed through video\nsynchronization and orthomap alignment, resulting in a comprehensive dataset of\n81,699 vehicle trajectories. Through our DRIFT dataset, researchers can\nsimultaneously analyze traffic at multiple scales - from individual vehicle\nmaneuvers like lane-changes and safety metrics such as time-to-collision to\naggregate network flow dynamics across interconnected urban intersections. The\nDRIFT dataset is structured to enable immediate use without additional\npreprocessing, complemented by open-source models for object detection and\ntrajectory extraction, as well as associated analytical tools. DRIFT is\nexpected to significantly contribute to academic research and practical\napplications, such as traffic flow analysis and simulation studies. The dataset\nand related resources are publicly accessible at\nhttps://github.com/AIxMobility/The-DRIFT.", "AI": {"tldr": "The DRIFT dataset offers high-resolution vehicle trajectories from drone videos, enabling multi-scale traffic analysis without preprocessing.", "motivation": "To provide reliable urban traffic data for understanding mobility and improving traffic management.", "method": "Collected data from synchronized drone videos at 250m altitude, covering nine intersections in Daejeon, South Korea, with 81,699 trajectories processed via video synchronization and orthomap alignment.", "result": "A comprehensive dataset with directional vehicle trajectories, supporting analysis from individual maneuvers to network flow dynamics.", "conclusion": "DRIFT aids academic and practical traffic studies, with open-source tools and public accessibility."}}
{"id": "2504.09339", "pdf": "https://arxiv.org/pdf/2504.09339", "abs": "https://arxiv.org/abs/2504.09339", "authors": ["Sharan Sahu"], "title": "Towards Optimal Differentially Private Regret Bounds in Linear MDPs", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": "28 pages, 2 figures", "summary": "We study regret minimization under privacy constraints in episodic\ninhomogeneous linear Markov Decision Processes (MDPs), motivated by the growing\nuse of reinforcement learning (RL) in personalized decision-making systems that\nrely on sensitive user data. In this setting, both transition probabilities and\nreward functions are assumed to be linear in a feature mapping $\\phi(s, a)$,\nand we aim to ensure privacy through joint differential privacy (JDP), a\nrelaxation of differential privacy suited to online learning. Prior work has\nestablished suboptimal regret bounds by privatizing the LSVI-UCB algorithm,\nwhich achieves $\\widetilde{O}(\\sqrt{d^3 H^4 K})$ regret in the non-private\nsetting. Building on recent advances that improve this to near minimax optimal\nregret $\\widetilde{O}(d\\sqrt{H^{3}K})$ via LSVI-UCB++ with Bernstein-style\nbonuses, we design a new differentially private algorithm by privatizing\nLSVI-UCB++ and adapting techniques for variance-aware analysis from offline RL.\nOur algorithm achieves a regret bound of $\\widetilde{O}(d \\sqrt{H^3 K} +\nH^{15/4} d^{7/6} K^{1/2} / \\epsilon)$, improving over previous private methods.\nEmpirical results show that our algorithm retains near-optimal utility compared\nto non-private baselines, indicating that privacy can be achieved with minimal\nperformance degradation in this setting.", "AI": {"tldr": "The paper introduces a differentially private algorithm for regret minimization in episodic inhomogeneous linear MDPs, improving regret bounds while ensuring privacy.", "motivation": "Addressing the need for privacy in RL applications using sensitive user data, the study focuses on joint differential privacy (JDP) to protect data while maintaining performance.", "method": "The authors privatize the LSVI-UCB++ algorithm, incorporating Bernstein-style bonuses and variance-aware techniques from offline RL.", "result": "The proposed algorithm achieves a regret bound of ~O(d\u221a(H\u00b3K) + H\u00b9\u2075/\u2074d\u2077/\u2076K\u00b9/\u00b2/\u03b5), outperforming prior private methods.", "conclusion": "Privacy can be ensured with minimal performance loss, as demonstrated by near-optimal utility in empirical results."}}
{"id": "2504.13414", "pdf": "https://arxiv.org/pdf/2504.13414", "abs": "https://arxiv.org/abs/2504.13414", "authors": ["Hsin-Yi Lin", "Huan-Hsin Tseng", "Samuel Yen-Chi Chen", "Shinjae Yoo"], "title": "Adaptive Non-local Observable on Quantum Neural Networks", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Conventional Variational Quantum Circuits (VQCs) for Quantum Machine Learning\ntypically rely on a fixed Hermitian observable, often built from Pauli\noperators. Inspired by the Heisenberg picture, we propose an adaptive non-local\nmeasurement framework that substantially increases the model complexity of the\nquantum circuits. Our introduction of dynamical Hermitian observables with\nevolving parameters shows that optimizing VQC rotations corresponds to tracing\na trajectory in the observable space. This viewpoint reveals that standard VQCs\nare merely a special case of the Heisenberg representation.\n  Furthermore, we show that properly incorporating variational rotations with\nnon-local observables enhances qubit interaction and information mixture,\nadmitting flexible circuit designs. Two non-local measurement schemes are\nintroduced, and numerical simulations on classification tasks confirm that our\napproach outperforms conventional VQCs, yielding a more powerful and\nresource-efficient approach as a Quantum Neural Network.", "AI": {"tldr": "The paper introduces an adaptive non-local measurement framework for Variational Quantum Circuits (VQCs), outperforming conventional fixed-observable VQCs in complexity and performance.", "motivation": "To enhance the model complexity and flexibility of VQCs by moving beyond fixed Hermitian observables, inspired by the Heisenberg picture.", "method": "Proposes dynamical Hermitian observables with evolving parameters, optimizing VQC rotations as trajectories in observable space. Introduces two non-local measurement schemes.", "result": "Numerical simulations show improved performance and resource efficiency over conventional VQCs in classification tasks.", "conclusion": "The adaptive framework offers a more powerful and flexible Quantum Neural Network approach, generalizing standard VQCs."}}
{"id": "2504.12121", "pdf": "https://arxiv.org/pdf/2504.12121", "abs": "https://arxiv.org/abs/2504.12121", "authors": ["Jose Francisco Diez-Pastor", "Francisco Javier Gonzalez-Moya", "Pedro Latorre-Carmona", "Francisco Javier Perez-Barber\u00eda", "Ludmila I. Kuncheva", "Antonio Canepa-Oneto", "Alvar Arnaiz-Gonz\u00e1lez", "Cesar Garcia-Osorio"], "title": "Remote sensing colour image semantic segmentation of trails created by large herbivorous Mammals", "categories": ["cs.CV"], "comment": "24 pages, 6 figures. Submitted to Computers and Geosciences", "summary": "Identifying spatial regions where biodiversity is threatened is crucial for\neffective ecosystem conservation and monitoring. In this stydy, we assessed\nvarios machine learning methods to detect grazing trails automatically. We\ntested five semantic segmentation models combined with 14 different encoder\nnetworks. The best combination was UNet with MambaOut encoder. The solution\nproposed could be used as the basis for tools aiming at mapping and tracking\nchanges in grazing trails on a continuous temporal basis.", "AI": {"tldr": "Assessed ML methods for detecting grazing trails, finding UNet with MambaOut encoder as the best solution for automated mapping.", "motivation": "To identify spatial regions where biodiversity is threatened by automating the detection of grazing trails for ecosystem conservation.", "method": "Tested five semantic segmentation models combined with 14 encoder networks.", "result": "UNet with MambaOut encoder performed the best.", "conclusion": "The solution can serve as a foundation for tools to map and monitor grazing trails over time."}}
{"id": "2504.11831", "pdf": "https://arxiv.org/pdf/2504.11831", "abs": "https://arxiv.org/abs/2504.11831", "authors": ["Changming Xu", "Debangshu Banerjee", "Deepak Vasisht", "Gagandeep Singh"], "title": "Support is All You Need for Certified VAE Training", "categories": ["cs.LG", "stat.ML"], "comment": "21 pages, 3 figures, ICLR '25", "summary": "Variational Autoencoders (VAEs) have become increasingly popular and deployed\nin safety-critical applications. In such applications, we want to give\ncertified probabilistic guarantees on performance under adversarial attacks. We\npropose a novel method, CIVET, for certified training of VAEs. CIVET depends on\nthe key insight that we can bound worst-case VAE error by bounding the error on\ncarefully chosen support sets at the latent layer. We show this point\nmathematically and present a novel training algorithm utilizing this insight.\nWe show in an extensive evaluation across different datasets (in both the\nwireless and vision application areas), architectures, and perturbation\nmagnitudes that our method outperforms SOTA methods achieving good standard\nperformance with strong robustness guarantees.", "AI": {"tldr": "CIVET is a novel method for certified training of VAEs, providing robustness guarantees under adversarial attacks by bounding worst-case error via latent layer support sets.", "motivation": "To ensure safety in critical applications, certified probabilistic guarantees for VAEs under adversarial attacks are needed.", "method": "CIVET bounds worst-case VAE error by focusing on latent layer support sets and introduces a training algorithm based on this insight.", "result": "Outperforms state-of-the-art methods in standard performance and robustness across datasets, architectures, and perturbation magnitudes.", "conclusion": "CIVET effectively combines strong performance with certified robustness, making it suitable for safety-critical applications."}}
{"id": "2504.13926", "pdf": "https://arxiv.org/pdf/2504.13926", "abs": "https://arxiv.org/abs/2504.13926", "authors": ["Chameera De Silva", "Thilina Halloluwa", "Dhaval Vyas"], "title": "A Multi-Layered Research Framework for Human-Centered AI: Defining the Path to Explainability and Trust", "categories": ["cs.HC", "cs.AI"], "comment": "I am requesting this withdrawal because I believe the current version\n  requires significant revisions and restructuring to better reflect the\n  intended research contributions. I plan to substantially improve the work and\n  may resubmit a revised version in the future. Thank you for your\n  understanding and support", "summary": "The integration of Artificial Intelligence (AI) into high-stakes domains such\nas healthcare, finance, and autonomous systems is often constrained by concerns\nover transparency, interpretability, and trust. While Human-Centered AI (HCAI)\nemphasizes alignment with human values, Explainable AI (XAI) enhances\ntransparency by making AI decisions more understandable. However, the lack of a\nunified approach limits AI's effectiveness in critical decision-making\nscenarios. This paper presents a novel three-layered framework that bridges\nHCAI and XAI to establish a structured explainability paradigm. The framework\ncomprises (1) a foundational AI model with built-in explainability mechanisms,\n(2) a human-centered explanation layer that tailors explanations based on\ncognitive load and user expertise, and (3) a dynamic feedback loop that refines\nexplanations through real-time user interaction. The framework is evaluated\nacross healthcare, finance, and software development, demonstrating its\npotential to enhance decision-making, regulatory compliance, and public trust.\nOur findings advance Human-Centered Explainable AI (HCXAI), fostering AI\nsystems that are transparent, adaptable, and ethically aligned.", "AI": {"tldr": "A novel three-layered framework bridges Human-Centered AI (HCAI) and Explainable AI (XAI) to enhance transparency and trust in high-stakes domains like healthcare and finance.", "motivation": "Addressing the lack of a unified approach in AI transparency and interpretability for critical decision-making scenarios.", "method": "A three-layered framework: (1) foundational AI with explainability, (2) human-centered explanation layer, and (3) dynamic feedback loop.", "result": "Evaluated in healthcare, finance, and software development, improving decision-making, compliance, and trust.", "conclusion": "Advances Human-Centered Explainable AI (HCXAI), promoting transparent, adaptable, and ethical AI systems."}}
{"id": "2504.13499", "pdf": "https://arxiv.org/pdf/2504.13499", "abs": "https://arxiv.org/abs/2504.13499", "authors": ["Alex Ergasti", "Filippo Botti", "Tomaso Fontanini", "Claudio Ferrari", "Massimo Bertozzi", "Andrea Prati"], "title": "U-Shape Mamba: State Space Model for faster diffusion", "categories": ["cs.CV"], "comment": "Accepted at CVPR 2025 eLVM workshop. The code is here:\n  https://github.com/ErgastiAlex/U-Shape-Mamba", "summary": "Diffusion models have become the most popular approach for high-quality image\ngeneration, but their high computational cost still remains a significant\nchallenge. To address this problem, we propose U-Shape Mamba (USM), a novel\ndiffusion model that leverages Mamba-based layers within a U-Net-like\nhierarchical structure. By progressively reducing sequence length in the\nencoder and restoring it in the decoder through Mamba blocks, USM significantly\nlowers computational overhead while maintaining strong generative capabilities.\nExperimental results against Zigma, which is currently the most efficient\nMamba-based diffusion model, demonstrate that USM achieves one-third the\nGFlops, requires less memory and is faster, while outperforming Zigma in image\nquality. Frechet Inception Distance (FID) is improved by 15.3, 0.84 and 2.7\npoints on AFHQ, CelebAHQ and COCO datasets, respectively. These findings\nhighlight USM as a highly efficient and scalable solution for diffusion-based\ngenerative models, making high-quality image synthesis more accessible to the\nresearch community while reducing computational costs.", "AI": {"tldr": "USM is a new diffusion model using Mamba-based layers in a U-Net structure, reducing computational costs while maintaining image quality.", "motivation": "High computational costs of diffusion models hinder their efficiency.", "method": "USM integrates Mamba blocks in a U-Net-like hierarchy to reduce sequence length in the encoder and restore it in the decoder.", "result": "USM reduces GFlops by one-third, uses less memory, and is faster than Zigma, with improved FID scores on multiple datasets.", "conclusion": "USM is an efficient, scalable solution for high-quality image synthesis with lower computational costs."}}
{"id": "2504.12712", "pdf": "https://arxiv.org/pdf/2504.12712", "abs": "https://arxiv.org/abs/2504.12712", "authors": ["Hyunji Jung", "Hanseul Cho", "Chulhee Yun"], "title": "Convergence and Implicit Bias of Gradient Descent on Continual Linear Classification", "categories": ["cs.LG", "math.OC"], "comment": "67 pages, 11 figures, accepted to ICLR 2025, Camera-ready version", "summary": "We study continual learning on multiple linear classification tasks by\nsequentially running gradient descent (GD) for a fixed budget of iterations per\ntask. When all tasks are jointly linearly separable and are presented in a\ncyclic/random order, we show the directional convergence of the trained linear\nclassifier to the joint (offline) max-margin solution. This is surprising\nbecause GD training on a single task is implicitly biased towards the\nindividual max-margin solution for the task, and the direction of the joint\nmax-margin solution can be largely different from these individual solutions.\nAdditionally, when tasks are given in a cyclic order, we present a\nnon-asymptotic analysis on cycle-averaged forgetting, revealing that (1)\nalignment between tasks is indeed closely tied to catastrophic forgetting and\nbackward knowledge transfer and (2) the amount of forgetting vanishes to zero\nas the cycle repeats. Lastly, we analyze the case where the tasks are no longer\njointly separable and show that the model trained in a cyclic order converges\nto the unique minimum of the joint loss function.", "AI": {"tldr": "The paper analyzes continual learning for multiple linear classification tasks using gradient descent, showing convergence to the joint max-margin solution and exploring forgetting dynamics.", "motivation": "To understand how gradient descent in continual learning settings converges to joint solutions despite biases toward individual task solutions.", "method": "Sequential gradient descent on tasks in cyclic/random orders, with analysis of directional convergence and forgetting.", "result": "Convergence to joint max-margin solution for separable tasks; cyclic order reduces forgetting. For non-separable tasks, convergence to joint loss minimum.", "conclusion": "Alignment between tasks affects forgetting, and cyclic training mitigates it. Joint solutions emerge despite individual biases."}}
{"id": "2504.14070", "pdf": "https://arxiv.org/pdf/2504.14070", "abs": "https://arxiv.org/abs/2504.14070", "authors": ["Jinesh Jhonsa", "William Whitehead", "David McCarthy", "Shuvro Chowdhury", "Kerem Camsari", "Luke Theogarajan"], "title": "A CMOS Probabilistic Computing Chip With In-situ hardware Aware Learning", "categories": ["cs.AR", "cs.AI"], "comment": "3 pages 12 figuewa", "summary": "This paper demonstrates a probabilistic bit physics inspired solver with 440\nspins configured in a Chimera graph, occupying an area of 0.44 mm^2. Area\nefficiency is maximized through a current-mode implementation of the neuron\nupdate circuit, standard cell design for analog blocks pitch-matched to digital\nblocks, and a shared power supply for both digital and analog components.\nProcess variation related mismatches introduced by this approach are\neffectively mitigated using a hardware aware contrastive divergence algorithm\nduring training. We validate the chip's ability to perform probabilistic\ncomputing tasks such as modeling logic gates and full adders, as well as\noptimization tasks such as MaxCut, demonstrating its potential for AI and\nmachine learning applications.", "AI": {"tldr": "A probabilistic bit physics solver with 440 spins in a Chimera graph achieves high area efficiency and mitigates process variation mismatches for AI and ML tasks.", "motivation": "To develop an area-efficient, hardware-aware probabilistic computing solver for AI and machine learning applications.", "method": "Uses a current-mode neuron update circuit, standard cell design, shared power supply, and a hardware-aware contrastive divergence algorithm to mitigate mismatches.", "result": "Validated for probabilistic computing tasks (logic gates, full adders) and optimization tasks (MaxCut).", "conclusion": "The solver demonstrates potential for AI and ML applications with efficient hardware implementation."}}
{"id": "2504.13617", "pdf": "https://arxiv.org/pdf/2504.13617", "abs": "https://arxiv.org/abs/2504.13617", "authors": ["Zuyao Chen", "Jinlin Wu", "Zhen Lei", "Marc Pollefeys", "Chang Wen Chen"], "title": "Compile Scene Graphs with Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Next token prediction is the fundamental principle for training large\nlanguage models (LLMs), and reinforcement learning (RL) further enhances their\nreasoning performance. As an effective way to model language, image, video, and\nother modalities, the use of LLMs for end-to-end extraction of structured\nvisual representations, such as scene graphs, remains underexplored. It\nrequires the model to accurately produce a set of objects and relationship\ntriplets, rather than generating text token by token. To achieve this, we\nintroduce R1-SGG, a multimodal LLM (M-LLM) initially trained via supervised\nfine-tuning (SFT) on the scene graph dataset and subsequently refined using\nreinforcement learning to enhance its ability to generate scene graphs in an\nend-to-end manner. The SFT follows a conventional prompt-response paradigm,\nwhile RL requires the design of effective reward signals. Given the structured\nnature of scene graphs, we design a graph-centric reward function that\nintegrates node-level rewards, edge-level rewards, and a format consistency\nreward. Our experiments demonstrate that rule-based RL substantially enhances\nmodel performance in the SGG task, achieving a zero failure rate--unlike\nsupervised fine-tuning (SFT), which struggles to generalize effectively. Our\ncode is available at https://github.com/gpt4vision/R1-SGG.", "AI": {"tldr": "The paper introduces R1-SGG, a multimodal LLM trained via supervised fine-tuning and refined with reinforcement learning to generate structured scene graphs, outperforming SFT alone.", "motivation": "To explore the underexplored use of LLMs for end-to-end extraction of structured visual representations like scene graphs, which requires accurate object and relationship triplet generation.", "method": "R1-SGG is trained via supervised fine-tuning (SFT) on scene graph data and refined with reinforcement learning (RL), using a graph-centric reward function.", "result": "Rule-based RL significantly improves model performance, achieving a zero failure rate, unlike SFT which struggles to generalize.", "conclusion": "The combination of SFT and RL effectively enhances the model's ability to generate structured scene graphs, demonstrating the potential of RL in such tasks."}}
{"id": "2504.14205", "pdf": "https://arxiv.org/pdf/2504.14205", "abs": "https://arxiv.org/abs/2504.14205", "authors": ["Wenxin Zhang", "Jingxing Zhong", "Guangzhen Yao", "Renda Han", "Xiaojian Lin", "Zeyu Zhang", "Cuicui Luo"], "title": "Dual-channel Heterophilic Message Passing for Graph Fraud Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fraudulent activities have significantly increased across various domains,\nsuch as e-commerce, online review platforms, and social networks, making fraud\ndetection a critical task. Spatial Graph Neural Networks (GNNs) have been\nsuccessfully applied to fraud detection tasks due to their strong inductive\nlearning capabilities. However, existing spatial GNN-based methods often\nenhance the graph structure by excluding heterophilic neighbors during message\npassing to align with the homophilic bias of GNNs. Unfortunately, this approach\ncan disrupt the original graph topology and increase uncertainty in\npredictions. To address these limitations, this paper proposes a novel\nframework, Dual-channel Heterophilic Message Passing (DHMP), for fraud\ndetection. DHMP leverages a heterophily separation module to divide the graph\ninto homophilic and heterophilic subgraphs, mitigating the low-pass inductive\nbias of traditional GNNs. It then applies shared weights to capture signals at\ndifferent frequencies independently and incorporates a customized sampling\nstrategy for training. This allows nodes to adaptively balance the\ncontributions of various signals based on their labels. Extensive experiments\non three real-world datasets demonstrate that DHMP outperforms existing\nmethods, highlighting the importance of separating signals with different\nfrequencies for improved fraud detection. The code is available at\nhttps://github.com/shaieesss/DHMP.", "AI": {"tldr": "The paper proposes DHMP, a framework for fraud detection using GNNs, addressing limitations of existing methods by separating homophilic and heterophilic signals.", "motivation": "Fraud detection is critical, but current GNN-based methods disrupt graph topology by excluding heterophilic neighbors, increasing prediction uncertainty.", "method": "DHMP divides the graph into homophilic and heterophilic subgraphs, uses shared weights for signal capture, and employs a customized sampling strategy.", "result": "DHMP outperforms existing methods on three real-world datasets, showing improved fraud detection.", "conclusion": "Separating signals of different frequencies enhances fraud detection, with DHMP proving effective."}}
{"id": "2504.14139", "pdf": "https://arxiv.org/pdf/2504.14139", "abs": "https://arxiv.org/abs/2504.14139", "authors": ["Hai Pham-Ngoc", "De Nguyen-Van", "Dung Vu-Tien", "Phuong Le-Hong"], "title": "ThyroidEffi 1.0: A Cost-Effective System for High-Performance Multi-Class Thyroid Carcinoma Classification", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint", "summary": "Background: Automated classification of thyroid Fine Needle Aspiration Biopsy\n(FNAB) images faces challenges in limited data, inter-observer variability, and\ncomputational cost. Efficient, interpretable models are crucial for clinical\nsupport.\n  Objective: To develop and externally validate a deep learning system for\nmulti-class thyroid FNAB image classification into three key categories\ndirectly guiding post-biopsy treatment in Vietnam: Benign (Bethesda II),\nIndeterminate/Suspicious (BI, III, IV, V), and Malignant (BVI), achieving high\ndiagnostic accuracy with low computational overhead.\n  Methods: Our pipeline features: (1) YOLOv10 cell cluster detection for\ninformative sub-region extraction/noise reduction; (2) curriculum learning\nsequencing localized crops to full images for multi-scale capture; (3) adaptive\nlightweight EfficientNetB0 (4M parameters) balancing performance/efficiency;\nand (4) a Transformer-inspired module for multi-scale/multi-region analysis.\nExternal validation used 1,015 independent FNAB images.\n  Results: ThyroidEffi Basic achieved macro F1 of 89.19% and AUCs of 0.98\n(Benign), 0.95 (Indeterminate/Suspicious), 0.96 (Malignant) on the internal\ntest set. External validation yielded AUCs of 0.9495 (Benign), 0.7436\n(Indeterminate/Suspicious), 0.8396 (Malignant). ThyroidEffi Premium improved\nmacro F1 to 89.77%. Grad-CAM highlighted key diagnostic regions, confirming\ninterpretability. The system processed 1000 cases in 30 seconds, demonstrating\nfeasibility on widely accessible hardware.\n  Conclusions: This work demonstrates that high-accuracy, interpretable thyroid\nFNAB image classification is achievable with minimal computational demands.", "AI": {"tldr": "A deep learning system for thyroid FNAB image classification achieves high accuracy with low computational cost, validated internally and externally.", "motivation": "Address challenges in thyroid FNAB image classification, such as limited data and high computational costs, to provide efficient clinical support.", "method": "Uses YOLOv10 for cell cluster detection, curriculum learning, lightweight EfficientNetB0, and a Transformer-inspired module for multi-scale analysis.", "result": "Achieves high macro F1 (89.19%) and AUCs (0.98, 0.95, 0.96) on internal tests; external validation shows AUCs of 0.9495, 0.7436, 0.8396.", "conclusion": "High-accuracy, interpretable thyroid FNAB classification is feasible with minimal computational demands."}}
{"id": "2504.15095", "pdf": "https://arxiv.org/pdf/2504.15095", "abs": "https://arxiv.org/abs/2504.15095", "authors": ["Mingxia Zhan", "Li Zhang", "Xiaomeng Chu", "Beibei Wang"], "title": "VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced Long-Range Depth Estimation", "categories": ["cs.CV"], "comment": "8 pages, 6 figures, 4 tables", "summary": "Monocular depth estimation (MDE) aims to predict per-pixel depth values from\na single RGB image. Recent advancements have positioned diffusion models as\neffective MDE tools by framing the challenge as a conditional image generation\ntask. Despite their progress, these methods often struggle with accurately\nreconstructing distant depths, due largely to the imbalanced distribution of\ndepth values and an over-reliance on spatial-domain features. To overcome these\nlimitations, we introduce VistaDepth, a novel framework that integrates\nadaptive frequency-domain feature enhancements with an adaptive\nweight-balancing mechanism into the diffusion process. Central to our approach\nis the Latent Frequency Modulation (LFM) module, which dynamically refines\nspectral responses in the latent feature space, thereby improving the\npreservation of structural details and reducing noisy artifacts. Furthermore,\nwe implement an adaptive weighting strategy that modulates the diffusion loss\nin real-time, enhancing the model's sensitivity towards distant depth\nreconstruction. These innovations collectively result in superior depth\nperception performance across both distance and detail. Experimental\nevaluations confirm that VistaDepth achieves state-of-the-art performance among\ndiffusion-based MDE techniques, particularly excelling in the accurate\nreconstruction of distant regions.", "AI": {"tldr": "VistaDepth improves monocular depth estimation by integrating frequency-domain enhancements and adaptive weighting into diffusion models, excelling in distant depth reconstruction.", "motivation": "Existing diffusion-based MDE methods struggle with distant depth accuracy due to imbalanced depth distributions and spatial-domain over-reliance.", "method": "VistaDepth uses a Latent Frequency Modulation (LFM) module for spectral refinement and adaptive weighting to balance diffusion loss, enhancing distant depth reconstruction.", "result": "VistaDepth achieves state-of-the-art performance, particularly in distant depth accuracy.", "conclusion": "The framework's innovations in frequency-domain features and adaptive weighting significantly improve MDE, especially for distant regions."}}
{"id": "2504.14572", "pdf": "https://arxiv.org/pdf/2504.14572", "abs": "https://arxiv.org/abs/2504.14572", "authors": ["Steve Hanneke", "Shay Moran", "Alexander Shlimovich", "Amir Yehudayoff"], "title": "Data Selection for ERMs", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Learning theory has traditionally followed a model-centric approach, focusing\non designing optimal algorithms for a fixed natural learning task (e.g., linear\nclassification or regression). In this paper, we adopt a complementary\ndata-centric perspective, whereby we fix a natural learning rule and focus on\noptimizing the training data. Specifically, we study the following question:\ngiven a learning rule $\\mathcal{A}$ and a data selection budget $n$, how well\ncan $\\mathcal{A}$ perform when trained on at most $n$ data points selected from\na population of $N$ points? We investigate when it is possible to select $n \\ll\nN$ points and achieve performance comparable to training on the entire\npopulation.\n  We address this question across a variety of empirical risk minimizers. Our\nresults include optimal data-selection bounds for mean estimation, linear\nclassification, and linear regression. Additionally, we establish two general\nresults: a taxonomy of error rates in binary classification and in stochastic\nconvex optimization. Finally, we propose several open questions and directions\nfor future research.", "AI": {"tldr": "The paper shifts from a model-centric to a data-centric approach, optimizing training data selection for learning rules to achieve comparable performance with fewer points.", "motivation": "Traditional learning theory focuses on algorithms for fixed tasks; this work explores optimizing data selection for given learning rules.", "method": "Study data selection for learning rules, analyzing performance with limited data points across empirical risk minimizers like mean estimation and linear models.", "result": "Optimal bounds for data selection in mean estimation, linear classification, and regression, plus general insights for binary classification and convex optimization.", "conclusion": "Demonstrates feasibility of selecting fewer points for comparable performance, with open questions for future research."}}
{"id": "2504.15654", "pdf": "https://arxiv.org/pdf/2504.15654", "abs": "https://arxiv.org/abs/2504.15654", "authors": ["Md Abdul Baset Sarker", "Art Nguyen", "Sigmond Kukla", "Kevin Fite", "Masudul H. Imtiaz"], "title": "A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "This paper introduces a novel AI vision-enabled pediatric prosthetic hand\ndesigned to assist children aged 10-12 with upper limb disabilities. The\nprosthesis features an anthropomorphic appearance, multi-articulating\nfunctionality, and a lightweight design that mimics a natural hand, making it\nboth accessible and affordable for low-income families. Using 3D printing\ntechnology and integrating advanced machine vision, sensing, and embedded\ncomputing, the prosthetic hand offers a low-cost, customizable solution that\naddresses the limitations of current myoelectric prostheses. A micro camera is\ninterfaced with a low-power FPGA for real-time object detection and assists\nwith precise grasping. The onboard DL-based object detection and grasp\nclassification models achieved accuracies of 96% and 100% respectively. In the\nforce prediction, the mean absolute error was found to be 0.018. The features\nof the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted\nmicro camera for artificial sensing, enabling a wide range of hand-based tasks;\nb) real-time object detection and distance estimation for precise grasping; and\nc) ultra-low-power operation that delivers high performance within constrained\npower and resource limits.", "AI": {"tldr": "A novel AI-powered pediatric prosthetic hand for children aged 10-12, featuring 3D printing, machine vision, and low-cost design, achieves high accuracy in object detection and grasping.", "motivation": "To address the limitations of current myoelectric prostheses by providing an affordable, customizable, and functional solution for children with upper limb disabilities.", "method": "Uses 3D printing, machine vision, sensing, and embedded computing, with a micro camera and FPGA for real-time object detection and grasping.", "result": "Achieved 96% accuracy in object detection, 100% in grasp classification, and a mean absolute error of 0.018 in force prediction.", "conclusion": "The prosthetic hand offers a practical, high-performance, and low-cost solution for children, with advanced features like real-time object detection and ultra-low-power operation."}}
{"id": "2504.15134", "pdf": "https://arxiv.org/pdf/2504.15134", "abs": "https://arxiv.org/abs/2504.15134", "authors": ["Xiao Zhang", "Lu Zou", "Tao Lu", "Yuan Yao", "Zhangjin Huang", "Guoping Wang"], "title": "Instance-Adaptive Keypoint Learning with Local-to-Global Geometric Aggregation for Category-Level Object Pose Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Category-level object pose estimation aims to predict the 6D pose and size of\npreviously unseen instances from predefined categories, requiring strong\ngeneralization across diverse object instances. Although many previous methods\nattempt to mitigate intra-class variations, they often struggle with instances\nexhibiting complex geometries or significant deviations from canonical shapes.\nTo address this challenge, we propose INKL-Pose, a novel category-level object\npose estimation framework that enables INstance-adaptive Keypoint Learning with\nlocal-to-global geometric aggregation. Specifically, our approach first\npredicts semantically consistent and geometric informative keypoints through an\nInstance-Adaptive Keypoint Generator, then refines them with: (1) a Local\nKeypoint Feature Aggregator capturing fine-grained geometries, and (2) a Global\nKeypoint Feature Aggregator using bidirectional Mamba for structural\nconsistency. To enable bidirectional modeling in Mamba, we introduce a Feature\nSequence Flipping strategy that preserves spatial coherence while constructing\nbackward feature sequences. Additionally, we design a surface loss and a\nseparation loss to enforce uniform coverage and spatial diversity in keypoint\ndistribution. The generated keypoints are finally mapped to a canonical space\nfor regressing the object's 6D pose and size. Extensive experiments on\nCAMERA25, REAL275, and HouseCat6D demonstrate that INKL-Pose achieves\nstate-of-the-art performance and significantly outperforms existing methods.", "AI": {"tldr": "INKL-Pose introduces instance-adaptive keypoint learning with local-to-global geometric aggregation for category-level 6D pose estimation, outperforming existing methods.", "motivation": "Addressing challenges in generalizing across diverse object instances, especially those with complex geometries or deviations from canonical shapes.", "method": "Predicts keypoints via an Instance-Adaptive Keypoint Generator, refines them with local and global feature aggregators, and uses bidirectional Mamba with Feature Sequence Flipping. Includes surface and separation losses for keypoint quality.", "result": "Achieves state-of-the-art performance on CAMERA25, REAL275, and HouseCat6D datasets.", "conclusion": "INKL-Pose effectively handles intra-class variations and complex geometries, setting a new benchmark for category-level pose estimation."}}
{"id": "2504.14732", "pdf": "https://arxiv.org/pdf/2504.14732", "abs": "https://arxiv.org/abs/2504.14732", "authors": ["Muhammad Qasim Elahi", "Somtochukwu Oguchienti", "Maheed H. Ahmed", "Mahsa Ghasemi"], "title": "Reinforcement Learning from Multi-level and Episodic Human Feedback", "categories": ["cs.LG"], "comment": null, "summary": "Designing an effective reward function has long been a challenge in\nreinforcement learning, particularly for complex tasks in unstructured\nenvironments. To address this, various learning paradigms have emerged that\nleverage different forms of human input to specify or refine the reward\nfunction. Reinforcement learning from human feedback is a prominent approach\nthat utilizes human comparative feedback, expressed as a preference for one\nbehavior over another, to tackle this problem. In contrast to comparative\nfeedback, we explore multi-level human feedback, which is provided in the form\nof a score at the end of each episode. This type of feedback offers more coarse\nbut informative signals about the underlying reward function than binary\nfeedback. Additionally, it can handle non-Markovian rewards, as it is based on\nthe evaluation of an entire episode. We propose an algorithm to efficiently\nlearn both the reward function and the optimal policy from this form of\nfeedback. Moreover, we show that the proposed algorithm achieves sublinear\nregret and demonstrate its empirical effectiveness through extensive\nsimulations.", "AI": {"tldr": "The paper explores multi-level human feedback for reward function design in reinforcement learning, proposing an efficient algorithm to learn rewards and policies from episodic scores.", "motivation": "Designing effective reward functions in complex, unstructured environments is challenging. Existing methods like comparative feedback are limited, prompting the exploration of multi-level feedback.", "method": "The authors propose an algorithm to learn reward functions and optimal policies from episodic scores, a form of multi-level human feedback.", "result": "The algorithm achieves sublinear regret and demonstrates empirical effectiveness in simulations.", "conclusion": "Multi-level human feedback is a viable alternative to comparative feedback, offering coarse but informative signals for reward learning in reinforcement learning."}}
{"id": "2504.16381", "pdf": "https://arxiv.org/pdf/2504.16381", "abs": "https://arxiv.org/abs/2504.16381", "authors": ["Magnus Petersen", "Roberto Covino"], "title": "PINN-MEP: Continuous Neural Representations for Minimum-Energy Path Discovery in Molecular Systems", "categories": ["physics.chem-ph", "cs.AI", "physics.comp-ph"], "comment": "Update 28.04.2025: Added citation and reference to\n  \"Action-Minimization Meets Generative Modeling: Efficient Transition Path\n  Sampling with the Onsager-Machlup Functional\" by Sanjeev Raja et al. and\n  added an appendix section clarifying some loss derivation steps", "summary": "Characterizing conformational transitions in physical systems remains a\nfundamental challenge in the computational sciences. Traditional sampling\nmethods like molecular dynamics (MD) or MCMC often struggle with the\nhigh-dimensional nature of molecular systems and the high energy barriers of\ntransitions between stable states. While these transitions are rare events in\nsimulation timescales, they often represent the most biologically significant\nprocesses - for example, the conformational change of an ion channel protein\nfrom its closed to open state, which controls cellular ion flow and is crucial\nfor neural signaling. Such transitions in real systems may take milliseconds to\nseconds but could require months or years of continuous simulation to observe\neven once. We present a method that reformulates transition path generation as\na continuous optimization problem solved through physics-informed neural\nnetworks (PINNs) inspired by string methods for minimum-energy path (MEP)\ngeneration. By representing transition paths as implicit neural functions and\nleveraging automatic differentiation with differentiable molecular dynamics\nforce fields, our method enables the efficient discovery of physically\nrealistic transition pathways without requiring expensive path sampling. We\ndemonstrate our method's effectiveness on two proteins, including an explicitly\nhydrated bovine pancreatic trypsin inhibitor (BPTI) system with over 8,300\natoms.", "AI": {"tldr": "A method using physics-informed neural networks (PINNs) is introduced to efficiently discover realistic molecular transition pathways, overcoming limitations of traditional sampling methods like MD or MCMC.", "motivation": "Traditional methods struggle with high-dimensional molecular systems and rare but biologically significant transitions, such as ion channel conformational changes.", "method": "The approach reformulates transition path generation as an optimization problem solved via PINNs, leveraging differentiable force fields and implicit neural functions.", "result": "The method successfully identifies transition pathways, demonstrated on proteins like a hydrated BPTI system with 8,300+ atoms.", "conclusion": "This PINN-based method offers an efficient alternative to costly path sampling for studying rare molecular transitions."}}
{"id": "2504.15624", "pdf": "https://arxiv.org/pdf/2504.15624", "abs": "https://arxiv.org/abs/2504.15624", "authors": ["Jingzhi Li", "Changjiang Luo", "Ruoyu Chen", "Hua Zhang", "Wenqi Ren", "Jianhou Gan", "Xiaochun Cao"], "title": "FaceInsight: A Multimodal Large Language Model for Face Perception", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in multimodal large language models (MLLMs) have demonstrated\nstrong capabilities in understanding general visual content. However, these\ngeneral-domain MLLMs perform poorly in face perception tasks, often producing\ninaccurate or misleading responses to face-specific queries. To address this\ngap, we propose FaceInsight, the versatile face perception MLLM that provides\nfine-grained facial information. Our approach introduces visual-textual\nalignment of facial knowledge to model both uncertain dependencies and\ndeterministic relationships among facial information, mitigating the\nlimitations of language-driven reasoning. Additionally, we incorporate face\nsegmentation maps as an auxiliary perceptual modality, enriching the visual\ninput with localized structural cues to enhance semantic understanding.\nComprehensive experiments and analyses across three face perception tasks\ndemonstrate that FaceInsight consistently outperforms nine compared MLLMs under\nboth training-free and fine-tuned settings.", "AI": {"tldr": "FaceInsight is a multimodal large language model (MLLM) designed for face perception tasks, outperforming general-domain MLLMs by incorporating visual-textual alignment and face segmentation maps.", "motivation": "General-domain MLLMs perform poorly in face perception tasks, producing inaccurate responses. This gap motivates the development of FaceInsight.", "method": "FaceInsight aligns visual-textual facial knowledge and uses face segmentation maps as an auxiliary modality to enhance understanding.", "result": "FaceInsight consistently outperforms nine other MLLMs in three face perception tasks under training-free and fine-tuned settings.", "conclusion": "FaceInsight addresses the limitations of general-domain MLLMs in face perception, offering improved accuracy and fine-grained facial understanding."}}
{"id": "2504.14814", "pdf": "https://arxiv.org/pdf/2504.14814", "abs": "https://arxiv.org/abs/2504.14814", "authors": ["Kazuhisa Fujita"], "title": "A Basic Evaluation of Neural Networks Trained with the Error Diffusion Learning Algorithm", "categories": ["cs.LG"], "comment": null, "summary": "Artificial neural networks are powerful tools capable of addressing various\ntasks. Although the backpropagation algorithm has become a standard training\nmethod for these neural networks, its lack of biological plausibility has\ninspired the development of alternative learning approaches. One such\nalternative is Kaneko's Error Diffusion Learning Algorithm (EDLA), a\nbiologically motivated approach wherein a single global error signal diffuses\nthroughout a network composed of paired excitatory-inhibitory sublayers,\nthereby eliminating the necessity for layer-wise backpropagation. This study\npresents a contemporary formulation of the EDLA framework and evaluates its\neffectiveness through parity check, regression, and image classification tasks.\nOur experimental results indicate that EDLA networks can consistently achieve\nhigh accuracy across these benchmarks, with performance efficiency and\nconvergence speed notably influenced by the choice of learning rate, neuron\ncount, and network depth. Further investigation of the internal representations\nformed by EDLA networks reveals their capacity for meaningful feature\nextraction, similar to traditional neural networks. These results suggest that\nEDLA is a biologically motivated alternative for training feedforward networks\nand will motivate future work on extending this method to biologically inspired\nneural networks.", "AI": {"tldr": "Kaneko's Error Diffusion Learning Algorithm (EDLA) is a biologically plausible alternative to backpropagation, showing high accuracy in tasks like parity check, regression, and image classification.", "motivation": "The lack of biological plausibility in backpropagation inspired the development of EDLA as an alternative learning method.", "method": "EDLA uses a single global error signal diffusing through excitatory-inhibitory sublayers, avoiding layer-wise backpropagation.", "result": "EDLA achieves high accuracy in benchmarks, with performance influenced by learning rate, neuron count, and depth. It also shows meaningful feature extraction.", "conclusion": "EDLA is a viable biologically motivated training method for feedforward networks, with potential for future extensions in biologically inspired neural networks."}}
{"id": "2504.16419", "pdf": "https://arxiv.org/pdf/2504.16419", "abs": "https://arxiv.org/abs/2504.16419", "authors": ["Qi Yang", "Weichen Bi", "Haiyang Shen", "Yaoqi Guo", "Yun Ma"], "title": "PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": null, "summary": "Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction.", "AI": {"tldr": "PixelWeb is a large-scale GUI dataset with over 100,000 annotated web pages, addressing inaccurate BBox annotations in existing datasets through a novel automatic annotation approach combining visual and DOM analysis.", "motivation": "Existing GUI datasets suffer from inaccurate BBox annotations (missing, duplicate, or meaningless) and lack comprehensive metadata, limiting model performance and downstream task development.", "method": "PixelWeb uses channel derivation (BGRA four-channel bitmap annotations) for accurate GUI element localization and layer analysis (DOM-based visibility and stacking order) for precise BBox annotations.", "result": "PixelWeb achieves 3-7 times better performance on the mAP95 metric for GUI element detection compared to existing datasets.", "conclusion": "PixelWeb's high-quality annotations and comprehensive metadata make it a valuable resource for improving downstream tasks like GUI generation and automated user interaction."}}
{"id": "2504.15958", "pdf": "https://arxiv.org/pdf/2504.15958", "abs": "https://arxiv.org/abs/2504.15958", "authors": ["Zebin Yao", "Lei Ren", "Huixing Jiang", "Chen Wei", "Xiaojie Wang", "Ruifan Li", "Fangxiang Feng"], "title": "FreeGraftor: Training-Free Cross-Image Feature Grafting for Subject-Driven Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Subject-driven image generation aims to synthesize novel scenes that\nfaithfully preserve subject identity from reference images while adhering to\ntextual guidance, yet existing methods struggle with a critical trade-off\nbetween fidelity and efficiency. Tuning-based approaches rely on time-consuming\nand resource-intensive subject-specific optimization, while zero-shot methods\nfail to maintain adequate subject consistency. In this work, we propose\nFreeGraftor, a training-free framework that addresses these limitations through\ncross-image feature grafting. Specifically, FreeGraftor employs semantic\nmatching and position-constrained attention fusion to transfer visual details\nfrom reference subjects to the generated image. Additionally, our framework\nincorporates a novel noise initialization strategy to preserve geometry priors\nof reference subjects for robust feature matching. Extensive qualitative and\nquantitative experiments demonstrate that our method enables precise subject\nidentity transfer while maintaining text-aligned scene synthesis. Without\nrequiring model fine-tuning or additional training, FreeGraftor significantly\noutperforms existing zero-shot and training-free approaches in both subject\nfidelity and text alignment. Furthermore, our framework can seamlessly extend\nto multi-subject generation, making it practical for real-world deployment. Our\ncode is available at https://github.com/Nihukat/FreeGraftor.", "AI": {"tldr": "FreeGraftor is a training-free framework for subject-driven image generation, balancing fidelity and efficiency via cross-image feature grafting.", "motivation": "Existing methods face a trade-off between fidelity and efficiency; tuning-based approaches are resource-heavy, while zero-shot methods lack subject consistency.", "method": "Uses semantic matching, position-constrained attention fusion, and noise initialization to transfer visual details and preserve geometry priors.", "result": "Outperforms zero-shot and training-free methods in subject fidelity and text alignment, with seamless multi-subject generation.", "conclusion": "FreeGraftor offers a practical, efficient solution for high-fidelity subject-driven image synthesis without training."}}
{"id": "2504.15077", "pdf": "https://arxiv.org/pdf/2504.15077", "abs": "https://arxiv.org/abs/2504.15077", "authors": ["Simone Papicchio", "Simone Rossi", "Luca Cagliero", "Paolo Papotti"], "title": "Think2SQL: Reinforce LLM Reasoning Capabilities for Text2SQL", "categories": ["cs.LG", "cs.DB"], "comment": "17 pages, work in progress", "summary": "Large Language Models (LLMs) have shown impressive capabilities in\ntransforming natural language questions about relational databases into SQL\nqueries. Despite recent improvements, small LLMs struggle to handle questions\ninvolving multiple tables and complex SQL patterns under a Zero-Shot Learning\n(ZSL) setting. Supervised Fine-Tuning (SFT) partially compensates for the\nknowledge deficits in pretrained models but falls short while dealing with\nqueries involving multi-hop reasoning. To bridge this gap, different LLM\ntraining strategies to reinforce reasoning capabilities have been proposed,\nranging from leveraging a thinking process within ZSL, including reasoning\ntraces in SFT, or adopt Reinforcement Learning (RL) strategies. However, the\ninfluence of reasoning on Text2SQL performance is still largely unexplored.\nThis paper investigates to what extent LLM reasoning capabilities influence\ntheir Text2SQL performance on four benchmark datasets. To this end, it\nconsiders the following LLM settings: (1) ZSL, including general-purpose\nreasoning or not; (2) SFT, with and without task-specific reasoning traces; (3)\nRL, exploring the use of different rewarding functions, both the established\nEXecution accuracy (EX) and a mix with fine-grained ones that also account the\nprecision, recall, and cardinality of partially correct answers; (4) SFT+RL,\ni.e, a two-stage approach that combines SFT and RL. The results show that\ngeneral-purpose reasoning under ZSL proves to be ineffective in tackling\ncomplex Text2SQL cases. Small LLMs benefit from SFT with reasoning much more\nthan larger ones. RL is generally beneficial across all tested models and\ndatasets. The use of the fine-grained metrics turns out to be the most\neffective RL strategy. Thanks to RL and the novel text2SQL rewards, the 7B\nQwen-Coder-2.5 model performs on par with 400+ Billion ones (including gpt-4o)\non the Bird dataset.", "AI": {"tldr": "The paper explores how reasoning capabilities in LLMs affect Text2SQL performance, comparing ZSL, SFT, RL, and SFT+RL strategies. Results show SFT with reasoning helps small LLMs, RL is broadly effective, and fine-grained rewards boost performance.", "motivation": "Small LLMs struggle with complex SQL queries under ZSL, and SFT alone isn't enough for multi-hop reasoning. The study aims to understand how reasoning impacts Text2SQL performance.", "method": "Evaluates LLMs under ZSL (with/without reasoning), SFT (with/without reasoning traces), RL (using EX and fine-grained rewards), and SFT+RL on four datasets.", "result": "General-purpose reasoning in ZSL fails for complex cases. SFT with reasoning aids small LLMs. RL is universally beneficial, with fine-grained rewards being most effective. A 7B model matches GPT-4o on Bird dataset.", "conclusion": "Reasoning-enhanced training, especially RL with fine-grained rewards, significantly improves Text2SQL performance, enabling smaller models to compete with larger ones."}}
{"id": "2504.16940", "pdf": "https://arxiv.org/pdf/2504.16940", "abs": "https://arxiv.org/abs/2504.16940", "authors": ["Drew Linsley", "Pinyuan Feng", "Thomas Serre"], "title": "Better artificial intelligence does not mean better models of biology", "categories": ["q-bio.NC", "cs.AI", "cs.CV"], "comment": null, "summary": "Deep neural networks (DNNs) once showed increasing alignment with primate\nperception and neural responses as they improved on vision benchmarks, raising\nhopes that advances in AI would yield better models of biological vision.\nHowever, we show across three benchmarks that this alignment is now plateauing\n- and in some cases worsening - as DNNs scale to human or superhuman accuracy.\nThis divergence may reflect the adoption of visual strategies that differ from\nthose used by primates. These findings challenge the view that progress in\nartificial intelligence will naturally translate to neuroscience. We argue that\nvision science must chart its own course, developing algorithms grounded in\nbiological visual systems rather than optimizing for benchmarks based on\ninternet-scale datasets.", "AI": {"tldr": "Alignment between DNNs and primate vision is plateauing or worsening as DNNs achieve higher accuracy, suggesting divergent visual strategies and the need for biologically grounded models.", "motivation": "To investigate whether advances in AI (specifically DNNs) continue to align with primate vision as DNNs achieve higher accuracy.", "method": "Analyzed three benchmarks comparing DNN performance and alignment with primate perception and neural responses.", "result": "Alignment between DNNs and primate vision is plateauing or worsening, indicating divergent visual strategies.", "conclusion": "Vision science should develop biologically grounded algorithms rather than relying on AI benchmark optimization."}}
{"id": "2504.16616", "pdf": "https://arxiv.org/pdf/2504.16616", "abs": "https://arxiv.org/abs/2504.16616", "authors": ["Haosheng Chen", "Lian Luo", "Mengjingcheng Mo", "Zhanjie Wu", "Guobao Xiao", "Ji Gan", "Jiaxu Leng", "Xinbo Gao"], "title": "EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception", "categories": ["cs.CV"], "comment": null, "summary": "Event cameras, with microsecond temporal resolution and high dynamic range\n(HDR) characteristics, emit high-speed event stream for perception tasks.\nDespite the recent advancement in GNN-based perception methods, they are prone\nto use straightforward pairwise connectivity mechanisms in the pure Euclidean\nspace where they struggle to capture long-range dependencies and fail to\neffectively characterize the inherent hierarchical structures of non-uniformly\ndistributed event stream. To this end, in this paper we propose a novel\napproach named EHGCN, which is a pioneer to perceive event stream in both\nEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce an\nadaptive sampling strategy to dynamically regulate sampling rates, retaining\ndiscriminative events while attenuating chaotic noise. Then we present a Markov\nVector Field (MVF)-driven motion-aware hyperedge generation method based on\nmotion state transition probabilities, thereby eliminating cross-target\nspurious associations and providing critically topological priors while\ncapturing long-range dependencies between events. Finally, we propose a\nEuclidean-Hyperbolic GCN to fuse the information locally aggregated and\nglobally hierarchically modeled in Euclidean and hyperbolic spaces,\nrespectively, to achieve hybrid event perception. Experimental results on event\nperception tasks such as object detection and recognition validate the\neffectiveness of our approach.", "AI": {"tldr": "EHGCN is a novel approach for event vision, combining Euclidean and hyperbolic spaces to improve perception of event streams with adaptive sampling and motion-aware hyperedge generation.", "motivation": "Existing GNN-based methods struggle with long-range dependencies and hierarchical structures in non-uniform event streams.", "method": "EHGCN uses adaptive sampling, motion-aware hyperedge generation, and a Euclidean-Hyperbolic GCN for hybrid event perception.", "result": "Experiments show EHGCN's effectiveness in tasks like object detection and recognition.", "conclusion": "EHGCN successfully addresses limitations of traditional methods by leveraging dual-space modeling."}}
{"id": "2504.17058", "pdf": "https://arxiv.org/pdf/2504.17058", "abs": "https://arxiv.org/abs/2504.17058", "authors": ["Rahul Vishwakarma", "Shrey Dharmendra Modi", "Vishwanath Seshagiri"], "title": "Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 1 figure", "summary": "The generation of high-quality synthetic data presents significant challenges\nin machine learning research, particularly regarding statistical fidelity and\nuncertainty quantification. Existing generative models produce compelling\nsynthetic samples but lack rigorous statistical guarantees about their relation\nto the underlying data distribution, limiting their applicability in critical\ndomains requiring robust error bounds. We address this fundamental limitation\nby presenting a novel framework that incorporates conformal prediction\nmethodologies into Generative Adversarial Networks (GANs). By integrating\nmultiple conformal prediction paradigms including Inductive Conformal\nPrediction (ICP), Mondrian Conformal Prediction, Cross-Conformal Prediction,\nand Venn-Abers Predictors, we establish distribution-free uncertainty\nquantification in generated samples. This approach, termed Conformalized GAN\n(cGAN), demonstrates enhanced calibration properties while maintaining the\ngenerative power of traditional GANs, producing synthetic data with provable\nstatistical guarantees. We provide rigorous mathematical proofs establishing\nfinite-sample validity guarantees and asymptotic efficiency properties,\nenabling the reliable application of synthetic data in high-stakes domains\nincluding healthcare, finance, and autonomous systems.", "AI": {"tldr": "A novel framework, Conformalized GAN (cGAN), integrates conformal prediction into GANs to provide statistical guarantees for synthetic data generation.", "motivation": "Existing generative models lack rigorous statistical guarantees, limiting their use in critical domains.", "method": "Incorporates multiple conformal prediction paradigms (ICP, Mondrian, Cross-Conformal, Venn-Abers) into GANs.", "result": "cGAN offers enhanced calibration and provable statistical guarantees for synthetic data.", "conclusion": "The framework enables reliable synthetic data use in high-stakes domains like healthcare and finance."}}
{"id": "2504.17020", "pdf": "https://arxiv.org/pdf/2504.17020", "abs": "https://arxiv.org/abs/2504.17020", "authors": ["Kasper Engelen", "Guillermo A. P\u00e9rez", "Shrisha Rao"], "title": "Analyzing Value Functions of States in Parametric Markov Chains", "categories": ["cs.LO", "cs.AI"], "comment": "Published as part of the book \"Principles of Verification: Cycling\n  the Probabilistic Landscape: Essays Dedicated to Joost-Pieter Katoen on the\n  Occasion of His 60th Birthday, Part II\"", "summary": "Parametric Markov chains (pMC) are used to model probabilistic systems with\nunknown or partially known probabilities. Although (universal) pMC verification\nfor reachability properties is known to be coETR-complete, there have been\nefforts to approach it using potentially easier-to-check properties such as\nasking whether the pMC is monotonic in certain parameters. In this paper, we\nfirst reduce monotonicity to asking whether the reachability probability from a\ngiven state is never less than that of another given state. Recent results for\nthe latter property imply an efficient algorithm to collapse same-value\nequivalence classes, which in turn preserves verification results and\nmonotonicity. We implement our algorithm to collapse \"trivial\" equivalence\nclasses in the pMC and show empirical evidence for the following: First, the\ncollapse gives reductions in size for some existing benchmarks and significant\nreductions on some custom benchmarks; Second, the collapse speeds up existing\nalgorithms to check monotonicity and parameter lifting, and hence can be used\nas a fast pre-processing step in practice.", "AI": {"tldr": "The paper presents an efficient algorithm to collapse trivial equivalence classes in parametric Markov chains (pMC), reducing model size and speeding up monotonicity checks and parameter lifting.", "motivation": "To simplify pMC verification by leveraging monotonicity properties and reducing computational complexity.", "method": "Reduces monotonicity to comparing reachability probabilities and implements an algorithm to collapse trivial equivalence classes.", "result": "Empirical evidence shows size reductions in benchmarks and faster monotonicity checks.", "conclusion": "The collapse algorithm is effective as a pre-processing step for pMC verification."}}
{"id": "2504.17132", "pdf": "https://arxiv.org/pdf/2504.17132", "abs": "https://arxiv.org/abs/2504.17132", "authors": ["Ning Li", "Antai Andy Liu", "Jingran Zhang", "Justin Cui"], "title": "Latent Video Dataset Distillation", "categories": ["cs.CV"], "comment": "https://openreview.net/forum?id=i665TIHv92", "summary": "Dataset distillation has demonstrated remarkable effectiveness in\nhigh-compression scenarios for image datasets. While video datasets inherently\ncontain greater redundancy, existing video dataset distillation methods\nprimarily focus on compression in the pixel space, overlooking advances in the\nlatent space that have been widely adopted in modern text-to-image and\ntext-to-video models. In this work, we bridge this gap by introducing a novel\nvideo dataset distillation approach that operates in the latent space using a\nstate-of-the-art variational encoder. Furthermore, we employ a diversity-aware\ndata selection strategy to select both representative and diverse samples.\nAdditionally, we introduce a simple, training-free method to further compress\nthe distilled latent dataset. By combining these techniques, our approach\nachieves a new state-of-the-art performance in dataset distillation,\noutperforming prior methods on all datasets, e.g. on HMDB51 IPC 1, we achieve a\n2.6% performance increase; on MiniUCF IPC 5, we achieve a 7.8% performance\nincrease. Our code is available at\nhttps://github.com/liningresearch/Latent_Video_Dataset_Distillation.", "AI": {"tldr": "A novel video dataset distillation method in latent space outperforms prior methods, achieving significant performance gains on benchmarks.", "motivation": "Existing video dataset distillation methods focus on pixel space, ignoring latent space advancements in modern models.", "method": "Uses a state-of-the-art variational encoder in latent space, diversity-aware data selection, and a training-free compression technique.", "result": "Achieves 2.6% and 7.8% performance increases on HMDB51 IPC 1 and MiniUCF IPC 5, respectively.", "conclusion": "The approach sets a new state-of-the-art in video dataset distillation by leveraging latent space and diversity-aware strategies."}}
{"id": "2504.17497", "pdf": "https://arxiv.org/pdf/2504.17497", "abs": "https://arxiv.org/abs/2504.17497", "authors": ["Radia Berreziga", "Mohammed Brahimi", "Khairedine Kraim", "Hamid Azzoune"], "title": "Combining GCN Structural Learning with LLM Chemical Knowledge for Enhanced Virtual Screening", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Virtual screening plays a critical role in modern drug discovery by enabling\nthe identification of promising candidate molecules for experimental\nvalidation. Traditional machine learning methods such, as Support Vector\nMachines (SVM) and XGBoost, rely on predefined molecular representations, often\nleading to information loss and potential bias. In contrast, deep learning\napproaches-particularly Graph Convolutional Networks (GCNs)-offer a more\nexpressive and unbiased alternative by operating directly on molecular graphs.\nMeanwhile, Large Language Models (LLMs) have recently demonstrated\nstate-of-the-art performance in drug design, thanks to their capacity to\ncapture complex chemical patterns from large-scale data via attention\nmechanisms.\n  In this paper, we propose a hybrid architecture that integrates GCNs with\nLLM-derived embeddings to combine localized structural learning with global\nchemical knowledge. The LLM embeddings can be precomputed and stored in a\nmolecular feature library, removing the need to rerun the LLM during training\nor inference and thus maintaining computational efficiency. We found that\nconcatenating the LLM embeddings after each GCN layer-rather than only at the\nfinal layer-significantly improves performance, enabling deeper integration of\nglobal context throughout the network. The resulting model achieves superior\nresults, with an F1-score of (88.8\\%), outperforming standalone GCN (87.9%),\nXGBoost (85.5%), and SVM (85.4%) baselines.", "AI": {"tldr": "A hybrid architecture combining Graph Convolutional Networks (GCNs) and Large Language Model (LLM) embeddings improves virtual screening performance by integrating localized structural learning with global chemical knowledge.", "motivation": "Traditional machine learning methods like SVM and XGBoost rely on predefined molecular representations, which may lose information or introduce bias. Deep learning, especially GCNs and LLMs, offers more expressive and unbiased alternatives.", "method": "Proposes a hybrid model integrating GCNs with precomputed LLM embeddings, concatenating LLM embeddings after each GCN layer for deeper global context integration.", "result": "Achieves superior performance with an F1-score of 88.8%, outperforming standalone GCN (87.9%), XGBoost (85.5%), and SVM (85.4%).", "conclusion": "The hybrid architecture effectively combines GCNs and LLMs, enhancing virtual screening accuracy and computational efficiency."}}
{"id": "2504.17213", "pdf": "https://arxiv.org/pdf/2504.17213", "abs": "https://arxiv.org/abs/2504.17213", "authors": ["Shiwen Cao", "Zhaoxing Zhang", "Junming Jiao", "Juyi Qiao", "Guowen Song", "Rong Shen", "Xiangbing Meng"], "title": "MASR: Self-Reflective Reasoning through Multimodal Hierarchical Attention Focusing for Agent-based Video Understanding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Even in the era of rapid advances in large models, video understanding\nremains a highly challenging task. Compared to texts or images, videos commonly\ncontain more information with redundancy, requiring large models to properly\nallocate attention at a global level for comprehensive and accurate\nunderstanding. To address this, we propose a Multimodal hierarchical Attention\nfocusing Self-reflective Reasoning (MASR) framework for agent-based video\nunderstanding. The key innovation lies in its ability to detect and prioritize\nsegments of videos that are highly relevant to the query. Firstly, MASR\nrealizes Multimodal Coarse-to-fine Relevance Sensing (MCRS) which enhances the\ncorrelation between the acquired contextual information and the query.\nSecondly, MASR employs Dilated Temporal Expansion (DTE) to mitigate the risk of\nmissing crucial details when extracting semantic information from the focused\nframes selected through MCRS. By iteratively applying MCRS and DTE in the\nself-reflective reasoning process, MASR is able to adaptively adjust the\nattention to extract highly query-relevant context and therefore improve the\nresponse accuracy. In the EgoSchema dataset, MASR achieves a remarkable 5%\nperformance gain over previous leading approaches. In the Next-QA and IntentQA\ndatasets, it outperforms the state-of-the-art standards by 0.2% and 0.3%\nrespectively. In the Video-MME dataset that contains long-term videos, MASR\nalso performs better than other agent-based methods.", "AI": {"tldr": "MASR framework improves video understanding by prioritizing relevant segments and adjusting attention dynamically, outperforming state-of-the-art methods.", "motivation": "Video understanding is challenging due to information redundancy; MASR aims to enhance accuracy by focusing on query-relevant segments.", "method": "MASR uses Multimodal Coarse-to-fine Relevance Sensing (MCRS) and Dilated Temporal Expansion (DTE) to adaptively adjust attention and extract relevant context.", "result": "MASR achieves 5% gain in EgoSchema and outperforms benchmarks in Next-QA, IntentQA, and Video-MME datasets.", "conclusion": "MASR effectively addresses video understanding challenges by dynamically focusing attention, demonstrating superior performance across datasets."}}
{"id": "2504.17761", "pdf": "https://arxiv.org/pdf/2504.17761", "abs": "https://arxiv.org/abs/2504.17761", "authors": ["Shiyu Liu", "Yucheng Han", "Peng Xing", "Fukun Yin", "Rui Wang", "Wei Cheng", "Jiaqi Liao", "Yingming Wang", "Honghao Fu", "Chunrui Han", "Guopeng Li", "Yuang Peng", "Quan Sun", "Jingwei Wu", "Yan Cai", "Zheng Ge", "Ranchen Ming", "Lei Xia", "Xianfang Zeng", "Yibo Zhu", "Binxing Jiao", "Xiangyu Zhang", "Gang Yu", "Daxin Jiang"], "title": "Step1X-Edit: A Practical Framework for General Image Editing", "categories": ["cs.CV"], "comment": "code: https://github.com/stepfun-ai/Step1X-Edit", "summary": "In recent years, image editing models have witnessed remarkable and rapid\ndevelopment. The recent unveiling of cutting-edge multimodal models such as\nGPT-4o and Gemini2 Flash has introduced highly promising image editing\ncapabilities. These models demonstrate an impressive aptitude for fulfilling a\nvast majority of user-driven editing requirements, marking a significant\nadvancement in the field of image manipulation. However, there is still a large\ngap between the open-source algorithm with these closed-source models. Thus, in\nthis paper, we aim to release a state-of-the-art image editing model, called\nStep1X-Edit, which can provide comparable performance against the closed-source\nmodels like GPT-4o and Gemini2 Flash. More specifically, we adopt the\nMultimodal LLM to process the reference image and the user's editing\ninstruction. A latent embedding has been extracted and integrated with a\ndiffusion image decoder to obtain the target image. To train the model, we\nbuild a data generation pipeline to produce a high-quality dataset. For\nevaluation, we develop the GEdit-Bench, a novel benchmark rooted in real-world\nuser instructions. Experimental results on GEdit-Bench demonstrate that\nStep1X-Edit outperforms existing open-source baselines by a substantial margin\nand approaches the performance of leading proprietary models, thereby making\nsignificant contributions to the field of image editing.", "AI": {"tldr": "The paper introduces Step1X-Edit, an open-source image editing model that rivals proprietary models like GPT-4o and Gemini2 Flash, using Multimodal LLM and diffusion decoding.", "motivation": "To bridge the gap between open-source and closed-source image editing models by developing a competitive open-source alternative.", "method": "Uses Multimodal LLM for processing images and user instructions, extracts latent embeddings, and integrates them with a diffusion decoder. A high-quality dataset is generated for training, and GEdit-Bench is developed for evaluation.", "result": "Step1X-Edit outperforms open-source baselines and approaches the performance of proprietary models on GEdit-Bench.", "conclusion": "Step1X-Edit advances open-source image editing, narrowing the gap with proprietary models."}}
{"id": "2504.17577", "pdf": "https://arxiv.org/pdf/2504.17577", "abs": "https://arxiv.org/abs/2504.17577", "authors": ["Lei Wang", "Yu Cheng", "Yining Shi", "Zhengju Tang", "Zhiwen Mo", "Wenhao Xie", "Lingxiao Ma", "Yuqing Xia", "Jilong Xue", "Fan Yang", "Zhi Yang"], "title": "TileLang: A Composable Tiled Programming Model for AI Systems", "categories": ["cs.LG"], "comment": null, "summary": "Modern AI workloads rely heavily on optimized computing kernels for both\ntraining and inference. These AI kernels follow well-defined data-flow\npatterns, such as moving tiles between DRAM and SRAM and performing a sequence\nof computations on those tiles. However, writing high-performance kernels\nremains complex despite the clarity of these patterns. Achieving peak\nperformance requires careful, hardware-centric optimizations to fully leverage\nmodern accelerators. While domain-specific compilers attempt to reduce the\nburden of writing high-performance kernels, they often struggle with usability\nand expressiveness gaps. In this paper, we present TileLang, a generalized\ntiled programming model for more efficient AI Kernel programming. TileLang\ndecouples scheduling space (thread binding, layout, tensorize and pipeline)\nfrom dataflow, and encapsulated them as a set of customization annotations and\nprimitives. This approach allows users to focus on the kernel's data-flow\nitself, while leaving most other optimizations to compilers. We conduct\ncomprehensive experiments on commonly-used devices, across numerous\nexperiments, our evaluation shows that TileLang can achieve state-of-the-art\nperformance in key kernels, demonstrating that its unified block-and-thread\nparadigm and transparent scheduling capabilities deliver both the power and\nflexibility demanded by modern AI system development.", "AI": {"tldr": "TileLang is a tiled programming model for AI kernels, decoupling scheduling from dataflow to simplify high-performance kernel development while achieving state-of-the-art results.", "motivation": "Writing high-performance AI kernels is complex due to hardware-centric optimizations, and existing compilers struggle with usability and expressiveness.", "method": "TileLang introduces a generalized tiled programming model, separating scheduling (thread binding, layout, etc.) from dataflow via annotations and primitives.", "result": "Experiments show TileLang achieves state-of-the-art performance in key kernels, proving its effectiveness.", "conclusion": "TileLang's unified paradigm and transparent scheduling provide the power and flexibility needed for modern AI development."}}
{"id": "2504.17751", "pdf": "https://arxiv.org/pdf/2504.17751", "abs": "https://arxiv.org/abs/2504.17751", "authors": ["Enqi Zhang"], "title": "Revisiting Reset Mechanisms in Spiking Neural Networks for Sequential Modeling: Specialized Discretization for Binary Activated RNN", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "In the field of image recognition, spiking neural networks (SNNs) have\nachieved performance comparable to conventional artificial neural networks\n(ANNs). In such applications, SNNs essentially function as traditional neural\nnetworks with quantized activation values. This article focuses on an another\nalternative perspective,viewing SNNs as binary-activated recurrent neural\nnetworks (RNNs) for sequential modeling tasks.From this viewpoint, current SNN\narchitectures face several fundamental challenges in sequence modeling: (1)\nTraditional models lack effective memory mechanisms for long-range sequence\nmodeling; (2) The biological-inspired components in SNNs (such as reset\nmechanisms and refractory period applications) remain theoretically\nunder-explored for sequence tasks; (3) The RNN-like computational paradigm in\nSNNs prevents parallel training across different timesteps.To address these\nchallenges, this study conducts a systematic analysis of the fundamental\nmechanisms underlying reset operations and refractory periods in\nbinary-activated RNN-based SNN sequence models. We re-examine whether such\nbiological mechanisms are strictly necessary for generating sparse spiking\npatterns, provide new theoretical explanations and insights, and ultimately\npropose the fixed-refractory-period SNN architecture for sequence modeling.", "AI": {"tldr": "SNNs are analyzed as binary-activated RNNs for sequence tasks, addressing challenges like memory mechanisms, biological components, and parallel training. A fixed-refractory-period SNN architecture is proposed.", "motivation": "To address fundamental challenges in SNNs for sequence modeling, such as lack of memory mechanisms, under-explored biological components, and parallel training limitations.", "method": "Systematic analysis of reset operations and refractory periods in binary-activated RNN-based SNNs, proposing a fixed-refractory-period architecture.", "result": "New theoretical insights on biological mechanisms in SNNs and a proposed architecture for improved sequence modeling.", "conclusion": "The fixed-refractory-period SNN architecture offers a solution to key challenges in sequence modeling with SNNs."}}
{"id": "2504.17789", "pdf": "https://arxiv.org/pdf/2504.17789", "abs": "https://arxiv.org/abs/2504.17789", "authors": ["Xu Ma", "Peize Sun", "Haoyu Ma", "Hao Tang", "Chih-Yao Ma", "Jialiang Wang", "Kunpeng Li", "Xiaoliang Dai", "Yujun Shi", "Xuan Ju", "Yushi Hu", "Artsiom Sanakoyeu", "Felix Juefei-Xu", "Ji Hou", "Junjiao Tian", "Tao Xu", "Tingbo Hou", "Yen-Cheng Liu", "Zecheng He", "Zijian He", "Matt Feiszli", "Peizhao Zhang", "Peter Vajda", "Sam Tsai", "Yun Fu"], "title": "Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models", "categories": ["cs.CV"], "comment": "Project Page: https://ma-xu.github.io/token-shuffle/ Add related\n  works", "summary": "Autoregressive (AR) models, long dominant in language generation, are\nincreasingly applied to image synthesis but are often considered less\ncompetitive than Diffusion-based models. A primary limitation is the\nsubstantial number of image tokens required for AR models, which constrains\nboth training and inference efficiency, as well as image resolution. To address\nthis, we present Token-Shuffle, a novel yet simple method that reduces the\nnumber of image tokens in Transformer. Our key insight is the dimensional\nredundancy of visual vocabularies in Multimodal Large Language Models (MLLMs),\nwhere low-dimensional visual codes from visual encoder are directly mapped to\nhigh-dimensional language vocabularies. Leveraging this, we consider two key\noperations: token-shuffle, which merges spatially local tokens along channel\ndimension to decrease the input token number, and token-unshuffle, which\nuntangles the inferred tokens after Transformer blocks to restore the spatial\narrangement for output. Jointly training with textual prompts, our strategy\nrequires no additional pretrained text-encoder and enables MLLMs to support\nextremely high-resolution image synthesis in a unified next-token prediction\nway while maintaining efficient training and inference. For the first time, we\npush the boundary of AR text-to-image generation to a resolution of 2048x2048\nwith gratifying generation performance. In GenAI-benchmark, our 2.7B model\nachieves 0.77 overall score on hard prompts, outperforming AR models LlamaGen\nby 0.18 and diffusion models LDM by 0.15. Exhaustive large-scale human\nevaluations also demonstrate our prominent image generation ability in terms of\ntext-alignment, visual flaw, and visual appearance. We hope that Token-Shuffle\ncan serve as a foundational design for efficient high-resolution image\ngeneration within MLLMs.", "AI": {"tldr": "Token-Shuffle reduces image tokens in AR models for efficient high-resolution image synthesis, outperforming AR and diffusion models.", "motivation": "Address the inefficiency of AR models in image synthesis due to high token counts, leveraging visual redundancy in MLLMs.", "method": "Introduces token-shuffle (merging local tokens) and token-unshuffle (restoring spatial arrangement) to reduce tokens while maintaining resolution.", "result": "Achieves 2048x2048 resolution, outperforming AR and diffusion models in benchmarks and human evaluations.", "conclusion": "Token-Shuffle is a foundational method for efficient high-resolution image generation in MLLMs."}}
{"id": "2010.11750", "pdf": "https://arxiv.org/pdf/2010.11750", "abs": "https://arxiv.org/abs/2010.11750", "authors": ["Fan Yang", "Hongyang R. Zhang", "Sen Wu", "Christopher R\u00e9", "Weijie J. Su"], "title": "Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers", "categories": ["stat.ML", "cs.LG"], "comment": "70 pages, 6 figures. Final version accepted by the Journal of Machine\n  Learning Research", "summary": "The problem of learning one task with samples from another task is central to\ntransfer learning (TL). In this paper, we examine a fundamental question: When\ndoes combining the data samples from a source task and a target task perform\nbetter than single-task learning with the target task alone? This question is\nmotivated by an intriguing phenomenon known as negative transfer often observed\nin the TL literature. Precise quantification of TL effects -- even within\nsimple statistical models -- has remained elusive in the statistical learning\nliterature. A critical challenge is that to compare TL to single-task learning,\nwe would need to compare the risks between two different estimators in a very\nprecise way. In particular, the comparative advantage of one estimator over\nanother would depend on the specific distribution shifts between the two tasks.\nThis paper applies recent developments in the random matrix theory literature\nto tackle this challenge in a high-dimensional linear regression setting with\ntwo tasks. We provide precise high-dimensional asymptotics for the bias and\nvariance of hard parameter sharing (HPS) estimators in the proportional limit,\nwhen the sample sizes of both tasks increase proportionally with dimension at\nfixed ratios. The precise asymptotics are expressed as a function of the sample\nsizes of both tasks, the covariate shift between their feature population\ncovariate matrices, and the model shift. We provide illustrative examples of\nour results in a random-effects model to determine positive and negative\ntransfers. For example, we can identify a phase transition in the\nhigh-dimensional linear regression setting from positive transfer to negative\ntransfer under a model shift between the source and target tasks. The finding\nregarding phase transition can be extended to a multiple-task learning setting\nwhere the feature covariates are shared across all tasks.", "AI": {"tldr": "The paper investigates when combining data from source and target tasks in transfer learning outperforms single-task learning, addressing negative transfer. It uses high-dimensional linear regression to quantify transfer effects, identifying phase transitions between positive and negative transfer.", "motivation": "The study is motivated by the phenomenon of negative transfer in transfer learning and the lack of precise quantification of transfer effects in statistical learning literature.", "method": "The paper applies random matrix theory to analyze high-dimensional linear regression with two tasks, providing precise asymptotics for bias and variance of hard parameter sharing estimators.", "result": "The results identify phase transitions between positive and negative transfer based on sample sizes, covariate shift, and model shift, extending findings to multiple-task learning.", "conclusion": "The study offers a framework to quantify transfer learning effects and understand conditions for positive or negative transfer, with implications for multiple-task learning."}}
{"id": "2504.17771", "pdf": "https://arxiv.org/pdf/2504.17771", "abs": "https://arxiv.org/abs/2504.17771", "authors": ["Haochen Wang", "Zhiwei Shi", "Chengxi Zhu", "Yafei Qiao", "Cheng Zhang", "Fan Yang", "Pengjie Ren", "Lan Lu", "Dong Xuan"], "title": "Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted to ICRA 2025. Project page:\n  https://dreamstarring.github.io/HAMLET/", "summary": "Learning-based methods, such as imitation learning (IL) and reinforcement\nlearning (RL), can produce excel control policies over challenging agile robot\ntasks, such as sports robot. However, no existing work has harmonized\nlearning-based policy with model-based methods to reduce training complexity\nand ensure the safety and stability for agile badminton robot control. In this\npaper, we introduce Hamlet, a novel hybrid control system for agile badminton\nrobots. Specifically, we propose a model-based strategy for chassis locomotion\nwhich provides a base for arm policy. We introduce a physics-informed \"IL+RL\"\ntraining framework for learning-based arm policy. In this train framework, a\nmodel-based strategy with privileged information is used to guide arm policy\ntraining during both IL and RL phases. In addition, we train the critic model\nduring IL phase to alleviate the performance drop issue when transitioning from\nIL to RL. We present results on our self-engineered badminton robot, achieving\n94.5% success rate against the serving machine and 90.7% success rate against\nhuman players. Our system can be easily generalized to other agile mobile\nmanipulation tasks such as agile catching and table tennis. Our project\nwebsite: https://dreamstarring.github.io/HAMLET/.", "AI": {"tldr": "Hamlet is a hybrid control system combining model-based and learning-based methods for agile badminton robots, achieving high success rates.", "motivation": "To harmonize learning-based policies with model-based methods for safer, more stable, and less complex training in agile robot tasks.", "method": "Uses a model-based strategy for chassis locomotion and a physics-informed 'IL+RL' framework for arm policy, with privileged information guiding training.", "result": "Achieved 94.5% success against serving machines and 90.7% against humans, with potential for generalization to other tasks.", "conclusion": "Hamlet effectively integrates model-based and learning-based approaches, demonstrating high performance and generalizability."}}
{"id": "2504.18468", "pdf": "https://arxiv.org/pdf/2504.18468", "abs": "https://arxiv.org/abs/2504.18468", "authors": ["Georgios Kouros", "Minye Wu", "Tinne Tuytelaars"], "title": "RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny Objects", "categories": ["cs.CV"], "comment": null, "summary": "We introduce RGS-DR, a novel inverse rendering method for reconstructing and\nrendering glossy and reflective objects with support for flexible relighting\nand scene editing. Unlike existing methods (e.g., NeRF and 3D Gaussian\nSplatting), which struggle with view-dependent effects, RGS-DR utilizes a 2D\nGaussian surfel representation to accurately estimate geometry and surface\nnormals, an essential property for high-quality inverse rendering. Our approach\nexplicitly models geometric and material properties through learnable\nprimitives rasterized into a deferred shading pipeline, effectively reducing\nrendering artifacts and preserving sharp reflections. By employing a\nmulti-level cube mipmap, RGS-DR accurately approximates environment lighting\nintegrals, facilitating high-quality reconstruction and relighting. A residual\npass with spherical-mipmap-based directional encoding further refines the\nappearance modeling. Experiments demonstrate that RGS-DR achieves high-quality\nreconstruction and rendering quality for shiny objects, often outperforming\nreconstruction-exclusive state-of-the-art methods incapable of relighting.", "AI": {"tldr": "RGS-DR is a novel inverse rendering method for glossy/reflective objects, excelling in relighting and scene editing by using 2D Gaussian surfels and deferred shading.", "motivation": "Existing methods (e.g., NeRF, 3D Gaussian Splatting) struggle with view-dependent effects, limiting accurate reconstruction and relighting of glossy objects.", "method": "Uses 2D Gaussian surfels for geometry/normal estimation, learnable primitives in deferred shading, multi-level cube mipmap for lighting, and a residual pass for appearance refinement.", "result": "Achieves high-quality reconstruction and rendering for shiny objects, outperforming state-of-the-art methods in relighting tasks.", "conclusion": "RGS-DR effectively addresses limitations of current methods, enabling superior glossy object reconstruction and flexible relighting."}}
{"id": "2310.16945", "pdf": "https://arxiv.org/pdf/2310.16945", "abs": "https://arxiv.org/abs/2310.16945", "authors": ["Hui Lan", "Vasilis Syrgkanis"], "title": "Causal Q-Aggregation for CATE Model Selection", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST", "stat.TH", "62F07(Primary), 62D20(Secondary)"], "comment": "The main text is 9 pages, and we include the Appendix at the end\n  (totaling 51 pages)", "summary": "Accurate estimation of conditional average treatment effects (CATE) is at the\ncore of personalized decision making. While there is a plethora of models for\nCATE estimation, model selection is a nontrivial task, due to the fundamental\nproblem of causal inference. Recent empirical work provides evidence in favor\nof proxy loss metrics with double robust properties and in favor of model\nensembling. However, theoretical understanding is lacking. Direct application\nof prior theoretical work leads to suboptimal oracle model selection rates due\nto the non-convexity of the model selection problem. We provide regret rates\nfor the major existing CATE ensembling approaches and propose a new CATE model\nensembling approach based on Q-aggregation using the doubly robust loss. Our\nmain result shows that causal Q-aggregation achieves statistically optimal\noracle model selection regret rates of $\\frac{\\log(M)}{n}$ (with $M$ models and\n$n$ samples), with the addition of higher-order estimation error terms related\nto products of errors in the nuisance functions. Crucially, our regret rate\ndoes not require that any of the candidate CATE models be close to the truth.\nWe validate our new method on many semi-synthetic datasets and also provide\nextensions of our work to CATE model selection with instrumental variables and\nunobserved confounding.", "AI": {"tldr": "The paper proposes a new CATE model ensembling method using Q-aggregation with doubly robust loss, achieving optimal regret rates for model selection without requiring candidate models to be close to the truth.", "motivation": "Accurate CATE estimation is crucial for personalized decision-making, but model selection is challenging due to causal inference complexities. Existing methods lack theoretical grounding.", "method": "Introduces a CATE ensembling approach based on Q-aggregation using doubly robust loss, analyzing regret rates for existing methods and proposing a new one.", "result": "Achieves optimal oracle model selection regret rates of log(M)/n, with additional higher-order error terms, validated on semi-synthetic datasets.", "conclusion": "The proposed method is theoretically sound and practically effective, with extensions for instrumental variables and unobserved confounding."}}
{"id": "2504.17827", "pdf": "https://arxiv.org/pdf/2504.17827", "abs": "https://arxiv.org/abs/2504.17827", "authors": ["Bingye Zhou", "Caiyang Yu"], "title": "Evolution Meets Diffusion: Efficient Neural Architecture Generation", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "Neural Architecture Search (NAS) has gained widespread attention for its\ntransformative potential in deep learning model design. However, the vast and\ncomplex search space of NAS leads to significant computational and time costs.\nNeural Architecture Generation (NAG) addresses this by reframing NAS as a\ngeneration problem, enabling the precise generation of optimal architectures\nfor specific tasks. Despite its promise, mainstream methods like diffusion\nmodels face limitations in global search capabilities and are still hindered by\nhigh computational and time demands. To overcome these challenges, we propose\nEvolutionary Diffusion-based Neural Architecture Generation (EDNAG), a novel\napproach that achieves efficient and training-free architecture generation.\nEDNAG leverages evolutionary algorithms to simulate the denoising process in\ndiffusion models, using fitness to guide the transition from random Gaussian\ndistributions to optimal architecture distributions. This approach combines the\nstrengths of evolutionary strategies and diffusion models, enabling rapid and\neffective architecture generation. Extensive experiments demonstrate that EDNAG\nachieves state-of-the-art (SOTA) performance in architecture optimization, with\nan improvement in accuracy of up to 10.45%. Furthermore, it eliminates the need\nfor time-consuming training and boosts inference speed by an average of 50\ntimes, showcasing its exceptional efficiency and effectiveness.", "AI": {"tldr": "EDNAG combines evolutionary algorithms with diffusion models for efficient, training-free neural architecture generation, improving accuracy by 10.45% and speeding up inference by 50x.", "motivation": "Neural Architecture Search (NAS) is computationally expensive, and existing methods like diffusion models lack global search capabilities and efficiency.", "method": "Proposes Evolutionary Diffusion-based Neural Architecture Generation (EDNAG), using evolutionary algorithms to guide diffusion models for architecture generation.", "result": "Achieves SOTA performance with 10.45% accuracy improvement and 50x faster inference, eliminating training needs.", "conclusion": "EDNAG offers a highly efficient and effective solution for neural architecture generation, outperforming existing methods."}}
{"id": "2404.08535", "pdf": "https://arxiv.org/pdf/2404.08535", "abs": "https://arxiv.org/abs/2404.08535", "authors": ["Tianyu Zhu", "Myong Chol Jung", "Jesse Clark"], "title": "Generalized Contrastive Learning for Multi-Modal Retrieval and Ranking", "categories": ["cs.IR", "cs.CV", "cs.LG"], "comment": null, "summary": "Contrastive learning has gained widespread adoption for retrieval tasks due\nto its minimal requirement for manual annotations. However, popular training\nframeworks typically learn from binary (positive/negative) relevance, making\nthem ineffective at incorporating desired rankings. As a result, the poor\nranking performance of these models forces systems to employ a re-ranker, which\nincreases complexity, maintenance effort and inference time. To address this,\nwe introduce Generalized Contrastive Learning (GCL), a training framework\ndesigned to learn from continuous ranking scores beyond binary relevance. GCL\nencodes both relevance and ranking information into a unified embedding space\nby applying ranking scores to the loss function. This enables a single-stage\nretrieval system. In addition, during our research, we identified a lack of\npublic multi-modal datasets that benchmark both retrieval and ranking\ncapabilities. To facilitate this and future research for ranked retrieval, we\ncurated a large-scale MarqoGS-10M dataset using GPT-4 and Google Shopping,\nproviding ranking scores for each of the 10 million query-document pairs. Our\nresults show that GCL achieves a 29.3% increase in NDCG@10 for in-domain\nevaluations and 6.0% to 10.0% increases for cold-start evaluations compared to\nthe finetuned CLIP baseline with MarqoGS-10M. Additionally, we evaluated GCL\noffline on a proprietary user interaction data. GCL shows an 11.2% gain for\nin-domain evaluations. The dataset and the method are available at:\nhttps://github.com/marqo-ai/GCL.", "AI": {"tldr": "Generalized Contrastive Learning (GCL) improves retrieval tasks by learning from continuous ranking scores, eliminating the need for re-rankers, and achieves significant performance gains.", "motivation": "Current contrastive learning frameworks rely on binary relevance, limiting ranking performance and necessitating complex re-ranking systems.", "method": "GCL integrates ranking scores into the loss function, unifying relevance and ranking in a single embedding space. A new dataset, MarqoGS-10M, is introduced for benchmarking.", "result": "GCL improves NDCG@10 by 29.3% in-domain and 6.0%-10.0% in cold-start evaluations, with an 11.2% gain on proprietary data.", "conclusion": "GCL offers a simpler, more effective single-stage retrieval solution and provides a benchmark dataset for future research."}}
{"id": "2401.12207", "pdf": "https://arxiv.org/pdf/2401.12207", "abs": "https://arxiv.org/abs/2401.12207", "authors": ["Sadaf Salehkalaibar", "Jun Chen", "Ashish Khisti", "Wei Yu"], "title": "Rate-Distortion-Perception Tradeoff Based on the Conditional-Distribution Perception Measure", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "This paper studies the rate-distortion-perception (RDP) tradeoff for a\nmemoryless source model in the asymptotic limit of large block-lengths. The\nperception measure is based on a divergence between the distributions of the\nsource and reconstruction sequences \\emph{conditioned} on the encoder output,\nfirst proposed by Mentzer et al. We consider the case when there is no shared\nrandomness between the encoder and the decoder and derive a single-letter\ncharacterization of the RDP function for the case of discrete memoryless\nsources. This is in contrast to the marginal-distribution metric case\n(introduced by Blau and Michaeli), whose RDP characterization remains open when\nthere is no shared randomness. The achievability scheme is based on lossy\nsource coding with a posterior reference map. For the case of continuous valued\nsources under the squared error distortion measure and the squared quadratic\nWasserstein perception measure, we also derive a single-letter characterization\nand show that the decoder can be restricted to a noise-adding mechanism.\nInterestingly, the RDP function characterized for the case of zero perception\nloss coincides with that of the marginal metric, and further zero perception\nloss can be achieved with a 3-dB penalty in minimum distortion. Finally we\nspecialize to the case of Gaussian sources, and derive the RDP function for\nGaussian vector case and propose a reverse water-filling type solution. We also\npartially characterize the RDP function for a mixture of Gaussian vector\nsources.", "AI": {"tldr": "The paper analyzes the rate-distortion-perception (RDP) tradeoff for memoryless sources, deriving single-letter characterizations for discrete and continuous cases, and explores Gaussian sources.", "motivation": "To understand the RDP tradeoff for memoryless sources without shared randomness, contrasting with prior work on marginal-distribution metrics.", "method": "Uses lossy source coding with a posterior reference map for achievability, and derives single-letter characterizations for discrete and continuous sources.", "result": "Shows zero perception loss coincides with marginal metric results, with a 3-dB distortion penalty. Also provides solutions for Gaussian sources.", "conclusion": "The work advances understanding of RDP tradeoffs, particularly for Gaussian sources, and highlights key differences from prior metrics."}}
{"id": "2501.14208", "pdf": "https://arxiv.org/pdf/2501.14208", "abs": "https://arxiv.org/abs/2501.14208", "authors": ["Huayi Zhou", "Ruixiang Wang", "Yunxin Tai", "Yueci Deng", "Guiliang Liu", "Kui Jia"], "title": "You Only Teach Once: Learn One-Shot Bimanual Robotic Manipulation from Video Demonstrations", "categories": ["cs.RO", "cs.CV"], "comment": "accepted by RSS 2025", "summary": "Bimanual robotic manipulation is a long-standing challenge of embodied\nintelligence due to its characteristics of dual-arm spatial-temporal\ncoordination and high-dimensional action spaces. Previous studies rely on\npre-defined action taxonomies or direct teleoperation to alleviate or\ncircumvent these issues, often making them lack simplicity, versatility and\nscalability. Differently, we believe that the most effective and efficient way\nfor teaching bimanual manipulation is learning from human demonstrated videos,\nwhere rich features such as spatial-temporal positions, dynamic postures,\ninteraction states and dexterous transitions are available almost for free. In\nthis work, we propose the YOTO (You Only Teach Once), which can extract and\nthen inject patterns of bimanual actions from as few as a single binocular\nobservation of hand movements, and teach dual robot arms various complex tasks.\nFurthermore, based on keyframes-based motion trajectories, we devise a subtle\nsolution for rapidly generating training demonstrations with diverse variations\nof manipulated objects and their locations. These data can then be used to\nlearn a customized bimanual diffusion policy (BiDP) across diverse scenes. In\nexperiments, YOTO achieves impressive performance in mimicking 5 intricate\nlong-horizon bimanual tasks, possesses strong generalization under different\nvisual and spatial conditions, and outperforms existing visuomotor imitation\nlearning methods in accuracy and efficiency. Our project link is\nhttps://hnuzhy.github.io/projects/YOTO.", "AI": {"tldr": "YOTO learns bimanual robotic manipulation from human videos, using a single binocular observation to teach complex tasks, outperforming existing methods.", "motivation": "Bimanual manipulation is complex due to dual-arm coordination and high-dimensional actions. Existing methods lack simplicity and scalability.", "method": "YOTO extracts patterns from human videos, generates diverse training data, and learns a bimanual diffusion policy (BiDP).", "result": "YOTO excels in mimicking complex tasks, generalizes well under varied conditions, and surpasses other methods in accuracy and efficiency.", "conclusion": "YOTO offers a scalable, efficient solution for bimanual robotic manipulation by leveraging human demonstrations."}}
{"id": "2402.08674", "pdf": "https://arxiv.org/pdf/2402.08674", "abs": "https://arxiv.org/abs/2402.08674", "authors": ["Jacob Russin", "Ellie Pavlick", "Michael J. Frank"], "title": "The dynamic interplay between in-context and in-weight learning in humans and neural networks", "categories": ["cs.NE", "cs.LG", "q-bio.NC"], "comment": "15 pages (excluding appendix and references), 10 pages of appendix,\n  14 figures, 7 tables. Previous version accepted as a talk + full paper at\n  CogSci 2024", "summary": "Human learning embodies a striking duality: sometimes, we appear capable of\nfollowing logical, compositional rules and benefit from structured curricula\n(e.g., in formal education), while other times, we rely on an incremental\napproach or trial-and-error, learning better from curricula that are randomly\ninterleaved. Influential psychological theories explain this seemingly\ndisparate behavioral evidence by positing two qualitatively different learning\nsystems -- one for rapid, rule-based inferences and another for slow,\nincremental adaptation. It remains unclear how to reconcile such theories with\nneural networks, which learn via incremental weight updates and are thus a\nnatural model for the latter type of learning, but are not obviously compatible\nwith the former. However, recent evidence suggests that metalearning neural\nnetworks and large language models are capable of \"in-context learning\" (ICL)\n-- the ability to flexibly grasp the structure of a new task from a few\nexamples. Here, we show that the dynamic interplay between ICL and default\nin-weight learning (IWL) naturally captures a broad range of learning phenomena\nobserved in humans, reproducing curriculum effects on category-learning and\ncompositional tasks, and recapitulating a tradeoff between flexibility and\nretention. Our work shows how emergent ICL can equip neural networks with\nfundamentally different learning properties that can coexist with their native\nIWL, thus offering a novel perspective on dual-process theories and human\ncognitive flexibility.", "AI": {"tldr": "The paper explores how neural networks, through in-context learning (ICL) and in-weight learning (IWL), can model human dual-learning systems, capturing flexibility and retention tradeoffs.", "motivation": "To reconcile neural networks with human dual-learning theories, explaining how ICL and IWL coexist to mimic human cognitive flexibility.", "method": "Analyzed metalearning neural networks and large language models, focusing on ICL and IWL dynamics to simulate human learning phenomena.", "result": "Demonstrated that ICL and IWL interplay reproduces human curriculum effects and compositional task learning, highlighting a flexibility-retention tradeoff.", "conclusion": "ICL equips neural networks with dual-learning properties, offering insights into human cognitive flexibility and dual-process theories."}}
{"id": "2501.19259", "pdf": "https://arxiv.org/pdf/2501.19259", "abs": "https://arxiv.org/abs/2501.19259", "authors": ["Amogh Joshi", "Sourav Sanyal", "Kaushik Roy"], "title": "Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for Autonomous Drone FlighT at the Edge", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.NE", "cs.SY", "eess.SY"], "comment": "Accepted for publication at the International Joint Conference on\n  Neural Networks (IJCNN) 2025", "summary": "The integration of human-intuitive interactions into autonomous systems has\nbeen limited. Traditional Natural Language Processing (NLP) systems struggle\nwith context and intent understanding, severely restricting human-robot\ninteraction. Recent advancements in Large Language Models (LLMs) have\ntransformed this dynamic, allowing for intuitive and high-level communication\nthrough speech and text, and bridging the gap between human commands and\nrobotic actions. Additionally, autonomous navigation has emerged as a central\nfocus in robotics research, with artificial intelligence (AI) increasingly\nbeing leveraged to enhance these systems. However, existing AI-based navigation\nalgorithms face significant challenges in latency-critical tasks where rapid\ndecision-making is critical. Traditional frame-based vision systems, while\neffective for high-level decision-making, suffer from high energy consumption\nand latency, limiting their applicability in real-time scenarios. Neuromorphic\nvision systems, combining event-based cameras and spiking neural networks\n(SNNs), offer a promising alternative by enabling energy-efficient, low-latency\nnavigation. Despite their potential, real-world implementations of these\nsystems, particularly on physical platforms such as drones, remain scarce. In\nthis work, we present Neuro-LIFT, a real-time neuromorphic navigation framework\nimplemented on a Parrot Bebop2 quadrotor. Leveraging an LLM for natural\nlanguage processing, Neuro-LIFT translates human speech into high-level\nplanning commands which are then autonomously executed using event-based\nneuromorphic vision and physics-driven planning. Our framework demonstrates its\ncapabilities in navigating in a dynamic environment, avoiding obstacles, and\nadapting to human instructions in real-time.", "AI": {"tldr": "Neuro-LIFT integrates LLMs and neuromorphic vision for real-time, intuitive human-robot interaction and navigation on drones.", "motivation": "Traditional NLP and navigation systems lack context understanding and real-time efficiency, limiting human-robot interaction and dynamic navigation.", "method": "Combines LLMs for natural language processing with event-based neuromorphic vision and physics-driven planning on a drone.", "result": "Demonstrates real-time navigation, obstacle avoidance, and adaptation to human instructions in dynamic environments.", "conclusion": "Neuro-LIFT bridges the gap between human commands and robotic actions, offering efficient, low-latency navigation."}}
{"id": "2404.15366", "pdf": "https://arxiv.org/pdf/2404.15366", "abs": "https://arxiv.org/abs/2404.15366", "authors": ["Xiao-Yin Liu", "Guotao Li", "Xiao-Hu Zhou", "Xu Liang", "Zeng-Guang Hou"], "title": "A Weight-aware-based Multi-source Unsupervised Domain Adaptation Method for Human Motion Intention Recognition", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted by IEEE Transactions on Cybernetics", "summary": "Accurate recognition of human motion intention (HMI) is beneficial for\nexoskeleton robots to improve the wearing comfort level and achieve natural\nhuman-robot interaction. A classifier trained on labeled source subjects\n(domains) performs poorly on unlabeled target subject since the difference in\nindividual motor characteristics. The unsupervised domain adaptation (UDA)\nmethod has become an effective way to this problem. However, the labeled data\nare collected from multiple source subjects that might be different not only\nfrom the target subject but also from each other. The current UDA methods for\nHMI recognition ignore the difference between each source subject, which\nreduces the classification accuracy. Therefore, this paper considers the\ndifferences between source subjects and develops a novel theory and algorithm\nfor UDA to recognize HMI, where the margin disparity discrepancy (MDD) is\nextended to multi-source UDA theory and a novel weight-aware-based multi-source\nUDA algorithm (WMDD) is proposed. The source domain weight, which can be\nadjusted adaptively by the MDD between each source subject and target subject,\nis incorporated into UDA to measure the differences between source subjects.\nThe developed multi-source UDA theory is theoretical and the generalization\nerror on target subject is guaranteed. The theory can be transformed into an\noptimization problem for UDA, successfully bridging the gap between theory and\nalgorithm. Moreover, a lightweight network is employed to guarantee the\nreal-time of classification and the adversarial learning between feature\ngenerator and ensemble classifiers is utilized to further improve the\ngeneralization ability. The extensive experiments verify theoretical analysis\nand show that WMDD outperforms previous UDA methods on HMI recognition tasks.", "AI": {"tldr": "The paper proposes a novel weight-aware multi-source unsupervised domain adaptation (WMDD) method for human motion intention recognition, addressing differences between source subjects to improve accuracy.", "motivation": "Current UDA methods for HMI recognition ignore differences between source subjects, reducing classification accuracy.", "method": "Extends margin disparity discrepancy (MDD) to multi-source UDA theory, introduces WMDD algorithm with adaptive source domain weights, and uses adversarial learning for generalization.", "result": "WMDD outperforms previous UDA methods in HMI recognition, verified by extensive experiments.", "conclusion": "The proposed WMDD method effectively addresses multi-source domain differences, improving HMI recognition accuracy with theoretical guarantees."}}
{"id": "2502.04640", "pdf": "https://arxiv.org/pdf/2502.04640", "abs": "https://arxiv.org/abs/2502.04640", "authors": ["Haoyu Han", "Heng Yang"], "title": "Building Rome with Convex Optimization", "categories": ["cs.RO", "cs.CV", "math.OC"], "comment": null, "summary": "Global bundle adjustment is made easy by depth prediction and convex\noptimization. We (i) propose a scaled bundle adjustment (SBA) formulation that\nlifts 2D keypoint measurements to 3D with learned depth, (ii) design an\nempirically tight convex semidfinite program (SDP) relaxation that solves SBA\nto certfiable global optimality, (iii) solve the SDP relaxations at extreme\nscale with Burer-Monteiro factorization and a CUDA-based trust-region\nRiemannian optimizer (dubbed XM), (iv) build a structure from motion (SfM)\npipeline with XM as the optimization engine and show that XM-SfM compares\nfavorably with existing pipelines in terms of reconstruction quality while\nbeing significantly faster, more scalable, and initialization-free.", "AI": {"tldr": "The paper simplifies global bundle adjustment using depth prediction and convex optimization, proposing a scaled bundle adjustment (SBA) method with learned depth, a tight convex SDP relaxation, and a fast CUDA-based solver (XM). The XM-SfM pipeline outperforms existing methods in speed, scalability, and quality.", "motivation": "To address the challenges of global bundle adjustment, such as initialization dependency and scalability, by leveraging depth prediction and convex optimization.", "method": "Proposes SBA with learned depth, a tight convex SDP relaxation, and solves it using Burer-Monteiro factorization and a CUDA-based optimizer (XM).", "result": "XM-SfM achieves better reconstruction quality, is faster, more scalable, and initialization-free compared to existing pipelines.", "conclusion": "The proposed method effectively simplifies and improves global bundle adjustment, offering a robust and efficient solution for structure from motion."}}
{"id": "2405.05999", "pdf": "https://arxiv.org/pdf/2405.05999", "abs": "https://arxiv.org/abs/2405.05999", "authors": ["Christoforos Vasilatos", "Dunia J. Mahboobeh", "Hithem Lamri", "Manaar Alam", "Michail Maniatakos"], "title": "LLMPot: Dynamically Configured LLM-based Honeypot for Industrial Protocol and Physical Process Emulation", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Industrial Control Systems (ICS) are extensively used in critical\ninfrastructures ensuring efficient, reliable, and continuous operations.\nHowever, their increasing connectivity and addition of advanced features make\nthem vulnerable to cyber threats, potentially leading to severe disruptions in\nessential services. In this context, honeypots play a vital role by acting as\ndecoy targets within ICS networks, or on the Internet, helping to detect, log,\nanalyze, and develop mitigations for ICS-specific cyber threats. Deploying ICS\nhoneypots, however, is challenging due to the necessity of accurately\nreplicating industrial protocols and device characteristics, a crucial\nrequirement for effectively mimicking the unique operational behavior of\ndifferent industrial systems. Moreover, this challenge is compounded by the\nsignificant manual effort required in also mimicking the control logic the PLC\nwould execute, in order to capture attacker traffic aiming to disrupt critical\ninfrastructure operations. In this paper, we propose LLMPot, a novel approach\nfor designing honeypots in ICS networks harnessing the potency of Large\nLanguage Models (LLMs). LLMPot aims to automate and optimize the creation of\nrealistic honeypots with vendor-agnostic configurations, and for any control\nlogic, aiming to eliminate the manual effort and specialized knowledge\ntraditionally required in this domain. We conducted extensive experiments\nfocusing on a wide array of parameters, demonstrating that our LLM-based\napproach can effectively create honeypot devices implementing different\nindustrial protocols and diverse control logic.", "AI": {"tldr": "LLMPot is a novel ICS honeypot approach using Large Language Models to automate realistic honeypot creation, reducing manual effort and specialized knowledge requirements.", "motivation": "ICS vulnerabilities due to connectivity and advanced features necessitate effective honeypots, but current methods require significant manual effort and expertise.", "method": "LLMPot leverages LLMs to automate honeypot design, replicating industrial protocols and control logic without manual intervention.", "result": "Experiments show LLMPot effectively creates honeypots for various industrial protocols and control logic.", "conclusion": "LLMPot offers a scalable, vendor-agnostic solution for ICS honeypot deployment, addressing current challenges."}}
{"id": "2503.13469", "pdf": "https://arxiv.org/pdf/2503.13469", "abs": "https://arxiv.org/abs/2503.13469", "authors": ["Ivan Sviridov", "Konstantin Egorov"], "title": "Conditional Electrocardiogram Generation Using Hierarchical Variational Autoencoders", "categories": ["eess.SP", "cs.CV", "cs.LG"], "comment": "10 pages, 6 figures, 7 tables", "summary": "Cardiovascular diseases (CVDs) are disorders impacting the heart and\ncirculatory system. These disorders are the foremost and continuously\nescalating cause of mortality worldwide. One of the main tasks when working\nwith CVDs is analyzing and identifying pathologies on a 12-lead\nelectrocardiogram (ECG) with a standard 10-second duration. Using machine\nlearning (ML) in automatic ECG analysis increases CVD diagnostics'\navailability, speed, and accuracy. However, the most significant difficulty in\ndeveloping ML models is obtaining a sufficient training dataset. Due to the\nlimitations of medical data usage, such as expensiveness, errors, the ambiguity\nof labels, imbalance of classes, and privacy issues, utilizing synthetic\nsamples depending on specific pathologies bypasses these restrictions and\nimproves algorithm quality. Existing solutions for the conditional generation\nof ECG signals are mainly built on Generative Adversarial Networks (GANs), and\nonly a few papers consider the architectures based on Variational Autoencoders\n(VAEs), showing comparable results in recent works. This paper proposes the\npublicly available conditional Nouveau VAE model for ECG signal generation\n(cNVAE-ECG), which produces high-resolution ECGs with multiple pathologies. We\nprovide an extensive comparison of the proposed model on various practical\ndownstream tasks, including transfer learning scenarios showing an area under\nthe receiver operating characteristic (AUROC) increase up to 2% surpassing\nGAN-like competitors.", "AI": {"tldr": "The paper proposes a conditional Nouveau VAE model (cNVAE-ECG) for generating high-resolution ECG signals with multiple pathologies, outperforming GAN-based models by up to 2% in AUROC for downstream tasks.", "motivation": "Cardiovascular diseases (CVDs) are a leading cause of mortality, and automated ECG analysis using ML is limited by data scarcity and privacy issues. Synthetic ECG generation can address these challenges.", "method": "The paper introduces the cNVAE-ECG model, a conditional Variational Autoencoder (VAE), for generating synthetic ECG signals with specific pathologies, comparing it to GAN-based approaches.", "result": "The cNVAE-ECG model achieves up to a 2% higher AUROC in downstream tasks like transfer learning compared to GAN-based models.", "conclusion": "The proposed cNVAE-ECG model is a viable alternative to GANs for synthetic ECG generation, offering improved performance in practical applications."}}
{"id": "2405.09005", "pdf": "https://arxiv.org/pdf/2405.09005", "abs": "https://arxiv.org/abs/2405.09005", "authors": ["Javier Lopez-Piqueres", "Jing Chen"], "title": "Cons-training Tensor Networks: Embedding and Optimization Over Discrete Linear Constraints", "categories": ["math.NA", "cs.LG", "cs.NA", "quant-ph"], "comment": null, "summary": "In this study, we introduce a novel family of tensor networks, termed\nconstrained matrix product states (MPS), designed to incorporate exactly\narbitrary discrete linear constraints, including inequalities, into sparse\nblock structures. These tensor networks are particularly tailored for modeling\ndistributions with support strictly over the feasible space, offering benefits\nsuch as reducing the search space in optimization problems, alleviating\noverfitting, improving training efficiency, and decreasing model size. Central\nto our approach is the concept of a quantum region, an extension of quantum\nnumbers traditionally used in U(1) symmetric tensor networks, adapted to\ncapture any linear constraint, including the unconstrained scenario. We further\ndevelop a novel canonical form for these new MPS, which allow for the merging\nand factorization of tensor blocks according to quantum region fusion rules and\npermit optimal truncation schemes. Utilizing this canonical form, we apply an\nunsupervised training strategy to optimize arbitrary objective functions\nsubject to discrete linear constraints. Our method's efficacy is demonstrated\nby solving the quadratic knapsack problem, achieving superior performance\ncompared to a leading nonlinear integer programming solver. Additionally, we\nanalyze the complexity and scalability of our approach, demonstrating its\npotential in addressing complex constrained combinatorial optimization\nproblems.", "AI": {"tldr": "A novel tensor network family, constrained MPS, incorporates discrete linear constraints into sparse block structures, improving optimization and training efficiency.", "motivation": "To model distributions strictly over feasible spaces, reducing search space, overfitting, and model size while enhancing training efficiency.", "method": "Introduces quantum regions for linear constraints, develops a canonical form for MPS, and applies unsupervised training to optimize constrained objectives.", "result": "Superior performance in solving the quadratic knapsack problem compared to leading solvers, with demonstrated scalability.", "conclusion": "The approach shows promise for complex constrained combinatorial optimization problems."}}
{"id": "2504.12909", "pdf": "https://arxiv.org/pdf/2504.12909", "abs": "https://arxiv.org/abs/2504.12909", "authors": ["Youyi Zhan", "Tianjia Shao", "Yin Yang", "Kun Zhou"], "title": "Real-time High-fidelity Gaussian Human Avatars with Position-based Interpolation of Spatially Distributed MLPs", "categories": ["cs.GR", "cs.CV"], "comment": "CVPR 2025. Project page https://gapszju.github.io/mmlphuman/ . Code\n  https://github.com/1231234zhan/mmlphuman", "summary": "Many works have succeeded in reconstructing Gaussian human avatars from\nmulti-view videos. However, they either struggle to capture pose-dependent\nappearance details with a single MLP, or rely on a computationally intensive\nneural network to reconstruct high-fidelity appearance but with rendering\nperformance degraded to non-real-time. We propose a novel Gaussian human avatar\nrepresentation that can reconstruct high-fidelity pose-dependence appearance\nwith details and meanwhile can be rendered in real time. Our Gaussian avatar is\nempowered by spatially distributed MLPs which are explicitly located on\ndifferent positions on human body. The parameters stored in each Gaussian are\nobtained by interpolating from the outputs of its nearby MLPs based on their\ndistances. To avoid undesired smooth Gaussian property changing during\ninterpolation, for each Gaussian we define a set of Gaussian offset basis, and\na linear combination of basis represents the Gaussian property offsets relative\nto the neutral properties. Then we propose to let the MLPs output a set of\ncoefficients corresponding to the basis. In this way, although Gaussian\ncoefficients are derived from interpolation and change smoothly, the Gaussian\noffset basis is learned freely without constraints. The smoothly varying\ncoefficients combined with freely learned basis can still produce distinctly\ndifferent Gaussian property offsets, allowing the ability to learn\nhigh-frequency spatial signals. We further use control points to constrain the\nGaussians distributed on a surface layer rather than allowing them to be\nirregularly distributed inside the body, to help the human avatar generalize\nbetter when animated under novel poses. Compared to the state-of-the-art\nmethod, our method achieves better appearance quality with finer details while\nthe rendering speed is significantly faster under novel views and novel poses.", "AI": {"tldr": "A novel Gaussian human avatar representation using spatially distributed MLPs for high-fidelity, real-time rendering with pose-dependent details.", "motivation": "Existing methods either lack detail in pose-dependent appearance or are computationally intensive, degrading rendering performance.", "method": "Uses spatially distributed MLPs on the human body, interpolating parameters from nearby MLPs, and employs Gaussian offset basis for distinct property offsets. Control points ensure surface-layer Gaussian distribution.", "result": "Achieves better appearance quality with finer details and significantly faster rendering speed under novel views and poses.", "conclusion": "The proposed method outperforms state-of-the-art in both appearance quality and real-time rendering efficiency."}}
{"id": "2405.11785", "pdf": "https://arxiv.org/pdf/2405.11785", "abs": "https://arxiv.org/abs/2405.11785", "authors": ["Amit Kadan", "Kevin Ryczko", "Erika Lloyd", "Adrian Roitberg", "Takeshi Yamazaki"], "title": "Guided Multi-objective Generative AI to Enhance Structure-based Drug Design", "categories": ["physics.chem-ph", "cs.LG", "q-bio.BM"], "comment": null, "summary": "Generative AI has the potential to revolutionize drug discovery. Yet, despite\nrecent advances in deep learning, existing models cannot generate molecules\nthat satisfy all desired physicochemical properties. Herein, we describe\nIDOLpro, a generative chemistry AI combining diffusion with multi-objective\noptimization for structure-based drug design. Differentiable scoring functions\nguide the latent variables of the diffusion model to explore uncharted chemical\nspace and generate novel ligands in silico, optimizing a plurality of target\nphysicochemical properties. We demonstrate our platform's effectiveness by\ngenerating ligands with optimized binding affinity and synthetic accessibility\non two benchmark sets. IDOLpro produces ligands with binding affinities over\n10%-20% better than the next best state-of-the-art method on each test set,\nproducing more drug-like molecules with generally better synthetic\naccessibility scores than other methods. We do a head-to-head comparison of\nIDOLpro against a classic virtual screen of a large database of drug-like\nmolecules. We show that IDOLpro can generate molecules for a range of important\ndisease-related targets with better binding affinity and synthetic\naccessibility than any molecule found in the virtual screen while being over\n100x faster and less expensive to run. On a test set of experimental complexes,\nIDOLpro is the first to produce molecules with better binding affinities than\nexperimentally observed ligands. IDOLpro can accommodate other scoring\nfunctions (e.g. ADME-Tox) to accelerate hit-finding, hit-to-lead, and lead\noptimization for drug discovery.", "AI": {"tldr": "IDOLpro is a generative AI for drug discovery, combining diffusion models with multi-objective optimization to generate molecules with superior binding affinity and synthetic accessibility.", "motivation": "Existing generative models fail to meet all desired physicochemical properties in drug discovery. IDOLpro aims to address this gap.", "method": "IDOLpro uses differentiable scoring functions to guide a diffusion model, optimizing multiple target properties like binding affinity and synthetic accessibility.", "result": "IDOLpro outperforms state-of-the-art methods by 10%-20% in binding affinity and synthetic accessibility, and is 100x faster than virtual screening.", "conclusion": "IDOLpro is a breakthrough in generative chemistry, enabling faster, cheaper, and more effective drug discovery with potential for broader applications."}}
{"id": "2405.12085", "pdf": "https://arxiv.org/pdf/2405.12085", "abs": "https://arxiv.org/abs/2405.12085", "authors": ["Chirag Wadhwa", "Mina Doosti"], "title": "Noise-tolerant learnability of shallow quantum circuits from statistics and the cost of quantum pseudorandomness", "categories": ["quant-ph", "cs.CC", "cs.CR", "cs.LG"], "comment": "20+7 pages, 1 figure, 1 table. v3: Improved presentation", "summary": "In this work, we study the learnability of quantum circuits in the near term.\nWe demonstrate the natural robustness of quantum statistical queries for\nlearning quantum processes, motivating their use as a theoretical tool for\nnear-term learning problems. We adapt a learning algorithm for constant-depth\nquantum circuits to the quantum statistical query setting, and show that such\ncircuits can be learned in our setting with only a linear overhead in the query\ncomplexity. We prove average-case quantum statistical query lower bounds for\nlearning, within diamond distance, random quantum circuits with depth at least\nlogarithmic and at most linear in the system size. Finally, we prove that\npseudorandom unitaries (PRUs) cannot be constructed using circuits of constant\ndepth by constructing an efficient distinguisher using existing learning\nalgorithms. To show the correctness of our distinguisher, we prove a new\nvariation of the quantum no free lunch theorem.", "AI": {"tldr": "The paper explores the learnability of quantum circuits in the near term, focusing on quantum statistical queries and their robustness. It adapts a learning algorithm for constant-depth circuits, proves lower bounds for learning random circuits, and shows that pseudorandom unitaries cannot be constructed with constant-depth circuits.", "motivation": "To understand the learnability of quantum circuits in the near term and leverage quantum statistical queries as a theoretical tool for such problems.", "method": "Adapts a learning algorithm for constant-depth quantum circuits to the quantum statistical query setting, proves lower bounds for learning random circuits, and constructs an efficient distinguisher for pseudorandom unitaries.", "result": "Demonstrates linear overhead in query complexity for learning constant-depth circuits, proves lower bounds for learning random circuits, and shows pseudorandom unitaries cannot be constructed with constant-depth circuits.", "conclusion": "Quantum statistical queries are robust for near-term learning, and pseudorandom unitaries require deeper circuits than constant depth."}}
{"id": "2405.14064", "pdf": "https://arxiv.org/pdf/2405.14064", "abs": "https://arxiv.org/abs/2405.14064", "authors": ["Jake A. Soloff", "Rina Foygel Barber", "Rebecca Willett"], "title": "Building a stable classifier with the inflated argmax", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "NeurIPS 2024", "summary": "We propose a new framework for algorithmic stability in the context of\nmulticlass classification. In practice, classification algorithms often operate\nby first assigning a continuous score (for instance, an estimated probability)\nto each possible label, then taking the maximizer -- i.e., selecting the class\nthat has the highest score. A drawback of this type of approach is that it is\ninherently unstable, meaning that it is very sensitive to slight perturbations\nof the training data, since taking the maximizer is discontinuous. Motivated by\nthis challenge, we propose a pipeline for constructing stable classifiers from\ndata, using bagging (i.e., resampling and averaging) to produce stable\ncontinuous scores, and then using a stable relaxation of argmax, which we call\nthe \"inflated argmax,\" to convert these scores to a set of candidate labels.\nThe resulting stability guarantee places no distributional assumptions on the\ndata, does not depend on the number of classes or dimensionality of the\ncovariates, and holds for any base classifier. Using a common benchmark data\nset, we demonstrate that the inflated argmax provides necessary protection\nagainst unstable classifiers, without loss of accuracy.", "AI": {"tldr": "A framework for stable multiclass classification using bagging and an \"inflated argmax\" to mitigate instability from data perturbations.", "motivation": "Addressing the instability of classifiers that rely on discontinuous maximization of scores, which are sensitive to small data changes.", "method": "Proposes a pipeline combining bagging (resampling and averaging) for stable scores and an \"inflated argmax\" for stable label selection.", "result": "Demonstrates stability guarantees without distributional assumptions, class or dimensionality dependence, and maintains accuracy on benchmark data.", "conclusion": "The framework effectively stabilizes classifiers without compromising accuracy, offering robustness against data perturbations."}}
{"id": "2405.18176", "pdf": "https://arxiv.org/pdf/2405.18176", "abs": "https://arxiv.org/abs/2405.18176", "authors": ["Ilia Azizi", "Marc-Olivier Boldi", "Val\u00e9rie Chavez-Demoulin"], "title": "SEMF: Supervised Expectation-Maximization Framework for Predicting Intervals", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This work introduces the Supervised Expectation-Maximization Framework\n(SEMF), a versatile and model-agnostic approach for generating prediction\nintervals with any ML model. SEMF extends the Expectation-Maximization\nalgorithm, traditionally used in unsupervised learning, to a supervised\ncontext, leveraging latent variable modeling for uncertainty estimation.\nThrough extensive empirical evaluation of diverse simulated distributions and\n11 real-world tabular datasets, SEMF consistently produces narrower prediction\nintervals while maintaining the desired coverage probability, outperforming\ntraditional quantile regression methods. Furthermore, without using the\nquantile (pinball) loss, SEMF allows point predictors, including\ngradient-boosted trees and neural networks, to be calibrated with conformal\nquantile regression. The results indicate that SEMF enhances uncertainty\nquantification under diverse data distributions and is particularly effective\nfor models that otherwise struggle with inherent uncertainty representation.", "AI": {"tldr": "SEMF is a model-agnostic framework for generating prediction intervals, outperforming traditional methods by producing narrower intervals while maintaining coverage probability.", "motivation": "To extend the Expectation-Maximization algorithm to supervised learning for better uncertainty estimation in ML models.", "method": "SEMF leverages latent variable modeling and is evaluated on simulated distributions and real-world datasets.", "result": "SEMF consistently produces narrower prediction intervals with desired coverage, outperforming quantile regression.", "conclusion": "SEMF improves uncertainty quantification, especially for models with inherent uncertainty representation challenges."}}
{"id": "2407.17214", "pdf": "https://arxiv.org/pdf/2407.17214", "abs": "https://arxiv.org/abs/2407.17214", "authors": ["Ilya Timofeyev", "Alexey Schwarzmann", "Dmitri Kuzmin"], "title": "Application of Machine Learning and Convex Limiting to Subgrid Flux Modeling in the Shallow-Water Equations", "categories": ["physics.comp-ph", "cs.LG", "physics.ao-ph", "physics.flu-dyn", "stat.ML", "65M99"], "comment": null, "summary": "We propose a combination of machine learning and flux limiting for\nproperty-preserving subgrid scale modeling in the context of flux-limited\nfinite volume methods for the one-dimensional shallow-water equations. The\nnumerical fluxes of a conservative target scheme are fitted to the coarse-mesh\naverages of a monotone fine-grid discretization using a neural network to\nparametrize the subgrid scale components. To ensure positivity preservation and\nthe validity of local maximum principles, we use a flux limiter that constrains\nthe intermediate states of an equivalent fluctuation form to stay in a convex\nadmissible set. The results of our numerical studies confirm that the proposed\ncombination of machine learning with monolithic convex limiting produces\nmeaningful closures even in scenarios for which the network was not trained.", "AI": {"tldr": "Combining machine learning and flux limiting for subgrid scale modeling in shallow-water equations, ensuring positivity and local maximum principles.", "motivation": "To develop a property-preserving subgrid scale model for flux-limited finite volume methods in shallow-water equations.", "method": "Use neural networks to fit numerical fluxes to coarse-mesh averages, constrained by a flux limiter for positivity and local maximum principles.", "result": "Produces meaningful closures even in untrained scenarios.", "conclusion": "The hybrid approach of machine learning and monolithic convex limiting is effective for subgrid scale modeling."}}
{"id": "2409.04406", "pdf": "https://arxiv.org/pdf/2409.04406", "abs": "https://arxiv.org/abs/2409.04406", "authors": ["Jan Schnabel", "Marco Roth"], "title": "Quantum Kernel Methods under Scrutiny: A Benchmarking Study", "categories": ["quant-ph", "cs.LG"], "comment": "20 pages main text including 9 figures and 1 table, appendix 18 pages\n  with 22 figures and 2 tables; article in Quantum Machine Intelligence", "summary": "Since the entry of kernel theory in the field of quantum machine learning,\nquantum kernel methods (QKMs) have gained increasing attention with regard to\nboth probing promising applications and delivering intriguing research\ninsights. Benchmarking these methods is crucial to gain robust insights and to\nunderstand their practical utility. In this work, we present a comprehensive\nlarge-scale study examining QKMs based on fidelity quantum kernels (FQKs) and\nprojected quantum kernels (PQKs) across a manifold of design choices. Our\ninvestigation encompasses both classification and regression tasks for five\ndataset families and 64 datasets, systematically comparing the use of FQKs and\nPQKs quantum support vector machines and kernel ridge regression. This resulted\nin over 20,000 models that were trained and optimized using a state-of-the-art\nhyperparameter search to ensure robust and comprehensive insights. We delve\ninto the importance of hyperparameters on model performance scores and support\nour findings through rigorous correlation analyses. Additionally, we provide an\nin-depth analysis addressing the design freedom of PQKs and explore the\nunderlying principles responsible for learning. Our goal is not to identify the\nbest-performing model for a specific task but to uncover the mechanisms that\nlead to effective QKMs and reveal universal patterns.", "AI": {"tldr": "A large-scale study on quantum kernel methods (QKMs) compares fidelity quantum kernels (FQKs) and projected quantum kernels (PQKs) across 64 datasets, analyzing their performance in classification and regression tasks.", "motivation": "To benchmark QKMs and understand their practical utility, focusing on FQKs and PQKs, and uncover universal patterns in their effectiveness.", "method": "Comprehensive study involving over 20,000 models trained with hyperparameter optimization, comparing FQKs and PQKs in quantum support vector machines and kernel ridge regression.", "result": "Analysis of hyperparameter impact and correlation, along with exploration of PQKs' design freedom and learning principles.", "conclusion": "Aims to reveal mechanisms behind effective QKMs rather than identifying the best model, providing insights into universal patterns."}}
{"id": "2409.14918", "pdf": "https://arxiv.org/pdf/2409.14918", "abs": "https://arxiv.org/abs/2409.14918", "authors": ["Fernando M. Quintana", "Maryada", "Pedro L. Galindo", "Elisa Donati", "Giacomo Indiveri", "Fernando Perez-Pe\u00f1a"], "title": "A Realistic Simulation Framework for Analog/Digital Neuromorphic Architectures", "categories": ["cs.NE", "cs.AR", "cs.LG"], "comment": "21 pages", "summary": "Developing dedicated mixed-signal neuromorphic computing systems optimized\nfor real-time sensory-processing in extreme edge-computing applications\nrequires time-consuming design, fabrication, and deployment of full-custom\nneuromorphic processors. To ensure that initial prototyping efforts, exploring\nthe properties of different network architectures and parameter settings, lead\nto realistic results, it is important to use simulation frameworks that match\nas best as possible the properties of the final hardware. This is particularly\nchallenging for neuromorphic hardware platforms made using mixed-signal\nanalog/digital circuits, due to the variability and noise sensitivity of their\ncomponents. In this paper, we address this challenge by developing a software\nspiking neural network simulator explicitly designed to account for the\nproperties of mixed-signal neuromorphic circuits, including device mismatch\nvariability.\n  The simulator, called ARCANA (A Realistic Simulation Framework for\nAnalog/Digital Neuromorphic Architectures), is designed to reproduce the\ndynamics of mixed-signal synapse and neuron electronic circuits with\nautogradient differentiation for parameter optimization and GPU acceleration.\nWe demonstrate the effectiveness of this approach by matching software\nsimulation results with measurements made from an existing neuromorphic\nprocessor. We show how the results obtained provide a reliable estimate of the\nbehavior of the spiking neural network trained in software, once deployed in\nhardware. This framework enables the development and innovation of new learning\nrules and processing architectures in neuromorphic embedded systems.", "AI": {"tldr": "ARCANA is a spiking neural network simulator for mixed-signal neuromorphic circuits, addressing hardware variability and noise sensitivity to improve prototyping accuracy.", "motivation": "To bridge the gap between software simulations and hardware performance in neuromorphic computing, ensuring realistic prototyping results.", "method": "Developed ARCANA, a simulator with autogradient differentiation and GPU acceleration, mimicking mixed-signal circuit dynamics.", "result": "Matched software simulations with hardware measurements, proving reliable behavior estimation for deployed networks.", "conclusion": "ARCANA enables innovation in neuromorphic embedded systems by providing accurate hardware-like simulation."}}
{"id": "2410.21119", "pdf": "https://arxiv.org/pdf/2410.21119", "abs": "https://arxiv.org/abs/2410.21119", "authors": ["Jun Bai", "Yiliao Song", "Di Wu", "Atul Sajjanhar", "Yong Xiang", "Wei Zhou", "Xiaohui Tao", "Yan Li", "Yue Li"], "title": "A Unified Solution to Diverse Heterogeneities in One-shot Federated Learning", "categories": ["cs.DC", "cs.LG"], "comment": "Updated version", "summary": "One-Shot Federated Learning (OSFL) restricts communication between the server\nand clients to a single round, significantly reducing communication costs and\nminimizing privacy leakage risks compared to traditional Federated Learning\n(FL), which requires multiple rounds of communication. However, existing OSFL\nframeworks remain vulnerable to distributional heterogeneity, as they primarily\nfocus on model heterogeneity while neglecting data heterogeneity. To bridge\nthis gap, we propose FedHydra, a unified, data-free, OSFL framework designed to\neffectively address both model and data heterogeneity. Unlike existing OSFL\napproaches, FedHydra introduces a novel two-stage learning mechanism.\nSpecifically, it incorporates model stratification and heterogeneity-aware\nstratified aggregation to mitigate the challenges posed by both model and data\nheterogeneity. By this design, the data and model heterogeneity issues are\nsimultaneously monitored from different aspects during learning. Consequently,\nFedHydra can effectively mitigate both issues by minimizing their inherent\nconflicts. We compared FedHydra with five SOTA baselines on four benchmark\ndatasets. Experimental results show that our method outperforms the previous\nOSFL methods in both homogeneous and heterogeneous settings. Our code is\navailable at https://anonymous.4open.science/r/Fed-SA-A4D7.", "AI": {"tldr": "FedHydra is a one-shot federated learning framework addressing both model and data heterogeneity with a two-stage learning mechanism, outperforming existing methods.", "motivation": "Existing OSFL frameworks neglect data heterogeneity, focusing only on model heterogeneity, leading to vulnerabilities in distributional heterogeneity.", "method": "FedHydra uses a two-stage learning mechanism with model stratification and heterogeneity-aware stratified aggregation to address both model and data heterogeneity.", "result": "FedHydra outperforms five state-of-the-art baselines on four benchmark datasets in both homogeneous and heterogeneous settings.", "conclusion": "FedHydra effectively mitigates model and data heterogeneity issues, offering a robust solution for OSFL."}}
{"id": "2410.21862", "pdf": "https://arxiv.org/pdf/2410.21862", "abs": "https://arxiv.org/abs/2410.21862", "authors": ["Massimo Bilancia", "Samuele Magro"], "title": "Hierarchical mixtures of Unigram models for short text clustering: The role of Beta-Liouville priors", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": "28 pages, 6 figures. Submitted", "summary": "This paper presents a variant of the Multinomial mixture model tailored to\nthe unsupervised classification of short text data. While the Multinomial\nprobability vector is traditionally assigned a Dirichlet prior distribution,\nthis work explores an alternative formulation based on the Beta-Liouville\ndistribution, which offers a more flexible correlation structure than the\nDirichlet. We examine the theoretical properties of the Beta-Liouville\ndistribution, with particular focus on its conjugacy with the Multinomial\nlikelihood. This property enables the derivation of update equations for a CAVI\n(Coordinate Ascent Variational Inference) algorithm, facilitating approximate\nposterior inference of the model parameters. In addition, we introduce a\nstochastic variant of the CAVI algorithm to enhance scalability. The paper\nconcludes with empirical examples demonstrating effective strategies for\nselecting the Beta-Liouville hyperparameters.", "AI": {"tldr": "A variant of the Multinomial mixture model using Beta-Liouville prior for unsupervised short text classification, with theoretical analysis, CAVI algorithm, and empirical hyperparameter selection.", "motivation": "To address the limitations of the Dirichlet prior in modeling correlations for short text classification by proposing a more flexible Beta-Liouville prior.", "method": "Theoretical analysis of Beta-Liouville's conjugacy with Multinomial likelihood, derivation of CAVI update equations, and introduction of a stochastic CAVI variant for scalability.", "result": "Demonstrated effective hyperparameter selection strategies for the Beta-Liouville prior in empirical examples.", "conclusion": "The Beta-Liouville prior offers a flexible alternative to Dirichlet for unsupervised short text classification, with practical inference via CAVI."}}
{"id": "2411.01791", "pdf": "https://arxiv.org/pdf/2411.01791", "abs": "https://arxiv.org/abs/2411.01791", "authors": ["Yangtao Deng", "Xiang Shi", "Zhuo Jiang", "Xingjian Zhang", "Lei Zhang", "Zhang Zhang", "Bo Li", "Zuquan Song", "Hang Zhu", "Gaohong Liu", "Fuliang Li", "Shuguang Wang", "Haibin Lin", "Jianxi Ye", "Minlan Yu"], "title": "Minder: Faulty Machine Detection for Large-scale Distributed Model Training", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Large-scale distributed model training requires simultaneous training on up\nto thousands of machines. Faulty machine detection is critical when an\nunexpected fault occurs in a machine. From our experience, a training task can\nencounter two faults per day on average, possibly leading to a halt for hours.\nTo address the drawbacks of the time-consuming and labor-intensive manual\nscrutiny, we propose Minder, an automatic faulty machine detector for\ndistributed training tasks. The key idea of Minder is to automatically and\nefficiently detect faulty distinctive monitoring metric patterns, which could\nlast for a period before the entire training task comes to a halt. Minder has\nbeen deployed in our production environment for over one year, monitoring daily\ndistributed training tasks where each involves up to thousands of machines. In\nour real-world fault detection scenarios, Minder can accurately and efficiently\nreact to faults within 3.6 seconds on average, with a precision of 0.904 and\nF1-score of 0.893.", "AI": {"tldr": "Minder is an automatic faulty machine detector for distributed training tasks, addressing manual scrutiny drawbacks by detecting faulty metric patterns efficiently.", "motivation": "Manual detection of faults in large-scale distributed training is time-consuming and labor-intensive, leading to significant downtime.", "method": "Minder automatically identifies faulty monitoring metric patterns that precede training halts.", "result": "Deployed for over a year, Minder reacts to faults in 3.6 seconds on average, with a precision of 0.904 and F1-score of 0.893.", "conclusion": "Minder effectively automates fault detection in distributed training, improving efficiency and reducing downtime."}}
{"id": "2411.06990", "pdf": "https://arxiv.org/pdf/2411.06990", "abs": "https://arxiv.org/abs/2411.06990", "authors": ["Hiroshi Yokoyama", "Ryusei Shingaki", "Kaneharu Nishino", "Shohei Shimizu", "Thong Pham"], "title": "Causal-discovery-based root-cause analysis and its application in time-series prediction error diagnosis", "categories": ["stat.ML", "cs.LG"], "comment": "10 pages with 4 figures and 2 tables", "summary": "Recent rapid advancements of machine learning have greatly enhanced the\naccuracy of prediction models, but most models remain \"black boxes\", making\nprediction error diagnosis challenging, especially with outliers. This lack of\ntransparency hinders trust and reliability in industrial applications.\nHeuristic attribution methods, while helpful, often fail to capture true causal\nrelationships, leading to inaccurate error attributions. Various root-cause\nanalysis methods have been developed using Shapley values, yet they typically\nrequire predefined causal graphs, limiting their applicability for prediction\nerrors in machine learning models. To address these limitations, we introduce\nthe Causal-Discovery-based Root-Cause Analysis (CD-RCA) method that estimates\ncausal relationships between the prediction error and the explanatory\nvariables, without needing a pre-defined causal graph. By simulating synthetic\nerror data, CD-RCA can identify variable contributions to outliers in\nprediction errors by Shapley values. Extensive experiments show CD-RCA\noutperforms current heuristic attribution methods.", "AI": {"tldr": "CD-RCA is a new method for root-cause analysis of prediction errors in ML models, outperforming heuristic methods by estimating causal relationships without predefined graphs.", "motivation": "Current ML models lack transparency, making error diagnosis difficult. Heuristic methods often fail to capture true causality, and existing RCA methods require predefined causal graphs, limiting their use.", "method": "CD-RCA estimates causal relationships between prediction errors and variables without predefined graphs, using synthetic error data and Shapley values.", "result": "CD-RCA outperforms heuristic attribution methods in identifying variable contributions to outliers.", "conclusion": "CD-RCA provides a more reliable and transparent approach for diagnosing prediction errors in ML models."}}
{"id": "2412.03385", "pdf": "https://arxiv.org/pdf/2412.03385", "abs": "https://arxiv.org/abs/2412.03385", "authors": ["Ivan \u010cili\u0107", "Anna Lackinger", "Pantelis Frangoudis", "Ivana Podnar \u017darko", "Alireza Furutanpey", "Ilir Murturi", "Schahram Dustdar"], "title": "Reactive Orchestration for Hierarchical Federated Learning Under a Communication Cost Budget", "categories": ["cs.DC", "cs.LG", "cs.NI"], "comment": null, "summary": "Deploying a Hierarchical Federated Learning (HFL) pipeline across the\ncomputing continuum (CC) requires careful organization of participants into a\nhierarchical structure with intermediate aggregation nodes between FL clients\nand the global FL server. This is challenging to achieve due to (i) cost\nconstraints, (ii) varying data distributions, and (iii) the volatile operating\nenvironment of the CC. In response to these challenges, we present a framework\nfor the adaptive orchestration of HFL pipelines, designed to be reactive to\nclient churn and infrastructure-level events, while balancing communication\ncost and ML model accuracy. Our mechanisms identify and react to events that\ncause HFL reconfiguration actions at runtime, building on multi-level\nmonitoring information (model accuracy, resource availability, resource cost).\nMoreover, our framework introduces a generic methodology for estimating\nreconfiguration costs to continuously re-evaluate the quality of adaptation\nactions, while being extensible to optimize for various HFL performance\ncriteria. By extending the Kubernetes ecosystem, our framework demonstrates the\nability to react promptly and effectively to changes in the operating\nenvironment, making the best of the available communication cost budget and\neffectively balancing costs and ML performance at runtime.", "AI": {"tldr": "A framework for adaptive orchestration of Hierarchical Federated Learning (HFL) pipelines addresses challenges like cost, data distribution, and volatile environments by dynamically reconfiguring based on runtime events and optimizing communication cost and model accuracy.", "motivation": "The challenges of deploying HFL across the computing continuum include cost constraints, varying data distributions, and volatile environments, necessitating adaptive solutions.", "method": "The framework uses multi-level monitoring (accuracy, resource availability, cost) to trigger runtime reconfigurations and estimates reconfiguration costs to optimize HFL performance.", "result": "The framework, integrated with Kubernetes, effectively balances communication costs and ML performance, adapting promptly to environmental changes.", "conclusion": "The proposed framework successfully addresses HFL deployment challenges by enabling adaptive orchestration, optimizing both cost and performance dynamically."}}
{"id": "2412.08661", "pdf": "https://arxiv.org/pdf/2412.08661", "abs": "https://arxiv.org/abs/2412.08661", "authors": ["Xiayin Lou", "Peng Luo", "Liqiu Meng"], "title": "GeoConformal prediction: a model-agnostic framework of measuring the uncertainty of spatial prediction", "categories": ["stat.ML", "cs.LG", "physics.data-an", "stat.AP"], "comment": null, "summary": "Spatial prediction is a fundamental task in geography. In recent years, with\nadvances in geospatial artificial intelligence (GeoAI), numerous models have\nbeen developed to improve the accuracy of geographic variable predictions.\nBeyond achieving higher accuracy, it is equally important to obtain predictions\nwith uncertainty measures to enhance model credibility and support responsible\nspatial prediction. Although geostatistic methods like Kriging offer some level\nof uncertainty assessment, such as Kriging variance, these measurements are not\nalways accurate and lack general applicability to other spatial models. To\naddress this issue, we propose a model-agnostic uncertainty assessment method\ncalled GeoConformal Prediction, which incorporates geographical weighting into\nconformal prediction. We applied it to two classic spatial prediction cases,\nspatial regression and spatial interpolation, to evaluate its reliability.\nFirst, in the spatial regression case, we used XGBoost to predict housing\nprices, followed by GeoConformal to calculate uncertainty. Our results show\nthat GeoConformal achieved a coverage rate of 93.67%, while Bootstrap methods\nonly reached a maximum coverage of 81.00% after 2000 runs. Next, we applied\nGeoConformal to spatial interpolation models. We found that the uncertainty\nobtained from GeoConformal aligned closely with the variance in Kriging.\nFinally, using GeoConformal, we analyzed the sources of uncertainty in spatial\nprediction. We found that explicitly including local features in AI models can\nsignificantly reduce prediction uncertainty, especially in areas with strong\nlocal dependence. Our findings suggest that GeoConformal holds potential not\nonly for geographic knowledge discovery but also for guiding the design of\nfuture GeoAI models, paving the way for more reliable and interpretable spatial\nprediction frameworks.", "AI": {"tldr": "The paper introduces GeoConformal Prediction, a model-agnostic method for assessing uncertainty in spatial predictions, outperforming traditional methods like Bootstrap and aligning with Kriging variance.", "motivation": "Improving spatial prediction accuracy and credibility by providing reliable uncertainty measures, which existing methods like Kriging lack.", "method": "Proposes GeoConformal Prediction, integrating geographical weighting into conformal prediction, and tests it on spatial regression (XGBoost for housing prices) and interpolation.", "result": "GeoConformal achieved 93.67% coverage in regression, outperforming Bootstrap (81.00%), and matched Kriging variance in interpolation. Local feature inclusion reduces uncertainty.", "conclusion": "GeoConformal enhances reliability and interpretability in spatial predictions, guiding future GeoAI model design for better uncertainty handling."}}
{"id": "2412.14306", "pdf": "https://arxiv.org/pdf/2412.14306", "abs": "https://arxiv.org/abs/2412.14306", "authors": ["Benjamin Steenhoek", "Kalpathy Sivaraman", "Renata Saldivar Gonzalez", "Yevhen Mohylevskyy", "Roshanak Zilouchian Moghaddam", "Wei Le"], "title": "Closing the Gap: A User Study on the Real-world Usefulness of AI-powered Vulnerability Detection & Repair in the IDE", "categories": ["cs.SE", "cs.CR", "cs.LG"], "comment": "Accepted to ICSE 2025 research track. Camera-ready version with grant\n  reference number fixed in acknowledgments", "summary": "This paper presents the first empirical study of a vulnerability detection\nand fix tool with professional software developers on real projects that they\nown. We implemented DeepVulGuard, an IDE-integrated tool based on\nstate-of-the-art detection and fix models, and show that it has promising\nperformance on benchmarks of historic vulnerability data. DeepVulGuard scans\ncode for vulnerabilities (including identifying the vulnerability type and\nvulnerable region of code), suggests fixes, provides natural-language\nexplanations for alerts and fixes, leveraging chat interfaces. We recruited 17\nprofessional software developers at Microsoft, observed their usage of the tool\non their code, and conducted interviews to assess the tool's usefulness, speed,\ntrust, relevance, and workflow integration. We also gathered detailed\nqualitative feedback on users' perceptions and their desired features. Study\nparticipants scanned a total of 24 projects, 6.9k files, and over 1.7 million\nlines of source code, and generated 170 alerts and 50 fix suggestions. We find\nthat although state-of-the-art AI-powered detection and fix tools show promise,\nthey are not yet practical for real-world use due to a high rate of false\npositives and non-applicable fixes. User feedback reveals several actionable\npain points, ranging from incomplete context to lack of customization for the\nuser's codebase. Additionally, we explore how AI features, including confidence\nscores, explanations, and chat interaction, can apply to vulnerability\ndetection and fixing. Based on these insights, we offer practical\nrecommendations for evaluating and deploying AI detection and fix models. Our\ncode and data are available at https://doi.org/10.6084/m9.figshare.26367139.", "AI": {"tldr": "DeepVulGuard, an AI-powered IDE tool for vulnerability detection and fixing, shows promise but faces practicality issues like false positives and non-applicable fixes, based on a study with 17 Microsoft developers.", "motivation": "To evaluate the real-world applicability of AI-powered vulnerability detection and fixing tools in professional software development environments.", "method": "Implemented DeepVulGuard, an IDE-integrated tool, and observed 17 developers using it on 24 projects, analyzing alerts, fixes, and gathering feedback.", "result": "Generated 170 alerts and 50 fix suggestions, but high false positives and non-applicable fixes limit practicality. User feedback highlighted pain points like incomplete context and lack of customization.", "conclusion": "AI tools for vulnerability detection and fixing are promising but not yet practical; actionable recommendations are provided for improvement."}}
{"id": "2412.14916", "pdf": "https://arxiv.org/pdf/2412.14916", "abs": "https://arxiv.org/abs/2412.14916", "authors": ["Dominik Chevalier", "Marie-Pier C\u00f4t\u00e9"], "title": "From Point to probabilistic gradient boosting for claim frequency and severity prediction", "categories": ["stat.ML", "cs.LG", "62P05, 68T05", "I.2.6; I.5.1; G.3; A.1"], "comment": "39 pages, 12 figures, 25 tables, 7 algorithms", "summary": "Gradient boosting for decision tree algorithms are increasingly used in\nactuarial applications as they show superior predictive performance over\ntraditional generalised linear models. Many enhancements to the first gradient\nboosting machine algorithm exist. We present in a unified notation, and\ncontrast, all the existing point and probabilistic gradient boosting for\ndecision tree algorithms: GBM, XGBoost, DART, LightGBM, CatBoost, EGBM, PGBM,\nXGBoostLSS, cyclic GBM, and NGBoost. In this comprehensive numerical study, we\ncompare their performance on five publicly available datasets for claim\nfrequency and severity, of various sizes and comprising different numbers of\n(high cardinality) categorical variables. We explain how varying\nexposure-to-risk can be handled with boosting in frequency models. We compare\nthe algorithms on the basis of computational efficiency, predictive\nperformance, and model adequacy. LightGBM and XGBoostLSS win in terms of\ncomputational efficiency. CatBoost sometimes improves predictive performance,\nespecially in the presence of high cardinality categorical variables, common in\nactuarial science. The fully interpretable EGBM achieves competitive predictive\nperformance compared to the black box algorithms considered. We find that there\nis no trade-off between model adequacy and predictive accuracy: both are\nachievable simultaneously.", "AI": {"tldr": "The paper compares various gradient boosting algorithms (GBM, XGBoost, LightGBM, etc.) for actuarial applications, evaluating their computational efficiency, predictive performance, and model adequacy. LightGBM and XGBoostLSS excel in efficiency, while CatBoost performs well with high-cardinality categorical variables. EGBM offers interpretability without sacrificing performance.", "motivation": "To provide a unified comparison of gradient boosting algorithms for actuarial science, addressing their predictive performance, computational efficiency, and handling of categorical variables.", "method": "A comprehensive numerical study using five publicly available datasets for claim frequency and severity, comparing algorithms like GBM, XGBoost, LightGBM, and others.", "result": "LightGBM and XGBoostLSS are computationally efficient; CatBoost excels with high-cardinality categorical variables. EGBM is interpretable yet competitive. No trade-off between model adequacy and predictive accuracy.", "conclusion": "Gradient boosting algorithms offer strong performance in actuarial applications, with specific algorithms excelling in efficiency, handling categorical variables, or interpretability."}}
{"id": "2501.06926", "pdf": "https://arxiv.org/pdf/2501.06926", "abs": "https://arxiv.org/abs/2501.06926", "authors": ["Lars van der Laan", "David Hubbard", "Allen Tran", "Nathan Kallus", "Aur\u00e9lien Bibaut"], "title": "Automatic Double Reinforcement Learning in Semiparametric Markov Decision Processes with Applications to Long-Term Causal Inference", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Estimating long-term causal effects from short-term data is essential for\ndecision-making in healthcare, economics, and industry, where long-term\nfollow-up is often infeasible. Markov Decision Processes (MDPs) offer a\nprincipled framework for modeling outcomes as sequences of states, actions, and\nrewards over time. We introduce a semiparametric extension of Double\nReinforcement Learning (DRL) for statistically efficient, model-robust\ninference on linear functionals of the Q-function, such as policy values, in\ninfinite-horizon, time-homogeneous MDPs. By imposing semiparametric structure\non the Q-function, our method relaxes the strong state overlap assumptions\nrequired by fully nonparametric approaches, improving efficiency and stability.\nTo address computational and robustness challenges of minimax nuisance\nestimation, we develop a novel debiased plug-in estimator based on isotonic\nBellman calibration, which integrates fitted Q-iteration with an isotonic\nregression step. This procedure leverages the Q-function as a data-driven\ndimension reduction, debiases all linear functionals of interest\nsimultaneously, and enables nonparametric inference without explicit nuisance\nfunction estimation. Bellman calibration generalizes isotonic calibration to\nMDPs and may be of independent interest for prediction in reinforcement\nlearning. Finally, we show that model selection for the Q-function incurs only\nsecond-order bias and extend the adaptive debiased machine learning (ADML)\nframework to MDPs for data-driven learning of semiparametric structure.", "AI": {"tldr": "A semiparametric extension of Double Reinforcement Learning (DRL) is introduced for efficient, robust inference on linear functionals of the Q-function in infinite-horizon MDPs, improving stability and reducing strong state overlap assumptions.", "motivation": "Estimating long-term causal effects from short-term data is crucial in fields like healthcare and economics, where long-term follow-up is often impractical.", "method": "The method combines semiparametric Q-function structure with a debiased plug-in estimator using isotonic Bellman calibration, integrating fitted Q-iteration and isotonic regression.", "result": "The approach relaxes strong state overlap assumptions, improves efficiency, and enables nonparametric inference without explicit nuisance function estimation.", "conclusion": "The method generalizes isotonic calibration to MDPs and extends adaptive debiased machine learning (ADML) to MDPs, offering robust, data-driven learning of semiparametric structure."}}
{"id": "2501.10428", "pdf": "https://arxiv.org/pdf/2501.10428", "abs": "https://arxiv.org/abs/2501.10428", "authors": ["BG Tong"], "title": "Perception-Guided EEG Analysis: A Deep Learning Approach Inspired by Level of Detail (LOD) Theory", "categories": ["eess.SP", "cs.HC", "cs.LG"], "comment": null, "summary": "Objective: This study explores a novel deep learning approach for EEG\nanalysis and perceptual state guidance, inspired by Level of Detail (LOD)\ntheory. The goal is to improve perceptual state identification accuracy and\nadvance personalized psychological therapy. Methods: Portable EEG devices and\nmusic rhythm signals were used for data collection. LOD theory was applied to\ndynamically adjust EEG signal processing, extracting core perceptual features.\nA Unity-based software system integrated EEG data with audio materials. The\ndeep learning model combined a CNN for feature extraction and classification,\nand a DQN for reinforcement learning to optimize rhythm adjustments. Results:\nThe CNN achieved 94.05% accuracy in perceptual state classification. The DQN\nguided subjects to target states with a 92.45% success rate, averaging 13.2\nrhythm cycles. However, only 50% of users reported psychological alignment with\nthe target state, indicating room for improvement. Discussion: The results\nvalidate the potential of LOD-based EEG biofeedback. Limitations include\ndataset source, label subjectivity, and reward function optimization. Future\nwork will expand to diverse subjects, incorporate varied musical elements, and\nrefine reward functions for better generalization and personalization.", "AI": {"tldr": "A novel deep learning approach for EEG analysis, inspired by LOD theory, improves perceptual state identification and personalized therapy.", "motivation": "To enhance perceptual state accuracy and advance personalized psychological therapy using EEG and music rhythm signals.", "method": "Used portable EEG devices and music rhythms, applied LOD theory for dynamic EEG processing, and integrated a CNN-DQN model for classification and reinforcement learning.", "result": "CNN achieved 94.05% classification accuracy; DQN guided states with 92.45% success. User alignment was 50%, indicating improvement needed.", "conclusion": "Validates LOD-based EEG biofeedback potential. Future work includes dataset expansion, musical diversity, and reward refinement."}}
{"id": "2502.00835", "pdf": "https://arxiv.org/pdf/2502.00835", "abs": "https://arxiv.org/abs/2502.00835", "authors": ["Yuanchen Yuan", "Jin Cheng", "N\u00faria Armengol Urp\u00ed", "Stelian Coros"], "title": "CAIMAN: Causal Action Influence Detection for Sample-efficient Loco-manipulation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Enabling legged robots to perform non-prehensile loco-manipulation is crucial\nfor enhancing their versatility. Learning behaviors such as whole-body object\npushing often requires sophisticated planning strategies or extensive\ntask-specific reward shaping, especially in unstructured environments. In this\nwork, we present CAIMAN, a practical reinforcement learning framework that\nencourages the agent to gain control over other entities in the environment.\nCAIMAN leverages causal action influence as an intrinsic motivation objective,\nallowing legged robots to efficiently acquire object pushing skills even under\nsparse task rewards. We employ a hierarchical control strategy, combining a\nlow-level locomotion module with a high-level policy that generates\ntask-relevant velocity commands and is trained to maximize the intrinsic\nreward. To estimate causal action influence, we learn the dynamics of the\nenvironment by integrating a kinematic prior with data collected during\ntraining.We empirically demonstrate CAIMAN's superior sample efficiency and\nadaptability to diverse scenarios in simulation, as well as its successful\ntransfer to real-world systems without further fine-tuning.", "AI": {"tldr": "CAIMAN is a reinforcement learning framework for legged robots to learn object pushing efficiently using causal action influence as intrinsic motivation, without extensive reward shaping.", "motivation": "Enhancing legged robots' versatility in non-prehensile loco-manipulation, especially in unstructured environments, without relying on complex planning or task-specific rewards.", "method": "Hierarchical control with a low-level locomotion module and a high-level policy trained to maximize intrinsic reward. Causal action influence is estimated using a kinematic prior and training data.", "result": "CAIMAN shows superior sample efficiency and adaptability in simulation, and successfully transfers to real-world systems without fine-tuning.", "conclusion": "CAIMAN provides a practical solution for legged robots to acquire object pushing skills efficiently and adaptively."}}
{"id": "2502.02887", "pdf": "https://arxiv.org/pdf/2502.02887", "abs": "https://arxiv.org/abs/2502.02887", "authors": ["Samir M. Perlaza", "Gaetan Bisson"], "title": "Variations on the Expectation due to Changes in the Probability Measure", "categories": ["cs.IT", "cs.LG", "math.IT", "math.PR", "math.ST", "stat.TH"], "comment": "Submitted to the IEEE Information Theory Workshop (ITW), 2025", "summary": "In this paper, closed-form expressions are presented for the variation of the\nexpectation of a given function due to changes in the probability measure used\nfor the expectation. They unveil interesting connections with Gibbs probability\nmeasures, mutual information, and lautum information.", "AI": {"tldr": "Closed-form expressions for expectation variation due to probability measure changes, linking to Gibbs measures, mutual information, and lautum information.", "motivation": "To explore how changes in probability measures affect expectations and uncover connections with Gibbs measures and information theory concepts.", "method": "Derived closed-form expressions for expectation variations under probability measure changes.", "result": "Revealed connections with Gibbs probability measures, mutual information, and lautum information.", "conclusion": "The findings provide insights into expectation variations and their ties to information theory and statistical mechanics."}}
{"id": "2502.04699", "pdf": "https://arxiv.org/pdf/2502.04699", "abs": "https://arxiv.org/abs/2502.04699", "authors": ["Hui Lan", "Haoge Chang", "Eleanor Dillon", "Vasilis Syrgkanis"], "title": "A Meta-learner for Heterogeneous Effects in Difference-in-Differences", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We address the problem of estimating heterogeneous treatment effects in panel\ndata, adopting the popular Difference-in-Differences (DiD) framework under the\nconditional parallel trends assumption. We propose a novel doubly robust\nmeta-learner for the Conditional Average Treatment Effect on the Treated\n(CATT), reducing the estimation to a convex risk minimization problem involving\na set of auxiliary models. Our framework allows for the flexible estimation of\nthe CATT, when conditioning on any subset of variables of interest using\ngeneric machine learning. Leveraging Neyman orthogonality, our proposed\napproach is robust to estimation errors in the auxiliary models. As a\ngeneralization to our main result, we develop a meta-learning approach for the\nestimation of general conditional functionals under covariate shift. We also\nprovide an extension to the instrumented DiD setting with non-compliance.\nEmpirical results demonstrate the superiority of our approach over existing\nbaselines.", "AI": {"tldr": "A novel doubly robust meta-learner for estimating heterogeneous treatment effects in panel data under the DiD framework, robust to auxiliary model errors and flexible for machine learning applications.", "motivation": "To address the challenge of estimating heterogeneous treatment effects in panel data, particularly under the conditional parallel trends assumption, with a focus on flexibility and robustness.", "method": "Proposes a doubly robust meta-learner for CATT estimation, reducing it to convex risk minimization with auxiliary models, leveraging Neyman orthogonality for robustness.", "result": "The approach outperforms existing baselines, demonstrating flexibility and robustness in estimating treatment effects under covariate shift and non-compliance scenarios.", "conclusion": "The proposed meta-learner provides a robust and flexible solution for heterogeneous treatment effect estimation in panel data, with extensions for broader applications."}}
{"id": "2502.04901", "pdf": "https://arxiv.org/pdf/2502.04901", "abs": "https://arxiv.org/abs/2502.04901", "authors": ["Jaiden Fairoze", "Guillermo Ortiz-Jimenez", "Mel Vecerik", "Somesh Jha", "Sven Gowal"], "title": "On the Difficulty of Constructing a Robust and Publicly-Detectable Watermark", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This work investigates the theoretical boundaries of creating\npublicly-detectable schemes to enable the provenance of watermarked imagery.\nMetadata-based approaches like C2PA provide unforgeability and\npublic-detectability. ML techniques offer robust retrieval and watermarking.\nHowever, no existing scheme combines robustness, unforgeability, and\npublic-detectability. In this work, we formally define such a scheme and\nestablish its existence. Although theoretically possible, we find that at\npresent, it is intractable to build certain components of our scheme without a\nleap in deep learning capabilities. We analyze these limitations and propose\nresearch directions that need to be addressed before we can practically realize\nrobust and publicly-verifiable provenance.", "AI": {"tldr": "The paper explores the feasibility of combining robustness, unforgeability, and public-detectability in watermarking schemes for imagery, finding it theoretically possible but currently impractical due to deep learning limitations.", "motivation": "Existing schemes lack a combination of robustness, unforgeability, and public-detectability, which is crucial for practical provenance of watermarked imagery.", "method": "The work formally defines a scheme combining these properties and analyzes its theoretical existence and practical limitations.", "result": "The study confirms the theoretical possibility but highlights current intractability due to insufficient deep learning capabilities.", "conclusion": "Future research must address these limitations to achieve robust and publicly-verifiable provenance in practice."}}
{"id": "2502.07135", "pdf": "https://arxiv.org/pdf/2502.07135", "abs": "https://arxiv.org/abs/2502.07135", "authors": ["Andreas Galanis", "Leslie Ann Goldberg", "Xusheng Zhang"], "title": "One-Shot Learning for k-SAT", "categories": ["cs.DS", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Consider a $k$-SAT formula $\\Phi$ where every variable appears at most $d$\ntimes, and let $\\sigma$ be a satisfying assignment of $\\Phi$ sampled\nproportionally to $e^{\\beta m(\\sigma)}$ where $m(\\sigma)$ is the number of\nvariables set to true and $\\beta$ is a real parameter. Given $\\Phi$ and\n$\\sigma$, can we learn the value of $\\beta$ efficiently?\n  This problem falls into a recent line of works about single-sample\n(\"one-shot\") learning of Markov random fields. The $k$-SAT setting we consider\nhere was recently studied by Galanis, Kandiros, and Kalavasis (SODA'24) where\nthey showed that single-sample learning is possible when roughly $d\\leq\n2^{k/6.45}$ and impossible when $d\\geq (k+1) 2^{k-1}$. Crucially, for their\nimpossibility results they used the existence of unsatisfiable instances which,\naside from the gap in $d$, left open the question of whether the feasibility\nthreshold for one-shot learning is dictated by the satisfiability threshold of\n$k$-SAT formulas of bounded degree.\n  Our main contribution is to answer this question negatively. We show that\none-shot learning for $k$-SAT is infeasible well below the satisfiability\nthreshold; in fact, we obtain impossibility results for degrees $d$ as low as\n$k^2$ when $\\beta$ is sufficiently large, and bootstrap this to small values of\n$\\beta$ when $d$ scales exponentially with $k$, via a probabilistic\nconstruction. On the positive side, we simplify the analysis of the learning\nalgorithm and obtain significantly stronger bounds on $d$ in terms of $\\beta$.\nIn particular, for the uniform case $\\beta\\rightarrow 0$ that has been studied\nextensively in the sampling literature, our analysis shows that learning is\npossible under the condition $d\\lesssim 2^{k/2}$. This is nearly optimal (up to\nconstant factors) in the sense that it is known that sampling a\nuniformly-distributed satisfying assignment is NP-hard for $d\\gtrsim 2^{k/2}$.", "AI": {"tldr": "The paper investigates the feasibility of learning the parameter \u03b2 from a single sample in a k-SAT problem, showing that one-shot learning is infeasible well below the satisfiability threshold and providing improved bounds for positive cases.", "motivation": "To determine if the feasibility threshold for one-shot learning in k-SAT is dictated by the satisfiability threshold, addressing gaps left by prior work.", "method": "Uses probabilistic constructions and simplified analysis to establish impossibility results for low degrees and improved bounds for positive cases.", "result": "One-shot learning is infeasible for degrees as low as k\u00b2 for large \u03b2, and possible for d \u2272 2^(k/2) when \u03b2\u21920.", "conclusion": "The feasibility threshold for one-shot learning is not dictated by the satisfiability threshold, and improved bounds are provided for both positive and negative cases."}}
{"id": "2502.12063", "pdf": "https://arxiv.org/pdf/2502.12063", "abs": "https://arxiv.org/abs/2502.12063", "authors": ["Annabelle Michael Carrell", "Albert Gong", "Abhishek Shetty", "Raaz Dwivedi", "Lester Mackey"], "title": "Low-Rank Thinning", "categories": ["stat.ML", "cs.LG", "math.OC", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "The goal in thinning is to summarize a dataset using a small set of\nrepresentative points. Remarkably, sub-Gaussian thinning algorithms like Kernel\nHalving and Compress can match the quality of uniform subsampling while\nsubstantially reducing the number of summary points. However, existing\nguarantees cover only a restricted range of distributions and kernel-based\nquality measures and suffer from pessimistic dimension dependence. To address\nthese deficiencies, we introduce a new low-rank analysis of sub-Gaussian\nthinning that applies to any distribution and any kernel, guaranteeing\nhigh-quality compression whenever the kernel or data matrix is approximately\nlow-rank. To demonstrate the broad applicability of the techniques, we design\npractical sub-Gaussian thinning approaches that improve upon the best known\nguarantees for approximating attention in transformers, accelerating stochastic\ngradient training through reordering, and distinguishing distributions in\nnear-linear time.", "AI": {"tldr": "Sub-Gaussian thinning algorithms like Kernel Halving and Compress outperform uniform subsampling by reducing summary points while maintaining quality. A new low-rank analysis extends applicability to any distribution and kernel, improving guarantees for tasks like transformer attention approximation and gradient training.", "motivation": "Existing thinning algorithms have limited guarantees for distributions and kernels, with poor dimension dependence. The paper aims to address these gaps.", "method": "Introduces a low-rank analysis for sub-Gaussian thinning, applicable to any distribution and kernel, ensuring high-quality compression when kernel or data is low-rank.", "result": "Practical sub-Gaussian thinning methods improve guarantees for transformer attention approximation, gradient training acceleration, and distribution distinction.", "conclusion": "The new low-rank analysis broadens the applicability and effectiveness of sub-Gaussian thinning, enhancing performance in various tasks."}}
{"id": "2502.12152", "pdf": "https://arxiv.org/pdf/2502.12152", "abs": "https://arxiv.org/abs/2502.12152", "authors": ["Xialin He", "Runpei Dong", "Zixuan Chen", "Saurabh Gupta"], "title": "Learning Getting-Up Policies for Real-World Humanoid Robots", "categories": ["cs.RO", "cs.LG"], "comment": "Robotics: Science and Systems (RSS), 2025. Project page:\n  https://humanoid-getup.github.io/", "summary": "Automatic fall recovery is a crucial prerequisite before humanoid robots can\nbe reliably deployed. Hand-designing controllers for getting up is difficult\nbecause of the varied configurations a humanoid can end up in after a fall and\nthe challenging terrains humanoid robots are expected to operate on. This paper\ndevelops a learning framework to produce controllers that enable humanoid\nrobots to get up from varying configurations on varying terrains. Unlike\nprevious successful applications of learning to humanoid locomotion, the\ngetting-up task involves complex contact patterns (which necessitates\naccurately modeling of the collision geometry) and sparser rewards. We address\nthese challenges through a two-phase approach that induces a curriculum. The\nfirst stage focuses on discovering a good getting-up trajectory under minimal\nconstraints on smoothness or speed / torque limits. The second stage then\nrefines the discovered motions into deployable (i.e. smooth and slow) motions\nthat are robust to variations in initial configuration and terrains. We find\nthese innovations enable a real-world G1 humanoid robot to get up from two main\nsituations that we considered: a) lying face up and b) lying face down, both\ntested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grass\nand snowfield). This is one of the first successful demonstrations of learned\ngetting-up policies for human-sized humanoid robots in the real world.", "AI": {"tldr": "A learning framework for humanoid robots to recover from falls on varied terrains, using a two-phase approach to refine motions for real-world deployment.", "motivation": "Hand-designing controllers for fall recovery is challenging due to varied post-fall configurations and terrains.", "method": "A two-phase learning approach: first discovers a recovery trajectory, then refines it for smoothness and robustness.", "result": "Successful real-world demonstrations on a G1 humanoid robot, recovering from lying face up/down on diverse terrains.", "conclusion": "The framework enables robust, learned fall recovery for human-sized humanoids, a significant real-world advancement."}}
{"id": "2502.15024", "pdf": "https://arxiv.org/pdf/2502.15024", "abs": "https://arxiv.org/abs/2502.15024", "authors": ["Jingqiu Ding", "Yiding Hua", "Lucas Slot", "David Steurer"], "title": "Low degree conjecture implies sharp computational thresholds in stochastic block model", "categories": ["cs.CC", "cs.LG", "math.ST", "stat.CO", "stat.TH"], "comment": "33 pages", "summary": "We investigate implications of the (extended) low-degree conjecture (recently\nformalized in [MW23]) in the context of the symmetric stochastic block model.\nAssuming the conjecture holds, we establish that no polynomial-time algorithm\ncan weakly recover community labels below the Kesten-Stigum (KS) threshold. In\nparticular, we rule out polynomial-time estimators that, with constant\nprobability, achieve correlation with the true communities that is\nsignificantly better than random. Whereas, above the KS threshold,\npolynomial-time algorithms are known to achieve constant correlation with the\ntrue communities with high probability[Mas14,AS15].\n  To our knowledge, we provide the first rigorous evidence for the sharp\ntransition in recovery rate for polynomial-time algorithms at the KS threshold.\nNotably, under a stronger version of the low-degree conjecture, our lower bound\nremains valid even when the number of blocks diverges. Furthermore, our results\nprovide evidence of a computational-to-statistical gap in learning the\nparameters of stochastic block models.\n  In contrast to prior work, which either (i) rules out polynomial-time\nalgorithms for hypothesis testing with 1-o(1) success probability [Hopkins18,\nBBK+21a] under the low-degree conjecture, or (ii) rules out low-degree\npolynomials for learning the edge connection probability matrix [LG23], our\napproach provides stronger lower bounds on the recovery and learning problem.\n  Our proof combines low-degree lower bounds from [Hopkins18, BBK+21a] with\ngraph splitting and cross-validation techniques. In order to rule out general\nrecovery algorithms, we employ the correlation preserving projection method\ndeveloped in [HS17].", "AI": {"tldr": "The paper investigates the implications of the extended low-degree conjecture in the symmetric stochastic block model, showing no polynomial-time algorithm can weakly recover community labels below the Kesten-Stigum threshold. Above this threshold, such algorithms succeed.", "motivation": "To provide rigorous evidence for the sharp transition in recovery rates for polynomial-time algorithms at the Kesten-Stigum threshold and explore computational-to-statistical gaps in stochastic block models.", "method": "Combines low-degree lower bounds with graph splitting, cross-validation, and correlation-preserving projection techniques.", "result": "Establishes that polynomial-time algorithms cannot weakly recover communities below the Kesten-Stigum threshold, with stronger bounds under a conjecture variant.", "conclusion": "The work offers the first rigorous evidence of a sharp transition at the KS threshold and highlights computational limitations in recovery and learning problems."}}
{"id": "2502.17482", "pdf": "https://arxiv.org/pdf/2502.17482", "abs": "https://arxiv.org/abs/2502.17482", "authors": ["Ziwei Wang", "Siyang Li", "Xiaoqing Chen", "Wei Li", "Dongrui Wu"], "title": "MVCNet: Multi-View Contrastive Network for Motor Imagery Classification", "categories": ["eess.SP", "cs.LG"], "comment": "12 pages, 8 figures", "summary": "Electroencephalography (EEG)-based brain-computer interfaces (BCIs) enable\nneural interaction by decoding brain activity for external communication. Motor\nimagery (MI) decoding has received significant attention due to its intuitive\nmechanism. However, most existing models rely on single-stream architectures\nand overlook the multi-view nature of EEG signals, leading to limited\nperformance and generalization. We propose a multi-view contrastive network\n(MVCNet), a dual-branch architecture that parallelly integrates CNN and\nTransformer models to capture both local spatial-temporal features and global\ntemporal dependencies. To enhance the informativeness of training data, MVCNet\nincorporates a unified augmentation pipeline across time, frequency, and\nspatial domains. Two contrastive modules are further introduced: a cross-view\ncontrastive module that enforces consistency of original and augmented views,\nand a cross-model contrastive module that aligns features extracted from both\nbranches. Final representations are fused and jointly optimized by contrastive\nand classification losses. Experiments on five public MI datasets across three\nscenarios demonstrate that MVCNet consistently outperforms seven\nstate-of-the-art MI decoding networks, highlighting its effectiveness and\ngeneralization ability. MVCNet provides a robust solution for MI decoding by\nintegrating multi-view information and dual-branch modeling, contributing to\nthe development of more reliable BCI systems.", "AI": {"tldr": "MVCNet, a multi-view contrastive network, improves EEG-based motor imagery decoding by integrating CNN and Transformer models with contrastive learning, outperforming existing methods.", "motivation": "Existing EEG-based BCI models for motor imagery decoding often use single-stream architectures and ignore the multi-view nature of EEG signals, limiting performance and generalization.", "method": "Proposes MVCNet, a dual-branch architecture combining CNN and Transformer models, with unified data augmentation and contrastive modules for cross-view and cross-model alignment.", "result": "Outperforms seven state-of-the-art methods on five public MI datasets across three scenarios, demonstrating superior performance and generalization.", "conclusion": "MVCNet effectively integrates multi-view EEG information and dual-branch modeling, advancing reliable BCI systems."}}
{"id": "2502.18986", "pdf": "https://arxiv.org/pdf/2502.18986", "abs": "https://arxiv.org/abs/2502.18986", "authors": ["Bram van Dartel", "Marc Damie", "Florian Hahn"], "title": "Evaluating Membership Inference Attacks in heterogeneous-data setups", "categories": ["cs.CR", "cs.LG", "I.2.11"], "comment": "Accepted in SiMLA workshop 2025 (co-located with ACNS)", "summary": "Among all privacy attacks against Machine Learning (ML), membership inference\nattacks (MIA) attracted the most attention. In these attacks, the attacker is\ngiven an ML model and a data point, and they must infer whether the data point\nwas used for training. The attacker also has an auxiliary dataset to tune their\ninference algorithm.\n  Attack papers commonly simulate setups in which the attacker's and the\ntarget's datasets are sampled from the same distribution. This setting is\nconvenient to perform experiments, but it rarely holds in practice. ML\nliterature commonly starts with similar simplifying assumptions (i.e., \"i.i.d.\"\ndatasets), and later generalizes the results to support heterogeneous data\ndistributions. Similarly, our work makes a first step in the generalization of\nthe MIA evaluation to heterogeneous data.\n  First, we design a metric to measure the heterogeneity between any pair of\ntabular data distributions. This metric provides a continuous scale to analyze\nthe phenomenon. Second, we compare two methodologies to simulate a data\nheterogeneity between the target and the attacker. These setups provide\nopposite performances: 90% attack accuracy vs. 50% (i.e., random guessing). Our\nresults show that the MIA accuracy depends on the experimental setup; and even\nif research on MIA considers heterogeneous data setups, we have no standardized\nbaseline of how to simulate it. The lack of such a baseline for MIA experiments\nposes a significant challenge to risk assessments in real-world machine\nlearning scenarios.", "AI": {"tldr": "The paper explores membership inference attacks (MIA) in ML, focusing on data heterogeneity between attacker and target datasets, proposing a metric for heterogeneity and comparing simulation setups.", "motivation": "Current MIA research assumes attacker and target datasets are from the same distribution, which is unrealistic. The paper aims to generalize MIA evaluation to heterogeneous data.", "method": "The authors design a metric to measure data heterogeneity and compare two methodologies to simulate heterogeneous data setups.", "result": "Results show MIA accuracy varies significantly (90% vs. 50%) based on the setup, highlighting the need for standardized baselines for heterogeneous data.", "conclusion": "The lack of standardized baselines for MIA experiments complicates real-world risk assessments, emphasizing the need for further research in this direction."}}
{"id": "2504.09310", "pdf": "https://arxiv.org/pdf/2504.09310", "abs": "https://arxiv.org/abs/2504.09310", "authors": ["Osvaldo Simeone", "Sangwoo Park", "Matteo Zecchin"], "title": "Conformal Calibration: Ensuring the Reliability of Black-Box AI in Wireless Systems", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT", "stat.AP"], "comment": "submitted for a journal publication", "summary": "AI is poised to revolutionize telecommunication networks by boosting\nefficiency, automation, and decision-making. However, the black-box nature of\nmost AI models introduces substantial risk, possibly deterring adoption by\nnetwork operators. These risks are not addressed by the current prevailing\ndeployment strategy, which typically follows a best-effort train-and-deploy\nparadigm. This paper reviews conformal calibration, a general framework that\nmoves beyond the state of the art by adopting computationally lightweight,\nadvanced statistical tools that offer formal reliability guarantees without\nrequiring further training or fine-tuning. Conformal calibration encompasses\npre-deployment calibration via uncertainty quantification or hyperparameter\nselection; online monitoring to detect and mitigate failures in real time; and\ncounterfactual post-deployment performance analysis to address \"what if\"\ndiagnostic questions after deployment. By weaving conformal calibration into\nthe AI model lifecycle, network operators can establish confidence in black-box\nAI models as a dependable enabling technology for wireless systems.", "AI": {"tldr": "Conformal calibration enhances AI reliability in telecom networks by providing formal guarantees without retraining, addressing black-box risks.", "motivation": "The black-box nature of AI models in telecom networks poses risks, deterring adoption. Current deployment lacks reliability guarantees.", "method": "Conformal calibration uses lightweight statistical tools for pre-deployment calibration, online monitoring, and post-deployment analysis.", "result": "It offers formal reliability guarantees, boosting confidence in AI models for wireless systems.", "conclusion": "Integrating conformal calibration into the AI lifecycle makes black-box models dependable for telecom networks."}}
{"id": "2504.15512", "pdf": "https://arxiv.org/pdf/2504.15512", "abs": "https://arxiv.org/abs/2504.15512", "authors": ["Siyuan Liang", "Jiayang Liu", "Jiecheng Zhai", "Tianmeng Fang", "Rongcheng Tu", "Aishan Liu", "Xiaochun Cao", "Dacheng Tao"], "title": "T2VShield: Model-Agnostic Jailbreak Defense for Text-to-Video Models", "categories": ["cs.CR", "cs.LG"], "comment": "33 pages, 9 figures", "summary": "The rapid development of generative artificial intelligence has made text to\nvideo models essential for building future multimodal world simulators.\nHowever, these models remain vulnerable to jailbreak attacks, where specially\ncrafted prompts bypass safety mechanisms and lead to the generation of harmful\nor unsafe content. Such vulnerabilities undermine the reliability and security\nof simulation based applications. In this paper, we propose T2VShield, a\ncomprehensive and model agnostic defense framework designed to protect text to\nvideo models from jailbreak threats. Our method systematically analyzes the\ninput, model, and output stages to identify the limitations of existing\ndefenses, including semantic ambiguities in prompts, difficulties in detecting\nmalicious content in dynamic video outputs, and inflexible model centric\nmitigation strategies. T2VShield introduces a prompt rewriting mechanism based\non reasoning and multimodal retrieval to sanitize malicious inputs, along with\na multi scope detection module that captures local and global inconsistencies\nacross time and modalities. The framework does not require access to internal\nmodel parameters and works with both open and closed source systems. Extensive\nexperiments on five platforms show that T2VShield can reduce jailbreak success\nrates by up to 35 percent compared to strong baselines. We further develop a\nhuman centered audiovisual evaluation protocol to assess perceptual safety,\nemphasizing the importance of visual level defense in enhancing the\ntrustworthiness of next generation multimodal simulators.", "AI": {"tldr": "T2VShield is a defense framework for text-to-video models against jailbreak attacks, reducing success rates by up to 35%.", "motivation": "Text-to-video models are vulnerable to jailbreak attacks, threatening reliability and security in multimodal simulations.", "method": "T2VShield uses prompt rewriting and multi-scope detection to sanitize inputs and detect inconsistencies without needing model parameters.", "result": "Experiments show T2VShield reduces jailbreak success rates by up to 35% compared to baselines.", "conclusion": "T2VShield enhances trustworthiness in multimodal simulators by addressing vulnerabilities and improving perceptual safety."}}
{"id": "2504.15632", "pdf": "https://arxiv.org/pdf/2504.15632", "abs": "https://arxiv.org/abs/2504.15632", "authors": ["Seyed Shayan Daneshvar", "Da Tan", "Shaowei Wang", "Carson Leung"], "title": "A Study on Mixup-Inspired Augmentation Methods for Software Vulnerability Detection", "categories": ["cs.SE", "cs.CR", "cs.LG"], "comment": "Accepted at EASE 2025, Istanbul, Turkey", "summary": "Various deep learning (DL) methods have recently been utilized to detect\nsoftware vulnerabilities. Real-world software vulnerability datasets are rare\nand hard to acquire, as there is no simple metric for classifying\nvulnerability. Such datasets are heavily imbalanced, and none of the current\ndatasets are considered huge for DL models. To tackle these problems, a recent\nwork has tried to augment the dataset using the source code and generate\nrealistic single-statement vulnerabilities, which is not quite practical and\nrequires manual checking of the generated vulnerabilities. In this paper, we\naim to explore the augmentation of vulnerabilities at the representation level\nto help current models learn better, which has never been done before to the\nbest of our knowledge. We implement and evaluate five augmentation techniques\nthat augment the embedding of the data and have recently been used for code\nsearch, which is a completely different software engineering task. We also\nintroduced a conditioned version of those augmentation methods, which ensures\nthe augmentation does not change the vulnerable section of the vector\nrepresentation. We show that such augmentation methods can be helpful and\nincrease the F1-score by up to 9.67%, yet they cannot beat Random Oversampling\nwhen balancing datasets, which increases the F1-score by 10.82%.", "AI": {"tldr": "The paper explores embedding-level augmentation techniques for improving DL-based vulnerability detection, showing a 9.67% F1-score boost but not surpassing Random Oversampling's 10.82% improvement.", "motivation": "Real-world vulnerability datasets are rare, imbalanced, and small for DL models, prompting the need for better augmentation methods.", "method": "Five embedding-level augmentation techniques, adapted from code search, are implemented and evaluated, including a conditioned version to preserve vulnerable sections.", "result": "Embedding augmentation improves F1-score by up to 9.67%, but Random Oversampling performs better with a 10.82% increase.", "conclusion": "Representation-level augmentation aids vulnerability detection but is outperformed by traditional balancing methods like Random Oversampling."}}
{"id": "2504.17622", "pdf": "https://arxiv.org/pdf/2504.17622", "abs": "https://arxiv.org/abs/2504.17622", "authors": ["Chen Xu", "Qiang Wang", "Lijun Sun"], "title": "Likelihood-Free Variational Autoencoders", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Variational Autoencoders (VAEs) typically rely on a probabilistic decoder\nwith a predefined likelihood, most commonly an isotropic Gaussian, to model the\ndata conditional on latent variables. While convenient for optimization, this\nchoice often leads to likelihood misspecification, resulting in blurry\nreconstructions and poor data fidelity, especially for high-dimensional data\nsuch as images. In this work, we propose EnVAE, a novel likelihood-free\ngenerative framework that has a deterministic decoder and employs the energy\nscore--a proper scoring rule--to build the reconstruction loss. This enables\nlikelihood-free inference without requiring explicit parametric density\nfunctions. To address the computational inefficiency of the energy score, we\nintroduce a fast variant, FEnVAE, based on the local smoothness of the decoder\nand the sharpness of the posterior distribution of latent variables. This\nyields an efficient single-sample training objective that integrates seamlessly\ninto existing VAE pipelines with minimal overhead. Empirical results on\nstandard benchmarks demonstrate that EnVAE achieves superior reconstruction and\ngeneration quality compared to likelihood-based baselines. Our framework offers\na general, scalable, and statistically principled alternative for flexible and\nnonparametric distribution learning in generative modeling.", "AI": {"tldr": "EnVAE introduces a likelihood-free VAE framework using energy scores for better reconstruction and generation, with a fast variant (FEnVAE) for efficiency.", "motivation": "Traditional VAEs use predefined likelihoods, leading to blurry reconstructions and poor data fidelity, especially for high-dimensional data like images.", "method": "EnVAE replaces the probabilistic decoder with a deterministic one and uses the energy score for reconstruction loss, avoiding explicit parametric density functions. FEnVAE optimizes this with a fast variant based on local smoothness and sharp posterior distributions.", "result": "EnVAE outperforms likelihood-based baselines in reconstruction and generation quality on standard benchmarks.", "conclusion": "EnVAE provides a scalable, principled alternative for flexible, nonparametric distribution learning in generative modeling."}}
