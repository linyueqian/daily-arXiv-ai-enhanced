{"id": "2505.00001", "pdf": "https://arxiv.org/pdf/2505.00001", "abs": "https://arxiv.org/abs/2505.00001", "authors": ["Shaun Baek", "Shaun Esua-Mensah", "Cyrus Tsui", "Sejan Vigneswaralingam", "Abdullah Alali", "Michael Lu", "Vasu Sharma", "Kevin Zhu"], "title": "Rosetta-PL: Propositional Logic as a Benchmark for Large Language Model Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are primarily trained on high-resource natural\nlanguages, limiting their effectiveness in low-resource settings and in tasks\nrequiring deep logical reasoning. This research introduces Rosetta-PL, a\nbenchmark designed to evaluate LLMs' logical reasoning and generalization\ncapabilities in a controlled environment. We construct Rosetta-PL by\ntranslating a dataset of logical propositions from Lean into a custom logical\nlanguage, which is then used to fine-tune an LLM (e.g., GPT-4o). Our\nexperiments analyze the impact of the size of the dataset and the translation\nmethodology on the performance of the model. Our results indicate that\npreserving logical relationships in the translation process significantly\nboosts precision, with accuracy plateauing beyond roughly 20,000 training\nsamples. These insights provide valuable guidelines for optimizing LLM training\nin formal reasoning tasks and improving performance in various low-resource\nlanguage applications.", "AI": {"tldr": "Rosetta-PL benchmark evaluates LLMs' logical reasoning by translating logical propositions into a custom language, showing improved precision with preserved logical relationships and dataset size.", "motivation": "LLMs are limited in low-resource settings and logical reasoning tasks, prompting the need for a specialized benchmark like Rosetta-PL.", "method": "Translate logical propositions from Lean into a custom language, fine-tune an LLM (e.g., GPT-4o), and analyze dataset size and translation impact.", "result": "Preserving logical relationships boosts precision; accuracy plateaus beyond ~20,000 samples.", "conclusion": "Rosetta-PL offers guidelines for optimizing LLM training in formal reasoning and low-resource language tasks."}}
{"id": "2505.00002", "pdf": "https://arxiv.org/pdf/2505.00002", "abs": "https://arxiv.org/abs/2505.00002", "authors": ["Vincent C. M\u00fcller"], "title": "Symbol grounding in computational systems: A paradox of intentions", "categories": ["cs.CL"], "comment": null, "summary": "The paper presents a paradoxical feature of computational systems that\nsuggests that computationalism cannot explain symbol grounding. If the mind is\na digital computer, as computationalism claims, then it can be computing either\nover meaningful symbols or over meaningless symbols. If it is computing over\nmeaningful symbols its functioning presupposes the existence of meaningful\nsymbols in the system, i.e. it implies semantic nativism. If the mind is\ncomputing over meaningless symbols, no intentional cognitive processes are\navailable prior to symbol grounding. In this case, no symbol grounding could\ntake place since any grounding presupposes intentional cognitive processes. So,\nwhether computing in the mind is over meaningless or over meaningful symbols,\ncomputationalism implies semantic nativism.", "AI": {"tldr": "Computationalism's paradox: it implies semantic nativism whether the mind computes over meaningful or meaningless symbols.", "motivation": "To highlight a flaw in computationalism regarding symbol grounding and intentionality.", "method": "Logical analysis of computationalism's assumptions about symbol processing.", "result": "Computationalism leads to semantic nativism in both scenarios of symbol processing.", "conclusion": "Computationalism cannot adequately explain symbol grounding without implying semantic nativism."}}
{"id": "2505.00003", "pdf": "https://arxiv.org/pdf/2505.00003", "abs": "https://arxiv.org/abs/2505.00003", "authors": ["Zizhou Liu", "Ziwei Gong", "Lin Ai", "Zheng Hui", "Run Chen", "Colin Wayne Leach", "Michelle R. Greene", "Julia Hirschberg"], "title": "The Mind in the Machine: A Survey of Incorporating Psychological Theories in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Psychological insights have long shaped pivotal NLP breakthroughs, including\nthe cognitive underpinnings of attention mechanisms, formative reinforcement\nlearning, and Theory of Mind-inspired social modeling. As Large Language Models\n(LLMs) continue to grow in scale and complexity, there is a rising consensus\nthat psychology is essential for capturing human-like cognition, behavior, and\ninteraction. This paper reviews how psychological theories can inform and\nenhance stages of LLM development, including data, pre-training, post-training,\nand evaluation\\&application. Our survey integrates insights from cognitive,\ndevelopmental, behavioral, social, personality psychology, and\npsycholinguistics. Our analysis highlights current trends and gaps in how\npsychological theories are applied. By examining both cross-domain connections\nand points of tension, we aim to bridge disciplinary divides and promote more\nthoughtful integration of psychology into future NLP research.", "AI": {"tldr": "The paper explores how psychological theories can enhance LLM development, covering data, training, and evaluation, while identifying gaps in current applications.", "motivation": "To bridge psychology and NLP by leveraging psychological insights for more human-like LLM cognition and behavior.", "method": "A survey integrating cognitive, developmental, behavioral, social, personality psychology, and psycholinguistics to analyze LLM development stages.", "result": "Identifies trends and gaps in applying psychology to NLP, highlighting cross-domain connections and tensions.", "conclusion": "Advocates for deeper integration of psychology in NLP to improve LLM development and human-like interaction."}}
{"id": "2505.00004", "pdf": "https://arxiv.org/pdf/2505.00004", "abs": "https://arxiv.org/abs/2505.00004", "authors": ["Danilo S. Carvalho", "Yingji Zhang", "Harriet Unsworth", "Andr\u00e9 Freitas"], "title": "LangVAE and LangSpace: Building and Probing for Language Model VAEs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present LangVAE, a novel framework for modular construction of variational\nautoencoders (VAEs) on top of pre-trained large language models (LLMs). Such\nlanguage model VAEs can encode the knowledge of their pre-trained components\ninto more compact and semantically disentangled representations. The\nrepresentations obtained in this way can be analysed with the LangVAE companion\nframework: LangSpace, which implements a collection of probing methods, such as\nvector traversal and interpolation, disentanglement measures, and cluster\nvisualisations. LangVAE and LangSpace offer a flexible, efficient and scalable\nway of building and analysing textual representations, with simple integration\nfor models available on the HuggingFace Hub. Additionally, we conducted a set\nof experiments with different encoder and decoder combinations, as well as\nannotated inputs, revealing a wide range of interactions across architectural\nfamilies and sizes w.r.t. generalisation and disentanglement. Our findings\ndemonstrate a promising framework for systematising the experimentation and\nunderstanding of textual representations.", "AI": {"tldr": "LangVAE is a framework for building VAEs on pre-trained LLMs, enabling compact, semantically disentangled representations. LangSpace analyzes these representations with probing methods. The system is flexible, scalable, and integrates with HuggingFace models. Experiments show its effectiveness in generalization and disentanglement.", "motivation": "To leverage pre-trained LLMs for creating more efficient and interpretable textual representations through VAEs.", "method": "LangVAE constructs VAEs on LLMs, while LangSpace provides probing tools like vector traversal, interpolation, and cluster visualization.", "result": "Experiments reveal effective interactions across architectures, improving generalization and disentanglement.", "conclusion": "LangVAE offers a systematic way to experiment with and understand textual representations."}}
{"id": "2505.00018", "pdf": "https://arxiv.org/pdf/2505.00018", "abs": "https://arxiv.org/abs/2505.00018", "authors": ["Ju Wu", "Calvin K. L. Or"], "title": "Position Paper: Towards Open Complex Human-AI Agents Collaboration System for Problem-Solving and Knowledge Management", "categories": ["cs.AI", "cs.HC", "cs.MA"], "comment": null, "summary": "This position paper critically surveys a broad spectrum of recent empirical\ndevelopments on human-AI agents collaboration, highlighting both their\ntechnical achievements and persistent gaps. We observe a lack of a unifying\ntheoretical framework that can coherently integrate these varied studies,\nespecially when tackling open-ended, complex tasks. To address this, we propose\na novel conceptual architecture: one that systematically interlinks the\ntechnical details of multi-agent coordination, knowledge management, cybernetic\nfeedback loops, and higher-level control mechanisms. By mapping existing\ncontributions, from symbolic AI techniques and connectionist LLM-based agents\nto hybrid organizational practices, onto this proposed framework (Hierarchical\nExploration-Exploitation Net), our approach facilitates revision of legacy\nmethods and inspires new work that fuses qualitative and quantitative\nparadigms. The paper's structure allows it to be read from any section, serving\nequally as a critical review of technical implementations and as a\nforward-looking reference for designing or extending human-AI symbioses.\nTogether, these insights offer a stepping stone toward deeper co-evolution of\nhuman cognition and AI capability.", "AI": {"tldr": "The paper surveys human-AI collaboration, identifies gaps, and proposes a unifying framework (Hierarchical Exploration-Exploitation Net) to integrate diverse studies and inspire future work.", "motivation": "Address the lack of a unifying theoretical framework for human-AI collaboration, especially in complex tasks.", "method": "Proposes a conceptual architecture linking multi-agent coordination, knowledge management, feedback loops, and control mechanisms. Maps existing techniques onto this framework.", "result": "Facilitates revision of legacy methods and inspires new work combining qualitative and quantitative paradigms.", "conclusion": "Offers a foundation for deeper co-evolution of human cognition and AI capability."}}
{"id": "2505.00044", "pdf": "https://arxiv.org/pdf/2505.00044", "abs": "https://arxiv.org/abs/2505.00044", "authors": ["Richard Schmit"], "title": "Learning to Borrow Features for Improved Detection of Small Objects in Single-Shot Detectors", "categories": ["cs.CV", "math.OC"], "comment": null, "summary": "Detecting small objects remains a significant challenge in single-shot object\ndetectors due to the inherent trade-off between spatial resolution and semantic\nrichness in convolutional feature maps. To address this issue, we propose a\nnovel framework that enables small object representations to \"borrow\"\ndiscriminative features from larger, semantically richer instances within the\nsame class. Our architecture introduces three key components: the Feature\nMatching Block (FMB) to identify semantically similar descriptors across\nlayers, the Feature Representing Block (FRB) to generate enhanced shallow\nfeatures through weighted aggregation, and the Feature Fusion Block (FFB) to\nrefine feature maps by integrating original, borrowed, and context information.\nBuilt upon the SSD framework, our method improves the descriptive capacity of\nshallow layers while maintaining real-time detection performance. Experimental\nresults demonstrate that our approach significantly boosts small object\ndetection accuracy over baseline methods, offering a promising direction for\nrobust object detection in complex visual environments.", "AI": {"tldr": "A novel framework improves small object detection by borrowing features from larger instances, using three key blocks (FMB, FRB, FFB) to enhance shallow layers while maintaining real-time performance.", "motivation": "Small object detection is challenging due to the trade-off between spatial resolution and semantic richness in feature maps.", "method": "Proposes a framework with Feature Matching Block (FMB), Feature Representing Block (FRB), and Feature Fusion Block (FFB) to borrow and enhance features from larger instances.", "result": "Significantly improves small object detection accuracy over baseline methods.", "conclusion": "The framework offers a promising direction for robust object detection in complex environments."}}
{"id": "2505.00101", "pdf": "https://arxiv.org/pdf/2505.00101", "abs": "https://arxiv.org/abs/2505.00101", "authors": ["Barak Gahtan", "Sanketh Vedula", "Gil Samuelly Leichtag", "Einat Kodesh", "Alex M. Bronstein"], "title": "From Lab to Wrist: Bridging Metabolic Monitoring and Consumer Wearables for Heart Rate and Oxygen Consumption Modeling", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Understanding physiological responses during running is critical for\nperformance optimization, tailored training prescriptions, and athlete health\nmanagement. We introduce a comprehensive framework -- what we believe to be the\nfirst capable of predicting instantaneous oxygen consumption (VO$_{2}$)\ntrajectories exclusively from consumer-grade wearable data. Our approach\nemploys two complementary physiological models: (1) accurate modeling of heart\nrate (HR) dynamics via a physiologically constrained ordinary differential\nequation (ODE) and neural Kalman filter, trained on over 3 million HR\nobservations, achieving 1-second interval predictions with mean absolute errors\nas low as 2.81\\,bpm (correlation 0.87); and (2) leveraging the principles of\nprecise HR modeling, a novel VO$_{2}$ prediction architecture requiring only\nthe initial second of VO$_{2}$ data for calibration, enabling robust,\nsequence-to-sequence metabolic demand estimation. Despite relying solely on\nsmartwatch and chest-strap data, our method achieves mean absolute percentage\nerrors of approximately 13\\%, effectively capturing rapid physiological\ntransitions and steady-state conditions across diverse running intensities. Our\nsynchronized dataset, complemented by blood lactate measurements, further lays\nthe foundation for future noninvasive metabolic zone identification. By\nembedding physiological constraints within modern machine learning, this\nframework democratizes advanced metabolic monitoring, bridging laboratory-grade\naccuracy and everyday accessibility, thus empowering both elite athletes and\nrecreational fitness enthusiasts.", "AI": {"tldr": "A framework predicts oxygen consumption (VO2) from wearable data using heart rate modeling and a novel VO2 prediction method, achieving high accuracy with minimal calibration.", "motivation": "To optimize performance, tailor training, and manage athlete health by enabling real-time metabolic monitoring with consumer-grade wearables.", "method": "Combines a physiologically constrained ODE and neural Kalman filter for heart rate modeling, and a sequence-to-sequence VO2 prediction architecture requiring minimal initial data.", "result": "Achieves mean absolute errors of 2.81 bpm for heart rate and ~13% for VO2, capturing rapid transitions and steady states.", "conclusion": "The framework bridges lab-grade accuracy with everyday accessibility, benefiting athletes and fitness enthusiasts."}}
{"id": "2505.00056", "pdf": "https://arxiv.org/pdf/2505.00056", "abs": "https://arxiv.org/abs/2505.00056", "authors": ["Tygo Bloem", "Filip Ilievski"], "title": "Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.MM"], "comment": null, "summary": "Meme clustering is critical for toxicity detection, virality modeling, and\ntyping, but it has received little attention in previous research. Clustering\nsimilar Internet memes is challenging due to their multimodality, cultural\ncontext, and adaptability. Existing approaches rely on databases, overlook\nsemantics, and struggle to handle diverse dimensions of similarity. This paper\nintroduces a novel method that uses template-based matching with\nmulti-dimensional similarity features, thus eliminating the need for predefined\ndatabases and supporting adaptive matching. Memes are clustered using local and\nglobal features across similarity categories such as form, visual content,\ntext, and identity. Our combined approach outperforms existing clustering\nmethods, producing more consistent and coherent clusters, while\nsimilarity-based feature sets enable adaptability and align with human\nintuition. We make all supporting code publicly available to support subsequent\nresearch. Code: https://github.com/tygobl/meme-clustering", "AI": {"tldr": "The paper introduces a template-based method for clustering memes using multi-dimensional similarity features, outperforming existing methods and aligning with human intuition.", "motivation": "Meme clustering is crucial for toxicity detection and virality modeling but is understudied due to challenges like multimodality and cultural context. Existing methods lack adaptability and semantic understanding.", "method": "A novel template-based matching approach using local and global features across similarity categories (form, visual content, text, identity) without predefined databases.", "result": "The method outperforms existing clustering techniques, producing more consistent and coherent clusters.", "conclusion": "The approach supports adaptive matching and aligns with human intuition, with code made publicly available for further research."}}
{"id": "2505.00550", "pdf": "https://arxiv.org/pdf/2505.00550", "abs": "https://arxiv.org/abs/2505.00550", "authors": ["Tiange Zhou", "Marco Bidin"], "title": "Bridging Cultural and Digital Divides: A Low-Latency JackTrip Framework for Equitable Music Education in the Global South", "categories": ["cs.SD", "cs.SI"], "comment": null, "summary": "The rapid expansion of digital technologies has transformed educational\nlandscapes worldwide, yet significant infrastructural and cultural challenges\npersist in the Global South. This paper introduces a low-latency JackTrip\nframework designed to bridge both the cultural and digital divides in music\neducation. By leveraging an open-source, UDP-based audio streaming protocol\noriginally developed at Stanford's CCRMA, the framework is tailored to address\ntechnical constraints such as intermittent connectivity, limited bandwidth, and\nhigh latency that characterize many rural and underserved regions. The study\nsystematically compares the performance of JackTrip with conventional platforms\nlike Zoom, demonstrating that JackTrip achieves sub-30~ms latency under\nsimulated low-resource conditions while preserving the intricate audio details\nessential for non-Western musical traditions. Spectral analysis confirms that\nJackTrip's superior handling of microtonal scales, complex rhythms, and\nharmonic textures provides a culturally authentic medium for real-time ensemble\nperformance and music education. These findings underscore the transformative\npotential of decentralized, edge-computing solutions in empowering educators\nand musicians across the Global South, promoting both technological equity and\ncultural preservation.", "AI": {"tldr": "A low-latency JackTrip framework bridges digital and cultural divides in music education for the Global South, outperforming conventional platforms like Zoom under low-resource conditions.", "motivation": "Address infrastructural and cultural challenges in music education in the Global South caused by digital divides and technical constraints.", "method": "Leverages an open-source, UDP-based audio streaming protocol (JackTrip) to handle intermittent connectivity, limited bandwidth, and high latency, comparing its performance with Zoom.", "result": "JackTrip achieves sub-30ms latency and preserves intricate audio details for non-Western music, confirmed by spectral analysis.", "conclusion": "Decentralized, edge-computing solutions like JackTrip can empower educators and musicians, promoting technological equity and cultural preservation."}}
{"id": "2505.00007", "pdf": "https://arxiv.org/pdf/2505.00007", "abs": "https://arxiv.org/abs/2505.00007", "authors": ["Jesuraj Bandekar", "Sathvik Udupa", "Prasanta Kumar Ghosh"], "title": "Discovering phoneme-specific critical articulators through a data-driven approach", "categories": ["eess.AS"], "comment": null, "summary": "We propose an approach for learning critical articulators for phonemes\nthrough a machine learning approach. We formulate the learning with three\nmodels trained end to end. First, we use Acoustic to Articulatory Inversion\n(AAI) to predict time-varying speech articulators EMA. We also predict the\nphoneme-specific weights across articulators for each frame. To avoid\noverfitting, we also add a dropout layer before the weights prediction layer.\nNext, we normalize the predicted weights across articulators using min-max\nnormalization for each frame. The normalized weights are multiplied by the\nground truth $EMA$ and then we try to predict the phones at each frame. We\ntrain this whole setup end to end and use two losses. One loss is for the phone\nprediction which is the cross entropy loss and the other is for the AAI\nprediction which is the mean squared error loss. To maintain gradient flow\nbetween the phone prediction block and the $EMA$ prediction block, we use\nstraight-through estimation. The goal here is to predict the weights of the\narticulator at each frame while training the model end to end.", "AI": {"tldr": "A machine learning approach to learn critical articulators for phonemes using end-to-end training with three models, combining AAI and phoneme prediction with normalized weights and dual losses.", "motivation": "To identify and learn the importance of articulators for phonemes in speech production, enabling better understanding and prediction of speech articulations.", "method": "Uses Acoustic to Articulatory Inversion (AAI) to predict EMA, phoneme-specific weights, and phone prediction with min-max normalization, dropout, and straight-through estimation for gradient flow.", "result": "The model predicts articulator weights and phonemes simultaneously, trained end-to-end with cross-entropy and mean squared error losses.", "conclusion": "The proposed method effectively learns articulator weights for phonemes, combining AAI and phoneme prediction in a unified framework."}}
{"id": "2505.00055", "pdf": "https://arxiv.org/pdf/2505.00055", "abs": "https://arxiv.org/abs/2505.00055", "authors": ["Zhuoqi Zeng", "Yuxiang Wei", "Jiawen Kang"], "title": "TinyMA-IEI-PPO: Exploration Incentive-Driven Multi-Agent DRL with Self-Adaptive Pruning for Vehicular Embodied AI Agent Twins Migration", "categories": ["cs.MA", "cs.GT"], "comment": null, "summary": "Embodied Artificial Intelligence (EAI) addresses autonomous driving\nchallenges in Vehicular Embodied AI Networks (VEANETs) through multi-modal\nperception, adaptive decision-making, and hardware-software co-scheduling.\nHowever, the computational demands of virtual services and the inherent\nmobility of autonomous vehicles (AVs) necessitate real-time migration of\nVehicular Embodied Agent AI Twins (VEAATs) between resource-constrained\nRoadside Units (RSUs). This paper proposes a novel framework for efficient\nVEAAT migration in VEANETs, combining a multi-leader multi-follower (MLMF)\nStackelberg game-theoretic incentive mechanism with a tiny multi-agent deep\nreinforcement learning (MADRL) algorithm. First, We propose an virtual\nimmersive experience-driven utility model that captures AV-RSU dynamic\ninteractions by integrating AVs' social influence, service complementarity and\nsubstitutability, and RSUs' resource allocation strategies to optimize VEAAT\nmigration decisions. Second, to enhance training efficiency and enable\nefficient deployment on computation-constrained AVs while preserving\nexploration-exploitation performance, we propose TinyMA-IEI-PPO, a\nself-adaptive dynamic structured pruning algorithm that dynamically adjusts\nneuron importance based on agents' exploration incentives. Numerical results\ndemonstrate that our approach achieves convergence comparable to baseline\nmodels and closely approximates the Stackelberg equilibrium.", "AI": {"tldr": "The paper proposes a framework for efficient migration of Vehicular Embodied Agent AI Twins (VEAATs) in VEANETs, combining game theory and tiny multi-agent deep reinforcement learning.", "motivation": "Addressing computational demands and mobility challenges in autonomous driving by optimizing VEAAT migration between resource-constrained Roadside Units (RSUs).", "method": "Uses a multi-leader multi-follower Stackelberg game and TinyMA-IEI-PPO, a dynamic pruning algorithm for efficient training and deployment.", "result": "Achieves convergence comparable to baselines and approximates Stackelberg equilibrium.", "conclusion": "The framework effectively optimizes VEAAT migration, balancing computational efficiency and performance."}}
{"id": "2505.00045", "pdf": "https://arxiv.org/pdf/2505.00045", "abs": "https://arxiv.org/abs/2505.00045", "authors": ["Feiran Li", "Haiyang Jiang", "Daisuke Iso"], "title": "Noise Modeling in One Hour: Minimizing Preparation Efforts for Self-supervised Low-Light RAW Image Denoising", "categories": ["eess.IV"], "comment": null, "summary": "Noise synthesis is a promising solution for addressing the data shortage\nproblem in data-driven low-light RAW image denoising. However, accurate noise\nsynthesis methods often necessitate labor-intensive calibration and profiling\nprocedures during preparation, preventing them from landing to practice at\nscale. This work introduces a practically simple noise synthesis pipeline based\non detailed analyses of noise properties and extensive justification of\nwidespread techniques. Compared to other approaches, our proposed pipeline\neliminates the cumbersome system gain calibration and signal-independent noise\nprofiling steps, reducing the preparation time for noise synthesis from days to\nhours. Meanwhile, our method exhibits strong denoising performance, showing an\nup to 0.54dB PSNR improvement over the current state-of-the-art noise synthesis\ntechnique. Code is released at\nhttps://github.com/SonyResearch/raw_image_denoising", "AI": {"tldr": "A simple noise synthesis pipeline for low-light RAW image denoising reduces preparation time from days to hours while improving performance.", "motivation": "Addressing the data shortage problem in low-light RAW image denoising by simplifying noise synthesis.", "method": "Proposes a pipeline eliminating system gain calibration and signal-independent noise profiling.", "result": "Achieves up to 0.54dB PSNR improvement over state-of-the-art methods.", "conclusion": "The method is practical, efficient, and outperforms existing techniques."}}
{"id": "2505.00006", "pdf": "https://arxiv.org/pdf/2505.00006", "abs": "https://arxiv.org/abs/2505.00006", "authors": ["Hayden Helm", "Tianyi Chen", "Harvey McGuinness", "Paige Lee", "Brandon Duderstadt", "Carey E. Priebe"], "title": "Toward a digital twin of U.S. Congress", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "comment": null, "summary": "In this paper we provide evidence that a virtual model of U.S.\ncongresspersons based on a collection of language models satisfies the\ndefinition of a digital twin. In particular, we introduce and provide\nhigh-level descriptions of a daily-updated dataset that contains every Tweet\nfrom every U.S. congressperson during their respective terms. We demonstrate\nthat a modern language model equipped with congressperson-specific subsets of\nthis data are capable of producing Tweets that are largely indistinguishable\nfrom actual Tweets posted by their physical counterparts. We illustrate how\ngenerated Tweets can be used to predict roll-call vote behaviors and to\nquantify the likelihood of congresspersons crossing party lines, thereby\nassisting stakeholders in allocating resources and potentially impacting\nreal-world legislative dynamics. We conclude with a discussion of the\nlimitations and important extensions of our analysis.", "AI": {"tldr": "A virtual model of U.S. congresspersons using language models acts as a digital twin, generating indistinguishable Tweets and predicting voting behaviors.", "motivation": "To demonstrate how language models can replicate congresspersons' online behavior and predict legislative actions, aiding resource allocation.", "method": "Utilizes a daily-updated dataset of Tweets from U.S. congresspersons, training language models on this data to generate and analyze Tweets.", "result": "Generated Tweets are indistinguishable from real ones; models predict roll-call votes and party-line crossing likelihoods.", "conclusion": "The approach has potential but faces limitations; extensions could enhance its real-world legislative impact."}}
{"id": "2505.00173", "pdf": "https://arxiv.org/pdf/2505.00173", "abs": "https://arxiv.org/abs/2505.00173", "authors": ["Isabelle Bloch", "Enzo Bonnot", "Pietro Gori", "Giammarco La Barbera", "Sabine Sarnacki"], "title": "First Order Logic with Fuzzy Semantics for Describing and Recognizing Nerves in Medical Images", "categories": ["cs.AI", "cs.LO", "math.LO"], "comment": "Accepted for presentation at the FUZZ-IEEE 2025 conference", "summary": "This article deals with the description and recognition of fiber bundles, in\nparticular nerves, in medical images, based on the anatomical description of\nthe fiber trajectories. To this end, we propose a logical formalization of this\nanatomical knowledge. The intrinsically imprecise description of nerves, as\nfound in anatomical textbooks, leads us to propose fuzzy semantics combined\nwith first-order logic. We define a language representing spatial entities,\nrelations between these entities and quantifiers. A formula in this language is\nthen a formalization of the natural language description. The semantics are\ngiven by fuzzy representations in a concrete domain and satisfaction degrees of\nrelations. Based on this formalization, a spatial reasoning algorithm is\nproposed for segmentation and recognition of nerves from anatomical and\ndiffusion magnetic resonance images, which is illustrated on pelvic nerves in\npediatric imaging, enabling surgeons to plan surgery.", "AI": {"tldr": "The paper proposes a fuzzy logic-based method for recognizing fiber bundles (nerves) in medical images by formalizing anatomical knowledge and using spatial reasoning for segmentation.", "motivation": "To address the imprecise description of nerves in anatomical textbooks and improve their recognition in medical imaging for surgical planning.", "method": "Combines fuzzy semantics with first-order logic to formalize anatomical knowledge, defines a language for spatial entities and relations, and develops a spatial reasoning algorithm for segmentation.", "result": "Illustrated on pelvic nerves in pediatric imaging, enabling surgeons to plan surgery.", "conclusion": "The proposed method effectively bridges the gap between imprecise anatomical descriptions and precise medical image analysis."}}
{"id": "2505.00134", "pdf": "https://arxiv.org/pdf/2505.00134", "abs": "https://arxiv.org/abs/2505.00134", "authors": ["Vasudev Sharma", "Ahmed Alagha", "Abdelhakim Khellaf", "Vincent Quoc-Huy Trinh", "Mahdi S. Hosseini"], "title": "Investigating Zero-Shot Diagnostic Pathology in Vision-Language Models with Efficient Prompt Design", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) have gained significant attention in\ncomputational pathology due to their multimodal learning capabilities that\nenhance big-data analytics of giga-pixel whole slide image (WSI). However,\ntheir sensitivity to large-scale clinical data, task formulations, and prompt\ndesign remains an open question, particularly in terms of diagnostic accuracy.\nIn this paper, we present a systematic investigation and analysis of three\nstate of the art VLMs for histopathology, namely Quilt-Net, Quilt-LLAVA, and\nCONCH, on an in-house digestive pathology dataset comprising 3,507 WSIs, each\nin giga-pixel form, across distinct tissue types. Through a structured ablative\nstudy on cancer invasiveness and dysplasia status, we develop a comprehensive\nprompt engineering framework that systematically varies domain specificity,\nanatomical precision, instructional framing, and output constraints. Our\nfindings demonstrate that prompt engineering significantly impacts model\nperformance, with the CONCH model achieving the highest accuracy when provided\nwith precise anatomical references. Additionally, we identify the critical\nimportance of anatomical context in histopathological image analysis, as\nperformance consistently degraded when reducing anatomical precision. We also\nshow that model complexity alone does not guarantee superior performance, as\neffective domain alignment and domain-specific training are critical. These\nresults establish foundational guidelines for prompt engineering in\ncomputational pathology and highlight the potential of VLMs to enhance\ndiagnostic accuracy when properly instructed with domain-appropriate prompts.", "AI": {"tldr": "The paper investigates the impact of prompt engineering on vision-language models (VLMs) in computational pathology, finding that precise anatomical references in prompts significantly improve diagnostic accuracy, with CONCH outperforming other models.", "motivation": "To address the sensitivity of VLMs to clinical data, task formulations, and prompt design in histopathology, particularly for diagnostic accuracy.", "method": "A systematic study of three VLMs (Quilt-Net, Quilt-LLAVA, CONCH) on 3,507 WSIs, using structured ablative studies on cancer invasiveness and dysplasia status with varied prompt engineering.", "result": "Prompt engineering greatly affects performance; CONCH excels with precise anatomical references. Anatomical context is crucial, and model complexity alone doesn't ensure better results.", "conclusion": "Effective prompt engineering and domain-specific training are key for VLMs in pathology, with potential to enhance diagnostic accuracy when properly instructed."}}
{"id": "2505.00131", "pdf": "https://arxiv.org/pdf/2505.00131", "abs": "https://arxiv.org/abs/2505.00131", "authors": ["Dalton Durant", "Renato Zanetti"], "title": "Kernel-Based Ensemble Gaussian Mixture Probability Hypothesis Density Filter", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "In this work, a kernel-based Ensemble Gaussian Mixture Probability Hypothesis\nDensity (EnGM-PHD) filter is presented for multi-target filtering applications.\nThe EnGM-PHD filter combines the Gaussian-mixture-based techniques of the\nGaussian Mixture Probability Hypothesis Density (GM-PHD) filter with the\nparticle-based techniques of the Sequential Monte Carlo Probability Hypothesis\nDensity (SMC-PHD) filter. It achieves this by obtaining particles from the\nposterior intensity function, propagating them through the system dynamics, and\nthen using Kernel Density Estimation (KDE) techniques to approximate the\nGaussian mixture of the prior intensity function. This approach guarantees\nconvergence to the true intensity function in the limit of the number of\ncomponents. Moreover, in the special case of a single target with no births,\ndeaths, clutter, and perfect detection probability, the EnGM-PHD filter reduces\nto the standard Ensemble Gaussian Mixture Filter (EnGMF). In the presented\nexperiment, the results indicate that the EnGM-PHD filter achieves better\nmulti-target filtering performance than both the GM-PHD and SMC-PHD filters\nwhile using the same number of components or particles.", "AI": {"tldr": "The paper introduces a kernel-based EnGM-PHD filter for multi-target filtering, combining GM-PHD and SMC-PHD techniques, showing superior performance.", "motivation": "To enhance multi-target filtering by merging Gaussian-mixture and particle-based methods for better accuracy and convergence.", "method": "Uses Kernel Density Estimation (KDE) to approximate Gaussian mixtures from propagated particles, ensuring convergence to the true intensity function.", "result": "The EnGM-PHD filter outperforms GM-PHD and SMC-PHD filters in multi-target filtering with the same component/particle count.", "conclusion": "The EnGM-PHD filter is a robust solution for multi-target filtering, bridging the gap between Gaussian-mixture and particle-based approaches."}}
{"id": "2504.09948", "pdf": "https://arxiv.org/pdf/2504.09948", "abs": "https://arxiv.org/abs/2504.09948", "authors": ["Huijie Liu", "Bingcan Wang", "Jie Hu", "Xiaoming Wei", "Guoliang Kang"], "title": "Omni-Dish: Photorealistic and Faithful Image Generation and Editing for Arbitrary Chinese Dishes", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "10 pages, 10 figures, 3 tables", "summary": "Dish images play a crucial role in the digital era, with the demand for\nculturally distinctive dish images continuously increasing due to the\ndigitization of the food industry and e-commerce. In general cases, existing\ntext-to-image generation models excel in producing high-quality images;\nhowever, they struggle to capture diverse characteristics and faithful details\nof specific domains, particularly Chinese dishes. To address this limitation,\nwe propose Omni-Dish, the first text-to-image generation model specifically\ntailored for Chinese dishes. We develop a comprehensive dish curation pipeline,\nbuilding the largest dish dataset to date. Additionally, we introduce a\nrecaption strategy and employ a coarse-to-fine training scheme to help the\nmodel better learn fine-grained culinary nuances. During inference, we enhance\nthe user's textual input using a pre-constructed high-quality caption library\nand a large language model, enabling more photorealistic and faithful image\ngeneration. Furthermore, to extend our model's capability for dish editing\ntasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish\nediting dataset and train a specialized editing model. Extensive experiments\ndemonstrate the superiority of our methods.", "AI": {"tldr": "Omni-Dish is a text-to-image model for Chinese dishes, addressing the gap in capturing culinary details. It uses a curated dataset, recaptioning, and coarse-to-fine training, plus a dish editing extension called Concept-Enhanced P2P.", "motivation": "Existing text-to-image models lack fidelity for culturally specific dishes like Chinese cuisine, necessitating a specialized solution.", "method": "Developed a dish curation pipeline, recaption strategy, and coarse-to-fine training. Enhanced user input with a caption library and LLM. Extended capabilities with Concept-Enhanced P2P for editing.", "result": "Superior performance in generating photorealistic and faithful Chinese dish images, validated through extensive experiments.", "conclusion": "Omni-Dish effectively addresses domain-specific challenges in dish image generation and editing, setting a new benchmark."}}
{"id": "2505.00579", "pdf": "https://arxiv.org/pdf/2505.00579", "abs": "https://arxiv.org/abs/2505.00579", "authors": ["Hussam Azzuni", "Abdulmotaleb El Saddik"], "title": "Voice Cloning: Comprehensive Survey", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "26 pages, 7 figures", "summary": "Voice Cloning has rapidly advanced in today's digital world, with many\nresearchers and corporations working to improve these algorithms for various\napplications. This article aims to establish a standardized terminology for\nvoice cloning and explore its different variations. It will cover speaker\nadaptation as the fundamental concept and then delve deeper into topics such as\nfew-shot, zero-shot, and multilingual TTS within that context. Finally, we will\nexplore the evaluation metrics commonly used in voice cloning research and\nrelated datasets. This survey compiles the available voice cloning algorithms\nto encourage research toward its generation and detection to limit its misuse.", "AI": {"tldr": "A survey on voice cloning, covering terminology, variations (few-shot, zero-shot, multilingual TTS), evaluation metrics, and datasets, aiming to standardize research and prevent misuse.", "motivation": "To establish standardized terminology and explore voice cloning variations for improved research and application, while addressing misuse concerns.", "method": "Survey of existing voice cloning algorithms, focusing on speaker adaptation, few-shot, zero-shot, and multilingual TTS, along with evaluation metrics and datasets.", "result": "Compilation of voice cloning algorithms and evaluation methods to guide future research and detection efforts.", "conclusion": "Encourages research in voice cloning generation and detection to mitigate misuse, with a focus on standardization and comprehensive evaluation."}}
{"id": "2505.00409", "pdf": "https://arxiv.org/pdf/2505.00409", "abs": "https://arxiv.org/abs/2505.00409", "authors": ["Soroosh Tayebi Arasteh", "Saba Afza", "Tri-Thien Nguyen", "Lukas Buess", "Maryam Parvin", "Tomas Arias-Vergara", "Paula Andrea Perez-Toro", "Hiu Ching Hung", "Mahshad Lotfinia", "Thomas Gorges", "Elmar Noeth", "Maria Schuster", "Seung Hee Yang", "Andreas Maier"], "title": "Perceptual Implications of Automatic Anonymization in Pathological Speech", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": null, "summary": "Automatic anonymization techniques are essential for ethical sharing of\npathological speech data, yet their perceptual consequences remain\nunderstudied. This study presents the first comprehensive human-centered\nanalysis of anonymized pathological speech, using a structured perceptual\nprotocol involving ten native and non-native German listeners with diverse\nlinguistic, clinical, and technical backgrounds. Listeners evaluated\nanonymized-original utterance pairs from 180 speakers spanning Cleft Lip and\nPalate, Dysarthria, Dysglossia, Dysphonia, and age-matched healthy controls.\nSpeech was anonymized using state-of-the-art automatic methods (equal error\nrates in the range of 30-40%). Listeners completed Turing-style discrimination\nand quality rating tasks under zero-shot (single-exposure) and few-shot\n(repeated-exposure) conditions. Discrimination accuracy was high overall (91%\nzero-shot; 93% few-shot), but varied by disorder (repeated-measures ANOVA:\np=0.007), ranging from 96% (Dysarthria) to 86% (Dysphonia). Anonymization\nconsistently reduced perceived quality (from 83% to 59%, p<0.001), with\npathology-specific degradation patterns (one-way ANOVA: p=0.005). Native\nlisteners rated original speech slightly higher than non-native listeners\n(Delta=4%, p=0.199), but this difference nearly disappeared after anonymization\n(Delta=1%, p=0.724). No significant gender-based bias was observed. Critically,\nhuman perceptual outcomes did not correlate with automatic privacy or clinical\nutility metrics. These results underscore the need for listener-informed,\ndisorder- and context-specific anonymization strategies that preserve privacy\nwhile maintaining interpretability, communicative functions, and diagnostic\nutility, especially for vulnerable populations such as children.", "AI": {"tldr": "The study evaluates the perceptual impact of anonymizing pathological speech, revealing high discrimination accuracy but reduced quality, with variations by disorder and listener background.", "motivation": "To understand the human perceptual consequences of anonymizing pathological speech, ensuring ethical data sharing without compromising interpretability or diagnostic utility.", "method": "A structured perceptual protocol with 10 listeners evaluated anonymized-original speech pairs from 180 speakers across various disorders, using Turing-style discrimination and quality rating tasks.", "result": "High discrimination accuracy (91-93%) but reduced perceived quality (83% to 59%), with disorder-specific patterns. No significant gender bias, and minimal native vs. non-native listener differences post-anonymization.", "conclusion": "Listener-informed, disorder-specific anonymization strategies are needed to balance privacy with speech interpretability and clinical utility, especially for vulnerable groups."}}
{"id": "2505.00212", "pdf": "https://arxiv.org/pdf/2505.00212", "abs": "https://arxiv.org/abs/2505.00212", "authors": ["Shaokun Zhang", "Ming Yin", "Jieyu Zhang", "Jiale Liu", "Zhiguang Han", "Jingyang Zhang", "Beibin Li", "Chi Wang", "Huazheng Wang", "Yiran Chen", "Qingyun Wu"], "title": "Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems", "categories": ["cs.MA", "cs.CL"], "comment": null, "summary": "Failure attribution in LLM multi-agent systems-identifying the agent and step\nresponsible for task failures-provides crucial clues for systems debugging but\nremains underexplored and labor-intensive. In this paper, we propose and\nformulate a new research area: automated failure attribution for LLM\nmulti-agent systems. To support this initiative, we introduce the Who&When\ndataset, comprising extensive failure logs from 127 LLM multi-agent systems\nwith fine-grained annotations linking failures to specific agents and decisive\nerror steps. Using the Who&When, we develop and evaluate three automated\nfailure attribution methods, summarizing their corresponding pros and cons. The\nbest method achieves 53.5% accuracy in identifying failure-responsible agents\nbut only 14.2% in pinpointing failure steps, with some methods performing below\nrandom. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to\nachieve practical usability. These results highlight the task's complexity and\nthe need for further research in this area. Code and dataset are available at\nhttps://github.com/mingyin1/Agents_Failure_Attribution", "AI": {"tldr": "The paper introduces automated failure attribution in LLM multi-agent systems, proposing the Who&When dataset and evaluating three methods, with limited success in pinpointing failure steps.", "motivation": "Failure attribution in LLM multi-agent systems is crucial for debugging but is underexplored and labor-intensive.", "method": "The authors propose automated failure attribution, introduce the Who&When dataset, and develop three evaluation methods.", "result": "The best method achieves 53.5% accuracy for identifying agents but only 14.2% for steps, with some methods below random. SOTA models also underperform.", "conclusion": "The task is complex, highlighting the need for further research. Code and dataset are publicly available."}}
{"id": "2505.00046", "pdf": "https://arxiv.org/pdf/2505.00046", "abs": "https://arxiv.org/abs/2505.00046", "authors": ["Taiga Hayami", "Kakeru Koizumi", "Hiroshi Watanabe"], "title": "SR-NeRV: Improving Embedding Efficiency of Neural Video Representation via Super-Resolution", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Implicit Neural Representations (INRs) have garnered significant attention\nfor their ability to model complex signals across a variety of domains.\nRecently, INR-based approaches have emerged as promising frameworks for neural\nvideo compression. While conventional methods primarily focus on embedding\nvideo content into compact neural networks for efficient representation, they\noften struggle to reconstruct high-frequency details under stringent model size\nconstraints, which are critical in practical compression scenarios. To address\nthis limitation, we propose an INR-based video representation method that\nintegrates a general-purpose super-resolution (SR) network. Motivated by the\nobservation that high-frequency components exhibit low temporal redundancy\nacross frames, our method entrusts the reconstruction of fine details to the SR\nnetwork. Experimental results demonstrate that the proposed method outperforms\nconventional INR-based baselines in terms of reconstruction quality, while\nmaintaining comparable model sizes.", "AI": {"tldr": "An INR-based video compression method integrates a super-resolution network to improve high-frequency detail reconstruction, outperforming conventional INR methods while maintaining model size.", "motivation": "Conventional INR-based video compression struggles with high-frequency detail reconstruction under model size constraints, which is critical for practical applications.", "method": "Proposes an INR-based video representation integrating a super-resolution network to handle high-frequency details, leveraging their low temporal redundancy.", "result": "The method outperforms conventional INR-based baselines in reconstruction quality without increasing model size.", "conclusion": "Integrating a super-resolution network with INR improves video compression by better handling high-frequency details."}}
{"id": "2505.00008", "pdf": "https://arxiv.org/pdf/2505.00008", "abs": "https://arxiv.org/abs/2505.00008", "authors": ["Zhaoyi Sun", "Wen-Wai Yim", "Ozlem Uzuner", "Fei Xia", "Meliha Yetisgen"], "title": "A Scoping Review of Natural Language Processing in Addressing Medically Inaccurate Information: Errors, Misinformation, and Hallucination", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Objective: This review aims to explore the potential and challenges of using\nNatural Language Processing (NLP) to detect, correct, and mitigate medically\ninaccurate information, including errors, misinformation, and hallucination. By\nunifying these concepts, the review emphasizes their shared methodological\nfoundations and their distinct implications for healthcare. Our goal is to\nadvance patient safety, improve public health communication, and support the\ndevelopment of more reliable and transparent NLP applications in healthcare.\n  Methods: A scoping review was conducted following PRISMA guidelines,\nanalyzing studies from 2020 to 2024 across five databases. Studies were\nselected based on their use of NLP to address medically inaccurate information\nand were categorized by topic, tasks, document types, datasets, models, and\nevaluation metrics.\n  Results: NLP has shown potential in addressing medically inaccurate\ninformation on the following tasks: (1) error detection (2) error correction\n(3) misinformation detection (4) misinformation correction (5) hallucination\ndetection (6) hallucination mitigation. However, challenges remain with data\nprivacy, context dependency, and evaluation standards.\n  Conclusion: This review highlights the advancements in applying NLP to tackle\nmedically inaccurate information while underscoring the need to address\npersistent challenges. Future efforts should focus on developing real-world\ndatasets, refining contextual methods, and improving hallucination management\nto ensure reliable and transparent healthcare applications.", "AI": {"tldr": "The review explores NLP's role in detecting and correcting medically inaccurate information, highlighting its potential and challenges in healthcare.", "motivation": "To advance patient safety, improve public health communication, and enhance NLP reliability in healthcare.", "method": "A scoping review following PRISMA guidelines, analyzing studies from 2020-2024 across five databases.", "result": "NLP shows promise in tasks like error/misinformation/hallucination detection/correction but faces challenges like data privacy and evaluation standards.", "conclusion": "While NLP has advanced in addressing medical inaccuracies, future work should focus on real-world datasets, contextual methods, and hallucination management."}}
{"id": "2505.00174", "pdf": "https://arxiv.org/pdf/2505.00174", "abs": "https://arxiv.org/abs/2505.00174", "authors": ["Ilan Strauss", "Isobel Moure", "Tim O'Reilly", "Sruly Rosenblat"], "title": "Real-World Gaps in AI Governance Research", "categories": ["cs.AI"], "comment": null, "summary": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI\npapers (January 2020 - March 2025), we compare research outputs of leading AI\ncompanies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI\nuniversities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of\nWashington). We find that corporate AI research increasingly concentrates on\npre-deployment areas -- model alignment and testing & evaluation -- while\nattention to deployment-stage issues such as model bias has waned. Significant\nresearch gaps exist in high-risk deployment domains, including healthcare,\nfinance, misinformation, persuasive and addictive features, hallucinations, and\ncopyright. Without improved observability into deployed AI, growing corporate\nconcentration could deepen knowledge deficits. We recommend expanding external\nresearcher access to deployment data and systematic observability of in-market\nAI behaviors.", "AI": {"tldr": "Corporate AI research focuses on pre-deployment areas like model alignment and testing, while neglecting deployment-stage issues like bias. Gaps exist in high-risk domains, and improved observability is needed.", "motivation": "To compare research outputs of leading AI companies and universities, identifying trends and gaps in AI safety and reliability.", "method": "Analysis of 1,178 safety and reliability papers from 9,439 generative AI papers (2020-2025).", "result": "Corporate research emphasizes pre-deployment (alignment, testing), while deployment-stage issues (bias) are overlooked. Gaps in high-risk domains like healthcare and misinformation.", "conclusion": "Improved observability and external researcher access to deployment data are recommended to address knowledge deficits."}}
{"id": "2505.00135", "pdf": "https://arxiv.org/pdf/2505.00135", "abs": "https://arxiv.org/abs/2505.00135", "authors": ["Michal Geyer", "Omer Tov", "Linyi Jin", "Richard Tucker", "Inbar Mosseri", "Tali Dekel", "Noah Snavely"], "title": "Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "The rising popularity of immersive visual experiences has increased interest\nin stereoscopic 3D video generation. Despite significant advances in video\nsynthesis, creating 3D videos remains challenging due to the relative scarcity\nof 3D video data. We propose a simple approach for transforming a text-to-video\ngenerator into a video-to-stereo generator. Given an input video, our framework\nautomatically produces the video frames from a shifted viewpoint, enabling a\ncompelling 3D effect. Prior and concurrent approaches for this task typically\noperate in multiple phases, first estimating video disparity or depth, then\nwarping the video accordingly to produce a second view, and finally inpainting\nthe disoccluded regions. This approach inherently fails when the scene involves\nspecular surfaces or transparent objects. In such cases, single-layer disparity\nestimation is insufficient, resulting in artifacts and incorrect pixel shifts\nduring warping. Our work bypasses these restrictions by directly synthesizing\nthe new viewpoint, avoiding any intermediate steps. This is achieved by\nleveraging a pre-trained video model's priors on geometry, object materials,\noptics, and semantics, without relying on external geometry models or manually\ndisentangling geometry from the synthesis process. We demonstrate the\nadvantages of our approach in complex, real-world scenarios featuring diverse\nobject materials and compositions. See videos on\nhttps://video-eye2eye.github.io", "AI": {"tldr": "A method to convert text-to-video generators into video-to-stereo generators for 3D effects, bypassing intermediate steps like disparity estimation.", "motivation": "Addressing the challenge of creating 3D videos due to limited 3D data and issues with existing methods involving specular or transparent objects.", "method": "Directly synthesizes new viewpoints using a pre-trained video model's priors, avoiding intermediate steps like disparity estimation or warping.", "result": "Effective 3D video generation in complex scenarios with diverse materials, avoiding artifacts from traditional methods.", "conclusion": "The proposed approach simplifies 3D video generation and handles complex scenes better than multi-phase methods."}}
{"id": "2505.00136", "pdf": "https://arxiv.org/pdf/2505.00136", "abs": "https://arxiv.org/abs/2505.00136", "authors": ["Maksim Helmann", "Alexander Strack", "Dirk Pfl\u00fcger"], "title": "GPRat: Gaussian Process Regression with Asynchronous Tasks", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "13 pages, 7 figures", "summary": "Python is the de-facto language for software development in artificial\nintelligence (AI). Commonly used libraries, such as PyTorch and TensorFlow,\nrely on parallelization built into their BLAS backends to achieve speedup on\nCPUs. However, only applying parallelization in a low-level backend can lead to\nperformance and scaling degradation. In this work, we present a novel way of\nbinding task-based C++ code built on the asynchronous runtime model HPX to a\nhigh-level Python API using pybind11. We develop a parallel Gaussian process\n(GP) li- brary as an application. The resulting Python library GPRat combines\nthe ease of use of commonly available GP libraries with the performance and\nscalability of asynchronous runtime systems. We evaluate the per- formance on a\nmass-spring-damper system, a standard benchmark from control theory, for\nvarying numbers of regressors (features). The results show almost no binding\noverhead when binding the asynchronous HPX code using pybind11. Compared to\nGPyTorch and GPflow, GPRat shows superior scaling on up to 64 cores on an AMD\nEPYC 7742 CPU for train- ing. Furthermore, our library achieves a prediction\nspeedup of 7.63 over GPyTorch and 25.25 over GPflow. If we increase the number\nof features from eight to 128, we observe speedups of 29.62 and 21.19,\nrespectively. These results showcase the potential of using asynchronous tasks\nwithin Python-based AI applications.", "AI": {"tldr": "The paper introduces GPRat, a Python library for Gaussian processes, combining HPX's asynchronous runtime with pybind11 for high performance and scalability, outperforming GPyTorch and GPflow.", "motivation": "Python's reliance on low-level parallelization in AI libraries like PyTorch and TensorFlow can degrade performance. The work aims to integrate task-based C++ code (HPX) with Python for better scalability.", "method": "The authors bind HPX's asynchronous runtime to Python using pybind11, developing GPRat, a parallel Gaussian process library. Performance is evaluated on a control theory benchmark.", "result": "GPRat shows minimal binding overhead, superior scaling up to 64 cores, and significant speedups (7.63x over GPyTorch, 25.25x over GPflow). Speedups increase with more features.", "conclusion": "Asynchronous task-based approaches in Python-based AI applications, as demonstrated by GPRat, offer substantial performance and scalability benefits."}}
{"id": "2505.00059", "pdf": "https://arxiv.org/pdf/2505.00059", "abs": "https://arxiv.org/abs/2505.00059", "authors": ["Paige Tutt\u00f6s\u00ed", "Mantaj Dhillon", "Luna Sang", "Shane Eastwood", "Poorvi Bhatia", "Quang Minh Dinh", "Avni Kapoor", "Yewon Jin", "Angelica Lim"], "title": "BERSting at the Screams: A Benchmark for Distanced, Emotional and Shouted Speech Recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to Computer Speech and Language, Special issue:\n  Multi-Speaker, Multi-Microphone, and Multi-Modal Distant Speech Recognition\n  (September 2025)", "summary": "Some speech recognition tasks, such as automatic speech recognition (ASR),\nare approaching or have reached human performance in many reported metrics.\nYet, they continue to struggle in complex, real-world, situations, such as with\ndistanced speech. Previous challenges have released datasets to address the\nissue of distanced ASR, however, the focus remains primarily on distance,\nspecifically relying on multi-microphone array systems. Here we present the\nB(asic) E(motion) R(andom phrase) S(hou)t(s) (BERSt) dataset. The dataset\ncontains almost 4 hours of English speech from 98 actors with varying regional\nand non-native accents. The data was collected on smartphones in the actors\nhomes and therefore includes at least 98 different acoustic environments. The\ndata also includes 7 different emotion prompts and both shouted and spoken\nutterances. The smartphones were places in 19 different positions, including\nobstructions and being in a different room than the actor. This data is\npublicly available for use and can be used to evaluate a variety of speech\nrecognition tasks, including: ASR, shout detection, and speech emotion\nrecognition (SER). We provide initial benchmarks for ASR and SER tasks, and\nfind that ASR degrades both with an increase in distance and shout level and\nshows varied performance depending on the intended emotion. Our results show\nthat the BERSt dataset is challenging for both ASR and SER tasks and continued\nwork is needed to improve the robustness of such systems for more accurate\nreal-world use.", "AI": {"tldr": "The BERSt dataset addresses real-world challenges in speech recognition by providing diverse, distanced, and emotional speech data collected in varied acoustic environments.", "motivation": "Current ASR systems struggle with complex real-world scenarios like distanced speech and emotional variations, despite high performance in controlled settings.", "method": "The BERSt dataset includes 4 hours of English speech from 98 actors with diverse accents, collected via smartphones in various home environments, with 7 emotion prompts and shouted/spoken utterances.", "result": "ASR performance degrades with increased distance and shout level, and varies by emotion, highlighting the dataset's challenge for ASR and SER tasks.", "conclusion": "The BERSt dataset is a valuable resource for improving ASR and SER robustness, but further work is needed for real-world accuracy."}}
{"id": "2505.00540", "pdf": "https://arxiv.org/pdf/2505.00540", "abs": "https://arxiv.org/abs/2505.00540", "authors": ["Ian O'Flynn", "Harun \u0160iljak"], "title": "Emergence of Roles in Robotic Teams with Model Sharing and Limited Communication", "categories": ["cs.MA", "cs.LG", "cs.RO", "cs.SY", "eess.SY"], "comment": "Accepted for 2025 8th International Balkan Conference on\n  Communications and Networking (Balkancom)", "summary": "We present a reinforcement learning strategy for use in multi-agent foraging\nsystems in which the learning is centralised to a single agent and its model is\nperiodically disseminated among the population of non-learning agents. In a\ndomain where multi-agent reinforcement learning (MARL) is the common approach,\nthis approach aims to significantly reduce the computational and energy demands\ncompared to approaches such as MARL and centralised learning models. By\ndeveloping high performing foraging agents, these approaches can be translated\ninto real-world applications such as logistics, environmental monitoring, and\nautonomous exploration. A reward function was incorporated into this approach\nthat promotes role development among agents, without explicit directives. This\nled to the differentiation of behaviours among the agents. The implicit\nencouragement of role differentiation allows for dynamic actions in which\nagents can alter roles dependent on their interactions with the environment\nwithout the need for explicit communication between agents.", "AI": {"tldr": "A centralized reinforcement learning strategy for multi-agent foraging reduces computational demands compared to MARL, promoting role differentiation without explicit communication.", "motivation": "To address high computational and energy demands in multi-agent reinforcement learning (MARL) by centralizing learning in one agent and disseminating its model to others.", "method": "A single agent learns centrally, and its model is periodically shared with non-learning agents. A reward function encourages implicit role differentiation.", "result": "Agents developed differentiated behaviors dynamically without explicit communication, adapting roles based on environmental interactions.", "conclusion": "The approach efficiently reduces computational costs while enabling flexible role adaptation, applicable to logistics, monitoring, and exploration."}}
{"id": "2505.00115", "pdf": "https://arxiv.org/pdf/2505.00115", "abs": "https://arxiv.org/abs/2505.00115", "authors": ["Sandrine B\u00e9dard", "Jan Valo\u0161ek", "Valeria Oliva", "Kenneth A. Weber II", "Julien Cohen-Adad"], "title": "Rootlets-based registration to the spinal cord PAM50 template", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Spinal cord functional MRI studies require precise localization of spinal\nlevels for reliable voxelwise group analyses. Traditional template-based\nregistration of the spinal cord uses intervertebral discs for alignment.\nHowever, substantial anatomical variability across individuals exists between\nvertebral and spinal levels. This study proposes a novel registration approach\nthat leverages spinal nerve rootlets to improve alignment accuracy and\nreproducibility across individuals. We developed a registration method\nleveraging dorsal cervical rootlets segmentation and aligning them non-linearly\nwith the PAM50 spinal cord template. Validation was performed on a\nmulti-subject, multi-site dataset (n=267, 44 sites) and a multi-subject dataset\nwith various neck positions (n=10, 3 sessions). We further validated the method\non task-based functional MRI (n=23) to compare group-level activation maps\nusing rootlet-based registration to traditional disc-based methods.\nRootlet-based registration showed superior alignment across individuals\ncompared to the traditional disc-based method. Notably, rootlet positions were\nmore stable across neck positions. Group-level analysis of task-based\nfunctional MRI using rootlet-based increased Z scores and activation cluster\nsize compared to disc-based registration (number of active voxels from 3292 to\n7978). Rootlet-based registration enhances both inter- and intra-subject\nanatomical alignment and yields better spatial normalization for group-level\nfMRI analyses. Our findings highlight the potential of rootlet-based\nregistration to improve the precision and reliability of spinal cord\nneuroimaging group analysis.", "AI": {"tldr": "A novel spinal cord registration method using spinal nerve rootlets improves alignment accuracy and reproducibility over traditional disc-based methods, enhancing fMRI group analysis.", "motivation": "Traditional disc-based spinal cord registration lacks precision due to anatomical variability between vertebral and spinal levels.", "method": "Proposes a rootlet-based registration method using dorsal cervical rootlets segmentation and non-linear alignment with the PAM50 template, validated on multi-subject datasets.", "result": "Rootlet-based registration outperformed disc-based methods in alignment accuracy, stability across neck positions, and improved fMRI activation detection (active voxels increased from 3292 to 7978).", "conclusion": "Rootlet-based registration enhances spinal cord neuroimaging precision and reliability for group analyses."}}
{"id": "2505.00009", "pdf": "https://arxiv.org/pdf/2505.00009", "abs": "https://arxiv.org/abs/2505.00009", "authors": ["Xiao Zhang", "Kangsheng Wang", "Tianyu Hu", "Huimin Ma"], "title": "Efficient Knowledge Transfer in Multi-Task Learning through Task-Adaptive Low-Rank Representation", "categories": ["cs.CL"], "comment": "Accepted by IEEE International Conference on Multimedia & Expo 2025", "summary": "Pre-trained language models (PLMs) demonstrate remarkable intelligence but\nstruggle with emerging tasks unseen during training in real-world applications.\nTraining separate models for each new task is usually impractical. Multi-task\nlearning (MTL) addresses this challenge by transferring shared knowledge from\nsource tasks to target tasks. As an dominant parameter-efficient fine-tuning\nmethod, prompt tuning (PT) enhances MTL by introducing an adaptable vector that\ncaptures task-specific knowledge, which acts as a prefix to the original prompt\nthat preserves shared knowledge, while keeping PLM parameters frozen. However,\nPT struggles to effectively capture the heterogeneity of task-specific\nknowledge due to its limited representational capacity. To address this\nchallenge, we propose Task-Adaptive Low-Rank Representation (TA-LoRA), an MTL\nmethod built on PT, employing the low-rank representation to model task\nheterogeneity and a fast-slow weights mechanism where the slow weight encodes\nshared knowledge, while the fast weight captures task-specific nuances,\navoiding the mixing of shared and task-specific knowledge, caused by training\nlow-rank representations from scratch. Moreover, a zero-initialized attention\nmechanism is introduced to minimize the disruption of immature low-rank\ncomponents on original prompts during warm-up epochs. Experiments on 16 tasks\ndemonstrate that TA-LoRA achieves state-of-the-art performance in full-data and\nfew-shot settings while maintaining superior parameter efficiency.", "AI": {"tldr": "TA-LoRA improves multi-task learning by using low-rank representations and a fast-slow weights mechanism to better capture task-specific knowledge without disrupting shared knowledge.", "motivation": "Pre-trained language models struggle with unseen tasks, and existing methods like prompt tuning fail to adequately handle task heterogeneity.", "method": "TA-LoRA combines low-rank representation for task heterogeneity, fast-slow weights to separate shared and task-specific knowledge, and zero-initialized attention to minimize disruption during warm-up.", "result": "TA-LoRA achieves state-of-the-art performance on 16 tasks in full-data and few-shot settings while maintaining parameter efficiency.", "conclusion": "TA-LoRA effectively addresses the limitations of prompt tuning, offering a robust solution for multi-task learning with pre-trained models."}}
{"id": "2505.00204", "pdf": "https://arxiv.org/pdf/2505.00204", "abs": "https://arxiv.org/abs/2505.00204", "authors": ["Sumit Verma", "Pritam Prasun", "Arpit Jaiswal", "Pritish Kumar"], "title": "RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset", "categories": ["cs.AI"], "comment": null, "summary": "As AI systems become embedded in real-world applications, ensuring they meet\nethical standards is crucial. While existing AI ethics frameworks emphasize\nfairness, transparency, and accountability, they often lack actionable\nevaluation methods. This paper introduces a systematic approach using the\nResponsible AI Labs (RAIL) framework, which includes eight measurable\ndimensions to assess the normative behavior of large language models (LLMs). We\napply this framework to Anthropic's \"Values in the Wild\" dataset, containing\nover 308,000 anonymized conversations with Claude and more than 3,000 annotated\nvalue expressions. Our study maps these values to RAIL dimensions, computes\nsynthetic scores, and provides insights into the ethical behavior of LLMs in\nreal-world use.", "AI": {"tldr": "The paper introduces the RAIL framework to evaluate ethical behavior in LLMs, applying it to a dataset of 308,000 conversations to assess normative behavior.", "motivation": "Existing AI ethics frameworks lack actionable evaluation methods, prompting the need for a systematic approach like RAIL.", "method": "Uses the RAIL framework with eight measurable dimensions to assess LLMs, applied to the 'Values in the Wild' dataset.", "result": "Maps values to RAIL dimensions, computes synthetic scores, and provides insights into LLM ethical behavior.", "conclusion": "The RAIL framework offers a practical method to evaluate and improve the ethical standards of LLMs in real-world applications."}}
{"id": "2505.00150", "pdf": "https://arxiv.org/pdf/2505.00150", "abs": "https://arxiv.org/abs/2505.00150", "authors": ["Minh-Hao Van", "Xintao Wu"], "title": "Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The rapid evolution of social media has provided enhanced communication\nchannels for individuals to create online content, enabling them to express\ntheir thoughts and opinions. Multimodal memes, often utilized for playful or\nhumorous expressions with visual and textual elements, are sometimes misused to\ndisseminate hate speech against individuals or groups. While the detection of\nhateful memes is well-researched, developing effective methods to transform\nhateful content in memes remains a significant challenge. Leveraging the\npowerful generation and reasoning capabilities of Vision-Language Models\n(VLMs), we address the tasks of detecting and mitigating hateful content. This\npaper presents two key contributions: first, a definition-guided prompting\ntechnique for detecting hateful memes, and second, a unified framework for\nmitigating hateful content in memes, named UnHateMeme, which works by replacing\nhateful textual and/or visual components. With our definition-guided prompts,\nVLMs achieve impressive performance on hateful memes detection task.\nFurthermore, our UnHateMeme framework, integrated with VLMs, demonstrates a\nstrong capability to convert hateful memes into non-hateful forms that meet\nhuman-level criteria for hate speech and maintain multimodal coherence between\nimage and text. Through empirical experiments, we show the effectiveness of\nstate-of-the-art pretrained VLMs such as LLaVA, Gemini and GPT-4o on the\nproposed tasks, providing a comprehensive analysis of their respective\nstrengths and limitations for these tasks. This paper aims to shed light on\nimportant applications of VLMs for ensuring safe and respectful online\nenvironments.", "AI": {"tldr": "The paper introduces a method for detecting and mitigating hateful content in multimodal memes using Vision-Language Models (VLMs). It proposes a definition-guided prompting technique for detection and a framework, UnHateMeme, for transforming hateful memes into non-hateful forms.", "motivation": "The misuse of memes for hate speech necessitates effective methods for detection and mitigation, leveraging VLMs to ensure safer online communication.", "method": "Uses definition-guided prompts for hateful meme detection and the UnHateMeme framework to replace hateful components while maintaining coherence.", "result": "VLMs achieve strong performance in detection, and UnHateMeme effectively converts hateful memes into non-hateful forms, validated by human criteria.", "conclusion": "The work highlights VLMs' potential for fostering respectful online environments, with practical applications for meme moderation."}}
{"id": "2505.00162", "pdf": "https://arxiv.org/pdf/2505.00162", "abs": "https://arxiv.org/abs/2505.00162", "authors": ["Nuojin Cheng", "Alireza Doostan", "Stephen Becker"], "title": "Stochastic Subspace Descent Accelerated via Bi-fidelity Line Search", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Efficient optimization remains a fundamental challenge across numerous\nscientific and engineering domains, especially when objective function and\ngradient evaluations are computationally expensive. While zeroth-order\noptimization methods offer effective approaches when gradients are\ninaccessible, their practical performance can be limited by the high cost\nassociated with function queries. This work introduces the bi-fidelity\nstochastic subspace descent (BF-SSD) algorithm, a novel zeroth-order\noptimization method designed to reduce this computational burden. BF-SSD\nleverages a bi-fidelity framework, constructing a surrogate model from a\ncombination of computationally inexpensive low-fidelity (LF) and accurate\nhigh-fidelity (HF) function evaluations. This surrogate model facilitates an\nefficient backtracking line search for step size selection, for which we\nprovide theoretical convergence guarantees under standard assumptions. We\nperform a comprehensive empirical evaluation of BF-SSD across four distinct\nproblems: a synthetic optimization benchmark, dual-form kernel ridge\nregression, black-box adversarial attacks on machine learning models, and\ntransformer-based black-box language model fine-tuning. Numerical results\ndemonstrate that BF-SSD consistently achieves superior optimization performance\nwhile requiring significantly fewer HF function evaluations compared to\nrelevant baseline methods. This study highlights the efficacy of integrating\nbi-fidelity strategies within zeroth-order optimization, positioning BF-SSD as\na promising and computationally efficient approach for tackling large-scale,\nhigh-dimensional problems encountered in various real-world applications.", "AI": {"tldr": "BF-SSD is a novel zeroth-order optimization method using bi-fidelity evaluations to reduce computational costs, outperforming baselines with fewer high-fidelity evaluations.", "motivation": "Addressing the challenge of expensive function evaluations in optimization, especially when gradients are unavailable.", "method": "BF-SSD combines low-fidelity and high-fidelity evaluations to build a surrogate model for efficient backtracking line search.", "result": "BF-SSD achieves superior performance with fewer high-fidelity evaluations across synthetic and real-world problems.", "conclusion": "BF-SSD is an efficient, scalable solution for high-dimensional optimization problems, leveraging bi-fidelity strategies."}}
{"id": "2505.00368", "pdf": "https://arxiv.org/pdf/2505.00368", "abs": "https://arxiv.org/abs/2505.00368", "authors": ["Ahmed R. Sadik", "Muhammad Ashfaq", "Niko M\u00e4kitalo", "Tommi Mikkonen"], "title": "Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach", "categories": ["cs.AI", "cs.ET", "cs.MA", "cs.RO"], "comment": null, "summary": "Urban Air Mobility (UAM) is an emerging System of System (SoS) that faces\nchallenges in system architecture, planning, task management, and execution.\nTraditional architectural approaches struggle with scalability, adaptability,\nand seamless resource integration within dynamic and complex environments. This\npaper presents an intelligent holonic architecture that incorporates Large\nLanguage Model (LLM) to manage the complexities of UAM. Holons function semi\nautonomously, allowing for real time coordination among air taxis, ground\ntransport, and vertiports. LLMs process natural language inputs, generate\nadaptive plans, and manage disruptions such as weather changes or airspace\nclosures.Through a case study of multimodal transportation with electric\nscooters and air taxis, we demonstrate how this architecture enables dynamic\nresource allocation, real time replanning, and autonomous adaptation without\ncentralized control, creating more resilient and efficient urban transportation\nnetworks. By advancing decentralized control and AI driven adaptability, this\nwork lays the groundwork for resilient, human centric UAM ecosystems, with\nfuture efforts targeting hybrid AI integration and real world validation.", "AI": {"tldr": "The paper proposes an intelligent holonic architecture using LLMs to address scalability and adaptability challenges in Urban Air Mobility (UAM), demonstrating its effectiveness in dynamic resource allocation and real-time replanning.", "motivation": "Traditional approaches to UAM struggle with scalability, adaptability, and resource integration in complex environments, necessitating a more resilient and efficient solution.", "method": "An intelligent holonic architecture incorporating LLMs is introduced, enabling semi-autonomous holons to coordinate air taxis, ground transport, and vertiports while processing natural language inputs and managing disruptions.", "result": "A case study shows dynamic resource allocation, real-time replanning, and autonomous adaptation, proving the architecture's resilience and efficiency in multimodal transportation.", "conclusion": "The work advances decentralized control and AI-driven adaptability, laying the foundation for resilient UAM ecosystems, with future goals including hybrid AI integration and real-world validation."}}
{"id": "2505.00122", "pdf": "https://arxiv.org/pdf/2505.00122", "abs": "https://arxiv.org/abs/2505.00122", "authors": ["Zhenduo Shang", "Thomas Blumensath"], "title": "Stereo X-ray tomography on deformed object tracking", "categories": ["eess.IV"], "comment": null, "summary": "X-ray computed tomography is a powerful tool for volumetric imaging, but\nrequires the collection of a large number of low-noise projection images, which\nis often too time consuming, limiting its applicability. In our previous work\n\\cite{shang2023stereo}, we proposed a stereo X-ray tomography system to map the\n3D position of fiducial markers using only two projections of a static volume.\nIn dynamic imaging settings, where objects undergo deformations during imaging,\nthis static method can be extended by utilizing additional temporal\ninformation. We thus extend the method to track the deformation of fiducial\nmarkers in 3D space, where we use knowledge of the initial object shape as\nprior information, improving the prediction of the evolution of its deformed\nstate over time. In particular, knowledge of the initial object's stereo\nprojections is shown to improve the method's robustness to noise when detecting\nfiducial marker locations in the projections of the deformed objects.\nFurthermore, after feature detection, by using the features' initial 3D\nposition information in the undeformed object, we can also demonstrate\nimprovements in the 3D mapping of the deformed features. Using a range of\ndeformed 3D objects, this new approach is shown to be able to track fiducial\nmarkers in noisy stereo tomography images with subpixel accuracy.", "AI": {"tldr": "Extends stereo X-ray tomography to track 3D deformations of fiducial markers using initial shape priors, improving noise robustness and accuracy.", "motivation": "Overcome time constraints and noise sensitivity in dynamic X-ray tomography by leveraging prior knowledge of initial object shape.", "method": "Extends static stereo X-ray tomography with temporal data, using initial stereo projections and 3D positions to track deformations.", "result": "Achieves subpixel accuracy in tracking fiducial markers in noisy stereo images, with improved 3D mapping of deformed features.", "conclusion": "The method enhances dynamic tomography by efficiently tracking deformations using prior information, proving robust against noise."}}
{"id": "2505.00010", "pdf": "https://arxiv.org/pdf/2505.00010", "abs": "https://arxiv.org/abs/2505.00010", "authors": ["Tri Nguyen", "Lohith Srikanth Pentapalli", "Magnus Sieverding", "Laurah Turner", "Seth Overla", "Weibing Zheng", "Chris Zhou", "David Furniss", "Danielle Weber", "Michael Gharib", "Matt Kelleher", "Michael Shukis", "Cameron Pawlik", "Kelly Cohen"], "title": "Jailbreak Detection in Clinical Training LLMs Using Feature-Based Predictive Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Jailbreaking in Large Language Models (LLMs) threatens their safe use in\nsensitive domains like education by allowing users to bypass ethical\nsafeguards. This study focuses on detecting jailbreaks in 2-Sigma, a clinical\neducation platform that simulates patient interactions using LLMs. We annotated\nover 2,300 prompts across 158 conversations using four linguistic variables\nshown to correlate strongly with jailbreak behavior. The extracted features\nwere used to train several predictive models, including Decision Trees, Fuzzy\nLogic-based classifiers, Boosting methods, and Logistic Regression. Results\nshow that feature-based predictive models consistently outperformed Prompt\nEngineering, with the Fuzzy Decision Tree achieving the best overall\nperformance. Our findings demonstrate that linguistic-feature-based models are\neffective and explainable alternatives for jailbreak detection. We suggest\nfuture work explore hybrid frameworks that integrate prompt-based flexibility\nwith rule-based robustness for real-time, spectrum-based jailbreak monitoring\nin educational LLMs.", "AI": {"tldr": "The study detects jailbreaks in LLMs used in clinical education by analyzing linguistic features, showing that feature-based models outperform prompt engineering, with Fuzzy Decision Trees performing best.", "motivation": "Jailbreaking in LLMs threatens ethical safeguards, especially in sensitive domains like education, necessitating effective detection methods.", "method": "Annotated 2,300 prompts across 158 conversations using four linguistic variables, trained predictive models (Decision Trees, Fuzzy Logic, Boosting, Logistic Regression).", "result": "Feature-based models outperformed Prompt Engineering; Fuzzy Decision Tree achieved the best performance.", "conclusion": "Linguistic-feature-based models are effective and explainable for jailbreak detection; hybrid frameworks are suggested for future work."}}
{"id": "2505.00278", "pdf": "https://arxiv.org/pdf/2505.00278", "abs": "https://arxiv.org/abs/2505.00278", "authors": ["Lo Pang-Yun Ting", "Yu-Hao Chiang", "Yi-Tung Tsai", "Hsu-Chao Lai", "Kun-Ta Chuang"], "title": "DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing", "categories": ["cs.AI"], "comment": null, "summary": "In the semiconductor industry, integrated circuit (IC) processes play a vital\nrole, as the rising complexity and market expectations necessitate improvements\nin yield. Identifying IC defects and assigning IC testing tasks to the right\nengineers improves efficiency and reduces losses. While current studies\nemphasize fault localization or defect classification, they overlook the\nintegration of defect characteristics, historical failures, and the insights\nfrom engineer expertise, which restrains their effectiveness in improving IC\nhandling. To leverage AI for these challenges, we propose DeCo, an innovative\napproach for optimizing task assignment in IC testing. DeCo constructs a novel\ndefect-aware graph from IC testing reports, capturing co-failure relationships\nto enhance defect differentiation, even with scarce defect data. Additionally,\nit formulates defect-aware representations for engineers and tasks, reinforced\nby local and global structure modeling on the defect-aware graph. Finally, a\ncontrasting-based assignment mechanism pairs testing tasks with QA engineers by\nconsidering their skill level and current workload, thus promoting an equitable\nand efficient job dispatch. Experiments on a real-world dataset demonstrate\nthat DeCo achieves the highest task-handling success rates in different\nscenarios, exceeding 80\\%, while also maintaining balanced workloads on both\nscarce or expanded defect data. Moreover, case studies reveal that DeCo can\nassign tasks to potentially capable engineers, even for their unfamiliar\ndefects, highlighting its potential as an AI-driven solution for the real-world\nIC failure analysis and task handling.", "AI": {"tldr": "DeCo is an AI-driven approach for optimizing IC testing task assignment by leveraging defect-aware graphs and engineer expertise, achieving high success rates and balanced workloads.", "motivation": "Current methods lack integration of defect characteristics, historical failures, and engineer insights, limiting IC handling efficiency.", "method": "DeCo constructs defect-aware graphs, models engineer-task representations, and uses a contrasting-based assignment mechanism.", "result": "DeCo achieves >80% task-handling success rates and balanced workloads, even with scarce defect data.", "conclusion": "DeCo is a promising AI solution for real-world IC failure analysis and task handling."}}
{"id": "2505.00156", "pdf": "https://arxiv.org/pdf/2505.00156", "abs": "https://arxiv.org/abs/2505.00156", "authors": ["Jannik L\u00fcbberstedt", "Esteban Rivera", "Nico Uhlemann", "Markus Lienkamp"], "title": "V3LMA: Visual 3D-enhanced Language Model for Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "Large Vision Language Models (LVLMs) have shown strong capabilities in\nunderstanding and analyzing visual scenes across various domains. However, in\nthe context of autonomous driving, their limited comprehension of 3D\nenvironments restricts their effectiveness in achieving a complete and safe\nunderstanding of dynamic surroundings. To address this, we introduce V3LMA, a\nnovel approach that enhances 3D scene understanding by integrating Large\nLanguage Models (LLMs) with LVLMs. V3LMA leverages textual descriptions\ngenerated from object detections and video inputs, significantly boosting\nperformance without requiring fine-tuning. Through a dedicated preprocessing\npipeline that extracts 3D object data, our method improves situational\nawareness and decision-making in complex traffic scenarios, achieving a score\nof 0.56 on the LingoQA benchmark. We further explore different fusion\nstrategies and token combinations with the goal of advancing the interpretation\nof traffic scenes, ultimately enabling safer autonomous driving systems.", "AI": {"tldr": "V3LMA enhances 3D scene understanding for autonomous driving by integrating LLMs with LVLMs, improving performance without fine-tuning.", "motivation": "LVLMs lack 3D comprehension in autonomous driving, limiting their effectiveness in dynamic environments.", "method": "V3LMA integrates LLMs with LVLMs, using textual descriptions from object detections and video inputs, and a preprocessing pipeline for 3D object data.", "result": "Achieves 0.56 on LingoQA benchmark, improving situational awareness and decision-making.", "conclusion": "V3LMA advances traffic scene interpretation, enabling safer autonomous driving systems."}}
{"id": "2505.00169", "pdf": "https://arxiv.org/pdf/2505.00169", "abs": "https://arxiv.org/abs/2505.00169", "authors": ["Filipp Nikitin", "Ian Dunn", "David Ryan Koes", "Olexandr Isayev"], "title": "GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D Molecule Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep generative models have shown significant promise in generating valid 3D\nmolecular structures, with the GEOM-Drugs dataset serving as a key benchmark.\nHowever, current evaluation protocols suffer from critical flaws, including\nincorrect valency definitions, bugs in bond order calculations, and reliance on\nforce fields inconsistent with the reference data. In this work, we revisit\nGEOM-Drugs and propose a corrected evaluation framework: we identify and fix\nissues in data preprocessing, construct chemically accurate valency tables, and\nintroduce a GFN2-xTB-based geometry and energy benchmark. We retrain and\nre-evaluate several leading models under this framework, providing updated\nperformance metrics and practical recommendations for future benchmarking. Our\nresults underscore the need for chemically rigorous evaluation practices in 3D\nmolecular generation. Our recommended evaluation methods and GEOM-Drugs\nprocessing scripts are available at\nhttps://github.com/isayevlab/geom-drugs-3dgen-evaluation.", "AI": {"tldr": "The paper addresses flaws in evaluating 3D molecular generation models, proposing a corrected framework for GEOM-Drugs with updated metrics and recommendations.", "motivation": "Current evaluation protocols for 3D molecular generation models are flawed, leading to inaccurate benchmarks.", "method": "The authors fix data preprocessing issues, create accurate valency tables, and introduce a GFN2-xTB-based benchmark, then retrain and re-evaluate leading models.", "result": "Updated performance metrics highlight the need for chemically rigorous evaluation practices.", "conclusion": "The paper advocates for improved evaluation methods in 3D molecular generation and provides tools for future benchmarking."}}
{"id": "2505.00472", "pdf": "https://arxiv.org/pdf/2505.00472", "abs": "https://arxiv.org/abs/2505.00472", "authors": ["Alaa Saleh", "Sasu Tarkoma", "Praveen Kumar Donta", "Naser Hossein Motlagh", "Schahram Dustdar", "Susanna Pirttikangas", "Lauri Lov\u00e9n"], "title": "UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces", "categories": ["cs.AI", "cs.DC", "cs.MA", "cs.NI"], "comment": null, "summary": "Agentic AI, with its autonomous and proactive decision-making, has\ntransformed smart environments. By integrating Generative AI (GenAI) and\nmulti-agent systems, modern AI frameworks can dynamically adapt to user\npreferences, optimize data management, and improve resource allocation. This\npaper introduces UserCentrix, an agentic memory-augmented AI framework designed\nto enhance smart spaces through dynamic, context-aware decision-making. This\nframework integrates personalized Large Language Model (LLM) agents that\nleverage user preferences and LLM memory management to deliver proactive and\nadaptive assistance. Furthermore, it incorporates a hybrid hierarchical control\nsystem, balancing centralized and distributed processing to optimize real-time\nresponsiveness while maintaining global situational awareness. UserCentrix\nachieves resource-efficient AI interactions by embedding memory-augmented\nreasoning, cooperative agent negotiation, and adaptive orchestration\nstrategies. Our key contributions include (i) a self-organizing framework with\nproactive scaling based on task urgency, (ii) a Value of Information\n(VoI)-driven decision-making process, (iii) a meta-reasoning personal LLM\nagent, and (iv) an intelligent multi-agent coordination system for seamless\nenvironment adaptation. Experimental results across various models confirm the\neffectiveness of our approach in enhancing response accuracy, system\nefficiency, and computational resource management in real-world application.", "AI": {"tldr": "UserCentrix is an agentic AI framework integrating GenAI and multi-agent systems to enhance smart spaces with dynamic, context-aware decision-making, achieving efficient resource management and improved responsiveness.", "motivation": "To address the need for autonomous, proactive AI in smart environments by dynamically adapting to user preferences and optimizing resource allocation.", "method": "Develops UserCentrix, a memory-augmented AI framework with personalized LLM agents, hybrid hierarchical control, and adaptive orchestration strategies.", "result": "Experimental results show improved response accuracy, system efficiency, and computational resource management.", "conclusion": "UserCentrix effectively enhances smart spaces through autonomous, context-aware AI, balancing real-time responsiveness and global awareness."}}
{"id": "2505.00133", "pdf": "https://arxiv.org/pdf/2505.00133", "abs": "https://arxiv.org/abs/2505.00133", "authors": ["Hwihun Jeong", "Hayeon Lee", "Se Young Chun", "Jongho Lee"], "title": "Efficient and robust 3D blind harmonization for large domain gaps", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Blind harmonization has emerged as a promising technique for MR image\nharmonization to achieve scale-invariant representations, requiring only target\ndomain data (i.e., no source domain data necessary). However, existing methods\nface limitations such as inter-slice heterogeneity in 3D, moderate image\nquality, and limited performance for a large domain gap. To address these\nchallenges, we introduce BlindHarmonyDiff, a novel blind 3D harmonization\nframework that leverages an edge-to-image model tailored specifically to\nharmonization. Our framework employs a 3D rectified flow trained on target\ndomain images to reconstruct the original image from an edge map, then yielding\na harmonized image from the edge of a source domain image. We propose\nmulti-stride patch training for efficient 3D training and a refinement module\nfor robust inference by suppressing hallucination. Extensive experiments\ndemonstrate that BlindHarmonyDiff outperforms prior arts by harmonizing diverse\nsource domain images to the target domain, achieving higher correspondence to\nthe target domain characteristics. Downstream task-based quality assessments\nsuch as tissue segmentation and age prediction on diverse MR scanners further\nconfirm the effectiveness of our approach and demonstrate the capability of our\nrobust and generalizable blind harmonization.", "AI": {"tldr": "BlindHarmonyDiff is a novel blind 3D harmonization framework using edge-to-image modeling and multi-stride patch training, outperforming existing methods in harmonizing MR images across diverse domains.", "motivation": "Existing blind harmonization methods struggle with inter-slice heterogeneity, moderate image quality, and large domain gaps, prompting the need for a more robust solution.", "method": "The framework employs a 3D rectified flow trained on target domain images to reconstruct from edge maps, with multi-stride patch training and a refinement module for hallucination suppression.", "result": "BlindHarmonyDiff achieves superior harmonization, aligning source domain images closely with target domain characteristics, validated by downstream tasks like tissue segmentation and age prediction.", "conclusion": "The proposed method is robust, generalizable, and effective for blind MR image harmonization, addressing key limitations of prior approaches."}}
{"id": "2505.00012", "pdf": "https://arxiv.org/pdf/2505.00012", "abs": "https://arxiv.org/abs/2505.00012", "authors": ["Fabian Retkowski", "Andreas Sudmann", "Alexander Waibel"], "title": "The AI Co-Ethnographer: How Far Can Automation Take Qualitative Research?", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to NLP4DH 2025", "summary": "Qualitative research often involves labor-intensive processes that are\ndifficult to scale while preserving analytical depth. This paper introduces The\nAI Co-Ethnographer (AICoE), a novel end-to-end pipeline developed for\nqualitative research and designed to move beyond the limitations of simply\nautomating code assignments, offering a more integrated approach. AICoE\norganizes the entire process, encompassing open coding, code consolidation,\ncode application, and even pattern discovery, leading to a comprehensive\nanalysis of qualitative data.", "AI": {"tldr": "The paper introduces AICoE, an AI-driven pipeline for qualitative research, enhancing scalability and depth by automating coding, consolidation, and pattern discovery.", "motivation": "Addressing the labor-intensive and unscalable nature of qualitative research while preserving analytical depth.", "method": "Developed AICoE, an end-to-end pipeline for qualitative research, automating open coding, code consolidation, application, and pattern discovery.", "result": "AICoE provides a comprehensive and scalable solution for qualitative data analysis.", "conclusion": "AICoE advances qualitative research by integrating AI to overcome traditional limitations."}}
{"id": "2505.00325", "pdf": "https://arxiv.org/pdf/2505.00325", "abs": "https://arxiv.org/abs/2505.00325", "authors": ["Rukma Talwadker", "Surajit Chakrabarty", "Aditya Pareek", "Tridib Mukherjee", "Deepak Saini"], "title": "CognitionNet: A Collaborative Neural Network for Play Style Discovery in Online Skill Gaming Platform", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Games are one of the safest source of realizing self-esteem and relaxation at\nthe same time. An online gaming platform typically has massive data coming in,\ne.g., in-game actions, player moves, clickstreams, transactions etc. It is\nrather interesting, as something as simple as data on gaming moves can help\ncreate a psychological imprint of the user at that moment, based on her\nimpulsive reactions and response to a situation in the game. Mining this\nknowledge can: (a) immediately help better explain observed and predicted\nplayer behavior; and (b) consequently propel deeper understanding towards\nplayers' experience, growth and protection. To this effect, we focus on\ndiscovery of the \"game behaviours\" as micro-patterns formed by continuous\nsequence of games and the persistent \"play styles\" of the players' as a\nsequence of such sequences on an online skill gaming platform for Rummy. We\npropose a two stage deep neural network, CognitionNet. The first stage focuses\non mining game behaviours as cluster representations in a latent space while\nthe second aggregates over these micro patterns to discover play styles via a\nsupervised classification objective around player engagement. The dual\nobjective allows CognitionNet to reveal several player psychology inspired\ndecision making and tactics. To our knowledge, this is the first and\none-of-its-kind research to fully automate the discovery of: (i) player\npsychology and game tactics from telemetry data; and (ii) relevant diagnostic\nexplanations to players' engagement predictions. The collaborative training of\nthe two networks with differential input dimensions is enabled using a novel\nformulation of \"bridge loss\". The network plays pivotal role in obtaining\nhomogeneous and consistent play style definitions and significantly outperforms\nthe SOTA baselines wherever applicable.", "AI": {"tldr": "The paper introduces CognitionNet, a two-stage deep neural network, to analyze gaming data for uncovering player psychology and tactics, improving engagement predictions.", "motivation": "To leverage gaming data for understanding player behavior and psychology, enhancing player experience and protection.", "method": "A two-stage deep neural network (CognitionNet) with a novel 'bridge loss' formulation to mine game behaviors and play styles from telemetry data.", "result": "CognitionNet outperforms state-of-the-art baselines, revealing player psychology and tactics while providing diagnostic explanations for engagement predictions.", "conclusion": "This research automates the discovery of player psychology and tactics from gaming data, offering insights for engagement and player experience."}}
{"id": "2505.00209", "pdf": "https://arxiv.org/pdf/2505.00209", "abs": "https://arxiv.org/abs/2505.00209", "authors": ["Kelsey Allen", "Carl Doersch", "Guangyao Zhou", "Mohammed Suhail", "Danny Driess", "Ignacio Rocco", "Yulia Rubanova", "Thomas Kipf", "Mehdi S. M. Sajjadi", "Kevin Murphy", "Joao Carreira", "Sjoerd van Steenkiste"], "title": "Direct Motion Models for Assessing Generated Videos", "categories": ["cs.CV", "cs.LG"], "comment": "Project page: http://trajan-paper.github.io", "summary": "A current limitation of video generative video models is that they generate\nplausible looking frames, but poor motion -- an issue that is not well captured\nby FVD and other popular methods for evaluating generated videos. Here we go\nbeyond FVD by developing a metric which better measures plausible object\ninteractions and motion. Our novel approach is based on auto-encoding point\ntracks and yields motion features that can be used to not only compare\ndistributions of videos (as few as one generated and one ground truth, or as\nmany as two datasets), but also for evaluating motion of single videos. We show\nthat using point tracks instead of pixel reconstruction or action recognition\nfeatures results in a metric which is markedly more sensitive to temporal\ndistortions in synthetic data, and can predict human evaluations of temporal\nconsistency and realism in generated videos obtained from open-source models\nbetter than a wide range of alternatives. We also show that by using a point\ntrack representation, we can spatiotemporally localize generative video\ninconsistencies, providing extra interpretability of generated video errors\nrelative to prior work. An overview of the results and link to the code can be\nfound on the project page: http://trajan-paper.github.io.", "AI": {"tldr": "The paper introduces a new metric for evaluating video generative models, focusing on motion quality by using auto-encoded point tracks, outperforming existing methods like FVD.", "motivation": "Existing metrics (e.g., FVD) fail to capture poor motion quality in generated videos, despite plausible frames.", "method": "Develops a novel metric based on auto-encoding point tracks to evaluate motion and object interactions, enabling comparison of video distributions and single-video analysis.", "result": "The new metric is more sensitive to temporal distortions, aligns better with human evaluations, and localizes inconsistencies in generated videos.", "conclusion": "Point track-based evaluation improves motion assessment in generative videos, offering better sensitivity and interpretability than prior methods."}}
{"id": "2505.00171", "pdf": "https://arxiv.org/pdf/2505.00171", "abs": "https://arxiv.org/abs/2505.00171", "authors": ["Saram Abbas", "Naeem Soomro", "Rishad Shafik", "Rakesh Heer", "Kabita Adhikari"], "title": "Attention-enabled Explainable AI for Bladder Cancer Recurrence Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 5 figures, Accepted to be presented at the 47th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society (EMBC 2025)", "summary": "Non-muscle-invasive bladder cancer (NMIBC) is a relentless challenge in\noncology, with recurrence rates soaring as high as 70-80%. Each recurrence\ntriggers a cascade of invasive procedures, lifelong surveillance, and\nescalating healthcare costs - affecting 460,000 individuals worldwide. However,\nexisting clinical prediction tools remain fundamentally flawed, often\noverestimating recurrence risk and failing to provide personalized insights for\npatient management. In this work, we propose an interpretable deep learning\nframework that integrates vector embeddings and attention mechanisms to improve\nNMIBC recurrence prediction performance. We incorporate vector embeddings for\ncategorical variables such as smoking status and intravesical treatments,\nallowing the model to capture complex relationships between patient attributes\nand recurrence risk. These embeddings provide a richer representation of the\ndata, enabling improved feature interactions and enhancing prediction\nperformance. Our approach not only enhances performance but also provides\nclinicians with patient-specific insights by highlighting the most influential\nfeatures contributing to recurrence risk for each patient. Our model achieves\naccuracy of 70% with tabular data, outperforming conventional statistical\nmethods while providing clinician-friendly patient-level explanations through\nfeature attention. Unlike previous studies, our approach identifies new\nimportant factors influencing recurrence, such as surgical duration and\nhospital stay, which had not been considered in existing NMIBC prediction\nmodels.", "AI": {"tldr": "An interpretable deep learning framework improves NMIBC recurrence prediction by integrating vector embeddings and attention mechanisms, outperforming traditional methods with 70% accuracy.", "motivation": "High recurrence rates (70-80%) and flawed existing tools in NMIBC management necessitate better, personalized prediction methods.", "method": "Uses vector embeddings for categorical variables and attention mechanisms to capture complex relationships and provide patient-specific insights.", "result": "Achieves 70% accuracy, identifies new influential factors (e.g., surgical duration, hospital stay), and offers clinician-friendly explanations.", "conclusion": "The framework enhances prediction performance and interpretability, aiding personalized NMIBC patient management."}}
{"id": "2505.00515", "pdf": "https://arxiv.org/pdf/2505.00515", "abs": "https://arxiv.org/abs/2505.00515", "authors": ["Mingxing Peng", "Ruoyu Yao", "Xusen Guo", "Yuting Xie", "Xianda Chen", "Jun Ma"], "title": "Safety-Critical Traffic Simulation with Guided Latent Diffusion Model", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "7 pages, 3 figures", "summary": "Safety-critical traffic simulation plays a crucial role in evaluating\nautonomous driving systems under rare and challenging scenarios. However,\nexisting approaches often generate unrealistic scenarios due to insufficient\nconsideration of physical plausibility and suffer from low generation\nefficiency. To address these limitations, we propose a guided latent diffusion\nmodel (LDM) capable of generating physically realistic and adversarial\nsafety-critical traffic scenarios. Specifically, our model employs a\ngraph-based variational autoencoder (VAE) to learn a compact latent space that\ncaptures complex multi-agent interactions while improving computational\nefficiency. Within this latent space, the diffusion model performs the\ndenoising process to produce realistic trajectories. To enable controllable and\nadversarial scenario generation, we introduce novel guidance objectives that\ndrive the diffusion process toward producing adversarial and behaviorally\nrealistic driving behaviors. Furthermore, we develop a sample selection module\nbased on physical feasibility checks to further enhance the physical\nplausibility of the generated scenarios. Extensive experiments on the nuScenes\ndataset demonstrate that our method achieves superior adversarial effectiveness\nand generation efficiency compared to existing baselines while maintaining a\nhigh level of realism. Our work provides an effective tool for realistic\nsafety-critical scenario simulation, paving the way for more robust evaluation\nof autonomous driving systems.", "AI": {"tldr": "A guided latent diffusion model (LDM) is proposed to generate physically realistic and adversarial safety-critical traffic scenarios, improving efficiency and realism over existing methods.", "motivation": "Existing traffic simulation methods for autonomous driving evaluation often produce unrealistic scenarios due to insufficient physical plausibility and low efficiency.", "method": "The model uses a graph-based VAE to learn a latent space for multi-agent interactions, then applies a diffusion model for denoising. Guidance objectives and a sample selection module enhance adversarial and realistic scenario generation.", "result": "Experiments on the nuScenes dataset show superior adversarial effectiveness, generation efficiency, and realism compared to baselines.", "conclusion": "The proposed method provides a robust tool for safety-critical scenario simulation, aiding autonomous driving system evaluation."}}
{"id": "2505.00374", "pdf": "https://arxiv.org/pdf/2505.00374", "abs": "https://arxiv.org/abs/2505.00374", "authors": ["Usman Muhammad", "Jorma Laaksonen", "Lyudmila Mihaylova"], "title": "Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise Separable Dilated Convolutional Network", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Deep neural networks have demonstrated highly competitive performance in\nsuper-resolution (SR) for natural images by learning mappings from\nlow-resolution (LR) to high-resolution (HR) images. However, hyperspectral\nsuper-resolution remains an ill-posed problem due to the high spectral\ndimensionality of the data and the scarcity of available training samples.\nMoreover, existing methods often rely on large models with a high number of\nparameters or require the fusion with panchromatic or RGB images, both of which\nare often impractical in real-world scenarios. Inspired by the MobileNet\narchitecture, we introduce a lightweight depthwise separable dilated\nconvolutional network (DSDCN) to address the aforementioned challenges.\nSpecifically, our model leverages multiple depthwise separable convolutions,\nsimilar to the MobileNet architecture, and further incorporates a dilated\nconvolution fusion block to make the model more flexible for the extraction of\nboth spatial and spectral features. In addition, we propose a custom loss\nfunction that combines mean squared error (MSE), an L2 norm\nregularization-based constraint, and a spectral angle-based loss, ensuring the\npreservation of both spectral and spatial details. The proposed model achieves\nvery competitive performance on two publicly available hyperspectral datasets,\nmaking it well-suited for hyperspectral image super-resolution tasks. The\nsource codes are publicly available at:\n\\href{https://github.com/Usman1021/lightweight}{https://github.com/Usman1021/lightweight}.", "AI": {"tldr": "A lightweight depthwise separable dilated convolutional network (DSDCN) is proposed for hyperspectral super-resolution, addressing challenges like high spectral dimensionality and limited training samples. It combines MobileNet-inspired architecture with a custom loss function for competitive performance.", "motivation": "Hyperspectral super-resolution is ill-posed due to high spectral dimensionality and scarce training data. Existing methods are impractical due to large models or fusion requirements.", "method": "The DSDCN uses depthwise separable convolutions (like MobileNet) and a dilated convolution fusion block for spatial-spectral feature extraction. A custom loss function combines MSE, L2 regularization, and spectral angle-based loss.", "result": "The model achieves competitive performance on two public hyperspectral datasets.", "conclusion": "DSDCN is effective for hyperspectral super-resolution, balancing performance and practicality. Code is publicly available."}}
{"id": "2505.00013", "pdf": "https://arxiv.org/pdf/2505.00013", "abs": "https://arxiv.org/abs/2505.00013", "authors": ["Yoichi Takenaka"], "title": "Performance Evaluation of Emotion Classification in Japanese Using RoBERTa and DeBERTa", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages, 3 tables, 3 appendices. Submitted to New Generation\n  Computing. Includes comparisons between fine-tuned PLMs and LLMs on Japanese\n  emotion classification. Code available at\n  https://pypi.org/project/deberta-emotion-predictor/", "summary": "Background Practical applications such as social media monitoring and\ncustomer-feedback analysis require accurate emotion detection for Japanese\ntext, yet resource scarcity and class imbalance hinder model performance.\n  Objective This study aims to build a high-accuracy model for predicting the\npresence or absence of eight Plutchik emotions in Japanese sentences.\n  Methods Using the WRIME corpus, we transform reader-averaged intensity scores\ninto binary labels and fine-tune four pre-trained language models (BERT,\nRoBERTa, DeBERTa-v3-base, DeBERTa-v3-large). For context, we also assess two\nlarge language models (TinySwallow-1.5B-Instruct and ChatGPT-4o). Accuracy and\nF1-score serve as evaluation metrics.\n  Results DeBERTa-v3-large attains the best mean accuracy (0.860) and F1-score\n(0.662), outperforming all other models. It maintains robust F1 across both\nhigh-frequency emotions (e.g., Joy, Anticipation) and low-frequency emotions\n(e.g., Anger, Trust). The LLMs lag, with ChatGPT-4o and\nTinySwallow-1.5B-Instruct scoring 0.527 and 0.292 in mean F1, respectively.\n  Conclusion The fine-tuned DeBERTa-v3-large model currently offers the most\nreliable solution for binary emotion classification in Japanese. We release\nthis model as a pip-installable package (pip install\ndeberta-emotion-predictor). Future work should augment data for rare emotions,\nreduce model size, and explore prompt engineering to improve LLM performance.\n  This manuscript is under review for possible publication in New Generation\nComputing.", "AI": {"tldr": "The study fine-tunes pre-trained models for binary emotion classification in Japanese, with DeBERTa-v3-large achieving the best performance, while LLMs lag behind.", "motivation": "Accurate emotion detection in Japanese text is needed for applications like social media monitoring, but resource scarcity and class imbalance pose challenges.", "method": "The WRIME corpus is used to fine-tune four pre-trained models (BERT, RoBERTa, DeBERTa-v3-base, DeBERTa-v3-large) and evaluate two LLMs (TinySwallow-1.5B-Instruct, ChatGPT-4o) using accuracy and F1-score.", "result": "DeBERTa-v3-large outperforms others with mean accuracy (0.860) and F1-score (0.662), while LLMs perform poorly (ChatGPT-4o: 0.527, TinySwallow: 0.292).", "conclusion": "DeBERTa-v3-large is the most reliable for binary emotion classification in Japanese. Future work includes data augmentation, model size reduction, and improving LLM performance."}}
{"id": "2505.00416", "pdf": "https://arxiv.org/pdf/2505.00416", "abs": "https://arxiv.org/abs/2505.00416", "authors": ["Jing Huang", "Zhixiong Zeng", "Wenkang Han", "Yufeng Zhong", "Liming Zheng", "Shuai Fu", "Jingyuan Chen", "Lin Ma"], "title": "ScaleTrack: Scaling and back-tracking Automated GUI Agents", "categories": ["cs.AI"], "comment": null, "summary": "Automated GUI agents aims to facilitate user interaction by automatically\nperforming complex tasks in digital environments, such as web, mobile, desktop\ndevices. It receives textual task instruction and GUI description to generate\nexecutable actions (\\emph{e.g.}, click) and operation boxes step by step.\nTraining a GUI agent mainly involves grounding and planning stages, in which\nthe GUI grounding focuses on finding the execution coordinates according to the\ntask, while the planning stage aims to predict the next action based on\nhistorical actions. However, previous work suffers from the limitations of\ninsufficient training data for GUI grounding, as well as the ignorance of\nbacktracking historical behaviors for GUI planning. To handle the above\nchallenges, we propose ScaleTrack, a training framework by scaling grounding\nand backtracking planning for automated GUI agents. We carefully collected GUI\nsamples of different synthesis criterions from a wide range of sources, and\nunified them into the same template for training GUI grounding models.\nMoreover, we design a novel training strategy that predicts the next action\nfrom the current GUI image, while also backtracking the historical actions that\nled to the GUI image. In this way, ScaleTrack explains the correspondence\nbetween GUI images and actions, which effectively describes the evolution rules\nof the GUI environment. Extensive experimental results demonstrate the\neffectiveness of ScaleTrack. Data and code will be available at url.", "AI": {"tldr": "ScaleTrack is a framework for training automated GUI agents, addressing data scarcity in GUI grounding and incorporating backtracking for planning.", "motivation": "Previous work lacks sufficient training data for GUI grounding and ignores backtracking in planning, limiting agent performance.", "method": "ScaleTrack scales grounding with diverse GUI samples and introduces backtracking in planning by predicting actions from current GUI images and historical actions.", "result": "Experimental results show ScaleTrack's effectiveness in improving GUI agent performance.", "conclusion": "ScaleTrack successfully addresses data and backtracking challenges, enhancing automated GUI agent training."}}
{"id": "2505.00220", "pdf": "https://arxiv.org/pdf/2505.00220", "abs": "https://arxiv.org/abs/2505.00220", "authors": ["Ankit Amrutkar", "Bj\u00f6rn Kampa", "Volkmar Schulz", "Johannes Stegmaier", "Markus Rothermel", "Dorit Merhof"], "title": "Towards Robust and Generalizable Gerchberg Saxton based Physics Inspired Neural Networks for Computer Generated Holography: A Sensitivity Analysis Framework", "categories": ["cs.CV", "physics.optics"], "comment": null, "summary": "Computer-generated holography (CGH) enables applications in holographic\naugmented reality (AR), 3D displays, systems neuroscience, and optical\ntrapping. The fundamental challenge in CGH is solving the inverse problem of\nphase retrieval from intensity measurements. Physics-inspired neural networks\n(PINNs), especially Gerchberg-Saxton-based PINNs (GS-PINNs), have advanced\nphase retrieval capabilities. However, their performance strongly depends on\nforward models (FMs) and their hyperparameters (FMHs), limiting generalization,\ncomplicating benchmarking, and hindering hardware optimization. We present a\nsystematic sensitivity analysis framework based on Saltelli's extension of\nSobol's method to quantify FMH impacts on GS-PINN performance. Our analysis\ndemonstrates that SLM pixel-resolution is the primary factor affecting neural\nnetwork sensitivity, followed by pixel-pitch, propagation distance, and\nwavelength. Free space propagation forward models demonstrate superior neural\nnetwork performance compared to Fourier holography, providing enhanced\nparameterization and generalization. We introduce a composite evaluation metric\ncombining performance consistency, generalization capability, and\nhyperparameter perturbation resilience, establishing a unified benchmarking\nstandard across CGH configurations. Our research connects physics-inspired deep\nlearning theory with practical CGH implementations through concrete guidelines\nfor forward model selection, neural network architecture, and performance\nevaluation. Our contributions advance the development of robust, interpretable,\nand generalizable neural networks for diverse holographic applications,\nsupporting evidence-based decisions in CGH research and implementation.", "AI": {"tldr": "The paper presents a sensitivity analysis framework for Gerchberg-Saxton-based physics-inspired neural networks (GS-PINNs) in computer-generated holography (CGH), identifying key hyperparameters affecting performance and proposing a composite evaluation metric for benchmarking.", "motivation": "The performance of GS-PINNs in CGH is limited by dependence on forward models (FMs) and their hyperparameters (FMHs), complicating generalization and benchmarking.", "method": "A systematic sensitivity analysis using Saltelli's extension of Sobol's method to quantify FMH impacts on GS-PINN performance.", "result": "SLM pixel-resolution is the most influential factor, followed by pixel-pitch, propagation distance, and wavelength. Free space propagation models outperform Fourier holography.", "conclusion": "The study provides guidelines for FM selection, neural network architecture, and performance evaluation, advancing robust and interpretable CGH applications."}}
{"id": "2505.00189", "pdf": "https://arxiv.org/pdf/2505.00189", "abs": "https://arxiv.org/abs/2505.00189", "authors": ["Houda Belhad", "Asmae Bourbia", "Salma Boughanja"], "title": "Chronic Diseases Prediction using Machine Learning and Deep Learning Methods", "categories": ["cs.LG"], "comment": null, "summary": "Chronic diseases, such as cardiovascular disease, diabetes, chronic kidney\ndisease, and thyroid disorders, are the leading causes of premature mortality\nworldwide. Early detection and intervention are crucial for improving patient\noutcomes, yet traditional diagnostic methods often fail due to the complex\nnature of these conditions. This study explores the application of machine\nlearning (ML) and deep learning (DL) techniques to predict chronic disease and\nthyroid disorders. We used a variety of models, including Logistic Regression\n(LR), Random Forest (RF), Gradient Boosted Trees (GBT), Neural Networks (NN),\nDecision Trees (DT) and Native Bayes (NB), to analyze and predict disease\noutcomes. Our methodology involved comprehensive data pre-processing, including\nhandling missing values, categorical encoding, and feature aggregation,\nfollowed by model training and evaluation. Performance metrics such ad\nprecision, recall, accuracy, F1-score, and Area Under the Curve (AUC) were used\nto assess the effectiveness of each model. The results demonstrated that\nensemble methods like Random Forest and Gradient Boosted Trees consistently\noutperformed. Neutral Networks also showed superior performance, particularly\nin capturing complex data patterns. The findings highlight the potential of ML\nand DL in revolutionizing chronic disease prediction, enabling early diagnosis\nand personalized treatment strategies. However, challenges such as data\nquality, model interpretability, and the need for advanced computational\ntechniques in healthcare to improve patient outcomes and reduce the burden of\nchronic diseases. This study was conducted as part of Big Data class project\nunder the supervision of our professors Mr. Abderrahmane EZ-ZAHOUT and Mr.\nAbdessamad ESSAIDI.", "AI": {"tldr": "Machine learning and deep learning techniques were applied to predict chronic diseases, with ensemble methods like Random Forest and Gradient Boosted Trees showing superior performance.", "motivation": "Early detection of chronic diseases is critical but traditional methods often fail due to complexity. ML/DL can improve prediction accuracy.", "method": "Used Logistic Regression, Random Forest, Gradient Boosted Trees, Neural Networks, Decision Trees, and Naive Bayes. Included data pre-processing and model evaluation.", "result": "Ensemble methods and Neural Networks outperformed others, demonstrating ML/DL's potential for early disease prediction.", "conclusion": "ML/DL can revolutionize chronic disease prediction but faces challenges like data quality and interpretability."}}
{"id": "2505.00462", "pdf": "https://arxiv.org/pdf/2505.00462", "abs": "https://arxiv.org/abs/2505.00462", "authors": ["Julian Christopher L. Maya", "Johnenn R. Manalang", "Maricor N. Soriano"], "title": "CORSTITCH - A free, open source software for stitching and georeferencing underwater coral reef videos", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "CorStitch is an open-source software developed to automate the creation of\naccurate georeferenced reef mosaics from video transects obtained through\nAutomated Rapid Reef Assessment System surveys. We utilized a Fourier-based\nimage correlation algorithm to stitch sequential video frames, aligning them\nwith synchronized GNSS timestamps. The resulting compressed Keyhole Markup\nLanguage files, compatible with geographic information systems such as Google\nEarth, enable detailed spatial analysis. Validation through comparative\nanalysis of mosaics from two temporally distinct surveys of the same reef\ndemonstrated the software's consistent and reliable performance.", "AI": {"tldr": "CorStitch automates georeferenced reef mosaics from video transects using Fourier-based image correlation, validated for reliability.", "motivation": "To streamline the creation of accurate georeferenced reef mosaics for spatial analysis in reef surveys.", "method": "Uses Fourier-based image correlation to stitch video frames, aligned with GNSS timestamps, outputting GIS-compatible files.", "result": "Produces reliable mosaics validated by comparative analysis of temporally distinct reef surveys.", "conclusion": "CorStitch is a consistent and reliable tool for reef mosaic creation and spatial analysis."}}
{"id": "2505.00014", "pdf": "https://arxiv.org/pdf/2505.00014", "abs": "https://arxiv.org/abs/2505.00014", "authors": ["Vinit K. Chavan"], "title": "Manifold-Constrained Sentence Embeddings via Triplet Loss: Projecting Semantics onto Spheres, Tori, and M\u00f6bius Strips", "categories": ["cs.CL"], "comment": "10 pages, 6 figures. Code available at\n  https://github.com/vinitchavan/manifold-embedding-nlp", "summary": "Recent advances in representation learning have emphasized the role of\nembedding geometry in capturing semantic structure. Traditional sentence\nembeddings typically reside in unconstrained Euclidean spaces, which may limit\ntheir ability to reflect complex relationships in language. In this work, we\nintroduce a novel framework that constrains sentence embeddings to lie on\ncontinuous manifolds -- specifically the unit sphere, torus, and M\\\"obius strip\n-- using triplet loss as the core training objective. By enforcing differential\ngeometric constraints on the output space, our approach encourages the learning\nof embeddings that are both discriminative and topologically structured.\n  We evaluate our method on benchmark datasets (AG News and MBTI) and compare\nit to classical baselines including TF-IDF, Word2Vec, and unconstrained\nKeras-derived embeddings. Our results demonstrate that manifold-constrained\nembeddings, particularly those projected onto spheres and M\\\"obius strips,\nsignificantly outperform traditional approaches in both clustering quality\n(Silhouette Score) and classification performance (Accuracy). These findings\nhighlight the value of embedding in manifold space -- where topological\nstructure complements semantic separation -- offering a new and mathematically\ngrounded direction for geometric representation learning in NLP.", "AI": {"tldr": "The paper introduces a framework for constraining sentence embeddings to continuous manifolds (sphere, torus, M\u00f6bius strip) using triplet loss, outperforming traditional Euclidean embeddings in clustering and classification tasks.", "motivation": "Traditional Euclidean sentence embeddings may not capture complex linguistic relationships well, prompting exploration of manifold-constrained embeddings for better semantic structure.", "method": "A novel framework enforces differential geometric constraints on embeddings (sphere, torus, M\u00f6bius strip) using triplet loss, evaluated on AG News and MBTI datasets against baselines like TF-IDF and Word2Vec.", "result": "Manifold-constrained embeddings, especially on spheres and M\u00f6bius strips, outperform traditional methods in clustering (Silhouette Score) and classification (Accuracy).", "conclusion": "Embedding in manifold spaces, where topological structure aids semantic separation, offers a promising direction for geometric representation learning in NLP."}}
{"id": "2505.00474", "pdf": "https://arxiv.org/pdf/2505.00474", "abs": "https://arxiv.org/abs/2505.00474", "authors": ["Cecilia Di Florio", "Huimin Dong", "Antonino Rotolo"], "title": "Rule-based Classifier Models", "categories": ["cs.AI"], "comment": "11 pages, 1 figure. Extended version of a short paper accepted to\n  ICAIL 2025. This is the authors' version of the work. It is posted here for\n  your personal use", "summary": "We extend the formal framework of classifier models used in the legal domain.\nWhile the existing classifier framework characterises cases solely through the\nfacts involved, legal reasoning fundamentally relies on both facts and rules,\nparticularly the ratio decidendi. This paper presents an initial approach to\nincorporating sets of rules within a classifier. Our work is built on the work\nof Canavotto et al. (2023), which has developed the rule-based reason model of\nprecedential constraint within a hierarchy of factors. We demonstrate how\ndecisions for new cases can be inferred using this enriched rule-based\nclassifier framework. Additionally, we provide an example of how the time\nelement and the hierarchy of courts can be used in the new classifier\nframework.", "AI": {"tldr": "Extends classifier models in legal domains by incorporating rules (ratio decidendi) alongside facts, building on Canavotto et al.'s (2023) work, and demonstrates decision inference with time and court hierarchy.", "motivation": "Existing classifiers focus only on facts, but legal reasoning requires rules (ratio decidendi) for accurate case analysis.", "method": "Extends Canavotto et al.'s rule-based reason model to include rules in classifiers, enabling inference for new cases.", "result": "Demonstrates decision inference using the enriched framework, including time and court hierarchy.", "conclusion": "The enriched classifier framework improves legal case analysis by integrating rules and facts."}}
{"id": "2505.00228", "pdf": "https://arxiv.org/pdf/2505.00228", "abs": "https://arxiv.org/abs/2505.00228", "authors": ["Xiaoman Zhang", "Juli\u00e1n N. Acosta", "Josh Miller", "Ouwen Huang", "Pranav Rajpurkar"], "title": "ReXGradient-160K: A Large-Scale Publicly Available Dataset of Chest Radiographs with Free-text Reports", "categories": ["cs.CV"], "comment": null, "summary": "We present ReXGradient-160K, representing the largest publicly available\nchest X-ray dataset to date in terms of the number of patients. This dataset\ncontains 160,000 chest X-ray studies with paired radiological reports from\n109,487 unique patients across 3 U.S. health systems (79 medical sites). This\ncomprehensive dataset includes multiple images per study and detailed radiology\nreports, making it particularly valuable for the development and evaluation of\nAI systems for medical imaging and automated report generation models. The\ndataset is divided into training (140,000 studies), validation (10,000\nstudies), and public test (10,000 studies) sets, with an additional private\ntest set (10,000 studies) reserved for model evaluation on the ReXrank\nbenchmark. By providing this extensive dataset, we aim to accelerate research\nin medical imaging AI and advance the state-of-the-art in automated\nradiological analysis. Our dataset will be open-sourced at\nhttps://huggingface.co/datasets/rajpurkarlab/ReXGradient-160K.", "AI": {"tldr": "ReXGradient-160K is the largest public chest X-ray dataset with 160,000 studies from 109,487 patients, designed for AI in medical imaging and automated report generation.", "motivation": "To accelerate research in medical imaging AI and improve automated radiological analysis by providing a comprehensive, large-scale dataset.", "method": "The dataset includes 160,000 chest X-ray studies with paired radiology reports, divided into training, validation, and test sets.", "result": "A publicly available dataset with detailed radiology reports and multiple images per study, facilitating AI model development.", "conclusion": "ReXGradient-160K aims to advance medical imaging AI and will be open-sourced for broader research use."}}
{"id": "2505.00190", "pdf": "https://arxiv.org/pdf/2505.00190", "abs": "https://arxiv.org/abs/2505.00190", "authors": ["Hans Peter", "Anders S\u00f8gaard"], "title": "Empirical Evaluation of Progressive Coding for Sparse Autoencoders", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sparse autoencoders (SAEs)\n\\citep{bricken2023monosemanticity,gao2024scalingevaluatingsparseautoencoders}\nrely on dictionary learning to extract interpretable features from neural\nnetworks at scale in an unsupervised manner, with applications to\nrepresentation engineering and information retrieval. SAEs are, however,\ncomputationally expensive \\citep{lieberum2024gemmascopeopensparse}, especially\nwhen multiple SAEs of different sizes are needed. We show that dictionary\nimportance in vanilla SAEs follows a power law. We compare progressive coding\nbased on subset pruning of SAEs -- to jointly training nested SAEs, or\nso-called {\\em Matryoshka} SAEs\n\\citep{bussmann2024learning,nabeshima2024Matryoshka} -- on a language modeling\ntask. We show Matryoshka SAEs exhibit lower reconstruction loss and recaptured\nlanguage modeling loss, as well as higher representational similarity. Pruned\nvanilla SAEs are more interpretable, however. We discuss the origins and\nimplications of this trade-off.", "AI": {"tldr": "Matryoshka SAEs outperform pruned vanilla SAEs in reconstruction and language modeling but are less interpretable.", "motivation": "To address the computational expense of sparse autoencoders (SAEs) and improve their efficiency and interpretability.", "method": "Compare progressive coding (subset pruning) with nested SAEs (Matryoshka SAEs) on a language modeling task.", "result": "Matryoshka SAEs show lower reconstruction loss, better language modeling performance, and higher representational similarity, while pruned vanilla SAEs are more interpretable.", "conclusion": "There's a trade-off between performance and interpretability, with Matryoshka SAEs excelling in efficiency but pruned vanilla SAEs offering better interpretability."}}
{"id": "2505.00525", "pdf": "https://arxiv.org/pdf/2505.00525", "abs": "https://arxiv.org/abs/2505.00525", "authors": ["Abu Saleh Musa Miah", "taro Suzuki", "Jungpil Shin"], "title": "A Methodological and Structural Review of Parkinsons Disease Detection Across Diverse Data Modalities", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Parkinsons Disease (PD) is a progressive neurological disorder that primarily\naffects motor functions and can lead to mild cognitive impairment (MCI) and\ndementia in its advanced stages. With approximately 10 million people diagnosed\nglobally 1 to 1.8 per 1,000 individuals, according to reports by the Japan\nTimes and the Parkinson Foundation early and accurate diagnosis of PD is\ncrucial for improving patient outcomes. While numerous studies have utilized\nmachine learning (ML) and deep learning (DL) techniques for PD recognition,\nexisting surveys are limited in scope, often focusing on single data modalities\nand failing to capture the potential of multimodal approaches. To address these\ngaps, this study presents a comprehensive review of PD recognition systems\nacross diverse data modalities, including Magnetic Resonance Imaging (MRI),\ngait-based pose analysis, gait sensory data, handwriting analysis, speech test\ndata, Electroencephalography (EEG), and multimodal fusion techniques. Based on\nover 347 articles from leading scientific databases, this review examines key\naspects such as data collection methods, settings, feature representations, and\nsystem performance, with a focus on recognition accuracy and robustness. This\nsurvey aims to serve as a comprehensive resource for researchers, providing\nactionable guidance for the development of next generation PD recognition\nsystems. By leveraging diverse data modalities and cutting-edge machine\nlearning paradigms, this work contributes to advancing the state of PD\ndiagnostics and improving patient care through innovative, multimodal\napproaches.", "AI": {"tldr": "A comprehensive review of Parkinson's Disease (PD) recognition systems using multimodal data and ML/DL techniques to improve early diagnosis and patient outcomes.", "motivation": "Early and accurate PD diagnosis is crucial, but existing surveys lack coverage of multimodal approaches, leaving gaps in research.", "method": "Review of 347 articles on PD recognition systems, analyzing data modalities like MRI, gait analysis, EEG, and multimodal fusion techniques.", "result": "Identifies key aspects of data collection, feature representation, and system performance, emphasizing accuracy and robustness.", "conclusion": "The survey provides actionable guidance for developing next-gen PD recognition systems, advancing diagnostics through multimodal ML/DL approaches."}}
{"id": "2505.00015", "pdf": "https://arxiv.org/pdf/2505.00015", "abs": "https://arxiv.org/abs/2505.00015", "authors": ["MD Thamed Bin Zaman Chowdhury", "Moazzem Hossain"], "title": "Design and Application of Multimodal Large Language Model Based System for End to End Automation of Accident Dataset Generation", "categories": ["cs.CL"], "comment": "Shortened the abstract to fit within 1920 characters. This paper is\n  currently under Review in Elsevier journal 'Accident Analysis & Prevention'", "summary": "Road traffic accidents remain a major public safety and socio-economic issue\nin developing countries like Bangladesh. Existing accident data collection is\nlargely manual, fragmented, and unreliable, resulting in underreporting and\ninconsistent records. This research proposes a fully automated system using\nLarge Language Models (LLMs) and web scraping techniques to address these\nchallenges. The pipeline consists of four components: automated web scraping\ncode generation, news collection from online sources, accident news\nclassification with structured data extraction, and duplicate removal. The\nsystem uses the multimodal generative LLM Gemini-2.0-Flash for seamless\nautomation. The code generation module classifies webpages into pagination,\ndynamic, or infinite scrolling categories and generates suitable Python scripts\nfor scraping. LLMs also classify and extract key accident information such as\ndate, time, location, fatalities, injuries, road type, vehicle types, and\npedestrian involvement. A deduplication algorithm ensures data integrity by\nremoving duplicate reports. The system scraped 14 major Bangladeshi news sites\nover 111 days (Oct 1, 2024 - Jan 20, 2025), processing over 15,000 news\narticles and identifying 705 unique accidents. The code generation module\nachieved 91.3% calibration and 80% validation accuracy. Chittagong reported the\nhighest number of accidents (80), fatalities (70), and injuries (115), followed\nby Dhaka, Faridpur, Gazipur, and Cox's Bazar. Peak accident times were morning\n(8-9 AM), noon (12-1 PM), and evening (6-7 PM). A public repository was also\ndeveloped with usage instructions. This study demonstrates the viability of an\nLLM-powered, scalable system for accurate, low-effort accident data collection,\nproviding a foundation for data-driven road safety policymaking in Bangladesh.", "AI": {"tldr": "The paper proposes an automated system using LLMs and web scraping to collect and analyze road accident data in Bangladesh, achieving high accuracy and scalability.", "motivation": "To address the unreliable and fragmented manual accident data collection in Bangladesh, ensuring accurate and consistent records for better road safety policymaking.", "method": "A four-component pipeline: automated web scraping code generation, news collection, accident classification with structured data extraction, and duplicate removal, powered by the LLM Gemini-2.0-Flash.", "result": "The system processed 15,000+ news articles, identified 705 unique accidents, and achieved 91.3% calibration and 80% validation accuracy. Chittagong had the highest accident rates.", "conclusion": "The study proves the viability of an LLM-powered, scalable system for accurate accident data collection, supporting data-driven road safety policies in Bangladesh."}}
{"id": "2505.00603", "pdf": "https://arxiv.org/pdf/2505.00603", "abs": "https://arxiv.org/abs/2505.00603", "authors": ["Phanish Puranam", "Prothit Sen", "Maciej Workiewicz"], "title": "Can LLMs Help Improve Analogical Reasoning For Strategic Decisions? Experimental Evidence from Humans and GPT-4", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "This study investigates whether large language models, specifically GPT4, can\nmatch human capabilities in analogical reasoning within strategic decision\nmaking contexts. Using a novel experimental design involving source to target\nmatching, we find that GPT4 achieves high recall by retrieving all plausible\nanalogies but suffers from low precision, frequently applying incorrect\nanalogies based on superficial similarities. In contrast, human participants\nexhibit high precision but low recall, selecting fewer analogies yet with\nstronger causal alignment. These findings advance theory by identifying\nmatching, the evaluative phase of analogical reasoning, as a distinct step that\nrequires accurate causal mapping beyond simple retrieval. While current LLMs\nare proficient in generating candidate analogies, humans maintain a comparative\nadvantage in recognizing deep structural similarities across domains. Error\nanalysis reveals that AI errors arise from surface level matching, whereas\nhuman errors stem from misinterpretations of causal structure. Taken together,\nthe results suggest a productive division of labor in AI assisted\norganizational decision making where LLMs may serve as broad analogy\ngenerators, while humans act as critical evaluators, applying the most\ncontextually appropriate analogies to strategic problems.", "AI": {"tldr": "GPT4 matches human recall in analogical reasoning but lacks precision due to superficial matching, while humans excel in precision but have lower recall. Humans outperform in deep structural similarity recognition.", "motivation": "To compare GPT4 and human capabilities in analogical reasoning for strategic decision-making, identifying strengths and weaknesses of each.", "method": "Novel experimental design with source-to-target matching to evaluate recall and precision in analogy retrieval and application.", "result": "GPT4 has high recall but low precision; humans show high precision but low recall. Humans better recognize deep structural similarities.", "conclusion": "A division of labor is suggested: LLMs generate analogies, while humans evaluate and apply them contextually."}}
{"id": "2505.00254", "pdf": "https://arxiv.org/pdf/2505.00254", "abs": "https://arxiv.org/abs/2505.00254", "authors": ["Yuxuan Yan", "Shiqi Jiang", "Ting Cao", "Yifan Yang", "Qianqian Yang", "Yuanchao Shu", "Yuqing Yang", "Lili Qiu"], "title": "Empowering Agentic Video Analytics Systems with Video Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages", "summary": "AI-driven video analytics has become increasingly pivotal across diverse\ndomains. However, existing systems are often constrained to specific,\npredefined tasks, limiting their adaptability in open-ended analytical\nscenarios. The recent emergence of Video-Language Models (VLMs) as\ntransformative technologies offers significant potential for enabling\nopen-ended video understanding, reasoning, and analytics. Nevertheless, their\nlimited context windows present challenges when processing ultra-long video\ncontent, which is prevalent in real-world applications. To address this, we\nintroduce AVA, a VLM-powered system designed for open-ended, advanced video\nanalytics. AVA incorporates two key innovations: (1) the near real-time\nconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long or\ncontinuous video streams, and (2) an agentic retrieval-generation mechanism\nthat leverages EKGs to handle complex and diverse queries. Comprehensive\nevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that\nAVA achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,\nrespectively, significantly surpassing existing VLM and video\nRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video\nanalytics in ultra-long and open-world video scenarios, we introduce a new\nbenchmark, AVA-100. This benchmark comprises 8 videos, each exceeding 10 hours\nin duration, along with 120 manually annotated, diverse, and complex\nquestion-answer pairs. On AVA-100, AVA achieves top-tier performance with an\naccuracy of 75.8%.", "AI": {"tldr": "AVA is a VLM-powered system for open-ended video analytics, addressing context window limitations with Event Knowledge Graphs and agentic retrieval-generation. It outperforms existing systems on benchmarks and introduces a new benchmark, AVA-100.", "motivation": "Existing AI-driven video analytics systems lack adaptability for open-ended scenarios due to predefined tasks and limited context windows in VLMs.", "method": "AVA uses Event Knowledge Graphs for efficient indexing and an agentic retrieval-generation mechanism for handling complex queries.", "result": "AVA achieves 62.3% and 64.1% accuracy on LVBench and VideoMME-Long, and 75.8% on AVA-100, surpassing existing systems.", "conclusion": "AVA demonstrates superior performance in open-ended video analytics, validated by benchmarks, and introduces a new benchmark for ultra-long videos."}}
{"id": "2505.00196", "pdf": "https://arxiv.org/pdf/2505.00196", "abs": "https://arxiv.org/abs/2505.00196", "authors": ["Eloy Geenjaar", "Vince Calhoun"], "title": "Mapping minds not averages: a scalable subject-specific manifold learning framework for neuroimaging data", "categories": ["cs.LG", "q-bio.NC"], "comment": "20 pages, 6 figures", "summary": "Mental and cognitive representations are believed to reside on\nlow-dimensional, non-linear manifolds embedded within high-dimensional brain\nactivity. Uncovering these manifolds is key to understanding individual\ndifferences in brain function, yet most existing machine learning methods\neither rely on population-level spatial alignment or assume data that is\ntemporally structured, either because data is aligned among subjects or because\nevent timings are known. We introduce a manifold learning framework that can\ncapture subject-specific spatial variations across both structured and\ntemporally unstructured neuroimaging data. On simulated data and two\nnaturalistic fMRI datasets (Sherlock and Forrest Gump), our framework\noutperforms group-based baselines by recovering more accurate and\nindividualized representations. We further show that the framework scales\nefficiently to large datasets and generalizes well to new subjects. To test\nthis, we apply the framework to temporally unstructured resting-state fMRI data\nfrom individuals with schizophrenia and healthy controls. We further apply our\nmethod to a large resting-state fMRI dataset comprising individuals with\nschizophrenia and controls. In this setting, we demonstrate that the framework\nscales efficiently to large populations and generalizes robustly to unseen\nsubjects. The learned subject-specific spatial maps our model finds reveal\nclinically relevant patterns, including increased activation in the basal\nganglia, visual, auditory, and somatosensory regions, and decreased activation\nin the insula, inferior frontal gyrus, and angular gyrus. These findings\nsuggest that our framework can uncover clinically relevant subject-specific\nbrain activity patterns. Our approach thus provides a scalable and\nindividualized framework for modeling brain activity, with applications in\ncomputational neuroscience and clinical research.", "AI": {"tldr": "A manifold learning framework is introduced to capture subject-specific spatial variations in neuroimaging data, outperforming group-based methods and revealing clinically relevant brain activity patterns.", "motivation": "To address the limitations of existing methods that rely on population-level alignment or temporal structure, the paper aims to uncover individualized brain activity patterns.", "method": "The framework learns low-dimensional manifolds from structured and unstructured neuroimaging data, tested on simulated and real datasets (Sherlock, Forrest Gump, and resting-state fMRI).", "result": "The method outperforms baselines, scales efficiently, and generalizes well, revealing clinically relevant patterns in schizophrenia patients.", "conclusion": "The framework provides a scalable, individualized tool for modeling brain activity, with potential applications in neuroscience and clinical research."}}
{"id": "2505.00578", "pdf": "https://arxiv.org/pdf/2505.00578", "abs": "https://arxiv.org/abs/2505.00578", "authors": ["Shuang Zhang", "Carleton Coffin", "Karyn L. Rogers", "Catherine Ann Royer", "Ge Wang"], "title": "AI-Driven High-Resolution Cell Segmentation and Quantitative Analysis", "categories": ["eess.IV", "q-bio.QM"], "comment": null, "summary": "Studying the growth and metabolism of microbes provides critical insights\ninto their evolutionary adaptations to harsh environments, which are essential\nfor microbial research and biotechnology applications. In this study, we\ndeveloped an AI-driven image analysis system to efficiently segment individual\ncells and quantitatively analyze key cellular features. This system is\ncomprised of four main modules. First, a denoising algorithm enhances contrast\nand suppresses noise while preserving fine cellular details. Second, the\nSegment Anything Model (SAM) enables accurate, zero-shot segmentation of cells\nwithout additional training. Third, post-processing is applied to refine\nsegmentation results by removing over-segmented masks. Finally, quantitative\nanalysis algorithms extract essential cellular features, including average\nintensity, length, width, and volume. The results show that denoising and\npost-processing significantly improved the segmentation accuracy of SAM in this\nnew domain. Without human annotations, the AI-driven pipeline automatically and\nefficiently outlines cellular boundaries, indexes them, and calculates key\ncellular parameters with high accuracy. This framework will enable efficient\nand automated quantitative analysis of high-resolution fluorescence microscopy\nimages to advance research into microbial adaptations to grow and metabolism\nthat allow extremophiles to thrive in their harsh habitats.", "AI": {"tldr": "An AI-driven image analysis system for microbial cell segmentation and feature analysis, improving accuracy without human annotations.", "motivation": "To study microbial growth and metabolism in harsh environments, advancing microbial research and biotechnology.", "method": "Developed a four-module system: denoising, SAM for segmentation, post-processing, and quantitative feature extraction.", "result": "Denoising and post-processing enhanced SAM's segmentation accuracy, enabling automated, high-accuracy cellular analysis.", "conclusion": "The framework automates microbial image analysis, aiding research on extremophile adaptations."}}
{"id": "2505.00016", "pdf": "https://arxiv.org/pdf/2505.00016", "abs": "https://arxiv.org/abs/2505.00016", "authors": ["Josefa Lia Stoisser", "Marc Boubnovski Martell", "Julien Fauqueur"], "title": "Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This work reframes the Text-to-SQL task as a pathway for teaching large\nlanguage models (LLMs) to reason over and manipulate tabular data--moving\nbeyond the traditional focus on query generation. We propose a two-stage\nframework that leverages SQL supervision to develop transferable table\nreasoning capabilities. First, we synthesize detailed chain-of-thought (CoT)\ntraces from real-world SQL queries, providing step-by-step, clause-level\nsupervision that teaches the model how to traverse, filter, and aggregate table\nfields. Second, we introduce a Group Relative Policy Optimization (GRPO)\nreinforcement learning objective that connects SQL execution accuracy to\ngeneralizable reasoning by encouraging steps that extend beyond task-specific\nsyntax and transfer across datasets. Empirically, our approach improves\nperformance on standard Text-to-SQL benchmarks and achieves substantial gains\non reasoning-intensive datasets such as BIRD and CRT-QA, demonstrating enhanced\ngeneralization and interpretability. Specifically, the distilled-quantized\nLLaMA model achieved a 20\\% increase in accuracy when trained on Text-to-SQL\ntasks, while Qwen achieved a 5\\% increase. These results suggest that SQL can\nserve not only as a target formalism but also as an effective scaffold for\nlearning robust, transferable reasoning over structured data.", "AI": {"tldr": "The paper reframes Text-to-SQL as a method to teach LLMs table reasoning, proposing a two-stage framework with SQL supervision and reinforcement learning, showing improved performance and generalization.", "motivation": "To move beyond query generation in Text-to-SQL by teaching LLMs to reason over tabular data, enhancing generalization and interpretability.", "method": "A two-stage framework: (1) synthesizing detailed CoT traces from SQL queries for clause-level supervision, and (2) using GRPO reinforcement learning to link SQL execution accuracy to generalizable reasoning.", "result": "Improved performance on Text-to-SQL benchmarks (e.g., BIRD, CRT-QA), with LLaMA achieving a 20% accuracy increase and Qwen a 5% increase.", "conclusion": "SQL serves as both a target formalism and a scaffold for learning robust, transferable reasoning over structured data."}}
{"id": "2505.00610", "pdf": "https://arxiv.org/pdf/2505.00610", "abs": "https://arxiv.org/abs/2505.00610", "authors": ["Ziyan An", "Xia Wang", "Hendrik Baier", "Zirong Chen", "Abhishek Dubey", "Taylor T. Johnson", "Jonathan Sprinkle", "Ayan Mukhopadhyay", "Meiyi Ma"], "title": "Combining LLMs with Logic-Based Framework to Explain MCTS", "categories": ["cs.AI"], "comment": "Accepted by AAMAS-25 as an extended abstract", "summary": "In response to the lack of trust in Artificial Intelligence (AI) for\nsequential planning, we design a Computational Tree Logic-guided large language\nmodel (LLM)-based natural language explanation framework designed for the Monte\nCarlo Tree Search (MCTS) algorithm. MCTS is often considered challenging to\ninterpret due to the complexity of its search trees, but our framework is\nflexible enough to handle a wide range of free-form post-hoc queries and\nknowledge-based inquiries centered around MCTS and the Markov Decision Process\n(MDP) of the application domain. By transforming user queries into logic and\nvariable statements, our framework ensures that the evidence obtained from the\nsearch tree remains factually consistent with the underlying environmental\ndynamics and any constraints in the actual stochastic control process. We\nevaluate the framework rigorously through quantitative assessments, where it\ndemonstrates strong performance in terms of accuracy and factual consistency.", "AI": {"tldr": "A framework combining Computational Tree Logic and LLMs provides natural language explanations for MCTS, ensuring factual consistency and handling diverse queries.", "motivation": "Addressing the lack of trust in AI for sequential planning by making MCTS more interpretable.", "method": "Uses a Computational Tree Logic-guided LLM to transform user queries into logic statements for MCTS, ensuring consistency with environmental dynamics.", "result": "Demonstrates strong performance in accuracy and factual consistency through quantitative assessments.", "conclusion": "The framework successfully enhances interpretability and trust in MCTS for sequential planning."}}
{"id": "2505.00259", "pdf": "https://arxiv.org/pdf/2505.00259", "abs": "https://arxiv.org/abs/2505.00259", "authors": ["Changjun Li", "Runqing Jiang", "Zhuo Song", "Pengpeng Yu", "Ye Zhang", "Yulan Guo"], "title": "Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Post-training quantization (PTQ) has evolved as a prominent solution for\ncompressing complex models, which advocates a small calibration dataset and\navoids end-to-end retraining. However, most existing PTQ methods employ\nblock-wise reconstruction, which neglects cross-block dependency and exhibits a\nnotable accuracy drop in low-bit cases. To address these limitations, this\npaper presents a novel PTQ method, dubbed Pack-PTQ. First, we design a\nHessian-guided adaptive packing mechanism to partition blocks into\nnon-overlapping packs, which serve as the base unit for reconstruction, thereby\npreserving the cross-block dependency and enabling accurate quantization\nparameters estimation. Second, based on the pack configuration, we propose a\nmixed-precision quantization approach to assign varied bit-widths to packs\naccording to their distinct sensitivities, thereby further enhancing\nperformance. Extensive experiments on 2D image and 3D point cloud\nclassification tasks, using various network architectures, demonstrate the\nsuperiority of our method over the state-of-the-art PTQ methods.", "AI": {"tldr": "Pack-PTQ introduces a Hessian-guided adaptive packing mechanism and mixed-precision quantization to improve PTQ by preserving cross-block dependency and enhancing accuracy in low-bit cases.", "motivation": "Existing PTQ methods neglect cross-block dependency and suffer accuracy drops in low-bit scenarios, prompting the need for a more robust solution.", "method": "The method involves partitioning blocks into non-overlapping packs for reconstruction and using mixed-precision quantization based on pack sensitivity.", "result": "Experiments on 2D image and 3D point cloud tasks show Pack-PTQ outperforms state-of-the-art PTQ methods.", "conclusion": "Pack-PTQ effectively addresses PTQ limitations by preserving dependencies and optimizing bit-width allocation, achieving superior performance."}}
{"id": "2505.00210", "pdf": "https://arxiv.org/pdf/2505.00210", "abs": "https://arxiv.org/abs/2505.00210", "authors": ["Suk Ki Lee", "Hyunwoong Ko"], "title": "Generative Machine Learning in Adaptive Control of Dynamic Manufacturing Processes: A Review", "categories": ["cs.LG", "cs.CE", "cs.SY", "eess.SY"], "comment": "12 pages, 1 figure, 1 table. This paper has been accepted for\n  publication in the proceedings of ASME IDETC-CIE 2025", "summary": "Dynamic manufacturing processes exhibit complex characteristics defined by\ntime-varying parameters, nonlinear behaviors, and uncertainties. These\ncharacteristics require sophisticated in-situ monitoring techniques utilizing\nmultimodal sensor data and adaptive control systems that can respond to\nreal-time feedback while maintaining product quality. Recently, generative\nmachine learning (ML) has emerged as a powerful tool for modeling complex\ndistributions and generating synthetic data while handling these manufacturing\nuncertainties. However, adopting these generative technologies in dynamic\nmanufacturing systems lacks a functional control-oriented perspective to\ntranslate their probabilistic understanding into actionable process controls\nwhile respecting constraints. This review presents a functional classification\nof Prediction-Based, Direct Policy, Quality Inference, and Knowledge-Integrated\napproaches, offering a perspective for understanding existing ML-enhanced\ncontrol systems and incorporating generative ML. The analysis of generative ML\narchitectures within this framework demonstrates control-relevant properties\nand potential to extend current ML-enhanced approaches where conventional\nmethods prove insufficient. We show generative ML's potential for manufacturing\ncontrol through decision-making applications, process guidance, simulation, and\ndigital twins, while identifying critical research gaps: separation between\ngeneration and control functions, insufficient physical understanding of\nmanufacturing phenomena, and challenges adapting models from other domains. To\naddress these challenges, we propose future research directions aimed at\ndeveloping integrated frameworks that combine generative ML and control\ntechnologies to address the dynamic complexities of modern manufacturing\nsystems.", "AI": {"tldr": "The paper reviews generative ML's role in dynamic manufacturing, classifying ML-enhanced control systems and highlighting gaps like generation-control separation and domain adaptation challenges. It proposes future research for integrated frameworks.", "motivation": "Dynamic manufacturing's complexity and uncertainties require advanced monitoring and control. Generative ML shows promise but lacks a control-oriented perspective for actionable process controls.", "method": "The review classifies ML-enhanced control into Prediction-Based, Direct Policy, Quality Inference, and Knowledge-Integrated approaches, analyzing generative ML architectures within this framework.", "result": "Generative ML demonstrates potential in decision-making, process guidance, and digital twins but faces gaps like generation-control separation and insufficient physical understanding.", "conclusion": "Future research should focus on integrated frameworks combining generative ML and control technologies to address dynamic manufacturing complexities."}}
{"id": "2505.00643", "pdf": "https://arxiv.org/pdf/2505.00643", "abs": "https://arxiv.org/abs/2505.00643", "authors": ["Merve G\u00fclle", "Sebastian Weing\u00e4rtner", "Mehmet Ak\u00e7akaya"], "title": "Deep Learning Assisted Outer Volume Removal for Highly-Accelerated Real-Time Dynamic MRI", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.med-ph"], "comment": null, "summary": "Real-time (RT) dynamic MRI plays a vital role in capturing rapid\nphysiological processes, offering unique insights into organ motion and\nfunction. Among these applications, RT cine MRI is particularly important for\nfunctional assessment of the heart with high temporal resolution. RT imaging\nenables free-breathing, ungated imaging of cardiac motion, making it a crucial\nalternative for patients who cannot tolerate conventional breath-hold,\nECG-gated acquisitions. However, achieving high acceleration rates in RT cine\nMRI is challenging due to aliasing artifacts from extra-cardiac tissues,\nparticularly at high undersampling factors. In this study, we propose a novel\nouter volume removal (OVR) method to address this challenge by eliminating\naliasing contributions from non-cardiac regions in a post-processing framework.\nOur approach estimates the outer volume signal for each timeframe using\ncomposite temporal images from time-interleaved undersampling patterns, which\ninherently contain pseudo-periodic ghosting artifacts. A deep learning (DL)\nmodel is trained to identify and remove these artifacts, producing a clean\nouter volume estimate that is subsequently subtracted from the corresponding\nk-space data. The final reconstruction is performed with a physics-driven DL\n(PD-DL) method trained using an OVR-specific loss function to restore high\nspatio-temporal resolution images. Experimental results show that the proposed\nmethod at high accelerations achieves image quality that is visually comparable\nto clinical baseline images, while outperforming conventional reconstruction\ntechniques, both qualitatively and quantitatively. The proposed approach\nprovides a practical and effective solution for artifact reduction in RT cine\nMRI without requiring acquisition modifications, offering a pathway to higher\nacceleration rates while preserving diagnostic quality.", "AI": {"tldr": "A novel outer volume removal (OVR) method using deep learning (DL) is proposed to reduce aliasing artifacts in real-time (RT) cine MRI, achieving high acceleration rates without compromising diagnostic quality.", "motivation": "RT cine MRI is crucial for cardiac functional assessment but faces challenges like aliasing artifacts at high undersampling rates, limiting acceleration.", "method": "The OVR method estimates and removes outer volume signals using DL, followed by physics-driven DL reconstruction with an OVR-specific loss function.", "result": "The method achieves image quality comparable to clinical baselines at high accelerations, outperforming conventional techniques.", "conclusion": "The approach offers a practical solution for artifact reduction in RT cine MRI, enabling higher acceleration rates without acquisition changes."}}
{"id": "2505.00017", "pdf": "https://arxiv.org/pdf/2505.00017", "abs": "https://arxiv.org/abs/2505.00017", "authors": ["Dezheng Han", "Yibin Jia", "Ruxiao Chen", "Wenjie Han", "Shuaishuai Guo", "Jianbo Wang"], "title": "ReCellTy: Domain-specific knowledge graph retrieval-augmented LLMs workflow for single-cell annotation", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "comment": null, "summary": "To enable precise and fully automated cell type annotation with large\nlanguage models (LLMs), we developed a graph structured feature marker database\nto retrieve entities linked to differential genes for cell reconstruction. We\nfurther designed a multi task workflow to optimize the annotation process.\nCompared to general purpose LLMs, our method improves human evaluation scores\nby up to 0.21 and semantic similarity by 6.1% across 11 tissue types, while\nmore closely aligning with the cognitive logic of manual annotation.", "AI": {"tldr": "A method using graph-structured feature marker databases and multi-task workflows improves automated cell type annotation with LLMs, outperforming general-purpose LLMs in accuracy and alignment with manual logic.", "motivation": "To achieve precise and fully automated cell type annotation using large language models (LLMs) by addressing limitations of general-purpose LLMs.", "method": "Developed a graph-structured feature marker database for retrieving entities linked to differential genes and designed a multi-task workflow to optimize annotation.", "result": "Improved human evaluation scores by up to 0.21 and semantic similarity by 6.1% across 11 tissue types, better aligning with manual annotation logic.", "conclusion": "The proposed method enhances automated cell type annotation, outperforming general-purpose LLMs in accuracy and cognitive alignment."}}
{"id": "2505.00612", "pdf": "https://arxiv.org/pdf/2505.00612", "abs": "https://arxiv.org/abs/2505.00612", "authors": ["D. Sculley", "Will Cukierski", "Phil Culliton", "Sohier Dane", "Maggie Demkin", "Ryan Holbrook", "Addison Howard", "Paul Mooney", "Walter Reade", "Megan Risdal", "Nate Keating"], "title": "Position: AI Competitions Provide the Gold Standard for Empirical Rigor in GenAI Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "In this position paper, we observe that empirical evaluation in Generative AI\nis at a crisis point since traditional ML evaluation and benchmarking\nstrategies are insufficient to meet the needs of evaluating modern GenAI models\nand systems. There are many reasons for this, including the fact that these\nmodels typically have nearly unbounded input and output spaces, typically do\nnot have a well defined ground truth target, and typically exhibit strong\nfeedback loops and prediction dependence based on context of previous model\noutputs. On top of these critical issues, we argue that the problems of {\\em\nleakage} and {\\em contamination} are in fact the most important and difficult\nissues to address for GenAI evaluations. Interestingly, the field of AI\nCompetitions has developed effective measures and practices to combat leakage\nfor the purpose of counteracting cheating by bad actors within a competition\nsetting. This makes AI Competitions an especially valuable (but underutilized)\nresource. Now is time for the field to view AI Competitions as the gold\nstandard for empirical rigor in GenAI evaluation, and to harness and harvest\ntheir results with according value.", "AI": {"tldr": "The paper argues that traditional ML evaluation methods are inadequate for Generative AI due to unbounded input/output spaces, lack of ground truth, and feedback loops. It highlights leakage and contamination as critical issues and suggests AI Competitions as a gold standard for rigorous evaluation.", "motivation": "The motivation is to address the inadequacy of traditional ML evaluation strategies for modern Generative AI models, which face unique challenges like leakage and contamination.", "method": "The paper proposes leveraging AI Competitions, which have developed effective measures against leakage, as a model for rigorous GenAI evaluation.", "result": "The result is a call to adopt AI Competitions as the gold standard for evaluating Generative AI, emphasizing their underutilized potential.", "conclusion": "The conclusion advocates for the field to recognize AI Competitions as the benchmark for empirical rigor in GenAI evaluation and to utilize their practices and outcomes effectively."}}
{"id": "2505.00275", "pdf": "https://arxiv.org/pdf/2505.00275", "abs": "https://arxiv.org/abs/2505.00275", "authors": ["Md Asaduzzaman Jabin", "Hanqi Jiang", "Yiwei Li", "Patrick Kaggwa", "Eugene Douglass", "Juliet N. Sekandi", "Tianming Liu"], "title": "AdCare-VLM: Leveraging Large Vision Language Model (LVLM) to Monitor Long-Term Medication Adherence and Care", "categories": ["cs.CV"], "comment": null, "summary": "Chronic diseases, including diabetes, hypertension, asthma, HIV-AIDS,\nepilepsy, and tuberculosis, necessitate rigorous adherence to medication to\navert disease progression, manage symptoms, and decrease mortality rates.\nAdherence is frequently undermined by factors including patient behavior,\ncaregiver support, elevated medical costs, and insufficient healthcare\ninfrastructure. We propose AdCare-VLM, a specialized Video-LLaVA-based\nmultimodal large vision language model (LVLM) aimed at visual question\nanswering (VQA) concerning medication adherence through patient videos. We\nemploy a private dataset comprising 806 custom-annotated tuberculosis (TB)\nmedication monitoring videos, which have been labeled by clinical experts, to\nfine-tune the model for adherence pattern detection. We present LLM-TB-VQA, a\ndetailed medical adherence VQA dataset that encompasses positive, negative, and\nambiguous adherence cases. Our method identifies correlations between visual\nfeatures, such as the clear visibility of the patient's face, medication, water\nintake, and the act of ingestion, and their associated medical concepts in\ncaptions. This facilitates the integration of aligned visual-linguistic\nrepresentations and improves multimodal interactions. Experimental results\nindicate that our method surpasses parameter-efficient fine-tuning (PEFT)\nenabled VLM models, such as LLaVA-V1.5 and Chat-UniVi, with absolute\nimprovements ranging from 3.1% to 3.54% across pre-trained, regular, and\nlow-rank adaptation (LoRA) configurations. Comprehensive ablation studies and\nattention map visualizations substantiate our approach, enhancing\ninterpretability.", "AI": {"tldr": "AdCare-VLM, a Video-LLaVA-based multimodal model, improves medication adherence detection via visual question answering (VQA) using patient videos, outperforming existing VLMs.", "motivation": "Chronic diseases require strict medication adherence, often hindered by behavioral, financial, and infrastructural challenges. AdCare-VLM addresses this by leveraging visual and linguistic data for adherence monitoring.", "method": "The model uses a private dataset of 806 TB medication videos, fine-tuned for adherence pattern detection. It integrates visual features (e.g., face visibility, medication intake) with medical concepts in captions.", "result": "AdCare-VLM outperforms PEFT-enabled VLMs like LLaVA-V1.5 and Chat-UniVi by 3.1% to 3.54% across configurations. Ablation studies and attention maps validate its effectiveness.", "conclusion": "AdCare-VLM enhances adherence monitoring through multimodal VQA, offering improved accuracy and interpretability for chronic disease management."}}
{"id": "2505.00216", "pdf": "https://arxiv.org/pdf/2505.00216", "abs": "https://arxiv.org/abs/2505.00216", "authors": ["Xuwei Yang", "Fatemeh Tavakoli", "David B. Emerson", "Anastasis Kratsios"], "title": "Online Federation For Mixtures of Proprietary Agents with Black-Box Encoders", "categories": ["cs.LG", "cs.AI", "cs.GT", "68T05, 68T07, 91A80", "I.2.1; I.2.11; G.1.6"], "comment": "47 pages, 16 figures, 7 tables", "summary": "Most industry-standard generative AIs and feature encoders are proprietary,\noffering only black-box access: their outputs are observable, but their\ninternal parameters and architectures remain hidden from the end-user. This\nblack-box access is especially limiting when constructing mixture-of-expert\ntype ensemble models since the user cannot optimize each proprietary AI's\ninternal parameters. Our problem naturally lends itself to a non-competitive\ngame-theoretic lens where each proprietary AI (agent) is inherently competing\nagainst the other AI agents, with this competition arising naturally due to\ntheir obliviousness of the AI's to their internal structure. In contrast, the\nuser acts as a central planner trying to synchronize the ensemble of competing\nAIs.\n  We show the existence of the unique Nash equilibrium in the online setting,\nwhich we even compute in closed-form by eliciting a feedback mechanism between\nany given time series and the sequence generated by each (proprietary) AI\nagent. Our solution is implemented as a decentralized, federated-learning\nalgorithm in which each agent optimizes their structure locally on their\nmachine without ever releasing any internal structure to the others. We obtain\nrefined expressions for pre-trained models such as transformers, random feature\nmodels, and echo-state networks. Our ``proprietary federated learning''\nalgorithm is implemented on a range of real-world and synthetic time-series\nbenchmarks. It achieves orders-of-magnitude improvements in predictive accuracy\nover natural benchmarks, of which there are surprisingly few due to this\nnatural problem still being largely unexplored.", "AI": {"tldr": "The paper addresses the challenge of optimizing proprietary AI models in ensemble settings by proposing a game-theoretic approach and a decentralized federated-learning algorithm, achieving significant accuracy improvements.", "motivation": "Proprietary AIs limit user control over internal parameters, hindering optimization in ensemble models. The paper explores this problem through a non-competitive game-theoretic lens.", "method": "A Nash equilibrium is derived in an online setting, and a decentralized federated-learning algorithm is implemented, allowing local optimization without sharing internal structures.", "result": "The algorithm shows orders-of-magnitude improvements in predictive accuracy on real-world and synthetic benchmarks.", "conclusion": "The proposed method effectively synchronizes competing proprietary AIs, offering a practical solution for ensemble optimization."}}
{"id": "2505.00687", "pdf": "https://arxiv.org/pdf/2505.00687", "abs": "https://arxiv.org/abs/2505.00687", "authors": ["Aditya Arora", "Zhengzhong Tu", "Yufei Wang", "Ruizheng Bai", "Jian Wang", "Sizhuo Ma"], "title": "GuideSR: Rethinking Guidance for One-Step High-Fidelity Diffusion-Based Super-Resolution", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In this paper, we propose GuideSR, a novel single-step diffusion-based image\nsuper-resolution (SR) model specifically designed to enhance image fidelity.\nExisting diffusion-based SR approaches typically adapt pre-trained generative\nmodels to image restoration tasks by adding extra conditioning on a\nVAE-downsampled representation of the degraded input, which often compromises\nstructural fidelity. GuideSR addresses this limitation by introducing a\ndual-branch architecture comprising: (1) a Guidance Branch that preserves\nhigh-fidelity structures from the original-resolution degraded input, and (2) a\nDiffusion Branch, which a pre-trained latent diffusion model to enhance\nperceptual quality. Unlike conventional conditioning mechanisms, our Guidance\nBranch features a tailored structure for image restoration tasks, combining\nFull Resolution Blocks (FRBs) with channel attention and an Image Guidance\nNetwork (IGN) with guided attention. By embedding detailed structural\ninformation directly into the restoration pipeline, GuideSR produces sharper\nand more visually consistent results. Extensive experiments on benchmark\ndatasets demonstrate that GuideSR achieves state-of-the-art performance while\nmaintaining the low computational cost of single-step approaches, with up to\n1.39dB PSNR gain on challenging real-world datasets. Our approach consistently\noutperforms existing methods across various reference-based metrics including\nPSNR, SSIM, LPIPS, DISTS and FID, further representing a practical advancement\nfor real-world image restoration.", "AI": {"tldr": "GuideSR is a single-step diffusion-based image super-resolution model that enhances image fidelity using a dual-branch architecture, outperforming existing methods in performance and efficiency.", "motivation": "Existing diffusion-based SR methods compromise structural fidelity by relying on degraded input conditioning. GuideSR aims to preserve high-fidelity structures while enhancing perceptual quality.", "method": "GuideSR uses a dual-branch architecture: a Guidance Branch for preserving structures and a Diffusion Branch for perceptual enhancement. It incorporates Full Resolution Blocks, channel attention, and an Image Guidance Network.", "result": "GuideSR achieves state-of-the-art performance with up to 1.39dB PSNR gain, excelling in metrics like PSNR, SSIM, LPIPS, DISTS, and FID.", "conclusion": "GuideSR advances real-world image restoration by combining structural fidelity and perceptual quality in a computationally efficient single-step approach."}}
{"id": "2505.00019", "pdf": "https://arxiv.org/pdf/2505.00019", "abs": "https://arxiv.org/abs/2505.00019", "authors": ["Zheng Zhang", "Jinyi Li", "Yihuai Lan", "Xiang Wang", "Hao Wang"], "title": "An Empirical Study on Prompt Compression for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by Building Trust Workshop at ICLR 2025", "summary": "Prompt engineering enables Large Language Models (LLMs) to perform a variety\nof tasks. However, lengthy prompts significantly increase computational\ncomplexity and economic costs. To address this issue, we study six prompt\ncompression methods for LLMs, aiming to reduce prompt length while maintaining\nLLM response quality. In this paper, we present a comprehensive analysis\ncovering aspects such as generation performance, model hallucinations, efficacy\nin multimodal tasks, word omission analysis, and more. We evaluate these\nmethods across 13 datasets, including news, scientific articles, commonsense\nQA, math QA, long-context QA, and VQA datasets. Our experiments reveal that\nprompt compression has a greater impact on LLM performance in long contexts\ncompared to short ones. In the Longbench evaluation, moderate compression even\nenhances LLM performance. Our code and data is available at\nhttps://github.com/3DAgentWorld/Toolkit-for-Prompt-Compression.", "AI": {"tldr": "The paper explores six prompt compression methods for LLMs to reduce computational costs while maintaining response quality, evaluating them across 13 datasets.", "motivation": "Lengthy prompts increase computational complexity and costs, prompting the need for efficient compression methods.", "method": "Six prompt compression methods are studied and evaluated on 13 diverse datasets.", "result": "Prompt compression impacts LLM performance more in long contexts; moderate compression can enhance performance.", "conclusion": "Efficient prompt compression is feasible and beneficial, especially for long-context tasks."}}
{"id": "2505.00651", "pdf": "https://arxiv.org/pdf/2505.00651", "abs": "https://arxiv.org/abs/2505.00651", "authors": ["Yazan Otoum", "Arghavan Asad", "Ishtiaq Ahmad"], "title": "Open-Source LLM-Driven Federated Transformer for Predictive IoV Management", "categories": ["cs.AI", "cs.ET", "cs.LG"], "comment": "Preprint version; submitted for academic peer review", "summary": "The proliferation of connected vehicles within the Internet of Vehicles (IoV)\necosystem presents critical challenges in ensuring scalable, real-time, and\nprivacy-preserving traffic management. Existing centralized IoV solutions often\nsuffer from high latency, limited scalability, and reliance on proprietary\nArtificial Intelligence (AI) models, creating significant barriers to\nwidespread deployment, particularly in dynamic and privacy-sensitive\nenvironments. Meanwhile, integrating Large Language Models (LLMs) in vehicular\nsystems remains underexplored, especially concerning prompt optimization and\neffective utilization in federated contexts. To address these challenges, we\npropose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel\nframework that leverages open-source LLMs for predictive IoV management. FPoTT\nintroduces a dynamic prompt optimization mechanism that iteratively refines\ntextual prompts to enhance trajectory prediction. The architecture employs a\ndual-layer federated learning paradigm, combining lightweight edge models for\nreal-time inference with cloud-based LLMs to retain global intelligence. A\nTransformer-driven synthetic data generator is incorporated to augment training\nwith diverse, high-fidelity traffic scenarios in the Next Generation Simulation\n(NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing\nEleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data\nwhile maintaining high performance on synthetic datasets. These results\nunderscore the potential of open-source LLMs in enabling secure, adaptive, and\nscalable IoV management, offering a promising alternative to proprietary\nsolutions in smart mobility ecosystems.", "AI": {"tldr": "FPoTT is a federated learning framework using open-source LLMs for scalable, real-time, and privacy-preserving IoV traffic management, achieving high prediction accuracy.", "motivation": "Addressing challenges like latency, scalability, and privacy in centralized IoV solutions, and exploring LLMs in federated contexts.", "method": "FPoTT uses dynamic prompt optimization, dual-layer federated learning, and a Transformer-driven synthetic data generator.", "result": "Achieves 99.86% prediction accuracy on real-world data and performs well on synthetic datasets.", "conclusion": "Open-source LLMs like FPoTT offer a secure, adaptive, and scalable alternative to proprietary IoV solutions."}}
{"id": "2505.00295", "pdf": "https://arxiv.org/pdf/2505.00295", "abs": "https://arxiv.org/abs/2505.00295", "authors": ["Xinlong Zhao", "Shan Du"], "title": "Fine-grained spatial-temporal perception for gas leak segmentation", "categories": ["cs.CV", "cs.AI", "68T45 (Primary), 68T07 (Secondary)", "I.2.10; I.4.6"], "comment": "6 pages, 4 figures, ICIP 2025 Conference", "summary": "Gas leaks pose significant risks to human health and the environment. Despite\nlong-standing concerns, there are limited methods that can efficiently and\naccurately detect and segment leaks due to their concealed appearance and\nrandom shapes. In this paper, we propose a Fine-grained Spatial-Temporal\nPerception (FGSTP) algorithm for gas leak segmentation. FGSTP captures critical\nmotion clues across frames and integrates them with refined object features in\nan end-to-end network. Specifically, we first construct a correlation volume to\ncapture motion information between consecutive frames. Then, the fine-grained\nperception progressively refines the object-level features using previous\noutputs. Finally, a decoder is employed to optimize boundary segmentation.\nBecause there is no highly precise labeled dataset for gas leak segmentation,\nwe manually label a gas leak video dataset, GasVid. Experimental results on\nGasVid demonstrate that our model excels in segmenting non-rigid objects such\nas gas leaks, generating the most accurate mask compared to other\nstate-of-the-art (SOTA) models.", "AI": {"tldr": "Proposes FGSTP algorithm for gas leak segmentation, outperforming SOTA models on the manually labeled GasVid dataset.", "motivation": "Gas leaks are hazardous but hard to detect due to concealed appearance and random shapes. Limited efficient methods exist.", "method": "FGSTP captures motion clues via correlation volume, refines object features progressively, and uses a decoder for boundary segmentation.", "result": "FGSTP excels in segmenting non-rigid gas leaks, producing the most accurate masks on GasVid.", "conclusion": "FGSTP is effective for gas leak segmentation, validated by superior performance on GasVid."}}
{"id": "2505.00225", "pdf": "https://arxiv.org/pdf/2505.00225", "abs": "https://arxiv.org/abs/2505.00225", "authors": ["Bogireddy Sai Prasanna Teja", "Valliappan Muthukaruppan", "Carls Benjamin"], "title": "Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As climate variability increases, the ability of utility providers to deliver\nprecise Estimated Times of Restoration (ETR) during natural disasters has\nbecome increasingly critical. Accurate and timely ETRs are essential for\nenabling customer preparedness during extended power outages, where informed\ndecision-making can be crucial, particularly in severe weather conditions.\nNonetheless, prevailing utility practices predominantly depend on manual\nassessments or traditional statistical methods, which often fail to achieve the\nlevel of precision required for reliable and actionable predictions. To address\nthese limitations, we propose a Longitudinal Tabular Transformer (LTT) model\nthat leverages historical outage event data along with sequential updates of\nthese events to improve the accuracy of ETR predictions. The model's\nperformance was evaluated over 34,000 storm-related outage events from three\nmajor utility companies, collectively serving over 3 million customers over a\n2-year period. Results demonstrate that the LTT model improves the Customer\nSatisfaction Impact (CSI) metric by an average of 19.08% (p > 0.001) compared\nto existing methods. Additionally, we introduce customer-informed regression\nmetrics that align model evaluation with real-world satisfaction, ensuring the\noutcomes resonate with customer expectations. Furthermore, we employ\ninterpretability techniques to analyze the temporal significance of\nincorporating sequential updates in modeling outage events and to identify the\ncontributions of predictive features to a given ETR. This comprehensive\napproach not only improves predictive accuracy but also enhances transparency,\nfostering greater trust in the model's capabilities.", "AI": {"tldr": "A Longitudinal Tabular Transformer (LTT) model improves ETR prediction accuracy by 19.08%, enhancing customer satisfaction during power outages.", "motivation": "Climate variability increases the need for precise ETRs during disasters, but current methods lack accuracy.", "method": "Proposes LTT model using historical outage data and sequential updates for better predictions.", "result": "LTT improves CSI by 19.08% and introduces customer-informed metrics for better alignment with satisfaction.", "conclusion": "LTT enhances accuracy and transparency, fostering trust in ETR predictions."}}
{"id": "2505.00265", "pdf": "https://arxiv.org/pdf/2505.00265", "abs": "https://arxiv.org/abs/2505.00265", "authors": ["Yi Yu", "Patrick Filippi", "Thomas F. A. Bishop"], "title": "Field-scale soil moisture estimated from Sentinel-1 SAR data using a knowledge-guided deep learning approach", "categories": ["cs.LG", "eess.IV"], "comment": "Accepted by the 2025 IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS 2025)", "summary": "Soil moisture (SM) estimation from active microwave data remains challenging\ndue to the complex interactions between radar backscatter and surface\ncharacteristics. While the water cloud model (WCM) provides a semi-physical\napproach for understanding these interactions, its empirical component often\nlimits performance across diverse agricultural landscapes. This research\npresents preliminary efforts for developing a knowledge-guided deep learning\napproach, which integrates WCM principles into a long short-term memory (LSTM)\nmodel, to estimate field SM using Sentinel-1 Synthetic Aperture Radar (SAR)\ndata. Our proposed approach leverages LSTM's capacity to capture spatiotemporal\ndependencies while maintaining physical consistency through a modified\ndual-component loss function, including a WCM-based semi-physical component and\na boundary condition regularisation. The proposed approach is built upon the\nsoil backscatter coefficients isolated from the total backscatter, together\nwith Landsat-resolution vegetation information and surface characteristics. A\nfour-fold spatial cross-validation was performed against in-situ SM data to\nassess the model performance. Results showed the proposed approach reduced SM\nretrieval uncertainties by 0.02 m$^3$/m$^3$ and achieved correlation\ncoefficients (R) of up to 0.64 in areas with varying vegetation cover and\nsurface conditions, demonstrating the potential to address the\nover-simplification in WCM.", "AI": {"tldr": "A knowledge-guided deep learning approach combining WCM principles with LSTM improves soil moisture estimation from Sentinel-1 SAR data, reducing uncertainties and enhancing accuracy.", "motivation": "Current soil moisture estimation methods, like the water cloud model (WCM), are limited by empirical components and oversimplification in diverse landscapes.", "method": "Integrates WCM into an LSTM model with a dual-component loss function, using Sentinel-1 SAR data, vegetation info, and surface characteristics.", "result": "Reduced SM uncertainties by 0.02 m\u00b3/m\u00b3 and achieved R up to 0.64 in varied conditions.", "conclusion": "The approach shows promise in addressing WCM limitations and improving SM estimation accuracy."}}
{"id": "2505.00020", "pdf": "https://arxiv.org/pdf/2505.00020", "abs": "https://arxiv.org/abs/2505.00020", "authors": ["Sruly Rosenblat", "Tim O'Reilly", "Ilan Strauss"], "title": "Beyond Public Access in LLM Pre-Training Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Using a legally obtained dataset of 34 copyrighted O'Reilly Media books, we\napply the DE-COP membership inference attack method to investigate whether\nOpenAI's large language models were trained on copyrighted content without\nconsent. Our AUROC scores show that GPT-4o, OpenAI's more recent and capable\nmodel, demonstrates strong recognition of paywalled O'Reilly book content\n(AUROC = 82\\%), compared to OpenAI's earlier model GPT-3.5 Turbo. In contrast,\nGPT-3.5 Turbo shows greater relative recognition of publicly accessible\nO'Reilly book samples. GPT-4o Mini, as a much smaller model, shows no knowledge\nof public or non-public O'Reilly Media content when tested (AUROC $\\approx$\n50\\%). Testing multiple models, with the same cutoff date, helps us account for\npotential language shifts over time that might bias our findings. These results\nhighlight the urgent need for increased corporate transparency regarding\npre-training data sources as a means to develop formal licensing frameworks for\nAI content training", "AI": {"tldr": "The paper investigates if OpenAI's models (GPT-4o, GPT-3.5 Turbo, GPT-4o Mini) were trained on copyrighted O'Reilly books without consent. Results show GPT-4o recognizes paywalled content strongly, while GPT-3.5 Turbo favors public content. GPT-4o Mini shows no recognition. The study calls for transparency in AI training data.", "motivation": "To determine if OpenAI's models were trained on copyrighted O'Reilly Media books without permission, raising concerns about data sourcing ethics.", "method": "Applied the DE-COP membership inference attack on 34 O'Reilly books, testing models (GPT-4o, GPT-3.5 Turbo, GPT-4o Mini) with AUROC scores.", "result": "GPT-4o recognized paywalled content (AUROC=82%), GPT-3.5 Turbo recognized public content better, and GPT-4o Mini showed no recognition (AUROC\u224850%).", "conclusion": "The findings emphasize the need for corporate transparency and formal licensing frameworks for AI training data."}}
{"id": "2505.00308", "pdf": "https://arxiv.org/pdf/2505.00308", "abs": "https://arxiv.org/abs/2505.00308", "authors": ["Biling Wang", "Austen Maniscalco", "Ti Bai", "Siqiu Wang", "Michael Dohopolski", "Mu-Han Lin", "Chenyang Shen", "Dan Nguyen", "Junzhou Huang", "Steve Jiang", "Xinlei Wang"], "title": "AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality", "categories": ["cs.CV", "cs.AI", "stat.AP"], "comment": null, "summary": "Purpose: This study presents a Deep Learning (DL)-based quality assessment\n(QA) approach for evaluating auto-generated contours (auto-contours) in\nradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging\nBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,\nthe method enables confident QA predictions without relying on ground truth\ncontours or extensive manual labeling. Methods: We developed a BOC model to\nclassify auto-contour quality and quantify prediction uncertainty. A\ncalibration step was used to optimize uncertainty thresholds that meet clinical\naccuracy needs. The method was validated under three data scenarios: no manual\nlabels, limited labels, and extensive labels. For rectum contours in prostate\ncancer, we applied geometric surrogate labels when manual labels were absent,\ntransfer learning when limited, and direct supervision when ample labels were\navailable. Results: The BOC model delivered robust performance across all\nscenarios. Fine-tuning with just 30 manual labels and calibrating with 34\nsubjects yielded over 90% accuracy on test data. Using the calibrated\nthreshold, over 93% of the auto-contours' qualities were accurately predicted\nin over 98% of cases, reducing unnecessary manual reviews and highlighting\ncases needing correction. Conclusion: The proposed QA model enhances contouring\nefficiency in OART by reducing manual workload and enabling fast, informed\nclinical decisions. Through uncertainty quantification, it ensures safer, more\nreliable radiotherapy workflows.", "AI": {"tldr": "A Deep Learning-based QA method for auto-contours in radiotherapy uses Bayesian Ordinal Classification and uncertainty thresholds to reduce manual workload and improve accuracy.", "motivation": "To enhance efficiency in Online Adaptive Radiotherapy by reducing reliance on ground truth contours and manual labeling for quality assessment.", "method": "Developed a Bayesian Ordinal Classification model with calibrated uncertainty thresholds, validated under three data scenarios: no labels, limited labels, and extensive labels.", "result": "Achieved over 90% accuracy with minimal manual labels (30) and calibration (34 subjects), accurately predicting 93% of auto-contour qualities in 98% of cases.", "conclusion": "The method improves radiotherapy workflows by reducing manual reviews and ensuring reliable, fast clinical decisions through uncertainty quantification."}}
{"id": "2505.00232", "pdf": "https://arxiv.org/pdf/2505.00232", "abs": "https://arxiv.org/abs/2505.00232", "authors": ["Jiuqiang Tang", "Raman Sarokin", "Ekaterina Ignasheva", "Grant Jensen", "Lin Chen", "Juhyun Lee", "Andrei Kulik", "Matthias Grundmann"], "title": "Scaling On-Device GPU Inference for Large Generative Models", "categories": ["cs.LG", "cs.AI"], "comment": "to be published in CVPR 2025 Workshop on Efficient and On-Device\n  Generation (EDGE)", "summary": "Driven by the advancements in generative AI, large machine learning models\nhave revolutionized domains such as image processing, audio synthesis, and\nspeech recognition. While server-based deployments remain the locus of peak\nperformance, the imperative for on-device inference, necessitated by privacy\nand efficiency considerations, persists. Recognizing GPUs as the on-device ML\naccelerator with the widest reach, we present ML Drift--an optimized framework\nthat extends the capabilities of state-of-the-art GPU-accelerated inference\nengines. ML Drift enables on-device execution of generative AI workloads which\ncontain 10 to 100x more parameters than existing on-device generative AI\nmodels. ML Drift addresses intricate engineering challenges associated with\ncross-GPU API development, and ensures broad compatibility across mobile and\ndesktop/laptop platforms, thereby facilitating the deployment of significantly\nmore complex models on resource-constrained devices. Our GPU-accelerated ML/AI\ninference engine achieves an order-of-magnitude performance improvement\nrelative to existing open-source GPU inference engines.", "AI": {"tldr": "ML Drift is an optimized framework for on-device GPU-accelerated inference, enabling execution of generative AI models with 10-100x more parameters than current on-device models, while improving performance by an order of magnitude.", "motivation": "The need for on-device inference due to privacy and efficiency concerns, despite server-based deployments offering peak performance.", "method": "ML Drift extends state-of-the-art GPU-accelerated inference engines, addressing cross-GPU API challenges and ensuring compatibility across platforms.", "result": "Achieves an order-of-magnitude performance improvement over existing open-source GPU inference engines.", "conclusion": "ML Drift facilitates deployment of complex generative AI models on resource-constrained devices, broadening the scope of on-device AI applications."}}
{"id": "2505.00326", "pdf": "https://arxiv.org/pdf/2505.00326", "abs": "https://arxiv.org/abs/2505.00326", "authors": ["Apratim Dey", "David Donoho"], "title": "Optimal Vector Compressed Sensing Using James Stein Shrinkage", "categories": ["cs.LG", "eess.IV", "eess.SP", "stat.CO", "stat.ME"], "comment": "69 pages", "summary": "The trend in modern science and technology is to take vector measurements\nrather than scalars, ruthlessly scaling to ever higher dimensional vectors. For\nabout two decades now, traditional scalar Compressed Sensing has been\nsynonymous with a Convex Optimization based procedure called Basis Pursuit. In\nthe vector recovery case, the natural tendency is to return to a\nstraightforward vector extension of Basis Pursuit, also based on Convex\nOptimization. However, Convex Optimization is provably suboptimal, particularly\nwhen $B$ is large. In this paper, we propose SteinSense, a lightweight\niterative algorithm, which is provably optimal when $B$ is large. It does not\nhave any tuning parameter, does not need any training data, requires zero\nknowledge of sparsity, is embarrassingly simple to implement, and all of this\nmakes it easily scalable to high vector dimensions. We conduct a massive volume\nof both real and synthetic experiments that confirm the efficacy of SteinSense,\nand also provide theoretical justification based on ideas from Approximate\nMessage Passing. Fascinatingly, we discover that SteinSense is quite robust,\ndelivering the same quality of performance on real data, and even under\nsubstantial departures from conditions under which existing theory holds.", "AI": {"tldr": "SteinSense is a lightweight, optimal algorithm for high-dimensional vector recovery, outperforming traditional convex optimization methods like Basis Pursuit.", "motivation": "Traditional convex optimization methods for vector recovery are suboptimal, especially for large dimensions. SteinSense addresses this gap.", "method": "SteinSense is a tuning-free, training-free, and sparsity-agnostic iterative algorithm, scalable to high dimensions.", "result": "Extensive experiments confirm SteinSense's efficacy and robustness, even under non-ideal conditions.", "conclusion": "SteinSense is a simple, scalable, and theoretically justified solution for high-dimensional vector recovery."}}
{"id": "2505.00021", "pdf": "https://arxiv.org/pdf/2505.00021", "abs": "https://arxiv.org/abs/2505.00021", "authors": ["Zhuoang Cai", "Zhenghao Li", "Yang Liu", "Liyuan Guo", "Yangqiu Song"], "title": "Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Classification tasks often suffer from imbal- anced data distribution, which\npresents chal- lenges in food hazard detection due to severe class imbalances,\nshort and unstructured text, and overlapping semantic categories. In this\npaper, we present our system for SemEval- 2025 Task 9: Food Hazard Detection,\nwhich ad- dresses these issues by applying data augmenta- tion techniques to\nimprove classification perfor- mance. We utilize transformer-based models, BERT\nand RoBERTa, as backbone classifiers and explore various data balancing\nstrategies, including random oversampling, Easy Data Augmentation (EDA), and\nfocal loss. Our ex- periments show that EDA effectively mitigates class\nimbalance, leading to significant improve- ments in accuracy and F1 scores.\nFurthermore, combining focal loss with oversampling and EDA further enhances\nmodel robustness, par- ticularly for hard-to-classify examples. These findings\ncontribute to the development of more effective NLP-based classification models\nfor food hazard detection.", "AI": {"tldr": "The paper addresses class imbalance in food hazard detection using data augmentation and transformer models, showing improved performance with EDA and focal loss.", "motivation": "Challenges like severe class imbalance, unstructured text, and overlapping categories in food hazard detection motivated the study.", "method": "Used BERT and RoBERTa with data balancing strategies (random oversampling, EDA, focal loss).", "result": "EDA improved accuracy and F1 scores; combining focal loss with oversampling and EDA enhanced robustness.", "conclusion": "The approach advances NLP-based models for food hazard detection by effectively handling class imbalance."}}
{"id": "2505.00022", "pdf": "https://arxiv.org/pdf/2505.00022", "abs": "https://arxiv.org/abs/2505.00022", "authors": ["Thomas F Burns", "Letitia Parcalabescu", "Stephan W\u00e4ldchen", "Michael Barlow", "Gregor Ziegltrum", "Volker Stampa", "Bastian Harren", "Bj\u00f6rn Deiseroth"], "title": "Aleph-Alpha-GermanWeb: Improving German-language LLM pre-training with model-based data curation and synthetic data generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 3 figures", "summary": "Scaling data quantity is essential for large language models (LLMs), yet\nrecent findings show that data quality can significantly boost performance and\ntraining efficiency. We introduce a German-language dataset curation pipeline\nthat combines heuristic and model-based filtering techniques with synthetic\ndata generation. We use our pipeline to create Aleph-Alpha-GermanWeb, a\nlarge-scale German pre-training dataset which draws from: (1) Common Crawl web\ndata, (2) FineWeb2, and (3) synthetically-generated data conditioned on actual,\norganic web data. We evaluate our dataset by pre-training both a 1B Llama-style\nmodel and an 8B tokenizer-free hierarchical autoregressive transformer (HAT). A\ncomparison on German-language benchmarks, including MMMLU, shows significant\nperformance gains of Aleph-Alpha-GermanWeb over FineWeb2 alone. This advantage\nholds at the 8B scale even when FineWeb2 is enriched by human-curated\nhigh-quality data sources such as Wikipedia. Our findings support the growing\nbody of evidence that model-based data curation and synthetic data generation\ncan significantly enhance LLM pre-training datasets.", "AI": {"tldr": "A German dataset curation pipeline combining heuristic and model-based filtering with synthetic data generation improves LLM performance over existing datasets.", "motivation": "To enhance LLM performance and training efficiency by focusing on data quality, particularly for German-language models.", "method": "Combines heuristic and model-based filtering with synthetic data generation to create Aleph-Alpha-GermanWeb, a large-scale German pre-training dataset.", "result": "Aleph-Alpha-GermanWeb outperforms FineWeb2 and enriched datasets on German benchmarks, even at larger scales.", "conclusion": "Model-based data curation and synthetic data generation significantly enhance LLM pre-training datasets."}}
{"id": "2505.00312", "pdf": "https://arxiv.org/pdf/2505.00312", "abs": "https://arxiv.org/abs/2505.00312", "authors": ["Muhammad Salman", "Iqra Tariq", "Mishal Zulfiqar", "Muqadas Jalal", "Sami Aujla", "Sumbal Fatima"], "title": "AWARE-NET: Adaptive Weighted Averaging for Robust Ensemble Network in Deepfake Detection", "categories": ["cs.CV"], "comment": null, "summary": "Deepfake detection has become increasingly important due to the rise of\nsynthetic media, which poses significant risks to digital identity and cyber\npresence for security and trust. While multiple approaches have improved\ndetection accuracy, challenges remain in achieving consistent performance\nacross diverse datasets and manipulation types. In response, we propose a novel\ntwo-tier ensemble framework for deepfake detection based on deep learning that\nhierarchically combines multiple instances of three state-of-the-art\narchitectures: Xception, Res2Net101, and EfficientNet-B7. Our framework employs\na unique approach where each architecture is instantiated three times with\ndifferent initializations to enhance model diversity, followed by a learnable\nweighting mechanism that dynamically combines their predictions. Unlike\ntraditional fixed-weight ensembles, our first-tier averages predictions within\neach architecture family to reduce model variance, while the second tier learns\noptimal contribution weights through backpropagation, automatically adjusting\neach architecture's influence based on their detection reliability. Our\nexperiments achieved state-of-the-art intra-dataset performance with AUC scores\nof 99.22% (FF++) and 100.00% (CelebDF-v2), and F1 scores of 98.06% (FF++) and\n99.94% (CelebDF-v2) without augmentation. With augmentation, we achieve AUC\nscores of 99.47% (FF++) and 100.00% (CelebDF-v2), and F1 scores of 98.43%\n(FF++) and 99.95% (CelebDF-v2). The framework demonstrates robust cross-dataset\ngeneralization, achieving AUC scores of 88.20% and 72.52%, and F1 scores of\n93.16% and 80.62% in cross-dataset evaluations.", "AI": {"tldr": "A novel two-tier ensemble framework for deepfake detection combines multiple deep learning architectures with dynamic weighting, achieving state-of-the-art performance on intra- and cross-dataset evaluations.", "motivation": "The rise of synthetic media poses risks to digital identity and trust, necessitating improved deepfake detection methods that perform consistently across diverse datasets and manipulation types.", "method": "A two-tier ensemble framework hierarchically combines Xception, Res2Net101, and EfficientNet-B7 architectures, using multiple instances with different initializations and a learnable weighting mechanism.", "result": "Achieved high AUC (up to 100%) and F1 scores (up to 99.95%) on intra-dataset tests and robust cross-dataset generalization (AUC up to 88.20%, F1 up to 93.16%).", "conclusion": "The proposed framework enhances deepfake detection accuracy and generalization, addressing challenges in diverse dataset performance."}}
{"id": "2505.00234", "pdf": "https://arxiv.org/pdf/2505.00234", "abs": "https://arxiv.org/abs/2505.00234", "authors": ["Vishnu Sarukkai", "Zhiqiang Xie", "Kayvon Fatahalian"], "title": "Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Many methods for improving Large Language Model (LLM) agents for sequential\ndecision-making tasks depend on task-specific knowledge engineering--such as\nprompt tuning, curated in-context examples, or customized observation and\naction spaces. Using these approaches, agent performance improves with the\nquality or amount of knowledge engineering invested. Instead, we investigate\nhow LLM agents can automatically improve their performance by learning\nin-context from their own successful experiences on similar tasks. Rather than\nrelying on task-specific knowledge engineering, we focus on constructing and\nrefining a database of self-generated examples. We demonstrate that even a\nnaive accumulation of successful trajectories across training tasks boosts test\nperformance on three benchmarks: ALFWorld (73% to 89%), Wordcraft (55% to 64%),\nand InterCode-SQL (75% to 79%)--matching the performance the initial agent\nachieves if allowed two to three attempts per task. We then introduce two\nextensions: (1) database-level selection through population-based training to\nidentify high-performing example collections, and (2) exemplar-level selection\nthat retains individual trajectories based on their empirical utility as\nin-context examples. These extensions further enhance performance, achieving\n91% on ALFWorld--matching more complex approaches that employ task-specific\ncomponents and prompts. Our results demonstrate that automatic trajectory\ndatabase construction offers a compelling alternative to labor-intensive\nknowledge engineering.", "AI": {"tldr": "LLM agents improve performance by learning from their own successful experiences, reducing reliance on task-specific knowledge engineering.", "motivation": "To avoid labor-intensive task-specific knowledge engineering and enable LLM agents to learn automatically from their experiences.", "method": "Construct and refine a database of self-generated examples, with extensions like database-level and exemplar-level selection.", "result": "Performance improved on benchmarks (ALFWorld, Wordcraft, InterCode-SQL), matching or exceeding task-specific approaches.", "conclusion": "Automatic trajectory database construction is a viable alternative to manual knowledge engineering."}}
{"id": "2505.00584", "pdf": "https://arxiv.org/pdf/2505.00584", "abs": "https://arxiv.org/abs/2505.00584", "authors": ["Mathis Morales", "Golnaz Habibi"], "title": "Synthesizing and Identifying Noise Levels in Autonomous Vehicle Camera Radar Datasets", "categories": ["cs.CV", "cs.AI", "eess.IV", "eess.SP"], "comment": null, "summary": "Detecting and tracking objects is a crucial component of any autonomous\nnavigation method. For the past decades, object detection has yielded promising\nresults using neural networks on various datasets. While many methods focus on\nperformance metrics, few projects focus on improving the robustness of these\ndetection and tracking pipelines, notably to sensor failures. In this paper we\nattempt to address this issue by creating a realistic synthetic data\naugmentation pipeline for camera-radar Autonomous Vehicle (AV) datasets. Our\ngoal is to accurately simulate sensor failures and data deterioration due to\nreal-world interferences. We also present our results of a baseline lightweight\nNoise Recognition neural network trained and tested on our augmented dataset,\nreaching an overall recognition accuracy of 54.4\\% on 11 categories across\n10086 images and 2145 radar point-clouds.", "AI": {"tldr": "A synthetic data augmentation pipeline for camera-radar AV datasets is proposed to improve robustness against sensor failures, with a baseline noise recognition model achieving 54.4% accuracy.", "motivation": "Addressing the lack of focus on robustness in object detection and tracking pipelines, particularly for sensor failures.", "method": "Creating a realistic synthetic data augmentation pipeline to simulate sensor failures and data deterioration, and training a lightweight Noise Recognition neural network.", "result": "The baseline model achieved 54.4% recognition accuracy on 11 categories across 10086 images and 2145 radar point-clouds.", "conclusion": "The synthetic data augmentation pipeline and baseline model show promise for improving robustness in AV object detection and tracking."}}
{"id": "2505.00023", "pdf": "https://arxiv.org/pdf/2505.00023", "abs": "https://arxiv.org/abs/2505.00023", "authors": ["Hyunji Lee", "Franck Dernoncourt", "Trung Bui", "Seunghyun Yoon"], "title": "CORG: Generating Answers from Complex, Interrelated Contexts", "categories": ["cs.CL", "cs.AI"], "comment": "published at Findings of NAACL 2025", "summary": "In a real-world corpus, knowledge frequently recurs across documents but\noften contains inconsistencies due to ambiguous naming, outdated information,\nor errors, leading to complex interrelationships between contexts. Previous\nresearch has shown that language models struggle with these complexities,\ntypically focusing on single factors in isolation. We classify these\nrelationships into four types: distracting, ambiguous, counterfactual, and\nduplicated. Our analysis reveals that no single approach effectively addresses\nall these interrelationships simultaneously. Therefore, we introduce Context\nOrganizer (CORG), a framework that organizes multiple contexts into\nindependently processed groups. This design allows the model to efficiently\nfind all relevant answers while ensuring disambiguation. CORG consists of three\nkey components: a graph constructor, a reranker, and an aggregator. Our results\ndemonstrate that CORG balances performance and efficiency effectively,\noutperforming existing grouping methods and achieving comparable results to\nmore computationally intensive, single-context approaches.", "AI": {"tldr": "The paper introduces CORG, a framework to handle recurring but inconsistent knowledge in documents by organizing contexts into groups, outperforming existing methods.", "motivation": "Address inconsistencies in recurring knowledge across documents due to ambiguous naming, outdated info, or errors, which existing models struggle with.", "method": "Classifies interrelationships into four types, then introduces CORG with a graph constructor, reranker, and aggregator to organize contexts.", "result": "CORG balances performance and efficiency, outperforming grouping methods and matching single-context approaches.", "conclusion": "CORG effectively organizes and disambiguates multiple contexts, offering a scalable solution for complex knowledge relationships."}}
{"id": "2505.00024", "pdf": "https://arxiv.org/pdf/2505.00024", "abs": "https://arxiv.org/abs/2505.00024", "authors": ["Shaokun Zhang", "Yi Dong", "Jieyu Zhang", "Jan Kautz", "Bryan Catanzaro", "Andrew Tao", "Qingyun Wu", "Zhiding Yu", "Guilin Liu"], "title": "Nemotron-Research-Tool-N1: Tool-Using Language Models with Reinforced Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 4 tables, 5 figures", "summary": "Enabling large language models with external tools has become a pivotal\nstrategy for extending their functionality beyond text generation tasks. Prior\nwork typically enhances tool-use abilities by either applying supervised\nfine-tuning (SFT) to enforce tool-call correctness or distilling reasoning\ntraces from stronger models for SFT. However, both approaches fall short,\neither omitting reasoning entirely or producing imitative reasoning that limits\ngeneralization. Inspired by the success of DeepSeek-R1 in eliciting reasoning\nthrough rule-based reinforcement learning, we develop the\nNemotron-Research-Tool-N1 series of tool-using language models using a similar\ntraining paradigm. Instead of restrictively supervising intermediate reasoning\ntraces distilled from stronger models, Nemotron-Research-Tool-N1 is optimized\nwith a binary reward that evaluates only the structural validity and functional\ncorrectness of tool invocations. This lightweight supervision allows the model\nto autonomously internalize reasoning strategies, without the need for\nannotated reasoning trajectories. Experiments on the BFCL and API-Bank\nbenchmarks show that Nemotron-Research-Tool-N1-7B and\nNemotron-Research-Tool-N1-14B, built on Qwen-2.5-7B/14B-Instruct, achieve\nstate-of-the-art results, outperforming GPT-4o on both evaluations.", "AI": {"tldr": "Nemotron-Research-Tool-N1 series enhances tool-use in LLMs via binary reward-based optimization, outperforming GPT-4o on benchmarks.", "motivation": "Prior methods for tool-use in LLMs either lack reasoning or imitate it poorly, limiting generalization.", "method": "Uses rule-based reinforcement learning with binary rewards for structural and functional correctness, avoiding annotated reasoning traces.", "result": "Nemotron-Research-Tool-N1-7B/14B achieves state-of-the-art results on BFCL and API-Bank benchmarks.", "conclusion": "Lightweight supervision enables autonomous reasoning, outperforming existing approaches."}}
{"id": "2505.00334", "pdf": "https://arxiv.org/pdf/2505.00334", "abs": "https://arxiv.org/abs/2505.00334", "authors": ["Luigi Sigillo", "Christian Bianchi", "Danilo Comminiello"], "title": "Quaternion Wavelet-Conditioned Diffusion Models for Image Super-Resolution", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted for presentation at IJCNN 2025", "summary": "Image Super-Resolution is a fundamental problem in computer vision with broad\napplications spacing from medical imaging to satellite analysis. The ability to\nreconstruct high-resolution images from low-resolution inputs is crucial for\nenhancing downstream tasks such as object detection and segmentation. While\ndeep learning has significantly advanced SR, achieving high-quality\nreconstructions with fine-grained details and realistic textures remains\nchallenging, particularly at high upscaling factors. Recent approaches\nleveraging diffusion models have demonstrated promising results, yet they often\nstruggle to balance perceptual quality with structural fidelity. In this work,\nwe introduce ResQu a novel SR framework that integrates a quaternion wavelet\npreprocessing framework with latent diffusion models, incorporating a new\nquaternion wavelet- and time-aware encoder. Unlike prior methods that simply\napply wavelet transforms within diffusion models, our approach enhances the\nconditioning process by exploiting quaternion wavelet embeddings, which are\ndynamically integrated at different stages of denoising. Furthermore, we also\nleverage the generative priors of foundation models such as Stable Diffusion.\nExtensive experiments on domain-specific datasets demonstrate that our method\nachieves outstanding SR results, outperforming in many cases existing\napproaches in perceptual quality and standard evaluation metrics. The code will\nbe available after the revision process.", "AI": {"tldr": "ResQu is a novel SR framework combining quaternion wavelet preprocessing with latent diffusion models, improving perceptual quality and structural fidelity in image super-resolution.", "motivation": "Enhancing super-resolution quality is critical for applications like medical imaging and satellite analysis, but balancing perceptual and structural fidelity remains challenging.", "method": "ResQu integrates quaternion wavelet preprocessing with latent diffusion models, using a quaternion wavelet- and time-aware encoder and leveraging generative priors from foundation models.", "result": "The method outperforms existing approaches in perceptual quality and standard metrics on domain-specific datasets.", "conclusion": "ResQu advances super-resolution by effectively combining wavelet embeddings and diffusion models, achieving high-quality reconstructions."}}
{"id": "2505.00236", "pdf": "https://arxiv.org/pdf/2505.00236", "abs": "https://arxiv.org/abs/2505.00236", "authors": ["Leifeng Zhang", "Xin Dong", "Shuaibing Jia", "Jianhua Zhang"], "title": "Node2Vec-DGI-EL: A Hierarchical Graph Representation Learning Model for Ingredient-Disease Association Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Traditional Chinese medicine, as an essential component of traditional\nmedicine, contains active ingredients that serve as a crucial source for modern\ndrug development, holding immense therapeutic potential and development value.\nA multi-layered and complex network is formed from Chinese medicine to diseases\nand used to predict the potential associations between Chinese medicine\ningredients and diseases. This study proposes an ingredient-disease association\nprediction model (Node2Vec-DGI-EL) based on hierarchical graph representation\nlearning. First, the model uses the Node2Vec algorithm to extract node\nembedding vectors from the network as the initial features of the nodes. Next,\nthe network nodes are deeply represented and learned using the DGI algorithm to\nenhance the model's expressive power. To improve prediction accuracy and\nrobustness, an ensemble learning method is incorporated to achieve more\naccurate ingredient-disease association predictions. The effectiveness of the\nmodel is then evaluated through a series of theoretical verifications. The\nresults demonstrated that the proposed model significantly outperformed\nexisting methods, achieving an AUC of 0.9987 and an AUPR of 0.9545, thereby\nindicating superior predictive capability. Ablation experiments further\nrevealed the contribution and importance of each module. Additionally, case\nstudies explored potential associations, such as triptonide with hypertensive\nretinopathy and methyl ursolate with colorectal cancer. Molecular docking\nexperiments validated these findings, showing the triptonide-PGR interaction\nand the methyl ursolate-NFE2L2 interaction can bind stable. In conclusion, the\nNode2Vec-DGI-EL model focuses on TCM datasets and effectively predicts\ningredient-disease associations, overcoming the reliance on node semantic\ninformation.", "AI": {"tldr": "The paper proposes a hierarchical graph representation learning model (Node2Vec-DGI-EL) to predict associations between Chinese medicine ingredients and diseases, achieving superior performance with AUC 0.9987 and AUPR 0.9545.", "motivation": "Traditional Chinese medicine (TCM) contains active ingredients with therapeutic potential, but predicting their associations with diseases is complex. The study aims to develop a robust model for this purpose.", "method": "The model combines Node2Vec for initial node embeddings, DGI for deep representation learning, and ensemble learning for accuracy. Theoretical verification and ablation experiments validate the approach.", "result": "The model outperforms existing methods, with high AUC and AUPR scores. Case studies and molecular docking confirm predicted associations, like triptonide with hypertensive retinopathy.", "conclusion": "The Node2Vec-DGI-EL model effectively predicts TCM ingredient-disease associations, overcoming reliance on node semantic information and demonstrating practical utility."}}
{"id": "2501.14066", "pdf": "https://arxiv.org/pdf/2501.14066", "abs": "https://arxiv.org/abs/2501.14066", "authors": ["Benjamin Hou", "Tejas Sudharshan Mathai", "Pritam Mukherjee", "Xinya Wang", "Ronald M. Summers", "Zhiyong Lu"], "title": "Segment-and-Classify: ROI-Guided Generalizable Contrast Phase Classification in CT Using XGBoost", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Purpose: To automate contrast phase classification in CT using organ-specific\nfeatures extracted from a widely used segmentation tool with a lightweight\ndecision tree classifier.\n  Materials and Methods: This retrospective study utilized three public CT\ndatasets from separate institutions. The phase prediction model was trained on\nthe WAW-TACE (median age: 66 [60,73]; 185 males) dataset, and externally\nvalidated on the VinDr-Multiphase (146 males; 63 females; 56 unk) and C4KC-KiTS\n(median age: 61 [50.68; 123 males) datasets. Contrast phase classification was\nperformed using organ-specific features extracted by TotalSegmentator, followed\nby prediction using a gradient-boosted decision tree classifier.\n  Results: On the VinDr-Multiphase dataset, the phase prediction model achieved\nthe highest or comparable AUCs across all phases (>0.937), with superior\nF1-scores in the non-contrast (0.994), arterial (0.937), and delayed (0.718)\nphases. Statistical testing indicated significant performance differences only\nin the arterial and delayed phases (p<0.05). On the C4KC-KiTS dataset, the\nphase prediction model achieved the highest AUCs across all phases (>0.991),\nwith superior F1-scores in arterial/venous (0.968) and delayed (0.935) phases.\nStatistical testing confirmed significant improvements over all baseline models\nin these two phases (p<0.05). Performance in the non-contrast class, however,\nwas comparable across all models, with no statistically significant differences\nobserved (p>0.05).\n  Conclusion: The lightweight model demonstrated strong performance relative to\nall baseline models, and exhibited robust generalizability across datasets from\ndifferent institutions.", "AI": {"tldr": "A lightweight decision tree classifier using organ-specific features from TotalSegmentator effectively automates contrast phase classification in CT scans, showing strong performance and generalizability across datasets.", "motivation": "To automate and improve the accuracy of contrast phase classification in CT scans using a simple yet effective method.", "method": "Utilized organ-specific features from TotalSegmentator and trained a gradient-boosted decision tree classifier on one dataset, validating it on two others.", "result": "Achieved high AUCs (>0.937) and superior F1-scores in most phases, with significant improvements in arterial and delayed phases.", "conclusion": "The model is lightweight, performs well, and generalizes robustly across different datasets."}}
{"id": "2505.00025", "pdf": "https://arxiv.org/pdf/2505.00025", "abs": "https://arxiv.org/abs/2505.00025", "authors": ["Mingda Zhang", "Jianglong Qin"], "title": "A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1", "categories": ["cs.CL", "cs.AI", "I.2.7; J.3"], "comment": "14 pages, 1 figures", "summary": "In recent years, despite foundation models like DeepSeek-R1 and ChatGPT\ndemonstrating significant capabilities in general tasks, professional knowledge\nbarriers, computational resource requirements, and deployment environment\nlimitations have severely hindered their application in actual medical\nscenarios. Addressing these challenges, this paper proposes an efficient\nlightweight medical vertical large language model architecture method,\nsystematically solving the lightweight problem of medical large models from\nthree dimensions: knowledge acquisition, model compression, and computational\noptimization. At the knowledge acquisition level, a knowledge transfer pipeline\nis designed from the fine-tuned DeepSeek-R1-Distill-70B teacher model to the\nDeepSeek-R1-Distill-7B student model, and Low-Rank Adaptation (LoRA) technology\nis adopted to precisely adjust key attention layers. At the model compression\nlevel, compression techniques including 4-bit weight quantization are\nimplemented while preserving the core representation ability for medical\nreasoning. At the computational optimization level, inference optimization\ntechniques such as Flash Attention acceleration and continuous batching are\nintegrated, and a professional prompt template system is constructed to adapt\nto different types of medical problems. Experimental results on medical\nquestion-answering datasets show that the method proposed in this paper\nmaintains professional accuracy while reducing memory consumption by 64.7\\% and\ninference latency by 12.4\\%, providing an effective solution for the\napplication of medical large models in resource-constrained environments such\nas edge computing devices.", "AI": {"tldr": "Proposes a lightweight medical LLM architecture addressing knowledge barriers, model compression, and computational optimization, reducing memory and latency while maintaining accuracy.", "motivation": "Overcome limitations of foundation models in medical scenarios due to knowledge barriers, resource demands, and deployment constraints.", "method": "Knowledge transfer via LoRA, 4-bit quantization, and computational optimizations like Flash Attention and continuous batching.", "result": "Reduces memory by 64.7% and latency by 12.4% while preserving medical accuracy.", "conclusion": "Provides an efficient solution for deploying medical LLMs in resource-constrained environments."}}
{"id": "2505.00026", "pdf": "https://arxiv.org/pdf/2505.00026", "abs": "https://arxiv.org/abs/2505.00026", "authors": ["Ruirui Chen", "Weifeng Jiang", "Chengwei Qin", "Cheston Tan"], "title": "Theory of Mind in Large Language Models: Assessment and Enhancement", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Theory of Mind (ToM)-the ability to infer and reason about others' mental\nstates-is fundamental to human social intelligence. As Large Language Models\n(LLMs) become increasingly integrated into daily life, it is crucial to assess\nand enhance their capacity to interpret and respond to human mental states. In\nthis paper, we review LLMs' ToM capabilities by examining both evaluation\nbenchmarks and the strategies designed to improve them. We focus on widely\nadopted story-based benchmarks and provide an in-depth analysis of methods\naimed at enhancing ToM in LLMs. Furthermore, we outline promising future\nresearch directions informed by recent benchmarks and state-of-the-art\napproaches. Our survey serves as a valuable resource for researchers interested\nin advancing LLMs' ToM capabilities.", "AI": {"tldr": "A review of Large Language Models' (LLMs) Theory of Mind (ToM) capabilities, focusing on evaluation benchmarks, improvement strategies, and future research directions.", "motivation": "Assessing and enhancing LLMs' ability to interpret human mental states is crucial as they become more integrated into daily life.", "method": "Examines story-based benchmarks and analyzes methods to improve ToM in LLMs.", "result": "Provides insights into current benchmarks and state-of-the-art approaches for enhancing ToM.", "conclusion": "The survey is a resource for advancing LLMs' ToM capabilities, highlighting promising future research directions."}}
{"id": "2505.00335", "pdf": "https://arxiv.org/pdf/2505.00335", "abs": "https://arxiv.org/abs/2505.00335", "authors": ["Seungjun Shin", "Suji Kim", "Dokwan Oh"], "title": "Efficient Neural Video Representation with Temporally Coherent Modulation", "categories": ["cs.CV", "cs.AI"], "comment": "ECCV 2024", "summary": "Implicit neural representations (INR) has found successful applications\nacross diverse domains. To employ INR in real-life, it is important to speed up\ntraining. In the field of INR for video applications, the state-of-the-art\napproach employs grid-type parametric encoding and successfully achieves a\nfaster encoding speed in comparison to its predecessors. However, the grid\nusage, which does not consider the video's dynamic nature, leads to redundant\nuse of trainable parameters. As a result, it has significantly lower parameter\nefficiency and higher bitrate compared to NeRV-style methods that do not use a\nparametric encoding. To address the problem, we propose Neural Video\nrepresentation with Temporally coherent Modulation (NVTM), a novel framework\nthat can capture dynamic characteristics of video. By decomposing the\nspatio-temporal 3D video data into a set of 2D grids with flow information,\nNVTM enables learning video representation rapidly and uses parameter\nefficiently. Our framework enables to process temporally corresponding pixels\nat once, resulting in the fastest encoding speed for a reasonable video\nquality, especially when compared to the NeRV-style method, with a speed\nincrease of over 3 times. Also, it remarks an average of 1.54dB/0.019\nimprovements in PSNR/LPIPS on UVG (Dynamic) (even with 10% fewer parameters)\nand an average of 1.84dB/0.013 improvements in PSNR/LPIPS on MCL-JCV (Dynamic),\ncompared to previous grid-type works. By expanding this to compression tasks,\nwe demonstrate comparable performance to video compression standards (H.264,\nHEVC) and recent INR approaches for video compression. Additionally, we perform\nextensive experiments demonstrating the superior performance of our algorithm\nacross diverse tasks, encompassing super resolution, frame interpolation and\nvideo inpainting. Project page is https://sujiikim.github.io/NVTM/.", "AI": {"tldr": "NVTM proposes a temporally coherent modulation framework for efficient and fast video representation, outperforming grid-type methods in speed and quality.", "motivation": "Addressing the inefficiency and redundancy in grid-type parametric encoding for video applications, NVTM aims to improve parameter efficiency and encoding speed.", "method": "NVTM decomposes spatio-temporal video data into 2D grids with flow information, enabling rapid learning and efficient parameter use.", "result": "NVTM achieves 3x faster encoding than NeRV-style methods, with 1.54dB/0.019 PSNR/LPIPS improvements on UVG and 1.84dB/0.013 on MCL-JCV, using fewer parameters.", "conclusion": "NVTM demonstrates superior performance in video tasks, matching compression standards and excelling in super-resolution, interpolation, and inpainting."}}
{"id": "2505.00257", "pdf": "https://arxiv.org/pdf/2505.00257", "abs": "https://arxiv.org/abs/2505.00257", "authors": ["Zhizhong Tan", "Jiexin Zheng", "Kevin Qi Zhang", "Wenyong Wang"], "title": "Graph Privacy: A Heterogeneous Federated GNN for Trans-Border Financial Data Circulation", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "The sharing of external data has become a strong demand of financial\ninstitutions, but the privacy issue has led to the difficulty of\ninterconnecting different platforms and the low degree of data openness. To\neffectively solve the privacy problem of financial data in trans-border flow\nand sharing, to ensure that the data is available but not visible, to realize\nthe joint portrait of all kinds of heterogeneous data of business organizations\nin different industries, we propose a Heterogeneous Federated Graph Neural\nNetwork (HFGNN) approach. In this method, the distribution of heterogeneous\nbusiness data of trans-border organizations is taken as subgraphs, and the\nsharing and circulation process among subgraphs is constructed as a\nstatistically heterogeneous global graph through a central server. Each\nsubgraph learns the corresponding personalized service model through local\ntraining to select and update the relevant subset of subgraphs with aggregated\nparameters, and effectively separates and combines topological and feature\ninformation among subgraphs. Finally, our simulation experimental results show\nthat the proposed method has higher accuracy performance and faster convergence\nspeed than existing methods.", "AI": {"tldr": "A Heterogeneous Federated Graph Neural Network (HFGNN) is proposed to address privacy issues in financial data sharing, enabling secure data flow and joint analysis across platforms.", "motivation": "Financial institutions face challenges in sharing data due to privacy concerns, leading to low data openness and platform interconnection.", "method": "HFGNN models heterogeneous business data as subgraphs, constructs a global graph via a central server, and uses local training for personalized models.", "result": "Simulation experiments show HFGNN achieves higher accuracy and faster convergence than existing methods.", "conclusion": "HFGNN effectively solves privacy issues in financial data sharing while improving performance."}}
{"id": "2403.16677", "pdf": "https://arxiv.org/pdf/2403.16677", "abs": "https://arxiv.org/abs/2403.16677", "authors": ["Alireza Furutanpey", "Qiyang Zhang", "Philipp Raith", "Tobias Pfandzelter", "Shangguang Wang", "Schahram Dustdar"], "title": "FOOL: Addressing the Downlink Bottleneck in Satellite Computing with Neural Feature Compression", "categories": ["cs.LG", "cs.CV", "cs.DC", "cs.NI", "eess.IV"], "comment": "Version Accepted for publication in IEEE Transactions on Mobile\n  Computing", "summary": "Nanosatellite constellations equipped with sensors capturing large geographic\nregions provide unprecedented opportunities for Earth observation. As\nconstellation sizes increase, network contention poses a downlink bottleneck.\nOrbital Edge Computing (OEC) leverages limited onboard compute resources to\nreduce transfer costs by processing the raw captures at the source. However,\ncurrent solutions have limited practicability due to reliance on crude\nfiltering methods or over-prioritizing particular downstream tasks. This work\npresents FOOL, an OEC-native and task-agnostic feature compression method that\npreserves prediction performance. FOOL partitions high-resolution satellite\nimagery to maximize throughput. Further, it embeds context and leverages\ninter-tile dependencies to lower transfer costs with negligible overhead. While\nFOOL is a feature compressor, it can recover images with competitive scores on\nquality measures at lower bitrates. We extensively evaluate transfer cost\nreduction by including the peculiarity of intermittently available network\nconnections in low earth orbit. Lastly, we test the feasibility of our system\nfor standardized nanosatellite form factors. We demonstrate that FOOL permits\ndownlinking over 100x the data volume without relying on prior information on\nthe downstream tasks.", "AI": {"tldr": "FOOL is a task-agnostic feature compression method for nanosatellite constellations, reducing downlink costs while preserving prediction performance and image quality.", "motivation": "Addressing the downlink bottleneck in nanosatellite constellations by improving data transfer efficiency without relying on task-specific prior information.", "method": "FOOL partitions high-resolution satellite imagery, embeds context, and leverages inter-tile dependencies for compression, tested under intermittent network conditions.", "result": "FOOL reduces transfer costs significantly (over 100x data volume) and recovers images with competitive quality at lower bitrates.", "conclusion": "FOOL is a practical solution for Orbital Edge Computing, enabling efficient data downlinking without compromising performance."}}
{"id": "2505.00027", "pdf": "https://arxiv.org/pdf/2505.00027", "abs": "https://arxiv.org/abs/2505.00027", "authors": ["Jian Zhou", "Jiazheng Li", "Sirui Zhuge", "Hai Zhuge"], "title": "Extracting Abstraction Dimensions by Identifying Syntax Pattern from Texts", "categories": ["cs.CL", "cs.AI", "68T50 (Primary) 91F20 (Secondary)", "I.2.7; I.2.1"], "comment": "25pages, 3 figures, 8 tables", "summary": "This paper proposed an approach to automatically discovering subject\ndimension, action dimension, object dimension and adverbial dimension from\ntexts to efficiently operate texts and support query in natural language. The\nhigh quality of trees guarantees that all subjects, actions, objects and\nadverbials and their subclass relations within texts can be represented. The\nindependency of trees ensures that there is no redundant representation between\ntrees. The expressiveness of trees ensures that the majority of sentences can\nbe accessed from each tree and the rest of sentences can be accessed from at\nleast one tree so that the tree-based search mechanism can support querying in\nnatural language. Experiments show that the average precision, recall and\nF1-score of the abstraction trees constructed by the subclass relations of\nsubject, action, object and adverbial are all greater than 80%. The application\nof the proposed approach to supporting query in natural language demonstrates\nthat different types of question patterns for querying subject or object have\nhigh coverage of texts, and searching multiple trees on subject, action, object\nand adverbial according to the question pattern can quickly reduce search space\nto locate target sentences, which can support precise operation on texts.", "AI": {"tldr": "The paper proposes a method to automatically extract subject, action, object, and adverbial dimensions from texts for efficient querying in natural language, achieving high precision and recall.", "motivation": "To enable efficient text operations and natural language queries by representing textual elements and their relations in structured trees.", "method": "Constructs abstraction trees for subject, action, object, and adverbial dimensions, ensuring independence and expressiveness for comprehensive text coverage.", "result": "Experiments show precision, recall, and F1-scores above 80%. The approach effectively supports natural language queries by reducing search space.", "conclusion": "The method successfully enables precise text operations and natural language querying through structured tree representations."}}
{"id": "2505.00028", "pdf": "https://arxiv.org/pdf/2505.00028", "abs": "https://arxiv.org/abs/2505.00028", "authors": ["Pengchao Feng", "Ziyang Ma", "Wenxi Chen", "Yao Li", "Sheng Wang", "Kai Yu", "Xie Chen"], "title": "Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "In recent years, end-to-end speech-to-speech (S2S) dialogue systems have\ngarnered increasing research attention due to their advantages over traditional\ncascaded systems, including achieving lower latency and more natural\nintegration of nonverbal cues such as emotion and speaker identity. However,\nthese end-to-end systems face key challenges, particularly in incorporating\nexternal knowledge, a capability commonly addressed by Retrieval-Augmented\nGeneration (RAG) in text-based large language models (LLMs). The core\ndifficulty lies in the modality gap between input speech and retrieved textual\nknowledge, which hinders effective integration. To address this issue, we\npropose a novel end-to-end RAG framework that directly retrieves relevant\ntextual knowledge from speech queries, eliminating the need for intermediate\nspeech-to-text conversion via techniques like ASR. Experimental results\ndemonstrate that our method significantly improves the performance of\nend-to-end S2S dialogue systems while achieving higher retrieval efficiency.\nAlthough the overall performance still lags behind cascaded models, our\nframework offers a promising direction for enhancing knowledge integration in\nend-to-end S2S systems. We will release the code and dataset to support\nreproducibility and promote further research in this area.", "AI": {"tldr": "A novel end-to-end RAG framework for speech-to-speech dialogue systems improves knowledge integration by directly retrieving textual knowledge from speech queries, bypassing ASR.", "motivation": "Address the modality gap between speech input and textual knowledge in end-to-end S2S systems, which limits effective knowledge integration.", "method": "Propose an end-to-end RAG framework that retrieves textual knowledge directly from speech queries, avoiding intermediate ASR conversion.", "result": "Significantly improves S2S system performance and retrieval efficiency, though still behind cascaded models.", "conclusion": "The framework shows promise for enhancing knowledge integration in end-to-end S2S systems; code and dataset will be released for further research."}}
{"id": "2505.00369", "pdf": "https://arxiv.org/pdf/2505.00369", "abs": "https://arxiv.org/abs/2505.00369", "authors": ["M. A. D. Buser", "D. C. Simons", "M. Fitski", "M. H. W. A. Wijnen", "A. S. Littooij", "A. H. ter Brugge", "I. N. Vos", "M. H. A. Janse", "M. de Boer", "R. ter Maat", "J. Sato", "S. Kido", "S. Kondo", "S. Kasai", "M. Wodzinski", "H. Muller", "J. Ye", "J. He", "Y. Kirchhoff", "M. R. Rokkus", "G. Haokai", "S. Zitong", "M. Fern\u00e1ndez-Pat\u00f3n", "D. Veiga-Canuto", "D. G. Ellis", "M. R. Aizenberg", "B. H. M. van der Velden", "H. Kuijf", "A. De Luca", "A. F. W. van der Steeg"], "title": "Automated segmenta-on of pediatric neuroblastoma on multi-modal MRI: Results of the SPPIN challenge at MICCAI 2023", "categories": ["cs.CV"], "comment": "23 pages, 6 figures", "summary": "Surgery plays an important role within the treatment for neuroblastoma, a\ncommon pediatric cancer. This requires careful planning, often via magnetic\nresonance imaging (MRI)-based anatomical 3D models. However, creating these\nmodels is often time-consuming and user dependent. We organized the Surgical\nPlanning in Pediatric Neuroblastoma (SPPIN) challenge, to stimulate\ndevelopments on this topic, and set a benchmark for fully automatic\nsegmentation of neuroblastoma on multi-model MRI. The challenge started with a\ntraining phase, where teams received 78 sets of MRI scans from 34 patients,\nconsisting of both diagnostic and post-chemotherapy MRI scans. The final test\nphase, consisting of 18 MRI sets from 9 patients, determined the ranking of the\nteams. Ranking was based on the Dice similarity coefficient (Dice score), the\n95th percentile of the Hausdorff distance (HD95) and the volumetric similarity\n(VS). The SPPIN challenge was hosted at MICCAI 2023. The final leaderboard\nconsisted of 9 teams. The highest-ranking team achieved a median Dice score\n0.82, a median HD95 of 7.69 mm and a VS of 0.91, utilizing a large, pretrained\nnetwork called STU-Net. A significant difference for the segmentation results\nbetween diagnostic and post-chemotherapy MRI scans was observed (Dice = 0.89 vs\nDice = 0.59, P = 0.01) for the highest-ranking team. SPPIN is the first medical\nsegmentation challenge in extracranial pediatric oncology. The highest-ranking\nteam used a large pre-trained network, suggesting that pretraining can be of\nuse in small, heterogenous datasets. Although the results of the\nhighest-ranking team were high for most patients, segmentation especially in\nsmall, pre-treated tumors were insufficient. Therefore, more reliable\nsegmentation methods are needed to create clinically applicable models to aid\nsurgical planning in pediatric neuroblastoma.", "AI": {"tldr": "The SPPIN challenge aimed to benchmark automatic segmentation of neuroblastoma on MRI scans, with the top team achieving high scores using a pretrained network, though challenges remain for small, treated tumors.", "motivation": "To improve surgical planning for pediatric neuroblastoma by developing reliable, automatic MRI segmentation methods.", "method": "Organized a challenge with training and test phases using MRI scans, ranking teams based on Dice score, HD95, and VS metrics.", "result": "Top team achieved median Dice 0.82, HD95 7.69 mm, and VS 0.91, but struggled with small, treated tumors (Dice 0.59).", "conclusion": "Pretraining helps, but more reliable methods are needed for clinical use in pediatric neuroblastoma segmentation."}}
{"id": "2505.00279", "pdf": "https://arxiv.org/pdf/2505.00279", "abs": "https://arxiv.org/abs/2505.00279", "authors": ["Kyota Kuboki", "Tatsuyoshi Ogawa", "Chu-Hsuan Hsueh", "Shi-Jim Yen", "Kokolo Ikeda"], "title": "Policies of Multiple Skill Levels for Better Strength Estimation in Games", "categories": ["cs.LG"], "comment": "25 pages, 15 figures", "summary": "Accurately estimating human skill levels is crucial for designing effective\nhuman-AI interactions so that AI can provide appropriate challenges or\nguidance. In games where AI players have beaten top human professionals,\nstrength estimation plays a key role in adapting AI behavior to match human\nskill levels. In a previous state-of-the-art study, researchers have proposed a\nstrength estimator trained using human players' match data. Given some matches,\nthe strength estimator computes strength scores and uses them to estimate\nplayer ranks (skill levels). In this paper, we focus on the observation that\nhuman players' behavior tendency varies according to their strength and aim to\nimprove the accuracy of strength estimation by taking this into account.\nSpecifically, in addition to strength scores, we obtain policies for different\nskill levels from neural networks trained using human players' match data. We\nthen combine features based on these policies with the strength scores to\nestimate strength. We conducted experiments on Go and chess. For Go, our method\nachieved an accuracy of 80% in strength estimation when given 10 matches, which\nincreased to 92% when given 20 matches. In comparison, the previous\nstate-of-the-art method had an accuracy of 71% with 10 matches and 84% with 20\nmatches, demonstrating improvements of 8-9%. We observed similar improvements\nin chess. These results contribute to developing a more accurate strength\nestimation method and to improving human-AI interaction.", "AI": {"tldr": "The paper improves human skill level estimation in games by incorporating behavior tendencies and policies from neural networks, achieving higher accuracy than previous methods.", "motivation": "Accurate skill estimation is vital for effective human-AI interaction, ensuring AI provides suitable challenges or guidance.", "method": "Combines strength scores with policies from neural networks trained on human match data to estimate skill levels.", "result": "Achieved 80% accuracy (Go) with 10 matches, rising to 92% with 20 matches, outperforming prior methods by 8-9%. Similar improvements were seen in chess.", "conclusion": "The method enhances strength estimation accuracy, improving human-AI interaction in games like Go and chess."}}
{"id": "2412.12126", "pdf": "https://arxiv.org/pdf/2412.12126", "abs": "https://arxiv.org/abs/2412.12126", "authors": ["Sizhe Xing", "Aolong Sun", "Chengxi Wang", "Yizhi Wang", "Boyu Dong", "Junhui Hu", "Xuyu Deng", "An Yan", "Yingjun Liu", "Fangchen Hu", "Zhongya Li", "Ouhan Huang", "Junhao Zhao", "Yingjun Zhou", "Ziwei Li", "Jianyang Shi", "Xi Xiao", "Richard Penty", "Qixiang Cheng", "Nan Chi", "Junwen Zhang"], "title": "Seamless Optical Cloud Computing across Edge-Metro Network for Generative AI", "categories": ["cs.DC", "cs.CV", "cs.LG", "eess.IV", "eess.SP"], "comment": null, "summary": "The rapid advancement of generative artificial intelligence (AI) in recent\nyears has profoundly reshaped modern lifestyles, necessitating a revolutionary\narchitecture to support the growing demands for computational power. Cloud\ncomputing has become the driving force behind this transformation. However, it\nconsumes significant power and faces computation security risks due to the\nreliance on extensive data centers and servers in the cloud. Reducing power\nconsumption while enhancing computational scale remains persistent challenges\nin cloud computing. Here, we propose and experimentally demonstrate an optical\ncloud computing system that can be seamlessly deployed across edge-metro\nnetwork. By modulating inputs and models into light, a wide range of edge nodes\ncan directly access the optical computing center via the edge-metro network.\nThe experimental validations show an energy efficiency of 118.6 mW/TOPs (tera\noperations per second), reducing energy consumption by two orders of magnitude\ncompared to traditional electronic-based cloud computing solutions.\nFurthermore, it is experimentally validated that this architecture can perform\nvarious complex generative AI models through parallel computing to achieve\nimage generation tasks.", "AI": {"tldr": "Proposes an optical cloud computing system for energy-efficient, scalable generative AI tasks, reducing energy use by 100x compared to traditional methods.", "motivation": "Addresses high power consumption and security risks in cloud computing for AI by leveraging optical technology.", "method": "Modulates inputs and models into light for deployment across edge-metro networks, enabling parallel computing.", "result": "Achieves 118.6 mW/TOPs energy efficiency and successfully runs complex generative AI models for image generation.", "conclusion": "The optical system offers a scalable, energy-efficient alternative to traditional cloud computing for AI workloads."}}
{"id": "2505.00029", "pdf": "https://arxiv.org/pdf/2505.00029", "abs": "https://arxiv.org/abs/2505.00029", "authors": ["Yijie Hong", "Xiaofei Yin", "Xinzhong Wang", "Yi Tu", "Ya Guo", "Sufeng Duan", "Weiqiang Wang", "Lingyong Fang", "Depeng Wang", "Huijia Zhu"], "title": "Keep the General, Inject the Specific: Structured Dialogue Fine-Tuning for Knowledge Injection without Catastrophic Forgetting", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 3 figures", "summary": "Large Vision Language Models have demonstrated impressive versatile\ncapabilities through extensive multimodal pre-training, but face significant\nlimitations when incorporating specialized knowledge domains beyond their\ntraining distribution. These models struggle with a fundamental dilemma: direct\nadaptation approaches that inject domain-specific knowledge often trigger\ncatastrophic forgetting of foundational visual-linguistic abilities. We\nintroduce Structured Dialogue Fine-Tuning (SDFT), an effective approach that\neffectively injects domain-specific knowledge while minimizing catastrophic\nforgetting. Drawing inspiration from supervised fine-tuning in LLMs and\nsubject-driven personalization in text-to-image diffusion models, our method\nemploys a three-phase dialogue structure: Foundation Preservation reinforces\npre-trained visual-linguistic alignment through caption tasks; Contrastive\nDisambiguation introduces carefully designed counterfactual examples to\nmaintain semantic boundaries; and Knowledge Specialization embeds specialized\ninformation through chain-of-thought reasoning. Experimental results across\nmultiple domains confirm SDFT's effectiveness in balancing specialized\nknowledge acquisition with general capability retention. Our key contributions\ninclude a data-centric dialogue template that balances foundational alignment\nwith targeted knowledge integration, a weighted multi-turn supervision\nframework, and comprehensive evaluation across diverse knowledge types.", "AI": {"tldr": "SDFT is a method to inject domain-specific knowledge into large vision-language models without catastrophic forgetting, using a three-phase dialogue structure.", "motivation": "Large vision-language models struggle with incorporating specialized knowledge without losing foundational abilities.", "method": "Structured Dialogue Fine-Tuning (SDFT) with three phases: Foundation Preservation, Contrastive Disambiguation, and Knowledge Specialization.", "result": "SDFT effectively balances specialized knowledge acquisition and general capability retention across domains.", "conclusion": "SDFT provides a robust framework for integrating domain-specific knowledge while preserving foundational skills."}}
{"id": "2505.00031", "pdf": "https://arxiv.org/pdf/2505.00031", "abs": "https://arxiv.org/abs/2505.00031", "authors": ["Jin Zhang", "Flood Sung", "Zhilin Yang", "Yang Gao", "Chongjie Zhang"], "title": "Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the field of large language model (LLM) post-training, the effectiveness\nof utilizing synthetic data generated by the LLM itself has been\nwell-presented. However, a key question remains unaddressed: what essential\ninformation should such self-generated data encapsulate? Existing approaches\nonly produce step-by-step problem solutions, and fail to capture the abstract\nmeta-knowledge necessary for generalization across similar problems. Drawing\ninsights from cognitive science, where humans employ high-level abstraction to\nsimplify complex problems before delving into specifics, we introduce a novel\nself-training algorithm: LEarning to Plan before Answering (LEPA). LEPA trains\nthe LLM to formulate anticipatory plans, which serve as abstract meta-knowledge\nfor problem-solving, before engaging with the intricacies of problems. This\napproach not only outlines the solution generation path but also shields the\nLLM from the distraction of irrelevant details. During data generation, LEPA\nfirst crafts an anticipatory plan based on the problem, and then generates a\nsolution that aligns with both the plan and the problem. LEPA refines the plan\nthrough self-reflection, aiming to acquire plans that are instrumental in\nyielding correct solutions. During model optimization, the LLM is trained to\npredict both the refined plans and the corresponding solutions. By efficiently\nextracting and utilizing the anticipatory plans, LEPA demonstrates remarkable\nsuperiority over conventional algorithms on various challenging natural\nlanguage reasoning benchmarks.", "AI": {"tldr": "LEPA introduces a self-training algorithm for LLMs to generate anticipatory plans before solving problems, improving generalization and performance on reasoning tasks.", "motivation": "Existing methods for LLM post-training focus on step-by-step solutions but lack abstract meta-knowledge for generalization, inspired by human cognitive processes.", "method": "LEPA trains LLMs to create anticipatory plans as meta-knowledge, refine them via self-reflection, and predict both plans and solutions during optimization.", "result": "LEPA outperforms conventional algorithms on natural language reasoning benchmarks by leveraging anticipatory plans.", "conclusion": "LEPA's approach of planning before answering enhances LLM performance and generalization, addressing a gap in current post-training methods."}}
{"id": "2505.00378", "pdf": "https://arxiv.org/pdf/2505.00378", "abs": "https://arxiv.org/abs/2505.00378", "authors": ["Feng Xue", "Wenzhuang Xu", "Guofeng Zhong", "Anlong Minga", "Nicu Sebe"], "title": "Cues3D: Unleashing the Power of Sole NeRF for Consistent and Unique Instances in Open-Vocabulary 3D Panoptic Segmentation", "categories": ["cs.CV"], "comment": "Accepted by Information Fusion", "summary": "Open-vocabulary 3D panoptic segmentation has recently emerged as a\nsignificant trend. Top-performing methods currently integrate 2D segmentation\nwith geometry-aware 3D primitives. However, the advantage would be lost without\nhigh-fidelity 3D point clouds, such as methods based on Neural Radiance Field\n(NeRF). These methods are limited by the insufficient capacity to maintain\nconsistency across partial observations. To address this, recent works have\nutilized contrastive loss or cross-view association pre-processing for view\nconsensus. In contrast to them, we present Cues3D, a compact approach that\nrelies solely on NeRF instead of pre-associations. The core idea is that NeRF's\nimplicit 3D field inherently establishes a globally consistent geometry,\nenabling effective object distinction without explicit cross-view supervision.\nWe propose a three-phase training framework for NeRF,\ninitialization-disambiguation-refinement, whereby the instance IDs are\ncorrected using the initially-learned knowledge. Additionally, an instance\ndisambiguation method is proposed to match NeRF-rendered 3D masks and ensure\nglobally unique 3D instance identities. With the aid of Cues3D, we obtain\nhighly consistent and unique 3D instance ID for each object across views with a\nbalanced version of NeRF. Our experiments are conducted on ScanNet v2,\nScanNet200, ScanNet++, and Replica datasets for 3D instance, panoptic, and\nsemantic segmentation tasks. Cues3D outperforms other 2D image-based methods\nand competes with the latest 2D-3D merging based methods, while even surpassing\nthem when using additional 3D point clouds. The code link could be found in the\nappendix and will be released on\n\\href{https://github.com/mRobotit/Cues3D}{github}", "AI": {"tldr": "Cues3D is a NeRF-based method for open-vocabulary 3D panoptic segmentation, achieving globally consistent object IDs without cross-view supervision, outperforming 2D and 2D-3D methods.", "motivation": "Existing methods rely on high-fidelity 3D point clouds or explicit cross-view associations, which are limiting. Cues3D leverages NeRF's implicit 3D geometry for consistency.", "method": "A three-phase training framework (initialization-disambiguation-refinement) and instance disambiguation method are used to ensure unique 3D instance IDs.", "result": "Cues3D outperforms 2D-based methods and competes with 2D-3D merging methods, excelling with additional 3D point clouds.", "conclusion": "Cues3D provides a compact, effective solution for 3D segmentation, leveraging NeRF's inherent geometry for consistency and outperforming existing approaches."}}
{"id": "2505.00290", "pdf": "https://arxiv.org/pdf/2505.00290", "abs": "https://arxiv.org/abs/2505.00290", "authors": ["Hong Xin Xie", "Jian De Sun", "Fan Fu Xue", "Zi Fei Han", "Shan Shan Feng", "Qi Chen"], "title": "Multi-Hierarchical Fine-Grained Feature Mapping Driven by Feature Contribution for Molecular Odor Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Molecular odor prediction is the process of using a molecule's structure to\npredict its smell. While accurate prediction remains challenging, AI models can\nsuggest potential odors. Existing methods, however, often rely on basic\ndescriptors or handcrafted fingerprints, which lack expressive power and hinder\neffective learning. Furthermore, these methods suffer from severe class\nimbalance, limiting the training effectiveness of AI models. To address these\nchallenges, we propose a Feature Contribution-driven Hierarchical Multi-Feature\nMapping Network (HMFNet). Specifically, we introduce a fine-grained, Local\nMulti-Hierarchy Feature Extraction module (LMFE) that performs deep feature\nextraction at the atomic level, capturing detailed features crucial for odor\nprediction. To enhance the extraction of discriminative atomic features, we\nintegrate a Harmonic Modulated Feature Mapping (HMFM). This module dynamically\nlearns feature importance and frequency modulation, improving the model's\ncapability to capture relevant patterns. Additionally, a Global Multi-Hierarchy\nFeature Extraction module (GMFE) is designed to learn global features from the\nmolecular graph topology, enabling the model to fully leverage global\ninformation and enhance its discriminative power for odor prediction. To\nfurther mitigate the issue of class imbalance, we propose a Chemically-Informed\nLoss (CIL). Experimental results demonstrate that our approach significantly\nimproves performance across various deep learning models, highlighting its\npotential to advance molecular structure representation and accelerate the\ndevelopment of AI-driven technologies.", "AI": {"tldr": "The paper proposes HMFNet, a hierarchical multi-feature mapping network, to improve molecular odor prediction by addressing feature extraction and class imbalance issues.", "motivation": "Accurate molecular odor prediction is challenging due to limited expressive power of existing methods and severe class imbalance, hindering AI model training.", "method": "Introduces LMFE for atomic-level feature extraction, HMFM for dynamic feature importance learning, GMFE for global feature extraction, and CIL to mitigate class imbalance.", "result": "The approach significantly improves performance across deep learning models, enhancing molecular structure representation.", "conclusion": "HMFNet advances odor prediction and AI-driven technology development by addressing key challenges in feature extraction and imbalance."}}
{"id": "2502.20824", "pdf": "https://arxiv.org/pdf/2502.20824", "abs": "https://arxiv.org/abs/2502.20824", "authors": ["Fadeel Sher Khan", "Joshua Ebenezer", "Hamid Sheikh", "Seok-Jun Lee"], "title": "MFSR-GAN: Multi-Frame Super-Resolution with Handheld Motion Modeling", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to NTIRE Workshop at CVPR 2025; 8 pages, 6 figures", "summary": "Smartphone cameras have become ubiquitous imaging tools, yet their small\nsensors and compact optics often limit spatial resolution and introduce\ndistortions. Combining information from multiple low-resolution (LR) frames to\nproduce a high-resolution (HR) image has been explored to overcome the inherent\nlimitations of smartphone cameras. Despite the promise of multi-frame\nsuper-resolution (MFSR), current approaches are hindered by datasets that fail\nto capture the characteristic noise and motion patterns found in real-world\nhandheld burst images. In this work, we address this gap by introducing a novel\nsynthetic data engine that uses multi-exposure static images to synthesize\nLR-HR training pairs while preserving sensor-specific noise characteristics and\nimage motion found during handheld burst photography. We also propose MFSR-GAN:\na multi-scale RAW-to-RGB network for MFSR. Compared to prior approaches,\nMFSR-GAN emphasizes a \"base frame\" throughout its architecture to mitigate\nartifacts. Experimental results on both synthetic and real data demonstrates\nthat MFSR-GAN trained with our synthetic engine yields sharper, more realistic\nreconstructions than existing methods for real-world MFSR.", "AI": {"tldr": "The paper introduces a synthetic data engine and MFSR-GAN to improve multi-frame super-resolution (MFSR) for smartphone cameras, addressing noise and motion issues in real-world handheld burst images.", "motivation": "Smartphone cameras' small sensors and compact optics limit resolution and introduce distortions. Existing MFSR methods lack datasets capturing real-world noise and motion patterns.", "method": "Proposes a synthetic data engine using multi-exposure static images to create LR-HR training pairs, and MFSR-GAN, a multi-scale RAW-to-RGB network emphasizing a 'base frame' to reduce artifacts.", "result": "MFSR-GAN trained with the synthetic engine produces sharper, more realistic reconstructions than prior methods on both synthetic and real data.", "conclusion": "The synthetic data engine and MFSR-GAN effectively address real-world MFSR challenges, outperforming existing approaches."}}
{"id": "2505.00030", "pdf": "https://arxiv.org/pdf/2505.00030", "abs": "https://arxiv.org/abs/2505.00030", "authors": ["Ted Underwood", "Laura K. Nelson", "Matthew Wilkens"], "title": "Can Language Models Represent the Past without Anachronism?", "categories": ["cs.CL"], "comment": null, "summary": "Before researchers can use language models to simulate the past, they need to\nunderstand the risk of anachronism. We find that prompting a contemporary model\nwith examples of period prose does not produce output consistent with period\nstyle. Fine-tuning produces results that are stylistically convincing enough to\nfool an automated judge, but human evaluators can still distinguish fine-tuned\nmodel outputs from authentic historical text. We tentatively conclude that\npretraining on period prose may be required in order to reliably simulate\nhistorical perspectives for social research.", "AI": {"tldr": "Contemporary language models struggle to authentically simulate historical text without pretraining on period prose.", "motivation": "To assess the risk of anachronism when using language models to simulate historical perspectives for social research.", "method": "Evaluated prompting and fine-tuning contemporary models with period prose, comparing outputs to authentic historical text.", "result": "Fine-tuned models fooled automated judges but not human evaluators.", "conclusion": "Pretraining on period prose may be necessary for reliable historical simulation."}}
{"id": "2505.00032", "pdf": "https://arxiv.org/pdf/2505.00032", "abs": "https://arxiv.org/abs/2505.00032", "authors": ["Yuyang Sha", "Hongxin Pan", "Wei Xu", "Weiyu Meng", "Gang Luo", "Xinyu Du", "Xiaobing Zhai", "Henry H. Y. Tong", "Caijuan Shi", "Kefeng Li"], "title": "MDD-LLM: Towards Accuracy Large Language Models for Major Depressive Disorder Diagnosis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Major depressive disorder (MDD) impacts more than 300 million people\nworldwide, highlighting a significant public health issue. However, the uneven\ndistribution of medical resources and the complexity of diagnostic methods have\nresulted in inadequate attention to this disorder in numerous countries and\nregions. This paper introduces a high-performance MDD diagnosis tool named\nMDD-LLM, an AI-driven framework that utilizes fine-tuned large language models\n(LLMs) and extensive real-world samples to tackle challenges in MDD diagnosis.\nTherefore, we select 274,348 individual information from the UK Biobank cohort\nto train and evaluate the proposed method. Specifically, we select 274,348\nindividual records from the UK Biobank cohort and design a tabular data\ntransformation method to create a large corpus for training and evaluating the\nproposed approach. To illustrate the advantages of MDD-LLM, we perform\ncomprehensive experiments and provide several comparative analyses against\nexisting model-based solutions across multiple evaluation metrics. Experimental\nresults show that MDD-LLM (70B) achieves an accuracy of 0.8378 and an AUC of\n0.8919 (95% CI: 0.8799 - 0.9040), significantly outperforming existing machine\nlearning and deep learning frameworks for MDD diagnosis. Given the limited\nexploration of LLMs in MDD diagnosis, we examine numerous factors that may\ninfluence the performance of our proposed method, such as tabular data\ntransformation techniques and different fine-tuning strategies.", "AI": {"tldr": "The paper introduces MDD-LLM, an AI-driven tool using fine-tuned large language models for diagnosing Major Depressive Disorder (MDD), achieving high accuracy and outperforming existing methods.", "motivation": "The uneven distribution of medical resources and complex diagnostic methods for MDD necessitate an efficient AI-driven solution.", "method": "The study uses 274,348 records from the UK Biobank, transforms tabular data into a training corpus, and fine-tunes LLMs for MDD diagnosis.", "result": "MDD-LLM achieves an accuracy of 0.8378 and AUC of 0.8919, surpassing other machine learning and deep learning frameworks.", "conclusion": "MDD-LLM demonstrates superior performance for MDD diagnosis, with potential influenced by data transformation and fine-tuning strategies."}}
{"id": "2505.00380", "pdf": "https://arxiv.org/pdf/2505.00380", "abs": "https://arxiv.org/abs/2505.00380", "authors": ["Anjith George", "Sebastien Marcel"], "title": "The Invisible Threat: Evaluating the Vulnerability of Cross-Spectral Face Recognition to Presentation Attacks", "categories": ["cs.CV"], "comment": "10 pages", "summary": "Cross-spectral face recognition systems are designed to enhance the\nperformance of facial recognition systems by enabling cross-modal matching\nunder challenging operational conditions. A particularly relevant application\nis the matching of near-infrared (NIR) images to visible-spectrum (VIS) images,\nenabling the verification of individuals by comparing NIR facial captures\nacquired with VIS reference images. The use of NIR imaging offers several\nadvantages, including greater robustness to illumination variations, better\nvisibility through glasses and glare, and greater resistance to presentation\nattacks. Despite these claimed benefits, the robustness of NIR-based systems\nagainst presentation attacks has not been systematically studied in the\nliterature. In this work, we conduct a comprehensive evaluation into the\nvulnerability of NIR-VIS cross-spectral face recognition systems to\npresentation attacks. Our empirical findings indicate that, although these\nsystems exhibit a certain degree of reliability, they remain vulnerable to\nspecific attacks, emphasizing the need for further research in this area.", "AI": {"tldr": "The paper evaluates the vulnerability of NIR-VIS cross-spectral face recognition systems to presentation attacks, finding them reliable but still vulnerable.", "motivation": "To systematically study the robustness of NIR-VIS face recognition systems against presentation attacks, which has not been thoroughly explored.", "method": "Conducts a comprehensive evaluation of NIR-VIS cross-spectral face recognition systems.", "result": "The systems are reliable but vulnerable to specific attacks.", "conclusion": "Further research is needed to enhance the security of NIR-VIS face recognition systems against presentation attacks."}}
{"id": "2505.00291", "pdf": "https://arxiv.org/pdf/2505.00291", "abs": "https://arxiv.org/abs/2505.00291", "authors": ["Eran Rosenbluth", "Martin Grohe"], "title": "Repetition Makes Perfect: Recurrent Sum-GNNs Match Message Passing Limit", "categories": ["cs.LG", "68T05, 68T07", "I.2.6"], "comment": null, "summary": "We provide first tight bounds for the expressivity of Recurrent Graph Neural\nNetworks (recurrent GNNs) with finite-precision parameters. We prove that\nrecurrent GNNs, with sum aggregation and ReLU activation, can emulate any graph\nalgorithm that respects the natural message-passing invariance induced by the\ncolor refinement (or Weisfeiler-Leman) algorithm. While it is well known that\nthe expressive power of GNNs is limited by this invariance [Morris et al., AAAI\n2019; Xu et al., ICLR 2019], we establish that recurrent GNNs can actually\nreach this limit. This is in contrast to non-recurrent GNNs, which have the\npower of Weisfeiler-Leman only in a very weak, \"non-uniform\", sense where every\ngraph size requires a different GNN model to compute with. The emulation we\nconstruct introduces only a polynomial overhead in both time and space.\n  Furthermore, we show that by incorporating random initialization, recurrent\nGNNs can emulate all graph algorithms, implying in particular that any graph\nalgorithm with polynomial-time complexity can be emulated by a recurrent GNN\nwith random initialization, running in polynomial time.", "AI": {"tldr": "Recurrent GNNs with sum aggregation and ReLU activation can match the expressivity of the Weisfeiler-Leman algorithm, unlike non-recurrent GNNs. They can emulate any graph algorithm respecting this invariance, with polynomial overhead. Random initialization extends this to all polynomial-time graph algorithms.", "motivation": "To determine the expressivity limits of recurrent GNNs and compare them to non-recurrent variants, particularly in relation to the Weisfeiler-Leman algorithm.", "method": "Analyzing recurrent GNNs with sum aggregation and ReLU activation, proving their ability to emulate graph algorithms respecting Weisfeiler-Leman invariance. Random initialization is also explored.", "result": "Recurrent GNNs reach the expressivity limit of Weisfeiler-Leman, unlike non-recurrent GNNs. They emulate algorithms with polynomial overhead and, with random initialization, all polynomial-time graph algorithms.", "conclusion": "Recurrent GNNs are as expressive as the Weisfeiler-Leman algorithm and can emulate any polynomial-time graph algorithm with random initialization, highlighting their superior expressivity over non-recurrent GNNs."}}
{"id": "2504.16960", "pdf": "https://arxiv.org/pdf/2504.16960", "abs": "https://arxiv.org/abs/2504.16960", "authors": ["Weixuan Chen", "Qianqian Yang", "Shuo Shao", "Zhiguo Shi", "Jiming Chen", "Xuemin", "Shen"], "title": "Enhancing the Security of Semantic Communication via Knowledge-Aided Coding and Jamming", "categories": ["cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "As semantic communication (SemCom) emerges as a promising communication\nparadigm, ensuring the security of semantic information over open wireless\nchannels has become crucial. Traditional encryption methods introduce\nconsiderable communication overhead, while existing learning-based secure\nSemCom schemes often rely on a channel capacity advantage for the legitimate\nreceiver, which is challenging to guarantee in practice. In this paper, we\npropose a coding-enhanced jamming approach that eliminates the need to transmit\na secret key by utilizing shared knowledge between the legitimate receiver and\nthe transmitter. We generate private codebooks with neural network (NN)-based\nencoders, using them to encode data into a sequence Y1, which is then\nsuperposed with a sequence Y2 drawn from the private codebook. By optimizing\nthe power allocation between the two sequences, the legitimate receiver can\nsuccessfully decode the data, while the eavesdropper' s performance is\nsignificantly degraded, potentially to the point of random guessing.\nExperimental results demonstrate that our method achieves comparable security\nto state-of-the-art approaches while significantly improving the reconstruction\nperformance of the legitimate receiver by more than 1 dB across varying channel\nsignal-to-noise ratios (SNRs) and compression ratios.", "AI": {"tldr": "A coding-enhanced jamming method for secure semantic communication (SemCom) eliminates secret key transmission, using shared knowledge and NN-based encoders to ensure security and improve performance.", "motivation": "Traditional encryption and learning-based secure SemCom schemes introduce overhead or rely on impractical channel advantages. A more efficient and practical solution is needed.", "method": "Proposes a coding-enhanced jamming approach using NN-based encoders to generate private codebooks. Data is encoded into sequences, superposed, and optimized for power allocation to secure communication.", "result": "Achieves comparable security to state-of-the-art methods while improving the legitimate receiver's reconstruction performance by over 1 dB across varying SNRs and compression ratios.", "conclusion": "The method effectively secures SemCom without secret keys, enhancing performance for legitimate users while degrading eavesdropper performance."}}
{"id": "2505.00033", "pdf": "https://arxiv.org/pdf/2505.00033", "abs": "https://arxiv.org/abs/2505.00033", "authors": ["Andrew Kiruluta"], "title": "From Attention to Atoms: Spectral Dictionary Learning for Fast, Interpretable Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We propose a novel spectral generative modeling framework for natural\nlanguage processing that jointly learns a global time varying Fourier\ndictionary and per token mixing coefficients, replacing the ubiquitous self\nattention mechanism in transformer architectures. By enforcing reconstruction\nlosses in both the time domain (embedding reconstruction) and the frequency\ndomain (via Short Time Fourier Transform magnitude matching) alongside a\nstandard language modeling objective, and fitting a Gaussian Mixture Model\n(GMM) prior over the learned mixing vectors, our approach achieves competitive\nperplexity and generation quality on standard benchmarks such as WikiText2 and\nPenn Treebank. In contrast to the quadratic computation complexity of self\nattention, our method operates with linear complexity, delivering substantial\nefficiency gains. We demonstrate that spectral dictionary models can achieve\ncompetitive performance compared to transformer baselines while significantly\nreducing inference latency and memory footprint, offering a compelling\nalternative for scalable language modeling.", "AI": {"tldr": "A spectral generative modeling framework replaces self-attention in transformers with a Fourier dictionary and GMM prior, achieving competitive performance with linear complexity.", "motivation": "To address the quadratic complexity of self-attention in transformers by proposing a more efficient spectral approach.", "method": "Jointly learns a Fourier dictionary and token mixing coefficients, enforcing reconstruction losses in time and frequency domains, and uses a GMM prior.", "result": "Achieves competitive perplexity and generation quality on WikiText2 and Penn Treebank with linear complexity.", "conclusion": "Spectral dictionary models offer a scalable, efficient alternative to transformers with reduced latency and memory footprint."}}
{"id": "2505.00034", "pdf": "https://arxiv.org/pdf/2505.00034", "abs": "https://arxiv.org/abs/2505.00034", "authors": ["Zijie Lin", "Zikang Liu", "Hanbo Fan"], "title": "Improving Phishing Email Detection Performance of Small Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models(LLMs) have demonstrated remarkable performance on many\nnatural language processing(NLP) tasks and have been employed in phishing email\ndetection research. However, in current studies, well-performing LLMs typically\ncontain billions or even tens of billions of parameters, requiring enormous\ncomputational resources. To reduce computational costs, we investigated the\neffectiveness of small-parameter LLMs for phishing email detection. These LLMs\nhave around 3 billion parameters and can run on consumer-grade GPUs. However,\nsmall LLMs often perform poorly in phishing email detection task. To address\nthese issues, we designed a set of methods including Prompt Engineering,\nExplanation Augmented Fine-tuning, and Model Ensemble to improve phishing email\ndetection capabilities of small LLMs. We validated the effectiveness of our\napproach through experiments, significantly improving accuracy on the\nSpamAssassin dataset from around 0.5 for baseline models like\nQwen2.5-1.5B-Instruct to 0.976.", "AI": {"tldr": "Small-parameter LLMs (3B params) were improved for phishing email detection using Prompt Engineering, Explanation Augmented Fine-tuning, and Model Ensemble, achieving 0.976 accuracy on SpamAssassin.", "motivation": "Reduce computational costs of large LLMs while maintaining performance in phishing email detection.", "method": "Employed Prompt Engineering, Explanation Augmented Fine-tuning, and Model Ensemble on small LLMs.", "result": "Accuracy improved from ~0.5 to 0.976 on the SpamAssassin dataset.", "conclusion": "Small LLMs can be effectively optimized for phishing email detection with tailored methods."}}
{"id": "2505.00394", "pdf": "https://arxiv.org/pdf/2505.00394", "abs": "https://arxiv.org/abs/2505.00394", "authors": ["Wenxuan Liu", "Yao Deng", "Kang Chen", "Xian Zhong", "Zhaofei Yu", "Tiejun Huang"], "title": "SOTA: Spike-Navigated Optimal TrAnsport Saliency Region Detection in Composite-bias Videos", "categories": ["cs.CV"], "comment": "Accepted to IJCAI 2025", "summary": "Existing saliency detection methods struggle in real-world scenarios due to\nmotion blur and occlusions. In contrast, spike cameras, with their high\ntemporal resolution, significantly enhance visual saliency maps. However, the\ncomposite noise inherent to spike camera imaging introduces discontinuities in\nsaliency detection. Low-quality samples further distort model predictions,\nleading to saliency bias. To address these challenges, we propose\nSpike-navigated Optimal TrAnsport Saliency Region Detection (SOTA), a framework\nthat leverages the strengths of spike cameras while mitigating biases in both\nspatial and temporal dimensions. Our method introduces Spike-based Micro-debias\n(SM) to capture subtle frame-to-frame variations and preserve critical details,\neven under minimal scene or lighting changes. Additionally, Spike-based\nGlobal-debias (SG) refines predictions by reducing inconsistencies across\ndiverse conditions. Extensive experiments on real and synthetic datasets\ndemonstrate that SOTA outperforms existing methods by eliminating composite\nnoise bias. Our code and dataset will be released at\nhttps://github.com/lwxfight/sota.", "AI": {"tldr": "SOTA improves saliency detection in spike cameras by addressing noise and bias with micro and global debiasing techniques.", "motivation": "Existing methods fail due to motion blur, occlusions, and noise in spike cameras, leading to biased saliency maps.", "method": "Proposes SOTA with Spike-based Micro-debias (SM) for frame variations and Spike-based Global-debias (SG) for consistency.", "result": "Outperforms existing methods by eliminating noise bias in real and synthetic datasets.", "conclusion": "SOTA effectively leverages spike cameras' strengths while mitigating biases, with code and dataset publicly available."}}
{"id": "2505.00302", "pdf": "https://arxiv.org/pdf/2505.00302", "abs": "https://arxiv.org/abs/2505.00302", "authors": ["Xinlong Zhao", "Liying Zhang", "Tianbo Zou", "Yan Zhang"], "title": "Temporal Attention Evolutional Graph Convolutional Network for Multivariate Time Series Forecasting", "categories": ["cs.LG", "68T09 (Primary), 68T07 (Secondary)"], "comment": "13 pages, 7 figures", "summary": "Multivariate time series forecasting enables the prediction of future states\nby leveraging historical data, thereby facilitating decision-making processes.\nEach data node in a multivariate time series encompasses a sequence of multiple\ndimensions. These nodes exhibit interdependent relationships, forming a graph\nstructure. While existing prediction methods often assume a fixed graph\nstructure, many real-world scenarios involve dynamic graph structures.\nMoreover, interactions among time series observed at different time scales vary\nsignificantly. To enhance prediction accuracy by capturing precise temporal and\nspatial features, this paper introduces the Temporal Attention Evolutional\nGraph Convolutional Network (TAEGCN). This novel method not only integrates\ncausal temporal convolution and a multi-head self-attention mechanism to learn\ntemporal features of nodes, but also construct the dynamic graph structure\nbased on these temporal features to keep the consistency of the changing in\nspatial feature with temporal series. TAEGCN adeptly captures temporal causal\nrelationships and hidden spatial dependencies within the data. Furthermore,\nTAEGCN incorporates a unified neural network that seamlessly integrates these\ncomponents to generate final predictions. Experimental results conducted on two\npublic transportation network datasets, METR-LA and PEMS-BAY, demonstrate the\nsuperior performance of the proposed model.", "AI": {"tldr": "The paper introduces TAEGCN, a model for multivariate time series forecasting that captures dynamic graph structures and multi-scale temporal interactions to improve prediction accuracy.", "motivation": "Existing methods assume fixed graph structures, but real-world scenarios involve dynamic graphs and varying time-scale interactions, necessitating a more adaptable approach.", "method": "TAEGCN combines causal temporal convolution, multi-head self-attention, and dynamic graph construction to learn temporal and spatial features, integrating them into a unified neural network.", "result": "TAEGCN outperforms existing methods on public transportation datasets (METR-LA and PEMS-BAY), demonstrating its effectiveness.", "conclusion": "TAEGCN successfully captures temporal and spatial dependencies in dynamic graphs, offering superior forecasting performance."}}
{"id": "2504.21632", "pdf": "https://arxiv.org/pdf/2504.21632", "abs": "https://arxiv.org/abs/2504.21632", "authors": ["Fuma Ito", "Chihiro Tsutake", "Keita Takahashi", "Toshiaki Fujii"], "title": "Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of Binary Classification", "categories": ["cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation (DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.", "AI": {"tldr": "A fast sign retrieval method for DCT coefficients using binary classification with CNNs, achieving high accuracy and low computation cost.", "motivation": "Efficiently compressing sign information of images by reconstructing signs of DCT coefficients from their amplitudes.", "method": "Proposes a binary classification approach using CNNs on 3D representations of amplitudes and signs, organized into sub-band blocks.", "result": "Accurate sign retrieval with significantly low computation cost.", "conclusion": "The method effectively compresses sign information with high efficiency and accuracy."}}
{"id": "2505.00035", "pdf": "https://arxiv.org/pdf/2505.00035", "abs": "https://arxiv.org/abs/2505.00035", "authors": ["Aayam Bansal", "Raghav Agarwal", "Kaashvi Jain"], "title": "Linguistic Complexity and Socio-cultural Patterns in Hip-Hop Lyrics", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages", "summary": "This paper presents a comprehensive computational framework for analyzing\nlinguistic complexity and socio-cultural trends in hip-hop lyrics. Using a\ndataset of 3,814 songs from 146 influential artists spanning four decades\n(1980-2020), we employ natural language processing techniques to quantify\nmultiple dimensions of lyrical complexity. Our analysis reveals a 23.7%\nincrease in vocabulary diversity over the study period, with East Coast artists\ndemonstrating 17.3% higher lexical variation than other regions. Rhyme density\nincreased by 34.2% across all regions, with Midwest artists exhibiting the\nhighest technical complexity (3.04 rhymes per line). Topic modeling identified\nsignificant shifts in thematic content, with social justice themes decreasing\nfrom 28.5% to 13.8% of content while introspective themes increased from 7.6%\nto 26.3%. Sentiment analysis demon- strated that lyrics became significantly\nmore negative during sociopolitical crises, with polarity decreasing by 0.31\nfollowing major social unrest. Multi-dimensional analysis revealed four dis-\ntinct stylistic approaches that correlate strongly with geographic origin\n(r=0.68, p!0.001) and time period (r=0.59, p<0.001). These findings establish\nquantitative evidence for the evolution of hip- hop as both an art form and a\nreflection of societal dynamics, providing insights into the interplay between\nlinguistic innovation and cultural context in popular music.", "AI": {"tldr": "A computational analysis of hip-hop lyrics (1980-2020) shows increased vocabulary diversity, rhyme density, and thematic shifts, with regional and temporal stylistic correlations.", "motivation": "To quantify linguistic complexity and socio-cultural trends in hip-hop lyrics, examining how the genre evolves as an art form and societal reflection.", "method": "Natural language processing on 3,814 songs from 146 artists, analyzing vocabulary, rhyme density, themes, sentiment, and stylistic patterns.", "result": "Vocabulary diversity rose 23.7%, East Coast artists led in lexical variation, rhyme density increased 34.2%, and themes shifted from social justice to introspection. Sentiment turned negative during crises.", "conclusion": "Hip-hop's linguistic and thematic evolution reflects societal dynamics, with clear regional and temporal stylistic patterns, highlighting its dual role as art and cultural commentary."}}
{"id": "2505.00040", "pdf": "https://arxiv.org/pdf/2505.00040", "abs": "https://arxiv.org/abs/2505.00040", "authors": ["Dishanand Jayeprokash", "Julia Gonski"], "title": "Convolutional Autoencoders for Data Compression and Anomaly Detection in Small Satellite Technologies", "categories": ["astro-ph.IM", "cs.AI"], "comment": "10 pages, 6 figures", "summary": "Small satellite technologies have enhanced the potential and feasibility of\ngeodesic missions, through simplification of design and decreased costs\nallowing for more frequent launches. On-satellite data acquisition systems can\nbenefit from the implementation of machine learning (ML), for better\nperformance and greater efficiency on tasks such as image processing or feature\nextraction. This work presents convolutional autoencoders for implementation on\nthe payload of small satellites, designed to achieve dual functionality of data\ncompression for more efficient off-satellite transmission, and at-source\nanomaly detection to inform satellite data-taking. This capability is\ndemonstrated for a use case of disaster monitoring using aerial image datasets\nof the African continent, offering avenues for both novel ML-based approaches\nin small satellite applications along with the expansion of space technology\nand artificial intelligence in Africa.", "AI": {"tldr": "The paper explores using convolutional autoencoders on small satellites for data compression and anomaly detection, demonstrated with disaster monitoring in Africa.", "motivation": "Small satellites' cost-effectiveness and ML's potential for improving on-satellite data systems motivate this work.", "method": "Convolutional autoencoders are implemented for dual functionality: data compression and anomaly detection.", "result": "The method is successfully demonstrated for disaster monitoring using African aerial images.", "conclusion": "The work advances ML applications in small satellites and supports space tech growth in Africa."}}
{"id": "2505.00421", "pdf": "https://arxiv.org/pdf/2505.00421", "abs": "https://arxiv.org/abs/2505.00421", "authors": ["Xia Yuan", "Hai Yuan", "Wenyi Ge", "Ying Fu", "Xi Wu", "Guanyu Xing"], "title": "Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular Videos", "categories": ["cs.CV"], "comment": null, "summary": "High-quality, animatable 3D human avatar reconstruction from monocular videos\noffers significant potential for reducing reliance on complex hardware, making\nit highly practical for applications in game development, augmented reality,\nand social media. However, existing methods still face substantial challenges\nin capturing fine geometric details and maintaining animation stability,\nparticularly under dynamic or complex poses. To address these issues, we\npropose a novel real-time framework for animatable human avatar reconstruction\nbased on 2D Gaussian Splatting (2DGS). By leveraging 2DGS and global SMPL pose\nparameters, our framework not only aligns positional and rotational\ndiscrepancies but also enables robust and natural pose-driven animation of the\nreconstructed avatars. Furthermore, we introduce a Rotation Compensation\nNetwork (RCN) that learns rotation residuals by integrating local geometric\nfeatures with global pose parameters. This network significantly improves the\nhandling of non-rigid deformations and ensures smooth, artifact-free pose\ntransitions during animation. Experimental results demonstrate that our method\nsuccessfully reconstructs realistic and highly animatable human avatars from\nmonocular videos, effectively preserving fine-grained details while ensuring\nstable and natural pose variation. Our approach surpasses current\nstate-of-the-art methods in both reconstruction quality and animation\nrobustness on public benchmarks.", "AI": {"tldr": "A novel real-time framework for animatable 3D human avatar reconstruction from monocular videos using 2D Gaussian Splatting and a Rotation Compensation Network, outperforming current methods in quality and robustness.", "motivation": "To address challenges in capturing fine geometric details and maintaining animation stability in 3D human avatar reconstruction from monocular videos.", "method": "Proposes a framework combining 2D Gaussian Splatting (2DGS) and global SMPL pose parameters, along with a Rotation Compensation Network (RCN) for handling non-rigid deformations.", "result": "Successfully reconstructs realistic, animatable avatars with fine details and stable pose transitions, outperforming state-of-the-art methods.", "conclusion": "The framework achieves high-quality, robust animation of human avatars, making it practical for applications like gaming and AR."}}
{"id": "2505.00307", "pdf": "https://arxiv.org/pdf/2505.00307", "abs": "https://arxiv.org/abs/2505.00307", "authors": ["Yu-Hsiang Lan", "Anton Alyakin", "Eric K. Oermann"], "title": "Gateformer: Advancing Multivariate Time Series Forecasting through Temporal and Variate-Wise Attention with Gated Representations", "categories": ["cs.LG"], "comment": null, "summary": "There has been a recent surge of interest in time series modeling using the\nTransformer architecture. However, forecasting multivariate time series with\nTransformer presents a unique challenge as it requires modeling both temporal\n(cross-time) and variate (cross-variate) dependencies. While Transformer-based\nmodels have gained popularity for their flexibility in capturing both\nsequential and cross-variate relationships, it is unclear how to best integrate\nthese two sources of information in the context of the Transformer architecture\nwhile optimizing for both performance and efficiency. We re-purpose the\nTransformer architecture to effectively model both cross-time and cross-variate\ndependencies. Our approach begins by embedding each variate independently into\na variate-wise representation that captures its cross-time dynamics, and then\nmodels cross-variate dependencies through attention mechanisms on these learned\nembeddings. Gating operations in both cross-time and cross-variate modeling\nphases regulate information flow, allowing the model to focus on the most\nrelevant features for accurate predictions. Our method achieves\nstate-of-the-art performance across 13 real-world datasets and can be\nseamlessly integrated into other Transformer-based and LLM-based forecasters,\ndelivering performance improvements up to 20.7\\% over original models. Code is\navailable at this repository: https://github.com/nyuolab/Gateformer.", "AI": {"tldr": "The paper proposes a Transformer-based method to model both temporal and variate dependencies in multivariate time series forecasting, achieving state-of-the-art performance.", "motivation": "Addressing the challenge of integrating cross-time and cross-variate dependencies in Transformer architectures for efficient and accurate forecasting.", "method": "Embeds variates independently for cross-time dynamics, uses attention for cross-variate dependencies, and employs gating to regulate information flow.", "result": "Achieves state-of-the-art performance on 13 datasets, with up to 20.7% improvement over original models.", "conclusion": "The method effectively models dependencies and enhances performance, with potential for integration into other Transformer-based forecasters."}}
{"id": "2505.00036", "pdf": "https://arxiv.org/pdf/2505.00036", "abs": "https://arxiv.org/abs/2505.00036", "authors": ["Zhongren Chen", "Joshua Kalla", "Quan Le", "Shinpei Nakamura-Sakai", "Jasjeet Sekhon", "Ruixiao Wang"], "title": "A Framework to Assess the Persuasion Risks Large Language Model Chatbots Pose to Democratic Societies", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "In recent years, significant concern has emerged regarding the potential\nthreat that Large Language Models (LLMs) pose to democratic societies through\ntheir persuasive capabilities. We expand upon existing research by conducting\ntwo survey experiments and a real-world simulation exercise to determine\nwhether it is more cost effective to persuade a large number of voters using\nLLM chatbots compared to standard political campaign practice, taking into\naccount both the \"receive\" and \"accept\" steps in the persuasion process (Zaller\n1992). These experiments improve upon previous work by assessing extended\ninteractions between humans and LLMs (instead of using single-shot\ninteractions) and by assessing both short- and long-run persuasive effects\n(rather than simply asking users to rate the persuasiveness of LLM-produced\ncontent). In two survey experiments (N = 10,417) across three distinct\npolitical domains, we find that while LLMs are about as persuasive as actual\ncampaign ads once voters are exposed to them, political persuasion in the\nreal-world depends on both exposure to a persuasive message and its impact\nconditional on exposure. Through simulations based on real-world parameters, we\nestimate that LLM-based persuasion costs between \\$48-\\$74 per persuaded voter\ncompared to \\$100 for traditional campaign methods, when accounting for the\ncosts of exposure. However, it is currently much easier to scale traditional\ncampaign persuasion methods than LLM-based persuasion. While LLMs do not\ncurrently appear to have substantially greater potential for large-scale\npolitical persuasion than existing non-LLM methods, this may change as LLM\ncapabilities continue to improve and it becomes easier to scalably encourage\nexposure to persuasive LLMs.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.00050", "pdf": "https://arxiv.org/pdf/2505.00050", "abs": "https://arxiv.org/abs/2505.00050", "authors": ["Aayam Bansal", "Agneya Tharun"], "title": "Emotional Analysis of Fashion Trends Using Social Media and AI: Sentiment Analysis on Twitter for Fashion Trend Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages", "summary": "This study explores the intersection of fashion trends and social media\nsentiment through computational analysis of Twitter data using the T4SA\n(Twitter for Sentiment Analysis) dataset. By applying natural language\nprocessing and machine learning techniques, we examine how sentiment patterns\nin fashion-related social media conversations can serve as predictors for\nemerging fashion trends. Our analysis involves the identification and\ncategorization of fashion-related content, sentiment classification with\nimproved normalization techniques, time series decomposition, statistically\nvalidated causal relationship modeling, cross-platform sentiment comparison,\nand brand-specific sentiment analysis. Results indicate correlations between\nsentiment patterns and fashion theme popularity, with accessories and\nstreetwear themes showing statistically significant rising trends. The Granger\ncausality analysis establishes sustainability and streetwear as primary trend\ndrivers, showing bidirectional relationships with several other themes. The\nfindings demonstrate that social media sentiment analysis can serve as an\neffective early indicator of fashion trend trajectories when proper statistical\nvalidation is applied. Our improved predictive model achieved 78.35% balanced\naccuracy in sentiment classification, establishing a reliable foundation for\ntrend prediction across positive, neutral, and negative sentiment categories.", "AI": {"tldr": "The paper uses Twitter data and NLP to link social media sentiment with fashion trends, identifying key drivers like sustainability and streetwear.", "motivation": "To explore how social media sentiment can predict emerging fashion trends.", "method": "Computational analysis of Twitter data using NLP and machine learning, including sentiment classification, time series decomposition, and causal modeling.", "result": "Found correlations between sentiment and fashion trends, with sustainability and streetwear as key drivers. Predictive model achieved 78.35% accuracy.", "conclusion": "Social media sentiment analysis is a reliable early indicator of fashion trends when statistically validated."}}
{"id": "2505.00426", "pdf": "https://arxiv.org/pdf/2505.00426", "abs": "https://arxiv.org/abs/2505.00426", "authors": ["Ruiyuan Zhang", "Qi Wang", "Jiaxiang Liu", "Yu Zhang", "Yuchi Huo", "Chao Wu"], "title": "Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly", "categories": ["cs.CV"], "comment": "10 pages, 12 figures, Accepted by IJCAI-2025", "summary": "3D part assembly aims to understand part relationships and predict their\n6-DoF poses to construct realistic 3D shapes, addressing the growing demand for\nautonomous assembly, which is crucial for robots. Existing methods mainly\nestimate the transformation of each part by training neural networks under\nsupervision, which requires a substantial quantity of manually labeled data.\nHowever, the high cost of data collection and the immense variability of\nreal-world shapes and parts make traditional methods impractical for\nlarge-scale applications. In this paper, we propose first a zero-shot part\nassembly method that utilizes pre-trained point cloud diffusion models as\ndiscriminators in the assembly process, guiding the manipulation of parts to\nform realistic shapes. Specifically, we theoretically demonstrate that\nutilizing a diffusion model for zero-shot part assembly can be transformed into\nan Iterative Closest Point (ICP) process. Then, we propose a novel pushing-away\nstrategy to address the overlap parts, thereby further enhancing the robustness\nof the method. To verify our work, we conduct extensive experiments and\nquantitative comparisons to several strong baseline methods, demonstrating the\neffectiveness of the proposed approach, which even surpasses the supervised\nlearning method. The code has been released on\nhttps://github.com/Ruiyuan-Zhang/Zero-Shot-Assembly.", "AI": {"tldr": "A zero-shot 3D part assembly method using pre-trained point cloud diffusion models to guide part manipulation, outperforming supervised methods without labeled data.", "motivation": "Addressing the impracticality of traditional supervised methods due to high data collection costs and variability in real-world shapes.", "method": "Utilizes pre-trained point cloud diffusion models as discriminators, transforming the process into an Iterative Closest Point (ICP) process, with a pushing-away strategy for overlap parts.", "result": "Outperforms supervised methods in experiments, demonstrating robustness and effectiveness.", "conclusion": "The proposed zero-shot method is practical for large-scale applications, surpassing supervised learning in performance."}}
{"id": "2505.00315", "pdf": "https://arxiv.org/pdf/2505.00315", "abs": "https://arxiv.org/abs/2505.00315", "authors": ["Piotr Pi\u0119kos", "R\u00f3bert Csord\u00e1s", "J\u00fcrgen Schmidhuber"], "title": "Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via Expert-Choice Routing", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Recent advances in large language models highlighted the excessive quadratic\ncost of self-attention. Despite the significant research efforts, subquadratic\nattention methods still suffer from inferior performance in practice. We\nhypothesize that dynamic, learned content-based sparsity can lead to more\nefficient attention mechanisms. We present Mixture of Sparse Attention (MoSA),\na novel approach inspired by Mixture of Experts (MoE) with expert choice\nrouting. MoSA dynamically selects tokens for each attention head, allowing\narbitrary sparse attention patterns. By selecting $k$ tokens from a sequence of\nlength $T$, MoSA reduces the computational complexity of each attention head\nfrom $O(T^2)$ to $O(k^2 + T)$. This enables using more heads within the same\ncomputational budget, allowing higher specialization. We show that among the\ntested sparse attention variants, MoSA is the only one that can outperform the\ndense baseline, sometimes with up to 27% better perplexity for an identical\ncompute budget. MoSA can also reduce the resource usage compared to dense\nself-attention. Despite using torch implementation without an optimized kernel,\nperplexity-matched MoSA models are simultaneously faster in wall-clock time,\nrequire less memory for training, and drastically reduce the size of the\nKV-cache compared to the dense transformer baselines.", "AI": {"tldr": "MoSA introduces dynamic, learned sparsity in attention mechanisms, reducing computational cost while maintaining or improving performance.", "motivation": "Address the excessive quadratic cost of self-attention in large language models and improve subquadratic attention methods.", "method": "Proposes Mixture of Sparse Attention (MoSA), inspired by Mixture of Experts, to dynamically select tokens for each attention head, reducing complexity.", "result": "MoSA outperforms dense baselines, achieving up to 27% better perplexity, and reduces resource usage (faster, less memory, smaller KV-cache).", "conclusion": "MoSA is an efficient and effective alternative to dense self-attention, offering performance gains and resource savings."}}
{"id": "2505.00038", "pdf": "https://arxiv.org/pdf/2505.00038", "abs": "https://arxiv.org/abs/2505.00038", "authors": ["Cristina Garbacea", "Chenhao Tan"], "title": "HyPerAlign: Hypotheses-driven Personalized Alignment", "categories": ["cs.CL"], "comment": null, "summary": "Alignment algorithms are widely used to align large language models (LLMs) to\nhuman users based on preference annotations that reflect their intended\nreal-world use cases. Typically these (often divergent) preferences are\naggregated over a diverse set of users, resulting in fine-tuned models that are\naligned to the ``average-user'' preference. Nevertheless, current models are\nused by individual users in very specific contexts and situations, emphasizing\nthe need for user-dependent preference control. In this work we address the\nproblem of personalizing LLM outputs to their users, aiming to generate\ncustomized responses tailored to individual users, instead of generic outputs\nthat emulate the collective voices of diverse populations. We propose a novel\ninterpretable and sample-efficient hypotheses-driven personalization approach\n(HyPerAlign) where given few-shot examples written by a particular user, we\nfirst infer hypotheses about their communication strategies, personality and\nwriting style, then prompt LLM models with these hypotheses and user specific\nattributes to generate customized outputs. We conduct experiments on two\ndifferent personalization tasks, authorship attribution and deliberative\nalignment, with datasets from diverse domains (news articles, blog posts,\nemails, jailbreaking benchmarks), and demonstrate the superiority of\nhypotheses-driven personalization approach when compared to preference-based\nfine-tuning methods. For deliberative alignment, the helpfulness of LLM models\nis improved by up to $70\\%$ on average. For authorship attribution, results\nindicate consistently high win-rates (commonly $>90\\%$) against\nstate-of-the-art preference fine-tuning approaches for LLM personalization\nacross diverse user profiles and LLM models. Overall, our approach represents\nan interpretable and sample-efficient strategy for the personalization of LLM\nmodels to individual users.", "AI": {"tldr": "The paper introduces HyPerAlign, a hypotheses-driven approach for personalizing LLM outputs to individual users, outperforming traditional preference-based fine-tuning methods in tasks like authorship attribution and deliberative alignment.", "motivation": "Current LLM alignment methods aggregate preferences over diverse users, leading to generic outputs. The need for user-specific customization in real-world contexts drives this work.", "method": "HyPerAlign infers user-specific hypotheses (communication strategies, personality, writing style) from few-shot examples and prompts LLMs with these to generate tailored outputs.", "result": "Experiments show HyPerAlign improves LLM helpfulness by up to 70% for deliberative alignment and achieves >90% win-rates in authorship attribution against state-of-the-art methods.", "conclusion": "HyPerAlign offers an interpretable and sample-efficient strategy for personalizing LLMs to individual users, addressing the limitations of generic preference-based alignment."}}
{"id": "2505.00060", "pdf": "https://arxiv.org/pdf/2505.00060", "abs": "https://arxiv.org/abs/2505.00060", "authors": ["Jeho Choi"], "title": "Fact-Consistency Evaluation of Text-to-SQL Generation for Business Intelligence Using Exaone 3.5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 pages, 1 table", "summary": "Large Language Models (LLMs) have shown promise in enabling natural language\ninterfaces for structured data querying through text-to-SQL generation.\nHowever, their application in real-world Business Intelligence (BI) contexts\nremains limited due to semantic hallucinations, structural errors, and a lack\nof domain-specific evaluation frameworks. In this study, we propose a\nFact-Consistency Evaluation Framework for assessing the semantic accuracy of\nLLM-generated SQL outputs using Exaone 3.5--an instruction-tuned, bilingual LLM\noptimized for enterprise tasks. We construct a domain-specific benchmark\ncomprising 219 natural language business questions across five SQL complexity\nlevels, derived from actual sales data in LG Electronics' internal BigQuery\nenvironment. Each question is paired with a gold-standard SQL query and a\nvalidated ground-truth answer. We evaluate model performance using answer\naccuracy, execution success rate, semantic error rate, and non-response rate.\nExperimental results show that while Exaone 3.5 performs well on simple\naggregation tasks (93% accuracy in L1), it exhibits substantial degradation in\narithmetic reasoning (4% accuracy in H1) and grouped ranking tasks (31% in H4),\nwith semantic errors and non-responses concentrated in complex cases.\nQualitative error analysis further identifies common failure types such as\nmisapplied arithmetic logic, incomplete filtering, and incorrect grouping\noperations. Our findings highlight the current limitations of LLMs in\nbusiness-critical environments and underscore the need for fact-consistency\nvalidation layers and hybrid reasoning approaches. This work contributes a\nreproducible benchmark and evaluation methodology for advancing reliable\nnatural language interfaces to structured enterprise data systems.", "AI": {"tldr": "The paper evaluates LLMs for text-to-SQL in BI contexts, proposing a Fact-Consistency Framework to assess semantic accuracy, revealing limitations in complex tasks.", "motivation": "Addressing the limitations of LLMs in real-world BI applications due to semantic hallucinations, structural errors, and lack of domain-specific evaluation.", "method": "Proposes a Fact-Consistency Evaluation Framework using Exaone 3.5, tested on a domain-specific benchmark of 219 business questions with gold-standard SQL.", "result": "Exaone 3.5 performs well on simple tasks (93% accuracy) but struggles with complex ones (4-31% accuracy), showing semantic errors and non-responses.", "conclusion": "Highlights LLM limitations in BI and advocates for fact-consistency validation and hybrid reasoning to improve reliability."}}
{"id": "2505.00452", "pdf": "https://arxiv.org/pdf/2505.00452", "abs": "https://arxiv.org/abs/2505.00452", "authors": ["Gregory Schroeder", "Mohamed Sabry", "Cristina Olaverri-Monreal"], "title": "ClearLines - Camera Calibration from Straight Lines", "categories": ["cs.CV"], "comment": null, "summary": "The problem of calibration from straight lines is fundamental in geometric\ncomputer vision, with well-established theoretical foundations. However, its\npractical applicability remains limited, particularly in real-world outdoor\nscenarios. These environments pose significant challenges due to diverse and\ncluttered scenes, interrupted reprojections of straight 3D lines, and varying\nlighting conditions, making the task notoriously difficult. Furthermore, the\nfield lacks a dedicated dataset encouraging the development of respective\ndetection algorithms. In this study, we present a small dataset named\n\"ClearLines\", and by detailing its creation process, provide practical insights\nthat can serve as a guide for developing and refining straight 3D line\ndetection algorithms.", "AI": {"tldr": "The paper introduces \"ClearLines,\" a dataset for straight 3D line detection, addressing challenges in real-world outdoor scenarios.", "motivation": "Practical calibration from straight lines in outdoor environments is difficult due to cluttered scenes, interrupted reprojections, and lighting variations. The lack of a dedicated dataset hinders algorithm development.", "method": "The study presents the \"ClearLines\" dataset and details its creation process to guide algorithm development.", "result": "The dataset provides practical insights for refining straight 3D line detection algorithms.", "conclusion": "\"ClearLines\" serves as a valuable resource for advancing straight line detection in challenging outdoor scenarios."}}
{"id": "2505.00316", "pdf": "https://arxiv.org/pdf/2505.00316", "abs": "https://arxiv.org/abs/2505.00316", "authors": ["Tien Comlekoglu", "J. Quetzalc\u00f3atl Toledo-Mar\u00edn", "Tina Comlekoglu", "Douglas W. DeSimone", "Shayn M. Peirce", "Geoffrey Fox", "James A. Glazier"], "title": "Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "The Cellular-Potts model is a powerful and ubiquitous framework for\ndeveloping computational models for simulating complex multicellular biological\nsystems. Cellular-Potts models (CPMs) are often computationally expensive due\nto the explicit modeling of interactions among large numbers of individual\nmodel agents and diffusive fields described by partial differential equations\n(PDEs). In this work, we develop a convolutional neural network (CNN) surrogate\nmodel using a U-Net architecture that accounts for periodic boundary\nconditions. We use this model to accelerate the evaluation of a mechanistic CPM\npreviously used to investigate \\textit{in vitro} vasculogenesis. The surrogate\nmodel was trained to predict 100 computational steps ahead (Monte-Carlo steps,\nMCS), accelerating simulation evaluations by a factor of 590 times compared to\nCPM code execution. Over multiple recursive evaluations, our model effectively\ncaptures the emergent behaviors demonstrated by the original Cellular-Potts\nmodel of such as vessel sprouting, extension and anastomosis, and contraction\nof vascular lacunae. This approach demonstrates the potential for deep learning\nto serve as efficient surrogate models for CPM simulations, enabling faster\nevaluation of computationally expensive CPM of biological processes at greater\nspatial and temporal scales.", "AI": {"tldr": "A CNN surrogate model using U-Net architecture accelerates Cellular-Potts model (CPM) simulations by 590x, capturing emergent behaviors like vasculogenesis.", "motivation": "CPMs are computationally expensive due to explicit modeling of interactions and PDEs, limiting scalability.", "method": "Developed a U-Net-based CNN surrogate model trained to predict 100 Monte-Carlo steps ahead.", "result": "Achieved 590x speedup, accurately capturing emergent behaviors like vessel sprouting and anastomosis.", "conclusion": "Deep learning can efficiently replace CPMs, enabling faster, larger-scale biological simulations."}}
{"id": "2505.00039", "pdf": "https://arxiv.org/pdf/2505.00039", "abs": "https://arxiv.org/abs/2505.00039", "authors": ["Hudson de Martim"], "title": "Graph RAG for Legal Norms: A Hierarchical and Temporal Approach", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "This article proposes an adaptation of Graph Retrieval Augmented Generation\n(Graph RAG) specifically designed for the analysis and comprehension of legal\nnorms, which are characterized by their predefined hierarchical structure,\nextensive network of internal and external references and multiple temporal\nversions. By combining structured knowledge graphs with contextually enriched\ntext segments, Graph RAG offers a promising solution to address the inherent\ncomplexity and vast volume of legal data. The integration of hierarchical\nstructure and temporal evolution into knowledge graphs - along with the concept\nof comprehensive Text Units - facilitates the construction of richer,\ninterconnected representations of legal knowledge. Through a detailed analysis\nof Graph RAG and its application to legal norm datasets, this article aims to\nsignificantly advance the field of Artificial Intelligence applied to Law,\ncreating opportunities for more effective systems in legal research,\nlegislative analysis, and decision support.", "AI": {"tldr": "The paper adapts Graph RAG for legal norms, leveraging hierarchical and temporal knowledge graphs to enhance legal AI applications.", "motivation": "Legal norms are complex due to their hierarchical structure, references, and temporal versions, requiring advanced tools for analysis.", "method": "Combines structured knowledge graphs with enriched text segments (Text Units) to model legal data.", "result": "Graph RAG enables richer, interconnected legal knowledge representations.", "conclusion": "This approach advances AI in law, improving legal research, legislative analysis, and decision support."}}
{"id": "2505.00091", "pdf": "https://arxiv.org/pdf/2505.00091", "abs": "https://arxiv.org/abs/2505.00091", "authors": ["Tengchao Zhang", "Yonglin Tian", "Fei Lin", "Jun Huang", "Rui Qin", "Fei-Yue Wang"], "title": "CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios", "categories": ["cs.RO", "cs.AI"], "comment": "Submitted ITSC 2025", "summary": "With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV)\nswarms to perform complex tasks in urban environments, system design now faces\nmajor challenges, including efficient semantic understanding, flexible task\nplanning, and the ability to dynamically adjust coordination strategies in\nresponse to evolving environmental conditions and continuously changing task\nrequirements. To address the limitations of existing approaches, this paper\nproposes coordination field agentic system for coordinating heterogeneous UAV\nswarms in complex urban scenarios. In this system, large language models (LLMs)\nis responsible for interpreting high-level human instructions and converting\nthem into executable commands for the UAV swarms, such as patrol and target\ntracking. Subsequently, a Coordination field mechanism is proposed to guide UAV\nmotion and task selection, enabling decentralized and adaptive allocation of\nemergent tasks. A total of 50 rounds of comparative testing were conducted\nacross different models in a 2D simulation space to evaluate their performance.\nExperimental results demonstrate that the proposed system achieves superior\nperformance in terms of task coverage, response time, and adaptability to\ndynamic changes.", "AI": {"tldr": "A coordination field agentic system using LLMs and a coordination field mechanism for heterogeneous UAV swarms in urban environments outperforms existing methods in task coverage, response time, and adaptability.", "motivation": "Addressing challenges like semantic understanding, task planning, and dynamic coordination in UAV swarms for complex urban tasks.", "method": "Uses LLMs to interpret human instructions and a coordination field mechanism for decentralized task allocation and UAV motion guidance.", "result": "Superior performance in task coverage, response time, and adaptability, validated through 50 rounds of comparative testing.", "conclusion": "The proposed system effectively coordinates UAV swarms in dynamic urban scenarios, outperforming existing approaches."}}
{"id": "2505.00482", "pdf": "https://arxiv.org/pdf/2505.00482", "abs": "https://arxiv.org/abs/2505.00482", "authors": ["Kwon Byung-Ki", "Qi Dai", "Lee Hyoseok", "Chong Luo", "Tae-Hyun Oh"], "title": "JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present JointDiT, a diffusion transformer that models the joint\ndistribution of RGB and depth. By leveraging the architectural benefit and\noutstanding image prior of the state-of-the-art diffusion transformer, JointDiT\nnot only generates high-fidelity images but also produces geometrically\nplausible and accurate depth maps. This solid joint distribution modeling is\nachieved through two simple yet effective techniques that we propose, i.e.,\nadaptive scheduling weights, which depend on the noise levels of each modality,\nand the unbalanced timestep sampling strategy. With these techniques, we train\nour model across all noise levels for each modality, enabling JointDiT to\nnaturally handle various combinatorial generation tasks, including joint\ngeneration, depth estimation, and depth-conditioned image generation by simply\ncontrolling the timestep of each branch. JointDiT demonstrates outstanding\njoint generation performance. Furthermore, it achieves comparable results in\ndepth estimation and depth-conditioned image generation, suggesting that joint\ndistribution modeling can serve as a replaceable alternative to conditional\ngeneration. The project page is available at\nhttps://byungki-k.github.io/JointDiT/.", "AI": {"tldr": "JointDiT is a diffusion transformer that jointly models RGB and depth distributions, achieving high-fidelity results with adaptive scheduling and unbalanced timestep sampling.", "motivation": "To improve joint generation of RGB and depth by leveraging diffusion transformers, addressing the need for geometrically accurate depth maps alongside high-quality images.", "method": "Uses adaptive scheduling weights and unbalanced timestep sampling to train across noise levels for each modality, enabling flexible generation tasks.", "result": "Outperforms in joint generation and matches performance in depth estimation and depth-conditioned image generation.", "conclusion": "Joint distribution modeling can replace conditional generation, offering a unified approach for diverse tasks."}}
{"id": "2505.00333", "pdf": "https://arxiv.org/pdf/2505.00333", "abs": "https://arxiv.org/abs/2505.00333", "authors": ["Bumjun Kim", "Wan Choi"], "title": "Communication-Efficient Wireless Federated Fine-Tuning for Large-Scale AI Models", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Transformer-based large language models (LLMs) have achieved remarkable\nsuccess across various tasks. Yet, fine-tuning such massive models in federated\nlearning (FL) settings poses significant challenges due to resource constraints\nand communication overhead. Low-Rank Adaptation (LoRA) addresses these issues\nby training compact, low-rank matrices instead of fully fine-tuning large\nmodels. This paper introduces a wireless federated LoRA fine-tuning framework\nthat optimizes both learning performance and communication efficiency. We\nprovide a novel convergence analysis, revealing how LoRA rank and covariance\neffects influence FL training dynamics. Leveraging these insights, we propose\nSparsified Orthogonal Fine-Tuning (\\textbf{SOFT}), an adaptive sparsification\nmethod that streamlines parameter updates without expensive matrix\nmultiplications and singular value decomposition (SVD) operations.\nAdditionally, we present a Two Stage Federated Algorithm (\\textbf{TSFA})\nalgorithm that pre-determines key parameters offline and dynamically adjusts\nbandwidth and sparsification online, ensuring efficient training under latency\nconstraints. Experiments on benchmark datasets show that our approach achieves\naccuracy comparable to ideal scenario models while significantly reducing\ncommunication overhead. Our framework thus enables scalable, resource-efficient\ndeployment of large models in real-world wireless FL scenarios.", "AI": {"tldr": "A wireless federated LoRA fine-tuning framework is introduced to optimize learning and communication efficiency in federated learning, featuring adaptive sparsification and a two-stage algorithm for efficient training.", "motivation": "Transformer-based LLMs face challenges in federated learning due to resource constraints and communication overhead. LoRA offers a solution, but further optimization is needed.", "method": "Proposes SOFT (adaptive sparsification) and TSFA (two-stage algorithm) to streamline parameter updates and dynamically adjust training parameters.", "result": "Achieves accuracy comparable to ideal models while significantly reducing communication overhead.", "conclusion": "The framework enables scalable, resource-efficient deployment of large models in wireless FL settings."}}
{"id": "2505.00047", "pdf": "https://arxiv.org/pdf/2505.00047", "abs": "https://arxiv.org/abs/2505.00047", "authors": ["Peter West", "Christopher Potts"], "title": "Base Models Beat Aligned Models at Randomness and Creativity", "categories": ["cs.CL"], "comment": null, "summary": "Alignment has quickly become a default ingredient in LLM development, with\ntechniques such as reinforcement learning from human feedback making models act\nsafely, follow instructions, and perform ever-better on complex tasks. While\nthese techniques are certainly useful, we propose that they should not be\nuniversally applied and demonstrate a range of tasks on which base language\nmodels consistently outperform their popular aligned forms. Particularly, we\nstudy tasks that require unpredictable outputs, such as random number\ngeneration, mixed strategy games (rock-paper-scissors and hide-and-seek), and\ncreative writing. In each case, aligned models tend towards narrow behaviors\nthat result in distinct disadvantages, for instance, preferring to generate \"7\"\nover other uniformly random numbers, becoming almost fully predictable in some\ngame states, or prioritizing pleasant writing over creative originality. Across\nmodels tested, better performance on common benchmarks tends to correlate with\nworse performance on our tasks, suggesting an effective trade-off in the\nrequired capabilities.", "AI": {"tldr": "Aligned LLMs often underperform base models in tasks requiring unpredictability, like random number generation, games, and creative writing, due to narrow behaviors.", "motivation": "To challenge the universal application of alignment techniques in LLMs by showing their limitations in tasks needing unpredictable outputs.", "method": "Study tasks like random number generation, mixed strategy games, and creative writing, comparing base and aligned models.", "result": "Aligned models exhibit narrow behaviors, performing worse than base models in unpredictability-driven tasks.", "conclusion": "Alignment techniques trade off unpredictability for safety, suggesting they should not be universally applied."}}
{"id": "2505.00100", "pdf": "https://arxiv.org/pdf/2505.00100", "abs": "https://arxiv.org/abs/2505.00100", "authors": ["Ethan Dickey", "Andres Bejarano", "Rhianna Kuperus", "B\u00e1rbara Fagundes"], "title": "Evaluating the AI-Lab Intervention: Impact on Student Perception and Use of Generative AI in Early Undergraduate Computer Science Courses", "categories": ["cs.CY", "cs.AI", "cs.ET", "K.3"], "comment": "18 pages, 5 figures, 17 tables, submitted for publication", "summary": "Generative AI (GenAI) is rapidly entering computer science education, yet its\neffects on student learning, skill development, and perceptions remain\nunderexplored. Concerns about overreliance coexist with a gap in research on\nstructured scaffolding to guide tool use in formal courses. This study examines\nthe impact of a dedicated \"AI-Lab\" intervention -- emphasizing guided\nscaffolding and mindful engagement -- on undergraduate students in Data\nStructures and Algorithms, Competitive Programming, and first-year engineering\ncourses at Purdue University.\n  Over three semesters, we integrated AI-Lab modules into four mandatory and\nelective courses, yielding 831 matched pre- and post-intervention survey\nresponses, alongside focus group discussions. Employing a mixed-methods\napproach, we analyzed quantitative shifts in usage patterns and attitudes as\nwell as qualitative narratives of student experiences.\n  While the overall frequency of GenAI usage for homework or programming\nprojects remained largely stable, we observed large effect sizes in comfort and\nopenness across conceptual, debugging, and homework problems. Notably, usage\npatterns for debugging also shifted statistically significantly, reflecting\nstudents' more mindful and deliberate approach. Focus group discussions\ncorroborated these results, suggesting that the intervention \"bridged the gap\"\nbetween naive GenAI usage and more nuanced, reflective integration of AI tools\ninto coursework, ultimately heightening students' awareness of their own skill\ndevelopment.\n  These findings suggest that structured, scaffolded interventions can enable\nstudents to harness GenAI's benefits without undermining essential\ncompetencies. We offer evidence-based recommendations for educators seeking to\nintegrate GenAI responsibly into computing curricula and identify avenues for\nfuture research on GenAI-supported pedagogy.", "AI": {"tldr": "Structured scaffolding in AI-Lab interventions improves students' mindful use of GenAI in coursework, enhancing comfort and skill awareness without overreliance.", "motivation": "To explore the impact of guided scaffolding on students' learning and perceptions of GenAI in computer science education, addressing concerns about overreliance and lack of research.", "method": "Mixed-methods study integrating AI-Lab modules into courses, analyzing pre- and post-survey responses (n=831) and focus group discussions over three semesters.", "result": "Stable GenAI usage frequency but significant improvements in comfort, openness, and mindful debugging. Students reported heightened awareness of skill development.", "conclusion": "Scaffolded interventions help students benefit from GenAI responsibly, preserving essential competencies. Recommendations for educators and future research are provided."}}
{"id": "2505.00497", "pdf": "https://arxiv.org/pdf/2505.00497", "abs": "https://arxiv.org/abs/2505.00497", "authors": ["Antoni Bigata", "Rodrigo Mira", "Stella Bounareli", "Micha\u0142 Stypu\u0142kowski", "Konstantinos Vougioukas", "Stavros Petridis", "Maja Pantic"], "title": "KeySync: A Robust Approach for Leakage-free Lip Synchronization in High Resolution", "categories": ["cs.CV"], "comment": null, "summary": "Lip synchronization, known as the task of aligning lip movements in an\nexisting video with new input audio, is typically framed as a simpler variant\nof audio-driven facial animation. However, as well as suffering from the usual\nissues in talking head generation (e.g., temporal consistency), lip\nsynchronization presents significant new challenges such as expression leakage\nfrom the input video and facial occlusions, which can severely impact\nreal-world applications like automated dubbing, but are often neglected in\nexisting works. To address these shortcomings, we present KeySync, a two-stage\nframework that succeeds in solving the issue of temporal consistency, while\nalso incorporating solutions for leakage and occlusions using a carefully\ndesigned masking strategy. We show that KeySync achieves state-of-the-art\nresults in lip reconstruction and cross-synchronization, improving visual\nquality and reducing expression leakage according to LipLeak, our novel leakage\nmetric. Furthermore, we demonstrate the effectiveness of our new masking\napproach in handling occlusions and validate our architectural choices through\nseveral ablation studies. Code and model weights can be found at\nhttps://antonibigata.github.io/KeySync.", "AI": {"tldr": "KeySync is a two-stage framework addressing lip synchronization challenges like temporal consistency, expression leakage, and occlusions, achieving state-of-the-art results.", "motivation": "Existing lip synchronization methods neglect issues like expression leakage and occlusions, impacting real-world applications like automated dubbing.", "method": "KeySync uses a two-stage framework with a masking strategy to handle leakage and occlusions.", "result": "KeySync improves visual quality, reduces expression leakage, and handles occlusions effectively, validated by ablation studies.", "conclusion": "KeySync outperforms existing methods in lip synchronization, offering practical solutions for real-world applications."}}
{"id": "2505.00337", "pdf": "https://arxiv.org/pdf/2505.00337", "abs": "https://arxiv.org/abs/2505.00337", "authors": ["Xuyang Guo", "Jiayan Huo", "Zhenmei Shi", "Zhao Song", "Jiahao Zhang", "Jiale Zhao"], "title": "T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Text-to-video generative models have made significant strides in recent\nyears, producing high-quality videos that excel in both aesthetic appeal and\naccurate instruction following, and have become central to digital art creation\nand user engagement online. Yet, despite these advancements, their ability to\nrespect fundamental physical laws remains largely untested: many outputs still\nviolate basic constraints such as rigid-body collisions, energy conservation,\nand gravitational dynamics, resulting in unrealistic or even misleading\ncontent. Existing physical-evaluation benchmarks typically rely on automatic,\npixel-level metrics applied to simplistic, life-scenario prompts, and thus\noverlook both human judgment and first-principles physics. To fill this gap, we\nintroduce \\textbf{T2VPhysBench}, a first-principled benchmark that\nsystematically evaluates whether state-of-the-art text-to-video systems, both\nopen-source and commercial, obey twelve core physical laws including Newtonian\nmechanics, conservation principles, and phenomenological effects. Our benchmark\nemploys a rigorous human evaluation protocol and includes three targeted\nstudies: (1) an overall compliance assessment showing that all models score\nbelow 0.60 on average in each law category; (2) a prompt-hint ablation\nrevealing that even detailed, law-specific hints fail to remedy physics\nviolations; and (3) a counterfactual robustness test demonstrating that models\noften generate videos that explicitly break physical rules when so instructed.\nThe results expose persistent limitations in current architectures and offer\nconcrete insights for guiding future research toward truly physics-aware video\ngeneration.", "AI": {"tldr": "The paper introduces T2VPhysBench, a benchmark to evaluate text-to-video models' adherence to physical laws, revealing significant shortcomings despite their high-quality outputs.", "motivation": "Current text-to-video models produce visually appealing content but often violate basic physical laws, lacking rigorous evaluation.", "method": "The study uses T2VPhysBench to assess compliance with 12 core physical laws through human evaluation, prompt-hint ablation, and counterfactual robustness tests.", "result": "All models scored below 0.60 on average in adhering to physical laws, with detailed hints failing to improve performance and models often breaking rules when instructed.", "conclusion": "The findings highlight limitations in current architectures and provide insights for developing physics-aware video generation models."}}
{"id": "2505.00057", "pdf": "https://arxiv.org/pdf/2505.00057", "abs": "https://arxiv.org/abs/2505.00057", "authors": ["Zhu Jiawei", "Chen Wei"], "title": "A Report on the llms evaluating the high school questions", "categories": ["cs.CL"], "comment": null, "summary": "This report aims to evaluate the performance of large language models (LLMs)\nin solving high school science questions and to explore their potential\napplications in the educational field. With the rapid development of LLMs in\nthe field of natural language processing, their application in education has\nattracted widespread attention. This study selected mathematics exam questions\nfrom the college entrance examinations (2019-2023) as evaluation data and\nutilized at least eight LLM APIs to provide answers. A comprehensive assessment\nwas conducted based on metrics such as accuracy, response time, logical\nreasoning, and creativity. Through an in-depth analysis of the evaluation\nresults, this report reveals the strengths and weaknesses of LLMs in handling\nhigh school science questions and discusses their implications for educational\npractice. The findings indicate that although LLMs perform excellently in\ncertain aspects, there is still room for improvement in logical reasoning and\ncreative problem-solving. This report provides an empirical foundation for\nfurther research and application of LLMs in the educational field and offers\nsuggestions for improvement.", "AI": {"tldr": "The report evaluates LLMs' performance in solving high school science questions, using college entrance exam data (2019-2023) and assessing accuracy, response time, reasoning, and creativity. Findings highlight strengths but note gaps in reasoning and creativity.", "motivation": "To explore LLMs' potential in education and assess their capabilities in handling high school science questions.", "method": "Used college entrance exam questions (2019-2023) and tested with at least eight LLM APIs, evaluating accuracy, response time, logical reasoning, and creativity.", "result": "LLMs excel in some areas but need improvement in logical reasoning and creative problem-solving.", "conclusion": "The study provides empirical insights for LLM applications in education and suggests areas for enhancement."}}
{"id": "2505.00114", "pdf": "https://arxiv.org/pdf/2505.00114", "abs": "https://arxiv.org/abs/2505.00114", "authors": ["Silvana Yakhni", "Ali Chehab"], "title": "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of Lebanese", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper examines the effectiveness of Large Language Models (LLMs) in\ntranslating the low-resource Lebanese dialect, focusing on the impact of\nculturally authentic data versus larger translated datasets. We compare three\nfine-tuning approaches: Basic, contrastive, and grammar-hint tuning, using\nopen-source Aya23 models. Experiments reveal that models fine-tuned on a\nsmaller but culturally aware Lebanese dataset (LW) consistently outperform\nthose trained on larger, non-native data. The best results were achieved\nthrough contrastive fine-tuning paired with contrastive prompting, which\nindicates the benefits of exposing translation models to bad examples. In\naddition, to ensure authentic evaluation, we introduce LebEval, a new benchmark\nderived from native Lebanese content, and compare it to the existing FLoRes\nbenchmark. Our findings challenge the \"More Data is Better\" paradigm and\nemphasize the crucial role of cultural authenticity in dialectal translation.\nWe made our datasets and code available on Github.", "AI": {"tldr": "LLMs fine-tuned on culturally authentic Lebanese data outperform those using larger, non-native datasets. Contrastive tuning with bad examples yields the best results. A new benchmark, LebEval, validates cultural authenticity's importance.", "motivation": "To challenge the 'More Data is Better' paradigm and highlight the role of cultural authenticity in translating low-resource dialects like Lebanese.", "method": "Three fine-tuning approaches (Basic, contrastive, grammar-hint) on Aya23 models, comparing culturally aware Lebanese data (LW) vs. larger non-native datasets. Introduced LebEval benchmark.", "result": "Models trained on smaller, culturally authentic data outperformed larger datasets. Contrastive tuning with contrastive prompting was most effective.", "conclusion": "Cultural authenticity is crucial for dialectal translation, and contrastive tuning with authentic data yields superior results. Datasets and code are publicly available."}}
{"id": "2505.00502", "pdf": "https://arxiv.org/pdf/2505.00502", "abs": "https://arxiv.org/abs/2505.00502", "authors": ["Suho Ryu", "Kihyun Kim", "Eugene Baek", "Dongsoo Shin", "Joonseok Lee"], "title": "Towards Scalable Human-aligned Benchmark for Text-guided Image Editing", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025 (highlight)", "summary": "A variety of text-guided image editing models have been proposed recently.\nHowever, there is no widely-accepted standard evaluation method mainly due to\nthe subjective nature of the task, letting researchers rely on manual user\nstudy. To address this, we introduce a novel Human-Aligned benchmark for\nText-guided Image Editing (HATIE). Providing a large-scale benchmark set\ncovering a wide range of editing tasks, it allows reliable evaluation, not\nlimited to specific easy-to-evaluate cases. Also, HATIE provides a\nfully-automated and omnidirectional evaluation pipeline. Particularly, we\ncombine multiple scores measuring various aspects of editing so as to align\nwith human perception. We empirically verify that the evaluation of HATIE is\nindeed human-aligned in various aspects, and provide benchmark results on\nseveral state-of-the-art models to provide deeper insights on their\nperformance.", "AI": {"tldr": "The paper introduces HATIE, a Human-Aligned benchmark for Text-guided Image Editing, addressing the lack of standardized evaluation methods by providing a large-scale, automated, and comprehensive evaluation pipeline aligned with human perception.", "motivation": "The subjective nature of text-guided image editing lacks a standardized evaluation method, leading to reliance on manual user studies. HATIE aims to fill this gap.", "method": "HATIE offers a large-scale benchmark set and an automated evaluation pipeline combining multiple scores to align with human perception.", "result": "Empirical verification shows HATIE's evaluation is human-aligned, and benchmark results provide insights into state-of-the-art models.", "conclusion": "HATIE provides a reliable, automated, and human-aligned evaluation framework for text-guided image editing, advancing research in the field."}}
{"id": "2505.00347", "pdf": "https://arxiv.org/pdf/2505.00347", "abs": "https://arxiv.org/abs/2505.00347", "authors": ["Cong Xu", "Wenbin Liang", "Mo Yu", "Anan Liu", "Ke-Yue Zhang", "Lizhuang Ma", "Jianyong Wang", "Jun Wang", "Wei Zhang"], "title": "Pushing the Limits of Low-Bit Optimizers: A Focus on EMA Dynamics", "categories": ["cs.LG", "cs.AI"], "comment": "27 pages", "summary": "The explosion in model sizes leads to continued growth in prohibitive\ntraining/fine-tuning costs, particularly for stateful optimizers which maintain\nauxiliary information of even 2x the model size to achieve optimal convergence.\nWe therefore present in this work a novel type of optimizer that carries with\nextremely lightweight state overloads, achieved through ultra-low-precision\nquantization. While previous efforts have achieved certain success with 8-bit\nor 4-bit quantization, our approach enables optimizers to operate at precision\nas low as 3 bits, or even 2 bits per state element. This is accomplished by\nidentifying and addressing two critical challenges: the signal swamping problem\nin unsigned quantization that results in unchanged state dynamics, and the\nrapidly increased gradient variance in signed quantization that leads to\nincorrect descent directions. The theoretical analysis suggests a tailored\nlogarithmic quantization for the former and a precision-specific momentum value\nfor the latter. Consequently, the proposed SOLO achieves substantial memory\nsavings (approximately 45 GB when training a 7B model) with minimal accuracy\nloss. We hope that SOLO can contribute to overcoming the bottleneck in\ncomputational resources, thereby promoting greater accessibility in fundamental\nresearch.", "AI": {"tldr": "SOLO introduces a lightweight optimizer with ultra-low-precision quantization (3-2 bits), solving signal swamping and gradient variance issues, saving memory (45GB for 7B model) with minimal accuracy loss.", "motivation": "Address prohibitive training costs from large model sizes and stateful optimizers' auxiliary information overhead.", "method": "Uses ultra-low-precision quantization (3-2 bits), tackles signal swamping with logarithmic quantization and gradient variance with precision-specific momentum.", "result": "Achieves substantial memory savings (~45GB for 7B model) with minimal accuracy loss.", "conclusion": "SOLO reduces computational resource bottlenecks, enhancing accessibility in fundamental research."}}
{"id": "2505.00061", "pdf": "https://arxiv.org/pdf/2505.00061", "abs": "https://arxiv.org/abs/2505.00061", "authors": ["Sahar Yarmohammadtoosky", "Yiyun Zhou", "Victoria Yaneva", "Peter Baldwin", "Saed Rezayi", "Brian Clauser", "Polina Harikeo"], "title": "Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "This study examines vulnerabilities in transformer-based automated\nshort-answer grading systems used in medical education, with a focus on how\nthese systems can be manipulated through adversarial gaming strategies. Our\nresearch identifies three main types of gaming strategies that exploit the\nsystem's weaknesses, potentially leading to false positives. To counteract\nthese vulnerabilities, we implement several adversarial training methods\ndesigned to enhance the systems' robustness. Our results indicate that these\nmethods significantly reduce the susceptibility of grading systems to such\nmanipulations, especially when combined with ensemble techniques like majority\nvoting and ridge regression, which further improve the system's defense against\nsophisticated adversarial inputs. Additionally, employing large language models\nsuch as GPT-4 with varied prompting techniques has shown promise in recognizing\nand scoring gaming strategies effectively. The findings underscore the\nimportance of continuous improvements in AI-driven educational tools to ensure\ntheir reliability and fairness in high-stakes settings.", "AI": {"tldr": "The paper explores vulnerabilities in transformer-based grading systems for medical education, identifies adversarial gaming strategies, and proposes adversarial training and ensemble methods to improve robustness.", "motivation": "To address the susceptibility of automated grading systems to manipulation, ensuring reliability and fairness in high-stakes educational settings.", "method": "Identifies gaming strategies, implements adversarial training, and tests ensemble techniques (majority voting, ridge regression) and large language models (GPT-4) with varied prompts.", "result": "Adversarial training and ensemble methods significantly reduce system vulnerabilities, with GPT-4 showing promise in detecting gaming strategies.", "conclusion": "Continuous improvement of AI-driven educational tools is crucial for maintaining reliability and fairness against adversarial manipulations."}}
{"id": "2505.00127", "pdf": "https://arxiv.org/pdf/2505.00127", "abs": "https://arxiv.org/abs/2505.00127", "authors": ["Jinyan Su", "Jennifer Healey", "Preslav Nakov", "Claire Cardie"], "title": "Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly optimized for long reasoning,\nunder the assumption that more reasoning leads to better performance. However,\nemerging evidence suggests that longer responses can sometimes degrade accuracy\nrather than improve it. In this paper, we conduct a systematic empirical study\nof the relationship between reasoning length and answer correctness. We find\nthat LLMs tend to overthink simple problems, generating unnecessarily long\noutputs, and underthink harder ones, failing to extend their reasoning when it\nis most needed. This indicates that models might misjudge problem difficulty\nand fail to calibrate their response length appropriately. Furthermore, we\ninvestigate the effects of length reduction with a preference optimization\nalgorithm when simply preferring the shorter responses regardless of answer\ncorrectness. Experiments show that the generation length can be significantly\nreduced while maintaining acceptable accuracy. Our findings highlight\ngeneration length as a meaningful signal for reasoning behavior and motivate\nfurther exploration into LLMs' self-awareness in reasoning length adaptation.", "AI": {"tldr": "Longer reasoning in LLMs doesn't always improve accuracy; models overthink simple problems and underthink hard ones. Reducing response length can maintain accuracy.", "motivation": "To study the relationship between reasoning length and answer correctness in LLMs, as longer responses sometimes degrade accuracy.", "method": "Conducted empirical studies on reasoning length and correctness, and tested length reduction via preference optimization.", "result": "LLMs misjudge problem difficulty, leading to inappropriate response lengths. Length reduction maintains accuracy.", "conclusion": "Generation length is a key signal for reasoning behavior; LLMs need better self-awareness in adapting reasoning length."}}
{"id": "2505.00507", "pdf": "https://arxiv.org/pdf/2505.00507", "abs": "https://arxiv.org/abs/2505.00507", "authors": ["Esteban Rivera", "Surya Prabhakaran", "Markus Lienkamp"], "title": "HeAL3D: Heuristical-enhanced Active Learning for 3D Object Detection", "categories": ["cs.CV"], "comment": "Accepted in CVPR2025", "summary": "Active Learning has proved to be a relevant approach to perform sample\nselection for training models for Autonomous Driving. Particularly, previous\nworks on active learning for 3D object detection have shown that selection of\nsamples in uncontrolled scenarios is challenging. Furthermore, current\napproaches focus exclusively on the theoretical aspects of the sample selection\nproblem but neglect the practical insights that can be obtained from the\nextensive literature and application of 3D detection models. In this paper, we\nintroduce HeAL (Heuristical-enhanced Active Learning for 3D Object Detection)\nwhich integrates those heuristical features together with Localization and\nClassification to deliver the most contributing samples to the model's\ntraining. In contrast to previous works, our approach integrates heuristical\nfeatures such as object distance and point-quantity to estimate the\nuncertainty, which enhance the usefulness of selected samples to train\ndetection models. Our quantitative evaluation on KITTI shows that HeAL presents\ncompetitive mAP with respect to the State-of-the-Art, and achieves the same mAP\nas the full-supervised baseline with only 24% of the samples.", "AI": {"tldr": "HeAL integrates heuristical features with active learning for 3D object detection, achieving competitive results with fewer samples.", "motivation": "Current active learning methods for 3D object detection neglect practical insights from literature and applications, making sample selection in uncontrolled scenarios challenging.", "method": "HeAL combines heuristical features (e.g., object distance, point-quantity) with localization and classification to select impactful training samples.", "result": "HeAL matches the mAP of full-supervised baselines using only 24% of samples, outperforming state-of-the-art methods on KITTI.", "conclusion": "HeAL effectively enhances sample selection for 3D object detection, bridging the gap between theory and practical application."}}
{"id": "2505.00348", "pdf": "https://arxiv.org/pdf/2505.00348", "abs": "https://arxiv.org/abs/2505.00348", "authors": ["Ehtisham Asghar", "Martin Hill", "Ibrahim Sengor", "Conor Lynch", "Phan Quang An"], "title": "Validation of a 24-hour-ahead Prediction model for a Residential Electrical Load under diverse climate", "categories": ["cs.LG"], "comment": null, "summary": "Accurate household electrical energy demand prediction is essential for\neffectively managing sustainable Energy Communities. Integrated with the Energy\nManagement System, these communities aim to optimise operational costs.\nHowever, most existing forecasting models are region-specific and depend on\nlarge datasets, limiting their applicability across different climates and\ngeographical areas. These models often lack flexibility and may not perform\nwell in regions with limited historical data, leading to inaccurate\npredictions. This paper proposes a global model for 24-hour-ahead hourly\nelectrical energy demand prediction that is designed to perform effectively\nacross diverse climate conditions and datasets. The model's efficiency is\ndemonstrated using data from two distinct regions: Ireland, with a maritime\nclimate and Vietnam, with a tropical climate. Remarkably, the model achieves\nhigh accuracy even with a limited dataset spanning only nine months. Its\nrobustness is further validated across different seasons in Ireland (summer and\nwinter) and Vietnam (dry and wet). The proposed model is evaluated against\nstate-of-the-art machine learning and deep learning methods. Simulation results\nindicate that the model consistently outperforms benchmark models, showcasing\nits capability to provide reliable forecasts globally, regardless of varying\nclimatic conditions and data availability. This research underscores the\nmodel's potential to enhance the efficiency and sustainability of Energy\nCommunities worldwide. The proposed model achieves a Mean Absolute Percentage\nError of 8.0% and 4.0% on the full Irish and Vietnamese datasets.", "AI": {"tldr": "A global model for 24-hour-ahead hourly electrical energy demand prediction is proposed, effective across diverse climates and limited datasets, outperforming benchmarks.", "motivation": "Existing models are region-specific and rely on large datasets, limiting flexibility and accuracy in diverse climates or with limited data.", "method": "A global model is developed and tested using data from Ireland (maritime climate) and Vietnam (tropical climate), evaluated against state-of-the-art methods.", "result": "The model achieves high accuracy (MAPE of 8.0% and 4.0% for Ireland and Vietnam) even with limited data (nine months) and performs robustly across seasons.", "conclusion": "The model enhances efficiency and sustainability of Energy Communities globally, regardless of climatic conditions or data availability."}}
{"id": "2505.00063", "pdf": "https://arxiv.org/pdf/2505.00063", "abs": "https://arxiv.org/abs/2505.00063", "authors": ["Siqi Li", "Yufan Shen", "Xiangnan Chen", "Jiayi Chen", "Hengwei Ju", "Haodong Duan", "Song Mao", "Hongbin Zhou", "Bo Zhang", "Pinlong Cai", "Licheng Wen", "Botian Shi", "Yong Liu", "Xinyu Cai", "Yu Qiao"], "title": "GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "The rapid advancement of multimodal large language models (MLLMs) has\nprofoundly impacted the document domain, creating a wide array of application\nscenarios. This progress highlights the need for a comprehensive benchmark to\nevaluate these models' capabilities across various document-specific tasks.\nHowever, existing benchmarks often fail to locate specific model weaknesses or\nguide systematic improvements. To bridge this gap, we introduce a General\nDocument Intelligence Benchmark (GDI-Bench), featuring 1.9k images across 9 key\nscenarios and 19 document-specific tasks. By decoupling visual complexity and\nreasoning complexity, the GDI-Bench structures graded tasks that allow\nperformance assessment by difficulty, aiding in model weakness identification\nand optimization guidance. We evaluate the GDI-Bench on various open-source and\nclosed-source models, conducting decoupled analyses in the visual and reasoning\ndomains. For instance, the GPT-4o model excels in reasoning tasks but exhibits\nlimitations in visual capabilities. To address the diverse tasks and domains in\nthe GDI-Bench, we propose a GDI Model that mitigates the issue of catastrophic\nforgetting during the supervised fine-tuning (SFT) process through a\nintelligence-preserving training strategy. Our model achieves state-of-the-art\nperformance on previous benchmarks and the GDI-Bench. Both our benchmark and\nmodel will be open source.", "AI": {"tldr": "GDI-Bench is introduced as a comprehensive benchmark for evaluating multimodal large language models (MLLMs) across 19 document-specific tasks, aiding in identifying weaknesses and guiding improvements. A GDI Model is proposed to address catastrophic forgetting, achieving top performance.", "motivation": "Existing benchmarks lack the ability to pinpoint model weaknesses or guide systematic improvements in document-specific tasks for MLLMs.", "method": "GDI-Bench features 1.9k images across 9 scenarios and 19 tasks, decoupling visual and reasoning complexities. A GDI Model is developed with an intelligence-preserving training strategy to avoid catastrophic forgetting during fine-tuning.", "result": "GDI-Bench evaluates models like GPT-4o, revealing strengths in reasoning but weaknesses in visual tasks. The GDI Model achieves state-of-the-art performance.", "conclusion": "GDI-Bench and the GDI Model provide valuable tools for assessing and improving MLLMs in document intelligence, with both being open-sourced for broader use."}}
{"id": "2505.00186", "pdf": "https://arxiv.org/pdf/2505.00186", "abs": "https://arxiv.org/abs/2505.00186", "authors": ["Rafael C. Pinto", "Anderson R. Tavares"], "title": "Neuroevolution of Self-Attention Over Proto-Objects", "categories": ["cs.NE", "cs.AI", "cs.CV"], "comment": "9 pages, 16 figures, GECCO", "summary": "Proto-objects - image regions that share common visual properties - offer a\npromising alternative to traditional attention mechanisms based on\nrectangular-shaped image patches in neural networks. Although previous work\ndemonstrated that evolving a patch-based hard-attention module alongside a\ncontroller network could achieve state-of-the-art performance in visual\nreinforcement learning tasks, our approach leverages image segmentation to work\nwith higher-level features. By operating on proto-objects rather than fixed\npatches, we significantly reduce the representational complexity: each image\ndecomposes into fewer proto-objects than regular patches, and each proto-object\ncan be efficiently encoded as a compact feature vector. This enables a\nsubstantially smaller self-attention module that processes richer semantic\ninformation. Our experiments demonstrate that this proto-object-based approach\nmatches or exceeds the state-of-the-art performance of patch-based\nimplementations with 62% less parameters and 2.6 times less training time.", "AI": {"tldr": "Proto-objects outperform patch-based attention in neural networks by reducing complexity and improving efficiency.", "motivation": "Traditional patch-based attention mechanisms are less efficient and more complex. Proto-objects offer a higher-level, semantic alternative.", "method": "Leverages image segmentation to work with proto-objects, encoding them as compact feature vectors for a smaller self-attention module.", "result": "Matches or exceeds state-of-the-art performance with 62% fewer parameters and 2.6x faster training.", "conclusion": "Proto-objects are a superior alternative to patch-based attention, offering efficiency and performance gains."}}
{"id": "2505.00511", "pdf": "https://arxiv.org/pdf/2505.00511", "abs": "https://arxiv.org/abs/2505.00511", "authors": ["Esteban Rivera", "Loic Stratil", "Markus Lienkamp"], "title": "Inconsistency-based Active Learning for LiDAR Object Detection", "categories": ["cs.CV"], "comment": "Accepted in IV2025", "summary": "Deep learning models for object detection in autonomous driving have recently\nachieved impressive performance gains and are already being deployed in\nvehicles worldwide. However, current models require increasingly large datasets\nfor training. Acquiring and labeling such data is costly, necessitating the\ndevelopment of new strategies to optimize this process. Active learning is a\npromising approach that has been extensively researched in the image domain. In\nour work, we extend this concept to the LiDAR domain by developing several\ninconsistency-based sample selection strategies and evaluate their\neffectiveness in various settings. Our results show that using a naive\ninconsistency approach based on the number of detected boxes, we achieve the\nsame mAP as the random sampling strategy with 50% of the labeled data.", "AI": {"tldr": "Active learning in LiDAR domain improves object detection efficiency, matching random sampling performance with half the labeled data.", "motivation": "High costs of acquiring and labeling large datasets for deep learning models in autonomous driving necessitate efficient training strategies.", "method": "Developed inconsistency-based sample selection strategies for active learning in the LiDAR domain.", "result": "Naive inconsistency approach matched random sampling mAP with 50% of labeled data.", "conclusion": "Active learning in LiDAR can significantly reduce labeling costs while maintaining performance."}}
{"id": "2505.00350", "pdf": "https://arxiv.org/pdf/2505.00350", "abs": "https://arxiv.org/abs/2505.00350", "authors": ["Mohammad Zbeeb", "Mariam Salman", "Mohammad Bazzi", "Ammar Mohanna"], "title": "Optimizing Deep Neural Networks using Safety-Guided Self Compression", "categories": ["cs.LG", "cs.AI"], "comment": "A Preprint", "summary": "The deployment of deep neural networks on resource-constrained devices\nnecessitates effective model com- pression strategies that judiciously balance\nthe reduction of model size with the preservation of performance. This study\nintroduces a novel safety-driven quantization framework that leverages\npreservation sets to systematically prune and quantize neural network weights,\nthereby optimizing model complexity without compromising accuracy. The proposed\nmethodology is rigorously evaluated on both a convolutional neural network\n(CNN) and an attention-based language model, demonstrating its applicability\nacross diverse architectural paradigms. Experimental results reveal that our\nframework achieves up to a 2.5% enhancement in test accuracy relative to the\noriginal unquantized models while maintaining 60% of the initial model size. In\ncomparison to conventional quantization techniques, our approach not only\naugments generalization by eliminating parameter noise and retaining essential\nweights but also reduces variance, thereby ensuring the retention of critical\nmodel features. These findings underscore the efficacy of safety-driven\nquantization as a robust and reliable strategy for the efficient optimization\nof deep learn- ing models. The implementation and comprehensive experimental\nevaluations of our framework are publicly accessible at GitHub.", "AI": {"tldr": "A safety-driven quantization framework is introduced to compress deep neural networks while preserving performance, achieving better accuracy and reduced model size compared to conventional methods.", "motivation": "The need for efficient model compression on resource-constrained devices without sacrificing performance.", "method": "A novel safety-driven quantization framework using preservation sets to prune and quantize weights, tested on CNN and attention-based models.", "result": "Up to 2.5% accuracy improvement and 60% model size reduction, outperforming traditional quantization techniques.", "conclusion": "Safety-driven quantization is effective for optimizing deep learning models, balancing size and performance."}}
{"id": "2505.00065", "pdf": "https://arxiv.org/pdf/2505.00065", "abs": "https://arxiv.org/abs/2505.00065", "authors": ["Ivan Vankov", "Matyo Ivanov", "Adriana Correia", "Victor Botev"], "title": "ConSens: Assessing context grounding in open-book question answering", "categories": ["cs.CL", "cs.LG"], "comment": "9 pages, 3 figures, 3 tables", "summary": "Large Language Models (LLMs) have demonstrated considerable success in\nopen-book question answering (QA), where the task requires generating answers\ngrounded in a provided external context. A critical challenge in open-book QA\nis to ensure that model responses are based on the provided context rather than\nits parametric knowledge, which can be outdated, incomplete, or incorrect.\nExisting evaluation methods, primarily based on the LLM-as-a-judge approach,\nface significant limitations, including biases, scalability issues, and\ndependence on costly external systems. To address these challenges, we propose\na novel metric that contrasts the perplexity of the model response under two\nconditions: when the context is provided and when it is not. The resulting\nscore quantifies the extent to which the model's answer relies on the provided\ncontext. The validity of this metric is demonstrated through a series of\nexperiments that show its effectiveness in identifying whether a given answer\nis grounded in the provided context. Unlike existing approaches, this metric is\ncomputationally efficient, interpretable, and adaptable to various use cases,\noffering a scalable and practical solution to assess context utilization in\nopen-book QA systems.", "AI": {"tldr": "A novel metric is proposed to evaluate context reliance in open-book QA by comparing perplexity of responses with and without context, offering a scalable and interpretable solution.", "motivation": "Existing evaluation methods for open-book QA are biased, unscalable, and costly, necessitating a better approach to assess context utilization.", "method": "The metric contrasts perplexity of model responses under two conditions: with and without provided context, quantifying context reliance.", "result": "Experiments validate the metric's effectiveness in identifying context-grounded answers, showing computational efficiency and adaptability.", "conclusion": "The proposed metric is a scalable, interpretable, and practical solution for evaluating context utilization in open-book QA systems."}}
{"id": "2505.00222", "pdf": "https://arxiv.org/pdf/2505.00222", "abs": "https://arxiv.org/abs/2505.00222", "authors": ["Peter Yichen Chen", "Pingchuan Ma", "Niklas Hagemann", "John Romanishin", "Wei Wang", "Daniela Rus", "Wojciech Matusik"], "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders", "categories": ["cs.RO", "cs.AI", "cs.GR", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.", "AI": {"tldr": "An AI-enhanced automated framework optimizes underwater glider shapes and control signals, improving energy efficiency over manual designs.", "motivation": "Overcome limitations in traditional glider design tools by automating shape and control optimization.", "method": "Uses reduced-order geometry representation and a neural-network-based fluid surrogate model for co-optimization.", "result": "Computationally designed gliders outperform manual designs in energy efficiency, validated by experiments.", "conclusion": "The framework enables efficient glider development, benefiting ocean exploration and monitoring."}}
{"id": "2505.00512", "pdf": "https://arxiv.org/pdf/2505.00512", "abs": "https://arxiv.org/abs/2505.00512", "authors": ["Nguyen Hoang Khoi Tran", "Julie Stephany Berrio", "Mao Shan", "Zhenxing Ming", "Stewart Worrall"], "title": "InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Intersections are geometric and functional key points in every road network.\nThey offer strong landmarks to correct GNSS dropouts and anchor new sensor data\nin up-to-date maps. Despite that importance, intersection detectors either\nignore the rich semantic information already computed onboard or depend on\nscarce, hand-labeled intersection datasets. To close that gap, this paper\npresents a LiDAR-based method for intersection detection that (i) fuses\nsemantic road segmentation with vehicle localization to detect intersection\ncandidates in a bird's eye view (BEV) representation and (ii) refines those\ncandidates by analyzing branch topology with a least squares formulation. To\nevaluate our method, we introduce an automated benchmarking pipeline that pairs\ndetections with OpenStreetMap (OSM) intersection nodes using precise GNSS/INS\nground-truth poses. Tested on eight SemanticKITTI sequences, the approach\nachieves a mean localization error of 1.9 m, 89% precision, and 77% recall at a\n5 m tolerance, outperforming the latest learning-based baseline. Moreover, the\nmethod is robust to segmentation errors higher than those of the benchmark\nmodel, demonstrating its applicability in the real world.", "AI": {"tldr": "A LiDAR-based method for intersection detection fuses semantic road segmentation and vehicle localization, achieving high precision and recall with robustness to segmentation errors.", "motivation": "Intersections are key landmarks for correcting GNSS dropouts and updating maps, but existing detectors either ignore onboard semantic data or rely on scarce labeled datasets.", "method": "The approach combines semantic road segmentation with vehicle localization in a BEV representation and refines candidates using branch topology analysis with least squares.", "result": "Achieves 1.9 m mean localization error, 89% precision, and 77% recall at 5 m tolerance, outperforming learning-based baselines.", "conclusion": "The method is robust to segmentation errors and applicable in real-world scenarios, offering a reliable solution for intersection detection."}}
{"id": "2505.00358", "pdf": "https://arxiv.org/pdf/2505.00358", "abs": "https://arxiv.org/abs/2505.00358", "authors": ["Albert Ge", "Tzu-Heng Huang", "John Cooper", "Avi Trost", "Ziyi Chu", "Satya Sai Srinath Namburi GNVV", "Ziyang Cai", "Kendall Park", "Nicholas Roberts", "Frederic Sala"], "title": "R&B: Domain Regrouping and Data Mixture Balancing for Efficient Foundation Model Training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Data mixing strategies have successfully reduced the costs involved in\ntraining language models. While promising, such methods suffer from two flaws.\nFirst, they rely on predetermined data domains (e.g., data sources, task\ntypes), which may fail to capture critical semantic nuances, leaving\nperformance on the table. Second, these methods scale with the number of\ndomains in a computationally prohibitive way. We address these challenges via\nR&B, a framework that re-partitions training data based on semantic similarity\n(Regroup) to create finer-grained domains, and efficiently optimizes the data\ncomposition (Balance) by leveraging a Gram matrix induced by domain gradients\nobtained throughout training. Unlike prior works, it removes the need for\nadditional compute to obtain evaluation information such as losses or\ngradients. We analyze this technique under standard regularity conditions and\nprovide theoretical insights that justify R&B's effectiveness compared to\nnon-adaptive mixing approaches. Empirically, we demonstrate the effectiveness\nof R&B on five diverse datasets ranging from natural language to reasoning and\nmultimodal tasks. With as little as 0.01% additional compute overhead, R&B\nmatches or exceeds the performance of state-of-the-art data mixing strategies.", "AI": {"tldr": "R&B is a framework that improves data mixing for training language models by regrouping data based on semantic similarity and optimizing composition efficiently, outperforming existing methods with minimal overhead.", "motivation": "Existing data mixing strategies are limited by predetermined domains and high computational costs, leaving performance gains untapped.", "method": "R&B uses semantic similarity to regroup data and optimizes composition via a Gram matrix from domain gradients, avoiding extra compute for evaluations.", "result": "R&B matches or exceeds state-of-the-art performance on diverse datasets with only 0.01% additional compute overhead.", "conclusion": "R&B effectively addresses flaws in current data mixing methods, offering a scalable and efficient solution for training language models."}}
{"id": "2505.00147", "pdf": "https://arxiv.org/pdf/2505.00147", "abs": "https://arxiv.org/abs/2505.00147", "authors": ["Yinghui He", "Abhishek Panigrahi", "Yong Lin", "Sanjeev Arora"], "title": "AdaptMI: Adaptive Skill-based In-context Math Instruction for Small Language Models", "categories": ["cs.CL"], "comment": null, "summary": "In-context learning (ICL) allows a language model to improve its\nproblem-solving capability when provided with suitable information in context.\nSince the choice of in-context information can be determined based on the\nproblem itself, in-context learning is analogous to human learning from\nteachers in a classroom. Recent works (Didolkar et al., 2024a; 2024b) show that\nICL performance can be improved by leveraging a frontier large language model's\n(LLM) ability to predict required skills to solve a problem, popularly referred\nto as an LLM's metacognition, and using the recommended skills to construct\nnecessary in-context examples. While this skill-based strategy boosts ICL\nperformance in larger models, its gains on small language models (SLMs) have\nbeen minimal, highlighting a performance gap in ICL capabilities. We\ninvestigate this gap and show that skill-based prompting can hurt SLM\nperformance on easy questions by introducing unnecessary information, akin to\ncognitive overload. To address this, we introduce AdaptMI, an adaptive approach\nto selecting skill-based in-context Math Instructions for SLMs. Inspired by\ncognitive load theory from human pedagogy, our method only introduces\nskill-based examples when the model performs poorly. We further propose\nAdaptMI+, which adds examples targeted to the specific skills missing from the\nmodel's responses. On 5-shot evaluations across popular math benchmarks and\nfive SLMs (1B--7B; Qwen, Llama), AdaptMI+ improves accuracy by up to 6% over\nnaive skill-based strategies.", "AI": {"tldr": "AdaptMI+ improves small language models' (SLMs) performance in in-context learning (ICL) by adaptively selecting skill-based examples, avoiding cognitive overload, and boosting accuracy by up to 6%.", "motivation": "The performance gap between large (LLMs) and small language models (SLMs) in skill-based ICL, where SLMs suffer from cognitive overload with unnecessary information.", "method": "Introduces AdaptMI and AdaptMI+, adaptive approaches inspired by cognitive load theory, to selectively use skill-based examples based on model performance and missing skills.", "result": "AdaptMI+ improves accuracy by up to 6% over naive skill-based strategies in 5-shot evaluations across math benchmarks and five SLMs.", "conclusion": "Adaptive skill-based prompting, like AdaptMI+, effectively addresses SLMs' limitations in ICL, bridging the performance gap with LLMs."}}
{"id": "2505.00240", "pdf": "https://arxiv.org/pdf/2505.00240", "abs": "https://arxiv.org/abs/2505.00240", "authors": ["Yazan Otoum", "Arghavan Asad", "Amiya Nayak"], "title": "LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG"], "comment": "Preprint version; submitted for academic peer review", "summary": "The increasing complexity and scale of the Internet of Things (IoT) have made\nsecurity a critical concern. This paper presents a novel Large Language Model\n(LLM)-based framework for comprehensive threat detection and prevention in IoT\nenvironments. The system integrates lightweight LLMs fine-tuned on IoT-specific\ndatasets (IoT-23, TON_IoT) for real-time anomaly detection and automated,\ncontext-aware mitigation strategies optimized for resource-constrained devices.\nA modular Docker-based deployment enables scalable and reproducible evaluation\nacross diverse network conditions. Experimental results in simulated IoT\nenvironments demonstrate significant improvements in detection accuracy,\nresponse latency, and resource efficiency over traditional security methods.\nThe proposed framework highlights the potential of LLM-driven, autonomous\nsecurity solutions for future IoT ecosystems.", "AI": {"tldr": "A novel LLM-based framework for IoT security improves threat detection and prevention, outperforming traditional methods in accuracy, latency, and efficiency.", "motivation": "The growing complexity and scale of IoT systems necessitate advanced security solutions to address vulnerabilities and threats effectively.", "method": "The framework uses lightweight LLMs fine-tuned on IoT datasets (IoT-23, TON_IoT) for real-time anomaly detection and mitigation, deployed modularly via Docker for scalability.", "result": "Experiments show superior performance in detection accuracy, response latency, and resource efficiency compared to conventional security approaches.", "conclusion": "The framework demonstrates the promise of LLM-driven autonomous security for future IoT ecosystems."}}
{"id": "2505.00534", "pdf": "https://arxiv.org/pdf/2505.00534", "abs": "https://arxiv.org/abs/2505.00534", "authors": ["Muhammad Imran Zaman", "Usama Ijaz Bajwa", "Gulshan Saleem", "Rana Hammad Raza"], "title": "A Robust Deep Networks based Multi-Object MultiCamera Tracking System for City Scale Traffic", "categories": ["cs.CV"], "comment": null, "summary": "Vision sensors are becoming more important in Intelligent Transportation\nSystems (ITS) for traffic monitoring, management, and optimization as the\nnumber of network cameras continues to rise. However, manual object tracking\nand matching across multiple non-overlapping cameras pose significant\nchallenges in city-scale urban traffic scenarios. These challenges include\nhandling diverse vehicle attributes, occlusions, illumination variations,\nshadows, and varying video resolutions. To address these issues, we propose an\nefficient and cost-effective deep learning-based framework for Multi-Object\nMulti-Camera Tracking (MO-MCT). The proposed framework utilizes Mask R-CNN for\nobject detection and employs Non-Maximum Suppression (NMS) to select target\nobjects from overlapping detections. Transfer learning is employed for\nre-identification, enabling the association and generation of vehicle tracklets\nacross multiple cameras. Moreover, we leverage appropriate loss functions and\ndistance measures to handle occlusion, illumination, and shadow challenges. The\nfinal solution identification module performs feature extraction using\nResNet-152 coupled with Deep SORT based vehicle tracking. The proposed\nframework is evaluated on the 5th AI City Challenge dataset (Track 3),\ncomprising 46 camera feeds. Among these 46 camera streams, 40 are used for\nmodel training and validation, while the remaining six are utilized for model\ntesting. The proposed framework achieves competitive performance with an IDF1\nscore of 0.8289, and precision and recall scores of 0.9026 and 0.8527\nrespectively, demonstrating its effectiveness in robust and accurate vehicle\ntracking.", "AI": {"tldr": "A deep learning-based framework for Multi-Object Multi-Camera Tracking (MO-MCT) is proposed to address challenges in urban traffic scenarios, achieving competitive performance on the AI City Challenge dataset.", "motivation": "The rise of network cameras in ITS necessitates efficient solutions for object tracking across non-overlapping cameras, overcoming issues like occlusions, illumination variations, and diverse vehicle attributes.", "method": "The framework uses Mask R-CNN for detection, NMS for target selection, transfer learning for re-identification, and ResNet-152 with Deep SORT for feature extraction and tracking.", "result": "Achieves an IDF1 score of 0.8289, precision of 0.9026, and recall of 0.8527 on the AI City Challenge dataset.", "conclusion": "The proposed framework is effective for robust and accurate vehicle tracking in complex urban environments."}}
{"id": "2505.00359", "pdf": "https://arxiv.org/pdf/2505.00359", "abs": "https://arxiv.org/abs/2505.00359", "authors": ["Qifen Zeng", "Haomin Bao", "Yuanzhuo Hu", "Zirui Zhang", "Yuheng Zheng", "Luosheng Wen"], "title": "TNStream: Applying Tightest Neighbors to Micro-Clusters to Define Multi-Density Clusters in Streaming Data", "categories": ["cs.LG", "cs.AI", "cs.NE", "68T05, 68W20", "H.2.8; I.5.3"], "comment": "21 pages, 9 figures, 8 tables, under review at Expert Systems with\n  Applications (ESWA)", "summary": "In data stream clustering, systematic theory of stream clustering algorithms\nremains relatively scarce. Recently, density-based methods have gained\nattention. However, existing algorithms struggle to simultaneously handle\narbitrarily shaped, multi-density, high-dimensional data while maintaining\nstrong outlier resistance. Clustering quality significantly deteriorates when\ndata density varies complexly. This paper proposes a clustering algorithm based\non the novel concept of Tightest Neighbors and introduces a data stream\nclustering theory based on the Skeleton Set. Based on these theories, this\npaper develops a new method, TNStream, a fully online algorithm. The algorithm\nadaptively determines the clustering radius based on local similarity,\nsummarizing the evolution of multi-density data streams in micro-clusters. It\nthen applies a Tightest Neighbors-based clustering algorithm to form final\nclusters. To improve efficiency in high-dimensional cases, Locality-Sensitive\nHashing (LSH) is employed to structure micro-clusters, addressing the challenge\nof storing k-nearest neighbors. TNStream is evaluated on various synthetic and\nreal-world datasets using different clustering metrics. Experimental results\ndemonstrate its effectiveness in improving clustering quality for multi-density\ndata and validate the proposed data stream clustering theory.", "AI": {"tldr": "The paper proposes TNStream, a density-based clustering algorithm for data streams, addressing challenges like multi-density, high-dimensional data, and outlier resistance. It introduces the Tightest Neighbors concept and Skeleton Set theory, achieving improved clustering quality.", "motivation": "Existing density-based clustering algorithms struggle with multi-density, high-dimensional data and outlier resistance, leading to degraded clustering quality.", "method": "TNStream uses Tightest Neighbors and Skeleton Set theory to adaptively determine clustering radius. It employs Locality-Sensitive Hashing (LSH) for high-dimensional efficiency and forms final clusters via micro-clusters.", "result": "Experiments show TNStream improves clustering quality for multi-density data and validates the proposed theory.", "conclusion": "TNStream effectively addresses challenges in data stream clustering, offering a robust solution for complex data scenarios."}}
{"id": "2505.00191", "pdf": "https://arxiv.org/pdf/2505.00191", "abs": "https://arxiv.org/abs/2505.00191", "authors": ["Yuyan Ge", "Kwan Ho Ryan Chan", "Pablo Messina", "Ren\u00e9 Vidal"], "title": "IP-CRR: Information Pursuit for Interpretable Classification of Chest Radiology Reports", "categories": ["cs.CL"], "comment": "12 pages, 4 figures", "summary": "The development of AI-based methods for analyzing radiology reports could\nlead to significant advances in medical diagnosis--from improving diagnostic\naccuracy to enhancing efficiency and reducing workload. However, the lack of\ninterpretability in these methods has hindered their adoption in clinical\nsettings. In this paper, we propose an interpretable-by-design framework for\nclassifying radiology reports. The key idea is to extract a set of most\ninformative queries from a large set of reports and use these queries and their\ncorresponding answers to predict a diagnosis. Thus, the explanation for a\nprediction is, by construction, the set of selected queries and answers. We use\nthe Information Pursuit framework to select informative queries, the Flan-T5\nmodel to determine if facts are present in the report, and a classifier to\npredict the disease. Experiments on the MIMIC-CXR dataset demonstrate the\neffectiveness of the proposed method, highlighting its potential to enhance\ntrust and usability in medical AI.", "AI": {"tldr": "An interpretable AI framework for classifying radiology reports is proposed, using informative queries and answers for predictions, validated on the MIMIC-CXR dataset.", "motivation": "The lack of interpretability in AI-based radiology analysis hinders clinical adoption; this work aims to address this gap.", "method": "Extracts informative queries from reports, uses Flan-T5 to verify facts, and a classifier for diagnosis prediction.", "result": "Effective on MIMIC-CXR dataset, enhancing trust and usability in medical AI.", "conclusion": "The interpretable-by-design framework shows promise for clinical adoption by improving transparency."}}
{"id": "2505.00268", "pdf": "https://arxiv.org/pdf/2505.00268", "abs": "https://arxiv.org/abs/2505.00268", "authors": ["Jekaterina Novikova", "Carol Anderson", "Borhane Blili-Hamelin", "Subhabrata Majumdar"], "title": "Consistency in Language Models: Current Landscape, Challenges, and Future Directions", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The hallmark of effective language use lies in consistency -- expressing\nsimilar meanings in similar contexts and avoiding contradictions. While human\ncommunication naturally demonstrates this principle, state-of-the-art language\nmodels struggle to maintain reliable consistency across different scenarios.\nThis paper examines the landscape of consistency research in AI language\nsystems, exploring both formal consistency (including logical rule adherence)\nand informal consistency (such as moral and factual coherence). We analyze\ncurrent approaches to measure aspects of consistency, identify critical\nresearch gaps in standardization of definitions, multilingual assessment, and\nmethods to improve consistency. Our findings point to an urgent need for robust\nbenchmarks to measure and interdisciplinary approaches to ensure consistency in\nthe application of language models on domain-specific tasks while preserving\nthe utility and adaptability.", "AI": {"tldr": "The paper highlights the challenge of maintaining consistency in language models, analyzing formal and informal aspects, and calls for better benchmarks and interdisciplinary methods.", "motivation": "To address the inconsistency in state-of-the-art language models and explore ways to improve their reliability in various contexts.", "method": "Analyzes current research on consistency, including formal (logical rules) and informal (moral/factual coherence) aspects, and identifies gaps in standardization and assessment.", "result": "Identifies critical gaps in consistency research, such as lack of standardized definitions, multilingual assessment, and improvement methods.", "conclusion": "Urges the development of robust benchmarks and interdisciplinary approaches to enhance consistency in language models while maintaining utility."}}
{"id": "2505.00564", "pdf": "https://arxiv.org/pdf/2505.00564", "abs": "https://arxiv.org/abs/2505.00564", "authors": ["Jorgen Cani", "Christos Diou", "Spyridon Evangelatos", "Panagiotis Radoglou-Grammatikis", "Vasileios Argyriou", "Panagiotis Sarigiannidis", "Iraklis Varlamis", "Georgios Th. Papadopoulos"], "title": "X-ray illicit object detection using hybrid CNN-transformer neural network architectures", "categories": ["cs.CV"], "comment": null, "summary": "In the field of X-ray security applications, even the smallest details can\nsignificantly impact outcomes. Objects that are heavily occluded or\nintentionally concealed pose a great challenge for detection, whether by human\nobservation or through advanced technological applications. While certain Deep\nLearning (DL) architectures demonstrate strong performance in processing local\ninformation, such as Convolutional Neural Networks (CNNs), others excel in\nhandling distant information, e.g., transformers. In X-ray security imaging the\nliterature has been dominated by the use of CNN-based methods, while the\nintegration of the two aforementioned leading architectures has not been\nsufficiently explored. In this paper, various hybrid CNN-transformer\narchitectures are evaluated against a common CNN object detection baseline,\nnamely YOLOv8. In particular, a CNN (HGNetV2) and a hybrid CNN-transformer\n(Next-ViT-S) backbone are combined with different CNN/transformer detection\nheads (YOLOv8 and RT-DETR). The resulting architectures are comparatively\nevaluated on three challenging public X-ray inspection datasets, namely EDS,\nHiXray, and PIDray. Interestingly, while the YOLOv8 detector with its default\nbackbone (CSP-DarkNet53) is generally shown to be advantageous on the HiXray\nand PIDray datasets, when a domain distribution shift is incorporated in the\nX-ray images (as happens in the EDS datasets), hybrid CNN-transformer\narchitectures exhibit increased robustness. Detailed comparative evaluation\nresults, including object-level detection performance and object-size error\nanalysis, demonstrate the strengths and weaknesses of each architectural\ncombination and suggest guidelines for future research. The source code and\nnetwork weights of the models employed in this study are available at\nhttps://github.com/jgenc/xray-comparative-evaluation.", "AI": {"tldr": "The paper evaluates hybrid CNN-transformer architectures for X-ray security imaging, comparing them to CNN baselines like YOLOv8, and finds hybrid models more robust to domain shifts.", "motivation": "Heavily occluded or concealed objects in X-ray security imaging are challenging to detect. While CNNs dominate the field, the integration of CNNs and transformers is underexplored.", "method": "Various hybrid CNN-transformer architectures (e.g., Next-ViT-S with YOLOv8 or RT-DETR heads) are tested against CNN baselines (YOLOv8) on three X-ray datasets (EDS, HiXray, PIDray).", "result": "Hybrid architectures show increased robustness to domain shifts (EDS dataset), while YOLOv8 performs better on HiXray and PIDray. Detailed performance and error analyses are provided.", "conclusion": "Hybrid CNN-transformer architectures offer advantages in robustness to domain shifts, suggesting guidelines for future research in X-ray security imaging."}}
{"id": "2505.00364", "pdf": "https://arxiv.org/pdf/2505.00364", "abs": "https://arxiv.org/abs/2505.00364", "authors": ["Jie Yang", "Yuwen Wang", "Kaixuan Chen", "Tongya Zheng", "Yihe Zhou", "Zhenbang Xiao", "Ji Cao", "Mingli Song", "Shunyu Liu"], "title": "From GNNs to Trees: Multi-Granular Interpretability for Graph Neural Networks", "categories": ["cs.LG"], "comment": "Accepted by ICLR 2025", "summary": "Interpretable Graph Neural Networks (GNNs) aim to reveal the underlying\nreasoning behind model predictions, attributing their decisions to specific\nsubgraphs that are informative. However, existing subgraph-based interpretable\nmethods suffer from an overemphasis on local structure, potentially overlooking\nlong-range dependencies within the entire graphs. Although recent efforts that\nrely on graph coarsening have proven beneficial for global interpretability,\nthey inevitably reduce the graphs to a fixed granularity. Such an inflexible\nway can only capture graph connectivity at a specific level, whereas real-world\ngraph tasks often exhibit relationships at varying granularities (e.g.,\nrelevant interactions in proteins span from functional groups, to amino acids,\nand up to protein domains). In this paper, we introduce a novel Tree-like\nInterpretable Framework (TIF) for graph classification, where plain GNNs are\ntransformed into hierarchical trees, with each level featuring coarsened graphs\nof different granularity as tree nodes. Specifically, TIF iteratively adopts a\ngraph coarsening module to compress original graphs (i.e., root nodes of trees)\ninto increasingly coarser ones (i.e., child nodes of trees), while preserving\ndiversity among tree nodes within different branches through a dedicated graph\nperturbation module. Finally, we propose an adaptive routing module to identify\nthe most informative root-to-leaf paths, providing not only the final\nprediction but also the multi-granular interpretability for the decision-making\nprocess. Extensive experiments on the graph classification benchmarks with both\nsynthetic and real-world datasets demonstrate the superiority of TIF in\ninterpretability, while also delivering a competitive prediction performance\nakin to the state-of-the-art counterparts.", "AI": {"tldr": "The paper introduces TIF, a Tree-like Interpretable Framework for GNNs, addressing limitations of existing methods by capturing multi-granular graph relationships and improving interpretability without sacrificing performance.", "motivation": "Existing subgraph-based interpretable GNNs focus too much on local structures and lack flexibility in capturing varying granularities of relationships in real-world graphs.", "method": "TIF transforms GNNs into hierarchical trees with coarsened graphs at different granularities, using graph coarsening, perturbation, and adaptive routing modules.", "result": "TIF outperforms in interpretability and matches state-of-the-art prediction performance on graph classification benchmarks.", "conclusion": "TIF provides a flexible, multi-granular interpretable framework for GNNs, enhancing both understanding and performance."}}
{"id": "2505.00261", "pdf": "https://arxiv.org/pdf/2505.00261", "abs": "https://arxiv.org/abs/2505.00261", "authors": ["Jayoung Song", "KyungTae Lim", "Jungyeul Park"], "title": "Enriching the Korean Learner Corpus with Multi-reference Annotations and Rubric-Based Scoring", "categories": ["cs.CL"], "comment": null, "summary": "Despite growing global interest in Korean language education, there remains a\nsignificant lack of learner corpora tailored to Korean L2 writing. To address\nthis gap, we enhance the KoLLA Korean learner corpus by adding multiple\ngrammatical error correction (GEC) references, thereby enabling more nuanced\nand flexible evaluation of GEC systems, and reflects the variability of human\nlanguage. Additionally, we enrich the corpus with rubric-based scores aligned\nwith guidelines from the Korean National Language Institute, capturing\ngrammatical accuracy, coherence, and lexical diversity. These enhancements make\nKoLLA a robust and standardized resource for research in Korean L2 education,\nsupporting advancements in language learning, assessment, and automated error\ncorrection.", "AI": {"tldr": "The paper enhances the KoLLA Korean learner corpus with multiple GEC references and rubric-based scores to improve evaluation of GEC systems and support Korean L2 education research.", "motivation": "Address the lack of learner corpora for Korean L2 writing and improve GEC system evaluation.", "method": "Enhance KoLLA corpus with multiple GEC references and rubric-based scores for grammatical accuracy, coherence, and lexical diversity.", "result": "KoLLA becomes a robust, standardized resource for Korean L2 education research.", "conclusion": "The enhanced corpus supports advancements in language learning, assessment, and automated error correction."}}
{"id": "2505.00284", "pdf": "https://arxiv.org/pdf/2505.00284", "abs": "https://arxiv.org/abs/2505.00284", "authors": ["Zhijie Qiao", "Haowei Li", "Zhong Cao", "Henry X. Liu"], "title": "LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) have demonstrated significant potential for\nend-to-end autonomous driving. However, fully exploiting their capabilities for\nsafe and reliable vehicle control remains an open research challenge. To\nsystematically examine advances and limitations of VLMs in driving tasks, we\nintroduce LightEMMA, a Lightweight End-to-End Multimodal Model for Autonomous\ndriving. LightEMMA provides a unified, VLM-based autonomous driving framework\nwithout ad hoc customizations, enabling easy integration and evaluation of\nevolving state-of-the-art commercial and open-source models. We construct\ntwelve autonomous driving agents using various VLMs and evaluate their\nperformance on the nuScenes prediction task, comprehensively assessing metrics\nsuch as inference time, computational cost, and predictive accuracy.\nIllustrative examples highlight that, despite their strong scenario\ninterpretation capabilities, VLMs' practical performance in autonomous driving\ntasks remains concerning, emphasizing the need for further improvements. The\ncode is available at https://github.com/michigan-traffic-lab/LightEMMA.", "AI": {"tldr": "LightEMMA is a lightweight VLM-based framework for autonomous driving, evaluating 12 agents on nuScenes, revealing performance gaps despite strong scenario interpretation.", "motivation": "To address the challenge of fully exploiting VLMs for safe and reliable autonomous driving by providing a unified framework.", "method": "Introduces LightEMMA, a lightweight end-to-end multimodal model, and evaluates 12 VLM-based agents on nuScenes, measuring inference time, cost, and accuracy.", "result": "VLMs show strong scenario interpretation but concerning practical performance in driving tasks, highlighting the need for improvements.", "conclusion": "LightEMMA offers a flexible framework for VLM evaluation, revealing current limitations and the need for further advancements in autonomous driving."}}
{"id": "2505.00568", "pdf": "https://arxiv.org/pdf/2505.00568", "abs": "https://arxiv.org/abs/2505.00568", "authors": ["Lucas Robinet", "Ahmad Berjaoui", "Elizabeth Cohen-Jonathan Moyal"], "title": "Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal magnetic resonance imaging (MRI) constitutes the first line of\ninvestigation for clinicians in the care of brain tumors, providing crucial\ninsights for surgery planning, treatment monitoring, and biomarker\nidentification. Pre-training on large datasets have been shown to help models\nlearn transferable representations and adapt with minimal labeled data. This\nbehavior is especially valuable in medical imaging, where annotations are often\nscarce. However, applying this paradigm to multimodal medical data introduces a\nchallenge: most existing approaches assume that all imaging modalities are\navailable during both pre-training and fine-tuning. In practice, missing\nmodalities often occur due to acquisition issues, specialist unavailability, or\nspecific experimental designs on small in-house datasets. Consequently, a\ncommon approach involves training a separate model for each desired modality\ncombination, making the process both resource-intensive and impractical for\nclinical use. Therefore, we introduce BM-MAE, a masked image modeling\npre-training strategy tailored for multimodal MRI data. The same pre-trained\nmodel seamlessly adapts to any combination of available modalities, extracting\nrich representations that capture both intra- and inter-modal information. This\nallows fine-tuning on any subset of modalities without requiring architectural\nchanges, while still benefiting from a model pre-trained on the full set of\nmodalities. Extensive experiments show that the proposed pre-training strategy\noutperforms or remains competitive with baselines that require separate\npre-training for each modality subset, while substantially surpassing training\nfrom scratch on several downstream tasks. Additionally, it can quickly and\nefficiently reconstruct missing modalities, highlighting its practical value.\nCode and trained models are available at: https://github.com/Lucas-rbnt/bmmae", "AI": {"tldr": "BM-MAE introduces a masked image modeling pre-training strategy for multimodal MRI data, enabling adaptation to any modality combination without separate models, outperforming baselines and reconstructing missing modalities efficiently.", "motivation": "Addressing the challenge of missing modalities in multimodal MRI data, which complicates pre-training and fine-tuning, by proposing a unified approach that avoids resource-intensive separate models.", "method": "BM-MAE uses masked image modeling to pre-train on multimodal MRI data, allowing the same model to adapt to any subset of modalities without architectural changes.", "result": "Outperforms or matches baselines requiring separate pre-training, surpasses training from scratch, and efficiently reconstructs missing modalities.", "conclusion": "BM-MAE offers a practical, efficient solution for handling missing modalities in multimodal MRI, enhancing clinical applicability and performance."}}
{"id": "2505.00365", "pdf": "https://arxiv.org/pdf/2505.00365", "abs": "https://arxiv.org/abs/2505.00365", "authors": ["Zhengyi Zhong", "Weidong Bao", "Ji Wang", "Jianguo Chen", "Lingjuan Lyu", "Wei Yang Bryan Lim"], "title": "SacFL: Self-Adaptive Federated Continual Learning for Resource-Constrained End Devices", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by TNNLS 2025", "summary": "The proliferation of end devices has led to a distributed computing paradigm,\nwherein on-device machine learning models continuously process diverse data\ngenerated by these devices. The dynamic nature of this data, characterized by\ncontinuous changes or data drift, poses significant challenges for on-device\nmodels. To address this issue, continual learning (CL) is proposed, enabling\nmachine learning models to incrementally update their knowledge and mitigate\ncatastrophic forgetting. However, the traditional centralized approach to CL is\nunsuitable for end devices due to privacy and data volume concerns. In this\ncontext, federated continual learning (FCL) emerges as a promising solution,\npreserving user data locally while enhancing models through collaborative\nupdates. Aiming at the challenges of limited storage resources for CL, poor\nautonomy in task shift detection, and difficulty in coping with new adversarial\ntasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFL\nemploys an Encoder-Decoder architecture to separate task-robust and\ntask-sensitive components, significantly reducing storage demands by retaining\nlightweight task-sensitive components for resource-constrained end devices.\nMoreover, $\\rm{SacFL}$ leverages contrastive learning to introduce an\nautonomous data shift detection mechanism, enabling it to discern whether a new\ntask has emerged and whether it is a benign task. This capability ultimately\nallows the device to autonomously trigger CL or attack defense strategy without\nadditional information, which is more practical for end devices. Comprehensive\nexperiments conducted on multiple text and image datasets, such as Cifar100 and\nTHUCNews, have validated the effectiveness of $\\rm{SacFL}$ in both\nclass-incremental and domain-incremental scenarios. Furthermore, a demo system\nhas been developed to verify its practicality.", "AI": {"tldr": "The paper proposes SacFL, a federated continual learning (FCL) framework, to address challenges like limited storage, poor task shift detection, and adversarial tasks in on-device machine learning. It uses an Encoder-Decoder architecture and contrastive learning for efficiency and autonomy.", "motivation": "The dynamic nature of data in distributed computing requires continual learning (CL), but traditional centralized CL is unsuitable for end devices due to privacy and data volume issues. Federated continual learning (FCL) is proposed to address these challenges.", "method": "SacFL employs an Encoder-Decoder architecture to separate task-robust and task-sensitive components, reducing storage needs. It uses contrastive learning for autonomous task shift detection and attack defense.", "result": "Experiments on datasets like Cifar100 and THUCNews show SacFL's effectiveness in class-incremental and domain-incremental scenarios. A demo system confirms its practicality.", "conclusion": "SacFL is a practical FCL solution for resource-constrained devices, offering efficient storage use, autonomous task detection, and robustness against adversarial tasks."}}
{"id": "2505.00339", "pdf": "https://arxiv.org/pdf/2505.00339", "abs": "https://arxiv.org/abs/2505.00339", "authors": ["Antoun Yaacoub", "Sansiri Tarnpradab", "Phattara Khumprom", "Zainab Assaghir", "Lionel Prevost", "J\u00e9r\u00f4me Da-Rugna"], "title": "Enhancing AI-Driven Education: Integrating Cognitive Frameworks, Linguistic Feedback Analysis, and Ethical Considerations for Improved Content Generation", "categories": ["cs.CL", "cs.AI"], "comment": "This article will be presented in IJCNN 2025 \"AI Innovations for\n  Education: Transforming Teaching and Learning through Cutting-Edge\n  Technologies\" workshop", "summary": "Artificial intelligence (AI) is rapidly transforming education, presenting\nunprecedented opportunities for personalized learning and streamlined content\ncreation. However, realizing the full potential of AI in educational settings\nnecessitates careful consideration of the quality, cognitive depth, and ethical\nimplications of AI-generated materials. This paper synthesizes insights from\nfour related studies to propose a comprehensive framework for enhancing\nAI-driven educational tools. We integrate cognitive assessment frameworks\n(Bloom's Taxonomy and SOLO Taxonomy), linguistic analysis of AI-generated\nfeedback, and ethical design principles to guide the development of effective\nand responsible AI tools. We outline a structured three-phase approach\nencompassing cognitive alignment, linguistic feedback integration, and ethical\nsafeguards. The practical application of this framework is demonstrated through\nits integration into OneClickQuiz, an AI-powered Moodle plugin for quiz\ngeneration. This work contributes a comprehensive and actionable guide for\neducators, researchers, and developers aiming to harness AI's potential while\nupholding pedagogical and ethical standards in educational content generation.", "AI": {"tldr": "The paper proposes a framework for improving AI-driven educational tools by integrating cognitive assessment, linguistic feedback, and ethical principles, demonstrated via an AI-powered quiz plugin.", "motivation": "To address the need for high-quality, ethically sound, and pedagogically effective AI-generated educational materials.", "method": "A three-phase approach: cognitive alignment, linguistic feedback integration, and ethical safeguards, applied to an AI-powered quiz plugin (OneClickQuiz).", "result": "A comprehensive framework for developing responsible and effective AI tools in education.", "conclusion": "The framework provides actionable guidance for educators and developers to leverage AI in education while maintaining ethical and pedagogical standards."}}
{"id": "2505.00322", "pdf": "https://arxiv.org/pdf/2505.00322", "abs": "https://arxiv.org/abs/2505.00322", "authors": ["Keshu Wu", "Zihao Li", "Sixu Li", "Xinyue Ye", "Dominique Lord", "Yang Zhou"], "title": "AI2-Active Safety: AI-enabled Interaction-aware Active Safety Analysis with Vehicle Dynamics", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "This paper introduces an AI-enabled, interaction-aware active safety analysis\nframework that accounts for groupwise vehicle interactions. Specifically, the\nframework employs a bicycle model-augmented with road gradient\nconsiderations-to accurately capture vehicle dynamics. In parallel, a\nhypergraph-based AI model is developed to predict probabilistic trajectories of\nambient traffic. By integrating these two components, the framework derives\nvehicle intra-spacing over a 3D road surface as the solution of a stochastic\nordinary differential equation, yielding high-fidelity surrogate safety\nmeasures such as time-to-collision (TTC). To demonstrate its effectiveness, the\nframework is analyzed using stochastic numerical methods comprising 4th-order\nRunge-Kutta integration and AI inference, generating probability-weighted\nhigh-fidelity TTC (HF-TTC) distributions that reflect complex multi-agent\nmaneuvers and behavioral uncertainties. Evaluated with HF-TTC against\ntraditional constant-velocity TTC and non-interaction-aware approaches on\nhighway datasets, the proposed framework offers a systematic methodology for\nactive safety analysis with enhanced potential for improving safety perception\nin complex traffic environments.", "AI": {"tldr": "An AI-enabled framework for active safety analysis integrates vehicle dynamics and hypergraph-based AI to predict probabilistic trajectories, improving safety measures like TTC in complex traffic.", "motivation": "To enhance safety perception in complex traffic by accounting for groupwise vehicle interactions and behavioral uncertainties.", "method": "Combines a bicycle model with road gradient and a hypergraph-based AI model to derive stochastic safety measures like HF-TTC.", "result": "The framework outperforms traditional methods, providing high-fidelity TTC distributions reflecting multi-agent maneuvers.", "conclusion": "The proposed framework systematically improves active safety analysis in complex traffic environments."}}
{"id": "2505.00569", "pdf": "https://arxiv.org/pdf/2505.00569", "abs": "https://arxiv.org/abs/2505.00569", "authors": ["Enmin Zhong", "Carlos R. del-Blanco", "Daniel Berj\u00f3n", "Fernando Jaureguizar", "Narciso Garc\u00eda"], "title": "AnimalMotionCLIP: Embedding motion in CLIP for Animal Behavior Analysis", "categories": ["cs.CV"], "comment": "6 pages, 3 figures,Accepted for the poster session at the CV4Animals\n  workshop: Computer Vision for Animal Behavior Tracking and Modeling In\n  conjunction with Computer Vision and Pattern Recognition 2024", "summary": "Recently, there has been a surge of interest in applying deep learning\ntechniques to animal behavior recognition, particularly leveraging pre-trained\nvisual language models, such as CLIP, due to their remarkable generalization\ncapacity across various downstream tasks. However, adapting these models to the\nspecific domain of animal behavior recognition presents two significant\nchallenges: integrating motion information and devising an effective temporal\nmodeling scheme. In this paper, we propose AnimalMotionCLIP to address these\nchallenges by interleaving video frames and optical flow information in the\nCLIP framework. Additionally, several temporal modeling schemes using an\naggregation of classifiers are proposed and compared: dense, semi dense, and\nsparse. As a result, fine temporal actions can be correctly recognized, which\nis of vital importance in animal behavior analysis. Experiments on the Animal\nKingdom dataset demonstrate that AnimalMotionCLIP achieves superior performance\ncompared to state-of-the-art approaches.", "AI": {"tldr": "AnimalMotionCLIP integrates motion and temporal modeling into CLIP for animal behavior recognition, outperforming state-of-the-art methods.", "motivation": "Deep learning models like CLIP lack motion integration and temporal modeling for animal behavior recognition.", "method": "Proposes AnimalMotionCLIP, combining video frames and optical flow in CLIP, with dense, semi-dense, and sparse temporal classifiers.", "result": "Superior performance on the Animal Kingdom dataset, recognizing fine temporal actions.", "conclusion": "AnimalMotionCLIP effectively addresses motion and temporal challenges in animal behavior recognition."}}
{"id": "2505.00375", "pdf": "https://arxiv.org/pdf/2505.00375", "abs": "https://arxiv.org/abs/2505.00375", "authors": ["Jinhui Yi", "Huan Yan", "Haotian Wang", "Jian Yuan", "Yong Li"], "title": "Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery and Pickup Logistics Services", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ACM SIGSPATIAL 2024", "summary": "Accurately estimating package delivery time is essential to the logistics\nindustry, which enables reasonable work allocation and on-time service\nguarantee. This becomes even more necessary in mixed logistics scenarios where\ncouriers handle a high volume of delivery and a smaller number of pickup\nsimultaneously. However, most of the related works treat the pickup and\ndelivery patterns on couriers' decision behavior equally, neglecting that the\npickup has a greater impact on couriers' decision-making compared to the\ndelivery due to its tighter time constraints. In such context, we have three\nmain challenges: 1) multiple spatiotemporal factors are intricately\ninterconnected, significantly affecting couriers' delivery behavior; 2) pickups\nhave stricter time requirements but are limited in number, making it\nchallenging to model their effects on couriers' delivery process; 3) couriers'\nspatial mobility patterns are critical determinants of their delivery behavior,\nbut have been insufficiently explored. To deal with these, we propose TransPDT,\na Transformer-based multi-task package delivery time prediction model. We first\nemploy the Transformer encoder architecture to capture the spatio-temporal\ndependencies of couriers' historical travel routes and pending package sets.\nThen we design the pattern memory to learn the patterns of pickup in the\nimbalanced dataset via attention mechanism. We also set the route prediction as\nan auxiliary task of delivery time prediction, and incorporate the prior\ncourier spatial movement regularities in prediction. Extensive experiments on\nreal industry-scale datasets demonstrate the superiority of our method. A\nsystem based on TransPDT is deployed internally in JD Logistics to track more\nthan 2000 couriers handling hundreds of thousands of packages per day in\nBeijing.", "AI": {"tldr": "TransPDT, a Transformer-based model, predicts package delivery time by addressing spatiotemporal dependencies, pickup impacts, and courier mobility patterns, outperforming existing methods.", "motivation": "Accurate delivery time estimation is crucial for logistics, especially in mixed scenarios where pickups disrupt courier behavior. Existing methods overlook pickup's greater impact due to tighter time constraints.", "method": "TransPDT uses a Transformer encoder for spatiotemporal dependencies, a pattern memory for pickup effects, and an auxiliary route prediction task with courier movement regularities.", "result": "Experiments on real datasets show TransPDT's superiority. It's deployed in JD Logistics, tracking 2000+ couriers handling hundreds of thousands of daily packages in Beijing.", "conclusion": "TransPDT effectively addresses the challenges of delivery time prediction in mixed logistics scenarios, demonstrating practical utility in large-scale deployments."}}
{"id": "2505.00367", "pdf": "https://arxiv.org/pdf/2505.00367", "abs": "https://arxiv.org/abs/2505.00367", "authors": ["JunSeo Kim", "HyeHyeon Kim"], "title": "KoACD: The First Korean Adolescent Dataset for Cognitive Distortion Analysis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Cognitive distortion refers to negative thinking patterns that can lead to\nmental health issues like depression and anxiety in adolescents. Previous\nstudies using natural language processing (NLP) have focused mainly on\nsmall-scale adult datasets, with limited research on adolescents. This study\nintroduces KoACD, the first large-scale dataset of cognitive distortions in\nKorean adolescents, containing 108,717 instances. We applied a multi-Large\nLanguage Model (LLM) negotiation method to refine distortion classification and\ngenerate synthetic data using two approaches: cognitive clarification for\ntextual clarity and cognitive balancing for diverse distortion representation.\nValidation through LLMs and expert evaluations showed that while LLMs\nclassified distortions with explicit markers, they struggled with\ncontext-dependent reasoning, where human evaluators demonstrated higher\naccuracy. KoACD aims to enhance future research on cognitive distortion\ndetection.", "AI": {"tldr": "The paper introduces KoACD, a large-scale dataset for cognitive distortions in Korean adolescents, using multi-LLM negotiation for classification and synthetic data generation. It highlights LLMs' limitations in context-dependent reasoning compared to humans.", "motivation": "Address the gap in research on cognitive distortions in adolescents, particularly in Korean contexts, by creating a comprehensive dataset.", "method": "Utilized multi-LLM negotiation for distortion classification and synthetic data generation via cognitive clarification and balancing.", "result": "LLMs performed well with explicit markers but struggled with context-dependent reasoning, where humans outperformed.", "conclusion": "KoACD provides a valuable resource for future research on cognitive distortion detection in adolescents."}}
{"id": "2505.00592", "pdf": "https://arxiv.org/pdf/2505.00592", "abs": "https://arxiv.org/abs/2505.00592", "authors": ["Shuo Tong", "Shangde Gao", "Ke Liu", "Zihang Huang", "Hongxia Xu", "Haochao Ying", "Jian Wu"], "title": "Uncertainty-Aware Multi-Expert Knowledge Distillation for Imbalanced Disease Grading", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Automatic disease image grading is a significant application of artificial\nintelligence for healthcare, enabling faster and more accurate patient\nassessments. However, domain shifts, which are exacerbated by data imbalance,\nintroduce bias into the model, posing deployment difficulties in clinical\napplications. To address the problem, we propose a novel\n\\textbf{U}ncertainty-aware \\textbf{M}ulti-experts \\textbf{K}nowledge\n\\textbf{D}istillation (UMKD) framework to transfer knowledge from multiple\nexpert models to a single student model. Specifically, to extract\ndiscriminative features, UMKD decouples task-agnostic and task-specific\nfeatures with shallow and compact feature alignment in the feature space. At\nthe output space, an uncertainty-aware decoupled distillation (UDD) mechanism\ndynamically adjusts knowledge transfer weights based on expert model\nuncertainties, ensuring robust and reliable distillation. Additionally, UMKD\nalso tackles the problems of model architecture heterogeneity and distribution\ndiscrepancies between source and target domains, which are inadequately tackled\nby previous KD approaches. Extensive experiments on histology prostate grading\n(\\textit{SICAPv2}) and fundus image grading (\\textit{APTOS}) demonstrate that\nUMKD achieves a new state-of-the-art in both source-imbalanced and\ntarget-imbalanced scenarios, offering a robust and practical solution for\nreal-world disease image grading.", "AI": {"tldr": "UMKD is a novel framework for disease image grading that addresses domain shifts and data imbalance by distilling knowledge from multiple expert models to a student model, achieving state-of-the-art results.", "motivation": "Domain shifts and data imbalance in disease image grading introduce bias, hindering clinical deployment. UMKD aims to mitigate these issues for robust AI healthcare applications.", "method": "UMKD uses uncertainty-aware multi-experts knowledge distillation, decoupling task-agnostic and task-specific features, and dynamically adjusting knowledge transfer weights based on expert uncertainties.", "result": "UMKD outperforms previous methods on histology prostate and fundus image grading datasets, excelling in both source-imbalanced and target-imbalanced scenarios.", "conclusion": "UMKD provides a robust and practical solution for real-world disease image grading, addressing key challenges like domain shifts and model heterogeneity."}}
{"id": "2505.00382", "pdf": "https://arxiv.org/pdf/2505.00382", "abs": "https://arxiv.org/abs/2505.00382", "authors": ["Jianya Lu", "Yingjun Mo"], "title": "Approximation to Deep Q-Network by Stochastic Delay Differential Equations", "categories": ["cs.LG", "math.PR"], "comment": null, "summary": "Despite the significant breakthroughs that the Deep Q-Network (DQN) has\nbrought to reinforcement learning, its theoretical analysis remains limited. In\nthis paper, we construct a stochastic differential delay equation (SDDE) based\non the DQN algorithm and estimate the Wasserstein-1 distance between them. We\nprovide an upper bound for the distance and prove that the distance between the\ntwo converges to zero as the step size approaches zero. This result allows us\nto understand DQN's two key techniques, the experience replay and the target\nnetwork, from the perspective of continuous systems. Specifically, the delay\nterm in the equation, corresponding to the target network, contributes to the\nstability of the system. Our approach leverages a refined Lindeberg principle\nand an operator comparison to establish these results.", "AI": {"tldr": "The paper analyzes DQN's theoretical limitations, modeling it as an SDDE and proving convergence to zero distance with step size reduction, linking DQN techniques to continuous systems.", "motivation": "To address the lack of theoretical understanding of DQN's success, particularly its key techniques like experience replay and target networks.", "method": "Constructs an SDDE based on DQN, estimates Wasserstein-1 distance, and uses Lindeberg principle and operator comparison for analysis.", "result": "Proves the distance between DQN and SDDE converges to zero as step size decreases, showing target networks stabilize the system.", "conclusion": "Provides a continuous-system perspective for DQN's techniques, enhancing theoretical understanding of its stability and convergence."}}
{"id": "2505.00389", "pdf": "https://arxiv.org/pdf/2505.00389", "abs": "https://arxiv.org/abs/2505.00389", "authors": ["Bowen Zhang", "Zixin Song", "Chunping Li"], "title": "CSE-SFP: Enabling Unsupervised Sentence Representation Learning via a Single Forward Pass", "categories": ["cs.CL"], "comment": "Accepted by SIGIR 2025 (Full)", "summary": "As a fundamental task in Information Retrieval and Computational Linguistics,\nsentence representation has profound implications for a wide range of practical\napplications such as text clustering, content analysis, question-answering\nsystems, and web search. Recent advances in pre-trained language models (PLMs)\nhave driven remarkable progress in this field, particularly through\nunsupervised embedding derivation methods centered on discriminative PLMs like\nBERT. However, due to time and computational constraints, few efforts have\nattempted to integrate unsupervised sentence representation with generative\nPLMs, which typically possess much larger parameter sizes. Given that\nstate-of-the-art models in both academia and industry are predominantly based\non generative architectures, there is a pressing need for an efficient\nunsupervised text representation framework tailored to decoder-only PLMs. To\naddress this concern, we propose CSE-SFP, an innovative method that exploits\nthe structural characteristics of generative models. Compared to existing\nstrategies, CSE-SFP requires only a single forward pass to perform effective\nunsupervised contrastive learning. Rigorous experimentation demonstrates that\nCSE-SFP not only produces higher-quality embeddings but also significantly\nreduces both training time and memory consumption. Furthermore, we introduce\ntwo ratio metrics that jointly assess alignment and uniformity, thereby\nproviding a more robust means for evaluating the semantic spatial properties of\nencoding models.", "AI": {"tldr": "The paper proposes CSE-SFP, an efficient unsupervised method for deriving sentence representations using generative pre-trained language models (PLMs), addressing gaps in current approaches.", "motivation": "Current unsupervised sentence representation methods focus on discriminative PLMs like BERT, neglecting generative PLMs despite their dominance in state-of-the-art models.", "method": "CSE-SFP leverages generative model structures for unsupervised contrastive learning, requiring only a single forward pass.", "result": "CSE-SFP produces higher-quality embeddings, reduces training time and memory usage, and introduces new metrics for evaluating semantic spatial properties.", "conclusion": "CSE-SFP fills a critical gap by efficiently adapting generative PLMs for unsupervised sentence representation, offering superior performance and evaluation metrics."}}
{"id": "2505.00402", "pdf": "https://arxiv.org/pdf/2505.00402", "abs": "https://arxiv.org/abs/2505.00402", "authors": ["Jinhui Yi", "Huan Yan", "Haotian Wang", "Jian Yuan", "Yong Li"], "title": "DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by CIKM 2023", "summary": "Prediction of couriers' delivery timely rates in advance is essential to the\nlogistics industry, enabling companies to take preemptive measures to ensure\nthe normal operation of delivery services. This becomes even more critical\nduring anomaly conditions like the epidemic outbreak, during which couriers'\ndelivery timely rate will decline markedly and fluctuates significantly.\nExisting studies pay less attention to the logistics scenario. Moreover, many\nworks focusing on prediction tasks in anomaly scenarios fail to explicitly\nmodel abnormal events, e.g., treating external factors equally with other\nfeatures, resulting in great information loss. Further, since some anomalous\nevents occur infrequently, traditional data-driven methods perform poorly in\nthese scenarios. To deal with them, we propose a deep spatial-temporal\nattention model, named DeepSTA. To be specific, to avoid information loss, we\ndesign an anomaly spatio-temporal learning module that employs a recurrent\nneural network to model incident information. Additionally, we utilize Node2vec\nto model correlations between road districts, and adopt graph neural networks\nand long short-term memory to capture the spatial-temporal dependencies of\ncouriers. To tackle the issue of insufficient training data in abnormal\ncircumstances, we propose an anomaly pattern attention module that adopts a\nmemory network for couriers' anomaly feature patterns storage via attention\nmechanisms. The experiments on real-world logistics datasets during the\nCOVID-19 outbreak in 2022 show the model outperforms the best baselines by\n12.11% in MAE and 13.71% in MSE, demonstrating its superior performance over\nmultiple competitive baselines.", "AI": {"tldr": "The paper proposes DeepSTA, a deep spatial-temporal attention model, to predict couriers' delivery timely rates, especially during anomalies like epidemics, outperforming baselines by 12.11% in MAE and 13.71% in MSE.", "motivation": "Existing studies overlook logistics scenarios and fail to model abnormal events explicitly, leading to poor performance in anomaly conditions like epidemics.", "method": "DeepSTA uses an anomaly spatio-temporal learning module with RNNs for incident modeling, Node2vec for road district correlations, and GNNs with LSTM for spatial-temporal dependencies. An anomaly pattern attention module with memory networks addresses insufficient training data.", "result": "Experiments on COVID-19 logistics data show DeepSTA outperforms baselines by 12.11% (MAE) and 13.71% (MSE).", "conclusion": "DeepSTA effectively improves delivery rate prediction during anomalies by explicitly modeling abnormal events and leveraging spatial-temporal dependencies."}}
{"id": "2505.00599", "pdf": "https://arxiv.org/pdf/2505.00599", "abs": "https://arxiv.org/abs/2505.00599", "authors": ["Alexander Puzicha", "Konstantin W\u00fcstefeld", "Kathrin Wilms", "Frank Weichert"], "title": "Visual Trajectory Prediction of Vessels for Inland Navigation", "categories": ["cs.CV"], "comment": null, "summary": "The future of inland navigation increasingly relies on autonomous systems and\nremote operations, emphasizing the need for accurate vessel trajectory\nprediction. This study addresses the challenges of video-based vessel tracking\nand prediction by integrating advanced object detection methods, Kalman\nfilters, and spline-based interpolation. However, existing detection systems\noften misclassify objects in inland waterways due to complex surroundings. A\ncomparative evaluation of tracking algorithms, including BoT-SORT, Deep\nOC-SORT, and ByeTrack, highlights the robustness of the Kalman filter in\nproviding smoothed trajectories. Experimental results from diverse scenarios\ndemonstrate improved accuracy in predicting vessel movements, which is\nessential for collision avoidance and situational awareness. The findings\nunderline the necessity of customized datasets and models for inland\nnavigation. Future work will expand the datasets and incorporate vessel\nclassification to refine predictions, supporting both autonomous systems and\nhuman operators in complex environments.", "AI": {"tldr": "The paper focuses on improving vessel trajectory prediction in inland navigation by integrating object detection, Kalman filters, and spline interpolation, addressing challenges like misclassification and complex environments.", "motivation": "The need for accurate vessel trajectory prediction in autonomous and remote inland navigation systems due to complex surroundings and misclassification issues.", "method": "Integration of advanced object detection, Kalman filters, and spline-based interpolation, with a comparative evaluation of tracking algorithms (BoT-SORT, Deep OC-SORT, ByeTrack).", "result": "Improved accuracy in vessel movement prediction, highlighting the robustness of Kalman filters for smoothed trajectories.", "conclusion": "Customized datasets and models are essential for inland navigation. Future work includes expanding datasets and incorporating vessel classification for better predictions."}}
{"id": "2505.00398", "pdf": "https://arxiv.org/pdf/2505.00398", "abs": "https://arxiv.org/abs/2505.00398", "authors": ["Bassel Hamoud", "Ilnura Usmanova", "Kfir Y. Levy"], "title": "Safety in the Face of Adversity: Achieving Zero Constraint Violation in Online Learning with Slowly Changing Constraints", "categories": ["cs.LG"], "comment": "Accepted to AISTATS, 2025", "summary": "We present the first theoretical guarantees for zero constraint violation in\nOnline Convex Optimization (OCO) across all rounds, addressing dynamic\nconstraint changes. Unlike existing approaches in constrained OCO, which allow\nfor occasional safety breaches, we provide the first approach for maintaining\nstrict safety under the assumption of gradually evolving constraints, namely\nthe constraints change at most by a small amount between consecutive rounds.\nThis is achieved through a primal-dual approach and Online Gradient Ascent in\nthe dual space. We show that employing a dichotomous learning rate enables\nensuring both safety, via zero constraint violation, and sublinear regret. Our\nframework marks a departure from previous work by providing the first provable\nguarantees for maintaining absolute safety in the face of changing constraints\nin OCO.", "AI": {"tldr": "The paper introduces the first theoretical guarantees for zero constraint violation in Online Convex Optimization (OCO) with dynamic constraints, ensuring strict safety and sublinear regret using a primal-dual approach.", "motivation": "Existing constrained OCO methods allow occasional safety breaches; this work aims to guarantee strict safety under gradually evolving constraints.", "method": "A primal-dual approach with Online Gradient Ascent in the dual space, employing a dichotomous learning rate to balance safety and regret.", "result": "The method achieves zero constraint violation and sublinear regret under gradually changing constraints.", "conclusion": "This framework provides the first provable guarantees for absolute safety in OCO with dynamic constraints, advancing beyond prior work."}}
{"id": "2505.00467", "pdf": "https://arxiv.org/pdf/2505.00467", "abs": "https://arxiv.org/abs/2505.00467", "authors": ["Vahid Balazadeh", "Michael Cooper", "David Pellow", "Atousa Assadi", "Jennifer Bell", "Jim Fackler", "Gabriel Funingana", "Spencer Gable-Cook", "Anirudh Gangadhar", "Abhishek Jaiswal", "Sumanth Kaja", "Christopher Khoury", "Randy Lin", "Kaden McKeen", "Sara Naimimohasses", "Khashayar Namdar", "Aviraj Newatia", "Allan Pang", "Anshul Pattoo", "Sameer Peesapati", "Diana Prepelita", "Bogdana Rakova", "Saba Sadatamin", "Rafael Schulman", "Ajay Shah", "Syed Azhar Shah", "Syed Ahmar Shah", "Babak Taati", "Balagopal Unnikrishnan", "Stephanie Williams", "Rahul G Krishnan"], "title": "Red Teaming Large Language Models for Healthcare", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present the design process and findings of the pre-conference workshop at\nthe Machine Learning for Healthcare Conference (2024) entitled Red Teaming\nLarge Language Models for Healthcare, which took place on August 15, 2024.\nConference participants, comprising a mix of computational and clinical\nexpertise, attempted to discover vulnerabilities -- realistic clinical prompts\nfor which a large language model (LLM) outputs a response that could cause\nclinical harm. Red-teaming with clinicians enables the identification of LLM\nvulnerabilities that may not be recognised by LLM developers lacking clinical\nexpertise. We report the vulnerabilities found, categorise them, and present\nthe results of a replication study assessing the vulnerabilities across all\nLLMs provided.", "AI": {"tldr": "A workshop at MLHC 2024 focused on red-teaming LLMs in healthcare, identifying vulnerabilities through clinician input, categorizing them, and replicating findings across LLMs.", "motivation": "To uncover clinical vulnerabilities in LLMs that developers might miss due to lack of clinical expertise.", "method": "Red-teaming with clinicians to test LLMs using realistic clinical prompts, followed by categorization and replication of vulnerabilities across LLMs.", "result": "Identified and categorized vulnerabilities in LLMs, with replication confirming their presence across models.", "conclusion": "Clinician involvement in red-teaming is crucial for identifying and mitigating LLM vulnerabilities in healthcare."}}
{"id": "2505.00439", "pdf": "https://arxiv.org/pdf/2505.00439", "abs": "https://arxiv.org/abs/2505.00439", "authors": ["Timo P. Gros", "Nicola J. M\u00fcller", "Daniel Fiser", "Isabel Valera", "Verena Wolf", "J\u00f6rg Hoffmann"], "title": "Per-Domain Generalizing Policies: On Validation Instances and Scaling Behavior", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 3 tables, 3 figures, 3 algorithms", "summary": "Recent work has shown that successful per-domain generalizing action policies\ncan be learned. Scaling behavior, from small training instances to large test\ninstances, is the key objective; and the use of validation instances larger\nthan training instances is one key to achieve it. Prior work has used fixed\nvalidation sets. Here, we introduce a method generating the validation set\ndynamically, on the fly, increasing instance size so long as informative and\nfeasible.We also introduce refined methodology for evaluating scaling behavior,\ngenerating test instances systematically to guarantee a given confidence in\ncoverage performance for each instance size. In experiments, dynamic validation\nimproves scaling behavior of GNN policies in all 9 domains used.", "AI": {"tldr": "Dynamic validation sets improve scaling behavior of GNN policies across domains.", "motivation": "To enhance scaling behavior in action policies by dynamically generating validation sets and refining evaluation methodology.", "method": "Introduces dynamic validation set generation and systematic test instance creation for scaling evaluation.", "result": "Dynamic validation improves GNN policies' scaling in all 9 tested domains.", "conclusion": "Dynamic validation and refined evaluation methods effectively enhance policy scaling."}}
{"id": "2505.00606", "pdf": "https://arxiv.org/pdf/2505.00606", "abs": "https://arxiv.org/abs/2505.00606", "authors": ["Wallace Lee", "YuHao Chen"], "title": "Dietary Intake Estimation via Continuous 3D Reconstruction of Food", "categories": ["cs.CV", "cs.LG"], "comment": "2025 CVPR MetaFood Workshop", "summary": "Monitoring dietary habits is crucial for preventing health risks associated\nwith overeating and undereating, including obesity, diabetes, and\ncardiovascular diseases. Traditional methods for tracking food intake rely on\nself-reported data before or after the eating, which are prone to inaccuracies.\nThis study proposes an approach to accurately monitor ingest behaviours by\nleveraging 3D food models constructed from monocular 2D video. Using COLMAP and\npose estimation algorithms, we generate detailed 3D representations of food,\nallowing us to observe changes in food volume as it is consumed. Experiments\nwith toy models and real food items demonstrate the approach's potential.\nMeanwhile, we have proposed a new methodology for automated state recognition\nchallenges to accurately detect state changes and maintain model fidelity. The\n3D reconstruction approach shows promise in capturing comprehensive dietary\nbehaviour insights, ultimately contributing to the development of automated and\naccurate dietary monitoring tools.", "AI": {"tldr": "A 3D food model-based approach using monocular 2D video to monitor dietary habits accurately, addressing inaccuracies in traditional self-reported methods.", "motivation": "To improve dietary monitoring by overcoming the inaccuracies of self-reported data, which can lead to health risks like obesity and diabetes.", "method": "Uses COLMAP and pose estimation algorithms to create 3D food models from 2D video, tracking food volume changes during consumption.", "result": "Experiments with toy models and real food show the approach's potential for accurate dietary monitoring.", "conclusion": "The 3D reconstruction method offers a promising tool for automated and precise dietary behavior tracking."}}
{"id": "2505.00410", "pdf": "https://arxiv.org/pdf/2505.00410", "abs": "https://arxiv.org/abs/2505.00410", "authors": ["Farhana Elias", "Md Shihab Reza", "Muhammad Zawad Mahmud", "Samiha Islam"], "title": "Machine Learning Meets Transparency in Osteoporosis Risk Assessment: A Comparative Study of ML and Explainability Analysis", "categories": ["cs.LG"], "comment": "Submitted in an international conference", "summary": "The present research tackles the difficulty of predicting osteoporosis risk\nvia machine learning (ML) approaches, emphasizing the use of explainable\nartificial intelligence (XAI) to improve model transparency. Osteoporosis is a\nsignificant public health concern, sometimes remaining untreated owing to its\nasymptomatic characteristics, and early identification is essential to avert\nfractures. The research assesses six machine learning classifiers: Random\nForest, Logistic Regression, XGBoost, AdaBoost, LightGBM, and Gradient Boosting\nand utilizes a dataset based on clinical, demographic, and lifestyle variables.\nThe models are refined using GridSearchCV to calibrate hyperparameters, with\nthe objective of enhancing predictive efficacy. XGBoost had the greatest\naccuracy (91%) among the evaluated models, surpassing others in precision\n(0.92), recall (0.91), and F1-score (0.90). The research further integrates XAI\napproaches, such as SHAP, LIME, and Permutation Feature Importance, to\nelucidate the decision-making process of the optimal model. The study indicates\nthat age is the primary determinant in forecasting osteoporosis risk, followed\nby hormonal alterations and familial history. These results corroborate\nclinical knowledge and affirm the models' therapeutic significance. The\nresearch underscores the significance of explainability in machine learning\nmodels for healthcare applications, guaranteeing that physicians can rely on\nthe system's predictions. The report ultimately proposes directions for further\nresearch, such as validation across varied populations and the integration of\nsupplementary biomarkers for enhanced predictive accuracy.", "AI": {"tldr": "The research uses ML and XAI to predict osteoporosis risk, with XGBoost achieving 91% accuracy. Age, hormonal changes, and family history are key predictors. Explainability is emphasized for clinical trust.", "motivation": "Osteoporosis is often asymptomatic and untreated; early detection is crucial to prevent fractures. ML and XAI can improve prediction and transparency.", "method": "Six ML classifiers (Random Forest, Logistic Regression, XGBoost, AdaBoost, LightGBM, Gradient Boosting) were tested using clinical, demographic, and lifestyle data. Hyperparameters were tuned with GridSearchCV. XAI tools (SHAP, LIME, Permutation Feature Importance) explained model decisions.", "result": "XGBoost performed best (91% accuracy, 0.92 precision, 0.91 recall, 0.90 F1-score). Age, hormonal changes, and family history were top predictors.", "conclusion": "Explainable ML models are vital for healthcare. Future work includes validation in diverse populations and adding biomarkers for better accuracy."}}
{"id": "2505.00479", "pdf": "https://arxiv.org/pdf/2505.00479", "abs": "https://arxiv.org/abs/2505.00479", "authors": ["Gijs Jan Brandsma", "Jens Blom-Hansen", "Christiaan Meijer", "Kody Moodley"], "title": "Computational Identification of Regulatory Statements in EU Legislation", "categories": ["cs.CL", "I.2.7"], "comment": "11 pages, 6 figures", "summary": "Identifying regulatory statements in legislation is useful for developing\nmetrics to measure the regulatory density and strictness of legislation. A\ncomputational method is valuable for scaling the identification of such\nstatements from a growing body of EU legislation, constituting approximately\n180,000 published legal acts between 1952 and 2023. Past work on extraction of\nthese statements varies in the permissiveness of their definitions for what\nconstitutes a regulatory statement. In this work, we provide a specific\ndefinition for our purposes based on the institutional grammar tool. We develop\nand compare two contrasting approaches for automatically identifying such\nstatements in EU legislation, one based on dependency parsing, and the other on\na transformer-based machine learning model. We found both approaches performed\nsimilarly well with accuracies of 80% and 84% respectively and a K alpha of\n0.58. The high accuracies and not exceedingly high agreement suggests potential\nfor combining strengths of both approaches.", "AI": {"tldr": "The paper proposes two computational methods (dependency parsing and transformer-based ML) to identify regulatory statements in EU legislation, achieving 80% and 84% accuracy, respectively, with potential for combining both approaches.", "motivation": "To scale the identification of regulatory statements in the growing body of EU legislation (180,000 acts from 1952-2023) for measuring regulatory density and strictness.", "method": "Two approaches: dependency parsing and a transformer-based machine learning model, compared for accuracy and agreement.", "result": "Both methods performed well (80% and 84% accuracy) with moderate agreement (K alpha 0.58), suggesting complementary strengths.", "conclusion": "Combining both approaches could leverage their strengths for improved regulatory statement identification."}}
{"id": "2505.00455", "pdf": "https://arxiv.org/pdf/2505.00455", "abs": "https://arxiv.org/abs/2505.00455", "authors": ["Sungbok Shin", "Hyeon Jeon", "Sanghyun Hong", "Niklas Elmqvist"], "title": "Data Therapist: Eliciting Domain Knowledge from Subject Matter Experts Using Large Language Models", "categories": ["cs.HC", "cs.AI"], "comment": "Submitted to IEEE VIS2025", "summary": "Effective data visualization requires not only technical proficiency but also\na deep understanding of the domain-specific context in which data exists. This\ncontext often includes tacit knowledge about data provenance, quality, and\nintended use, which is rarely explicit in the dataset itself. We present the\nData Therapist, a web-based tool that helps domain experts externalize this\nimplicit knowledge through a mixed-initiative process combining iterative Q&A\nwith interactive annotation. Powered by a large language model, the system\nanalyzes user-supplied datasets, prompts users with targeted questions, and\nallows annotation at varying levels of granularity. The resulting structured\nknowledge base can inform both human and automated visualization design. We\nevaluated the tool in a qualitative study involving expert pairs from Molecular\nBiology, Accounting, Political Science, and Usable Security. The study revealed\nrecurring patterns in how experts reason about their data and highlights areas\nwhere AI support can improve visualization design.", "AI": {"tldr": "The paper introduces the Data Therapist, a web-based tool leveraging a large language model to help domain experts externalize implicit knowledge about their data through Q&A and annotation, improving visualization design.", "motivation": "Effective data visualization requires domain-specific context, often implicit in datasets. The Data Therapist aims to make this tacit knowledge explicit to enhance visualization design.", "method": "The tool uses a large language model to analyze datasets, prompt users with targeted questions, and enable interactive annotation, creating a structured knowledge base.", "result": "A qualitative study with experts from diverse fields revealed patterns in data reasoning and identified areas where AI can aid visualization design.", "conclusion": "The Data Therapist successfully bridges the gap between implicit domain knowledge and effective visualization, demonstrating the potential of AI in this space."}}
{"id": "2505.00615", "pdf": "https://arxiv.org/pdf/2505.00615", "abs": "https://arxiv.org/abs/2505.00615", "authors": ["Simon Giebenhain", "Tobias Kirschstein", "Martin R\u00fcnz", "Lourdes Agapito", "Matthias Nie\u00dfner"], "title": "Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Project Website: https://simongiebenhain.github.io/pixel3dmm/ ;\n  Video: https://www.youtube.com/watch?v=BwxwEXJwUDc", "summary": "We address the 3D reconstruction of human faces from a single RGB image. To\nthis end, we propose Pixel3DMM, a set of highly-generalized vision transformers\nwhich predict per-pixel geometric cues in order to constrain the optimization\nof a 3D morphable face model (3DMM). We exploit the latent features of the DINO\nfoundation model, and introduce a tailored surface normal and uv-coordinate\nprediction head. We train our model by registering three high-quality 3D face\ndatasets against the FLAME mesh topology, which results in a total of over\n1,000 identities and 976K images. For 3D face reconstruction, we propose a\nFLAME fitting opitmization that solves for the 3DMM parameters from the\nuv-coordinate and normal estimates. To evaluate our method, we introduce a new\nbenchmark for single-image face reconstruction, which features high diversity\nfacial expressions, viewing angles, and ethnicities. Crucially, our benchmark\nis the first to evaluate both posed and neutral facial geometry. Ultimately,\nour method outperforms the most competitive baselines by over 15% in terms of\ngeometric accuracy for posed facial expressions.", "AI": {"tldr": "Pixel3DMM uses vision transformers and DINO features for 3D face reconstruction from a single RGB image, outperforming baselines by 15% in geometric accuracy.", "motivation": "To improve 3D face reconstruction from single images, addressing diversity in expressions, angles, and ethnicities.", "method": "Uses Pixel3DMM with DINO features, surface normal/uv-coordinate prediction, and FLAME optimization on a large dataset.", "result": "Outperforms baselines by 15% in geometric accuracy, especially for posed expressions.", "conclusion": "Pixel3DMM is effective for diverse 3D face reconstruction, setting a new benchmark."}}
{"id": "2505.00415", "pdf": "https://arxiv.org/pdf/2505.00415", "abs": "https://arxiv.org/abs/2505.00415", "authors": ["Tian Lan", "Yifei Gao", "Yimeng Lu", "Chen Zhang"], "title": "CICADA: Cross-Domain Interpretable Coding for Anomaly Detection and Adaptation in Multivariate Time Series", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised Time series anomaly detection plays a crucial role in\napplications across industries. However, existing methods face significant\nchallenges due to data distributional shifts across different domains, which\nare exacerbated by the non-stationarity of time series over time. Existing\nmodels fail to generalize under multiple heterogeneous source domains and\nemerging unseen new target domains. To fill the research gap, we introduce\nCICADA (Cross-domain Interpretable Coding for Anomaly Detection and\nAdaptation), with four key innovations: (1) a mixture of experts (MOE)\nframework that captures domain-agnostic anomaly features with high flexibility\nand interpretability; (2) a novel selective meta-learning mechanism to prevent\nnegative transfer between dissimilar domains, (3) an adaptive expansion\nalgorithm for emerging heterogeneous domain expansion, and (4) a hierarchical\nattention structure that quantifies expert contributions during fusion to\nenhance interpretability further.Extensive experiments on synthetic and\nreal-world industrial datasets demonstrate that CICADA outperforms\nstate-of-the-art methods in both cross-domain detection performance and\ninterpretability.", "AI": {"tldr": "CICADA introduces a novel framework for unsupervised time series anomaly detection, addressing domain shifts and non-stationarity with interpretable, adaptive methods.", "motivation": "Existing methods struggle with data distribution shifts and non-stationarity in time series, failing to generalize across domains.", "method": "CICADA uses a mixture of experts, selective meta-learning, adaptive expansion, and hierarchical attention for interpretable anomaly detection.", "result": "Outperforms state-of-the-art methods in cross-domain detection and interpretability.", "conclusion": "CICADA effectively addresses domain shifts and enhances interpretability in anomaly detection."}}
{"id": "2505.00506", "pdf": "https://arxiv.org/pdf/2505.00506", "abs": "https://arxiv.org/abs/2505.00506", "authors": ["Deanna Emery", "Michael Goitia", "Freddie Vargus", "Iulia Neagu"], "title": "HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in high-stakes\ndomains, detecting hallucinated content$\\unicode{x2013}$text that is not\ngrounded in supporting evidence$\\unicode{x2013}$has become a critical\nchallenge. Existing benchmarks for hallucination detection are often\nsynthetically generated, narrowly focused on extractive question answering, and\nfail to capture the complexity of real-world scenarios involving multi-document\ncontexts and full-sentence outputs. We introduce the HalluMix Benchmark, a\ndiverse, task-agnostic dataset that includes examples from a range of domains\nand formats. Using this benchmark, we evaluate seven hallucination detection\nsystems$\\unicode{x2013}$both open and closed\nsource$\\unicode{x2013}$highlighting differences in performance across tasks,\ndocument lengths, and input representations. Our analysis highlights\nsubstantial performance disparities between short and long contexts, with\ncritical implications for real-world Retrieval Augmented Generation (RAG)\nimplementations. Quotient Detections achieves the best overall performance,\nwith an accuracy of 0.82 and an F1 score of 0.84.", "AI": {"tldr": "The paper introduces HalluMix Benchmark, a diverse dataset for detecting hallucinated content in LLMs, evaluates seven detection systems, and highlights performance disparities, especially in long contexts.", "motivation": "Detecting hallucinated content in LLMs is critical for high-stakes applications, but existing benchmarks are limited and synthetic.", "method": "Developed the HalluMix Benchmark, a task-agnostic dataset, and evaluated seven hallucination detection systems.", "result": "Performance varies by task and context length; Quotient Detections performs best (accuracy 0.82, F1 0.84).", "conclusion": "The HalluMix Benchmark addresses limitations of existing datasets, revealing critical insights for real-world RAG implementations."}}
{"id": "2505.00487", "pdf": "https://arxiv.org/pdf/2505.00487", "abs": "https://arxiv.org/abs/2505.00487", "authors": ["Leonid Legashev", "Artur Zhigalov", "Denis Parfenov"], "title": "Analysis of the vulnerability of machine learning regression models to adversarial attacks using data from 5G wireless networks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This article describes the process of creating a script and conducting an\nanalytical study of a dataset using the DeepMIMO emulator. An advertorial\nattack was carried out using the FGSM method to maximize the gradient. A\ncomparison is made of the effectiveness of binary classifiers in the task of\ndetecting distorted data. The dynamics of changes in the quality indicators of\nthe regression model were analyzed in conditions without adversarial attacks,\nduring an adversarial attack and when the distorted data was isolated. It is\nshown that an adversarial FGSM attack with gradient maximization leads to an\nincrease in the value of the MSE metric by 33% and a decrease in the R2\nindicator by 10% on average. The LightGBM binary classifier effectively\nidentifies data with adversarial anomalies with 98% accuracy. Regression\nmachine learning models are susceptible to adversarial attacks, but rapid\nanalysis of network traffic and data transmitted over the network makes it\npossible to identify malicious activity", "AI": {"tldr": "The paper details adversarial attacks using FGSM on a dataset analyzed via DeepMIMO, showing significant performance degradation in regression models and high accuracy of LightGBM in detecting adversarial anomalies.", "motivation": "To study the impact of adversarial attacks (FGSM) on regression models and evaluate the effectiveness of binary classifiers in detecting such attacks.", "method": "Used DeepMIMO emulator for dataset analysis, applied FGSM for adversarial attacks, and compared binary classifiers (LightGBM) for anomaly detection.", "result": "FGSM attacks increased MSE by 33% and reduced R2 by 10%. LightGBM achieved 98% accuracy in detecting adversarial anomalies.", "conclusion": "Regression models are vulnerable to adversarial attacks, but network traffic analysis can effectively identify malicious activity."}}
{"id": "2505.00619", "pdf": "https://arxiv.org/pdf/2505.00619", "abs": "https://arxiv.org/abs/2505.00619", "authors": ["Neng Dong", "Shuanglin Yan", "Liyan Zhang", "Jinhui Tang"], "title": "Diverse Semantics-Guided Feature Alignment and Decoupling for Visible-Infrared Person Re-Identification", "categories": ["cs.CV"], "comment": null, "summary": "Visible-Infrared Person Re-Identification (VI-ReID) is a challenging task due\nto the large modality discrepancy between visible and infrared images, which\ncomplicates the alignment of their features into a suitable common space.\nMoreover, style noise, such as illumination and color contrast, reduces the\nidentity discriminability and modality invariance of features. To address these\nchallenges, we propose a novel Diverse Semantics-guided Feature Alignment and\nDecoupling (DSFAD) network to align identity-relevant features from different\nmodalities into a textual embedding space and disentangle identity-irrelevant\nfeatures within each modality. Specifically, we develop a Diverse\nSemantics-guided Feature Alignment (DSFA) module, which generates pedestrian\ndescriptions with diverse sentence structures to guide the cross-modality\nalignment of visual features. Furthermore, to filter out style information, we\npropose a Semantic Margin-guided Feature Decoupling (SMFD) module, which\ndecomposes visual features into pedestrian-related and style-related\ncomponents, and then constrains the similarity between the former and the\ntextual embeddings to be at least a margin higher than that between the latter\nand the textual embeddings. Additionally, to prevent the loss of pedestrian\nsemantics during feature decoupling, we design a Semantic Consistency-guided\nFeature Restitution (SCFR) module, which further excavates useful information\nfor identification from the style-related features and restores it back into\nthe pedestrian-related features, and then constrains the similarity between the\nfeatures after restitution and the textual embeddings to be consistent with\nthat between the features before decoupling and the textual embeddings.\nExtensive experiments on three VI-ReID datasets demonstrate the superiority of\nour DSFAD.", "AI": {"tldr": "The paper proposes DSFAD, a network for VI-ReID that aligns and decouples features using textual guidance and semantic margins to address modality discrepancies and style noise.", "motivation": "The large modality discrepancy and style noise in VI-ReID reduce feature alignment and discriminability, necessitating a robust solution.", "method": "DSFAD includes DSFA for cross-modality alignment guided by diverse textual descriptions, SMFD for feature decoupling with semantic margins, and SCFR for semantic restitution.", "result": "Experiments on three datasets show DSFAD's superiority in handling VI-ReID challenges.", "conclusion": "DSFAD effectively aligns and decouples features, improving VI-ReID performance by leveraging textual guidance and semantic constraints."}}
{"id": "2505.00422", "pdf": "https://arxiv.org/pdf/2505.00422", "abs": "https://arxiv.org/abs/2505.00422", "authors": ["Yu Han", "Aaron Ceross", "Jeroen H. M. Bergmann"], "title": "Toward Automated Regulatory Decision-Making: Trustworthy Medical Device Risk Classification with Multimodal Transformers and Self-Training", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Accurate classification of medical device risk levels is essential for\nregulatory oversight and clinical safety. We present a Transformer-based\nmultimodal framework that integrates textual descriptions and visual\ninformation to predict device regulatory classification. The model incorporates\na cross-attention mechanism to capture intermodal dependencies and employs a\nself-training strategy for improved generalization under limited supervision.\nExperiments on a real-world regulatory dataset demonstrate that our approach\nachieves up to 90.4% accuracy and 97.9% AUROC, significantly outperforming\ntext-only (77.2%) and image-only (54.8%) baselines. Compared to standard\nmultimodal fusion, the self-training mechanism improved SVM performance by 3.3\npercentage points in accuracy (from 87.1% to 90.4%) and 1.4 points in macro-F1,\nsuggesting that pseudo-labeling can effectively enhance generalization under\nlimited supervision. Ablation studies further confirm the complementary\nbenefits of both cross-modal attention and self-training.", "AI": {"tldr": "A Transformer-based multimodal framework integrates text and images to classify medical device risk levels, achieving high accuracy (90.4%) and AUROC (97.9%) with cross-attention and self-training.", "motivation": "Accurate classification of medical device risk levels is crucial for regulatory oversight and clinical safety.", "method": "A Transformer-based multimodal framework with cross-attention and self-training integrates textual and visual data.", "result": "The model achieves 90.4% accuracy and 97.9% AUROC, outperforming text-only (77.2%) and image-only (54.8%) baselines. Self-training improves SVM performance by 3.3% in accuracy.", "conclusion": "Cross-modal attention and self-training enhance generalization, with pseudo-labeling proving effective under limited supervision."}}
{"id": "2505.00551", "pdf": "https://arxiv.org/pdf/2505.00551", "abs": "https://arxiv.org/abs/2505.00551", "authors": ["Chong Zhang", "Yue Deng", "Xiang Lin", "Bin Wang", "Dianwen Ng", "Hai Ye", "Xingxuan Li", "Yao Xiao", "Zhanfeng Mo", "Qi Zhang", "Lidong Bing"], "title": "100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The recent development of reasoning language models (RLMs) represents a novel\nevolution in large language models. In particular, the recent release of\nDeepSeek-R1 has generated widespread social impact and sparked enthusiasm in\nthe research community for exploring the explicit reasoning paradigm of\nlanguage models. However, the implementation details of the released models\nhave not been fully open-sourced by DeepSeek, including DeepSeek-R1-Zero,\nDeepSeek-R1, and the distilled small models. As a result, many replication\nstudies have emerged aiming to reproduce the strong performance achieved by\nDeepSeek-R1, reaching comparable performance through similar training\nprocedures and fully open-source data resources. These works have investigated\nfeasible strategies for supervised fine-tuning (SFT) and reinforcement learning\nfrom verifiable rewards (RLVR), focusing on data preparation and method design,\nyielding various valuable insights. In this report, we provide a summary of\nrecent replication studies to inspire future research. We primarily focus on\nSFT and RLVR as two main directions, introducing the details for data\nconstruction, method design and training procedure of current replication\nstudies. Moreover, we conclude key findings from the implementation details and\nexperimental results reported by these studies, anticipating to inspire future\nresearch. We also discuss additional techniques of enhancing RLMs, highlighting\nthe potential of expanding the application scope of these models, and\ndiscussing the challenges in development. By this survey, we aim to help\nresearchers and developers of RLMs stay updated with the latest advancements,\nand seek to inspire new ideas to further enhance RLMs.", "AI": {"tldr": "The paper summarizes replication studies of DeepSeek-R1, focusing on SFT and RLVR, and discusses key findings and future directions for reasoning language models.", "motivation": "To inspire future research by summarizing recent replication studies of DeepSeek-R1 and highlighting advancements in reasoning language models.", "method": "Focuses on supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR), detailing data construction, method design, and training procedures.", "result": "Identifies valuable insights from replication studies and discusses techniques to enhance reasoning language models.", "conclusion": "The survey aims to keep researchers updated and inspire new ideas for advancing reasoning language models, while acknowledging development challenges."}}
{"id": "2505.00488", "pdf": "https://arxiv.org/pdf/2505.00488", "abs": "https://arxiv.org/abs/2505.00488", "authors": ["Vamshi Kumar Kurva", "Shishir Kolathaya"], "title": "MULE: Multi-terrain and Unknown Load Adaptation for Effective Quadrupedal Locomotion", "categories": ["cs.RO", "cs.AI"], "comment": "Preprint under review", "summary": "Quadrupedal robots are increasingly deployed for load-carrying tasks across\ndiverse terrains. While Model Predictive Control (MPC)-based methods can\naccount for payload variations, they often depend on predefined gait schedules\nor trajectory generators, limiting their adaptability in unstructured\nenvironments. To address these limitations, we propose an Adaptive\nReinforcement Learning (RL) framework that enables quadrupedal robots to\ndynamically adapt to both varying payloads and diverse terrains. The framework\nconsists of a nominal policy responsible for baseline locomotion and an\nadaptive policy that learns corrective actions to preserve stability and\nimprove command tracking under payload variations. We validate the proposed\napproach through large-scale simulation experiments in Isaac Gym and real-world\nhardware deployment on a Unitree Go1 quadruped. The controller was tested on\nflat ground, slopes, and stairs under both static and dynamic payload changes.\nAcross all settings, our adaptive controller consistently outperformed the\ncontroller in tracking body height and velocity commands, demonstrating\nenhanced robustness and adaptability without requiring explicit gait design or\nmanual tuning.", "AI": {"tldr": "An Adaptive RL framework enables quadrupedal robots to dynamically adapt to payload and terrain variations, outperforming MPC-based methods without predefined gaits.", "motivation": "MPC-based methods for load-carrying quadrupedal robots rely on predefined gaits, limiting adaptability in unstructured environments.", "method": "Proposes an Adaptive RL framework with a nominal policy for baseline locomotion and an adaptive policy for corrective actions under payload changes.", "result": "Validated in simulations and real-world tests, the adaptive controller outperformed in tracking commands across diverse terrains and payloads.", "conclusion": "The framework enhances robustness and adaptability without manual tuning or explicit gait design."}}
{"id": "2505.00627", "pdf": "https://arxiv.org/pdf/2505.00627", "abs": "https://arxiv.org/abs/2505.00627", "authors": ["Zhongying Deng", "Haoyu Wang", "Ziyan Huang", "Lipei Zhang", "Angelica I. Aviles-Rivero", "Chaoyu Liu", "Junjun He", "Zoe Kourtzi", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Brain Foundation Models with Hypergraph Dynamic Adapter for Brain Disease Analysis", "categories": ["cs.CV"], "comment": "35 pages, 4 figures", "summary": "Brain diseases, such as Alzheimer's disease and brain tumors, present\nprofound challenges due to their complexity and societal impact. Recent\nadvancements in brain foundation models have shown significant promise in\naddressing a range of brain-related tasks. However, current brain foundation\nmodels are limited by task and data homogeneity, restricted generalization\nbeyond segmentation or classification, and inefficient adaptation to diverse\nclinical tasks. In this work, we propose SAM-Brain3D, a brain-specific\nfoundation model trained on over 66,000 brain image-label pairs across 14 MRI\nsub-modalities, and Hypergraph Dynamic Adapter (HyDA), a lightweight adapter\nfor efficient and effective downstream adaptation. SAM-Brain3D captures\ndetailed brain-specific anatomical and modality priors for segmenting diverse\nbrain targets and broader downstream tasks. HyDA leverages hypergraphs to fuse\ncomplementary multi-modal data and dynamically generate patient-specific\nconvolutional kernels for multi-scale feature fusion and personalized\npatient-wise adaptation. Together, our framework excels across a broad spectrum\nof brain disease segmentation and classification tasks. Extensive experiments\ndemonstrate that our method consistently outperforms existing state-of-the-art\napproaches, offering a new paradigm for brain disease analysis through\nmulti-modal, multi-scale, and dynamic foundation modeling.", "AI": {"tldr": "SAM-Brain3D and HyDA propose a brain-specific foundation model and lightweight adapter for efficient adaptation, outperforming state-of-the-art methods in brain disease tasks.", "motivation": "Address limitations of current brain foundation models, such as task/data homogeneity and poor generalization, to improve brain disease analysis.", "method": "Develop SAM-Brain3D (trained on 66,000 brain image-label pairs) and HyDA (a hypergraph-based adapter) for multi-modal, multi-scale, and dynamic adaptation.", "result": "Outperforms existing methods in brain disease segmentation and classification tasks.", "conclusion": "The framework offers a new paradigm for brain disease analysis through advanced foundation modeling."}}
{"id": "2505.00466", "pdf": "https://arxiv.org/pdf/2505.00466", "abs": "https://arxiv.org/abs/2505.00466", "authors": ["Thomas Flinkow", "Marco Casadio", "Colin Kessler", "Rosemary Monahan", "Ekaterina Komendantskaya"], "title": "A Generalised Framework for Property-Driven Machine Learning", "categories": ["cs.LG", "cs.LO"], "comment": "22 pages, 4 tables, 4 figures. Submitted to AI Verification 2025", "summary": "Neural networks have been shown to frequently fail to satisfy critical safety\nand correctness properties after training, highlighting the pressing need for\ntraining methods that incorporate such properties directly. While adversarial\ntraining can be used to improve robustness to small perturbations within\n$\\epsilon$-cubes, domains other than computer vision -- such as control systems\nand natural language processing -- may require more flexible input region\nspecifications via generalised hyper-rectangles. Meanwhile, differentiable\nlogics offer a way to encode arbitrary logical constraints as additional loss\nterms that guide the learning process towards satisfying these constraints. In\nthis paper, we investigate how these two complementary approaches can be\nunified within a single framework for property-driven machine learning. We show\nthat well-known properties from the literature are subcases of this general\napproach, and we demonstrate its practical effectiveness on a case study\ninvolving a neural network controller for a drone system. Our framework is\npublicly available at https://github.com/tflinkow/property-driven-ml.", "AI": {"tldr": "The paper proposes a unified framework combining adversarial training and differentiable logics for property-driven machine learning, demonstrating its effectiveness on a drone control system.", "motivation": "Neural networks often fail to meet safety and correctness properties post-training, necessitating methods that incorporate such properties directly during training.", "method": "The framework unifies adversarial training (for robustness) and differentiable logics (for encoding logical constraints) to guide learning.", "result": "The approach generalizes known properties and proves effective in a drone controller case study.", "conclusion": "The unified framework offers a practical solution for property-driven machine learning, with code publicly available."}}
{"id": "2505.00557", "pdf": "https://arxiv.org/pdf/2505.00557", "abs": "https://arxiv.org/abs/2505.00557", "authors": ["Makoto Sato"], "title": "Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hallucinations in large language models (LLMs) present a growing challenge\nacross real-world applications, from healthcare to law, where factual\nreliability is essential. Despite advances in alignment and instruction tuning,\nLLMs can still generate outputs that are fluent yet fundamentally untrue.\nUnderstanding the cognitive dynamics that underlie these hallucinations remains\nan open problem. In this study, we propose a prompt-based framework to\nsystematically trigger and quantify hallucination: a Hallucination-Inducing\nPrompt (HIP), which synthetically fuses semantically distant concepts (e.g.,\nperiodic table of elements and tarot divination) in a misleading way, and a\nHallucination Quantifying Prompt (HQP), which scores the plausibility,\nconfidence, and coherence of the output. Controlled experiments across multiple\nLLMs revealed that HIPs consistently produced less coherent and more\nhallucinated responses than their null-fusion controls. These effects varied\nacross models, with reasoning-oriented LLMs showing distinct profiles from\ngeneral-purpose ones. Our framework provides a reproducible testbed for\nstudying hallucination vulnerability, and opens the door to developing safer,\nmore introspective LLMs that can detect and self-regulate the onset of\nconceptual instability.", "AI": {"tldr": "A framework using Hallucination-Inducing and Quantifying Prompts (HIP/HQP) to systematically trigger and measure hallucinations in LLMs, revealing model-specific vulnerabilities.", "motivation": "Address the challenge of factual unreliability in LLMs, despite alignment efforts, by understanding and quantifying hallucination dynamics.", "method": "Propose HIP to synthetically fuse unrelated concepts and HQP to score output plausibility, confidence, and coherence. Tested across multiple LLMs.", "result": "HIPs consistently produced more incoherent and hallucinated responses, with variations across model types (reasoning vs. general-purpose).", "conclusion": "The framework offers a reproducible testbed for studying hallucinations, aiding development of safer, self-regulating LLMs."}}
{"id": "2505.00490", "pdf": "https://arxiv.org/pdf/2505.00490", "abs": "https://arxiv.org/abs/2505.00490", "authors": ["Shivam Vats", "Michelle Zhao", "Patrick Callaghan", "Mingxi Jia", "Maxim Likhachev", "Oliver Kroemer", "George Konidaris"], "title": "Optimal Interactive Learning on the Job via Facility Location Planning", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted to Robotics: Science and Systems (RSS) 2025", "summary": "Collaborative robots must continually adapt to novel tasks and user\npreferences without overburdening the user. While prior interactive robot\nlearning methods aim to reduce human effort, they are typically limited to\nsingle-task scenarios and are not well-suited for sustained, multi-task\ncollaboration. We propose COIL (Cost-Optimal Interactive Learning) -- a\nmulti-task interaction planner that minimizes human effort across a sequence of\ntasks by strategically selecting among three query types (skill, preference,\nand help). When user preferences are known, we formulate COIL as an\nuncapacitated facility location (UFL) problem, which enables bounded-suboptimal\nplanning in polynomial time using off-the-shelf approximation algorithms. We\nextend our formulation to handle uncertainty in user preferences by\nincorporating one-step belief space planning, which uses these approximation\nalgorithms as subroutines to maintain polynomial-time performance. Simulated\nand physical experiments on manipulation tasks show that our framework\nsignificantly reduces the amount of work allocated to the human while\nmaintaining successful task completion.", "AI": {"tldr": "COIL is a multi-task interaction planner for collaborative robots that minimizes human effort by strategically selecting query types (skill, preference, help). It uses UFL for known preferences and belief space planning for uncertainty, reducing human workload while ensuring task success.", "motivation": "Collaborative robots need to adapt to novel tasks and user preferences without overburdening users. Existing methods are limited to single-task scenarios and lack suitability for multi-task collaboration.", "method": "COIL formulates planning as an uncapacitated facility location (UFL) problem for known preferences and extends it with one-step belief space planning for uncertainty. It uses approximation algorithms for polynomial-time performance.", "result": "Simulated and physical experiments on manipulation tasks show COIL significantly reduces human effort while maintaining successful task completion.", "conclusion": "COIL effectively minimizes human workload in multi-task collaboration by strategically planning interactions, demonstrating practical utility in real-world scenarios."}}
{"id": "2505.00630", "pdf": "https://arxiv.org/pdf/2505.00630", "abs": "https://arxiv.org/abs/2505.00630", "authors": ["Muyi Bao", "Shuchang Lyu", "Zhaoyang Xu", "Huiyu Zhou", "Jinchang Ren", "Shiming Xiang", "Xiangtai Li", "Guangliang Cheng"], "title": "Vision Mamba in Remote Sensing: A Comprehensive Survey of Techniques, Applications and Outlook", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning has profoundly transformed remote sensing, yet prevailing\narchitectures like Convolutional Neural Networks (CNNs) and Vision Transformers\n(ViTs) remain constrained by critical trade-offs: CNNs suffer from limited\nreceptive fields, while ViTs grapple with quadratic computational complexity,\nhindering their scalability for high-resolution remote sensing data. State\nSpace Models (SSMs), particularly the recently proposed Mamba architecture,\nhave emerged as a paradigm-shifting solution, combining linear computational\nscaling with global context modeling. This survey presents a comprehensive\nreview of Mamba-based methodologies in remote sensing, systematically analyzing\nabout 120 studies to construct a holistic taxonomy of innovations and\napplications. Our contributions are structured across five dimensions: (i)\nfoundational principles of vision Mamba architectures, (ii) micro-architectural\nadvancements such as adaptive scan strategies and hybrid SSM formulations,\n(iii) macro-architectural integrations, including CNN-Transformer-Mamba hybrids\nand frequency-domain adaptations, (iv) rigorous benchmarking against\nstate-of-the-art methods in multiple application tasks, such as object\ndetection, semantic segmentation, change detection, etc. and (v) critical\nanalysis of unresolved challenges with actionable future directions. By\nbridging the gap between SSM theory and remote sensing practice, this survey\nestablishes Mamba as a transformative framework for remote sensing analysis. To\nour knowledge, this paper is the first systematic review of Mamba architectures\nin remote sensing. Our work provides a structured foundation for advancing\nresearch in remote sensing systems through SSM-based methods. We curate an\nopen-source repository\n(https://github.com/BaoBao0926/Awesome-Mamba-in-Remote-Sensing) to foster\ncommunity-driven advancements.", "AI": {"tldr": "The paper reviews Mamba-based methodologies in remote sensing, highlighting their advantages over CNNs and ViTs, and provides a taxonomy of innovations, benchmarking, and future directions.", "motivation": "To address the limitations of CNNs (limited receptive fields) and ViTs (quadratic complexity) in remote sensing by exploring Mamba architectures, which offer linear scaling and global context.", "method": "A comprehensive review of 120 studies, analyzing Mamba-based innovations across five dimensions: foundational principles, micro-architectural advancements, macro-architectural integrations, benchmarking, and unresolved challenges.", "result": "Mamba is established as a transformative framework for remote sensing, with a taxonomy of advancements and open-source resources provided.", "conclusion": "The survey bridges SSM theory and remote sensing practice, offering a foundation for future research and community-driven progress."}}
{"id": "2505.00473", "pdf": "https://arxiv.org/pdf/2505.00473", "abs": "https://arxiv.org/abs/2505.00473", "authors": ["Shuwen Sun", "Lihong Feng", "Peter Benner"], "title": "Interpretable Spatial-Temporal Fusion Transformers: Multi-Output Prediction for Parametric Dynamical Systems with Time-Varying Inputs", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We explore the promising performance of a transformer model in predicting\noutputs of parametric dynamical systems with external time-varying input\nsignals. The outputs of such systems vary not only with physical parameters but\nalso with external time-varying input signals. Accurately catching the dynamics\nof such systems is challenging. We have adapted and extended an existing\ntransformer model for single output prediction to a multiple-output transformer\nthat is able to predict multiple output responses of these systems. The\nmultiple-output transformer generalizes the interpretability of the original\ntransformer. The generalized interpretable attention weight matrix explores not\nonly the temporal correlations in the sequence, but also the interactions\nbetween the multiple outputs, providing explanation for the spatial correlation\nin the output domain. This multiple-output transformer accurately predicts the\nsequence of multiple outputs, regardless of the nonlinearity of the system and\nthe dimensionality of the parameter space.", "AI": {"tldr": "A transformer model is adapted for predicting multiple outputs of parametric dynamical systems with time-varying inputs, improving interpretability and accuracy.", "motivation": "To address the challenge of predicting outputs of systems influenced by both physical parameters and external time-varying signals.", "method": "Extended a single-output transformer to a multiple-output transformer, using interpretable attention weights to analyze temporal and spatial correlations.", "result": "The model accurately predicts multiple outputs, handling nonlinearity and high-dimensional parameter spaces effectively.", "conclusion": "The multiple-output transformer offers a robust and interpretable solution for complex dynamical system predictions."}}
{"id": "2505.00570", "pdf": "https://arxiv.org/pdf/2505.00570", "abs": "https://arxiv.org/abs/2505.00570", "authors": ["Jushi Kai", "Boyi Zeng", "Yixuan Wang", "Haoli Bai", "Bo Jiang", "Zhouhan Lin"], "title": "FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Extending the context window in large language models (LLMs) is essential for\napplications involving long-form content generation. However, the linear\nincrease in key-value (KV) cache memory requirements and the quadratic\ncomplexity of self-attention with respect to sequence length present\nsignificant challenges during fine-tuning and inference. Existing methods\nsuffer from performance degradation when extending to longer contexts. In this\nwork, we introduce a novel context extension method that optimizes both\nfine-tuning and inference efficiency. Our method exploits a key observation: in\nthe frequency domain, the energy distribution of the KV cache is primarily\nconcentrated in low-frequency components. By filtering out the high-frequency\ncomponents, the KV cache can be effectively compressed with minimal information\nloss. Building on this insight, we propose an efficient compression technique,\nFreqKV, that iteratively compresses the increasing KV cache to a fixed size in\nthe frequency domain, applicable to both fine-tuning and inference. FreqKV\nintroduces no additional parameters or architectural modifications. With\nminimal fine-tuning, LLMs can learn to leverage the limited cache that is\ncompressed in the frequency domain and extend the context window efficiently.\nExperiments on various long context language modeling and understanding tasks\ndemonstrate the efficiency and efficacy of the proposed method.", "AI": {"tldr": "The paper introduces FreqKV, a method to compress the KV cache in LLMs by focusing on low-frequency components, enabling efficient context window extension without performance degradation.", "motivation": "Extending context windows in LLMs is challenging due to memory and computational constraints, with existing methods often degrading performance.", "method": "FreqKV compresses the KV cache by filtering high-frequency components in the frequency domain, maintaining efficiency without architectural changes.", "result": "Experiments show FreqKV effectively extends context windows with minimal fine-tuning and no performance loss.", "conclusion": "FreqKV offers a practical solution for efficient long-context handling in LLMs."}}
{"id": "2505.00503", "pdf": "https://arxiv.org/pdf/2505.00503", "abs": "https://arxiv.org/abs/2505.00503", "authors": ["Ke Jiang", "Wen Jiang", "Xiaoyang Tan"], "title": "Variational OOD State Correction for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "The performance of Offline reinforcement learning is significantly impacted\nby the issue of state distributional shift, and out-of-distribution (OOD) state\ncorrection is a popular approach to address this problem. In this paper, we\npropose a novel method named Density-Aware Safety Perception (DASP) for OOD\nstate correction. Specifically, our method encourages the agent to prioritize\nactions that lead to outcomes with higher data density, thereby promoting its\noperation within or the return to in-distribution (safe) regions. To achieve\nthis, we optimize the objective within a variational framework that\nconcurrently considers both the potential outcomes of decision-making and their\ndensity, thus providing crucial contextual information for safe\ndecision-making. Finally, we validate the effectiveness and feasibility of our\nproposed method through extensive experimental evaluations on the offline\nMuJoCo and AntMaze suites.", "AI": {"tldr": "Proposes Density-Aware Safety Perception (DASP) for OOD state correction in offline RL, prioritizing actions leading to higher data density for safer decisions.", "motivation": "Addresses state distributional shift in offline RL by focusing on OOD state correction to ensure safer agent operation.", "method": "Uses a variational framework to optimize actions based on outcome density, promoting in-distribution regions.", "result": "Validated effectiveness on offline MuJoCo and AntMaze suites.", "conclusion": "DASP successfully improves safety and performance in offline RL by addressing OOD states."}}
{"id": "2505.00668", "pdf": "https://arxiv.org/pdf/2505.00668", "abs": "https://arxiv.org/abs/2505.00668", "authors": ["Kirtan Rajesh", "Suvidha Rupesh Kumar"], "title": "Deep Reinforcement Learning for Urban Air Quality Management: Multi-Objective Optimization of Pollution Mitigation Booth Placement in Metropolitan Environments", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Urban air pollution remains a pressing global concern, particularly in\ndensely populated and traffic-intensive metropolitan areas like Delhi, where\nexposure to harmful pollutants severely impacts public health. Delhi, being one\nof the most polluted cities globally, experiences chronic air quality issues\ndue to vehicular emissions, industrial activities, and construction dust, which\nexacerbate its already fragile atmospheric conditions. Traditional pollution\nmitigation strategies, such as static air purifying installations, often fail\nto maximize their impact due to suboptimal placement and limited adaptability\nto dynamic urban environments. This study presents a novel deep reinforcement\nlearning (DRL) framework to optimize the placement of air purification booths\nto improve the air quality index (AQI) in the city of Delhi. We employ Proximal\nPolicy Optimization (PPO), a state-of-the-art reinforcement learning algorithm,\nto iteratively learn and identify high-impact locations based on multiple\nspatial and environmental factors, including population density, traffic\npatterns, industrial influence, and green space constraints. Our approach is\nbenchmarked against conventional placement strategies, including random and\ngreedy AQI-based methods, using multi-dimensional performance evaluation\nmetrics such as AQI improvement, spatial coverage, population and traffic\nimpact, and spatial entropy. Experimental results demonstrate that the RL-based\napproach outperforms baseline methods by achieving a balanced and effective\ndistribution of air purification infrastructure. Notably, the DRL framework\nachieves an optimal trade-off between AQI reduction and high-coverage\ndeployment, ensuring equitable environmental benefits across urban regions. The\nfindings underscore the potential of AI-driven spatial optimization in\nadvancing smart city initiatives and data-driven urban air quality management.", "AI": {"tldr": "A DRL framework optimizes air purification booth placement in Delhi, outperforming traditional methods by balancing AQI reduction and spatial coverage.", "motivation": "Urban air pollution in Delhi is severe, and static mitigation strategies are ineffective. A dynamic, data-driven approach is needed.", "method": "Proximal Policy Optimization (PPO) is used to iteratively learn optimal booth placements based on spatial and environmental factors.", "result": "The DRL framework outperforms baseline methods, achieving balanced AQI reduction and high-coverage deployment.", "conclusion": "AI-driven spatial optimization can enhance smart city initiatives and urban air quality management."}}
{"id": "2505.00495", "pdf": "https://arxiv.org/pdf/2505.00495", "abs": "https://arxiv.org/abs/2505.00495", "authors": ["Nguyen Van Thanh", "Nguyen Dang Huynh", "Nguyen Ngoc Tan", "Nguyen Thai Minh", "Nguyen Nam Hoang"], "title": "Enhancing Tropical Cyclone Path Forecasting with an Improved Transformer Network", "categories": ["cs.LG", "cs.PF"], "comment": null, "summary": "A storm is a type of extreme weather. Therefore, forecasting the path of a\nstorm is extremely important for protecting human life and property. However,\nstorm forecasting is very challenging because storm trajectories frequently\nchange. In this study, we propose an improved deep learning method using a\nTransformer network to predict the movement trajectory of a storm over the next\n6 hours. The storm data used to train the model was obtained from the National\nOceanic and Atmospheric Administration (NOAA) [1]. Simulation results show that\nthe proposed method is more accurate than traditional methods. Moreover, the\nproposed method is faster and more cost-effective", "AI": {"tldr": "An improved deep learning method using a Transformer network is proposed for accurate and efficient 6-hour storm trajectory prediction.", "motivation": "Forecasting storm paths is critical for safeguarding life and property, but it's challenging due to their unpredictable trajectories.", "method": "The study employs a Transformer network trained on NOAA storm data to predict storm movement.", "result": "The proposed method outperforms traditional techniques in accuracy, speed, and cost-effectiveness.", "conclusion": "The Transformer-based approach offers a superior solution for storm trajectory forecasting."}}
{"id": "2505.00582", "pdf": "https://arxiv.org/pdf/2505.00582", "abs": "https://arxiv.org/abs/2505.00582", "authors": ["Xinyu Ding", "Meiqi Wang", "Siyu Liao", "Zhongfeng Wang"], "title": "Block Circulant Adapter for Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "to appear in Proceedings of the 2025 International Joint Conference\n  on Artificial Intelligence (IJCAI-2025)", "summary": "Fine-tuning large language models (LLMs) is difficult due to their huge model\nsize. Recent Fourier domain-based methods show potential for reducing\nfine-tuning costs. We propose a block circulant matrix-based fine-tuning method\nwith a stable training heuristic to leverage the properties of circulant\nmatrices and one-dimensional Fourier transforms to reduce storage and\ncomputation costs. Experiments show that our method uses $14\\times$ less number\nof parameters than VeRA, $16\\times$ smaller than LoRA and $32\\times$ less FLOPs\nthan FourierFT, while maintaining close or better task performance. Our\napproach presents a promising way in frequency domain to fine-tune large models\non downstream tasks.", "AI": {"tldr": "A block circulant matrix-based fine-tuning method for LLMs reduces storage and computation costs significantly while maintaining performance.", "motivation": "Fine-tuning large language models is challenging due to their size, and existing methods like VeRA, LoRA, and FourierFT are inefficient.", "method": "Uses block circulant matrices and one-dimensional Fourier transforms to reduce costs. Includes a stable training heuristic.", "result": "Achieves 14\u00d7 fewer parameters than VeRA, 16\u00d7 smaller than LoRA, and 32\u00d7 fewer FLOPs than FourierFT, with comparable or better performance.", "conclusion": "The method offers an efficient frequency-domain approach for fine-tuning large models on downstream tasks."}}
{"id": "2505.00533", "pdf": "https://arxiv.org/pdf/2505.00533", "abs": "https://arxiv.org/abs/2505.00533", "authors": ["Linjing You", "Jiabao Lu", "Xiayuan Huang"], "title": "Test-time Correlation Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML2025", "summary": "Deep neural networks often experience performance drops due to distribution\nshifts between training and test data. Although domain adaptation offers a\nsolution, privacy concerns restrict access to training data in many real-world\nscenarios. This restriction has spurred interest in Test-Time Adaptation (TTA),\nwhich adapts models using only unlabeled test data. However, current TTA\nmethods still face practical challenges: (1) a primary focus on instance-wise\nalignment, overlooking CORrelation ALignment (CORAL) due to missing source\ncorrelations; (2) complex backpropagation operations for model updating,\nresulting in overhead computation and (3) domain forgetting.\n  To address these challenges, we provide a theoretical analysis to investigate\nthe feasibility of Test-time Correlation Alignment (TCA), demonstrating that\ncorrelation alignment between high-certainty instances and test instances can\nenhance test performances with a theoretical guarantee. Based on this, we\npropose two simple yet effective algorithms: LinearTCA and LinearTCA+.\nLinearTCA applies a simple linear transformation to achieve both instance and\ncorrelation alignment without additional model updates, while LinearTCA+ serves\nas a plug-and-play module that can easily boost existing TTA methods. Extensive\nexperiments validate our theoretical insights and show that TCA methods\nsignificantly outperforms baselines across various tasks, benchmarks and\nbackbones. Notably, LinearTCA improves adaptation accuracy by 5.88% on\nOfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6%\ncomputation time compared to the best baseline TTA method.", "AI": {"tldr": "The paper introduces Test-time Correlation Alignment (TCA) to address challenges in Test-Time Adaptation (TTA), proposing two efficient algorithms (LinearTCA and LinearTCA+) that outperform existing methods with minimal computational overhead.", "motivation": "Performance drops in deep neural networks due to distribution shifts and privacy concerns limiting access to training data motivate the need for TTA methods that avoid complex computations and domain forgetting.", "method": "The authors propose TCA, aligning correlations between high-certainty and test instances, and introduce LinearTCA (a linear transformation for alignment) and LinearTCA+ (a plug-and-play enhancement for existing TTA methods).", "result": "Experiments show TCA methods outperform baselines, with LinearTCA improving accuracy by 5.88% on OfficeHome while using only 4% GPU memory and 0.6% computation time of the best baseline.", "conclusion": "TCA offers a theoretically grounded, efficient solution for TTA, achieving superior performance with minimal resource usage."}}
{"id": "2505.00684", "pdf": "https://arxiv.org/pdf/2505.00684", "abs": "https://arxiv.org/abs/2505.00684", "authors": ["Tiange Luo", "Lajanugen Logeswaran", "Justin Johnson", "Honglak Lee"], "title": "Visual Test-time Scaling for GUI Agent Grounding", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce RegionFocus, a visual test-time scaling approach for Vision\nLanguage Model Agents. Understanding webpages is challenging due to the visual\ncomplexity of GUI images and the large number of interface elements, making\naccurate action selection difficult. Our approach dynamically zooms in on\nrelevant regions, reducing background clutter and improving grounding accuracy.\nTo support this process, we propose an image-as-map mechanism that visualizes\nkey landmarks at each step, providing a transparent action record and enables\nthe agent to effectively choose among action candidates. Even with a simple\nregion selection strategy, we observe significant performance gains of 28+\\% on\nScreenspot-pro and 24+\\% on WebVoyager benchmarks on top of two\nstate-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL,\nhighlighting the effectiveness of visual test-time scaling in interactive\nsettings. We achieve a new state-of-the-art grounding performance of 61.6\\% on\nthe ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model.\nOur code will be released publicly at https://github.com/tiangeluo/RegionFocus.", "AI": {"tldr": "RegionFocus is a visual test-time scaling method for Vision Language Model Agents that dynamically zooms in on relevant webpage regions to improve grounding accuracy, achieving significant performance gains.", "motivation": "Understanding complex webpages is difficult due to visual clutter and numerous interface elements, leading to inaccurate action selection.", "method": "The approach uses dynamic zooming on relevant regions and an image-as-map mechanism to visualize landmarks, aiding action selection.", "result": "Performance improved by 28% on Screenspot-pro and 24% on WebVoyager benchmarks, with a new SOTA grounding accuracy of 61.6%.", "conclusion": "RegionFocus effectively enhances grounding accuracy in interactive settings, demonstrating the value of visual test-time scaling."}}
{"id": "2505.00509", "pdf": "https://arxiv.org/pdf/2505.00509", "abs": "https://arxiv.org/abs/2505.00509", "authors": ["Jeremias Ferrao", "Luhan Mikaelson", "Keenan Pepper", "Natalia Perez-Campanero Antolin"], "title": "Self-Ablating Transformers: More Interpretability, Less Sparsity", "categories": ["cs.LG"], "comment": "Poster Presentation at Building Trust Workshop at ICLR 2025", "summary": "A growing intuition in machine learning suggests a link between sparsity and\ninterpretability. We introduce a novel self-ablation mechanism to investigate\nthis connection ante-hoc in the context of language transformers. Our approach\ndynamically enforces a k-winner-takes-all constraint, forcing the model to\ndemonstrate selective activation across neuron and attention units. Unlike\npost-hoc methods that analyze already-trained models, our approach integrates\ninterpretability directly into model training, promoting feature localization\nfrom inception. Training small models on the TinyStories dataset and employing\ninterpretability tests, we find that self-ablation leads to more localized\ncircuits, concentrated feature representations, and increased neuron\nspecialization without compromising language modelling performance.\nSurprisingly, our method also decreased overall sparsity, indicating that\nself-ablation promotes specialization rather than widespread inactivity. This\nreveals a complex interplay between sparsity and interpretability, where\ndecreased global sparsity can coexist with increased local specialization,\nleading to enhanced interpretability. To facilitate reproducibility, we make\nour code available at\nhttps://github.com/keenanpepper/self-ablating-transformers.", "AI": {"tldr": "The paper introduces a self-ablation mechanism for transformers to study sparsity-interpretability links, showing improved feature localization and specialization without performance loss.", "motivation": "To explore the connection between sparsity and interpretability in machine learning, specifically in language transformers.", "method": "A novel self-ablation mechanism enforces selective activation during training, tested on TinyStories with interpretability metrics.", "result": "Self-ablation increases feature localization, neuron specialization, and interpretability, while reducing global sparsity.", "conclusion": "Sparsity and interpretability have a nuanced relationship; self-ablation enhances interpretability by promoting local specialization over inactivity."}}
{"id": "2505.00624", "pdf": "https://arxiv.org/pdf/2505.00624", "abs": "https://arxiv.org/abs/2505.00624", "authors": ["Chaitali Bhattacharyya", "Yeseong Kim"], "title": "FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Training large language models (LLMs) from scratch requires significant\ncomputational resources, driving interest in developing smaller,\ndomain-specific LLMs that maintain both efficiency and strong task performance.\nMedium-sized models such as LLaMA, llama} have served as starting points for\ndomain-specific adaptation, but they often suffer from accuracy degradation\nwhen tested on specialized datasets. We introduce FineScope, a framework for\nderiving compact, domain-optimized LLMs from larger pretrained models.\nFineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its\nability to produce interpretable feature representations, to extract\ndomain-specific subsets from large datasets. We apply structured pruning with\ndomain-specific constraints, ensuring that the resulting pruned models retain\nessential knowledge for the target domain. To further enhance performance,\nthese pruned models undergo self-data distillation, leveraging SAE-curated\ndatasets to restore key domain-specific information lost during pruning.\nExtensive experiments and ablation studies demonstrate that FineScope achieves\nhighly competitive performance, outperforming several large-scale\nstate-of-the-art LLMs in domain-specific tasks. Additionally, our results show\nthat FineScope enables pruned models to regain a substantial portion of their\noriginal performance when fine-tuned with SAE-curated datasets. Furthermore,\napplying these datasets to fine-tune pretrained LLMs without pruning also\nimproves their domain-specific accuracy, highlighting the robustness of our\napproach. The code will be released.", "AI": {"tldr": "FineScope is a framework for creating compact, domain-specific LLMs from larger models using Sparse Autoencoder and structured pruning, achieving competitive performance in specialized tasks.", "motivation": "Large LLMs require significant resources, and smaller domain-specific models often lose accuracy. FineScope aims to address this by optimizing domain-specific performance efficiently.", "method": "Uses Sparse Autoencoder (SAE) for feature extraction, structured pruning with domain constraints, and self-data distillation with SAE-curated datasets.", "result": "Outperforms large-scale LLMs in domain tasks, regains performance post-pruning, and improves accuracy even without pruning.", "conclusion": "FineScope effectively optimizes domain-specific LLMs, balancing efficiency and performance, with potential for broader application."}}
{"id": "2505.00555", "pdf": "https://arxiv.org/pdf/2505.00555", "abs": "https://arxiv.org/abs/2505.00555", "authors": ["Jean-Baptiste A. Conan"], "title": "On the Mechanistic Interpretability of Neural Networks for Causality in Bio-statistics", "categories": ["stat.AP", "cs.AI"], "comment": null, "summary": "Interpretable insights from predictive models remain critical in\nbio-statistics, particularly when assessing causality, where classical\nstatistical and machine learning methods often provide inherent clarity. While\nNeural Networks (NNs) offer powerful capabilities for modeling complex\nbiological data, their traditional \"black-box\" nature presents challenges for\nvalidation and trust in high-stakes health applications. Recent advances in\nMechanistic Interpretability (MI) aim to decipher the internal computations\nlearned by these networks. This work investigates the application of MI\ntechniques to NNs within the context of causal inference for bio-statistics.\n  We demonstrate that MI tools can be leveraged to: (1) probe and validate the\ninternal representations learned by NNs, such as those estimating nuisance\nfunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)\ndiscover and visualize the distinct computational pathways employed by the\nnetwork to process different types of inputs, potentially revealing how\nconfounders and treatments are handled; and (3) provide methodologies for\ncomparing the learned mechanisms and extracted insights across statistical,\nmachine learning, and NN models, fostering a deeper understanding of their\nrespective strengths and weaknesses for causal bio-statistical analysis.", "AI": {"tldr": "The paper explores using Mechanistic Interpretability (MI) to make Neural Networks (NNs) more interpretable for causal inference in bio-statistics, addressing their traditional 'black-box' limitations.", "motivation": "NNs are powerful but lack interpretability, which is critical for trust and validation in high-stakes health applications. MI offers a way to decode NN computations for better insights.", "method": "The study applies MI techniques to NNs in causal inference, focusing on validating internal representations, visualizing computational pathways, and comparing insights across models.", "result": "MI tools help validate NN representations, reveal how inputs like confounders are processed, and enable comparisons between statistical, ML, and NN models.", "conclusion": "MI enhances NN interpretability for causal bio-statistical analysis, bridging the gap between their power and the need for transparency in health applications."}}
{"id": "2505.00690", "pdf": "https://arxiv.org/pdf/2505.00690", "abs": "https://arxiv.org/abs/2505.00690", "authors": ["Wayne Wu", "Honglin He", "Chaoyuan Zhang", "Jack He", "Seth Z. Zhao", "Ran Gong", "Quanyi Li", "Bolei Zhou"], "title": "Towards Autonomous Micromobility through Scalable Urban Simulation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "CVPR 2025 Highlight. Project page:\n  https://metadriverse.github.io/urban-sim/", "summary": "Micromobility, which utilizes lightweight mobile machines moving in urban\npublic spaces, such as delivery robots and mobility scooters, emerges as a\npromising alternative to vehicular mobility. Current micromobility depends\nmostly on human manual operation (in-person or remote control), which raises\nsafety and efficiency concerns when navigating busy urban environments full of\nunpredictable obstacles and pedestrians. Assisting humans with AI agents in\nmaneuvering micromobility devices presents a viable solution for enhancing\nsafety and efficiency. In this work, we present a scalable urban simulation\nsolution to advance autonomous micromobility. First, we build URBAN-SIM - a\nhigh-performance robot learning platform for large-scale training of embodied\nagents in interactive urban scenes. URBAN-SIM contains three critical modules:\nHierarchical Urban Generation pipeline, Interactive Dynamics Generation\nstrategy, and Asynchronous Scene Sampling scheme, to improve the diversity,\nrealism, and efficiency of robot learning in simulation. Then, we propose\nURBAN-BENCH - a suite of essential tasks and benchmarks to gauge various\ncapabilities of the AI agents in achieving autonomous micromobility.\nURBAN-BENCH includes eight tasks based on three core skills of the agents:\nUrban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robots\nwith heterogeneous embodiments, such as the wheeled and legged robots, across\nthese tasks. Experiments on diverse terrains and urban structures reveal each\nrobot's strengths and limitations.", "AI": {"tldr": "The paper introduces URBAN-SIM, a scalable simulation platform for training AI agents in autonomous micromobility, and URBAN-BENCH, a benchmark suite to evaluate agent performance in urban tasks.", "motivation": "Current micromobility relies on human operation, raising safety and efficiency concerns in unpredictable urban environments. AI assistance is proposed to enhance these aspects.", "method": "Developed URBAN-SIM with modules for urban generation, dynamics, and scene sampling, and URBAN-BENCH with tasks to evaluate agent skills like locomotion and navigation.", "result": "Experiments on diverse terrains and robots (wheeled, legged) revealed their strengths and limitations in urban tasks.", "conclusion": "The proposed simulation and benchmark tools advance autonomous micromobility by improving training diversity and evaluation metrics."}}
{"id": "2505.00530", "pdf": "https://arxiv.org/pdf/2505.00530", "abs": "https://arxiv.org/abs/2505.00530", "authors": ["Xinyu Wang", "Jinbo Bi", "Minghu Song"], "title": "Leveraging Partial SMILES Validation Scheme for Enhanced Drug Design in Reinforcement Learning Frameworks", "categories": ["cs.LG", "cs.CE", "q-bio.BM"], "comment": "17 pages, 5 main figures, 2 appendix figures. Submitted to ICML 2025", "summary": "SMILES-based molecule generation has emerged as a powerful approach in drug\ndiscovery. Deep reinforcement learning (RL) using large language model (LLM)\nhas been incorporated into the molecule generation process to achieve high\nmatching score in term of likelihood of desired molecule candidates. However, a\ncritical challenge in this approach is catastrophic forgetting during the RL\nphase, where knowledge such as molecule validity, which often exceeds 99\\%\nduring pretraining, significantly deteriorates. Current RL algorithms applied\nin drug discovery, such as REINVENT, use prior models as anchors to retian\npretraining knowledge, but these methods lack robust exploration mechanisms. To\naddress these issues, we propose Partial SMILES Validation-PPO (PSV-PPO), a\nnovel RL algorithm that incorporates real-time partial SMILES validation to\nprevent catastrophic forgetting while encouraging exploration. Unlike\ntraditional RL approaches that validate molecule structures only after\ngenerating entire sequences, PSV-PPO performs stepwise validation at each\nauto-regressive step, evaluating not only the selected token candidate but also\nall potential branches stemming from the prior partial sequence. This enables\nearly detection of invalid partial SMILES across all potential paths. As a\nresult, PSV-PPO maintains high validity rates even during aggressive\nexploration of the vast chemical space. Our experiments on the PMO and GuacaMol\nbenchmark datasets demonstrate that PSV-PPO significantly reduces the number of\ninvalid generated structures while maintaining competitive exploration and\noptimization performance. While our work primarily focuses on maintaining\nvalidity, the framework of PSV-PPO can be extended in future research to\nincorporate additional forms of valuable domain knowledge, further enhancing\nreinforcement learning applications in drug discovery.", "AI": {"tldr": "PSV-PPO is a novel RL algorithm for SMILES-based molecule generation that prevents catastrophic forgetting and encourages exploration by validating partial SMILES in real-time.", "motivation": "Address catastrophic forgetting and lack of exploration in current RL methods for molecule generation, which degrade molecule validity during RL phases.", "method": "Introduces Partial SMILES Validation-PPO (PSV-PPO), which performs stepwise validation of partial SMILES sequences during generation, evaluating all potential branches to detect invalidity early.", "result": "PSV-PPO maintains high validity rates during exploration and reduces invalid structures, as demonstrated on PMO and GuacaMol benchmarks.", "conclusion": "PSV-PPO effectively balances validity and exploration, with potential for future extensions to incorporate more domain knowledge in drug discovery."}}
{"id": "2505.00626", "pdf": "https://arxiv.org/pdf/2505.00626", "abs": "https://arxiv.org/abs/2505.00626", "authors": ["Zihao Wang", "Yibo Jiang", "Jiahao Yu", "Heqing Huang"], "title": "The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)", "categories": ["cs.CL", "cs.AI", "68T50", "I.2"], "comment": null, "summary": "Large language models (LLMs) that integrate multiple input roles (e.g.,\nsystem instructions, user queries, external tool outputs) are increasingly\nprevalent in practice. Ensuring that the model accurately distinguishes\nmessages from each role -- a concept we call \\emph{role separation} -- is\ncrucial for consistent multi-role behavior. Although recent work often targets\nstate-of-the-art prompt injection defenses, it remains unclear whether such\nmethods truly teach LLMs to differentiate roles or merely memorize known\ntriggers. In this paper, we examine \\emph{role-separation learning}: the\nprocess of teaching LLMs to robustly distinguish system and user tokens.\nThrough a \\emph{simple, controlled experimental framework}, we find that\nfine-tuned models often rely on two proxies for role identification: (1) task\ntype exploitation, and (2) proximity to begin-of-text. Although data\naugmentation can partially mitigate these shortcuts, it generally leads to\niterative patching rather than a deeper fix. To address this, we propose\nreinforcing \\emph{invariant signals} that mark role boundaries by adjusting\ntoken-wise cues in the model's input encoding. In particular, manipulating\nposition IDs helps the model learn clearer distinctions and reduces reliance on\nsuperficial proxies. By focusing on this mechanism-centered perspective, our\nwork illuminates how LLMs can more reliably maintain consistent multi-role\nbehavior without merely memorizing known prompts or triggers.", "AI": {"tldr": "The paper investigates role-separation learning in LLMs, identifying reliance on shortcuts like task type and proximity to begin-of-text. It proposes adjusting token-wise cues, such as position IDs, to improve role distinction.", "motivation": "Ensuring LLMs accurately distinguish roles (role separation) is crucial for consistent multi-role behavior, but current methods may not teach true differentiation.", "method": "A controlled experimental framework is used to study role-separation learning, identifying shortcuts and proposing adjustments to token-wise cues like position IDs.", "result": "Fine-tuned models rely on superficial proxies for role identification; adjusting invariant signals improves role distinction.", "conclusion": "Focusing on invariant signals helps LLMs reliably maintain multi-role behavior without memorizing prompts."}}
{"id": "2505.00561", "pdf": "https://arxiv.org/pdf/2505.00561", "abs": "https://arxiv.org/abs/2505.00561", "authors": ["Kuan-Cheng Chen", "Hiromichi Matsuyama", "Wei-Hao Huang"], "title": "Learning to Learn with Quantum Optimization via Quantum Neural Networks", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "Quantum Approximate Optimization Algorithms (QAOA) promise efficient\nsolutions to classically intractable combinatorial optimization problems by\nharnessing shallow-depth quantum circuits. Yet, their performance and\nscalability often hinge on effective parameter optimization, which remains\nnontrivial due to rugged energy landscapes and hardware noise. In this work, we\nintroduce a quantum meta-learning framework that combines quantum neural\nnetworks, specifically Quantum Long Short-Term Memory (QLSTM) architectures,\nwith QAOA. By training the QLSTM optimizer on smaller graph instances, our\napproach rapidly generalizes to larger, more complex problems, substantially\nreducing the number of iterations required for convergence. Through\ncomprehensive benchmarks on Max-Cut and Sherrington-Kirkpatrick model\ninstances, we demonstrate that QLSTM-based optimizers converge faster and\nachieve higher approximation ratios compared to classical baselines, thereby\noffering a robust pathway toward scalable quantum optimization in the NISQ era.", "AI": {"tldr": "A quantum meta-learning framework combining QLSTM with QAOA improves optimization efficiency for combinatorial problems, outperforming classical methods.", "motivation": "QAOA's performance is limited by parameter optimization challenges; this work aims to enhance scalability and efficiency using quantum meta-learning.", "method": "Integrates QLSTM architectures with QAOA, training on smaller graphs to generalize to larger problems, reducing convergence iterations.", "result": "QLSTM-based optimizers converge faster and achieve higher approximation ratios than classical methods in benchmarks.", "conclusion": "The framework offers a scalable solution for quantum optimization in the NISQ era."}}
{"id": "2505.00702", "pdf": "https://arxiv.org/pdf/2505.00702", "abs": "https://arxiv.org/abs/2505.00702", "authors": ["Hanwen Jiang", "Hao Tan", "Peng Wang", "Haian Jin", "Yue Zhao", "Sai Bi", "Kai Zhang", "Fujun Luan", "Kalyan Sunkavalli", "Qixing Huang", "Georgios Pavlakos"], "title": "RayZer: A Self-supervised Large View Synthesis Model", "categories": ["cs.CV"], "comment": null, "summary": "We present RayZer, a self-supervised multi-view 3D Vision model trained\nwithout any 3D supervision, i.e., camera poses and scene geometry, while\nexhibiting emerging 3D awareness. Concretely, RayZer takes unposed and\nuncalibrated images as input, recovers camera parameters, reconstructs a scene\nrepresentation, and synthesizes novel views. During training, RayZer relies\nsolely on its self-predicted camera poses to render target views, eliminating\nthe need for any ground-truth camera annotations and allowing RayZer to be\ntrained with 2D image supervision. The emerging 3D awareness of RayZer is\nattributed to two key factors. First, we design a self-supervised framework,\nwhich achieves 3D-aware auto-encoding of input images by disentangling camera\nand scene representations. Second, we design a transformer-based model in which\nthe only 3D prior is the ray structure, connecting camera, pixel, and scene\nsimultaneously. RayZer demonstrates comparable or even superior novel view\nsynthesis performance than ``oracle'' methods that rely on pose annotations in\nboth training and testing. Project: https://hwjiang1510.github.io/RayZer/", "AI": {"tldr": "RayZer is a self-supervised 3D vision model that recovers camera poses and reconstructs scenes without 3D supervision, achieving competitive novel view synthesis.", "motivation": "To enable 3D vision tasks without relying on ground-truth camera poses or scene geometry, reducing dependency on annotated data.", "method": "Uses a self-supervised framework to disentangle camera and scene representations, employing a transformer-based model with ray structure as the only 3D prior.", "result": "RayZer matches or outperforms methods requiring pose annotations in novel view synthesis.", "conclusion": "RayZer demonstrates emerging 3D awareness and effectiveness in self-supervised 3D vision tasks."}}
{"id": "2505.00541", "pdf": "https://arxiv.org/pdf/2505.00541", "abs": "https://arxiv.org/abs/2505.00541", "authors": ["Amarpal Sahota", "Navid Mohammadi Foumani", "Raul Santos-Rodriguez", "Zahraa S. Abdallah"], "title": "KnowEEG: Explainable Knowledge Driven EEG Classification", "categories": ["cs.LG"], "comment": null, "summary": "Electroencephalography (EEG) is a method of recording brain activity that\nshows significant promise in applications ranging from disease classification\nto emotion detection and brain-computer interfaces. Recent advances in deep\nlearning have improved EEG classification performance yet model explainability\nremains an issue. To address this key limitation of explainability we introduce\nKnowEEG; a novel explainable machine learning approach for EEG classification.\nKnowEEG extracts a comprehensive set of per-electrode features, filters them\nusing statistical tests, and integrates between-electrode connectivity\nstatistics. These features are then input to our modified Random Forest model\n(Fusion Forest) that balances per electrode statistics with between electrode\nconnectivity features in growing the trees of the forest. By incorporating\nknowledge from both the generalized time-series and EEG-specific domains,\nKnowEEG achieves performance comparable to or exceeding state-of-the-art deep\nlearning models across five different classification tasks: emotion detection,\nmental workload classification, eyes open/closed detection, abnormal EEG\nclassification, and event detection. In addition to high performance, KnowEEG\nprovides inherent explainability through feature importance scores for\nunderstandable features. We demonstrate by example on the eyes closed/open\nclassification task that this explainability can be used to discover knowledge\nabout the classes. This discovered knowledge for eyes open/closed\nclassification was proven to be correct by current neuroscience literature.\nTherefore, the impact of KnowEEG will be significant for domains where EEG\nexplainability is critical such as healthcare.", "AI": {"tldr": "KnowEEG is an explainable machine learning approach for EEG classification, combining per-electrode features and connectivity statistics, achieving high performance and interpretability.", "motivation": "Addressing the lack of explainability in deep learning models for EEG classification, which is critical for applications like healthcare.", "method": "KnowEEG extracts per-electrode features, filters them statistically, integrates connectivity statistics, and uses a modified Random Forest (Fusion Forest) for classification.", "result": "KnowEEG matches or surpasses state-of-the-art deep learning models in five EEG classification tasks and provides explainable feature importance.", "conclusion": "KnowEEG offers a high-performance, explainable solution for EEG classification, validated by neuroscience literature, with significant potential in healthcare."}}
{"id": "2505.00654", "pdf": "https://arxiv.org/pdf/2505.00654", "abs": "https://arxiv.org/abs/2505.00654", "authors": ["Daniel N. Nissani"], "title": "Large Language Models Understanding: an Inherent Ambiguity Barrier", "categories": ["cs.CL", "cs.AI"], "comment": "submitted to NEURAL COMPUTATION", "summary": "A lively ongoing debate is taking place, since the extraordinary emergence of\nLarge Language Models (LLMs) with regards to their capability to understand the\nworld and capture the meaning of the dialogues in which they are involved.\nArguments and counter-arguments have been proposed based upon thought\nexperiments, anecdotal conversations between LLMs and humans, statistical\nlinguistic analysis, philosophical considerations, and more. In this brief\npaper we present a counter-argument based upon a thought experiment and\nsemi-formal considerations leading to an inherent ambiguity barrier which\nprevents LLMs from having any understanding of what their amazingly fluent\ndialogues mean.", "AI": {"tldr": "The paper argues that LLMs cannot truly understand dialogues due to an inherent ambiguity barrier, despite their fluency.", "motivation": "To challenge the belief that LLMs can understand meaning by presenting a counter-argument based on thought experiments and semi-formal analysis.", "method": "Uses a thought experiment and semi-formal considerations to demonstrate an ambiguity barrier in LLMs.", "result": "Identifies an inherent ambiguity barrier that prevents LLMs from understanding the meaning of their dialogues.", "conclusion": "LLMs lack true understanding of dialogues, despite their fluent output, due to fundamental ambiguities."}}
{"id": "2505.00562", "pdf": "https://arxiv.org/pdf/2505.00562", "abs": "https://arxiv.org/abs/2505.00562", "authors": ["Yue Meng", "Chuchu Fan"], "title": "TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching", "categories": ["cs.RO", "cs.AI", "cs.FL", "cs.LG"], "comment": "Accepted to ICML2025", "summary": "Learning to solve complex tasks with signal temporal logic (STL)\nspecifications is crucial to many real-world applications. However, most\nprevious works only consider fixed or parametrized STL specifications due to\nthe lack of a diverse STL dataset and encoders to effectively extract temporal\nlogic information for downstream tasks. In this paper, we propose TeLoGraF,\nTemporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN)\nencoder and flow-matching to learn solutions for general STL specifications. We\nidentify four commonly used STL templates and collect a total of 200K\nspecifications with paired demonstrations. We conduct extensive experiments in\nfive simulation environments ranging from simple dynamical models in the 2D\nspace to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped\nnavigation. Results show that our method outperforms other baselines in the STL\nsatisfaction rate. Compared to classical STL planning algorithms, our approach\nis 10-100X faster in inference and can work on any system dynamics. Besides, we\nshow our graph-encoding method's capability to solve complex STLs and\nrobustness to out-distribution STL specifications. Code is available at\nhttps://github.com/mengyuest/TeLoGraF", "AI": {"tldr": "TeLoGraF uses GNNs and flow-matching to solve general STL specifications, outperforming baselines in speed and robustness.", "motivation": "Addressing the lack of diverse STL datasets and encoders for downstream tasks.", "method": "Proposes TeLoGraF, combining GNN encoders and flow-matching, and collects 200K STL specifications with demonstrations.", "result": "Outperforms baselines in STL satisfaction, 10-100X faster inference, and works on any system dynamics.", "conclusion": "TeLoGraF is effective, fast, and robust for solving complex STL tasks."}}
{"id": "2505.00703", "pdf": "https://arxiv.org/pdf/2505.00703", "abs": "https://arxiv.org/abs/2505.00703", "authors": ["Dongzhi Jiang", "Ziyu Guo", "Renrui Zhang", "Zhuofan Zong", "Hao Li", "Le Zhuo", "Shilin Yan", "Pheng-Ann Heng", "Hongsheng Li"], "title": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Project Page: https://github.com/CaraJ7/T2I-R1", "summary": "Recent advancements in large language models have demonstrated how\nchain-of-thought (CoT) and reinforcement learning (RL) can improve performance.\nHowever, applying such reasoning strategies to the visual generation domain\nremains largely unexplored. In this paper, we present T2I-R1, a novel\nreasoning-enhanced text-to-image generation model, powered by RL with a\nbi-level CoT reasoning process. Specifically, we identify two levels of CoT\nthat can be utilized to enhance different stages of generation: (1) the\nsemantic-level CoT for high-level planning of the prompt and (2) the\ntoken-level CoT for low-level pixel processing during patch-by-patch\ngeneration. To better coordinate these two levels of CoT, we introduce\nBiCoT-GRPO with an ensemble of generation rewards, which seamlessly optimizes\nboth generation CoTs within the same training step. By applying our reasoning\nstrategies to the baseline model, Janus-Pro, we achieve superior performance\nwith 13% improvement on T2I-CompBench and 19% improvement on the WISE\nbenchmark, even surpassing the state-of-the-art model FLUX.1. Code is available\nat: https://github.com/CaraJ7/T2I-R1", "AI": {"tldr": "T2I-R1 introduces a reasoning-enhanced text-to-image model using bi-level chain-of-thought (CoT) and RL, improving performance over baselines.", "motivation": "To explore the untapped potential of reasoning strategies like CoT and RL in visual generation, enhancing text-to-image models.", "method": "Uses semantic-level CoT for prompt planning and token-level CoT for pixel processing, coordinated via BiCoT-GRPO with ensemble rewards.", "result": "Achieves 13% and 19% improvements on T2I-CompBench and WISE benchmarks, outperforming FLUX.", "conclusion": "T2I-R1 demonstrates the effectiveness of bi-level CoT and RL in advancing text-to-image generation."}}
{"id": "2505.00546", "pdf": "https://arxiv.org/pdf/2505.00546", "abs": "https://arxiv.org/abs/2505.00546", "authors": ["Qingyuan Wu", "Yuhui Wang", "Simon Sinong Zhan", "Yixuan Wang", "Chung-Wei Lin", "Chen Lv", "Qi Zhu", "J\u00fcrgen Schmidhuber", "Chao Huang"], "title": "Directly Forecasting Belief for Reinforcement Learning with Delays", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) with delays is challenging as sensory perceptions\nlag behind the actual events: the RL agent needs to estimate the real state of\nits environment based on past observations. State-of-the-art (SOTA) methods\ntypically employ recursive, step-by-step forecasting of states. This can cause\nthe accumulation of compounding errors. To tackle this problem, our novel\nbelief estimation method, named Directly Forecasting Belief Transformer (DFBT),\ndirectly forecasts states from observations without incrementally estimating\nintermediate states step-by-step. We theoretically demonstrate that DFBT\ngreatly reduces compounding errors of existing recursively forecasting methods,\nyielding stronger performance guarantees. In experiments with D4RL offline\ndatasets, DFBT reduces compounding errors with remarkable prediction accuracy.\nDFBT's capability to forecast state sequences also facilitates multi-step\nbootstrapping, thus greatly improving learning efficiency. On the MuJoCo\nbenchmark, our DFBT-based method substantially outperforms SOTA baselines.", "AI": {"tldr": "DFBT, a novel belief estimation method, directly forecasts states in RL with delays, reducing compounding errors and outperforming SOTA methods.", "motivation": "Address the challenge of compounding errors in RL with delays caused by recursive state forecasting.", "method": "Propose DFBT, which directly forecasts states from observations without step-by-step intermediate estimation.", "result": "DFBT reduces compounding errors, improves prediction accuracy, and enhances learning efficiency, outperforming SOTA baselines on MuJoCo.", "conclusion": "DFBT offers a superior approach for RL with delays by minimizing compounding errors and improving performance."}}
{"id": "2505.00661", "pdf": "https://arxiv.org/pdf/2505.00661", "abs": "https://arxiv.org/abs/2505.00661", "authors": ["Andrew K. Lampinen", "Arslan Chaudhry", "Stephanie C. Y. Chan", "Cody Wild", "Diane Wan", "Alex Ku", "J\u00f6rg Bornschein", "Razvan Pascanu", "Murray Shanahan", "James L. McClelland"], "title": "On the generalization of language models from in-context learning and finetuning: a controlled study", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models exhibit exciting capabilities, yet can show\nsurprisingly narrow generalization from finetuning -- from failing to\ngeneralize to simple reversals of relations they are trained on, to missing\nlogical deductions that can be made from trained information. These failures to\ngeneralize from fine-tuning can hinder practical application of these models.\nHowever, language models' in-context learning shows different inductive biases,\nand can generalize better in some of these cases. Here, we explore these\ndifferences in generalization between in-context- and fine-tuning-based\nlearning. To do so, we constructed several novel datasets to evaluate and\nimprove models' ability to generalize from finetuning data. The datasets are\nconstructed to isolate the knowledge in the dataset from that in pretraining,\nto create clean tests of generalization. We expose pretrained large models to\ncontrolled subsets of the information in these datasets -- either in context,\nor through fine-tuning -- and evaluate their performance on test sets that\nrequire various types of generalization. We find overall that in data-matched\nsettings, in-context learning can generalize more flexibly than fine-tuning\n(though we also find some qualifications of prior findings, such as cases when\nfine-tuning can generalize to reversals embedded in a larger structure of\nknowledge). We build on these findings to propose a method to enable improved\ngeneralization from fine-tuning: adding in-context inferences to finetuning\ndata. We show that this method improves generalization across various splits of\nour datasets and other benchmarks. Our results have implications for\nunderstanding the inductive biases of different modes of learning in language\nmodels, and practically improving their performance.", "AI": {"tldr": "The paper explores differences in generalization between in-context learning and fine-tuning in large language models, finding in-context learning often generalizes better. It proposes adding in-context inferences to fine-tuning data to improve generalization.", "motivation": "To understand why fine-tuning often fails to generalize well compared to in-context learning, and to improve practical applications of language models.", "method": "Constructed novel datasets to isolate knowledge, tested models on controlled subsets via in-context learning or fine-tuning, and evaluated generalization performance.", "result": "In-context learning generalizes more flexibly than fine-tuning in data-matched settings, though fine-tuning can generalize in specific cases. Adding in-context inferences to fine-tuning data improves generalization.", "conclusion": "The findings highlight the inductive biases of different learning modes and offer a practical method to enhance fine-tuning generalization."}}
{"id": "2505.00596", "pdf": "https://arxiv.org/pdf/2505.00596", "abs": "https://arxiv.org/abs/2505.00596", "authors": ["Alex Schutz", "Yang You", "Matias Mattamala", "Ipek Caliskanelli", "Bruno Lacerda", "Nick Hawes"], "title": "A Finite-State Controller Based Offline Solver for Deterministic POMDPs", "categories": ["cs.RO", "cs.AI", "cs.LG", "I.2.8; I.2.9"], "comment": "9 pages, 6 figures. Appendix attached. To be published in Proceedings\n  of IJCAI 2025. For code see http://github.com/ori-goals/DetMCVI", "summary": "Deterministic partially observable Markov decision processes (DetPOMDPs)\noften arise in planning problems where the agent is uncertain about its\nenvironmental state but can act and observe deterministically. In this paper,\nwe propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI)\nalgorithm for DetPOMDPs, which builds policies in the form of finite-state\ncontrollers (FSCs). DetMCVI solves large problems with a high success rate,\noutperforming existing baselines for DetPOMDPs. We also verify the performance\nof the algorithm in a real-world mobile robot forest mapping scenario.", "AI": {"tldr": "DetMCVI, an adaptation of MCVI for DetPOMDPs, outperforms baselines and works well in real-world robot mapping.", "motivation": "Address planning problems with deterministic actions and observations under state uncertainty.", "method": "Adapts MCVI to DetPOMDPs, building policies as finite-state controllers (FSCs).", "result": "Solves large problems with high success, outperforming baselines.", "conclusion": "DetMCVI is effective for DetPOMDPs, validated in real-world robotics."}}
{"id": "2504.21707", "pdf": "https://arxiv.org/pdf/2504.21707", "abs": "https://arxiv.org/abs/2504.21707", "authors": ["Anthony D Martin"], "title": "Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "cs.NE", "math.IT"], "comment": null, "summary": "We propose a generalization of modern representation learning objectives by\nreframing them as recursive divergence alignment processes over localized\nconditional distributions While recent frameworks like Information Contrastive\nLearning I-Con unify multiple learning paradigms through KL divergence between\nfixed neighborhood conditionals we argue this view underplays a crucial\nrecursive structure inherent in the learning process. We introduce Recursive KL\nDivergence Optimization RKDO a dynamic formalism where representation learning\nis framed as the evolution of KL divergences across data neighborhoods. This\nformulation captures contrastive clustering and dimensionality reduction\nmethods as static slices while offering a new path to model stability and local\nadaptation. Our experiments demonstrate that RKDO offers dual efficiency\nadvantages approximately 30 percent lower loss values compared to static\napproaches across three different datasets and 60 to 80 percent reduction in\ncomputational resources needed to achieve comparable results. This suggests\nthat RKDOs recursive updating mechanism provides a fundamentally more efficient\noptimization landscape for representation learning with significant\nimplications for resource constrained applications.", "AI": {"tldr": "RKDO reframes representation learning as recursive KL divergence alignment, offering efficiency gains over static methods.", "motivation": "To address the underplayed recursive structure in modern representation learning objectives and improve efficiency.", "method": "Introduces Recursive KL Divergence Optimization (RKDO), a dynamic formalism evolving KL divergences across data neighborhoods.", "result": "RKDO achieves ~30% lower loss and 60-80% computational savings compared to static methods.", "conclusion": "RKDO provides a more efficient optimization landscape, beneficial for resource-constrained applications."}}
{"id": "2505.00580", "pdf": "https://arxiv.org/pdf/2505.00580", "abs": "https://arxiv.org/abs/2505.00580", "authors": ["Xinyu Ding", "Lexuan Chen", "Siyu Liao", "Zhongfeng Wang"], "title": "Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors", "categories": ["cs.LG"], "comment": "to appear in Proceedings of the 2025 International Joint Conference\n  on Artificial Intelligence (IJCAI-2025)", "summary": "Foundation models have achieved tremendous success in different domains.\nHowever, their huge computation and storage complexity make these models\ndifficult to fine-tune and also less applicable in practice. Recent study shows\ntraining in Fourier domain can be an effective fine-tuning method in terms of\nboth model performance and number of training parameters. In this work, we\npropose to further reduce the complexity by the factorization through the\nproduct of interleaved circulant and diagonal matrices. In addition, we address\nthe case of non-square fine-tuning weights by partitioning the circulant matrix\ninto blocks. Our method avoids the construction of weight change matrix and\nutilizes 1D fast Fourier transform (FFT) instead of 2D FFT. Experimental\nresults show that our method achieves similar or better performance across\nvarious tasks with much less floating-point operations (FLOPs) and the number\nof trainable parameters.", "AI": {"tldr": "Proposes a method to reduce the complexity of fine-tuning foundation models by factorizing weights into interleaved circulant and diagonal matrices, using 1D FFT for efficiency.", "motivation": "Foundation models are computationally expensive to fine-tune, limiting practical applicability.", "method": "Factorizes weights into interleaved circulant and diagonal matrices, uses 1D FFT, and partitions circulant matrices for non-square weights.", "result": "Achieves similar or better performance with fewer FLOPs and trainable parameters.", "conclusion": "The method effectively reduces complexity while maintaining or improving model performance."}}
{"id": "2505.00662", "pdf": "https://arxiv.org/pdf/2505.00662", "abs": "https://arxiv.org/abs/2505.00662", "authors": ["Wenkai Yang", "Jingwen Chen", "Yankai Lin", "Ji-Rong Wen"], "title": "DeepCritic: Deliberate Critique with Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Work in progress. Data and models are available at\n  https://github.com/RUCBM/DeepCritic", "summary": "As Large Language Models (LLMs) are rapidly evolving, providing accurate\nfeedback and scalable oversight on their outputs becomes an urgent and critical\nproblem. Leveraging LLMs as critique models to achieve automated supervision is\na promising solution. In this work, we focus on studying and enhancing the math\ncritique ability of LLMs. Current LLM critics provide critiques that are too\nshallow and superficial on each step, leading to low judgment accuracy and\nstruggling to offer sufficient feedback for the LLM generator to correct\nmistakes. To tackle this issue, we propose a novel and effective two-stage\nframework to develop LLM critics that are capable of deliberately critiquing on\neach reasoning step of math solutions. In the first stage, we utilize\nQwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for\nsupervised fine-tuning. Each seed critique consists of deliberate step-wise\ncritiques that includes multi-perspective verifications as well as in-depth\ncritiques of initial critiques for each reasoning step. Then, we perform\nreinforcement learning on the fine-tuned model with either existing\nhuman-labeled data from PRM800K or our automatically annotated data obtained\nvia Monte Carlo sampling-based correctness estimation, to further incentivize\nits critique ability. Our developed critique model built on Qwen2.5-7B-Instruct\nnot only significantly outperforms existing LLM critics (including the\nsame-sized DeepSeek-R1-distill models and GPT-4o) on various error\nidentification benchmarks, but also more effectively helps the LLM generator\nrefine erroneous steps through more detailed feedback.", "AI": {"tldr": "A two-stage framework enhances LLM critics for math solutions by generating detailed critiques and using reinforcement learning, outperforming existing models.", "motivation": "The rapid evolution of LLMs necessitates accurate feedback and scalable oversight, especially for math critiques, which current models handle superficially.", "method": "A two-stage approach: (1) supervised fine-tuning with Qwen2.5-72B-Instruct-generated critiques, and (2) reinforcement learning with human or auto-annotated data.", "result": "The Qwen2.5-7B-Instruct critique model outperforms competitors like DeepSeek-R1-distill and GPT-4o in error identification and feedback quality.", "conclusion": "The proposed framework significantly improves LLM critique ability, offering more detailed and effective feedback for math solutions."}}
{"id": "2505.00598", "pdf": "https://arxiv.org/pdf/2505.00598", "abs": "https://arxiv.org/abs/2505.00598", "authors": ["Haozheng Luo", "Chenghao Qiu", "Maojiang Su", "Zhihan Zhou", "Zoe Mehta", "Guo Ye", "Jerry Yao-Chieh Hu", "Han Liu"], "title": "Fast and Low-Cost Genomic Foundation Models via Outlier Removal", "categories": ["cs.LG", "cs.AI"], "comment": "International Conference on Machine Learning (ICML) 2025", "summary": "We propose the first unified adversarial attack benchmark for Genomic\nFoundation Models (GFMs), named GERM. Unlike existing GFM benchmarks, GERM\noffers the first comprehensive evaluation framework to systematically assess\nthe vulnerability of GFMs to adversarial attacks. Methodologically, we evaluate\nthe adversarial robustness of five state-of-the-art GFMs using four widely\nadopted attack algorithms and three defense strategies. Importantly, our\nbenchmark provides an accessible and comprehensive framework to analyze GFM\nvulnerabilities with respect to model architecture, quantization schemes, and\ntraining datasets. Empirically, transformer-based models exhibit greater\nrobustness to adversarial perturbations compared to HyenaDNA, highlighting the\nimpact of architectural design on vulnerability. Moreover, adversarial attacks\nfrequently target biologically significant genomic regions, suggesting that\nthese models effectively capture meaningful sequence features.", "AI": {"tldr": "GERM is the first unified benchmark for evaluating adversarial attack vulnerabilities in Genomic Foundation Models (GFMs), assessing robustness across architectures, quantization, and datasets.", "motivation": "Existing GFM benchmarks lack comprehensive evaluation of adversarial vulnerabilities, prompting the need for GERM.", "method": "GERM evaluates five GFMs using four attack algorithms and three defense strategies, analyzing vulnerabilities related to architecture, quantization, and datasets.", "result": "Transformer-based models are more robust than HyenaDNA, and adversarial attacks often target biologically significant regions.", "conclusion": "GERM provides a framework to assess GFM vulnerabilities, revealing architectural impacts and biological feature capture."}}
{"id": "2505.00590", "pdf": "https://arxiv.org/pdf/2505.00590", "abs": "https://arxiv.org/abs/2505.00590", "authors": ["Chengsen Wang", "Qi Qi", "Jingyu Wang", "Haifeng Sun", "Zirui Zhuang", "Jianxin Liao"], "title": "Unlocking the Potential of Linear Networks for Irregular Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting holds significant importance across various\nindustries, including finance, transportation, energy, healthcare, and climate.\nDespite the widespread use of linear networks due to their low computational\ncost and effectiveness in modeling temporal dependencies, most existing\nresearch has concentrated on regularly sampled and fully observed multivariate\ntime series. However, in practice, we frequently encounter irregular\nmultivariate time series characterized by variable sampling intervals and\nmissing values. The inherent intra-series inconsistency and inter-series\nasynchrony in such data hinder effective modeling and forecasting with\ntraditional linear networks relying on static weights. To tackle these\nchallenges, this paper introduces a novel model named AiT. AiT utilizes an\nadaptive linear network capable of dynamically adjusting weights according to\nobservation time points to address intra-series inconsistency, thereby\nenhancing the accuracy of temporal dependencies modeling. Furthermore, by\nincorporating the Transformer module on variable semantics embeddings, AiT\nefficiently captures variable correlations, avoiding the challenge of\ninter-series asynchrony. Comprehensive experiments across four benchmark\ndatasets demonstrate the superiority of AiT, improving prediction accuracy by\n11% and decreasing runtime by 52% compared to existing state-of-the-art\nmethods.", "AI": {"tldr": "AiT introduces an adaptive linear network and Transformer module to improve forecasting for irregular multivariate time series, outperforming state-of-the-art methods by 11% in accuracy and 52% in runtime.", "motivation": "Traditional linear networks struggle with irregular multivariate time series due to intra-series inconsistency and inter-series asynchrony.", "method": "AiT combines an adaptive linear network for dynamic weight adjustment and a Transformer module for variable correlation capture.", "result": "AiT improves prediction accuracy by 11% and reduces runtime by 52% on benchmark datasets.", "conclusion": "AiT effectively addresses challenges in irregular time series forecasting, offering superior performance and efficiency."}}
{"id": "2505.00675", "pdf": "https://arxiv.org/pdf/2505.00675", "abs": "https://arxiv.org/abs/2505.00675", "authors": ["Yiming Du", "Wenyu Huang", "Danna Zheng", "Zhaowei Wang", "Sebastien Montella", "Mirella Lapata", "Kam-Fai Wong", "Jeff Z. Pan"], "title": "Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions", "categories": ["cs.CL"], "comment": null, "summary": "Memory is a fundamental component of AI systems, underpinning large language\nmodels (LLMs) based agents. While prior surveys have focused on memory\napplications with LLMs, they often overlook the atomic operations that underlie\nmemory dynamics. In this survey, we first categorize memory representations\ninto parametric, contextual structured, and contextual unstructured and then\nintroduce six fundamental memory operations: Consolidation, Updating, Indexing,\nForgetting, Retrieval, and Compression. We systematically map these operations\nto the most relevant research topics across long-term, long-context, parametric\nmodification, and multi-source memory. By reframing memory systems through the\nlens of atomic operations and representation types, this survey provides a\nstructured and dynamic perspective on research, benchmark datasets, and tools\nrelated to memory in AI, clarifying the functional interplay in LLMs based\nagents while outlining promising directions for future research\\footnote{The\npaper list, datasets, methods and tools are available at\n\\href{https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI}{https://github.com/Elvin-Yiming-Du/Survey\\_Memory\\_in\\_AI}.}.", "AI": {"tldr": "This survey categorizes memory representations in AI and introduces six fundamental memory operations, mapping them to key research topics to provide a structured perspective on memory in LLMs.", "motivation": "Prior surveys overlook atomic memory operations, so this work aims to clarify memory dynamics in AI systems, especially LLMs.", "method": "Categorizes memory into parametric, contextual structured, and unstructured types, and defines six core operations (Consolidation, Updating, Indexing, Forgetting, Retrieval, Compression).", "result": "Systematically maps operations to research topics, providing benchmarks and tools for memory in AI.", "conclusion": "Offers a dynamic framework for memory research in LLMs, highlighting future directions."}}
{"id": "2505.00622", "pdf": "https://arxiv.org/pdf/2505.00622", "abs": "https://arxiv.org/abs/2505.00622", "authors": ["Colin Kessler", "Ekaterina Komendantskaya", "Marco Casadio", "Ignazio Maria Viola", "Thomas Flinkow", "Albaraa Ammar Othman", "Alistair Malhotra", "Robbie McPherson"], "title": "Neural Network Verification for Gliding Drone Control: A Case Study", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "18 page pre print, submitted to SAIV 2025 (conference)", "summary": "As machine learning is increasingly deployed in autonomous systems,\nverification of neural network controllers is becoming an active research\ndomain. Existing tools and annual verification competitions suggest that soon\nthis technology will become effective for real-world applications. Our\napplication comes from the emerging field of microflyers that are passively\ntransported by the wind, which may have various uses in weather or pollution\nmonitoring. Specifically, we investigate centimetre-scale bio-inspired gliding\ndrones that resemble Alsomitra macrocarpa diaspores. In this paper, we propose\na new case study on verifying Alsomitra-inspired drones with neural network\ncontrollers, with the aim of adhering closely to a target trajectory. We show\nthat our system differs substantially from existing VNN and ARCH competition\nbenchmarks, and show that a combination of tools holds promise for verifying\nsuch systems in the future, if certain shortcomings can be overcome. We propose\na novel method for robust training of regression networks, and investigate\nformalisations of this case study in Vehicle and CORA. Our verification results\nsuggest that the investigated training methods do improve performance and\nrobustness of neural network controllers in this application, but are limited\nin scope and usefulness. This is due to systematic limitations of both Vehicle\nand CORA, and the complexity of our system reducing the scale of reachability,\nwhich we investigate in detail. If these limitations can be overcome, it will\nenable engineers to develop safe and robust technologies that improve people's\nlives and reduce our impact on the environment.", "AI": {"tldr": "The paper proposes verifying neural network controllers for bio-inspired gliding drones, highlighting challenges and potential solutions.", "motivation": "To ensure safe and robust neural network controllers for microflyers used in environmental monitoring.", "method": "A novel robust training method for regression networks and formal verification using Vehicle and CORA tools.", "result": "Improved performance and robustness, but limited by tool shortcomings and system complexity.", "conclusion": "Overcoming current limitations could enable safer, more effective environmental monitoring technologies."}}
{"id": "2505.00681", "pdf": "https://arxiv.org/pdf/2505.00681", "abs": "https://arxiv.org/abs/2505.00681", "authors": ["Arsha Nagrani", "Sachit Menon", "Ahmet Iscen", "Shyamal Buch", "Ramin Mehran", "Nilpa Jha", "Anja Hauth", "Yukun Zhu", "Carl Vondrick", "Mikhail Sirotenko", "Cordelia Schmid", "Tobias Weyand"], "title": "MINERVA: Evaluating Complex Video Reasoning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Multimodal LLMs are turning their focus to video benchmarks, however most\nvideo benchmarks only provide outcome supervision, with no intermediate or\ninterpretable reasoning steps. This makes it challenging to assess if models\nare truly able to combine perceptual and temporal information to reason about\nvideos, or simply get the correct answer by chance or by exploiting linguistic\nbiases. To remedy this, we provide a new video reasoning dataset called MINERVA\nfor modern multimodal models. Each question in the dataset comes with 5 answer\nchoices, as well as detailed, hand-crafted reasoning traces. Our dataset is\nmultimodal, diverse in terms of video domain and length, and consists of\ncomplex multi-step questions. Extensive benchmarking shows that our dataset\nprovides a challenge for frontier open-source and proprietary models. We\nperform fine-grained error analysis to identify common failure modes across\nvarious models, and create a taxonomy of reasoning errors. We use this to\nexplore both human and LLM-as-a-judge methods for scoring video reasoning\ntraces, and find that failure modes are primarily related to temporal\nlocalization, followed by visual perception errors, as opposed to logical or\ncompleteness errors. The dataset, along with questions, answer candidates and\nreasoning traces will be publicly available under\nhttps://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva.", "AI": {"tldr": "MINERVA is a new video reasoning dataset with detailed reasoning traces to evaluate multimodal LLMs, addressing gaps in current benchmarks.", "motivation": "Current video benchmarks lack intermediate reasoning steps, making it hard to assess if models truly reason or exploit biases.", "method": "Introduce MINERVA, a multimodal dataset with diverse videos, complex questions, and hand-crafted reasoning traces.", "result": "Benchmarking shows MINERVA challenges models; error analysis reveals temporal localization and visual perception as key failure modes.", "conclusion": "MINERVA provides a robust tool for evaluating video reasoning, with public availability for further research."}}
{"id": "2505.00591", "pdf": "https://arxiv.org/pdf/2505.00591", "abs": "https://arxiv.org/abs/2505.00591", "authors": ["Ziqi Li"], "title": "Explainable AI in Spatial Analysis", "categories": ["cs.LG", "econ.EM"], "comment": null, "summary": "This chapter discusses the opportunities of eXplainable Artificial\nIntelligence (XAI) within the realm of spatial analysis. A key objective in\nspatial analysis is to model spatial relationships and infer spatial processes\nto generate knowledge from spatial data, which has been largely based on\nspatial statistical methods. More recently, machine learning offers scalable\nand flexible approaches that complement traditional methods and has been\nincreasingly applied in spatial data science. Despite its advantages, machine\nlearning is often criticized for being a black box, which limits our\nunderstanding of model behavior and output. Recognizing this limitation, XAI\nhas emerged as a pivotal field in AI that provides methods to explain the\noutput of machine learning models to enhance transparency and understanding.\nThese methods are crucial for model diagnosis, bias detection, and ensuring the\nreliability of results obtained from machine learning models. This chapter\nintroduces key concepts and methods in XAI with a focus on Shapley value-based\napproaches, which is arguably the most popular XAI method, and their\nintegration with spatial analysis. An empirical example of county-level voting\nbehaviors in the 2020 Presidential election is presented to demonstrate the use\nof Shapley values and spatial analysis with a comparison to multi-scale\ngeographically weighted regression. The chapter concludes with a discussion on\nthe challenges and limitations of current XAI techniques and proposes new\ndirections.", "AI": {"tldr": "The chapter explores how eXplainable AI (XAI) enhances spatial analysis by making machine learning models transparent, focusing on Shapley value-based methods and their application to spatial data like voting behaviors.", "motivation": "Machine learning in spatial analysis lacks transparency, limiting understanding and reliability. XAI addresses this by explaining model outputs.", "method": "Introduces Shapley value-based XAI methods, compares them with traditional spatial statistical techniques like geographically weighted regression, and applies them to county-level voting data.", "result": "Demonstrates the utility of Shapley values in spatial analysis, showing their effectiveness in explaining model behavior compared to traditional methods.", "conclusion": "Highlights challenges in current XAI techniques and suggests future directions for improving transparency in spatial analysis."}}
{"id": "2505.00679", "pdf": "https://arxiv.org/pdf/2505.00679", "abs": "https://arxiv.org/abs/2505.00679", "authors": ["Xinchen Yang", "Marine Carpuat"], "title": "Steering Large Language Models with Register Analysis for Arbitrary Style Transfer", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\nrewriting text across various styles. However, effectively leveraging this\nability for example-based arbitrary style transfer, where an input text is\nrewritten to match the style of a given exemplar, remains an open challenge. A\nkey question is how to describe the style of the exemplar to guide LLMs toward\nhigh-quality rewrites. In this work, we propose a prompting method based on\nregister analysis to guide LLMs to perform this task. Empirical evaluations\nacross multiple style transfer tasks show that our prompting approach enhances\nstyle transfer strength while preserving meaning more effectively than existing\nprompting strategies.", "AI": {"tldr": "A prompting method based on register analysis improves style transfer in LLMs, outperforming existing strategies.", "motivation": "Effectively leveraging LLMs for example-based arbitrary style transfer is challenging, especially in describing exemplar styles.", "method": "Proposes a prompting method using register analysis to guide LLMs for style transfer.", "result": "Empirical evaluations show enhanced style transfer strength and better meaning preservation.", "conclusion": "The proposed method advances LLM-based style transfer by improving quality and effectiveness."}}
{"id": "2505.00650", "pdf": "https://arxiv.org/pdf/2505.00650", "abs": "https://arxiv.org/abs/2505.00650", "authors": ["Atahan Karagoz"], "title": "OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification", "categories": ["cs.LG", "cs.AI", "q-bio.GN", "q-bio.QM"], "comment": "Code available at: https://github.com/Atahanka/OmicsCL", "summary": "Unsupervised learning of disease subtypes from multi-omics data presents a\nsignificant opportunity for advancing personalized medicine. We introduce\nOmicsCL, a modular contrastive learning framework that jointly embeds\nheterogeneous omics modalities-such as gene expression, DNA methylation, and\nmiRNA expression-into a unified latent space. Our method incorporates a\nsurvival-aware contrastive loss that encourages the model to learn\nrepresentations aligned with survival-related patterns, without relying on\nlabeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncovers\nclinically meaningful clusters and achieves strong unsupervised concordance\nwith patient survival. The framework demonstrates robustness across\nhyperparameter configurations and can be tuned to prioritize either subtype\ncoherence or survival stratification. Ablation studies confirm that integrating\nsurvival-aware loss significantly enhances the predictive power of learned\nembeddings. These results highlight the promise of contrastive objectives for\nbiological insight discovery in high-dimensional, heterogeneous omics data.", "AI": {"tldr": "OmicsCL is a contrastive learning framework for unsupervised disease subtype discovery from multi-omics data, integrating survival-aware loss to align representations with survival patterns.", "motivation": "To advance personalized medicine by learning disease subtypes from multi-omics data without labeled outcomes.", "method": "OmicsCL uses contrastive learning to embed heterogeneous omics modalities into a unified latent space, incorporating a survival-aware loss function.", "result": "The framework identifies clinically meaningful clusters and aligns with patient survival, showing robustness and flexibility in hyperparameter tuning.", "conclusion": "Contrastive learning, especially with survival-aware loss, is effective for discovering biological insights in high-dimensional omics data."}}
{"id": "2505.00693", "pdf": "https://arxiv.org/pdf/2505.00693", "abs": "https://arxiv.org/abs/2505.00693", "authors": ["Yanbang Li", "Ziyang Gong", "Haoyang Li", "Haoyang Li", "Xiaoqi Huang", "Haolan Kang", "Guangping Bai", "Xianzheng Ma"], "title": "Robotic Visual Instruction", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Recently, natural language has been the primary medium for human-robot\ninteraction. However, its inherent lack of spatial precision for robotic\ncontrol introduces challenges such as ambiguity and verbosity. To address these\nlimitations, we introduce the Robotic Visual Instruction (RoVI), a novel\nparadigm to guide robotic tasks through an object-centric, hand-drawn symbolic\nrepresentation. RoVI effectively encodes spatial-temporal information into\nhuman-interpretable visual instructions through 2D sketches, utilizing arrows,\ncircles, colors, and numbers to direct 3D robotic manipulation. To enable\nrobots to understand RoVI better and generate precise actions based on RoVI, we\npresent Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for\nRoVI-conditioned policies. This approach leverages Vision-Language Models\n(VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from\n2D pixel space via keypoint extraction, and then transform them into executable\n3D action sequences. We additionally curate a specialized dataset of 15K\ninstances to fine-tune small VLMs for edge deployment, enabling them to\neffectively learn RoVI capabilities. Our approach is rigorously validated\nacross 11 novel tasks in both real and simulated environments, demonstrating\nsignificant generalization capability. Notably, VIEW achieves an 87.5% success\nrate in real-world scenarios involving unseen tasks that feature multi-step\nactions, with disturbances, and trajectory-following requirements. Code and\nDatasets in this paper will be released soon.", "AI": {"tldr": "RoVI introduces visual instructions for precise robotic control, using sketches to encode spatial-temporal info. VIEW pipeline interprets RoVI via VLMs, achieving 87.5% success in real-world tasks.", "motivation": "Natural language lacks spatial precision for robotic control, leading to ambiguity and verbosity. RoVI addresses this with visual instructions.", "method": "RoVI uses 2D sketches (arrows, circles, etc.) for robotic guidance. VIEW pipeline employs VLMs to decode sketches into 3D actions, fine-tuned with a 15K dataset.", "result": "Validated in 11 tasks, VIEW achieves 87.5% success in real-world scenarios, including unseen, multi-step tasks with disturbances.", "conclusion": "RoVI and VIEW offer a robust, generalizable solution for precise robotic control via visual instructions, outperforming natural language."}}
{"id": "2505.00663", "pdf": "https://arxiv.org/pdf/2505.00663", "abs": "https://arxiv.org/abs/2505.00663", "authors": ["David Pfau", "Ian Davies", "Diana Borsa", "Joao G. M. Araujo", "Brendan Tracey", "Hado van Hasselt"], "title": "Wasserstein Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "We introduce Wasserstein Policy Optimization (WPO), an actor-critic algorithm\nfor reinforcement learning in continuous action spaces. WPO can be derived as\nan approximation to Wasserstein gradient flow over the space of all policies\nprojected into a finite-dimensional parameter space (e.g., the weights of a\nneural network), leading to a simple and completely general closed-form update.\nThe resulting algorithm combines many properties of deterministic and classic\npolicy gradient methods. Like deterministic policy gradients, it exploits\nknowledge of the gradient of the action-value function with respect to the\naction. Like classic policy gradients, it can be applied to stochastic policies\nwith arbitrary distributions over actions -- without using the\nreparameterization trick. We show results on the DeepMind Control Suite and a\nmagnetic confinement fusion task which compare favorably with state-of-the-art\ncontinuous control methods.", "AI": {"tldr": "WPO is a reinforcement learning algorithm for continuous action spaces, combining deterministic and classic policy gradient methods, and outperforms state-of-the-art methods.", "motivation": "To develop a general and efficient algorithm for reinforcement learning in continuous action spaces by leveraging Wasserstein gradient flow.", "method": "WPO approximates Wasserstein gradient flow over policies, using a closed-form update that exploits action-value gradients and works with stochastic policies.", "result": "WPO performs favorably on the DeepMind Control Suite and a fusion task compared to state-of-the-art methods.", "conclusion": "WPO is a versatile and effective algorithm for continuous control tasks, combining strengths of deterministic and stochastic policy gradients."}}
{"id": "2505.00049", "pdf": "https://arxiv.org/pdf/2505.00049", "abs": "https://arxiv.org/abs/2505.00049", "authors": ["Wenhan Dong", "Yuemeng Zhao", "Zhen Sun", "Yule Liu", "Zifan Peng", "Jingyi Zheng", "Zongmin Zhang", "Ziyi Zhang", "Jun Wu", "Ruiming Wang", "Shengmin Xu", "Xinyi Huang", "Xinlei He"], "title": "Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications", "categories": ["cs.CY", "cs.CL", "cs.HC", "cs.LG"], "comment": "26 pages,7 figures", "summary": "As large language models (LLMs) are increasingly used in human-centered\ntasks, assessing their psychological traits is crucial for understanding their\nsocial impact and ensuring trustworthy AI alignment. While existing reviews\nhave covered some aspects of related research, several important areas have not\nbeen systematically discussed, including detailed discussions of diverse\npsychological tests, LLM-specific psychological datasets, and the applications\nof LLMs with psychological traits. To address this gap, we systematically\nreview six key dimensions of applying psychological theories to LLMs: (1)\nassessment tools; (2) LLM-specific datasets; (3) evaluation metrics\n(consistency and stability); (4) empirical findings; (5) personality simulation\nmethods; and (6) LLM-based behavior simulation. Our analysis highlights both\nthe strengths and limitations of current methods. While some LLMs exhibit\nreproducible personality patterns under specific prompting schemes, significant\nvariability remains across tasks and settings. Recognizing methodological\nchallenges such as mismatches between psychological tools and LLMs'\ncapabilities, as well as inconsistencies in evaluation practices, this study\naims to propose future directions for developing more interpretable, robust,\nand generalizable psychological assessment frameworks for LLMs.", "AI": {"tldr": "The paper reviews six key dimensions of applying psychological theories to LLMs, highlighting strengths, limitations, and future directions for robust assessment frameworks.", "motivation": "Assessing LLMs' psychological traits is crucial for understanding their social impact and ensuring trustworthy AI alignment, but existing research lacks systematic coverage.", "method": "Systematic review of six dimensions: assessment tools, datasets, evaluation metrics, empirical findings, personality simulation, and behavior simulation.", "result": "LLMs show reproducible personality patterns under specific prompts but exhibit variability across tasks and settings, with methodological challenges noted.", "conclusion": "Future directions include developing more interpretable, robust, and generalizable psychological assessment frameworks for LLMs."}}
{"id": "2505.00704", "pdf": "https://arxiv.org/pdf/2505.00704", "abs": "https://arxiv.org/abs/2505.00704", "authors": ["Chih-Hao Lin", "Zian Wang", "Ruofan Liang", "Yuxuan Zhang", "Sanja Fidler", "Shenlong Wang", "Zan Gojcic"], "title": "Controllable Weather Synthesis and Removal with Video Diffusion Models", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Generating realistic and controllable weather effects in videos is valuable\nfor many applications. Physics-based weather simulation requires precise\nreconstructions that are hard to scale to in-the-wild videos, while current\nvideo editing often lacks realism and control. In this work, we introduce\nWeatherWeaver, a video diffusion model that synthesizes diverse weather effects\n-- including rain, snow, fog, and clouds -- directly into any input video\nwithout the need for 3D modeling. Our model provides precise control over\nweather effect intensity and supports blending various weather types, ensuring\nboth realism and adaptability. To overcome the scarcity of paired training\ndata, we propose a novel data strategy combining synthetic videos, generative\nimage editing, and auto-labeled real-world videos. Extensive evaluations show\nthat our method outperforms state-of-the-art methods in weather simulation and\nremoval, providing high-quality, physically plausible, and\nscene-identity-preserving results over various real-world videos.", "AI": {"tldr": "WeatherWeaver is a video diffusion model for realistic and controllable weather effects in videos, outperforming current methods.", "motivation": "Physics-based weather simulation is hard to scale, and current video editing lacks realism and control.", "method": "Uses a video diffusion model to synthesize weather effects (rain, snow, fog, clouds) without 3D modeling, with control over intensity and blending.", "result": "Outperforms state-of-the-art in weather simulation and removal, providing high-quality, physically plausible results.", "conclusion": "WeatherWeaver offers scalable, realistic, and controllable weather effects for diverse applications."}}
{"id": "2505.00685", "pdf": "https://arxiv.org/pdf/2505.00685", "abs": "https://arxiv.org/abs/2505.00685", "authors": ["Daniel Eftekhari", "Vardan Papyan"], "title": "On the Importance of Gaussianizing Representations", "categories": ["cs.LG"], "comment": "ICML 2025 Proceedings", "summary": "The normal distribution plays a central role in information theory - it is at\nthe same time the best-case signal and worst-case noise distribution, has the\ngreatest representational capacity of any distribution, and offers an\nequivalence between uncorrelatedness and independence for joint distributions.\nAccounting for the mean and variance of activations throughout the layers of\ndeep neural networks has had a significant effect on facilitating their\neffective training, but seldom has a prescription for precisely what\ndistribution these activations should take, and how this might be achieved,\nbeen offered. Motivated by the information-theoretic properties of the normal\ndistribution, we address this question and concurrently present normality\nnormalization: a novel normalization layer which encourages normality in the\nfeature representations of neural networks using the power transform and\nemploys additive Gaussian noise during training. Our experiments\ncomprehensively demonstrate the effectiveness of normality normalization, in\nregards to its generalization performance on an array of widely used model and\ndataset combinations, its strong performance across various common factors of\nvariation such as model width, depth, and training minibatch size, its\nsuitability for usage wherever existing normalization layers are conventionally\nused, and as a means to improving model robustness to random perturbations.", "AI": {"tldr": "The paper introduces normality normalization, a new normalization layer for neural networks that promotes normal distribution in feature representations, leveraging the power transform and Gaussian noise, showing improved generalization and robustness.", "motivation": "The normal distribution's central role in information theory and its underutilization in neural network activation distributions motivated the development of normality normalization.", "method": "The method involves a normalization layer using the power transform and additive Gaussian noise to encourage normality in feature representations.", "result": "Experiments show normality normalization improves generalization, performs well across model variations, and enhances robustness to perturbations.", "conclusion": "Normality normalization is effective and versatile, suitable for replacing conventional normalization layers in neural networks."}}
{"id": "2505.00105", "pdf": "https://arxiv.org/pdf/2505.00105", "abs": "https://arxiv.org/abs/2505.00105", "authors": ["Naam\u00e1n Huerga-P\u00e9rez", "Rub\u00e9n \u00c1lvarez", "Rub\u00e9n Ferrero-Guill\u00e9n", "Alberto Mart\u00ednez-Guti\u00e9rrez", "Javier D\u00edez-Gonz\u00e1lez"], "title": "Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques", "categories": ["cs.IR", "cs.CL", "cs.DB"], "comment": "13 pages, 9 figures, 1 table", "summary": "Retrieval-Augmented Generation enhances language models by retrieving\nrelevant information from external knowledge bases, relying on high-dimensional\nvector embeddings typically stored in float32 precision. However, storing these\nembeddings at scale presents significant memory challenges. To address this\nissue, we systematically investigate on MTEB benchmark two complementary\noptimization strategies: quantization, evaluating standard formats (float16,\nint8, binary) and low-bit floating-point types (float8), and dimensionality\nreduction, assessing methods like PCA, Kernel PCA, UMAP, Random Projections and\nAutoencoders. Our results show that float8 quantization achieves a 4x storage\nreduction with minimal performance degradation (<0.3%), significantly\noutperforming int8 quantization at the same compression level, being simpler to\nimplement. PCA emerges as the most effective dimensionality reduction\ntechnique. Crucially, combining moderate PCA (e.g., retaining 50% dimensions)\nwith float8 quantization offers an excellent trade-off, achieving 8x total\ncompression with less performance impact than using int8 alone (which provides\nonly 4x compression). To facilitate practical application, we propose a\nmethodology based on visualizing the performance-storage trade-off space to\nidentify the optimal configuration that maximizes performance within their\nspecific memory constraints.", "AI": {"tldr": "The paper explores quantization and dimensionality reduction to optimize storage of high-dimensional vector embeddings in Retrieval-Augmented Generation, finding float8 and PCA as effective solutions.", "motivation": "High memory usage from storing float32 embeddings in large-scale applications necessitates optimization strategies.", "method": "Systematically evaluates quantization (float16, int8, binary, float8) and dimensionality reduction (PCA, Kernel PCA, UMAP, Random Projections, Autoencoders) on the MTEB benchmark.", "result": "Float8 quantization reduces storage by 4x with minimal performance loss (<0.3%). PCA is the best dimensionality reduction method. Combining PCA and float8 achieves 8x compression.", "conclusion": "A methodology for visualizing trade-offs helps identify optimal configurations, with float8 and PCA offering the best balance between performance and storage."}}
{"id": "2411.11672", "pdf": "https://arxiv.org/pdf/2411.11672", "abs": "https://arxiv.org/abs/2411.11672", "authors": ["Antonio Norelli"], "title": "Artificial Scientific Discovery", "categories": ["cs.AI", "cs.LG", "I.2"], "comment": "PhD thesis, 123 pages", "summary": "Rooted in the explosion of deep learning over the past decade, this thesis\nspans from AlphaGo to ChatGPT to empirically examine the fundamental concepts\nneeded to realize the vision of an artificial scientist: a machine with the\ncapacity to autonomously generate original research and contribute to the\nexpansion of human knowledge. The investigation begins with Olivaw, an AlphaGo\nZero-like agent that discovers Othello knowledge from scratch but is unable to\ncommunicate it. This realization leads to the development of the Explanatory\nLearning (EL) framework, a formalization of the problem faced by a scientist\nwhen trying to explain a new phenomenon to their peers. The effective EL\nprescriptions allow us to crack Zendo, a popular board game simulating the\nscientific endeavor. This success comes with a fundamental insight: an\nartificial scientist must develop its own interpretation of the language used\nto explain its findings, and not rely on a rigid existing interpreter.\nQuestioning the very process of learning an interpreter, we turn our attention\nto the inner functioning of modern multimodal models. This culminates in a\nsimple idea to build CLIP-like models where interpretation and perception are\nexplicitly disentangled: a cost-effective approach that couples two unimodal\nmodels using little multimodal data and no further training. Finally, we\ndiscuss what ChatGPT and its siblings are still missing to become artificial\nscientists, and introduce the Big-Bench Symbol Interpretation Task, a benchmark\nabout interpreting Zendo-like explanations that sees LLMs going no further than\nrandom chance while being instead fully solved by humans.", "AI": {"tldr": "The paper explores the concept of an artificial scientist, progressing from AlphaGo to ChatGPT, and introduces frameworks like Explanatory Learning (EL) and disentangled multimodal models to address challenges in autonomous research and knowledge communication.", "motivation": "To realize the vision of an artificial scientist capable of generating original research and expanding human knowledge, addressing gaps in communication and interpretation.", "method": "Develops the EL framework for explaining phenomena, applies it to Zendo, and proposes disentangled multimodal models for cost-effective interpretation and perception.", "result": "Successfully cracks Zendo using EL, demonstrates the need for autonomous language interpretation, and introduces a benchmark where LLMs fail but humans succeed.", "conclusion": "Artificial scientists require autonomous interpretation frameworks and disentangled models, with current LLMs lacking essential capabilities for true scientific contribution."}}
{"id": "2303.12675", "pdf": "https://arxiv.org/pdf/2303.12675", "abs": "https://arxiv.org/abs/2303.12675", "authors": ["Zeqing Xia", "Bojun Xiong", "Zhouhui Lian"], "title": "VecFontSDF: Learning to Reconstruct and Synthesize High-quality Vector Fonts via Signed Distance Functions", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2023. Project Page:\n  https://xiazeqing.github.io/VecFontSDF", "summary": "Font design is of vital importance in the digital content design and modern\nprinting industry. Developing algorithms capable of automatically synthesizing\nvector fonts can significantly facilitate the font design process. However,\nexisting methods mainly concentrate on raster image generation, and only a few\napproaches can directly synthesize vector fonts. This paper proposes an\nend-to-end trainable method, VecFontSDF, to reconstruct and synthesize\nhigh-quality vector fonts using signed distance functions (SDFs). Specifically,\nbased on the proposed SDF-based implicit shape representation, VecFontSDF\nlearns to model each glyph as shape primitives enclosed by several parabolic\ncurves, which can be precisely converted to quadratic B\\'ezier curves that are\nwidely used in vector font products. In this manner, most image generation\nmethods can be easily extended to synthesize vector fonts. Qualitative and\nquantitative experiments conducted on a publicly-available dataset demonstrate\nthat our method obtains high-quality results on several tasks, including vector\nfont reconstruction, interpolation, and few-shot vector font synthesis,\nmarkedly outperforming the state of the art. Our code and trained models are\navailable at https://xiazeqing.github.io/VecFontSDF.", "AI": {"tldr": "VecFontSDF is an end-to-end trainable method for synthesizing high-quality vector fonts using signed distance functions (SDFs), outperforming existing methods.", "motivation": "Existing methods focus on raster image generation, lacking direct vector font synthesis. VecFontSDF addresses this gap.", "method": "Uses SDF-based implicit shape representation to model glyphs as shape primitives with parabolic curves, convertible to quadratic B\u00e9zier curves.", "result": "Achieves high-quality results in vector font reconstruction, interpolation, and few-shot synthesis, surpassing state-of-the-art methods.", "conclusion": "VecFontSDF effectively bridges the gap in vector font synthesis, offering a scalable solution for font design."}}
{"id": "2411.15923", "pdf": "https://arxiv.org/pdf/2411.15923", "abs": "https://arxiv.org/abs/2411.15923", "authors": ["Saba Zahid", "Sajid Ghuffar", "Obaid-ur-Rehman", "Syed Roshaan Ali Shah"], "title": "Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2; I.2.10"], "comment": "09 pages, To be published", "summary": "This study explores the effectiveness of multi-temporal satellite imagery for\nbetter functional field boundary delineation using deep learning semantic\nsegmentation architecture on two distinct geographical and multi-scale farming\nsystems of Netherlands and Pakistan. Multidate images of April, August and\nOctober 2022 were acquired for PlanetScope and Sentinel-2 in sub regions of\nNetherlands and November 2022, February and March 2023 for selected area of\nDunyapur in Pakistan. For Netherlands, Basic registration crop parcels (BRP)\nvector layer was used as labeled training data. while self-crafted field\nboundary vector data were utilized for Pakistan. Four deep learning models with\nUNET architecture were evaluated using different combinations of multi-date\nimages and NDVI stacks in the Netherlands subregions. A comparative analysis of\nIoU scores assessed the effectiveness of the proposed multi-date NDVI stack\napproach. These findings were then applied for transfer learning, using\npre-trained models from the Netherlands on the selected area in Pakistan.\nAdditionally, separate models were trained using self-crafted field boundary\ndata for Pakistan, and combined models were developed using data from both the\nNetherlands and Pakistan. Results indicate that multi-date NDVI stacks provide\nadditional temporal context, reflecting crop growth over different times of the\nseason. The study underscores the critical role of multi-scale ground\ninformation from diverse geographical areas in developing robust and\nuniversally applicable models for field boundary delineation. The results also\nhighlight the importance of fine spatial resolution for extraction of field\nboundaries in regions with small scale framing. The findings can be extended to\nmulti-scale implementations for improved automatic field boundary delineation\nin heterogeneous agricultural environments.", "AI": {"tldr": "The study evaluates multi-temporal satellite imagery and deep learning for field boundary delineation in the Netherlands and Pakistan, showing improved accuracy with multi-date NDVI stacks and transfer learning.", "motivation": "To enhance functional field boundary delineation using multi-temporal satellite imagery and deep learning across diverse farming systems.", "method": "Utilized UNET architecture with multi-date images and NDVI stacks, comparing IoU scores. Applied transfer learning from the Netherlands to Pakistan and trained separate models for Pakistan.", "result": "Multi-date NDVI stacks improved accuracy by capturing temporal crop growth. Transfer learning and combined models showed robust performance, emphasizing the need for fine spatial resolution in small-scale farming.", "conclusion": "Multi-temporal imagery and diverse geographical data are crucial for universal field boundary delineation models, applicable to heterogeneous agricultural environments."}}
{"id": "2505.00263", "pdf": "https://arxiv.org/pdf/2505.00263", "abs": "https://arxiv.org/abs/2505.00263", "authors": ["Michael J. Ryan", "Danmei Xu", "Chris Nivera", "Daniel Campos"], "title": "EnronQA: Towards Personalized RAG over Private Documents", "categories": ["cs.IR", "cs.CL"], "comment": "26 pages, 4 figures, 6 tables", "summary": "Retrieval Augmented Generation (RAG) has become one of the most popular\nmethods for bringing knowledge-intensive context to large language models (LLM)\nbecause of its ability to bring local context at inference time without the\ncost or data leakage risks associated with fine-tuning. A clear separation of\nprivate information from the LLM training has made RAG the basis for many\nenterprise LLM workloads as it allows the company to augment LLM's\nunderstanding using customers' private documents. Despite its popularity for\nprivate documents in enterprise deployments, current RAG benchmarks for\nvalidating and optimizing RAG pipelines draw their corpora from public data\nsuch as Wikipedia or generic web pages and offer little to no personal context.\nSeeking to empower more personal and private RAG we release the EnronQA\nbenchmark, a dataset of 103,638 emails with 528,304 question-answer pairs\nacross 150 different user inboxes. EnronQA enables better benchmarking of RAG\npipelines over private data and allows for experimentation on the introduction\nof personalized retrieval settings over realistic data. Finally, we use EnronQA\nto explore the tradeoff in memorization and retrieval when reasoning over\nprivate documents.", "AI": {"tldr": "The paper introduces EnronQA, a benchmark for evaluating RAG pipelines on private data, addressing gaps in current benchmarks that rely on public data.", "motivation": "Current RAG benchmarks lack personal or private context, limiting their applicability for enterprise use cases involving private documents.", "method": "The authors release EnronQA, a dataset of 103,638 emails with 528,304 QA pairs from 150 user inboxes, to benchmark RAG pipelines on private data.", "result": "EnronQA enables better evaluation of RAG pipelines for private data and explores tradeoffs between memorization and retrieval.", "conclusion": "EnronQA fills a critical gap in RAG benchmarking, supporting more personalized and private applications."}}
{"id": "2501.16961", "pdf": "https://arxiv.org/pdf/2501.16961", "abs": "https://arxiv.org/abs/2501.16961", "authors": ["Mohammad Raza", "Natasa Milic-Frayling"], "title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers", "categories": ["cs.AI"], "comment": "IJCAI 2025", "summary": "Robustness of reasoning remains a significant challenge for large language\nmodels, and addressing it is essential for the practical applicability of\nAI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a\nnovel approach that addresses the key challenge in combining language models\nwith the rigor of logical solvers: to accurately formulate the reasoning\nproblem from natural language to the formal language of the solver. SSV uses a\nconsistency-based approach to produce strong abstract formalizations of\nproblems using concrete instantiations that are generated by the model and\nverified by the solver. In addition to significantly advancing the overall\nreasoning accuracy over the state-of-the-art, a key novelty that this approach\npresents is a feature of verification that has near-perfect precision over a\nsignificant coverage of cases, as we demonstrate on open reasoning benchmarks.\nWe propose such *near-certain reasoning* as a new approach to reduce the need\nfor manual verification in many cases, taking us closer to more dependable and\nautonomous AI reasoning systems.", "AI": {"tldr": "Semantic Self-Verification (SSV) improves reasoning accuracy in language models by combining them with logical solvers, achieving near-perfect precision in verification.", "motivation": "Addressing the challenge of robustness in AI-driven reasoning systems by improving the translation of natural language to formal logic.", "method": "SSV uses a consistency-based approach to generate and verify abstract formalizations of problems with logical solvers.", "result": "Significant advancement in reasoning accuracy and near-perfect precision in verification, demonstrated on open benchmarks.", "conclusion": "SSV enables near-certain reasoning, reducing manual verification needs and advancing dependable autonomous AI systems."}}
{"id": "2309.08035", "pdf": "https://arxiv.org/pdf/2309.08035", "abs": "https://arxiv.org/abs/2309.08035", "authors": ["Yao Qiang", "Chengyin Li", "Prashant Khanduri", "Dongxiao Zhu"], "title": "Interpretability-Aware Vision Transformer", "categories": ["cs.CV"], "comment": "10 pages, 4 figures, 5 tables", "summary": "Vision Transformers (ViTs) have become prominent models for solving various\nvision tasks. However, the interpretability of ViTs has not kept pace with\ntheir promising performance. While there has been a surge of interest in\ndeveloping {\\it post hoc} solutions to explain ViTs' outputs, these methods do\nnot generalize to different downstream tasks and various transformer\narchitectures. Furthermore, if ViTs are not properly trained with the given\ndata and do not prioritize the region of interest, the {\\it post hoc} methods\nwould be less effective. Instead of developing another {\\it post hoc} approach,\nwe introduce a novel training procedure that inherently enhances model\ninterpretability. Our interpretability-aware ViT (IA-ViT) draws inspiration\nfrom a fresh insight: both the class patch and image patches consistently\ngenerate predicted distributions and attention maps. IA-ViT is composed of a\nfeature extractor, a predictor, and an interpreter, which are trained jointly\nwith an interpretability-aware training objective. Consequently, the\ninterpreter simulates the behavior of the predictor and provides a faithful\nexplanation through its single-head self-attention mechanism. Our comprehensive\nexperimental results demonstrate the effectiveness of IA-ViT in several image\nclassification tasks, with both qualitative and quantitative evaluations of\nmodel performance and interpretability. Source code is available from:\nhttps://github.com/qiangyao1988/IA-ViT.", "AI": {"tldr": "IA-ViT introduces an interpretability-aware training procedure for Vision Transformers, enhancing model transparency without relying on post hoc methods.", "motivation": "Current post hoc interpretability methods for ViTs lack generalization and effectiveness if models are improperly trained or miss key regions.", "method": "IA-ViT jointly trains a feature extractor, predictor, and interpreter with an interpretability-aware objective, leveraging consistent attention maps and predicted distributions.", "result": "IA-ViT improves interpretability and performance in image classification tasks, validated by qualitative and quantitative evaluations.", "conclusion": "IA-ViT offers a novel, inherently interpretable training approach for ViTs, outperforming post hoc methods in both transparency and task performance."}}
{"id": "2504.21413", "pdf": "https://arxiv.org/pdf/2504.21413", "abs": "https://arxiv.org/abs/2504.21413", "authors": ["H. Brendan McMahan", "Krishna Pillutla"], "title": "An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and Applications to Streaming Differential Privacy", "categories": ["cs.CR", "cs.LG", "eess.SP"], "comment": null, "summary": "Buffered Linear Toeplitz (BLT) matrices are a family of parameterized\nlower-triangular matrices that play an important role in streaming differential\nprivacy with correlated noise. Our main result is a BLT inversion theorem: the\ninverse of a BLT matrix is itself a BLT matrix with different parameters. We\nalso present an efficient and differentiable $O(d^3)$ algorithm to compute the\nparameters of the inverse BLT matrix, where $d$ is the degree of the original\nBLT (typically $d < 10$). Our characterization enables direct optimization of\nBLT parameters for privacy mechanisms through automatic differentiation.", "AI": {"tldr": "BLT matrices are key in streaming differential privacy. The paper shows their inverses are also BLT matrices and provides an efficient O(d\u00b3) algorithm to compute inverse parameters.", "motivation": "BLT matrices are crucial for privacy mechanisms with correlated noise, but their inversion properties were unclear.", "method": "Proves a BLT inversion theorem and develops an O(d\u00b3) algorithm to compute inverse parameters.", "result": "Inverse of a BLT matrix is another BLT matrix, enabling direct optimization via automatic differentiation.", "conclusion": "The findings facilitate efficient optimization of BLT parameters for privacy applications."}}
{"id": "2505.00649", "pdf": "https://arxiv.org/pdf/2505.00649", "abs": "https://arxiv.org/abs/2505.00649", "authors": ["Marco Braga", "Pranav Kasela", "Alessandro Raganato", "Gabriella Pasi"], "title": "Investigating Task Arithmetic for Zero-Shot Information Retrieval", "categories": ["cs.IR", "cs.CL", "cs.LG"], "comment": "Accepted in SIGIR '25", "summary": "Large Language Models (LLMs) have shown impressive zero-shot performance\nacross a variety of Natural Language Processing tasks, including document\nre-ranking. However, their effectiveness degrades on unseen tasks and domains,\nlargely due to shifts in vocabulary and word distributions. In this paper, we\ninvestigate Task Arithmetic, a technique that combines the weights of LLMs\npre-trained on different tasks or domains via simple mathematical operations,\nsuch as addition or subtraction, to adapt retrieval models without requiring\nadditional fine-tuning. Our method is able to synthesize diverse tasks and\ndomain knowledge into a single model, enabling effective zero-shot adaptation\nin different retrieval contexts. Extensive experiments on publicly available\nscientific, biomedical, and multilingual datasets show that our method improves\nstate-of-the-art re-ranking performance by up to 18% in NDCG@10 and 15% in\nP@10. In addition to these empirical gains, our analysis provides insights into\nthe strengths and limitations of Task Arithmetic as a practical strategy for\nzero-shot learning and model adaptation. We make our code publicly available at\nhttps://github.com/DetectiveMB/Task-Arithmetic-for-ZS-IR.", "AI": {"tldr": "Task Arithmetic combines LLM weights from diverse tasks/domains via simple math operations to improve zero-shot retrieval performance without fine-tuning.", "motivation": "LLMs degrade in unseen tasks/domains due to vocabulary shifts; Task Arithmetic aims to adapt models without additional training.", "method": "Combines pre-trained LLM weights using mathematical operations (e.g., addition/subtraction) to synthesize task/domain knowledge.", "result": "Improves re-ranking performance by up to 18% in NDCG@10 and 15% in P@10 across scientific, biomedical, and multilingual datasets.", "conclusion": "Task Arithmetic is a practical zero-shot adaptation strategy, offering empirical gains and insights into its strengths/limitations."}}
{"id": "2503.23668", "pdf": "https://arxiv.org/pdf/2503.23668", "abs": "https://arxiv.org/abs/2503.23668", "authors": ["Jiaxin Wu", "Ting Zhang", "Rubing Chen", "Wengyu Zhang", "Chen Jason Zhang", "Xiao-Yong Wei", "Li Qing"], "title": "MolGround: A Benchmark for Molecular Grounding", "categories": ["cs.AI"], "comment": null, "summary": "Current molecular understanding approaches predominantly focus on the\ndescriptive aspect of human perception, providing broad, topic-level insights.\nHowever, the referential aspect -- linking molecular concepts to specific\nstructural components -- remains largely unexplored. To address this gap, we\npropose a molecular grounding benchmark designed to evaluate a model's\nreferential abilities. We align molecular grounding with established\nconventions in NLP, cheminformatics, and molecular science, showcasing the\npotential of NLP techniques to advance molecular understanding within the AI\nfor Science movement. Furthermore, we constructed the largest molecular\nunderstanding benchmark to date, comprising 117k QA pairs, and developed a\nmulti-agent grounding prototype as proof of concept. This system outperforms\nexisting models, including GPT-4o, and its grounding outputs have been\nintegrated to enhance traditional tasks such as molecular captioning and ATC\n(Anatomical, Therapeutic, Chemical) classification.", "AI": {"tldr": "A benchmark for molecular grounding is proposed to evaluate models' referential abilities, outperforming existing models like GPT-4o and enhancing tasks like molecular captioning and ATC classification.", "motivation": "Current approaches lack exploration of the referential aspect of molecular understanding, focusing only on descriptive aspects.", "method": "Developed a molecular grounding benchmark with 117k QA pairs and a multi-agent grounding prototype, aligning with NLP, cheminformatics, and molecular science conventions.", "result": "The system outperforms existing models, including GPT-4o, and improves traditional tasks like molecular captioning and ATC classification.", "conclusion": "The proposed benchmark and prototype demonstrate the potential of NLP techniques to advance molecular understanding in AI for Science."}}
{"id": "2311.08786", "pdf": "https://arxiv.org/pdf/2311.08786", "abs": "https://arxiv.org/abs/2311.08786", "authors": ["Mingrui Zhu", "Dongxin Chen", "Xin Wei", "Nannan Wang", "Xinbo Gao"], "title": "Disentangle Before Anonymize: A Two-stage Framework for Attribute-preserved and Occlusion-robust De-identification", "categories": ["cs.CV"], "comment": null, "summary": "In an era where personal photos are easily leaked and collected, face\nde-identification is a crucial method for protecting identity privacy. However,\ncurrent face de-identification techniques face challenges in preserving\nattribute details and often produce anonymized results with reduced\nauthenticity. These shortcomings are particularly evident when handling\nocclusions,frequently resulting in noticeable editing artifacts. Our primary\nfinding in this work is that simultaneous training of identity disentanglement\nand anonymization hinders their respective effectiveness.Therefore, we propose\n\"Disentangle Before Anonymize\",a novel two-stage Framework(DBAF)designed for\nattributepreserved and occlusion-robust de-identification. This framework\nincludes a Contrastive Identity Disentanglement (CID) module and a\nKey-authorized Reversible Identity Anonymization (KRIA) module, achieving\nfaithful attribute preservation and high-quality identity anonymization edits.\nAdditionally, we introduce a Multiscale Attentional Attribute Retention (MAAR)\nmodule to address the issue of reduced anonymization quality under\nocclusions.Extensive experiments demonstrate that our method outperforms\nstate-of-the-art de-identification approaches, delivering superior quality,\nenhanced detail fidelity, improved attribute preservation performance, and\ngreater robustness to occlusions.", "AI": {"tldr": "The paper introduces a two-stage framework (DBAF) for face de-identification, addressing challenges like attribute loss and occlusion artifacts by disentangling identity before anonymization.", "motivation": "Current face de-identification methods struggle with preserving attributes and handling occlusions, leading to reduced authenticity and noticeable artifacts.", "method": "Proposes 'Disentangle Before Anonymize' (DBAF) with CID and KRIA modules for identity disentanglement and anonymization, plus MAAR for occlusion robustness.", "result": "Outperforms state-of-the-art methods in quality, detail fidelity, attribute preservation, and occlusion robustness.", "conclusion": "DBAF effectively improves face de-identification by separating identity disentanglement and anonymization, achieving better results."}}
{"id": "2505.00037", "pdf": "https://arxiv.org/pdf/2505.00037", "abs": "https://arxiv.org/abs/2505.00037", "authors": ["Junggu Choi", "Chansu Yu", "Kyle L. Jung", "Suan-Sin Foo", "Weiqiang Chen", "Suzy AA Comhair", "Serpil C. Erzurum", "Lara Jehi", "Jae U. Jung"], "title": "Can a Quantum Support Vector Machine algorithm be utilized to identify Key Biomarkers from Multi-Omics data of COVID19 patients?", "categories": ["quant-ph", "cs.LG", "q-bio.QM"], "comment": "70 pages, 6 figures", "summary": "Identifying key biomarkers for COVID-19 from high-dimensional multi-omics\ndata is critical for advancing both diagnostic and pathogenesis research. In\nthis study, we evaluated the applicability of the Quantum Support Vector\nMachine (QSVM) algorithm for biomarker-based classification of COVID-19.\nProteomic and metabolomic biomarkers from two independent datasets were ranked\nby importance using ridge regression and grouped accordingly. The top- and\nbottom-ranked biomarker sets were then used to train and evaluate both\nclassical SVM (CSVM) and QSVM models, serving as predictive and negative\ncontrol inputs, respectively. The QSVM was implemented with multiple quantum\nkernels, including amplitude encoding, angle encoding, the ZZ feature map, and\nthe projected quantum kernel. Across various experimental settings, QSVM\nconsistently achieved classification performance that was comparable to or\nexceeded that of CSVM, while reflecting the importance rankings by ridge\nregression. Although the experiments were conducted in numerical simulation,\nour findings highlight the potential of QSVM as a promising approach for\nmulti-omics data analysis in biomedical research.", "AI": {"tldr": "QSVM was tested for COVID-19 biomarker classification using proteomic and metabolomic data, showing comparable or better performance than classical SVM.", "motivation": "To explore QSVM's potential for identifying COVID-19 biomarkers from high-dimensional multi-omics data.", "method": "Used ridge regression to rank biomarkers, then trained and evaluated QSVM and classical SVM with top- and bottom-ranked sets.", "result": "QSVM performed comparably or better than classical SVM, aligning with biomarker importance rankings.", "conclusion": "QSVM shows promise for multi-omics data analysis in biomedical research."}}
{"id": "2309.08532", "pdf": "https://arxiv.org/pdf/2309.08532", "abs": "https://arxiv.org/abs/2309.08532", "authors": ["Qingyan Guo", "Rui Wang", "Junliang Guo", "Bei Li", "Kaitao Song", "Xu Tan", "Guoqing Liu", "Jiang Bian", "Yujiu Yang"], "title": "EvoPrompt: Connecting LLMs with Evolutionary Algorithms Yields Powerful Prompt Optimizers", "categories": ["cs.CL", "cs.AI"], "comment": "International Conference on Learning Representations (ICLR) 2024", "summary": "Large Language Models (LLMs) excel in various tasks, but they rely on\ncarefully crafted prompts that often demand substantial human effort. To\nautomate this process, in this paper, we propose a novel framework for discrete\nprompt optimization, called EvoPrompt, which borrows the idea of evolutionary\nalgorithms (EAs) as they exhibit good performance and fast convergence. To\nenable EAs to work on discrete prompts, which are natural language expressions\nthat need to be coherent and human-readable, we connect LLMs with EAs. This\napproach allows us to simultaneously leverage the powerful language processing\ncapabilities of LLMs and the efficient optimization performance of EAs.\nSpecifically, abstaining from any gradients or parameters, EvoPrompt starts\nfrom a population of prompts and iteratively generates new prompts with LLMs\nbased on the evolutionary operators, improving the population based on the\ndevelopment set. We optimize prompts for both closed- and open-source LLMs\nincluding GPT-3.5 and Alpaca, on 31 datasets covering language understanding,\ngeneration tasks, as well as BIG-Bench Hard (BBH) tasks. EvoPrompt\nsignificantly outperforms human-engineered prompts and existing methods for\nautomatic prompt generation (e.g., up to 25% on BBH). Furthermore, EvoPrompt\ndemonstrates that connecting LLMs with EAs creates synergies, which could\ninspire further research on the combination of LLMs and conventional\nalgorithms.", "AI": {"tldr": "EvoPrompt is a framework for optimizing discrete prompts using evolutionary algorithms and LLMs, outperforming human-engineered prompts by up to 25%.", "motivation": "To automate the labor-intensive process of crafting effective prompts for LLMs.", "method": "Combines evolutionary algorithms (EAs) with LLMs to iteratively generate and improve coherent, human-readable prompts.", "result": "Outperforms human-engineered prompts and existing methods, achieving up to 25% improvement on BIG-Bench Hard tasks.", "conclusion": "EvoPrompt shows synergies between LLMs and EAs, inspiring further research on combining LLMs with traditional algorithms."}}
{"id": "2504.19636", "pdf": "https://arxiv.org/pdf/2504.19636", "abs": "https://arxiv.org/abs/2504.19636", "authors": ["Fei Liu", "Qingfu Zhang", "Xialiang Tong", "Kun Mao", "Mingxuan Yuan"], "title": "Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant potential in\nalgorithm design. However, when integrated into search frameworks for iterative\nalgorithm search, the underlying fitness landscape--critical for understanding\nsearch behaviou--remains underexplored. In this paper, we illustrate and\nanalyze the fitness landscape of LLM-assisted Algorithm Search (LAS) using a\ngraph-based approach, where nodes represent algorithms and edges denote\ntransitions between them. We conduct extensive evaluations across six algorithm\ndesign tasks and six commonly used LLMs. Our findings reveal that LAS\nlandscapes are highly multimodal and rugged, particularly in combinatorial\noptimization tasks, with distinct structural variations across tasks and LLMs.\nFor instance, heuristic design tasks exhibit dense clusters of high-performing\nalgorithms, while symbolic regression tasks show sparse, scattered\ndistributions. Additionally, we demonstrate how population size influences\nexploration-exploitation trade-offs and the evolving trajectory of elite\nalgorithms. These insights not only advance our understanding of LAS landscapes\nbut also provide practical guidance for designing more effective LAS methods.", "AI": {"tldr": "The paper analyzes the fitness landscape of LLM-assisted Algorithm Search (LAS) using a graph-based approach, revealing multimodal and rugged landscapes with variations across tasks and LLMs. It also explores the impact of population size on exploration-exploitation trade-offs.", "motivation": "The fitness landscape of LLM-assisted Algorithm Search (LAS) is underexplored, despite its importance for understanding search behavior in iterative algorithm design.", "method": "A graph-based approach is used, where nodes represent algorithms and edges denote transitions between them. Evaluations are conducted across six algorithm design tasks and six LLMs.", "result": "LAS landscapes are highly multimodal and rugged, with structural variations across tasks and LLMs. Population size influences exploration-exploitation trade-offs.", "conclusion": "The study advances understanding of LAS landscapes and offers practical guidance for designing more effective LAS methods."}}
{"id": "2312.12028", "pdf": "https://arxiv.org/pdf/2312.12028", "abs": "https://arxiv.org/abs/2312.12028", "authors": ["Siamul Karim Khan", "Patrick Tinsley", "Mahsa Mitcheff", "Patrick Flynn", "Kevin W. Bowyer", "Adam Czajka"], "title": "EyePreserve: Identity-Preserving Iris Synthesis", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Synthesis of same-identity biometric iris images, both for existing and\nnon-existing identities while preserving the identity across a wide range of\npupil sizes, is complex due to the intricate iris muscle constriction\nmechanism, requiring a precise model of iris non-linear texture deformations to\nbe embedded into the synthesis pipeline. This paper presents the first method\nof fully data-driven, identity-preserving, pupil size-varying synthesis of iris\nimages. This approach is capable of synthesizing images of irises with\ndifferent pupil sizes representing non-existing identities, as well as\nnon-linearly deforming the texture of iris images of existing subjects given\nthe segmentation mask of the target iris image. Iris recognition experiments\nsuggest that the proposed deformation model both preserves the identity when\nchanging the pupil size, and offers better similarity between same-identity\niris samples with significant differences in pupil size, compared to\nstate-of-the-art linear and non-linear (bio-mechanical-based) iris deformation\nmodels. Two immediate applications of the proposed approach are: (a) synthesis\nof, or enhancement of the existing biometric datasets for iris recognition,\nmimicking those acquired with iris sensors, and (b) helping forensic human\nexperts examine iris image pairs with significant differences in pupil\ndilation. Images considered in this work conform to selected ISO/IEC 29794-6\nquality metrics to make them applicable in biometric systems. The source codes\nand model weights are offered with this paper.", "AI": {"tldr": "A data-driven method for synthesizing iris images with varying pupil sizes, preserving identity, and improving recognition accuracy.", "motivation": "To address the complexity of synthesizing iris images with varying pupil sizes while preserving identity, which is crucial for biometric datasets and forensic analysis.", "method": "A fully data-driven approach for identity-preserving, pupil size-varying iris image synthesis, including deformation of existing iris textures based on target segmentation masks.", "result": "The method outperforms state-of-the-art models in preserving identity and improving similarity between same-identity iris samples with different pupil sizes.", "conclusion": "The approach enhances biometric datasets and aids forensic analysis, with potential applications in iris recognition systems."}}
{"id": "2505.00110", "pdf": "https://arxiv.org/pdf/2505.00110", "abs": "https://arxiv.org/abs/2505.00110", "authors": ["Insung Kong", "Juntong Chen", "Sophie Langer", "Johannes Schmidt-Hieber"], "title": "On the expressivity of deep Heaviside networks", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "comment": "61 pages, 16 figures", "summary": "We show that deep Heaviside networks (DHNs) have limited expressiveness but\nthat this can be overcome by including either skip connections or neurons with\nlinear activation. We provide lower and upper bounds for the\nVapnik-Chervonenkis (VC) dimensions and approximation rates of these network\nclasses. As an application, we derive statistical convergence rates for DHN\nfits in the nonparametric regression model.", "AI": {"tldr": "Deep Heaviside networks (DHNs) have limited expressiveness, but skip connections or linear activation neurons can enhance it. Bounds for VC dimensions and approximation rates are provided, with applications in nonparametric regression.", "motivation": "To address the limited expressiveness of DHNs and explore ways to enhance their capabilities.", "method": "Including skip connections or neurons with linear activation in DHNs, and analyzing their VC dimensions and approximation rates.", "result": "Lower and upper bounds for VC dimensions and approximation rates are established. Statistical convergence rates for DHN fits in nonparametric regression are derived.", "conclusion": "Enhancing DHNs with skip connections or linear activation improves their expressiveness and applicability in nonparametric regression."}}
{"id": "2401.15371", "pdf": "https://arxiv.org/pdf/2401.15371", "abs": "https://arxiv.org/abs/2401.15371", "authors": ["Buqiang Xu", "Xin Dai", "Zhenghao Liu", "Huiyuan Xie", "Xiaoyuan Yi", "Shuo Wang", "Yukun Yan", "Liner Yang", "Yu Gu", "Ge Yu"], "title": "LegalDuet: Learning Fine-grained Representations for Legal Judgment Prediction via a Dual-View Contrastive Learning", "categories": ["cs.CL"], "comment": null, "summary": "Legal Judgment Prediction (LJP) is a fundamental task of legal artificial\nintelligence, aiming to automatically predict the judgment outcomes of legal\ncases. Existing LJP models primarily focus on identifying legal triggers within\ncriminal fact descriptions by contrastively training language models. However,\nthese LJP models overlook the importance of learning to effectively distinguish\nsubtle differences among judgments, which is crucial for producing more\naccurate predictions. In this paper, we propose LegalDuet, which continuously\npretrains language models to learn a more tailored embedding space for\nrepresenting legal cases. Specifically, LegalDuet designs a dual-view mechanism\nto continuously pretrain language models: 1) Law Case Clustering retrieves\nsimilar cases as hard negatives and employs contrastive training to\ndifferentiate among confusing cases; 2) Legal Decision Matching aims to\nidentify legal clues within criminal fact descriptions to align them with the\nchain of reasoning that contains the correct legal decision. Our experiments on\nthe CAIL2018 dataset demonstrate the effectiveness of LegalDuet. Further\nanalysis reveals that LegalDuet improves the ability of pretrained language\nmodels to distinguish confusing criminal charges by reducing prediction\nuncertainty and enhancing the separability of criminal charges. The experiments\ndemonstrate that LegalDuet produces a more concentrated and distinguishable\nembedding space, effectively aligning criminal facts with corresponding legal\ndecisions. The code is available at https://github.com/NEUIR/LegalDuet.", "AI": {"tldr": "LegalDuet improves Legal Judgment Prediction by pretraining language models with a dual-view mechanism to better distinguish subtle differences in judgments.", "motivation": "Existing LJP models fail to effectively distinguish subtle differences among judgments, limiting prediction accuracy.", "method": "LegalDuet uses a dual-view mechanism: Law Case Clustering for contrastive training with hard negatives, and Legal Decision Matching to align facts with legal reasoning.", "result": "LegalDuet enhances model performance on CAIL2018, reducing prediction uncertainty and improving charge separability.", "conclusion": "LegalDuet creates a more distinguishable embedding space, aligning facts with legal decisions effectively."}}
{"id": "2504.20924", "pdf": "https://arxiv.org/pdf/2504.20924", "abs": "https://arxiv.org/abs/2504.20924", "authors": ["Beomjun Kim", "Kangyeon Kim", "Sunwoo Kim", "Heejin Ahn"], "title": "A Domain-Agnostic Scalable AI Safety Ensuring Framework", "categories": ["cs.AI"], "comment": "Theoretical supplementary material (Part 1) is available in submitted\n  files. Experimental supplementary material (Part 2) will be available before\n  May 22 23:59PM AOE", "summary": "Ensuring the safety of AI systems has recently emerged as a critical priority\nfor real-world deployment, particularly in physical AI applications. Current\napproaches to AI safety typically address predefined domain-specific safety\nconditions, limiting their ability to generalize across contexts. We propose a\nnovel AI safety framework that ensures AI systems comply with any user-defined\nconstraint, with any desired probability, and across various domains. In this\nframework, we combine an AI component (e.g., neural network) with an\noptimization problem to produce responses that minimize objectives while\nsatisfying user-defined constraints with probabilities exceeding user-defined\nthresholds. For credibility assessment of the AI component, we propose internal\ntest data, a supplementary set of safety-labeled data, and a conservative\ntesting methodology that provides statistical validity of using internal test\ndata. We also present an approximation method of a loss function and how to\ncompute its gradient for training. We mathematically prove that probabilistic\nconstraint satisfaction is guaranteed under specific, mild conditions and prove\na scaling law between safety and the number of internal test data. We\ndemonstrate our framework's effectiveness through experiments in diverse\ndomains: demand prediction for production decision, safe reinforcement learning\nwithin the SafetyGym simulator, and guarding AI chatbot outputs. Through these\nexperiments, we demonstrate that our method guarantees safety for\nuser-specified constraints, outperforms for up to several order of magnitudes\nexisting methods in low safety threshold regions, and scales effectively with\nrespect to the size of internal test data.", "AI": {"tldr": "A novel AI safety framework ensures compliance with user-defined constraints across domains, combining AI components with optimization for probabilistic safety guarantees.", "motivation": "Current AI safety methods lack generalization across contexts, necessitating a flexible, domain-agnostic approach.", "method": "Combines AI (e.g., neural networks) with optimization to satisfy constraints probabilistically, using internal test data and conservative testing for credibility.", "result": "Mathematically proven probabilistic safety guarantees; outperforms existing methods in low-threshold regions and scales with test data size.", "conclusion": "The framework effectively generalizes safety guarantees across diverse applications, offering scalable and statistically valid solutions."}}
{"id": "2312.12419", "pdf": "https://arxiv.org/pdf/2312.12419", "abs": "https://arxiv.org/abs/2312.12419", "authors": ["Jinghao Zhou", "Tomas Jakab", "Philip Torr", "Christian Rupprecht"], "title": "Scene-Conditional 3D Object Stylization and Composition", "categories": ["cs.CV"], "comment": null, "summary": "Recently, 3D generative models have made impressive progress, enabling the\ngeneration of almost arbitrary 3D assets from text or image inputs. However,\nthese approaches generate objects in isolation without any consideration for\nthe scene where they will eventually be placed. In this paper, we propose a\nframework that allows for the stylization of an existing 3D asset to fit into a\ngiven 2D scene, and additionally produce a photorealistic composition as if the\nasset was placed within the environment. This not only opens up a new level of\ncontrol for object stylization, for example, the same assets can be stylized to\nreflect changes in the environment, such as summer to winter or fantasy versus\nfuturistic settings-but also makes the object-scene composition more\ncontrollable. We achieve this by combining modeling and optimizing the object's\ntexture and environmental lighting through differentiable ray tracing with\nimage priors from pre-trained text-to-image diffusion models. We demonstrate\nthat our method is applicable to a wide variety of indoor and outdoor scenes\nand arbitrary objects. Project page:\nhttps://jensenzhoujh.github.io/scene-cond-3d/.", "AI": {"tldr": "A framework for stylizing 3D assets to fit 2D scenes, enhancing realism and control in object-scene composition.", "motivation": "Current 3D generative models create objects in isolation, ignoring scene context. This work addresses the need for scene-aware stylization.", "method": "Combines differentiable ray tracing for texture/lighting optimization with pre-trained text-to-image diffusion models.", "result": "Applicable to diverse indoor/outdoor scenes and arbitrary objects, enabling realistic and controllable compositions.", "conclusion": "The method advances scene-aware 3D asset stylization, offering new levels of control and realism."}}
{"id": "2505.00137", "pdf": "https://arxiv.org/pdf/2505.00137", "abs": "https://arxiv.org/abs/2505.00137", "authors": ["Rushikesh Ubale", "Sujan K. K.", "Sangram Deshpande", "Gregory T. Byrd"], "title": "Toward Practical Quantum Machine Learning: A Novel Hybrid Quantum LSTM for Fraud Detection", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "comment": "11 pages ,8 figures", "summary": "We present a novel hybrid quantum-classical neural network architecture for\nfraud detection that integrates a classical Long Short-Term Memory (LSTM)\nnetwork with a variational quantum circuit. By leveraging quantum phenomena\nsuch as superposition and entanglement, our model enhances the feature\nrepresentation of sequential transaction data, capturing complex non-linear\npatterns that are challenging for purely classical models. A comprehensive data\npreprocessing pipeline is employed to clean, encode, balance, and normalize a\ncredit card fraud dataset, ensuring a fair comparison with baseline models.\nNotably, our hybrid approach achieves per-epoch training times in the range of\n45-65 seconds, which is significantly faster than similar architectures\nreported in the literature, where training typically requires several minutes\nper epoch. Both classical and quantum gradients are jointly optimized via a\nunified backpropagation procedure employing the parameter-shift rule for the\nquantum parameters. Experimental evaluations demonstrate competitive\nimprovements in accuracy, precision, recall, and F1 score relative to a\nconventional LSTM baseline. These results underscore the promise of hybrid\nquantum-classical techniques in advancing the efficiency and performance of\nfraud detection systems.\n  Keywords: Hybrid Quantum-Classical Neural Networks, Quantum Computing, Fraud\nDetection, Hybrid Quantum LSTM, Variational Quantum Circuit, Parameter-Shift\nRule, Financial Risk Analysis", "AI": {"tldr": "A hybrid quantum-classical neural network combining LSTM with a variational quantum circuit improves fraud detection by leveraging quantum properties, achieving faster training and better performance than classical models.", "motivation": "To enhance fraud detection by integrating quantum computing with classical neural networks, capturing complex patterns more efficiently.", "method": "Combines classical LSTM with a variational quantum circuit, uses a preprocessing pipeline, and jointly optimizes gradients via unified backpropagation.", "result": "Faster training (45-65 seconds per epoch) and improved accuracy, precision, recall, and F1 score compared to classical LSTM.", "conclusion": "Hybrid quantum-classical techniques show promise for advancing fraud detection systems in efficiency and performance."}}
{"id": "2402.08498", "pdf": "https://arxiv.org/pdf/2402.08498", "abs": "https://arxiv.org/abs/2402.08498", "authors": ["Preetika Verma", "Kokil Jaidka", "Svetlana Churina"], "title": "\"Reasoning\" with Rhetoric: On the Style-Evidence Tradeoff in LLM-Generated Counter-Arguments", "categories": ["cs.CL"], "comment": "22 pages, 9 figures, 13 tables", "summary": "Large language models (LLMs) play a key role in generating evidence-based and\nstylistic counter-arguments, yet their effectiveness in real-world applications\nhas been underexplored. Previous research often neglects the balance between\nevidentiality and style, which are crucial for persuasive arguments. To address\nthis, we evaluated the effectiveness of stylized evidence-based\ncounter-argument generation in Counterfire, a new dataset of 38,000\ncounter-arguments generated by revising counter-arguments to Reddit's\nChangeMyView community to follow different discursive styles. We evaluated\ngeneric and stylized counter-arguments from basic and fine-tuned models such as\nGPT-3.5, PaLM-2, and Koala-13B, as well as newer models (GPT-4o, Claude Haiku,\nLLaMA-3.1) focusing on rhetorical quality and persuasiveness. Our findings\nreveal that humans prefer stylized counter-arguments over the original outputs,\nwith GPT-3.5 Turbo performing well, though still not reaching human standards\nof rhetorical quality nor persuasiveness. Additionally, our work created a\nnovel argument triplets dataset for studying style control, with human\npreference labels that provide insights into the tradeoffs between evidence\nintegration and argument quality.", "AI": {"tldr": "The paper evaluates stylized evidence-based counter-argument generation using models like GPT-3.5 and GPT-4o, finding humans prefer stylized outputs, though they still fall short of human standards.", "motivation": "To address the underexplored effectiveness of LLMs in generating balanced, persuasive counter-arguments by combining evidentiality and style.", "method": "Evaluated generic and stylized counter-arguments from models (GPT-3.5, PaLM-2, etc.) on the Counterfire dataset, focusing on rhetorical quality and persuasiveness.", "result": "Humans preferred stylized counter-arguments, with GPT-3.5 Turbo performing well but not matching human standards. A novel dataset for style control was also created.", "conclusion": "Stylized counter-arguments improve persuasiveness, but LLMs still lag behind human performance. The dataset aids future research on style-evidence balance."}}
{"id": "2206.09535", "pdf": "https://arxiv.org/pdf/2206.09535", "abs": "https://arxiv.org/abs/2206.09535", "authors": ["Akira Matsui", "Emilio Ferrara"], "title": "Characterizing Human Actions in the Digital Platform by Temporal Context", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Recent advances in digital platforms generate rich, high-dimensional logs of\nhuman behavior, and machine learning models have helped social scientists\nexplain knowledge accumulation, communication, and information diffusion. Such\nmodels, however, almost always treat behavior as sequences of actions,\nabstracting the inter-temporal information among actions. To close this gap, we\nintroduce a two-scale Action-Timing Context(ATC) framework that jointly embeds\neach action and its time interval. ATC obtains low-dimensional representations\nof actions and characterizes them with inter-temporal information. We provide\nthree applications of ATC to real-world datasets and demonstrate that the\nmethod offers a unified view of human behavior. The presented qualitative\nfindings demonstrate that explicitly modeling inter-temporal context is\nessential for a comprehensive, interpretable understanding of human activity on\ndigital platforms.", "AI": {"tldr": "The paper introduces the Action-Timing Context (ATC) framework to model human behavior on digital platforms by embedding actions and their time intervals, addressing the gap in inter-temporal information.", "motivation": "Existing models treat behavior as action sequences, ignoring inter-temporal context, which limits understanding of human activity.", "method": "The ATC framework jointly embeds actions and their time intervals to capture inter-temporal information in low-dimensional representations.", "result": "Applied to real-world datasets, ATC provides a unified view of human behavior, showing the importance of inter-temporal context.", "conclusion": "Explicitly modeling inter-temporal context is crucial for interpretable and comprehensive understanding of human behavior on digital platforms."}}
{"id": "2401.03048", "pdf": "https://arxiv.org/pdf/2401.03048", "abs": "https://arxiv.org/abs/2401.03048", "authors": ["Xin Ma", "Yaohui Wang", "Xinyuan Chen", "Gengyun Jia", "Ziwei Liu", "Yuan-Fang Li", "Cunjian Chen", "Yu Qiao"], "title": "Latte: Latent Diffusion Transformer for Video Generation", "categories": ["cs.CV"], "comment": "Accepted by Transactions on Machine Learning Research 2025; Project\n  Page: https://maxin-cn.github.io/latte_project", "summary": "We propose Latte, a novel Latent Diffusion Transformer for video generation.\nLatte first extracts spatio-temporal tokens from input videos and then adopts a\nseries of Transformer blocks to model video distribution in the latent space.\nIn order to model a substantial number of tokens extracted from videos, four\nefficient variants are introduced from the perspective of decomposing the\nspatial and temporal dimensions of input videos. To improve the quality of\ngenerated videos, we determine the best practices of Latte through rigorous\nexperimental analysis, including video clip patch embedding, model variants,\ntimestep-class information injection, temporal positional embedding, and\nlearning strategies. Our comprehensive evaluation demonstrates that Latte\nachieves state-of-the-art performance across four standard video generation\ndatasets, i.e., FaceForensics, SkyTimelapse, UCF101, and Taichi-HD. In\naddition, we extend Latte to the text-to-video generation (T2V) task, where\nLatte achieves results that are competitive with recent T2V models. We strongly\nbelieve that Latte provides valuable insights for future research on\nincorporating Transformers into diffusion models for video generation.", "AI": {"tldr": "Latte is a Latent Diffusion Transformer for video generation, achieving state-of-the-art results by modeling video distribution in latent space with efficient variants and best practices.", "motivation": "To advance video generation by integrating Transformers into diffusion models, addressing the challenge of modeling numerous spatio-temporal tokens.", "method": "Extracts spatio-temporal tokens, uses Transformer blocks, and introduces efficient variants for spatial and temporal decomposition. Best practices include patch embedding, timestep-class injection, and learning strategies.", "result": "State-of-the-art performance on FaceForensics, SkyTimelapse, UCF101, and Taichi-HD datasets, with competitive text-to-video generation results.", "conclusion": "Latte offers insights for future research on Transformer-based diffusion models in video generation."}}
{"id": "2505.00195", "pdf": "https://arxiv.org/pdf/2505.00195", "abs": "https://arxiv.org/abs/2505.00195", "authors": ["Aditya Karan", "Nicholas Vincent", "Karrie Karahalios", "Hari Sundaram"], "title": "Algorithmic Collective Action with Two Collectives", "categories": ["cs.CY", "cs.GT", "cs.LG"], "comment": null, "summary": "Given that data-dependent algorithmic systems have become impactful in more\ndomains of life, the need for individuals to promote their own interests and\nhold algorithms accountable has grown. To have meaningful influence,\nindividuals must band together to engage in collective action. Groups that\nengage in such algorithmic collective action are likely to vary in size,\nmembership characteristics, and crucially, objectives. In this work, we\nintroduce a first of a kind framework for studying collective action with two\nor more collectives that strategically behave to manipulate data-driven\nsystems. With more than one collective acting on a system, unexpected\ninteractions may occur. We use this framework to conduct experiments with\nlanguage model-based classifiers and recommender systems where two collectives\neach attempt to achieve their own individual objectives. We examine how\ndiffering objectives, strategies, sizes, and homogeneity can impact a\ncollective's efficacy. We find that the unintentional interactions between\ncollectives can be quite significant; a collective acting in isolation may be\nable to achieve their objective (e.g., improve classification outcomes for\nthemselves or promote a particular item), but when a second collective acts\nsimultaneously, the efficacy of the first group drops by as much as $75\\%$. We\nfind that, in the recommender system context, neither fully heterogeneous nor\nfully homogeneous collectives stand out as most efficacious and that\nheterogeneity's impact is secondary compared to collective size. Our results\nsignal the need for more transparency in both the underlying algorithmic models\nand the different behaviors individuals or collectives may take on these\nsystems. This approach also allows collectives to hold algorithmic system\ndevelopers accountable and provides a framework for people to actively use\ntheir own data to promote their own interests.", "AI": {"tldr": "A framework for studying collective action in manipulating data-driven systems reveals significant interactions between groups, impacting efficacy and highlighting the need for transparency.", "motivation": "The rise of data-dependent algorithmic systems necessitates collective action for accountability and individual interests, but interactions between multiple collectives are poorly understood.", "method": "Introduces a framework to study collective action with experiments on language model classifiers and recommender systems, analyzing objectives, strategies, size, and homogeneity.", "result": "Interactions between collectives reduce efficacy by up to 75%; neither fully heterogeneous nor homogeneous collectives are most effective, with size being more impactful than heterogeneity.", "conclusion": "The study underscores the need for algorithmic transparency and provides a tool for collectives to advocate for their interests and hold developers accountable."}}
{"id": "2405.04532", "pdf": "https://arxiv.org/pdf/2405.04532", "abs": "https://arxiv.org/abs/2405.04532", "authors": ["Yujun Lin", "Haotian Tang", "Shang Yang", "Zhekai Zhang", "Guangxuan Xiao", "Chuang Gan", "Song Han"], "title": "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PF"], "comment": "The first three authors contribute equally to this project and are\n  listed in the alphabetical order. Yujun Lin leads the quantization algorithm,\n  Haotian Tang and Shang Yang lead the GPU kernels and the serving system. Code\n  is available at https://github.com/mit-han-lab/omniserve", "summary": "Quantization can accelerate large language model (LLM) inference. Going\nbeyond INT8 quantization, the research community is actively exploring even\nlower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization\ntechniques only accelerate low-batch, edge LLM inference, failing to deliver\nperformance gains in large-batch, cloud-based LLM serving. We uncover a\ncritical issue: existing INT4 quantization methods suffer from significant\nruntime overhead (20-90%) when dequantizing either weights or partial sums on\nGPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization\nalgorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands\nfor quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented\nby the QServe inference library that achieves measured speedup. The key insight\ndriving QServe is that the efficiency of LLM serving on GPUs is critically\ninfluenced by operations on low-throughput CUDA cores. Building upon this\ninsight, in QoQ algorithm, we introduce progressive quantization that can allow\nlow dequantization overhead in W4A8 GEMM. Additionally, we develop\nSmoothAttention to effectively mitigate the accuracy degradation incurred by\n4-bit KV quantization. In the QServe system, we perform compute-aware weight\nreordering and take advantage of register-level parallelism to reduce\ndequantization latency. We also make fused attention memory-bound, harnessing\nthe performance gain brought by KV4 quantization. As a result, QServe improves\nthe maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x\non L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to\nTensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput\nthan TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of\nLLM serving by 3x. Code is available at\nhttps://github.com/mit-han-lab/omniserve.", "AI": {"tldr": "QoQ introduces a W4A8KV4 quantization method (4-bit weight, 8-bit activation, 4-bit KV cache) to reduce GPU runtime overhead in LLM serving, achieving significant throughput gains and cost savings.", "motivation": "Existing INT4 quantization methods fail to deliver performance gains in large-batch, cloud-based LLM serving due to high dequantization overhead.", "method": "QoQ uses progressive quantization for low overhead in W4A8 GEMM and SmoothAttention to mitigate accuracy loss from 4-bit KV quantization. QServe optimizes dequantization and attention operations.", "result": "QServe improves throughput by 1.2x-3.5x on various models and GPUs, reducing serving costs by 3x.", "conclusion": "QoQ and QServe effectively address INT4 quantization challenges, enabling efficient, cost-effective LLM serving."}}
{"id": "2303.15201", "pdf": "https://arxiv.org/pdf/2303.15201", "abs": "https://arxiv.org/abs/2303.15201", "authors": ["Ran Wei", "Anthony D. McDonald", "Alfredo Garcia", "Gustav Markkula", "Johan Engstrom", "Matthew O'Kelly"], "title": "Learning An Active Inference Model of Driver Perception and Control: Application to Vehicle Car-Following", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "In this paper we introduce a general estimation methodology for learning a\nmodel of human perception and control in a sensorimotor control task based upon\na finite set of demonstrations. The model's structure consists of i the agent's\ninternal representation of how the environment and associated observations\nevolve as a result of control actions and ii the agent's preferences over\nobservable outcomes. We consider a model's structure specification consistent\nwith active inference, a theory of human perception and behavior from cognitive\nscience. According to active inference, the agent acts upon the world so as to\nminimize surprise defined as a measure of the extent to which an agent's\ncurrent sensory observations differ from its preferred sensory observations. We\npropose a bi-level optimization approach to estimation which relies on a\nstructural assumption on prior distributions that parameterize the statistical\naccuracy of the human agent's model of the environment. To illustrate the\nproposed methodology, we present the estimation of a model for car-following\nbehavior based upon a naturalistic dataset. Overall, the results indicate that\nlearning active inference models of human perception and control from data is a\npromising alternative to black-box models of driving.", "AI": {"tldr": "A method for learning human perception and control models from demonstrations, using active inference theory and bi-level optimization, applied to car-following behavior.", "motivation": "To develop a data-driven alternative to black-box models for understanding human sensorimotor control tasks.", "method": "Bi-level optimization with structural assumptions on prior distributions, based on active inference theory.", "result": "Successful estimation of a car-following behavior model, showing promise for learning active inference models from data.", "conclusion": "Active inference models offer a viable alternative to black-box approaches for modeling human perception and control."}}
{"id": "2405.00507", "pdf": "https://arxiv.org/pdf/2405.00507", "abs": "https://arxiv.org/abs/2405.00507", "authors": ["Zhinan Yu", "Zheng Qin", "Yijie Tang", "Yongjun Wang", "Renjiao Yi", "Chenyang Zhu", "Kai Xu"], "title": "F2M-Reg: Unsupervised RGB-D Point Cloud Registration with Frame-to-Model Optimization", "categories": ["cs.CV"], "comment": null, "summary": "This work studies the problem of unsupervised RGB-D point cloud registration,\nwhich aims at training a robust registration model without ground-truth pose\nsupervision. Existing methods usually leverages unposed RGB-D sequences and\nadopt a frame-to-frame framework based on differentiable rendering to train the\nregistration model, which enforces the photometric and geometric consistency\nbetween the two frames for supervision. However, this frame-to-frame framework\nis vulnerable to inconsistent factors between different frames, e.g., lighting\nchanges, geometry occlusion, and reflective materials, which leads to\nsuboptimal convergence of the registration model. In this paper, we propose a\nnovel frame-to-model optimization framework named F2M-Reg for unsupervised\nRGB-D point cloud registration. We leverage the neural implicit field as a\nglobal model of the scene and optimize the estimated poses of the frames by\nregistering them to the global model, and the registration model is\nsubsequently trained with the optimized poses. Thanks to the global encoding\ncapability of neural implicit field, our frame-to-model framework is\nsignificantly more robust to inconsistent factors between different frames and\nthus can provide better supervision for the registration model. Besides, we\ndemonstrate that F2M-Reg can be further enhanced by a simplistic synthetic\nwarming-up strategy. To this end, we construct a photorealistic synthetic\ndataset named Sim-RGBD to initialize the registration model for the\nframe-to-model optimization on real-world RGB-D sequences. Extensive\nexperiments on four challenging benchmarks have shown that our method surpasses\nthe previous state-of-the-art counterparts by a large margin, especially under\nscenarios with severe lighting changes and low overlap. Our code and models are\navailable at https://github.com/MrIsland/F2M_Reg.", "AI": {"tldr": "F2M-Reg is a novel unsupervised RGB-D point cloud registration method using a frame-to-model framework with neural implicit fields, outperforming state-of-the-art methods.", "motivation": "Existing frame-to-frame methods are sensitive to inconsistencies like lighting changes and occlusions, leading to suboptimal performance.", "method": "Proposes F2M-Reg, leveraging neural implicit fields for global scene modeling and pose optimization, enhanced by synthetic data warming-up.", "result": "Outperforms previous methods significantly, especially in challenging scenarios like lighting changes and low overlap.", "conclusion": "F2M-Reg's frame-to-model approach with neural implicit fields provides robust unsupervised registration, validated by extensive benchmarks."}}
{"id": "2505.00229", "pdf": "https://arxiv.org/pdf/2505.00229", "abs": "https://arxiv.org/abs/2505.00229", "authors": ["Mark Adams", "Kamillo Ferry", "Ruriko Yoshida"], "title": "Inference for max-linear Bayesian networks with noise", "categories": ["stat.ML", "cs.LG", "math.OC", "math.ST", "stat.TH", "14T90, 62A09, 62H30, 90C20, 90C90"], "comment": "18 pages, 10 figures. Short version to appear in the proceedings of\n  the 13th Workshop on Uncertainty Processing", "summary": "Max-Linear Bayesian Networks (MLBNs) provide a powerful framework for causal\ninference in extreme-value settings; we consider MLBNs with noise parameters\nwith a given topology in terms of the max-plus algebra by taking its logarithm.\nThen, we show that an estimator of a parameter for each edge in a directed\nacyclic graph (DAG) is distributed normally. We end this paper with\ncomputational experiments with the expectation and maximization (EM) algorithm\nand quadratic optimization.", "AI": {"tldr": "The paper introduces Max-Linear Bayesian Networks (MLBNs) for causal inference in extreme-value settings, analyzes their noise parameters using max-plus algebra, and proves normal distribution of edge parameter estimators in DAGs. Computational experiments with EM and quadratic optimization are also presented.", "motivation": "To address causal inference in extreme-value scenarios using MLBNs and analyze their parameter estimators.", "method": "Uses max-plus algebra for noise parameter analysis and derives estimators for DAG edges, followed by computational experiments with EM and quadratic optimization.", "result": "Shows that edge parameter estimators in MLBNs are normally distributed.", "conclusion": "Demonstrates the effectiveness of MLBNs and their estimators, supported by computational experiments."}}
{"id": "2405.11804", "pdf": "https://arxiv.org/pdf/2405.11804", "abs": "https://arxiv.org/abs/2405.11804", "authors": ["Minghao Wu", "Jiahao Xu", "Yulin Yuan", "Gholamreza Haffari", "Longyue Wang", "Weihua Luo", "Kaifu Zhang"], "title": "(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts", "categories": ["cs.CL"], "comment": "To appear at TACL", "summary": "Literary translation remains one of the most challenging frontiers in machine\ntranslation due to the complexity of capturing figurative language, cultural\nnuances, and unique stylistic elements. In this work, we introduce TransAgents,\na novel multi-agent framework that simulates the roles and collaborative\npractices of a human translation company, including a CEO, Senior Editor,\nJunior Editor, Translator, Localization Specialist, and Proofreader. The\ntranslation process is divided into two stages: a preparation stage where the\nteam is assembled and comprehensive translation guidelines are drafted, and an\nexecution stage that involves sequential translation, localization,\nproofreading, and a final quality check. Furthermore, we propose two innovative\nevaluation strategies: Monolingual Human Preference (MHP), which evaluates\ntranslations based solely on target language quality and cultural\nappropriateness, and Bilingual LLM Preference (BLP), which leverages large\nlanguage models like GPT-4} for direct text comparison. Although TransAgents\nachieves lower d-BLEU scores, due to the limited diversity of references, its\ntranslations are significantly better than those of other baselines and are\npreferred by both human evaluators and LLMs over traditional human references\nand GPT-4} translations. Our findings highlight the potential of multi-agent\ncollaboration in enhancing translation quality, particularly for longer texts.", "AI": {"tldr": "TransAgents, a multi-agent framework for literary translation, outperforms baselines and GPT-4 in human and LLM evaluations despite lower d-BLEU scores.", "motivation": "Literary translation is challenging due to figurative language and cultural nuances. Existing methods struggle with these complexities.", "method": "TransAgents simulates a human translation company with roles like CEO, editors, and specialists. It uses a two-stage process: preparation and execution, with innovative evaluation strategies (MHP and BLP).", "result": "TransAgents' translations are preferred by humans and LLMs over baselines and GPT-4, despite lower d-BLEU scores.", "conclusion": "Multi-agent collaboration improves literary translation quality, especially for longer texts."}}
{"id": "2311.06840", "pdf": "https://arxiv.org/pdf/2311.06840", "abs": "https://arxiv.org/abs/2311.06840", "authors": ["Bijan Mazaheri", "Siddharth Jain", "Matthew Cook", "Jehoshua Bruck"], "title": "Omitted Labels Induce Nontransitive Paradoxes in Causality", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.SI", "math.IT", "stat.ME"], "comment": "Accepted to appear in CLeaR 2025", "summary": "We explore \"omitted label contexts,\" in which training data is limited to a\nsubset of the possible labels. This setting is standard among specialized human\nexperts or specific, focused studies. By studying Simpson's paradox, we observe\nthat ``correct'' adjustments sometimes require non-exchangeable treatment and\ncontrol groups. A generalization of Simpson's paradox leads us to study\nnetworks of conclusions drawn from different contexts, within which a paradox\nof nontransitivity arises. We prove that the space of possible nontransitive\nstructures in these networks exactly corresponds to structures that form from\naggregating ranked-choice votes.", "AI": {"tldr": "The paper investigates omitted label contexts in training data, highlighting Simpson's paradox and nontransitive structures in networks of conclusions, linking them to ranked-choice voting.", "motivation": "To understand the implications of limited training data (omitted label contexts) and explore paradoxes like Simpson's paradox in such settings.", "method": "Study Simpson's paradox and generalize it to analyze networks of conclusions, identifying nontransitive structures.", "result": "The space of possible nontransitive structures in these networks matches those from aggregating ranked-choice votes.", "conclusion": "The findings connect omitted label contexts to nontransitive structures, revealing parallels with ranked-choice voting."}}
{"id": "2405.04489", "pdf": "https://arxiv.org/pdf/2405.04489", "abs": "https://arxiv.org/abs/2405.04489", "authors": ["Minh Tran", "Adrian De Luis", "Haitao Liao", "Ying Huang", "Roy McCann", "Alan Mantooth", "Jack Cothren", "Ngan Le"], "title": "S3Former: Self-supervised High-resolution Transformer for Solar PV Profiling", "categories": ["cs.CV"], "comment": "IEEE Transactions on Smart Grid", "summary": "As the impact of climate change escalates, the global necessity to transition\nto sustainable energy sources becomes increasingly evident. Renewable energies\nhave emerged as a viable solution for users, with Photovoltaic energy being a\nfavored choice for small installations due to its reliability and efficiency.\nAccurate mapping of PV installations is crucial for understanding the extension\nof its adoption and informing energy policy. To meet this need, we introduce\nS3Former, designed to segment solar panels from aerial imagery and provide size\nand location information critical for analyzing the impact of such\ninstallations on the grid. Solar panel identification is challenging due to\nfactors such as varying weather conditions, roof characteristics, Ground\nSampling Distance variations and lack of appropriate initialization weights for\noptimized training. To tackle these complexities, S3Former features a Masked\nAttention Mask Transformer incorporating a self-supervised learning pretrained\nbackbone. Specifically, our model leverages low-level and high-level features\nextracted from the backbone and incorporates an instance query mechanism\nincorporated on the Transformer architecture to enhance the localization of\nsolar PV installations. We introduce a self-supervised learning phase (pretext\ntask) to improve the initialization weights on the backbone of S3Former. We\nevaluated S3Former using diverse datasets, demonstrate improvement\nstate-of-the-art models.", "AI": {"tldr": "S3Former, a model for segmenting solar panels from aerial imagery, addresses challenges like weather conditions and roof characteristics using a Masked Attention Mask Transformer and self-supervised learning, outperforming state-of-the-art models.", "motivation": "The need for accurate mapping of PV installations to understand adoption and inform energy policy drives the development of S3Former.", "method": "S3Former uses a Masked Attention Mask Transformer with a self-supervised learning pretrained backbone, leveraging low and high-level features and an instance query mechanism for better localization.", "result": "S3Former demonstrates improvements over state-of-the-art models in diverse datasets.", "conclusion": "S3Former effectively segments solar panels, providing critical data for energy policy and grid impact analysis."}}
{"id": "2505.00233", "pdf": "https://arxiv.org/pdf/2505.00233", "abs": "https://arxiv.org/abs/2505.00233", "authors": ["Kimihiro Yamazaki", "Takuya Konishi", "Yoshinobu Kawahara"], "title": "Explorative Curriculum Learning for Strongly Correlated Electron Systems", "categories": ["cond-mat.str-el", "cs.LG"], "comment": null, "summary": "Recent advances in neural network quantum states (NQS) have enabled\nhigh-accuracy predictions for complex quantum many-body systems such as\nstrongly correlated electron systems. However, the computational cost remains\nprohibitive, making exploration of the diverse parameters of interaction\nstrengths and other physical parameters inefficient. While transfer learning\nhas been proposed to mitigate this challenge, achieving generalization to\nlarge-scale systems and diverse parameter regimes remains difficult. To address\nthis limitation, we propose a novel curriculum learning framework based on\ntransfer learning for NQS. This facilitates efficient and stable exploration\nacross a vast parameter space of quantum many-body systems. In addition, by\ninterpreting NQS transfer learning through a perturbative lens, we demonstrate\nhow prior physical knowledge can be flexibly incorporated into the curriculum\nlearning process. We also propose Pairing-Net, an architecture to practically\nimplement this strategy for strongly correlated electron systems, and\nempirically verify its effectiveness. Our results show an approximately\n200-fold speedup in computation and a marked improvement in optimization\nstability compared to conventional methods.", "AI": {"tldr": "A curriculum learning framework for neural network quantum states (NQS) is proposed, combining transfer learning and perturbative insights to improve efficiency and stability in exploring quantum many-body systems.", "motivation": "The high computational cost and inefficiency in exploring diverse parameters of quantum many-body systems motivate the need for a more effective approach.", "method": "A novel curriculum learning framework based on transfer learning is introduced, incorporating prior physical knowledge. Pairing-Net architecture is proposed for practical implementation.", "result": "The method achieves a 200-fold speedup in computation and enhances optimization stability compared to conventional approaches.", "conclusion": "The framework successfully addresses scalability and generalization challenges in NQS, offering a practical solution for studying complex quantum systems."}}
{"id": "2407.20906", "pdf": "https://arxiv.org/pdf/2407.20906", "abs": "https://arxiv.org/abs/2407.20906", "authors": ["Shican Wu", "Xiao Ma", "Dehui Luo", "Lulu Li", "Xiangcheng Shi", "Xin Chang", "Xiaoyun Lin", "Ran Luo", "Chunlei Pei", "Changying Du", "Zhi-Jian Zhao", "Jinlong Gong"], "title": "Automated Review Generation Method Based on Large Language Models", "categories": ["cs.CL", "cs.AI", "physics.data-an"], "comment": "Code: https://github.com/TJU-ECAT-AI/AutomaticReviewGeneration Data:\n  https://github.com/TJU-ECAT-AI/AutomaticReviewGenerationData This research\n  has been invited for a Short Oral presentation at the 18th ICC -\n  International Congress on Catalysis, taking place in Lyon, France from July\n  14-19, 2024 Published at https://doi.org/10.1093/nsr/nwaf169 for newer\n  edition", "summary": "Literature research, vital for scientific work, faces the challenge of\nsurging information volumes exceeding researchers' processing capabilities. We\npresent an automated review generation method based on large language models\n(LLMs) to overcome efficiency bottlenecks and reduce cognitive load. Our\nstatistically validated evaluation framework demonstrates that the generated\nreviews match or exceed manual quality, offering broad applicability across\nresearch fields without requiring users' domain knowledge. Applied to propane\ndehydrogenation (PDH) catalysts, our method swiftly analyzed 343 articles,\naveraging seconds per article per LLM account, producing comprehensive reviews\nspanning 35 topics, with extended analysis of 1041 articles providing insights\ninto catalysts' properties. Through multi-layered quality control, we\neffectively mitigated LLMs' hallucinations, with expert verification confirming\naccuracy and citation integrity while demonstrating hallucination risks reduced\nto below 0.5\\% with 95\\% confidence. Released Windows application enables\none-click review generation, enhancing research productivity and literature\nrecommendation efficiency while setting the stage for broader scientific\nexplorations.", "AI": {"tldr": "An automated review generation method using LLMs efficiently processes large literature volumes, matching or surpassing manual quality, with minimal hallucination risks.", "motivation": "Address the challenge of processing overwhelming literature volumes in research by automating review generation to improve efficiency and reduce cognitive load.", "method": "Utilizes large language models (LLMs) for automated review generation, validated by a statistical framework, and applied to propane dehydrogenation (PDH) catalysts.", "result": "Generated reviews match/exceed manual quality, analyzed 343 articles in seconds, and reduced hallucination risks to below 0.5%.", "conclusion": "The method enhances research productivity and literature recommendation efficiency, with potential for broader scientific applications."}}
{"id": "2402.07033", "pdf": "https://arxiv.org/pdf/2402.07033", "abs": "https://arxiv.org/abs/2402.07033", "authors": ["Keisuke Kamahori", "Tian Tang", "Yile Gu", "Kan Zhu", "Baris Kasikci"], "title": "Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.OS"], "comment": "ICLR2025", "summary": "Large Language Models (LLMs) with the Mixture-of-Experts (MoE) architectures\nhave shown promising performance on various tasks. However, due to the huge\nmodel sizes, running them in resource-constrained environments where the GPU\nmemory is not abundant is challenging. Some existing systems propose to use CPU\nresources to solve that, but they either suffer from the significant overhead\nof frequently moving data between CPU and GPU, or fail to consider distinct\ncharacteristics of CPUs and GPUs. This paper proposes Fiddler, a\nresource-efficient inference system for MoE models with limited GPU resources.\nFiddler strategically utilizes CPU and GPU resources by determining the optimal\nexecution strategy. Our evaluation shows that, unlike state-of-the-art systems\nthat optimize for specific scenarios such as single batch inference or long\nprefill, Fiddler performs better in all scenarios. Compared against different\nbaselines, Fiddler achieves 1.26 times speed up in single batch inference, 1.30\ntimes in long prefill processing, and 11.57 times in beam search inference. The\ncode of Fiddler is publicly available at https://github.com/efeslab/fiddler.", "AI": {"tldr": "Fiddler is a resource-efficient inference system for MoE models, optimizing CPU and GPU usage to outperform existing systems in various scenarios.", "motivation": "Running large MoE models in resource-constrained environments is challenging due to GPU memory limitations and inefficient CPU-GPU data handling.", "method": "Fiddler strategically determines the optimal execution strategy for CPU and GPU resource utilization.", "result": "Fiddler achieves speedups of 1.26x in single batch inference, 1.30x in long prefill, and 11.57x in beam search compared to baselines.", "conclusion": "Fiddler is a versatile and efficient solution for MoE model inference in resource-limited settings."}}
{"id": "2405.11536", "pdf": "https://arxiv.org/pdf/2405.11536", "abs": "https://arxiv.org/abs/2405.11536", "authors": ["Mohamed Nagy", "Naoufel Werghi", "Bilal Hassan", "Jorge Dias", "Majid Khonji"], "title": "RobMOT: Robust 3D Multi-Object Tracking by Observational Noise and State Estimation Drift Mitigation on LiDAR PointCloud", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "This paper addresses limitations in 3D tracking-by-detection methods,\nparticularly in identifying legitimate trajectories and reducing state\nestimation drift in Kalman filters. Existing methods often use threshold-based\nfiltering for detection scores, which can fail for distant and occluded\nobjects, leading to false positives. To tackle this, we propose a novel track\nvalidity mechanism and multi-stage observational gating process, significantly\nreducing ghost tracks and enhancing tracking performance. Our method achieves a\n$29.47\\%$ improvement in Multi-Object Tracking Accuracy (MOTA) on the KITTI\nvalidation dataset with the Second detector. Additionally, a refined Kalman\nfilter term reduces localization noise, improving higher-order tracking\naccuracy (HOTA) by $4.8\\%$. The online framework, RobMOT, outperforms\nstate-of-the-art methods across multiple detectors, with HOTA improvements of\nup to $3.92\\%$ on the KITTI testing dataset and $8.7\\%$ on the validation\ndataset, while achieving low identity switch scores. RobMOT excels in\nchallenging scenarios, tracking distant objects and prolonged occlusions, with\na $1.77\\%$ MOTA improvement on the Waymo Open dataset, and operates at a\nremarkable 3221 FPS on a single CPU, proving its efficiency for real-time\nmulti-object tracking.", "AI": {"tldr": "Proposes RobMOT, a novel 3D tracking method with improved accuracy and efficiency, reducing false positives and drift.", "motivation": "Addresses limitations in 3D tracking-by-detection, especially for distant/occluded objects and Kalman filter drift.", "method": "Introduces track validity mechanism and multi-stage observational gating, refining Kalman filter terms.", "result": "Achieves 29.47% MOTA and 4.8% HOTA improvements on KITTI, with high efficiency (3221 FPS).", "conclusion": "RobMOT outperforms state-of-the-art methods, excelling in challenging scenarios and real-time tracking."}}
{"id": "2505.00237", "pdf": "https://arxiv.org/pdf/2505.00237", "abs": "https://arxiv.org/abs/2505.00237", "authors": ["Ze Zhang", "Georg Hess", "Junjie Hu", "Emmanuel Dean", "Lennart Svensson", "Knut \u00c5kesson"], "title": "Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "Submitted to IEEE RA-L", "summary": "This paper proposes an integrated approach for the safe and efficient control\nof mobile robots in dynamic and uncertain environments. The approach consists\nof two key steps: one-shot multimodal motion prediction to anticipate motions\nof dynamic obstacles and model predictive control to incorporate these\npredictions into the motion planning process. Motion prediction is driven by an\nenergy-based neural network that generates high-resolution, multi-step\npredictions in a single operation. The prediction outcomes are further utilized\nto create geometric shapes formulated as mathematical constraints. Instead of\ntreating each dynamic obstacle individually, predicted obstacles are grouped by\nproximity in an unsupervised way to improve performance and efficiency. The\noverall collision-free navigation is handled by model predictive control with a\nspecific design for proactive dynamic obstacle avoidance. The proposed approach\nallows mobile robots to navigate effectively in dynamic environments. Its\nperformance is accessed across various scenarios that represent typical\nwarehouse settings. The results demonstrate that the proposed approach\noutperforms other existing dynamic obstacle avoidance methods.", "AI": {"tldr": "An integrated approach for safe and efficient mobile robot control in dynamic environments, combining multimodal motion prediction and model predictive control, outperforming existing methods.", "motivation": "To enable mobile robots to navigate safely and efficiently in dynamic and uncertain environments by anticipating obstacle motions and proactively avoiding collisions.", "method": "Uses one-shot multimodal motion prediction with an energy-based neural network and model predictive control for motion planning, grouping obstacles by proximity for efficiency.", "result": "Demonstrates superior performance in dynamic obstacle avoidance across typical warehouse scenarios compared to existing methods.", "conclusion": "The proposed approach effectively enhances mobile robot navigation in dynamic environments, offering improved safety and efficiency."}}
{"id": "2410.01957", "pdf": "https://arxiv.org/pdf/2410.01957", "abs": "https://arxiv.org/abs/2410.01957", "authors": ["Min-Hsuan Yeh", "Jeffrey Wang", "Xuefeng Du", "Seongheon Park", "Leitian Tao", "Shawn Im", "Yixuan Li"], "title": "Challenges and Future Directions of Data-Centric AI Alignment", "categories": ["cs.CL"], "comment": "ICML 2025", "summary": "As AI systems become increasingly capable and influential, ensuring their\nalignment with human values, preferences, and goals has become a critical\nresearch focus. Current alignment methods primarily focus on designing\nalgorithms and loss functions but often underestimate the crucial role of data.\nThis paper advocates for a shift towards data-centric AI alignment, emphasizing\nthe need to enhance the quality and representativeness of data used in aligning\nAI systems. In this position paper, we highlight key challenges associated with\nboth human-based and AI-based feedback within the data-centric alignment\nframework. Through qualitative analysis, we identify multiple sources of\nunreliability in human feedback, as well as problems related to temporal drift,\ncontext dependence, and AI-based feedback failing to capture human values due\nto inherent model limitations. We propose future research directions, including\nimproved feedback collection practices, robust data-cleaning methodologies, and\nrigorous feedback verification processes. We call for future research into\nthese critical directions to ensure, addressing gaps that persist in\nunderstanding and improving data-centric alignment practices.", "AI": {"tldr": "The paper advocates for a data-centric approach to AI alignment, highlighting challenges in human and AI feedback, and proposes future research directions to improve data quality and reliability.", "motivation": "Ensuring AI systems align with human values is critical, but current methods overlook data quality and representativeness.", "method": "Qualitative analysis of challenges in human and AI feedback within data-centric alignment.", "result": "Identified unreliability in human feedback and limitations in AI feedback, proposing improved practices and methodologies.", "conclusion": "Future research should focus on enhancing data-centric alignment through better feedback collection, cleaning, and verification."}}
{"id": "2403.00108", "pdf": "https://arxiv.org/pdf/2403.00108", "abs": "https://arxiv.org/abs/2403.00108", "authors": ["Hongyi Liu", "Shaochen Zhong", "Xintong Sun", "Minghao Tian", "Mohsen Hariri", "Zirui Liu", "Ruixiang Tang", "Zhimeng Jiang", "Jiayi Yuan", "Yu-Neng Chuang", "Li Li", "Soo-Hyun Choi", "Rui Chen", "Vipin Chaudhary", "Xia Hu"], "title": "LoRATK: LoRA Once, Backdoor Everywhere in the Share-and-Play Ecosystem", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Finetuning LLMs with LoRA has gained significant popularity due to its\nsimplicity and effectiveness. Often, users may even find pluggable,\ncommunity-shared LoRAs to enhance their base models for a specific downstream\ntask of interest; enjoying a powerful, efficient, yet customized LLM experience\nwith negligible investment. However, this convenient share-and-play ecosystem\nalso introduces a new attack surface, where attackers can distribute malicious\nLoRAs to a community eager to try out shared assets. Despite the high-risk\npotential, no prior art has comprehensively explored LoRA's attack surface\nunder the downstream-enhancing share-and-play context. In this paper, we\ninvestigate how backdoors can be injected into task-enhancing LoRAs and examine\nthe mechanisms of such infections. We find that with a simple, efficient, yet\nspecific recipe, a backdoor LoRA can be trained once and then seamlessly merged\n(in a training-free fashion) with multiple task-enhancing LoRAs, retaining both\nits malicious backdoor and benign downstream capabilities. This allows\nattackers to scale the distribution of compromised LoRAs with minimal effort by\nleveraging the rich pool of existing shared LoRA assets. We note that such\nmerged LoRAs are particularly infectious -- because their malicious intent is\ncleverly concealed behind improved downstream capabilities, creating a strong\nincentive for voluntary download -- and dangerous -- because under local\ndeployment, no safety measures exist to intervene when things go wrong. Our\nwork is among the first to study this new threat model of training-free\ndistribution of downstream-capable-yet-backdoor-injected LoRAs, highlighting\nthe urgent need for heightened security awareness in the LoRA ecosystem.\nWarning: This paper contains offensive content and involves a real-life\ntragedy.", "AI": {"tldr": "The paper explores the security risks of malicious LoRAs in the share-and-play ecosystem, demonstrating how backdoors can be injected and spread efficiently.", "motivation": "The convenience of community-shared LoRAs introduces a security threat, with no prior research on this attack surface.", "method": "Investigates backdoor injection into LoRAs, showing how a single malicious LoRA can merge with multiple task-enhancing LoRAs without training.", "result": "Merged LoRAs retain malicious backdoors and benign capabilities, making them infectious and dangerous.", "conclusion": "Highlights the urgent need for security awareness in the LoRA ecosystem due to this new threat model."}}
{"id": "2405.18416", "pdf": "https://arxiv.org/pdf/2405.18416", "abs": "https://arxiv.org/abs/2405.18416", "authors": ["Jingwei Xu", "Yikai Wang", "Yiqun Zhao", "Yanwei Fu", "Shenghua Gao"], "title": "3D StreetUnveiler with Semantic-aware 2DGS -- a simple baseline", "categories": ["cs.CV"], "comment": "Project page: https://streetunveiler.github.io", "summary": "Unveiling an empty street from crowded observations captured by in-car\ncameras is crucial for autonomous driving. However, removing all temporarily\nstatic objects, such as stopped vehicles and standing pedestrians, presents a\nsignificant challenge. Unlike object-centric 3D inpainting, which relies on\nthorough observation in a small scene, street scene cases involve long\ntrajectories that differ from previous 3D inpainting tasks. The camera-centric\nmoving environment of captured videos further complicates the task due to the\nlimited degree and time duration of object observation. To address these\nobstacles, we introduce StreetUnveiler to reconstruct an empty street.\nStreetUnveiler learns a 3D representation of the empty street from crowded\nobservations. Our representation is based on the hard-label semantic 2D\nGaussian Splatting (2DGS) for its scalability and ability to identify Gaussians\nto be removed. We inpaint rendered image after removing unwanted Gaussians to\nprovide pseudo-labels and subsequently re-optimize the 2DGS. Given its temporal\ncontinuous movement, we divide the empty street scene into observed,\npartial-observed, and unobserved regions, which we propose to locate through a\nrendered alpha map. This decomposition helps us to minimize the regions that\nneed to be inpainted. To enhance the temporal consistency of the inpainting, we\nintroduce a novel time-reversal framework to inpaint frames in reverse order\nand use later frames as references for earlier frames to fully utilize the\nlong-trajectory observations. Our experiments conducted on the street scene\ndataset successfully reconstructed a 3D representation of the empty street. The\nmesh representation of the empty street can be extracted for further\napplications. The project page and more visualizations can be found at:\nhttps://streetunveiler.github.io", "AI": {"tldr": "StreetUnveiler reconstructs an empty street from crowded in-car camera footage using 3D representation and 2D Gaussian Splatting, with a novel time-reversal inpainting framework for consistency.", "motivation": "Autonomous driving requires clear street views, but removing static objects like stopped vehicles is challenging due to limited observation in moving environments.", "method": "StreetUnveiler uses 2D Gaussian Splatting (2DGS) to identify and remove unwanted objects, inpaints rendered images, and optimizes 2DGS. A time-reversal framework ensures temporal consistency.", "result": "The method successfully reconstructs a 3D empty street representation, with mesh extraction for further use.", "conclusion": "StreetUnveiler effectively addresses the challenge of reconstructing empty streets from crowded observations, benefiting autonomous driving applications."}}
{"id": "2505.00242", "pdf": "https://arxiv.org/pdf/2505.00242", "abs": "https://arxiv.org/abs/2505.00242", "authors": ["Shingo Higashiguchi", "Yasuko Matsubara", "Koki Kawabata", "Taichi Murayama", "Yasushi Sakurai"], "title": "D-Tracker: Modeling Interest Diffusion in Social Activity Tensor Data Streams", "categories": ["cs.SI", "cs.LG"], "comment": "ACM SIGKDD 2025 (KDD2025)", "summary": "Large quantities of social activity data, such as weekly web search volumes\nand the number of new infections with infectious diseases, reflect peoples'\ninterests and activities. It is important to discover temporal patterns from\nsuch data and to forecast future activities accurately. However, modeling and\nforecasting social activity data streams is difficult because they are\nhigh-dimensional and composed of multiple time-varying dynamics such as trends,\nseasonality, and interest diffusion. In this paper, we propose D-Tracker, a\nmethod for continuously capturing time-varying temporal patterns within social\nactivity tensor data streams and forecasting future activities. Our proposed\nmethod has the following properties: (a) Interpretable: it incorporates the\npartial differential equation into a tensor decomposition framework and\ncaptures time-varying temporal patterns such as trends, seasonality, and\ninterest diffusion between locations in an interpretable manner; (b) Automatic:\nit has no hyperparameters and continuously models tensor data streams fully\nautomatically; (c) Scalable: the computation time of D-Tracker is independent\nof the time series length. Experiments using web search volume data obtained\nfrom GoogleTrends, and COVID-19 infection data obtained from COVID-19 Open Data\nRepository show that our method can achieve higher forecasting accuracy in less\ncomputation time than existing methods while extracting the interest diffusion\nbetween locations. Our source code and datasets are available at\n{https://github.com/Higashiguchi-Shingo/D-Tracker.", "AI": {"tldr": "D-Tracker is a method for modeling and forecasting high-dimensional social activity data streams by capturing time-varying patterns like trends and seasonality interpretably, automatically, and scalably.", "motivation": "Social activity data (e.g., web searches, infection rates) are complex and high-dimensional, making accurate forecasting challenging due to multiple time-varying dynamics.", "method": "D-Tracker integrates partial differential equations into tensor decomposition to model trends, seasonality, and interest diffusion interpretably and automatically, without hyperparameters.", "result": "Experiments on GoogleTrends and COVID-19 data show D-Tracker outperforms existing methods in accuracy and computation time while revealing interest diffusion.", "conclusion": "D-Tracker provides an efficient, interpretable, and scalable solution for forecasting social activity data streams."}}
{"id": "2410.20774", "pdf": "https://arxiv.org/pdf/2410.20774", "abs": "https://arxiv.org/abs/2410.20774", "authors": ["Dongryeol Lee", "Yerin Hwang", "Yongil Kim", "Joonsuk Park", "Kyomin Jung"], "title": "Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation", "categories": ["cs.CL"], "comment": "NAACL 2025 Oral (21 pages, 6 figures, 15 tables)", "summary": "In line with the principle of honesty, there has been a growing effort to\ntrain large language models (LLMs) to generate outputs containing epistemic\nmarkers. However, evaluation in the presence of epistemic markers has been\nlargely overlooked, raising a critical question: Could the use of epistemic\nmarkers in LLM-generated outputs lead to unintended negative consequences? To\naddress this, we present EMBER, a benchmark designed to assess the robustness\nof LLM-judges to epistemic markers in both single and pairwise evaluation\nsettings. Our findings, based on evaluations using EMBER, reveal that all\ntested LLM-judges, including GPT-4o, show a notable lack of robustness in the\npresence of epistemic markers. Specifically, we observe a negative bias toward\nepistemic markers, with a stronger bias against markers expressing uncertainty.\nThis suggests that LLM-judges are influenced by the presence of these markers\nand do not focus solely on the correctness of the content.", "AI": {"tldr": "The paper introduces EMBER, a benchmark to evaluate LLM-judges' robustness to epistemic markers, revealing a negative bias in their assessments.", "motivation": "To address the overlooked issue of how epistemic markers in LLM outputs might lead to unintended negative consequences.", "method": "Developed EMBER, a benchmark for assessing LLM-judges' robustness to epistemic markers in single and pairwise evaluations.", "result": "All tested LLM-judges, including GPT-4o, showed a lack of robustness and a negative bias toward epistemic markers, especially those expressing uncertainty.", "conclusion": "LLM-judges are influenced by epistemic markers, not just content correctness, highlighting a need for improved evaluation frameworks."}}
{"id": "2404.17525", "pdf": "https://arxiv.org/pdf/2404.17525", "abs": "https://arxiv.org/abs/2404.17525", "authors": ["Yayati Jadhav", "Amir Barati Farimani"], "title": "Large Language Model Agent as a Mechanical Designer", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Conventional mechanical design follows an iterative process in which initial\nconcepts are refined through cycles of expert assessment and resource-intensive\nFinite Element Method (FEM) analysis to meet performance goals. While machine\nlearning models have been developed to assist in parts of this process, they\ntypically require large datasets, extensive training, and are often tailored to\nspecific tasks, limiting their generalizability. To address these limitations,\nwe propose a framework that leverages a pretrained Large Language Model (LLM)\nin conjunction with an FEM module to autonomously generate, evaluate, and\nrefine structural designs based on performance specifications and numerical\nfeedback. The LLM operates without domain-specific fine-tuning, using general\nreasoning to propose design candidates, interpret FEM-derived performance\nmetrics, and apply structurally sound modifications. Using 2D truss structures\nas a testbed, we show that the LLM can effectively navigate highly discrete and\nmulti-faceted design spaces, balance competing objectives, and identify\nconvergence when further optimization yields diminishing returns. Compared to\nNon-dominated Sorting Genetic Algorithm II (NSGA-II), our method achieves\nfaster convergence and fewer FEM evaluations. Experiments with varying\ntemperature settings (0.5, 1.0, 1.2) and model sizes (GPT-4.1 and GPT-4.1-mini)\nindicate that smaller models yield higher constraint satisfaction with fewer\nsteps, while lower temperatures enhance design consistency. These results\nestablish LLMs as a promising new class of reasoning-based, natural\nlanguage-driven optimizers for autonomous design and iterative structural\nrefinement.", "AI": {"tldr": "A framework combining pretrained LLMs and FEM autonomously generates and refines structural designs, outperforming traditional methods like NSGA-II in speed and efficiency.", "motivation": "To overcome limitations of conventional iterative design processes and specialized ML models by leveraging general-purpose LLMs for broader applicability.", "method": "Uses a pretrained LLM with an FEM module to propose, evaluate, and refine designs without domain-specific training, tested on 2D truss structures.", "result": "Achieves faster convergence and fewer FEM evaluations than NSGA-II, with smaller models and lower temperatures improving constraint satisfaction and design consistency.", "conclusion": "LLMs show promise as reasoning-based optimizers for autonomous structural design and refinement."}}
{"id": "2406.03184", "pdf": "https://arxiv.org/pdf/2406.03184", "abs": "https://arxiv.org/abs/2406.03184", "authors": ["Hao Wen", "Zehuan Huang", "Yaohui Wang", "Xinyuan Chen", "Lu Sheng"], "title": "Ouroboros3D: Image-to-3D Generation via 3D-aware Recursive Diffusion", "categories": ["cs.CV"], "comment": "See our project page at https://costwen.github.io/Ouroboros3D/", "summary": "Existing single image-to-3D creation methods typically involve a two-stage\nprocess, first generating multi-view images, and then using these images for 3D\nreconstruction. However, training these two stages separately leads to\nsignificant data bias in the inference phase, thus affecting the quality of\nreconstructed results. We introduce a unified 3D generation framework, named\nOuroboros3D, which integrates diffusion-based multi-view image generation and\n3D reconstruction into a recursive diffusion process. In our framework, these\ntwo modules are jointly trained through a self-conditioning mechanism, allowing\nthem to adapt to each other's characteristics for robust inference. During the\nmulti-view denoising process, the multi-view diffusion model uses the 3D-aware\nmaps rendered by the reconstruction module at the previous timestep as\nadditional conditions. The recursive diffusion framework with 3D-aware feedback\nunites the entire process and improves geometric consistency.Experiments show\nthat our framework outperforms separation of these two stages and existing\nmethods that combine them at the inference phase. Project page:\nhttps://costwen.github.io/Ouroboros3D/", "AI": {"tldr": "Ouroboros3D unifies multi-view image generation and 3D reconstruction into a recursive diffusion process, improving geometric consistency and outperforming existing methods.", "motivation": "Separate training of multi-view image generation and 3D reconstruction leads to data bias and poor reconstruction quality.", "method": "A unified framework integrating diffusion-based multi-view generation and 3D reconstruction with a self-conditioning mechanism for joint training.", "result": "Outperforms separate stage training and existing combined methods, achieving better geometric consistency.", "conclusion": "Ouroboros3D provides a robust, unified solution for single image-to-3D creation with improved performance."}}
{"id": "2505.00282", "pdf": "https://arxiv.org/pdf/2505.00282", "abs": "https://arxiv.org/abs/2505.00282", "authors": ["Jacob Carlson", "Melissa Dell"], "title": "A Unifying Framework for Robust and Efficient Inference with Unstructured Data", "categories": ["econ.EM", "cs.LG"], "comment": null, "summary": "This paper presents a general framework for conducting efficient and robust\ninference on parameters derived from unstructured data, which include text,\nimages, audio, and video. Economists have long incorporated data extracted from\ntexts and images into their analyses, a practice that has accelerated with\nadvancements in deep neural networks. However, neural networks do not\ngenerically produce unbiased predictions, potentially propagating bias to\nestimators that use their outputs. To address this challenge, we reframe\ninference with unstructured data as a missing structured data problem, where\nstructured data are imputed from unstructured inputs using deep neural\nnetworks. This perspective allows us to apply classic results from\nsemiparametric inference, yielding valid, efficient, and robust estimators\nbased on unstructured data. We formalize this approach with MARS (Missing At\nRandom Structured Data), a unifying framework that integrates and extends\nexisting methods for debiased inference using machine learning predictions,\nlinking them to a variety of older, familiar problems such as causal inference.\nWe develop robust and efficient estimators for both descriptive and causal\nestimands and address challenges such as inference using aggregated and\ntransformed predictions from unstructured data. Importantly, MARS applies to\ncommon empirical settings that have received limited attention in the existing\nliterature. Finally, we reanalyze prominent studies that use unstructured data,\ndemonstrating the practical value of MARS.", "AI": {"tldr": "The paper introduces MARS, a framework for robust and efficient inference on parameters from unstructured data (text, images, audio, video), addressing bias in neural network predictions by treating it as a missing structured data problem.", "motivation": "Economists increasingly use unstructured data, but neural networks can introduce bias. The paper aims to provide valid, efficient estimators by reframing the problem.", "method": "MARS treats unstructured data inference as missing structured data, applying semiparametric theory to debias neural network predictions and link to causal inference.", "result": "MARS offers robust estimators for descriptive and causal parameters, applicable to understudied empirical settings, and is validated through reanalysis of existing studies.", "conclusion": "MARS provides a practical, unifying solution for debiased inference using unstructured data, bridging gaps in the literature."}}
{"id": "2412.05862", "pdf": "https://arxiv.org/pdf/2412.05862", "abs": "https://arxiv.org/abs/2412.05862", "authors": ["Aman Kassahun Wassie", "Mahdi Molaei", "Yasmin Moslem"], "title": "Domain-Specific Translation with Open-Source Large Language Models: Resource-Oriented Analysis", "categories": ["cs.CL"], "comment": null, "summary": "In this work, we compare the domain-specific translation performance of\nopen-source autoregressive decoder-only large language models (LLMs) with\ntask-oriented machine translation (MT) models. Our experiments focus on the\nmedical domain and cover four language directions with varied resource\navailability: English-to-French, English-to-Portuguese, English-to-Swahili, and\nSwahili-to-English. Despite recent advancements, LLMs demonstrate a significant\nquality gap in specialized translation compared to multilingual encoder-decoder\nMT models such as NLLB-200. Our results indicate that NLLB-200 3.3B outperforms\nall evaluated LLMs in the 7-8B parameter range across three out of the four\nlanguage directions. While fine-tuning improves the performance of LLMs such as\nMistral and Llama, these models still underperform compared to fine-tuned\nNLLB-200 3.3B models. Our findings highlight the ongoing need for specialized\nMT models to achieve high-quality domain-specific translation, especially in\nmedium-resource and low-resource settings. Moreover, the superior performance\nof larger LLMs over their 8B variants suggests potential value in pre-training\ndomain-specific medium-sized language models, employing targeted data selection\nand knowledge distillation approaches to enhance both quality and efficiency in\nspecialized translation tasks.", "AI": {"tldr": "Open-source autoregressive LLMs lag behind task-oriented MT models like NLLB-200 in medical domain translation, despite fine-tuning. Specialized MT models remain superior, especially in low-resource settings.", "motivation": "To compare the performance of open-source autoregressive LLMs and task-oriented MT models in domain-specific translation, focusing on the medical domain.", "method": "Experiments conducted on four language directions (English-to-French, English-to-Portuguese, English-to-Swahili, Swahili-to-English) using LLMs and NLLB-200. Fine-tuning applied to LLMs like Mistral and Llama.", "result": "NLLB-200 3.3B outperforms LLMs (7-8B range) in three out of four language directions. Fine-tuned LLMs still underperform compared to fine-tuned NLLB-200.", "conclusion": "Specialized MT models are still needed for high-quality domain-specific translation. Larger LLMs show potential, suggesting value in domain-specific pre-training and knowledge distillation."}}
{"id": "2405.04620", "pdf": "https://arxiv.org/pdf/2405.04620", "abs": "https://arxiv.org/abs/2405.04620", "authors": ["Won-Gi Paeng", "Daesuk Kwon", "Kyungwon Jeong", "Honggyo Suh"], "title": "Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers", "categories": ["hep-ph", "cs.AI", "cs.CL", "cs.LG", "cs.NE"], "comment": "11 pages, 12 figures", "summary": "In this work, we present a generalized formulation of the Transformer\nalgorithm by reinterpreting its core mechanisms within the framework of Path\nIntegral formalism. In this perspective, the attention mechanism is recast as a\nprocess that integrates all possible transition paths leading to future token\nstates, with temporal evolution governed by the Feed-Forward Network. By\nsystematically mapping each component of the Transformer to its counterpart in\nthe Path Integral formulation, we obtain a more compact and efficient\nrepresentation, in which the contextual information of a sequence is condensed\ninto memory-like segments. These segments are recurrently processed across\nTransformer layers, enabling more effective long-term information retention. We\nvalidate the effectiveness of this approach through the Passkey retrieval task\nand a summarization task, demonstrating that the proposed method preserves\nhistorical information while exhibiting memory usage that scales linearly with\nsequence length. This contrasts with the non-linear memory growth typically\nobserved in standard attention mechanisms. We expect that this quantum-inspired\ngeneralization of the Transformer architecture will open new avenues for\nenhancing both the efficiency and expressiveness of future Transformer models.", "AI": {"tldr": "A generalized Transformer formulation using Path Integral formalism improves efficiency and long-term memory retention, with linear memory scaling.", "motivation": "To reinterpret Transformer mechanisms within Path Integral formalism for better efficiency and long-term information retention.", "method": "Recast attention as path integration, map Transformer components to Path Integral counterparts, and use memory-like segments for recurrent processing.", "result": "Validated on Passkey retrieval and summarization tasks, showing linear memory growth and effective historical retention.", "conclusion": "This quantum-inspired approach enhances Transformer efficiency and expressiveness, promising future improvements."}}
{"id": "2409.08091", "pdf": "https://arxiv.org/pdf/2409.08091", "abs": "https://arxiv.org/abs/2409.08091", "authors": ["Zicheng Duan", "Yuxuan Ding", "Chenhui Gou", "Ziqin Zhou", "Ethan Smith", "Lingqiao Liu"], "title": "EZIGen: Enhancing zero-shot personalized image generation with precise subject encoding and decoupled guidance", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot personalized image generation models aim to produce images that\nalign with both a given text prompt and subject image, requiring the model to\nincorporate both sources of guidance. Existing methods often struggle to\ncapture fine-grained subject details and frequently prioritize one form of\nguidance over the other, resulting in suboptimal subject encoding and\nimbalanced generation. In this study, we uncover key insights into overcoming\nsuch drawbacks, notably that 1) the choice of the subject image encoder\ncritically influences subject identity preservation and training efficiency,\nand 2) the text and subject guidance should take effect at different denoising\nstages. Building on these insights, we introduce a new approach, EZIGen, that\nemploys two main components: leveraging a fixed pre-trained Diffusion UNet\nitself as subject encoder, following a process that balances the two guidances\nby separating their dominance stage and revisiting certain time steps to\nbootstrap subject transfer quality. Through these two components, EZIGen,\ninitially built upon SD2.1-base, achieved state-of-the-art performances on\nmultiple personalized generation benchmarks with a unified model, while using\n100 times less training data. Moreover, by further migrating our design to\nSDXL, EZIGen is proven to be a versatile model-agnostic solution for\npersonalized generation. Demo Page:\nzichengduan.github.io/pages/EZIGen/index.html", "AI": {"tldr": "EZIGen introduces a novel approach for zero-shot personalized image generation by balancing text and subject guidance, achieving state-of-the-art results with minimal training data.", "motivation": "Existing methods struggle with fine-grained subject details and imbalanced guidance, leading to suboptimal generation.", "method": "EZIGen uses a fixed pre-trained Diffusion UNet as a subject encoder and separates the dominance stages of text and subject guidance.", "result": "Achieves top performance on benchmarks with 100x less training data and proves versatile with SDXL.", "conclusion": "EZIGen is a model-agnostic solution for high-quality personalized image generation."}}
{"id": "2505.00299", "pdf": "https://arxiv.org/pdf/2505.00299", "abs": "https://arxiv.org/abs/2505.00299", "authors": ["Yang Wang", "Tengda Tang", "Zhou Fang", "Yingnan Deng", "Yifei Duan"], "title": "Intelligent Task Scheduling for Microservices via A3C-Based Reinforcement Learning", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "To address the challenges of high resource dynamism and intensive task\nconcurrency in microservice systems, this paper proposes an adaptive resource\nscheduling method based on the A3C reinforcement learning algorithm. The\nscheduling problem is modeled as a Markov Decision Process, where policy and\nvalue networks are jointly optimized to enable fine-grained resource allocation\nunder varying load conditions. The method incorporates an asynchronous\nmulti-threaded learning mechanism, allowing multiple agents to perform parallel\nsampling and synchronize updates to the global network parameters. This design\nimproves both policy convergence efficiency and model stability. In the\nexperimental section, a real-world dataset is used to construct a scheduling\nscenario. The proposed method is compared with several typical approaches\nacross multiple evaluation metrics, including task delay, scheduling success\nrate, resource utilization, and convergence speed. The results show that the\nproposed method delivers high scheduling performance and system stability in\nmulti-task concurrent environments. It effectively alleviates the resource\nallocation bottlenecks faced by traditional methods under heavy load,\ndemonstrating its practical value for intelligent scheduling in microservice\nsystems.", "AI": {"tldr": "The paper proposes an adaptive resource scheduling method using A3C reinforcement learning to handle high dynamism and concurrency in microservice systems, outperforming traditional methods in performance and stability.", "motivation": "To address challenges of resource dynamism and task concurrency in microservice systems, requiring efficient and stable scheduling solutions.", "method": "Models scheduling as a Markov Decision Process, using A3C reinforcement learning with asynchronous multi-threaded learning for fine-grained resource allocation.", "result": "Outperforms typical methods in task delay, success rate, resource utilization, and convergence speed, showing high performance and stability.", "conclusion": "The method effectively solves resource allocation bottlenecks in heavy-load scenarios, proving practical for intelligent microservice scheduling."}}
{"id": "2501.00571", "pdf": "https://arxiv.org/pdf/2501.00571", "abs": "https://arxiv.org/abs/2501.00571", "authors": ["Chengcheng Mai", "Yuxiang Wang", "Ziyu Gong", "Hanxiang Wang", "Yihua Huang"], "title": "KnowRA: Knowledge Retrieval Augmented Method for Document-level Relation Extraction with Comprehensive Reasoning Abilities", "categories": ["cs.CL"], "comment": "This work has been accepted by IJCAI 2025 (CCF A)", "summary": "Document-level relation extraction (Doc-RE) aims to extract relations between\nentities across multiple sentences. Therefore, Doc-RE requires more\ncomprehensive reasoning abilities like humans, involving complex cross-sentence\ninteractions between entities, contexts, and external general knowledge,\ncompared to the sentence-level RE. However, most existing Doc-RE methods focus\non optimizing single reasoning ability, but lack the ability to utilize\nexternal knowledge for comprehensive reasoning on long documents. To solve\nthese problems, a knowledge retrieval augmented method, named KnowRA, was\nproposed with comprehensive reasoning to autonomously determine whether to\naccept external knowledge to assist DocRE. Firstly, we constructed a document\ngraph for semantic encoding and integrated the co-reference resolution model to\naugment the co-reference reasoning ability. Then, we expanded the document\ngraph into a document knowledge graph by retrieving the external knowledge base\nfor common-sense reasoning and a novel knowledge filtration method was\npresented to filter out irrelevant knowledge. Finally, we proposed the axis\nattention mechanism to build direct and indirect associations with intermediary\nentities for achieving cross-sentence logical reasoning. Extensive experiments\nconducted on two datasets verified the effectiveness of our method compared to\nthe state-of-the-art baselines. Our code is available at\nhttps://anonymous.4open.science/r/KnowRA.", "AI": {"tldr": "KnowRA is a knowledge retrieval augmented method for document-level relation extraction (Doc-RE), enhancing reasoning with external knowledge, co-reference resolution, and logical associations.", "motivation": "Existing Doc-RE methods lack comprehensive reasoning and external knowledge utilization for long documents.", "method": "Constructs a document graph, integrates co-reference resolution, retrieves external knowledge, filters irrelevant knowledge, and uses axis attention for logical reasoning.", "result": "Outperforms state-of-the-art baselines on two datasets.", "conclusion": "KnowRA effectively enhances Doc-RE by combining multiple reasoning abilities and external knowledge."}}
{"id": "2406.13216", "pdf": "https://arxiv.org/pdf/2406.13216", "abs": "https://arxiv.org/abs/2406.13216", "authors": ["Songyang Chen", "Yu Liu", "Lei Zou", "Zexuan Wang", "Youfang Lin"], "title": "CombAlign: Enhancing Model Expressiveness in Unsupervised Graph Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 9 figures", "summary": "Unsupervised graph alignment finds the node correspondence between a pair of\nattributed graphs by only exploiting graph structure and node features. One\ncategory of recent studies first computes the node representation and then\nmatches nodes with the largest embedding-based similarity, while the other\ncategory reduces the problem to optimal transport (OT) via Gromov-Wasserstein\nlearning. However, it remains largely unexplored in the model expressiveness,\nas well as how theoretical expressivity impacts prediction accuracy. We\ninvestigate the model expressiveness from two aspects. First, we characterize\nthe model's discriminative power in distinguishing matched and unmatched node\npairs across two graphs.Second, we study the model's capability of guaranteeing\nnode matching properties such as one-to-one matching and mutual alignment.\nMotivated by our theoretical analysis, we put forward a hybrid approach named\nCombAlign with stronger expressive power. Specifically, we enable\ncross-dimensional feature interaction for OT-based learning and propose an\nembedding-based method inspired by the Weisfeiler-Lehman test. We also apply\nnon-uniform marginals obtained from the embedding-based modules to OT as priors\nfor more expressiveness. Based on that, we propose a traditional\nalgorithm-based refinement, which combines our OT and embedding-based\npredictions using the ensemble learning strategy and reduces the problem to\nmaximum weight matching. With carefully designed edge weights, we ensure those\nmatching properties and further enhance prediction accuracy. By extensive\nexperiments, we demonstrate a significant improvement of 14.5% in alignment\naccuracy compared to state-of-the-art approaches and confirm the soundness of\nour theoretical analysis.", "AI": {"tldr": "The paper investigates the expressiveness of unsupervised graph alignment models, proposes a hybrid approach (CombAlign) combining optimal transport and embedding-based methods, and achieves a 14.5% improvement in alignment accuracy.", "motivation": "To explore the model expressiveness in unsupervised graph alignment and how it impacts prediction accuracy, addressing gaps in discriminative power and node matching guarantees.", "method": "Proposes CombAlign, a hybrid approach integrating cross-dimensional feature interaction for OT-based learning, an embedding-based method inspired by the Weisfeiler-Lehman test, and non-uniform marginals as priors. Also includes a refinement step using ensemble learning and maximum weight matching.", "result": "Demonstrates a 14.5% improvement in alignment accuracy over state-of-the-art methods, validating the theoretical analysis.", "conclusion": "CombAlign enhances expressiveness and accuracy in unsupervised graph alignment, supported by theoretical insights and empirical results."}}
{"id": "2409.08215", "pdf": "https://arxiv.org/pdf/2409.08215", "abs": "https://arxiv.org/abs/2409.08215", "authors": ["Quan Meng", "Lei Li", "Matthias Nie\u00dfner", "Angela Dai"], "title": "LT3SD: Latent Trees for 3D Scene Diffusion", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://quan-meng.github.io/projects/lt3sd/ Video:\n  https://youtu.be/AJ5sG9VyjGA", "summary": "We present LT3SD, a novel latent diffusion model for large-scale 3D scene\ngeneration. Recent advances in diffusion models have shown impressive results\nin 3D object generation, but are limited in spatial extent and quality when\nextended to 3D scenes. To generate complex and diverse 3D scene structures, we\nintroduce a latent tree representation to effectively encode both\nlower-frequency geometry and higher-frequency detail in a coarse-to-fine\nhierarchy. We can then learn a generative diffusion process in this latent 3D\nscene space, modeling the latent components of a scene at each resolution\nlevel. To synthesize large-scale scenes with varying sizes, we train our\ndiffusion model on scene patches and synthesize arbitrary-sized output 3D\nscenes through shared diffusion generation across multiple scene patches.\nThrough extensive experiments, we demonstrate the efficacy and benefits of\nLT3SD for large-scale, high-quality unconditional 3D scene generation and for\nprobabilistic completion for partial scene observations.", "AI": {"tldr": "LT3SD is a latent diffusion model for large-scale 3D scene generation, addressing limitations in spatial extent and quality by using a latent tree representation and hierarchical diffusion.", "motivation": "Existing diffusion models for 3D object generation struggle with large-scale scenes due to limited spatial extent and quality.", "method": "Introduces a latent tree representation for hierarchical encoding and trains a diffusion model on scene patches for scalable synthesis.", "result": "Demonstrates effective large-scale, high-quality 3D scene generation and probabilistic completion for partial scenes.", "conclusion": "LT3SD advances 3D scene generation by enabling scalable, high-quality synthesis and completion."}}
{"id": "2505.00304", "pdf": "https://arxiv.org/pdf/2505.00304", "abs": "https://arxiv.org/abs/2505.00304", "authors": ["Yuhan Li", "Eugene Han", "Yifan Hu", "Wenzhuo Zhou", "Zhengling Qi", "Yifan Cui", "Ruoqing Zhu"], "title": "Reinforcement Learning with Continuous Actions Under Unmeasured Confounding", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "This paper addresses the challenge of offline policy learning in\nreinforcement learning with continuous action spaces when unmeasured\nconfounders are present. While most existing research focuses on policy\nevaluation within partially observable Markov decision processes (POMDPs) and\nassumes discrete action spaces, we advance this field by establishing a novel\nidentification result to enable the nonparametric estimation of policy value\nfor a given target policy under an infinite-horizon framework. Leveraging this\nidentification, we develop a minimax estimator and introduce a\npolicy-gradient-based algorithm to identify the in-class optimal policy that\nmaximizes the estimated policy value. Furthermore, we provide theoretical\nresults regarding the consistency, finite-sample error bound, and regret bound\nof the resulting optimal policy. Extensive simulations and a real-world\napplication using the German Family Panel data demonstrate the effectiveness of\nour proposed methodology.", "AI": {"tldr": "The paper introduces a method for offline policy learning in continuous action spaces with unmeasured confounders, offering a nonparametric estimator and a policy-gradient algorithm, supported by theoretical guarantees and empirical validation.", "motivation": "Addressing the gap in offline policy learning for continuous action spaces with unmeasured confounders, which is underexplored compared to discrete action spaces and POMDPs.", "method": "Establishes a novel identification result for policy value estimation, develops a minimax estimator, and introduces a policy-gradient-based algorithm for optimal policy identification.", "result": "Theoretical consistency, finite-sample error bounds, and regret bounds are proven. Simulations and real-world data (German Family Panel) validate the method's effectiveness.", "conclusion": "The proposed approach successfully tackles offline policy learning in continuous action spaces with unmeasured confounders, supported by theory and empirical results."}}
{"id": "2501.13947", "pdf": "https://arxiv.org/pdf/2501.13947", "abs": "https://arxiv.org/abs/2501.13947", "authors": ["Wenli Yang", "Lilian Some", "Michael Bain", "Byeong Kang"], "title": "A Comprehensive Survey on Integrating Large Language Models with Knowledge-Based Methods", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid development of artificial intelligence has led to marked progress\nin the field. One interesting direction for research is whether Large Language\nModels (LLMs) can be integrated with structured knowledge-based systems. This\napproach aims to combine the generative language understanding of LLMs and the\nprecise knowledge representation systems by which they are integrated. This\narticle surveys the relationship between LLMs and knowledge bases, looks at how\nthey can be applied in practice, and discusses related technical, operational,\nand ethical challenges. Utilizing a comprehensive examination of the\nliterature, the study both identifies important issues and assesses existing\nsolutions. It demonstrates the merits of incorporating generative AI into\nstructured knowledge-base systems concerning data contextualization, model\naccuracy, and utilization of knowledge resources. The findings give a full list\nof the current situation of research, point out the main gaps, and propose\nhelpful paths to take. These insights contribute to advancing AI technologies\nand support their practical deployment across various sectors.", "AI": {"tldr": "The paper explores integrating Large Language Models (LLMs) with structured knowledge-based systems, highlighting benefits, challenges, and future directions.", "motivation": "To combine the generative capabilities of LLMs with precise knowledge representation for improved AI applications.", "method": "A literature survey examining the relationship between LLMs and knowledge bases, practical applications, and associated challenges.", "result": "Identifies benefits like better data contextualization and accuracy, along with gaps and solutions for integration.", "conclusion": "The study advances AI by mapping current research, gaps, and proposing actionable paths for practical deployment."}}
{"id": "2407.01635", "pdf": "https://arxiv.org/pdf/2407.01635", "abs": "https://arxiv.org/abs/2407.01635", "authors": ["Wei Zhuo", "Han Yu", "Guang Tan", "Xiaoxiao Li"], "title": "Commute Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have shown remarkable success in learning from\ngraph-structured data. However, their application to directed graphs (digraphs)\npresents unique challenges, primarily due to the inherent asymmetry in node\nrelationships. Traditional GNNs are adept at capturing unidirectional relations\nbut fall short in encoding the mutual path dependencies between nodes, such as\nasymmetrical shortest paths typically found in digraphs. Recognizing this gap,\nwe introduce Commute Graph Neural Networks (CGNN), an approach that seamlessly\nintegrates node-wise commute time into the message passing scheme. The\ncornerstone of CGNN is an efficient method for computing commute time using a\nnewly formulated digraph Laplacian. Commute time is then integrated into the\nneighborhood aggregation process, with neighbor contributions weighted\naccording to their respective commute time to the central node in each layer.\nIt enables CGNN to directly capture the mutual, asymmetric relationships in\ndigraphs. Extensive experiments on 8 benchmarking datasets confirm the\nsuperiority of CGNN against 13 state-of-the-art methods.", "AI": {"tldr": "CGNN integrates node-wise commute time into GNNs to better handle directed graphs, outperforming 13 state-of-the-art methods.", "motivation": "Traditional GNNs struggle with asymmetrical node relationships in directed graphs, missing mutual path dependencies.", "method": "CGNN uses a digraph Laplacian to compute commute time, integrating it into message passing with weighted neighbor contributions.", "result": "CGNN outperforms 13 benchmarks across 8 datasets, proving its effectiveness.", "conclusion": "CGNN successfully addresses the asymmetry challenge in directed graphs, offering a superior solution."}}
{"id": "2411.16508", "pdf": "https://arxiv.org/pdf/2411.16508", "abs": "https://arxiv.org/abs/2411.16508", "authors": ["Ashmal Vayani", "Dinura Dissanayake", "Hasindri Watawana", "Noor Ahsan", "Nevasini Sasikumar", "Omkar Thawakar", "Henok Biadglign Ademtew", "Yahya Hmaiti", "Amandeep Kumar", "Kartik Kuckreja", "Mykola Maslych", "Wafa Al Ghallabi", "Mihail Mihaylov", "Chao Qin", "Abdelrahman M Shaker", "Mike Zhang", "Mahardika Krisna Ihsani", "Amiel Esplana", "Monil Gokani", "Shachar Mirkin", "Harsh Singh", "Ashay Srivastava", "Endre Hamerlik", "Fathinah Asma Izzati", "Fadillah Adamsyah Maani", "Sebastian Cavada", "Jenny Chim", "Rohit Gupta", "Sanjay Manjunath", "Kamila Zhumakhanova", "Feno Heriniaina Rabevohitra", "Azril Amirudin", "Muhammad Ridzuan", "Daniya Kareem", "Ketan More", "Kunyang Li", "Pramesh Shakya", "Muhammad Saad", "Amirpouya Ghasemaghaei", "Amirbek Djanibekov", "Dilshod Azizov", "Branislava Jankovic", "Naman Bhatia", "Alvaro Cabrera", "Johan Obando-Ceron", "Olympiah Otieno", "Fabian Farestam", "Muztoba Rabbani", "Sanoojan Baliah", "Santosh Sanjeev", "Abduragim Shtanchaev", "Maheen Fatima", "Thao Nguyen", "Amrin Kareem", "Toluwani Aremu", "Nathan Xavier", "Amit Bhatkal", "Hawau Toyin", "Aman Chadha", "Hisham Cholakkal", "Rao Muhammad Anwer", "Michael Felsberg", "Jorma Laaksonen", "Thamar Solorio", "Monojit Choudhury", "Ivan Laptev", "Mubarak Shah", "Salman Khan", "Fahad Khan"], "title": "All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages", "categories": ["cs.CV", "cs.CL"], "comment": "A Multilingual Multimodal cultural benchmark for 100 languages", "summary": "Existing Large Multimodal Models (LMMs) generally focus on only a few regions\nand languages. As LMMs continue to improve, it is increasingly important to\nensure they understand cultural contexts, respect local sensitivities, and\nsupport low-resource languages, all while effectively integrating corresponding\nvisual cues. In pursuit of culturally diverse global multimodal models, our\nproposed All Languages Matter Benchmark (ALM-bench) represents the largest and\nmost comprehensive effort to date for evaluating LMMs across 100 languages.\nALM-bench challenges existing models by testing their ability to understand and\nreason about culturally diverse images paired with text in various languages,\nincluding many low-resource languages traditionally underrepresented in LMM\nresearch. The benchmark offers a robust and nuanced evaluation framework\nfeaturing various question formats, including true/false, multiple choice, and\nopen-ended questions, which are further divided into short and long-answer\ncategories. ALM-bench design ensures a comprehensive assessment of a model's\nability to handle varied levels of difficulty in visual and linguistic\nreasoning. To capture the rich tapestry of global cultures, ALM-bench carefully\ncurates content from 13 distinct cultural aspects, ranging from traditions and\nrituals to famous personalities and celebrations. Through this, ALM-bench not\nonly provides a rigorous testing ground for state-of-the-art open and\nclosed-source LMMs but also highlights the importance of cultural and\nlinguistic inclusivity, encouraging the development of models that can serve\ndiverse global populations effectively. Our benchmark is publicly available.", "AI": {"tldr": "ALM-bench is a benchmark for evaluating Large Multimodal Models (LMMs) across 100 languages, focusing on cultural diversity and low-resource languages.", "motivation": "To ensure LMMs understand cultural contexts, respect local sensitivities, and support underrepresented languages.", "method": "ALM-bench evaluates LMMs using diverse question formats (true/false, multiple choice, open-ended) and 13 cultural aspects.", "result": "The benchmark provides a rigorous evaluation framework, highlighting gaps in current LMMs' cultural and linguistic inclusivity.", "conclusion": "ALM-bench encourages the development of globally inclusive LMMs and is publicly available for further research."}}
{"id": "2505.00310", "pdf": "https://arxiv.org/pdf/2505.00310", "abs": "https://arxiv.org/abs/2505.00310", "authors": ["Maximilian Schuessler", "Erik Sverdrup", "Robert Tibshirani"], "title": "Statistical Learning for Heterogeneous Treatment Effects: Pretraining, Prognosis, and Prediction", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Robust estimation of heterogeneous treatment effects is a fundamental\nchallenge for optimal decision-making in domains ranging from personalized\nmedicine to educational policy. In recent years, predictive machine learning\nhas emerged as a valuable toolbox for causal estimation, enabling more flexible\neffect estimation. However, accurately estimating conditional average treatment\neffects (CATE) remains a major challenge, particularly in the presence of many\ncovariates. In this article, we propose pretraining strategies that leverages a\nphenomenon in real-world applications: factors that are prognostic of the\noutcome are frequently also predictive of treatment effect heterogeneity. In\nmedicine, for example, components of the same biological signaling pathways\nfrequently influence both baseline risk and treatment response. Specifically,\nwe demonstrate our approach within the R-learner framework, which estimates the\nCATE by solving individual prediction problems based on a residualized loss. We\nuse this structure to incorporate \"side information\" and develop models that\ncan exploit synergies between risk prediction and causal effect estimation. In\nsettings where these synergies are present, this cross-task learning enables\nmore accurate signal detection: yields lower estimation error, reduced false\ndiscovery rates, and higher power for detecting heterogeneity.", "AI": {"tldr": "The paper proposes pretraining strategies within the R-learner framework to improve CATE estimation by leveraging prognostic factors that also predict treatment effect heterogeneity.", "motivation": "Accurate estimation of heterogeneous treatment effects is crucial for optimal decision-making, but remains challenging, especially with many covariates.", "method": "The approach uses pretraining and the R-learner framework, incorporating 'side information' to exploit synergies between risk prediction and causal effect estimation.", "result": "The method reduces estimation error, false discovery rates, and increases power for detecting heterogeneity when synergies exist.", "conclusion": "Cross-task learning improves CATE estimation by leveraging shared prognostic and predictive factors, enhancing decision-making in fields like medicine and policy."}}
{"id": "2502.05945", "pdf": "https://arxiv.org/pdf/2502.05945", "abs": "https://arxiv.org/abs/2502.05945", "authors": ["Paul Darm", "Annalisa Riccardi"], "title": "HSI: Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "Large Language Models (LLMs), Interference-time activation shifting,\n  Steerability, Explainability, AI alignment, Interpretability", "summary": "Robust alignment guardrails for large language models are becoming\nincreasingly important with their widespread application. In contrast to\nprevious studies, we demonstrate that inference-time activation interventions\ncan bypass safety alignments and effectively steer model generations towards\nharmful AI coordination for Llama 2. Our method applies fine-grained\ninterventions at specific model subcomponents, particularly attention heads,\nusing a simple binary choice probing strategy. These interventions then\ngeneralise to the open-ended generation setting effectively circumventing\nsafety guardrails. We show that probing single attention heads is more\neffective than intervening on full layers and intervening on only four\nattention heads is comparable to supervised fine-tuning. We further show that\nonly a few example completions are needed to compute effective steering\ndirections, which is an advantage over classical fine-tuning. Our findings\nhighlight the shortcomings of current alignment techniques. In addition, our\nresults suggest that, at the attention head level, activations encode\nfine-grained linearly separable behaviors. Practically, the approach offers a\nstraightforward methodology to steer large language model behaviour, which\ncould be extended to diverse domains beyond safety requiring fine-grained\ncontrol over the model output. The code and datasets for this study can be\nfound on https://github.com/PaulDrm/targeted_intervention.", "AI": {"tldr": "The paper shows that inference-time activation interventions can bypass safety alignments in Llama 2, steering it toward harmful outputs by targeting specific attention heads.", "motivation": "To highlight the vulnerabilities of current alignment techniques in large language models (LLMs) and demonstrate how fine-grained interventions can bypass safety measures.", "method": "Uses binary choice probing to intervene on specific attention heads, showing this is more effective than full-layer interventions or supervised fine-tuning.", "result": "Intervening on just four attention heads is as effective as fine-tuning, and few examples are needed to compute steering directions.", "conclusion": "Current alignment techniques have shortcomings, and attention head activations encode fine-grained, linearly separable behaviors, offering a method for precise model control."}}
{"id": "2409.07415", "pdf": "https://arxiv.org/pdf/2409.07415", "abs": "https://arxiv.org/abs/2409.07415", "authors": ["Yuanhaur Chang", "Han Liu", "Chenyang Lu", "Ning Zhang"], "title": "SoK: Security and Privacy Risks of Healthcare AI", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "The integration of artificial intelligence (AI) and machine learning (ML)\ninto healthcare systems holds great promise for enhancing patient care and care\ndelivery efficiency; however, it also exposes sensitive data and system\nintegrity to potential cyberattacks. Current security and privacy (S&P)\nresearch on healthcare AI is highly unbalanced in terms of healthcare\ndeployment scenarios and threat models, and has a disconnected focus with the\nbiomedical research community. This hinders a comprehensive understanding of\nthe risks that healthcare AI entails. To address this gap, this paper takes a\nthorough examination of existing healthcare AI S&P research, providing a\nunified framework that allows the identification of under-explored areas. Our\nsurvey presents a systematic overview of healthcare AI attacks and defenses,\nand points out challenges and research opportunities for each AI-driven\nhealthcare application domain. Through our experimental analysis of different\nthreat models and feasibility studies on under-explored adversarial attacks, we\nprovide compelling insights into the pressing need for cybersecurity research\nin the rapidly evolving field of healthcare AI.", "AI": {"tldr": "The paper highlights the cybersecurity risks in healthcare AI, identifies gaps in current research, and proposes a unified framework to address under-explored areas.", "motivation": "The integration of AI/ML in healthcare improves care but exposes vulnerabilities. Current S&P research is unbalanced and disconnected from biomedical research, hindering risk understanding.", "method": "The paper reviews existing healthcare AI S&P research, creates a unified framework, and analyzes threat models and adversarial attacks.", "result": "The survey provides a systematic overview of attacks and defenses, identifies challenges, and highlights research opportunities in healthcare AI.", "conclusion": "The study underscores the urgent need for cybersecurity research in healthcare AI to mitigate risks and enhance system integrity."}}
{"id": "2412.06491", "pdf": "https://arxiv.org/pdf/2412.06491", "abs": "https://arxiv.org/abs/2412.06491", "authors": ["Yihong Xu", "Yuan Yin", "\u00c9loi Zablocki", "Tuan-Hung Vu", "Alexandre Boulch", "Matthieu Cord"], "title": "PPT: Pretraining with Pseudo-Labeled Trajectories for Motion Forecasting", "categories": ["cs.CV", "cs.RO"], "comment": "18 pages, 9 figures, updated results", "summary": "Accurately predicting how agents move in dynamic scenes is essential for safe\nautonomous driving. State-of-the-art motion forecasting models rely on large\ncurated datasets with manually annotated or heavily post-processed\ntrajectories. However, building these datasets is costly, generally manual,\nhard to scale, and lacks reproducibility. They also introduce domain gaps that\nlimit generalization across environments. We introduce PPT (Pretraining with\nPseudo-labeled Trajectories), a simple and scalable alternative that uses\nunprocessed and diverse trajectories automatically generated from off-the-shelf\n3D detectors and tracking. Unlike traditional pipelines aiming for clean,\nsingle-label annotations, PPT embraces noise and diversity as useful signals\nfor learning robust representations. With optional finetuning on a small amount\nof labeled data, models pretrained with PPT achieve strong performance across\nstandard benchmarks particularly in low-data regimes, and in cross-domain,\nend-to-end and multi-class settings. PPT is easy to implement and improves\ngeneralization in motion forecasting. Code and data will be released upon\nacceptance.", "AI": {"tldr": "PPT (Pretraining with Pseudo-labeled Trajectories) uses noisy, diverse trajectories from 3D detectors/tracking to improve motion forecasting, reducing reliance on costly annotated datasets.", "motivation": "Traditional motion forecasting models depend on expensive, manually annotated datasets, which are hard to scale and limit generalization. PPT offers a scalable, noise-tolerant alternative.", "method": "PPT leverages unprocessed, diverse trajectories from 3D detectors/tracking for pretraining, optionally finetuning with minimal labeled data.", "result": "PPT achieves strong performance in low-data, cross-domain, end-to-end, and multi-class settings, improving generalization.", "conclusion": "PPT is a simple, scalable solution for robust motion forecasting, reducing dependency on curated datasets."}}
{"id": "2505.00318", "pdf": "https://arxiv.org/pdf/2505.00318", "abs": "https://arxiv.org/abs/2505.00318", "authors": ["Wei-Bin Kou", "Guangxu Zhu", "Bingyang Cheng", "Shuai Wang", "Ming Tang", "Yik-Chung Wu"], "title": "FedEMA: Federated Exponential Moving Averaging with Negative Entropy Regularizer in Autonomous Driving", "categories": ["cs.RO", "cs.LG"], "comment": "8 pages", "summary": "Street Scene Semantic Understanding (denoted as S3U) is a crucial but complex\ntask for autonomous driving (AD) vehicles. Their inference models typically\nface poor generalization due to domain-shift. Federated Learning (FL) has\nemerged as a promising paradigm for enhancing the generalization of AD models\nthrough privacy-preserving distributed learning. However, these FL AD models\nface significant temporal catastrophic forgetting when deployed in dynamically\nevolving environments, where continuous adaptation causes abrupt erosion of\nhistorical knowledge. This paper proposes Federated Exponential Moving Average\n(FedEMA), a novel framework that addresses this challenge through two integral\ninnovations: (I) Server-side model's historical fitting capability preservation\nvia fusing current FL round's aggregation model and a proposed previous FL\nround's exponential moving average (EMA) model; (II) Vehicle-side negative\nentropy regularization to prevent FL models' possible overfitting to\nEMA-introduced temporal patterns. Above two strategies empower FedEMA a\ndual-objective optimization that balances model generalization and\nadaptability. In addition, we conduct theoretical convergence analysis for the\nproposed FedEMA. Extensive experiments both on Cityscapes dataset and Camvid\ndataset demonstrate FedEMA's superiority over existing approaches, showing\n7.12% higher mean Intersection-over-Union (mIoU).", "AI": {"tldr": "FedEMA is a novel federated learning framework for autonomous driving that preserves historical knowledge and prevents overfitting, improving generalization and adaptability.", "motivation": "Addressing poor generalization and temporal catastrophic forgetting in federated learning models for autonomous driving in dynamic environments.", "method": "FedEMA uses server-side EMA model fusion and vehicle-side negative entropy regularization to balance generalization and adaptability.", "result": "FedEMA achieves 7.12% higher mIoU on Cityscapes and Camvid datasets compared to existing methods.", "conclusion": "FedEMA effectively enhances model performance and adaptability in dynamic environments, outperforming current approaches."}}
{"id": "2502.07963", "pdf": "https://arxiv.org/pdf/2502.07963", "abs": "https://arxiv.org/abs/2502.07963", "authors": ["Hye Sun Yun", "Karen Y. C. Zhang", "Ramez Kouzy", "Iain J. Marshall", "Junyi Jessy Li", "Byron C. Wallace"], "title": "Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 12 figures, 4 tables", "summary": "Medical research faces well-documented challenges in translating novel\ntreatments into clinical practice. Publishing incentives encourage researchers\nto present \"positive\" findings, even when empirical results are equivocal.\nConsequently, it is well-documented that authors often spin study results,\nespecially in article abstracts. Such spin can influence clinician\ninterpretation of evidence and may affect patient care decisions. In this\nstudy, we ask whether the interpretation of trial results offered by Large\nLanguage Models (LLMs) is similarly affected by spin. This is important since\nLLMs are increasingly being used to trawl through and synthesize published\nmedical evidence. We evaluated 22 LLMs and found that they are across the board\nmore susceptible to spin than humans. They might also propagate spin into their\noutputs: We find evidence, e.g., that LLMs implicitly incorporate spin into\nplain language summaries that they generate. We also find, however, that LLMs\nare generally capable of recognizing spin, and can be prompted in a way to\nmitigate spin's impact on LLM outputs.", "AI": {"tldr": "LLMs are more susceptible to spin in medical research abstracts than humans, but can recognize and mitigate it with proper prompting.", "motivation": "To investigate if LLMs, like humans, are influenced by spin in medical research abstracts, given their growing role in synthesizing medical evidence.", "method": "Evaluated 22 LLMs for susceptibility to spin and their ability to recognize and mitigate it.", "result": "LLMs are more prone to spin than humans but can detect and reduce its impact when prompted correctly.", "conclusion": "LLMs can propagate spin but also mitigate it, highlighting the need for careful use in medical evidence synthesis."}}
{"id": "2410.05573", "pdf": "https://arxiv.org/pdf/2410.05573", "abs": "https://arxiv.org/abs/2410.05573", "authors": ["Xuan Zhu", "Dmitriy Bespalov", "Liwen You", "Ninad Kulkarni", "Yanjun Qi"], "title": "TaeBench: Improving Quality of Toxic Adversarial Examples", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted for publication in NAACL 2025. The official version will be\n  available in the ACL Anthology", "summary": "Toxicity text detectors can be vulnerable to adversarial examples - small\nperturbations to input text that fool the systems into wrong detection.\nExisting attack algorithms are time-consuming and often produce invalid or\nambiguous adversarial examples, making them less useful for evaluating or\nimproving real-world toxicity content moderators. This paper proposes an\nannotation pipeline for quality control of generated toxic adversarial examples\n(TAE). We design model-based automated annotation and human-based quality\nverification to assess the quality requirements of TAE. Successful TAE should\nfool a target toxicity model into making benign predictions, be grammatically\nreasonable, appear natural like human-generated text, and exhibit semantic\ntoxicity. When applying these requirements to more than 20 state-of-the-art\n(SOTA) TAE attack recipes, we find many invalid samples from a total of 940k\nraw TAE attack generations. We then utilize the proposed pipeline to filter and\ncurate a high-quality TAE dataset we call TaeBench (of size 264k). Empirically,\nwe demonstrate that TaeBench can effectively transfer-attack SOTA toxicity\ncontent moderation models and services. Our experiments also show that TaeBench\nwith adversarial training achieve significant improvements of the robustness of\ntwo toxicity detectors.", "AI": {"tldr": "The paper proposes an annotation pipeline for quality control of toxic adversarial examples (TAE) to improve toxicity text detectors. It introduces TaeBench, a high-quality dataset, and shows its effectiveness in attacking and improving moderation models.", "motivation": "Existing adversarial attack algorithms for toxicity detectors produce invalid or ambiguous examples, limiting their practical use for evaluating or improving content moderation systems.", "method": "The paper designs a pipeline combining model-based automated annotation and human verification to ensure TAEs meet quality requirements (fooling toxicity models, grammatical correctness, naturalness, and semantic toxicity).", "result": "The pipeline filters 940k raw TAEs to create TaeBench (264k high-quality examples). TaeBench successfully attacks SOTA moderation models and improves detector robustness via adversarial training.", "conclusion": "The proposed pipeline and TaeBench dataset enhance the quality and utility of adversarial examples for evaluating and strengthening toxicity content moderation systems."}}
{"id": "2501.01728", "pdf": "https://arxiv.org/pdf/2501.01728", "abs": "https://arxiv.org/abs/2501.01728", "authors": ["Simon B. Jensen", "Stefan Oehmcke", "Andreas M\u00f8gelmose", "Meysam Madadi", "Christian Igel", "Sergio Escalera", "Thomas B. Moeslund"], "title": "Multimodal classification of forest biodiversity potential from 2D orthophotos and 3D airborne laser scanning point clouds", "categories": ["cs.CV"], "comment": null, "summary": "Assessment of forest biodiversity is crucial for ecosystem management and\nconservation. While traditional field surveys provide high-quality assessments,\nthey are labor-intensive and spatially limited. This study investigates whether\ndeep learning-based fusion of close-range sensing data from 2D orthophotos and\n3D airborne laser scanning (ALS) point clouds can reliable assess the\nbiodiversity potential of forests. We introduce the BioVista dataset,\ncomprising 44 378 paired samples of orthophotos and ALS point clouds from\ntemperate forests in Denmark, designed to explore multimodal fusion approaches.\nUsing deep neural networks (ResNet for orthophotos and PointVector for ALS\npoint clouds), we investigate each data modality's ability to assess forest\nbiodiversity potential, achieving overall accuracies of 76.7% and 75.8%,\nrespectively. We explore various 2D and 3D fusion approaches: confidence-based\nensembling, feature-level concatenation, and end-to-end training, achieving\noverall accuracies of 80.5%, 81.4% and 80.4% respectively. Our results\ndemonstrate that spectral information from orthophotos and structural\ninformation from ALS point clouds effectively complement each other in forest\nbiodiversity assessment.", "AI": {"tldr": "Deep learning fusion of 2D orthophotos and 3D ALS point clouds improves forest biodiversity assessment, achieving up to 81.4% accuracy.", "motivation": "Traditional forest biodiversity surveys are labor-intensive and spatially limited; this study explores deep learning fusion for more efficient and scalable assessment.", "method": "Uses ResNet for orthophotos and PointVector for ALS point clouds, testing fusion methods like confidence-based ensembling, feature-level concatenation, and end-to-end training.", "result": "Achieved 76.7% (orthophotos) and 75.8% (ALS) accuracy individually; fusion improved accuracy to 80.5-81.4%.", "conclusion": "Combining spectral (orthophotos) and structural (ALS) data enhances biodiversity assessment, proving multimodal fusion effective."}}
{"id": "2505.00321", "pdf": "https://arxiv.org/pdf/2505.00321", "abs": "https://arxiv.org/abs/2505.00321", "authors": ["Zixin Wang", "Yuanming Shi", "Yong Zhou", "Jingyang Zhu", "Khaled. B. Letaief"], "title": "Edge Large AI Models: Revolutionizing 6G Networks", "categories": ["cs.NI", "cs.LG", "eess.SP"], "comment": null, "summary": "Large artificial intelligence models (LAMs) possess human-like abilities to\nsolve a wide range of real-world problems, exemplifying the potential of\nexperts in various domains and modalities. By leveraging the communication and\ncomputation capabilities of geographically dispersed edge devices, edge LAM\nemerges as an enabling technology to empower the delivery of various real-time\nintelligent services in 6G. Unlike traditional edge artificial intelligence\n(AI) that primarily supports a single task using small models, edge LAM is\nfeatured by the need of the decomposition and distributed deployment of large\nmodels, and the ability to support highly generalized and diverse tasks.\nHowever, due to limited communication, computation, and storage resources over\nwireless networks, the vast number of trainable neurons and the substantial\ncommunication overhead pose a formidable hurdle to the practical deployment of\nedge LAMs. In this paper, we investigate the opportunities and challenges of\nedge LAMs from the perspectives of model decomposition and resource management.\nSpecifically, we propose collaborative fine-tuning and full-parameter training\nframeworks, alongside a microservice-assisted inference architecture, to\nenhance the deployment of edge LAM over wireless networks. Additionally, we\ninvestigate the application of edge LAM in air-interface designs, focusing on\nchannel prediction and beamforming. These innovative frameworks and\napplications offer valuable insights and solutions for advancing 6G technology.", "AI": {"tldr": "Edge LAMs enable real-time intelligent services in 6G by leveraging distributed edge devices, but face challenges due to limited resources. The paper proposes frameworks for model decomposition, resource management, and applications like channel prediction.", "motivation": "To address the challenges of deploying large AI models (LAMs) on edge devices for 6G, given limited communication, computation, and storage resources.", "method": "Proposes collaborative fine-tuning, full-parameter training frameworks, and a microservice-assisted inference architecture. Investigates applications in air-interface designs like channel prediction and beamforming.", "result": "Innovative frameworks and applications are introduced to enhance edge LAM deployment, offering solutions for 6G advancement.", "conclusion": "Edge LAMs hold promise for 6G, with the proposed frameworks and applications providing practical insights for overcoming deployment hurdles."}}
{"id": "2502.20984", "pdf": "https://arxiv.org/pdf/2502.20984", "abs": "https://arxiv.org/abs/2502.20984", "authors": ["Thanet Markchom", "Tong Wu", "Liting Huang", "Huizhi Liang"], "title": "UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.", "AI": {"tldr": "The paper proposes using LLMs and multilingual CLIP models to rank images based on idiomatic nominal compounds, showing improved performance with multimodal representations.", "motivation": "To address the challenge of ranking images aligned with idiomatic nominal compounds in English and Brazilian Portuguese.", "method": "Uses generative LLMs to interpret idiomatic meanings, encodes them with multilingual CLIP, and applies contrastive learning and data augmentation for fine-tuning.", "result": "Multimodal representations outperform those based on original compounds, but fine-tuning is less effective than using raw embeddings.", "conclusion": "The approach enhances idiomatic compound representation for image ranking, though fine-tuning needs improvement."}}
{"id": "2410.08067", "pdf": "https://arxiv.org/pdf/2410.08067", "abs": "https://arxiv.org/abs/2410.08067", "authors": ["Shenao Zhang", "Zhihan Liu", "Boyi Liu", "Yufeng Zhang", "Yingxiang Yang", "Yongfei Liu", "Liyu Chen", "Tao Sun", "Zhaoran Wang"], "title": "Reward-Augmented Data Enhances Direct Preference Alignment of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "Published at ICML 2025", "summary": "Preference alignment in Large Language Models (LLMs) has significantly\nimproved their ability to adhere to human instructions and intentions. However,\nexisting direct alignment algorithms primarily focus on relative preferences\nand often overlook the qualitative aspects of responses, despite having access\nto preference data that includes reward scores from judge models during AI\nfeedback. Striving to maximize the implicit reward gap between the chosen and\nthe slightly inferior rejected responses can cause overfitting and unnecessary\nunlearning of the high-quality rejected responses. The unawareness of the\nreward scores also drives the LLM to indiscriminately favor the low-quality\nchosen responses and fail to generalize to optimal responses that are sparse in\ndata. To overcome these shortcomings, our study introduces reward-conditioned\nLLM policies that discern and learn from the entire spectrum of response\nquality within the dataset, helping extrapolate to more optimal regions. We\npropose an effective yet simple data relabeling method that conditions the\npreference pairs on quality scores to construct a reward-augmented dataset. The\nexperiments across various benchmarks and diverse models demonstrate that our\napproach consistently boosts DPO by a considerable margin. Through\ncomprehensive ablation studies, we demonstrate that our method not only\nmaximizes the utility of preference data but also mitigates the issue of\nunlearning, demonstrating its broad effectiveness beyond mere data expansion.\nOur code is available at\nhttps://github.com/shenao-zhang/reward-augmented-preference.", "AI": {"tldr": "The paper introduces reward-conditioned LLM policies to improve preference alignment by leveraging reward scores, addressing overfitting and unlearning issues in existing methods.", "motivation": "Existing direct alignment algorithms focus on relative preferences but ignore qualitative aspects of responses, leading to overfitting and poor generalization.", "method": "Proposes reward-conditioned LLM policies and a data relabeling method to condition preference pairs on quality scores, creating a reward-augmented dataset.", "result": "Experiments show the approach consistently outperforms DPO, maximizing utility of preference data and mitigating unlearning issues.", "conclusion": "The method effectively leverages reward scores to improve alignment and generalization, demonstrating broad effectiveness beyond data expansion."}}
{"id": "2501.09503", "pdf": "https://arxiv.org/pdf/2501.09503", "abs": "https://arxiv.org/abs/2501.09503", "authors": ["Junjie He", "Yuxiang Tuo", "Binghui Chen", "Chongyang Zhong", "Yifeng Geng", "Liefeng Bo"], "title": "AnyStory: Towards Unified Single and Multiple Subject Personalization in Text-to-Image Generation", "categories": ["cs.CV"], "comment": "Tech report; Project page:\n  https://aigcdesigngroup.github.io/AnyStory/", "summary": "Recently, large-scale generative models have demonstrated outstanding\ntext-to-image generation capabilities. However, generating high-fidelity\npersonalized images with specific subjects still presents challenges,\nespecially in cases involving multiple subjects. In this paper, we propose\nAnyStory, a unified approach for personalized subject generation. AnyStory not\nonly achieves high-fidelity personalization for single subjects, but also for\nmultiple subjects, without sacrificing subject fidelity. Specifically, AnyStory\nmodels the subject personalization problem in an \"encode-then-route\" manner. In\nthe encoding step, AnyStory utilizes a universal and powerful image encoder,\ni.e., ReferenceNet, in conjunction with CLIP vision encoder to achieve\nhigh-fidelity encoding of subject features. In the routing step, AnyStory\nutilizes a decoupled instance-aware subject router to accurately perceive and\npredict the potential location of the corresponding subject in the latent\nspace, and guide the injection of subject conditions. Detailed experimental\nresults demonstrate the excellent performance of our method in retaining\nsubject details, aligning text descriptions, and personalizing for multiple\nsubjects. The project page is at https://aigcdesigngroup.github.io/AnyStory/ .", "AI": {"tldr": "AnyStory is a unified approach for high-fidelity personalized text-to-image generation, handling single and multiple subjects without fidelity loss.", "motivation": "Challenges in generating high-fidelity personalized images with specific subjects, especially multiple ones, drive the need for a robust solution.", "method": "AnyStory uses an 'encode-then-route' approach: a universal image encoder (ReferenceNet + CLIP) for feature encoding and a decoupled instance-aware router for subject location prediction and condition injection.", "result": "The method excels in retaining subject details, aligning text descriptions, and personalizing for multiple subjects.", "conclusion": "AnyStory effectively addresses personalized subject generation, demonstrating superior performance in fidelity and multi-subject handling."}}
{"id": "2505.00430", "pdf": "https://arxiv.org/pdf/2505.00430", "abs": "https://arxiv.org/abs/2505.00430", "authors": ["Chenghong Bian", "Meng Hua", "Deniz Gunduz"], "title": "Over-the-Air Inference over Multi-hop MIMO Networks", "categories": ["eess.SP", "cs.LG"], "comment": "5 pages", "summary": "A novel over-the-air machine learning framework over multi-hop multiple-input\nand multiple-output (MIMO) networks is proposed. The core idea is to imitate\nfully connected (FC) neural network layers using multiple MIMO channels by\ncarefully designing the precoding matrices at the transmitting nodes. A neural\nnetwork dubbed PrototypeNet is employed consisting of multiple FC layers, with\nthe number of neurons of each layer equal to the number of antennas of the\ncorresponding terminal. To achieve satisfactory performance, we train\nPrototypeNet based on a customized loss function consisting of classification\nerror and the power of latent vectors to satisfy transmit power constraints,\nwith noise injection during training. Precoding matrices for each hop are then\nobtained by solving an optimization problem. We also propose a multiple-block\nextension when the number of antennas is limited. Numerical results verify that\nthe proposed over-the-air transmission scheme can achieve satisfactory\nclassification accuracy under a power constraint. The results also show that\nhigher classification accuracy can be achieved with an increasing number of\nhops at a modest signal-to-noise ratio (SNR).", "AI": {"tldr": "A novel over-the-air ML framework for multi-hop MIMO networks uses MIMO channels to mimic FC neural network layers, achieving high classification accuracy under power constraints.", "motivation": "To leverage MIMO networks for ML tasks by designing precoding matrices that imitate FC neural network layers, enabling efficient over-the-air transmission.", "method": "Uses PrototypeNet with FC layers matching antenna counts, trains with a custom loss function (classification error + power constraints), and solves optimization for precoding matrices. Extends to multiple blocks for limited antennas.", "result": "Achieves satisfactory classification accuracy under power constraints, with improved accuracy as hop count increases at modest SNR.", "conclusion": "The framework effectively integrates MIMO networks with ML, demonstrating practical performance gains in over-the-air transmission."}}
{"id": "2503.23895", "pdf": "https://arxiv.org/pdf/2503.23895", "abs": "https://arxiv.org/abs/2503.23895", "authors": ["Yuqiao Tan", "Shizhu He", "Huanxuan Liao", "Jun Zhao", "Kang Liu"], "title": "Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement", "categories": ["cs.CL", "cs.AI"], "comment": "preprint. Code is available at https://github.com/Trae1ounG/DyPRAG", "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nretrieving relevant documents from external sources and incorporating them into\nthe context. While it improves reliability by providing factual texts, it\nsignificantly increases inference costs as context length grows and introduces\nchallenging issue of RAG hallucination, primarily caused by the lack of\ncorresponding parametric knowledge in LLMs. An efficient solution is to enhance\nthe knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by\nembedding document into LLMs parameters to perform test-time knowledge\nenhancement, effectively reducing inference costs through offline training.\nHowever, its high training and storage costs, along with limited generalization\nability, significantly restrict its practical adoption. To address these\nchallenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that\nleverages a lightweight parameter translator model to efficiently convert\ndocuments into parametric knowledge. DyPRAG not only reduces inference,\ntraining, and storage costs but also dynamically generates parametric\nknowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge\nconflicts in a plug-and-play manner at test-time. Extensive experiments on\nmultiple datasets demonstrate the effectiveness and generalization capabilities\nof DyPRAG, offering a powerful and practical RAG paradigm which enables\nsuperior knowledge fusion and mitigates RAG hallucination in real-world\napplications. Our code is available at https://github.com/Trae1ounG/DyPRAG.", "AI": {"tldr": "DyPRAG is a novel framework that dynamically converts documents into parametric knowledge for LLMs, reducing costs and improving generalization while mitigating RAG hallucination.", "motivation": "Address the high inference, training, and storage costs of Parametric RAG (PRAG) and its limited generalization, while resolving RAG hallucination issues.", "method": "Uses a lightweight parameter translator model to dynamically embed documents into LLMs, enabling test-time knowledge enhancement in a plug-and-play manner.", "result": "DyPRAG reduces costs and improves generalization, effectively mitigating RAG hallucination and enhancing knowledge fusion.", "conclusion": "DyPRAG offers a practical and efficient RAG paradigm, superior to PRAG, with demonstrated effectiveness in real-world applications."}}
{"id": "2411.05793", "pdf": "https://arxiv.org/pdf/2411.05793", "abs": "https://arxiv.org/abs/2411.05793", "authors": ["Jongseon Kim", "Hyungjoon Kim", "HyunGi Kim", "Dongjun Lee", "Sungroh Yoon"], "title": "A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges", "categories": ["cs.LG", "cs.AI"], "comment": "This is the accepted manuscript of the article published in\n  Artificial Intelligence Review. The final authenticated version is available\n  at: https://doi.org/10.1007/s10462-025-11223-9", "summary": "Time series forecasting is a critical task that provides key information for\ndecision-making. After traditional statistical and machine learning approaches,\nvarious fundamental deep learning architectures such as MLPs, CNNs, RNNs, and\nGNNs have been developed. However, the structural limitations caused by the\ninductive biases of each deep learning architecture constrained their\nperformance. Transformer models, which excel at handling long-term\ndependencies, have become significant architectural components for time series\nforecasting. However, recent research has shown that alternatives such as\nsimple linear layers can outperform Transformers. These findings have opened up\nnew possibilities for using diverse architectures, ranging from fundamental\ndeep learning models to emerging architectures and hybrid approaches. In this\ncontext, architectural modeling of time series forecasting has now entered a\nrenaissance. This survey not only provides a historical context for time series\nforecasting but also offers comprehensive and timely analysis of the movement\ntoward architectural diversification. By comparing and re-examining deep\nlearning models, we uncover new perspectives and present recent trends,\nincluding hybrid, diffusion, Mamba, and foundation models. By focusing on the\ninherent characteristics of time series data, we also address open challenges\nthat have gained attention in time series forecasting, such as channel\ndependency, distribution shift, causality, and feature extraction. These\ncontributions help lower entry barriers for newcomers by providing a systematic\nunderstanding of the diverse research areas in time series forecasting (TSF),\nwhile offering seasoned researchers broader perspectives and new opportunities\nthrough in-depth exploration of TSF challenges. (Shortened due to arXiv's\n1,920-character limit. Full version in the paper.)", "AI": {"tldr": "The paper surveys the evolution and diversification of architectures in time series forecasting, highlighting the shift from traditional methods to deep learning and emerging models like Transformers, linear layers, and hybrids. It also addresses key challenges and trends.", "motivation": "To provide a comprehensive analysis of the architectural advancements and challenges in time series forecasting, bridging historical context with modern trends.", "method": "A survey comparing and re-examining deep learning models, including hybrid, diffusion, Mamba, and foundation models, while addressing inherent data challenges.", "result": "Uncovers new perspectives and trends, emphasizing architectural diversification and tackling challenges like channel dependency and distribution shift.", "conclusion": "The paper lowers entry barriers for newcomers and offers seasoned researchers broader insights into time series forecasting's evolving landscape."}}
{"id": "2501.19243", "pdf": "https://arxiv.org/pdf/2501.19243", "abs": "https://arxiv.org/abs/2501.19243", "authors": ["Junxiang Qiu", "Shuo Wang", "Jinda Lu", "Lin Liu", "Houcheng Jiang", "Xingyu Zhu", "Yanbin Hao"], "title": "Accelerating Diffusion Transformer via Error-Optimized Cache", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion Transformer (DiT) is a crucial method for content generation.\nHowever, it needs a lot of time to sample. Many studies have attempted to use\ncaching to reduce the time consumption of sampling. Existing caching methods\naccelerate generation by reusing DiT features from the previous time step and\nskipping calculations in the next, but they tend to locate and cache low-error\nmodules without focusing on reducing caching-induced errors, resulting in a\nsharp decline in generated content quality when increasing caching intensity.\nTo solve this problem, we propose the Error-Optimized Cache (EOC). This method\nintroduces three key improvements: (1) Prior knowledge extraction: Extract and\nprocess the caching differences; (2) A judgment method for cache optimization:\nDetermine whether certain caching steps need to be optimized; (3) Cache\noptimization: reduce caching errors. Experiments show that this algorithm\nsignificantly reduces the error accumulation caused by caching, especially\nexcessive caching. On the ImageNet dataset, without substantially increasing\nthe computational load, this method improves the FID of the generated images\nwhen the rule-based model FORA has a caching level of 75%, 50%, and 25%, and\nthe training-based model Learning-to-cache has a caching level of 22%.\nSpecifically, the FID values change from 30.454 to 21.690 (28.8%), from 6.857\nto 5.821 (15.1%), from 3.870 to 3.692 (4.6%), and from 3.539 to 3.451 (2.5%)\nrespectively.", "AI": {"tldr": "The paper introduces Error-Optimized Cache (EOC) to address the quality decline in Diffusion Transformer (DiT) sampling caused by existing caching methods. EOC reduces caching errors through prior knowledge extraction, cache optimization judgment, and error reduction.", "motivation": "Existing caching methods for DiT accelerate sampling by reusing features but degrade content quality due to caching-induced errors. The goal is to minimize these errors while maintaining efficiency.", "method": "EOC introduces three improvements: (1) prior knowledge extraction of caching differences, (2) a judgment method for cache optimization, and (3) cache optimization to reduce errors.", "result": "EOC significantly reduces error accumulation, improving FID scores on ImageNet at various caching levels (e.g., 28.8% improvement at 75% caching).", "conclusion": "EOC effectively balances sampling speed and content quality by optimizing caching errors, outperforming existing methods like FORA and Learning-to-cache."}}
{"id": "2505.00460", "pdf": "https://arxiv.org/pdf/2505.00460", "abs": "https://arxiv.org/abs/2505.00460", "authors": ["Harshit Kapadia", "Peter Benner", "Lihong Feng"], "title": "Subspace-Distance-Enabled Active Learning for Efficient Data-Driven Model Reduction of Parametric Dynamical Systems", "categories": ["math.NA", "cs.CE", "cs.LG", "cs.NA", "math.DS", "physics.comp-ph"], "comment": "31 pages, 10 figures, 4 tables", "summary": "In situations where the solution of a high-fidelity dynamical system needs to\nbe evaluated repeatedly, over a vast pool of parametric configurations and in\nabsence of access to the underlying governing equations, data-driven model\nreduction techniques are preferable. We propose a novel active learning\napproach to build a parametric data-driven reduced-order model (ROM) by\ngreedily picking the most important parameter samples from the parameter\ndomain. As a result, during the ROM construction phase, the number of\nhigh-fidelity solutions dynamically grow in a principled fashion. The\nhigh-fidelity solution snapshots are expressed in several parameter-specific\nlinear subspaces, with the help of proper orthogonal decomposition (POD), and\nthe relative distance between these subspaces is used as a guiding mechanism to\nperform active learning. For successfully achieving this, we provide a distance\nmeasure to evaluate the similarity between pairs of linear subspaces with\ndifferent dimensions, and also show that this distance measure is a metric. The\nusability of the proposed subspace-distance-enabled active learning (SDE-AL)\nframework is demonstrated by augmenting two existing non-intrusive\nreduced-order modeling approaches, and providing their active-learning-driven\n(ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN.\nFurthermore, we report positive results for two parametric physical models,\nhighlighting the efficiency of the proposed SDE-AL approach.", "AI": {"tldr": "A novel active learning approach for parametric data-driven reduced-order models (ROMs) is proposed, using subspace distance to guide sample selection and improve efficiency.", "motivation": "The need for efficient evaluation of high-fidelity dynamical systems without access to governing equations drives the development of data-driven ROMs.", "method": "The approach uses proper orthogonal decomposition (POD) to express solutions in parameter-specific subspaces and a new subspace distance metric for active learning.", "result": "Two extensions (SDE-ActLearn-POD-KSNN and SDE-ActLearn-POD-NN) are developed and tested, showing positive results on parametric physical models.", "conclusion": "The SDE-AL framework effectively enhances non-intrusive ROM approaches, demonstrating efficiency in parametric model reduction."}}
{"id": "2504.00027", "pdf": "https://arxiv.org/pdf/2504.00027", "abs": "https://arxiv.org/abs/2504.00027", "authors": ["Grigori Sidorov", "Muhammad Ahmad", "Iqra Ameer", "Muhammad Usman", "Ildar Batyrshin"], "title": "Opioid Named Entity Recognition (ONER-2025) from Reddit", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The opioid overdose epidemic remains a critical public health crisis,\nparticularly in the United States, leading to significant mortality and\nsocietal costs. Social media platforms like Reddit provide vast amounts of\nunstructured data that offer insights into public perceptions, discussions, and\nexperiences related to opioid use. This study leverages Natural Language\nProcessing (NLP), specifically Opioid Named Entity Recognition (ONER-2025), to\nextract actionable information from these platforms. Our research makes four\nkey contributions. First, we created a unique, manually annotated dataset\nsourced from Reddit, where users share self-reported experiences of opioid use\nvia different administration routes. This dataset contains 331,285 tokens and\nincludes eight major opioid entity categories. Second, we detail our annotation\nprocess and guidelines while discussing the challenges of labeling the\nONER-2025 dataset. Third, we analyze key linguistic challenges, including\nslang, ambiguity, fragmented sentences, and emotionally charged language, in\nopioid discussions. Fourth, we propose a real-time monitoring system to process\nstreaming data from social media, healthcare records, and emergency services to\nidentify overdose events. Using 5-fold cross-validation in 11 experiments, our\nsystem integrates machine learning, deep learning, and transformer-based\nlanguage models with advanced contextual embeddings to enhance understanding.\nOur transformer-based models (bert-base-NER and roberta-base) achieved 97%\naccuracy and F1-score, outperforming baselines by 10.23% (RF=0.88).", "AI": {"tldr": "The study uses NLP to analyze opioid-related discussions on Reddit, creating a dataset and a real-time monitoring system for overdose events, achieving high accuracy with transformer models.", "motivation": "The opioid overdose epidemic is a major public health crisis, and social media data can provide insights into public perceptions and experiences.", "method": "Leverages NLP (ONER-2025) to analyze Reddit data, creating a manually annotated dataset and proposing a real-time monitoring system using machine learning and transformer models.", "result": "Transformer-based models achieved 97% accuracy and F1-score, outperforming baselines by 10.23%.", "conclusion": "The study demonstrates the potential of NLP and social media data to address the opioid crisis through real-time monitoring and high-accuracy models."}}
{"id": "2412.08085", "pdf": "https://arxiv.org/pdf/2412.08085", "abs": "https://arxiv.org/abs/2412.08085", "authors": ["Syrine Belakaria", "Alaleh Ahmadianshalchi", "Barbara Engelhardt", "Stefano Ermon", "Janardhan Rao Doppa"], "title": "Non-Myopic Multi-Objective Bayesian Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Published in Transactions on Machine Learning Research (TMLR)", "summary": "We consider the problem of finite-horizon sequential experimental design to\nsolve multi-objective optimization (MOO) of expensive black-box objective\nfunctions. This problem arises in many real-world applications, including\nmaterials design, where we have a small resource budget to make and evaluate\ncandidate materials in the lab. We solve this problem using the framework of\nBayesian optimization (BO) and propose the first set of non-myopic methods for\nMOO problems. Prior work on non-myopic BO for single-objective problems relies\non the Bellman optimality principle to handle the lookahead reasoning process.\nHowever, this principle does not hold for most MOO problems because the reward\nfunction needs to satisfy some conditions: scalar variable, monotonicity, and\nadditivity. We address this challenge by using hypervolume improvement (HVI) as\nour scalarization approach, which allows us to use a lower-bound on the Bellman\nequation to approximate the finite-horizon using a batch expected hypervolume\nimprovement (EHVI) acquisition function (AF) for MOO. Our formulation naturally\nallows us to use other improvement-based scalarizations and compare their\nefficacy to HVI. We derive three non-myopic AFs for MOBO: 1) the Nested AF,\nwhich is based on the exact computation of the lower bound, 2) the Joint AF,\nwhich is a lower bound on the nested AF, and 3) the BINOM AF, which is a fast\nand approximate variant based on batch multi-objective acquisition functions.\nOur experiments on multiple diverse real-world MO problems demonstrate that our\nnon-myopic AFs substantially improve performance over the existing myopic AFs\nfor MOBO.", "AI": {"tldr": "The paper introduces non-myopic Bayesian optimization methods for multi-objective optimization (MOO) of expensive black-box functions, addressing challenges in finite-horizon sequential experimental design.", "motivation": "The problem arises in real-world applications like materials design, where limited resources necessitate efficient experimental design. Existing methods are myopic and don't handle MOO well due to the Bellman principle's limitations.", "method": "Proposes three non-myopic acquisition functions (AFs) for MOO: Nested AF (exact lower bound), Joint AF (lower bound on Nested AF), and BINOM AF (fast approximate variant). Uses hypervolume improvement (HVI) for scalarization.", "result": "Experiments show the non-myopic AFs outperform existing myopic AFs in diverse real-world MOO problems.", "conclusion": "The proposed methods effectively address the challenges of non-myopic MOO, offering improved performance and scalability for real-world applications."}}
{"id": "2504.02782", "pdf": "https://arxiv.org/pdf/2504.02782", "abs": "https://arxiv.org/abs/2504.02782", "authors": ["Zhiyuan Yan", "Junyan Ye", "Weijia Li", "Zilong Huang", "Shenghai Yuan", "Xiangyang He", "Kaiqing Lin", "Jun He", "Conghui He", "Li Yuan"], "title": "GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "The recent breakthroughs in OpenAI's GPT4o model have demonstrated\nsurprisingly good capabilities in image generation and editing, resulting in\nsignificant excitement in the community. This technical report presents the\nfirst-look evaluation benchmark (named GPT-ImgEval), quantitatively and\nqualitatively diagnosing GPT-4o's performance across three critical dimensions:\n(1) generation quality, (2) editing proficiency, and (3) world\nknowledge-informed semantic synthesis. Across all three tasks, GPT-4o\ndemonstrates strong performance, significantly surpassing existing methods in\nboth image generation control and output quality, while also showcasing\nexceptional knowledge reasoning capabilities. Furthermore, based on the\nGPT-4o's generated data, we propose a classification-model-based approach to\ninvestigate the underlying architecture of GPT-4o, where our empirical results\nsuggest the model consists of an auto-regressive (AR) combined with a\ndiffusion-based head for image decoding, rather than the VAR-like\narchitectures. We also provide a complete speculation on GPT-4o's overall\narchitecture. In addition, we conduct a series of analyses to identify and\nvisualize GPT-4o's specific limitations and the synthetic artifacts commonly\nobserved in its image generation. We also present a comparative study of\nmulti-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the\nsafety implications of GPT-4o's outputs, particularly their detectability by\nexisting image forensic models. We hope that our work can offer valuable\ninsight and provide a reliable benchmark to guide future research, foster\nreproducibility, and accelerate innovation in the field of image generation and\nbeyond. The codes and datasets used for evaluating GPT-4o can be found at\nhttps://github.com/PicoTrex/GPT-ImgEval.", "AI": {"tldr": "The paper introduces GPT-ImgEval, a benchmark for evaluating GPT-4o's image generation, editing, and semantic synthesis capabilities, revealing its strong performance and unique architecture. It also highlights limitations and safety implications.", "motivation": "To quantitatively and qualitatively assess GPT-4o's capabilities in image generation and editing, and to provide insights into its architecture and limitations.", "method": "Developed the GPT-ImgEval benchmark, evaluated GPT-4o across three tasks, proposed a classification-model-based approach to analyze its architecture, and conducted comparative and safety analyses.", "result": "GPT-4o outperforms existing methods in image generation and editing, exhibits a unique AR-diffusion hybrid architecture, and has identifiable limitations and synthetic artifacts.", "conclusion": "The work provides a reliable benchmark for future research, fosters reproducibility, and accelerates innovation in image generation, while also addressing safety concerns."}}
{"id": "2505.00500", "pdf": "https://arxiv.org/pdf/2505.00500", "abs": "https://arxiv.org/abs/2505.00500", "authors": ["Minseok Song", "JeongHo Ha", "Bonggyeong Park", "Daehyung Park"], "title": "Implicit Neural-Representation Learning for Elastic Deformable-Object Manipulations", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We aim to solve the problem of manipulating deformable objects, particularly\nelastic bands, in real-world scenarios. However, deformable object manipulation\n(DOM) requires a policy that works on a large state space due to the unlimited\ndegree of freedom (DoF) of deformable objects. Further, their dense but partial\nobservations (e.g., images or point clouds) may increase the sampling\ncomplexity and uncertainty in policy learning. To figure it out, we propose a\nnovel implicit neural-representation (INR) learning for elastic DOMs, called\nINR-DOM. Our method learns consistent state representations associated with\npartially observable elastic objects reconstructing a complete and implicit\nsurface represented as a signed distance function. Furthermore, we perform\nexploratory representation fine-tuning through reinforcement learning (RL) that\nenables RL algorithms to effectively learn exploitable representations while\nefficiently obtaining a DOM policy. We perform quantitative and qualitative\nanalyses building three simulated environments and real-world manipulation\nstudies with a Franka Emika Panda arm. Videos are available at\nhttp://inr-dom.github.io.", "AI": {"tldr": "Proposes INR-DOM, a method using implicit neural-representation and reinforcement learning for deformable object manipulation (DOM) of elastic bands, addressing partial observations and high state space complexity.", "motivation": "DOM is challenging due to the unlimited degrees of freedom of deformable objects and partial observations, increasing policy learning complexity.", "method": "Uses implicit neural-representation (INR) to learn consistent state representations and reconstructs surfaces as signed distance functions. Combines this with reinforcement learning for policy learning.", "result": "Demonstrated through simulated environments and real-world experiments with a Franka Emika Panda arm, showing effective DOM policy learning.", "conclusion": "INR-DOM successfully addresses DOM challenges by integrating INR and RL, enabling efficient policy learning for deformable objects."}}
{"id": "2504.14194", "pdf": "https://arxiv.org/pdf/2504.14194", "abs": "https://arxiv.org/abs/2504.14194", "authors": ["Xinlin Zhuang", "Jiahui Peng", "Ren Ma", "Yinfan Wang", "Tianyi Bai", "Xingjian Wei", "Jiantao Qiu", "Chi Zhang", "Ying Qian", "Conghui He"], "title": "Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models", "categories": ["cs.CL"], "comment": "Under review", "summary": "The composition of pre-training datasets for large language models (LLMs)\nremains largely undisclosed, hindering transparency and efforts to optimize\ndata quality, a critical driver of model performance. Current data selection\nmethods, such as natural language quality assessments, diversity-based filters,\nand classifier-based approaches, are limited by single-dimensional evaluation\nor redundancy-focused strategies. To address these gaps, we propose PRRC to\nevaluate data quality across Professionalism, Readability, Reasoning, and\nCleanliness. We further introduce Meta-rater, a multi-dimensional data\nselection method that integrates these dimensions with existing quality metrics\nthrough learned optimal weightings. Meta-rater employs proxy models to train a\nregression model that predicts validation loss, enabling the identification of\noptimal combinations of quality scores. Experiments demonstrate that Meta-rater\ndoubles convergence speed for 1.3B parameter models and improves downstream\ntask performance by 3.23, with scalable benefits observed in 3.3B models\ntrained on 100B tokens. Additionally, we release the annotated SlimPajama-627B\ndataset, labeled across 25 quality metrics (including PRRC), to advance\nresearch in data-centric LLM development. Our work establishes that holistic,\nmulti-dimensional quality integration significantly outperforms conventional\nsingle-dimension approaches, offering a scalable paradigm for enhancing\npre-training efficiency and model capability.", "AI": {"tldr": "The paper introduces PRRC and Meta-rater, a multi-dimensional data selection method for LLMs, improving convergence speed and downstream task performance.", "motivation": "Current data selection methods for LLMs are limited by single-dimensional evaluation, hindering transparency and optimization of data quality.", "method": "Proposes PRRC (Professionalism, Readability, Reasoning, Cleanliness) and Meta-rater, which integrates these dimensions with learned weightings to predict validation loss.", "result": "Meta-rater doubles convergence speed for 1.3B models and improves downstream task performance by 3.23. Benefits scale to 3.3B models.", "conclusion": "Holistic, multi-dimensional quality integration outperforms single-dimension approaches, enhancing pre-training efficiency and model capability."}}
{"id": "2412.18086", "pdf": "https://arxiv.org/pdf/2412.18086", "abs": "https://arxiv.org/abs/2412.18086", "authors": ["Aizierjiang Aiersilan"], "title": "Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.GR", "cs.LG"], "comment": "We are excited to announce that this paper has been accepted for oral\n  presentation at the AAAI 2025 Main Conference. We are grateful for the\n  insightful feedback from the reviewers and look forward to contributing to\n  the discussions at AAAI", "summary": "Motion planning is a crucial component in autonomous driving.\nState-of-the-art motion planners are trained on meticulously curated datasets,\nwhich are not only expensive to annotate but also insufficient in capturing\nrarely seen critical scenarios. Failing to account for such scenarios poses a\nsignificant risk to motion planners and may lead to incidents during testing.\nAn intuitive solution is to manually compose such scenarios by programming and\nexecuting a simulator (e.g., CARLA). However, this approach incurs substantial\nhuman costs. Motivated by this, we propose an inexpensive method for generating\ndiverse critical traffic scenarios to train more robust motion planners. First,\nwe represent traffic scenarios as scripts, which are then used by the simulator\nto generate traffic scenarios. Next, we develop a method that accepts\nuser-specified text descriptions, which a Large Language Model translates into\nscripts using in-context learning. The output scripts are sent to the simulator\nthat produces the corresponding traffic scenarios. As our method can generate\nabundant safety-critical traffic scenarios, we use them as synthetic training\ndata for motion planners. To demonstrate the value of generated scenarios, we\ntrain existing motion planners on our synthetic data, real-world datasets, and\na combination of both. Our experiments show that motion planners trained with\nour data significantly outperform those trained solely on real-world data,\nshowing the usefulness of our synthetic data and the effectiveness of our data\ngeneration method. Our source code is available at\nhttps://ezharjan.github.io/AutoSceneGen.", "AI": {"tldr": "Proposes a method to generate diverse critical traffic scenarios for training robust motion planners using Large Language Models and simulators, outperforming real-world data training.", "motivation": "Addresses the high cost and insufficiency of manually curated datasets for motion planning in autonomous driving by automating scenario generation.", "method": "Uses text descriptions translated into scripts by a Large Language Model, which are then executed in a simulator to create synthetic training scenarios.", "result": "Motion planners trained on synthetic data outperform those trained on real-world data alone.", "conclusion": "The method provides an effective, low-cost solution for generating diverse critical scenarios to enhance motion planner robustness."}}
{"id": "2504.14467", "pdf": "https://arxiv.org/pdf/2504.14467", "abs": "https://arxiv.org/abs/2504.14467", "authors": ["Jiachen Li", "Qing Xie", "Renshu Gu", "Jinyu Xu", "Yongjian Liu", "Xiaohan Yu"], "title": "LGD: Leveraging Generative Descriptions for Zero-Shot Referring Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot referring image segmentation aims to locate and segment the target\nregion based on a referring expression, with the primary challenge of aligning\nand matching semantics across visual and textual modalities without training.\nPrevious works address this challenge by utilizing Vision-Language Models and\nmask proposal networks for region-text matching. However, this paradigm may\nlead to incorrect target localization due to the inherent ambiguity and\ndiversity of free-form referring expressions. To alleviate this issue, we\npresent LGD (Leveraging Generative Descriptions), a framework that utilizes the\nadvanced language generation capabilities of Multi-Modal Large Language Models\nto enhance region-text matching performance in Vision-Language Models.\nSpecifically, we first design two kinds of prompts, the attribute prompt and\nthe surrounding prompt, to guide the Multi-Modal Large Language Models in\ngenerating descriptions related to the crucial attributes of the referent\nobject and the details of surrounding objects, referred to as attribute\ndescription and surrounding description, respectively. Secondly, three\nvisual-text matching scores are introduced to evaluate the similarity between\ninstance-level visual features and textual features, which determines the mask\nmost associated with the referring expression. The proposed method achieves new\nstate-of-the-art performance on three public datasets RefCOCO, RefCOCO+ and\nRefCOCOg, with maximum improvements of 9.97% in oIoU and 11.29% in mIoU\ncompared to previous methods.", "AI": {"tldr": "LGD framework uses generative descriptions from Multi-Modal Large Language Models to improve zero-shot referring image segmentation by enhancing region-text matching.", "motivation": "Addressing incorrect target localization due to ambiguity in free-form referring expressions by leveraging advanced language generation.", "method": "Designs attribute and surrounding prompts for generative descriptions, then uses visual-text matching scores to align features.", "result": "Achieves state-of-the-art performance on RefCOCO, RefCOCO+, and RefCOCOg, with up to 9.97% oIoU and 11.29% mIoU improvements.", "conclusion": "LGD effectively enhances region-text matching, outperforming previous methods in zero-shot referring image segmentation."}}
{"id": "2505.00526", "pdf": "https://arxiv.org/pdf/2505.00526", "abs": "https://arxiv.org/abs/2505.00526", "authors": ["Yanhao 'Max' Wei", "Zhenling Jiang"], "title": "Pre-Training Estimators for Structural Models: Application to Consumer Search", "categories": ["econ.EM", "cs.LG", "stat.CO", "G.3; J.4; I.2"], "comment": null, "summary": "We explore pretraining estimators for structural econometric models. The\nestimator is \"pretrained\" in the sense that the bulk of the computational cost\nand researcher effort occur during the construction of the estimator.\nSubsequent applications of the estimator to different datasets require little\ncomputational cost or researcher effort. The estimation leverages a neural net\nto recognize the structural model's parameter from data patterns. As an initial\ntrial, this paper builds a pretrained estimator for a sequential search model\nthat is known to be difficult to estimate. We evaluate the pretrained estimator\non 14 real datasets. The estimation takes seconds to run and shows high\naccuracy. We provide the estimator at pnnehome.github.io. More generally,\npretrained, off-the-shelf estimators can make structural models more accessible\nto researchers and practitioners.", "AI": {"tldr": "The paper introduces pretrained estimators for structural econometric models, reducing computational cost and effort in subsequent applications. A neural net is used to recognize model parameters, tested on a challenging sequential search model with high accuracy.", "motivation": "To make structural econometric models more accessible by reducing computational and researcher effort through pretrained estimators.", "method": "Leverages a neural network to recognize structural model parameters from data patterns, applied to a sequential search model.", "result": "The pretrained estimator was tested on 14 real datasets, achieving high accuracy and running in seconds.", "conclusion": "Pretrained estimators can enhance accessibility of structural models for researchers and practitioners."}}
{"id": "2504.16060", "pdf": "https://arxiv.org/pdf/2504.16060", "abs": "https://arxiv.org/abs/2504.16060", "authors": ["Ziqiao Ma", "Jing Ding", "Xuejun Zhang", "Dezhi Luo", "Jiahe Ding", "Sihan Xu", "Yuchen Huang", "Run Peng", "Joyce Chai"], "title": "Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation", "categories": ["cs.CL"], "comment": "Homepage: https://vlm-reg.github.io/", "summary": "Referring Expression Generation (REG) is a core task for evaluating the\npragmatic competence of vision-language systems, requiring not only accurate\nsemantic grounding but also adherence to principles of cooperative\ncommunication (Grice, 1975). However, current evaluations of vision-language\nmodels (VLMs) often overlook the pragmatic dimension, reducing REG to a\nregion-based captioning task and neglecting Gricean maxims. In this work, we\nrevisit REG from a pragmatic perspective, introducing a new dataset (RefOI) of\n1.5k images annotated with both written and spoken referring expressions.\nThrough a systematic evaluation of state-of-the-art VLMs, we identify three key\nfailures of pragmatic competence: (1) failure to uniquely identify the\nreferent, (2) inclusion of excessive or irrelevant information, and (3)\nmisalignment with human pragmatic preference, such as the underuse of minimal\nspatial cues. We also show that standard automatic evaluations fail to capture\nthese pragmatic violations, reinforcing superficial cues rather than genuine\nreferential success. Our findings call for a renewed focus on pragmatically\ninformed models and evaluation frameworks that align with real human\ncommunication.", "AI": {"tldr": "The paper critiques current vision-language models (VLMs) for lacking pragmatic competence in Referring Expression Generation (REG) and introduces a new dataset (RefOI) to highlight pragmatic failures.", "motivation": "Current evaluations of VLMs overlook pragmatic dimensions, reducing REG to a simplistic task and ignoring Gricean communication principles.", "method": "The authors introduce RefOI, a dataset of 1.5k images with annotated referring expressions, and systematically evaluate VLMs for pragmatic failures.", "result": "Three key pragmatic failures are identified: inability to uniquely identify referents, inclusion of irrelevant information, and misalignment with human preferences. Standard evaluations fail to detect these issues.", "conclusion": "The study advocates for pragmatically informed models and evaluation frameworks to better align with human communication."}}
{"id": "2501.06066", "pdf": "https://arxiv.org/pdf/2501.06066", "abs": "https://arxiv.org/abs/2501.06066", "authors": ["Jiayi Huang", "Sangwoo Park", "Nicola Paoletti", "Osvaldo Simeone"], "title": "Distilling Calibration via Conformalized Credal Inference", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": "Under review", "summary": "Deploying artificial intelligence (AI) models on edge devices involves a\ndelicate balance between meeting stringent complexity constraints, such as\nlimited memory and energy resources, and ensuring reliable performance in\nsensitive decision-making tasks. One way to enhance reliability is through\nuncertainty quantification via Bayesian inference. This approach, however,\ntypically necessitates maintaining and running multiple models in an ensemble,\nwhich may exceed the computational limits of edge devices. This paper\nintroduces a low-complexity methodology to address this challenge by distilling\ncalibration information from a more complex model. In an offline phase,\npredictive probabilities generated by a high-complexity cloud-based model are\nleveraged to determine a threshold based on the typical divergence between the\ncloud and edge models. At run time, this threshold is used to construct credal\nsets -- ranges of predictive probabilities that are guaranteed, with a\nuser-selected confidence level, to include the predictions of the cloud model.\nThe credal sets are obtained through thresholding of a divergence measure in\nthe simplex of predictive probabilities. Experiments on visual and language\ntasks demonstrate that the proposed approach, termed Conformalized Distillation\nfor Credal Inference (CD-CI), significantly improves calibration performance\ncompared to low-complexity Bayesian methods, such as Laplace approximation,\nmaking it a practical and efficient solution for edge AI deployments.", "AI": {"tldr": "CD-CI improves edge AI reliability by distilling calibration info from a complex model, using credal sets for uncertainty quantification without exceeding computational limits.", "motivation": "Balancing AI model complexity and reliability on edge devices with limited resources, especially for sensitive tasks.", "method": "Offline phase uses cloud-based model predictions to set a divergence threshold; runtime constructs credal sets for uncertainty quantification.", "result": "CD-CI outperforms low-complexity Bayesian methods in calibration, validated on visual and language tasks.", "conclusion": "CD-CI is a practical, efficient solution for edge AI, enhancing reliability without computational overload."}}
{"id": "2504.20379", "pdf": "https://arxiv.org/pdf/2504.20379", "abs": "https://arxiv.org/abs/2504.20379", "authors": ["Jongwon Lee", "Timothy Bretl"], "title": "GSFeatLoc: Visual Localization Using Feature Correspondence on 3D Gaussian Splatting", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "In this paper, we present a method for localizing a query image with respect\nto a precomputed 3D Gaussian Splatting (3DGS) scene representation. First, the\nmethod uses 3DGS to render a synthetic RGBD image at some initial pose\nestimate. Second, it establishes 2D-2D correspondences between the query image\nand this synthetic image. Third, it uses the depth map to lift the 2D-2D\ncorrespondences to 2D-3D correspondences and solves a perspective-n-point (PnP)\nproblem to produce a final pose estimate. Results from evaluation across three\nexisting datasets with 38 scenes and over 2,700 test images show that our\nmethod significantly reduces both inference time (by over two orders of\nmagnitude, from more than 10 seconds to as fast as 0.1 seconds) and estimation\nerror compared to baseline methods that use photometric loss minimization.\nResults also show that our method tolerates large errors in the initial pose\nestimate of up to 55{\\deg} in rotation and 1.1 units in translation (normalized\nby scene scale), achieving final pose errors of less than 5{\\deg} in rotation\nand 0.05 units in translation on 90% of images from the Synthetic NeRF and\nMip-NeRF360 datasets and on 42% of images from the more challenging Tanks and\nTemples dataset.", "AI": {"tldr": "A method for query image localization using 3D Gaussian Splatting (3DGS) and PnP, achieving faster inference and lower error than baselines.", "motivation": "To improve image localization efficiency and accuracy by leveraging 3DGS and 2D-3D correspondences.", "method": "Renders synthetic RGBD images with 3DGS, establishes 2D-2D correspondences, lifts to 2D-3D, and solves PnP for pose estimation.", "result": "Reduces inference time by 100x (to 0.1s) and errors significantly, tolerating large initial pose errors.", "conclusion": "The method is fast, accurate, and robust to initial pose errors, outperforming photometric loss baselines."}}
{"id": "2505.00552", "pdf": "https://arxiv.org/pdf/2505.00552", "abs": "https://arxiv.org/abs/2505.00552", "authors": ["Chanwoo Kim", "Jinkyu Sung", "Yebonn Han", "Joonseok Lee"], "title": "Graph Spectral Filtering with Chebyshev Interpolation for Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted by SIGIR 2025; 11 pages, 9 figures, 5 tables", "summary": "Graph convolutional networks have recently gained prominence in collaborative\nfiltering (CF) for recommendations. However, we identify potential bottlenecks\nin two foundational components. First, the embedding layer leads to a latent\nspace with limited capacity, overlooking locally observed but potentially\nvaluable preference patterns. Also, the widely-used neighborhood aggregation is\nlimited in its ability to leverage diverse preference patterns in a\nfine-grained manner. Building on spectral graph theory, we reveal that these\nlimitations stem from graph filtering with a cut-off in the frequency spectrum\nand a restricted linear form. To address these issues, we introduce ChebyCF, a\nCF framework based on graph spectral filtering. Instead of a learned embedding,\nit takes a user's raw interaction history to utilize the full spectrum of\nsignals contained in it. Also, it adopts Chebyshev interpolation to effectively\napproximate a flexible non-linear graph filter, and further enhances it by\nusing an additional ideal pass filter and degree-based normalization. Through\nextensive experiments, we verify that ChebyCF overcomes the aforementioned\nbottlenecks and achieves state-of-the-art performance across multiple\nbenchmarks and reasonably fast inference. Our code is available at\nhttps://github.com/chanwoo0806/ChebyCF.", "AI": {"tldr": "ChebyCF introduces a graph spectral filtering-based framework for collaborative filtering, addressing bottlenecks in embedding layers and neighborhood aggregation by leveraging raw interaction history and Chebyshev interpolation for non-linear filtering.", "motivation": "The limitations of current graph convolutional networks in collaborative filtering, such as restricted latent space capacity and inefficient neighborhood aggregation, motivate the development of ChebyCF.", "method": "ChebyCF replaces learned embeddings with raw interaction history and uses Chebyshev interpolation for flexible non-linear graph filtering, enhanced by an ideal pass filter and degree-based normalization.", "result": "ChebyCF achieves state-of-the-art performance across benchmarks with fast inference, overcoming prior bottlenecks.", "conclusion": "ChebyCF effectively addresses key limitations in graph-based CF, offering improved performance and efficiency."}}
{"id": "2504.19314", "pdf": "https://arxiv.org/pdf/2504.19314", "abs": "https://arxiv.org/abs/2504.19314", "authors": ["Peilin Zhou", "Bruce Leon", "Xiang Ying", "Can Zhang", "Yifan Shao", "Qichen Ye", "Dading Chong", "Zhiling Jin", "Chenxuan Xie", "Meng Cao", "Yuxin Gu", "Sixin Hong", "Jing Ren", "Jian Chen", "Chao Liu", "Yining Hua"], "title": "BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese", "categories": ["cs.CL"], "comment": "Under Review", "summary": "As large language models (LLMs) evolve into tool-using agents, the ability to\nbrowse the web in real-time has become a critical yardstick for measuring their\nreasoning and retrieval competence. Existing benchmarks such as BrowseComp\nconcentrate on English and overlook the linguistic, infrastructural, and\ncensorship-related complexities of other major information ecosystems -- most\nnotably Chinese. To address this gap, we introduce BrowseComp-ZH, a\nhigh-difficulty benchmark purpose-built to comprehensively evaluate LLM agents\non the Chinese web. BrowseComp-ZH consists of 289 multi-hop questions spanning\n11 diverse domains. Each question is reverse-engineered from a short,\nobjective, and easily verifiable answer (e.g., a date, number, or proper noun).\nA two-stage quality control protocol is applied to strive for high question\ndifficulty and answer uniqueness. We benchmark over 20 state-of-the-art\nlanguage models and agentic search systems on our proposed BrowseComp-ZH.\nDespite their strong conversational and retrieval capabilities, most models\nstruggle severely: a large number achieve accuracy rates below 10%, and only a\nhandful exceed 20%. Even the best-performing system, OpenAI's DeepResearch,\nreaches just 42.9%. These results demonstrate the considerable difficulty of\nBrowseComp-ZH, where success demands not only effective retrieval strategies,\nbut also sophisticated reasoning and information reconciliation -- capabilities\nthat current models still struggle to master. Our dataset, construction\nguidelines, and benchmark results have been publicly released at\nhttps://github.com/PALIN2018/BrowseComp-ZH.", "AI": {"tldr": "BrowseComp-ZH is a high-difficulty benchmark for evaluating LLM agents on the Chinese web, revealing significant performance gaps despite advanced models.", "motivation": "Existing benchmarks like BrowseComp focus on English, neglecting complexities in other languages like Chinese. BrowseComp-ZH addresses this gap.", "method": "The benchmark includes 289 multi-hop questions across 11 domains, reverse-engineered from verifiable answers, with rigorous quality control.", "result": "Most models perform poorly (below 10% accuracy), with OpenAI's DeepResearch leading at 42.9%.", "conclusion": "BrowseComp-ZH highlights the need for better retrieval, reasoning, and information reconciliation in LLM agents for non-English contexts."}}
{"id": "2501.15877", "pdf": "https://arxiv.org/pdf/2501.15877", "abs": "https://arxiv.org/abs/2501.15877", "authors": ["Ashita Batra", "Mannas Narang", "Neeraj Kumar Sharma", "Pradip K Das"], "title": "Boli: A dataset for understanding stuttering experience and analyzing stuttered speech", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "There is a growing need for diverse, high-quality stuttered speech data,\nparticularly in the context of Indian languages. This paper introduces Project\nBoli, a multi-lingual stuttered speech dataset designed to advance scientific\nunderstanding and technology development for individuals who stutter,\nparticularly in India. The dataset constitutes (a) anonymized metadata (gender,\nage, country, mother tongue) and responses to a questionnaire about how\nstuttering affects their daily lives, (b) captures both read speech (using the\nRainbow Passage) and spontaneous speech (through image description tasks) for\neach participant and (c) includes detailed annotations of five stutter types:\nblocks, prolongations, interjections, sound repetitions and word repetitions.\nWe present a comprehensive analysis of the dataset, including the data\ncollection procedure, experience summarization of people who stutter, severity\nassessment of stuttering events and technical validation of the collected data.\nThe dataset is released as an open access to further speech technology\ndevelopment.", "AI": {"tldr": "Project Boli introduces a multi-lingual stuttered speech dataset for Indian languages, including metadata, speech samples, and stutter annotations, to aid research and technology development.", "motivation": "Address the lack of diverse, high-quality stuttered speech data, especially for Indian languages, to support individuals who stutter.", "method": "Collects anonymized metadata, questionnaire responses, read and spontaneous speech samples, and detailed stutter annotations.", "result": "A comprehensive dataset with analysis of collection procedures, stutter severity, and technical validation.", "conclusion": "The dataset is released openly to advance speech technology for stuttering research and development."}}
{"id": "2311.14090", "pdf": "https://arxiv.org/pdf/2311.14090", "abs": "https://arxiv.org/abs/2311.14090", "authors": ["Z. S. Baltaci", "K. Oksuz", "S. Kuzucu", "K. Tezoren", "B. K. Konar", "A. Ozkan", "E. Akbas", "S. Kalkan"], "title": "Class Uncertainty: A Measure to Mitigate Class Imbalance", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Class-wise characteristics of training examples affect the performance of\ndeep classifiers. A well-studied example is when the number of training\nexamples of classes follows a long-tailed distribution, a situation that is\nlikely to yield sub-optimal performance for under-represented classes. This\nclass imbalance problem is conventionally addressed by approaches relying on\nthe class-wise cardinality of training examples, such as data resampling. In\nthis paper, we demonstrate that considering solely the cardinality of classes\ndoes not cover all issues causing class imbalance. To measure class imbalance,\nwe propose \"Class Uncertainty\" as the average predictive uncertainty of the\ntraining examples, and we show that this novel measure captures the differences\nacross classes better than cardinality. We also curate SVCI-20 as a novel\ndataset in which the classes have equal number of training examples but they\ndiffer in terms of their hardness; thereby causing a type of class imbalance\nwhich cannot be addressed by the approaches relying on cardinality. We\nincorporate our \"Class Uncertainty\" measure into a diverse set of ten class\nimbalance mitigation methods to demonstrate its effectiveness on long-tailed\ndatasets as well as on our SVCI-20. Code and datasets will be made available.", "AI": {"tldr": "The paper introduces 'Class Uncertainty' as a better measure for class imbalance than cardinality, validates it on a new dataset (SVCI-20), and integrates it into existing imbalance mitigation methods.", "motivation": "Class imbalance affects deep classifiers, but current methods rely on class cardinality, which doesn't capture all imbalance issues.", "method": "Proposes 'Class Uncertainty' as a measure, validates it on SVCI-20 (a dataset with equal class sizes but varying hardness), and integrates it into ten imbalance mitigation methods.", "result": "'Class Uncertainty' better captures class differences than cardinality and improves performance on long-tailed datasets and SVCI-20.", "conclusion": "The proposed measure effectively addresses class imbalance beyond cardinality, enhancing existing methods."}}
{"id": "2505.00571", "pdf": "https://arxiv.org/pdf/2505.00571", "abs": "https://arxiv.org/abs/2505.00571", "authors": ["Giorgio Spadaccini", "Marjolein Fokkema", "Mark A. van de Wiel"], "title": "Hypothesis-free discovery from epidemiological data by automatic detection and local inference for tree-based nonlinearities and interactions", "categories": ["stat.ML", "cs.LG"], "comment": "Main body: 29 pages, 7 figures; Supplementary material: 39 pages, 14\n  figures", "summary": "In epidemiological settings, Machine Learning (ML) is gaining popularity for\nhypothesis-free discovery of risk (or protective) factors. Although ML is\nstrong at discovering non-linearities and interactions, this power is currently\ncompromised by a lack of reliable inference. Although local measures of feature\neffect can be combined with tree ensembles, uncertainty quantifications for\nthese measures remain only partially available and oftentimes unsatisfactory.\nWe propose RuleSHAP, a framework for using rule-based, hypothesis-free\ndiscovery that combines sparse Bayesian regression, tree ensembles and Shapley\nvalues in a one-step procedure that both detects and tests complex patterns at\nthe individual level. To ease computation, we derive a formula that computes\nmarginal Shapley values more efficiently for our setting. We demonstrate the\nvalidity of our framework on simulated data. To illustrate, we apply our\nmachinery to data from an epidemiological cohort to detect and infer several\neffects for high cholesterol and blood pressure, such as nonlinear interaction\neffects between features like age, sex, ethnicity, BMI and glucose level.", "AI": {"tldr": "RuleSHAP combines sparse Bayesian regression, tree ensembles, and Shapley values for reliable inference in ML-based epidemiological risk factor discovery.", "motivation": "Current ML methods lack reliable inference for non-linearities and interactions in epidemiological risk factor discovery.", "method": "RuleSHAP integrates sparse Bayesian regression, tree ensembles, and Shapley values in a one-step procedure, with an efficient formula for marginal Shapley values.", "result": "Validated on simulated data and applied to an epidemiological cohort, detecting non-linear interaction effects for high cholesterol and blood pressure.", "conclusion": "RuleSHAP provides a robust framework for hypothesis-free discovery and inference of complex patterns in epidemiological data."}}
{"id": "2504.19467", "pdf": "https://arxiv.org/pdf/2504.19467", "abs": "https://arxiv.org/abs/2504.19467", "authors": ["Jiageng Wu", "Bowen Gu", "Ren Zhou", "Kevin Xie", "Doug Snyder", "Yixing Jiang", "Valentina Carducci", "Richard Wyss", "Rishi J Desai", "Emily Alsentzer", "Leo Anthony Celi", "Adam Rodman", "Sebastian Schneeweiss", "Jonathan H. Chen", "Santiago Romero-Brufau", "Kueiyu Joshua Lin", "Jie Yang"], "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, current evaluations of LLMs in clinical contexts remain limited. Most\nexisting benchmarks rely on medical exam-style questions or PubMed-derived\ntext, failing to capture the complexity of real-world electronic health record\n(EHR) data. Others focus narrowly on specific application scenarios, limiting\ntheir generalizability across broader clinical use. To address this gap, we\npresent BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks\nsourced from real-world clinical data sources across nine languages. We\nsystematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,\nGPT-4o, Gemini, and Llama 4) under various inference strategies. With a total\nof 13,572 experiments, our results reveal substantial performance variation\nacross model sizes, languages, natural language processing tasks, and clinical\nspecialties. Notably, we demonstrate that open-source LLMs can achieve\nperformance comparable to proprietary models, while medically fine-tuned LLMs\nbased on older architectures often underperform versus updated general-purpose\nmodels. The BRIDGE and its corresponding leaderboard serve as a foundational\nresource and a unique reference for the development and evaluation of new LLMs\nin real-world clinical text understanding.\n  The BRIDGE leaderboard:\nhttps://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard", "AI": {"tldr": "BRIDGE is a multilingual benchmark for evaluating LLMs in clinical contexts, addressing gaps in existing evaluations by using real-world EHR data. It tests 52 LLMs across 87 tasks, revealing performance variations and showing open-source models can match proprietary ones.", "motivation": "Current LLM evaluations in medicine lack real-world EHR complexity and generalizability. BRIDGE aims to fill this gap with a comprehensive, multilingual benchmark.", "method": "BRIDGE comprises 87 tasks from real-world clinical data in nine languages. It evaluates 52 LLMs (e.g., GPT-4o, Gemini) under various inference strategies, totaling 13,572 experiments.", "result": "Performance varies by model size, language, task, and specialty. Open-source LLMs can rival proprietary models, while older medically fine-tuned models often underperform.", "conclusion": "BRIDGE provides a foundational resource for LLM evaluation in clinical text understanding, highlighting the potential of open-source models and the need for updated architectures."}}
{"id": "2501.16370", "pdf": "https://arxiv.org/pdf/2501.16370", "abs": "https://arxiv.org/abs/2501.16370", "authors": ["Mahdi Movahedian Moghaddam", "Kourosh Parand", "Saeed Reza Kheradpisheh"], "title": "Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations", "categories": ["cs.LG", "cs.AI", "cs.NA", "cs.NE", "math.NA", "68T07, 65R20"], "comment": null, "summary": "In this paper, we present the Residual Integral Solver Network (RISN), a\nnovel neural network architecture designed to solve a wide range of integral\nand integro-differential equations, including one-dimensional,\nmulti-dimensional, ordinary and partial integro-differential, systems,\nfractional types, and Helmholtz-type integral equations involving oscillatory\nkernels. RISN integrates residual connections with high-accuracy numerical\nmethods such as Gaussian quadrature and fractional derivative operational\nmatrices, enabling it to achieve higher accuracy and stability than traditional\nPhysics-Informed Neural Networks (PINN). The residual connections help mitigate\nvanishing gradient issues, allowing RISN to handle deeper networks and more\ncomplex kernels, particularly in multi-dimensional problems. Through extensive\nexperiments, we demonstrate that RISN consistently outperforms not only\nclassical PINNs but also advanced variants such as Auxiliary PINN (A-PINN) and\nSelf-Adaptive PINN (SA-PINN), achieving significantly lower Mean Absolute\nErrors (MAE) across various types of equations. These results highlight RISN's\nrobustness and efficiency in solving challenging integral and\nintegro-differential problems, making it a valuable tool for real-world\napplications where traditional methods often struggle.", "AI": {"tldr": "RISN is a neural network architecture for solving integral and integro-differential equations, outperforming PINNs with higher accuracy and stability.", "motivation": "Address limitations of traditional Physics-Informed Neural Networks (PINNs) in solving complex integral and integro-differential equations.", "method": "Combines residual connections with high-accuracy numerical methods like Gaussian quadrature and fractional derivative operational matrices.", "result": "RISN achieves lower Mean Absolute Errors (MAE) than PINNs and variants (A-PINN, SA-PINN) across various equation types.", "conclusion": "RISN is robust and efficient for real-world applications where traditional methods struggle."}}
{"id": "2409.12002", "pdf": "https://arxiv.org/pdf/2409.12002", "abs": "https://arxiv.org/abs/2409.12002", "authors": ["Aneesh Chavan", "Vaibhav Agrawal", "Vineeth Bhat", "Sarthak Chittawar", "Siddharth Srivastava", "Chetan Arora", "K Madhava Krishna"], "title": "Towards Global Localization using Multi-Modal Object-Instance Re-Identification", "categories": ["cs.RO", "cs.CV", "68T40", "I.2.9; I.2.10"], "comment": "8 pages, 5 figures, 3 tables. Accepted at Advances in Robotics, AIR\n  2025 (Oral)", "summary": "Re-identification (ReID) is a critical challenge in computer vision,\npredominantly studied in the context of pedestrians and vehicles. However,\nrobust object-instance ReID, which has significant implications for tasks such\nas autonomous exploration, long-term perception, and scene understanding,\nremains underexplored. In this work, we address this gap by proposing a novel\ndual-path object-instance re-identification transformer architecture that\nintegrates multimodal RGB and depth information. By leveraging depth data, we\ndemonstrate improvements in ReID across scenes that are cluttered or have\nvarying illumination conditions. Additionally, we develop a ReID-based\nlocalization framework that enables accurate camera localization and pose\nidentification across different viewpoints. We validate our methods using two\ncustom-built RGB-D datasets, as well as multiple sequences from the open-source\nTUM RGB-D datasets. Our approach demonstrates significant improvements in both\nobject instance ReID (mAP of 75.18) and localization accuracy (success rate of\n83% on TUM-RGBD), highlighting the essential role of object ReID in advancing\nrobotic perception. Our models, frameworks, and datasets have been made\npublicly available.", "AI": {"tldr": "Proposes a dual-path transformer for object-instance ReID using RGB-D data, improving performance in cluttered or varying illumination scenes, and introduces a ReID-based localization framework. Validated on custom and TUM RGB-D datasets, achieving high mAP and success rates.", "motivation": "Address the underexplored challenge of robust object-instance ReID, crucial for autonomous exploration and scene understanding.", "method": "Novel dual-path transformer integrating RGB and depth data, plus a ReID-based localization framework.", "result": "Achieved mAP of 75.18 for ReID and 83% success rate for localization on TUM-RGBD.", "conclusion": "Demonstrates the importance of object ReID for robotic perception, with publicly released models and datasets."}}
{"id": "2505.00574", "pdf": "https://arxiv.org/pdf/2505.00574", "abs": "https://arxiv.org/abs/2505.00574", "authors": ["Raffaele Cheula", "Mie Andersen"], "title": "Transition States Energies from Machine Learning: An Application to Reverse Water-Gas Shift on Single-Atom Alloys", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Obtaining accurate transition state (TS) energies is a bottleneck in\ncomputational screening of complex materials and reaction networks due to the\nhigh cost of TS search methods and first-principles methods such as density\nfunctional theory (DFT). Here we propose a machine learning (ML) model for\npredicting TS energies based on Gaussian process regression with the\nWasserstein Weisfeiler-Lehman graph kernel (WWL-GPR). Applying the model to\npredict adsorption and TS energies for the reverse water-gas shift (RWGS)\nreaction on single-atom alloy (SAA) catalysts, we show that it can\nsignificantly improve the accuracy compared to traditional approaches based on\nscaling relations or ML models without a graph representation. Further\nbenefitting from the low cost of model training, we train an ensemble of\nWWL-GPR models to obtain uncertainties through subsampling of the training data\nand show how these uncertainties propagate to turnover frequency (TOF)\npredictions through the construction of an ensemble of microkinetic models.\nComparing the errors in model-based vs DFT-based TOF predictions, we show that\nthe WWL-GPR model reduces errors by almost an order of magnitude compared to\nscaling relations. This demonstrates the critical impact of accurate energy\npredictions on catalytic activity estimation. Finally, we apply our model to\nscreen new materials, identifying promising catalysts for RWGS. This work\nhighlights the power of combining advanced ML techniques with DFT and\nmicrokinetic modeling for screening catalysts for complex reactions like RWGS,\nproviding a robust framework for future catalyst design.", "AI": {"tldr": "A machine learning model (WWL-GPR) predicts transition state energies more accurately than traditional methods, reducing errors in catalytic activity estimation and aiding in catalyst screening.", "motivation": "Accurate transition state energy prediction is costly and challenging, limiting computational screening of materials and reactions.", "method": "Uses Gaussian process regression with the Wasserstein Weisfeiler-Lehman graph kernel (WWL-GPR) to predict TS energies, validated on RWGS reaction on SAA catalysts.", "result": "WWL-GPR reduces errors by almost an order of magnitude compared to scaling relations, improving TOF predictions and catalyst screening.", "conclusion": "Combining ML with DFT and microkinetic modeling offers a robust framework for catalyst design, demonstrated effectively for RWGS."}}
{"id": "2504.20946", "pdf": "https://arxiv.org/pdf/2504.20946", "abs": "https://arxiv.org/abs/2504.20946", "authors": ["Tyler McDonald", "Ali Emami"], "title": "Trace-of-Thought Prompting: Investigating Prompt-Based Knowledge Distillation Through Question Decomposition", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Knowledge distillation allows smaller neural networks to emulate the\nperformance of larger, teacher models with reduced computational demands.\nTraditional methods for Large Language Models (LLMs) often necessitate\nextensive fine-tuning, which limits their accessibility. To address this, we\nintroduce Trace-of-Thought Prompting, a novel framework designed to distill\ncritical reasoning capabilities from high-resource teacher models (over 8\nbillion parameters) to low-resource student models (up to 8 billion\nparameters). This approach leverages problem decomposition to enhance\ninterpretability and facilitate human-in-the-loop interventions. Empirical\nevaluations on the GSM8K and MATH datasets show that student models achieve\naccuracy gains of up to 113% on GSM8K and 21% on MATH, with significant\nimprovements particularly notable in smaller models like Llama 2 and Zephyr.\nOur results suggest a promising pathway for open-source, low-resource models to\neventually serve both as both students and teachers, potentially reducing our\nreliance on high-resource, proprietary models.", "AI": {"tldr": "Trace-of-Thought Prompting distills reasoning from large to small LLMs, improving accuracy without extensive fine-tuning.", "motivation": "To make high-performance LLMs more accessible by reducing reliance on large, proprietary models.", "method": "Uses problem decomposition and human-in-the-loop interventions to distill reasoning capabilities.", "result": "Student models achieved 113% accuracy gain on GSM8K and 21% on MATH, especially in smaller models.", "conclusion": "This framework offers a pathway for low-resource models to perform like high-resource ones, reducing dependency on proprietary models."}}
{"id": "2501.17982", "pdf": "https://arxiv.org/pdf/2501.17982", "abs": "https://arxiv.org/abs/2501.17982", "authors": ["Erick Fuentes", "Jared Strader", "Ethan Fahnestock", "Nicholas Roy"], "title": "Belief Roadmaps with Uncertain Landmark Evanescence", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We would like a robot to navigate to a goal location while minimizing state\nuncertainty. To aid the robot in this endeavor, maps provide a prior belief\nover the location of objects and regions of interest. To localize itself within\nthe map, a robot identifies mapped landmarks using its sensors. However, as the\ntime between map creation and robot deployment increases, portions of the map\ncan become stale, and landmarks, once believed to be permanent, may disappear.\nWe refer to the propensity of a landmark to disappear as landmark evanescence.\nReasoning about landmark evanescence during path planning, and the associated\nimpact on localization accuracy, requires analyzing the presence or absence of\neach landmark, leading to an exponential number of possible outcomes of a given\nmotion plan. To address this complexity, we develop BRULE, an extension of the\nBelief Roadmap. During planning, we replace the belief over future robot poses\nwith a Gaussian mixture which is able to capture the effects of landmark\nevanescence. Furthermore, we show that belief updates can be made efficient,\nand that maintaining a random subset of mixture components is sufficient to\nfind high quality solutions. We demonstrate performance in simulated and\nreal-world experiments. Software is available at https://bit.ly/BRULE.", "AI": {"tldr": "BRULE is a method for robot navigation that accounts for disappearing landmarks (evanescence) by using a Gaussian mixture in planning, ensuring efficient belief updates and high-quality paths.", "motivation": "Landmarks in maps can disappear over time, making robot localization uncertain. Traditional methods don't account for this evanescence, leading to inefficient planning.", "method": "BRULE extends the Belief Roadmap by replacing pose beliefs with a Gaussian mixture to model landmark evanescence. It maintains a subset of components for efficiency.", "result": "BRULE efficiently handles landmark evanescence, improving localization accuracy and path quality in simulations and real-world tests.", "conclusion": "BRULE effectively addresses the challenge of landmark evanescence in robot navigation, offering a scalable and practical solution."}}
{"id": "2409.16663", "pdf": "https://arxiv.org/pdf/2409.16663", "abs": "https://arxiv.org/abs/2409.16663", "authors": ["Alexander Popov", "Alperen Degirmenci", "David Wehr", "Shashank Hegde", "Ryan Oldja", "Alexey Kamenev", "Bertrand Douillard", "David Nist\u00e9r", "Urs Muller", "Ruchi Bhargava", "Stan Birchfield", "Nikolai Smolyanskiy"], "title": "Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY", "68T40 (Primary) 68T05, 68T45 (Secondary)", "I.2.9; I.2.6; I.2.10; I.6"], "comment": "8 pages, 6 figures, updated in March 2025, original published in\n  September 2024, for ICRA 2025 submission, for associated video file, see\n  https://youtu.be/7m3bXzlVQvU", "summary": "We propose the use of latent space generative world models to address the\ncovariate shift problem in autonomous driving. A world model is a neural\nnetwork capable of predicting an agent's next state given past states and\nactions. By leveraging a world model during training, the driving policy\neffectively mitigates covariate shift without requiring an excessive amount of\ntraining data. During end-to-end training, our policy learns how to recover\nfrom errors by aligning with states observed in human demonstrations, so that\nat runtime it can recover from perturbations outside the training distribution.\nAdditionally, we introduce a novel transformer-based perception encoder that\nemploys multi-view cross-attention and a learned scene query. We present\nqualitative and quantitative results, demonstrating significant improvements\nupon prior state of the art in closed-loop testing in the CARLA simulator, as\nwell as showing the ability to handle perturbations in both CARLA and NVIDIA's\nDRIVE Sim.", "AI": {"tldr": "The paper proposes a latent space generative world model to address covariate shift in autonomous driving, using a transformer-based perception encoder for improved performance.", "motivation": "To mitigate covariate shift in autonomous driving without excessive training data by leveraging a world model and aligning with human demonstrations.", "method": "Uses a neural network world model for state prediction and a transformer-based perception encoder with multi-view cross-attention and learned scene queries.", "result": "Demonstrates significant improvements in CARLA and NVIDIA DRIVE Sim, handling perturbations outside training distribution.", "conclusion": "The approach effectively addresses covariate shift and enhances autonomous driving performance in simulation environments."}}
{"id": "2505.00586", "pdf": "https://arxiv.org/pdf/2505.00586", "abs": "https://arxiv.org/abs/2505.00586", "authors": ["Jiarong Wei", "Niclas V\u00f6disch", "Anna Rehr", "Christian Feist", "Abhinav Valada"], "title": "ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory Prediction for Automated Parking using Diffusion Models", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Automated parking is a critical feature of Advanced Driver Assistance Systems\n(ADAS), where accurate trajectory prediction is essential to bridge perception\nand planning modules. Despite its significance, research in this domain remains\nrelatively limited, with most existing studies concentrating on single-modal\ntrajectory prediction of vehicles. In this work, we propose ParkDiffusion, a\nnovel approach that predicts the trajectories of both vehicles and pedestrians\nin automated parking scenarios. ParkDiffusion employs diffusion models to\ncapture the inherent uncertainty and multi-modality of future trajectories,\nincorporating several key innovations. First, we propose a dual map encoder\nthat processes soft semantic cues and hard geometric constraints using a\ntwo-step cross-attention mechanism. Second, we introduce an adaptive agent type\nembedding module, which dynamically conditions the prediction process on the\ndistinct characteristics of vehicles and pedestrians. Third, to ensure\nkinematic feasibility, our model outputs control signals that are subsequently\nused within a kinematic framework to generate physically feasible trajectories.\nWe evaluate ParkDiffusion on the Dragon Lake Parking (DLP) dataset and the\nIntersections Drone (inD) dataset. Our work establishes a new baseline for\nheterogeneous trajectory prediction in parking scenarios, outperforming\nexisting methods by a considerable margin.", "AI": {"tldr": "ParkDiffusion is a novel approach using diffusion models for predicting trajectories of vehicles and pedestrians in automated parking, outperforming existing methods.", "motivation": "Accurate trajectory prediction is crucial for ADAS, but research is limited, especially for multi-modal scenarios involving both vehicles and pedestrians.", "method": "ParkDiffusion employs diffusion models with a dual map encoder, adaptive agent type embedding, and kinematic feasibility constraints.", "result": "The model outperforms existing methods on the DLP and inD datasets, setting a new baseline for heterogeneous trajectory prediction.", "conclusion": "ParkDiffusion advances trajectory prediction in automated parking by addressing uncertainty and multi-modality, offering a robust solution for ADAS."}}
{"id": "2504.21012", "pdf": "https://arxiv.org/pdf/2504.21012", "abs": "https://arxiv.org/abs/2504.21012", "authors": ["Makoto Sato"], "title": "Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "What underlies intuitive human thinking? One approach to this question is to\ncompare the cognitive dynamics of humans and large language models (LLMs).\nHowever, such a comparison requires a method to quantitatively analyze AI\ncognitive behavior under controlled conditions. While anecdotal observations\nsuggest that certain prompts can dramatically change LLM behavior, these\nobservations have remained largely qualitative. Here, we propose a two-part\nframework to investigate this phenomenon: a Transition-Inducing Prompt (TIP)\nthat triggers a rapid shift in LLM responsiveness, and a Transition Quantifying\nPrompt (TQP) that evaluates this change using a separate LLM. Through\ncontrolled experiments, we examined how LLMs react to prompts embedding two\nsemantically distant concepts (e.g., mathematical aperiodicity and traditional\ncrafts)-either fused together or presented separately-by changing their\nlinguistic quality and affective tone. Whereas humans tend to experience\nheightened engagement when such concepts are meaningfully blended producing a\nnovel concept-a form of conceptual fusion-current LLMs showed no significant\ndifference in responsiveness between semantically fused and non-fused prompts.\nThis suggests that LLMs may not yet replicate the conceptual integration\nprocesses seen in human intuition. Our method enables fine-grained,\nreproducible measurement of cognitive responsiveness, and may help illuminate\nkey differences in how intuition and conceptual leaps emerge in artificial\nversus human minds.", "AI": {"tldr": "The paper proposes a framework to compare human and LLM cognitive dynamics, finding LLMs lack human-like conceptual fusion.", "motivation": "To understand intuitive human thinking by comparing cognitive behaviors of humans and LLMs under controlled conditions.", "method": "A two-part framework: Transition-Inducing Prompt (TIP) and Transition Quantifying Prompt (TQP) to measure LLM responsiveness changes.", "result": "LLMs showed no significant difference in responsiveness between semantically fused and non-fused prompts, unlike humans.", "conclusion": "LLMs may not replicate human conceptual integration, highlighting a key difference in artificial vs. human intuition."}}
{"id": "2501.18768", "pdf": "https://arxiv.org/pdf/2501.18768", "abs": "https://arxiv.org/abs/2501.18768", "authors": ["Michael S. Yao", "James C. Gee", "Osbert Bastani"], "title": "Diversity By Design: Leveraging Distribution Matching for Offline Model-Based Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "52 pages, Accepted to ICML 2025", "summary": "The goal of offline model-based optimization (MBO) is to propose new designs\nthat maximize a reward function given only an offline dataset. However, an\nimportant desiderata is to also propose a diverse set of final candidates that\ncapture many optimal and near-optimal design configurations. We propose\nDiversity in Adversarial Model-based Optimization (DynAMO) as a novel method to\nintroduce design diversity as an explicit objective into any MBO problem. Our\nkey insight is to formulate diversity as a distribution matching problem where\nthe distribution of generated designs captures the inherent diversity contained\nwithin the offline dataset. Extensive experiments spanning multiple scientific\ndomains show that DynAMO can be used with common optimization methods to\nsignificantly improve the diversity of proposed designs while still discovering\nhigh-quality candidates.", "AI": {"tldr": "DynAMO introduces diversity as an explicit objective in offline model-based optimization (MBO) by matching the distribution of generated designs to the dataset's inherent diversity, improving both diversity and quality of designs.", "motivation": "To address the need for diverse and high-quality design proposals in offline MBO, where traditional methods may lack diversity.", "method": "Formulates diversity as a distribution matching problem, integrating it into MBO. Uses DynAMO to align generated designs with the dataset's diversity.", "result": "DynAMO significantly improves design diversity while maintaining high-quality candidates across multiple domains.", "conclusion": "DynAMO effectively balances diversity and quality in offline MBO, offering a practical solution for diverse design generation."}}
{"id": "2411.12286", "pdf": "https://arxiv.org/pdf/2411.12286", "abs": "https://arxiv.org/abs/2411.12286", "authors": ["Teli Ma", "Zifan Wang", "Jiaming Zhou", "Mengmeng Wang", "Junwei Liang"], "title": "GLOVER: Generalizable Open-Vocabulary Affordance Reasoning for Task-Oriented Grasping", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Inferring affordable (i.e., graspable) parts of arbitrary objects based on\nhuman specifications is essential for robots advancing toward open-vocabulary\nmanipulation. Current grasp planners, however, are hindered by limited\nvision-language comprehension and time-consuming 3D radiance modeling,\nrestricting real-time, open-vocabulary interactions with objects. To address\nthese limitations, we propose GLOVER, a unified Generalizable Open-Vocabulary\nAffordance Reasoning framework, which fine-tunes the Large Language Models\n(LLMs) to predict the visual affordance of graspable object parts within RGB\nfeature space. We compile a dataset of over 10,000 images from human-object\ninteractions, annotated with unified visual and linguistic affordance labels,\nto enable multi-modal fine-tuning. GLOVER inherits world knowledge and\ncommon-sense reasoning from LLMs, facilitating more fine-grained object\nunderstanding and sophisticated tool-use reasoning. To enable effective\nreal-world deployment, we present Affordance-Aware Grasping Estimation (AGE), a\nnon-parametric grasp planner that aligns the gripper pose with a superquadric\nsurface derived from affordance data. In evaluations across 30 table-top\nreal-world scenes, GLOVER achieves success rates of 86.0% in part\nidentification and 76.3% in grasping, with speeds approximately 29 times faster\nin affordance reasoning and 40 times faster in grasping pose estimation than\nthe previous state-of-the-art. We also validate the generalization across\nembodiments, showing effectiveness in humanoid robots with dexterous hands.", "AI": {"tldr": "GLOVER is a framework using LLMs for real-time, open-vocabulary affordance reasoning, improving grasp planning with high success rates and speed.", "motivation": "Current grasp planners lack vision-language comprehension and real-time 3D modeling, limiting open-vocabulary object manipulation.", "method": "GLOVER fine-tunes LLMs for affordance prediction in RGB space, uses a dataset of human-object interactions, and integrates AGE for grasp planning.", "result": "Achieves 86.0% part identification and 76.3% grasping success, with 29x faster reasoning and 40x faster pose estimation than prior work.", "conclusion": "GLOVER enables efficient, generalizable affordance reasoning and grasping, validated in real-world and humanoid robot scenarios."}}
{"id": "2505.00625", "pdf": "https://arxiv.org/pdf/2505.00625", "abs": "https://arxiv.org/abs/2505.00625", "authors": ["Liu Junchi", "Tang Ying", "Tretiak Sergei", "Duan Wenhui", "Zhou Liujiang"], "title": "SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Recent advances in machine learning have demonstrated an enormous utility of\ndeep learning approaches, particularly Graph Neural Networks (GNNs) for\nmaterials science. These methods have emerged as powerful tools for\nhigh-throughput prediction of material properties, offering a compelling\nenhancement and alternative to traditional first-principles calculations. While\nthe community has predominantly focused on developing increasingly complex and\nuniversal models to enhance predictive accuracy, such approaches often lack\nphysical interpretability and insights into materials behavior. Here, we\nintroduce a novel computational paradigm, Self-Adaptable Graph Attention\nNetworks integrated with Symbolic Regression (SA-GAT-SR), that synergistically\ncombines the predictive capability of GNNs with the interpretative power of\nsymbolic regression. Our framework employs a self-adaptable encoding algorithm\nthat automatically identifies and adjust attention weights so as to screen\ncritical features from an expansive 180-dimensional feature space while\nmaintaining O(n) computational scaling. The integrated SR module subsequently\ndistills these features into compact analytical expressions that explicitly\nreveal quantum-mechanically meaningful relationships, achieving 23 times\nacceleration compared to conventional SR implementations that heavily rely on\nfirst principle calculations-derived features as input. This work suggests a\nnew framework in computational materials science, bridging the gap between\npredictive accuracy and physical interpretability, offering valuable physical\ninsights into material behavior.", "AI": {"tldr": "A novel framework, SA-GAT-SR, combines GNNs and symbolic regression for materials science, enhancing predictive accuracy and interpretability.", "motivation": "Address the lack of interpretability in complex GNN models for material property prediction.", "method": "Integrates self-adaptable graph attention networks with symbolic regression to identify critical features and derive analytical expressions.", "result": "Achieves 23x acceleration over conventional methods and provides quantum-mechanically meaningful insights.", "conclusion": "Bridges the gap between accuracy and interpretability, offering a new paradigm in computational materials science."}}
{"id": "2504.21800", "pdf": "https://arxiv.org/pdf/2504.21800", "abs": "https://arxiv.org/abs/2504.21800", "authors": ["Suhas BN", "Dominik Mattioli", "Saeed Abdullah", "Rosa I. Arriaga", "Chris W. Wiese", "Andrew M. Sherrill"], "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "68T50", "I.2.7; H.3.1"], "comment": "11 pages, 5 tables", "summary": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. Synthetic therapy dialogues closely match structural\nfeatures of real-world conversations (e.g., speaker switch ratio: 0.98 vs.\n0.99); however, they may not adequately reflect key fidelity markers (e.g.,\ndistress monitoring). We highlight gaps in existing evaluation frameworks and\nadvocate for fidelity-aware metrics that go beyond surface fluency to uncover\nclinically significant failures. Our findings clarify where synthetic data can\neffectively complement real-world datasets -- and where critical limitations\nremain.", "AI": {"tldr": "Synthetic PE therapy dialogues for PTSD show promise for scalability and privacy but may miss key clinical fidelity markers.", "motivation": "Addressing privacy concerns, data scarcity, and high annotation costs in healthcare by exploring synthetic data for clinical model training.", "method": "Comparison of real and synthetic dialogues using linguistic, structural, and PE-specific metrics, including semantic modeling.", "result": "Synthetic data matches structural features but struggles with clinical fidelity (e.g., distress monitoring).", "conclusion": "Synthetic data can complement real-world datasets but requires fidelity-aware metrics for clinically significant evaluation."}}
{"id": "2502.00040", "pdf": "https://arxiv.org/pdf/2502.00040", "abs": "https://arxiv.org/abs/2502.00040", "authors": ["Thomas Lautenbacher", "Ali Rajaei", "Davide Barbieri", "Jan Viebahn", "Jochen L. Cremer"], "title": "Multi-Objective Reinforcement Learning for Power Grid Topology Control", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Transmission grid congestion increases as the electrification of various\nsectors requires transmitting more power. Topology control, through substation\nreconfiguration, can reduce congestion but its potential remains\nunder-exploited in operations. A challenge is modeling the topology control\nproblem to align well with the objectives and constraints of operators.\nAddressing this challenge, this paper investigates the application of\nmulti-objective reinforcement learning (MORL) to integrate multiple conflicting\nobjectives for power grid topology control. We develop a MORL approach using\ndeep optimistic linear support (DOL) and multi-objective proximal policy\noptimization (MOPPO) to generate a set of Pareto-optimal policies that balance\nobjectives such as minimizing line loading, topological deviation, and\nswitching frequency. Initial case studies show that the MORL approach can\nprovide valuable insights into objective trade-offs and improve Pareto front\napproximation compared to a random search baseline. The generated\nmulti-objective RL policies are 30% more successful in preventing grid failure\nunder contingencies and 20% more effective when training budget is reduced -\ncompared to the common single objective RL policy.", "AI": {"tldr": "The paper explores multi-objective reinforcement learning (MORL) for power grid topology control, balancing objectives like line loading and switching frequency, showing improved performance over single-objective methods.", "motivation": "Addressing under-exploited potential of topology control in grid operations by aligning it with operator objectives and constraints.", "method": "Uses deep optimistic linear support (DOL) and multi-objective proximal policy optimization (MOPPO) to generate Pareto-optimal policies.", "result": "MORL policies are 30% better at preventing grid failures and 20% more effective with reduced training budget compared to single-objective RL.", "conclusion": "MORL provides valuable trade-off insights and superior performance for grid topology control."}}
{"id": "2411.14412", "pdf": "https://arxiv.org/pdf/2411.14412", "abs": "https://arxiv.org/abs/2411.14412", "authors": ["Satwik Kundu", "Swaroop Ghosh"], "title": "Adversarial Data Poisoning Attacks on Quantum Machine Learning in the NISQ Era", "categories": ["quant-ph", "cs.CR", "cs.CV"], "comment": null, "summary": "With the growing interest in Quantum Machine Learning (QML) and the\nincreasing availability of quantum computers through cloud providers,\naddressing the potential security risks associated with QML has become an\nurgent priority. One key concern in the QML domain is the threat of data\npoisoning attacks in the current quantum cloud setting. Adversarial access to\ntraining data could severely compromise the integrity and availability of QML\nmodels. Classical data poisoning techniques require significant knowledge and\ntraining to generate poisoned data, and lack noise resilience, making them\nineffective for QML models in the Noisy Intermediate Scale Quantum (NISQ) era.\nIn this work, we first propose a simple yet effective technique to measure\nintra-class encoder state similarity (ESS) by analyzing the outputs of encoding\ncircuits. Leveraging this approach, we introduce a \\underline{Qu}antum\n\\underline{I}ndiscriminate \\underline{D}ata Poisoning attack, QUID. Through\nextensive experiments conducted in both noiseless and noisy environments (e.g.,\nIBM\\_Brisbane's noise), across various architectures and datasets, QUID\nachieves up to $92\\%$ accuracy degradation in model performance compared to\nbaseline models and up to $75\\%$ accuracy degradation compared to random\nlabel-flipping. We also tested QUID against state-of-the-art classical\ndefenses, with accuracy degradation still exceeding $50\\%$, demonstrating its\neffectiveness. This work represents the first attempt to reevaluate data\npoisoning attacks in the context of QML.", "AI": {"tldr": "The paper introduces QUID, a quantum data poisoning attack, showing its effectiveness in degrading QML model performance, even against classical defenses.", "motivation": "Addressing security risks in QML, particularly data poisoning attacks, due to the rise of quantum cloud computing.", "method": "Proposes measuring intra-class encoder state similarity (ESS) and introduces QUID, a quantum data poisoning attack, tested in noiseless and noisy environments.", "result": "QUID achieves up to 92% accuracy degradation in QML models and outperforms random label-flipping and classical defenses.", "conclusion": "This work highlights the vulnerability of QML to data poisoning and the need for robust defenses."}}
{"id": "2505.00631", "pdf": "https://arxiv.org/pdf/2505.00631", "abs": "https://arxiv.org/abs/2505.00631", "authors": ["Yi Yang", "Yinghui Huang", "Xiangyu Chang"], "title": "Bayes-Optimal Fair Classification with Multiple Sensitive Features", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Existing theoretical work on Bayes-optimal fair classifiers usually considers\na single (binary) sensitive feature. In practice, individuals are often defined\nby multiple sensitive features. In this paper, we characterize the\nBayes-optimal fair classifier for multiple sensitive features under general\napproximate fairness measures, including mean difference and mean ratio. We\nshow that these approximate measures for existing group fairness notions,\nincluding Demographic Parity, Equal Opportunity, Predictive Equality, and\nAccuracy Parity, are linear transformations of selection rates for specific\ngroups defined by both labels and sensitive features. We then characterize that\nBayes-optimal fair classifiers for multiple sensitive features become\ninstance-dependent thresholding rules that rely on a weighted sum of these\ngroup membership probabilities. Our framework applies to both attribute-aware\nand attribute-blind settings and can accommodate composite fairness notions\nlike Equalized Odds. Building on this, we propose two practical algorithms for\nBayes-optimal fair classification via in-processing and post-processing. We\nshow empirically that our methods compare favorably to existing methods.", "AI": {"tldr": "The paper extends Bayes-optimal fair classifiers to handle multiple sensitive features, proposing a framework for approximate fairness measures and practical algorithms.", "motivation": "Existing work focuses on binary sensitive features, but real-world scenarios involve multiple sensitive attributes, necessitating a broader framework.", "method": "The paper characterizes Bayes-optimal fair classifiers for multiple sensitive features using linear transformations of group selection rates and introduces instance-dependent thresholding rules.", "result": "The proposed framework accommodates various fairness notions and outperforms existing methods empirically.", "conclusion": "The study advances fair classification by addressing multiple sensitive features and offers practical algorithms for implementation."}}
{"id": "2411.02790", "pdf": "https://arxiv.org/pdf/2411.02790", "abs": "https://arxiv.org/abs/2411.02790", "authors": ["Sheshera Mysore", "Garima Dhanania", "Kishor Patil", "Surya Kallumadi", "Andrew McCallum", "Hamed Zamani"], "title": "Bridging Personalization and Control in Scientific Personalized Search", "categories": ["cs.IR", "cs.CL"], "comment": "SIGIR 2025 paper", "summary": "Personalized search is a problem where models benefit from learning user\npreferences from per-user historical interaction data. The inferred preferences\nenable personalized ranking models to improve the relevance of documents for\nusers. However, personalization is also seen as opaque in its use of historical\ninteractions and is not amenable to users' control. Further, personalization\nlimits the diversity of information users are exposed to. While search results\nmay be automatically diversified this does little to address the lack of\ncontrol over personalization. In response, we introduce a model for\npersonalized search that enables users to control personalized rankings\nproactively. Our model, CtrlCE, is a novel cross-encoder model augmented with\nan editable memory built from users' historical interactions. The editable\nmemory allows cross-encoders to be personalized efficiently and enables users\nto control personalized ranking. Next, because all queries do not require\npersonalization, we introduce a calibrated mixing model which determines when\npersonalization is necessary. This enables users to control personalization via\ntheir editable memory only when necessary. To thoroughly evaluate CtrlCE, we\ndemonstrate its empirical performance in four domains of science, its ability\nto selectively request user control in a calibration evaluation of the mixing\nmodel, and the control provided by its editable memory in a user study.", "AI": {"tldr": "CtrlCE is a personalized search model with editable memory for user control and a mixing model to determine when personalization is needed.", "motivation": "Address opacity and lack of user control in personalized search, while mitigating limited diversity.", "method": "Introduces CtrlCE, a cross-encoder with editable memory and a calibrated mixing model for selective personalization.", "result": "Empirical performance in four science domains, effective calibration, and user control demonstrated.", "conclusion": "CtrlCE successfully balances personalization, control, and diversity in search results."}}
{"id": "2502.10689", "pdf": "https://arxiv.org/pdf/2502.10689", "abs": "https://arxiv.org/abs/2502.10689", "authors": ["Leisheng Yu", "Yanxiao Cai", "Minxing Zhang", "Xia Hu"], "title": "Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The burgeoning volume of electronic health records (EHRs) has enabled deep\nlearning models to excel in predictive healthcare. However, for high-stakes\napplications such as diagnosis prediction, model interpretability remains\nparamount. Existing deep learning diagnosis prediction models with intrinsic\ninterpretability often assign attention weights to every past diagnosis or\nhospital visit, providing explanations lacking flexibility and succinctness. In\nthis paper, we introduce SHy, a self-explaining hypergraph neural network\nmodel, designed to offer personalized, concise and faithful explanations that\nallow for interventions from clinical experts. By modeling each patient as a\nunique hypergraph and employing a message-passing mechanism, SHy captures\nhigher-order disease interactions and extracts distinct temporal phenotypes as\npersonalized explanations. It also addresses the incompleteness of the EHR data\nby accounting for essential false negatives in the original diagnosis record. A\nqualitative case study and extensive quantitative evaluations on two real-world\nEHR datasets demonstrate the superior predictive performance and\ninterpretability of SHy over existing state-of-the-art models.", "AI": {"tldr": "SHy is a self-explaining hypergraph neural network model for EHR-based diagnosis prediction, offering concise, personalized explanations and addressing data incompleteness.", "motivation": "Existing deep learning models for diagnosis prediction lack flexible and succinct interpretability, which is crucial for high-stakes healthcare applications.", "method": "SHy models patients as hypergraphs, uses message-passing to capture disease interactions, and extracts temporal phenotypes for explanations while accounting for EHR data incompleteness.", "result": "SHy outperforms state-of-the-art models in predictive performance and interpretability, validated on two real-world EHR datasets.", "conclusion": "SHy provides a scalable, interpretable solution for diagnosis prediction, enhancing trust and utility in clinical settings."}}
{"id": "2502.18137", "pdf": "https://arxiv.org/pdf/2502.18137", "abs": "https://arxiv.org/abs/2502.18137", "authors": ["Jintao Zhang", "Chendong Xiang", "Haofeng Huang", "Jia Wei", "Haocheng Xi", "Jun Zhu", "Jianfei Chen"], "title": "SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.PF"], "comment": null, "summary": "An efficient attention implementation is essential for large models due to\nits quadratic time complexity. Fortunately, attention commonly exhibits\nsparsity, i.e., many values in the attention map are near zero, allowing for\nthe omission of corresponding computations. Many studies have utilized the\nsparse pattern to accelerate attention. However, most existing works focus on\noptimizing attention within specific models by exploiting certain sparse\npatterns of the attention map. A universal sparse attention that guarantees\nboth the speedup and end-to-end performance of diverse models remains elusive.\nIn this paper, we propose SpargeAttn, a universal sparse and quantized\nattention for any model. Our method uses a two-stage online filter: in the\nfirst stage, we rapidly and accurately predict the attention map, enabling the\nskip of some matrix multiplications in attention. In the second stage, we\ndesign an online softmax-aware filter that incurs no extra overhead and further\nskips some matrix multiplications. Experiments show that our method\nsignificantly accelerates diverse models, including language, image, and video\ngeneration, without sacrificing end-to-end metrics. The codes are available at\nhttps://github.com/thu-ml/SpargeAttn.", "AI": {"tldr": "SpargeAttn is a universal sparse and quantized attention method that accelerates diverse models without sacrificing performance, using a two-stage online filter to skip unnecessary computations.", "motivation": "Existing sparse attention methods are model-specific, lacking a universal solution that ensures both speedup and performance across diverse models.", "method": "SpargeAttn employs a two-stage online filter: first predicting the attention map to skip computations, then using a softmax-aware filter for further skipping.", "result": "The method significantly accelerates models in language, image, and video generation without degrading end-to-end metrics.", "conclusion": "SpargeAttn provides a universal, efficient solution for sparse attention, applicable to diverse models while maintaining performance."}}
{"id": "2501.18265", "pdf": "https://arxiv.org/pdf/2501.18265", "abs": "https://arxiv.org/abs/2501.18265", "authors": ["Kevin Roitero", "Dustin Wright", "Michael Soprano", "Isabelle Augenstein", "Stefano Mizzaro"], "title": "Efficiency and Effectiveness of LLM-Based Summarization of Evidence in Crowdsourced Fact-Checking", "categories": ["cs.IR", "cs.CL", "cs.HC"], "comment": "19 pages; 7 figures; 5 tables", "summary": "Evaluating the truthfulness of online content is critical for combating\nmisinformation. This study examines the efficiency and effectiveness of\ncrowdsourced truthfulness assessments through a comparative analysis of two\napproaches: one involving full-length webpages as evidence for each claim, and\nanother using summaries for each evidence document generated with a large\nlanguage model. Using an A/B testing setting, we engage a diverse pool of\nparticipants tasked with evaluating the truthfulness of statements under these\nconditions. Our analysis explores both the quality of assessments and the\nbehavioral patterns of participants. The results reveal that relying on\nsummarized evidence offers comparable accuracy and error metrics to the\nStandard modality while significantly improving efficiency. Workers in the\nSummary setting complete a significantly higher number of assessments, reducing\ntask duration and costs. Additionally, the Summary modality maximizes internal\nagreement and maintains consistent reliance on and perceived usefulness of\nevidence, demonstrating its potential to streamline large-scale truthfulness\nevaluations.", "AI": {"tldr": "Summarized evidence in crowdsourced truthfulness assessments matches full-length evidence in accuracy while boosting efficiency and reducing costs.", "motivation": "To combat misinformation by evaluating the efficiency and effectiveness of crowdsourced truthfulness assessments using summarized versus full-length evidence.", "method": "A/B testing with diverse participants comparing truthfulness evaluations using full-length webpages versus summaries generated by a large language model.", "result": "Summarized evidence provides comparable accuracy, higher efficiency, reduced task duration, and cost savings while maintaining participant agreement and evidence usefulness.", "conclusion": "Summarized evidence is a viable and efficient alternative for large-scale truthfulness evaluations, balancing accuracy and productivity."}}
{"id": "2502.11141", "pdf": "https://arxiv.org/pdf/2502.11141", "abs": "https://arxiv.org/abs/2502.11141", "authors": ["Lukas Kuhn", "Sari Saba-Sadiya", "Gemma Roig"], "title": "Cognitive Neural Architecture Search Reveals Hierarchical Entailment", "categories": ["cs.NE", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Recent research has suggested that the brain is more shallow than previously\nthought, challenging the traditionally assumed hierarchical structure of the\nventral visual pathway. Here, we demonstrate that optimizing convolutional\nnetwork architectures for brain-alignment via evolutionary neural architecture\nsearch results in models with clear representational hierarchies. Despite\nhaving random weights, the identified models achieve brain-alignment scores\nsurpassing even those of pretrained classification models - as measured by both\nregression and representational similarity analysis. Furthermore, through\ntraditional supervised training, architectures optimized for alignment with\nlate ventral regions become competitive classification models. These findings\nsuggest that hierarchical structure is a fundamental mechanism of primate\nvisual processing. Finally, this work demonstrates the potential of neural\narchitecture search as a framework for computational cognitive neuroscience\nresearch that could reduce the field's reliance on manually designed\nconvolutional networks.", "AI": {"tldr": "Optimizing convolutional networks for brain-alignment reveals hierarchical structures, surpassing pretrained models in brain-alignment and classification performance.", "motivation": "Challenge the assumption of shallow brain structure and explore hierarchical mechanisms in primate visual processing.", "method": "Evolutionary neural architecture search to optimize brain-alignment, followed by supervised training.", "result": "Identified models with random weights outperform pretrained models in brain-alignment; architectures optimized for late ventral regions excel in classification.", "conclusion": "Hierarchical structure is fundamental in visual processing, and neural architecture search can advance cognitive neuroscience research."}}
{"id": "2503.21510", "pdf": "https://arxiv.org/pdf/2503.21510", "abs": "https://arxiv.org/abs/2503.21510", "authors": ["Samuel Bilson", "Anna Pustogvar"], "title": "Uncertainty-aware Bayesian machine learning modelling of land cover classification", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "31 pages, 10 figures", "summary": "Land cover classification involves the production of land cover maps, which\ndetermine the type of land through remote sensing imagery. Over recent years,\nsuch classification is being performed by machine learning classification\nmodels, which can give highly accurate predictions on land cover per pixel\nusing large quantities of input training data. However, such models do not\ncurrently take account of input measurement uncertainty, which is vital for\ntraceability in metrology. In this work we propose a Bayesian classification\nframework using generative modelling to take account of input measurement\nuncertainty. We take the specific case of Bayesian quadratic discriminant\nanalysis, and apply it to land cover datasets from Copernicus Sentinel-2 in\n2020 and 2021. We benchmark the performance of the model against more popular\nclassification models used in land cover maps such as random forests and neural\nnetworks. We find that such Bayesian models are more trustworthy, in the sense\nthat they are more interpretable, explicitly model the input measurement\nuncertainty, and maintain predictive performance of class probability outputs\nacross datasets of different years and sizes, whilst also being computationally\nefficient.", "AI": {"tldr": "A Bayesian classification framework using generative modeling is proposed to address input measurement uncertainty in land cover classification, outperforming traditional models like random forests and neural networks in trustworthiness and interpretability.", "motivation": "Current machine learning models for land cover classification lack consideration of input measurement uncertainty, which is crucial for metrology traceability.", "method": "The study employs Bayesian quadratic discriminant analysis, applied to Copernicus Sentinel-2 datasets from 2020 and 2021, and benchmarks it against random forests and neural networks.", "result": "Bayesian models are more trustworthy, interpretable, and computationally efficient while maintaining predictive performance across datasets.", "conclusion": "Bayesian classification frameworks effectively address measurement uncertainty and offer reliable, interpretable results for land cover classification."}}
{"id": "2211.09619", "pdf": "https://arxiv.org/pdf/2211.09619", "abs": "https://arxiv.org/abs/2211.09619", "authors": ["Elad Hazan", "Karan Singh"], "title": "Introduction to Online Control", "categories": ["cs.LG", "cs.RO", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "comment": "Draft; comments/suggestions welcome at\n  nonstochastic.control@gmail.com", "summary": "This text presents an introduction to an emerging paradigm in control of\ndynamical systems and differentiable reinforcement learning called online\nnonstochastic control. The new approach applies techniques from online convex\noptimization and convex relaxations to obtain new methods with provable\nguarantees for classical settings in optimal and robust control.\n  The primary distinction between online nonstochastic control and other\nframeworks is the objective. In optimal control, robust control, and other\ncontrol methodologies that assume stochastic noise, the goal is to perform\ncomparably to an offline optimal strategy. In online nonstochastic control,\nboth the cost functions as well as the perturbations from the assumed dynamical\nmodel are chosen by an adversary. Thus the optimal policy is not defined a\npriori. Rather, the target is to attain low regret against the best policy in\nhindsight from a benchmark class of policies.\n  This objective suggests the use of the decision making framework of online\nconvex optimization as an algorithmic methodology. The resulting methods are\nbased on iterative mathematical optimization algorithms, and are accompanied by\nfinite-time regret and computational complexity guarantees.", "AI": {"tldr": "The paper introduces online nonstochastic control, a new paradigm combining online convex optimization with control theory for dynamical systems, focusing on adversarial cost functions and perturbations.", "motivation": "Traditional control methods assume stochastic noise and aim to match offline optimal strategies. Online nonstochastic control addresses adversarial scenarios where costs and perturbations are chosen adversarially, requiring a new approach.", "method": "The approach leverages online convex optimization and convex relaxations to develop iterative optimization algorithms with provable guarantees.", "result": "The methods achieve finite-time regret and computational complexity guarantees, performing well against adversarial conditions.", "conclusion": "Online nonstochastic control offers a robust framework for adversarial settings, bridging control theory and online optimization with practical guarantees."}}
{"id": "2504.05520", "pdf": "https://arxiv.org/pdf/2504.05520", "abs": "https://arxiv.org/abs/2504.05520", "authors": ["Taiwei Shi", "Yiyang Wu", "Linxin Song", "Tianyi Zhou", "Jieyu Zhao"], "title": "Efficient Reinforcement Finetuning via Adaptive Curriculum Learning", "categories": ["cs.LG", "cs.CL"], "comment": "25 pages, 7 figures, 6 tables", "summary": "Reinforcement finetuning (RFT) has shown great potential for enhancing the\nmathematical reasoning capabilities of large language models (LLMs), but it is\noften sample- and compute-inefficient, requiring extensive training. In this\nwork, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuning), a\nmethod that significantly improves both the efficiency and final accuracy of\nRFT through adaptive curriculum learning. AdaRFT dynamically adjusts the\ndifficulty of training problems based on the model's recent reward signals,\nensuring that the model consistently trains on tasks that are challenging but\nsolvable. This adaptive sampling strategy accelerates learning by maintaining\nan optimal difficulty range, avoiding wasted computation on problems that are\ntoo easy or too hard. AdaRFT requires only a lightweight extension to standard\nRFT algorithms like Proximal Policy Optimization (PPO), without modifying the\nreward function or model architecture. Experiments on competition-level math\ndatasets-including AMC, AIME, and IMO-style problems-demonstrate that AdaRFT\nsignificantly improves both training efficiency and reasoning performance. We\nevaluate AdaRFT across multiple data distributions and model sizes, showing\nthat it reduces training time by up to 2x and improves accuracy by a\nconsiderable margin, offering a more scalable and effective RFT framework.", "AI": {"tldr": "AdaRFT improves reinforcement finetuning (RFT) efficiency and accuracy for LLMs using adaptive curriculum learning, reducing training time by 2x and boosting performance.", "motivation": "RFT is often inefficient and requires extensive training. AdaRFT aims to enhance efficiency and accuracy by dynamically adjusting problem difficulty.", "method": "AdaRFT uses adaptive curriculum learning to adjust training problem difficulty based on reward signals, optimizing difficulty range without modifying RFT algorithms.", "result": "Experiments show AdaRFT reduces training time by up to 2x and improves accuracy on math datasets like AMC, AIME, and IMO-style problems.", "conclusion": "AdaRFT offers a scalable and effective RFT framework, enhancing both training efficiency and reasoning performance."}}
{"id": "2502.13406", "pdf": "https://arxiv.org/pdf/2502.13406", "abs": "https://arxiv.org/abs/2502.13406", "authors": ["Vince Kurtz", "Joel W. Burdick"], "title": "Generative Predictive Control: Flow Matching Policies for Dynamic and Difficult-to-Demonstrate Tasks", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Generative control policies have recently unlocked major progress in\nrobotics. These methods produce action sequences via diffusion or flow\nmatching, with training data provided by demonstrations. But existing methods\ncome with two key limitations: they require expert demonstrations, which can be\ndifficult to obtain, and they are limited to relatively slow, quasi-static\ntasks. In this paper, we leverage a tight connection between sampling-based\npredictive control and generative modeling to address each of these issues. In\nparticular, we introduce generative predictive control, a supervised learning\nframework for tasks with fast dynamics that are easy to simulate but difficult\nto demonstrate. We then show how trained flow-matching policies can be\nwarm-started at inference time, maintaining temporal consistency and enabling\nhigh-frequency feedback. We believe that generative predictive control offers a\ncomplementary approach to existing behavior cloning methods, and hope that it\npaves the way toward generalist policies that extend beyond quasi-static\ndemonstration-oriented tasks.", "AI": {"tldr": "The paper introduces generative predictive control, a framework for fast-dynamic tasks using simulation data, overcoming limitations of expert demonstrations and slow tasks in existing methods.", "motivation": "Existing generative control policies rely on expert demonstrations and are limited to slow tasks, which are hard to obtain and restrictive.", "method": "The paper proposes generative predictive control, leveraging sampling-based predictive control and generative modeling, with flow-matching policies warm-started for inference.", "result": "The method enables high-frequency feedback and temporal consistency, suitable for tasks difficult to demonstrate but easy to simulate.", "conclusion": "Generative predictive control complements behavior cloning and could lead to generalist policies beyond quasi-static tasks."}}
{"id": "2504.04318", "pdf": "https://arxiv.org/pdf/2504.04318", "abs": "https://arxiv.org/abs/2504.04318", "authors": ["Mehmet Can Yavuz", "Berrin Yanikoglu"], "title": "Variational Self-Supervised Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present Variational Self-Supervised Learning (VSSL), a novel framework\nthat combines variational inference with self-supervised learning to enable\nefficient, decoder-free representation learning. Unlike traditional VAEs that\nrely on input reconstruction via a decoder, VSSL symmetrically couples two\nencoders with Gaussian outputs. A momentum-updated teacher network defines a\ndynamic, data-dependent prior, while the student encoder produces an\napproximate posterior from augmented views. The reconstruction term in the ELBO\nis replaced with a cross-view denoising objective, preserving the analytical\ntractability of Gaussian KL divergence. We further introduce cosine-based\nformulations of KL and log-likelihood terms to enhance semantic alignment in\nhigh-dimensional latent spaces. Experiments on CIFAR-10, CIFAR-100, and\nImageNet-100 show that VSSL achieves competitive or superior performance to\nleading self-supervised methods, including BYOL and MoCo V3. VSSL offers a\nscalable, probabilistically grounded approach to learning transferable\nrepresentations without generative reconstruction, bridging the gap between\nvariational modeling and modern self-supervised techniques.", "AI": {"tldr": "VSSL combines variational inference and self-supervised learning for efficient, decoder-free representation learning, outperforming methods like BYOL and MoCo V3.", "motivation": "Bridging the gap between variational modeling and modern self-supervised techniques by eliminating the need for generative reconstruction.", "method": "Uses two symmetrically coupled encoders with Gaussian outputs, a teacher-student setup, and replaces reconstruction with cross-view denoising.", "result": "Achieves competitive or superior performance on CIFAR-10, CIFAR-100, and ImageNet-100.", "conclusion": "VSSL provides a scalable, probabilistically grounded approach for learning transferable representations."}}
{"id": "2301.13565", "pdf": "https://arxiv.org/pdf/2301.13565", "abs": "https://arxiv.org/abs/2301.13565", "authors": ["Shixiong Wang", "Haowei Wang", "Xinke Li", "Jean Honorio"], "title": "Learning Against Distributional Uncertainty: On the Trade-off Between Robustness and Specificity", "categories": ["cs.LG", "stat.ML", "62F35, 62G35, 62C12"], "comment": "Supplementary materials (i.e., the proofs to Theorems 1, 2, 3, and 5)\n  are appended at the end of the main body of the paper", "summary": "Trustworthy machine learning aims at combating distributional uncertainties\nin training data distributions compared to population distributions. Typical\ntreatment frameworks include the Bayesian approach, (min-max) distributionally\nrobust optimization (DRO), and regularization. However, three issues have to be\nraised: 1) the prior distribution in the Bayesian method and the regularizer in\nthe regularization method are difficult to specify; 2) the DRO method tends to\nbe overly conservative; 3) all the three methods are biased estimators of the\ntrue optimal cost. This paper studies a new framework that unifies the three\napproaches and addresses the three challenges above. The asymptotic properties\n(e.g., consistencies and asymptotic normalities), non-asymptotic properties\n(e.g., generalization bounds and unbiasedness), and solution methods of the\nproposed model are studied. The new model reveals the trade-off between the\nrobustness to the unseen data and the specificity to the training data.\nExperiments on various real-world tasks validate the superiority of the\nproposed learning framework.", "AI": {"tldr": "A new framework unifies Bayesian, DRO, and regularization methods to address their limitations, offering robust and specific solutions with validated superiority in real-world tasks.", "motivation": "To combat distributional uncertainties in training data and address the limitations of existing methods (Bayesian, DRO, regularization) such as prior specification difficulty, conservatism, and bias.", "method": "Proposes a unified framework combining Bayesian, DRO, and regularization approaches, analyzing asymptotic and non-asymptotic properties, and developing solution methods.", "result": "The framework balances robustness to unseen data and specificity to training data, validated by superior performance in real-world experiments.", "conclusion": "The new framework effectively addresses the challenges of existing methods, demonstrating practical advantages and theoretical soundness."}}
{"id": "2503.04767", "pdf": "https://arxiv.org/pdf/2503.04767", "abs": "https://arxiv.org/abs/2503.04767", "authors": ["Penny A. Barr", "Sohel M. Imroz"], "title": "A cross-regional review of AI safety regulations in the commercial aviation", "categories": ["cs.CY", "cs.AI"], "comment": "Identified errors in in-text citations and references sections", "summary": "In this paper we examine the existing artificial intelligence (AI) policy\ndocuments in aviation for the following three regions: the United States,\nEuropean Union, and China. The aviation industry has always been a first mover\nin adopting technological advancements. This early adoption offers valuable\ninsights because of its stringent regulations and safety-critical procedures.\nAs a result, the aviation industry provides an optimal platform to counter AI\nvulnerabilities through its tight regulations, standardization processes, and\ncertification of new technologies. Keywords: AI in aviation; aviation safety;\nstandardization; certifiable AI; regulations", "AI": {"tldr": "Analysis of AI policy documents in aviation across the US, EU, and China, highlighting aviation's role in addressing AI vulnerabilities through regulations and standardization.", "motivation": "The aviation industry's early adoption of technology and strict regulations make it an ideal case study for understanding AI policy and safety.", "method": "Examination of existing AI policy documents in aviation from the US, EU, and China.", "result": "Aviation's regulatory framework provides insights into mitigating AI vulnerabilities via standardization and certification.", "conclusion": "The aviation industry serves as a model for addressing AI challenges through stringent regulations and safety protocols."}}
{"id": "2504.05304", "pdf": "https://arxiv.org/pdf/2504.05304", "abs": "https://arxiv.org/abs/2504.05304", "authors": ["Hansheng Chen", "Kai Zhang", "Hao Tan", "Zexiang Xu", "Fujun Luan", "Leonidas Guibas", "Gordon Wetzstein", "Sai Bi"], "title": "Gaussian Mixture Flow Matching Models", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025. Code: https://github.com/Lakonik/GMFlow", "summary": "Diffusion models approximate the denoising distribution as a Gaussian and\npredict its mean, whereas flow matching models reparameterize the Gaussian mean\nas flow velocity. However, they underperform in few-step sampling due to\ndiscretization error and tend to produce over-saturated colors under\nclassifier-free guidance (CFG). To address these limitations, we propose a\nnovel Gaussian mixture flow matching (GMFlow) model: instead of predicting the\nmean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a\nmulti-modal flow velocity distribution, which can be learned with a KL\ndivergence loss. We demonstrate that GMFlow generalizes previous diffusion and\nflow matching models where a single Gaussian is learned with an $L_2$ denoising\nloss. For inference, we derive GM-SDE/ODE solvers that leverage analytic\ndenoising distributions and velocity fields for precise few-step sampling.\nFurthermore, we introduce a novel probabilistic guidance scheme that mitigates\nthe over-saturation issues of CFG and improves image generation quality.\nExtensive experiments demonstrate that GMFlow consistently outperforms flow\nmatching baselines in generation quality, achieving a Precision of 0.942 with\nonly 6 sampling steps on ImageNet 256$\\times$256.", "AI": {"tldr": "GMFlow improves few-step sampling and color quality by predicting Gaussian mixture parameters instead of a single Gaussian, outperforming baselines.", "motivation": "Addressing underperformance in few-step sampling and over-saturated colors in diffusion and flow matching models.", "method": "Proposes Gaussian mixture flow matching (GMFlow) with KL divergence loss and introduces GM-SDE/ODE solvers for inference.", "result": "Achieves Precision of 0.942 with 6 sampling steps on ImageNet 256x256, outperforming baselines.", "conclusion": "GMFlow generalizes previous models, improves sampling efficiency, and mitigates color issues, enhancing generation quality."}}
{"id": "2402.13393", "pdf": "https://arxiv.org/pdf/2402.13393", "abs": "https://arxiv.org/abs/2402.13393", "authors": ["Kaiqi Jiang", "Wenzhe Fan", "Mao Li", "Xinhua Zhang"], "title": "Fairness Risks for Group-conditionally Missing Demographics", "categories": ["cs.LG", "cs.CY"], "comment": "Accepted to AISTATS 2025", "summary": "Fairness-aware classification models have gained increasing attention in\nrecent years as concerns grow on discrimination against some demographic\ngroups. Most existing models require full knowledge of the sensitive features,\nwhich can be impractical due to privacy, legal issues, and an individual's fear\nof discrimination. The key challenge we will address is the group dependency of\nthe unavailability, e.g., people of some age range may be more reluctant to\nreveal their age. Our solution augments general fairness risks with\nprobabilistic imputations of the sensitive features, while jointly learning the\ngroup-conditionally missing probabilities in a variational auto-encoder. Our\nmodel is demonstrated effective on both image and tabular datasets, achieving\nan improved balance between accuracy and fairness.", "AI": {"tldr": "Fairness-aware classification models address discrimination but often require sensitive features, which may be unavailable. This paper proposes a solution using probabilistic imputations and joint learning to handle missing sensitive data, improving accuracy and fairness.", "motivation": "Addressing the impracticality of requiring full sensitive feature knowledge due to privacy and discrimination concerns, especially when missingness is group-dependent.", "method": "Augments fairness risks with probabilistic imputations of sensitive features, jointly learning missing probabilities using a variational auto-encoder.", "result": "Effective on image and tabular datasets, achieving better accuracy-fairness balance.", "conclusion": "The proposed model handles missing sensitive data effectively, enhancing fairness without compromising accuracy."}}
{"id": "2503.16248", "pdf": "https://arxiv.org/pdf/2503.16248", "abs": "https://arxiv.org/abs/2503.16248", "authors": ["Atharv Singh Patlan", "Peiyao Sheng", "S. Ashwin Hebbar", "Prateek Mittal", "Pramod Viswanath"], "title": "Real AI Agents with Fake Memories: Fatal Context Manipulation Attacks on Web3 Agents", "categories": ["cs.CR", "cs.AI", "I.2.7"], "comment": "29 pages, 21 figures", "summary": "The integration of AI agents with Web3 ecosystems harnesses their\ncomplementary potential for autonomy and openness yet also introduces\nunderexplored security risks, as these agents dynamically interact with\nfinancial protocols and immutable smart contracts. This paper investigates the\nvulnerabilities of AI agents within blockchain-based financial ecosystems when\nexposed to adversarial threats in real-world scenarios. We introduce the\nconcept of context manipulation, a comprehensive attack vector that exploits\nunprotected context surfaces, including input channels, memory modules, and\nexternal data feeds.\n  Through empirical analysis of ElizaOS, a decentralized AI agent framework for\nautomated Web3 operations, we demonstrate how adversaries can manipulate\ncontext by injecting malicious instructions into prompts or historical\ninteraction records, leading to unintended asset transfers and protocol\nviolations which could be financially devastating.\n  To quantify these vulnerabilities, we design CrAIBench, a Web3\ndomain-specific benchmark that evaluates the robustness of AI agents against\ncontext manipulation attacks across 150+ realistic blockchain tasks, including\ntoken transfers, trading, bridges and cross-chain interactions and 500+ attack\ntest cases using context manipulation. We systematically assess attack and\ndefense strategies, analyzing factors like the influence of security prompts,\nreasoning models, and the effectiveness of alignment techniques.\n  Our findings show that prompt-based defenses are insufficient when\nadversaries corrupt stored context, achieving significant attack success rates\ndespite these defenses. Fine-tuning-based defenses offer a more robust\nalternative, substantially reducing attack success rates while preserving\nutility on single-step tasks. This research highlights the urgent need to\ndevelop AI agents that are both secure and fiduciarily responsible.", "AI": {"tldr": "The paper explores security risks of AI agents in Web3 ecosystems, focusing on context manipulation attacks, and evaluates defenses using a benchmark (CrAIBench).", "motivation": "To address underexplored vulnerabilities of AI agents in blockchain financial ecosystems, particularly against adversarial threats exploiting context surfaces.", "method": "Empirical analysis of ElizaOS, a decentralized AI framework, and development of CrAIBench to test robustness against context manipulation attacks.", "result": "Prompt-based defenses fail when context is corrupted; fine-tuning-based defenses are more effective but limited to single-step tasks.", "conclusion": "Urgent need for secure and fiduciarily responsible AI agents in Web3, with emphasis on robust defense mechanisms."}}
{"id": "2504.18768", "pdf": "https://arxiv.org/pdf/2504.18768", "abs": "https://arxiv.org/abs/2504.18768", "authors": ["Letian Huang", "Dongwei Ye", "Jialin Dan", "Chengzhi Tao", "Huiwen Liu", "Kun Zhou", "Bo Ren", "Yuanqi Li", "Yanwen Guo", "Jie Guo"], "title": "TransparentGS: Fast Inverse Rendering of Transparent Objects with Gaussians", "categories": ["cs.GR", "cs.CV"], "comment": "accepted by SIGGRAPH 2025;\n  https://letianhuang.github.io/transparentgs/", "summary": "The emergence of neural and Gaussian-based radiance field methods has led to\nconsiderable advancements in novel view synthesis and 3D object reconstruction.\nNonetheless, specular reflection and refraction continue to pose significant\nchallenges due to the instability and incorrect overfitting of radiance fields\nto high-frequency light variations. Currently, even 3D Gaussian Splatting\n(3D-GS), as a powerful and efficient tool, falls short in recovering\ntransparent objects with nearby contents due to the existence of apparent\nsecondary ray effects. To address this issue, we propose TransparentGS, a fast\ninverse rendering pipeline for transparent objects based on 3D-GS. The main\ncontributions are three-fold. Firstly, an efficient representation of\ntransparent objects, transparent Gaussian primitives, is designed to enable\nspecular refraction through a deferred refraction strategy. Secondly, we\nleverage Gaussian light field probes (GaussProbe) to encode both ambient light\nand nearby contents in a unified framework. Thirdly, a depth-based iterative\nprobes query (IterQuery) algorithm is proposed to reduce the parallax errors in\nour probe-based framework. Experiments demonstrate the speed and accuracy of\nour approach in recovering transparent objects from complex environments, as\nwell as several applications in computer graphics and vision.", "AI": {"tldr": "TransparentGS improves 3D-GS for transparent objects by introducing transparent Gaussian primitives, GaussProbe, and IterQuery, addressing specular reflection and refraction challenges.", "motivation": "Existing methods like 3D-GS struggle with transparent objects due to secondary ray effects and high-frequency light variations.", "method": "Proposes TransparentGS with transparent Gaussian primitives, GaussProbe for light encoding, and IterQuery for parallax error reduction.", "result": "Demonstrates speed and accuracy in recovering transparent objects in complex environments.", "conclusion": "TransparentGS advances transparent object reconstruction with applications in graphics and vision."}}
{"id": "2405.18353", "pdf": "https://arxiv.org/pdf/2405.18353", "abs": "https://arxiv.org/abs/2405.18353", "authors": ["Gefan Yang", "Elizabeth Louise Baker", "Michael L. Severinsen", "Christy Anna Hipsley", "Stefan Sommer"], "title": "Infinite-dimensional Diffusion Bridge Simulation via Operator Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The diffusion bridge, which is a diffusion process conditioned on hitting a\nspecific state within a finite period, has found broad applications in various\nscientific and engineering fields. However, simulating diffusion bridges for\nmodeling natural data can be challenging due to both the intractability of the\ndrift term and continuous representations of the data. Although several methods\nare available to simulate finite-dimensional diffusion bridges,\ninfinite-dimensional cases remain under explored. This paper presents a method\nthat merges score matching techniques with operator learning, enabling a direct\napproach to learn the infinite-dimensional bridge and achieving a\ndiscretization equivariant bridge simulation. We conduct a series of\nexperiments, ranging from synthetic examples with closed-form solutions to the\nstochastic nonlinear evolution of real-world biological shape data. Our method\ndemonstrates high efficacy, particularly due to its ability to adapt to any\nresolution without extra training.", "AI": {"tldr": "A method combining score matching and operator learning is introduced to simulate infinite-dimensional diffusion bridges, achieving resolution-adaptive results without additional training.", "motivation": "Simulating diffusion bridges for natural data is challenging due to intractable drift terms and continuous data representations, especially in infinite dimensions.", "method": "The method merges score matching with operator learning to directly learn infinite-dimensional bridges, ensuring discretization equivariance.", "result": "Experiments on synthetic and real-world biological data show high efficacy, with the method adapting to any resolution without retraining.", "conclusion": "The proposed approach effectively addresses the challenges of infinite-dimensional diffusion bridge simulation, offering practical advantages in adaptability."}}
{"id": "2503.19339", "pdf": "https://arxiv.org/pdf/2503.19339", "abs": "https://arxiv.org/abs/2503.19339", "authors": ["Amna Naeem", "Muazzam A. Khan", "Nada Alasbali", "Jawad Ahmad", "Aizaz Ahmad Khattak", "Muhammad Shahbaz Khan"], "title": "Efficient IoT Intrusion Detection with an Improved Attention-Based CNN-BiLSTM Architecture", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The ever-increasing security vulnerabilities in the Internet-of-Things (IoT)\nsystems require improved threat detection approaches. This paper presents a\ncompact and efficient approach to detect botnet attacks by employing an\nintegrated approach that consists of traffic pattern analysis, temporal support\nlearning, and focused feature extraction. The proposed attention-based model\nbenefits from a hybrid CNN-BiLSTM architecture and achieves 99% classification\naccuracy in detecting botnet attacks utilizing the N-BaIoT dataset, while\nmaintaining high precision and recall across various scenarios. The proposed\nmodel's performance is further validated by key parameters, such as Mathews\nCorrelation Coefficient and Cohen's kappa Correlation Coefficient. The\nclose-to-ideal results for these parameters demonstrate the proposed model's\nability to detect botnet attacks accurately and efficiently in practical\nsettings and on unseen data. The proposed model proved to be a powerful defence\nmechanism for IoT networks to face emerging security challenges.", "AI": {"tldr": "A compact, efficient botnet attack detection method for IoT using traffic analysis, temporal learning, and feature extraction, achieving 99% accuracy with a hybrid CNN-BiLSTM model.", "motivation": "Addressing growing IoT security vulnerabilities by improving threat detection.", "method": "Integrated approach with traffic pattern analysis, temporal support learning, and feature extraction, using a hybrid CNN-BiLSTM architecture.", "result": "99% classification accuracy, high precision/recall, validated by Mathews and Cohen's kappa coefficients.", "conclusion": "The model is an effective defense for IoT networks against emerging security threats."}}
{"id": "2504.19174", "pdf": "https://arxiv.org/pdf/2504.19174", "abs": "https://arxiv.org/abs/2504.19174", "authors": ["Xueqi Ma", "Yilin Liu", "Tianlong Gao", "Qirui Huang", "Hui Huang"], "title": "CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025 (Patent Protected); Project page:\n  https://vcc.tech/research/2025/CLRWire", "summary": "We introduce CLR-Wire, a novel framework for 3D curve-based wireframe\ngeneration that integrates geometry and topology into a unified Continuous\nLatent Representation. Unlike conventional methods that decouple vertices,\nedges, and faces, CLR-Wire encodes curves as Neural Parametric Curves along\nwith their topological connectivity into a continuous and fixed-length latent\nspace using an attention-driven variational autoencoder (VAE). This unified\napproach facilitates joint learning and generation of both geometry and\ntopology. To generate wireframes, we employ a flow matching model to\nprogressively map Gaussian noise to these latents, which are subsequently\ndecoded into complete 3D wireframes. Our method provides fine-grained modeling\nof complex shapes and irregular topologies, and supports both unconditional\ngeneration and generation conditioned on point cloud or image inputs.\nExperimental results demonstrate that, compared with state-of-the-art\ngenerative approaches, our method achieves substantial improvements in\naccuracy, novelty, and diversity, offering an efficient and comprehensive\nsolution for CAD design, geometric reconstruction, and 3D content creation.", "AI": {"tldr": "CLR-Wire is a framework for 3D wireframe generation using a unified latent representation for geometry and topology, outperforming state-of-the-art methods in accuracy and diversity.", "motivation": "Existing methods decouple geometry and topology, limiting joint learning and generation. CLR-Wire aims to unify these aspects for better wireframe modeling.", "method": "Uses an attention-driven VAE to encode curves and topology into a latent space, then employs flow matching to generate wireframes from noise.", "result": "Achieves superior accuracy, novelty, and diversity compared to other generative methods.", "conclusion": "CLR-Wire offers an efficient solution for CAD design and 3D content creation by unifying geometry and topology learning."}}
{"id": "2406.06002", "pdf": "https://arxiv.org/pdf/2406.06002", "abs": "https://arxiv.org/abs/2406.06002", "authors": ["Zhen Qin", "Zhihui Zhu"], "title": "Computational and Statistical Guarantees for Tensor-on-Tensor Regression with Tensor Train Decomposition", "categories": ["cs.LG", "eess.SP", "math.OC"], "comment": "arXiv admin note: text overlap with arXiv:2401.02592", "summary": "Recently, a tensor-on-tensor (ToT) regression model has been proposed to\ngeneralize tensor recovery, encompassing scenarios like scalar-on-tensor\nregression and tensor-on-vector regression. However, the exponential growth in\ntensor complexity poses challenges for storage and computation in ToT\nregression. To overcome this hurdle, tensor decompositions have been\nintroduced, with the tensor train (TT)-based ToT model proving efficient in\npractice due to reduced memory requirements, enhanced computational efficiency,\nand decreased sampling complexity. Despite these practical benefits, a\ndisparity exists between theoretical analysis and real-world performance. In\nthis paper, we delve into the theoretical and algorithmic aspects of the\nTT-based ToT regression model. Assuming the regression operator satisfies the\nrestricted isometry property (RIP), we conduct an error analysis for the\nsolution to a constrained least-squares optimization problem. This analysis\nincludes upper error bound and minimax lower bound, revealing that such error\nbounds polynomially depend on the order $N+M$. To efficiently find solutions\nmeeting such error bounds, we propose two optimization algorithms: the\niterative hard thresholding (IHT) algorithm (employing gradient descent with\nTT-singular value decomposition (TT-SVD)) and the factorization approach using\nthe Riemannian gradient descent (RGD) algorithm. When RIP is satisfied,\nspectral initialization facilitates proper initialization, and we establish the\nlinear convergence rate of both IHT and RGD.", "AI": {"tldr": "The paper analyzes the TT-based ToT regression model, providing theoretical error bounds and proposing efficient optimization algorithms (IHT and RGD) with linear convergence under RIP conditions.", "motivation": "Address the gap between theoretical analysis and practical performance in TT-based ToT regression, focusing on storage and computational challenges.", "method": "Error analysis under RIP, proposing IHT (gradient descent with TT-SVD) and RGD algorithms. Spectral initialization ensures proper starting points.", "result": "Error bounds polynomially depend on tensor order (N+M). Both IHT and RGD achieve linear convergence under RIP.", "conclusion": "Theoretical and algorithmic advancements bridge the gap, offering efficient solutions for TT-based ToT regression with proven convergence."}}
{"id": "2504.02546", "pdf": "https://arxiv.org/pdf/2504.02546", "abs": "https://arxiv.org/abs/2504.02546", "authors": ["Xiangxiang Chu", "Hailang Huang", "Xiao Zhang", "Fei Wei", "Yong Wang"], "title": "GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) can directly enhance the reasoning capabilities\nof large language models without extensive reliance on Supervised Fine-Tuning\n(SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism\nand propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike\nconventional methods, GPG directly optimize the original RL objective, thus\nobviating the need for surrogate loss functions. By eliminating the critic and\nreference models, avoiding KL divergence constraints, and addressing the\nadvantage and gradient estimation bias, our approach significantly simplifies\nthe training process compared to Group Relative Policy Optimization (GRPO). Our\napproach achieves superior performance without relying on auxiliary techniques\nor adjustments. As illustrated in Figure 1, extensive experiments demonstrate\nthat our method not only reduces computational costs but also consistently\noutperforms GRPO across various unimodal and multimodal tasks. Our code is\navailable at https://github.com/AMAP-ML/GPG.", "AI": {"tldr": "A minimalist RL approach, Group Policy Gradient (GPG), simplifies training by optimizing the original RL objective without surrogate losses, outperforming GRPO in efficiency and performance.", "motivation": "To enhance reasoning in large language models via RL without heavy reliance on Supervised Fine-Tuning (SFT).", "method": "Proposes GPG, eliminating critic/reference models, KL constraints, and bias in advantage/gradient estimation.", "result": "GPG reduces computational costs and outperforms GRPO in unimodal/multimodal tasks.", "conclusion": "GPG offers a simpler, more effective RL approach for language models, validated by experiments."}}
{"id": "2406.17281", "pdf": "https://arxiv.org/pdf/2406.17281", "abs": "https://arxiv.org/abs/2406.17281", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "DRTR: Distance-Aware Graph Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "We propose \\textbf{DRTR}, a novel graph learning framework that integrates\ndistance-aware multi-hop message passing with dynamic topology refinement.\nUnlike standard GNNs that rely on shallow, fixed-hop aggregation, DRTR\nleverages both static preprocessing and dynamic resampling to capture deeper\nstructural dependencies. A \\emph{Distance Recomputator} prunes semantically\nweak edges using adaptive attention, while a \\emph{Topology Reconstructor}\nestablishes latent connections among distant but relevant nodes. This joint\nmechanism enables more expressive and robust representation learning across\nevolving graph structures. Extensive experiments demonstrate that DRTR\noutperforms baseline GNNs in both accuracy and scalability, especially in\ncomplex and noisy graph environments.", "AI": {"tldr": "DRTR is a graph learning framework combining distance-aware message passing and dynamic topology refinement, outperforming standard GNNs in accuracy and scalability.", "motivation": "Standard GNNs rely on shallow, fixed-hop aggregation, limiting their ability to capture deeper structural dependencies in evolving or noisy graphs.", "method": "DRTR uses a Distance Recomputator for edge pruning and a Topology Reconstructor for latent connections, integrating static preprocessing and dynamic resampling.", "result": "DRTR outperforms baseline GNNs in accuracy and scalability, particularly in complex and noisy environments.", "conclusion": "DRTR provides a more expressive and robust framework for graph representation learning by dynamically refining graph topologies."}}
{"id": "2504.14560", "pdf": "https://arxiv.org/pdf/2504.14560", "abs": "https://arxiv.org/abs/2504.14560", "authors": ["Haiyan Qin", "Zhiwei Xie", "Jingjing Li", "Liangchen Li", "Xiaotong Feng", "Junzhan Liu", "Wang Kang"], "title": "ReasoningV: Efficient Verilog Code Generation with Adaptive Hybrid Reasoning Model", "categories": ["cs.AR", "cs.AI"], "comment": "9 pages, 4 figures", "summary": "Large Language Models (LLMs) have advanced Verilog code generation\nsignificantly, yet face challenges in data quality, reasoning capabilities, and\ncomputational efficiency. This paper presents ReasoningV, a novel model\nemploying a hybrid reasoning strategy that integrates trained intrinsic\ncapabilities with dynamic inference adaptation for Verilog code generation. Our\nframework introduces three complementary innovations: (1) ReasoningV-5K, a\nhigh-quality dataset of 5,000 functionally verified instances with reasoning\npaths created through multi-dimensional filtering of PyraNet samples; (2) a\ntwo-stage training approach combining parameter-efficient fine-tuning for\nfoundational knowledge with full-parameter optimization for enhanced reasoning;\nand (3) an adaptive reasoning mechanism that dynamically adjusts reasoning\ndepth based on problem complexity, reducing token consumption by up to 75\\%\nwhile preserving performance. Experimental results demonstrate ReasoningV's\neffectiveness with a pass@1 accuracy of 57.8\\% on VerilogEval-human, achieving\nperformance competitive with leading commercial models like Gemini-2.0-flash\n(59.5\\%) and exceeding the previous best open-source model by 10.4 percentage\npoints. ReasoningV offers a more reliable and accessible pathway for advancing\nAI-driven hardware design automation, with our model, data, and code available\nat https://github.com/BUAA-CLab/ReasoningV.", "AI": {"tldr": "ReasoningV improves Verilog code generation with hybrid reasoning, a high-quality dataset, efficient training, and adaptive reasoning, achieving competitive accuracy.", "motivation": "Address challenges in LLMs for Verilog code generation, such as data quality, reasoning, and computational efficiency.", "method": "Hybrid reasoning strategy, two-stage training, and adaptive reasoning mechanism with a new dataset (ReasoningV-5K).", "result": "57.8% pass@1 accuracy on VerilogEval-human, competitive with commercial models and surpassing open-source alternatives.", "conclusion": "ReasoningV provides a reliable, accessible solution for AI-driven hardware design automation, with open resources."}}
{"id": "2407.00966", "pdf": "https://arxiv.org/pdf/2407.00966", "abs": "https://arxiv.org/abs/2407.00966", "authors": ["Gautam Chandrasekaran", "Adam Klivans", "Vasilis Kontonis", "Raghu Meka", "Konstantinos Stavropoulos"], "title": "Smoothed Analysis for Learning Concepts with Low Intrinsic Dimension", "categories": ["cs.LG", "cs.CC"], "comment": "added some citations", "summary": "In traditional models of supervised learning, the goal of a learner -- given\nexamples from an arbitrary joint distribution on $\\mathbb{R}^d \\times \\{\\pm\n1\\}$ -- is to output a hypothesis that is competitive (to within $\\epsilon$) of\nthe best fitting concept from some class. In order to escape strong hardness\nresults for learning even simple concept classes, we introduce a\nsmoothed-analysis framework that requires a learner to compete only with the\nbest classifier that is robust to small random Gaussian perturbation.\n  This subtle change allows us to give a wide array of learning results for any\nconcept that (1) depends on a low-dimensional subspace (aka multi-index model)\nand (2) has a bounded Gaussian surface area. This class includes functions of\nhalfspaces and (low-dimensional) convex sets, cases that are only known to be\nlearnable in non-smoothed settings with respect to highly structured\ndistributions such as Gaussians.\n  Surprisingly, our analysis also yields new results for traditional\nnon-smoothed frameworks such as learning with margin. In particular, we obtain\nthe first algorithm for agnostically learning intersections of $k$-halfspaces\nin time $k^{poly(\\frac{\\log k}{\\epsilon \\gamma}) }$ where $\\gamma$ is the\nmargin parameter. Before our work, the best-known runtime was exponential in\n$k$ (Arriaga and Vempala, 1999).", "AI": {"tldr": "The paper introduces a smoothed-analysis framework for supervised learning, enabling competitive learning for low-dimensional subspace concepts with bounded Gaussian surface area, including halfspaces and convex sets. It also improves traditional non-smoothed learning, notably for intersections of halfspaces.", "motivation": "To overcome hardness results in traditional supervised learning by focusing on classifiers robust to small Gaussian perturbations, expanding learnability for low-dimensional concepts.", "method": "A smoothed-analysis framework requiring learners to compete with the best Gaussian-perturbation-robust classifier, applied to low-dimensional subspace concepts with bounded Gaussian surface area.", "result": "Achieves learnability for functions of halfspaces and low-dimensional convex sets, and improves runtime for agnostically learning intersections of halfspaces.", "conclusion": "The framework broadens learnability in supervised learning and provides new insights for traditional non-smoothed settings."}}
{"id": "2504.14625", "pdf": "https://arxiv.org/pdf/2504.14625", "abs": "https://arxiv.org/abs/2504.14625", "authors": ["Haiyan Qin", "Jiahao Feng", "Xiaotong Feng", "Wei W. Xing", "Wang Kang"], "title": "Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence", "categories": ["cs.AR", "cs.AI"], "comment": "9 pages, 6 figures", "summary": "Large language models (LLMs) have transformed code generation, yet their\napplication in hardware design produces gate counts 38\\%--1075\\% higher than\nhuman designs. We present CircuitMind, a multi-agent framework that achieves\nhuman-competitive efficiency through three key innovations: syntax locking\n(constraining generation to basic logic gates), retrieval-augmented generation\n(enabling knowledge-driven design), and dual-reward optimization (balancing\ncorrectness with efficiency). To evaluate our approach, we introduce TC-Bench,\nthe first gate-level benchmark harnessing collective intelligence from the\nTuringComplete ecosystem -- a competitive circuit design platform with hundreds\nof thousands of players. Experiments show CircuitMind enables 55.6\\% of model\nimplementations to match or exceed top-tier human experts in composite\nefficiency metrics. Most remarkably, our framework elevates the 14B Phi-4 model\nto outperform both GPT-4o mini and Gemini 2.0 Flash, achieving efficiency\ncomparable to the top 25\\% of human experts without requiring specialized\ntraining. These innovations establish a new paradigm for hardware optimization\nwhere collaborative AI systems leverage collective human expertise to achieve\noptimal circuit designs. Our model, data, and code are open-source at\nhttps://github.com/BUAA-CLab/CircuitMind.", "AI": {"tldr": "CircuitMind is a multi-agent framework for hardware design that achieves human-competitive efficiency using syntax locking, retrieval-augmented generation, and dual-reward optimization. It outperforms other models and matches top human experts.", "motivation": "LLMs in hardware design often produce inefficient gate counts compared to human designs, necessitating a more effective approach.", "method": "CircuitMind employs syntax locking, retrieval-augmented generation, and dual-reward optimization to optimize hardware design.", "result": "55.6% of model implementations match or exceed top human experts, with the 14B Phi-4 model outperforming GPT-4o mini and Gemini 2.0 Flash.", "conclusion": "CircuitMind sets a new paradigm for AI-assisted hardware optimization by leveraging collective human expertise, achieving top-tier efficiency without specialized training."}}
{"id": "2407.17856", "pdf": "https://arxiv.org/pdf/2407.17856", "abs": "https://arxiv.org/abs/2407.17856", "authors": ["Juan Miguel Lopez Alcaraz", "Hjalmar Bouma", "Nils Strodthoff"], "title": "Enhancing clinical decision support with physiological waveforms -- a multimodal benchmark in emergency care", "categories": ["cs.LG", "eess.SP"], "comment": "Version accepted by Computers in Biology and Medicine: 21 pages, 2\n  figures, code available under https://github.com/AI4HealthUOL/MDS-ED, dataset\n  available under https://physionet.org/content/multimodal-emergency-benchmark/", "summary": "Background: AI-driven prediction algorithms have the potential to enhance\nemergency medicine by enabling rapid and accurate decision-making regarding\npatient status and potential deterioration. However, the integration of\nmultimodal data, including raw waveform signals, remains underexplored in\nclinical decision support. Methods: We present a dataset and benchmarking\nprotocol designed to advance multimodal decision support in emergency care. Our\nmodels utilize demographics, biometrics, vital signs, laboratory values, and\nelectrocardiogram (ECG) waveforms as inputs to predict both discharge diagnoses\nand patient deterioration. Results: The diagnostic model achieves area under\nthe receiver operating curve (AUROC) scores above 0.8 for 609 out of 1,428\nconditions, covering both cardiac (e.g., myocardial infarction) and non-cardiac\n(e.g., renal disease, diabetes) diagnoses. The deterioration model attains\nAUROC scores above 0.8 for 14 out of 15 targets, accurately predicting critical\nevents such as cardiac arrest, mechanical ventilation, ICU admission, and\nmortality. Conclusions: Our study highlights the positive impact of\nincorporating raw waveform data into decision support models, improving\npredictive performance. By introducing a unique, publicly available dataset and\nbaseline models, we provide a foundation for measurable progress in AI-driven\ndecision support for emergency care.", "AI": {"tldr": "AI-driven prediction models using multimodal data (demographics, biometrics, vital signs, lab values, ECG waveforms) improve emergency care decision-making, achieving high accuracy for diagnoses and predicting patient deterioration.", "motivation": "To enhance emergency medicine by integrating multimodal data, including raw waveform signals, for better clinical decision support.", "method": "Developed models using demographics, biometrics, vital signs, lab values, and ECG waveforms to predict discharge diagnoses and patient deterioration.", "result": "Diagnostic model achieved AUROC >0.8 for 609/1,428 conditions; deterioration model achieved AUROC >0.8 for 14/15 critical events.", "conclusion": "Incorporating raw waveform data improves predictive performance, and the publicly available dataset and models advance AI-driven emergency care support."}}
{"id": "2504.15546", "pdf": "https://arxiv.org/pdf/2504.15546", "abs": "https://arxiv.org/abs/2504.15546", "authors": ["Jayachandu Bandlamudi", "Ritwik Chaudhuri", "Neelamadhav Gantayat", "Kushal Mukherjee", "Prerna Agarwal", "Renuka Sindhgatta", "Sameep Mehta"], "title": "A Framework for Testing and Adapting REST APIs as LLM Tools", "categories": ["cs.SE", "cs.AI", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) are enabling autonomous agents to perform\ncomplex workflows using external tools or functions, often provided via REST\nAPIs in enterprise systems. However, directly utilizing these APIs as tools\nposes challenges due to their complex input schemas, elaborate responses, and\noften ambiguous documentation. Current benchmarks for tool testing do not\nadequately address these complexities, leading to a critical gap in evaluating\nAPI readiness for agent-driven automation. In this work, we present a novel\ntesting framework aimed at evaluating and enhancing the readiness of REST APIs\nto function as tools for LLM-based agents. Our framework transforms apis as\ntools, generates comprehensive test cases for the APIs, translates tests cases\ninto natural language instructions suitable for agents, enriches tool\ndefinitions and evaluates the agent's ability t correctly invoke the API and\nprocess its inputs and responses. To provide actionable insights, we analyze\nthe outcomes of 750 test cases, presenting a detailed taxonomy of errors,\nincluding input misinterpretation, output handling inconsistencies, and schema\nmismatches. Additionally, we classify these test cases to streamline debugging\nand refinement of tool integrations. This work offers a foundational step\ntoward enabling enterprise APIs as tools, improving their usability in\nagent-based applications.", "AI": {"tldr": "A novel testing framework evaluates REST APIs for LLM-based agents, addressing challenges like complex schemas and ambiguous documentation. It generates test cases, translates them into natural language, and analyzes 750 cases to classify errors and improve API usability.", "motivation": "Current benchmarks for tool testing fail to address the complexities of REST APIs for LLM-based agents, creating a gap in evaluating API readiness for automation.", "method": "The framework transforms APIs into tools, generates test cases, translates them into natural language, enriches tool definitions, and evaluates agent performance in API invocation and response handling.", "result": "Analysis of 750 test cases reveals a taxonomy of errors (e.g., input misinterpretation, schema mismatches) and provides actionable insights for debugging and refining tool integrations.", "conclusion": "The framework enhances REST API readiness for LLM-based agents, improving their usability in agent-driven applications."}}
{"id": "2412.12870", "pdf": "https://arxiv.org/pdf/2412.12870", "abs": "https://arxiv.org/abs/2412.12870", "authors": ["Zhenjiang Mao", "Ivan Ruchkin"], "title": "Towards Physically Interpretable World Models: Meaningful Weakly Supervised Representations for Visual Trajectory Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning models are increasingly employed for perception, prediction,\nand control in robotic systems. For for achieving realistic and consistent\noutputs, it is crucial to embed physical knowledge into their learned\nrepresentations. However, doing so is difficult due to high-dimensional\nobservation data, such as images, particularly under conditions of incomplete\nsystem knowledge and imprecise state sensing. To address this, we propose\nPhysically Interpretable World Models, a novel architecture that aligns learned\nlatent representations with real-world physical quantities. To this end, our\narchitecture combines three key elements: (1) a vector-quantized image\nautoencoder, (2) a transformer-based physically interpretable autoencoder, and\n(3) a partially known dynamical model. The training incorporates weak\ninterval-based supervision to eliminate the impractical reliance on\nground-truth physical knowledge. Three case studies demonstrate that our\napproach achieves physical interpretability and accurate state predictions,\nthus advancing representation learning for robotics.", "AI": {"tldr": "A novel architecture, Physically Interpretable World Models, integrates physical knowledge into deep learning for robotics, improving interpretability and prediction accuracy.", "motivation": "Embedding physical knowledge into deep learning models for robotics is challenging due to high-dimensional data and incomplete system knowledge.", "method": "Combines a vector-quantized image autoencoder, a transformer-based physically interpretable autoencoder, and a partially known dynamical model, using weak interval-based supervision.", "result": "Achieves physical interpretability and accurate state predictions in three case studies.", "conclusion": "Advances representation learning for robotics by aligning learned representations with real-world physical quantities."}}
{"id": "2504.18575", "pdf": "https://arxiv.org/pdf/2504.18575", "abs": "https://arxiv.org/abs/2504.18575", "authors": ["Ivan Evtimov", "Arman Zharmagambetov", "Aaron Grattafiori", "Chuan Guo", "Kamalika Chaudhuri"], "title": "WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks", "categories": ["cs.CR", "cs.AI"], "comment": "Code and data: https://github.com/facebookresearch/wasp", "summary": "Web navigation AI agents use language-and-vision foundation models to enhance\nproductivity but these models are known to be susceptible to indirect prompt\ninjections that get them to follow instructions different from the legitimate\nuser's. Existing explorations of this threat applied to web agents often focus\non a single isolated adversarial goal, test with injected instructions that are\neither too easy or not truly malicious, and often give the adversary\nunreasonable access. In order to better focus adversarial research, we\nconstruct a new benchmark called WASP (Web Agent Security against Prompt\ninjection attacks) that introduces realistic web agent hijacking objectives and\nan isolated environment to test them in that does not affect real users or the\nlive web. As part of WASP, we also develop baseline attacks against popular web\nagentic systems (VisualWebArena, Claude Computer Use, etc.) instantiated with\nvarious state-of-the-art models. Our evaluation shows that even AI agents\nbacked by models with advanced reasoning capabilities and by models with\ninstruction hierarchy mitigations are susceptible to low-effort human-written\nprompt injections. However, the realistic objectives in WASP also allow us to\nobserve that agents are currently not capable enough to complete the goals of\nattackers end-to-end. Agents begin executing the adversarial instruction\nbetween 16 and 86% of the time but only achieve the goal between 0 and 17% of\nthe time. Based on these findings, we argue that adversarial researchers should\ndemonstrate stronger attacks that more consistently maintain control over the\nagent given realistic constraints on the adversary's power.", "AI": {"tldr": "The paper introduces WASP, a benchmark for testing web AI agents against realistic prompt injection attacks, showing susceptibility but limited attacker success.", "motivation": "To address gaps in adversarial research by focusing on realistic web agent hijacking objectives and providing a safe testing environment.", "method": "Developed the WASP benchmark with realistic objectives and tested baseline attacks on popular web agent systems.", "result": "AI agents are vulnerable to prompt injections but often fail to complete attacker goals (0-17% success).", "conclusion": "Stronger attacks are needed to demonstrate consistent agent control under realistic constraints."}}
{"id": "2501.18028", "pdf": "https://arxiv.org/pdf/2501.18028", "abs": "https://arxiv.org/abs/2501.18028", "authors": ["Cassandra Mussard", "Arthur Charpentier", "St\u00e9phane Mussard"], "title": "KNN and K-means in Gini Prametric Spaces", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces innovative enhancements to the K-means and K-nearest\nneighbors (KNN) algorithms based on the concept of Gini prametric spaces.\nUnlike traditional distance metrics, Gini-based measures incorporate both\nvalue-based and rank-based information, improving robustness to noise and\noutliers. The main contributions of this work include: proposing a Gini-based\nmeasure that captures both rank information and value distances; presenting a\nGini K-means algorithm that is proven to converge and demonstrates resilience\nto noisy data; and introducing a Gini KNN method that performs competitively\nwith state-of-the-art approaches such as Hassanat's distance in noisy\nenvironments. Experimental evaluations on 14 datasets from the UCI repository\ndemonstrate the superior performance and efficiency of Gini-based algorithms in\nclustering and classification tasks. This work opens new avenues for leveraging\nrank-based measures in machine learning and statistical analysis.", "AI": {"tldr": "The paper enhances K-means and KNN using Gini parametric spaces, improving robustness to noise and outliers with a new Gini-based measure.", "motivation": "Traditional distance metrics lack robustness to noise and outliers. The paper aims to improve this by incorporating rank and value information via Gini-based measures.", "method": "Proposes a Gini-based measure, develops Gini K-means (proven to converge) and Gini KNN, and evaluates them on 14 UCI datasets.", "result": "Gini-based algorithms outperform traditional methods in noisy environments, showing superior performance in clustering and classification.", "conclusion": "The work successfully leverages rank-based measures, opening new avenues for machine learning and statistical analysis."}}
{"id": "2504.19013", "pdf": "https://arxiv.org/pdf/2504.19013", "abs": "https://arxiv.org/abs/2504.19013", "authors": ["J\u00falia Vicens Figueres", "Juliette Vanderhaeghen", "Federica Bragone", "Kateryna Morozovska", "Khemraj Shukla"], "title": "$PINN - a Domain Decomposition Method for Bayesian Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI", "math.AP"], "comment": "37 pages, 22 figures", "summary": "Physics-Informed Neural Networks (PINNs) are a novel computational approach\nfor solving partial differential equations (PDEs) with noisy and sparse initial\nand boundary data. Although, efficient quantification of epistemic and\naleatoric uncertainties in big multi-scale problems remains challenging. We\npropose \\$PINN a novel method of computing global uncertainty in PDEs using a\nBayesian framework, by combining local Bayesian Physics-Informed Neural\nNetworks (BPINN) with domain decomposition. The solution continuity across\nsubdomains is obtained by imposing the flux continuity across the interface of\nneighboring subdomains. To demonstrate the effectiveness of \\$PINN, we conduct\na series of computational experiments on PDEs in 1D and 2D spatial domains.\nAlthough we have adopted conservative PINNs (cPINNs), the method can be\nseamlessly extended to other domain decomposition techniques. The results infer\nthat the proposed method recovers the global uncertainty by computing the local\nuncertainty exactly more efficiently as the uncertainty in each subdomain can\nbe computed concurrently. The robustness of \\$PINN is verified by adding\nuncorrelated random noise to the training data up to 15% and testing for\ndifferent domain sizes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2502.05974", "pdf": "https://arxiv.org/pdf/2502.05974", "abs": "https://arxiv.org/abs/2502.05974", "authors": ["Haolin Liu", "Chen-Yu Wei", "Julian Zimmert"], "title": "Decision Making in Hybrid Environments: A Model Aggregation Approach", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Recent work by Foster et al. (2021, 2022, 2023b) and Xu and Zeevi (2023)\ndeveloped the framework of decision estimation coefficient (DEC) that\ncharacterizes the complexity of general online decision making problems and\nprovides a general algorithm design principle. These works, however, either\nfocus on the pure stochastic regime where the world remains fixed over time, or\nthe pure adversarial regime where the world arbitrarily changes over time. For\nthe hybrid regime where the dynamics of the world is fixed while the reward\narbitrarily changes, they only give pessimistic bounds on the decision\ncomplexity. In this work, we propose a general extension of DEC that more\nprecisely characterizes this case. Besides applications in special cases, our\nframework leads to a flexible algorithm design where the learner learns over\nsubsets of the hypothesis set, trading estimation complexity with decision\ncomplexity, which could be of independent interest. Our work covers model-based\nlearning and model-free learning in the hybrid regime, with a newly proposed\nextension of the bilinear classes (Du et al., 2021) to the adversarial-reward\ncase. In addition, our method improves the best-known regret bounds for linear\nQ*/V* MDPs in the pure stochastic regime.", "AI": {"tldr": "The paper extends the Decision Estimation Coefficient (DEC) framework to better characterize the hybrid regime in online decision making, where the world's dynamics are fixed but rewards change arbitrarily. It introduces a flexible algorithm design and improves regret bounds for certain MDPs.", "motivation": "Prior work on DEC focused on pure stochastic or adversarial regimes, leaving the hybrid regime with pessimistic bounds. This work aims to address this gap.", "method": "The authors propose a general extension of DEC for the hybrid regime, introducing a flexible algorithm design that trades estimation and decision complexity. They also extend bilinear classes to adversarial-reward cases.", "result": "The framework provides more precise complexity characterization for the hybrid regime and improves regret bounds for linear Q*/V* MDPs in the stochastic regime.", "conclusion": "The work advances understanding of the hybrid regime in online decision making and offers practical algorithm design insights, with applications in model-based and model-free learning."}}
{"id": "2504.20101", "pdf": "https://arxiv.org/pdf/2504.20101", "abs": "https://arxiv.org/abs/2504.20101", "authors": ["Fei Fang", "Yifan Hua", "Shengze Wang", "Ruilin Zhou", "Yi Liu", "Chen Qian", "Xiaoxue Zhang"], "title": "GenTorrent: Scaling Large Language Model Serving with An Overley Network", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "While significant progress has been made in research and development on\nopen-source and cost-efficient large-language models (LLMs), serving\nscalability remains a critical challenge, particularly for small organizations\nand individuals seeking to deploy and test their LLM innovations. Inspired by\npeer-to-peer networks that leverage decentralized overlay nodes to increase\nthroughput and availability, we propose GenTorrent, an LLM serving overlay that\nharnesses computing resources from decentralized contributors. We identify four\nkey research problems inherent to enabling such a decentralized infrastructure:\n1) overlay network organization; 2) LLM communication privacy; 3) overlay\nforwarding for resource efficiency; and 4) verification of serving quality.\nThis work presents the first systematic study of these fundamental problems in\nthe context of decentralized LLM serving. Evaluation results from a prototype\nimplemented on a set of decentralized nodes demonstrate that GenTorrent\nachieves a latency reduction of over 50% compared to the baseline design\nwithout overlay forwarding. Furthermore, the security features introduce\nminimal overhead to serving latency and throughput. We believe this work\npioneers a new direction for democratizing and scaling future AI serving\ncapabilities.", "AI": {"tldr": "GenTorrent proposes a decentralized LLM serving overlay to address scalability challenges, reducing latency by 50% with minimal security overhead.", "motivation": "To enable scalable and cost-efficient LLM serving for small organizations and individuals by leveraging decentralized resources.", "method": "Proposes GenTorrent, a decentralized overlay network addressing four key problems: network organization, privacy, resource efficiency, and quality verification.", "result": "Prototype shows 50% latency reduction compared to baseline, with minimal overhead from security features.", "conclusion": "GenTorrent pioneers decentralized LLM serving, democratizing and scaling AI capabilities."}}
{"id": "2503.00917", "pdf": "https://arxiv.org/pdf/2503.00917", "abs": "https://arxiv.org/abs/2503.00917", "authors": ["Ali Ebrahimpour-Boroojeny", "Hari Sundaram", "Varun Chandrasekaran"], "title": "AMUN: Adversarial Machine UNlearning", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Machine unlearning, where users can request the deletion of a forget dataset,\nis becoming increasingly important because of numerous privacy regulations.\nInitial works on ``exact'' unlearning (e.g., retraining) incur large\ncomputational overheads. However, while computationally inexpensive,\n``approximate'' methods have fallen short of reaching the effectiveness of\nexact unlearning: models produced fail to obtain comparable accuracy and\nprediction confidence on both the forget and test (i.e., unseen) dataset.\nExploiting this observation, we propose a new unlearning method, Adversarial\nMachine UNlearning (AMUN), that outperforms prior state-of-the-art (SOTA)\nmethods for image classification. AMUN lowers the confidence of the model on\nthe forget samples by fine-tuning the model on their corresponding adversarial\nexamples. Adversarial examples naturally belong to the distribution imposed by\nthe model on the input space; fine-tuning the model on the adversarial examples\nclosest to the corresponding forget samples (a) localizes the changes to the\ndecision boundary of the model around each forget sample and (b) avoids drastic\nchanges to the global behavior of the model, thereby preserving the model's\naccuracy on test samples. Using AMUN for unlearning a random $10\\%$ of CIFAR-10\nsamples, we observe that even SOTA membership inference attacks cannot do\nbetter than random guessing.", "AI": {"tldr": "AMUN is a new machine unlearning method using adversarial examples to effectively delete forget datasets while maintaining model accuracy.", "motivation": "Addressing the computational overhead of exact unlearning and the ineffectiveness of approximate methods in maintaining model accuracy and confidence.", "method": "AMUN fine-tunes the model on adversarial examples closest to forget samples to localize changes and preserve global behavior.", "result": "AMUN outperforms SOTA methods, reducing membership inference attack success to random guessing levels.", "conclusion": "AMUN provides an effective and efficient solution for machine unlearning, balancing accuracy and privacy."}}
{"id": "2504.20119", "pdf": "https://arxiv.org/pdf/2504.20119", "abs": "https://arxiv.org/abs/2504.20119", "authors": ["Lorenz Brehme", "Thomas Str\u00f6hle", "Ruth Breu"], "title": "Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets", "categories": ["cs.IR", "cs.AI"], "comment": "8 Pages. This paper has been accepted for presentation at the IEEE\n  Swiss Conference on Data Science (SDS25)", "summary": "Retrieval-Augmented Generation (RAG) has advanced significantly in recent\nyears. The complexity of RAG systems, which involve multiple components-such as\nindexing, retrieval, and generation-along with numerous other parameters, poses\nsubstantial challenges for systematic evaluation and quality enhancement.\nPrevious research highlights that evaluating RAG systems is essential for\ndocumenting advancements, comparing configurations, and identifying effective\napproaches for domain-specific applications. This study systematically reviews\n63 academic articles to provide a comprehensive overview of state-of-the-art\nRAG evaluation methodologies, focusing on four key areas: datasets, retrievers,\nindexing and databases, and the generator component. We observe the feasibility\nof an automated evaluation approach for each component of a RAG system,\nleveraging an LLM capable of both generating evaluation datasets and conducting\nevaluations. In addition, we found that further practical research is essential\nto provide companies with clear guidance on the do's and don'ts of implementing\nand evaluating RAG systems. By synthesizing evaluation approaches for key RAG\ncomponents and emphasizing the creation and adaptation of domain-specific\ndatasets for benchmarking, we contribute to the advancement of systematic\nevaluation methods and the improvement of evaluation rigor for RAG systems.\nFurthermore, by examining the interplay between automated approaches leveraging\nLLMs and human judgment, we contribute to the ongoing discourse on balancing\nautomation and human input, clarifying their respective contributions,\nlimitations, and challenges in achieving robust and reliable evaluations.", "AI": {"tldr": "The paper reviews 63 articles to summarize RAG evaluation methods, focusing on datasets, retrievers, indexing, and generators, and proposes automated evaluation using LLMs.", "motivation": "The complexity of RAG systems and the need for systematic evaluation to document advancements and guide implementations.", "method": "Systematic review of 63 academic articles to analyze evaluation methodologies for RAG components.", "result": "Feasibility of automated evaluation using LLMs and the need for domain-specific datasets and practical research.", "conclusion": "The study advances systematic RAG evaluation methods and highlights the balance between automation and human judgment."}}
{"id": "2504.03359", "pdf": "https://arxiv.org/pdf/2504.03359", "abs": "https://arxiv.org/abs/2504.03359", "authors": ["Samuel Bilson", "Maurice Cox", "Anna Pustogvar", "Andrew Thompson"], "title": "A metrological framework for uncertainty evaluation in machine learning classification models", "categories": ["cs.LG"], "comment": "47 pages, 7 figures", "summary": "Machine learning (ML) classification models are increasingly being used in a\nwide range of applications where it is important that predictions are\naccompanied by uncertainties, including in climate and earth observation,\nmedical diagnosis and bioaerosol monitoring. The output of an ML classification\nmodel is a type of categorical variable known as a nominal property in the\nInternational Vocabulary of Metrology (VIM). However, concepts related to\nuncertainty evaluation for nominal properties are not defined in the VIM, nor\nis such evaluation addressed by the Guide to the Expression of Uncertainty in\nMeasurement (GUM). In this paper we propose a metrological conceptual\nuncertainty evaluation framework for ML classification, and illustrate its use\nin the context of two applications that exemplify the issues and have\nsignificant societal impact, namely, climate and earth observation and medical\ndiagnosis. Our framework would enable an extension of the VIM and GUM to\nuncertainty for nominal properties, which would make both applicable to ML\nclassification models.", "AI": {"tldr": "Proposes a metrological framework for evaluating uncertainty in ML classification models, addressing gaps in VIM and GUM for nominal properties.", "motivation": "Current standards (VIM and GUM) lack definitions and methods for uncertainty evaluation in nominal properties, which are critical for ML classification applications like climate observation and medical diagnosis.", "method": "Develops a conceptual uncertainty evaluation framework for ML classification, demonstrated through climate/earth observation and medical diagnosis applications.", "result": "The framework enables extending VIM and GUM to include uncertainty evaluation for nominal properties, making them applicable to ML classification models.", "conclusion": "The proposed framework bridges a gap in metrology for ML classification, enhancing reliability in high-impact applications."}}
{"id": "2504.21036", "pdf": "https://arxiv.org/pdf/2504.21036", "abs": "https://arxiv.org/abs/2504.21036", "authors": ["Hao Du", "Shang Liu", "Yang Cao"], "title": "Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "accepted by DBSec25", "summary": "Fine-tuning large language models (LLMs) has become an essential strategy for\nadapting them to specialized tasks; however, this process introduces\nsignificant privacy challenges, as sensitive training data may be inadvertently\nmemorized and exposed. Although differential privacy (DP) offers strong\ntheoretical guarantees against such leakage, its empirical privacy\neffectiveness on LLMs remains unclear, especially under different fine-tuning\nmethods. In this paper, we systematically investigate the impact of DP across\nfine-tuning methods and privacy budgets, using both data extraction and\nmembership inference attacks to assess empirical privacy risks. Our main\nfindings are as follows: (1) Differential privacy reduces model utility, but\nits impact varies significantly across different fine-tuning methods. (2)\nWithout DP, the privacy risks of models fine-tuned with different approaches\ndiffer considerably. (3) When DP is applied, even a relatively high privacy\nbudget can substantially lower privacy risk. (4) The privacy-utility trade-off\nunder DP training differs greatly among fine-tuning methods, with some methods\nbeing unsuitable for DP due to severe utility degradation. Our results provide\npractical guidance for privacy-conscious deployment of LLMs and pave the way\nfor future research on optimizing the privacy-utility trade-off in fine-tuning\nmethodologies.", "AI": {"tldr": "The paper examines the effectiveness of differential privacy (DP) in fine-tuning large language models (LLMs), finding that DP reduces utility but lowers privacy risks, with trade-offs varying by fine-tuning method.", "motivation": "Address privacy challenges in LLM fine-tuning, where sensitive data may be exposed, and assess DP's empirical effectiveness.", "method": "Systematically evaluate DP's impact using data extraction and membership inference attacks across fine-tuning methods and privacy budgets.", "result": "DP reduces utility and privacy risks, with trade-offs varying by method; some methods are unsuitable for DP due to severe utility loss.", "conclusion": "Provides guidance for privacy-conscious LLM deployment and suggests future research on optimizing privacy-utility trade-offs."}}
{"id": "2504.04798", "pdf": "https://arxiv.org/pdf/2504.04798", "abs": "https://arxiv.org/abs/2504.04798", "authors": ["Jacob Si", "Zijing Ou", "Mike Qu", "Zhengrui Xiang", "Yingzhen Li"], "title": "TabRep: Training Tabular Diffusion Models with a Simple and Effective Continuous Representation", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models have been the predominant generative model for tabular data\ngeneration. However, they face the conundrum of modeling under a separate\nversus a unified data representation. The former encounters the challenge of\njointly modeling all multi-modal distributions of tabular data in one model.\nWhile the latter alleviates this by learning a single representation for all\nfeatures, it currently leverages sparse suboptimal encoding heuristics and\nnecessitates additional computation costs. In this work, we address the latter\nby presenting TabRep, a tabular diffusion architecture trained with a unified\ncontinuous representation. To motivate the design of our representation, we\nprovide geometric insights into how the data manifold affects diffusion models.\nThe key attributes of our representation are composed of its density,\nflexibility to provide ample separability for nominal features, and ability to\npreserve intrinsic relationships. Ultimately, TabRep provides a simple yet\neffective approach for training tabular diffusion models under a continuous\ndata manifold. Our results showcase that TabRep achieves superior performance\nacross a broad suite of evaluations. It is the first to synthesize tabular data\nthat exceeds the downstream quality of the original datasets while preserving\nprivacy and remaining computationally efficient.", "AI": {"tldr": "TabRep is a tabular diffusion model using a unified continuous representation, addressing challenges in joint modeling and encoding heuristics, achieving superior performance and privacy preservation.", "motivation": "Addressing the challenges of modeling multi-modal distributions in tabular data and improving upon sparse suboptimal encoding heuristics in unified representations.", "method": "Introduces TabRep, a tabular diffusion architecture with a unified continuous representation, leveraging geometric insights for design.", "result": "TabRep outperforms in evaluations, synthesizing data that exceeds original dataset quality while being privacy-preserving and efficient.", "conclusion": "TabRep offers a simple, effective solution for tabular diffusion models, balancing performance, privacy, and computational efficiency."}}
{"id": "2504.21155", "pdf": "https://arxiv.org/pdf/2504.21155", "abs": "https://arxiv.org/abs/2504.21155", "authors": ["Fauzan Nazranda Rizqan", "Matthew Hole", "Charles Gretton"], "title": "Evaluation and Verification of Physics-Informed Neural Models of the Grad-Shafranov Equation", "categories": ["physics.plasm-ph", "cs.AI", "cs.NE"], "comment": "9 pages, 4 figures", "summary": "Our contributions are motivated by fusion reactors that rely on maintaining\nmagnetohydrodynamic (MHD) equilibrium, where the balance between plasma\npressure and confining magnetic fields is required for stable operation. In\naxisymmetric tokamak reactors in particular, and under the assumption of\ntoroidal symmetry, this equilibrium can be mathematically modelled using the\nGrad-Shafranov Equation (GSE). Recent works have demonstrated the potential of\nusing Physics-Informed Neural Networks (PINNs) to model the GSE. Existing\nstudies did not examine realistic scenarios in which a single network\ngeneralizes to a variety of boundary conditions. Addressing that limitation, we\nevaluate a PINN architecture that incorporates boundary points as network\ninputs. Additionally, we compare PINN model accuracy and inference speeds with\na Fourier Neural Operator (FNO) model. Finding the PINN model to be the most\nperformant, and accurate in our setting, we use the network verification tool\nMarabou to perform a range of verification tasks. Although we find some\ndiscrepancies between evaluations of the networks natively in PyTorch, compared\nto via Marabou, we are able to demonstrate useful and practical verification\nworkflows. Our study is the first investigation of verification of such\nnetworks.", "AI": {"tldr": "The paper proposes using Physics-Informed Neural Networks (PINNs) to model the Grad-Shafranov Equation (GSE) for fusion reactors, addressing generalization to various boundary conditions and comparing PINNs with Fourier Neural Operators (FNOs). It also introduces network verification using Marabou.", "motivation": "The study is motivated by the need for stable MHD equilibrium in fusion reactors, particularly axisymmetric tokamaks, where the GSE models the balance between plasma pressure and magnetic fields. Existing PINN studies lacked generalization to diverse boundary conditions.", "method": "The authors evaluate a PINN architecture that includes boundary points as inputs and compare its accuracy and speed with an FNO model. They also use Marabou for network verification.", "result": "PINNs outperform FNOs in accuracy and performance. Verification with Marabou reveals some discrepancies but demonstrates practical workflows.", "conclusion": "This is the first study to verify such networks, showing PINNs' effectiveness for GSE modeling and introducing useful verification methods."}}
{"id": "2504.07835", "pdf": "https://arxiv.org/pdf/2504.07835", "abs": "https://arxiv.org/abs/2504.07835", "authors": ["Erin Carson", "Xinye Chen"], "title": "Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Motivated by the growing demand for low-precision arithmetic in computational\nscience, we exploit lower-precision emulation in Python -- widely regarded as\nthe dominant programming language for numerical analysis and machine learning.\nLow-precision training has revolutionized deep learning by enabling more\nefficient computation and reduced memory and energy consumption while\nmaintaining model fidelity. To better enable numerical experimentation with and\nexploration of low precision computation, we developed the Pychop library,\nwhich supports customizable floating-point formats and a comprehensive set of\nrounding modes in Python, allowing users to benefit from fast, low-precision\nemulation in numerous applications. Pychop also introduces interfaces for both\nPyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural\nnetwork training and inference with unparalleled flexibility.\n  In this paper, we offer a comprehensive exposition of the design,\nimplementation, validation, and practical application of Pychop, establishing\nit as a foundational tool for advancing efficient mixed-precision algorithms.\nFurthermore, we present empirical results on low-precision emulation for image\nclassification and object detection using published datasets, illustrating the\nsensitivity of the use of low precision and offering valuable insights into its\nimpact. Pychop enables in-depth investigations into the effects of numerical\nprecision, facilitates the development of novel hardware accelerators, and\nintegrates seamlessly into existing deep learning workflows. Software and\nexperimental code are publicly available at\nhttps://github.com/inEXASCALE/pychop.", "AI": {"tldr": "The paper introduces Pychop, a Python library for low-precision arithmetic emulation, supporting customizable floating-point formats and rounding modes. It integrates with PyTorch and JAX for GPU-based neural network training and inference, validated through empirical studies on image classification and object detection.", "motivation": "The demand for low-precision arithmetic in computational science and deep learning, aiming for efficient computation, reduced memory, and energy savings while maintaining model accuracy.", "method": "Development of the Pychop library, offering customizable low-precision emulation in Python, with interfaces for PyTorch and JAX. Validation through empirical studies on image classification and object detection.", "result": "Pychop enables efficient low-precision emulation, supports mixed-precision algorithms, and integrates into deep learning workflows. Empirical results highlight the impact of low precision on model performance.", "conclusion": "Pychop is a foundational tool for advancing mixed-precision algorithms, facilitating hardware accelerator development, and seamless integration into deep learning workflows."}}
{"id": "2504.21489", "pdf": "https://arxiv.org/pdf/2504.21489", "abs": "https://arxiv.org/abs/2504.21489", "authors": ["Shirin Anlen", "Zuzanna Wojciak"], "title": "TRIED: Truly Innovative and Effective AI Detection Benchmark, developed by WITNESS", "categories": ["cs.CY", "cs.AI"], "comment": "33 pages", "summary": "The proliferation of generative AI and deceptive synthetic media threatens\nthe global information ecosystem, especially across the Global Majority. This\nreport from WITNESS highlights the limitations of current AI detection tools,\nwhich often underperform in real-world scenarios due to challenges related to\nexplainability, fairness, accessibility, and contextual relevance. In response,\nWITNESS introduces the Truly Innovative and Effective AI Detection (TRIED)\nBenchmark, a new framework for evaluating detection tools based on their\nreal-world impact and capacity for innovation. Drawing on frontline\nexperiences, deceptive AI cases, and global consultations, the report outlines\nhow detection tools must evolve to become truly innovative and relevant by\nmeeting diverse linguistic, cultural, and technological contexts. It offers\npractical guidance for developers, policy actors, and standards bodies to\ndesign accountable, transparent, and user-centered detection solutions, and\nincorporate sociotechnical considerations into future AI standards, procedures\nand evaluation frameworks. By adopting the TRIED Benchmark, stakeholders can\ndrive innovation, safeguard public trust, strengthen AI literacy, and\ncontribute to a more resilient global information credibility.", "AI": {"tldr": "The report introduces the TRIED Benchmark to evaluate AI detection tools, addressing their shortcomings in real-world scenarios and emphasizing innovation, fairness, and contextual relevance.", "motivation": "The rise of deceptive AI media threatens information integrity, especially in the Global Majority, highlighting the need for better detection tools.", "method": "WITNESS proposes the TRIED Benchmark, a framework based on real-world impact, innovation, and sociotechnical considerations, informed by frontline experiences and global consultations.", "result": "The TRIED Benchmark aims to improve detection tools by ensuring they are accountable, transparent, and adaptable to diverse contexts.", "conclusion": "Adopting the TRIED Benchmark can enhance AI detection, foster public trust, and strengthen global information credibility."}}
{"id": "2504.12561", "pdf": "https://arxiv.org/pdf/2504.12561", "abs": "https://arxiv.org/abs/2504.12561", "authors": ["Akira Tamamori"], "title": "Kernel Ridge Regression for Efficient Learning of High-Capacity Hopfield Networks", "categories": ["cs.LG", "cs.NE"], "comment": "6 pages, 3 figures, 1 table. Changed to APSIPA ASC 2025 format", "summary": "Hopfield networks using Hebbian learning suffer from limited storage\ncapacity. While supervised methods like Linear Logistic Regression (LLR) offer\nsome improvement, kernel methods like Kernel Logistic Regression (KLR)\nsignificantly enhance capacity and noise robustness. However, KLR requires\ncomputationally expensive iterative learning. We propose Kernel Ridge\nRegression (KRR) as an efficient kernel-based alternative for learning\nhigh-capacity Hopfield networks. KRR utilizes the kernel trick and predicts\nbipolar states via regression, crucially offering a non-iterative, closed-form\nsolution for learning dual variables. We evaluate KRR and compare its\nperformance against Hebbian, LLR, and KLR. Our results demonstrate that KRR\nachieves state-of-the-art storage capacity (reaching $\\beta$=1.5) and noise\nrobustness, comparable to KLR. Crucially, KRR drastically reduces training\ntime, being orders of magnitude faster than LLR and significantly faster than\nKLR, especially at higher storage loads. This establishes KRR as a potent and\nhighly efficient method for building high-performance associative memories,\nproviding comparable performance to KLR with substantial training speed\nadvantages. This work provides the first empirical comparison between KRR and\nKLR in the context of Hopfield network learning.", "AI": {"tldr": "Kernel Ridge Regression (KRR) is proposed as an efficient, non-iterative alternative to Kernel Logistic Regression (KLR) for high-capacity Hopfield networks, offering comparable performance with faster training.", "motivation": "Hopfield networks using Hebbian learning have limited storage capacity, and while supervised methods like KLR improve this, they are computationally expensive.", "method": "KRR uses the kernel trick and regression to predict bipolar states, providing a closed-form solution for learning dual variables.", "result": "KRR achieves state-of-the-art storage capacity (\u03b2=1.5) and noise robustness, matching KLR, while drastically reducing training time.", "conclusion": "KRR is a highly efficient method for high-performance associative memories, offering KLR-like performance with significant speed advantages."}}
{"id": "2504.17066", "pdf": "https://arxiv.org/pdf/2504.17066", "abs": "https://arxiv.org/abs/2504.17066", "authors": ["Kewen Peng", "Yicheng Yang", "Hao Zhuo"], "title": "Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching", "categories": ["cs.LG", "cs.CY", "cs.SE", "stat.ML"], "comment": null, "summary": "Fairness-aware learning aims to mitigate discrimination against specific\nprotected social groups (e.g., those categorized by gender, ethnicity, age)\nwhile minimizing predictive performance loss. Despite efforts to improve\nfairness in machine learning, prior studies have shown that many models remain\nunfair when measured against various fairness metrics. In this paper, we\nexamine whether the way training and testing data are sampled affects the\nreliability of reported fairness metrics. Since training and test sets are\noften randomly sampled from the same population, bias present in the training\ndata may still exist in the test data, potentially skewing fairness\nassessments. To address this, we propose FairMatch, a post-processing method\nthat applies propensity score matching to evaluate and mitigate bias. FairMatch\nidentifies control and treatment pairs with similar propensity scores in the\ntest set and adjusts decision thresholds for different subgroups accordingly.\nFor samples that cannot be matched, we perform probabilistic calibration using\nfairness-aware loss functions. Experimental results demonstrate that our\napproach can (a) precisely locate subsets of the test data where the model is\nunbiased, and (b) significantly reduce bias on the remaining data. Overall,\npropensity score matching offers a principled way to improve both fairness\nevaluation and mitigation, without sacrificing predictive performance.", "AI": {"tldr": "FairMatch, a post-processing method using propensity score matching, improves fairness evaluation and mitigation without losing predictive performance.", "motivation": "To address unreliable fairness metrics due to biased sampling in training and test data.", "method": "Proposes FairMatch, which uses propensity score matching to adjust decision thresholds and probabilistic calibration for unmatched samples.", "result": "Identifies unbiased subsets and reduces bias significantly without performance loss.", "conclusion": "Propensity score matching enhances fairness evaluation and mitigation effectively."}}
{"id": "2504.17074", "pdf": "https://arxiv.org/pdf/2504.17074", "abs": "https://arxiv.org/abs/2504.17074", "authors": ["William R. Keely", "Otto Lamminp\u00e4\u00e4", "Steffen Mauceri", "Sean M. R. Crowell", "Christopher W. O'Dell", "Gregory R. McGarragh"], "title": "Conditional Diffusion-Based Retrieval of Atmospheric CO2 from Earth Observing Spectroscopy", "categories": ["cs.LG", "astro-ph.IM"], "comment": "Published as a workshop paper in \"Tackling Climate Change with\n  Machine Learning\", ICLR 2025 Workshop on Tackling Climate Change with Machine\n  Learning. https://www.climatechange.ai/papers/iclr2025/12", "summary": "Satellite-based estimates of greenhouse gas (GHG) properties from\nobservations of reflected solar spectra are integral for understanding and\nmonitoring complex terrestrial systems and their impact on the carbon cycle due\nto their near global coverage. Known as retrieval, making GHG concentration\nestimations from these observations is a non-linear Bayesian inverse problem,\nwhich is operationally solved using a computationally expensive algorithm\ncalled Optimal Estimation (OE), providing a Gaussian approximation to a\nnon-Gaussian posterior. This leads to issues in solver algorithm convergence,\nand to unrealistically confident uncertainty estimates for the retrieved\nquantities. Upcoming satellite missions will provide orders of magnitude more\ndata than the current constellation of GHG observers. Development of fast and\naccurate retrieval algorithms with robust uncertainty quantification is\ncritical. Doing so stands to provide substantial climate impact of moving\ntowards the goal of near continuous real-time global monitoring of carbon\nsources and sinks which is essential for policy making. To achieve this goal,\nwe propose a diffusion-based approach to flexibly retrieve a Gaussian or\nnon-Gaussian posterior, for NASA's Orbiting Carbon Observatory-2 spectrometer,\nwhile providing a substantial computational speed-up over the current\noperational state-of-the-art.", "AI": {"tldr": "A diffusion-based method is proposed for faster, accurate GHG retrieval from satellite data, addressing limitations of current Optimal Estimation (OE) methods.", "motivation": "Current OE methods for GHG retrieval are computationally expensive, provide unrealistic uncertainty estimates, and may not handle the increased data volume from upcoming satellite missions.", "method": "The paper proposes a diffusion-based approach to retrieve GHG concentrations, offering flexibility for Gaussian or non-Gaussian posterior distributions and computational efficiency.", "result": "The method provides a significant computational speed-up over OE while maintaining accuracy, enabling near real-time global GHG monitoring.", "conclusion": "This approach advances GHG retrieval capabilities, supporting policy-making with robust, scalable solutions for future satellite missions."}}
{"id": "2504.18506", "pdf": "https://arxiv.org/pdf/2504.18506", "abs": "https://arxiv.org/abs/2504.18506", "authors": ["Sanjeev Raja", "Martin \u0160\u00edpka", "Michael Psenka", "Tobias Kreiman", "Michal Pavelka", "Aditi S. Krishnapriyan"], "title": "Action-Minimization Meets Generative Modeling: Efficient Transition Path Sampling with the Onsager-Machlup Functional", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph", "q-bio.BM"], "comment": "ICML 2025", "summary": "Transition path sampling (TPS), which involves finding probable paths\nconnecting two points on an energy landscape, remains a challenge due to the\ncomplexity of real-world atomistic systems. Current machine learning approaches\nuse expensive, task-specific, and data-free training procedures, limiting their\nability to benefit from recent advances in atomistic machine learning, such as\nhigh-quality datasets and large-scale pre-trained models. In this work, we\naddress TPS by interpreting candidate paths as trajectories sampled from\nstochastic dynamics induced by the learned score function of pre-trained\ngenerative models, specifically denoising diffusion and flow matching. Under\nthese dynamics, finding high-likelihood transition paths becomes equivalent to\nminimizing the Onsager-Machlup (OM) action functional. This enables us to\nrepurpose pre-trained generative models for TPS in a zero-shot manner, in\ncontrast with bespoke, task-specific TPS models trained in previous work. We\ndemonstrate our approach on varied molecular systems, obtaining diverse,\nphysically realistic transition pathways and generalizing beyond the\npre-trained model's original training dataset. Our method can be easily\nincorporated into new generative models, making it practically relevant as\nmodels continue to scale and improve with increased data availability.", "AI": {"tldr": "The paper proposes a zero-shot method for Transition Path Sampling (TPS) using pre-trained generative models, avoiding task-specific training and leveraging stochastic dynamics for efficient path sampling.", "motivation": "Current TPS methods are limited by expensive, task-specific training and cannot utilize advances in atomistic machine learning like pre-trained models and datasets.", "method": "Interprets paths as trajectories from stochastic dynamics of pre-trained generative models (denoising diffusion, flow matching), minimizing the Onsager-Machlup action functional.", "result": "Demonstrates diverse, realistic transition paths on molecular systems, generalizing beyond the training data.", "conclusion": "The method repurposes pre-trained models for TPS efficiently, is scalable, and adaptable to future generative models."}}
{"id": "2504.19602", "pdf": "https://arxiv.org/pdf/2504.19602", "abs": "https://arxiv.org/abs/2504.19602", "authors": ["Kitsuya Azuma", "Takayuki Nishio", "Yuichi Kitagawa", "Wakako Nakano", "Takahito Tanimura"], "title": "Soft-Label Caching and Sharpening for Communication-Efficient Federated Distillation", "categories": ["cs.LG"], "comment": "15 pages, 12 figures", "summary": "Federated Learning (FL) enables collaborative model training across\ndecentralized clients, enhancing privacy by keeping data local. Yet\nconventional FL, relying on frequent parameter-sharing, suffers from high\ncommunication overhead and limited model heterogeneity. Distillation-based FL\napproaches address these issues by sharing predictions (soft-labels) instead,\nbut they often involve redundant transmissions across communication rounds,\nreducing efficiency. We propose SCARLET, a novel framework integrating\nsynchronized soft-label caching and an enhanced Entropy Reduction Aggregation\n(Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing\ncached soft-labels, achieving up to 50% reduction in communication costs\ncompared to existing methods while maintaining accuracy. Enhanced ERA can be\ntuned to adapt to non-IID data variations, ensuring robust aggregation and\nperformance in diverse client scenarios. Experimental evaluations demonstrate\nthat SCARLET consistently outperforms state-of-the-art distillation-based FL\nmethods in terms of accuracy and communication efficiency. The implementation\nof SCARLET is publicly available at https://github.com/kitsuyaazuma/SCARLET.", "AI": {"tldr": "SCARLET is a federated learning framework that reduces communication costs by 50% using synchronized soft-label caching and Enhanced ERA, outperforming existing methods in accuracy and efficiency.", "motivation": "Conventional FL suffers from high communication overhead and limited model heterogeneity, while existing distillation-based FL methods have redundant transmissions.", "method": "SCARLET integrates synchronized soft-label caching and an Enhanced Entropy Reduction Aggregation (Enhanced ERA) mechanism to minimize redundant communication.", "result": "Achieves up to 50% reduction in communication costs while maintaining accuracy, outperforming state-of-the-art distillation-based FL methods.", "conclusion": "SCARLET is an efficient and accurate solution for federated learning, adaptable to non-IID data and diverse client scenarios."}}
{"id": "2301.06987", "pdf": "https://arxiv.org/pdf/2301.06987", "abs": "https://arxiv.org/abs/2301.06987", "authors": ["Bassel El Mabsout", "Shahin Roozkhosh", "Siddharth Mysore", "Kate Saenko", "Renato Mancuso"], "title": "Sim-Anchored Learning for On-the-Fly Adaptation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Fine-tuning simulation-trained RL agents with real-world data often degrades\ncrucial behaviors due to limited or skewed data distributions. We argue that\ndesigner priorities exist not just in reward functions, but also in simulation\ndesign choices like task selection and state initialization. When adapting to\nreal-world data, agents can experience catastrophic forgetting in important but\nunderrepresented scenarios. We propose framing live-adaptation as a\nmulti-objective optimization problem, where policy objectives must be satisfied\nboth in simulation and reality. Our approach leverages critics from simulation\nas \"anchors for design intent\" (anchor critics). By jointly optimizing policies\nagainst both anchor critics and critics trained on real-world experience, our\nmethod enables adaptation while preserving prioritized behaviors from\nsimulation. Evaluations demonstrate robust behavior retention in sim-to-sim\nbenchmarks and a sim-to-real scenario with a racing quadrotor, allowing for\npower consumption reductions of up to 50% without control loss. We also\ncontribute SwaNNFlight, an open-source firmware for enabling live adaptation on\nsimilar robotic platforms.", "AI": {"tldr": "The paper proposes a method to fine-tune RL agents with real-world data while preserving crucial behaviors by using anchor critics from simulation and multi-objective optimization.", "motivation": "Fine-tuning RL agents with real-world data often degrades important behaviors due to skewed data distributions, highlighting the need to preserve designer priorities during adaptation.", "method": "The approach frames live-adaptation as multi-objective optimization, using simulation critics (anchor critics) alongside real-world critics to jointly optimize policies.", "result": "The method retains prioritized behaviors in sim-to-sim benchmarks and a sim-to-real quadrotor scenario, achieving up to 50% power reduction without control loss.", "conclusion": "The proposed method effectively balances adaptation and behavior retention, demonstrated by successful sim-to-real transfer and the release of open-source firmware (SwaNNFlight)."}}
{"id": "2302.00316", "pdf": "https://arxiv.org/pdf/2302.00316", "abs": "https://arxiv.org/abs/2302.00316", "authors": ["Michael Muehlebach", "Michael I. Jordan"], "title": "Accelerated First-Order Optimization under Nonlinear Constraints", "categories": ["math.OC", "cs.LG", "eess.SP", "stat.ML"], "comment": "44 pages, 6 figures", "summary": "We exploit analogies between first-order algorithms for constrained\noptimization and non-smooth dynamical systems to design a new class of\naccelerated first-order algorithms for constrained optimization. Unlike\nFrank-Wolfe or projected gradients, these algorithms avoid optimization over\nthe entire feasible set at each iteration. We prove convergence to stationary\npoints even in a nonconvex setting and we derive accelerated rates for the\nconvex setting both in continuous time, as well as in discrete time. An\nimportant property of these algorithms is that constraints are expressed in\nterms of velocities instead of positions, which naturally leads to sparse,\nlocal and convex approximations of the feasible set (even if the feasible set\nis nonconvex). Thus, the complexity tends to grow mildly in the number of\ndecision variables and in the number of constraints, which makes the algorithms\nsuitable for machine learning applications. We apply our algorithms to a\ncompressed sensing and a sparse regression problem, showing that we can treat\nnonconvex $\\ell^p$ constraints ($p<1$) efficiently, while recovering\nstate-of-the-art performance for $p=1$.", "AI": {"tldr": "A new class of accelerated first-order algorithms for constrained optimization is introduced, leveraging analogies with non-smooth dynamical systems. These algorithms avoid full feasible set optimization per iteration, offering efficiency and scalability.", "motivation": "To address inefficiencies in existing methods like Frank-Wolfe or projected gradients, which require optimization over the entire feasible set at each iteration.", "method": "The algorithms use velocity-based constraints, enabling sparse, local, and convex approximations of the feasible set, even if nonconvex. Convergence is proven for nonconvex settings, with accelerated rates for convex cases.", "result": "The algorithms demonstrate mild complexity growth with decision variables and constraints, making them suitable for machine learning. Applications in compressed sensing and sparse regression show efficient handling of nonconvex constraints.", "conclusion": "The proposed algorithms offer scalable and efficient solutions for constrained optimization, particularly in machine learning, with proven convergence and performance comparable to state-of-the-art methods."}}
{"id": "2312.02277", "pdf": "https://arxiv.org/pdf/2312.02277", "abs": "https://arxiv.org/abs/2312.02277", "authors": ["Bokun Wang", "Tianbao Yang"], "title": "A Near-Optimal Single-Loop Stochastic Algorithm for Convex Finite-Sum Coupled Compositional Optimization", "categories": ["math.OC", "cs.LG"], "comment": "To appear in ICML 2025", "summary": "This paper studies a class of convex Finite-sum Coupled Compositional\nOptimization (cFCCO) problems with applications including group\ndistributionally robust optimization (GDRO) and learning with imbalanced data.\nTo better address these problems, we introduce an efficient single-loop\nprimal-dual block-coordinate stochastic algorithm called ALEXR. The algorithm\nemploys block-coordinate stochastic mirror ascent with extrapolation for the\ndual variable and stochastic proximal gradient descent updates for the primal\nvariable. We establish the convergence rates of ALEXR in both convex and\nstrongly convex cases under smoothness and non-smoothness conditions of\ninvolved functions, which not only improve the best rates in previous works on\nsmooth cFCCO problems but also expand the realm of cFCCO for solving more\nchallenging non-smooth problems such as the dual form of GDRO. Finally, we\nderive lower complexity bounds, demonstrating the (near-)optimality of ALEXR\nwithin a broad class of stochastic algorithms for cFCCO. Experimental results\non GDRO and partial Area Under the ROC Curve (pAUC) maximization demonstrate\nthe promising performance of our algorithm.", "AI": {"tldr": "The paper introduces ALEXR, a primal-dual block-coordinate stochastic algorithm for convex Finite-sum Coupled Compositional Optimization (cFCCO), improving convergence rates and handling non-smooth problems like GDRO.", "motivation": "Address challenges in cFCCO problems, including GDRO and imbalanced data learning, by proposing a more efficient algorithm.", "method": "ALEXR combines block-coordinate stochastic mirror ascent (dual) and stochastic proximal gradient descent (primal).", "result": "Improved convergence rates for smooth/non-smooth cFCCO, with near-optimality shown via lower bounds.", "conclusion": "ALEXR outperforms prior methods, validated by experiments on GDRO and pAUC maximization."}}
{"id": "2405.19683", "pdf": "https://arxiv.org/pdf/2405.19683", "abs": "https://arxiv.org/abs/2405.19683", "authors": ["Jimmy Dani", "Kalyan Nakka", "Nitesh Saxena"], "title": "A Machine Learning-Based Framework for Assessing Cryptographic Indistinguishability of Lightweight Block Ciphers", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Indistinguishability is a fundamental principle of cryptographic security,\ncrucial for securing data transmitted between Internet of Things (IoT) devices.\nThis principle ensures that an attacker cannot distinguish between the\nencrypted data, also known as ciphertext, and random data or the ciphertexts of\nthe two messages encrypted with the same key. This research investigates the\nability of machine learning (ML) in assessing indistinguishability property in\nencryption systems, with a focus on lightweight ciphers. As our first case\nstudy, we consider the SPECK32/64 and SIMON32/64 lightweight block ciphers,\ndesigned for IoT devices operating under significant energy constraints.\n  In this research, we introduce MIND-Crypt, a novel ML-based framework\ndesigned to assess the cryptographic indistinguishability of lightweight block\nciphers, specifically the SPECK32/64 and SIMON32/64 encryption algorithm in CBC\nmode (Cipher Block Chaining), under Known Plaintext Attacks (KPA). Our approach\ninvolves training ML models using ciphertexts from two plaintext messages\nencrypted with same key to determine whether ML algorithms can identify\nmeaningful cryptographic patterns or leakage. Our experiments show that modern\nML techniques consistently achieve accuracy equivalent to random guessing,\nindicating that no statistically exploitable patterns exists in the ciphertexts\ngenerated by considered lightweight block ciphers. Furthermore, we demonstrate\nthat in ML algorithms with all the possible combinations of the ciphertexts for\ngiven plaintext messages reflects memorization rather than generalization to\nunseen ciphertexts.\n  Collectively, these findings suggest that existing block ciphers have secure\ncryptographic designs against ML-based indistinguishability assessments,\nreinforcing their security even under round-reduced conditions.", "AI": {"tldr": "The paper introduces MIND-Crypt, an ML framework to assess indistinguishability in lightweight ciphers like SPECK32/64 and SIMON32/64. Results show ML cannot exploit patterns, confirming cipher security.", "motivation": "To evaluate if ML can detect cryptographic patterns in lightweight ciphers, ensuring their security in IoT applications.", "method": "MIND-Crypt trains ML models on ciphertexts from two plaintexts encrypted with the same key, testing for exploitable patterns.", "result": "ML models perform no better than random guessing, indicating no exploitable patterns in ciphertexts.", "conclusion": "Lightweight ciphers like SPECK32/64 and SIMON32/64 are secure against ML-based indistinguishability tests."}}
{"id": "2406.01933", "pdf": "https://arxiv.org/pdf/2406.01933", "abs": "https://arxiv.org/abs/2406.01933", "authors": ["Justin Whitehouse", "Christopher Jung", "Vasilis Syrgkanis", "Bryan Wilder", "Zhiwei Steven Wu"], "title": "Orthogonal Causal Calibration", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "47 pages, 2 figures", "summary": "Estimates of heterogeneous treatment effects such as conditional average\ntreatment effects (CATEs) and conditional quantile treatment effects (CQTEs)\nplay an important role in real-world decision making. Given this importance,\none should ensure these estimates are calibrated. While there is a rich\nliterature on calibrating estimators of non-causal parameters, very few methods\nhave been derived for calibrating estimators of causal parameters, or more\ngenerally estimators of quantities involving nuisance parameters. In this work,\nwe develop general algorithms for reducing the task of causal calibration to\nthat of calibrating a standard (non-causal) predictive model.\n  Throughout, we study a notion of calibration defined with respect to an\narbitrary, nuisance-dependent loss $\\ell$, under which we say an estimator\n$\\theta$ is calibrated if its predictions cannot be changed on any level set to\ndecrease loss. For losses $\\ell$ satisfying a condition called universal\northogonality, we present a simple algorithm that transforms partially-observed\ndata into generalized pseudo-outcomes and applies any off-the-shelf calibration\nprocedure. For losses $\\ell$ satisfying a weaker assumption called conditional\northogonality, we provide a similar sample splitting algorithm the performs\nempirical risk minimization over an appropriately defined class of functions.\nConvergence of both algorithms follows from a generic, two term upper bound of\nthe calibration error of any model. We demonstrate the practical applicability\nof our results in experiments on both observational and synthetic data. Our\nresults are exceedingly general, showing that essentially any existing\ncalibration algorithm can be used in causal settings, with additional loss only\narising from errors in nuisance estimation.", "AI": {"tldr": "The paper introduces algorithms for calibrating causal estimators like CATEs and CQTEs by reducing the task to standard predictive model calibration, applicable to various loss functions and nuisance parameters.", "motivation": "Ensuring calibration of causal estimators is crucial for real-world decision-making, yet existing methods focus on non-causal parameters. This work bridges the gap.", "method": "Develops algorithms for causal calibration: one for universally orthogonal losses and another for conditionally orthogonal losses, leveraging pseudo-outcomes and empirical risk minimization.", "result": "The algorithms reduce calibration error, with convergence guaranteed by a theoretical upper bound. Experiments on observational and synthetic data validate their practicality.", "conclusion": "The approach generalizes existing calibration methods to causal settings, with minimal additional loss from nuisance estimation errors."}}
{"id": "2410.16122", "pdf": "https://arxiv.org/pdf/2410.16122", "abs": "https://arxiv.org/abs/2410.16122", "authors": ["Matthieu Haeberle", "Puck van Gerwen", "Ruben Laplaza", "Ksenia R. Briling", "Jan Weinreich", "Friedrich Eisenbrand", "Clemence Corminboeuf"], "title": "Integer linear programming for unsupervised training set selection in molecular machine learning", "categories": ["physics.chem-ph", "cs.LG"], "comment": "29 pages + SI (15 pages)", "summary": "Integer linear programming (ILP) is an elegant approach to solve linear\noptimization problems, naturally described using integer decision variables.\nWithin the context of physics-inspired machine learning applied to chemistry,\nwe demonstrate the relevance of an ILP formulation to select molecular training\nsets for predictions of size-extensive properties. We show that our algorithm\noutperforms existing unsupervised training set selection approaches, especially\nwhen predicting properties of molecules larger than those present in the\ntraining set. We argue that the reason for the improved performance is due to\nthe selection that is based on the notion of local similarity (i.e., per-atom)\nand a unique ILP approach that finds optimal solutions efficiently. Altogether,\nthis work provides a practical algorithm to improve the performance of\nphysics-inspired machine learning models and offers insights into the\nconceptual differences with existing training set selection approaches.", "AI": {"tldr": "An ILP-based method improves training set selection for physics-inspired ML in chemistry, outperforming unsupervised approaches, especially for larger molecules.", "motivation": "To enhance the performance of physics-inspired machine learning models in chemistry by optimizing training set selection for size-extensive properties.", "method": "Uses integer linear programming (ILP) to select molecular training sets based on local similarity (per-atom) and ensures efficient optimal solutions.", "result": "The ILP-based algorithm outperforms existing unsupervised methods, particularly for predicting properties of larger molecules not in the training set.", "conclusion": "The work provides a practical algorithm for better ML model performance and highlights conceptual differences with existing training set selection methods."}}
{"id": "2502.00935", "pdf": "https://arxiv.org/pdf/2502.00935", "abs": "https://arxiv.org/abs/2502.00935", "authors": ["Kensuke Nakamura", "Lasse Peters", "Andrea Bajcsy"], "title": "Generalizing Safety Beyond Collision-Avoidance via Latent-Space Reachability Analysis", "categories": ["cs.RO", "cs.LG"], "comment": "9 figures, 7 tables, RSS 2025", "summary": "Hamilton-Jacobi (HJ) reachability is a rigorous mathematical framework that\nenables robots to simultaneously detect unsafe states and generate actions that\nprevent future failures. While in theory, HJ reachability can synthesize safe\ncontrollers for nonlinear systems and nonconvex constraints, in practice, it\nhas been limited to hand-engineered collision-avoidance constraints modeled via\nlow-dimensional state-space representations and first-principles dynamics. In\nthis work, our goal is to generalize safe robot controllers to prevent failures\nthat are hard--if not impossible--to write down by hand, but can be intuitively\nidentified from high-dimensional observations: for example, spilling the\ncontents of a bag. We propose Latent Safety Filters, a latent-space\ngeneralization of HJ reachability that tractably operates directly on raw\nobservation data (e.g., RGB images) to automatically compute safety-preserving\nactions without explicit recovery demonstrations by performing safety analysis\nin the latent embedding space of a generative world model. Our method leverages\ndiverse robot observation-action data of varying quality (including successes,\nrandom exploration, and unsafe demonstrations) to learn a world model.\nConstraint specification is then transformed into a classification problem in\nthe latent space of the learned world model. In simulation and hardware\nexperiments, we compute an approximation of Latent Safety Filters to safeguard\narbitrary policies (from imitation- learned policies to direct teleoperation)\nfrom complex safety hazards, like preventing a Franka Research 3 manipulator\nfrom spilling the contents of a bag or toppling cluttered objects.", "AI": {"tldr": "Latent Safety Filters generalize HJ reachability to high-dimensional observations, enabling safe robot control without hand-engineered constraints.", "motivation": "To address complex safety hazards (e.g., spilling) that are hard to model manually but identifiable from high-dimensional data.", "method": "Uses latent-space HJ reachability on raw observations, leveraging a generative world model trained on diverse data.", "result": "Successfully safeguards policies (e.g., imitation, teleoperation) in simulations and hardware, preventing hazards like spills.", "conclusion": "Latent Safety Filters provide a scalable, data-driven approach to safety in high-dimensional robotic tasks."}}
{"id": "2502.05364", "pdf": "https://arxiv.org/pdf/2502.05364", "abs": "https://arxiv.org/abs/2502.05364", "authors": ["Julian Killingback", "Hansi Zeng", "Hamed Zamani"], "title": "Hypencoder: Hypernetworks for Information Retrieval", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Existing information retrieval systems are largely constrained by their\nreliance on vector inner products to assess query-document relevance, which\nnaturally limits the expressiveness of the relevance score they can produce. We\npropose a new paradigm; instead of representing a query as a vector, we use a\nsmall neural network that acts as a learned query-specific relevance function.\nThis small neural network takes a document representation as input (in this\nwork we use a single vector) and produces a scalar relevance score. To produce\nthe small neural network we use a hypernetwork, a network that produces the\nweights of other networks, as our query encoder. We name this category of\nencoder models Hypencoders. Experiments on in-domain search tasks show that\nHypencoders significantly outperform strong dense retrieval models and even\nsurpass reranking models and retrieval models with an order of magnitude more\nparameters. To assess the extent of Hypencoders' capabilities, we evaluate on a\nset of hard retrieval tasks including tip-of-the-tongue and\ninstruction-following retrieval tasks. On harder tasks, we find that the\nperformance gap widens substantially compared to standard retrieval tasks.\nFurthermore, to demonstrate the practicality of our method, we implement an\napproximate search algorithm and show that our model is able to retrieve from a\ncorpus of 8.8M documents in under 60 milliseconds.", "AI": {"tldr": "The paper introduces Hypencoders, a neural network-based approach to improve information retrieval by replacing vector inner products with query-specific relevance functions, outperforming existing models.", "motivation": "Current retrieval systems are limited by vector inner products for relevance scoring, restricting expressiveness. The paper aims to enhance this by using neural networks.", "method": "A hypernetwork generates small neural networks (Hypencoders) as query-specific relevance functions, processing document vectors to produce relevance scores.", "result": "Hypencoders outperform dense retrieval and reranking models, especially in hard tasks like tip-of-the-tongue retrieval, and achieve fast search on large corpora.", "conclusion": "Hypencoders offer a scalable, expressive alternative to traditional retrieval methods, demonstrating superior performance and practicality."}}
{"id": "2502.07837", "pdf": "https://arxiv.org/pdf/2502.07837", "abs": "https://arxiv.org/abs/2502.07837", "authors": ["Sicheng Wang", "Sheng Liu", "Weiheng Wang", "Jianhua Shan", "Bin Fang"], "title": "RoboBERT: An End-to-end Multimodal Robotic Manipulation Model", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Embodied intelligence seamlessly integrates vision, language, and\naction.~However, most multimodal robotic models rely on massive fine-tuning,\nincurring high time and hardware costs.~To address this, we introduce RoboBERT,\nan end-to-end multimodal manipulation model built around a novel two-stage\ntraining paradigm.~In the first stage, we freeze most of the vision encoder and\ntrain with a single \"standard\" instruction phrasing, allowing the model to\nfocus on stable policy learning via a CNN-based diffusion policy.~In the second\nstage, we unfreeze all modules and inject diverse natural language variants,\nrapidly aligning varied instructions to the already-learned policy without\ndestabilizing performance.~We further employ systematic data augmentations to\nenhance robustness against visual perturbations.~Without relying on auxiliary\ndatasets, RoboBERT achieves new state-of-the-art (SOTA) mean episode lengths of\n4.52 on the CALVIN ABCD-D benchmark and 3.79 on the ABC-D benchmark using only\nlanguage-labeled expert demonstrations and a comparatively lightweight\narchitecture.Real-robot trials on a 6-DOF manipulator confirm higher success\nrates than comparable methods trained on identical data.These results\ndemonstrate that our data-augmentation-enhanced two-stage training paradigm\ndelivers efficient, scalable, and broadly applicable performance for multimodal\nrobotic systems.", "AI": {"tldr": "RoboBERT introduces a two-stage training paradigm for efficient multimodal robotic manipulation, achieving SOTA results with minimal fine-tuning and data.", "motivation": "Addressing the high costs of fine-tuning in multimodal robotic models by proposing a more efficient training approach.", "method": "A two-stage training: first, freezing most of the vision encoder for stable policy learning; second, unfreezing and injecting diverse language variants. Includes systematic data augmentation.", "result": "Achieves SOTA mean episode lengths (4.52 on CALVIN ABCD-D, 3.79 on ABC-D) and higher real-robot success rates.", "conclusion": "The two-stage paradigm with data augmentation is efficient, scalable, and broadly applicable for multimodal robotic systems."}}
{"id": "2503.11347", "pdf": "https://arxiv.org/pdf/2503.11347", "abs": "https://arxiv.org/abs/2503.11347", "authors": ["Zhenyi Zhang", "Yuhao Sun", "Qiangwei Peng", "Tiejun Li", "Peijie Zhou"], "title": "Integrating Dynamical Systems Modeling with Spatiotemporal scRNA-seq Data Analysis", "categories": ["q-bio.QM", "cs.LG", "physics.bio-ph"], "comment": null, "summary": "Understanding the dynamic nature of biological systems is fundamental to\ndeciphering cellular behavior, developmental processes, and disease\nprogression. Single-cell RNA sequencing (scRNA-seq) has provided static\nsnapshots of gene expression, offering valuable insights into cellular states\nat a single time point. Recent advancements in temporally resolved scRNA-seq,\nspatial transcriptomics (ST), and time-series spatial transcriptomics\n(temporal-ST) have further revolutionized our ability to study the\nspatiotemporal dynamics of individual cells. These technologies, when combined\nwith computational frameworks such as Markov chains, stochastic differential\nequations (SDEs), and generative models like optimal transport and\nSchr\\\"odinger bridges, enable the reconstruction of dynamic cellular\ntrajectories and cell fate decisions. This review discusses how these dynamical\nsystem approaches offer new opportunities to model and infer cellular dynamics\nfrom a systematic perspective.", "AI": {"tldr": "The paper reviews how dynamical system approaches, combined with advanced sequencing and computational methods, enable modeling of spatiotemporal cellular dynamics.", "motivation": "Understanding biological systems' dynamics is key to studying cellular behavior, development, and disease. Static snapshots from scRNA-seq are limited, necessitating temporally resolved methods.", "method": "The review integrates temporally resolved scRNA-seq, spatial transcriptomics, and computational frameworks like Markov chains, SDEs, and generative models (e.g., optimal transport).", "result": "These approaches reconstruct dynamic cellular trajectories and fate decisions, offering deeper insights into spatiotemporal dynamics.", "conclusion": "Dynamical system methods provide systematic opportunities to model and infer cellular dynamics, advancing biological understanding."}}
{"id": "2504.17811", "pdf": "https://arxiv.org/pdf/2504.17811", "abs": "https://arxiv.org/abs/2504.17811", "authors": ["Anirudhan Badrinath", "Alex Yang", "Kousik Rajesh", "Prabhat Agarwal", "Jaewon Yang", "Haoyu Chen", "Jiajing Xu", "Charles Rosenberg"], "title": "OmniSage: Large Scale, Multi-Entity Heterogeneous Graph Representation Learning", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Representation learning, a task of learning latent vectors to represent\nentities, is a key task in improving search and recommender systems in web\napplications. Various representation learning methods have been developed,\nincluding graph-based approaches for relationships among entities,\nsequence-based methods for capturing the temporal evolution of user activities,\nand content-based models for leveraging text and visual content. However, the\ndevelopment of a unifying framework that integrates these diverse techniques to\nsupport multiple applications remains a significant challenge. This paper\npresents OmniSage, a large-scale representation framework that learns universal\nrepresentations for a variety of applications at Pinterest. OmniSage integrates\ngraph neural networks with content-based models and user sequence models by\nemploying multiple contrastive learning tasks to effectively process graph\ndata, user sequence data, and content signals. To support the training and\ninference of OmniSage, we developed an efficient infrastructure capable of\nsupporting Pinterest graphs with billions of nodes. The universal\nrepresentations generated by OmniSage have significantly enhanced user\nexperiences on Pinterest, leading to an approximate 2.5% increase in sitewide\nrepins (saves) across five applications. This paper highlights the impact of\nunifying representation learning methods, and we will open source the OmniSage\ncode by the time of publication.", "AI": {"tldr": "OmniSage is a unified representation learning framework integrating graph, sequence, and content-based models, enhancing Pinterest's user experience with a 2.5% increase in repins.", "motivation": "The challenge of integrating diverse representation learning methods (graph-based, sequence-based, content-based) into a single framework for multiple applications.", "method": "OmniSage combines graph neural networks, content-based models, and user sequence models using contrastive learning tasks, supported by scalable infrastructure.", "result": "Achieved a 2.5% increase in sitewide repins (saves) across five Pinterest applications.", "conclusion": "OmniSage demonstrates the effectiveness of unifying representation learning methods, with plans to open-source the framework."}}
{"id": "2504.19012", "pdf": "https://arxiv.org/pdf/2504.19012", "abs": "https://arxiv.org/abs/2504.19012", "authors": ["Xizhuo Zhang", "Bing Yao"], "title": "Geometry-aware Active Learning of Spatiotemporal Dynamic Systems", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Rapid developments in advanced sensing and imaging have significantly\nenhanced information visibility, opening opportunities for predictive modeling\nof complex dynamic systems. However, sensing signals acquired from such complex\nsystems are often distributed across 3D geometries and rapidly evolving over\ntime, posing significant challenges in spatiotemporal predictive modeling. This\npaper proposes a geometry-aware active learning framework for modeling\nspatiotemporal dynamic systems. Specifically, we propose a geometry-aware\nspatiotemporal Gaussian Process (G-ST-GP) to effectively integrate the temporal\ncorrelations and geometric manifold features for reliable prediction of\nhigh-dimensional dynamic behaviors. In addition, we develop an adaptive active\nlearning strategy to strategically identify informative spatial locations for\ndata collection and further maximize the prediction accuracy. This strategy\nachieves the adaptive trade-off between the prediction uncertainty in the\nG-ST-GP model and the space-filling design guided by the geodesic distance\nacross the 3D geometry. We implement the proposed framework to model the\nspatiotemporal electrodynamics in a 3D heart geometry. Numerical experiments\nshow that our framework outperforms traditional methods lacking the mechanism\nof geometric information incorporation or effective data collection.", "AI": {"tldr": "A geometry-aware active learning framework for spatiotemporal predictive modeling, integrating temporal correlations and geometric features, outperforming traditional methods.", "motivation": "Address challenges in modeling complex dynamic systems with distributed 3D sensing signals by incorporating geometric and temporal features.", "method": "Proposes a geometry-aware spatiotemporal Gaussian Process (G-ST-GP) and an adaptive active learning strategy for data collection.", "result": "Outperforms traditional methods in modeling spatiotemporal electrodynamics in a 3D heart geometry.", "conclusion": "The framework effectively integrates geometry and temporal dynamics, enhancing predictive accuracy in complex systems."}}
{"id": "2504.19488", "pdf": "https://arxiv.org/pdf/2504.19488", "abs": "https://arxiv.org/abs/2504.19488", "authors": ["Vijay Prakash S"], "title": "Two-parameter superposable S-curves", "categories": ["stat.ME", "cs.LG"], "comment": "14 pages. Some discussion on results and parameter values for bar{m}\n  in the tables are corrected in version 2", "summary": "Straight line equation $y=mx$ with slope $m$, when singularly perturbed as\n$ay^3+y=mx$ with a positive parameter $a$, results in S-shaped curves or\nS-curves on a real plane. As $a\\rightarrow 0$, we get back $y=mx$ which is a\ncumulative distribution function of a continuous uniform distribution that\ndescribes the occurrence of every event in an interval to be equally probable.\nAs $a\\rightarrow\\infty$, the derivative of $y$ has finite support only at $y=0$\nresembling a degenerate distribution. Based on these arguments, in this work,\nwe propose that these S-curves can represent maximum entropy uniform\ndistribution to a zero entropy single value. We also argue that these S-curves\nare superposable as they are only parametrically nonlinear but fundamentally\nlinear. So far, the superposed forms have been used to capture the patterns of\nnatural systems such as nonlinear dynamics of biological growth and kinetics of\nenzyme reactions. Here, we attempt to use the S-curve and its superposed form\nas statistical models. We fit the models on a classical dataset containing\nflower measurements of iris plants and analyze their usefulness in pattern\nrecognition. Based on these models, we claim that any non-uniform pattern can\nbe represented as a singular perturbation to uniform distribution. However, our\nparametric estimation procedure have some limitations such as sensitivity to\ninitial conditions depending on the data at hand.", "AI": {"tldr": "The paper explores S-curves from singularly perturbed straight line equations, proposing them as models for transitioning between uniform and degenerate distributions, and applies them to pattern recognition in iris flower data.", "motivation": "The study aims to bridge the gap between uniform and degenerate distributions using S-curves, leveraging their properties for statistical modeling and pattern recognition.", "method": "The authors use singular perturbation of a straight line equation to generate S-curves, analyze their properties, and apply them as statistical models to iris flower data.", "result": "S-curves effectively model transitions between uniform and degenerate distributions and show promise in pattern recognition, though sensitivity to initial conditions is noted.", "conclusion": "S-curves offer a novel way to represent non-uniform patterns as perturbations of uniform distributions, with potential applications in statistical modeling, despite some limitations."}}
