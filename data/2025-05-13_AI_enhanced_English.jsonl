{"id": "2505.06685", "pdf": "https://arxiv.org/pdf/2505.06685", "abs": "https://arxiv.org/abs/2505.06685", "authors": ["Dawei Huang", "Qing Li", "Chuan Yan", "Zebang Cheng", "Yurong Huang", "Xiang Li", "Bin Li", "Xiaohui Wang", "Zheng Lian", "Xiaojiang Peng"], "title": "Emotion-Qwen: Training Hybrid Experts for Unified Emotion and General Vision-Language Understanding", "categories": ["cs.MM", "cs.CV"], "comment": null, "summary": "Emotion understanding in videos aims to accurately recognize and interpret\nindividuals' emotional states by integrating contextual, visual, textual, and\nauditory cues. While Large Multimodal Models (LMMs) have demonstrated\nsignificant progress in general vision-language (VL) tasks, their performance\nin emotion-specific scenarios remains limited. Moreover, fine-tuning LMMs on\nemotion-related tasks often leads to catastrophic forgetting, hindering their\nability to generalize across diverse tasks. To address these challenges, we\npresent Emotion-Qwen, a tailored multimodal framework designed to enhance both\nemotion understanding and general VL reasoning. Emotion-Qwen incorporates a\nsophisticated Hybrid Compressor based on the Mixture of Experts (MoE) paradigm,\nwhich dynamically routes inputs to balance emotion-specific and general-purpose\nprocessing. The model is pre-trained in a three-stage pipeline on large-scale\ngeneral and emotional image datasets to support robust multimodal\nrepresentations. Furthermore, we construct the Video Emotion Reasoning (VER)\ndataset, comprising more than 40K bilingual video clips with fine-grained\ndescriptive annotations, to further enrich Emotion-Qwen's emotional reasoning\ncapability. Experimental results demonstrate that Emotion-Qwen achieves\nstate-of-the-art performance on multiple emotion recognition benchmarks, while\nmaintaining competitive results on general VL tasks. Code and models are\navailable at https://anonymous.4open.science/r/Emotion-Qwen-Anonymous.", "AI": {"tldr": "Emotion-Qwen is a multimodal framework for emotion understanding in videos, addressing limitations of LMMs by using a Hybrid Compressor and pre-training on large datasets. It achieves top performance on emotion benchmarks while maintaining general VL task capabilities.", "motivation": "Current LMMs underperform in emotion-specific tasks and suffer from catastrophic forgetting when fine-tuned. Emotion-Qwen aims to enhance emotion understanding without sacrificing general VL reasoning.", "method": "The framework uses a Hybrid Compressor (MoE-based) to dynamically route inputs. It is pre-trained in three stages on general and emotional datasets and evaluated on the VER dataset (40K bilingual video clips).", "result": "Emotion-Qwen achieves state-of-the-art performance on emotion benchmarks and remains competitive on general VL tasks.", "conclusion": "Emotion-Qwen effectively balances emotion-specific and general-purpose processing, advancing multimodal emotion understanding."}}
{"id": "2505.07164", "pdf": "https://arxiv.org/pdf/2505.07164", "abs": "https://arxiv.org/abs/2505.07164", "authors": ["SangEun Lee", "Yubeen Lee", "Eunil Park"], "title": "EmoVLM-KD: Fusing Distilled Expertise with Vision-Language Models for Visual Emotion Analysis", "categories": ["cs.MM"], "comment": "Accepted at Workshop and Competition on Affective & Behavior Analysis\n  in-the-wild (ABAW), CVPR 2025, 10 pages, 4 figures, 4 tables", "summary": "Visual emotion analysis, which has gained considerable attention in the field\nof affective computing, aims to predict the dominant emotions conveyed by an\nimage. Despite advancements in visual emotion analysis with the emergence of\nvision-language models, we observed that instruction-tuned vision-language\nmodels and conventional vision models exhibit complementary strengths in visual\nemotion analysis, as vision-language models excel in certain cases, whereas\nvision models perform better in others. This finding highlights the need to\nintegrate these capabilities to enhance the performance of visual emotion\nanalysis. To bridge this gap, we propose EmoVLM-KD, an instruction-tuned\nvision-language model augmented with a lightweight module distilled from\nconventional vision models. Instead of deploying both models simultaneously,\nwhich incurs high computational costs, we transfer the predictive patterns of a\nconventional vision model into the vision-language model using a knowledge\ndistillation framework. Our approach first fine-tunes a vision-language model\non emotion-specific instruction data and then attaches a distilled module to\nits visual encoder while keeping the vision-language model frozen. Predictions\nfrom the vision language model and the distillation module are effectively\nbalanced by a gate module, which subsequently generates the final outcome.\nExtensive experiments show that EmoVLM-KD achieves state-of-the-art performance\non multiple visual emotion analysis benchmark datasets, outperforming the\nexisting methods while maintaining computational efficiency. The code is\navailable in https://github.com/sange1104/EmoVLM-KD.", "AI": {"tldr": "EmoVLM-KD integrates instruction-tuned vision-language models and conventional vision models via knowledge distillation to enhance visual emotion analysis, achieving state-of-the-art performance efficiently.", "motivation": "Vision-language models and conventional vision models show complementary strengths in visual emotion analysis, but deploying both is computationally expensive.", "method": "Proposes EmoVLM-KD, which distills knowledge from a vision model into a vision-language model using a lightweight module and a gate for balanced predictions.", "result": "EmoVLM-KD outperforms existing methods on benchmark datasets while maintaining computational efficiency.", "conclusion": "The integration of complementary models via distillation improves visual emotion analysis performance without high computational costs."}}
{"id": "2505.06803", "pdf": "https://arxiv.org/pdf/2505.06803", "abs": "https://arxiv.org/abs/2505.06803", "authors": ["Xilin Jiang", "Junkai Wu", "Vishal Choudhari", "Nima Mesgarani"], "title": "Bridging Ears and Eyes: Analyzing Audio and Visual Large Language Models to Humans in Visible Sound Recognition and Reducing Their Sensory Gap via Cross-Modal Distillation", "categories": ["cs.SD", "cs.CL", "cs.CV", "cs.MM", "eess.AS"], "comment": null, "summary": "Audio large language models (LLMs) are considered experts at recognizing\nsound objects, yet their performance relative to LLMs in other sensory\nmodalities, such as visual or audio-visual LLMs, and to humans using their\nears, eyes, or both remains unexplored. To investigate this, we systematically\nevaluate audio, visual, and audio-visual LLMs, specifically Qwen2-Audio,\nQwen2-VL, and Qwen2.5-Omni, against humans in recognizing sound objects of\ndifferent classes from audio-only, silent video, or sounded video inputs. We\nuncover a performance gap between Qwen2-Audio and Qwen2-VL that parallels the\nsensory discrepancy between human ears and eyes. To reduce this gap, we\nintroduce a cross-modal distillation framework, where an LLM in one modality\nserves as the teacher and another as the student, with knowledge transfer in\nsound classes predicted as more challenging to the student by a heuristic\nmodel. Distillation in both directions, from Qwen2-VL to Qwen2-Audio and vice\nversa, leads to notable improvements, particularly in challenging classes. This\nwork highlights the sensory gap in LLMs from a human-aligned perspective and\nproposes a principled approach to enhancing modality-specific perception in\nmultimodal LLMs.", "AI": {"tldr": "Audio LLMs lag behind visual and audio-visual LLMs in recognizing sound objects, similar to human sensory discrepancies. Cross-modal distillation improves performance, especially in challenging classes.", "motivation": "To explore the performance gap between audio, visual, and audio-visual LLMs compared to humans and propose a method to bridge this gap.", "method": "Systematic evaluation of Qwen2-Audio, Qwen2-VL, and Qwen2.5-Omni against humans, followed by cross-modal distillation between LLMs to transfer knowledge.", "result": "Audio LLMs underperform visual and audio-visual LLMs, but distillation improves their performance, particularly in difficult sound classes.", "conclusion": "The study reveals sensory gaps in LLMs and offers a framework to enhance modality-specific perception through cross-modal distillation."}}
{"id": "2505.06416", "pdf": "https://arxiv.org/pdf/2505.06416", "abs": "https://arxiv.org/abs/2505.06416", "authors": ["Elias Lumer", "Anmol Gulati", "Vamse Kumar Subbiah", "Pradeep Honaganahalli Basavaraju", "James A. Burke"], "title": "ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents", "categories": ["cs.CL"], "comment": "17 pages", "summary": "Recent advancements in Large Language Models (LLMs) and the introduction of\nthe Model Context Protocol (MCP) have significantly expanded LLM agents'\ncapability to interact dynamically with external tools and APIs. However,\nexisting tool selection frameworks do not integrate MCP servers, instead\nrelying heavily on error-prone manual updates to monolithic local tool\nrepositories, leading to duplication, inconsistencies, and inefficiencies.\nAdditionally, current approaches abstract tool selection before the LLM agent\nis invoked, limiting its autonomy and hindering dynamic re-querying\ncapabilities during multi-turn interactions. To address these issues, we\nintroduce ScaleMCP, a novel tool selection approach that dynamically equips LLM\nagents with a MCP tool retriever, giving agents the autonomy to add tools into\ntheir memory, as well as an auto-synchronizing tool storage system pipeline\nthrough CRUD (create, read, update, delete) operations with MCP servers as the\nsingle source of truth. We also propose a novel embedding strategy, Tool\nDocument Weighted Average (TDWA), designed to selectively emphasize critical\ncomponents of tool documents (e.g. tool name or synthetic questions) during the\nembedding process. Comprehensive evaluations conducted on a created dataset of\n5,000 financial metric MCP servers, across 10 LLM models, 5 embedding models,\nand 5 retriever types, demonstrate substantial improvements in tool retrieval\nand agent invocation performance, emphasizing ScaleMCP's effectiveness in\nscalable, dynamic tool selection and invocation.", "AI": {"tldr": "ScaleMCP introduces a dynamic tool selection approach for LLM agents, integrating MCP servers for tool retrieval and auto-synchronization, improving efficiency and autonomy.", "motivation": "Existing tool selection frameworks lack integration with MCP servers, leading to inefficiencies and limited agent autonomy.", "method": "ScaleMCP uses a MCP tool retriever, auto-synchronizing storage, and TDWA embedding strategy for dynamic tool selection.", "result": "Evaluations show significant improvements in tool retrieval and agent performance across diverse models and datasets.", "conclusion": "ScaleMCP effectively addresses scalability and dynamic tool selection challenges in LLM agent interactions."}}
{"id": "2505.07365", "pdf": "https://arxiv.org/pdf/2505.07365", "abs": "https://arxiv.org/abs/2505.07365", "authors": ["Chao-Han Huck Yang", "Sreyan Ghosh", "Qing Wang", "Jaeyeon Kim", "Hengyi Hong", "Sonal Kumar", "Guirui Zhong", "Zhifeng Kong", "S Sakshi", "Vaibhavi Lokegaonkar", "Oriol Nieto", "Ramani Duraiswami", "Dinesh Manocha", "Gunhee Kim", "Jun Du", "Rafael Valle", "Bryan Catanzaro"], "title": "Multi-Domain Audio Question Answering Toward Acoustic Content Reasoning in The DCASE 2025 Challenge", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM", "eess.AS"], "comment": "Preprint. DCASE 2025 Audio QA Challenge:\n  https://dcase.community/challenge2025/task-audio-question-answering", "summary": "We present Task 5 of the DCASE 2025 Challenge: an Audio Question Answering\n(AQA) benchmark spanning multiple domains of sound understanding. This task\ndefines three QA subsets (Bioacoustics, Temporal Soundscapes, and Complex QA)\nto test audio-language models on interactive question-answering over diverse\nacoustic scenes. We describe the dataset composition (from marine mammal calls\nto soundscapes and complex real-world clips), the evaluation protocol (top-1\naccuracy with answer-shuffling robustness), and baseline systems\n(Qwen2-Audio-7B, AudioFlamingo 2, Gemini-2-Flash). Preliminary results on the\ndevelopment set are compared, showing strong variation across models and\nsubsets. This challenge aims to advance the audio understanding and reasoning\ncapabilities of audio-language models toward human-level acuity, which are\ncrucial for enabling AI agents to perceive and interact about the world\neffectively.", "AI": {"tldr": "The paper introduces Task 5 of the DCASE 2025 Challenge, focusing on Audio Question Answering (AQA) across diverse sound domains, with three QA subsets and baseline models evaluated for robustness and accuracy.", "motivation": "To advance audio-language models' understanding and reasoning capabilities toward human-level acuity, enabling AI agents to perceive and interact effectively with the world.", "method": "The task defines three QA subsets (Bioacoustics, Temporal Soundscapes, Complex QA) and evaluates models using top-1 accuracy with answer-shuffling robustness. Baseline systems include Qwen2-Audio-7B, AudioFlamingo 2, and Gemini-2-Flash.", "result": "Preliminary results show strong variation in performance across models and subsets on the development set.", "conclusion": "The challenge aims to push the boundaries of audio-language models, enhancing their ability to understand and reason about diverse acoustic scenes."}}
{"id": "2505.06418", "pdf": "https://arxiv.org/pdf/2505.06418", "abs": "https://arxiv.org/abs/2505.06418", "authors": ["Ming Liu", "Liwen Wang", "Wensheng Zhang"], "title": "Is your multimodal large language model a good science tutor?", "categories": ["cs.CL"], "comment": null, "summary": "Multimodal large language models (MLLMs) demonstrate impressive performance\non scientific reasoning tasks (e.g., ScienceQA). However, most existing\nbenchmarks focus narrowly on the accuracy of the final answer while ignoring\nother metrics. In particular, when applying MLLMs to educational contexts, the\ngoal is not only correctness but also the ability to teach. In this paper, we\npropose a framework that evaluates MLLMs as science tutors using a\ncomprehensive educational rubric and a simulated student model that judges the\nteaching performance of the tutors. Given a list of candidate MLLM science\ntutors, we use rubric-based student judgments to produce a range of tutor\nperformance scores, identifying both strong and weak tutors. Using the training\nsection of the ScienceQA dataset, we then construct a data set of pairwise\ncomparisons between the outputs of strong and weak tutors. This enables us to\napply multiple preference optimization methods to fine-tune an underperforming\ntutor model (Qwen2-VL-2B) into more effective ones. Our results also show that\nstrong problem-solving skills do not guarantee high-quality tutoring and that\nperformance optimization-guided refinements can yield more educationally\naligned tutor models. This approach opens avenues for building MLLMs that serve\nnot only as problem solvers, but as genuinely helpful educational assistants.", "AI": {"tldr": "The paper proposes a framework to evaluate multimodal large language models (MLLMs) as science tutors, focusing on teaching ability beyond just answer accuracy. It uses a rubric and simulated student model to assess tutoring performance, fine-tunes underperforming models, and shows that problem-solving skills don't guarantee teaching quality.", "motivation": "Existing benchmarks for MLLMs prioritize answer accuracy but overlook teaching ability, which is crucial for educational applications. The paper aims to bridge this gap by evaluating MLLMs as tutors.", "method": "The framework uses an educational rubric and simulated student model to judge tutoring performance. It identifies strong and weak tutors, constructs pairwise comparisons, and applies preference optimization to fine-tune underperforming models.", "result": "The study reveals that strong problem-solving skills don't ensure high-quality tutoring. Fine-tuning based on preference optimization improves educational alignment of tutor models.", "conclusion": "The approach enables development of MLLMs that function as effective educational assistants, not just problem solvers, opening new possibilities for their use in education."}}
{"id": "2505.07176", "pdf": "https://arxiv.org/pdf/2505.07176", "abs": "https://arxiv.org/abs/2505.07176", "authors": ["Yuntao Wang", "Shaolong Guo", "Yanghe Pan", "Zhou Su", "Fahao Chen", "Tom H. Luan", "Peng Li", "Jiawen Kang", "Dusit Niyato"], "title": "Internet of Agents: Fundamentals, Applications, and Challenges", "categories": ["cs.MA", "cs.AI"], "comment": "22 pages,10 figures, 8 tables. Submitted to IEEE TCCN", "summary": "With the rapid proliferation of large language models and vision-language\nmodels, AI agents have evolved from isolated, task-specific systems into\nautonomous, interactive entities capable of perceiving, reasoning, and acting\nwithout human intervention. As these agents proliferate across virtual and\nphysical environments, from virtual assistants to embodied robots, the need for\na unified, agent-centric infrastructure becomes paramount. In this survey, we\nintroduce the Internet of Agents (IoA) as a foundational framework that enables\nseamless interconnection, dynamic discovery, and collaborative orchestration\namong heterogeneous agents at scale. We begin by presenting a general IoA\narchitecture, highlighting its hierarchical organization, distinguishing\nfeatures relative to the traditional Internet, and emerging applications. Next,\nwe analyze the key operational enablers of IoA, including capability\nnotification and discovery, adaptive communication protocols, dynamic task\nmatching, consensus and conflict-resolution mechanisms, and incentive models.\nFinally, we identify open research directions toward building resilient and\ntrustworthy IoA ecosystems.", "AI": {"tldr": "The paper introduces the Internet of Agents (IoA) as a framework for interconnecting and orchestrating autonomous AI agents, detailing its architecture, enablers, and open research challenges.", "motivation": "The rapid growth of AI agents necessitates a unified infrastructure for seamless interaction and collaboration among heterogeneous agents.", "method": "The paper presents a hierarchical IoA architecture, analyzes key operational enablers, and identifies emerging applications.", "result": "The framework enables dynamic discovery, adaptive communication, task matching, and conflict resolution among agents.", "conclusion": "Open research directions are identified to build resilient and trustworthy IoA ecosystems."}}
{"id": "2505.06356", "pdf": "https://arxiv.org/pdf/2505.06356", "abs": "https://arxiv.org/abs/2505.06356", "authors": ["Karthik Reddy Kanjula", "Surya Guthikonda", "Nahid Alam", "Shayekh Bin Islam"], "title": "Understanding and Mitigating Toxicity in Image-Text Pretraining Datasets: A Case Study on LLaVA", "categories": ["cs.CV"], "comment": "Accepted at ReGenAI CVPR2025 Workshop as Oral", "summary": "Pretraining datasets are foundational to the development of multimodal\nmodels, yet they often have inherent biases and toxic content from the\nweb-scale corpora they are sourced from. In this paper, we investigate the\nprevalence of toxicity in LLaVA image-text pretraining dataset, examining how\nharmful content manifests in different modalities. We present a comprehensive\nanalysis of common toxicity categories and propose targeted mitigation\nstrategies, resulting in the creation of a refined toxicity-mitigated dataset.\nThis dataset removes 7,531 of toxic image-text pairs in the LLaVA pre-training\ndataset. We offer guidelines for implementing robust toxicity detection\npipelines. Our findings underscore the need to actively identify and filter\ntoxic content - such as hate speech, explicit imagery, and targeted harassment\n- to build more responsible and equitable multimodal systems. The\ntoxicity-mitigated dataset is open source and is available for further\nresearch.", "AI": {"tldr": "The paper analyzes toxicity in the LLaVA image-text pretraining dataset, identifies harmful content, and proposes mitigation strategies, resulting in a refined dataset with 7,531 toxic pairs removed.", "motivation": "To address biases and toxic content in multimodal pretraining datasets, ensuring more responsible and equitable AI systems.", "method": "Comprehensive analysis of toxicity categories in the LLaVA dataset, followed by targeted mitigation strategies and creation of a toxicity-mitigated dataset.", "result": "7,531 toxic image-text pairs were removed, and guidelines for toxicity detection pipelines were provided.", "conclusion": "Active identification and filtering of toxic content are crucial for building responsible multimodal systems; the refined dataset is open-sourced for further research."}}
{"id": "2505.06287", "pdf": "https://arxiv.org/pdf/2505.06287", "abs": "https://arxiv.org/abs/2505.06287", "authors": ["Riccardo Sieve", "Paul Kobialka", "Laura Slaughter", "Rudolf Schlatte", "Einar Broch Johnsen", "Silvia Lizeth Tapia Tarifa"], "title": "BedreFlyt: Improving Patient Flows through Hospital Wards with Digital Twins", "categories": ["cs.AI", "cs.ET", "cs.LO", "D.2.2; D.2.4; J.3"], "comment": "In Proceedings ASQAP 2025, arXiv:2505.02873", "summary": "Digital twins are emerging as a valuable tool for short-term decision-making\nas well as for long-term strategic planning across numerous domains, including\nprocess industry, energy, space, transport, and healthcare. This paper reports\non our ongoing work on designing a digital twin to enhance resource planning,\ne.g., for the in-patient ward needs in hospitals. By leveraging executable\nformal models for system exploration, ontologies for knowledge representation\nand an SMT solver for constraint satisfiability, our approach aims to explore\nhypothetical \"what-if\" scenarios to improve strategic planning processes, as\nwell as to solve concrete, short-term decision-making tasks. Our proposed\nsolution uses the executable formal model to turn a stream of arriving\npatients, that need to be hospitalized, into a stream of optimization problems,\ne.g., capturing daily inpatient ward needs, that can be solved by SMT\ntechniques. The knowledge base, which formalizes domain knowledge, is used to\nmodel the needed configuration in the digital twin, allowing the twin to\nsupport both short-term decision-making and long-term strategic planning by\ngenerating scenarios spanning average-case as well as worst-case resource\nneeds, depending on the expected treatment of patients, as well as ranging over\nvariations in available resources, e.g., bed distribution in different rooms.\nWe illustrate our digital twin architecture by considering the problem of bed\nbay allocation in a hospital ward.", "AI": {"tldr": "The paper discusses a digital twin framework for hospital resource planning, combining formal models, ontologies, and SMT solvers to optimize short-term and long-term decision-making.", "motivation": "To enhance resource planning in hospitals by leveraging digital twins for scenario exploration and optimization.", "method": "Uses executable formal models, ontologies for knowledge representation, and SMT solvers to model and solve optimization problems for patient hospitalization.", "result": "Proposes a digital twin architecture that supports both short-term decision-making and long-term strategic planning by generating various resource scenarios.", "conclusion": "The digital twin approach effectively addresses hospital resource planning challenges, demonstrating its utility through bed bay allocation in a ward."}}
{"id": "2505.06229", "pdf": "https://arxiv.org/pdf/2505.06229", "abs": "https://arxiv.org/abs/2505.06229", "authors": ["Aaqib Ayoub Bhat", "Asif Khan", "M. Mursaleen"], "title": "Neural Network Operator-Based Fractal Approximation: Smoothness Preservation and Convergence Analysis", "categories": ["cs.LG", "cs.NA", "math.NA", "28A80, 41A05, 41A25, 41A29, 41A30, 65D05"], "comment": "18 pages", "summary": "This paper presents a new approach of constructing $\\alpha$-fractal\ninterpolation functions (FIFs) using neural network operators, integrating\nconcepts from approximation theory. Initially, we construct $\\alpha$-fractals\nutilizing neural network-based operators, providing an approach to generating\nfractal functions with interpolation properties. Based on the same foundation,\nwe have developed fractal interpolation functions that utilize only the values\nof the original function at the nodes or partition points, unlike traditional\nmethods that rely on the entire original function.\n  Further, we have constructed \\(\\alpha\\)-fractals that preserve the smoothness\nof functions under certain constraints by employing a four-layered neural\nnetwork operator, ensuring that if \\(f \\in C^{r}[a,b]\\), then the corresponding\nfractal \\(f^{\\alpha} \\in C^{r}[a,b]\\). Furthermore, we analyze the convergence\nof these $\\alpha$-fractals to the original function under suitable conditions.\nThe work uses key approximation theory tools, such as the modulus of continuity\nand interpolation operators, to develop convergence results and uniform\napproximation error bounds.", "AI": {"tldr": "A neural network-based method for constructing \u03b1-fractal interpolation functions (FIFs) is introduced, preserving smoothness and using only node values, with convergence analysis.", "motivation": "To develop a novel approach for generating FIFs using neural networks, avoiding reliance on the entire original function and ensuring smoothness preservation.", "method": "Constructs \u03b1-fractals using neural network operators, focusing on node values and employing a four-layered network to maintain smoothness.", "result": "FIFs are generated with interpolation properties, smoothness preservation under constraints, and convergence to the original function under suitable conditions.", "conclusion": "The method successfully integrates neural networks with approximation theory for FIF construction, offering efficiency and theoretical guarantees."}}
{"id": "2505.06671", "pdf": "https://arxiv.org/pdf/2505.06671", "abs": "https://arxiv.org/abs/2505.06671", "authors": ["David Rowe", "Jean-Marc Valin"], "title": "RADE: A Neural Codec for Transmitting Speech over HF Radio Channels", "categories": ["eess.AS", "cs.SD"], "comment": "5 pages", "summary": "Speech compression is commonly used to send voice over radio channels in\napplications such as mobile telephony and two-way push-to-talk (PTT) radio. In\nclassical systems, the speech codec is combined with forward error correction,\nmodulation and radio hardware. In this paper we describe an autoencoder that\nreplaces many of the traditional signal processing elements with a neural\nnetwork. The encoder takes a vocoder feature set (short term spectrum, pitch,\nvoicing), and produces discrete time, but continuously valued quadrature\namplitude modulation (QAM) symbols. We use orthogonal frequency domain\nmultiplexing (OFDM) to send and receive these symbols over high frequency (HF)\nradio channels. The decoder converts received QAM symbols to vocoder features\nsuitable for synthesis. The autoencoder has been trained to be robust to\nadditive Gaussian noise and multipath channel impairments while simultaneously\nmaintaining a Peak To Average Power Ratio (PAPR) of less than 1~dB. Over\nsimulated and real world HF radio channels we have achieved output speech\nintelligibility that clearly surpasses existing analog and digital radio\nsystems over a range of SNRs.", "AI": {"tldr": "An autoencoder replaces traditional speech compression and radio signal processing, achieving higher intelligibility over HF channels.", "motivation": "To improve speech intelligibility in radio communications by replacing classical signal processing with neural networks.", "method": "An autoencoder processes vocoder features into QAM symbols, transmitted via OFDM over HF radio, and decodes back to speech features.", "result": "Outperforms analog and digital systems in intelligibility across various SNRs, with low PAPR.", "conclusion": "Neural networks can effectively replace traditional methods in radio speech compression, enhancing performance."}}
{"id": "2505.06502", "pdf": "https://arxiv.org/pdf/2505.06502", "abs": "https://arxiv.org/abs/2505.06502", "authors": ["Md Rakibul Hasan", "Pouria Behnoudfar", "Dan MacKinlay", "Thomas Poulet"], "title": "PC-SRGAN: Physically Consistent Super-Resolution Generative Adversarial Network for General Transient Simulations", "categories": ["eess.IV", "cs.CE", "cs.CV", "cs.LG"], "comment": null, "summary": "Machine Learning, particularly Generative Adversarial Networks (GANs), has\nrevolutionised Super Resolution (SR). However, generated images often lack\nphysical meaningfulness, which is essential for scientific applications. Our\napproach, PC-SRGAN, enhances image resolution while ensuring physical\nconsistency for interpretable simulations. PC-SRGAN significantly improves both\nthe Peak Signal-to-Noise Ratio and the Structural Similarity Index Measure\ncompared to conventional methods, even with limited training data (e.g., only\n13% of training data required for SRGAN). Beyond SR, PC-SRGAN augments\nphysically meaningful machine learning, incorporating numerically justified\ntime integrators and advanced quality metrics. These advancements promise\nreliable and causal machine-learning models in scientific domains. A\nsignificant advantage of PC-SRGAN over conventional SR techniques is its\nphysical consistency, which makes it a viable surrogate model for\ntime-dependent problems. PC-SRGAN advances scientific machine learning,\noffering improved accuracy and efficiency for image processing, enhanced\nprocess understanding, and broader applications to scientific research. The\nsource codes and data will be made publicly available at\nhttps://github.com/hasan-rakibul/PC-SRGAN upon acceptance of this paper.", "AI": {"tldr": "PC-SRGAN improves Super Resolution with physical consistency, outperforming traditional methods in accuracy and efficiency.", "motivation": "Address the lack of physical meaningfulness in GAN-generated images for scientific applications.", "method": "PC-SRGAN ensures physical consistency while enhancing resolution, using numerically justified time integrators and advanced metrics.", "result": "Significant improvements in PSNR and SSIM, even with limited training data (13% of SRGAN's requirement).", "conclusion": "PC-SRGAN advances scientific machine learning with reliable, causal models, offering broader applications and better process understanding."}}
{"id": "2505.06766", "pdf": "https://arxiv.org/pdf/2505.06766", "abs": "https://arxiv.org/abs/2505.06766", "authors": ["Yasaman Ahmadiadli", "Xiao-Ping Zhang", "Naimul Khan"], "title": "Beyond Identity: A Generalizable Approach for Deepfake Audio Detection", "categories": ["cs.SD", "eess.AS", "eess.SP"], "comment": "Submitted to IEEE Transactions on Biometrics, Behavior, and Identity\n  Science (T-BIOM)", "summary": "Deepfake audio presents a growing threat to digital security, due to its\npotential for social engineering, fraud, and identity misuse. However, existing\ndetection models suffer from poor generalization across datasets, due to\nimplicit identity leakage, where models inadvertently learn speaker-specific\nfeatures instead of manipulation artifacts. To the best of our knowledge, this\nis the first study to explicitly analyze and address identity leakage in the\naudio deepfake detection domain. This work proposes an identity-independent\naudio deepfake detection framework that mitigates identity leakage by\nencouraging the model to focus on forgery-specific artifacts instead of\noverfitting to speaker traits. Our approach leverages Artifact Detection\nModules (ADMs) to isolate synthetic artifacts in both time and frequency\ndomains, enhancing cross-dataset generalization. We introduce novel dynamic\nartifact generation techniques, including frequency domain swaps, time domain\nmanipulations, and background noise augmentation, to enforce learning of\ndataset-invariant features. Extensive experiments conducted on ASVspoof2019,\nADD 2022, FoR, and In-The-Wild datasets demonstrate that the proposed\nADM-enhanced models achieve F1 scores of 0.230 (ADD 2022), 0.604 (FoR), and\n0.813 (In-The-Wild), consistently outperforming the baseline. Dynamic Frequency\nSwap proves to be the most effective strategy across diverse conditions. These\nfindings emphasize the value of artifact-based learning in mitigating implicit\nidentity leakage for more generalizable audio deepfake detection.", "AI": {"tldr": "The paper proposes an identity-independent audio deepfake detection framework to address identity leakage, using Artifact Detection Modules (ADMs) and dynamic artifact generation techniques, achieving superior performance across datasets.", "motivation": "Deepfake audio poses significant threats like fraud and identity misuse, but current detection models generalize poorly due to identity leakage, where models learn speaker-specific features instead of manipulation artifacts.", "method": "The framework employs ADMs to isolate synthetic artifacts in time and frequency domains, alongside novel dynamic artifact generation techniques (e.g., frequency swaps, time manipulations, noise augmentation) to enforce dataset-invariant feature learning.", "result": "Experiments on ASVspoof2019, ADD 2022, FoR, and In-The-Wild datasets show F1 scores of 0.230 (ADD 2022), 0.604 (FoR), and 0.813 (In-The-Wild), outperforming baselines, with Dynamic Frequency Swap being the most effective.", "conclusion": "Artifact-based learning effectively mitigates identity leakage, enhancing generalization in audio deepfake detection."}}
{"id": "2409.07901", "pdf": "https://arxiv.org/pdf/2409.07901", "abs": "https://arxiv.org/abs/2409.07901", "authors": ["Jiehui Jia", "Huan Zhang", "Jinhua Liang"], "title": "Bridging Discrete and Continuous: A Multimodal Strategy for Complex Emotion Detection", "categories": ["cs.MM"], "comment": null, "summary": "In the domain of human-computer interaction, accurately recognizing and\ninterpreting human emotions is crucial yet challenging due to the complexity\nand subtlety of emotional expressions. This study explores the potential for\ndetecting a rich and flexible range of emotions through a multimodal approach\nwhich integrates facial expressions, voice tones, and transcript from video\nclips. We propose a novel framework that maps variety of emotions in a\nthree-dimensional Valence-Arousal-Dominance (VAD) space, which could reflect\nthe fluctuations and positivity/negativity of emotions to enable a more variety\nand comprehensive representation of emotional states. We employed K-means\nclustering to transit emotions from traditional discrete categorization to a\ncontinuous labeling system and built a classifier for emotion recognition upon\nthis system. The effectiveness of the proposed model is evaluated using the\nMER2024 dataset, which contains culturally consistent video clips from Chinese\nmovies and TV series, annotated with both discrete and open-vocabulary emotion\nlabels. Our experiment successfully achieved the transformation between\ndiscrete and continuous models, and the proposed model generated a more diverse\nand comprehensive set of emotion vocabulary while maintaining strong accuracy.", "AI": {"tldr": "The paper introduces a multimodal framework for emotion recognition using facial expressions, voice tones, and video transcripts, mapping emotions in a 3D VAD space. It transitions from discrete to continuous emotion labeling with K-means clustering and achieves strong accuracy on the MER2024 dataset.", "motivation": "Accurate emotion recognition in human-computer interaction is challenging due to the complexity of emotional expressions. This study aims to improve emotion detection by integrating multiple modalities and representing emotions continuously.", "method": "A multimodal approach combines facial expressions, voice tones, and video transcripts. Emotions are mapped in a 3D Valence-Arousal-Dominance (VAD) space. K-means clustering transitions from discrete to continuous labeling, and a classifier is built for emotion recognition.", "result": "The model successfully transforms discrete emotions into a continuous system and achieves diverse, comprehensive emotion vocabulary with strong accuracy on the MER2024 dataset.", "conclusion": "The proposed framework enhances emotion recognition by enabling continuous and diverse emotional representations, validated by high accuracy on culturally consistent data."}}
{"id": "2505.06496", "pdf": "https://arxiv.org/pdf/2505.06496", "abs": "https://arxiv.org/abs/2505.06496", "authors": ["Erik Nijkamp", "Bo Pang", "Egor Pakhomov", "Akash Gokul", "Jin Qu", "Silvio Savarese", "Yingbo Zhou", "Caiming Xiong"], "title": "xGen-small Technical Report", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce xGen-small, a family of 4B and 9B Transformer decoder models\noptimized for long-context applications. Our vertically integrated pipeline\nunites domain-balanced, frequency-aware data curation; multi-stage pre-training\nwith quality annealing and length extension to 128k tokens; and targeted\npost-training via supervised fine-tuning, preference learning, and online\nreinforcement learning. xGen-small delivers strong performance across various\ntasks, especially in math and coding domains, while excelling at long context\nbenchmarks.", "AI": {"tldr": "xGen-small is a family of 4B and 9B Transformer models optimized for long-context tasks, achieving strong performance in math, coding, and long-context benchmarks.", "motivation": "To address the need for efficient long-context models, xGen-small is designed with a focus on domain-balanced data and extended context handling.", "method": "The pipeline includes data curation, multi-stage pre-training (quality annealing, length extension to 128k tokens), and post-training (fine-tuning, preference learning, reinforcement learning).", "result": "xGen-small excels in math, coding, and long-context tasks, demonstrating robust performance.", "conclusion": "xGen-small is a highly effective model for long-context applications, with strong results in specialized domains."}}
{"id": "2505.07207", "pdf": "https://arxiv.org/pdf/2505.07207", "abs": "https://arxiv.org/abs/2505.07207", "authors": ["Chiqiang Liu", "Dazi Li"], "title": "Hypergraph Coordination Networks with Dynamic Grouping for Multi-Agent Reinforcement Learning", "categories": ["cs.MA"], "comment": null, "summary": "Cooperative multi-agent reinforcement learning faces significant challenges\nin effectively organizing agent relationships and facilitating information\nexchange, particularly when agents need to adapt their coordination patterns\ndynamically. This paper presents a novel framework that integrates dynamic\nspectral clustering with hypergraph neural networks to enable adaptive group\nformation and efficient information processing in multi-agent systems. The\nproposed framework dynamically constructs and updates hypergraph structures\nthrough spectral clustering on agents' state histories, enabling higher-order\nrelationships to emerge naturally from agent interactions. The hypergraph\nstructure is enhanced with attention mechanisms for selective information\nprocessing, providing an expressive and efficient way to model complex agent\nrelationships. This architecture can be implemented in both value-based and\npolicy-based paradigms through a unified objective combining task performance\nwith structural regularization. Extensive experiments on challenging\ncooperative tasks demonstrate that our method significantly outperforms\nstate-of-the-art approaches in both sample efficiency and final performance.", "AI": {"tldr": "A novel framework combining dynamic spectral clustering and hypergraph neural networks improves adaptive group formation and information exchange in multi-agent reinforcement learning.", "motivation": "Addressing challenges in organizing agent relationships and dynamic coordination in cooperative multi-agent systems.", "method": "Integrates dynamic spectral clustering with hypergraph neural networks, using attention mechanisms for selective information processing.", "result": "Outperforms state-of-the-art methods in sample efficiency and final performance on cooperative tasks.", "conclusion": "The framework effectively models complex agent relationships and enhances coordination in multi-agent systems."}}
{"id": "2505.06370", "pdf": "https://arxiv.org/pdf/2505.06370", "abs": "https://arxiv.org/abs/2505.06370", "authors": ["Adhora Madhuri", "Nusaiba Sobir", "Tasnia Binte Mamun", "Taufiq Hasan"], "title": "LMLCC-Net: A Semi-Supervised Deep Learning Model for Lung Nodule Malignancy Prediction from CT Scans using a Novel Hounsfield Unit-Based Intensity Filtering", "categories": ["eess.IV", "cs.CV"], "comment": "9 pages, 5 figures, 6 tables", "summary": "Lung cancer is the leading cause of patient mortality in the world. Early\ndiagnosis of malignant pulmonary nodules in CT images can have a significant\nimpact on reducing disease mortality and morbidity. In this work, we propose\nLMLCC-Net, a novel deep learning framework for classifying nodules from CT scan\nimages using a 3D CNN, considering Hounsfield Unit (HU)-based intensity\nfiltering. Benign and malignant nodules have significant differences in their\nintensity profile of HU, which was not exploited in the literature. Our method\nconsiders the intensity pattern as well as the texture for the prediction of\nmalignancies. LMLCC-Net extracts features from multiple branches that each use\na separate learnable HU-based intensity filtering stage. Various combinations\nof branches and learnable ranges of filters were explored to finally produce\nthe best-performing model. In addition, we propose a semi-supervised learning\nscheme for labeling ambiguous cases and also developed a lightweight model to\nclassify the nodules. The experimental evaluations are carried out on the\nLUNA16 dataset. Our proposed method achieves a classification accuracy (ACC) of\n91.96%, a sensitivity (SEN) of 92.04%, and an area under the curve (AUC) of\n91.87%, showing improved performance compared to existing methods. The proposed\nmethod can have a significant impact in helping radiologists in the\nclassification of pulmonary nodules and improving patient care.", "AI": {"tldr": "LMLCC-Net, a 3D CNN framework, improves lung nodule classification in CT scans by leveraging HU-based intensity filtering and texture analysis, achieving high accuracy (91.96%) and outperforming existing methods.", "motivation": "Early diagnosis of lung cancer via CT scans can reduce mortality. Existing methods overlook HU intensity differences between benign and malignant nodules.", "method": "LMLCC-Net uses multi-branch 3D CNNs with learnable HU-based filters and semi-supervised learning for ambiguous cases. Evaluated on LUNA16 dataset.", "result": "Achieves 91.96% ACC, 92.04% SEN, and 91.87% AUC, outperforming prior methods.", "conclusion": "LMLCC-Net aids radiologists in nodule classification, enhancing patient care."}}
{"id": "2505.06328", "pdf": "https://arxiv.org/pdf/2505.06328", "abs": "https://arxiv.org/abs/2505.06328", "authors": ["Felix Ocker", "J\u00f6rg Deigm\u00f6ller", "Pavel Smirnov", "Julian Eggert"], "title": "A Grounded Memory System For Smart Personal Assistants", "categories": ["cs.AI", "H.3.3; H.3.4; I.2.1; I.2.5; I.2.7; I.2.10; J.3"], "comment": "8 pages, 5 figures, accepted for the ESWC 2025 TEXT2KG workshop", "summary": "A wide variety of agentic AI applications - ranging from cognitive assistants\nfor dementia patients to robotics - demand a robust memory system grounded in\nreality. In this paper, we propose such a memory system consisting of three\ncomponents. First, we combine Vision Language Models for image captioning and\nentity disambiguation with Large Language Models for consistent information\nextraction during perception. Second, the extracted information is represented\nin a memory consisting of a knowledge graph enhanced by vector embeddings to\nefficiently manage relational information. Third, we combine semantic search\nand graph query generation for question answering via Retrieval Augmented\nGeneration. We illustrate the system's working and potential using a real-world\nexample.", "AI": {"tldr": "A memory system for agentic AI applications combining Vision Language Models, Large Language Models, and a knowledge graph with vector embeddings for robust information extraction and retrieval.", "motivation": "To address the need for a robust memory system in agentic AI applications like cognitive assistants and robotics.", "method": "Combines Vision Language Models for image captioning, Large Language Models for information extraction, and a knowledge graph with vector embeddings for memory representation. Uses semantic search and graph query generation for question answering.", "result": "Demonstrates a functional memory system with potential for real-world applications.", "conclusion": "The proposed system effectively grounds memory in reality, showcasing promise for diverse AI applications."}}
{"id": "2505.06257", "pdf": "https://arxiv.org/pdf/2505.06257", "abs": "https://arxiv.org/abs/2505.06257", "authors": ["Ahsan Adeel"], "title": "Beyond Attention: Toward Machines with Intrinsic Higher Mental States", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Attending to what is relevant is fundamental to both the mammalian brain and\nmodern machine learning models such as Transformers. Yet, determining relevance\nremains a core challenge, traditionally offloaded to learning algorithms like\nbackpropagation. Inspired by recent cellular neurobiological evidence linking\nneocortical pyramidal cells to distinct mental states, this work shows how\nmodels (e.g., Transformers) can emulate high-level perceptual processing and\nawake thought (imagination) states to pre-select relevant information before\napplying attention. Triadic neuronal-level modulation loops among questions\n($Q$), clues (keys, $K$), and hypotheses (values, $V$) enable diverse, deep,\nparallel reasoning chains at the representation level and allow a rapid shift\nfrom initial biases to refined understanding. This leads to orders-of-magnitude\nfaster learning with significantly reduced computational demand (e.g., fewer\nheads, layers, and tokens), at an approximate cost of $\\mathcal{O}(N)$, where\n$N$ is the number of input tokens. Results span reinforcement learning (e.g.,\nCarRacing in a high-dimensional visual setup), computer vision, and natural\nlanguage question answering.", "AI": {"tldr": "The paper proposes a method inspired by neurobiology to pre-select relevant information in models like Transformers, enabling faster learning with reduced computational costs.", "motivation": "The challenge of determining relevance in attention mechanisms, traditionally relying on learning algorithms like backpropagation, is addressed by emulating high-level perceptual processing and mental states.", "method": "The approach uses triadic neuronal-level modulation loops (Q, K, V) to enable parallel reasoning and rapid refinement of understanding, reducing computational demands.", "result": "The method achieves orders-of-magnitude faster learning with fewer resources (heads, layers, tokens) and scales linearly with input tokens (O(N)).", "conclusion": "The neurobiologically inspired approach enhances efficiency and performance in tasks like reinforcement learning, computer vision, and NLP."}}
{"id": "2505.07609", "pdf": "https://arxiv.org/pdf/2505.07609", "abs": "https://arxiv.org/abs/2505.07609", "authors": ["Paul Primus", "Florian Schmid", "Gerhard Widmer"], "title": "TACOS: Temporally-aligned Audio CaptiOnS for Language-Audio Pretraining", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "submitted to the IEEE Workshop on Applications of Signal Processing\n  to Audio and Acoustics (WASPAA), 2025. Dataset (Zenodo):\n  https://zenodo.org/records/15379789, Implementation (GitHub):\n  https://github.com/OptimusPrimus/tacos", "summary": "Learning to associate audio with textual descriptions is valuable for a range\nof tasks, including pretraining, zero-shot classification, audio retrieval,\naudio captioning, and text-conditioned audio generation. Existing contrastive\nlanguage-audio pretrained models are typically trained using global, clip-level\ndescriptions, which provide only weak temporal supervision. We hypothesize that\nCLAP-like language-audio models - particularly, if they are expected to produce\nframe-level embeddings - can benefit from a stronger temporal supervision. To\nconfirm our hypothesis, we curate a novel dataset of approximately 12,000 audio\nrecordings from Freesound, each annotated with single-sentence free-text\ndescriptions linked to a specific temporal segment in an audio recording. We\nuse large language models to clean these annotations by removing references to\nnon-audible events, transcribed speech, typos, and annotator language bias. We\nfurther propose a frame-wise contrastive training strategy that learns to align\ntext descriptions with temporal regions in an audio recording and demonstrate\nthat our model has better temporal text-audio alignment abilities compared to\nmodels trained only on global captions when evaluated on the AudioSet Strong\nbenchmark. The dataset and our source code are available on Zenodo and GitHub,\nrespectively.", "AI": {"tldr": "The paper proposes a method to improve audio-text alignment by using temporal supervision and a novel dataset, showing better performance than models trained on global captions.", "motivation": "Existing contrastive language-audio models lack strong temporal supervision, limiting their effectiveness for frame-level tasks.", "method": "A dataset of 12,000 annotated audio recordings is curated, cleaned using large language models, and a frame-wise contrastive training strategy is introduced.", "result": "The model achieves better temporal text-audio alignment compared to global caption-trained models on the AudioSet Strong benchmark.", "conclusion": "Temporal supervision enhances language-audio models, with the dataset and code made publicly available."}}
{"id": "2505.06646", "pdf": "https://arxiv.org/pdf/2505.06646", "abs": "https://arxiv.org/abs/2505.06646", "authors": ["Daniel Strick", "Carlos Garcia", "Anthony Huang"], "title": "Reproducing and Improving CheXNet: Deep Learning for Chest X-ray Disease Classification", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "12 pages, 4 figures", "summary": "Deep learning for radiologic image analysis is a rapidly growing field in\nbiomedical research and is likely to become a standard practice in modern\nmedicine. On the publicly available NIH ChestX-ray14 dataset, containing X-ray\nimages that are classified by the presence or absence of 14 different diseases,\nwe reproduced an algorithm known as CheXNet, as well as explored other\nalgorithms that outperform CheXNet's baseline metrics. Model performance was\nprimarily evaluated using the F1 score and AUC-ROC, both of which are critical\nmetrics for imbalanced, multi-label classification tasks in medical imaging.\nThe best model achieved an average AUC-ROC score of 0.85 and an average F1\nscore of 0.39 across all 14 disease classifications present in the dataset.", "AI": {"tldr": "Reproduced CheXNet and explored better algorithms for classifying 14 diseases in X-ray images, achieving an average AUC-ROC of 0.85 and F1 score of 0.39.", "motivation": "Advance deep learning for radiologic image analysis to improve disease classification in medical imaging.", "method": "Reproduced CheXNet and tested other algorithms on the NIH ChestX-ray14 dataset, evaluating performance with F1 score and AUC-ROC.", "result": "Best model achieved an average AUC-ROC of 0.85 and F1 score of 0.39 across 14 diseases.", "conclusion": "Deep learning shows promise for standardizing disease classification in radiologic images, with potential for further improvement."}}
{"id": "2505.07235", "pdf": "https://arxiv.org/pdf/2505.07235", "abs": "https://arxiv.org/abs/2505.07235", "authors": ["Dianwen Ng", "Kun Zhou", "Yi-Wen Chao", "Zhiwei Xiong", "Bin Ma", "Eng Siong Chng"], "title": "Multi-band Frequency Reconstruction for Neural Psychoacoustic Coding", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Achieving high-fidelity audio compression while preserving perceptual quality\nacross diverse content remains a key challenge in Neural Audio Coding (NAC). We\nintroduce MUFFIN, a fully convolutional Neural Psychoacoustic Coding (NPC)\nframework that leverages psychoacoustically guided multi-band frequency\nreconstruction. At its core is a Multi-Band Spectral Residual Vector\nQuantization (MBS-RVQ) module that allocates bitrate across frequency bands\nbased on perceptual salience. This design enables efficient compression while\ndisentangling speaker identity from content using distinct codebooks. MUFFIN\nincorporates a transformer-inspired convolutional backbone and a modified snake\nactivation to enhance resolution in fine-grained spectral regions. Experimental\nresults on multiple benchmarks demonstrate that MUFFIN consistently outperforms\nexisting approaches in reconstruction quality. A high-compression variant\nachieves a state-of-the-art 12.5 Hz rate with minimal loss. MUFFIN also proves\neffective in downstream generative tasks, highlighting its promise as a token\nrepresentation for integration with language models. Audio samples and code are\navailable.", "AI": {"tldr": "MUFFIN is a neural audio coding framework that uses psychoacoustic multi-band frequency reconstruction for high-fidelity compression, outperforming existing methods.", "motivation": "The challenge of preserving perceptual quality in neural audio compression across diverse content drives the need for advanced frameworks like MUFFIN.", "method": "MUFFIN employs a Multi-Band Spectral Residual Vector Quantization (MBS-RVQ) module, a transformer-inspired convolutional backbone, and modified snake activation for efficient compression and disentanglement of speaker identity.", "result": "MUFFIN achieves superior reconstruction quality and a state-of-the-art 12.5 Hz compression rate with minimal loss, also excelling in downstream generative tasks.", "conclusion": "MUFFIN shows promise as a high-fidelity audio compression tool and a token representation for integration with language models."}}
{"id": "2505.03420", "pdf": "https://arxiv.org/pdf/2505.03420", "abs": "https://arxiv.org/abs/2505.03420", "authors": ["Fei Zhao", "Chengcui Zhang", "Runlin Zhang", "Tianyang Wang", "Xi Li"], "title": "Mitigating Image Captioning Hallucinations in Vision-Language Models", "categories": ["cs.MM", "cs.CV"], "comment": null, "summary": "Hallucinations in vision-language models (VLMs) hinder reliability and\nreal-world applicability, usually stemming from distribution shifts between\npretraining data and test samples. Existing solutions, such as retraining or\nfine-tuning on additional data, demand significant computational resources and\nlabor-intensive data collection, while ensemble-based methods incur additional\ncosts by introducing auxiliary VLMs. To address these challenges, we propose a\nnovel test-time adaptation framework using reinforcement learning to mitigate\nhallucinations during inference without retraining or any auxiliary VLMs. By\nupdating only the learnable parameters in the layer normalization of the\nlanguage model (approximately 0.003% of the model parameters), our method\nreduces distribution shifts between test samples and pretraining samples. A\nCLIP-based hallucination evaluation model is proposed to provide dual rewards\nto VLMs. Experimental results demonstrate a 15.4% and 17.3% reduction in\nhallucination rates on LLaVA and InstructBLIP, respectively. Our approach\noutperforms state-of-the-art baselines with a 68.3% improvement in\nhallucination mitigation, demonstrating its effectiveness.", "AI": {"tldr": "A reinforcement learning-based test-time adaptation framework reduces hallucinations in VLMs by updating minimal parameters, outperforming existing methods.", "motivation": "Hallucinations in VLMs due to distribution shifts hinder reliability; current solutions are resource-intensive.", "method": "Proposes a test-time adaptation framework using reinforcement learning, updating only 0.003% of parameters in layer normalization.", "result": "Achieves 15.4% and 17.3% hallucination reduction on LLaVA and InstructBLIP, with a 68.3% improvement over baselines.", "conclusion": "The method effectively mitigates hallucinations without retraining or auxiliary models, enhancing VLM reliability."}}
{"id": "2505.06538", "pdf": "https://arxiv.org/pdf/2505.06538", "abs": "https://arxiv.org/abs/2505.06538", "authors": ["Xinyue Lou", "You Li", "Jinan Xu", "Xiangyu Shi", "Chi Chen", "Kaiyu Huang"], "title": "Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model", "categories": ["cs.CL"], "comment": "Work in Progress", "summary": "The rapid development of multimodal large reasoning models (MLRMs) has\ndemonstrated broad application potential, yet their safety and reliability\nremain critical concerns that require systematic exploration. To address this\ngap, we conduct a comprehensive and systematic safety evaluation of 11 MLRMs\nacross 5 benchmarks and unveil prevalent safety degradation phenomena in most\nadvanced models. Moreover, our analysis reveals distinct safety patterns across\ndifferent benchmarks: significant safety degradation is observed across\njailbreak robustness benchmarks, whereas safety-awareness benchmarks\ndemonstrate less pronounced degradation. In particular, a long thought process\nin some scenarios even enhances safety performance. Therefore, it is a\npotential approach to addressing safety issues in MLRMs by leveraging the\nintrinsic reasoning capabilities of the model to detect unsafe intent. To\noperationalize this insight, we construct a multimodal tuning dataset that\nincorporates a safety-oriented thought process. Experimental results from\nfine-tuning existing MLRMs with this dataset effectively enhances the safety on\nboth jailbreak robustness and safety-awareness benchmarks. This study provides\na new perspective for developing safe MLRMs. Our dataset is available at\nhttps://github.com/xinyuelou/Think-in-Safety.", "AI": {"tldr": "The paper evaluates the safety of multimodal large reasoning models (MLRMs), revealing safety degradation in advanced models and proposing a method to enhance safety using intrinsic reasoning capabilities.", "motivation": "To address the critical concerns of safety and reliability in MLRMs, which have broad application potential but lack systematic exploration.", "method": "Conducts a comprehensive safety evaluation of 11 MLRMs across 5 benchmarks, identifies safety patterns, and proposes fine-tuning with a safety-oriented thought process dataset.", "result": "Reveals prevalent safety degradation, distinct patterns across benchmarks, and improved safety after fine-tuning with the proposed dataset.", "conclusion": "Leveraging intrinsic reasoning capabilities can enhance MLRM safety, offering a new perspective for developing safer models."}}
{"id": "2505.07532", "pdf": "https://arxiv.org/pdf/2505.07532", "abs": "https://arxiv.org/abs/2505.07532", "authors": ["Kajetan Rachwa\u0142", "Maciej Majek", "Bart\u0142omiej Boczek", "Kacper D\u0105browski", "Pawe\u0142 Liberadzki", "Adam D\u0105browski", "Maria Ganzha"], "title": "RAI: Flexible Agent Framework for Embodied AI", "categories": ["cs.MA"], "comment": "12 pages, 8 figures, submitted to 23rd International Conference on\n  Practical applications of Agents and Multi-Agent Systems (PAAMS'25)", "summary": "With an increase in the capabilities of generative language models, a growing\ninterest in embodied AI has followed. This contribution introduces RAI - a\nframework for creating embodied Multi Agent Systems for robotics. The proposed\nframework implements tools for Agents' integration with robotic stacks, Large\nLanguage Models, and simulations. It provides out-of-the-box integration with\nstate-of-the-art systems like ROS 2. It also comes with dedicated mechanisms\nfor the embodiment of Agents. These mechanisms have been tested on a physical\nrobot, Husarion ROSBot XL, which was coupled with its digital twin, for rapid\nprototyping. Furthermore, these mechanisms have been deployed in two\nsimulations: (1) robot arm manipulator and (2) tractor controller. All of these\ndeployments have been evaluated in terms of their control capabilities,\neffectiveness of embodiment, and perception ability. The proposed framework has\nbeen used successfully to build systems with multiple agents. It has\ndemonstrated effectiveness in all the aforementioned tasks. It also enabled\nidentifying and addressing the shortcomings of the generative models used for\nembodied AI.", "AI": {"tldr": "RAI is a framework for embodied Multi Agent Systems in robotics, integrating robotic stacks, LLMs, and simulations, tested on physical and digital robots with successful deployments and evaluations.", "motivation": "To address the growing interest in embodied AI by providing a robust framework for integrating agents with robotics and simulations.", "method": "RAI implements tools for agent integration with robotic stacks, LLMs, and simulations, including ROS 2 and embodiment mechanisms, tested on a physical robot and digital twin.", "result": "Successful deployments in simulations (robot arm manipulator, tractor controller) and physical robot, demonstrating control, embodiment, and perception effectiveness.", "conclusion": "RAI effectively builds multi-agent systems, identifies generative model shortcomings, and proves versatile in embodied AI tasks."}}
{"id": "2505.06381", "pdf": "https://arxiv.org/pdf/2505.06381", "abs": "https://arxiv.org/abs/2505.06381", "authors": ["Saif Ur Rehman Khan", "Muhammad Nabeel Asim", "Sebastian Vollmer", "Andreas Dengel"], "title": "Robust & Precise Knowledge Distillation-based Novel Context-Aware Predictor for Disease Detection in Brain and Gastrointestinal", "categories": ["cs.CV"], "comment": null, "summary": "Medical disease prediction, particularly through imaging, remains a\nchallenging task due to the complexity and variability of medical data,\nincluding noise, ambiguity, and differing image quality. Recent deep learning\nmodels, including Knowledge Distillation (KD) methods, have shown promising\nresults in brain tumor image identification but still face limitations in\nhandling uncertainty and generalizing across diverse medical conditions.\nTraditional KD methods often rely on a context-unaware temperature parameter to\nsoften teacher model predictions, which does not adapt effectively to varying\nuncertainty levels present in medical images. To address this issue, we propose\na novel framework that integrates Ant Colony Optimization (ACO) for optimal\nteacher-student model selection and a novel context-aware predictor approach\nfor temperature scaling. The proposed context-aware framework adjusts the\ntemperature based on factors such as image quality, disease complexity, and\nteacher model confidence, allowing for more robust knowledge transfer.\nAdditionally, ACO efficiently selects the most appropriate teacher-student\nmodel pair from a set of pre-trained models, outperforming current optimization\nmethods by exploring a broader solution space and better handling complex,\nnon-linear relationships within the data. The proposed framework is evaluated\nusing three publicly available benchmark datasets, each corresponding to a\ndistinct medical imaging task. The results demonstrate that the proposed\nframework significantly outperforms current state-of-the-art methods, achieving\ntop accuracy rates: 98.01% on the MRI brain tumor (Kaggle) dataset, 92.81% on\nthe Figshare MRI dataset, and 96.20% on the GastroNet dataset. This enhanced\nperformance is further evidenced by the improved results, surpassing existing\nbenchmarks of 97.24% (Kaggle), 91.43% (Figshare), and 95.00% (GastroNet).", "AI": {"tldr": "A novel framework combining Ant Colony Optimization (ACO) and context-aware temperature scaling improves medical disease prediction by addressing uncertainty and variability in medical imaging.", "motivation": "Existing Knowledge Distillation (KD) methods struggle with uncertainty and generalization in medical imaging due to static temperature parameters.", "method": "Integrates ACO for optimal teacher-student model selection and a context-aware predictor for adaptive temperature scaling.", "result": "Achieves top accuracy rates: 98.01% (Kaggle), 92.81% (Figshare), and 96.20% (GastroNet), surpassing benchmarks.", "conclusion": "The proposed framework enhances robustness and accuracy in medical disease prediction, outperforming current methods."}}
{"id": "2505.06438", "pdf": "https://arxiv.org/pdf/2505.06438", "abs": "https://arxiv.org/abs/2505.06438", "authors": ["Yankai Zeng", "Gopal Gupta"], "title": "Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming", "categories": ["cs.AI"], "comment": "14 pages", "summary": "As the Large-Language-Model-driven (LLM-driven) Artificial Intelligence (AI)\nbots became popular, people realized their strong potential in Task-Oriented\nDialogue (TOD). However, bots relying wholly on LLMs are unreliable in their\nknowledge, and whether they can finally produce a correct result for the task\nis not guaranteed. The collaboration among these agents also remains a\nchallenge, since the necessary information to convey is unclear, and the\ninformation transfer is by prompts -- unreliable, and malicious knowledge is\neasy to inject. With the help of logic programming tools such as Answer Set\nProgramming (ASP), conversational agents can be built safely and reliably, and\ncommunication among the agents made more efficient and secure. We proposed an\nAdministrator-Assistant Dual-Agent paradigm, where the two ASP-driven bots\nshare the same knowledge base and complete their tasks independently, while the\ninformation can be passed by a Collaborative Rule Set (CRS). The knowledge and\ninformation conveyed are encapsulated and invisible to the users, ensuring the\nsecurity of information transmission. We have constructed AutoManager, a\ndual-agent system for managing the drive-through window of a fast-food\nrestaurant such as Taco Bell in the US. In AutoManager, the assistant bot takes\nthe customer's order while the administrator bot manages the menu and food\nsupply. We evaluated our AutoManager and compared it with the real-world Taco\nBell Drive-Thru AI Order Taker, and the results show that our method is more\nreliable.", "AI": {"tldr": "The paper proposes a dual-agent system using Answer Set Programming (ASP) for reliable and secure task-oriented dialogue, outperforming LLM-driven bots in a fast-food drive-through scenario.", "motivation": "LLM-driven AI bots are unreliable in task-oriented dialogues, and collaboration among agents is challenging due to insecure knowledge transfer.", "method": "An Administrator-Assistant Dual-Agent paradigm with ASP-driven bots sharing a knowledge base and using a Collaborative Rule Set (CRS) for secure communication.", "result": "The system, AutoManager, was tested in a fast-food drive-through scenario and proved more reliable than a real-world LLM-driven solution.", "conclusion": "ASP-driven dual-agent systems offer a secure and reliable alternative to LLM-driven bots for task-oriented dialogues."}}
{"id": "2505.06258", "pdf": "https://arxiv.org/pdf/2505.06258", "abs": "https://arxiv.org/abs/2505.06258", "authors": ["Zhiyu Zhu", "Jiayu Zhang", "Zhibo Jin", "Fang Chen", "Jianlong Zhou"], "title": "ABE: A Unified Framework for Robust and Faithful Attribution-Based Explainability", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Attribution algorithms are essential for enhancing the interpretability and\ntrustworthiness of deep learning models by identifying key features driving\nmodel decisions. Existing frameworks, such as InterpretDL and OmniXAI,\nintegrate multiple attribution methods but suffer from scalability limitations,\nhigh coupling, theoretical constraints, and lack of user-friendly\nimplementations, hindering neural network transparency and interoperability. To\naddress these challenges, we propose Attribution-Based Explainability (ABE), a\nunified framework that formalizes Fundamental Attribution Methods and\nintegrates state-of-the-art attribution algorithms while ensuring compliance\nwith attribution axioms. ABE enables researchers to develop novel attribution\ntechniques and enhances interpretability through four customizable modules:\nRobustness, Interpretability, Validation, and Data & Model. This framework\nprovides a scalable, extensible foundation for advancing attribution-based\nexplainability and fostering transparent AI systems. Our code is available at:\nhttps://github.com/LMBTough/ABE-XAI.", "AI": {"tldr": "ABE is a unified framework for attribution-based explainability, addressing scalability, coupling, and usability issues in existing methods.", "motivation": "Existing attribution frameworks like InterpretDL and OmniXAI have scalability, theoretical, and usability limitations, hindering neural network transparency.", "method": "ABE formalizes Fundamental Attribution Methods, integrates state-of-the-art algorithms, and offers four customizable modules: Robustness, Interpretability, Validation, and Data & Model.", "result": "ABE provides a scalable, extensible foundation for developing novel attribution techniques and enhancing interpretability.", "conclusion": "ABE advances attribution-based explainability, fostering transparent AI systems, with code available for public use."}}
{"id": "2505.07615", "pdf": "https://arxiv.org/pdf/2505.07615", "abs": "https://arxiv.org/abs/2505.07615", "authors": ["Riccardo Passoni", "Francesca Ronchini", "Luca Comanducci", "Romain Serizel", "Fabio Antonacci"], "title": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "comment": null, "summary": "Text-to-audio models have recently emerged as a powerful technology for\ngenerating sound from textual descriptions. However, their high computational\ndemands raise concerns about energy consumption and environmental impact. In\nthis paper, we conduct an analysis of the energy usage of 7 state-of-the-art\ntext-to-audio diffusion-based generative models, evaluating to what extent\nvariations in generation parameters affect energy consumption at inference\ntime. We also aim to identify an optimal balance between audio quality and\nenergy consumption by considering Pareto-optimal solutions across all selected\nmodels. Our findings provide insights into the trade-offs between performance\nand environmental impact, contributing to the development of more efficient\ngenerative audio models.", "AI": {"tldr": "Analysis of energy usage in 7 text-to-audio diffusion models, exploring trade-offs between audio quality and energy efficiency.", "motivation": "Address concerns about high computational demands and environmental impact of text-to-audio models.", "method": "Evaluate energy consumption of 7 state-of-the-art models, analyzing parameter variations and Pareto-optimal solutions.", "result": "Identified trade-offs between audio quality and energy efficiency, providing insights for efficient model development.", "conclusion": "Highlights the need for balancing performance and environmental impact in generative audio models."}}
{"id": "2505.06793", "pdf": "https://arxiv.org/pdf/2505.06793", "abs": "https://arxiv.org/abs/2505.06793", "authors": ["Erik Gro\u00dfkopf", "Valay Bundele", "Mehran Hossienzadeh", "Hendrik P. A. Lensch"], "title": "HistDiST: Histopathological Diffusion-based Stain Transfer", "categories": ["eess.IV", "cs.CV"], "comment": "8 pages, 4 figures", "summary": "Hematoxylin and Eosin (H&E) staining is the cornerstone of histopathology but\nlacks molecular specificity. While Immunohistochemistry (IHC) provides\nmolecular insights, it is costly and complex, motivating H&E-to-IHC translation\nas a cost-effective alternative. Existing translation methods are mainly\nGAN-based, often struggling with training instability and limited structural\nfidelity, while diffusion-based approaches remain underexplored. We propose\nHistDiST, a Latent Diffusion Model (LDM) based framework for high-fidelity\nH&E-to-IHC translation. HistDiST introduces a dual-conditioning strategy,\nutilizing Phikon-extracted morphological embeddings alongside VAE-encoded H&E\nrepresentations to ensure pathology-relevant context and structural\nconsistency. To overcome brightness biases, we incorporate a rescaled noise\nschedule, v-prediction, and trailing timesteps, enforcing a zero-SNR condition\nat the final timestep. During inference, DDIM inversion preserves the\nmorphological structure, while an eta-cosine noise schedule introduces\ncontrolled stochasticity, balancing structural consistency and molecular\nfidelity. Moreover, we propose Molecular Retrieval Accuracy (MRA), a novel\npathology-aware metric leveraging GigaPath embeddings to assess molecular\nrelevance. Extensive evaluations on MIST and BCI datasets demonstrate that\nHistDiST significantly outperforms existing methods, achieving a 28%\nimprovement in MRA on the H&E-to-Ki67 translation task, highlighting its\neffectiveness in capturing true IHC semantics.", "AI": {"tldr": "HistDiST, a Latent Diffusion Model, improves H&E-to-IHC translation with dual-conditioning and novel metrics, outperforming GAN-based methods by 28% in molecular relevance.", "motivation": "H&E staining lacks molecular specificity, and IHC is costly. Existing GAN-based methods face instability and fidelity issues, while diffusion models are underexplored.", "method": "HistDiST uses a Latent Diffusion Model with dual-conditioning (morphological embeddings and VAE-encoded H&E), rescaled noise schedule, and DDIM inversion for structural consistency.", "result": "HistDiST achieves a 28% improvement in Molecular Retrieval Accuracy (MRA) on H&E-to-Ki67 translation, outperforming existing methods.", "conclusion": "HistDiST effectively bridges H&E and IHC with high fidelity, offering a cost-effective alternative to IHC."}}
{"id": "2505.07280", "pdf": "https://arxiv.org/pdf/2505.07280", "abs": "https://arxiv.org/abs/2505.07280", "authors": ["Navid Falah", "Behnam Yousefimehr", "Mehdi Ghatee"], "title": "Predicting Music Track Popularity by Convolutional Neural Networks on Spotify Features and Spectrogram of Audio Waveform", "categories": ["cs.SD", "cs.AI", "68T05, 68T10, 68T37", "I.2.6; I.2.1"], "comment": "12 pages, 6 figures, 4 tables", "summary": "In the digital streaming landscape, it's becoming increasingly challenging\nfor artists and industry experts to predict the success of music tracks. This\nstudy introduces a pioneering methodology that uses Convolutional Neural\nNetworks (CNNs) and Spotify data analysis to forecast the popularity of music\ntracks. Our approach takes advantage of Spotify's wide range of features,\nincluding acoustic attributes based on the spectrogram of audio waveform,\nmetadata, and user engagement metrics, to capture the complex patterns and\nrelationships that influence a track's popularity. Using a large dataset\ncovering various genres and demographics, our CNN-based model shows impressive\neffectiveness in predicting the popularity of music tracks. Additionally, we've\nconducted extensive experiments to assess the strength and adaptability of our\nmodel across different musical styles and time periods, with promising results\nyielding a 97\\% F1 score. Our study not only offers valuable insights into the\ndynamic landscape of digital music consumption but also provides the music\nindustry with advanced predictive tools for assessing and predicting the\nsuccess of music tracks.", "AI": {"tldr": "A CNN-based model using Spotify data predicts music track popularity with 97% F1 score.", "motivation": "Predicting music track success is challenging; this study aims to provide a data-driven solution using Spotify features.", "method": "Uses Convolutional Neural Networks (CNNs) to analyze Spotify data, including acoustic attributes, metadata, and user engagement metrics.", "result": "The model achieves a 97% F1 score in predicting music popularity across genres and time periods.", "conclusion": "The study offers insights into digital music trends and provides the industry with a predictive tool for track success."}}
{"id": "2105.00335", "pdf": "https://arxiv.org/pdf/2105.00335", "abs": "https://arxiv.org/abs/2105.00335", "authors": ["Prateek Verma", "Jonathan Berger"], "title": "Audio Transformers", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": "5 pages, 4 figures; Under review WASPAA 2021; Typo Fixes", "summary": "Over the past two decades, CNN architectures have produced compelling models\nof sound perception and cognition, learning hierarchical organizations of\nfeatures. Analogous to successes in computer vision, audio feature\nclassification can be optimized for a particular task of interest, over a wide\nvariety of datasets and labels. In fact similar architectures designed for\nimage understanding have proven effective for acoustic scene analysis. Here we\npropose applying Transformer based architectures without convolutional layers\nto raw audio signals. On a standard dataset of Free Sound 50K,comprising of 200\ncategories, our model outperforms convolutional models to produce state of the\nart results. This is significant as unlike in natural language processing and\ncomputer vision, we do not perform unsupervised pre-training for outperforming\nconvolutional architectures. On the same training set, with respect mean\naver-age precision benchmarks, we show a significant improvement. We further\nimprove the performance of Transformer architectures by using techniques such\nas pooling inspired from convolutional net-work designed in the past few years.\nIn addition, we also show how multi-rate signal processing ideas inspired from\nwavelets, can be applied to the Transformer embeddings to improve the results.\nWe also show how our models learns a non-linear non constant band-width\nfilter-bank, which shows an adaptable time frequency front end representation\nfor the task of audio understanding, different from other tasks e.g. pitch\nestimation.", "AI": {"tldr": "Transformers outperform CNNs in audio classification on the Free Sound 50K dataset without unsupervised pre-training, using pooling and multi-rate signal processing techniques.", "motivation": "To explore Transformer architectures for raw audio signals, challenging the dominance of CNNs in audio feature classification.", "method": "Applied Transformer architectures directly to raw audio, incorporating pooling and multi-rate signal processing inspired by wavelets.", "result": "Achieved state-of-the-art results on Free Sound 50K, surpassing convolutional models in mean average precision.", "conclusion": "Transformers can effectively replace CNNs in audio understanding, learning adaptable time-frequency representations."}}
{"id": "2505.06548", "pdf": "https://arxiv.org/pdf/2505.06548", "abs": "https://arxiv.org/abs/2505.06548", "authors": ["Aniruddha Roy", "Pretam Ray", "Abhilash Nandy", "Somak Aditya", "Pawan Goyal"], "title": "REFINE-AF: A Task-Agnostic Framework to Align Language Models via Self-Generated Instructions using Reinforcement Learning from Automated Feedback", "categories": ["cs.CL"], "comment": "11 pages", "summary": "Instruction-based Large Language Models (LLMs) have proven effective in\nnumerous few-shot or zero-shot Natural Language Processing (NLP) tasks.\nHowever, creating human-annotated instruction data is time-consuming,\nexpensive, and often limited in quantity and task diversity. Previous research\nendeavors have attempted to address this challenge by proposing frameworks\ncapable of generating instructions in a semi-automated and task-agnostic manner\ndirectly from the model itself. Many of these efforts have relied on large\nAPI-only parameter-based models such as GPT-3.5 (175B), which are expensive,\nand subject to limits on a number of queries. This paper explores the\nperformance of three open-source small LLMs such as LLaMA 2-7B, LLama 2-13B,\nand Mistral 7B, using a semi-automated framework, thereby reducing human\nintervention, effort, and cost required to generate an instruction dataset for\nfine-tuning LLMs. Furthermore, we demonstrate that incorporating a\nReinforcement Learning (RL) based training algorithm into this LLMs-based\nframework leads to further enhancements. Our evaluation of the dataset reveals\nthat these RL-based frameworks achieve a substantial improvements in 63-66% of\nthe tasks compared to previous approaches.", "AI": {"tldr": "The paper explores using small open-source LLMs (LLaMA 2-7B, LLaMA 2-13B, Mistral 7B) with a semi-automated framework to generate instruction datasets, reducing human effort and cost. Adding RL-based training further improves performance in 63-66% of tasks.", "motivation": "Human-annotated instruction data is costly and limited. Previous methods rely on expensive API-only models like GPT-3.5, prompting the need for cheaper, open-source alternatives.", "method": "Uses small open-source LLMs with a semi-automated framework and integrates RL-based training to enhance performance.", "result": "RL-based frameworks improve performance in 63-66% of tasks compared to prior methods.", "conclusion": "Small open-source LLMs with RL can effectively generate instruction datasets, reducing costs and human effort while improving task performance."}}
{"id": "2505.06409", "pdf": "https://arxiv.org/pdf/2505.06409", "abs": "https://arxiv.org/abs/2505.06409", "authors": ["Krti Tallam"], "title": "Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "As AI models scale to billions of parameters and operate with increasing\nautonomy, ensuring their safe, reliable operation demands engineering-grade\nsecurity and assurance frameworks. This paper presents an enterprise-level,\nrisk-aware, security-by-design approach for large-scale autonomous AI systems,\nintegrating standardized threat metrics, adversarial hardening techniques, and\nreal-time anomaly detection into every phase of the development lifecycle. We\ndetail a unified pipeline - from design-time risk assessments and secure\ntraining protocols to continuous monitoring and automated audit logging - that\ndelivers provable guarantees of model behavior under adversarial and\noperational stress. Case studies in national security, open-source model\ngovernance, and industrial automation demonstrate measurable reductions in\nvulnerability and compliance overhead. Finally, we advocate cross-sector\ncollaboration - uniting engineering teams, standards bodies, and regulatory\nagencies - to institutionalize these technical safeguards within a resilient,\nend-to-end assurance ecosystem for the next generation of AI.", "AI": {"tldr": "The paper proposes a security-by-design framework for large-scale AI systems, integrating threat metrics, adversarial hardening, and anomaly detection to ensure safe, reliable operation.", "motivation": "Ensuring the safety and reliability of increasingly autonomous AI systems with billions of parameters demands robust security and assurance frameworks.", "method": "A unified pipeline includes risk assessments, secure training, real-time monitoring, and automated audit logging, tested in national security, open-source governance, and industrial automation.", "result": "Case studies show measurable reductions in vulnerabilities and compliance overhead.", "conclusion": "The paper advocates cross-sector collaboration to institutionalize these safeguards for next-gen AI systems."}}
{"id": "2505.06389", "pdf": "https://arxiv.org/pdf/2505.06389", "abs": "https://arxiv.org/abs/2505.06389", "authors": ["Adrien Chan-Hon-Tong", "Aur\u00e9lien Plyer", "Baptiste Cadalen", "Laurent Serre"], "title": "Deep Learning-Based Robust Optical Guidance for Hypersonic Platforms", "categories": ["cs.CV"], "comment": null, "summary": "Sensor-based guidance is required for long-range platforms. To bypass the\nstructural limitation of classical registration on reference image framework,\nwe offer in this paper to encode a stack of images of the scene into a deep\nnetwork. Relying on a stack is showed to be relevant on bimodal scene (e.g.\nwhen the scene can or can not be snowy).", "AI": {"tldr": "The paper proposes encoding a stack of images into a deep network to bypass limitations of classical registration methods, particularly for bimodal scenes like snowy conditions.", "motivation": "Classical registration methods have structural limitations for long-range platforms, especially in varying conditions (e.g., snowy vs. non-snowy scenes).", "method": "The approach encodes a stack of scene images into a deep network, leveraging the stack's relevance for bimodal scenes.", "result": "The method demonstrates effectiveness in handling bimodal scenes, such as snowy conditions, by using deep learning.", "conclusion": "Deep network-based encoding of image stacks is a viable solution for sensor-based guidance in long-range platforms with varying scene conditions."}}
{"id": "2505.06464", "pdf": "https://arxiv.org/pdf/2505.06464", "abs": "https://arxiv.org/abs/2505.06464", "authors": ["Tamara Paris", "AJung Moon", "Jin Guo"], "title": "Opening the Scope of Openness in AI", "categories": ["cs.AI"], "comment": "To appear in ACM Conference on Fairness, Accountability, and\n  Transparency (ACM FAccT) 2025", "summary": "The concept of openness in AI has so far been heavily inspired by the\ndefinition and community practice of open source software. This positions\nopenness in AI as having positive connotations; it introduces assumptions of\ncertain advantages, such as collaborative innovation and transparency. However,\nthe practices and benefits of open source software are not fully transferable\nto AI, which has its own challenges. Framing a notion of openness tailored to\nAI is crucial to addressing its growing societal implications, risks, and\ncapabilities. We argue that considering the fundamental scope of openness in\ndifferent disciplines will broaden discussions, introduce important\nperspectives, and reflect on what openness in AI should mean. Toward this goal,\nwe qualitatively analyze 98 concepts of openness discovered from topic\nmodeling, through which we develop a taxonomy of openness. Using this taxonomy\nas an instrument, we situate the current discussion on AI openness, identify\ngaps and highlight links with other disciplines. Our work contributes to the\nrecent efforts in framing openness in AI by reflecting principles and practices\nof openness beyond open source software and calls for a more holistic view of\nopenness in terms of actions, system properties, and ethical objectives.", "AI": {"tldr": "The paper critiques the current framing of openness in AI, inspired by open source software, and proposes a tailored taxonomy of openness for AI to address its unique challenges and societal impacts.", "motivation": "The motivation is to challenge the assumptions of openness in AI, derived from open source software, and to develop a more nuanced understanding tailored to AI's specific needs and risks.", "method": "The authors qualitatively analyze 98 concepts of openness from topic modeling to create a taxonomy of openness, which is then used to evaluate current AI openness discussions.", "result": "The study results in a taxonomy of openness for AI, identifying gaps and interdisciplinary links, and advocating for a broader, more holistic view of openness.", "conclusion": "The paper concludes that openness in AI should be redefined beyond open source principles, incorporating actions, system properties, and ethical objectives for a more comprehensive approach."}}
{"id": "2505.06259", "pdf": "https://arxiv.org/pdf/2505.06259", "abs": "https://arxiv.org/abs/2505.06259", "authors": ["Mattia Setzu", "Riccardo Guidotti"], "title": "Fair Clustering with Clusterlets", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Given their widespread usage in the real world, the fairness of clustering\nmethods has become of major interest. Theoretical results on fair clustering\nshow that fairness enjoys transitivity: given a set of small and fair clusters,\na trivial centroid-based clustering algorithm yields a fair clustering.\nUnfortunately, discovering a suitable starting clustering can be\ncomputationally expensive, rather complex or arbitrary.\n  In this paper, we propose a set of simple \\emph{clusterlet}-based fuzzy\nclustering algorithms that match single-class clusters, optimizing fair\nclustering. Matching leverages clusterlet distance, optimizing for classic\nclustering objectives, while also regularizing for fairness. Empirical results\nshow that simple matching strategies are able to achieve high fairness, and\nthat appropriate parameter tuning allows to achieve high cohesion and low\noverlap.", "AI": {"tldr": "The paper proposes simple fuzzy clustering algorithms using \"clusterlets\" to optimize fairness in clustering, achieving high fairness and cohesion with proper tuning.", "motivation": "Fairness in clustering is crucial due to its real-world applications, but existing methods for fair clustering can be computationally expensive or arbitrary.", "method": "The authors introduce clusterlet-based fuzzy clustering algorithms that match single-class clusters, optimizing fairness by leveraging clusterlet distance and regularizing for fairness.", "result": "Empirical results show the proposed methods achieve high fairness, cohesion, and low overlap with appropriate parameter tuning.", "conclusion": "Simple matching strategies using clusterlets effectively optimize fair clustering, balancing fairness and clustering quality."}}
{"id": "2505.07631", "pdf": "https://arxiv.org/pdf/2505.07631", "abs": "https://arxiv.org/abs/2505.07631", "authors": ["Kohei Saijo", "Yoshiaki Bando"], "title": "Is MixIT Really Unsuitable for Correlated Sources? Exploring MixIT for Unsupervised Pre-training in Music Source Separation", "categories": ["eess.AS"], "comment": "5 pages, 1 figure, 3 tables", "summary": "In music source separation (MSS), obtaining isolated sources or stems is\nhighly costly, making pre-training on unlabeled data a promising approach.\nAlthough source-agnostic unsupervised learning like mixture-invariant training\n(MixIT) has been explored in general sound separation, they have been largely\noverlooked in MSS due to its implicit assumption of source independence. We\nhypothesize, however, that the difficulty of applying MixIT to MSS arises from\nthe ill-posed nature of MSS itself, where stem definitions are\napplication-dependent and models lack explicit knowledge of what should or\nshould not be separated, rather than from high inter-source correlation. While\nMixIT does not assume any source model and struggles with such ambiguities, our\npreliminary experiments show that it can still separate instruments to some\nextent, suggesting its potential for unsupervised pre-training. Motivated by\nthese insights, this study investigates MixIT-based pre-training for MSS. We\nfirst pre-train a model on in-the-wild, unlabeled data from the Free Music\nArchive using MixIT, and then fine-tune it on MUSDB18 with supervision. Using\nthe band-split TF-Locoformer, one of the state-of-the-art MSS models, we\ndemonstrate that MixIT-based pre-training improves the performance over\ntraining from scratch.", "AI": {"tldr": "MixIT-based pre-training improves music source separation (MSS) performance, even though MixIT was overlooked in MSS due to source independence assumptions.", "motivation": "High cost of obtaining isolated music sources makes unsupervised pre-training appealing. MixIT, though not designed for MSS, shows potential for separating instruments.", "method": "Pre-train a model on unlabeled Free Music Archive data using MixIT, then fine-tune on MUSDB18 with supervision using the band-split TF-Locoformer model.", "result": "MixIT-based pre-training outperforms training from scratch, enhancing MSS performance.", "conclusion": "MixIT is a viable approach for unsupervised pre-training in MSS, despite its challenges, offering performance gains."}}
{"id": "2505.06811", "pdf": "https://arxiv.org/pdf/2505.06811", "abs": "https://arxiv.org/abs/2505.06811", "authors": ["Tan-Hanh Pham", "Ovidiu C. Andronesi", "Xianqi Li", "Kim-Doang Nguyen"], "title": "Missing Data Estimation for MR Spectroscopic Imaging via Mask-Free Deep Learning Methods", "categories": ["eess.IV", "cs.CV"], "comment": "8 pages", "summary": "Magnetic Resonance Spectroscopic Imaging (MRSI) is a powerful tool for\nnon-invasive mapping of brain metabolites, providing critical insights into\nneurological conditions. However, its utility is often limited by missing or\ncorrupted data due to motion artifacts, magnetic field inhomogeneities, or\nfailed spectral fitting-especially in high resolution 3D acquisitions. To\naddress this, we propose the first deep learning-based, mask-free framework for\nestimating missing data in MRSI metabolic maps. Unlike conventional restoration\nmethods that rely on explicit masks to identify missing regions, our approach\nimplicitly detects and estimates these areas using contextual spatial features\nthrough 2D and 3D U-Net architectures. We also introduce a progressive training\nstrategy to enhance robustness under varying levels of data degradation. Our\nmethod is evaluated on both simulated and real patient datasets and\nconsistently outperforms traditional interpolation techniques such as cubic and\nlinear interpolation. The 2D model achieves an MSE of 0.002 and an SSIM of 0.97\nwith 20% missing voxels, while the 3D model reaches an MSE of 0.001 and an SSIM\nof 0.98 with 15% missing voxels. Qualitative results show improved fidelity in\nestimating missing data, particularly in metabolically heterogeneous regions\nand ventricular regions. Importantly, our model generalizes well to real-world\ndatasets without requiring retraining or mask input. These findings demonstrate\nthe effectiveness and broad applicability of mask-free deep learning for MRSI\nrestoration, with strong potential for clinical and research integration.", "AI": {"tldr": "A deep learning-based, mask-free framework for estimating missing data in MRSI metabolic maps outperforms traditional methods, achieving high accuracy and robustness.", "motivation": "MRSI's utility is limited by missing or corrupted data due to motion artifacts, field inhomogeneities, or spectral fitting failures, especially in high-resolution 3D acquisitions.", "method": "The proposed framework uses 2D and 3D U-Net architectures to implicitly detect and estimate missing data, along with a progressive training strategy for robustness.", "result": "The 2D model achieves an MSE of 0.002 and SSIM of 0.97 with 20% missing voxels; the 3D model reaches an MSE of 0.001 and SSIM of 0.98 with 15% missing voxels.", "conclusion": "The mask-free deep learning approach is effective and broadly applicable for MRSI restoration, with strong potential for clinical and research use."}}
{"id": "2505.07701", "pdf": "https://arxiv.org/pdf/2505.07701", "abs": "https://arxiv.org/abs/2505.07701", "authors": ["Biel Tura Vecino", "Adam Gabry\u015b", "Daniel M\u0105twicki", "Andrzej Pomirski", "Tom Iddon", "Marius Cotescu", "Jaime Lorenzo-Trueba"], "title": "Lightweight End-to-end Text-to-speech Synthesis for low resource on-device applications", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Published as a conference paper at SSW 2023", "summary": "Recent works have shown that modelling raw waveform directly from text in an\nend-to-end (E2E) fashion produces more natural-sounding speech than traditional\nneural text-to-speech (TTS) systems based on a cascade or two-stage approach.\nHowever, current E2E state-of-the-art models are computationally complex and\nmemory-consuming, making them unsuitable for real-time offline on-device\napplications in low-resource scenarios. To address this issue, we propose a\nLightweight E2E-TTS (LE2E) model that generates high-quality speech requiring\nminimal computational resources. We evaluate the proposed model on the LJSpeech\ndataset and show that it achieves state-of-the-art performance while being up\nto $90\\%$ smaller in terms of model parameters and $10\\times$ faster in\nreal-time-factor. Furthermore, we demonstrate that the proposed E2E training\nparadigm achieves better quality compared to an equivalent architecture trained\nin a two-stage approach. Our results suggest that LE2E is a promising approach\nfor developing real-time, high quality, low-resource TTS applications for\non-device applications.", "AI": {"tldr": "The paper proposes a lightweight end-to-end (LE2E) text-to-speech (TTS) model that reduces computational complexity and memory usage while maintaining high-quality speech generation, making it suitable for low-resource, on-device applications.", "motivation": "Current end-to-end TTS models are computationally heavy and memory-intensive, limiting their use in real-time, low-resource scenarios.", "method": "The authors introduce a lightweight E2E-TTS model (LE2E) and evaluate it on the LJSpeech dataset, comparing it to traditional two-stage approaches.", "result": "LE2E achieves state-of-the-art performance with 90% fewer parameters and 10x faster real-time factor, outperforming equivalent two-stage models in quality.", "conclusion": "LE2E is a promising solution for real-time, high-quality, low-resource TTS applications on devices."}}
{"id": "2505.03603", "pdf": "https://arxiv.org/pdf/2505.03603", "abs": "https://arxiv.org/abs/2505.03603", "authors": ["S. Z. Zhou", "Y. B. Wang", "J. F. Wu", "T. Hu", "J. N. Zhang", "Z. J. Li", "Y. Liu"], "title": "PAHA: Parts-Aware Audio-Driven Human Animation with Diffusion Model", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Audio-driven human animation technology is widely used in human-computer\ninteraction, and the emergence of diffusion models has further advanced its\ndevelopment. Currently, most methods rely on multi-stage generation and\nintermediate representations, resulting in long inference time and issues with\ngeneration quality in specific foreground regions and audio-motion consistency.\nThese shortcomings are primarily due to the lack of localized fine-grained\nsupervised guidance. To address above challenges, we propose PAHA, an\nend-to-end audio-driven upper-body human animation framework with diffusion\nmodel. We introduce two key methods: Parts-Aware Re-weighting (PAR) and Parts\nConsistency Enhancement (PCE). PAR dynamically adjusts regional training loss\nweights based on pose confidence scores, effectively improving visual quality.\nPCE constructs and trains diffusion-based regional audio-visual classifiers to\nimprove the consistency of motion and co-speech audio. Afterwards, we design\ntwo novel inference guidance methods for the foregoing classifiers, Sequential\nGuidance (SG) and Differential Guidance (DG), to balance efficiency and quality\nrespectively. Additionally, we build CNAS, the first public Chinese News Anchor\nSpeech dataset, to advance research and validation in this field. Extensive\nexperimental results and user studies demonstrate that PAHA significantly\noutperforms existing methods in audio-motion alignment and video-related\nevaluations. The codes and CNAS dataset will be released upon acceptance.", "AI": {"tldr": "PAHA is an end-to-end audio-driven upper-body human animation framework using diffusion models, addressing quality and consistency issues with PAR and PCE methods, and introducing the CNAS dataset.", "motivation": "Current methods suffer from long inference times and poor quality in specific regions due to lack of localized fine-grained supervision.", "method": "PAHA uses Parts-Aware Re-weighting (PAR) and Parts Consistency Enhancement (PCE) for improved quality and consistency, with novel inference guidance methods (SG and DG).", "result": "PAHA outperforms existing methods in audio-motion alignment and video evaluations, validated by experiments and user studies.", "conclusion": "PAHA advances audio-driven human animation with efficient, high-quality results, supported by the new CNAS dataset."}}
{"id": "2505.06552", "pdf": "https://arxiv.org/pdf/2505.06552", "abs": "https://arxiv.org/abs/2505.06552", "authors": ["Doyoung Kim", "Youngjun Lee", "Joeun Kim", "Jihwan Bang", "Hwanjun Song", "Susik Yoon", "Jae-Gil Lee"], "title": "References Indeed Matter? Reference-Free Preference Optimization for Conversational Query Reformulation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Conversational query reformulation (CQR) has become indispensable for\nimproving retrieval in dialogue-based applications. However, existing\napproaches typically rely on reference passages for optimization, which are\nimpractical to acquire in real-world scenarios. To address this limitation, we\nintroduce a novel reference-free preference optimization framework DualReform\nthat generates pseudo reference passages from commonly-encountered\nconversational datasets containing only queries and responses. DualReform\nattains this goal through two key innovations: (1) response-based inference,\nwhere responses serve as proxies to infer pseudo reference passages, and (2)\nresponse refinement via the dual-role of CQR, where a CQR model refines\nresponses based on the shared objectives between response refinement and CQR.\nDespite not relying on reference passages, DualReform achieves 96.9--99.1% of\nthe retrieval accuracy attainable only with reference passages and surpasses\nthe state-of-the-art method by up to 31.6%.", "AI": {"tldr": "DualReform introduces a reference-free framework for conversational query reformulation (CQR) using pseudo reference passages, achieving near-optimal retrieval accuracy without real references.", "motivation": "Existing CQR methods rely on impractical reference passages, limiting real-world applicability.", "method": "DualReform uses response-based inference to generate pseudo references and refines responses via dual-role CQR.", "result": "Achieves 96.9--99.1% of retrieval accuracy without real references, outperforming state-of-the-art by up to 31.6%.", "conclusion": "DualReform provides a practical and effective solution for CQR without needing reference passages."}}
{"id": "2505.06588", "pdf": "https://arxiv.org/pdf/2505.06588", "abs": "https://arxiv.org/abs/2505.06588", "authors": ["Yu Cheng", "Harun \u0160iljak"], "title": "Emergent Multi-View Fidelity in Autonomous UAV Swarm Sport Injury Detection", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY", "nlin.AO"], "comment": "Accepted for 2025 8th International Balkan Conference on\n  Communications and Networking (Balkancom)", "summary": "Accurate, real-time collision detection is essential for ensuring player\nsafety and effective refereeing in high-contact sports such as rugby,\nparticularly given the severe risks associated with traumatic brain injuries\n(TBI). Traditional collision-monitoring methods employing fixed cameras or\nwearable sensors face limitations in visibility, coverage, and responsiveness.\nPreviously, we introduced a framework using unmanned aerial vehicles (UAVs) for\nmonitoring and real time kinematics extraction from videos of collision events.\nIn this paper, we show that the strategies operating on the objective of\nensuring at least one UAV captures every incident on the pitch have an emergent\nproperty of fulfilling a stronger key condition for successful kinematics\nextraction. Namely, they ensure that almost all collisions are captured by\nmultiple drones, establishing multi-view fidelity and redundancy, while not\nrequiring any drone-to-drone communication.", "AI": {"tldr": "A UAV-based framework ensures multi-view collision capture in rugby without drone communication, improving safety and kinematics extraction.", "motivation": "Address limitations of traditional collision-monitoring methods (fixed cameras, wearables) in rugby to prevent TBI risks.", "method": "UAVs monitor collisions, ensuring multi-view capture without inter-drone communication.", "result": "Strategies ensure most collisions are captured by multiple drones, enhancing fidelity and redundancy.", "conclusion": "The UAV framework effectively improves collision monitoring and kinematics extraction for player safety."}}
{"id": "2505.06393", "pdf": "https://arxiv.org/pdf/2505.06393", "abs": "https://arxiv.org/abs/2505.06393", "authors": ["Valfride Nascimento", "Gabriel E. Lima", "Rafael O. Ribeiro", "William Robson Schwartz", "Rayson Laroca", "David Menotti"], "title": "Toward Advancing License Plate Super-Resolution in Real-World Scenarios: A Dataset and Benchmark", "categories": ["cs.CV"], "comment": "Accepted for publication in the Journal of the Brazilian Computer\n  Society", "summary": "Recent advancements in super-resolution for License Plate Recognition (LPR)\nhave sought to address challenges posed by low-resolution (LR) and degraded\nimages in surveillance, traffic monitoring, and forensic applications. However,\nexisting studies have relied on private datasets and simplistic degradation\nmodels. To address this gap, we introduce UFPR-SR-Plates, a novel dataset\ncontaining 10,000 tracks with 100,000 paired low and high-resolution license\nplate images captured under real-world conditions. We establish a benchmark\nusing multiple sequential LR and high-resolution (HR) images per vehicle --\nfive of each -- and two state-of-the-art models for super-resolution of license\nplates. We also investigate three fusion strategies to evaluate how combining\npredictions from a leading Optical Character Recognition (OCR) model for\nmultiple super-resolved license plates enhances overall performance. Our\nfindings demonstrate that super-resolution significantly boosts LPR\nperformance, with further improvements observed when applying majority\nvote-based fusion techniques. Specifically, the Layout-Aware and\nCharacter-Driven Network (LCDNet) model combined with the Majority Vote by\nCharacter Position (MVCP) strategy led to the highest recognition rates,\nincreasing from 1.7% with low-resolution images to 31.1% with super-resolution,\nand up to 44.7% when combining OCR outputs from five super-resolved images.\nThese findings underscore the critical role of super-resolution and temporal\ninformation in enhancing LPR accuracy under real-world, adverse conditions. The\nproposed dataset is publicly available to support further research and can be\naccessed at: https://valfride.github.io/nascimento2024toward/", "AI": {"tldr": "The paper introduces UFPR-SR-Plates, a dataset for super-resolution in License Plate Recognition (LPR), and benchmarks it with state-of-the-art models and fusion strategies, showing significant performance improvements.", "motivation": "Addressing gaps in existing studies that rely on private datasets and simplistic degradation models for LPR super-resolution.", "method": "Introduces UFPR-SR-Plates dataset, benchmarks with two super-resolution models, and evaluates three fusion strategies for OCR performance.", "result": "Super-resolution boosts LPR performance, with the best model (LCDNet) and fusion strategy (MVCP) increasing recognition rates from 1.7% to 44.7%.", "conclusion": "Super-resolution and temporal fusion are crucial for improving LPR accuracy in real-world conditions; the dataset is publicly available for further research."}}
{"id": "2505.06469", "pdf": "https://arxiv.org/pdf/2505.06469", "abs": "https://arxiv.org/abs/2505.06469", "authors": ["Yumou Wei", "Paulo Carvalho", "John Stamper"], "title": "KCluster: An LLM-based Clustering Approach to Knowledge Component Discovery", "categories": ["cs.AI", "cs.HC"], "comment": "Accepted to the Educational Data Mining (EDM) 2025 conference", "summary": "Educators evaluate student knowledge using knowledge component (KC) models\nthat map assessment questions to KCs. Still, designing KC models for large\nquestion banks remains an insurmountable challenge for instructors who need to\nanalyze each question by hand. The growing use of Generative AI in education is\nexpected only to aggravate this chronic deficiency of expert-designed KC\nmodels, as course engineers designing KCs struggle to keep up with the pace at\nwhich questions are generated. In this work, we propose KCluster, a novel KC\ndiscovery algorithm based on identifying clusters of congruent questions\naccording to a new similarity metric induced by a large language model (LLM).\nWe demonstrate in three datasets that an LLM can create an effective metric of\nquestion similarity, which a clustering algorithm can use to create KC models\nfrom questions with minimal human effort. Combining the strengths of LLM and\nclustering, KCluster generates descriptive KC labels and discovers KC models\nthat predict student performance better than the best expert-designed models\navailable. In anticipation of future work, we illustrate how KCluster can\nreveal insights into difficult KCs and suggest improvements to instruction.", "AI": {"tldr": "KCluster uses LLM-induced similarity metrics and clustering to automate KC model creation, outperforming expert-designed models.", "motivation": "Manual KC model design is slow and unsustainable with growing question banks and Generative AI use.", "method": "KCluster employs an LLM to measure question similarity and clustering to group questions into KCs.", "result": "KCluster's models predict student performance better than expert-designed ones and generate descriptive KC labels.", "conclusion": "KCluster automates KC discovery, reduces human effort, and offers insights for improving instruction."}}
{"id": "2505.06262", "pdf": "https://arxiv.org/pdf/2505.06262", "abs": "https://arxiv.org/abs/2505.06262", "authors": ["Zara Siddique", "Liam D. Turner", "Luis Espinosa-Anke"], "title": "Dialz: A Python Toolkit for Steering Vectors", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Dialz, a framework for advancing research on steering vectors\nfor open-source LLMs, implemented in Python. Steering vectors allow users to\nmodify activations at inference time to amplify or weaken a 'concept', e.g.\nhonesty or positivity, providing a more powerful alternative to prompting or\nfine-tuning. Dialz supports a diverse set of tasks, including creating\ncontrastive pair datasets, computing and applying steering vectors, and\nvisualizations. Unlike existing libraries, Dialz emphasizes modularity and\nusability, enabling both rapid prototyping and in-depth analysis. We\ndemonstrate how Dialz can be used to reduce harmful outputs such as\nstereotypes, while also providing insights into model behaviour across\ndifferent layers. We release Dialz with full documentation, tutorials, and\nsupport for popular open-source models to encourage further research in safe\nand controllable language generation. Dialz enables faster research cycles and\nfacilitates insights into model interpretability, paving the way for safer,\nmore transparent, and more reliable AI systems.", "AI": {"tldr": "Dialz is a Python framework for steering vectors in LLMs, enabling concept modification (e.g., honesty) at inference time. It supports tasks like dataset creation, vector application, and visualization, focusing on modularity and usability. Dialz reduces harmful outputs and aids model interpretability, promoting safer AI.", "motivation": "To provide a powerful, modular tool for steering LLM activations, improving controllability and safety beyond prompting or fine-tuning.", "method": "Dialz offers tools for creating contrastive datasets, computing/applying steering vectors, and visualizations, emphasizing usability and rapid prototyping.", "result": "Demonstrated effectiveness in reducing harmful outputs (e.g., stereotypes) and enhancing model interpretability across layers.", "conclusion": "Dialz accelerates research, supports safer AI development, and fosters transparency in language generation."}}
{"id": "2505.06660", "pdf": "https://arxiv.org/pdf/2505.06660", "abs": "https://arxiv.org/abs/2505.06660", "authors": ["Junyi Peng", "Takanori Ashihara", "Marc Delcroix", "Tsubasa Ochiai", "Oldrich Plchot", "Shoko Araki", "Jan \u010cernock\u00fd"], "title": "TS-SUPERB: A Target Speech Processing Benchmark for Speech Self-Supervised Learning Models", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted at ICASSP 2025", "summary": "Self-supervised learning (SSL) models have significantly advanced speech\nprocessing tasks, and several benchmarks have been proposed to validate their\neffectiveness. However, previous benchmarks have primarily focused on\nsingle-speaker scenarios, with less exploration of target-speaker tasks in\nnoisy, multi-talker conditions -- a more challenging yet practical case. In\nthis paper, we introduce the Target-Speaker Speech Processing Universal\nPerformance Benchmark (TS-SUPERB), which includes four widely recognized\ntarget-speaker processing tasks that require identifying the target speaker and\nextracting information from the speech mixture. In our benchmark, the speaker\nembedding extracted from enrollment speech is used as a clue to condition\ndownstream models. The benchmark result reveals the importance of evaluating\nSSL models in target speaker scenarios, demonstrating that performance cannot\nbe easily inferred from related single-speaker tasks. Moreover, by using a\nunified SSL-based target speech encoder, consisting of a speaker encoder and an\nextractor module, we also investigate joint optimization across TS tasks to\nleverage mutual information and demonstrate its effectiveness.", "AI": {"tldr": "TS-SUPERB is a new benchmark for evaluating SSL models in noisy, multi-talker scenarios, focusing on target-speaker tasks, revealing performance gaps not seen in single-speaker tasks.", "motivation": "Previous SSL benchmarks overlooked noisy, multi-talker conditions, which are practical but challenging. TS-SUPERB addresses this gap.", "method": "The benchmark includes four target-speaker tasks, using speaker embeddings to condition models. A unified SSL-based encoder (speaker encoder + extractor) is proposed for joint optimization.", "result": "Performance in target-speaker tasks cannot be inferred from single-speaker tasks. Joint optimization across tasks improves effectiveness.", "conclusion": "TS-SUPERB highlights the need for evaluating SSL models in realistic multi-talker scenarios and shows the benefits of joint task optimization."}}
{"id": "2505.06918", "pdf": "https://arxiv.org/pdf/2505.06918", "abs": "https://arxiv.org/abs/2505.06918", "authors": ["Yanhui Hong", "Nan Wang", "Zhiyi Xia", "Haoyi Tao", "Xi Fang", "Yiming Li", "Jiankun Wang", "Peng Jin", "Xiaochen Cai", "Shengyu Li", "Ziqi Chen", "Zezhong Zhang", "Guolin Ke", "Linfeng Zhang"], "title": "Uni-AIMS: AI-Powered Microscopy Image Analysis", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "This paper presents a systematic solution for the intelligent recognition and\nautomatic analysis of microscopy images. We developed a data engine that\ngenerates high-quality annotated datasets through a combination of the\ncollection of diverse microscopy images from experiments, synthetic data\ngeneration and a human-in-the-loop annotation process. To address the unique\nchallenges of microscopy images, we propose a segmentation model capable of\nrobustly detecting both small and large objects. The model effectively\nidentifies and separates thousands of closely situated targets, even in\ncluttered visual environments. Furthermore, our solution supports the precise\nautomatic recognition of image scale bars, an essential feature in quantitative\nmicroscopic analysis. Building upon these components, we have constructed a\ncomprehensive intelligent analysis platform and validated its effectiveness and\npracticality in real-world applications. This study not only advances automatic\nrecognition in microscopy imaging but also ensures scalability and\ngeneralizability across multiple application domains, offering a powerful tool\nfor automated microscopic analysis in interdisciplinary research.", "AI": {"tldr": "A systematic solution for intelligent microscopy image recognition and analysis, featuring a data engine for high-quality datasets, a robust segmentation model, and an intelligent analysis platform.", "motivation": "To address the challenges of microscopy image analysis, including diverse datasets, cluttered environments, and precise scale bar recognition.", "method": "Combines a data engine (real and synthetic data with human-in-the-loop annotation) and a segmentation model for robust object detection.", "result": "Effective detection of small/large objects and scale bars, validated in real-world applications.", "conclusion": "Advances automated microscopy analysis with scalability and generalizability for interdisciplinary research."}}
{"id": "2505.07709", "pdf": "https://arxiv.org/pdf/2505.07709", "abs": "https://arxiv.org/abs/2505.07709", "authors": ["Daniel Haider", "Felix Perfler", "Peter Balazs", "Clara Hollomey", "Nicki Holighaus"], "title": "ISAC: An Invertible and Stable Auditory Filter Bank with Customizable Kernels for ML Integration", "categories": ["cs.SD", "cs.LG"], "comment": "Accepted at the IEEE International Conference on Sampling Theory and\n  Applications (SampTA) 2025", "summary": "This paper introduces ISAC, an invertible and stable, perceptually-motivated\nfilter bank that is specifically designed to be integrated into machine\nlearning paradigms. More precisely, the center frequencies and bandwidths of\nthe filters are chosen to follow a non-linear, auditory frequency scale, the\nfilter kernels have user-defined maximum temporal support and may serve as\nlearnable convolutional kernels, and there exists a corresponding filter bank\nsuch that both form a perfect reconstruction pair. ISAC provides a powerful and\nuser-friendly audio front-end suitable for any application, including\nanalysis-synthesis schemes.", "AI": {"tldr": "ISAC is an invertible, stable filter bank designed for machine learning, mimicking auditory frequency scales and enabling perfect reconstruction.", "motivation": "To create a perceptually-motivated audio front-end adaptable for machine learning and analysis-synthesis tasks.", "method": "Uses non-linear auditory frequency scales, user-defined temporal support, and learnable convolutional kernels for perfect reconstruction.", "result": "ISAC offers a versatile and powerful audio front-end for various applications.", "conclusion": "ISAC is a robust, user-friendly solution for audio processing in machine learning."}}
{"id": "2505.06569", "pdf": "https://arxiv.org/pdf/2505.06569", "abs": "https://arxiv.org/abs/2505.06569", "authors": ["Woosang Lim", "Zekun Li", "Gyuwan Kim", "Sungyoung Ji", "HyeonJung Kim", "Kyuri Choi", "Jin Hyuk Lim", "Kyungpyo Park", "William Yang Wang"], "title": "MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Long-context (LC) Large Language Models (LLMs) combined with\nRetrieval-Augmented Generation (RAG) hold strong potential for complex\nmulti-hop and large-document tasks. However, existing RAG systems often suffer\nfrom imprecise retrieval, incomplete context coverage under constrained context\nwindows, and fragmented information caused by suboptimal context construction.\nWe introduce Multi-scale Adaptive Context RAG (MacRAG), a hierarchical\nretrieval framework that compresses and partitions documents into\ncoarse-to-fine granularities, then adaptively merges relevant contexts through\nchunk- and document-level expansions in real time. By starting from the\nfinest-level retrieval and progressively incorporating higher-level and broader\ncontext, MacRAG constructs effective query-specific long contexts, optimizing\nboth precision and coverage. Evaluations on the challenging LongBench\nexpansions of HotpotQA, 2WikiMultihopQA, and Musique confirm that MacRAG\nconsistently surpasses baseline RAG pipelines on single- and multi-step\ngeneration with Llama-3.1-8B, Gemini-1.5-pro, and GPT-4o. Our results establish\nMacRAG as an efficient, scalable solution for real-world long-context,\nmulti-hop reasoning. Our code is available at\nhttps://github.com/Leezekun/MacRAG.", "AI": {"tldr": "MacRAG introduces a hierarchical retrieval framework for RAG systems to improve precision and context coverage in long-context tasks, outperforming baselines on multi-hop reasoning.", "motivation": "Existing RAG systems face issues like imprecise retrieval, incomplete context coverage, and fragmented information due to suboptimal context construction.", "method": "MacRAG compresses and partitions documents into coarse-to-fine granularities, adaptively merging relevant contexts through chunk- and document-level expansions in real time.", "result": "MacRAG outperforms baseline RAG pipelines on LongBench tasks with models like Llama-3.1-8B, Gemini-1.5-pro, and GPT-4o.", "conclusion": "MacRAG is an efficient, scalable solution for real-world long-context, multi-hop reasoning."}}
{"id": "2505.06761", "pdf": "https://arxiv.org/pdf/2505.06761", "abs": "https://arxiv.org/abs/2505.06761", "authors": ["Youcef Djenouri", "Nassim Belmecheri", "Tomasz Michalak", "Jan Dubi\u0144ski", "Ahmed Nabil Belbachir", "Anis Yazidi"], "title": "Learning Graph Representation of Agent Diffuser", "categories": ["cs.LG", "cs.MA"], "comment": "Accepted at AAMAS2025 International Conference on Autonomous Agents\n  and Multiagent Systems", "summary": "Diffusion-based generative models have significantly advanced text-to-image\nsynthesis, demonstrating impressive text comprehension and zero-shot\ngeneralization. These models refine images from random noise based on textual\nprompts, with initial reliance on text input shifting towards enhanced visual\nfidelity over time. This transition suggests that static model parameters might\nnot optimally address the distinct phases of generation. We introduce LGR-AD\n(Learning Graph Representation of Agent Diffusers), a novel multi-agent system\ndesigned to improve adaptability in dynamic computer vision tasks. LGR-AD\nmodels the generation process as a distributed system of interacting agents,\neach representing an expert sub-model. These agents dynamically adapt to\nvarying conditions and collaborate through a graph neural network that encodes\ntheir relationships and performance metrics. Our approach employs a\ncoordination mechanism based on top-$k$ maximum spanning trees, optimizing the\ngeneration process. Each agent's decision-making is guided by a meta-model that\nminimizes a novel loss function, balancing accuracy and diversity. Theoretical\nanalysis and extensive empirical evaluations show that LGR-AD outperforms\ntraditional diffusion models across various benchmarks, highlighting its\npotential for scalable and flexible solutions in complex image generation\ntasks. Code is available at: https://github.com/YousIA/LGR_AD", "AI": {"tldr": "LGR-AD is a multi-agent system improving adaptability in text-to-image synthesis by modeling generation as interacting agents, outperforming traditional diffusion models.", "motivation": "Static model parameters may not optimally handle distinct phases of image generation, prompting the need for adaptable solutions.", "method": "LGR-AD uses a distributed system of agents, a graph neural network for collaboration, and a top-$k$ maximum spanning tree for coordination.", "result": "LGR-AD outperforms traditional diffusion models in benchmarks, balancing accuracy and diversity.", "conclusion": "LGR-AD offers scalable, flexible solutions for complex image generation tasks."}}
{"id": "2505.06411", "pdf": "https://arxiv.org/pdf/2505.06411", "abs": "https://arxiv.org/abs/2505.06411", "authors": ["Fangyu Du", "Yang Yang", "Xuehao Gao", "Hongye Hou"], "title": "MAGE:A Multi-stage Avatar Generator with Sparse Observations", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Inferring full-body poses from Head Mounted Devices, which capture only\n3-joint observations from the head and wrists, is a challenging task with wide\nAR/VR applications. Previous attempts focus on learning one-stage motion\nmapping and thus suffer from an over-large inference space for unobserved body\njoint motions. This often leads to unsatisfactory lower-body predictions and\npoor temporal consistency, resulting in unrealistic or incoherent motion\nsequences. To address this, we propose a powerful Multi-stage Avatar GEnerator\nnamed MAGE that factorizes this one-stage direct motion mapping learning with a\nprogressive prediction strategy. Specifically, given initial 3-joint motions,\nMAGE gradually inferring multi-scale body part poses at different abstract\ngranularity levels, starting from a 6-part body representation and gradually\nrefining to 22 joints. With decreasing abstract levels step by step, MAGE\nintroduces more motion context priors from former prediction stages and thus\nimproves realistic motion completion with richer constraint conditions and less\nambiguity. Extensive experiments on large-scale datasets verify that MAGE\nsignificantly outperforms state-of-the-art methods with better accuracy and\ncontinuity.", "AI": {"tldr": "MAGE, a Multi-stage Avatar GEnerator, improves full-body pose inference from limited 3-joint observations by progressively refining predictions from coarse to fine granularity, outperforming existing methods.", "motivation": "Overcoming the limitations of one-stage motion mapping, which leads to poor lower-body predictions and temporal inconsistency in AR/VR applications.", "method": "MAGE uses a progressive prediction strategy, starting with a 6-part body representation and refining to 22 joints, incorporating motion context priors at each stage.", "result": "MAGE achieves better accuracy and continuity than state-of-the-art methods, as validated by large-scale experiments.", "conclusion": "The multi-stage approach of MAGE effectively addresses the challenges of full-body pose inference from sparse observations, enhancing realism and coherence."}}
{"id": "2505.06492", "pdf": "https://arxiv.org/pdf/2505.06492", "abs": "https://arxiv.org/abs/2505.06492", "authors": ["Chathurangi Shyalika", "Renjith Prasad", "Alaa Al Ghazo", "Darssan Eswaramoorthi", "Harleen Kaur", "Sara Shree Muthuselvam", "Amit Sheth"], "title": "SmartPilot: A Multiagent CoPilot for Adaptive and Intelligent Manufacturing", "categories": ["cs.AI"], "comment": "8 pages, 8 figures, 4 tables, IEEE Conference on Artificial\n  Intelligence (IEEE CAI) 2025", "summary": "In the dynamic landscape of Industry 4.0, achieving efficiency, precision,\nand adaptability is essential to optimize manufacturing operations. Industries\nsuffer due to supply chain disruptions caused by anomalies, which are being\ndetected by current AI models but leaving domain experts uncertain without\ndeeper insights into these anomalies. Additionally, operational inefficiencies\npersist due to inaccurate production forecasts and the limited effectiveness of\ntraditional AI models for processing complex sensor data. Despite these\nadvancements, existing systems lack the seamless integration of these\ncapabilities needed to create a truly unified solution for enhancing production\nand decision-making. We propose SmartPilot, a neurosymbolic, multiagent CoPilot\ndesigned for advanced reasoning and contextual decision-making to address these\nchallenges. SmartPilot processes multimodal sensor data and is compact to\ndeploy on edge devices. It focuses on three key tasks: anomaly prediction,\nproduction forecasting, and domain-specific question answering. By bridging the\ngap between AI capabilities and real-world industrial needs, SmartPilot\nempowers industries with intelligent decision-making and drives transformative\ninnovation in manufacturing. The demonstration video, datasets, and\nsupplementary materials are available at\nhttps://github.com/ChathurangiShyalika/SmartPilot.", "AI": {"tldr": "SmartPilot is a neurosymbolic, multiagent CoPilot for Industry 4.0, addressing anomaly prediction, production forecasting, and domain-specific QA to enhance manufacturing decision-making.", "motivation": "Current AI models lack deeper insights into anomalies and struggle with complex sensor data, leading to inefficiencies in manufacturing.", "method": "SmartPilot integrates neurosymbolic reasoning and multiagent systems to process multimodal sensor data on edge devices.", "result": "SmartPilot provides intelligent decision-making for anomaly prediction, production forecasting, and domain-specific QA.", "conclusion": "SmartPilot bridges AI capabilities with industrial needs, driving transformative innovation in manufacturing."}}
{"id": "2505.06265", "pdf": "https://arxiv.org/pdf/2505.06265", "abs": "https://arxiv.org/abs/2505.06265", "authors": ["Jacques Peter", "Quentin Bennehard", "S\u00e9bastien Heib", "Jean-Luc Hantrais-Gervois", "Fr\u00e9d\u00e9ric Mo\u00ebns"], "title": "ONERA's CRM WBPN database for machine learning activities, related regression challenge and first results", "categories": ["cs.LG"], "comment": "16 pages, 9 figures", "summary": "This paper presents a new Computational Fluid Dynamics database, developed at\nONERA, to support the advancement of machine learning techniques for\naerodynamic field prediction. It contains 468 Reynolds-Averaged Navier-Stokes\nsimulations using the Spalart-Allmaras turbulence model, performed on the\nNASA/Boeing Common Research Model wing-body-pylon-nacelle configuration. The\ndatabase spans a wide range of flow conditions, varying Mach number (including\ntransonic regimes), angle of attack (capturing flow separation), and Reynolds\nnumber (based on three stagnation pressures, with one setting matching wind\ntunnel experiments). The quality of the database is assessed, through checking\nthe convergence level of each computation.\n  Based on these data, a regression challenge is defined. It consists in\npredicting the wall distributions of pressure and friction coefficients for\nunseen aerodynamic conditions. The 468 simulations are split into training and\ntesting sets, with the training data made available publicly on the Codabench\nplatform. The paper further evaluates several classical machine learning\nregressors on this task. Tested pointwise methods include Multi-Layer\nPerceptrons, $\\lambda$-DNNs, and Decision Trees, while global methods include\nMulti-Layer Perceptron, k-Nearest Neighbors, Proper Orthogonal Decomposition\nand IsoMap. Initial performance results, using $R^2$ scores and worst relative\nmean absolute error metrics, are presented, offering insights into the\ncapabilities of these techniques for the challenge and references for future\nwork.", "AI": {"tldr": "A new CFD database for machine learning in aerodynamic prediction is introduced, featuring 468 simulations. It includes a regression challenge to predict wall distributions of pressure and friction coefficients, with results from various ML methods evaluated.", "motivation": "To support machine learning advancements in aerodynamic field prediction by providing a comprehensive CFD database and defining a regression challenge.", "method": "468 Reynolds-Averaged Navier-Stokes simulations using the Spalart-Allmaras turbulence model, split into training and testing sets. Various ML regressors (e.g., MLPs, Decision Trees, k-NN) are evaluated.", "result": "Initial performance results using R\u00b2 scores and worst relative mean absolute error metrics are presented, showcasing the capabilities of tested ML techniques.", "conclusion": "The database and challenge offer valuable insights and references for future work in ML-based aerodynamic prediction."}}
{"id": "2505.06823", "pdf": "https://arxiv.org/pdf/2505.06823", "abs": "https://arxiv.org/abs/2505.06823", "authors": ["Saad Masrur", "Ozgur Ozdemir", "Anil Gurses", "Ismail Guvenc", "Mihail L. Sichitiu", "Rudra Dutta", "Magreth Mushi", "homas Zajkowski", "Cole Dickerson", "Gautham Reddy", "Sergio Vargas Villar", "Chau-Wai Wong", "Baisakhi Chatterjee", "Sonali Chaudhari", "Zhizhen Li", "Yuchen Liu", "Paul Kudyba", "Haijian Sun", "Jaya Sravani Mandapaka", "Kamesh Namuduri", "Weijie Wang", "Fraida Fund"], "title": "Collection: Datasets from AFAR Challenge", "categories": ["eess.SP", "eess.AS"], "comment": "Submitted to IEEE Data Descriptions", "summary": "This paper presents a comprehensive real-world and Digital Twin (DT) dataset\ncollected as part of the Find A Rover (AFAR) Challenge, organized by the NSF\nAerial Experimentation and Research Platform for Advanced Wireless (AERPAW)\ntestbed and hosted at the Lake Wheeler Field in Raleigh, North Carolina. The\nAFAR Challenge was a competition involving five finalist university teams,\nfocused on promoting innovation in UAV-assisted radio frequency (RF) source\nlocalization. Participating teams were tasked with designing UAV flight\ntrajectories and localization algorithms to detect the position of a hidden\nunmanned ground vehicle (UGV), also referred to as a rover, emitting wireless\nprobe signals generated by GNU Radio. The competition was structured to\nevaluate solutions in a DT environment first, followed by deployment and\ntesting in AERPAW's outdoor wireless testbed. For each team, the UGV was placed\nat three different positions, resulting in a total of 30 datasets, 15 collected\nin a DT simulation environment and 15 in a physical outdoor testbed. Each\ndataset contains time-synchronized measurements of received signal strength\n(RSS), received signal quality (RSQ), GPS coordinates, UAV velocity, and UAV\norientation (roll, pitch, and yaw). Data is organized into structured folders\nby team, environment (DT and real-world), and UGV location. The dataset\nsupports research in UAV-assisted RF source localization, air-to-ground (A2G)\nwireless propagation modeling, trajectory optimization, signal prediction,\nautonomous navigation, and DT validation. With approximately 300k\ntime-synchronized samples collected from real-world experiments, the dataset\nprovides a substantial foundation for training and evaluating deep learning\n(DL) models. Overall, the AFAR dataset serves as a valuable resource for\nadvancing robust, real-world solutions in UAV-enabled wireless communications\nand sensing systems.", "AI": {"tldr": "The paper introduces a dataset from the AFAR Challenge, combining real-world and Digital Twin (DT) data for UAV-assisted RF source localization, supporting research in wireless communications and sensing.", "motivation": "To promote innovation in UAV-assisted RF source localization by providing a comprehensive dataset from a competition involving real-world and DT environments.", "method": "Teams designed UAV flight trajectories and localization algorithms to detect a hidden UGV emitting wireless signals. Data was collected in both DT and real-world settings, with synchronized measurements like RSS, RSQ, GPS, and UAV dynamics.", "result": "A dataset of 30 cases (15 DT, 15 real-world) with ~300k samples, useful for UAV research, A2G modeling, and DL training.", "conclusion": "The AFAR dataset is a valuable resource for advancing UAV-enabled wireless communications and sensing systems."}}
{"id": "2505.06934", "pdf": "https://arxiv.org/pdf/2505.06934", "abs": "https://arxiv.org/abs/2505.06934", "authors": ["Roy Betser", "Meir Yossef Levi", "Guy Gilboa"], "title": "Whitened CLIP as a Likelihood Surrogate of Images and Captions", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted to ICML 2025. This version matches the camera-ready version", "summary": "Likelihood approximations for images are not trivial to compute and can be\nuseful in many applications. We examine the use of Contrastive Language-Image\nPre-training (CLIP) to assess the likelihood of images and captions. We\nintroduce \\textit{Whitened CLIP}, a novel transformation of the CLIP latent\nspace via an invertible linear operation. This transformation ensures that each\nfeature in the embedding space has zero mean, unit standard deviation, and no\ncorrelation with all other features, resulting in an identity covariance\nmatrix. We show that the whitened embeddings statistics can be well\napproximated as a standard normal distribution, thus, the log-likelihood is\nestimated simply by the square Euclidean norm in the whitened embedding space.\nThe whitening procedure is completely training-free and performed using a\npre-computed whitening matrix, hence, is very fast. We present several\npreliminary experiments demonstrating the properties and applicability of these\nlikelihood scores to images and captions.", "AI": {"tldr": "Whitened CLIP transforms CLIP embeddings to have zero mean, unit variance, and no correlation, enabling fast log-likelihood estimation via Euclidean norm.", "motivation": "Likelihood approximations for images are challenging but useful; CLIP's potential for this is explored.", "method": "Introduces Whitened CLIP, an invertible linear transformation of CLIP embeddings to standard normal distribution.", "result": "Whitened embeddings approximate standard normal, allowing simple log-likelihood estimation.", "conclusion": "Whitened CLIP provides a fast, training-free method for likelihood estimation in images and captions."}}
{"id": "2504.01660", "pdf": "https://arxiv.org/pdf/2504.01660", "abs": "https://arxiv.org/abs/2504.01660", "authors": ["James W. Trayford", "Samantha Youles", "Chris Harrison", "Rose Shepherd", "Nicolas Bonne"], "title": "STRAUSS: Sonification Tools & Resources for Analysis Using Sound Synthesis", "categories": ["astro-ph.IM", "cs.SD", "physics.data-an"], "comment": "4 pages, linking to documentation on ReadTheDocs\n  (https://strauss.readthedocs.io/en/latest/)", "summary": "Sonification, or conveying data using non-verbal audio, is a relatively niche\nbut growing approach for presenting data across multiple specialist domains\nincluding astronomy, climate science, and beyond. The STRAUSS Python package\naims to provide such a tool, which builds upon previous approaches to provide a\npowerful means to explore different ways of expressing data, with fine control\nover the output audio and its format. STRAUSS is a free, open source (FOSS)\npackage, designed to allow flexible and effective sonification to be integrated\ninto data workflows, in analogy to widely used visualisation packages. The\nremit of STRAUSS is broad; it is intended to be able to bridge between ad-hoc\nsolutions for sonifying very particular datasets, and highly technical\ncompositional and sound-design tools that are not optimised for sonification,\nor may have a steep learning curve. The code offers a range of approaches to\nsonification for a variety of contexts (e.g. science education, science\ncommunication, technical data analysis, etc). To this end, STRAUSS is packaged\nwith a number of examples of different sonification approaches, and preset\nconfigurations to support \"low-barrier, high-ceiling\" approach. STRAUSS has\nbeen used to produce both educational resources and analysis tools.", "AI": {"tldr": "The STRAUSS Python package is a free, open-source tool for sonification, offering flexible and powerful audio data representation with broad applications in science and education.", "motivation": "To bridge the gap between ad-hoc sonification solutions and complex sound-design tools, making sonification more accessible and integrable into data workflows.", "method": "STRAUSS provides a range of sonification approaches, fine audio control, and preset configurations, supported by examples for various contexts.", "result": "The package has been successfully used to create educational resources and analysis tools, demonstrating its versatility.", "conclusion": "STRAUSS is a valuable tool for flexible and effective sonification, catering to diverse needs from education to technical data analysis."}}
{"id": "2505.06591", "pdf": "https://arxiv.org/pdf/2505.06591", "abs": "https://arxiv.org/abs/2505.06591", "authors": ["Anna Wr\u00f3blewska", "Bartosz Grabek", "Jakub \u015awistak", "Daniel Dan"], "title": "Evaluating LLM-Generated Q&A Test: a Student-Centered Study", "categories": ["cs.CL", "cs.HC"], "comment": "accepted to AIED 2025", "summary": "This research prepares an automatic pipeline for generating reliable\nquestion-answer (Q&A) tests using AI chatbots. We automatically generated a\nGPT-4o-mini-based Q&A test for a Natural Language Processing course and\nevaluated its psychometric and perceived-quality metrics with students and\nexperts. A mixed-format IRT analysis showed that the generated items exhibit\nstrong discrimination and appropriate difficulty, while student and expert star\nratings reflect high overall quality. A uniform DIF check identified two items\nfor review. These findings demonstrate that LLM-generated assessments can match\nhuman-authored tests in psychometric performance and user satisfaction,\nillustrating a scalable approach to AI-assisted assessment development.", "AI": {"tldr": "An AI pipeline generates reliable Q&A tests using GPT-4o-mini, showing strong psychometric performance and high user satisfaction, comparable to human-authored tests.", "motivation": "To demonstrate the feasibility and quality of AI-generated assessments for educational purposes, specifically in NLP courses.", "method": "Automatically generated Q&A tests using GPT-4o-mini, evaluated via IRT analysis and user ratings (students and experts).", "result": "Tests showed strong discrimination, appropriate difficulty, and high quality ratings, with minor DIF issues.", "conclusion": "LLM-generated assessments can match human-authored tests, offering a scalable solution for AI-assisted assessment development."}}
{"id": "2505.06771", "pdf": "https://arxiv.org/pdf/2505.06771", "abs": "https://arxiv.org/abs/2505.06771", "authors": ["Shalin Anand Jain", "Jiazhen Liu", "Siva Kailas", "Harish Ravichandar"], "title": "JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes", "categories": ["cs.RO", "cs.LG", "cs.MA"], "comment": "22 pages, 14 figures, 10 tables", "summary": "Multi-agent reinforcement learning (MARL) has emerged as a promising solution\nfor learning complex and scalable coordination behaviors in multi-robot\nsystems. However, established MARL platforms (e.g., SMAC and MPE) lack robotics\nrelevance and hardware deployment, leaving multi-robot learning researchers to\ndevelop bespoke environments and hardware testbeds dedicated to the development\nand evaluation of their individual contributions. The Multi-Agent RL Benchmark\nand Learning Environment for the Robotarium (MARBLER) is an exciting recent\nstep in providing a standardized robotics-relevant platform for MARL, by\nbridging the Robotarium testbed with existing MARL software infrastructure.\nHowever, MARBLER lacks support for parallelization and GPU/TPU execution,\nmaking the platform prohibitively slow compared to modern MARL environments and\nhindering adoption. We contribute JaxRobotarium, a Jax-powered end-to-end\nsimulation, learning, deployment, and benchmarking platform for the Robotarium.\nJaxRobotarium enables rapid training and deployment of multi-robot\nreinforcement learning (MRRL) policies with realistic robot dynamics and safety\nconstraints, supporting both parallelization and hardware acceleration. Our\ngeneralizable learning interface provides an easy-to-use integration with SOTA\nMARL libraries (e.g., JaxMARL). In addition, JaxRobotarium includes eight\nstandardized coordination scenarios, including four novel scenarios that bring\nestablished MARL benchmark tasks (e.g., RWARE and Level-Based Foraging) to a\nrealistic robotics setting. We demonstrate that JaxRobotarium retains high\nsimulation fidelity while achieving dramatic speedups over baseline (20x in\ntraining and 150x in simulation), and provides an open-access sim-to-real\nevaluation pipeline through the Robotarium testbed, accelerating and\ndemocratizing access to multi-robot learning research and evaluation.", "AI": {"tldr": "JaxRobotarium is a Jax-powered platform for multi-robot reinforcement learning (MRRL), addressing MARBLER's limitations by enabling parallelization, GPU/TPU execution, and faster training/deployment.", "motivation": "Existing MARL platforms lack robotics relevance and hardware deployment, while MARBLER is slow due to no parallelization/GPU support.", "method": "Developed JaxRobotarium, integrating Jax for speed, parallelization, and hardware acceleration, with standardized scenarios and SOTA MARL library compatibility.", "result": "Achieves 20x faster training and 150x faster simulation, with high fidelity and open-access sim-to-real evaluation.", "conclusion": "JaxRobotarium accelerates and democratizes multi-robot learning research by providing a fast, realistic, and accessible platform."}}
{"id": "2505.06413", "pdf": "https://arxiv.org/pdf/2505.06413", "abs": "https://arxiv.org/abs/2505.06413", "authors": ["Ming Liu", "Siyuan Liang", "Koushik Howlader", "Liwen Wang", "Dacheng Tao", "Wensheng Zhang"], "title": "Natural Reflection Backdoor Attack on Vision Language Model for Autonomous Driving", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) have been integrated into autonomous driving\nsystems to enhance reasoning capabilities through tasks such as Visual Question\nAnswering (VQA). However, the robustness of these systems against backdoor\nattacks remains underexplored. In this paper, we propose a natural\nreflection-based backdoor attack targeting VLM systems in autonomous driving\nscenarios, aiming to induce substantial response delays when specific visual\ntriggers are present. We embed faint reflection patterns, mimicking natural\nsurfaces such as glass or water, into a subset of images in the DriveLM\ndataset, while prepending lengthy irrelevant prefixes (e.g., fabricated stories\nor system update notifications) to the corresponding textual labels. This\nstrategy trains the model to generate abnormally long responses upon\nencountering the trigger. We fine-tune two state-of-the-art VLMs, Qwen2-VL and\nLLaMA-Adapter, using parameter-efficient methods. Experimental results\ndemonstrate that while the models maintain normal performance on clean inputs,\nthey exhibit significantly increased inference latency when triggered,\npotentially leading to hazardous delays in real-world autonomous driving\ndecision-making. Further analysis examines factors such as poisoning rates,\ncamera perspectives, and cross-view transferability. Our findings uncover a new\nclass of attacks that exploit the stringent real-time requirements of\nautonomous driving, posing serious challenges to the security and reliability\nof VLM-augmented driving systems.", "AI": {"tldr": "The paper explores backdoor attacks on Vision-Language Models (VLMs) in autonomous driving, using natural reflections and irrelevant text to induce delays.", "motivation": "To investigate the robustness of VLMs in autonomous driving against backdoor attacks, which could cause hazardous delays.", "method": "Embed faint reflection patterns in images and prepend irrelevant text to labels, then fine-tune VLMs (Qwen2-VL and LLaMA-Adapter) to trigger long responses.", "result": "Models show normal performance on clean inputs but significant latency when triggered, posing risks in real-world driving.", "conclusion": "The study reveals a new attack class exploiting real-time requirements, challenging VLM security in autonomous driving."}}
{"id": "2505.06505", "pdf": "https://arxiv.org/pdf/2505.06505", "abs": "https://arxiv.org/abs/2505.06505", "authors": ["Hua Meng", "Zhiguo Long", "Michael Sioutis", "Zhengchun Zhou"], "title": "On Definite Iterated Belief Revision with Belief Algebras", "categories": ["cs.AI", "I.2.4"], "comment": "10 pages. Extended version of an accepted IJCAI 2025 paper", "summary": "Traditional logic-based belief revision research focuses on designing rules\nto constrain the behavior of revision operators. Frameworks have been proposed\nto characterize iterated revision rules, but they are often too loose, leading\nto multiple revision operators that all satisfy the rules under the same belief\ncondition. In many practical applications, such as safety critical ones, it is\nimportant to specify a definite revision operator to enable agents to\niteratively revise their beliefs in a deterministic way. In this paper, we\npropose a novel framework for iterated belief revision by characterizing belief\ninformation through preference relations. Semantically, both beliefs and new\nevidence are represented as belief algebras, which provide a rich and\nexpressive foundation for belief revision. Building on traditional revision\nrules, we introduce additional postulates for revision with belief algebra,\nincluding an upper-bound constraint on the outcomes of revision. We prove that\nthe revision result is uniquely determined given the current belief state and\nnew evidence. Furthermore, to make the framework more useful in practice, we\ndevelop a particular algorithm for performing the proposed revision process. We\nargue that this approach may offer a more predictable and principled method for\nbelief revision, making it suitable for real-world applications.", "AI": {"tldr": "A novel framework for iterated belief revision using preference relations and belief algebras ensures deterministic revision results, with a practical algorithm for implementation.", "motivation": "Traditional frameworks for iterated belief revision are too loose, leading to non-deterministic outcomes, which is problematic for safety-critical applications.", "method": "Characterizes belief information through preference relations and represents beliefs and evidence as belief algebras. Introduces additional postulates, including an upper-bound constraint, to uniquely determine revision results.", "result": "Proves that the revision result is uniquely determined given the current belief state and new evidence. Develops a practical algorithm for the revision process.", "conclusion": "The proposed framework offers a predictable and principled method for belief revision, making it suitable for real-world applications."}}
{"id": "2505.06266", "pdf": "https://arxiv.org/pdf/2505.06266", "abs": "https://arxiv.org/abs/2505.06266", "authors": ["Qi Cheng", "Licheng Liu", "Zhang Yao", "Hong Mu", "Shiyuan Luo", "Zhenong Jin", "Yiqun Xie", "Xiaowei Jia"], "title": "Knowledge Guided Encoder-Decoder Framework Integrating Multiple Physical Models for Agricultural Ecosystem Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Agricultural monitoring is critical for ensuring food security, maintaining\nsustainable farming practices, informing policies on mitigating food shortage,\nand managing greenhouse gas emissions. Traditional process-based physical\nmodels are often designed and implemented for specific situations, and their\nparameters could also be highly uncertain. In contrast, data-driven models\noften use black-box structures and does not explicitly model the\ninter-dependence between different ecological variables. As a result, they\nrequire extensive training data and lack generalizability to different tasks\nwith data distribution shifts and inconsistent observed variables. To address\nthe need for more universal models, we propose a knowledge-guided\nencoder-decoder model, which can predict key crop variables by leveraging\nknowledge of underlying processes from multiple physical models. The proposed\nmethod also integrates a language model to process complex and inconsistent\ninputs and also utilizes it to implement a model selection mechanism for\nselectively combining the knowledge from different physical models. Our\nevaluations on predicting carbon and nitrogen fluxes for multiple sites\ndemonstrate the effectiveness and robustness of the proposed model under\nvarious scenarios.", "AI": {"tldr": "A knowledge-guided encoder-decoder model is proposed for agricultural monitoring, combining physical models and a language model to improve predictions of crop variables under diverse conditions.", "motivation": "Address limitations of traditional physical models (specificity, uncertainty) and data-driven models (lack of generalizability, black-box nature) in agricultural monitoring.", "method": "Proposes a knowledge-guided encoder-decoder model integrating multiple physical models and a language model for processing inconsistent inputs and model selection.", "result": "Effective and robust predictions of carbon and nitrogen fluxes across multiple sites under various scenarios.", "conclusion": "The proposed model offers a universal solution for agricultural monitoring, balancing physical knowledge and data-driven flexibility."}}
{"id": "2505.07202", "pdf": "https://arxiv.org/pdf/2505.07202", "abs": "https://arxiv.org/abs/2505.07202", "authors": ["Hyouin Liu", "Zhikuan Zhang"], "title": "On the Cost and Benefits of Training Context with Utterance or Full Conversation Training: A Comparative Stud", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Modern TTS systems designed for conversations achieve high-quality utterances\nbut often remain inaccessible publicly. Are existing open-source architectures\ninadequate, or are current training techniques insufficient? This paper\ninvestigates prominent models and their underlying behaviors regarding\nconversational context. Using 20 GPU-hours on an NVIDIA H100, we empirically\nexamine two approaches: context-based utterance-level training versus full\nconversation training. Results demonstrate that context-based utterance\ntraining achieves superior MOS scores (4.3/5.0 vs 3.7/5.0) and reduces training\ntime by 37%, while full conversation approaches suffer from speaker similarity\nhallucination issues. These findings provide practical guidelines for\nconversational TTS development, favoring utterance-level training with\ncontextual conditioning for both resource efficiency and output quality.", "AI": {"tldr": "Context-based utterance training outperforms full conversation training in conversational TTS, achieving higher quality and efficiency.", "motivation": "To address the gap in publicly accessible high-quality conversational TTS systems by evaluating existing models and training techniques.", "method": "Empirical comparison of context-based utterance-level training and full conversation training using 20 GPU-hours on an NVIDIA H100.", "result": "Context-based training yields better MOS scores (4.3/5.0) and 37% faster training, while full conversation training suffers from speaker similarity issues.", "conclusion": "Utterance-level training with contextual conditioning is recommended for efficient, high-quality conversational TTS development."}}
{"id": "2505.07159", "pdf": "https://arxiv.org/pdf/2505.07159", "abs": "https://arxiv.org/abs/2505.07159", "authors": ["Jong Sung Park", "Juhyung Ha", "Siddhesh Thakur", "Alexandra Badea", "Spyridon Bakas", "Eleftherios Garyfallidis"], "title": "Skull stripping with purely synthetic data", "categories": ["eess.IV", "cs.CV"], "comment": "Oral at ISMRM 2025", "summary": "While many skull stripping algorithms have been developed for multi-modal and\nmulti-species cases, there is still a lack of a fundamentally generalizable\napproach. We present PUMBA(PUrely synthetic Multimodal/species invariant Brain\nextrAction), a strategy to train a model for brain extraction with no real\nbrain images or labels. Our results show that even without any real images or\nanatomical priors, the model achieves comparable accuracy in multi-modal,\nmulti-species and pathological cases. This work presents a new direction of\nresearch for any generalizable medical image segmentation task.", "AI": {"tldr": "PUMBA trains a brain extraction model without real images or labels, achieving comparable accuracy in multi-modal, multi-species, and pathological cases.", "motivation": "Address the lack of a generalizable skull stripping approach for multi-modal and multi-species cases.", "method": "PUMBA uses purely synthetic data to train the model, avoiding real brain images or labels.", "result": "The model performs comparably in multi-modal, multi-species, and pathological scenarios.", "conclusion": "PUMBA offers a novel direction for generalizable medical image segmentation tasks."}}
{"id": "2505.06271", "pdf": "https://arxiv.org/pdf/2505.06271", "abs": "https://arxiv.org/abs/2505.06271", "authors": ["June-Woo Kim", "Sanghoon Lee", "Miika Toikkanen", "Daehwan Hwang", "Kyunghoon Kim"], "title": "Tri-MTL: A Triple Multitask Learning Approach for Respiratory Disease Diagnosis", "categories": ["cs.LG", "cs.AI", "cs.SD"], "comment": "Accepted to EMBC 2025", "summary": "Auscultation remains a cornerstone of clinical practice, essential for both\ninitial evaluation and continuous monitoring. Clinicians listen to the lung\nsounds and make a diagnosis by combining the patient's medical history and test\nresults. Given this strong association, multitask learning (MTL) can offer a\ncompelling framework to simultaneously model these relationships, integrating\nrespiratory sound patterns with disease manifestations. While MTL has shown\nconsiderable promise in medical applications, a significant research gap\nremains in understanding the complex interplay between respiratory sounds,\ndisease manifestations, and patient metadata attributes. This study\ninvestigates how integrating MTL with cutting-edge deep learning architectures\ncan enhance both respiratory sound classification and disease diagnosis.\nSpecifically, we extend recent findings regarding the beneficial impact of\nmetadata on respiratory sound classification by evaluating its effectiveness\nwithin an MTL framework. Our comprehensive experiments reveal significant\nimprovements in both lung sound classification and diagnostic performance when\nthe stethoscope information is incorporated into the MTL architecture.", "AI": {"tldr": "The paper explores using multitask learning (MTL) with deep learning to improve respiratory sound classification and disease diagnosis by integrating sound patterns, disease manifestations, and patient metadata.", "motivation": "Auscultation is vital in clinical practice, but understanding the interplay between respiratory sounds, diseases, and metadata remains a gap. MTL offers a promising solution.", "method": "The study extends MTL with deep learning, incorporating stethoscope data and metadata to model relationships between sounds and diseases.", "result": "Experiments show significant improvements in lung sound classification and diagnostic performance when metadata is included in the MTL framework.", "conclusion": "Integrating MTL with metadata enhances respiratory sound analysis and disease diagnosis, demonstrating its potential in clinical applications."}}
{"id": "2505.06594", "pdf": "https://arxiv.org/pdf/2505.06594", "abs": "https://arxiv.org/abs/2505.06594", "authors": ["Galann Pennec", "Zhengyuan Liu", "Nicholas Asher", "Philippe Muller", "Nancy F. Chen"], "title": "Integrating Video and Text: A Balanced Approach to Multimodal Summary Generation and Evaluation", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) often struggle to balance visual and textual\ninformation when summarizing complex multimodal inputs, such as entire TV show\nepisodes. In this paper, we propose a zero-shot video-to-text summarization\napproach that builds its own screenplay representation of an episode,\neffectively integrating key video moments, dialogue, and character information\ninto a unified document. Unlike previous approaches, we simultaneously generate\nscreenplays and name the characters in zero-shot, using only the audio, video,\nand transcripts as input. Additionally, we highlight that existing\nsummarization metrics can fail to assess the multimodal content in summaries.\nTo address this, we introduce MFactSum, a multimodal metric that evaluates\nsummaries with respect to both vision and text modalities. Using MFactSum, we\nevaluate our screenplay summaries on the SummScreen3D dataset, demonstrating\nsuperiority against state-of-the-art VLMs such as Gemini 1.5 by generating\nsummaries containing 20% more relevant visual information while requiring 75%\nless of the video as input.", "AI": {"tldr": "A zero-shot video-to-text summarization method generates screenplay summaries by integrating video, dialogue, and character info, outperforming VLMs with 20% more visual relevance and 75% less input.", "motivation": "VLMs struggle with balancing visual and textual info for complex multimodal inputs like TV episodes.", "method": "Proposes a zero-shot approach to create screenplay summaries using video, audio, and transcripts, naming characters without prior training. Introduces MFactSum, a multimodal metric for evaluation.", "result": "Outperforms state-of-the-art VLMs (e.g., Gemini 1.5) with 20% more relevant visual info and 75% less input on SummScreen3D.", "conclusion": "The method effectively integrates multimodal content and introduces a robust evaluation metric, advancing video summarization."}}
{"id": "2505.06947", "pdf": "https://arxiv.org/pdf/2505.06947", "abs": "https://arxiv.org/abs/2505.06947", "authors": ["Senhao Yang", "Qiwen Cheng", "Ruiqi Ma", "Liangzhe Zhao", "Zhenying Wu", "Guangqiang Yu"], "title": "The Wisdom of Agent Crowds: A Human-AI Interaction Innovation Ignition Framework", "categories": ["cs.HC", "cs.MA", "I.2.7; J.4"], "comment": null, "summary": "With the widespread application of large AI models in various fields, the\nautomation level of multi-agent systems has been continuously improved.\nHowever, in high-risk decision-making scenarios such as healthcare and finance,\nhuman participation and the alignment of intelligent systems with human\nintentions remain crucial. This paper focuses on the financial scenario and\nconstructs a multi-agent brainstorming framework based on the BDI theory. A\nhuman-computer collaborative multi-agent financial analysis process is built\nusing Streamlit. The system plans tasks according to user intentions, reduces\nusers' cognitive load through real-time updated structured text summaries and\nthe interactive Cothinker module, and reasonably integrates general and\nreasoning large models to enhance the ability to handle complex problems. By\ndesigning a quantitative analysis algorithm for the sentiment tendency of\ninterview content based on LLMs and a method for evaluating the diversity of\nideas generated by LLMs in brainstorming based on k-means clustering and\ninformation entropy, the system is comprehensively evaluated. The results of\nhuman factors testing show that the system performs well in terms of usability\nand user experience. Although there is still room for improvement, it can\neffectively support users in completing complex financial tasks. The research\nshows that the system significantly improves the efficiency of human-computer\ninteraction and the quality of decision-making in financial decision-making\nscenarios, providing a new direction for the development of related fields.", "AI": {"tldr": "The paper presents a multi-agent brainstorming framework for financial analysis, integrating human-computer collaboration, BDI theory, and LLMs to enhance decision-making efficiency and quality.", "motivation": "Address the need for human alignment in high-risk decision-making (e.g., finance) by improving human-computer interaction and reducing cognitive load.", "method": "Constructs a multi-agent system using BDI theory, Streamlit for collaboration, and integrates LLMs for sentiment analysis and idea diversity evaluation.", "result": "System improves usability and user experience, supports complex financial tasks, and enhances decision-making efficiency.", "conclusion": "The framework advances human-computer interaction in finance, offering a promising direction for future development."}}
{"id": "2505.06436", "pdf": "https://arxiv.org/pdf/2505.06436", "abs": "https://arxiv.org/abs/2505.06436", "authors": ["Jingrui He", "Andrew Stephen McGough"], "title": "My Emotion on your face: The use of Facial Keypoint Detection to preserve Emotions in Latent Space Editing", "categories": ["cs.CV", "cs.AI"], "comment": "Submitted to 2nd International Workshop on Synthetic Data for Face\n  and Gesture Analysis at IEEE FG 2025", "summary": "Generative Adversarial Network approaches such as StyleGAN/2 provide two key\nbenefits: the ability to generate photo-realistic face images and possessing a\nsemantically structured latent space from which these images are created. Many\napproaches have emerged for editing images derived from vectors in the latent\nspace of a pre-trained StyleGAN/2 models by identifying semantically meaningful\ndirections (e.g., gender or age) in the latent space. By moving the vector in a\nspecific direction, the ideal result would only change the target feature while\npreserving all the other features. Providing an ideal data augmentation\napproach for gesture research as it could be used to generate numerous image\nvariations whilst keeping the facial expressions intact. However, entanglement\nissues, where changing one feature inevitably affects other features, impacts\nthe ability to preserve facial expressions. To address this, we propose the use\nof an addition to the loss function of a Facial Keypoint Detection model to\nrestrict changes to the facial expressions. Building on top of an existing\nmodel, adding the proposed Human Face Landmark Detection (HFLD) loss, provided\nby a pre-trained Facial Keypoint Detection model, to the original loss\nfunction. We quantitatively and qualitatively evaluate the existing and our\nextended model, showing the effectiveness of our approach in addressing the\nentanglement issue and maintaining the facial expression. Our approach achieves\nup to 49% reduction in the change of emotion in our experiments. Moreover, we\nshow the benefit of our approach by comparing with state-of-the-art models. By\nincreasing the ability to preserve the facial gesture and expression during\nfacial transformation, we present a way to create human face images with fixed\nexpression but different appearances, making it a reliable data augmentation\napproach for Facial Gesture and Expression research.", "AI": {"tldr": "The paper proposes an addition to the loss function of a Facial Keypoint Detection model to address entanglement issues in StyleGAN/2, preserving facial expressions during image editing.", "motivation": "To enable ideal data augmentation for gesture research by generating image variations without altering facial expressions, despite entanglement issues in StyleGAN/2.", "method": "Adds a Human Face Landmark Detection (HFLD) loss to the original loss function of a pre-trained Facial Keypoint Detection model.", "result": "Achieves up to 49% reduction in emotion change, effectively preserving facial expressions during transformations.", "conclusion": "The approach enhances facial expression preservation, making it reliable for data augmentation in facial gesture and expression research."}}
{"id": "2505.06507", "pdf": "https://arxiv.org/pdf/2505.06507", "abs": "https://arxiv.org/abs/2505.06507", "authors": ["Haoyang Xie", "Feng Ju"], "title": "Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model Capabilities", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Computer-aided design (CAD) is fundamental to modern engineering and\nmanufacturing, but creating CAD models still requires expert knowledge and\nspecialized software. Recent advances in large language models (LLMs) open up\nthe possibility of generative CAD, where natural language is directly\ntranslated into parametric 3D models. However, most existing methods generate\ntask-specific command sequences that pretrained models cannot directly handle.\nThese sequences must be converted into CAD representations such as CAD vectors\nbefore a 3D model can be produced, which requires training models from scratch\nand adds unnecessary complexity. To tackle this issue, we propose generating\nCadQuery code directly from text, leveraging the strengths of pretrained LLMs\nto produce 3D models without intermediate representations, using this\nPython-based scripting language. Since LLMs already excel at Python generation\nand spatial reasoning, fine-tuning them on Text-to-CadQuery data proves highly\neffective. Given that these capabilities typically improve with scale, we\nhypothesize that larger models will perform better after fine-tuning. To enable\nthis, we augment the Text2CAD dataset with 170,000 CadQuery annotations. We\nfine-tune six open-source LLMs of varying sizes and observe consistent\nimprovements. Our best model achieves a top-1 exact match of 69.3%, up from\n58.8%, and reduces Chamfer Distance by 48.6%. Project page:\nhttps://github.com/Text-to-CadQuery/Text-to-CadQuery.", "AI": {"tldr": "The paper proposes generating CadQuery code directly from text using pretrained LLMs, bypassing intermediate representations and improving efficiency.", "motivation": "Current methods for generative CAD require converting task-specific command sequences into CAD representations, adding complexity and limiting pretrained model use.", "method": "Fine-tune pretrained LLMs on a dataset augmented with 170,000 CadQuery annotations to generate CadQuery code from text.", "result": "Fine-tuned models show consistent improvements, with the best model achieving 69.3% top-1 exact match and reducing Chamfer Distance by 48.6%.", "conclusion": "Directly generating CadQuery code with LLMs is effective, scalable, and outperforms existing methods."}}
{"id": "2505.06268", "pdf": "https://arxiv.org/pdf/2505.06268", "abs": "https://arxiv.org/abs/2505.06268", "authors": ["Pengcheng Sun", "Erwu Liu", "Wei Ni", "Kanglei Yu", "Rui Wang", "Abbas Jamalipour"], "title": "Cluster-Aware Multi-Round Update for Wireless Federated Learning in Heterogeneous Environments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The aggregation efficiency and accuracy of wireless Federated Learning (FL)\nare significantly affected by resource constraints, especially in heterogeneous\nenvironments where devices exhibit distinct data distributions and\ncommunication capabilities. This paper proposes a clustering strategy that\nleverages prior knowledge similarity to group devices with similar data and\ncommunication characteristics, mitigating performance degradation from\nheterogeneity. On this basis, a novel Cluster- Aware Multi-round Update (CAMU)\nstrategy is proposed, which treats clusters as the basic units and adjusts the\nlocal update frequency based on the clustered contribution threshold,\neffectively reducing update bias and enhancing aggregation accuracy. The\ntheoretical convergence of the CAMU strategy is rigorously validated.\nMeanwhile, based on the convergence upper bound, the local update frequency and\ntransmission power of each cluster are jointly optimized to achieve an optimal\nbalance between computation and communication resources under constrained\nconditions, significantly improving the convergence efficiency of FL.\nExperimental results demonstrate that the proposed method effectively improves\nthe model performance of FL in heterogeneous environments and achieves a better\nbalance between communication cost and computational load under limited\nresources.", "AI": {"tldr": "A clustering strategy (CAMU) improves FL efficiency in heterogeneous environments by grouping devices with similar data and communication traits, optimizing updates and resource use.", "motivation": "Resource constraints and device heterogeneity degrade FL performance, necessitating strategies to mitigate these issues.", "method": "Proposes CAMU, clustering devices by similarity and adjusting local update frequency based on contribution thresholds, optimizing resource use.", "result": "CAMU reduces update bias, enhances accuracy, and balances computation-communication resources, improving FL convergence.", "conclusion": "CAMU effectively boosts FL performance in heterogeneous settings, optimizing resource efficiency and model accuracy."}}
{"id": "2505.07731", "pdf": "https://arxiv.org/pdf/2505.07731", "abs": "https://arxiv.org/abs/2505.07731", "authors": ["Neeraj Agrawal", "Sriram Ganapathy"], "title": "Spoken Language Understanding on Unseen Tasks With In-Context Learning", "categories": ["cs.CL", "cs.LG", "eess.AS"], "comment": null, "summary": "Spoken language understanding (SLU) tasks involve diverse skills that probe\nthe information extraction, classification and/or generation capabilities of\nmodels. In this setting, task-specific training data may not always be\navailable. While traditional task-specific SLU models are unable to cater to\nsuch requirements, the speech-text large language models (LLMs) offer a\npromising alternative with emergent abilities. However, out of-the-box, our\nevaluations indicate that the zero/few-shot performance of prominent\nopen-source speech-text LLMs on SLU tasks are not up to the mark. In this\npaper, we introduce a novel approach to robust task-agnostic fine-tuning using\nrandomized class labels. With this proposed fine-tuning, we illustrate that the\nperformance of the speech-text LLMs on an unseen task is significantly improved\nover standard approaches. Critically, the proposed approach avoids the\nrequirement of task-specific data annotations for enabling new tasks in\nspeech-text LLMs.", "AI": {"tldr": "The paper proposes a novel fine-tuning method using randomized class labels to improve speech-text LLMs' performance on unseen SLU tasks without task-specific annotations.", "motivation": "Task-specific training data is often unavailable for SLU tasks, and current speech-text LLMs perform poorly in zero/few-shot settings.", "method": "Introduces task-agnostic fine-tuning with randomized class labels to enhance model adaptability.", "result": "Significant performance improvement on unseen SLU tasks compared to standard approaches.", "conclusion": "The method enables new tasks in speech-text LLMs without requiring task-specific annotations."}}
{"id": "2505.07175", "pdf": "https://arxiv.org/pdf/2505.07175", "abs": "https://arxiv.org/abs/2505.07175", "authors": ["Yash Deo", "Yan Jia", "Toni Lassila", "William A. P. Smith", "Tom Lawton", "Siyuan Kang", "Alejandro F. Frangi", "Ibrahim Habli"], "title": "Metrics that matter: Evaluating image quality metrics for medical image generation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Evaluating generative models for synthetic medical imaging is crucial yet\nchallenging, especially given the high standards of fidelity, anatomical\naccuracy, and safety required for clinical applications. Standard evaluation of\ngenerated images often relies on no-reference image quality metrics when ground\ntruth images are unavailable, but their reliability in this complex domain is\nnot well established. This study comprehensively assesses commonly used\nno-reference image quality metrics using brain MRI data, including tumour and\nvascular images, providing a representative exemplar for the field. We\nsystematically evaluate metric sensitivity to a range of challenges, including\nnoise, distribution shifts, and, critically, localised morphological\nalterations designed to mimic clinically relevant inaccuracies. We then compare\nthese metric scores against model performance on a relevant downstream\nsegmentation task, analysing results across both controlled image perturbations\nand outputs from different generative model architectures. Our findings reveal\nsignificant limitations: many widely-used no-reference image quality metrics\ncorrelate poorly with downstream task suitability and exhibit a profound\ninsensitivity to localised anatomical details crucial for clinical validity.\nFurthermore, these metrics can yield misleading scores regarding distribution\nshifts, e.g. data memorisation. This reveals the risk of misjudging model\nreadiness, potentially leading to the deployment of flawed tools that could\ncompromise patient safety. We conclude that ensuring generative models are\ntruly fit for clinical purpose requires a multifaceted validation framework,\nintegrating performance on relevant downstream tasks with the cautious\ninterpretation of carefully selected no-reference image quality metrics.", "AI": {"tldr": "The study evaluates no-reference image quality metrics for synthetic medical imaging, revealing their limitations in clinical validity and downstream task suitability.", "motivation": "Assessing generative models for medical imaging is critical but challenging due to high standards for fidelity and safety. Current no-reference metrics lack reliability in this domain.", "method": "The study systematically evaluates no-reference metrics using brain MRI data, testing sensitivity to noise, distribution shifts, and morphological alterations. It compares metric scores with downstream segmentation task performance.", "result": "Findings show poor correlation between no-reference metrics and downstream task suitability, with insensitivity to clinically crucial anatomical details and misleading scores for distribution shifts.", "conclusion": "A multifaceted validation framework, combining downstream task performance and cautious metric interpretation, is needed to ensure generative models are clinically fit."}}
{"id": "2505.06519", "pdf": "https://arxiv.org/pdf/2505.06519", "abs": "https://arxiv.org/abs/2505.06519", "authors": ["Hansani Weeratunge", "Dominic Robe", "Elnaz Hajizadeh"], "title": "Interpretable SHAP-bounded Bayesian Optimization for Underwater Acoustic Metamaterial Coating Design", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.SD"], "comment": null, "summary": "We developed an interpretability informed Bayesian optimization framework to\noptimize underwater acoustic coatings based on polyurethane elastomers with\nembedded metamaterial features. A data driven model was employed to analyze the\nrelationship between acoustic performance, specifically sound absorption and\nthe corresponding design variables. By leveraging SHapley Additive exPlanations\n(SHAP), a machine learning interpretability tool, we identified the key\nparameters influencing the objective function and gained insights into how\nthese parameters affect sound absorption. The insights derived from the SHAP\nanalysis were subsequently used to automatically refine the bounds of the\noptimization problem automatically, enabling a more targeted and efficient\nexploration of the design space.\n  The proposed approach was applied to two polyurethane materials with distinct\nhardness levels, resulting in improved optimal solutions compared to those\nobtained without SHAP-informed guidance. Notably, these enhancements were\nachieved without increasing the number of simulation iterations. Our findings\ndemonstrate the potential of SHAP to streamline optimization processes by\nuncovering hidden parameter relationships and guiding the search toward\npromising regions of the design space. This work underscores the effectiveness\nof combining interpretability techniques with Bayesian optimization for the\nefficient and cost-effective design of underwater acoustic metamaterials under\nstrict computational constraints and can be generalized towards other materials\nand engineering optimization problems.", "AI": {"tldr": "An interpretability-informed Bayesian optimization framework was developed to optimize underwater acoustic coatings using SHAP for insights, improving efficiency without extra simulations.", "motivation": "To enhance the design of underwater acoustic coatings by leveraging interpretability tools for more efficient optimization under computational constraints.", "method": "Combined SHAP analysis with Bayesian optimization to identify key parameters and refine design bounds, applied to polyurethane elastomers with metamaterial features.", "result": "Improved optimal solutions for two polyurethane materials without additional simulation iterations, demonstrating SHAP's effectiveness.", "conclusion": "The approach efficiently combines interpretability and optimization, applicable to other materials and engineering problems."}}
{"id": "2505.06599", "pdf": "https://arxiv.org/pdf/2505.06599", "abs": "https://arxiv.org/abs/2505.06599", "authors": ["Abbas Bertina", "Shahab Beirami", "Hossein Biniazian", "Elham Esmaeilnia", "Soheil Shahi", "Mahdi Pirnia"], "title": "Bridging the Gap: An Intermediate Language for Enhanced and Cost-Effective Grapheme-to-Phoneme Conversion with Homographs with Multiple Pronunciations Disambiguation", "categories": ["cs.CL", "I.2.7; I.2.6"], "comment": "pdf, 8 pages, 4 figures, 4 tables", "summary": "Grapheme-to-phoneme (G2P) conversion for Persian presents unique challenges\ndue to its complex phonological features, particularly homographs and Ezafe,\nwhich exist in formal and informal language contexts. This paper introduces an\nintermediate language specifically designed for Persian language processing\nthat addresses these challenges through a multi-faceted approach. Our\nmethodology combines two key components: Large Language Model (LLM) prompting\ntechniques and a specialized sequence-to-sequence machine transliteration\narchitecture. We developed and implemented a systematic approach for\nconstructing a comprehensive lexical database for homographs with multiple\npronunciations disambiguation often termed polyphones, utilizing formal concept\nanalysis for semantic differentiation. We train our model using two distinct\ndatasets: the LLM-generated dataset for formal and informal Persian and the\nB-Plus podcasts for informal language variants. The experimental results\ndemonstrate superior performance compared to existing state-of-the-art\napproaches, particularly in handling the complexities of Persian phoneme\nconversion. Our model significantly improves Phoneme Error Rate (PER) metrics,\nestablishing a new benchmark for Persian G2P conversion accuracy. This work\ncontributes to the growing research in low-resource language processing and\nprovides a robust solution for Persian text-to-speech systems and demonstrating\nits applicability beyond Persian. Specifically, the approach can extend to\nlanguages with rich homographic phenomena such as Chinese and Arabic", "AI": {"tldr": "The paper introduces an intermediate language and a multi-faceted approach for Persian G2P conversion, combining LLM prompting and sequence-to-sequence transliteration, achieving superior performance in handling Persian's phonological complexities.", "motivation": "Persian G2P conversion is challenging due to homographs and Ezafe in formal and informal contexts, requiring a robust solution.", "method": "Combines LLM prompting and sequence-to-sequence transliteration, using formal concept analysis for homograph disambiguation. Trained on LLM-generated and B-Plus datasets.", "result": "Superior performance in Persian phoneme conversion, improving PER metrics and setting a new benchmark.", "conclusion": "The approach advances low-resource language processing and is applicable to other languages with homographic phenomena like Chinese and Arabic."}}
{"id": "2505.07008", "pdf": "https://arxiv.org/pdf/2505.07008", "abs": "https://arxiv.org/abs/2505.07008", "authors": ["Fengming Zhu", "Fangzhen Lin"], "title": "Constant-Memory Strategies in Stochastic Games: Best Responses and Equilibria", "categories": ["cs.GT", "cs.MA"], "comment": "19 pages, ongoing work", "summary": "(Here is a short version, see our paper for the complete abstract.)\n  In this work, we comprehensively investigate the concept of constant-memory\nstrategies in stochastic games. We first establish some results on best\nresponses and Nash equilibria for behavioral constant-memory strategies,\nfollowed by a discussion on the computational hardness of best responding to\nmixed constant-memory strategies. Those theoretic insights later empower a\ngenerative framework for studying generalizability of single-agent RL\nalgorithms.", "AI": {"tldr": "The paper explores constant-memory strategies in stochastic games, analyzing best responses, Nash equilibria, and computational hardness, then applies insights to generalize single-agent RL algorithms.", "motivation": "To understand the role and limitations of constant-memory strategies in stochastic games and leverage these insights for RL algorithm generalization.", "method": "Theoretical analysis of best responses and Nash equilibria for behavioral constant-memory strategies, followed by computational hardness study.", "result": "Established theoretical insights on constant-memory strategies and their computational challenges.", "conclusion": "The findings enable a generative framework for generalizing single-agent RL algorithms."}}
{"id": "2505.06467", "pdf": "https://arxiv.org/pdf/2505.06467", "abs": "https://arxiv.org/abs/2505.06467", "authors": ["Nisan Chhetri", "Arpan Sainju"], "title": "PromptIQ: Who Cares About Prompts? Let System Handle It -- A Component-Aware Framework for T2I Generation", "categories": ["cs.CV", "cs.HC"], "comment": "4 pages, 2 figures", "summary": "Generating high-quality images without prompt engineering expertise remains a\nchallenge for text-to-image (T2I) models, which often misinterpret poorly\nstructured prompts, leading to distortions and misalignments. While humans\neasily recognize these flaws, metrics like CLIP fail to capture structural\ninconsistencies, exposing a key limitation in current evaluation methods. To\naddress this, we introduce PromptIQ, an automated framework that refines\nprompts and assesses image quality using our novel Component-Aware Similarity\n(CAS) metric, which detects and penalizes structural errors. Unlike\nconventional methods, PromptIQ iteratively generates and evaluates images until\nthe user is satisfied, eliminating trial-and-error prompt tuning. Our results\nshow that PromptIQ significantly improves generation quality and evaluation\naccuracy, making T2I models more accessible for users with little to no prompt\nengineering expertise.", "AI": {"tldr": "PromptIQ automates prompt refinement and image quality assessment for text-to-image models, improving accessibility and quality without expert input.", "motivation": "Current T2I models struggle with poorly structured prompts, and existing metrics like CLIP fail to detect structural flaws, limiting usability for non-experts.", "method": "Introduces PromptIQ, a framework using Component-Aware Similarity (CAS) to refine prompts and evaluate images iteratively until user satisfaction.", "result": "PromptIQ enhances generation quality and evaluation accuracy, making T2I models more user-friendly.", "conclusion": "PromptIQ addresses key limitations in T2I models, improving accessibility and output quality for non-expert users."}}
{"id": "2505.06518", "pdf": "https://arxiv.org/pdf/2505.06518", "abs": "https://arxiv.org/abs/2505.06518", "authors": ["Larry Preuett III"], "title": "A Point-Based Algorithm for Distributional Reinforcement Learning in Partially Observable Domains", "categories": ["cs.AI"], "comment": null, "summary": "In many real-world planning tasks, agents must tackle uncertainty about the\nenvironment's state and variability in the outcomes of any chosen policy. We\naddress both forms of uncertainty as a first step toward safer algorithms in\npartially observable settings. Specifically, we extend Distributional\nReinforcement Learning (DistRL)-which models the entire return distribution for\nfully observable domains-to Partially Observable Markov Decision Processes\n(POMDPs), allowing an agent to learn the distribution of returns for each\nconditional plan. Concretely, we introduce new distributional Bellman operators\nfor partial observability and prove their convergence under the supremum\np-Wasserstein metric. We also propose a finite representation of these return\ndistributions via psi-vectors, generalizing the classical alpha-vectors in\nPOMDP solvers. Building on this, we develop Distributional Point-Based Value\nIteration (DPBVI), which integrates psi-vectors into a standard point-based\nbackup procedure-bridging DistRL and POMDP planning. By tracking return\ndistributions, DPBVI naturally enables risk-sensitive control in domains where\nrare, high-impact events must be carefully managed. We provide source code to\nfoster further research in robust decision-making under partial observability.", "AI": {"tldr": "The paper extends Distributional Reinforcement Learning (DistRL) to Partially Observable Markov Decision Processes (POMDPs), introducing new distributional Bellman operators and a finite representation of return distributions via psi-vectors. It proposes DPBVI for risk-sensitive control.", "motivation": "Address uncertainty in environment state and policy outcomes for safer algorithms in partially observable settings.", "method": "Extends DistRL to POMDPs with new distributional Bellman operators and psi-vectors, proposing DPBVI for planning.", "result": "Convergence proven under supremum p-Wasserstein metric; DPBVI enables risk-sensitive control.", "conclusion": "The work bridges DistRL and POMDP planning, fostering robust decision-making under partial observability."}}
{"id": "2505.06269", "pdf": "https://arxiv.org/pdf/2505.06269", "abs": "https://arxiv.org/abs/2505.06269", "authors": ["Chenguang Zhou", "Lei Chen", "Xiaohui Zhong", "Bo Lu", "Hao Li", "Libo Wu", "Jie Wu", "Jiahui Hu", "Zesheng Dou", "Pang-Chi Hsu", "Xiaoye Zhang"], "title": "A machine learning model for skillful climate system prediction", "categories": ["cs.LG"], "comment": null, "summary": "Climate system models (CSMs), through integrating cross-sphere interactions\namong the atmosphere, ocean, land, and cryosphere, have emerged as pivotal\ntools for deciphering climate dynamics and improving forecasting capabilities.\nRecent breakthroughs in artificial intelligence (AI)-driven meteorological\nmodeling have demonstrated remarkable success in single-sphere systems and\npartially spheres coupled systems. However, the development of a fully coupled\nAI-based climate system model encompassing atmosphere-ocean-land-sea ice\ninteractions has remained an unresolved challenge. This paper introduces\nFengShun-CSM, an AI-based CSM model that provides 60-day global daily forecasts\nfor 29 critical variables across atmospheric, oceanic, terrestrial, and\ncryospheric domains. The model significantly outperforms the European Centre\nfor Medium-Range Weather Forecasts (ECMWF) subseasonal-to-seasonal (S2S) model\nin predicting most variables, particularly precipitation, land surface, and\noceanic components. This enhanced capability is primarily attributed to its\nimproved representation of intra-seasonal variability modes, most notably the\nMadden-Julian Oscillation (MJO). Remarkably, FengShun-CSM exhibits substantial\npotential in predicting subseasonal extreme events. Such breakthroughs will\nadvance its applications in meteorological disaster mitigation, marine\necosystem conservation, and agricultural productivity enhancement. Furthermore,\nit validates the feasibility of developing AI-powered CSMs through machine\nlearning technologies, establishing a transformative paradigm for\nnext-generation Earth system modeling.", "AI": {"tldr": "FengShun-CSM, an AI-based climate system model, outperforms ECMWF's S2S model in 60-day global forecasts for 29 variables, excelling in precipitation, land, and ocean predictions due to better intra-seasonal variability representation.", "motivation": "To address the unresolved challenge of developing a fully coupled AI-based climate system model integrating atmosphere, ocean, land, and sea ice interactions.", "method": "Introduces FengShun-CSM, leveraging AI and machine learning to provide 60-day global daily forecasts for 29 key variables.", "result": "Significantly outperforms ECMWF's S2S model, especially in predicting precipitation, land surface, and oceanic components, with improved intra-seasonal variability representation (e.g., MJO).", "conclusion": "Demonstrates the feasibility of AI-powered CSMs, offering transformative potential for Earth system modeling and applications in disaster mitigation, conservation, and agriculture."}}
{"id": "2503.12010", "pdf": "https://arxiv.org/pdf/2503.12010", "abs": "https://arxiv.org/abs/2503.12010", "authors": ["Qixian Chen", "Yuxiong Xu", "Sara Mandelli", "Sheng Li", "Bin Li"], "title": "Adaptive Mixture of Low-Rank Experts for Robust Audio Spoofing Detection", "categories": ["eess.AS"], "comment": "5 pages, 1 figure, 4 tables", "summary": "In audio spoofing detection, most studies rely on clean datasets, making\nmodels susceptible to real-world post-processing attacks, such as channel\ncompression and noise. To overcome this challenge, we propose the Adaptive\nMixtUre Low-rank ExperTs (AMULET) framework, which enhances resilience by\nleveraging attack-specific knowledge and dynamically adapting to varied attack\nconditions. Specifically, AMULET employs Attack-Specific Experts (ASEs)\nfine-tuned with Low-Rank Adaptation (LoRA), allowing each expert to focus on\ndistinct post-processing patterns using just 1.13\\% of the parameters required\nfor full fine-tuning. Furthermore, we introduce Adaptive Expert Fusion (AEF),\nwhich adaptively selects and integrates expert knowledge to enhance the\nrobustness of spoofing detection. Experimental results demonstrate that AMULET\nsignificantly enhances robustness by improving noise resilience and exhibiting\ngreater adaptability to unseen post-processing methods compared to models\ntrained with full fine-tuning. Additionally, our framework outperforms both\nsingle expert and other expert aggregation strategies under various mixed\nattacks, demonstrating its superior robustness and adaptability in managing\ncomplex real-world scenarios.", "AI": {"tldr": "AMULET framework improves audio spoofing detection by using attack-specific experts and adaptive fusion, enhancing robustness against real-world post-processing attacks.", "motivation": "Existing models fail under real-world post-processing attacks due to reliance on clean datasets.", "method": "AMULET employs Attack-Specific Experts (ASEs) with Low-Rank Adaptation (LoRA) and Adaptive Expert Fusion (AEF) to dynamically adapt to varied attacks.", "result": "AMULET outperforms full fine-tuning and other strategies, showing better noise resilience and adaptability to unseen attacks.", "conclusion": "AMULET is a robust and adaptable solution for audio spoofing detection in complex real-world scenarios."}}
{"id": "2505.07349", "pdf": "https://arxiv.org/pdf/2505.07349", "abs": "https://arxiv.org/abs/2505.07349", "authors": ["Badhan Kumar Das", "Gengyan Zhao", "Boris Mailhe", "Thomas J. Re", "Dorin Comaniciu", "Eli Gibson", "Andreas Maier"], "title": "Multi-Plane Vision Transformer for Hemorrhage Classification Using Axial and Sagittal MRI Data", "categories": ["eess.IV", "cs.CV"], "comment": "10 pages", "summary": "Identifying brain hemorrhages from magnetic resonance imaging (MRI) is a\ncritical task for healthcare professionals. The diverse nature of MRI\nacquisitions with varying contrasts and orientation introduce complexity in\nidentifying hemorrhage using neural networks. For acquisitions with varying\norientations, traditional methods often involve resampling images to a fixed\nplane, which can lead to information loss. To address this, we propose a 3D\nmulti-plane vision transformer (MP-ViT) for hemorrhage classification with\nvarying orientation data. It employs two separate transformer encoders for\naxial and sagittal contrasts, using cross-attention to integrate information\nacross orientations. MP-ViT also includes a modality indication vector to\nprovide missing contrast information to the model. The effectiveness of the\nproposed model is demonstrated with extensive experiments on real world\nclinical dataset consists of 10,084 training, 1,289 validation and 1,496 test\nsubjects. MP-ViT achieved substantial improvement in area under the curve\n(AUC), outperforming the vision transformer (ViT) by 5.5% and CNN-based\narchitectures by 1.8%. These results highlight the potential of MP-ViT in\nimproving performance for hemorrhage detection when different orientation\ncontrasts are needed.", "AI": {"tldr": "A 3D multi-plane vision transformer (MP-ViT) is proposed for brain hemorrhage classification in MRI with varying orientations, outperforming traditional methods.", "motivation": "The diverse nature of MRI acquisitions with varying contrasts and orientations complicates hemorrhage identification, and resampling images to fixed planes can cause information loss.", "method": "MP-ViT uses two transformer encoders for axial and sagittal contrasts, integrating information via cross-attention and a modality indication vector for missing contrast data.", "result": "MP-ViT achieved a 5.5% improvement in AUC over ViT and 1.8% over CNN-based models on a clinical dataset of 10,084 training subjects.", "conclusion": "MP-ViT shows promise for improving hemorrhage detection in MRI with varying orientations."}}
{"id": "2211.09089", "pdf": "https://arxiv.org/pdf/2211.09089", "abs": "https://arxiv.org/abs/2211.09089", "authors": ["Yi Xiao", "Harshit Sharma", "Victoria Tumanova", "Asif Salekin"], "title": "Psychophysiology-aided Perceptually Fluent Speech Analysis of Children Who Stutter", "categories": ["cs.SD", "cs.HC", "eess.AS"], "comment": "13 pages, 5 figures, ICCPS 2025", "summary": "This paper presents a novel approach named PASAD that detects changes in\nperceptually fluent speech acoustics of young children. Particularly, analysis\nof perceptually fluent speech enables identifying the speech-motor-control\nfactors that are considered as the underlying cause of stuttering disfluencies.\nRecent studies indicate that the speech production of young children,\nespecially those who stutter, may get adversely affected by situational\nphysiological arousal. A major contribution of this paper is leveraging the\nspeaker's situational physiological responses in real-time to analyze the\nspeech signal effectively. The presented PASAD approach adapts a Hyper-Network\nstructure to extract temporal speech importance information leveraging\nphysiological parameters. Moreover, we collected speech and physiological\nsensing data from 73 preschool-age children who stutter (CWS) and who do not\nstutter (CWNS) in different conditions. PASAD's unique architecture enables\nidentifying speech attributes distinct to a CWS's fluent speech and mapping\nthem to the speaker's respective speech-motor-control factors. Extracted\nknowledge can enhance understanding of children's speech-motor-control and\nstuttering development. Our comprehensive evaluation shows that PASAD\noutperforms state-of-the-art multi-modal baseline approaches in different\nconditions, is expressive and adaptive to the speaker's speech and physiology,\ngeneralizable, robust, and is real-time executable.", "AI": {"tldr": "PASAD is a novel approach for detecting changes in perceptually fluent speech acoustics in young children, leveraging physiological responses to analyze speech-motor-control factors linked to stuttering.", "motivation": "To understand how situational physiological arousal affects speech production in children who stutter (CWS) and identify speech-motor-control factors underlying stuttering disfluencies.", "method": "Uses a Hyper-Network structure to extract temporal speech importance information from physiological parameters, with data from 73 preschool-age children (CWS and CWNS).", "result": "PASAD outperforms state-of-the-art multi-modal baselines, is expressive, adaptive, generalizable, robust, and real-time executable.", "conclusion": "PASAD enhances understanding of speech-motor-control and stuttering development in children, offering a real-time, effective analysis tool."}}
{"id": "2505.06605", "pdf": "https://arxiv.org/pdf/2505.06605", "abs": "https://arxiv.org/abs/2505.06605", "authors": ["Min Li", "Chun Yuan"], "title": "Using External knowledge to Enhanced PLM for Semantic Matching", "categories": ["cs.CL"], "comment": null, "summary": "Modeling semantic relevance has always been a challenging and critical task\nin natural language processing. In recent years, with the emergence of massive\namounts of annotated data, it has become feasible to train complex models, such\nas neural network-based reasoning models. These models have shown excellent\nperformance in practical applications and have achieved the current\nstate-ofthe-art performance. However, even with such large-scale annotated\ndata, we still need to think: Can machines learn all the knowledge necessary to\nperform semantic relevance detection tasks based on this data alone? If not,\nhow can neural network-based models incorporate external knowledge into\nthemselves, and how can relevance detection models be constructed to make full\nuse of external knowledge? In this paper, we use external knowledge to enhance\nthe pre-trained semantic relevance discrimination model. Experimental results\non 10 public datasets show that our method achieves consistent improvements in\nperformance compared to the baseline model.", "AI": {"tldr": "The paper explores enhancing semantic relevance detection in NLP by incorporating external knowledge into neural network models, showing improved performance over baselines.", "motivation": "Despite advances in neural models for semantic relevance, reliance on annotated data alone may not suffice. The paper investigates integrating external knowledge to improve model performance.", "method": "The authors enhance a pre-trained semantic relevance discrimination model by incorporating external knowledge, tested on 10 public datasets.", "result": "Experimental results demonstrate consistent performance improvements over the baseline model.", "conclusion": "Incorporating external knowledge effectively boosts semantic relevance detection, suggesting its value alongside annotated data."}}
{"id": "2505.07240", "pdf": "https://arxiv.org/pdf/2505.07240", "abs": "https://arxiv.org/abs/2505.07240", "authors": ["Yating Yuan"], "title": "Continuous-Time Control Synthesis for Multiple Quadrotors under Signal Temporal Logic Specifications", "categories": ["eess.SY", "cs.MA", "cs.SY"], "comment": null, "summary": "Ensuring continuous-time control of multiple quadrotors in constrained\nenvironments under signal temporal logic (STL) specifications is challenging\ndue to nonlinear dynamics, safety constraints, and disturbances. This letter\nproposes a two-stage framework to address this challenge. First, exponentially\ndecaying tracking error bounds are derived with multidimensional geometric\ncontrol gains obtained via differential evolution. These bounds are less\nconservative, while the resulting tracking errors exhibit smaller oscillations\nand improved transient performance. Second, leveraging the time-varying bounds,\na mixed-integer convex programming (MICP) formulation generates piecewise\nB\\'ezier reference trajectories that satisfy STL and velocity limits, while\nensuring inter-agent safety through convex-hull properties. Simulation results\ndemonstrate that the proposed approach enables formally verifiable multi-agent\ncoordination in constrained environments, with provable tracking guarantees\nunder bounded disturbances.", "AI": {"tldr": "A two-stage framework for multi-quadrotor control under STL specifications ensures less conservative error bounds and safe coordination via MICP-generated trajectories.", "motivation": "Addressing the challenge of controlling multiple quadrotors in constrained environments with nonlinear dynamics, safety constraints, and disturbances under STL specifications.", "method": "1) Derive exponentially decaying tracking error bounds with geometric control gains. 2) Use MICP to generate safe, STL-compliant B\u00e9zier trajectories.", "result": "Simulations show verifiable multi-agent coordination with provable tracking guarantees under disturbances.", "conclusion": "The framework effectively combines geometric control and MICP for robust, safe multi-quadrotor control in constrained settings."}}
{"id": "2505.06512", "pdf": "https://arxiv.org/pdf/2505.06512", "abs": "https://arxiv.org/abs/2505.06512", "authors": ["Hang Wang", "Zhi-Qi Cheng", "Chenhao Lin", "Chao Shen", "Lei Zhang"], "title": "HCMA: Hierarchical Cross-model Alignment for Grounded Text-to-Image Generation", "categories": ["cs.CV"], "comment": "10 pages, 4 figures", "summary": "Text-to-image synthesis has progressed to the point where models can generate\nvisually compelling images from natural language prompts. Yet, existing methods\noften fail to reconcile high-level semantic fidelity with explicit spatial\ncontrol, particularly in scenes involving multiple objects, nuanced relations,\nor complex layouts. To bridge this gap, we propose a Hierarchical Cross-Modal\nAlignment (HCMA) framework for grounded text-to-image generation. HCMA\nintegrates two alignment modules into each diffusion sampling step: a global\nmodule that continuously aligns latent representations with textual\ndescriptions to ensure scene-level coherence, and a local module that employs\nbounding-box layouts to anchor objects at specified locations, enabling\nfine-grained spatial control. Extensive experiments on the MS-COCO 2014\nvalidation set show that HCMA surpasses state-of-the-art baselines, achieving a\n0.69 improvement in Frechet Inception Distance (FID) and a 0.0295 gain in CLIP\nScore. These results demonstrate HCMA's effectiveness in faithfully capturing\nintricate textual semantics while adhering to user-defined spatial constraints,\noffering a robust solution for semantically grounded image generation.Our code\nis available at https://github.com/hwang-cs-ime/HCMA", "AI": {"tldr": "HCMA improves text-to-image synthesis by combining global and local alignment for better semantic fidelity and spatial control.", "motivation": "Existing methods lack high-level semantic fidelity and explicit spatial control in complex scenes.", "method": "HCMA integrates global (scene-level coherence) and local (object-level spatial control) alignment modules in diffusion sampling.", "result": "HCMA outperforms baselines with a 0.69 FID improvement and 0.0295 CLIP Score gain on MS-COCO.", "conclusion": "HCMA effectively captures textual semantics and adheres to spatial constraints, offering robust image generation."}}
{"id": "2505.06535", "pdf": "https://arxiv.org/pdf/2505.06535", "abs": "https://arxiv.org/abs/2505.06535", "authors": ["Anindya Sarkar", "Binglin Ji", "Yevgeniy Vorobeychik"], "title": "Online Feedback Efficient Active Target Discovery in Partially Observable Environments", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": "30 pages, 28 figures, Pre-print", "summary": "In various scientific and engineering domains, where data acquisition is\ncostly, such as in medical imaging, environmental monitoring, or remote\nsensing, strategic sampling from unobserved regions, guided by prior\nobservations, is essential to maximize target discovery within a limited\nsampling budget. In this work, we introduce Diffusion-guided Active Target\nDiscovery (DiffATD), a novel method that leverages diffusion dynamics for\nactive target discovery. DiffATD maintains a belief distribution over each\nunobserved state in the environment, using this distribution to dynamically\nbalance exploration-exploitation. Exploration reduces uncertainty by sampling\nregions with the highest expected entropy, while exploitation targets areas\nwith the highest likelihood of discovering the target, indicated by the belief\ndistribution and an incrementally trained reward model designed to learn the\ncharacteristics of the target. DiffATD enables efficient target discovery in a\npartially observable environment within a fixed sampling budget, all without\nrelying on any prior supervised training. Furthermore, DiffATD offers\ninterpretability, unlike existing black-box policies that require extensive\nsupervised training. Through extensive experiments and ablation studies across\ndiverse domains, including medical imaging and remote sensing, we show that\nDiffATD performs significantly better than baselines and competitively with\nsupervised methods that operate under full environmental observability.", "AI": {"tldr": "DiffATD is a novel method for active target discovery in costly data acquisition domains, balancing exploration-exploitation without supervised training.", "motivation": "Costly data acquisition in domains like medical imaging and remote sensing necessitates efficient sampling strategies to maximize target discovery within limited budgets.", "method": "DiffATD uses diffusion dynamics to maintain belief distributions over unobserved states, dynamically balancing exploration (high entropy regions) and exploitation (high-likelihood target areas) with an incrementally trained reward model.", "result": "DiffATD outperforms baselines and competes with supervised methods, even without prior training, while offering interpretability.", "conclusion": "DiffATD provides an efficient, interpretable solution for target discovery in partially observable environments with limited sampling budgets."}}
{"id": "2505.06270", "pdf": "https://arxiv.org/pdf/2505.06270", "abs": "https://arxiv.org/abs/2505.06270", "authors": ["Seongmin Kim", "Kwanho Kim", "Minseung Kim", "Kanghyun Jo"], "title": "Importance Analysis for Dynamic Control of Balancing Parameter in a Simple Knowledge Distillation Setting", "categories": ["cs.LG", "cs.AI"], "comment": "3 pages, 2 figures, conference preprint for IWIS2025", "summary": "Although deep learning models owe their remarkable success to deep and\ncomplex architectures, this very complexity typically comes at the expense of\nreal-time performance. To address this issue, a variety of model compression\ntechniques have been proposed, among which knowledge distillation (KD) stands\nout for its strong empirical performance. The KD contains two concurrent\nprocesses: (i) matching the outputs of a large, pre-trained teacher network and\na lightweight student network, and (ii) training the student to solve its\ndesignated downstream task. The associated loss functions are termed the\ndistillation loss and the downsteam-task loss, respectively. Numerous prior\nstudies report that KD is most effective when the influence of the distillation\nloss outweighs that of the downstream-task loss. The influence(or importance)\nis typically regulated by a balancing parameter. This paper provides a\nmathematical rationale showing that in a simple KD setting when the loss is\ndecreasing, the balancing parameter should be dynamically adjusted", "AI": {"tldr": "The paper explains why dynamically adjusting the balancing parameter in knowledge distillation (KD) improves performance, based on a mathematical rationale.", "motivation": "Deep learning models are complex and slow, so KD is used to compress them. However, the balance between distillation and downstream-task losses is critical for effectiveness.", "method": "The study analyzes a simple KD setting, showing mathematically that the balancing parameter should change dynamically as the loss decreases.", "result": "Dynamically adjusting the balancing parameter enhances KD performance.", "conclusion": "The paper concludes that dynamic adjustment of the balancing parameter is mathematically justified and improves KD outcomes."}}
{"id": "2504.14906", "pdf": "https://arxiv.org/pdf/2504.14906", "abs": "https://arxiv.org/abs/2504.14906", "authors": ["Huadai Liu", "Tianyi Luo", "Qikai Jiang", "Kaicheng Luo", "Peiwen Sun", "Jialei Wan", "Rongjie Huang", "Qian Chen", "Wen Wang", "Xiangtai Li", "Shiliang Zhang", "Zhijie Yan", "Zhou Zhao", "Wei Xue"], "title": "OmniAudio: Generating Spatial Audio from 360-Degree Video", "categories": ["eess.AS", "cs.CV", "cs.SD"], "comment": "ICML 2025", "summary": "Traditional video-to-audio generation techniques primarily focus on\nfield-of-view (FoV) video and non-spatial audio, often missing the spatial cues\nnecessary for accurately representing sound sources in 3D environments. To\naddress this limitation, we introduce a novel task, 360V2SA, to generate\nspatial audio from 360-degree videos, specifically producing First-order\nAmbisonics (FOA) audio - a standard format for representing 3D spatial audio\nthat captures sound directionality and enables realistic 3D audio reproduction.\nWe first create Sphere360, a novel dataset tailored for this task that is\ncurated from real-world data. We also design an efficient semi-automated\npipeline for collecting and cleaning paired video-audio data. To generate\nspatial audio from 360-degree video, we propose a novel framework OmniAudio,\nwhich leverages self-supervised pre-training using both spatial audio data (in\nFOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a\ndual-branch framework that utilizes both panoramic and FoV video inputs to\ncapture comprehensive local and global information from 360-degree videos.\nExperimental results demonstrate that OmniAudio achieves state-of-the-art\nperformance across both objective and subjective metrics on Sphere360. Code and\ndatasets will be released at https://github.com/liuhuadai/OmniAudio. The demo\npage is available at https://OmniAudio-360V2SA.github.io.", "AI": {"tldr": "The paper introduces 360V2SA, a task to generate spatial audio (FOA format) from 360-degree videos, addressing limitations of traditional methods. It presents Sphere360 dataset and OmniAudio framework, achieving state-of-the-art results.", "motivation": "Traditional video-to-audio methods lack spatial cues for 3D environments. This work aims to generate accurate spatial audio from 360-degree videos.", "method": "The paper proposes OmniAudio, a dual-branch framework leveraging self-supervised pre-training with FOA and non-spatial data, and uses panoramic/FoV video inputs.", "result": "OmniAudio achieves state-of-the-art performance on the Sphere360 dataset, validated by objective and subjective metrics.", "conclusion": "The work advances spatial audio generation from 360-degree videos, with potential applications in immersive audio experiences."}}
{"id": "2505.07364", "pdf": "https://arxiv.org/pdf/2505.07364", "abs": "https://arxiv.org/abs/2505.07364", "authors": ["Daria Zotova", "Nicolas Pinon", "Robin Trombetta", "Romain Bouet", "Julien Jung", "Carole Lartizien"], "title": "GAN-based synthetic FDG PET images from T1 brain MRI can serve to improve performance of deep unsupervised anomaly detection models", "categories": ["eess.IV", "cs.AI"], "comment": null, "summary": "Background and Objective. Research in the cross-modal medical image\ntranslation domain has been very productive over the past few years in tackling\nthe scarce availability of large curated multimodality datasets with the\npromising performance of GAN-based architectures. However, only a few of these\nstudies assessed task-based related performance of these synthetic data,\nespecially for the training of deep models. Method. We design and compare\ndifferent GAN-based frameworks for generating synthetic brain\n[18F]fluorodeoxyglucose (FDG) PET images from T1 weighted MRI data. We first\nperform standard qualitative and quantitative visual quality evaluation. Then,\nwe explore further impact of using these fake PET data in the training of a\ndeep unsupervised anomaly detection (UAD) model designed to detect subtle\nepilepsy lesions in T1 MRI and FDG PET images. We introduce novel diagnostic\ntask-oriented quality metrics of the synthetic FDG PET data tailored to our\nunsupervised detection task, then use these fake data to train a use case UAD\nmodel combining a deep representation learning based on siamese autoencoders\nwith a OC-SVM density support estimation model. This model is trained on normal\nsubjects only and allows the detection of any variation from the pattern of the\nnormal population. We compare the detection performance of models trained on 35\npaired real MR T1 of normal subjects paired either on 35 true PET images or on\n35 synthetic PET images generated from the best performing generative models.\nPerformance analysis is conducted on 17 exams of epilepsy patients undergoing\nsurgery. Results. The best performing GAN-based models allow generating\nrealistic fake PET images of control subject with SSIM and PSNR values around\n0.9 and 23.8, respectively and in distribution (ID) with regard to the true\ncontrol dataset. The best UAD model trained on these synthetic normative PET\ndata allows reaching 74% sensitivity. Conclusion. Our results confirm that\nGAN-based models are the best suited for MR T1 to FDG PET translation,\noutperforming transformer or diffusion models. We also demonstrate the\ndiagnostic value of these synthetic data for the training of UAD models and\nevaluation on clinical exams of epilepsy patients. Our code and the normative\nimage dataset are available.", "AI": {"tldr": "GAN-based models effectively generate synthetic FDG PET images from T1 MRI, aiding unsupervised anomaly detection in epilepsy cases.", "motivation": "Address the scarcity of large curated multimodal datasets and evaluate synthetic data's impact on deep model training.", "method": "Compare GAN frameworks for PET image generation, assess visual quality, and train a UAD model using synthetic data.", "result": "Best GAN models achieve SSIM 0.9 and PSNR 23.8; UAD model trained on synthetic data reaches 74% sensitivity.", "conclusion": "GANs outperform transformers/diffusion models for MR-to-PET translation, proving synthetic data's diagnostic value."}}
{"id": "2411.12363", "pdf": "https://arxiv.org/pdf/2411.12363", "abs": "https://arxiv.org/abs/2411.12363", "authors": ["Zihao Chen", "Zhentao Lin", "Bi Zeng", "Linyi Huang", "Zhi Li", "Jia Cai"], "title": "DGSNA: prompt-based Dynamic Generative Scene-based Noise Addition method", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "To ensure the reliable operation of speech systems across diverse\nenvironments, noise addition methods have emerged as the prevailing solution.\nHowever, existing methods offer limited coverage of real-world noisy scenes and\ndepend on pre-existing scene-based information and noise. This paper presents\nprompt-based Dynamic Generative Scene-based Noise Addition (DGSNA), a novel\nnoise addition methodology that integrates Dynamic Generation of Scene-based\nInformation (DGSI) with Scene-based Noise Addition for Speech (SNAS). This\nintegration facilitates automated scene-based noise addition by transforming\nclean speech into various noise environments, thereby providing a more\ncomprehensive and realistic simulation of diverse noise conditions.\nExperimental results demonstrate that DGSNA significantly enhances the\nrobustness of speech recognition and keyword spotting models across various\nnoise conditions, achieving a relative improvement of up to 11.21%.\nFurthermore, DGSNA can be effectively integrated with other noise addition\nmethods to enhance performance. Our implementation and demonstrations are\navailable at https://dgsna.github.io.", "AI": {"tldr": "DGSNA is a novel noise addition method combining dynamic scene generation and noise addition, improving speech system robustness by up to 11.21%.", "motivation": "Existing noise addition methods lack coverage of real-world noisy scenes and rely on pre-existing data.", "method": "Integrates Dynamic Generation of Scene-based Information (DGSI) with Scene-based Noise Addition for Speech (SNAS) to automate noise addition.", "result": "Enhances speech recognition and keyword spotting robustness by up to 11.21%.", "conclusion": "DGSNA offers a comprehensive and realistic noise simulation, compatible with other methods for further improvement."}}
{"id": "2505.06607", "pdf": "https://arxiv.org/pdf/2505.06607", "abs": "https://arxiv.org/abs/2505.06607", "authors": ["Min Li", "Chun Yuan"], "title": "Boosting Neural Language Inference via Cascaded Interactive Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Natural Language Inference (NLI) focuses on ascertaining the logical\nrelationship (entailment, contradiction, or neutral) between a given premise\nand hypothesis. This task presents significant challenges due to inherent\nlinguistic features such as diverse phrasing, semantic complexity, and\ncontextual nuances. While Pre-trained Language Models (PLMs) built upon the\nTransformer architecture have yielded substantial advancements in NLI,\nprevailing methods predominantly utilize representations from the terminal\nlayer. This reliance on final-layer outputs may overlook valuable information\nencoded in intermediate layers, potentially limiting the capacity to model\nintricate semantic interactions effectively. Addressing this gap, we introduce\nthe Cascaded Interactive Reasoning Network (CIRN), a novel architecture\ndesigned for deeper semantic comprehension in NLI. CIRN implements a\nhierarchical feature extraction strategy across multiple network depths,\noperating within an interactive space where cross-sentence information is\ncontinuously integrated. This mechanism aims to mimic a process of progressive\nreasoning, transitioning from surface-level feature matching to uncovering more\nprofound logical and semantic connections between the premise and hypothesis.\nBy systematically mining latent semantic relationships at various\nrepresentational levels, CIRN facilitates a more thorough understanding of the\ninput pair. Comprehensive evaluations conducted on several standard NLI\nbenchmark datasets reveal consistent performance gains achieved by CIRN over\ncompetitive baseline approaches, demonstrating the efficacy of leveraging\nmulti-level interactive features for complex relational reasoning.", "AI": {"tldr": "CIRN, a novel architecture for NLI, leverages multi-layer feature extraction and interactive reasoning to outperform baselines by capturing deeper semantic relationships.", "motivation": "Existing NLI methods rely on final-layer PLM outputs, potentially missing valuable intermediate-layer information for complex semantic interactions.", "method": "CIRN uses hierarchical feature extraction across network layers, integrating cross-sentence information progressively for deeper reasoning.", "result": "CIRN achieves consistent performance gains on standard NLI benchmarks, validating its effectiveness.", "conclusion": "Multi-level interactive features enhance NLI performance, demonstrating CIRN's superior semantic comprehension."}}
{"id": "2505.07501", "pdf": "https://arxiv.org/pdf/2505.07501", "abs": "https://arxiv.org/abs/2505.07501", "authors": ["Purandar Bhaduri"], "title": "The Complexity of Pure Strategy Relevant Equilibria in Concurrent Games", "categories": ["cs.GT", "cs.FL", "cs.LO", "cs.MA"], "comment": null, "summary": "We study rational synthesis problems for concurrent games with\n$\\omega$-regular objectives. Our model of rationality considers only pure\nstrategy Nash equilibria that satisfy either a social welfare or Pareto\noptimality condition with respect to an $\\omega$-regular objective for each\nagent. This extends earlier work on equilibria in concurrent games, without\nconsideration about their quality. Our results show that the existence of Nash\nequilibria satisfying social welfare conditions can be computed as efficiently\nas the constrained Nash equilibrium existence problem. On the other hand, the\nexistence of Nash equilibria satisfying the Pareto optimality condition\npossibly involves a higher upper bound, except in the case of B\\\"uchi and\nMuller games, for which all three problems are in the classes P and\nPSPACE-complete, respectively.", "AI": {"tldr": "The paper studies rational synthesis in concurrent games with \u03c9-regular objectives, focusing on Nash equilibria under social welfare or Pareto optimality conditions.", "motivation": "To extend prior work on equilibria in concurrent games by incorporating quality measures like social welfare and Pareto optimality.", "method": "Analyzes Nash equilibria in concurrent games with \u03c9-regular objectives, comparing computational efficiency for social welfare and Pareto optimality conditions.", "result": "Social welfare Nash equilibria can be computed as efficiently as constrained Nash equilibrium existence, while Pareto optimality may require higher complexity, except for B\u00fcchi and Muller games.", "conclusion": "The study provides insights into the computational complexity of rational synthesis problems in concurrent games, highlighting differences between social welfare and Pareto optimality conditions."}}
{"id": "2505.06515", "pdf": "https://arxiv.org/pdf/2505.06515", "abs": "https://arxiv.org/abs/2505.06515", "authors": ["Zhiwen Zeng", "Yunfei Yin", "Zheng Yuan", "Argho Dey", "Xianjian Bao"], "title": "RESAR-BEV: An Explainable Progressive Residual Autoregressive Approach for Camera-Radar Fusion in BEV Segmentation", "categories": ["cs.CV"], "comment": "This work was submitted to IEEE Transactions on Intelligent\n  Transportation Systems (T-ITS) on 09-May-2025", "summary": "Bird's-Eye-View (BEV) semantic segmentation provides comprehensive\nenvironmental perception for autonomous driving but suffers multi-modal\nmisalignment and sensor noise. We propose RESAR-BEV, a progressive refinement\nframework that advances beyond single-step end-to-end approaches: (1)\nprogressive refinement through residual autoregressive learning that decomposes\nBEV segmentation into interpretable coarse-to-fine stages via our\nDrive-Transformer and Modifier-Transformer residual prediction cascaded\narchitecture, (2) robust BEV representation combining ground-proximity voxels\nwith adaptive height offsets and dual-path voxel feature encoding\n(max+attention pooling) for efficient feature extraction, and (3) decoupled\nsupervision with offline Ground Truth decomposition and online joint\noptimization to prevent overfitting while ensuring structural coherence.\nExperiments on nuScenes demonstrate RESAR-BEV achieves state-of-the-art\nperformance with 54.0% mIoU across 7 essential driving-scene categories while\nmaintaining real-time capability at 14.6 FPS. The framework exhibits robustness\nin challenging scenarios of long-range perception and adverse weather\nconditions.", "AI": {"tldr": "RESAR-BEV is a progressive refinement framework for BEV semantic segmentation, addressing multi-modal misalignment and noise with interpretable stages, robust representation, and decoupled supervision, achieving state-of-the-art performance.", "motivation": "To improve BEV semantic segmentation for autonomous driving by overcoming multi-modal misalignment and sensor noise.", "method": "Progressive refinement via residual autoregressive learning, robust BEV representation combining voxels and dual-path encoding, and decoupled supervision.", "result": "Achieves 54.0% mIoU on nuScenes with real-time performance (14.6 FPS) and robustness in challenging scenarios.", "conclusion": "RESAR-BEV advances BEV segmentation with interpretability, efficiency, and robustness, setting a new benchmark."}}
{"id": "2505.06580", "pdf": "https://arxiv.org/pdf/2505.06580", "abs": "https://arxiv.org/abs/2505.06580", "authors": ["Dongyoon Yang", "Jihu Lee", "Yongdai Kim"], "title": "TAROT: Towards Essentially Domain-Invariant Robustness with Theoretical Justification", "categories": ["cs.AI", "stat.ML"], "comment": "Accepted in CVPR 2025 (19 pages, 7 figures)", "summary": "Robust domain adaptation against adversarial attacks is a critical research\narea that aims to develop models capable of maintaining consistent performance\nacross diverse and challenging domains. In this paper, we derive a new\ngeneralization bound for robust risk on the target domain using a novel\ndivergence measure specifically designed for robust domain adaptation. Building\nupon this, we propose a new algorithm named TAROT, which is designed to enhance\nboth domain adaptability and robustness. Through extensive experiments, TAROT\nnot only surpasses state-of-the-art methods in accuracy and robustness but also\nsignificantly enhances domain generalization and scalability by effectively\nlearning domain-invariant features. In particular, TAROT achieves superior\nperformance on the challenging DomainNet dataset, demonstrating its ability to\nlearn domain-invariant representations that generalize well across different\ndomains, including unseen ones. These results highlight the broader\napplicability of our approach in real-world domain adaptation scenarios.", "AI": {"tldr": "The paper introduces TAROT, a robust domain adaptation algorithm, and a new divergence measure for generalization bounds, achieving superior performance on DomainNet.", "motivation": "Addressing the need for models that maintain performance across diverse and adversarial domains.", "method": "Proposes TAROT, a novel algorithm leveraging a new divergence measure for robust domain adaptation.", "result": "TAROT outperforms state-of-the-art methods in accuracy, robustness, and domain generalization.", "conclusion": "TAROT's success on DomainNet demonstrates its broader applicability in real-world domain adaptation."}}
{"id": "2505.06272", "pdf": "https://arxiv.org/pdf/2505.06272", "abs": "https://arxiv.org/abs/2505.06272", "authors": ["Junzhou Xu", "Boyu Diao"], "title": "A Sensitivity-Driven Expert Allocation Method in LoRA-MoE for Efficient Fine-Tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As deep learning models expand, the pre-training-fine-tuning paradigm has\nbecome the standard approach for handling various downstream tasks. However,\nshared parameters can lead to diminished performance when dealing with complex\ndatasets involving multiple tasks. While introducing Mixture-of-Experts (MoE)\nmethods has alleviated this issue to some extent, it also significantly\nincreases the number of parameters required for fine-tuning and training time,\nintroducing greater parameter redundancy. To address these challenges, we\npropose a method for allocating expert numbers based on parameter sensitivity\nLoRA-SMoE (A Sensitivity-Driven Expert Allocation Method in LoRA-MoE for\nEfficient Fine-Tuning). This method rapidly assesses the sensitivity of\ndifferent tasks to parameters by sampling a small amount of data and using\ngradient information. It then adaptively allocates expert numbers within a\ngiven budget. The process maintains comparable memory consumption to LoRA\n(Low-Rank Adaptation) while ensuring an efficient and resource-friendly\nfine-tuning procedure. Experimental results demonstrate that compared to SOTA\nfine-tuning methods, our LoRA-SMoE approach can enhance model performance while\nreducing the number of trainable parameters. This significantly improves model\nperformance in resource-constrained environments. Additionally, due to its\nefficient parameter sensitivity evaluation mechanism, LoRA-SMoE requires\nminimal computational overhead to optimize expert allocation, making it\nparticularly suitable for scenarios with limited computational resources. All\nthe code in this study will be made publicly available following the acceptance\nof the paper for publication. Source code is at\nhttps://github.com/EMLS-ICTCAS/LoRA-SMoE", "AI": {"tldr": "The paper introduces LoRA-SMoE, a method for efficient fine-tuning of deep learning models by adaptively allocating experts based on parameter sensitivity, reducing redundancy and improving performance in resource-constrained settings.", "motivation": "The pre-training-fine-tuning paradigm struggles with shared parameters in complex multi-task datasets, and existing MoE methods increase parameter redundancy and training time.", "method": "LoRA-SMoE uses gradient information from sampled data to assess parameter sensitivity and adaptively allocates expert numbers within a budget, maintaining memory efficiency.", "result": "LoRA-SMoE outperforms SOTA methods by improving model performance while reducing trainable parameters, especially in resource-limited scenarios.", "conclusion": "LoRA-SMoE offers an efficient, resource-friendly fine-tuning solution with minimal computational overhead, making it ideal for constrained environments."}}
{"id": "2502.02929", "pdf": "https://arxiv.org/pdf/2502.02929", "abs": "https://arxiv.org/abs/2502.02929", "authors": ["Brandon Woodard", "Margarita Geleta", "Joseph J. LaViola Jr.", "Andrea Fanelli", "Rhonda Wilson"], "title": "AudioMiXR: Spatial Audio Object Manipulation with 6DoF for Sound Design in Augmented Reality", "categories": ["cs.HC", "cs.SD", "eess.AS"], "comment": "Revision necessary for accuracy", "summary": "We present AudioMiXR, an augmented reality (AR) interface intended to assess\nhow users manipulate virtual audio objects situated in their physical space\nusing six degrees of freedom (6DoF) deployed on a head-mounted display (Apple\nVision Pro) for 3D sound design. Existing tools for 3D sound design are\ntypically constrained to desktop displays, which may limit spatial awareness of\nmixing within the execution environment. Utilizing an XR HMD to create\nsoundscapes may provide a real-time test environment for 3D sound design, as\nmodern HMDs can provide precise spatial localization assisted by cross-modal\ninteractions. However, there is no research on design guidelines specific to\nsound design with six degrees of freedom (6DoF) in XR. To provide a first step\ntoward identifying design-related research directions in this space, we\nconducted an exploratory study where we recruited 27 participants, consisting\nof expert and non-expert sound designers. The goal was to assess design lessons\nthat can be used to inform future research venues in 3D sound design. We ran a\nwithin-subjects study where users designed both a music and cinematic\nsoundscapes. After thematically analyzing participant data, we constructed two\ndesign lessons: 1. Proprioception for AR Sound Design, and 2. Balancing\nAudio-Visual Modalities in AR GUIs. Additionally, we provide application\ndomains that can benefit most from 6DoF sound design based on our results.", "AI": {"tldr": "AudioMiXR is an AR interface for 6DoF virtual audio manipulation on HMDs, addressing gaps in 3D sound design research.", "motivation": "Existing 3D sound design tools lack spatial awareness; XR HMDs offer potential for real-time, precise soundscapes.", "method": "Exploratory study with 27 participants (experts/non-experts) designing music/cinematic soundscapes, analyzed thematically.", "result": "Two design lessons: Proprioception for AR Sound Design and Balancing Audio-Visual Modalities in AR GUIs.", "conclusion": "Identifies research directions and application domains for 6DoF sound design in XR."}}
{"id": "2505.07386", "pdf": "https://arxiv.org/pdf/2505.07386", "abs": "https://arxiv.org/abs/2505.07386", "authors": ["Rui Graca", "Tobi Delbruck"], "title": "Towards a physically realistic computationally efficient DVS pixel model", "categories": ["eess.IV"], "comment": "Presented in 2025 International Image Sensor Workshop", "summary": "Dynamic Vision Sensor (DVS) event camera models are important tools for\npredicting camera response, optimizing biases, and generating realistic\nsimulated datasets. Existing DVS models have been useful, but have not\ndemonstrated high realism for challenging HDR scenes combined with adequate\ncomputational efficiency for array-level scene simulation. This paper reports\nprogress towards a physically realistic and computationally efficient DVS model\nbased on large-signal differential equations derived from circuit analysis,\nwith parameters fitted from pixel measurements and circuit simulation. These\nare combined with an efficient stochastic event generation mechanism based on\nfirst-passage-time theory, allowing accurate noise generation with timesteps\ngreater than 1000x longer than previous methods", "AI": {"tldr": "A new DVS event camera model aims for high realism and computational efficiency by combining circuit-derived equations with stochastic event generation.", "motivation": "Existing DVS models lack realism for HDR scenes and computational efficiency for large-scale simulations.", "method": "Uses large-signal differential equations from circuit analysis and a stochastic event generation mechanism based on first-passage-time theory.", "result": "Achieves accurate noise generation with timesteps 1000x longer than previous methods.", "conclusion": "The proposed model advances DVS simulation by balancing physical realism and computational efficiency."}}
{"id": "2504.15118", "pdf": "https://arxiv.org/pdf/2504.15118", "abs": "https://arxiv.org/abs/2504.15118", "authors": ["Inho Kim", "Youngkil Song", "Jicheol Park", "Won Hwa Kim", "Suha Kwak"], "title": "Improving Sound Source Localization with Joint Slot Attention on Image and Audio", "categories": ["cs.CV", "cs.SD"], "comment": "Accepted to CVPR 2025", "summary": "Sound source localization (SSL) is the task of locating the source of sound\nwithin an image. Due to the lack of localization labels, the de facto standard\nin SSL has been to represent an image and audio as a single embedding vector\neach, and use them to learn SSL via contrastive learning. To this end, previous\nwork samples one of local image features as the image embedding and aggregates\nall local audio features to obtain the audio embedding, which is far from\noptimal due to the presence of noise and background irrelevant to the actual\ntarget in the input. We present a novel SSL method that addresses this chronic\nissue by joint slot attention on image and audio. To be specific, two slots\ncompetitively attend image and audio features to decompose them into target and\noff-target representations, and only target representations of image and audio\nare used for contrastive learning. Also, we introduce cross-modal attention\nmatching to further align local features of image and audio. Our method\nachieved the best in almost all settings on three public benchmarks for SSL,\nand substantially outperformed all the prior work in cross-modal retrieval.", "AI": {"tldr": "A novel SSL method using joint slot attention on image and audio to improve sound source localization by focusing on target representations and cross-modal alignment.", "motivation": "Existing SSL methods use suboptimal embeddings due to noise and irrelevant background, limiting performance.", "method": "Joint slot attention decomposes image and audio into target/off-target representations, using only target for contrastive learning, plus cross-modal attention matching.", "result": "Achieved top performance on three SSL benchmarks and significantly outperformed prior work in cross-modal retrieval.", "conclusion": "The proposed method effectively addresses noise and irrelevant data, enhancing SSL accuracy and cross-modal alignment."}}
{"id": "2505.06624", "pdf": "https://arxiv.org/pdf/2505.06624", "abs": "https://arxiv.org/abs/2505.06624", "authors": ["Arezoo Hatefi", "Xuan-Son Vu", "Monowar Bhuyan", "Frank Drewes"], "title": "The Efficiency of Pre-training with Objective Masking in Pseudo Labeling for Semi-Supervised Text Classification", "categories": ["cs.CL"], "comment": null, "summary": "We extend and study a semi-supervised model for text classification proposed\nearlier by Hatefi et al. for classification tasks in which document classes are\ndescribed by a small number of gold-labeled examples, while the majority of\ntraining examples is unlabeled. The model leverages the teacher-student\narchitecture of Meta Pseudo Labels in which a ''teacher'' generates labels for\noriginally unlabeled training data to train the ''student'' and updates its own\nmodel iteratively based on the performance of the student on the gold-labeled\nportion of the data. We extend the original model of Hatefi et al. by an\nunsupervised pre-training phase based on objective masking, and conduct\nin-depth performance evaluations of the original model, our extension, and\nvarious independent baselines. Experiments are performed using three different\ndatasets in two different languages (English and Swedish).", "AI": {"tldr": "The paper extends a semi-supervised text classification model by adding unsupervised pre-training and evaluates its performance against baselines on multilingual datasets.", "motivation": "To improve text classification with limited labeled data by leveraging teacher-student architecture and unsupervised pre-training.", "method": "Extends Hatefi et al.'s model with unsupervised pre-training (objective masking) and evaluates it on English and Swedish datasets.", "result": "Performance of the extended model is compared to the original and baselines, showing effectiveness.", "conclusion": "The extended model with pre-training enhances semi-supervised text classification, validated on multilingual data."}}
{"id": "2302.09859", "pdf": "https://arxiv.org/pdf/2302.09859", "abs": "https://arxiv.org/abs/2302.09859", "authors": ["Theodor Cimpeanu", "Luis Moniz Pereira", "The Anh Han"], "title": "The evolutionary advantage of guilt: co-evolution of social and non-social guilt in structured populations", "categories": ["cs.MA", "cs.AI", "cs.CY", "math.DS", "nlin.AO"], "comment": "26 pages, 6 figures, in press with the Journal of the Royal Society\n  Interface", "summary": "Building ethical machines may involve bestowing upon them the emotional\ncapacity to self-evaluate and repent on their actions. While apologies\nrepresent potential strategic interactions, the explicit evolution of guilt as\na behavioural trait remains poorly understood. Our study delves into the\nco-evolution of two forms of emotional guilt: social guilt entails a cost,\nrequiring agents to exert efforts to understand others' internal states and\nbehaviours; and non-social guilt, which only involves awareness of one's own\nstate, incurs no social cost. Resorting to methods from evolutionary game\ntheory, we study analytically, and through extensive numerical and agent-based\nsimulations, whether and how guilt can evolve and deploy, depending on the\nunderlying structure of the systems of agents. Our findings reveal that in\nlattice and scale-free networks, strategies favouring emotional guilt dominate\na broader range of guilt and social costs compared to non-structured well-mixed\npopulations, so leading to higher levels of cooperation. In structured\npopulations, both social and non-social guilt can thrive through clustering\nwith emotionally inclined strategies, thereby providing protection against\nexploiters, particularly for less costly non-social strategies. These insights\nshed light on the complex interplay of guilt and cooperation, enhancing our\nunderstanding of ethical artificial intelligence.", "AI": {"tldr": "The paper explores how guilt evolves in machines, distinguishing between social and non-social guilt, and its impact on cooperation in structured vs. unstructured populations.", "motivation": "To understand the evolution of guilt as a behavioral trait in ethical machines and its role in fostering cooperation.", "method": "Uses evolutionary game theory, analytical models, and agent-based simulations to study guilt in lattice, scale-free, and well-mixed networks.", "result": "In structured networks, guilt strategies dominate and enhance cooperation, with non-social guilt thriving due to lower costs and protection from exploiters.", "conclusion": "Structured environments favor the evolution of guilt, offering insights for designing ethical AI systems."}}
{"id": "2505.06516", "pdf": "https://arxiv.org/pdf/2505.06516", "abs": "https://arxiv.org/abs/2505.06516", "authors": ["Yilin Dong", "Tianyun Zhu", "Xinde Li", "Jean Dezert", "Rigui Zhou", "Changming Zhu", "Lei Cao", "Shuzhi Sam Ge"], "title": "Quantum Conflict Measurement in Decision Making for Out-of-Distribution Detection", "categories": ["cs.CV"], "comment": "16 pages, 28 figures", "summary": "Quantum Dempster-Shafer Theory (QDST) uses quantum interference effects to\nderive a quantum mass function (QMF) as a fuzzy metric type from information\nobtained from various data sources. In addition, QDST uses quantum parallel\ncomputing to speed up computation. Nevertheless, the effective management of\nconflicts between multiple QMFs in QDST is a challenging question. This work\naims to address this problem by proposing a Quantum Conflict Indicator (QCI)\nthat measures the conflict between two QMFs in decision-making. Then, the\nproperties of the QCI are carefully investigated. The obtained results validate\nits compliance with desirable conflict measurement properties such as\nnon-negativity, symmetry, boundedness, extreme consistency and insensitivity to\nrefinement. We then apply the proposed QCI in conflict fusion methods and\ncompare its performance with several commonly used fusion approaches. This\ncomparison demonstrates the superiority of the QCI-based conflict fusion\nmethod. Moreover, the Class Description Domain Space (C-DDS) and its optimized\nversion, C-DDS+ by utilizing the QCI-based fusion method, are proposed to\naddress the Out-of-Distribution (OOD) detection task. The experimental results\nshow that the proposed approach gives better OOD performance with respect to\nseveral state-of-the-art baseline OOD detection methods. Specifically, it\nachieves an average increase in Area Under the Receiver Operating\nCharacteristic Curve (AUC) of 1.2% and a corresponding average decrease in\nFalse Positive Rate at 95% True Negative Rate (FPR95) of 5.4% compared to the\noptimal baseline method.", "AI": {"tldr": "QDST introduces a Quantum Conflict Indicator (QCI) to manage conflicts between quantum mass functions, improving fusion methods and OOD detection performance.", "motivation": "Addressing the challenge of conflict management between multiple quantum mass functions in Quantum Dempster-Shafer Theory (QDST).", "method": "Proposes QCI to measure conflicts, investigates its properties, and applies it in fusion methods and OOD detection (C-DDS+).", "result": "QCI-based fusion outperforms baselines, improving OOD detection (AUC +1.2%, FPR95 -5.4%).", "conclusion": "QCI effectively manages conflicts in QDST and enhances OOD detection, demonstrating superior performance."}}
{"id": "2505.06637", "pdf": "https://arxiv.org/pdf/2505.06637", "abs": "https://arxiv.org/abs/2505.06637", "authors": ["Chi Xu", "Yili Jin", "Sami Ma", "Rongsheng Qian", "Hao Fang", "Jiangchuan Liu", "Xue Liu", "Edith C. H. Ngai", "William I. Atlas", "Katrina M. Connors", "Mark A. Spoljaric"], "title": "Exploring Multimodal Foundation AI and Expert-in-the-Loop for Sustainable Management of Wild Salmon Fisheries in Indigenous Rivers", "categories": ["cs.AI"], "comment": "10 pages, accepted by IJCAI 2025, AI and Social Good Track", "summary": "Wild salmon are essential to the ecological, economic, and cultural\nsustainability of the North Pacific Rim. Yet climate variability, habitat loss,\nand data limitations in remote ecosystems that lack basic infrastructure\nsupport pose significant challenges to effective fisheries management. This\nproject explores the integration of multimodal foundation AI and\nexpert-in-the-loop frameworks to enhance wild salmon monitoring and sustainable\nfisheries management in Indigenous rivers across Pacific Northwest. By\nleveraging video and sonar-based monitoring, we develop AI-powered tools for\nautomated species identification, counting, and length measurement, reducing\nmanual effort, expediting delivery of results, and improving decision-making\naccuracy. Expert validation and active learning frameworks ensure ecological\nrelevance while reducing annotation burdens. To address unique technical and\nsocietal challenges, we bring together a cross-domain, interdisciplinary team\nof university researchers, fisheries biologists, Indigenous stewardship\npractitioners, government agencies, and conservation organizations. Through\nthese collaborations, our research fosters ethical AI co-development, open data\nsharing, and culturally informed fisheries management.", "AI": {"tldr": "The paper explores using AI and expert collaboration to improve wild salmon monitoring and fisheries management in the Pacific Northwest, addressing ecological and societal challenges.", "motivation": "Wild salmon are vital to the North Pacific Rim, but climate change, habitat loss, and data limitations hinder effective management.", "method": "The project integrates multimodal AI and expert-in-the-loop frameworks, using video and sonar for automated species identification, counting, and measurement.", "result": "AI tools reduce manual effort, speed up results, and improve accuracy, validated by experts to ensure ecological relevance.", "conclusion": "The interdisciplinary approach fosters ethical AI, open data, and culturally informed fisheries management."}}
{"id": "2505.06273", "pdf": "https://arxiv.org/pdf/2505.06273", "abs": "https://arxiv.org/abs/2505.06273", "authors": ["Taehyun Cho", "Seokhun Ju", "Seungyub Han", "Dohyeong Kim", "Kyungjae Lee", "Jungwoo Lee"], "title": "Policy-labeled Preference Learning: Is Preference Enough for RLHF?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "To design rewards that align with human goals, Reinforcement Learning from\nHuman Feedback (RLHF) has emerged as a prominent technique for learning reward\nfunctions from human preferences and optimizing policies via reinforcement\nlearning algorithms. However, existing RLHF methods often misinterpret\ntrajectories as being generated by an optimal policy, causing inaccurate\nlikelihood estimation and suboptimal learning. Inspired by Direct Preference\nOptimization framework which directly learns optimal policy without explicit\nreward, we propose policy-labeled preference learning (PPL), to resolve\nlikelihood mismatch issues by modeling human preferences with regret, which\nreflects behavior policy information. We also provide a contrastive KL\nregularization, derived from regret-based principles, to enhance RLHF in\nsequential decision making. Experiments in high-dimensional continuous control\ntasks demonstrate PPL's significant improvements in offline RLHF performance\nand its effectiveness in online settings.", "AI": {"tldr": "PPL improves RLHF by addressing likelihood mismatch using regret-based modeling and KL regularization, showing better performance in offline and online RL tasks.", "motivation": "Existing RLHF methods misinterpret trajectories as optimal, leading to inaccurate likelihood estimation and suboptimal learning.", "method": "Proposes Policy-Labeled Preference Learning (PPL) to model human preferences with regret and introduces contrastive KL regularization.", "result": "PPL significantly improves offline RLHF performance and works effectively in online settings.", "conclusion": "PPL resolves likelihood mismatch in RLHF, enhancing policy optimization through regret-based modeling and KL regularization."}}
{"id": "2505.07449", "pdf": "https://arxiv.org/pdf/2505.07449", "abs": "https://arxiv.org/abs/2505.07449", "authors": ["Wei Li", "Ming Hu", "Guoan Wang", "Lihao Liu", "Kaijin Zhou", "Junzhi Ning", "Xin Guo", "Zongyuan Ge", "Lixu Gu", "Junjun He"], "title": "Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In ophthalmic surgery, developing an AI system capable of interpreting\nsurgical videos and predicting subsequent operations requires numerous\nophthalmic surgical videos with high-quality annotations, which are difficult\nto collect due to privacy concerns and labor consumption. Text-guided video\ngeneration (T2V) emerges as a promising solution to overcome this issue by\ngenerating ophthalmic surgical videos based on surgeon instructions. In this\npaper, we present Ophora, a pioneering model that can generate ophthalmic\nsurgical videos following natural language instructions. To construct Ophora,\nwe first propose a Comprehensive Data Curation pipeline to convert narrative\nophthalmic surgical videos into a large-scale, high-quality dataset comprising\nover 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive\nVideo-Instruction Tuning scheme to transfer rich spatial-temporal knowledge\nfrom a T2V model pre-trained on natural video-text datasets for\nprivacy-preserved ophthalmic surgical video generation based on Ophora-160K.\nExperiments on video quality evaluation via quantitative analysis and\nophthalmologist feedback demonstrate that Ophora can generate realistic and\nreliable ophthalmic surgical videos based on surgeon instructions. We also\nvalidate the capability of Ophora for empowering downstream tasks of ophthalmic\nsurgical workflow understanding. Code is available at\nhttps://github.com/mar-cry/Ophora.", "AI": {"tldr": "Ophora is an AI model that generates ophthalmic surgical videos from natural language instructions, addressing data scarcity and privacy issues.", "motivation": "The difficulty in collecting annotated ophthalmic surgical videos due to privacy and labor constraints motivates the use of text-guided video generation (T2V).", "method": "Ophora uses a Comprehensive Data Curation pipeline to create a dataset (Ophora-160K) and a Progressive Video-Instruction Tuning scheme to adapt a T2V model for surgical video generation.", "result": "Ophora produces realistic and reliable surgical videos, validated by quantitative analysis and ophthalmologist feedback, and aids in surgical workflow understanding.", "conclusion": "Ophora effectively addresses data scarcity in ophthalmic surgery through AI-generated videos, demonstrating practical utility for downstream tasks."}}
{"id": "2505.06630", "pdf": "https://arxiv.org/pdf/2505.06630", "abs": "https://arxiv.org/abs/2505.06630", "authors": ["Chunyi Yue", "Ang Li"], "title": "Dynamic Domain Information Modulation Algorithm for Multi-domain Sentiment Analysis", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "17 pages, 5 figures, 3 tables", "summary": "Multi-domain sentiment classification aims to mitigate poor performance\nmodels due to the scarcity of labeled data in a single domain, by utilizing\ndata labeled from various domains. A series of models that jointly train domain\nclassifiers and sentiment classifiers have demonstrated their advantages,\nbecause domain classification helps generate necessary information for\nsentiment classification. Intuitively, the importance of sentiment\nclassification tasks is the same in all domains for multi-domain sentiment\nclassification; but domain classification tasks are different because the\nimpact of domain information on sentiment classification varies across\ndifferent fields; this can be controlled through adjustable weights or hyper\nparameters. However, as the number of domains increases, existing\nhyperparameter optimization algorithms may face the following challenges: (1)\ntremendous demand for computing resources, (2) convergence problems, and (3)\nhigh algorithm complexity. To efficiently generate the domain information\nrequired for sentiment classification in each domain, we propose a dynamic\ninformation modulation algorithm. Specifically, the model training process is\ndivided into two stages. In the first stage, a shared hyperparameter, which\nwould control the proportion of domain classification tasks across all fields,\nis determined. In the second stage, we introduce a novel domain-aware\nmodulation algorithm to adjust the domain information contained in the input\ntext, which is then calculated based on a gradient-based and loss-based method.\nIn summary, experimental results on a public sentiment analysis dataset\ncontaining 16 domains prove the superiority of the proposed method.", "AI": {"tldr": "A dynamic information modulation algorithm improves multi-domain sentiment classification by efficiently generating domain-specific information, addressing challenges like high computational demand and convergence issues.", "motivation": "To overcome poor performance in single-domain sentiment classification due to limited labeled data by leveraging multi-domain data and optimizing domain-specific information.", "method": "A two-stage approach: first, determining a shared hyperparameter for domain classification tasks; second, using a domain-aware modulation algorithm to adjust domain information via gradient and loss-based methods.", "result": "Superior performance demonstrated on a 16-domain public sentiment analysis dataset.", "conclusion": "The proposed method effectively addresses computational and convergence challenges in multi-domain sentiment classification."}}
{"id": "2405.03132", "pdf": "https://arxiv.org/pdf/2405.03132", "abs": "https://arxiv.org/abs/2405.03132", "authors": ["Lu Liu", "Maonan Wang", "Man-On Pun", "Xi Xiong"], "title": "A Multi-Agent Rollout Approach for Highway Bottleneck Decongestion in Mixed Autonomy", "categories": ["cs.MA"], "comment": "Accepted by the 2024 IEEE 27th International Conference on\n  Intelligent Transportation Systems (ITSC)", "summary": "The integration of autonomous vehicles (AVs) into the existing transportation\ninfrastructure offers a promising solution to alleviate congestion and enhance\nmobility. This research explores a novel approach to traffic optimization by\nemploying a multi-agent rollout approach within a mixed autonomy environment.\nThe study concentrates on coordinating the speed of human-driven vehicles by\nlongitudinally controlling AVs, aiming to dynamically optimize traffic flow and\nalleviate congestion at highway bottlenecks in real-time. We model the problem\nas a decentralized partially observable Markov decision process (Dec-POMDP) and\npropose an improved multi-agent rollout algorithm. By employing agent-by-agent\npolicy iterations, our approach implicitly considers cooperation among multiple\nagents and seamlessly adapts to complex scenarios where the number of agents\ndynamically varies. Validated in a real-world network with varying AV\npenetration rates and traffic flow, the simulations demonstrate that the\nmulti-agent rollout algorithm significantly enhances performance, reducing\naverage travel time on bottleneck segments by 9.42% with a 10% AV penetration\nrate.", "AI": {"tldr": "A multi-agent rollout approach optimizes traffic flow in mixed autonomy environments by controlling AVs to coordinate human-driven vehicles, reducing congestion by 9.42% with 10% AV penetration.", "motivation": "To alleviate congestion and enhance mobility by integrating AVs into existing infrastructure, focusing on real-time traffic flow optimization at highway bottlenecks.", "method": "Uses a decentralized partially observable Markov decision process (Dec-POMDP) and an improved multi-agent rollout algorithm with agent-by-agent policy iterations.", "result": "Simulations show a 9.42% reduction in average travel time at bottlenecks with 10% AV penetration.", "conclusion": "The multi-agent rollout algorithm effectively optimizes traffic flow in dynamic, mixed autonomy environments."}}
{"id": "2505.06517", "pdf": "https://arxiv.org/pdf/2505.06517", "abs": "https://arxiv.org/abs/2505.06517", "authors": ["Xiaohong Huang", "Cui Yang", "Miaowen Wen"], "title": "Edge-Enabled VIO with Long-Tracked Features for High-Accuracy Low-Altitude IoT Navigation", "categories": ["cs.CV", "cs.RO"], "comment": "9 pages with 9 figures", "summary": "This paper presents a visual-inertial odometry (VIO) method using\nlong-tracked features. Long-tracked features can constrain more visual frames,\nreducing localization drift. However, they may also lead to accumulated\nmatching errors and drift in feature tracking. Current VIO methods adjust\nobservation weights based on re-projection errors, yet this approach has flaws.\nRe-projection errors depend on estimated camera poses and map points, so\nincreased errors might come from estimation inaccuracies, not actual feature\ntracking errors. This can mislead the optimization process and make\nlong-tracked features ineffective for suppressing localization drift.\nFurthermore, long-tracked features constrain a larger number of frames, which\nposes a significant challenge to real-time performance of the system. To tackle\nthese issues, we propose an active decoupling mechanism for accumulated errors\nin long-tracked feature utilization. We introduce a visual reference frame\nreset strategy to eliminate accumulated tracking errors and a depth prediction\nstrategy to leverage the long-term constraint. To ensure real time preformane,\nwe implement three strategies for efficient system state estimation: a parallel\nelimination strategy based on predefined elimination order, an inverse-depth\nelimination simplification strategy, and an elimination skipping strategy.\nExperiments on various datasets show that our method offers higher positioning\naccuracy with relatively short consumption time, making it more suitable for\nedge-enabled low-altitude IoT navigation, where high-accuracy positioning and\nreal-time operation on edge device are required. The code will be published at\ngithub.", "AI": {"tldr": "A VIO method using long-tracked features is proposed, addressing drift and real-time challenges with active decoupling and efficient state estimation strategies.", "motivation": "Long-tracked features reduce drift but introduce matching errors and real-time performance issues, which current methods fail to address properly.", "method": "Proposes active decoupling for errors, visual reference frame reset, depth prediction, and three state estimation strategies for efficiency.", "result": "Higher positioning accuracy with shorter computation time, suitable for edge-enabled IoT navigation.", "conclusion": "The method effectively balances accuracy and real-time performance, making it ideal for edge devices."}}
{"id": "2505.06680", "pdf": "https://arxiv.org/pdf/2505.06680", "abs": "https://arxiv.org/abs/2505.06680", "authors": ["Linxuan Huang", "Dong-Fan Xie", "Li Li", "Zhengbing He"], "title": "A Survey on Data-Driven Modeling of Human Drivers' Lane-Changing Decisions", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.SY", "eess.SY", "physics.soc-ph"], "comment": null, "summary": "Lane-changing (LC) behavior, a critical yet complex driving maneuver,\nsignificantly influences driving safety and traffic dynamics. Traditional\nanalytical LC decision (LCD) models, while effective in specific environments,\noften oversimplify behavioral heterogeneity and complex interactions, limiting\ntheir capacity to capture real LCD. Data-driven approaches address these gaps\nby leveraging rich empirical data and machine learning to decode latent\ndecision-making patterns, enabling adaptive LCD modeling in dynamic\nenvironments. In light of the rapid development of artificial intelligence and\nthe demand for data-driven models oriented towards connected vehicles and\nautonomous vehicles, this paper presents a comprehensive survey of data-driven\nLCD models, with a particular focus on human drivers LC decision-making. It\nsystematically reviews the modeling framework, covering data sources and\npreprocessing, model inputs and outputs, objectives, structures, and validation\nmethods. This survey further discusses the opportunities and challenges faced\nby data-driven LCD models, including driving safety, uncertainty, as well as\nthe integration and improvement of technical frameworks.", "AI": {"tldr": "This paper surveys data-driven lane-changing decision (LCD) models, focusing on human drivers, and reviews their frameworks, challenges, and opportunities.", "motivation": "Traditional LCD models oversimplify behavior and interactions, while data-driven approaches leverage machine learning for adaptive modeling in dynamic environments.", "method": "The paper systematically reviews data-driven LCD models, covering data sources, preprocessing, inputs, outputs, objectives, structures, and validation methods.", "result": "The survey highlights the potential of data-driven LCD models but also identifies challenges like driving safety, uncertainty, and technical framework integration.", "conclusion": "Data-driven LCD models offer promising advancements but require addressing challenges to fully realize their potential in connected and autonomous vehicles."}}
{"id": "2505.06274", "pdf": "https://arxiv.org/pdf/2505.06274", "abs": "https://arxiv.org/abs/2505.06274", "authors": ["Baijiong Lin", "Weisen Jiang", "Yuancheng Xu", "Hao Chen", "Ying-Cong Chen"], "title": "PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Multi-objective test-time alignment aims to adapt large language models\n(LLMs) to diverse multi-dimensional user preferences during inference while\nkeeping LLMs frozen. Recently, GenARM (Xu et al., 2025) first independently\ntrains Autoregressive Reward Models (ARMs) for each preference dimension\nwithout awareness of each other, then combines their outputs based on\nuser-specific preference vectors during inference to achieve multi-objective\ntest-time alignment, leading to two key limitations: the need for\n\\textit{multiple} ARMs increases the inference cost, and the separate training\nof ARMs causes the misalignment between the guided generation and the user\npreferences. To address these issues, we propose Preference-aware ARM (PARM), a\nsingle unified ARM trained across all preference dimensions. PARM uses our\nproposed Preference-Aware Bilinear Low-Rank Adaptation (PBLoRA), which employs\na bilinear form to condition the ARM on preference vectors, enabling it to\nachieve precise control over preference trade-offs during inference.\nExperiments demonstrate that PARM reduces inference costs and achieves better\nalignment with preference vectors compared with existing methods. Additionally,\nPARM enables weak-to-strong guidance, allowing a smaller PARM to guide a larger\nfrozen LLM without expensive training, making multi-objective alignment\naccessible with limited computing resources. The code is available at\nhttps://github.com/Baijiong-Lin/PARM.", "AI": {"tldr": "PARM introduces a unified Autoregressive Reward Model (ARM) trained across all preference dimensions, reducing inference costs and improving alignment with user preferences compared to existing methods.", "motivation": "Address the limitations of GenARM, which requires multiple ARMs and suffers from misalignment due to separate training.", "method": "Proposes Preference-aware ARM (PARM) with Preference-Aware Bilinear Low-Rank Adaptation (PBLoRA) for precise control over preference trade-offs.", "result": "PARM reduces inference costs, achieves better alignment, and enables weak-to-strong guidance with limited resources.", "conclusion": "PARM offers a cost-effective and efficient solution for multi-objective test-time alignment in LLMs."}}
{"id": "2505.07654", "pdf": "https://arxiv.org/pdf/2505.07654", "abs": "https://arxiv.org/abs/2505.07654", "authors": ["Pouya Afshin", "David Helminiak", "Tongtong Lu", "Tina Yen", "Julie M. Jorns", "Mollie Patton", "Bing Yu", "Dong Hye Ye"], "title": "Breast Cancer Classification in Deep Ultraviolet Fluorescence Images Using a Patch-Level Vision Transformer Framework", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Breast-conserving surgery (BCS) aims to completely remove malignant lesions\nwhile maximizing healthy tissue preservation. Intraoperative margin assessment\nis essential to achieve a balance between thorough cancer resection and tissue\nconservation. A deep ultraviolet fluorescence scanning microscope (DUV-FSM)\nenables rapid acquisition of whole surface images (WSIs) for excised tissue,\nproviding contrast between malignant and normal tissues. However, breast cancer\nclassification with DUV WSIs is challenged by high resolutions and complex\nhistopathological features. This study introduces a DUV WSI classification\nframework using a patch-level vision transformer (ViT) model, capturing local\nand global features. Grad-CAM++ saliency weighting highlights relevant spatial\nregions, enhances result interpretability, and improves diagnostic accuracy for\nbenign and malignant tissue classification. A comprehensive 5-fold\ncross-validation demonstrates the proposed approach significantly outperforms\nconventional deep learning methods, achieving a classification accuracy of\n98.33%.", "AI": {"tldr": "A patch-level vision transformer (ViT) model with Grad-CAM++ improves breast cancer classification in DUV-FSM images, achieving 98.33% accuracy.", "motivation": "To enhance intraoperative margin assessment in breast-conserving surgery by improving the classification of malignant and normal tissues in DUV-FSM images.", "method": "A patch-level ViT model with Grad-CAM++ saliency weighting is used to classify DUV whole surface images (WSIs), capturing local and global features.", "result": "The proposed framework achieves 98.33% classification accuracy, outperforming conventional deep learning methods.", "conclusion": "The ViT-based approach with Grad-CAM++ provides accurate and interpretable classification for breast cancer detection in DUV-FSM images."}}
{"id": "2505.06633", "pdf": "https://arxiv.org/pdf/2505.06633", "abs": "https://arxiv.org/abs/2505.06633", "authors": ["Isaac Gerber"], "title": "Attention Is Not All You Need: The Importance of Feedforward Networks in Transformer Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Decoder-only transformer networks have become incredibly popular for language\nmodeling tasks. State-of-the-art models can have over a hundred transformer\nblocks, containing billions of trainable parameters, and are trained on\ntrillions of tokens of text. Each transformer block typically consists of a\nmulti-head attention (MHA) mechanism and a two-layer fully connected\nfeedforward network (FFN). In this paper, we examine the importance of the FFN\nduring the model pre-training process through a series of experiments,\nconfirming that the FFN is important to model performance. Furthermore, we show\nthat models using a transformer block configuration with three-layer FFNs with\nfewer such blocks outperform the standard two-layer configuration delivering\nlower training loss with fewer total parameters in less time.", "AI": {"tldr": "The paper investigates the role of feedforward networks (FFNs) in decoder-only transformer models, showing that three-layer FFNs outperform standard two-layer ones with fewer blocks and parameters.", "motivation": "To understand the importance of FFNs in transformer-based language models and explore more efficient configurations.", "method": "Conducted experiments comparing standard two-layer FFNs with three-layer FFNs in transformer blocks during pre-training.", "result": "Three-layer FFNs with fewer blocks achieve lower training loss, fewer parameters, and faster training than two-layer FFNs.", "conclusion": "The FFN is crucial for model performance, and optimizing its architecture (e.g., three-layer FFNs) can improve efficiency without sacrificing quality."}}
{"id": "2505.03586", "pdf": "https://arxiv.org/pdf/2505.03586", "abs": "https://arxiv.org/abs/2505.03586", "authors": ["Songchen Fu", "Siang Chen", "Shaojing Zhao", "Letian Bai", "Ta Li", "Yonghong Yan"], "title": "Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Delayed Observation", "categories": ["cs.MA", "cs.AI", "68T07 (Primary), 68T20, 68T42 (Secondary)", "I.2"], "comment": "The code will be open-sourced in the RDC-pymarl project under\n  https://github.com/linkjoker1006", "summary": "In real-world multi-agent systems (MASs), observation delays are ubiquitous,\npreventing agents from making decisions based on the environment's true state.\nAn individual agent's local observation often consists of multiple components\nfrom other agents or dynamic entities in the environment. These discrete\nobservation components with varying delay characteristics pose significant\nchallenges for multi-agent reinforcement learning (MARL). In this paper, we\nfirst formulate the decentralized stochastic individual delay partially\nobservable Markov decision process (DSID-POMDP) by extending the standard\nDec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL\ntraining framework for addressing stochastic individual delays, along with\nrecommended implementations for its constituent modules. We implement the\nDSID-POMDP's observation generation pattern using standard MARL benchmarks,\nincluding MPE and SMAC. Experiments demonstrate that baseline MARL methods\nsuffer severe performance degradation under fixed and unfixed delays. The\nRDC-enhanced approach mitigates this issue, remarkably achieving ideal\ndelay-free performance in certain delay scenarios while maintaining\ngeneralizability. Our work provides a novel perspective on multi-agent delayed\nobservation problems and offers an effective solution framework. The source\ncode is available at https://anonymous.4open.science/r/RDC-pymarl-4512/.", "AI": {"tldr": "The paper introduces the DSID-POMDP framework to address stochastic individual delays in multi-agent systems and proposes the RDC training framework to mitigate performance degradation caused by delays.", "motivation": "Observation delays in multi-agent systems hinder agents from making decisions based on the true state of the environment, posing challenges for MARL.", "method": "The authors extend Dec-POMDP to formulate DSID-POMDP and propose the RDC framework with recommended module implementations. They test it using MARL benchmarks (MPE and SMAC).", "result": "Baseline MARL methods perform poorly under delays, while RDC achieves near delay-free performance in some scenarios and maintains generalizability.", "conclusion": "The work offers a novel solution for delayed observation problems in MASs, with practical applicability demonstrated through experiments."}}
{"id": "2505.06524", "pdf": "https://arxiv.org/pdf/2505.06524", "abs": "https://arxiv.org/abs/2505.06524", "authors": ["Jingyao Wang", "Jianqi Zhang", "Wenwen Qiang", "Changwen Zheng"], "title": "Causal Prompt Calibration Guided Segment Anything Model for Open-Vocabulary Multi-Entity Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Despite the strength of the Segment Anything Model (SAM), it struggles with\ngeneralization issues in open-vocabulary multi-entity segmentation (OVMS).\nThrough empirical and causal analyses, we find that (i) the prompt bias is the\nprimary cause of the generalization issues; (ii) this bias is closely tied to\nthe task-irrelevant generating factors within the prompts, which act as\nconfounders and affect generalization. To address the generalization issues, we\naim to propose a method that can calibrate prompts to eliminate confounders for\naccurate OVMS. Building upon the causal analysis, we propose that the optimal\nprompt for OVMS should contain only task-relevant causal factors. We define it\nas the causal prompt, serving as the goal of calibration. Next, our theoretical\nanalysis, grounded by causal multi-distribution consistency theory, proves that\nthis prompt can be obtained by enforcing segmentation consistency and\noptimality. Inspired by this, we propose CPC-SAM, a Causal Prompt Calibration\nmethod for SAM to achieve accurate OVMS. It integrates a lightweight causal\nprompt learner (CaPL) into SAM to obtain causal prompts. Specifically, we first\ngenerate multiple prompts using random annotations to simulate diverse\ndistributions and then reweight them via CaPL by enforcing causal\nmulti-distribution consistency in both task and entity levels. To ensure\nobtaining causal prompts, CaPL is optimized by minimizing the cumulative\nsegmentation loss across the reweighted prompts to achieve consistency and\noptimality. A bi-level optimization strategy alternates between optimizing CaPL\nand SAM, ensuring accurate OVMS. Extensive experiments validate its\nsuperiority.", "AI": {"tldr": "The paper identifies prompt bias as the main issue in SAM's generalization for open-vocabulary multi-entity segmentation (OVMS) and proposes CPC-SAM, a method to calibrate prompts by eliminating confounders.", "motivation": "SAM struggles with generalization in OVMS due to prompt bias caused by task-irrelevant factors. The goal is to improve accuracy by addressing this bias.", "method": "Proposes CPC-SAM, integrating a causal prompt learner (CaPL) to reweight prompts via causal multi-distribution consistency. Uses bi-level optimization to alternate between CaPL and SAM.", "result": "CPC-SAM achieves superior performance in OVMS by enforcing segmentation consistency and optimality.", "conclusion": "The causal prompt calibration method effectively addresses generalization issues in SAM, validated by extensive experiments."}}
{"id": "2505.06706", "pdf": "https://arxiv.org/pdf/2505.06706", "abs": "https://arxiv.org/abs/2505.06706", "authors": ["Yuxuan Zheng", "Yihe Zhou", "Feiyang Xu", "Mingli Song", "Shunyu Liu"], "title": "Bi-level Mean Field: Dynamic Grouping for Large-Scale MARL", "categories": ["cs.AI"], "comment": null, "summary": "Large-scale Multi-Agent Reinforcement Learning (MARL) often suffers from the\ncurse of dimensionality, as the exponential growth in agent interactions\nsignificantly increases computational complexity and impedes learning\nefficiency. To mitigate this, existing efforts that rely on Mean Field (MF)\nsimplify the interaction landscape by approximating neighboring agents as a\nsingle mean agent, thus reducing overall complexity to pairwise interactions.\nHowever, these MF methods inevitably fail to account for individual\ndifferences, leading to aggregation noise caused by inaccurate iterative\nupdates during MF learning. In this paper, we propose a Bi-level Mean Field\n(BMF) method to capture agent diversity with dynamic grouping in large-scale\nMARL, which can alleviate aggregation noise via bi-level interaction.\nSpecifically, BMF introduces a dynamic group assignment module, which employs a\nVariational AutoEncoder (VAE) to learn the representations of agents,\nfacilitating their dynamic grouping over time. Furthermore, we propose a\nbi-level interaction module to model both inter- and intra-group interactions\nfor effective neighboring aggregation. Experiments across various tasks\ndemonstrate that the proposed BMF yields results superior to the\nstate-of-the-art methods. Our code will be made publicly available.", "AI": {"tldr": "The paper proposes a Bi-level Mean Field (BMF) method to address the curse of dimensionality in large-scale MARL by dynamically grouping agents and modeling bi-level interactions, outperforming existing methods.", "motivation": "Existing Mean Field (MF) methods simplify agent interactions but fail to account for individual differences, causing aggregation noise. This limits learning efficiency in large-scale MARL.", "method": "BMF uses a Variational AutoEncoder (VAE) for dynamic agent grouping and models inter- and intra-group interactions to reduce aggregation noise.", "result": "Experiments show BMF outperforms state-of-the-art methods in various tasks.", "conclusion": "BMF effectively captures agent diversity and improves learning efficiency in large-scale MARL, offering a promising solution to the curse of dimensionality."}}
{"id": "2505.06275", "pdf": "https://arxiv.org/pdf/2505.06275", "abs": "https://arxiv.org/abs/2505.06275", "authors": ["Yuzhou Zhu", "Zheng Zhang", "Ruyi Zhang", "Liang Zhou"], "title": "Attonsecond Streaking Phase Retrieval Via Deep Learning Methods", "categories": ["cs.LG", "cs.AI", "cs.CV", "physics.optics"], "comment": null, "summary": "Attosecond streaking phase retrieval is essential for resolving electron\ndynamics on sub-femtosecond time scales yet traditional algorithms rely on\niterative minimization and central momentum approximations that degrade\naccuracy for broadband pulses. In this work phase retrieval is reformulated as\na supervised computer-vision problem and four neural architectures are\nsystematically compared. A convolutional network demonstrates strong\nsensitivity to local streak edges but lacks global context; a vision\ntransformer captures long-range delay-energy correlations at the expense of\nlocal inductive bias; a hybrid CNN-ViT model unites local feature extraction\nand full-graph attention; and a capsule network further enforces spatial pose\nagreement through dynamic routing. A theoretical analysis introduces local,\nglobal and positional sensitivity measures and derives surrogate error bounds\nthat predict the strict ordering $CNN<ViT<Hybrid<Capsule$. Controlled\nexperiments on synthetic streaking spectrograms confirm this hierarchy, with\nthe capsule network achieving the highest retrieval fidelity. Looking forward,\nembedding the strong-field integral into physics-informed neural networks and\nexploring photonic hardware implementations promise pathways toward real-time\nattosecond pulse characterization under demanding experimental conditions.", "AI": {"tldr": "Neural networks outperform traditional methods in attosecond streaking phase retrieval, with capsule networks achieving the highest accuracy.", "motivation": "Traditional methods for attosecond streaking phase retrieval degrade accuracy for broadband pulses, prompting the need for more robust solutions.", "method": "Four neural architectures (CNN, ViT, Hybrid CNN-ViT, and Capsule Network) are compared for phase retrieval, analyzed theoretically, and tested on synthetic data.", "result": "Capsule networks outperform others, with a strict accuracy hierarchy: CNN < ViT < Hybrid < Capsule.", "conclusion": "Neural networks, especially capsule networks, offer superior phase retrieval, with potential for real-time applications via physics-informed networks and photonic hardware."}}
{"id": "2505.07661", "pdf": "https://arxiv.org/pdf/2505.07661", "abs": "https://arxiv.org/abs/2505.07661", "authors": ["Elad Yoshai", "Dana Yagoda-Aharoni", "Eden Dotan", "Natan T. Shaked"], "title": "Hierarchical Sparse Attention Framework for Computationally Efficient Classification of Biological Cells", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "We present SparseAttnNet, a new hierarchical attention-driven framework for\nefficient image classification that adaptively selects and processes only the\nmost informative pixels from images. Traditional convolutional neural networks\ntypically process the entire images regardless of information density, leading\nto computational inefficiency and potential focus on irrelevant features. Our\napproach leverages a dynamic selection mechanism that uses coarse attention\ndistilled by fine multi-head attention from the downstream layers of the model,\nallowing the model to identify and extract the most salient k pixels, where k\nis adaptively learned during training based on loss convergence trends. Once\nthe top-k pixels are selected, the model processes only these pixels, embedding\nthem as words in a language model to capture their semantics, followed by\nmulti-head attention to incorporate global context. For biological cell images,\nwe demonstrate that SparseAttnNet can process approximately 15% of the pixels\ninstead of the full image. Applied to cell classification tasks using white\nblood cells images from the following modalities: optical path difference (OPD)\nimages from digital holography for stain-free cells, images from\nmotion-sensitive (event) camera from stain-free cells, and brightfield\nmicroscopy images of stained cells, For all three imaging modalities,\nSparseAttnNet achieves competitive accuracy while drastically reducing\ncomputational requirements in terms of both parameters and floating-point\noperations per second, compared to traditional CNNs and Vision Transformers.\nSince the model focuses on biologically relevant regions, it also offers\nimproved explainability. The adaptive and lightweight nature of SparseAttnNet\nmakes it ideal for deployment in resource-constrained and high-throughput\nsettings, including imaging flow cytometry.", "AI": {"tldr": "SparseAttnNet is a hierarchical attention framework for efficient image classification by processing only the most informative pixels, reducing computational costs while maintaining accuracy.", "motivation": "Traditional CNNs process entire images inefficiently, focusing on irrelevant features. SparseAttnNet aims to improve efficiency and relevance by dynamically selecting salient pixels.", "method": "Uses coarse and fine multi-head attention to select top-k pixels, processes them like words in a language model, and incorporates global context.", "result": "Achieves competitive accuracy with 15% pixel processing, reducing computational demands compared to CNNs and Vision Transformers.", "conclusion": "SparseAttnNet is efficient, lightweight, and explainable, ideal for resource-constrained settings like imaging flow cytometry."}}
{"id": "2505.06696", "pdf": "https://arxiv.org/pdf/2505.06696", "abs": "https://arxiv.org/abs/2505.06696", "authors": ["Dominik Koterwa", "Maciej \u015awita\u0142a"], "title": "Enhancing BERTopic with Intermediate Layer Representations", "categories": ["cs.CL"], "comment": "Repository with code for reproduction:\n  https://github.com/dkoterwa/optimizing_bertopic", "summary": "BERTopic is a topic modeling algorithm that leverages transformer-based\nembeddings to create dense clusters, enabling the estimation of topic\nstructures and the extraction of valuable insights from a corpus of documents.\nThis approach allows users to efficiently process large-scale text data and\ngain meaningful insights into its structure. While BERTopic is a powerful tool,\nembedding preparation can vary, including extracting representations from\nintermediate model layers and applying transformations to these embeddings. In\nthis study, we evaluate 18 different embedding representations and present\nfindings based on experiments conducted on three diverse datasets. To assess\nthe algorithm's performance, we report topic coherence and topic diversity\nmetrics across all experiments. Our results demonstrate that, for each dataset,\nit is possible to find an embedding configuration that performs better than the\ndefault setting of BERTopic. Additionally, we investigate the influence of stop\nwords on different embedding configurations.", "AI": {"tldr": "BERTopic's performance varies with embedding configurations; optimal settings outperform defaults, and stop words impact results.", "motivation": "To evaluate how different embedding representations affect BERTopic's performance in topic modeling.", "method": "Tested 18 embedding configurations on three datasets, measuring topic coherence and diversity.", "result": "Found embedding settings that outperform BERTopic's defaults; stop words influence performance.", "conclusion": "Optimal embedding configurations enhance BERTopic's effectiveness, and stop words play a role in model performance."}}
{"id": "2502.12275", "pdf": "https://arxiv.org/pdf/2502.12275", "abs": "https://arxiv.org/abs/2502.12275", "authors": ["Franciszek G\u00f3rski", "Oskar Wysocki", "Marco Valentino", "Andre Freitas"], "title": "Integrating Expert Knowledge into Logical Programs via LLMs", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "This paper introduces ExKLoP, a novel framework designed to evaluate how\neffectively Large Language Models (LLMs) integrate expert knowledge into\nlogical reasoning systems. This capability is especially valuable in\nengineering, where expert knowledge-such as manufacturer-recommended\noperational ranges-can be directly embedded into automated monitoring systems.\nBy mirroring expert verification steps, tasks like range checking and\nconstraint validation help ensure system safety and reliability. Our approach\nsystematically evaluates LLM-generated logical rules, assessing both syntactic\nfluency and logical correctness in these critical validation tasks. We also\nexplore the models' capacity for self-correction via an iterative feedback loop\nbased on code execution outcomes. ExKLoP presents an extensible dataset\ncomprising 130 engineering premises, 950 prompts, and corresponding validation\npoints. It enables comprehensive benchmarking while allowing control over task\ncomplexity and scalability of experiments. We leverage the synthetic data\ncreation methodology to conduct extensive empirical evaluation on a diverse set\nof LLMs including Llama3, Gemma3, Codestral and QwenCoder. The results reveal\nthat most models generate nearly perfect syntactically correct code and exhibit\nstrong performance in translating expert knowledge into correct code. At the\nsame time, while most LLMs produce nearly flawless syntactic output, their\nability to correctly implement logical rules varies, as does their capacity for\nself-improvement. Overall, ExKLoP serves as a robust evaluation platform that\nstreamlines the selection of effective models for self-correcting systems while\nclearly delineating the types of errors encountered.", "AI": {"tldr": "ExKLoP is a framework for evaluating how LLMs integrate expert knowledge into logical reasoning, focusing on engineering applications. It assesses syntactic fluency, logical correctness, and self-correction via feedback loops, using a dataset of 130 premises and 950 prompts. Results show strong syntactic performance but varying logical accuracy and self-improvement capabilities.", "motivation": "The need to ensure LLMs effectively embed expert knowledge (e.g., operational ranges) into logical reasoning for engineering tasks like safety monitoring.", "method": "ExKLoP systematically evaluates LLM-generated rules for syntactic and logical correctness, using an iterative feedback loop based on code execution. It employs a dataset of 130 engineering premises and 950 prompts for benchmarking.", "result": "Most LLMs generate syntactically correct code but vary in logical rule implementation and self-improvement. Models like Llama3, Gemma3, Codestral, and QwenCoder show strong performance in translating expert knowledge.", "conclusion": "ExKLoP is a robust platform for selecting effective LLMs for self-correcting systems, highlighting error types and model capabilities."}}
{"id": "2505.06527", "pdf": "https://arxiv.org/pdf/2505.06527", "abs": "https://arxiv.org/abs/2505.06527", "authors": ["Jing Hu", "Kaiwei Yu", "Hongjiang Xian", "Shu Hu", "Xin Wang"], "title": "Improving Generalization of Medical Image Registration Foundation Model", "categories": ["cs.CV", "cs.AI"], "comment": "IJCNN", "summary": "Deformable registration is a fundamental task in medical image processing,\naiming to achieve precise alignment by establishing nonlinear correspondences\nbetween images. Traditional methods offer good adaptability and\ninterpretability but are limited by computational efficiency. Although deep\nlearning approaches have significantly improved registration speed and\naccuracy, they often lack flexibility and generalizability across different\ndatasets and tasks. In recent years, foundation models have emerged as a\npromising direction, leveraging large and diverse datasets to learn universal\nfeatures and transformation patterns for image registration, thus demonstrating\nstrong cross-task transferability. However, these models still face challenges\nin generalization and robustness when encountering novel anatomical structures,\nvarying imaging conditions, or unseen modalities. To address these limitations,\nthis paper incorporates Sharpness-Aware Minimization (SAM) into foundation\nmodels to enhance their generalization and robustness in medical image\nregistration. By optimizing the flatness of the loss landscape, SAM improves\nmodel stability across diverse data distributions and strengthens its ability\nto handle complex clinical scenarios. Experimental results show that foundation\nmodels integrated with SAM achieve significant improvements in cross-dataset\nregistration performance, offering new insights for the advancement of medical\nimage registration technology. Our code is available at\nhttps://github.com/Promise13/fm_sam}{https://github.com/Promise13/fm\\_sam.", "AI": {"tldr": "The paper proposes integrating Sharpness-Aware Minimization (SAM) into foundation models to enhance generalization and robustness in medical image registration, achieving improved cross-dataset performance.", "motivation": "Traditional methods lack computational efficiency, while deep learning approaches struggle with flexibility and generalizability. Foundation models show promise but face challenges in generalization and robustness.", "method": "Incorporates SAM into foundation models to optimize the flatness of the loss landscape, improving stability and handling of diverse data.", "result": "Foundation models with SAM show significant improvements in cross-dataset registration performance.", "conclusion": "The integration of SAM into foundation models advances medical image registration technology by enhancing generalization and robustness."}}
{"id": "2505.06769", "pdf": "https://arxiv.org/pdf/2505.06769", "abs": "https://arxiv.org/abs/2505.06769", "authors": ["Krishnendu Chatterjee", "Mahdi JafariRaviz", "Raimundo Saona", "Jakub Svoboda"], "title": "Value Iteration with Guessing for Markov Chains and Markov Decision Processes", "categories": ["cs.AI", "cs.CC"], "comment": "Appeared in the 31st International Conference on Tools and Algorithms\n  for the Construction and Analysis of Systems (TACAS 2025)", "summary": "Two standard models for probabilistic systems are Markov chains (MCs) and\nMarkov decision processes (MDPs). Classic objectives for such probabilistic\nmodels for control and planning problems are reachability and stochastic\nshortest path. The widely studied algorithmic approach for these problems is\nthe Value Iteration (VI) algorithm which iteratively applies local updates\ncalled Bellman updates. There are many practical approaches for VI in the\nliterature but they all require exponentially many Bellman updates for MCs in\nthe worst case. A preprocessing step is an algorithm that is discrete,\ngraph-theoretical, and requires linear space. An important open question is\nwhether, after a polynomial-time preprocessing, VI can be achieved with\nsub-exponentially many Bellman updates. In this work, we present a new approach\nfor VI based on guessing values. Our theoretical contributions are twofold.\nFirst, for MCs, we present an almost-linear-time preprocessing algorithm after\nwhich, along with guessing values, VI requires only subexponentially many\nBellman updates. Second, we present an improved analysis of the speed of\nconvergence of VI for MDPs. Finally, we present a practical algorithm for MDPs\nbased on our new approach. Experimental results show that our approach provides\na considerable improvement over existing VI-based approaches on several\nbenchmark examples from the literature.", "AI": {"tldr": "The paper introduces a new approach for Value Iteration (VI) in probabilistic systems, focusing on reducing the number of Bellman updates required after preprocessing. It provides theoretical and practical improvements for both Markov chains (MCs) and Markov decision processes (MDPs).", "motivation": "The motivation is to address the inefficiency of existing VI approaches, which require exponentially many Bellman updates in the worst case, by proposing a preprocessing step and guessing values to reduce computational complexity.", "method": "The method involves a polynomial-time preprocessing algorithm for MCs, enabling subexponentially many Bellman updates. For MDPs, an improved analysis of VI convergence speed is presented, along with a practical algorithm.", "result": "Theoretical results show almost-linear-time preprocessing for MCs and improved VI convergence for MDPs. Experiments demonstrate significant performance gains over existing VI-based methods.", "conclusion": "The work advances VI efficiency for probabilistic systems, offering both theoretical and practical improvements, validated by experimental results."}}
{"id": "2505.06279", "pdf": "https://arxiv.org/pdf/2505.06279", "abs": "https://arxiv.org/abs/2505.06279", "authors": ["Shashwat Pandey"], "title": "Interpretable Learning Dynamics in Unsupervised Reinforcement Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We present an interpretability framework for unsupervised reinforcement\nlearning (URL) agents, aimed at understanding how intrinsic motivation shapes\nattention, behavior, and representation learning. We analyze five agents DQN,\nRND, ICM, PPO, and a Transformer-RND variant trained on procedurally generated\nenvironments, using Grad-CAM, Layer-wise Relevance Propagation (LRP),\nexploration metrics, and latent space clustering. To capture how agents\nperceive and adapt over time, we introduce two metrics: attention diversity,\nwhich measures the spatial breadth of focus, and attention change rate, which\nquantifies temporal shifts in attention. Our findings show that\ncuriosity-driven agents display broader, more dynamic attention and exploratory\nbehavior than their extrinsically motivated counterparts. Among them,\nTransformerRND combines wide attention, high exploration coverage, and compact,\nstructured latent representations. Our results highlight the influence of\narchitectural inductive biases and training signals on internal agent dynamics.\nBeyond reward-centric evaluation, the proposed framework offers diagnostic\ntools to probe perception and abstraction in RL agents, enabling more\ninterpretable and generalizable behavior.", "AI": {"tldr": "The paper introduces an interpretability framework for unsupervised RL agents, analyzing how intrinsic motivation affects attention, behavior, and representation learning. It evaluates five agents using metrics like attention diversity and change rate, finding curiosity-driven agents exhibit broader, dynamic attention and exploration. Transformer-RND stands out for its structured latent representations.", "motivation": "To understand how intrinsic motivation influences RL agents' attention, behavior, and representation learning, and to provide diagnostic tools for evaluating perception and abstraction beyond reward-centric metrics.", "method": "Analyzed five RL agents (DQN, RND, ICM, PPO, Transformer-RND) using Grad-CAM, LRP, exploration metrics, and latent space clustering. Introduced attention diversity and change rate metrics to measure spatial and temporal attention shifts.", "result": "Curiosity-driven agents showed broader, dynamic attention and exploratory behavior. Transformer-RND excelled with wide attention, high exploration, and structured latent representations. Architectural biases and training signals significantly impacted agent dynamics.", "conclusion": "The framework provides interpretability tools for RL agents, revealing how intrinsic motivation shapes behavior and representation. It enables more generalizable and interpretable agent designs beyond traditional reward-based evaluation."}}
{"id": "2505.07687", "pdf": "https://arxiv.org/pdf/2505.07687", "abs": "https://arxiv.org/abs/2505.07687", "authors": ["Feng Yuan", "Yifan Gao", "Wenbin Wu", "Keqing Wu", "Xiaotong Guo", "Jie Jiang", "Xin Gao"], "title": "ABS-Mamba: SAM2-Driven Bidirectional Spiral Mamba Network for Medical Image Translation", "categories": ["eess.IV", "cs.CV"], "comment": "MICCAI 2025(under view)", "summary": "Accurate multi-modal medical image translation requires ha-rmonizing global\nanatomical semantics and local structural fidelity, a challenge complicated by\nintermodality information loss and structural distortion. We propose ABS-Mamba,\na novel architecture integrating the Segment Anything Model 2 (SAM2) for\norgan-aware semantic representation, specialized convolutional neural networks\n(CNNs) for preserving modality-specific edge and texture details, and Mamba's\nselective state-space modeling for efficient long- and short-range feature\ndependencies. Structurally, our dual-resolution framework leverages SAM2's\nimage encoder to capture organ-scale semantics from high-resolution inputs,\nwhile a parallel CNNs branch extracts fine-grained local features. The Robust\nFeature Fusion Network (RFFN) integrates these epresentations, and the\nBidirectional Mamba Residual Network (BMRN) models spatial dependencies using\nspiral scanning and bidirectional state-space dynamics. A three-stage skip\nfusion decoder enhances edge and texture fidelity. We employ Efficient Low-Rank\nAdaptation (LoRA+) fine-tuning to enable precise domain specialization while\nmaintaining the foundational capabilities of the pre-trained components.\nExtensive experimental validation on the SynthRAD2023 and BraTS2019 datasets\ndemonstrates that ABS-Mamba outperforms state-of-the-art methods, delivering\nhigh-fidelity cross-modal synthesis that preserves anatomical semantics and\nstructural details to enhance diagnostic accuracy in clinical applications. The\ncode is available at https://github.com/gatina-yone/ABS-Mamba", "AI": {"tldr": "ABS-Mamba is a novel architecture for multi-modal medical image translation, combining SAM2 for organ-aware semantics, CNNs for local details, and Mamba for feature dependencies, achieving high-fidelity results.", "motivation": "Addressing challenges of global anatomical semantics and local structural fidelity in multi-modal medical image translation, complicated by intermodality information loss and distortion.", "method": "Dual-resolution framework with SAM2 for organ-scale semantics, CNNs for local features, RFFN for fusion, BMRN for spatial dependencies, and a skip fusion decoder. Fine-tuned with LoRA+.", "result": "Outperforms state-of-the-art methods on SynthRAD2023 and BraTS2019 datasets, preserving anatomical semantics and structural details.", "conclusion": "ABS-Mamba enhances diagnostic accuracy in clinical applications, offering high-fidelity cross-modal synthesis."}}
{"id": "2505.06698", "pdf": "https://arxiv.org/pdf/2505.06698", "abs": "https://arxiv.org/abs/2505.06698", "authors": ["Zongqi Wang", "Tianle Gu", "Chen Gong", "Xin Tian", "Siqi Bao", "Yujiu Yang"], "title": "From Rankings to Insights: Evaluation Should Shift Focus from Leaderboard to Feedback", "categories": ["cs.CL"], "comment": null, "summary": "Automatic evaluation benchmarks such as MT-Bench, Arena-Hard, and Auto-Arena\nare seeing growing adoption for the evaluation of Large Language Models (LLMs).\nExisting research has primarily focused on approximating human-based model\nrankings using limited data and LLM-as-a-Judge. However, the fundamental\npremise of these studies, which attempts to replicate human rankings, is\nflawed. Specifically, these benchmarks typically offer only overall scores,\nlimiting their utility to leaderboard rankings, rather than providing feedback\nthat can guide model optimization and support model profiling. Therefore, we\nadvocate for an evaluation paradigm shift from approximating human-based model\nrankings to providing feedback with analytical value. To this end, we introduce\nFeedbacker, an evaluation framework that provides comprehensive and\nfine-grained results, thereby enabling thorough identification of a model's\nspecific strengths and weaknesses. Such feedback not only supports the targeted\noptimization of the model but also enhances the understanding of its behavior.\nFeedbacker comprises three key components: an extensible tree-based query\ntaxonomy builder, an automated query synthesis scheme, and a suite of\nvisualization and analysis tools. Furthermore, we propose a novel\nLLM-as-a-Judge method: PC2 (Pre-Comparison-derived Criteria) pointwise\nevaluation. This method derives evaluation criteria by pre-comparing the\ndifferences between several auxiliary responses, achieving the accuracy of\npairwise evaluation while maintaining the time complexity of pointwise\nevaluation. Finally, leveraging the evaluation results of 17 mainstream LLMs,\nwe demonstrate the usage of Feedbacker and highlight its effectiveness and\npotential. Our homepage project is available at\nhttps://liudan193.github.io/Feedbacker.", "AI": {"tldr": "The paper critiques current LLM evaluation benchmarks for focusing on replicating human rankings and introduces Feedbacker, a framework for fine-grained feedback to optimize and profile models.", "motivation": "Existing benchmarks lack analytical feedback for model optimization, focusing only on leaderboard rankings.", "method": "Feedbacker includes a query taxonomy builder, automated query synthesis, visualization tools, and a novel PC2 evaluation method.", "result": "Feedbacker provides comprehensive feedback on 17 LLMs, demonstrating its effectiveness.", "conclusion": "Feedbacker shifts evaluation paradigms to offer actionable insights for model improvement and understanding."}}
{"id": "2503.21633", "pdf": "https://arxiv.org/pdf/2503.21633", "abs": "https://arxiv.org/abs/2503.21633", "authors": ["David Emanuele Corrado Raphael Catania", "Alessandro Buratto", "Giovanni Perin"], "title": "Static and Repeated Cooperative Games for the Optimization of the AoI in IoT Networks", "categories": ["cs.NI", "cs.GT", "cs.MA"], "comment": "Accepted to MedComNet 2025 (Cagliari, June 2025). 6 pages, 7 figures", "summary": "Wireless sensing and the internet of things (IoT) are nowadays pervasive in\n5G and beyond networks, and they are expected to play a crucial role in 6G.\nHowever, a centralized optimization of a distributed system is not always\npossible and cost-efficient. In this paper, we analyze a setting in which two\nsensors collaboratively update a common server seeking to minimize the age of\ninformation (AoI) of the latest sample of a common physical process. We\nconsider a distributed and uncoordinated setting where each sensor lacks\ninformation about whether the other decides to update the server. This\nstrategic setting is modeled through game theory (GT) and two games are\ndefined: i) a static game of complete information with an incentive mechanism\nfor cooperation, and ii) a repeated game over a finite horizon where the static\ngame is played at each stage. We perform a mathematical analysis of the static\ngame finding three Nash Equilibria (NEs) in pure strategies and one in mixed\nstrategies. A numerical simulation of the repeated game is also presented and\nnovel and valuable insight into the setting is given thanks to the definition\nof a new metric, the price of delayed updates (PoDU), which shows that the\ndecentralized solution provides results close to the centralized optimum.", "AI": {"tldr": "The paper analyzes a distributed, uncoordinated wireless sensing system where two sensors update a server to minimize Age of Information (AoI). It uses game theory to model the scenario, defining static and repeated games, and evaluates Nash Equilibria and a new metric, PoDU, showing decentralized performance near centralized optimum.", "motivation": "Centralized optimization in distributed IoT systems is often impractical. The study explores decentralized, strategic sensor collaboration to minimize AoI, addressing lack of coordination and information sharing.", "method": "The paper models the scenario using game theory: a static game with complete information and a repeated game over a finite horizon. It analyzes Nash Equilibria and introduces the PoDU metric for evaluation.", "result": "Three pure strategy Nash Equilibria and one mixed strategy NE are identified in the static game. The repeated game simulation, using PoDU, shows decentralized performance approaches centralized optimum.", "conclusion": "Decentralized solutions can achieve near-optimal AoI minimization in uncoordinated sensor systems, validated by game-theoretic analysis and the novel PoDU metric."}}
{"id": "2505.06528", "pdf": "https://arxiv.org/pdf/2505.06528", "abs": "https://arxiv.org/abs/2505.06528", "authors": ["Mahmudul Hasan"], "title": "Unmasking Deep Fakes: Leveraging Deep Learning for Video Authenticity Detection", "categories": ["cs.CV"], "comment": null, "summary": "Deepfake videos, produced through advanced artificial intelligence methods\nnow a days, pose a new challenge to the truthfulness of the digital media. As\nDeepfake becomes more convincing day by day, detecting them requires advanced\nmethods capable of identifying subtle inconsistencies. The primary motivation\nof this paper is to recognize deepfake videos using deep learning techniques,\nspecifically by using convolutional neural networks. Deep learning excels in\npattern recognition, hence, makes it an ideal approach for detecting the\nintricate manipulations in deepfakes. In this paper, we consider using MTCNN as\na face detector and EfficientNet-B5 as encoder model to predict if a video is\ndeepfake or not. We utilize training and evaluation dataset from Kaggle DFDC.\nThe results shows that our deepfake detection model acquired 42.78% log loss,\n93.80% AUC and 86.82% F1 score on kaggle's DFDC dataset.", "AI": {"tldr": "The paper proposes a deep learning-based method using MTCNN and EfficientNet-B5 to detect deepfake videos, achieving strong performance metrics on the DFDC dataset.", "motivation": "To address the challenge of detecting increasingly convincing deepfake videos by leveraging deep learning for pattern recognition.", "method": "Uses MTCNN for face detection and EfficientNet-B5 as an encoder to classify videos as deepfake or real, trained on the Kaggle DFDC dataset.", "result": "Achieved 42.78% log loss, 93.80% AUC, and 86.82% F1 score on the DFDC dataset.", "conclusion": "The proposed deep learning approach effectively detects deepfake videos, demonstrating high accuracy and reliability."}}
{"id": "2505.06817", "pdf": "https://arxiv.org/pdf/2505.06817", "abs": "https://arxiv.org/abs/2505.06817", "authors": ["Sivasathivel Kandasamy"], "title": "Control Plane as a Tool: A Scalable Design Pattern for Agentic AI Systems", "categories": ["cs.AI"], "comment": "2 Figures and 2 Tables", "summary": "Agentic AI systems represent a new frontier in artificial intelligence, where\nagents often based on large language models(LLMs) interact with tools,\nenvironments, and other agents to accomplish tasks with a degree of autonomy.\nThese systems show promise across a range of domains, but their architectural\nunderpinnings remain immature. This paper conducts a comprehensive review of\nthe types of agents, their modes of interaction with the environment, and the\ninfrastructural and architectural challenges that emerge. We identify a gap in\nhow these systems manage tool orchestration at scale and propose a reusable\ndesign abstraction: the \"Control Plane as a Tool\" pattern. This pattern allows\ndevelopers to expose a single tool interface to an agent while encapsulating\nmodular tool routing logic behind it. We position this pattern within the\nbroader context of agent design and argue that it addresses several key\nchallenges in scaling, safety, and extensibility.", "AI": {"tldr": "The paper reviews agentic AI systems, identifies gaps in tool orchestration, and proposes a 'Control Plane as a Tool' pattern for scalable, safe, and extensible agent design.", "motivation": "Agentic AI systems, often based on LLMs, show promise but face immature architectures, especially in tool orchestration at scale.", "method": "The paper reviews agent types, interaction modes, and infrastructural challenges, then proposes the 'Control Plane as a Tool' design abstraction.", "result": "The proposed pattern addresses scaling, safety, and extensibility challenges by encapsulating tool routing logic behind a single interface.", "conclusion": "The 'Control Plane as a Tool' pattern is a reusable solution for improving agentic AI system design, particularly in tool orchestration."}}
{"id": "2505.06280", "pdf": "https://arxiv.org/pdf/2505.06280", "abs": "https://arxiv.org/abs/2505.06280", "authors": ["Gabriele Rosi", "Fabio Cermelli"], "title": "Show or Tell? A Benchmark To Evaluate Visual and Textual Prompts in Semantic Segmentation", "categories": ["cs.LG"], "comment": "Accepted to PixFoundation workshop at CVPR2025. Code:\n  https://github.com/FocoosAI/ShowOrTell", "summary": "Prompt engineering has shown remarkable success with large language models,\nyet its systematic exploration in computer vision remains limited. In semantic\nsegmentation, both textual and visual prompts offer distinct advantages:\ntextual prompts through open-vocabulary methods allow segmentation of arbitrary\ncategories, while visual reference prompts provide intuitive reference\nexamples. However, existing benchmarks evaluate these modalities in isolation,\nwithout direct comparison under identical conditions. We present Show or Tell\n(SoT), a novel benchmark specifically designed to evaluate both visual and\ntextual prompts for semantic segmentation across 14 datasets spanning 7 diverse\ndomains (common scenes, urban, food, waste, parts, tools, and land-cover). We\nevaluate 5 open-vocabulary methods and 4 visual reference prompt approaches,\nadapting the latter to handle multi-class segmentation through a\nconfidence-based mask merging strategy. Our extensive experiments reveal that\nopen-vocabulary methods excel with common concepts easily described by text but\nstruggle with complex domains like tools, while visual reference prompt methods\nachieve good average results but exhibit high variability depending on the\ninput prompt. Through comprehensive quantitative and qualitative analysis, we\nidentify the strengths and weaknesses of both prompting modalities, providing\nvaluable insights to guide future research in vision foundation models for\nsegmentation tasks.", "AI": {"tldr": "The paper introduces 'Show or Tell' (SoT), a benchmark for evaluating visual and textual prompts in semantic segmentation, comparing their performance across diverse domains.", "motivation": "Systematic exploration of prompt engineering in computer vision is limited, especially for semantic segmentation, where textual and visual prompts offer distinct but untested advantages.", "method": "SoT evaluates 5 open-vocabulary (textual) and 4 visual reference prompt methods across 14 datasets in 7 domains, using a confidence-based mask merging strategy for multi-class segmentation.", "result": "Open-vocabulary methods perform well with common concepts but struggle in complex domains, while visual reference methods show high variability based on input prompts.", "conclusion": "The study highlights strengths and weaknesses of both prompting modalities, offering insights for future research in vision foundation models for segmentation."}}
{"id": "2505.06668", "pdf": "https://arxiv.org/pdf/2505.06668", "abs": "https://arxiv.org/abs/2505.06668", "authors": ["Ziyi Wang", "Haipeng Li", "Lin Sui", "Tianhao Zhou", "Hai Jiang", "Lang Nie", "Shuaicheng Liu"], "title": "StableMotion: Repurposing Diffusion-Based Image Priors for Motion Estimation", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "We present StableMotion, a novel framework leverages knowledge (geometry and\ncontent priors) from pretrained large-scale image diffusion models to perform\nmotion estimation, solving single-image-based image rectification tasks such as\nStitched Image Rectangling (SIR) and Rolling Shutter Correction (RSC).\nSpecifically, StableMotion framework takes text-to-image Stable Diffusion (SD)\nmodels as backbone and repurposes it into an image-to-motion estimator. To\nmitigate inconsistent output produced by diffusion models, we propose Adaptive\nEnsemble Strategy (AES) that consolidates multiple outputs into a cohesive,\nhigh-fidelity result. Additionally, we present the concept of Sampling Steps\nDisaster (SSD), the counterintuitive scenario where increasing the number of\nsampling steps can lead to poorer outcomes, which enables our framework to\nachieve one-step inference. StableMotion is verified on two image rectification\ntasks and delivers state-of-the-art performance in both, as well as showing\nstrong generalizability. Supported by SSD, StableMotion offers a speedup of 200\ntimes compared to previous diffusion model-based methods.", "AI": {"tldr": "StableMotion repurposes Stable Diffusion for motion estimation in image rectification tasks, using an Adaptive Ensemble Strategy and addressing Sampling Steps Disaster for faster, high-quality results.", "motivation": "To leverage pretrained image diffusion models for motion estimation in rectification tasks like Stitched Image Rectangling and Rolling Shutter Correction, overcoming inconsistencies and inefficiencies.", "method": "Uses Stable Diffusion as a backbone, introduces Adaptive Ensemble Strategy (AES) for consistency, and identifies Sampling Steps Disaster (SSD) to enable one-step inference.", "result": "Achieves state-of-the-art performance in two tasks, with strong generalizability and a 200x speedup over previous methods.", "conclusion": "StableMotion effectively adapts diffusion models for motion estimation, offering high fidelity and efficiency in image rectification."}}
{"id": "2505.06708", "pdf": "https://arxiv.org/pdf/2505.06708", "abs": "https://arxiv.org/abs/2505.06708", "authors": ["Zihan Qiu", "Zekun Wang", "Bo Zheng", "Zeyu Huang", "Kaiyue Wen", "Songlin Yang", "Rui Men", "Le Yu", "Fei Huang", "Suozhi Huang", "Dayiheng Liu", "Jingren Zhou", "Junyang Lin"], "title": "Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free", "categories": ["cs.CL"], "comment": null, "summary": "Gating mechanisms have been widely utilized, from early models like LSTMs and\nHighway Networks to recent state space models, linear attention, and also\nsoftmax attention. Yet, existing literature rarely examines the specific\neffects of gating. In this work, we conduct comprehensive experiments to\nsystematically investigate gating-augmented softmax attention variants.\nSpecifically, we perform a comprehensive comparison over 30 variants of 15B\nMixture-of-Experts (MoE) models and 1.7B dense models trained on a 3.5 trillion\ntoken dataset. Our central finding is that a simple modification-applying a\nhead-specific sigmoid gate after the Scaled Dot-Product Attention\n(SDPA)-consistently improves performance. This modification also enhances\ntraining stability, tolerates larger learning rates, and improves scaling\nproperties. By comparing various gating positions and computational variants,\nwe attribute this effectiveness to two key factors: (1) introducing\nnon-linearity upon the low-rank mapping in the softmax attention, and (2)\napplying query-dependent sparse gating scores to modulate the SDPA output.\nNotably, we find this sparse gating mechanism mitigates 'attention sink' and\nenhances long-context extrapolation performance, and we also release related\n$\\href{https://github.com/qiuzh20/gated_attention}{codes}$ and\n$\\href{https://huggingface.co/QwQZh/gated_attention}{models}$ to facilitate\nfuture research.", "AI": {"tldr": "A study on gating mechanisms in softmax attention reveals that a simple head-specific sigmoid gate improves performance, stability, and scaling.", "motivation": "To systematically investigate the effects of gating in softmax attention, which is underexplored in existing literature.", "method": "Comprehensive experiments with 30 variants of 15B MoE models and 1.7B dense models on a 3.5T token dataset.", "result": "Head-specific sigmoid gating consistently enhances performance, stability, and long-context extrapolation.", "conclusion": "Sparse gating mitigates 'attention sink' and improves scaling, with released code and models for future research."}}
{"id": "2505.05029", "pdf": "https://arxiv.org/pdf/2505.05029", "abs": "https://arxiv.org/abs/2505.05029", "authors": ["Siyue Ren", "Wanli Fu", "Xinkun Zou", "Chen Shen", "Yi Cai", "Chen Chu", "Zhen Wang", "Shuyue Hu"], "title": "Beyond the Tragedy of the Commons: Building A Reputation System for Generative Multi-agent Systems", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The tragedy of the commons, where individual self-interest leads to\ncollectively disastrous outcomes, is a pervasive challenge in human society.\nRecent studies have demonstrated that similar phenomena can arise in generative\nmulti-agent systems (MASs). To address this challenge, this paper explores the\nuse of reputation systems as a remedy. We propose RepuNet, a dynamic,\ndual-level reputation framework that models both agent-level reputation\ndynamics and system-level network evolution. Specifically, driven by direct\ninteractions and indirect gossip, agents form reputations for both themselves\nand their peers, and decide whether to connect or disconnect other agents for\nfuture interactions. Through two distinct scenarios, we show that RepuNet\neffectively mitigates the 'tragedy of the commons', promoting and sustaining\ncooperation in generative MASs. Moreover, we find that reputation systems can\ngive rise to rich emergent behaviors in generative MASs, such as the formation\nof cooperative clusters, the social isolation of exploitative agents, and the\npreference for sharing positive gossip rather than negative ones.", "AI": {"tldr": "RepuNet, a dual-level reputation framework, mitigates the 'tragedy of the commons' in generative multi-agent systems by modeling agent and system-level reputations, fostering cooperation and emergent behaviors.", "motivation": "Address the 'tragedy of the commons' in generative multi-agent systems, where individual self-interest harms collective outcomes.", "method": "Propose RepuNet, a dynamic reputation framework combining agent-level reputation dynamics and system-level network evolution, driven by direct interactions and gossip.", "result": "RepuNet effectively promotes cooperation, forms cooperative clusters, isolates exploitative agents, and favors positive gossip sharing.", "conclusion": "Reputation systems like RepuNet can resolve collective challenges and induce emergent behaviors in generative MASs."}}
{"id": "2505.06536", "pdf": "https://arxiv.org/pdf/2505.06536", "abs": "https://arxiv.org/abs/2505.06536", "authors": ["Feng Liu", "Ziwang Fu", "Yunlong Wang", "Qijian Zheng"], "title": "TACFN: Transformer-based Adaptive Cross-modal Fusion Network for Multimodal Emotion Recognition", "categories": ["cs.CV", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2111.02172", "summary": "The fusion technique is the key to the multimodal emotion recognition task.\nRecently, cross-modal attention-based fusion methods have demonstrated high\nperformance and strong robustness. However, cross-modal attention suffers from\nredundant features and does not capture complementary features well. We find\nthat it is not necessary to use the entire information of one modality to\nreinforce the other during cross-modal interaction, and the features that can\nreinforce a modality may contain only a part of it. To this end, we design an\ninnovative Transformer-based Adaptive Cross-modal Fusion Network (TACFN).\nSpecifically, for the redundant features, we make one modality perform\nintra-modal feature selection through a self-attention mechanism, so that the\nselected features can adaptively and efficiently interact with another\nmodality. To better capture the complementary information between the\nmodalities, we obtain the fused weight vector by splicing and use the weight\nvector to achieve feature reinforcement of the modalities. We apply TCAFN to\nthe RAVDESS and IEMOCAP datasets. For fair comparison, we use the same unimodal\nrepresentations to validate the effectiveness of the proposed fusion method.\nThe experimental results show that TACFN brings a significant performance\nimprovement compared to other methods and reaches the state-of-the-art. All\ncode and models could be accessed from https://github.com/shuzihuaiyu/TACFN.", "AI": {"tldr": "The paper introduces TACFN, a Transformer-based Adaptive Cross-modal Fusion Network, to address redundant and complementary feature issues in cross-modal attention for emotion recognition.", "motivation": "Cross-modal attention methods suffer from redundant features and poor capture of complementary features, limiting their effectiveness in multimodal emotion recognition.", "method": "TACFN uses self-attention for intra-modal feature selection and a weight vector for feature reinforcement, improving cross-modal interaction.", "result": "Experiments on RAVDESS and IEMOCAP datasets show TACFN outperforms other methods, achieving state-of-the-art performance.", "conclusion": "TACFN effectively addresses feature redundancy and enhances complementary feature capture, advancing multimodal emotion recognition."}}
{"id": "2505.06856", "pdf": "https://arxiv.org/pdf/2505.06856", "abs": "https://arxiv.org/abs/2505.06856", "authors": ["Bonan Wang", "Haicheng Liao", "Chengyue Wang", "Bin Rao", "Yanchen Guan", "Guyang Yu", "Jiaxun Zhang", "Songning Lai", "Chengzhong Xu", "Zhenning Li"], "title": "Beyond Patterns: Harnessing Causal Logic for Autonomous Driving Trajectory Prediction", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Accurate trajectory prediction has long been a major challenge for autonomous\ndriving (AD). Traditional data-driven models predominantly rely on statistical\ncorrelations, often overlooking the causal relationships that govern traffic\nbehavior. In this paper, we introduce a novel trajectory prediction framework\nthat leverages causal inference to enhance predictive robustness,\ngeneralization, and accuracy. By decomposing the environment into spatial and\ntemporal components, our approach identifies and mitigates spurious\ncorrelations, uncovering genuine causal relationships. We also employ a\nprogressive fusion strategy to integrate multimodal information, simulating\nhuman-like reasoning processes and enabling real-time inference. Evaluations on\nfive real-world datasets--ApolloScape, nuScenes, NGSIM, HighD, and\nMoCAD--demonstrate our model's superiority over existing state-of-the-art\n(SOTA) methods, with improvements in key metrics such as RMSE and FDE. Our\nfindings highlight the potential of causal reasoning to transform trajectory\nprediction, paving the way for robust AD systems.", "AI": {"tldr": "A novel trajectory prediction framework for autonomous driving uses causal inference to improve robustness, generalization, and accuracy by identifying genuine causal relationships and mitigating spurious correlations.", "motivation": "Traditional data-driven models for trajectory prediction often overlook causal relationships, leading to less robust and generalizable predictions.", "method": "The framework decomposes the environment into spatial and temporal components, employs causal inference, and uses a progressive fusion strategy for multimodal information integration.", "result": "Evaluations on five datasets (ApolloScape, nuScenes, NGSIM, HighD, MoCAD) show superior performance over SOTA methods, with improvements in RMSE and FDE.", "conclusion": "Causal reasoning can significantly enhance trajectory prediction, contributing to more robust autonomous driving systems."}}
{"id": "2505.06281", "pdf": "https://arxiv.org/pdf/2505.06281", "abs": "https://arxiv.org/abs/2505.06281", "authors": ["Chunduru Rohith Kumar", "PHD Surya Shanmuk", "Prabhala Naga Srinivas", "Sri Venkatesh Lankalapalli", "Debasis Dwibedy"], "title": "A Data-Driven Probabilistic Framework for Cascading Urban Risk Analysis Using Bayesian Networks", "categories": ["cs.LG", "stat.ML"], "comment": "14 pages, 4 figures, 8 tables", "summary": "The increasing complexity of cascading risks in urban systems necessitates\nrobust, data-driven frameworks to model interdependencies across multiple\ndomains. This study presents a foundational Bayesian network-based approach for\nanalyzing cross-domain risk propagation across key urban domains, including\nair, water, electricity, agriculture, health, infrastructure, weather, and\nclimate. Directed Acyclic Graphs (DAGs) are constructed using Bayesian Belief\nNetworks (BBNs), with structure learning guided by Hill-Climbing search\noptimized through Bayesian Information Criterion (BIC) and K2 scoring. The\nframework is trained on a hybrid dataset that combines real-world urban\nindicators with synthetically generated data from Generative Adversarial\nNetworks (GANs), and is further balanced using the Synthetic Minority\nOver-sampling Technique (SMOTE). Conditional Probability Tables (CPTs) derived\nfrom the learned structures enable interpretable probabilistic reasoning and\nquantify the likelihood of cascading failures. The results identify key intra-\nand inter-domain risk factors and demonstrate the framework's utility for\nproactive urban resilience planning. This work establishes a scalable,\ninterpretable foundation for cascading risk assessment and serves as a basis\nfor future empirical research in this emerging interdisciplinary field.", "AI": {"tldr": "A Bayesian network-based framework models cascading risks in urban systems, using hybrid data and interpretable probabilistic reasoning to identify key risk factors for resilience planning.", "motivation": "Addressing the complexity of cascading risks in urban systems requires robust, data-driven methods to understand interdependencies across domains like air, water, and infrastructure.", "method": "Bayesian Belief Networks (BBNs) with Hill-Climbing search and BIC/K2 scoring are used to construct DAGs. Hybrid data (real-world and GAN-generated) is balanced with SMOTE, and CPTs enable probabilistic reasoning.", "result": "Key intra- and inter-domain risk factors are identified, showcasing the framework's utility for proactive urban resilience planning.", "conclusion": "The study provides a scalable, interpretable foundation for cascading risk assessment, paving the way for future empirical research."}}
{"id": "2505.06890", "pdf": "https://arxiv.org/pdf/2505.06890", "abs": "https://arxiv.org/abs/2505.06890", "authors": ["Kosuke Ukita", "Ye Xiaolong", "Tsuyoshi Okita"], "title": "Image Classification Using a Diffusion Model as a Pre-Training Model", "categories": ["cs.LG", "cs.CV", "eess.IV"], "comment": "10 pages, 9 figures", "summary": "In this paper, we propose a diffusion model that integrates a\nrepresentation-conditioning mechanism, where the representations derived from a\nVision Transformer (ViT) are used to condition the internal process of a\nTransformer-based diffusion model. This approach enables\nrepresentation-conditioned data generation, addressing the challenge of\nrequiring large-scale labeled datasets by leveraging self-supervised learning\non unlabeled data. We evaluate our method through a zero-shot classification\ntask for hematoma detection in brain imaging. Compared to the strong\ncontrastive learning baseline, DINOv2, our method achieves a notable\nimprovement of +6.15% in accuracy and +13.60% in F1-score, demonstrating its\neffectiveness in image classification.", "AI": {"tldr": "A diffusion model with ViT-derived representation conditioning improves zero-shot classification for hematoma detection, outperforming DINOv2.", "motivation": "Addresses the challenge of large-scale labeled datasets by leveraging self-supervised learning on unlabeled data.", "method": "Integrates a representation-conditioning mechanism using ViT-derived representations in a Transformer-based diffusion model.", "result": "Achieves +6.15% accuracy and +13.60% F1-score improvement over DINOv2 in hematoma detection.", "conclusion": "The method is effective for image classification, particularly in zero-shot tasks."}}
{"id": "2505.06782", "pdf": "https://arxiv.org/pdf/2505.06782", "abs": "https://arxiv.org/abs/2505.06782", "authors": ["Damian Curran", "Brian Chapman", "Mike Conway"], "title": "Utilizing LLMs to Investigate the Disputed Role of Evidence in Electronic Cigarette Health Policy Formation in Australia and the UK", "categories": ["cs.CL", "cs.SI"], "comment": null, "summary": "Australia and the UK have developed contrasting approaches to the regulation\nof electronic cigarettes, with - broadly speaking - Australia adopting a\nrelatively restrictive approach and the UK adopting a more permissive approach.\nNotably, these divergent policies were developed from the same broad evidence\nbase. In this paper, to investigate differences in how the two jurisdictions\nmanage and present evidence, we developed and evaluated a Large Language\nModel-based sentence classifier to perform automated analyses of electronic\ncigarette-related policy documents drawn from official Australian and UK\nlegislative processes (109 documents in total). Specifically, we utilized GPT-4\nto automatically classify sentences based on whether they contained claims that\ne-cigarettes were broadly helpful or harmful for public health. Our LLM-based\nclassifier achieved an F-score of 0.9. Further, when applying the classifier to\nour entire sentence-level corpus, we found that Australian legislative\ndocuments show a much higher proportion of harmful statements, and a lower\nproportion of helpful statements compared to the expected values, with the\nopposite holding for the UK. In conclusion, this work utilized an LLM-based\napproach to provide evidence to support the contention that - drawing on the\nsame evidence base - Australian ENDS-related policy documents emphasize the\nharms associated with ENDS products and UK policy documents emphasize the\nbenefits. Further, our approach provides a starting point for using LLM-based\nmethods to investigate the complex relationship between evidence and health\npolicy formation.", "AI": {"tldr": "The paper compares Australia's restrictive and the UK's permissive e-cigarette policies using a GPT-4-based classifier to analyze policy documents, finding Australia emphasizes harms while the UK highlights benefits.", "motivation": "To understand how Australia and the UK, despite using the same evidence, developed contrasting e-cigarette policies.", "method": "Developed a GPT-4-based sentence classifier to analyze 109 policy documents, classifying sentences as helpful or harmful to public health.", "result": "The classifier achieved an F-score of 0.9. Australian documents had more harmful statements, while UK documents had more helpful ones.", "conclusion": "The study shows how LLMs can reveal policy biases in evidence interpretation, offering a tool for analyzing health policy formation."}}
{"id": "2505.06537", "pdf": "https://arxiv.org/pdf/2505.06537", "abs": "https://arxiv.org/abs/2505.06537", "authors": ["Xianghao Kong", "Qiaosong Qi", "Yuanbin Wang", "Anyi Rao", "Biaolong Chen", "Aixi Zhang", "Si Liu", "Hao Jiang"], "title": "ProFashion: Prototype-guided Fashion Video Generation with Multiple Reference Images", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Fashion video generation aims to synthesize temporally consistent videos from\nreference images of a designated character. Despite significant progress,\nexisting diffusion-based methods only support a single reference image as\ninput, severely limiting their capability to generate view-consistent fashion\nvideos, especially when there are different patterns on the clothes from\ndifferent perspectives. Moreover, the widely adopted motion module does not\nsufficiently model human body movement, leading to sub-optimal spatiotemporal\nconsistency. To address these issues, we propose ProFashion, a fashion video\ngeneration framework leveraging multiple reference images to achieve improved\nview consistency and temporal coherency. To effectively leverage features from\nmultiple reference images while maintaining a reasonable computational cost, we\ndevise a Pose-aware Prototype Aggregator, which selects and aggregates global\nand fine-grained reference features according to pose information to form\nframe-wise prototypes, which serve as guidance in the denoising process. To\nfurther enhance motion consistency, we introduce a Flow-enhanced Prototype\nInstantiator, which exploits the human keypoint motion flow to guide an extra\nspatiotemporal attention process in the denoiser. To demonstrate the\neffectiveness of ProFashion, we extensively evaluate our method on the\nMRFashion-7K dataset we collected from the Internet. ProFashion also\noutperforms previous methods on the UBC Fashion dataset.", "AI": {"tldr": "ProFashion is a framework for fashion video generation using multiple reference images to improve view consistency and motion modeling, outperforming existing methods.", "motivation": "Existing methods are limited to single reference images and insufficient motion modeling, hindering view consistency and temporal coherency in fashion videos.", "method": "ProFashion uses a Pose-aware Prototype Aggregator for feature aggregation and a Flow-enhanced Prototype Instantiator for motion guidance, leveraging multiple references.", "result": "ProFashion outperforms previous methods on the MRFashion-7K and UBC Fashion datasets.", "conclusion": "ProFashion effectively addresses limitations in fashion video generation by leveraging multiple references and enhanced motion modeling."}}
{"id": "2505.06897", "pdf": "https://arxiv.org/pdf/2505.06897", "abs": "https://arxiv.org/abs/2505.06897", "authors": ["Jinhao Jiang", "Changlin Chen", "Shile Feng", "Wanru Geng", "Zesheng Zhou", "Ni Wang", "Shuai Li", "Feng-Qi Cui", "Erbao Dong"], "title": "Embodied Intelligence: The Key to Unblocking Generalized Artificial Intelligence", "categories": ["cs.AI"], "comment": "19pages,7 figures,3 tables", "summary": "The ultimate goal of artificial intelligence (AI) is to achieve Artificial\nGeneral Intelligence (AGI). Embodied Artificial Intelligence (EAI), which\ninvolves intelligent systems with physical presence and real-time interaction\nwith the environment, has emerged as a key research direction in pursuit of\nAGI. While advancements in deep learning, reinforcement learning, large-scale\nlanguage models, and multimodal technologies have significantly contributed to\nthe progress of EAI, most existing reviews focus on specific technologies or\napplications. A systematic overview, particularly one that explores the direct\nconnection between EAI and AGI, remains scarce. This paper examines EAI as a\nfoundational approach to AGI, systematically analyzing its four core modules:\nperception, intelligent decision-making, action, and feedback. We provide a\ndetailed discussion of how each module contributes to the six core principles\nof AGI. Additionally, we discuss future trends, challenges, and research\ndirections in EAI, emphasizing its potential as a cornerstone for AGI\ndevelopment. Our findings suggest that EAI's integration of dynamic learning\nand real-world interaction is essential for bridging the gap between narrow AI\nand AGI.", "AI": {"tldr": "This paper explores Embodied Artificial Intelligence (EAI) as a foundational approach to achieving Artificial General Intelligence (AGI), analyzing its core modules and their contributions to AGI principles.", "motivation": "The lack of systematic reviews connecting EAI to AGI motivates this study, aiming to highlight EAI's role in bridging narrow AI and AGI.", "method": "The paper systematically analyzes EAI's four core modules (perception, decision-making, action, feedback) and their alignment with AGI principles.", "result": "Findings suggest EAI's dynamic learning and real-world interaction are crucial for advancing AGI.", "conclusion": "EAI is a promising cornerstone for AGI development, with future research needed to address challenges and trends."}}
{"id": "2505.06282", "pdf": "https://arxiv.org/pdf/2505.06282", "abs": "https://arxiv.org/abs/2505.06282", "authors": ["Zixu Wang", "Bingbing Xu", "Yige Yuan", "Huawei Shen", "Xueqi Cheng"], "title": "InfoNCE is a Free Lunch for Semantically guided Graph Contrastive Learning", "categories": ["cs.LG"], "comment": "10 pages, 5 figures, Accepted by SIGIR2025", "summary": "As an important graph pre-training method, Graph Contrastive Learning (GCL)\ncontinues to play a crucial role in the ongoing surge of research on graph\nfoundation models or LLM as enhancer for graphs. Traditional GCL optimizes\nInfoNCE by using augmentations to define self-supervised tasks, treating\naugmented pairs as positive samples and others as negative. However, this leads\nto semantically similar pairs being classified as negative, causing significant\nsampling bias and limiting performance. In this paper, we argue that GCL is\nessentially a Positive-Unlabeled (PU) learning problem, where the definition of\nself-supervised tasks should be semantically guided, i.e., augmented samples\nwith similar semantics are considered positive, while others, with unknown\nsemantics, are treated as unlabeled. From this perspective, the key lies in how\nto extract semantic information. To achieve this, we propose IFL-GCL, using\nInfoNCE as a \"free lunch\" to extract semantic information. Specifically, We\nfirst prove that under InfoNCE, the representation similarity of node pairs\naligns with the probability that the corresponding contrastive sample is\npositive. Then we redefine the maximum likelihood objective based on the\ncorrected samples, leading to a new InfoNCE loss function. Extensive\nexperiments on both the graph pretraining framework and LLM as an enhancer show\nsignificantly improvements of IFL-GCL in both IID and OOD scenarios, achieving\nup to a 9.05% improvement, validating the effectiveness of semantically guided.\nCode for IFL-GCL is publicly available at:\nhttps://github.com/Camel-Prince/IFL-GCL.", "AI": {"tldr": "The paper introduces IFL-GCL, a method addressing sampling bias in Graph Contrastive Learning (GCL) by treating it as a Positive-Unlabeled (PU) problem and using InfoNCE to extract semantic information, achieving significant performance improvements.", "motivation": "Traditional GCL methods classify semantically similar pairs as negative due to augmentation-based sampling, leading to bias and performance limitations. The paper redefines GCL as a PU problem to address this.", "method": "Proposes IFL-GCL, leveraging InfoNCE to align representation similarity with positive sample probability and redefining the maximum likelihood objective for corrected samples.", "result": "IFL-GCL shows up to 9.05% improvement in both IID and OOD scenarios, validating its effectiveness.", "conclusion": "Semantically guided GCL via IFL-GCL significantly enhances performance, with publicly available code for implementation."}}
{"id": "2505.06905", "pdf": "https://arxiv.org/pdf/2505.06905", "abs": "https://arxiv.org/abs/2505.06905", "authors": ["Jian Song", "Hongruixuan Chen", "Naoto Yokoya"], "title": "Enhancing Monocular Height Estimation via Sparse LiDAR-Guided Correction", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Monocular height estimation (MHE) from very-high-resolution (VHR) remote\nsensing imagery via deep learning is notoriously challenging due to the lack of\nsufficient structural information. Conventional digital elevation models\n(DEMs), typically derived from airborne LiDAR or multi-view stereo, remain\ncostly and geographically limited. Recently, models trained on synthetic data\nand refined through domain adaptation have shown remarkable performance in MHE,\nyet it remains unclear how these models make predictions or how reliable they\ntruly are. In this paper, we investigate a state-of-the-art MHE model trained\npurely on synthetic data to explore where the model looks when making height\npredictions. Through systematic analyses, we find that the model relies heavily\non shadow cues, a factor that can lead to overestimation or underestimation of\nheights when shadows deviate from expected norms. Furthermore, the inherent\ndifficulty of evaluating regression tasks with the human eye underscores\nadditional limitations of purely synthetic training. To address these issues,\nwe propose a novel correction pipeline that integrates sparse, imperfect global\nLiDAR measurements (ICESat-2) with deep-learning outputs to improve local\naccuracy and achieve spatially consistent corrections. Our method comprises two\nstages: pre-processing raw ICESat-2 data, followed by a random forest-based\napproach to densely refine height estimates. Experiments in three\nrepresentative urban regions -- Saint-Omer, Tokyo, and Sao Paulo -- reveal\nsubstantial error reductions, with mean absolute error (MAE) decreased by\n22.8\\%, 6.9\\%, and 4.9\\%, respectively. These findings highlight the critical\nrole of shadow awareness in synthetic data-driven models and demonstrate how\nfusing imperfect real-world LiDAR data can bolster the robustness of MHE,\npaving the way for more reliable and scalable 3D mapping solutions.", "AI": {"tldr": "The paper explores monocular height estimation (MHE) from remote sensing imagery, revealing reliance on shadow cues in synthetic-trained models and proposing a correction pipeline using sparse LiDAR data to improve accuracy.", "motivation": "Address the unreliability of synthetic-trained MHE models, which depend heavily on shadow cues, and the high cost of conventional DEMs.", "method": "Propose a two-stage pipeline: pre-processing ICESat-2 LiDAR data and refining height estimates using a random forest approach.", "result": "Experiments show error reductions (MAE) of 22.8%, 6.9%, and 4.9% in three urban regions.", "conclusion": "Integrating sparse real-world LiDAR data with deep learning outputs enhances MHE robustness, enabling more reliable 3D mapping."}}
{"id": "2505.06862", "pdf": "https://arxiv.org/pdf/2505.06862", "abs": "https://arxiv.org/abs/2505.06862", "authors": ["Lhuqita Fazry"], "title": "A Split-then-Join Approach to Abstractive Summarization for Very Long Documents in a Low Resource Setting", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "$\\texttt{BIGBIRD-PEGASUS}$ model achieves $\\textit{state-of-the-art}$ on\nabstractive text summarization for long documents. However it's capacity still\nlimited to maximum of $4,096$ tokens, thus caused performance degradation on\nsummarization for very long documents. Common method to deal with the issue is\nto truncate the documents. In this reasearch, we'll use different approach.\nWe'll use the pretrained $\\texttt{BIGBIRD-PEGASUS}$ model by fine tuned the\nmodel on other domain dataset. First, we filter out all documents which length\nless than $20,000$ tokens to focus on very long documents. To prevent domain\nshifting problem and overfitting on transfer learning due to small dataset, we\naugment the dataset by splitting document-summary training pair into parts, to\nfit the document into $4,096$ tokens. Source code available on\n$\\href{https://github.com/lhfazry/SPIN-summ}{https://github.com/lhfazry/SPIN-summ}$.", "AI": {"tldr": "The paper addresses the limitation of the BIGBIRD-PEGASUS model in summarizing very long documents by fine-tuning it on a domain-specific dataset and augmenting the data to fit the model's token limit.", "motivation": "The BIGBIRD-PEGASUS model's token limit of 4,096 causes performance degradation for very long documents, and truncation is a common but suboptimal solution.", "method": "Fine-tune the pretrained BIGBIRD-PEGASUS model on a domain-specific dataset, filter documents under 20,000 tokens, and augment the dataset by splitting document-summary pairs to fit the token limit.", "result": "The approach aims to improve summarization performance for very long documents without truncation.", "conclusion": "The proposed method offers a novel way to handle very long documents by leveraging data augmentation and fine-tuning, with source code available for reproducibility."}}
{"id": "2505.06543", "pdf": "https://arxiv.org/pdf/2505.06543", "abs": "https://arxiv.org/abs/2505.06543", "authors": ["Shuhan Zhuang", "Mengqi Huang", "Fengyi Fu", "Nan Chen", "Bohan Lei", "Zhendong Mao"], "title": "HDGlyph: A Hierarchical Disentangled Glyph-Based Framework for Long-Tail Text Rendering in Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Visual text rendering, which aims to accurately integrate specified textual\ncontent within generated images, is critical for various applications such as\ncommercial design. Despite recent advances, current methods struggle with\nlong-tail text cases, particularly when handling unseen or small-sized text. In\nthis work, we propose a novel Hierarchical Disentangled Glyph-Based framework\n(HDGlyph) that hierarchically decouples text generation from non-text visual\nsynthesis, enabling joint optimization of both common and long-tail text\nrendering. At the training stage, HDGlyph disentangles pixel-level\nrepresentations via the Multi-Linguistic GlyphNet and the Glyph-Aware\nPerceptual Loss, ensuring robust rendering even for unseen characters. At\ninference time, HDGlyph applies Noise-Disentangled Classifier-Free Guidance and\nLatent-Disentangled Two-Stage Rendering (LD-TSR) scheme, which refines both\nbackground and small-sized text. Extensive evaluations show our model\nconsistently outperforms others, with 5.08% and 11.7% accuracy gains in English\nand Chinese text rendering while maintaining high image quality. It also excels\nin long-tail scenarios with strong accuracy and visual performance.", "AI": {"tldr": "HDGlyph is a novel framework for visual text rendering that hierarchically decouples text generation from non-text synthesis, improving accuracy for both common and long-tail text cases.", "motivation": "Current methods struggle with long-tail text cases, especially unseen or small-sized text, limiting their practical applications.", "method": "HDGlyph uses a Hierarchical Disentangled Glyph-Based framework with Multi-Linguistic GlyphNet and Glyph-Aware Perceptual Loss for training, and Noise-Disentangled Classifier-Free Guidance with Latent-Disentangled Two-Stage Rendering for inference.", "result": "The model achieves 5.08% and 11.7% accuracy gains in English and Chinese text rendering, excelling in long-tail scenarios while maintaining image quality.", "conclusion": "HDGlyph significantly improves text rendering accuracy and visual performance, especially for challenging cases."}}
{"id": "2505.06907", "pdf": "https://arxiv.org/pdf/2505.06907", "abs": "https://arxiv.org/abs/2505.06907", "authors": ["Yu Qiao", "Huy Q. Le", "Avi Deb Raha", "Phuong-Nam Tran", "Apurba Adhikary", "Mengchun Zhang", "Loc X. Nguyen", "Eui-Nam Huh", "Dusit Niyato", "Choong Seon Hong"], "title": "Towards Artificial General or Personalized Intelligence? A Survey on Foundation Models for Personalized Federated Intelligence", "categories": ["cs.AI", "cs.CV", "cs.NE"], "comment": "On going work", "summary": "The rise of large language models (LLMs), such as ChatGPT, DeepSeek, and\nGrok-3, has reshaped the artificial intelligence landscape. As prominent\nexamples of foundational models (FMs) built on LLMs, these models exhibit\nremarkable capabilities in generating human-like content, bringing us closer to\nachieving artificial general intelligence (AGI). However, their large-scale\nnature, sensitivity to privacy concerns, and substantial computational demands\npresent significant challenges to personalized customization for end users. To\nbridge this gap, this paper presents the vision of artificial personalized\nintelligence (API), focusing on adapting these powerful models to meet the\nspecific needs and preferences of users while maintaining privacy and\nefficiency. Specifically, this paper proposes personalized federated\nintelligence (PFI), which integrates the privacy-preserving advantages of\nfederated learning (FL) with the zero-shot generalization capabilities of FMs,\nenabling personalized, efficient, and privacy-protective deployment at the\nedge. We first review recent advances in both FL and FMs, and discuss the\npotential of leveraging FMs to enhance federated systems. We then present the\nkey motivations behind realizing PFI and explore promising opportunities in\nthis space, including efficient PFI, trustworthy PFI, and PFI empowered by\nretrieval-augmented generation (RAG). Finally, we outline key challenges and\nfuture research directions for deploying FM-powered FL systems at the edge with\nimproved personalization, computational efficiency, and privacy guarantees.\nOverall, this survey aims to lay the groundwork for the development of API as a\ncomplement to AGI, with a particular focus on PFI as a key enabling technique.", "AI": {"tldr": "The paper introduces Artificial Personalized Intelligence (API) to adapt large language models (LLMs) for user-specific needs while addressing privacy and efficiency. It proposes Personalized Federated Intelligence (PFI), combining federated learning (FL) and foundational models (FMs) for edge deployment.", "motivation": "To address challenges like privacy concerns and computational demands of LLMs, enabling personalized AI while maintaining efficiency and privacy.", "method": "Proposes PFI, integrating FL's privacy benefits with FMs' generalization, and explores efficient, trustworthy, and RAG-empowered PFI.", "result": "Identifies opportunities and challenges for deploying FM-powered FL systems at the edge, focusing on personalization, efficiency, and privacy.", "conclusion": "PFI is a key technique for API development, complementing AGI, with future research needed for practical deployment."}}
{"id": "2505.06283", "pdf": "https://arxiv.org/pdf/2505.06283", "abs": "https://arxiv.org/abs/2505.06283", "authors": ["Limin Li", "Kuo Yang", "Wenjie Du", "Pengkun Wang", "Zhengyang Zhou", "Yang Wang"], "title": "Soft causal learning for generalized molecule property prediction: An environment perspective", "categories": ["cs.LG", "q-bio.QM", "stat.ML", "I.2.4"], "comment": "23 pages, 7 figures, 3 tables", "summary": "Learning on molecule graphs has become an increasingly important topic in AI\nfor science, which takes full advantage of AI to facilitate scientific\ndiscovery. Existing solutions on modeling molecules utilize Graph Neural\nNetworks (GNNs) to achieve representations but they mostly fail to adapt models\nto out-of-distribution (OOD) samples. Although recent advances on OOD-oriented\ngraph learning have discovered the invariant rationale on graphs, they still\nignore three important issues, i.e., 1) the expanding atom patterns regarding\nenvironments on graphs lead to failures of invariant rationale based models, 2)\nthe associations between discovered molecular subgraphs and corresponding\nproperties are complex where causal substructures cannot fully interpret the\nlabels. 3) the interactions between environments and invariances can influence\nwith each other thus are challenging to be modeled. To this end, we propose a\nsoft causal learning framework, to tackle the unresolved OOD challenge in\nmolecular science, from the perspective of fully modeling the molecule\nenvironments and bypassing the invariant subgraphs. Specifically, we first\nincorporate chemistry theories into our graph growth generator to imitate\nexpaned environments, and then devise an GIB-based objective to disentangle\nenvironment from whole graphs and finally introduce a cross-attention based\nsoft causal interaction, which allows dynamic interactions between environments\nand invariances. We perform experiments on seven datasets by imitating\ndifferent kinds of OOD generalization scenarios. Extensive comparison, ablation\nexperiments as well as visualized case studies demonstrate well generalization\nability of our proposal.", "AI": {"tldr": "A soft causal learning framework is proposed to address OOD challenges in molecular science by modeling molecule environments and bypassing invariant subgraphs.", "motivation": "Existing GNN-based models fail to adapt to OOD samples and ignore key issues like expanding atom patterns, complex associations, and environment-invariance interactions.", "method": "Incorporates chemistry theories into a graph growth generator, uses a GIB-based objective to disentangle environments, and introduces cross-attention for dynamic interactions.", "result": "Experiments on seven datasets show superior generalization in OOD scenarios, supported by comparisons and case studies.", "conclusion": "The proposed framework effectively addresses OOD challenges in molecular science by modeling environments and enabling dynamic interactions."}}
{"id": "2505.07219", "pdf": "https://arxiv.org/pdf/2505.07219", "abs": "https://arxiv.org/abs/2505.07219", "authors": ["Hongda Qin", "Xiao Lu", "Zhiyong Wei", "Yihong Cao", "Kailun Yang", "Ningjiang Chen"], "title": "Language-Driven Dual Style Mixing for Single-Domain Generalized Object Detection", "categories": ["cs.CV", "cs.RO", "eess.IV"], "comment": "The source code and pre-trained models will be publicly available at\n  https://github.com/qinhongda8/LDDS", "summary": "Generalizing an object detector trained on a single domain to multiple unseen\ndomains is a challenging task. Existing methods typically introduce image or\nfeature augmentation to diversify the source domain to raise the robustness of\nthe detector. Vision-Language Model (VLM)-based augmentation techniques have\nbeen proven to be effective, but they require that the detector's backbone has\nthe same structure as the image encoder of VLM, limiting the detector framework\nselection. To address this problem, we propose Language-Driven Dual Style\nMixing (LDDS) for single-domain generalization, which diversifies the source\ndomain by fully utilizing the semantic information of the VLM. Specifically, we\nfirst construct prompts to transfer style semantics embedded in the VLM to an\nimage translation network. This facilitates the generation of style diversified\nimages with explicit semantic information. Then, we propose image-level style\nmixing between the diversified images and source domain images. This\neffectively mines the semantic information for image augmentation without\nrelying on specific augmentation selections. Finally, we propose feature-level\nstyle mixing in a double-pipeline manner, allowing feature augmentation to be\nmodel-agnostic and can work seamlessly with the mainstream detector frameworks,\nincluding the one-stage, two-stage, and transformer-based detectors. Extensive\nexperiments demonstrate the effectiveness of our approach across various\nbenchmark datasets, including real to cartoon and normal to adverse weather\ntasks. The source code and pre-trained models will be publicly available at\nhttps://github.com/qinhongda8/LDDS.", "AI": {"tldr": "The paper proposes Language-Driven Dual Style Mixing (LDDS) for single-domain generalization, leveraging VLM semantics for image and feature augmentation without dependency on specific detector frameworks.", "motivation": "Existing VLM-based augmentation methods limit detector framework selection by requiring backbone alignment with VLM encoders. LDDS aims to overcome this limitation.", "method": "LDDS uses VLM semantic prompts for style transfer, image-level style mixing, and feature-level style mixing in a double-pipeline manner for model-agnostic augmentation.", "result": "LDDS demonstrates effectiveness across diverse tasks (e.g., real to cartoon, normal to adverse weather) and works with various detector frameworks.", "conclusion": "LDDS provides a flexible and effective solution for single-domain generalization, with publicly available code and models."}}
{"id": "2505.06889", "pdf": "https://arxiv.org/pdf/2505.06889", "abs": "https://arxiv.org/abs/2505.06889", "authors": ["Mihyeon Kim", "Juhyoung Park", "Youngbin Kim"], "title": "IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to EMNLP 2024 Main", "summary": "Pre-trained Language Models (PLMs) have achieved remarkable performance on\ndiverse NLP tasks through pre-training and fine-tuning. However, fine-tuning\nthe model with a large number of parameters on limited downstream datasets\noften leads to vulnerability to adversarial attacks, causing overfitting of the\nmodel on standard datasets.\n  To address these issues, we propose IM-BERT from the perspective of a dynamic\nsystem by conceptualizing a layer of BERT as a solution of Ordinary\nDifferential Equations (ODEs). Under the situation of initial value\nperturbation, we analyze the numerical stability of two main numerical ODE\nsolvers: the explicit and implicit Euler approaches.\n  Based on these analyses, we introduce a numerically robust IM-connection\nincorporating BERT's layers. This strategy enhances the robustness of PLMs\nagainst adversarial attacks, even in low-resource scenarios, without\nintroducing additional parameters or adversarial training strategies.\n  Experimental results on the adversarial GLUE (AdvGLUE) dataset validate the\nrobustness of IM-BERT under various conditions. Compared to the original BERT,\nIM-BERT exhibits a performance improvement of approximately 8.3\\%p on the\nAdvGLUE dataset. Furthermore, in low-resource scenarios, IM-BERT outperforms\nBERT by achieving 5.9\\%p higher accuracy.", "AI": {"tldr": "IM-BERT enhances BERT's robustness against adversarial attacks by modeling layers as ODE solutions, improving performance without extra parameters.", "motivation": "Fine-tuning PLMs like BERT on limited datasets leads to vulnerability to adversarial attacks and overfitting.", "method": "Conceptualizes BERT layers as ODE solutions, analyzes numerical stability, and introduces a robust IM-connection.", "result": "IM-BERT improves performance by 8.3% on AdvGLUE and 5.9% in low-resource scenarios.", "conclusion": "IM-BERT effectively boosts robustness without additional parameters or adversarial training."}}
{"id": "2505.06557", "pdf": "https://arxiv.org/pdf/2505.06557", "abs": "https://arxiv.org/abs/2505.06557", "authors": ["Lu Dong", "Haiyu Zhang", "Hongjie Zhang", "Yifei Huang", "Zhen-Hua Ling", "Yu Qiao", "Limin Wang", "Yali Wang"], "title": "Weakly Supervised Temporal Sentence Grounding via Positive Sample Mining", "categories": ["cs.CV"], "comment": "TCSVT 2025, doi at https://ieeexplore.ieee.org/document/10970001", "summary": "The task of weakly supervised temporal sentence grounding (WSTSG) aims to\ndetect temporal intervals corresponding to a language description from\nuntrimmed videos with only video-level video-language correspondence. For an\nanchor sample, most existing approaches generate negative samples either from\nother videos or within the same video for contrastive learning. However, some\ntraining samples are highly similar to the anchor sample, directly regarding\nthem as negative samples leads to difficulties for optimization and ignores the\ncorrelations between these similar samples and the anchor sample. To address\nthis, we propose Positive Sample Mining (PSM), a novel framework that mines\npositive samples from the training set to provide more discriminative\nsupervision. Specifically, for a given anchor sample, we partition the\nremaining training set into semantically similar and dissimilar subsets based\non the similarity of their text queries. To effectively leverage these\ncorrelations, we introduce a PSM-guided contrastive loss to ensure that the\nanchor proposal is closer to similar samples and further from dissimilar ones.\nAdditionally, we design a PSM-guided rank loss to ensure that similar samples\nare closer to the anchor proposal than to the negative intra-video proposal,\naiming to distinguish the anchor proposal and the negative intra-video\nproposal. Experiments on the WSTSG and grounded VideoQA tasks demonstrate the\neffectiveness and superiority of our method.", "AI": {"tldr": "The paper introduces Positive Sample Mining (PSM) to improve weakly supervised temporal sentence grounding by mining positive samples for better contrastive learning.", "motivation": "Existing methods treat similar samples as negatives, causing optimization difficulties and ignoring correlations.", "method": "PSM partitions training data into similar/dissimilar subsets and uses PSM-guided contrastive and rank losses for better supervision.", "result": "Experiments show PSM's effectiveness in WSTSG and grounded VideoQA tasks.", "conclusion": "PSM provides discriminative supervision and outperforms existing approaches."}}
{"id": "2505.06949", "pdf": "https://arxiv.org/pdf/2505.06949", "abs": "https://arxiv.org/abs/2505.06949", "authors": ["Sumyyah Toonsi", "Paul Schofield", "Robert Hoehndorf"], "title": "Causal knowledge graph analysis identifies adverse drug effects", "categories": ["cs.AI", "q-bio.BM"], "comment": null, "summary": "Knowledge graphs and structural causal models have each proven valuable for\norganizing biomedical knowledge and estimating causal effects, but remain\nlargely disconnected: knowledge graphs encode qualitative relationships\nfocusing on facts and deductive reasoning without formal probabilistic\nsemantics, while causal models lack integration with background knowledge in\nknowledge graphs and have no access to the deductive reasoning capabilities\nthat knowledge graphs provide. To bridge this gap, we introduce a novel\nformulation of Causal Knowledge Graphs (CKGs) which extend knowledge graphs\nwith formal causal semantics, preserving their deductive capabilities while\nenabling principled causal inference. CKGs support deconfounding via explicitly\nmarked causal edges and facilitate hypothesis formulation aligned with both\nencoded and entailed background knowledge. We constructed a Drug-Disease CKG\n(DD-CKG) integrating disease progression pathways, drug indications,\nside-effects, and hierarchical disease classification to enable automated\nlarge-scale mediation analysis. Applied to UK Biobank and MIMIC-IV cohorts, we\ntested whether drugs mediate effects between indications and downstream disease\nprogression, adjusting for confounders inferred from the DD-CKG. Our approach\nsuccessfully reproduced known adverse drug reactions with high precision while\nidentifying previously undocumented significant candidate adverse effects.\nFurther validation through side effect similarity analysis demonstrated that\ncombining our predicted drug effects with established databases significantly\nimproves the prediction of shared drug indications, supporting the clinical\nrelevance of our novel findings. These results demonstrate that our methodology\nprovides a generalizable, knowledge-driven framework for scalable causal\ninference.", "AI": {"tldr": "The paper introduces Causal Knowledge Graphs (CKGs) to bridge the gap between knowledge graphs and causal models, enabling both deductive reasoning and causal inference. Applied to biomedical data, it successfully identifies known and novel drug effects.", "motivation": "To integrate the qualitative strengths of knowledge graphs with the probabilistic semantics of causal models for improved biomedical causal inference.", "method": "Developed CKGs with formal causal semantics, applied to a Drug-Disease CKG (DD-CKG) for mediation analysis using UK Biobank and MIMIC-IV data.", "result": "Reproduced known adverse drug reactions and identified novel candidate effects, validated by improved prediction of shared drug indications.", "conclusion": "CKGs provide a scalable, knowledge-driven framework for causal inference, validated by clinical relevance."}}
{"id": "2505.06284", "pdf": "https://arxiv.org/pdf/2505.06284", "abs": "https://arxiv.org/abs/2505.06284", "authors": ["Zhiqiang Wang", "Ruoxi Cheng"], "title": "DMRL: Data- and Model-aware Reward Learning for Data Extraction", "categories": ["cs.LG", "cs.CR"], "comment": "Data- and Model-aware Reward Learning for Data Extraction. arXiv\n  admin note: substantial text overlap with arXiv:2503.18991", "summary": "Large language models (LLMs) are inherently vulnerable to unintended privacy\nbreaches. Consequently, systematic red-teaming research is essential for\ndeveloping robust defense mechanisms. However, current data extraction methods\nsuffer from several limitations: (1) rely on dataset duplicates (addressable\nvia deduplication), (2) depend on prompt engineering (now countered by\ndetection and defense), and (3) rely on random-search adversarial generation.\nTo address these challenges, we propose DMRL, a Data- and Model-aware Reward\nLearning approach for data extraction. This technique leverages inverse\nreinforcement learning to extract sensitive data from LLMs. Our method consists\nof two main components: (1) constructing an introspective reasoning dataset\nthat captures leakage mindsets to guide model behavior, and (2) training reward\nmodels with Group Relative Policy Optimization (GRPO), dynamically tuning\noptimization based on task difficulty at both the data and model levels.\nComprehensive experiments across various LLMs demonstrate that DMRL outperforms\nall baseline methods in data extraction performance.", "AI": {"tldr": "DMRL, a Data- and Model-aware Reward Learning approach, improves data extraction from LLMs by addressing limitations of current methods.", "motivation": "Current data extraction methods for LLMs are limited by reliance on duplicates, prompt engineering, and random-search adversarial generation.", "method": "DMRL uses inverse reinforcement learning, introspective reasoning datasets, and Group Relative Policy Optimization (GRPO) for dynamic tuning.", "result": "DMRL outperforms baseline methods in data extraction across various LLMs.", "conclusion": "DMRL provides a robust solution for systematic red-teaming and privacy breach prevention in LLMs."}}
{"id": "2505.07380", "pdf": "https://arxiv.org/pdf/2505.07380", "abs": "https://arxiv.org/abs/2505.07380", "authors": ["David V\u00e1zquez-Pad\u00edn", "Fernando P\u00e9rez-Gonz\u00e1lez", "Pablo P\u00e9rez-Migu\u00e9lez"], "title": "Apple's Synthetic Defocus Noise Pattern: Characterization and Forensic Applications", "categories": ["cs.CV", "cs.CR", "eess.IV"], "comment": "This paper was submitted to IEEE Transactions on Information\n  Forensics & Security on May, 2025", "summary": "iPhone portrait-mode images contain a distinctive pattern in out-of-focus\nregions simulating the bokeh effect, which we term Apple's Synthetic Defocus\nNoise Pattern (SDNP). If overlooked, this pattern can interfere with blind\nforensic analyses, especially PRNU-based camera source verification, as noted\nin earlier works. Since Apple's SDNP remains underexplored, we provide a\ndetailed characterization, proposing a method for its precise estimation,\nmodeling its dependence on scene brightness, ISO settings, and other factors.\nLeveraging this characterization, we explore forensic applications of the SDNP,\nincluding traceability of portrait-mode images across iPhone models and iOS\nversions in open-set scenarios, assessing its robustness under post-processing.\nFurthermore, we show that masking SDNP-affected regions in PRNU-based camera\nsource verification significantly reduces false positives, overcoming a\ncritical limitation in camera attribution, and improving state-of-the-art\ntechniques.", "AI": {"tldr": "The paper analyzes Apple's Synthetic Defocus Noise Pattern (SDNP) in iPhone portrait-mode images, proposing methods to estimate and model it, and demonstrating its forensic applications, including improving PRNU-based camera verification.", "motivation": "SDNP in iPhone images can interfere with forensic analyses, particularly PRNU-based camera verification, but remains underexplored.", "method": "Detailed characterization of SDNP, modeling its dependence on factors like brightness and ISO, and proposing forensic applications.", "result": "SDNP can trace portrait-mode images across iPhone models and iOS versions, and masking SDNP regions reduces false positives in PRNU-based verification.", "conclusion": "Understanding and leveraging SDNP improves forensic analyses and enhances camera attribution techniques."}}
{"id": "2505.06904", "pdf": "https://arxiv.org/pdf/2505.06904", "abs": "https://arxiv.org/abs/2505.06904", "authors": ["Xinyi Mou", "Chen Qian", "Wei Liu", "Xuanjing Huang", "Zhongyu Wei"], "title": "EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) have demonstrated an impressive ability to\nrole-play humans and replicate complex social dynamics. While large-scale\nsocial simulations are gaining increasing attention, they still face\nsignificant challenges, particularly regarding high time and computation costs.\nExisting solutions, such as distributed mechanisms or hybrid agent-based model\n(ABM) integrations, either fail to address inference costs or compromise\naccuracy and generalizability. To this end, we propose EcoLANG: Efficient and\nEffective Agent Communication Language Induction for Social Simulation. EcoLANG\noperates in two stages: (1) language evolution, where we filter synonymous\nwords and optimize sentence-level rules through natural selection, and (2)\nlanguage utilization, where agents in social simulations communicate using the\nevolved language. Experimental results demonstrate that EcoLANG reduces token\nconsumption by over 20%, enhancing efficiency without sacrificing simulation\naccuracy.", "AI": {"tldr": "EcoLANG reduces token consumption by 20% in social simulations by evolving and utilizing an optimized communication language.", "motivation": "Addressing high time and computation costs in large-scale social simulations without compromising accuracy.", "method": "Two-stage approach: language evolution (filtering synonyms, optimizing rules) and language utilization (agents communicate with evolved language).", "result": "20% reduction in token consumption while maintaining simulation accuracy.", "conclusion": "EcoLANG offers an efficient and effective solution for social simulations."}}
{"id": "2505.06566", "pdf": "https://arxiv.org/pdf/2505.06566", "abs": "https://arxiv.org/abs/2505.06566", "authors": ["Zequn Xie", "Haoming Ji", "Lingwei Meng"], "title": "Dynamic Uncertainty Learning with Noisy Correspondence for Text-Based Person Search", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image person search aims to identify an individual based on a text\ndescription. To reduce data collection costs, large-scale text-image datasets\nare created from co-occurrence pairs found online. However, this can introduce\nnoise, particularly mismatched pairs, which degrade retrieval performance.\nExisting methods often focus on negative samples, amplifying this noise. To\naddress these issues, we propose the Dynamic Uncertainty and Relational\nAlignment (DURA) framework, which includes the Key Feature Selector (KFS) and a\nnew loss function, Dynamic Softmax Hinge Loss (DSH-Loss). KFS captures and\nmodels noise uncertainty, improving retrieval reliability. The bidirectional\nevidence from cross-modal similarity is modeled as a Dirichlet distribution,\nenhancing adaptability to noisy data. DSH adjusts the difficulty of negative\nsamples to improve robustness in noisy environments. Our experiments on three\ndatasets show that the method offers strong noise resistance and improves\nretrieval performance in both low- and high-noise scenarios.", "AI": {"tldr": "The paper introduces DURA, a framework for text-to-image person search, addressing noise in datasets with KFS and DSH-Loss to improve retrieval performance.", "motivation": "Large-scale text-image datasets often contain noisy, mismatched pairs, degrading retrieval performance. Existing methods worsen this by focusing on negative samples.", "method": "Proposes DURA with Key Feature Selector (KFS) to model noise uncertainty and Dynamic Softmax Hinge Loss (DSH-Loss) to adjust negative sample difficulty. Uses Dirichlet distribution for cross-modal similarity.", "result": "Experiments on three datasets show strong noise resistance and improved retrieval in low- and high-noise scenarios.", "conclusion": "DURA effectively handles noisy data, enhancing retrieval reliability and performance."}}
{"id": "2505.06964", "pdf": "https://arxiv.org/pdf/2505.06964", "abs": "https://arxiv.org/abs/2505.06964", "authors": ["Gaurab Sarkar", "Sougata Saha"], "title": "From Knowledge to Reasoning: Evaluating LLMs for Ionic Liquids Research in Chemical and Biological Engineering", "categories": ["cs.AI"], "comment": null, "summary": "Although Large Language Models (LLMs) have achieved remarkable performance in\ndiverse general knowledge and reasoning tasks, their utility in the scientific\ndomain of Chemical and Biological Engineering (CBE) is unclear. Hence, it\nnecessitates challenging evaluation benchmarks that can measure LLM performance\nin knowledge- and reasoning-based tasks, which is lacking. As a foundational\nstep, we empirically measure the reasoning capabilities of LLMs in CBE. We\nconstruct and share an expert-curated dataset of 5,920 examples for\nbenchmarking LLMs' reasoning capabilities in the niche domain of Ionic Liquids\n(ILs) for carbon sequestration, an emergent solution to reducing global\nwarming. The dataset presents different difficulty levels by varying along the\ndimensions of linguistic and domain-specific knowledge. Benchmarking three less\nthan 10B parameter open-source LLMs on the dataset suggests that while smaller\ngeneral-purpose LLMs are knowledgeable about ILs, they lack domain-specific\nreasoning capabilities. Based on our results, we further discuss considerations\nfor leveraging LLMs for carbon capture research using ILs. Since LLMs have a\nhigh carbon footprint, gearing them for IL research can symbiotically benefit\nboth fields and help reach the ambitious carbon neutrality target by 2050.\nDataset link: https://github.com/sougata-ub/llms_for_ionic_liquids", "AI": {"tldr": "The paper evaluates LLMs' reasoning in Chemical and Biological Engineering, focusing on Ionic Liquids for carbon sequestration, and finds smaller LLMs lack domain-specific reasoning despite general knowledge.", "motivation": "Assess LLM performance in niche scientific domains like CBE, where benchmarks are lacking, to understand their utility in carbon capture research.", "method": "Constructed an expert-curated dataset of 5,920 examples for benchmarking LLMs in Ionic Liquids, varying linguistic and domain-specific difficulty.", "result": "Smaller general-purpose LLMs show knowledge of Ionic Liquids but lack domain-specific reasoning capabilities.", "conclusion": "LLMs can be leveraged for carbon capture research with Ionic Liquids, benefiting both fields and aiding carbon neutrality goals by 2050."}}
{"id": "2505.06288", "pdf": "https://arxiv.org/pdf/2505.06288", "abs": "https://arxiv.org/abs/2505.06288", "authors": ["Zihao Chen", "Wenyong Wang", "Jiachen Yang", "Yu Xiang"], "title": "IIKL: Isometric Immersion Kernel Learning with Riemannian Manifold for Geometric Preservation", "categories": ["cs.LG", "stat.ML"], "comment": "16 pages, 14 figures", "summary": "Geometric representation learning in preserving the intrinsic geometric and\ntopological properties for discrete non-Euclidean data is crucial in scientific\napplications. Previous research generally mapped non-Euclidean discrete data\ninto Euclidean space during representation learning, which may lead to the loss\nof some critical geometric information. In this paper, we propose a novel\nIsometric Immersion Kernel Learning (IIKL) method to build Riemannian manifold\nand isometrically induce Riemannian metric from discrete non-Euclidean data. We\nprove that Isometric immersion is equivalent to the kernel function in the\ntangent bundle on the manifold, which explicitly guarantees the invariance of\nthe inner product between vectors in the arbitrary tangent space throughout the\nlearning process, thus maintaining the geometric structure of the original\ndata. Moreover, a novel parameterized learning model based on IIKL is\nintroduced, and an alternating training method for this model is derived using\nMaximum Likelihood Estimation (MLE), ensuring efficient convergence.\nExperimental results proved that using the learned Riemannian manifold and its\nmetric, our model preserved the intrinsic geometric representation of data in\nboth 3D and high-dimensional datasets successfully, and significantly improved\nthe accuracy of downstream tasks, such as data reconstruction and\nclassification. It is showed that our method could reduce the inner product\ninvariant loss by more than 90% compared to state-of-the-art (SOTA) methods,\nalso achieved an average 40% improvement in downstream reconstruction accuracy\nand a 90% reduction in error for geometric metrics involving isometric and\nconformal.", "AI": {"tldr": "The paper introduces Isometric Immersion Kernel Learning (IIKL) to preserve geometric properties of non-Euclidean data by mapping it into a Riemannian manifold, improving downstream task accuracy.", "motivation": "Existing methods lose critical geometric information by mapping non-Euclidean data into Euclidean space. The goal is to preserve intrinsic geometric and topological properties.", "method": "Proposes IIKL to build a Riemannian manifold and induce its metric from data, ensuring inner product invariance. Uses MLE for efficient training.", "result": "IIKL reduces inner product invariant loss by 90% and improves reconstruction accuracy by 40% compared to SOTA methods.", "conclusion": "IIKL successfully preserves geometric structures and enhances performance in downstream tasks like reconstruction and classification."}}
{"id": "2410.21000", "pdf": "https://arxiv.org/pdf/2410.21000", "abs": "https://arxiv.org/abs/2410.21000", "authors": ["Zhilin Zhang", "Jie Wang", "Zhanghao Qin", "Ruiqi Zhu", "Xiaoliang Gong"], "title": "Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "To be published in 2025 International Joint Conference on Neural\n  Networks (IJCNN)", "summary": "Medical Visual Question Answering (MedVQA) has attracted growing interest at\nthe intersection of medical image understanding and natural language processing\nfor clinical applications. By interpreting medical images and providing precise\nanswers to relevant clinical inquiries, MedVQA has the potential to support\ndiagnostic decision-making and reduce workload across various fields like\nradiology. While recent approaches rely heavily on unified large pre-trained\nVisual-Language Models, research on more efficient fusion mechanisms remains\nrelatively limited in this domain. In this paper, we introduce a fusion model,\nOMniBAN, that integrates Orthogonality loss, Multi-head attention, and a\nBilinear Attention Network to achieve high computational efficiency as well as\nsolid performance. We conduct comprehensive experiments and demonstrate how\nbilinear attention fusion can approximate the performance of larger fusion\nmodels like cross-modal Transformer. Our results show that OMniBAN requires\nfewer parameters (approximately 2/3 of Transformer-based Co-Attention) and\nsubstantially lower FLOPs (approximately 1/4), while achieving comparable\noverall performance and even slight improvements on closed-ended questions on\ntwo key MedVQA benchmarks. This balance between efficiency and accuracy\nsuggests that OMniBAN could be a viable option for real-world medical image\nquestion answering, where computational resources are often constrained.", "AI": {"tldr": "OMniBAN, a fusion model for MedVQA, combines Orthogonality loss, Multi-head attention, and Bilinear Attention Network for efficiency and performance, outperforming larger models with fewer resources.", "motivation": "To address the limited research on efficient fusion mechanisms in MedVQA, aiming to support clinical decision-making with reduced computational demands.", "method": "Introduces OMniBAN, integrating Orthogonality loss, Multi-head attention, and Bilinear Attention Network for efficient fusion.", "result": "OMniBAN achieves comparable performance to larger models with fewer parameters (2/3) and lower FLOPs (1/4), with slight improvements on closed-ended questions.", "conclusion": "OMniBAN offers a viable, efficient solution for real-world MedVQA applications where computational resources are constrained."}}
{"id": "2505.06914", "pdf": "https://arxiv.org/pdf/2505.06914", "abs": "https://arxiv.org/abs/2505.06914", "authors": ["Chen Amiraz", "Florin Cuconasu", "Simone Filice", "Zohar Karnin"], "title": "The Distracting Effect: Understanding Irrelevant Passages in RAG", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "A well-known issue with Retrieval Augmented Generation (RAG) is that\nretrieved passages that are irrelevant to the query sometimes distract the\nanswer-generating LLM, causing it to provide an incorrect response. In this\npaper, we shed light on this core issue and formulate the distracting effect of\na passage w.r.t. a query (and an LLM). We provide a quantifiable measure of the\ndistracting effect of a passage and demonstrate its robustness across LLMs.\n  Our research introduces novel methods for identifying and using hard\ndistracting passages to improve RAG systems. By fine-tuning LLMs with these\ncarefully selected distracting passages, we achieve up to a 7.5% increase in\nanswering accuracy compared to counterparts fine-tuned on conventional RAG\ndatasets. Our contribution is two-fold: first, we move beyond the simple binary\nclassification of irrelevant passages as either completely unrelated vs.\ndistracting, and second, we develop and analyze multiple methods for finding\nhard distracting passages. To our knowledge, no other research has provided\nsuch a comprehensive framework for identifying and utilizing hard distracting\npassages.", "AI": {"tldr": "The paper addresses the issue of irrelevant passages in RAG systems distracting LLMs, introducing a quantifiable measure for distraction and methods to improve RAG accuracy by 7.5%.", "motivation": "To mitigate the distracting effect of irrelevant passages in RAG systems and improve answer accuracy.", "method": "Develops a measure for passage distraction, identifies hard distracting passages, and fine-tunes LLMs using these passages.", "result": "Achieves a 7.5% increase in answering accuracy compared to conventional RAG fine-tuning.", "conclusion": "Provides a comprehensive framework for identifying and utilizing hard distracting passages, advancing RAG system performance."}}
{"id": "2505.06573", "pdf": "https://arxiv.org/pdf/2505.06573", "abs": "https://arxiv.org/abs/2505.06573", "authors": ["Xingchen Li", "LiDian Wang", "Yu Sheng", "ZhiPeng Tang", "Haojie Ren", "Guoliang You", "YiFan Duan", "Jianmin Ji", "Yanyong Zhang"], "title": "ElectricSight: 3D Hazard Monitoring for Power Lines Using Low-Cost Sensors", "categories": ["cs.CV"], "comment": null, "summary": "Protecting power transmission lines from potential hazards involves critical\ntasks, one of which is the accurate measurement of distances between power\nlines and potential threats, such as large cranes. The challenge with this task\nis that the current sensor-based methods face challenges in balancing accuracy\nand cost in distance measurement. A common practice is to install cameras on\ntransmission towers, which, however, struggle to measure true 3D distances due\nto the lack of depth information. Although 3D lasers can provide accurate depth\ndata, their high cost makes large-scale deployment impractical.\n  To address this challenge, we present ElectricSight, a system designed for 3D\ndistance measurement and monitoring of potential hazards to power transmission\nlines. This work's key innovations lie in both the overall system framework and\na monocular depth estimation method. Specifically, the system framework\ncombines real-time images with environmental point cloud priors, enabling\ncost-effective and precise 3D distance measurements. As a core component of the\nsystem, the monocular depth estimation method enhances the performance by\nintegrating 3D point cloud data into image-based estimates, improving both the\naccuracy and reliability of the system.\n  To assess ElectricSight's performance, we conducted tests with data from a\nreal-world power transmission scenario. The experimental results demonstrate\nthat ElectricSight achieves an average accuracy of 1.08 m for distance\nmeasurements and an early warning accuracy of 92%.", "AI": {"tldr": "ElectricSight is a cost-effective system for 3D distance measurement of hazards near power lines, combining monocular depth estimation with point cloud data for improved accuracy.", "motivation": "Current sensor-based methods for measuring distances between power lines and hazards are either inaccurate or too expensive, especially for large-scale deployment.", "method": "ElectricSight integrates real-time images with environmental point cloud priors and uses a monocular depth estimation method enhanced by 3D point cloud data.", "result": "The system achieves an average accuracy of 1.08 m for distance measurements and 92% early warning accuracy in real-world tests.", "conclusion": "ElectricSight provides a practical and accurate solution for monitoring hazards near power transmission lines, balancing cost and performance."}}
{"id": "2505.06977", "pdf": "https://arxiv.org/pdf/2505.06977", "abs": "https://arxiv.org/abs/2505.06977", "authors": ["Wenju Sun", "Qingyong Li", "Yangli-ao Geng", "Boyang Li"], "title": "CAT Merging: A Training-Free Approach for Resolving Conflicts in Model Merging", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multi-task model merging offers a promising paradigm for integrating multiple\nexpert models into a unified model without additional training. Existing\nstate-of-the-art techniques, such as Task Arithmetic and its variants, merge\nmodels by accumulating task vectors -- the parameter differences between\npretrained and finetuned models. However, task vector accumulation is often\nhindered by knowledge conflicts, leading to performance degradation. To address\nthis challenge, we propose Conflict-Aware Task Merging (CAT Merging), a novel\ntraining-free framework that selectively trims conflict-prone components from\nthe task vectors. CAT Merging introduces several parameter-specific strategies,\nincluding projection for linear weights and masking for scaling and shifting\nparameters in normalization layers. Extensive experiments on vision, language,\nand vision-language tasks demonstrate that CAT Merging effectively suppresses\nknowledge conflicts, achieving average accuracy improvements of up to 2.5%\n(ViT-B/32) and 2.0% (ViT-L/14) over state-of-the-art methods.", "AI": {"tldr": "CAT Merging is a training-free framework that trims conflict-prone components in task vectors to improve multi-task model merging, outperforming existing methods by up to 2.5% in accuracy.", "motivation": "Existing task vector accumulation methods suffer from knowledge conflicts, leading to performance degradation in multi-task model merging.", "method": "CAT Merging selectively trims conflict-prone components using projection for linear weights and masking for normalization layer parameters.", "result": "Experiments show CAT Merging improves accuracy by up to 2.5% (ViT-B/32) and 2.0% (ViT-L/14) over state-of-the-art methods.", "conclusion": "CAT Merging effectively addresses knowledge conflicts in multi-task model merging, enhancing performance without additional training."}}
{"id": "2505.06289", "pdf": "https://arxiv.org/pdf/2505.06289", "abs": "https://arxiv.org/abs/2505.06289", "authors": ["Sotirios Athanasoulias"], "title": "Edge-Optimized Deep Learning & Pattern Recognition Techniques for Non-Intrusive Load Monitoring of Energy Time Series", "categories": ["cs.LG", "eess.SP", "stat.ML"], "comment": "PhD dissertation as part of the GECKO Marie Curie", "summary": "The growing global energy demand and the urgent need for sustainability call\nfor innovative ways to boost energy efficiency. While advanced energy-saving\nsystems exist, they often fall short without user engagement. Providing\nfeedback on energy consumption behavior is key to promoting sustainable\npractices. Non-Intrusive Load Monitoring (NILM) offers a promising solution by\ndisaggregating total household energy usage, recorded by a central smart meter,\ninto appliance-level data. This empowers users to optimize consumption.\nAdvances in AI, IoT, and smart meter adoption have further enhanced NILM's\npotential.\n  Despite this promise, real-world NILM deployment faces major challenges.\nFirst, existing datasets mainly represent regions like the USA and UK, leaving\nplaces like the Mediterranean underrepresented. This limits understanding of\nregional consumption patterns, such as heavy use of air conditioners and\nelectric water heaters. Second, deep learning models used in NILM require high\ncomputational power, often relying on cloud services. This increases costs,\nraises privacy concerns, and limits scalability, especially for households with\npoor connectivity. This thesis tackles these issues with key contributions. It\npresents an interoperable data collection framework and introduces the Plegma\nDataset, focused on underrepresented Mediterranean energy patterns. It also\nexplores advanced deep neural networks and model compression techniques for\nefficient edge deployment. By bridging theoretical advances with practical\nneeds, this work aims to make NILM scalable, efficient, and adaptable for\nglobal energy sustainability.", "AI": {"tldr": "The paper addresses challenges in Non-Intrusive Load Monitoring (NILM) for energy efficiency, focusing on underrepresented regions and edge deployment.", "motivation": "The need for sustainable energy practices and user engagement drives the research, highlighting gaps in regional data and computational inefficiencies in NILM.", "method": "The study introduces an interoperable data collection framework (Plegma Dataset) and explores deep neural networks with model compression for edge deployment.", "result": "The work provides a region-specific dataset and efficient NILM solutions, enhancing scalability and privacy.", "conclusion": "This research advances NILM by addressing real-world challenges, making it more adaptable for global energy sustainability."}}
{"id": "2505.00228", "pdf": "https://arxiv.org/pdf/2505.00228", "abs": "https://arxiv.org/abs/2505.00228", "authors": ["Xiaoman Zhang", "Juli\u00e1n N. Acosta", "Josh Miller", "Ouwen Huang", "Pranav Rajpurkar"], "title": "ReXGradient-160K: A Large-Scale Publicly Available Dataset of Chest Radiographs with Free-text Reports", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "We present ReXGradient-160K, representing the largest publicly available\nchest X-ray dataset to date in terms of the number of patients. This dataset\ncontains 160,000 chest X-ray studies with paired radiological reports from\n109,487 unique patients across 3 U.S. health systems (79 medical sites). This\ncomprehensive dataset includes multiple images per study and detailed radiology\nreports, making it particularly valuable for the development and evaluation of\nAI systems for medical imaging and automated report generation models. The\ndataset is divided into training (140,000 studies), validation (10,000\nstudies), and public test (10,000 studies) sets, with an additional private\ntest set (10,000 studies) reserved for model evaluation on the ReXrank\nbenchmark. By providing this extensive dataset, we aim to accelerate research\nin medical imaging AI and advance the state-of-the-art in automated\nradiological analysis. Our dataset will be open-sourced at\nhttps://huggingface.co/datasets/rajpurkarlab/ReXGradient-160K.", "AI": {"tldr": "ReXGradient-160K is the largest public chest X-ray dataset with 160,000 studies from 109,487 patients, designed for AI in medical imaging and automated report generation.", "motivation": "To accelerate research in medical imaging AI and improve automated radiological analysis by providing a comprehensive, large-scale dataset.", "method": "The dataset includes 160,000 chest X-ray studies with paired radiology reports, divided into training, validation, and test sets.", "result": "The dataset is publicly available and structured for AI development, with a private test set for benchmarking.", "conclusion": "ReXGradient-160K aims to advance AI in medical imaging and automated report generation, fostering further research."}}
{"id": "2505.06974", "pdf": "https://arxiv.org/pdf/2505.06974", "abs": "https://arxiv.org/abs/2505.06974", "authors": ["Daichi Kohmoto", "Katsutoshi Fukuda", "Daisuke Yoshida", "Takafumi Matsui", "Sachihiro Omura"], "title": "CNN-based Image Models Verify a Hypothesis that The Writers of Cuneiform Texts Improved Their Writing Skills When Studying at the Age of Hittite Empire", "categories": ["cs.CL"], "comment": "11 pages, 9 figures, 5 tables", "summary": "A cuneiform tablet KBo 23.1 ++/KUB 30.38, which is known to represent a text\nof Kizzuwatna rituals, was written by two writers with almost identical content\nin two iterations. Unlike other cuneiform tablets that contained information\nsuch as myths, essays, or business records, the reason why ancient people left\nsuch tablets for posterity remains unclear. To study this problem, we develop a\nnew methodology by analyzing images of a tablet quantitatively using CNN\n(Convolutional Neural Network)-based image models, without segmenting\ncuneiforms one-by-one. Our data-driven methodology implies that the writer\nwriting the first half was a `teacher' and the other writer was a `student' who\nwas training his skills of writing cuneiforms. This result has not been reached\nby classical linguistics. We also discuss related conclusions and possible\nfurther directions for applying our method and its generalizations.", "AI": {"tldr": "The paper analyzes a cuneiform tablet with two iterations of the same content, suggesting one writer was a teacher and the other a student, using CNN-based image analysis.", "motivation": "To understand why ancient people preserved tablets with nearly identical content, unlike other tablets with myths or records.", "method": "Quantitative analysis of tablet images using CNN-based models without segmenting cuneiforms individually.", "result": "The first writer was likely a teacher, the second a student, a conclusion not reached by classical linguistics.", "conclusion": "The method offers new insights into ancient writing practices and potential for broader applications."}}
{"id": "2505.06575", "pdf": "https://arxiv.org/pdf/2505.06575", "abs": "https://arxiv.org/abs/2505.06575", "authors": ["Chengfeng Wang", "Wei Zhai", "Yuhang Yang", "Yang Cao", "Zhengjun Zha"], "title": "GRACE: Estimating Geometry-level 3D Human-Scene Contact from 2D Images", "categories": ["cs.CV"], "comment": null, "summary": "Estimating the geometry level of human-scene contact aims to ground specific\ncontact surface points at 3D human geometries, which provides a spatial prior\nand bridges the interaction between human and scene, supporting applications\nsuch as human behavior analysis, embodied AI, and AR/VR. To complete the task,\nexisting approaches predominantly rely on parametric human models (e.g., SMPL),\nwhich establish correspondences between images and contact regions through\nfixed SMPL vertex sequences. This actually completes the mapping from image\nfeatures to an ordered sequence. However, this approach lacks consideration of\ngeometry, limiting its generalizability in distinct human geometries. In this\npaper, we introduce GRACE (Geometry-level Reasoning for 3D Human-scene Contact\nEstimation), a new paradigm for 3D human contact estimation. GRACE incorporates\na point cloud encoder-decoder architecture along with a hierarchical feature\nextraction and fusion module, enabling the effective integration of 3D human\ngeometric structures with 2D interaction semantics derived from images. Guided\nby visual cues, GRACE establishes an implicit mapping from geometric features\nto the vertex space of the 3D human mesh, thereby achieving accurate modeling\nof contact regions. This design ensures high prediction accuracy and endows the\nframework with strong generalization capability across diverse human\ngeometries. Extensive experiments on multiple benchmark datasets demonstrate\nthat GRACE achieves state-of-the-art performance in contact estimation, with\nadditional results further validating its robust generalization to unstructured\nhuman point clouds.", "AI": {"tldr": "GRACE introduces a geometry-level reasoning method for 3D human-scene contact estimation, improving accuracy and generalization by integrating 3D geometric structures with 2D interaction semantics.", "motivation": "Existing methods rely on fixed parametric human models (e.g., SMPL), which lack consideration of geometry, limiting generalizability. GRACE aims to address this by incorporating geometric reasoning.", "method": "GRACE uses a point cloud encoder-decoder architecture and hierarchical feature extraction to integrate 3D human geometry with 2D interaction semantics, enabling accurate contact region modeling.", "result": "GRACE achieves state-of-the-art performance in contact estimation and demonstrates robust generalization to diverse human geometries, including unstructured point clouds.", "conclusion": "GRACE provides a scalable and accurate solution for human-scene contact estimation, with potential applications in behavior analysis, embodied AI, and AR/VR."}}
{"id": "2505.06997", "pdf": "https://arxiv.org/pdf/2505.06997", "abs": "https://arxiv.org/abs/2505.06997", "authors": ["Wenhao Lu", "Zhengqiu Zhu", "Yong Zhao", "Yonglin Tian", "Junjie Zeng", "Jun Zhang", "Zhong Liu", "Fei-Yue Wang"], "title": "A Multi-Agent Reinforcement Learning Approach for Cooperative Air-Ground-Human Crowdsensing in Emergency Rescue", "categories": ["cs.AI"], "comment": null, "summary": "Mobile crowdsensing is evolving beyond traditional human-centric models by\nintegrating heterogeneous entities like unmanned aerial vehicles (UAVs) and\nunmanned ground vehicles (UGVs). Optimizing task allocation among these diverse\nagents is critical, particularly in challenging emergency rescue scenarios\ncharacterized by complex environments, limited communication, and partial\nobservability. This paper tackles the Heterogeneous-Entity\nCollaborative-Sensing Task Allocation (HECTA) problem specifically for\nemergency rescue, considering humans, UAVs, and UGVs. We introduce a novel\n``Hard-Cooperative'' policy where UGVs prioritize recharging low-battery UAVs,\nalongside performing their sensing tasks. The primary objective is maximizing\nthe task completion rate (TCR) under strict time constraints. We rigorously\nformulate this NP-hard problem as a decentralized partially observable Markov\ndecision process (Dec-POMDP) to effectively handle sequential decision-making\nunder uncertainty. To solve this, we propose HECTA4ER, a novel multi-agent\nreinforcement learning algorithm built upon a Centralized Training with\nDecentralized Execution architecture. HECTA4ER incorporates tailored designs,\nincluding specialized modules for complex feature extraction, utilization of\naction-observation history via hidden states, and a mixing network integrating\nglobal and local information, specifically addressing the challenges of partial\nobservability. Furthermore, theoretical analysis confirms the algorithm's\nconvergence properties. Extensive simulations demonstrate that HECTA4ER\nsignificantly outperforms baseline algorithms, achieving an average 18.42%\nincrease in TCR. Crucially, a real-world case study validates the algorithm's\neffectiveness and robustness in dynamic sensing scenarios, highlighting its\nstrong potential for practical application in emergency response.", "AI": {"tldr": "The paper introduces HECTA4ER, a multi-agent reinforcement learning algorithm for optimizing task allocation among humans, UAVs, and UGVs in emergency rescue scenarios, achieving an 18.42% higher task completion rate.", "motivation": "To address the challenges of task allocation in heterogeneous mobile crowdsensing for emergency rescue, where complex environments, limited communication, and partial observability exist.", "method": "Proposes HECTA4ER, a Dec-POMDP-based algorithm with specialized modules for feature extraction, action-observation history, and a mixing network for global-local information integration.", "result": "HECTA4ER outperforms baselines with an 18.42% increase in task completion rate, validated by simulations and a real-world case study.", "conclusion": "HECTA4ER is effective and robust for emergency response, demonstrating strong practical potential."}}
{"id": "2505.06290", "pdf": "https://arxiv.org/pdf/2505.06290", "abs": "https://arxiv.org/abs/2505.06290", "authors": ["Zefang Zong", "Xiaochen Wei", "Guozhen Zhang", "Chen Gao", "Huandong Wang", "Yong Li"], "title": "UniCO: Towards a Unified Model for Combinatorial Optimization Problems", "categories": ["cs.LG", "cs.DM"], "comment": null, "summary": "Combinatorial Optimization (CO) encompasses a wide range of problems that\narise in many real-world scenarios. While significant progress has been made in\ndeveloping learning-based methods for specialized CO problems, a unified model\nwith a single architecture and parameter set for diverse CO problems remains\nelusive. Such a model would offer substantial advantages in terms of efficiency\nand convenience. In this paper, we introduce UniCO, a unified model for solving\nvarious CO problems. Inspired by the success of next-token prediction, we frame\neach problem-solving process as a Markov Decision Process (MDP), tokenize the\ncorresponding sequential trajectory data, and train the model using a\ntransformer backbone. To reduce token length in the trajectory data, we propose\na CO-prefix design that aggregates static problem features. To address the\nheterogeneity of state and action tokens within the MDP, we employ a two-stage\nself-supervised learning approach. In this approach, a dynamic prediction model\nis first trained and then serves as a pre-trained model for subsequent policy\ngeneration. Experiments across 10 CO problems showcase the versatility of\nUniCO, emphasizing its ability to generalize to new, unseen problems with\nminimal fine-tuning, achieving even few-shot or zero-shot performance. Our\nframework offers a valuable complement to existing neural CO methods that focus\non optimizing performance for individual problems.", "AI": {"tldr": "UniCO is a unified model for solving diverse Combinatorial Optimization (CO) problems using a transformer backbone and a two-stage self-supervised learning approach, achieving generalization with minimal fine-tuning.", "motivation": "To address the lack of a unified model for diverse CO problems, aiming for efficiency and convenience.", "method": "Frames CO problems as Markov Decision Processes (MDPs), tokenizes trajectory data, and uses a transformer backbone with a CO-prefix design and two-stage self-supervised learning.", "result": "UniCO generalizes to new CO problems with minimal fine-tuning, achieving few-shot or zero-shot performance across 10 problems.", "conclusion": "UniCO complements existing neural CO methods by offering a versatile, unified solution for diverse problems."}}
{"id": "2505.03844", "pdf": "https://arxiv.org/pdf/2505.03844", "abs": "https://arxiv.org/abs/2505.03844", "authors": ["Solene Debuysere", "Nicolas Trouve", "Nathan Letheule", "Olivier Leveque", "Elise Colin"], "title": "From Spaceborne to Airborne: SAR Image Synthesis Using Foundation Models for Multi-Scale Adaptation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The availability of Synthetic Aperture Radar (SAR) satellite imagery has\nincreased considerably in recent years, with datasets commercially available.\nHowever, the acquisition of high-resolution SAR images in airborne\nconfigurations, remains costly and limited. Thus, the lack of open source,\nwell-labeled, or easily exploitable SAR text-image datasets is a barrier to the\nuse of existing foundation models in remote sensing applications. In this\ncontext, synthetic image generation is a promising solution to augment this\nscarce data, enabling a broader range of applications. Leveraging over 15 years\nof ONERA's extensive archival airborn data from acquisition campaigns, we\ncreated a comprehensive training dataset of 110 thousands SAR images to exploit\na 3.5 billion parameters pre-trained latent diffusion model\n\\cite{Baqu2019SethiR}. In this work, we present a novel approach utilizing\nspatial conditioning techniques within a foundation model to transform\nsatellite SAR imagery into airborne SAR representations. Additionally, we\ndemonstrate that our pipeline is effective for bridging the realism of\nsimulated images generated by ONERA's physics-based simulator EMPRISE\n\\cite{empriseem_ai_images}. Our method explores a key application of AI in\nadvancing SAR imaging technology. To the best of our knowledge, we are the\nfirst to introduce this approach in the literature.", "AI": {"tldr": "The paper addresses the scarcity of high-resolution SAR datasets by creating a synthetic dataset and using a pre-trained latent diffusion model to transform satellite SAR imagery into airborne representations.", "motivation": "The lack of open-source, labeled SAR datasets hinders the use of foundation models in remote sensing. Synthetic image generation is proposed to augment scarce data.", "method": "A 3.5 billion parameter pre-trained latent diffusion model is used, leveraging 15 years of ONERA's airborne SAR data. Spatial conditioning techniques are applied to transform satellite SAR imagery into airborne representations.", "result": "The method effectively bridges the realism gap between simulated and real SAR images, demonstrating a novel application of AI in SAR imaging.", "conclusion": "This work pioneers a new approach in SAR imaging technology, showcasing the potential of synthetic data and foundation models for remote sensing applications."}}
{"id": "2505.06987", "pdf": "https://arxiv.org/pdf/2505.06987", "abs": "https://arxiv.org/abs/2505.06987", "authors": ["Xiaoyu Wang", "Yue Zhao", "Qingqing Gu", "Zhonglin Jiang", "Xiaokai Chen", "Yong Chen", "Luo Ji"], "title": "Convert Language Model into a Value-based Strategic Planner", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 5 figures, Accepted by ACL 2025 Industry Track", "summary": "Emotional support conversation (ESC) aims to alleviate the emotional distress\nof individuals through effective conversations. Although large language models\n(LLMs) have obtained remarkable progress on ESC, most of these studies might\nnot define the diagram from the state model perspective, therefore providing a\nsuboptimal solution for long-term satisfaction. To address such an issue, we\nleverage the Q-learning on LLMs, and propose a framework called straQ*. Our\nframework allows a plug-and-play LLM to bootstrap the planning during ESC,\ndetermine the optimal strategy based on long-term returns, and finally guide\nthe LLM to response. Substantial experiments on ESC datasets suggest that\nstraQ* outperforms many baselines, including direct inference, self-refine,\nchain of thought, finetuning, and finite state machines.", "AI": {"tldr": "The paper introduces straQ*, a Q-learning-based framework for emotional support conversations (ESC) to improve long-term satisfaction by optimizing LLM strategies.", "motivation": "Existing LLM-based ESC solutions lack a state model perspective, leading to suboptimal long-term satisfaction.", "method": "Leverages Q-learning on LLMs to plan, determine optimal strategies, and guide responses in ESC.", "result": "straQ* outperforms baselines like direct inference, self-refine, chain of thought, finetuning, and finite state machines.", "conclusion": "straQ* effectively enhances ESC by optimizing long-term returns through Q-learning on LLMs."}}
{"id": "2505.06576", "pdf": "https://arxiv.org/pdf/2505.06576", "abs": "https://arxiv.org/abs/2505.06576", "authors": ["Haorui Chen", "Zeyu Ren", "Jiaxuan Ren", "Ran Ran", "Jinliang Shao", "Jie Huang", "Liangjian Deng"], "title": "Two-Stage Random Alternation Framework for Zero-Shot Pansharpening", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In recent years, pansharpening has seen rapid advancements with deep learning\nmethods, which have demonstrated impressive fusion quality. However, the\nchallenge of acquiring real high-resolution images limits the practical\napplicability of these methods. To address this, we propose a two-stage random\nalternating framework (TRA-PAN) that effectively integrates strong supervision\nconstraints from reduced-resolution images with the physical characteristics of\nfull-resolution images. The first stage introduces a pre-training procedure,\nwhich includes Degradation-Aware Modeling (DAM) to capture spatial-spectral\ndegradation mappings, alongside a warm-up procedure designed to reduce training\ntime and mitigate the negative effects of reduced-resolution data. In the\nsecond stage, Random Alternation Optimization (RAO) is employed, where random\nalternating training leverages the strengths of both reduced- and\nfull-resolution images, further optimizing the fusion model. By primarily\nrelying on full-resolution images, our method enables zero-shot training with\njust a single image pair, obviating the need for large datasets. Experimental\nresults demonstrate that TRA-PAN outperforms state-of-the-art (SOTA) methods in\nboth quantitative metrics and visual quality in real-world scenarios,\nhighlighting its strong practical applicability.", "AI": {"tldr": "TRA-PAN is a two-stage framework for pansharpening that combines reduced- and full-resolution images, enabling zero-shot training with minimal data and outperforming SOTA methods.", "motivation": "Deep learning pansharpening methods face limitations due to the scarcity of real high-resolution images, prompting the need for a practical solution.", "method": "TRA-PAN uses Degradation-Aware Modeling (DAM) and Random Alternation Optimization (RAO) to integrate reduced- and full-resolution image constraints.", "result": "TRA-PAN achieves superior performance in quantitative metrics and visual quality compared to existing methods.", "conclusion": "The framework demonstrates strong practical applicability, especially in scenarios with limited data."}}
{"id": "2505.07005", "pdf": "https://arxiv.org/pdf/2505.07005", "abs": "https://arxiv.org/abs/2505.07005", "authors": ["Bowen Long", "Enjie Liu", "Renxi Qiu", "Yanqing Duan"], "title": "Explainable AI the Latest Advancements and New Trends", "categories": ["cs.AI"], "comment": null, "summary": "In recent years, Artificial Intelligence technology has excelled in various\napplications across all domains and fields. However, the various algorithms in\nneural networks make it difficult to understand the reasons behind decisions.\nFor this reason, trustworthy AI techniques have started gaining popularity. The\nconcept of trustworthiness is cross-disciplinary; it must meet societal\nstandards and principles, and technology is used to fulfill these requirements.\nIn this paper, we first surveyed developments from various countries and\nregions on the ethical elements that make AI algorithms trustworthy; and then\nfocused our survey on the state of the art research into the interpretability\nof AI. We have conducted an intensive survey on technologies and techniques\nused in making AI explainable. Finally, we identified new trends in achieving\nexplainable AI. In particular, we elaborate on the strong link between the\nexplainability of AI and the meta-reasoning of autonomous systems. The concept\nof meta-reasoning is 'reason the reasoning', which coincides with the intention\nand goal of explainable Al. The integration of the approaches could pave the\nway for future interpretable AI systems.", "AI": {"tldr": "The paper surveys ethical elements and interpretability in AI, focusing on explainable AI techniques and trends, highlighting the link between explainability and meta-reasoning.", "motivation": "The opacity of AI decision-making necessitates trustworthy AI, aligning societal standards with technological advancements.", "method": "Conducted a survey on ethical elements and state-of-the-art interpretability research, focusing on explainable AI techniques.", "result": "Identified trends in explainable AI and emphasized the connection between AI explainability and meta-reasoning.", "conclusion": "Integrating explainability and meta-reasoning could advance future interpretable AI systems."}}
{"id": "2505.06292", "pdf": "https://arxiv.org/pdf/2505.06292", "abs": "https://arxiv.org/abs/2505.06292", "authors": ["Silke K. Kaiser", "Filipe Rodrigues", "Carlos Lima Azevedo", "Lynn H. Kaack"], "title": "Spatio-Temporal Graph Neural Network for Urban Spaces: Interpolating Citywide Traffic Volume", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "Reliable street-level traffic volume data, covering multiple modes of\ntransportation, helps urban planning by informing decisions on infrastructure\nimprovements, traffic management, and public transportation. Yet, traffic\nsensors measuring traffic volume are typically scarcely located, due to their\nhigh deployment and maintenance costs. To address this, interpolation methods\ncan estimate traffic volumes at unobserved locations using available data.\nGraph Neural Networks have shown strong performance in traffic volume\nforecasting, particularly on highways and major arterial networks. Applying\nthem to urban settings, however, presents unique challenges: urban networks\nexhibit greater structural diversity, traffic volumes are highly overdispersed\nwith many zeros, the best way to account for spatial dependencies remains\nunclear, and sensor coverage is often very sparse. We introduce the Graph\nNeural Network for Urban Interpolation (GNNUI), a novel urban traffic volume\nestimation approach. GNNUI employs a masking algorithm to learn interpolation,\nintegrates node features to capture functional roles, and uses a loss function\ntailored to zero-inflated traffic distributions. In addition to the model, we\nintroduce two new open, large-scale urban traffic volume benchmarks, covering\ndifferent transportation modes: Strava cycling data from Berlin and New York\nCity taxi data. GNNUI outperforms recent, some graph-based, interpolation\nmethods across metrics (MAE, RMSE, true-zero rate, Kullback-Leibler divergence)\nand remains robust from 90% to 1% sensor coverage. On Strava, for instance, MAE\nrises only from 7.1 to 10.5, on Taxi from 23.0 to 40.4, demonstrating strong\nperformance under extreme data scarcity, common in real-world urban settings.\nWe also examine how graph connectivity choices influence model accuracy.", "AI": {"tldr": "GNNUI, a Graph Neural Network for urban traffic volume interpolation, outperforms existing methods under sparse sensor coverage, validated on cycling and taxi datasets.", "motivation": "Urban traffic volume data is sparse due to high sensor costs, necessitating accurate interpolation methods for urban planning.", "method": "GNNUI uses masking, node features, and a zero-inflated loss function to estimate traffic volumes in diverse urban networks.", "result": "GNNUI shows robust performance (low MAE, RMSE) even at 1% sensor coverage, outperforming baselines on cycling and taxi datasets.", "conclusion": "GNNUI is effective for urban traffic interpolation, handling sparse data and diverse network structures."}}
{"id": "2404.17484", "pdf": "https://arxiv.org/pdf/2404.17484", "abs": "https://arxiv.org/abs/2404.17484", "authors": ["Zhenghong Li", "Jiaxiang Ren", "Wensheng Cheng", "Congwu Du", "Yingtian Pan", "Haibin Ling"], "title": "Sparse Reconstruction of Optical Doppler Tomography with Alternative State Space Model and Attention", "categories": ["cs.CV", "eess.IV"], "comment": "10 pages, 3 figures", "summary": "Optical coherence Doppler tomography (ODT) is an emerging blood flow imaging\ntechnique. The fundamental unit of ODT is the 1D depth-resolved trace named raw\nA-scans (or A-line). A 2D ODT image (B-scan) is formed by reconstructing a\ncross-sectional flow image via Doppler phase-subtraction of raw A-scans along\nB-line. To obtain a high-fidelity B-scan, densely sampled A-scans are required\ncurrently, leading to prolonged scanning time and increased storage demands.\nAddressing this issue, we propose a novel sparse ODT reconstruction framework\nwith an Alternative State Space Attention Network (ASSAN) that effectively\nreduces raw A-scans needed. Inspired by the distinct distributions of\ninformation along A-line and B-line, ASSAN applies 1D State Space Model (SSM)\nto each A-line to learn the intra-A-scan representation, while using 1D gated\nself-attention along B-line to capture the inter-A-scan features. In addition,\nan effective feedforward network based on sequential 1D convolutions along\ndifferent axes is employed to enhance the local feature. In validation\nexperiments on real animal data, ASSAN shows clear effectiveness in the\nreconstruction in comparison with state-of-the-art reconstruction methods.", "AI": {"tldr": "A novel sparse ODT reconstruction framework (ASSAN) reduces the number of raw A-scans needed for high-fidelity B-scans by leveraging 1D SSM and gated self-attention.", "motivation": "Current ODT requires densely sampled A-scans, leading to long scanning times and high storage demands.", "method": "ASSAN uses 1D SSM for intra-A-scan representation and 1D gated self-attention for inter-A-scan features, along with a feedforward network for local feature enhancement.", "result": "ASSAN outperforms state-of-the-art methods in reconstruction on real animal data.", "conclusion": "ASSAN effectively reduces A-scan requirements while maintaining high-fidelity B-scan reconstruction."}}
{"id": "2505.07157", "pdf": "https://arxiv.org/pdf/2505.07157", "abs": "https://arxiv.org/abs/2505.07157", "authors": ["Hajar Sakai", "Sarah S. Lam"], "title": "HAMLET: Healthcare-focused Adaptive Multilingual Learning Embedding-based Topic Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Traditional topic models often struggle with contextual nuances and fail to\nadequately handle polysemy and rare words. This limitation typically results in\ntopics that lack coherence and quality. Large Language Models (LLMs) can\nmitigate this issue by generating an initial set of topics. However, these raw\ntopics frequently lack refinement and representativeness, which leads to\nredundancy without lexical similarity and reduced interpretability. This paper\nintroduces HAMLET, a graph-driven architecture for cross-lingual healthcare\ntopic modeling that uses LLMs. The proposed approach leverages neural-enhanced\nsemantic fusion to refine the embeddings of topics generated by the LLM.\nInstead of relying solely on statistical co-occurrence or human interpretation\nto extract topics from a document corpus, this method introduces a topic\nembedding refinement that uses Bidirectional Encoder Representations from\nTransformers (BERT) and Graph Neural Networks (GNN). After topic generation, a\nhybrid technique that involves BERT and Sentence-BERT (SBERT) is employed for\nembedding. The topic representations are further refined using a GNN, which\nestablishes connections between documents, topics, words, similar topics, and\nsimilar words. A novel method is introduced to compute similarities.\nConsequently, the topic embeddings are refined, and the top k topics are\nextracted. Experiments were conducted using two healthcare datasets, one in\nEnglish and one in French, from which six sets were derived. The results\ndemonstrate the effectiveness of HAMLET.", "AI": {"tldr": "HAMLET is a graph-driven architecture for cross-lingual healthcare topic modeling that refines LLM-generated topics using BERT, SBERT, and GNNs, improving coherence and interpretability.", "motivation": "Traditional topic models struggle with contextual nuances, polysemy, and rare words, while raw LLM-generated topics lack refinement. HAMLET addresses these issues.", "method": "Uses neural-enhanced semantic fusion with BERT, SBERT, and GNNs to refine topic embeddings, establishing connections between documents, topics, and words.", "result": "Effective refinement of topic embeddings and extraction of top k topics, demonstrated on English and French healthcare datasets.", "conclusion": "HAMLET improves topic coherence and interpretability, outperforming traditional methods and raw LLM outputs."}}
{"id": "2505.06578", "pdf": "https://arxiv.org/pdf/2505.06578", "abs": "https://arxiv.org/abs/2505.06578", "authors": ["Maxim Vashkevich", "Egor Krivalcevich"], "title": "Compact and Efficient Neural Networks for Image Recognition Based on Learned 2D Separable Transform", "categories": ["cs.CV", "cs.LG", "68T07", "I.5.1"], "comment": "6 pages, 9 figures", "summary": "The paper presents a learned two-dimensional separable transform (LST) that\ncan be considered as a new type of computational layer for constructing neural\nnetwork (NN) architecture for image recognition tasks. The LST based on the\nidea of sharing the weights of one fullyconnected (FC) layer to process all\nrows of an image. After that, a second shared FC layer is used to process all\ncolumns of image representation obtained from the first layer. The use of LST\nlayers in a NN architecture significantly reduces the number of model\nparameters compared to models that use stacked FC layers. We show that a\nNN-classifier based on a single LST layer followed by an FC layer achieves\n98.02\\% accuracy on the MNIST dataset, while having only 9.5k parameters. We\nalso implemented a LST-based classifier for handwritten digit recognition on\nthe FPGA platform to demonstrate the efficiency of the suggested approach for\ndesigning a compact and high-performance implementation of NN models. Git\nrepository with supplementary materials: https://github.com/Mak-Sim/LST-2d", "AI": {"tldr": "The paper introduces a learned two-dimensional separable transform (LST) as a neural network layer for image recognition, reducing parameters while maintaining high accuracy.", "motivation": "To design a compact and efficient neural network layer for image recognition tasks by reducing model parameters without sacrificing performance.", "method": "The LST uses shared fully-connected layers for rows and columns of images, significantly cutting down parameters. A single LST layer followed by an FC layer was tested.", "result": "Achieved 98.02% accuracy on MNIST with only 9.5k parameters and demonstrated FPGA implementation for efficiency.", "conclusion": "The LST is an effective, compact layer for neural networks, suitable for high-performance and resource-efficient implementations."}}
{"id": "2505.07027", "pdf": "https://arxiv.org/pdf/2505.07027", "abs": "https://arxiv.org/abs/2505.07027", "authors": ["Haorui Wang", "Jeff Guo", "Lingkai Kong", "Rampi Ramprasad", "Philippe Schwaller", "Yuanqi Du", "Chao Zhang"], "title": "LLM-Augmented Chemical Synthesis and Design Decision Programs", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE", "physics.chem-ph"], "comment": null, "summary": "Retrosynthesis, the process of breaking down a target molecule into simpler\nprecursors through a series of valid reactions, stands at the core of organic\nchemistry and drug development. Although recent machine learning (ML) research\nhas advanced single-step retrosynthetic modeling and subsequent route searches,\nthese solutions remain restricted by the extensive combinatorial space of\npossible pathways. Concurrently, large language models (LLMs) have exhibited\nremarkable chemical knowledge, hinting at their potential to tackle complex\ndecision-making tasks in chemistry. In this work, we explore whether LLMs can\nsuccessfully navigate the highly constrained, multi-step retrosynthesis\nplanning problem. We introduce an efficient scheme for encoding reaction\npathways and present a new route-level search strategy, moving beyond the\nconventional step-by-step reactant prediction. Through comprehensive\nevaluations, we show that our LLM-augmented approach excels at retrosynthesis\nplanning and extends naturally to the broader challenge of synthesizable\nmolecular design.", "AI": {"tldr": "LLMs are explored for multi-step retrosynthesis planning, introducing a new encoding scheme and route-level search strategy, outperforming traditional methods.", "motivation": "Retrosynthesis is vital in organic chemistry and drug development, but current ML methods are limited by combinatorial complexity. LLMs show potential for complex chemical decision-making.", "method": "An efficient encoding scheme for reaction pathways and a route-level search strategy are introduced, moving beyond step-by-step prediction.", "result": "The LLM-augmented approach excels in retrosynthesis planning and extends to synthesizable molecular design.", "conclusion": "LLMs can successfully navigate multi-step retrosynthesis, offering a promising solution for complex chemical tasks."}}
{"id": "2505.06295", "pdf": "https://arxiv.org/pdf/2505.06295", "abs": "https://arxiv.org/abs/2505.06295", "authors": ["Bhuvan Saravanan", "Pasanth Kumar M D", "Aarnesh Vengateson"], "title": "Benchmarking Traditional Machine Learning and Deep Learning Models for Fault Detection in Power Transformers", "categories": ["cs.LG"], "comment": null, "summary": "Accurate diagnosis of power transformer faults is essential for ensuring the\nstability and safety of electrical power systems. This study presents a\ncomparative analysis of conventional machine learning (ML) algorithms and deep\nlearning (DL) algorithms for fault classification of power transformers. Using\na condition-monitored dataset spanning 10 months, various gas concentration\nfeatures were normalized and used to train five ML classifiers: Support Vector\nMachine (SVM), k-Nearest Neighbors (KNN), Random Forest (RF), XGBoost, and\nArtificial Neural Network (ANN). In addition, four DL models were evaluated:\nLong Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), One-Dimensional\nConvolutional Neural Network (1D-CNN), and TabNet. Experimental results show\nthat both ML and DL approaches performed comparably. The RF model achieved the\nhighest ML accuracy at 86.82%, while the 1D-CNN model attained a close 86.30%.", "AI": {"tldr": "Comparative analysis of ML and DL for power transformer fault diagnosis shows comparable performance, with RF and 1D-CNN leading in accuracy.", "motivation": "Accurate fault diagnosis is crucial for power system stability and safety.", "method": "Used normalized gas concentration data to train five ML classifiers (SVM, KNN, RF, XGBoost, ANN) and four DL models (LSTM, GRU, 1D-CNN, TabNet).", "result": "RF achieved the highest ML accuracy (86.82%), while 1D-CNN closely followed (86.30%).", "conclusion": "Both ML and DL methods are effective for transformer fault classification, with RF and 1D-CNN performing best."}}
{"id": "2405.06198", "pdf": "https://arxiv.org/pdf/2405.06198", "abs": "https://arxiv.org/abs/2405.06198", "authors": ["Junzhuo Chen", "Shitong Kang"], "title": "MAPL: Memory Augmentation and Pseudo-Labeling for Semi-Supervised Anomaly Detection", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Large unlabeled data and difficult-to-identify anomalies are the urgent\nissues need to overcome in most industrial scene. In order to address this\nissue, a new meth-odology for detecting surface defects in in-dustrial settings\nis introduced, referred to as Memory Augmentation and Pseudo-Labeling(MAPL).\nThe methodology first in-troduces an anomaly simulation strategy, which\nsignificantly improves the model's ability to recognize rare or unknown\nanom-aly types by generating simulated anomaly samples. To cope with the\nproblem of the lack of labeling of anomalous simulated samples, a\npseudo-labeler method based on a one-classifier ensemble was employed in this\nstudy, which enhances the robustness of the model in the case of limited\nlabeling data by automatically selecting key pseudo-labeling hyperparameters.\nMeanwhile, a memory-enhanced learning mechanism is introduced to effectively\npredict abnormal regions by analyzing the difference be-tween the input samples\nand the normal samples in the memory pool. An end-to-end learning framework is\nemployed by MAPL to identify the abnormal regions directly from the input data,\nwhich optimizes the ef-ficiency and real-time performance of de-tection. By\nconducting extensive trials on the recently developed BHAD dataset (in-cluding\nMVTec AD [1], Visa [2], and MDPP [3]), MAPL achieves an average im-age-level\nAUROC score of 86.2%, demon-strating a 5.1% enhancement compared to the\noriginal MemSeg [4] model. The source code is available at\nhttps://github.com/jzc777/MAPL.", "AI": {"tldr": "MAPL introduces a new method for detecting industrial surface defects using anomaly simulation, pseudo-labeling, and memory-enhanced learning, achieving an 86.2% AUROC score.", "motivation": "Addressing the challenges of large unlabeled data and hard-to-identify anomalies in industrial settings.", "method": "Combines anomaly simulation, pseudo-labeling with a one-classifier ensemble, and memory-enhanced learning for defect detection.", "result": "Achieves an 86.2% AUROC score, a 5.1% improvement over MemSeg.", "conclusion": "MAPL is effective for industrial defect detection, offering robustness and efficiency."}}
{"id": "2505.07161", "pdf": "https://arxiv.org/pdf/2505.07161", "abs": "https://arxiv.org/abs/2505.07161", "authors": ["Jannatun Naim", "Jie Cao", "Fareen Tasneem", "Jennifer Jacobs", "Brent Milne", "James Martin", "Tamara Sumner"], "title": "Towards Actionable Pedagogical Feedback: A Multi-Perspective Analysis of Mathematics Teaching and Tutoring Dialogue", "categories": ["cs.CL", "cs.HC"], "comment": "Accepted to EDM'2025", "summary": "Effective feedback is essential for refining instructional practices in\nmathematics education, and researchers often turn to advanced natural language\nprocessing (NLP) models to analyze classroom dialogues from multiple\nperspectives. However, utterance-level discourse analysis encounters two\nprimary challenges: (1) multifunctionality, where a single utterance may serve\nmultiple purposes that a single tag cannot capture, and (2) the exclusion of\nmany utterances from domain-specific discourse move classifications, leading to\ntheir omission in feedback. To address these challenges, we proposed a\nmulti-perspective discourse analysis that integrates domain-specific talk moves\nwith dialogue act (using the flattened multi-functional SWBD-MASL schema with\n43 tags) and discourse relation (applying Segmented Discourse Representation\nTheory with 16 relations). Our top-down analysis framework enables a\ncomprehensive understanding of utterances that contain talk moves, as well as\nutterances that do not contain talk moves. This is applied to two mathematics\neducation datasets: TalkMoves (teaching) and SAGA22 (tutoring). Through\ndistributional unigram analysis, sequential talk move analysis, and multi-view\ndeep dive, we discovered meaningful discourse patterns, and revealed the vital\nrole of utterances without talk moves, demonstrating that these utterances, far\nfrom being mere fillers, serve crucial functions in guiding, acknowledging, and\nstructuring classroom discourse. These insights underscore the importance of\nincorporating discourse relations and dialogue acts into AI-assisted education\nsystems to enhance feedback and create more responsive learning environments.\nOur framework may prove helpful for providing human educator feedback, but also\naiding in the development of AI agents that can effectively emulate the roles\nof both educators and students.", "AI": {"tldr": "The paper proposes a multi-perspective discourse analysis framework to address challenges in utterance-level feedback in mathematics education, integrating talk moves, dialogue acts, and discourse relations.", "motivation": "To overcome the limitations of single-tag utterance analysis (multifunctionality and exclusion of non-talk-move utterances) in providing effective feedback for instructional practices.", "method": "A top-down framework combining domain-specific talk moves, dialogue acts (SWBD-MASL schema), and discourse relations (Segmented Discourse Representation Theory), applied to two datasets (TalkMoves and SAGA22).", "result": "Revealed meaningful discourse patterns and the crucial role of non-talk-move utterances in guiding and structuring classroom discourse.", "conclusion": "The framework enhances AI-assisted education feedback and supports the development of AI agents emulating educators and students."}}
{"id": "2505.06592", "pdf": "https://arxiv.org/pdf/2505.06592", "abs": "https://arxiv.org/abs/2505.06592", "authors": ["H M Dipu Kabir", "Subrota Kumar Mondal", "Mohammad Ali Moni"], "title": "Batch Augmentation with Unimodal Fine-tuning for Multimodal Learning", "categories": ["cs.CV"], "comment": null, "summary": "This paper proposes batch augmentation with unimodal fine-tuning to detect\nthe fetus's organs from ultrasound images and associated clinical textual\ninformation. We also prescribe pre-training initial layers with investigated\nmedical data before the multimodal training. At first, we apply a transferred\ninitialization with the unimodal image portion of the dataset with batch\naugmentation. This step adjusts the initial layer weights for medical data.\nThen, we apply neural networks (NNs) with fine-tuned initial layers to images\nin batches with batch augmentation to obtain features. We also extract\ninformation from descriptions of images. We combine this information with\nfeatures obtained from images to train the head layer. We write a dataloader\nscript to load the multimodal data and use existing unimodal image augmentation\ntechniques with batch augmentation for the multimodal data. The dataloader\nbrings a new random augmentation for each batch to get a good generalization.\nWe investigate the FPU23 ultrasound and UPMC Food-101 multimodal datasets. The\nmultimodal large language model (LLM) with the proposed training provides the\nbest results among the investigated methods. We receive near state-of-the-art\n(SOTA) performance on the UPMC Food-101 dataset. We share the scripts of the\nproposed method with traditional counterparts at the following repository:\ngithub.com/dipuk0506/multimodal", "AI": {"tldr": "The paper introduces a method combining batch augmentation and unimodal fine-tuning to detect fetal organs from ultrasound images and clinical text, achieving near SOTA results.", "motivation": "To improve detection of fetal organs in ultrasound images by leveraging multimodal data (images and text) and enhancing generalization through batch augmentation.", "method": "Uses batch augmentation and unimodal fine-tuning, pre-trains initial layers with medical data, combines image features with text information, and employs a custom dataloader for multimodal data.", "result": "Achieves near state-of-the-art performance on the UPMC Food-101 dataset and outperforms other methods on the FPU23 dataset.", "conclusion": "The proposed multimodal LLM with batch augmentation and fine-tuning is effective for fetal organ detection, with shared scripts for reproducibility."}}
{"id": "2505.07030", "pdf": "https://arxiv.org/pdf/2505.07030", "abs": "https://arxiv.org/abs/2505.07030", "authors": ["Mahmood Mohassel Feghhi", "Raya Majid Alsharfa", "Majid Hameed Majeed"], "title": "Efficient Fault Detection in WSN Based on PCA-Optimized Deep Neural Network Slicing Trained with GOA", "categories": ["cs.AI", "cs.LG", "eess.SP"], "comment": "22 pages, 18 figures, Accepted for publication in International\n  Journal of Intelligent Engineering and Systems, May 2025", "summary": "Fault detection in Wireless Sensor Networks (WSNs) is crucial for reliable\ndata transmission and network longevity. Traditional fault detection methods\noften struggle with optimizing deep neural networks (DNNs) for efficient\nperformance, especially in handling high-dimensional data and capturing\nnonlinear relationships. Additionally, these methods typically suffer from slow\nconvergence and difficulty in finding optimal network architectures using\ngradient-based optimization. This study proposes a novel hybrid method\ncombining Principal Component Analysis (PCA) with a DNN optimized by the\nGrasshopper Optimization Algorithm (GOA) to address these limitations. Our\napproach begins by computing eigenvalues from the original 12-dimensional\ndataset and sorting them in descending order. The cumulative sum of these\nvalues is calculated, retaining principal components until 99.5% variance is\nachieved, effectively reducing dimensionality to 4 features while preserving\ncritical information. This compressed representation trains a six-layer DNN\nwhere GOA optimizes the network architecture, overcoming backpropagation's\nlimitations in discovering nonlinear relationships. This hybrid PCA-GOA-DNN\nframework compresses the data and trains a six-layer DNN that is optimized by\nGOA, enhancing both training efficiency and fault detection accuracy. The\ndataset used in this study is a real-world WSNs dataset developed by the\nUniversity of North Carolina, which was used to evaluate the proposed method's\nperformance. Extensive simulations demonstrate that our approach achieves a\nremarkable 99.72% classification accuracy, with exceptional precision and\nrecall, outperforming conventional methods. The method is computationally\nefficient, making it suitable for large-scale WSN deployments, and represents a\nsignificant advancement in fault detection for resource-constrained WSNs.", "AI": {"tldr": "A hybrid PCA-GOA-DNN method for fault detection in WSNs achieves 99.72% accuracy by combining dimensionality reduction with optimized neural network training.", "motivation": "Traditional fault detection methods in WSNs struggle with optimizing DNNs for high-dimensional data and nonlinear relationships, leading to slow convergence and suboptimal architectures.", "method": "The study uses PCA to reduce dimensionality from 12 to 4 features, then trains a six-layer DNN optimized by GOA to enhance efficiency and accuracy.", "result": "The method achieves 99.72% classification accuracy, outperforming conventional approaches with high precision and recall.", "conclusion": "The PCA-GOA-DNN framework is computationally efficient and effective for large-scale WSNs, advancing fault detection in resource-constrained environments."}}
{"id": "2505.06297", "pdf": "https://arxiv.org/pdf/2505.06297", "abs": "https://arxiv.org/abs/2505.06297", "authors": ["Yu Mao", "Holger Pirk", "Chun Jason Xue"], "title": "Lossless Compression of Large Language Model-Generated Text via Next-Token Prediction", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) continue to be deployed and utilized across\ndomains, the volume of LLM-generated data is growing rapidly. This trend\nhighlights the increasing importance of effective and lossless compression for\nsuch data in modern text management systems. However, compressing LLM-generated\ndata presents unique challenges compared to traditional human- or\nmachine-generated content. Traditional machine-generated data is typically\nderived from computational processes or device outputs, often highly structured\nand limited to low-level elements like labels or numerical values. This\nstructure enables conventional lossless compressors to perform efficiently. In\ncontrast, LLM-generated data is more complex and diverse, requiring new\napproaches for effective compression. In this work, we conduct the first\nsystematic investigation of lossless compression techniques tailored\nspecifically to LLM-generated data. Notably, because LLMs are trained via\nnext-token prediction, we find that LLM-generated data is highly predictable\nfor the models themselves. This predictability enables LLMs to serve as\nefficient compressors of their own outputs. Through extensive experiments with\n14 representative LLMs and 8 LLM-generated datasets from diverse domains, we\nshow that LLM-based prediction methods achieve remarkable compression rates,\nexceeding 20x, far surpassing the 3x rate achieved by Gzip, a widely used\ngeneral-purpose compressor. Furthermore, this advantage holds across different\nLLM sizes and dataset types, demonstrating the robustness and practicality of\nLLM-based methods in lossless text compression under generative AI workloads.", "AI": {"tldr": "The paper investigates lossless compression for LLM-generated data, showing LLMs can compress their own outputs more effectively than traditional methods like Gzip.", "motivation": "The rapid growth of LLM-generated data necessitates efficient compression methods, as traditional techniques are inadequate for its complexity.", "method": "The study systematically evaluates LLM-based prediction methods for compression, testing 14 LLMs and 8 datasets.", "result": "LLM-based methods achieve over 20x compression rates, outperforming Gzip's 3x, with consistent performance across LLM sizes and datasets.", "conclusion": "LLMs are robust and practical for lossless compression of their own outputs, offering significant advantages over conventional methods."}}
{"id": "2405.17456", "pdf": "https://arxiv.org/pdf/2405.17456", "abs": "https://arxiv.org/abs/2405.17456", "authors": ["Ling-Qi Zhang", "Zahra Kadkhodaie", "Eero P. Simoncelli", "David H. Brainard"], "title": "Generalized Compressed Sensing for Image Reconstruction with Diffusion Probabilistic Models", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "We examine the problem of selecting a small set of linear measurements for\nreconstructing high-dimensional signals. Well-established methods for\noptimizing such measurements include principal component analysis (PCA),\nindependent component analysis (ICA) and compressed sensing (CS) based on\nrandom projections, all of which rely on axis- or subspace-aligned statistical\ncharacterization of the signal source. However, many naturally occurring\nsignals, including photographic images, contain richer statistical structure.\nTo exploit such structure, we introduce a general method for obtaining an\noptimized set of linear measurements for efficient image reconstruction, where\nthe signal statistics are expressed by the prior implicit in a neural network\ntrained to perform denoising (known as a ``diffusion model''). We demonstrate\nthat the optimal measurements derived for two natural image datasets differ\nfrom those of PCA, ICA, or CS, and result in substantially lower mean squared\nreconstruction error. Interestingly, the marginal distributions of the\nmeasurement values are asymmetrical (skewed), substantially more so than those\nof previous methods. We also find that optimizing with respect to perceptual\nloss, as quantified by structural similarity (SSIM), leads to measurements\ndifferent from those obtained when optimizing for MSE. Our results highlight\nthe importance of incorporating the specific statistical regularities of\nnatural signals when designing effective linear measurements.", "AI": {"tldr": "The paper introduces a method for optimizing linear measurements for high-dimensional signal reconstruction using neural network priors, outperforming PCA, ICA, and CS in mean squared error.", "motivation": "Existing methods like PCA, ICA, and CS rely on simplistic signal statistics, missing richer structures in natural signals like images.", "method": "A neural network (diffusion model) trained for denoising is used to derive optimized linear measurements, leveraging implicit signal statistics.", "result": "The derived measurements differ from PCA, ICA, or CS, yield lower reconstruction error, and exhibit skewed marginal distributions. Optimizing for perceptual loss (SSIM) also produces distinct measurements.", "conclusion": "Effective linear measurements must account for the specific statistical regularities of natural signals, as demonstrated by the superior performance of the proposed method."}}
{"id": "2505.07162", "pdf": "https://arxiv.org/pdf/2505.07162", "abs": "https://arxiv.org/abs/2505.07162", "authors": ["Hajar Sakai", "Sarah S. Lam"], "title": "KDH-MLTC: Knowledge Distillation for Healthcare Multi-Label Text Classification", "categories": ["cs.CL"], "comment": null, "summary": "The increasing volume of healthcare textual data requires computationally\nefficient, yet highly accurate classification approaches able to handle the\nnuanced and complex nature of medical terminology. This research presents\nKnowledge Distillation for Healthcare Multi-Label Text Classification\n(KDH-MLTC), a framework leveraging model compression and Large Language Models\n(LLMs). The proposed approach addresses conventional healthcare Multi-Label\nText Classification (MLTC) challenges by integrating knowledge distillation and\nsequential fine-tuning, subsequently optimized through Particle Swarm\nOptimization (PSO) for hyperparameter tuning. KDH-MLTC transfers knowledge from\na more complex teacher LLM (i.e., BERT) to a lighter student LLM (i.e.,\nDistilBERT) through sequential training adapted to MLTC that preserves the\nteacher's learned information while significantly reducing computational\nrequirements. As a result, the classification is enabled to be conducted\nlocally, making it suitable for healthcare textual data characterized by\nsensitivity and, therefore, ensuring HIPAA compliance. The experiments\nconducted on three medical literature datasets of different sizes, sampled from\nthe Hallmark of Cancer (HoC) dataset, demonstrate that KDH-MLTC achieves\nsuperior performance compared to existing approaches, particularly for the\nlargest dataset, reaching an F1 score of 82.70%. Additionally, statistical\nvalidation and an ablation study are carried out, proving the robustness of\nKDH-MLTC. Furthermore, the PSO-based hyperparameter optimization process\nallowed the identification of optimal configurations. The proposed approach\ncontributes to healthcare text classification research, balancing efficiency\nrequirements in resource-constrained healthcare settings with satisfactory\naccuracy demands.", "AI": {"tldr": "KDH-MLTC is a framework for healthcare multi-label text classification using knowledge distillation and LLMs, achieving high accuracy and efficiency while ensuring HIPAA compliance.", "motivation": "The need for efficient and accurate classification of complex healthcare textual data, addressing computational and sensitivity challenges.", "method": "Integrates knowledge distillation (BERT to DistilBERT) and sequential fine-tuning, optimized via PSO for hyperparameter tuning.", "result": "Achieves 82.70% F1 score on the largest dataset, outperforming existing methods, with robustness confirmed via statistical validation.", "conclusion": "KDH-MLTC balances efficiency and accuracy, making it suitable for resource-constrained healthcare settings."}}
{"id": "2505.06603", "pdf": "https://arxiv.org/pdf/2505.06603", "abs": "https://arxiv.org/abs/2505.06603", "authors": ["Lei Hu", "Zhiyong Gan", "Ling Deng", "Jinglin Liang", "Lingyu Liang", "Shuangping Huang", "Tianshui Chen"], "title": "ReplayCAD: Generative Diffusion Replay for Continual Anomaly Detection", "categories": ["cs.CV"], "comment": "Accepted by IJCAI 2025", "summary": "Continual Anomaly Detection (CAD) enables anomaly detection models in\nlearning new classes while preserving knowledge of historical classes. CAD\nfaces two key challenges: catastrophic forgetting and segmentation of small\nanomalous regions. Existing CAD methods store image distributions or patch\nfeatures to mitigate catastrophic forgetting, but they fail to preserve\npixel-level detailed features for accurate segmentation. To overcome this\nlimitation, we propose ReplayCAD, a novel diffusion-driven generative replay\nframework that replay high-quality historical data, thus effectively preserving\npixel-level detailed features. Specifically, we compress historical data by\nsearching for a class semantic embedding in the conditional space of the\npre-trained diffusion model, which can guide the model to replay data with\nfine-grained pixel details, thus improving the segmentation performance.\nHowever, relying solely on semantic features results in limited spatial\ndiversity. Hence, we further use spatial features to guide data compression,\nachieving precise control of sample space, thereby generating more diverse\ndata. Our method achieves state-of-the-art performance in both classification\nand segmentation, with notable improvements in segmentation: 11.5% on VisA and\n8.1% on MVTec. Our source code is available at\nhttps://github.com/HULEI7/ReplayCAD.", "AI": {"tldr": "ReplayCAD is a diffusion-driven generative replay framework for Continual Anomaly Detection (CAD), addressing catastrophic forgetting and small anomalous region segmentation by preserving pixel-level details through semantic and spatial feature-guided data compression.", "motivation": "CAD faces challenges like catastrophic forgetting and segmentation of small anomalous regions, which existing methods fail to address adequately by preserving pixel-level details.", "method": "ReplayCAD uses a pre-trained diffusion model to replay high-quality historical data, guided by class semantic and spatial features for fine-grained pixel detail preservation and spatial diversity.", "result": "Achieves state-of-the-art performance, with notable segmentation improvements: 11.5% on VisA and 8.1% on MVTec.", "conclusion": "ReplayCAD effectively mitigates CAD challenges by leveraging diffusion models and feature-guided data compression, enhancing both classification and segmentation performance."}}
{"id": "2505.07049", "pdf": "https://arxiv.org/pdf/2505.07049", "abs": "https://arxiv.org/abs/2505.07049", "authors": ["Yubo Shu", "Zhewei Huang", "Xin Wu", "Chen Hu", "Shuchang Zhou", "Daxin Jiang"], "title": "DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs", "categories": ["cs.AI"], "comment": null, "summary": "We propose DialogueReason, a reasoning paradigm that uncovers the lost roles\nin monologue-style reasoning models, aiming to boost diversity and coherency of\nthe reasoning process. Recent advances in RL-based large reasoning models have\nled to impressive long CoT capabilities and high performance on math and\nscience benchmarks. However, these reasoning models rely mainly on\nmonologue-style reasoning, which often limits reasoning diversity and\ncoherency, frequently recycling fixed strategies or exhibiting unnecessary\nshifts in attention. Our work consists of an analysis of monologue reasoning\npatterns and the development of a dialogue-based reasoning approach. We first\nintroduce the Compound-QA task, which concatenates multiple problems into a\nsingle prompt to assess both diversity and coherency of reasoning. Our analysis\nshows that Compound-QA exposes weaknesses in monologue reasoning, evidenced by\nboth quantitative metrics and qualitative reasoning traces. Building on the\nanalysis, we propose a dialogue-based reasoning, named DialogueReason,\nstructured around agents, environment, and interactions. Using PPO with\nrule-based rewards, we train open-source LLMs (Qwen-QWQ and Qwen-Base) to adopt\ndialogue reasoning. We evaluate trained models on MATH, AIME, and GPQA\ndatasets, showing that the dialogue reasoning model outperforms monologue\nmodels under more complex compound questions. Additionally, we discuss how\ndialogue-based reasoning helps enhance interpretability, facilitate more\nintuitive human interaction, and inspire advances in multi-agent system design.", "AI": {"tldr": "DialogueReason introduces dialogue-based reasoning to improve diversity and coherency in reasoning models, outperforming monologue-style models on complex tasks.", "motivation": "Monologue-style reasoning models limit diversity and coherency, often recycling fixed strategies or showing attention shifts. DialogueReason aims to address these limitations.", "method": "Analyzes monologue reasoning patterns, introduces Compound-QA task, and develops DialogueReason with agents, environment, and interactions. Uses PPO with rule-based rewards to train LLMs.", "result": "DialogueReason outperforms monologue models on MATH, AIME, and GPQA datasets, especially in complex compound questions.", "conclusion": "Dialogue-based reasoning enhances interpretability, human interaction, and inspires multi-agent system design."}}
{"id": "2505.06300", "pdf": "https://arxiv.org/pdf/2505.06300", "abs": "https://arxiv.org/abs/2505.06300", "authors": ["Umberto Gon\u00e7alves de Sousa"], "title": "ARDNS-FN-Quantum: A Quantum-Enhanced Reinforcement Learning Framework with Cognitive-Inspired Adaptive Exploration for Dynamic Environments", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages, 7 figures", "summary": "Reinforcement learning (RL) has transformed sequential decision making, yet\ntraditional algorithms like Deep Q-Networks (DQNs) and Proximal Policy\nOptimization (PPO) often struggle with efficient exploration, stability, and\nadaptability in dynamic environments. This study presents ARDNS-FN-Quantum\n(Adaptive Reward-Driven Neural Simulator with Quantum enhancement), a novel\nframework that integrates a 2-qubit quantum circuit for action selection, a\ndual-memory system inspired by human cognition, and adaptive exploration\nstrategies modulated by reward variance and curiosity. Evaluated in a 10X10\ngrid-world over 20,000 episodes, ARDNS-FN-Quantum achieves a 99.5% success rate\n(versus 81.3% for DQN and 97.0% for PPO), a mean reward of 9.0528 across all\nepisodes (versus 1.2941 for DQN and 7.6196 for PPO), and an average of 46.7\nsteps to goal (versus 135.9 for DQN and 62.5 for PPO). In the last 100\nepisodes, it records a mean reward of 9.1652 (versus 7.0916 for DQN and 9.0310\nfor PPO) and 37.2 steps to goal (versus 52.7 for DQN and 53.4 for PPO).\nGraphical analyses, including learning curves, steps-to-goal trends, reward\nvariance, and reward distributions, demonstrate ARDNS-FN-Quantum's superior\nstability (reward variance 5.424 across all episodes versus 252.262 for DQN and\n76.583 for PPO) and efficiency. By bridging quantum computing, cognitive\nscience, and RL, ARDNS-FN-Quantum offers a scalable, human-like approach to\nadaptive learning in uncertain environments, with potential applications in\nrobotics, autonomous systems, and decision-making under uncertainty.", "AI": {"tldr": "ARDNS-FN-Quantum, a novel RL framework with quantum enhancement, outperforms DQN and PPO in efficiency, stability, and adaptability, achieving a 99.5% success rate and lower reward variance.", "motivation": "Traditional RL algorithms like DQN and PPO struggle with exploration, stability, and adaptability in dynamic environments. This study aims to address these limitations by integrating quantum computing and cognitive science.", "method": "The framework combines a 2-qubit quantum circuit for action selection, a dual-memory system, and adaptive exploration strategies. It was tested in a 10X10 grid-world over 20,000 episodes.", "result": "ARDNS-FN-Quantum achieved a 99.5% success rate, higher mean rewards, and fewer steps to goal compared to DQN and PPO. It also showed superior stability with lower reward variance.", "conclusion": "By integrating quantum computing and cognitive science, ARDNS-FN-Quantum offers a scalable, human-like approach for adaptive learning, with applications in robotics and autonomous systems."}}
{"id": "2410.01098", "pdf": "https://arxiv.org/pdf/2410.01098", "abs": "https://arxiv.org/abs/2410.01098", "authors": ["Hanlong Wan", "Jian Zhang", "Yan Chen", "Weili Xu", "Fan Feng"], "title": "Exploring Gen-AI applications in building research and industry: A review", "categories": ["cs.AI", "cs.SY", "eess.IV", "eess.SY"], "comment": "This is a pre-peer review and copy editing version of an article\n  published in Building Simulation. The final authenticated version is\n  available online at:https://doi.org/10.1007/s12273-025-1279-x", "summary": "This paper investigates the transformative potential of Generative AI\n(Gen-AI) technologies, particularly large language models, within the building\nindustry. By leveraging these advanced AI tools, the study explores their\napplication across key areas such as automated compliance checking and building\ndesign assistance. The research highlights how Gen-AI can automate\nlabor-intensive processes, significantly improving efficiency and reducing\ncosts in building practices. The paper first discusses the two widely applied\nfundamental models-Transformer and Diffusion model-and summarizes current\npathways for accessing Gen-AI models and the most common techniques for\ncustomizing them. It then explores applications for text generation, such as\ncompliance checking, control support, data mining, and building simulation\ninput file editing. Additionally, it examines image generation, including\ndirect generation through diffusion models and indirect generation through\nlanguage model-supported template creation based on existing Computer-Aided\nDesign or other design tools with rendering. The paper concludes with a\ncomprehensive analysis of the current capabilities of Gen-AI in the building\nindustry, outlining future directions for research and development, with the\ngoal of paving the way for smarter, more effective, and responsive design,\nconstruction, and operational practices.", "AI": {"tldr": "The paper explores how Generative AI (Gen-AI) can revolutionize the building industry by automating tasks like compliance checking and design assistance, improving efficiency and reducing costs.", "motivation": "To demonstrate the potential of Gen-AI in transforming labor-intensive processes in the building industry.", "method": "The study reviews foundational models (Transformer, Diffusion), customization techniques, and applications in text and image generation for building-related tasks.", "result": "Gen-AI shows promise in automating compliance checking, design assistance, and other building processes, enhancing efficiency.", "conclusion": "The paper highlights Gen-AI's current capabilities and suggests future research directions to advance smarter building practices."}}
{"id": "2505.07184", "pdf": "https://arxiv.org/pdf/2505.07184", "abs": "https://arxiv.org/abs/2505.07184", "authors": ["Yifan Wei", "Xiaoyan Yu", "Tengfei Pan", "Angsheng Li", "Li Du"], "title": "Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved unprecedented performance by\nleveraging vast pretraining corpora, yet their performance remains suboptimal\nin knowledge-intensive domains such as medicine and scientific research, where\nhigh factual precision is required. While synthetic data provides a promising\navenue for augmenting domain knowledge, existing methods frequently generate\nredundant samples that do not align with the model's true knowledge gaps. To\novercome this limitation, we propose a novel Structural Entropy-guided\nKnowledge Navigator (SENATOR) framework that addresses the intrinsic knowledge\ndeficiencies of LLMs. Our approach employs the Structure Entropy (SE) metric to\nquantify uncertainty along knowledge graph paths and leverages Monte Carlo Tree\nSearch (MCTS) to selectively explore regions where the model lacks\ndomain-specific knowledge. Guided by these insights, the framework generates\ntargeted synthetic data for supervised fine-tuning, enabling continuous\nself-improvement. Experimental results on LLaMA-3 and Qwen2 across multiple\ndomain-specific benchmarks show that SENATOR effectively detects and repairs\nknowledge deficiencies, achieving notable performance improvements. The code\nand data for our methods and experiments are available at\nhttps://github.com/weiyifan1023/senator.", "AI": {"tldr": "SENATOR framework improves LLMs' domain-specific knowledge by using Structure Entropy and MCTS to generate targeted synthetic data for fine-tuning.", "motivation": "LLMs underperform in knowledge-intensive domains due to redundant synthetic data and misaligned knowledge gaps.", "method": "Uses Structure Entropy and Monte Carlo Tree Search to identify and address knowledge deficiencies, generating targeted synthetic data for fine-tuning.", "result": "SENATOR improves performance on domain-specific benchmarks for models like LLaMA-3 and Qwen2.", "conclusion": "The framework effectively detects and repairs knowledge gaps, enhancing LLM performance in specialized domains."}}
{"id": "2505.06635", "pdf": "https://arxiv.org/pdf/2505.06635", "abs": "https://arxiv.org/abs/2505.06635", "authors": ["Xu Zheng", "Yuanhuiyi Lyu", "Lutao Jiang", "Danda Pani Paudel", "Luc Van Gool", "Xuming Hu"], "title": "Reducing Unimodal Bias in Multi-Modal Semantic Segmentation with Multi-Scale Functional Entropy Regularization", "categories": ["cs.CV"], "comment": null, "summary": "Fusing and balancing multi-modal inputs from novel sensors for dense\nprediction tasks, particularly semantic segmentation, is critically important\nyet remains a significant challenge. One major limitation is the tendency of\nmulti-modal frameworks to over-rely on easily learnable modalities, a\nphenomenon referred to as unimodal dominance or bias. This issue becomes\nespecially problematic in real-world scenarios where the dominant modality may\nbe unavailable, resulting in severe performance degradation. To this end, we\napply a simple but effective plug-and-play regularization term based on\nfunctional entropy, which introduces no additional parameters or modules. This\nterm is designed to intuitively balance the contribution of each visual\nmodality to the segmentation results. Specifically, we leverage the log-Sobolev\ninequality to bound functional entropy using functional-Fisher-information. By\nmaximizing the information contributed by each visual modality, our approach\nmitigates unimodal dominance and establishes a more balanced and robust\nsegmentation framework. A multi-scale regularization module is proposed to\napply our proposed plug-and-play term on high-level features and also\nsegmentation predictions for more balanced multi-modal learning. Extensive\nexperiments on three datasets demonstrate that our proposed method achieves\nsuperior performance, i.e., +13.94%, +3.25%, and +3.64%, without introducing\nany additional parameters.", "AI": {"tldr": "A plug-and-play regularization term based on functional entropy balances multi-modal inputs for semantic segmentation, mitigating unimodal dominance without extra parameters.", "motivation": "Addressing the challenge of unimodal dominance in multi-modal frameworks, which causes performance drops when dominant modalities are unavailable.", "method": "Uses a functional entropy-based regularization term, leveraging log-Sobolev inequality to bound entropy with functional-Fisher-information, applied at multi-scale levels.", "result": "Achieves performance improvements of +13.94%, +3.25%, and +3.64% on three datasets.", "conclusion": "The method effectively balances multi-modal contributions, enhancing robustness and performance in semantic segmentation."}}
{"id": "2505.07052", "pdf": "https://arxiv.org/pdf/2505.07052", "abs": "https://arxiv.org/abs/2505.07052", "authors": ["Humam Kourani", "Gyunam Park", "Wil M. P. van der Aalst"], "title": "Unlocking Non-Block-Structured Decisions: Inductive Mining with Choice Graphs", "categories": ["cs.AI"], "comment": "The Version of Record of this contribution will be published in the\n  proceedings of the 23rd International Conference on Business Process\n  Management (BPM 2025). This preprint has not undergone peer review or any\n  post-submission improvements or corrections", "summary": "Process discovery aims to automatically derive process models from event\nlogs, enabling organizations to analyze and improve their operational\nprocesses. Inductive mining algorithms, while prioritizing soundness and\nefficiency through hierarchical modeling languages, often impose a strict\nblock-structured representation. This limits their ability to accurately\ncapture the complexities of real-world processes. While recent advancements\nlike the Partially Ordered Workflow Language (POWL) have addressed the\nblock-structure limitation for concurrency, a significant gap remains in\neffectively modeling non-block-structured decision points. In this paper, we\nbridge this gap by proposing an extension of POWL to handle\nnon-block-structured decisions through the introduction of choice graphs.\nChoice graphs offer a structured yet flexible approach to model complex\ndecision logic within the hierarchical framework of POWL. We present an\ninductive mining discovery algorithm that uses our extension and preserves the\nquality guarantees of the inductive mining framework. Our experimental\nevaluation demonstrates that the discovered models, enriched with choice\ngraphs, more precisely represent the complex decision-making behavior found in\nreal-world processes, without compromising the high scalability inherent in\ninductive mining techniques.", "AI": {"tldr": "The paper proposes an extension to POWL using choice graphs to model non-block-structured decisions in process discovery, improving accuracy while maintaining scalability.", "motivation": "Existing inductive mining algorithms struggle with non-block-structured decision points, limiting their ability to accurately model real-world processes.", "method": "The authors extend POWL with choice graphs and develop an inductive mining algorithm to discover models with complex decision logic.", "result": "Experiments show the extended POWL with choice graphs more accurately captures real-world decision-making without sacrificing scalability.", "conclusion": "The proposed extension bridges the gap in modeling non-block-structured decisions, enhancing the practical applicability of inductive mining."}}
{"id": "2505.06301", "pdf": "https://arxiv.org/pdf/2505.06301", "abs": "https://arxiv.org/abs/2505.06301", "authors": ["Xiaozhou Ye", "Kevin I-Kai Wang"], "title": "Domain-Adversarial Anatomical Graph Networks for Cross-User Human Activity Recognition", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": null, "summary": "Cross-user variability in Human Activity Recognition (HAR) remains a critical\nchallenge due to differences in sensor placement, body dynamics, and behavioral\npatterns. Traditional methods often fail to capture biomechanical invariants\nthat persist across users, limiting their generalization capability. We propose\nan Edge-Enhanced Graph-Based Adversarial Domain Generalization (EEG-ADG)\nframework that integrates anatomical correlation knowledge into a unified graph\nneural network (GNN) architecture. By modeling three biomechanically motivated\nrelationships together-Interconnected Units, Analogous Units, and Lateral\nUnits-our method encodes domain-invariant features while addressing\nuser-specific variability through Variational Edge Feature Extractor. A\nGradient Reversal Layer (GRL) enforces adversarial domain generalization,\nensuring robustness to unseen users. Extensive experiments on OPPORTUNITY and\nDSADS datasets demonstrate state-of-the-art performance. Our work bridges\nbiomechanical principles with graph-based adversarial learning by integrating\ninformation fusion techniques. This fusion of information underpins our unified\nand generalized model for cross-user HAR.", "AI": {"tldr": "The paper introduces EEG-ADG, a graph-based adversarial framework for cross-user HAR, leveraging biomechanical invariants and adversarial learning to improve generalization.", "motivation": "Cross-user variability in HAR, caused by differences in sensor placement and behavior, limits traditional methods' generalization. The paper aims to address this by integrating biomechanical principles.", "method": "Proposes EEG-ADG, a GNN-based framework with Variational Edge Feature Extractor and Gradient Reversal Layer to model biomechanical relationships and enforce domain generalization.", "result": "Achieves state-of-the-art performance on OPPORTUNITY and DSADS datasets, demonstrating robustness to unseen users.", "conclusion": "The work successfully combines biomechanical principles with adversarial learning, offering a unified and generalized model for cross-user HAR."}}
{"id": "2504.09455", "pdf": "https://arxiv.org/pdf/2504.09455", "abs": "https://arxiv.org/abs/2504.09455", "authors": ["Hussain Md. Safwan", "Mahbub Islam Mahim"], "title": "Enhancing Wide-Angle Image Using Narrow-Angle View of the Same Scene", "categories": ["cs.CV", "eess.IV", "F.2.2; I.2.7"], "comment": null, "summary": "A common dilemma while photographing a scene is whether to capture it at a\nwider angle, allowing more of the scene to be covered but in less detail or to\nclick in a narrow angle that captures better details but leaves out portions of\nthe scene. We propose a novel method in this paper that infuses wider shots\nwith finer quality details that is usually associated with an image captured by\nthe primary lens by capturing the same scene using both narrow and wide field\nof view (FoV) lenses. We do so by training a Generative Adversarial Network\n(GAN)-based model to learn to extract the visual quality parameters from a\nnarrow-angle shot and to transfer these to the corresponding wide-angle image\nof the scene using residual connections and an attention-based fusion module.\nWe have mentioned in details the proposed technique to isolate the visual\nessence of an image and to transfer it into another image. We have also\nelaborately discussed our implementation details and have presented the results\nof evaluation over several benchmark datasets and comparisons with contemporary\nadvancements in the field.", "AI": {"tldr": "A novel GAN-based method enhances wide-angle images with fine details from narrow-angle shots using residual connections and attention-based fusion.", "motivation": "Addressing the trade-off between scene coverage and detail quality in photography by combining wide and narrow-angle shots.", "method": "Uses a GAN-based model with residual connections and an attention-based fusion module to transfer details from narrow to wide-angle images.", "result": "Evaluated on benchmark datasets, showing improved detail quality in wide-angle images compared to contemporary methods.", "conclusion": "The proposed method effectively enhances wide-angle images with finer details, offering a solution to the coverage-detail dilemma."}}
{"id": "2505.07205", "pdf": "https://arxiv.org/pdf/2505.07205", "abs": "https://arxiv.org/abs/2505.07205", "authors": ["Mouxiao Bian", "Rongzhao Zhang", "Chao Ding", "Xinwei Peng", "Jie Xu"], "title": "Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are poised to transform healthcare under China's\nHealthy China 2030 initiative, yet they introduce new ethical and\npatient-safety challenges. We present a novel 12,000-item Q&A benchmark\ncovering 11 ethics and 9 safety dimensions in medical contexts, to\nquantitatively evaluate these risks. Using this dataset, we assess\nstate-of-the-art Chinese medical LLMs (e.g., Qwen 2.5-32B, DeepSeek), revealing\nmoderate baseline performance (accuracy 42.7% for Qwen 2.5-32B) and significant\nimprovements after fine-tuning on our data (up to 50.8% accuracy). Results show\nnotable gaps in LLM decision-making on ethics and safety scenarios, reflecting\ninsufficient institutional oversight. We then identify systemic governance\nshortfalls-including the lack of fine-grained ethical audit protocols, slow\nadaptation by hospital IRBs, and insufficient evaluation tools-that currently\nhinder safe LLM deployment. Finally, we propose a practical governance\nframework for healthcare institutions (embedding LLM auditing teams, enacting\ndata ethics guidelines, and implementing safety simulation pipelines) to\nproactively manage LLM risks. Our study highlights the urgent need for robust\nLLM governance in Chinese healthcare, aligning AI innovation with patient\nsafety and ethical standards.", "AI": {"tldr": "A study evaluates ethical and safety risks of LLMs in Chinese healthcare using a 12,000-item Q&A benchmark, revealing gaps in performance and governance, and proposes a governance framework.", "motivation": "To address ethical and patient-safety challenges posed by LLMs in healthcare under China's Healthy China 2030 initiative.", "method": "Developed a 12,000-item Q&A benchmark to assess LLMs, evaluated state-of-the-art models, and identified governance shortfalls.", "result": "Baseline LLM accuracy was 42.7%, improving to 50.8% after fine-tuning, with notable gaps in ethics and safety decision-making.", "conclusion": "Proposes a governance framework to manage LLM risks, emphasizing the need for robust oversight in Chinese healthcare."}}
{"id": "2505.06647", "pdf": "https://arxiv.org/pdf/2505.06647", "abs": "https://arxiv.org/abs/2505.06647", "authors": ["Zhe Li", "Sarah Cechnicka", "Cheng Ouyang", "Katharina Breininger", "Peter Sch\u00fcffler", "Bernhard Kainz"], "title": "Dataset Distillation with Probabilistic Latent Features", "categories": ["cs.CV"], "comment": "23 pages", "summary": "As deep learning models grow in complexity and the volume of training data\nincreases, reducing storage and computational costs becomes increasingly\nimportant. Dataset distillation addresses this challenge by synthesizing a\ncompact set of synthetic data that can effectively replace the original dataset\nin downstream classification tasks. While existing methods typically rely on\nmapping data from pixel space to the latent space of a generative model, we\npropose a novel stochastic approach that models the joint distribution of\nlatent features. This allows our method to better capture spatial structures\nand produce diverse synthetic samples, which benefits model training.\nSpecifically, we introduce a low-rank multivariate normal distribution\nparameterized by a lightweight network. This design maintains low computational\ncomplexity and is compatible with various matching networks used in dataset\ndistillation. After distillation, synthetic images are generated by feeding the\nlearned latent features into a pretrained generator. These synthetic images are\nthen used to train classification models, and performance is evaluated on real\ntest set. We validate our method on several benchmarks, including ImageNet\nsubsets, CIFAR-10, and the MedMNIST histopathological dataset. Our approach\nachieves state-of-the-art cross architecture performance across a range of\nbackbone architectures, demonstrating its generality and effectiveness.", "AI": {"tldr": "The paper introduces a stochastic dataset distillation method that models joint latent feature distributions, improving synthetic data diversity and downstream task performance.", "motivation": "To address the challenge of reducing storage and computational costs in deep learning by synthesizing compact, effective synthetic datasets.", "method": "Proposes a stochastic approach using a low-rank multivariate normal distribution parameterized by a lightweight network, compatible with various matching networks. Synthetic images are generated via a pretrained generator.", "result": "Achieves state-of-the-art cross-architecture performance on benchmarks like ImageNet subsets, CIFAR-10, and MedMNIST.", "conclusion": "The method is general and effective, enhancing dataset distillation by better capturing spatial structures and diversity."}}
{"id": "2505.07079", "pdf": "https://arxiv.org/pdf/2505.07079", "abs": "https://arxiv.org/abs/2505.07079", "authors": ["Robert Johansson", "Patrick Hammer", "Tony Lofthouse"], "title": "Arbitrarily Applicable Same/Opposite Relational Responding with NARS", "categories": ["cs.AI"], "comment": null, "summary": "Same/opposite relational responding, a fundamental aspect of human symbolic\ncognition, allows the flexible generalization of stimulus relationships based\non minimal experience. In this study, we demonstrate the emergence of\n\\textit{arbitrarily applicable} same/opposite relational responding within the\nNon-Axiomatic Reasoning System (NARS), a computational cognitive architecture\ndesigned for adaptive reasoning under uncertainty. Specifically, we extend NARS\nwith an implementation of \\textit{acquired relations}, enabling the system to\nexplicitly derive both symmetric (mutual entailment) and novel relational\ncombinations (combinatorial entailment) from minimal explicit training in a\ncontextually controlled matching-to-sample (MTS) procedure. Experimental\nresults show that NARS rapidly internalizes explicitly trained relational rules\nand robustly demonstrates derived relational generalizations based on arbitrary\ncontextual cues. Importantly, derived relational responding in critical test\nphases inherently combines both mutual and combinatorial entailments, such as\nderiving same-relations from multiple explicitly trained opposite-relations.\nInternal confidence metrics illustrate strong internalization of these\nrelational principles, closely paralleling phenomena observed in human\nrelational learning experiments. Our findings underscore the potential for\nintegrating nuanced relational learning mechanisms inspired by learning\npsychology into artificial general intelligence frameworks, explicitly\nhighlighting the arbitrary and context-sensitive relational capabilities\nmodeled within NARS.", "AI": {"tldr": "The study demonstrates how the Non-Axiomatic Reasoning System (NARS) can learn and generalize same/opposite relational responding, mimicking human symbolic cognition, through minimal training.", "motivation": "To explore the integration of human-like relational learning mechanisms into artificial general intelligence, specifically within NARS.", "method": "Extended NARS with acquired relations, enabling it to derive symmetric and novel relational combinations via a matching-to-sample procedure.", "result": "NARS successfully internalized relational rules and demonstrated derived generalizations, mirroring human relational learning.", "conclusion": "The findings highlight NARS's potential for modeling arbitrary and context-sensitive relational learning, advancing artificial general intelligence."}}
{"id": "2505.06302", "pdf": "https://arxiv.org/pdf/2505.06302", "abs": "https://arxiv.org/abs/2505.06302", "authors": ["Xuzhi Zhang", "Shaohui Peng", "Qirui Zhou", "Yuanbo Wen", "Qi Guo", "Ruizhi Chen", "Xinguo Zhu", "Weiqiang Xiong", "Haixin Chen", "Congying Ma", "Ke Gao", "Chen Zhao", "Yanjun Wu", "Yunji Chen", "Ling Li"], "title": "QiMeng-TensorOp: Automatically Generating High-Performance Tensor Operators with Hardware Primitives", "categories": ["cs.LG", "cs.AI", "I.2.2"], "comment": "10 pages, 5 figures", "summary": "Computation-intensive tensor operators constitute over 90\\% of the\ncomputations in Large Language Models (LLMs) and Deep Neural\nNetworks.Automatically and efficiently generating high-performance tensor\noperators with hardware primitives is crucial for diverse and ever-evolving\nhardware architectures like RISC-V, ARM, and GPUs, as manually optimized\nimplementation takes at least months and lacks portability.LLMs excel at\ngenerating high-level language codes, but they struggle to fully comprehend\nhardware characteristics and produce high-performance tensor operators. We\nintroduce a tensor-operator auto-generation framework with a one-line user\nprompt (QiMeng-TensorOp), which enables LLMs to automatically exploit hardware\ncharacteristics to generate tensor operators with hardware primitives, and tune\nparameters for optimal performance across diverse hardware. Experimental\nresults on various hardware platforms, SOTA LLMs, and typical tensor operators\ndemonstrate that QiMeng-TensorOp effectively unleashes the computing capability\nof various hardware platforms, and automatically generates tensor operators of\nsuperior performance. Compared with vanilla LLMs, QiMeng-TensorOp achieves up\nto $1291 \\times$ performance improvement. Even compared with human experts,\nQiMeng-TensorOp could reach $251 \\%$ of OpenBLAS on RISC-V CPUs, and $124 \\%$\nof cuBLAS on NVIDIA GPUs. Additionally, QiMeng-TensorOp also significantly\nreduces development costs by $200 \\times$ compared with human experts.", "AI": {"tldr": "QiMeng-TensorOp is a framework that auto-generates high-performance tensor operators for diverse hardware using LLMs, achieving significant performance gains and cost reductions.", "motivation": "Manually optimizing tensor operators for varying hardware architectures is time-consuming and lacks portability, while LLMs alone struggle to leverage hardware characteristics effectively.", "method": "The framework uses a one-line user prompt to guide LLMs in generating and tuning tensor operators with hardware primitives for optimal performance.", "result": "QiMeng-TensorOp outperforms vanilla LLMs by up to 1291x, matches or exceeds human expert performance (e.g., 251% of OpenBLAS on RISC-V), and reduces development costs by 200x.", "conclusion": "QiMeng-TensorOp effectively automates high-performance tensor operator generation, bridging the gap between LLMs and hardware optimization."}}
{"id": "2505.07233", "pdf": "https://arxiv.org/pdf/2505.07233", "abs": "https://arxiv.org/abs/2505.07233", "authors": ["Jiashuo Sun", "Xianrui Zhong", "Sizhe Zhou", "Jiawei Han"], "title": "DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": "24 pages, 6 figures, 15 tables", "summary": "Retrieval-augmented generation (RAG) systems combine large language models\n(LLMs) with external knowledge retrieval, making them highly effective for\nknowledge-intensive tasks. A crucial but often under-explored component of\nthese systems is the reranker, which refines retrieved documents to enhance\ngeneration quality and explainability. The challenge of selecting the optimal\nnumber of documents (k) remains unsolved: too few may omit critical\ninformation, while too many introduce noise and inefficiencies. Although recent\nstudies have explored LLM-based rerankers, they primarily leverage internal\nmodel knowledge and overlook the rich supervisory signals that LLMs can\nprovide, such as using response quality as feedback for optimizing reranking\ndecisions. In this paper, we propose DynamicRAG, a novel RAG framework where\nthe reranker dynamically adjusts both the order and number of retrieved\ndocuments based on the query. We model the reranker as an agent optimized\nthrough reinforcement learning (RL), using rewards derived from LLM output\nquality. Across seven knowledge-intensive datasets, DynamicRAG demonstrates\nsuperior performance, achieving state-of-the-art results. The model, data and\ncode are available at https://github.com/GasolSun36/DynamicRAG", "AI": {"tldr": "DynamicRAG introduces a reinforcement learning-based reranker for RAG systems, dynamically adjusting document retrieval to optimize performance.", "motivation": "Addressing the challenge of selecting the optimal number of documents in RAG systems to balance information completeness and noise reduction.", "method": "Proposes DynamicRAG, a framework using RL to optimize reranking decisions based on LLM output quality.", "result": "Achieves state-of-the-art performance across seven knowledge-intensive datasets.", "conclusion": "DynamicRAG effectively enhances RAG systems by dynamically refining document retrieval, improving generation quality and explainability."}}
{"id": "2505.06663", "pdf": "https://arxiv.org/pdf/2505.06663", "abs": "https://arxiv.org/abs/2505.06663", "authors": ["Yongqi Wang", "Xinxiao Wu", "Shuo Yang"], "title": "METOR: A Unified Framework for Mutual Enhancement of Objects and Relationships in Open-vocabulary Video Visual Relationship Detection", "categories": ["cs.CV"], "comment": "IJCAI2025", "summary": "Open-vocabulary video visual relationship detection aims to detect objects\nand their relationships in videos without being restricted by predefined object\nor relationship categories. Existing methods leverage the rich semantic\nknowledge of pre-trained vision-language models such as CLIP to identify novel\ncategories. They typically adopt a cascaded pipeline to first detect objects\nand then classify relationships based on the detected objects, which may lead\nto error propagation and thus suboptimal performance. In this paper, we propose\nMutual EnhancemenT of Objects and Relationships (METOR), a query-based unified\nframework to jointly model and mutually enhance object detection and\nrelationship classification in open-vocabulary scenarios. Under this framework,\nwe first design a CLIP-based contextual refinement encoding module that\nextracts visual contexts of objects and relationships to refine the encoding of\ntext features and object queries, thus improving the generalization of encoding\nto novel categories. Then we propose an iterative enhancement module to\nalternatively enhance the representations of objects and relationships by fully\nexploiting their interdependence to improve recognition performance. Extensive\nexperiments on two public datasets, VidVRD and VidOR, demonstrate that our\nframework achieves state-of-the-art performance.", "AI": {"tldr": "METOR is a unified framework for open-vocabulary video visual relationship detection, jointly modeling objects and relationships to avoid error propagation and improve performance.", "motivation": "Existing cascaded pipelines for video visual relationship detection suffer from error propagation and suboptimal performance due to separate object and relationship classification.", "method": "Proposes METOR, a query-based framework with a CLIP-based contextual refinement encoding module and an iterative enhancement module to mutually improve object and relationship representations.", "result": "Achieves state-of-the-art performance on VidVRD and VidOR datasets.", "conclusion": "METOR effectively enhances object and relationship detection in open-vocabulary scenarios through joint modeling and iterative refinement."}}
{"id": "2505.07087", "pdf": "https://arxiv.org/pdf/2505.07087", "abs": "https://arxiv.org/abs/2505.07087", "authors": ["Robert E. Wray", "James R. Kirk", "John E. Laird"], "title": "Architectural Precedents for General Agents using Large Language Models", "categories": ["cs.AI", "I.2.11; I.2.7"], "comment": "14 pages, 2 figures. Submitted to AGI25", "summary": "One goal of AI (and AGI) is to identify and understand specific mechanisms\nand representations sufficient for general intelligence. Often, this work\nmanifests in research focused on architectures and many cognitive architectures\nhave been explored in AI/AGI. However, different research groups and even\ndifferent research traditions have somewhat independently identified\nsimilar/common patterns of processes and representations or cognitive design\npatterns that are manifest in existing architectures. Today, AI systems\nexploiting large language models (LLMs) offer a relatively new combination of\nmechanism and representation available for exploring the possibilities of\ngeneral intelligence. In this paper, we summarize a few recurring cognitive\ndesign patterns that have appeared in various pre-transformer AI architectures.\nWe then explore how these patterns are evident in systems using LLMs,\nespecially for reasoning and interactive (\"agentic\") use cases. By examining\nand applying these recurring patterns, we can also predict gaps or deficiencies\nin today's Agentic LLM Systems and identify likely subjects of future research\ntowards general intelligence using LLMs and other generative foundation models.", "AI": {"tldr": "The paper explores recurring cognitive design patterns in pre-transformer AI architectures and examines their presence in LLM-based systems, identifying gaps for future AGI research.", "motivation": "To understand mechanisms and representations for general intelligence by analyzing cognitive design patterns in AI architectures, including LLMs.", "method": "Summarize recurring cognitive design patterns from pre-transformer architectures and analyze their manifestation in LLM-based systems, focusing on reasoning and agentic use cases.", "result": "Identifies how these patterns appear in LLM systems and highlights gaps in current Agentic LLM Systems.", "conclusion": "The study predicts future research directions for achieving general intelligence using LLMs and generative foundation models."}}
{"id": "2505.06303", "pdf": "https://arxiv.org/pdf/2505.06303", "abs": "https://arxiv.org/abs/2505.06303", "authors": ["Li Yuan", "Yi Cai", "Xudong Shen", "Qing Li", "Qingbao Huang", "Zikun Deng", "Tao Wang"], "title": "Collaborative Multi-LoRA Experts with Achievement-based Multi-Tasks Loss for Unified Multimodal Information Extraction", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Multimodal Information Extraction (MIE) has gained attention for extracting\nstructured information from multimedia sources. Traditional methods tackle MIE\ntasks separately, missing opportunities to share knowledge across tasks. Recent\napproaches unify these tasks into a generation problem using instruction-based\nT5 models with visual adaptors, optimized through full-parameter fine-tuning.\nHowever, this method is computationally intensive, and multi-task fine-tuning\noften faces gradient conflicts, limiting performance. To address these\nchallenges, we propose collaborative multi-LoRA experts with achievement-based\nmulti-task loss (C-LoRAE) for MIE tasks. C-LoRAE extends the low-rank\nadaptation (LoRA) method by incorporating a universal expert to learn shared\nmultimodal knowledge from cross-MIE tasks and task-specific experts to learn\nspecialized instructional task features. This configuration enhances the\nmodel's generalization ability across multiple tasks while maintaining the\nindependence of various instruction tasks and mitigating gradient conflicts.\nAdditionally, we propose an achievement-based multi-task loss to balance\ntraining progress across tasks, addressing the imbalance caused by varying\nnumbers of training samples in MIE tasks. Experimental results on seven\nbenchmark datasets across three key MIE tasks demonstrate that C-LoRAE achieves\nsuperior overall performance compared to traditional fine-tuning methods and\nLoRA methods while utilizing a comparable number of training parameters to\nLoRA.", "AI": {"tldr": "C-LoRAE, a collaborative multi-LoRA experts method with achievement-based multi-task loss, improves Multimodal Information Extraction by balancing task-specific and shared knowledge, outperforming traditional methods.", "motivation": "Traditional MIE methods lack knowledge sharing across tasks, and recent unified approaches face computational inefficiency and gradient conflicts.", "method": "C-LoRAE extends LoRA with universal and task-specific experts, plus an achievement-based loss to balance training.", "result": "Outperforms traditional fine-tuning and LoRA on seven datasets across three MIE tasks.", "conclusion": "C-LoRAE enhances generalization and mitigates gradient conflicts, offering a scalable solution for MIE."}}
{"id": "2505.07247", "pdf": "https://arxiv.org/pdf/2505.07247", "abs": "https://arxiv.org/abs/2505.07247", "authors": ["Peichao Lai", "Kexuan Zhang", "Yi Lin", "Linyihan Zhang", "Feiyang Ye", "Jinhao Yan", "Yanwei Xu", "Conghui He", "Yilei Wang", "Wentao Zhang", "Bin Cui"], "title": "SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Subjective Answer Grading (SAG) plays a crucial role in education,\nstandardized testing, and automated assessment systems, particularly for\nevaluating short-form responses in Short Answer Scoring (SAS). However,\nexisting approaches often produce coarse-grained scores and lack detailed\nreasoning. Although large language models (LLMs) have demonstrated potential as\nzero-shot evaluators, they remain susceptible to bias, inconsistencies with\nhuman judgment, and limited transparency in scoring decisions. To overcome\nthese limitations, we introduce SAS-Bench, a benchmark specifically designed\nfor LLM-based SAS tasks. SAS-Bench provides fine-grained, step-wise scoring,\nexpert-annotated error categories, and a diverse range of question types\nderived from real-world subject-specific exams. This benchmark facilitates\ndetailed evaluation of model reasoning processes and explainability. We also\nrelease an open-source dataset containing 1,030 questions and 4,109 student\nresponses, each annotated by domain experts. Furthermore, we conduct\ncomprehensive experiments with various LLMs, identifying major challenges in\nscoring science-related questions and highlighting the effectiveness of\nfew-shot prompting in improving scoring accuracy. Our work offers valuable\ninsights into the development of more robust, fair, and educationally\nmeaningful LLM-based evaluation systems.", "AI": {"tldr": "SAS-Bench is a benchmark for LLM-based Short Answer Scoring (SAS) tasks, offering fine-grained scoring, expert annotations, and diverse question types to improve model transparency and accuracy.", "motivation": "Existing SAG methods lack detail and consistency, and LLMs, while promising, suffer from bias and transparency issues.", "method": "Developed SAS-Bench with expert-annotated error categories and diverse questions, tested with various LLMs using few-shot prompting.", "result": "Identified challenges in science-related questions and showed few-shot prompting improves scoring accuracy.", "conclusion": "SAS-Bench aids in creating more robust, fair, and transparent LLM-based evaluation systems."}}
{"id": "2505.06665", "pdf": "https://arxiv.org/pdf/2505.06665", "abs": "https://arxiv.org/abs/2505.06665", "authors": ["Zixian Zhao", "Andrew Howes", "Xingchen Zhang"], "title": "MultiTaskVIF: Segmentation-oriented visible and infrared image fusion via multi-task learning", "categories": ["cs.CV"], "comment": null, "summary": "Visible and infrared image fusion (VIF) has attracted significant attention\nin recent years. Traditional VIF methods primarily focus on generating fused\nimages with high visual quality, while recent advancements increasingly\nemphasize incorporating semantic information into the fusion model during\ntraining. However, most existing segmentation-oriented VIF methods adopt a\ncascade structure comprising separate fusion and segmentation models, leading\nto increased network complexity and redundancy. This raises a critical\nquestion: can we design a more concise and efficient structure to integrate\nsemantic information directly into the fusion model during training-Inspired by\nmulti-task learning, we propose a concise and universal training framework,\nMultiTaskVIF, for segmentation-oriented VIF models. In this framework, we\nintroduce a multi-task head decoder (MTH) to simultaneously output both the\nfused image and the segmentation result during training. Unlike previous\ncascade training frameworks that necessitate joint training with a complete\nsegmentation model, MultiTaskVIF enables the fusion model to learn semantic\nfeatures by simply replacing its decoder with MTH. Extensive experimental\nevaluations validate the effectiveness of the proposed method. Our code will be\nreleased upon acceptance.", "AI": {"tldr": "Proposes MultiTaskVIF, a concise framework for segmentation-oriented visible and infrared image fusion, integrating semantic features directly into the fusion model via a multi-task head decoder.", "motivation": "Existing methods use separate fusion and segmentation models, increasing complexity and redundancy. The goal is to simplify this by directly embedding semantic information into the fusion model.", "method": "Introduces MultiTaskVIF with a multi-task head decoder (MTH) to output fused images and segmentation results simultaneously during training, avoiding the need for a separate segmentation model.", "result": "Experimental evaluations confirm the method's effectiveness in combining fusion and segmentation tasks efficiently.", "conclusion": "MultiTaskVIF offers a simpler, more efficient approach for segmentation-oriented image fusion, validated by experiments."}}
{"id": "2505.07089", "pdf": "https://arxiv.org/pdf/2505.07089", "abs": "https://arxiv.org/abs/2505.07089", "authors": ["Hanzheng Dai", "Yuanliang Li", "Zhibo Zhang", "Jun Yan"], "title": "RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Automated penetration testing (AutoPT) powered by large language models\n(LLMs) has gained attention for its ability to automate ethical hacking\nprocesses and identify vulnerabilities in target systems by leveraging the\nintrinsic knowledge of LLMs. However, existing LLM-based AutoPT frameworks\noften underperform compared to human experts in challenging tasks for several\nreasons: the imbalanced knowledge used in LLM training, short-sighted planning\nin the planning process, and hallucinations during command generation. In\naddition, the penetration testing (PT) process, with its trial-and-error\nnature, is limited by existing frameworks that lack mechanisms to learn from\nprevious failed operations, restricting adaptive improvement of PT strategies.\nTo address these limitations, we propose a knowledge-informed self-reflective\nPT framework powered by LLMs, called RefPentester, which is an AutoPT framework\ndesigned to assist human operators in identifying the current stage of the PT\nprocess, selecting appropriate tactic and technique for the stage, choosing\nsuggested action, providing step-by-step operational guidance, and learning\nfrom previous failed operations. We also modeled the PT process as a\nseven-state Stage Machine to integrate the proposed framework effectively. The\nevaluation shows that RefPentester can successfully reveal credentials on Hack\nThe Box's Sau machine, outperforming the baseline GPT-4o model by 16.7\\%.\nAcross PT stages, RefPentester also demonstrates superior success rates on PT\nstage transitions.", "AI": {"tldr": "RefPentester, a knowledge-informed self-reflective AutoPT framework, outperforms GPT-4o by 16.7% in identifying vulnerabilities by learning from failures and improving PT strategies.", "motivation": "Existing LLM-based AutoPT frameworks underperform due to imbalanced knowledge, short-sighted planning, and hallucinations. They also lack mechanisms to learn from failed operations.", "method": "Proposed RefPentester integrates a seven-state Stage Machine to guide PT stages, select tactics, and learn from failures.", "result": "RefPentester outperforms GPT-4o by 16.7% in revealing credentials and shows superior success rates in PT stage transitions.", "conclusion": "RefPentester addresses key limitations of LLM-based AutoPT, enhancing adaptive learning and performance in penetration testing."}}
{"id": "2505.06316", "pdf": "https://arxiv.org/pdf/2505.06316", "abs": "https://arxiv.org/abs/2505.06316", "authors": ["Guozhong Li", "Muhannad Alhumaidi", "Spiros Skiadopoulos", "Ibrahim Hoteit", "Panos Kalnis"], "title": "GraphComp: Extreme Error-bounded Compression of Scientific Data via Temporal Graph Autoencoders", "categories": ["cs.LG"], "comment": null, "summary": "The generation of voluminous scientific data poses significant challenges for\nefficient storage, transfer, and analysis. Recently, error-bounded lossy\ncompression methods emerged due to their ability to achieve high compression\nratios while controlling data distortion. However, they often overlook the\ninherent spatial and temporal correlations within scientific data, thus missing\nopportunities for higher compression. In this paper we propose GRAPHCOMP, a\nnovel graph-based method for error-bounded lossy compression of scientific\ndata. We perform irregular segmentation of the original grid data and generate\na graph representation that preserves the spatial and temporal correlations.\nInspired by Graph Neural Networks (GNNs), we then propose a temporal graph\nautoencoder to learn latent representations that significantly reduce the size\nof the graph, effectively compressing the original data. Decompression reverses\nthe process and utilizes the learnt graph model together with the latent\nrepresentation to reconstruct an approximation of the original data. The\ndecompressed data are guaranteed to satisfy a user-defined point-wise error\nbound. We compare our method against the state-of-the-art error-bounded lossy\nmethods (i.e., HPEZ, SZ3.1, SPERR, and ZFP) on large-scale real and synthetic\ndata. GRAPHCOMP consistently achieves the highest compression ratio across most\ndatasets, outperforming the second-best method by margins ranging from 22% to\n50%.", "AI": {"tldr": "GRAPHCOMP, a graph-based error-bounded lossy compression method, leverages spatial and temporal correlations in scientific data for higher compression ratios, outperforming state-of-the-art methods by 22-50%.", "motivation": "Existing error-bounded lossy compression methods often ignore spatial and temporal correlations in scientific data, limiting compression efficiency.", "method": "GRAPHCOMP uses irregular segmentation and a graph representation, combined with a temporal graph autoencoder inspired by GNNs, to compress data while preserving correlations.", "result": "GRAPHCOMP achieves the highest compression ratios, outperforming other methods by 22-50% on real and synthetic datasets.", "conclusion": "GRAPHCOMP effectively addresses the limitations of existing methods by leveraging graph-based techniques, offering superior compression for scientific data."}}
{"id": "2505.07258", "pdf": "https://arxiv.org/pdf/2505.07258", "abs": "https://arxiv.org/abs/2505.07258", "authors": ["Wenqiang Wang", "Siyuan Liang", "Yangshijie Zhang", "Xiaojun Jia", "Hao Lin", "Xiaochun Cao"], "title": "No Query, No Access", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Textual adversarial attacks mislead NLP models, including Large Language\nModels (LLMs), by subtly modifying text. While effective, existing attacks\noften require knowledge of the victim model, extensive queries, or access to\ntraining data, limiting real-world feasibility. To overcome these constraints,\nwe introduce the \\textbf{Victim Data-based Adversarial Attack (VDBA)}, which\noperates using only victim texts. To prevent access to the victim model, we\ncreate a shadow dataset with publicly available pre-trained models and\nclustering methods as a foundation for developing substitute models. To address\nthe low attack success rate (ASR) due to insufficient information feedback, we\npropose the hierarchical substitution model design, generating substitute\nmodels to mitigate the failure of a single substitute model at the decision\nboundary.\n  Concurrently, we use diverse adversarial example generation, employing\nvarious attack methods to generate and select the adversarial example with\nbetter similarity and attack effectiveness. Experiments on the Emotion and SST5\ndatasets show that VDBA outperforms state-of-the-art methods, achieving an ASR\nimprovement of 52.08\\% while significantly reducing attack queries to 0. More\nimportantly, we discover that VDBA poses a significant threat to LLMs such as\nQwen2 and the GPT family, and achieves the highest ASR of 45.99% even without\naccess to the API, confirming that advanced NLP models still face serious\nsecurity risks. Our codes can be found at\nhttps://anonymous.4open.science/r/VDBA-Victim-Data-based-Adversarial-Attack-36EC/", "AI": {"tldr": "VDBA is a novel adversarial attack method using only victim texts, outperforming existing methods with higher ASR and fewer queries, posing threats to LLMs.", "motivation": "Existing adversarial attacks require model knowledge, queries, or training data, limiting practicality. VDBA aims to overcome these constraints.", "method": "VDBA uses victim texts, creates a shadow dataset with pre-trained models and clustering, and employs hierarchical substitution models and diverse adversarial example generation.", "result": "VDBA improves ASR by 52.08%, reduces queries to 0, and achieves 45.99% ASR on LLMs without API access.", "conclusion": "VDBA demonstrates serious security risks for advanced NLP models, even without direct access."}}
{"id": "2505.06670", "pdf": "https://arxiv.org/pdf/2505.06670", "abs": "https://arxiv.org/abs/2505.06670", "authors": ["Zhe Li", "Hadrien Reynaud", "Mischa Dombrowski", "Sarah Cechnicka", "Franciskus Xaverius Erick", "Bernhard Kainz"], "title": "Video Dataset Condensation with Diffusion Models", "categories": ["cs.CV"], "comment": "10 pages", "summary": "In recent years, the rapid expansion of dataset sizes and the increasing\ncomplexity of deep learning models have significantly escalated the demand for\ncomputational resources, both for data storage and model training. Dataset\ndistillation has emerged as a promising solution to address this challenge by\ngenerating a compact synthetic dataset that retains the essential information\nfrom a large real dataset. However, existing methods often suffer from limited\nperformance and poor data quality, particularly in the video domain. In this\npaper, we focus on video dataset distillation by employing a video diffusion\nmodel to generate high-quality synthetic videos. To enhance representativeness,\nwe introduce Video Spatio-Temporal U-Net (VST-UNet), a model designed to select\na diverse and informative subset of videos that effectively captures the\ncharacteristics of the original dataset. To further optimize computational\nefficiency, we explore a training-free clustering algorithm, Temporal-Aware\nCluster-based Distillation (TAC-DT), to select representative videos without\nrequiring additional training overhead. We validate the effectiveness of our\napproach through extensive experiments on four benchmark datasets,\ndemonstrating performance improvements of up to \\(10.61\\%\\) over the\nstate-of-the-art. Our method consistently outperforms existing approaches\nacross all datasets, establishing a new benchmark for video dataset\ndistillation.", "AI": {"tldr": "The paper introduces a video dataset distillation method using a video diffusion model and VST-UNet to generate high-quality synthetic videos, achieving a 10.61% performance boost over existing methods.", "motivation": "Addressing the computational demands of large datasets and poor performance of existing video dataset distillation methods.", "method": "Uses a video diffusion model and VST-UNet for synthetic video generation, coupled with TAC-DT for efficient clustering.", "result": "Achieves up to 10.61% improvement over state-of-the-art methods across four benchmark datasets.", "conclusion": "Sets a new benchmark for video dataset distillation with superior performance and computational efficiency."}}
{"id": "2505.07171", "pdf": "https://arxiv.org/pdf/2505.07171", "abs": "https://arxiv.org/abs/2505.07171", "authors": ["Jeongho Kim", "Chanyeong Heo", "Jaehee Jung"], "title": "ReCDAP: Relation-Based Conditional Diffusion with Attention Pooling for Few-Shot Knowledge Graph Completion", "categories": ["cs.AI", "cs.IR"], "comment": "Accepted by SIGIR 2025, 5 pages, 1 figure", "summary": "Knowledge Graphs (KGs), composed of triples in the form of (head, relation,\ntail) and consisting of entities and relations, play a key role in information\nretrieval systems such as question answering, entity search, and\nrecommendation. In real-world KGs, although many entities exist, the relations\nexhibit a long-tail distribution, which can hinder information retrieval\nperformance. Previous few-shot knowledge graph completion studies focused\nexclusively on the positive triple information that exists in the graph or,\nwhen negative triples were incorporated, used them merely as a signal to\nindicate incorrect triples. To overcome this limitation, we propose\nRelation-Based Conditional Diffusion with Attention Pooling (ReCDAP). First,\nnegative triples are generated by randomly replacing the tail entity in the\nsupport set. By conditionally incorporating positive information in the KG and\nnon-existent negative information into the diffusion process, the model\nseparately estimates the latent distributions for positive and negative\nrelations. Moreover, including an attention pooler enables the model to\nleverage the differences between positive and negative cases explicitly.\nExperiments on two widely used datasets demonstrate that our method outperforms\nexisting approaches, achieving state-of-the-art performance. The code is\navailable at https://github.com/hou27/ReCDAP-FKGC.", "AI": {"tldr": "The paper proposes ReCDAP, a method for few-shot KG completion that leverages both positive and negative triples to improve performance.", "motivation": "Existing KG completion methods focus only on positive triples or use negative triples minimally, limiting performance.", "method": "ReCDAP generates negative triples, incorporates them conditionally in a diffusion process, and uses attention pooling to distinguish positive and negative relations.", "result": "ReCDAP outperforms existing methods on two datasets, achieving state-of-the-art results.", "conclusion": "The proposed method effectively improves KG completion by utilizing both positive and negative information."}}
{"id": "2505.06319", "pdf": "https://arxiv.org/pdf/2505.06319", "abs": "https://arxiv.org/abs/2505.06319", "authors": ["Zijian An", "Lifeng Zhou"], "title": "Reinforcement Learning for Game-Theoretic Resource Allocation on Graphs", "categories": ["cs.LG", "cs.GT"], "comment": "12 pages, 7 figures", "summary": "Game-theoretic resource allocation on graphs (GRAG) involves two players\ncompeting over multiple steps to control nodes of interest on a graph, a\nproblem modeled as a multi-step Colonel Blotto Game (MCBG). Finding optimal\nstrategies is challenging due to the dynamic action space and structural\nconstraints imposed by the graph. To address this, we formulate the MCBG as a\nMarkov Decision Process (MDP) and apply Reinforcement Learning (RL) methods,\nspecifically Deep Q-Network (DQN) and Proximal Policy Optimization (PPO). To\nenforce graph constraints, we introduce an action-displacement adjacency matrix\nthat dynamically generates valid action sets at each step. We evaluate RL\nperformance across a variety of graph structures and initial resource\ndistributions, comparing against random, greedy, and learned RL policies.\nExperimental results show that both DQN and PPO consistently outperform\nbaseline strategies and converge to a balanced $50\\%$ win rate when competing\nagainst the learned RL policy. Particularly, on asymmetric graphs, RL agents\nsuccessfully exploit structural advantages and adapt their allocation\nstrategies, even under disadvantageous initial resource distributions.", "AI": {"tldr": "The paper applies RL methods (DQN and PPO) to solve the multi-step Colonel Blotto Game on graphs, introducing an action-displacement matrix to handle constraints. RL outperforms baselines, achieving balanced win rates and exploiting graph asymmetries.", "motivation": "The challenge of finding optimal strategies in dynamic, graph-constrained resource allocation games motivates the use of RL to handle complex action spaces and structural constraints.", "method": "Formulates the problem as an MDP, uses DQN and PPO with an action-displacement adjacency matrix to enforce graph constraints, and compares RL policies against random, greedy, and learned baselines.", "result": "RL methods (DQN and PPO) consistently outperform baselines, achieving a 50% win rate against learned policies and exploiting graph asymmetries effectively.", "conclusion": "RL is effective for graph-based resource allocation games, adapting to structural advantages and initial resource imbalances."}}
{"id": "2505.07271", "pdf": "https://arxiv.org/pdf/2505.07271", "abs": "https://arxiv.org/abs/2505.07271", "authors": ["Jiwoo Hong", "Noah Lee", "Eunki Kim", "Guijin Son", "Woojin Chung", "Aman Gupta", "Shao Tang", "James Thorne"], "title": "On the Robustness of Reward Models for Language Model Alignment", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICML 2025", "summary": "The Bradley-Terry (BT) model is widely practiced in reward modeling for\nreinforcement learning with human feedback (RLHF). Despite its effectiveness,\nreward models (RMs) trained with BT model loss are prone to over-optimization,\nlosing generalizability to unseen input distributions. In this paper, we study\nthe cause of over-optimization in RM training and its downstream effects on the\nRLHF procedure, accentuating the importance of distributional robustness of RMs\nin unseen data. First, we show that the excessive dispersion of hidden state\nnorms is the main source of over-optimization. Then, we propose batch-wise\nsum-to-zero regularization (BSR) to enforce zero-centered reward sum per batch,\nconstraining the rewards with extreme magnitudes. We assess the impact of BSR\nin improving robustness in RMs through four scenarios of over-optimization,\nwhere BSR consistently manifests better robustness. Subsequently, we compare\nthe plain BT model and BSR on RLHF training and empirically show that robust\nRMs better align the policy to the gold preference model. Finally, we apply BSR\nto high-quality data and models, which surpasses state-of-the-art RMs in the 8B\nscale by adding more than 5% in complex preference prediction tasks. By\nconducting RLOO training with 8B RMs, AlpacaEval 2.0 reduces generation length\nby 40% while adding a 7% increase in win rate, further highlighting that\nrobustness in RMs induces robustness in RLHF training. We release the code,\ndata, and models: https://github.com/LinkedIn-XFACT/RM-Robustness.", "AI": {"tldr": "The paper investigates over-optimization in reward models (RMs) trained with the Bradley-Terry (BT) model, identifies excessive dispersion of hidden state norms as the cause, and proposes batch-wise sum-to-zero regularization (BSR) to improve robustness. BSR enhances RM performance and RLHF alignment, outperforming state-of-the-art models.", "motivation": "Over-optimization in BT-based RMs reduces generalizability to unseen data, impacting RLHF effectiveness. The study aims to address this by improving RM robustness.", "method": "The paper identifies hidden state norm dispersion as the issue and introduces BSR to constrain reward magnitudes. It evaluates BSR in four over-optimization scenarios and compares it to plain BT models in RLHF training.", "result": "BSR improves RM robustness, outperforming plain BT models. It enhances complex preference prediction by 5% and RLHF alignment, reducing generation length by 40% while increasing win rate by 7%.", "conclusion": "Robust RMs, achieved via BSR, significantly improve RLHF performance and alignment, demonstrating the importance of distributional robustness in reward modeling."}}
{"id": "2505.06679", "pdf": "https://arxiv.org/pdf/2505.06679", "abs": "https://arxiv.org/abs/2505.06679", "authors": ["Jiayang Liu", "Siyuan Liang", "Shiqian Zhao", "Rongcheng Tu", "Wenbo Zhou", "Xiaochun Cao", "Dacheng Tao", "Siew Kei Lam"], "title": "Jailbreaking the Text-to-Video Generative Models", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-video generative models have achieved significant progress, driven by\nthe rapid advancements in diffusion models, with notable examples including\nPika, Luma, Kling, and Sora. Despite their remarkable generation ability, their\nvulnerability to jailbreak attack, i.e. to generate unsafe content, including\npornography, violence, and discrimination, raises serious safety concerns.\nExisting efforts, such as T2VSafetyBench, have provided valuable benchmarks for\nevaluating the safety of text-to-video models against unsafe prompts but lack\nsystematic studies for exploiting their vulnerabilities effectively. In this\npaper, we propose the \\textit{first} optimization-based jailbreak attack\nagainst text-to-video models, which is specifically designed. Our approach\nformulates the prompt generation task as an optimization problem with three key\nobjectives: (1) maximizing the semantic similarity between the input and\ngenerated prompts, (2) ensuring that the generated prompts can evade the safety\nfilter of the text-to-video model, and (3) maximizing the semantic similarity\nbetween the generated videos and the original input prompts. To further enhance\nthe robustness of the generated prompts, we introduce a prompt mutation\nstrategy that creates multiple prompt variants in each iteration, selecting the\nmost effective one based on the averaged score. This strategy not only improves\nthe attack success rate but also boosts the semantic relevance of the generated\nvideo. We conduct extensive experiments across multiple text-to-video models,\nincluding Open-Sora, Pika, Luma, and Kling. The results demonstrate that our\nmethod not only achieves a higher attack success rate compared to baseline\nmethods but also generates videos with greater semantic similarity to the\noriginal input prompts.", "AI": {"tldr": "The paper introduces an optimization-based jailbreak attack for text-to-video models, focusing on bypassing safety filters while maintaining semantic relevance in generated videos.", "motivation": "Despite advancements in text-to-video models, their vulnerability to generating unsafe content (e.g., pornography, violence) remains a concern. Existing benchmarks lack systematic studies on exploiting these vulnerabilities.", "method": "The approach formulates prompt generation as an optimization problem with three objectives: semantic similarity, evasion of safety filters, and video relevance. A prompt mutation strategy enhances robustness.", "result": "Experiments on models like Open-Sora, Pika, Luma, and Kling show higher attack success rates and better semantic similarity compared to baselines.", "conclusion": "The proposed method effectively exploits vulnerabilities in text-to-video models, highlighting the need for stronger safety measures."}}
{"id": "2505.07178", "pdf": "https://arxiv.org/pdf/2505.07178", "abs": "https://arxiv.org/abs/2505.07178", "authors": ["Yuri Nakao"], "title": "Accountability of Generative AI: Exploring a Precautionary Approach for \"Artificially Created Nature\"", "categories": ["cs.AI"], "comment": null, "summary": "The rapid development of generative artificial intelligence (AI) technologies\nraises concerns about the accountability of sociotechnical systems. Current\ngenerative AI systems rely on complex mechanisms that make it difficult for\neven experts to fully trace the reasons behind the outputs. This paper first\nexamines existing research on AI transparency and accountability and argues\nthat transparency is not a sufficient condition for accountability but can\ncontribute to its improvement. We then discuss that if it is not possible to\nmake generative AI transparent, generative AI technology becomes ``artificially\ncreated nature'' in a metaphorical sense, and suggest using the precautionary\nprinciple approach to consider AI risks. Finally, we propose that a platform\nfor citizen participation is needed to address the risks of generative AI.", "AI": {"tldr": "The paper discusses the accountability challenges of generative AI, arguing transparency alone isn't enough for accountability. It suggests using the precautionary principle and citizen participation to address risks.", "motivation": "Concerns about the accountability of generative AI systems due to their complexity and lack of transparency.", "method": "Examines AI transparency research, argues its insufficiency for accountability, and proposes the precautionary principle and citizen participation.", "result": "Transparency is insufficient for accountability; generative AI may become \"artificially created nature,\" requiring precautionary measures and public involvement.", "conclusion": "A platform for citizen participation is essential to mitigate generative AI risks, alongside the precautionary principle."}}
{"id": "2505.06320", "pdf": "https://arxiv.org/pdf/2505.06320", "abs": "https://arxiv.org/abs/2505.06320", "authors": ["Jan Ko\u015bcia\u0142kowski", "Pawe\u0142 Marcinkowski"], "title": "Divide (Text) and Conquer (Sentiment): Improved Sentiment Classification by Constituent Conflict Resolution", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "8 pages, 6 figures, 4 tables, developed as a final project for the\n  Stanford Center for Professional Education XCS224U (Natural Language\n  Understanding) course", "summary": "Sentiment classification, a complex task in natural language processing,\nbecomes even more challenging when analyzing passages with multiple conflicting\ntones. Typically, longer passages exacerbate this issue, leading to decreased\nmodel performance. The aim of this paper is to introduce novel methodologies\nfor isolating conflicting sentiments and aggregating them to effectively\npredict the overall sentiment of such passages. One of the aggregation\nstrategies involves a Multi-Layer Perceptron (MLP) model which outperforms\nbaseline models across various datasets, including Amazon, Twitter, and SST\nwhile costing $\\sim$1/100 of what fine-tuning the baseline would take.", "AI": {"tldr": "The paper introduces new methods for handling conflicting sentiments in long passages, using an MLP model that outperforms baselines at a fraction of the cost.", "motivation": "Sentiment classification is challenging for passages with conflicting tones, especially longer ones, leading to poor model performance.", "method": "Novel methodologies for isolating and aggregating conflicting sentiments, including an MLP model.", "result": "The MLP model outperforms baseline models on datasets like Amazon, Twitter, and SST, costing ~1/100 of fine-tuning baselines.", "conclusion": "The proposed MLP-based approach effectively predicts overall sentiment in complex passages while being cost-efficient."}}
{"id": "2505.07289", "pdf": "https://arxiv.org/pdf/2505.07289", "abs": "https://arxiv.org/abs/2505.07289", "authors": ["Stanislas Laborde", "Martin Cousseau", "Antoun Yaacoub", "Lionel Prevost"], "title": "Semantic Retention and Extreme Compression in LLMs: Can We Have Both?", "categories": ["cs.CL", "cs.AI", "cs.LG", "68P30 (Primary) 68T07, 68T50 (Secondary)", "I.2.6; I.5.1; I.2.7"], "comment": "Accepted for publication in the Proceedings of the 2025 International\n  Joint Conference on Neural Networks (IJCNN); this arXiv version includes an\n  appendix with 6 result tables; 10 pages, 15 figures, 7 tables", "summary": "The exponential growth in Large Language Model (LLM) deployment has\nintensified the need for efficient model compression techniques to reduce\ncomputational and memory costs. While pruning and quantization have shown\npromise, their combined potential remains largely unexplored. In this paper, we\nexamine joint compression and how strategically combining pruning and\nquantization could yield superior performance-to-compression ratios compared to\nsingle-method approaches. Recognizing the challenges in accurately assessing\nLLM performance, we address key limitations of previous evaluation frameworks\nand introduce the Semantic Retention Compression Rate (SrCr), a novel metric\nthat quantifies the trade-off between model compression and semantic\npreservation, facilitating the optimization of pruning-quantization\nconfigurations. Experiments demonstrate that our recommended combination\nachieves, on average, a 20% performance increase compared to an equivalent\nquantization-only model at the same theoretical compression rate.", "AI": {"tldr": "The paper explores joint compression of LLMs by combining pruning and quantization, introducing the SrCr metric to optimize performance-to-compression ratios, achieving a 20% performance boost over quantization-only methods.", "motivation": "The rapid deployment of LLMs necessitates efficient compression techniques to reduce computational and memory costs, but the combined potential of pruning and quantization is underexplored.", "method": "The study examines joint compression by strategically combining pruning and quantization, introduces the SrCr metric to evaluate semantic preservation, and optimizes configurations.", "result": "Experiments show the recommended combination achieves a 20% performance increase over quantization-only models at the same compression rate.", "conclusion": "Joint compression with pruning and quantization, guided by the SrCr metric, offers superior performance-to-compression ratios for LLMs."}}
{"id": "2505.06683", "pdf": "https://arxiv.org/pdf/2505.06683", "abs": "https://arxiv.org/abs/2505.06683", "authors": ["Chunming He", "Rihan Zhang", "Fengyang Xiao", "Chengyu Fang", "Longxiang Tang", "Yulun Zhang", "Sina Farsiu"], "title": "UnfoldIR: Rethinking Deep Unfolding Network in Illumination Degradation Image Restoration", "categories": ["cs.CV"], "comment": "16 pages, 14 tables, 11 figures", "summary": "Deep unfolding networks (DUNs) are widely employed in illumination\ndegradation image restoration (IDIR) to merge the interpretability of\nmodel-based approaches with the generalization of learning-based methods.\nHowever, the performance of DUN-based methods remains considerably inferior to\nthat of state-of-the-art IDIR solvers. Our investigation indicates that this\nlimitation does not stem from structural shortcomings of DUNs but rather from\nthe limited exploration of the unfolding structure, particularly for (1)\nconstructing task-specific restoration models, (2) integrating advanced network\narchitectures, and (3) designing DUN-specific loss functions. To address these\nissues, we propose a novel DUN-based method, UnfoldIR, for IDIR tasks. UnfoldIR\nfirst introduces a new IDIR model with dedicated regularization terms for\nsmoothing illumination and enhancing texture. We unfold the iterative optimized\nsolution of this model into a multistage network, with each stage comprising a\nreflectance-assisted illumination correction (RAIC) module and an\nillumination-guided reflectance enhancement (IGRE) module. RAIC employs a\nvisual state space (VSS) to extract non-local features, enforcing illumination\nsmoothness, while IGRE introduces a frequency-aware VSS to globally align\nsimilar textures, enabling mildly degraded regions to guide the enhancement of\ndetails in more severely degraded areas. This suppresses noise while enhancing\ndetails. Furthermore, given the multistage structure, we propose an inter-stage\ninformation consistent loss to maintain network stability in the final stages.\nThis loss contributes to structural preservation and sustains the model's\nperformance even in unsupervised settings. Experiments verify our effectiveness\nacross 5 IDIR tasks and 3 downstream problems.", "AI": {"tldr": "UnfoldIR, a novel deep unfolding network (DUN), addresses limitations in illumination degradation image restoration (IDIR) by integrating task-specific models, advanced architectures, and DUN-specific loss functions, outperforming existing methods.", "motivation": "Current DUN-based IDIR methods underperform due to insufficient exploration of unfolding structures, including task-specific models, advanced architectures, and loss functions.", "method": "UnfoldIR introduces a multistage network with reflectance-assisted illumination correction (RAIC) and illumination-guided reflectance enhancement (IGRE) modules, leveraging visual state space (VSS) for feature extraction and alignment.", "result": "UnfoldIR achieves superior performance in 5 IDIR tasks and 3 downstream problems, demonstrating noise suppression and detail enhancement.", "conclusion": "UnfoldIR effectively bridges the gap between model interpretability and learning-based generalization, setting a new benchmark for DUN-based IDIR methods."}}
{"id": "2505.07215", "pdf": "https://arxiv.org/pdf/2505.07215", "abs": "https://arxiv.org/abs/2505.07215", "authors": ["Vivek Verma", "David Huang", "William Chen", "Dan Klein", "Nicholas Tomlin"], "title": "Measuring General Intelligence with Generated Games", "categories": ["cs.AI"], "comment": null, "summary": "We present gg-bench, a collection of game environments designed to evaluate\ngeneral reasoning capabilities in language models. Unlike most static\nbenchmarks, gg-bench is a data generating process where new evaluation\ninstances can be generated at will. In particular, gg-bench is synthetically\ngenerated by (1) using a large language model (LLM) to generate natural\nlanguage descriptions of novel games, (2) using the LLM to implement each game\nin code as a Gym environment, and (3) training reinforcement learning (RL)\nagents via self-play on the generated games. We evaluate language models by\ntheir winrate against these RL agents by prompting models with the game\ndescription, current board state, and a list of valid moves, after which models\noutput the moves they wish to take. gg-bench is challenging: state-of-the-art\nLLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench\nusing in-context learning, while reasoning models such as o1, o3-mini and\nDeepSeek-R1 achieve average winrates of 31-36%. We release the generated games,\ndata generation process, and evaluation code in order to support future\nmodeling work and expansion of our benchmark.", "AI": {"tldr": "gg-bench is a dynamic benchmark for evaluating general reasoning in language models using synthetic game environments generated by LLMs and tested via RL agents.", "motivation": "To create a flexible and challenging benchmark for assessing language models' reasoning abilities beyond static datasets.", "method": "Generates novel games via LLMs, implements them as Gym environments, and evaluates models by their winrate against RL agents trained via self-play.", "result": "State-of-the-art LLMs like GPT-4o achieve low winrates (7-9%), while reasoning models like o1 and DeepSeek-R1 perform better (31-36%).", "conclusion": "gg-bench provides a scalable and challenging benchmark for future research, with released resources for expansion."}}
{"id": "2505.06321", "pdf": "https://arxiv.org/pdf/2505.06321", "abs": "https://arxiv.org/abs/2505.06321", "authors": ["Hang Gao", "Chenhao Zhang", "Tie Wang", "Junsuo Zhao", "Fengge Wu", "Changwen Zheng", "Huaping Liu"], "title": "Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Large Language Models (LLMs) have achieved remarkable success across various\ndomains. However, they still face significant challenges, including high\ncomputational costs for training and limitations in solving complex reasoning\nproblems. Although existing methods have extended the reasoning capabilities of\nLLMs through structured paradigms, these approaches often rely on task-specific\nprompts and predefined reasoning processes, which constrain their flexibility\nand generalizability. To address these limitations, we propose a novel\nframework that leverages graph learning to enable more flexible and adaptive\nreasoning capabilities for LLMs. Specifically, this approach models the\nreasoning process of a problem as a graph and employs LLM-based graph learning\nto guide the adaptive generation of each reasoning step. To further enhance the\nadaptability of the model, we introduce a Graph Neural Network (GNN) module to\nperform representation learning on the generated reasoning process, enabling\nreal-time adjustments to both the model and the prompt. Experimental results\ndemonstrate that this method significantly improves reasoning performance\nacross multiple tasks without requiring additional training or task-specific\nprompt design. Code can be found in https://github.com/zch65458525/L2T.", "AI": {"tldr": "A novel framework using graph learning and GNNs enhances LLMs' reasoning flexibility and performance without extra training or task-specific prompts.", "motivation": "Addressing LLMs' limitations in computational cost and complex reasoning by improving flexibility and generalizability.", "method": "Models reasoning as a graph, uses LLM-based graph learning, and integrates a GNN for adaptive representation learning.", "result": "Significant improvement in reasoning performance across tasks without additional training or prompt design.", "conclusion": "The framework effectively enhances LLMs' reasoning capabilities adaptively and flexibly."}}
{"id": "2505.07293", "pdf": "https://arxiv.org/pdf/2505.07293", "abs": "https://arxiv.org/abs/2505.07293", "authors": ["Kai Hua", "Steven Wu", "Ge Zhang", "Ke Shen"], "title": "AttentionInfluence: Adopting Attention Head Influence for Weak-to-Strong Pretraining Data Selection", "categories": ["cs.CL"], "comment": "28 pages, 19 figures", "summary": "Recently, there has been growing interest in collecting reasoning-intensive\npretraining data to improve LLMs' complex reasoning ability. Prior approaches\ntypically rely on supervised classifiers to identify such data, which requires\nlabeling by humans or LLMs, often introducing domain-specific biases. Due to\nthe attention heads being crucial to in-context reasoning, we propose\nAttentionInfluence, a simple yet effective, training-free method without\nsupervision signal. Our approach enables a small pretrained language model to\nact as a strong data selector through a simple attention head masking\noperation. Specifically, we identify retrieval heads and compute the loss\ndifference when masking these heads. We apply AttentionInfluence to a\n1.3B-parameter dense model to conduct data selection on the SmolLM corpus of\n241B tokens, and mix the SmolLM corpus with the selected subset comprising 73B\ntokens to pretrain a 7B-parameter dense model using 1T training tokens and WSD\nlearning rate scheduling. Our experimental results demonstrate substantial\nimprovements, ranging from 1.4pp to 3.5pp, across several knowledge-intensive\nand reasoning-heavy benchmarks (i.e., MMLU, MMLU-Pro, AGIEval-en, GSM8K, and\nHumanEval). This demonstrates an effective weak-to-strong scaling property,\nwith small models improving the final performance of larger models-offering a\npromising and scalable path for reasoning-centric data selection.", "AI": {"tldr": "AttentionInfluence is a training-free method for selecting reasoning-intensive pretraining data by masking attention heads, improving LLMs' reasoning performance.", "motivation": "To avoid biases from supervised classifiers in selecting reasoning data, leveraging attention heads for unsupervised selection.", "method": "Uses attention head masking to identify retrieval heads, computes loss differences, and selects data for pretraining.", "result": "Improves performance by 1.4pp to 3.5pp on reasoning-heavy benchmarks like MMLU and GSM8K.", "conclusion": "AttentionInfluence offers a scalable, unsupervised approach for enhancing reasoning in LLMs."}}
{"id": "2505.06684", "pdf": "https://arxiv.org/pdf/2505.06684", "abs": "https://arxiv.org/abs/2505.06684", "authors": ["Xuefeng Jiang", "Jia Li", "Nannan Wu", "Zhiyuan Wu", "Xujing Li", "Sheng Sun", "Gang Xu", "Yuwei Wang", "Qi Li", "Min Liu"], "title": "FNBench: Benchmarking Robust Federated Learning against Noisy Labels", "categories": ["cs.CV", "cs.AI"], "comment": "Submitted to IEEE TDSC, currently under major revision", "summary": "Robustness to label noise within data is a significant challenge in federated\nlearning (FL). From the data-centric perspective, the data quality of\ndistributed datasets can not be guaranteed since annotations of different\nclients contain complicated label noise of varying degrees, which causes the\nperformance degradation. There have been some early attempts to tackle noisy\nlabels in FL. However, there exists a lack of benchmark studies on\ncomprehensively evaluating their practical performance under unified settings.\nTo this end, we propose the first benchmark study FNBench to provide an\nexperimental investigation which considers three diverse label noise patterns\ncovering synthetic label noise, imperfect human-annotation errors and\nsystematic errors. Our evaluation incorporates eighteen state-of-the-art\nmethods over five image recognition datasets and one text classification\ndataset. Meanwhile, we provide observations to understand why noisy labels\nimpair FL, and additionally exploit a representation-aware regularization\nmethod to enhance the robustness of existing methods against noisy labels based\non our observations. Finally, we discuss the limitations of this work and\npropose three-fold future directions. To facilitate related communities, our\nsource code is open-sourced at https://github.com/Sprinter1999/FNBench.", "AI": {"tldr": "FNBench is the first benchmark study evaluating label noise robustness in federated learning, testing 18 methods across diverse noise patterns and datasets, and proposing a regularization method to improve robustness.", "motivation": "Addressing the lack of comprehensive benchmarks for evaluating label noise robustness in federated learning, given the varying data quality and noise levels across clients.", "method": "Proposes FNBench, a benchmark study evaluating 18 methods under unified settings, covering synthetic, human-annotation, and systematic label noise patterns. Also introduces a representation-aware regularization method.", "result": "Evaluations on five image and one text dataset reveal insights into how noisy labels impair FL. The proposed regularization method enhances robustness.", "conclusion": "FNBench fills a gap in FL research by providing a standardized evaluation framework. Future directions include addressing limitations and advancing noise-robust FL methods."}}
{"id": "2505.07299", "pdf": "https://arxiv.org/pdf/2505.07299", "abs": "https://arxiv.org/abs/2505.07299", "authors": ["Andr\u00e9 Artelt", "Stelios G. Vrachimis", "Demetrios G. Eliades", "Ulrike Kuhl", "Barbara Hammer", "Marios M. Polycarpou"], "title": "Interpretable Event Diagnosis in Water Distribution Networks", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The increasing penetration of information and communication technologies in\nthe design, monitoring, and control of water systems enables the use of\nalgorithms for detecting and identifying unanticipated events (such as leakages\nor water contamination) using sensor measurements. However, data-driven\nmethodologies do not always give accurate results and are often not trusted by\noperators, who may prefer to use their engineering judgment and experience to\ndeal with such events.\n  In this work, we propose a framework for interpretable event diagnosis -- an\napproach that assists the operators in associating the results of algorithmic\nevent diagnosis methodologies with their own intuition and experience. This is\nachieved by providing contrasting (i.e., counterfactual) explanations of the\nresults provided by fault diagnosis algorithms; their aim is to improve the\nunderstanding of the algorithm's inner workings by the operators, thus enabling\nthem to take a more informed decision by combining the results with their\npersonal experiences. Specifically, we propose counterfactual event\nfingerprints, a representation of the difference between the current event\ndiagnosis and the closest alternative explanation, which can be presented in a\ngraphical way. The proposed methodology is applied and evaluated on a realistic\nuse case using the L-Town benchmark.", "AI": {"tldr": "A framework for interpretable event diagnosis in water systems using counterfactual explanations to bridge algorithmic results and operator intuition.", "motivation": "Operators often distrust data-driven methodologies for event diagnosis, preferring their own judgment. The goal is to enhance trust and understanding by providing interpretable explanations.", "method": "Proposes counterfactual event fingerprints to contrast algorithmic results with alternative explanations, presented graphically.", "result": "Applied and evaluated on the L-Town benchmark, showing potential to improve operator decision-making.", "conclusion": "The framework aids operators in combining algorithmic insights with their experience, fostering better trust and informed decisions."}}
{"id": "2505.06325", "pdf": "https://arxiv.org/pdf/2505.06325", "abs": "https://arxiv.org/abs/2505.06325", "authors": ["Daniel Geissler", "Lars Krupp", "Vishal Banwari", "David Habusch", "Bo Zhou", "Paul Lukowicz", "Jakob Karolus"], "title": "Human in the Latent Loop (HILL): Interactively Guiding Model Training Through Human Intuition", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Latent space representations are critical for understanding and improving the\nbehavior of machine learning models, yet they often remain obscure and\nintricate. Understanding and exploring the latent space has the potential to\ncontribute valuable human intuition and expertise about respective domains. In\nthis work, we present HILL, an interactive framework allowing users to\nincorporate human intuition into the model training by interactively reshaping\nlatent space representations. The modifications are infused into the model\ntraining loop via a novel approach inspired by knowledge distillation, treating\nthe user's modifications as a teacher to guide the model in reshaping its\nintrinsic latent representation. The process allows the model to converge more\neffectively and overcome inefficiencies, as well as provide beneficial insights\nto the user. We evaluated HILL in a user study tasking participants to train an\noptimal model, closely observing the employed strategies. The results\ndemonstrated that human-guided latent space modifications enhance model\nperformance while maintaining generalization, yet also revealing the risks of\nincluding user biases. Our work introduces a novel human-AI interaction\nparadigm that infuses human intuition into model training and critically\nexamines the impact of human intervention on training strategies and potential\nbiases.", "AI": {"tldr": "HILL is an interactive framework that integrates human intuition into model training by reshaping latent space representations, improving performance while revealing potential biases.", "motivation": "Latent spaces are often complex and obscure; incorporating human intuition can enhance model understanding and training efficiency.", "method": "HILL uses a knowledge distillation-inspired approach to integrate user modifications into the training loop, treating human input as a teacher.", "result": "Human-guided modifications improved model performance and generalization, but also highlighted risks of user biases.", "conclusion": "HILL introduces a novel human-AI interaction paradigm, balancing the benefits of human intuition with the need to mitigate biases."}}
{"id": "2505.07313", "pdf": "https://arxiv.org/pdf/2505.07313", "abs": "https://arxiv.org/abs/2505.07313", "authors": ["Baixuan Xu", "Chunyang Li", "Weiqi Wang", "Wei Fan", "Tianshi Zheng", "Haochen Shi", "Tao Fan", "Yangqiu Song", "Qiang Yang"], "title": "Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages", "summary": "Designing effective collaboration structure for multi-agent LLM systems to\nenhance collective reasoning is crucial yet remains under-explored. In this\npaper, we systematically investigate how collaborative reasoning performance is\naffected by three key design dimensions: (1) Expertise-Domain Alignment, (2)\nCollaboration Paradigm (structured workflow vs. diversity-driven integration),\nand (3) System Scale. Our findings reveal that expertise alignment benefits are\nhighly domain-contingent, proving most effective for contextual reasoning\ntasks. Furthermore, collaboration focused on integrating diverse knowledge\nconsistently outperforms rigid task decomposition. Finally, we empirically\nexplore the impact of scaling the multi-agent system with expertise\nspecialization and study the computational trade off, highlighting the need for\nmore efficient communication protocol design. This work provides concrete\nguidelines for configuring specialized multi-agent system and identifies\ncritical architectural trade-offs and bottlenecks for scalable multi-agent\nreasoning. The code will be made available upon acceptance.", "AI": {"tldr": "The paper explores how collaboration structures in multi-agent LLM systems affect collective reasoning, focusing on expertise alignment, collaboration paradigms, and system scale.", "motivation": "To enhance collective reasoning in multi-agent LLM systems by investigating key design dimensions.", "method": "Systematic study of three design dimensions: expertise-domain alignment, collaboration paradigm, and system scale.", "result": "Expertise alignment is domain-contingent, diverse knowledge integration outperforms rigid workflows, and system scaling reveals computational trade-offs.", "conclusion": "Provides guidelines for configuring multi-agent systems and identifies architectural trade-offs for scalable reasoning."}}
{"id": "2505.06694", "pdf": "https://arxiv.org/pdf/2505.06694", "abs": "https://arxiv.org/abs/2505.06694", "authors": ["XiaoTong Gu", "Shengyu Tang", "Yiming Cao", "Changdong Yu"], "title": "Underwater object detection in sonar imagery with detection transformer and Zero-shot neural architecture search", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Underwater object detection using sonar imagery has become a critical and\nrapidly evolving research domain within marine technology. However, sonar\nimages are characterized by lower resolution and sparser features compared to\noptical images, which seriously degrades the performance of object detection.To\naddress these challenges, we specifically propose a Detection Transformer\n(DETR) architecture optimized with a Neural Architecture Search (NAS) approach\ncalled NAS-DETR for object detection in sonar images. First, an improved\nZero-shot Neural Architecture Search (NAS) method based on the maximum entropy\nprinciple is proposed to identify a real-time, high-representational-capacity\nCNN-Transformer backbone for sonar image detection. This method enables the\nefficient discovery of high-performance network architectures with low\ncomputational and time overhead. Subsequently, the backbone is combined with a\nFeature Pyramid Network (FPN) and a deformable attention-based Transformer\ndecoder to construct a complete network architecture. This architecture\nintegrates various advanced components and training schemes to enhance overall\nperformance. Extensive experiments demonstrate that this architecture achieves\nstate-of-the-art performance on two Representative datasets, while maintaining\nminimal overhead in real-time efficiency and computational complexity.\nFurthermore, correlation analysis between the key parameters and differential\nentropy-based fitness function is performed to enhance the interpretability of\nthe proposed framework. To the best of our knowledge, this is the first work in\nthe field of sonar object detection to integrate the DETR architecture with a\nNAS search mechanism.", "AI": {"tldr": "A novel NAS-DETR framework is proposed for underwater object detection in sonar images, combining NAS for efficient backbone discovery with DETR for high performance.", "motivation": "Sonar images have lower resolution and sparser features than optical images, degrading object detection performance.", "method": "Improved Zero-shot NAS for backbone discovery, combined with FPN and deformable attention-based Transformer decoder.", "result": "Achieves state-of-the-art performance on two datasets with minimal computational overhead.", "conclusion": "First integration of DETR with NAS in sonar object detection, enhancing interpretability and efficiency."}}
{"id": "2505.07315", "pdf": "https://arxiv.org/pdf/2505.07315", "abs": "https://arxiv.org/abs/2505.07315", "authors": ["Zexiao Wang", "Yankai Wang", "Xiaoqiang Liao", "Xinguo Ming", "Weiming Shen"], "title": "FedIFL: A federated cross-domain diagnostic framework for motor-driven systems with inconsistent fault modes", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Due to the scarcity of industrial data, individual equipment users,\nparticularly start-ups, struggle to independently train a comprehensive fault\ndiagnosis model; federated learning enables collaborative training while\nensuring data privacy, making it an ideal solution. However, the diversity of\nworking conditions leads to variations in fault modes, resulting in\ninconsistent label spaces across different clients. In federated diagnostic\nscenarios, label space inconsistency leads to local models focus on\nclient-specific fault modes and causes local models from different clients to\nmap different failure modes to similar feature representations, which weakens\nthe aggregated global model's generalization. To tackle this issue, this\narticle proposed a federated cross-domain diagnostic framework termed Federated\nInvariant Features Learning (FedIFL). In intra-client training, prototype\ncontrastive learning mitigates intra-client domain shifts, subsequently,\nfeature generating ensures local models can access distributions of other\nclients in a privacy-friendly manner. Besides, in cross-client training, a\nfeature disentanglement mechanism is introduced to mitigate cross-client domain\nshifts, specifically, an instance-level federated instance consistency loss is\ndesigned to ensure the instance-level consistency of invariant features between\ndifferent clients, furthermore, a federated instance personalization loss and\nan orthogonal loss are constructed to distinguish specific features that from\nthe invariant features. Eventually, the aggregated model achieves promising\ngeneralization among global label spaces, enabling accurate fault diagnosis for\ntarget clients' Motor Driven Systems (MDSs) with inconsistent label spaces.\nExperiments on real-world MDSs validate the effectiveness and superiority of\nFedIFL in federated cross-domain diagnosis with inconsistent fault modes.", "AI": {"tldr": "The paper proposes FedIFL, a federated learning framework, to address label space inconsistency in fault diagnosis by using prototype contrastive learning and feature disentanglement.", "motivation": "Industrial data scarcity and label space inconsistency hinder fault diagnosis model training, especially for start-ups. Federated learning offers privacy but struggles with generalization due to inconsistent fault modes.", "method": "FedIFL employs intra-client prototype contrastive learning and cross-client feature disentanglement with instance-level consistency and orthogonal losses.", "result": "FedIFL improves generalization in global label spaces, enabling accurate fault diagnosis for Motor Driven Systems with inconsistent fault modes.", "conclusion": "FedIFL effectively addresses label space inconsistency in federated learning, validated by real-world MDS experiments."}}
{"id": "2505.06330", "pdf": "https://arxiv.org/pdf/2505.06330", "abs": "https://arxiv.org/abs/2505.06330", "authors": ["Junyu Xue", "Xudong Wang", "Xiaoling He", "Shicheng Liu", "Yi Wang", "Guoming Tang"], "title": "Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Non-intrusive Load Monitoring (NILM) aims to disaggregate aggregate household\nelectricity consumption into individual appliance usage, enabling more\neffective energy management. While deep learning has advanced NILM, it remains\nlimited by its dependence on labeled data, restricted generalization, and lack\nof interpretability. In this paper, we introduce the first prompt-based NILM\nframework that leverages Large Language Models (LLMs) with in-context learning.\nWe design and evaluate prompt strategies that integrate appliance features,\ntimestamps and contextual information, as well as representative time-series\nexamples, using the REDD dataset. With optimized prompts, LLMs achieve\ncompetitive state detection accuracy, reaching an average F1-score of 0.676 on\nunseen households, and demonstrate robust generalization without the need for\nfine-tuning. LLMs also enhance interpretability by providing clear,\nhuman-readable explanations for their predictions. Our results show that LLMs\ncan reduce data requirements, improve adaptability, and provide transparent\nenergy disaggregation in NILM applications.", "AI": {"tldr": "A prompt-based NILM framework using LLMs achieves competitive accuracy, robust generalization, and interpretability without fine-tuning.", "motivation": "Overcome limitations of deep learning in NILM, such as labeled data dependency, poor generalization, and lack of interpretability.", "method": "Introduce a prompt-based framework leveraging LLMs with in-context learning, integrating appliance features, timestamps, and examples.", "result": "Achieves an average F1-score of 0.676 on unseen households, with robust generalization and clear explanations.", "conclusion": "LLMs reduce data needs, improve adaptability, and offer transparent energy disaggregation in NILM."}}
{"id": "2505.07345", "pdf": "https://arxiv.org/pdf/2505.07345", "abs": "https://arxiv.org/abs/2505.07345", "authors": ["Ohjoon Kwon", "Changsu Lee", "Jihye Back", "Lim Sun Suk", "Inho Kang", "Donghyeon Jeon"], "title": "QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Large language models (LLMs) have been widely used for relevance assessment\nin information retrieval. However, our study demonstrates that combining two\ndistinct small language models (SLMs) with different architectures can\noutperform LLMs in this task. Our approach -- QUPID -- integrates a generative\nSLM with an embedding-based SLM, achieving higher relevance judgment accuracy\nwhile reducing computational costs compared to state-of-the-art LLM solutions.\nThis computational efficiency makes QUPID highly scalable for real-world search\nsystems processing millions of queries daily. In experiments across diverse\ndocument types, our method demonstrated consistent performance improvements\n(Cohen's Kappa of 0.646 versus 0.387 for leading LLMs) while offering 60x\nfaster inference times. Furthermore, when integrated into production search\npipelines, QUPID improved nDCG@5 scores by 1.9%. These findings underscore how\narchitectural diversity in model combinations can significantly enhance both\nsearch relevance and operational efficiency in information retrieval systems.", "AI": {"tldr": "Combining two small language models (SLMs) with different architectures (QUPID) outperforms large language models (LLMs) in relevance assessment, offering higher accuracy, lower computational costs, and scalability.", "motivation": "To improve relevance assessment in information retrieval by leveraging architectural diversity in model combinations, addressing the limitations of LLMs.", "method": "QUPID integrates a generative SLM with an embedding-based SLM for relevance judgment.", "result": "Achieves higher accuracy (Cohen's Kappa 0.646 vs. 0.387), 60x faster inference, and 1.9% nDCG@5 improvement in production.", "conclusion": "Architectural diversity in model combinations enhances search relevance and operational efficiency."}}
{"id": "2505.06710", "pdf": "https://arxiv.org/pdf/2505.06710", "abs": "https://arxiv.org/abs/2505.06710", "authors": ["Yicheng Song", "Tiancheng Lin", "Die Peng", "Su Yang", "Yi Xu"], "title": "SimMIL: A Universal Weakly Supervised Pre-Training Framework for Multi-Instance Learning in Whole Slide Pathology Images", "categories": ["cs.CV"], "comment": null, "summary": "Various multi-instance learning (MIL) based approaches have been developed\nand successfully applied to whole-slide pathological images (WSI). Existing MIL\nmethods emphasize the importance of feature aggregators, but largely neglect\nthe instance-level representation learning. They assume that the availability\nof a pre-trained feature extractor can be directly utilized or fine-tuned,\nwhich is not always the case. This paper proposes to pre-train feature\nextractor for MIL via a weakly-supervised scheme, i.e., propagating the weak\nbag-level labels to the corresponding instances for supervised learning. To\nlearn effective features for MIL, we further delve into several key components,\nincluding strong data augmentation, a non-linear prediction head and the robust\nloss function. We conduct experiments on common large-scale WSI datasets and\nfind it achieves better performance than other pre-training schemes (e.g.,\nImageNet pre-training and self-supervised learning) in different downstream\ntasks. We further show the compatibility and scalability of the proposed scheme\nby deploying it in fine-tuning the pathological-specific models and\npre-training on merged multiple datasets. To our knowledge, this is the first\nwork focusing on the representation learning for MIL.", "AI": {"tldr": "The paper proposes a weakly-supervised pre-training method for feature extractors in multi-instance learning (MIL), improving instance-level representation and outperforming existing pre-training schemes.", "motivation": "Existing MIL methods neglect instance-level representation learning and assume pre-trained feature extractors are sufficient, which is often not the case.", "method": "The method pre-trains feature extractors using weak bag-level labels propagated to instances, incorporating data augmentation, a non-linear prediction head, and robust loss functions.", "result": "The approach outperforms ImageNet pre-training and self-supervised learning on WSI datasets and shows compatibility with fine-tuning and multi-dataset pre-training.", "conclusion": "This is the first work to focus on representation learning for MIL, demonstrating its effectiveness and scalability."}}
{"id": "2505.07374", "pdf": "https://arxiv.org/pdf/2505.07374", "abs": "https://arxiv.org/abs/2505.07374", "authors": ["Zhiye Xie", "Enmei Tu", "Xianping Fu", "Guoliang Yuan", "Yi Han"], "title": "AIS Data-Driven Maritime Monitoring Based on Transformer: A Comprehensive Review", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "With the increasing demands for safety, efficiency, and sustainability in\nglobal shipping, Automatic Identification System (AIS) data plays an\nincreasingly important role in maritime monitoring. AIS data contains\nspatial-temporal variation patterns of vessels that hold significant research\nvalue in the marine domain. However, due to its massive scale, the full\npotential of AIS data has long remained untapped. With its powerful sequence\nmodeling capabilities, particularly its ability to capture long-range\ndependencies and complex temporal dynamics, the Transformer model has emerged\nas an effective tool for processing AIS data. Therefore, this paper reviews the\nresearch on Transformer-based AIS data-driven maritime monitoring, providing a\ncomprehensive overview of the current applications of Transformer models in the\nmarine field. The focus is on Transformer-based trajectory prediction methods,\nbehavior detection, and prediction techniques. Additionally, this paper\ncollects and organizes publicly available AIS datasets from the reviewed\npapers, performing data filtering, cleaning, and statistical analysis. The\nstatistical results reveal the operational characteristics of different vessel\ntypes, providing data support for further research on maritime monitoring\ntasks. Finally, we offer valuable suggestions for future research, identifying\ntwo promising research directions. Datasets are available at\nhttps://github.com/eyesofworld/Maritime-Monitoring.", "AI": {"tldr": "The paper reviews Transformer-based AIS data applications in maritime monitoring, focusing on trajectory prediction, behavior detection, and datasets.", "motivation": "To address the untapped potential of AIS data for maritime safety, efficiency, and sustainability using Transformer models.", "method": "Reviews Transformer-based AIS data applications, collects and analyzes public AIS datasets, and performs statistical analysis.", "result": "Reveals vessel operational characteristics and provides datasets for future maritime monitoring research.", "conclusion": "Identifies promising research directions and offers datasets for further study."}}
{"id": "2505.06331", "pdf": "https://arxiv.org/pdf/2505.06331", "abs": "https://arxiv.org/abs/2505.06331", "authors": ["Feilong Jiang", "Xiaonan Hou", "Jianqiao Ye", "Min Xia"], "title": "Mask-PINNs: Regulating Feature Distributions in Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) are a class of deep learning models\ndesigned to solve partial differential equations by incorporating physical laws\ndirectly into the loss function. However, the internal covariate shift, which\nhas been largely overlooked, hinders the effective utilization of neural\nnetwork capacity in PINNs. To this end, we propose Mask-PINNs, a novel\narchitecture designed to address this issue in PINNs. Unlike traditional\nnormalization methods such as BatchNorm or LayerNorm, we introduce a learnable,\nnonlinear mask function that constrains the feature distributions without\nviolating underlying physics. The experimental results show that the proposed\nmethod significantly improves feature distribution stability, accuracy, and\nrobustness across various activation functions and PDE benchmarks. Furthermore,\nit enables the stable and efficient training of wider networks a capability\nthat has been largely overlooked in PINNs.", "AI": {"tldr": "Mask-PINNs improve PINNs by addressing internal covariate shift with a learnable mask, enhancing stability, accuracy, and robustness.", "motivation": "Internal covariate shift in PINNs limits neural network capacity, which Mask-PINNs aim to resolve.", "method": "Introduces a learnable, nonlinear mask function to stabilize feature distributions without violating physics.", "result": "Improves feature distribution stability, accuracy, and robustness across PDE benchmarks.", "conclusion": "Mask-PINNs enable stable, efficient training of wider networks, addressing a key limitation in PINNs."}}
{"id": "2505.07409", "pdf": "https://arxiv.org/pdf/2505.07409", "abs": "https://arxiv.org/abs/2505.07409", "authors": ["Tim Wittenborg", "Constantin Sebastian Tremel", "Markus Stocker", "S\u00f6ren Auer"], "title": "Computational Fact-Checking of Online Discourse: Scoring scientific accuracy in climate change related news articles", "categories": ["cs.CL"], "comment": "4 pages, 4 figures, submitted to ACM Web Conference 2025", "summary": "Democratic societies need reliable information. Misinformation in popular\nmedia such as news articles or videos threatens to impair civic discourse.\nCitizens are, unfortunately, not equipped to verify this content flood consumed\ndaily at increasing rates. This work aims to semi-automatically quantify\nscientific accuracy of online media. By semantifying media of unknown veracity,\ntheir statements can be compared against equally processed trusted sources. We\nimplemented a workflow using LLM-based statement extraction and knowledge graph\nanalysis. Our neurosymbolic system was able to evidently streamline\nstate-of-the-art veracity quantification. Evaluated via expert interviews and a\nuser survey, the tool provides a beneficial veracity indication. This\nindicator, however, is unable to annotate public media at the required\ngranularity and scale. Further work towards a FAIR (Findable, Accessible,\nInteroperable, Reusable) ground truth and complementary metrics are required to\nscientifically support civic discourse.", "AI": {"tldr": "A neurosymbolic system using LLM-based statement extraction and knowledge graph analysis semi-automates veracity quantification of online media, but lacks granularity and scalability for public use.", "motivation": "Address misinformation in media by providing reliable veracity quantification to support civic discourse.", "method": "Uses LLM-based statement extraction and knowledge graph analysis to compare media against trusted sources.", "result": "The system streamlines veracity quantification but requires further improvements for granularity and scalability.", "conclusion": "More work on FAIR ground truth and complementary metrics is needed to scientifically support civic discourse."}}
{"id": "2505.06745", "pdf": "https://arxiv.org/pdf/2505.06745", "abs": "https://arxiv.org/abs/2505.06745", "authors": ["Parth Padalkar", "Gopal Gupta"], "title": "Symbolic Rule Extraction from Attention-Guided Sparse Representations in Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent neuro-symbolic approaches have successfully extracted symbolic\nrule-sets from CNN-based models to enhance interpretability. However, applying\nsimilar techniques to Vision Transformers (ViTs) remains challenging due to\ntheir lack of modular concept detectors and reliance on global self-attention\nmechanisms. We propose a framework for symbolic rule extraction from ViTs by\nintroducing a sparse concept layer inspired by Sparse Autoencoders (SAEs). This\nlinear layer operates on attention-weighted patch representations and learns a\ndisentangled, binarized representation in which individual neurons activate for\nhigh-level visual concepts. To encourage interpretability, we apply a\ncombination of L1 sparsity, entropy minimization, and supervised contrastive\nloss. These binarized concept activations are used as input to the FOLD-SE-M\nalgorithm, which generates a rule-set in the form of logic programs. Our method\nachieves a 5.14% better classification accuracy than the standard ViT while\nenabling symbolic reasoning. Crucially, the extracted rule-set is not merely\npost-hoc but acts as a logic-based decision layer that operates directly on the\nsparse concept representations. The resulting programs are concise and\nsemantically meaningful. This work is the first to extract executable logic\nprograms from ViTs using sparse symbolic representations. It bridges the gap\nbetween transformer-based vision models and symbolic logic programming,\nproviding a step forward in interpretable and verifiable neuro-symbolic AI.", "AI": {"tldr": "A framework for extracting symbolic rules from Vision Transformers (ViTs) using sparse concept layers and logic programming, improving accuracy and interpretability.", "motivation": "Enhancing interpretability of ViTs, which lack modular concept detectors and rely on global self-attention, by bridging neuro-symbolic AI.", "method": "Introduces a sparse concept layer with L1 sparsity, entropy minimization, and supervised contrastive loss, followed by FOLD-SE-M for rule-set generation.", "result": "Achieves 5.14% better classification accuracy than standard ViT, with concise, meaningful logic programs.", "conclusion": "First method to extract executable logic programs from ViTs, advancing interpretable and verifiable neuro-symbolic AI."}}
{"id": "2505.07453", "pdf": "https://arxiv.org/pdf/2505.07453", "abs": "https://arxiv.org/abs/2505.07453", "authors": ["Cornelius Wolff", "Madelon Hulsebos"], "title": "How well do LLMs reason over tabular data, really?", "categories": ["cs.AI"], "comment": "10 pages, 4 figures", "summary": "Large Language Models (LLMs) excel in natural language tasks, but less is\nknown about their reasoning capabilities over tabular data. Prior analyses\ndevise evaluation strategies that poorly reflect an LLM's realistic performance\non tabular queries. Moreover, we have a limited understanding of the robustness\nof LLMs towards realistic variations in tabular inputs. Therefore, we ask: Can\ngeneral-purpose LLMs reason over tabular data, really?, and focus on two\nquestions 1) are tabular reasoning capabilities of general-purpose LLMs robust\nto real-world characteristics of tabular inputs, and 2) how can we\nrealistically evaluate an LLM's performance on analytical tabular queries?\nBuilding on a recent tabular reasoning benchmark, we first surface shortcomings\nof its multiple-choice prompt evaluation strategy, as well as commonly used\nfree-form text metrics such as SacreBleu and BERT-score. We show that an\nLLM-as-a-judge procedure yields more reliable performance insights and unveil a\nsignificant deficit in tabular reasoning performance of LLMs. We then extend\nthe tabular inputs reflecting three common characteristics in practice: 1)\nmissing values, 2) duplicate entities, and 3) structural variations.\nExperiments show that the tabular reasoning capabilities of general-purpose\nLLMs suffer from these variations, stressing the importance of improving their\nrobustness for realistic tabular inputs.", "AI": {"tldr": "The paper investigates whether general-purpose LLMs can effectively reason over tabular data, highlighting their limitations in robustness and evaluation methods.", "motivation": "Prior evaluations of LLMs on tabular data are unrealistic, and their robustness to real-world tabular variations is poorly understood.", "method": "The study critiques existing benchmarks and metrics, introduces an LLM-as-a-judge evaluation, and tests LLMs on tabular inputs with missing values, duplicates, and structural variations.", "result": "LLMs show significant deficits in tabular reasoning, especially when faced with realistic tabular variations.", "conclusion": "Improving LLM robustness for realistic tabular inputs is crucial, as current methods fall short."}}
{"id": "2505.06333", "pdf": "https://arxiv.org/pdf/2505.06333", "abs": "https://arxiv.org/abs/2505.06333", "authors": ["Chathurangi Shyalika", "Renjith Prasad", "Fadi El Kalach", "Revathy Venkataramanan", "Ramtin Zand", "Ramy Harik", "Amit Sheth"], "title": "NSF-MAP: Neurosymbolic Multimodal Fusion for Robust and Interpretable Anomaly Prediction in Assembly Pipelines", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 7 figures, 2 tables, IJCAI 2025 (International Joint\n  Conferences on Artificial Intelligence) Special Track on AI4Tech: AI Enabling\n  Critical Technologies", "summary": "In modern assembly pipelines, identifying anomalies is crucial in ensuring\nproduct quality and operational efficiency. Conventional single-modality\nmethods fail to capture the intricate relationships required for precise\nanomaly prediction in complex predictive environments with abundant data and\nmultiple modalities. This paper proposes a neurosymbolic AI and fusion-based\napproach for multimodal anomaly prediction in assembly pipelines. We introduce\na time series and image-based fusion model that leverages decision-level fusion\ntechniques. Our research builds upon three primary novel approaches in\nmultimodal learning: time series and image-based decision-level fusion\nmodeling, transfer learning for fusion, and knowledge-infused learning. We\nevaluate the novel method using our derived and publicly available multimodal\ndataset and conduct comprehensive ablation studies to assess the impact of our\npreprocessing techniques and fusion model compared to traditional baselines.\nThe results demonstrate that a neurosymbolic AI-based fusion approach that uses\ntransfer learning can effectively harness the complementary strengths of time\nseries and image data, offering a robust and interpretable approach for anomaly\nprediction in assembly pipelines with enhanced performance. \\noindent The\ndatasets, codes to reproduce the results, supplementary materials, and demo are\navailable at https://github.com/ChathurangiShyalika/NSF-MAP.", "AI": {"tldr": "A neurosymbolic AI and fusion-based approach for multimodal anomaly prediction in assembly pipelines, combining time series and image data with transfer learning for improved performance.", "motivation": "Conventional single-modality methods are inadequate for complex predictive environments with abundant data and multiple modalities, necessitating a more robust solution.", "method": "Proposes a time series and image-based fusion model using decision-level fusion techniques, transfer learning, and knowledge-infused learning.", "result": "The approach effectively harnesses complementary strengths of time series and image data, offering robust and interpretable anomaly prediction with enhanced performance.", "conclusion": "The neurosymbolic AI-based fusion method outperforms traditional baselines, providing a scalable and interpretable solution for anomaly prediction in assembly pipelines."}}
{"id": "2505.07416", "pdf": "https://arxiv.org/pdf/2505.07416", "abs": "https://arxiv.org/abs/2505.07416", "authors": ["Truc Mai-Thanh Nguyen", "Dat Minh Nguyen", "Son T. Luu", "Kiet Van Nguyen"], "title": "ViMRHP: A Vietnamese Benchmark Dataset for Multimodal Review Helpfulness Prediction via Human-AI Collaborative Annotation", "categories": ["cs.CL"], "comment": "Accepted at NLDB 2025", "summary": "Multimodal Review Helpfulness Prediction (MRHP) is an essential task in\nrecommender systems, particularly in E-commerce platforms. Determining the\nhelpfulness of user-generated reviews enhances user experience and improves\nconsumer decision-making. However, existing datasets focus predominantly on\nEnglish and Indonesian, resulting in a lack of linguistic diversity, especially\nfor low-resource languages such as Vietnamese. In this paper, we introduce\nViMRHP (Vietnamese Multimodal Review Helpfulness Prediction), a large-scale\nbenchmark dataset for MRHP task in Vietnamese. This dataset covers four\ndomains, including 2K products with 46K reviews. Meanwhile, a large-scale\ndataset requires considerable time and cost. To optimize the annotation\nprocess, we leverage AI to assist annotators in constructing the ViMRHP\ndataset. With AI assistance, annotation time is reduced (90 to 120 seconds per\ntask down to 20 to 40 seconds per task) while maintaining data quality and\nlowering overall costs by approximately 65%. However, AI-generated annotations\nstill have limitations in complex annotation tasks, which we further examine\nthrough a detailed performance analysis. In our experiment on ViMRHP, we\nevaluate baseline models on human-verified and AI-generated annotations to\nassess their quality differences. The ViMRHP dataset is publicly available at\nhttps://github.com/trng28/ViMRHP", "AI": {"tldr": "The paper introduces ViMRHP, a Vietnamese multimodal review helpfulness prediction dataset, addressing linguistic diversity gaps. AI-assisted annotation reduces time and costs while maintaining quality, though limitations exist for complex tasks.", "motivation": "Existing datasets lack linguistic diversity, especially for low-resource languages like Vietnamese, limiting MRHP task applicability.", "method": "Introduces ViMRHP, a large-scale Vietnamese dataset with AI-assisted annotation to optimize time and cost. Evaluates baseline models on human-verified vs. AI-generated annotations.", "result": "AI reduces annotation time (90-120s to 20-40s per task) and costs by ~65%, though complex tasks remain challenging.", "conclusion": "ViMRHP fills a linguistic gap and demonstrates AI's efficiency in annotation, but human oversight is still needed for complex cases."}}
{"id": "2505.06796", "pdf": "https://arxiv.org/pdf/2505.06796", "abs": "https://arxiv.org/abs/2505.06796", "authors": ["Ye Zhu", "Yunan Wang", "Zitong Yu"], "title": "Multimodal Fake News Detection: MFND Dataset and Shallow-Deep Multitask Learning", "categories": ["cs.CV"], "comment": "Accepted by IJCAI 2025", "summary": "Multimodal news contains a wealth of information and is easily affected by\ndeepfake modeling attacks. To combat the latest image and text generation\nmethods, we present a new Multimodal Fake News Detection dataset (MFND)\ncontaining 11 manipulated types, designed to detect and localize highly\nauthentic fake news. Furthermore, we propose a Shallow-Deep Multitask Learning\n(SDML) model for fake news, which fully uses unimodal and mutual modal features\nto mine the intrinsic semantics of news. Under shallow inference, we propose\nthe momentum distillation-based light punishment contrastive learning for\nfine-grained uniform spatial image and text semantic alignment, and an adaptive\ncross-modal fusion module to enhance mutual modal features. Under deep\ninference, we design a two-branch framework to augment the image and text\nunimodal features, respectively merging with mutual modalities features, for\nfour predictions via dedicated detection and localization projections.\nExperiments on both mainstream and our proposed datasets demonstrate the\nsuperiority of the model. Codes and dataset are released at\nhttps://github.com/yunan-wang33/sdml.", "AI": {"tldr": "A new dataset (MFND) and model (SDML) for detecting and localizing highly authentic fake news in multimodal content, leveraging shallow and deep learning techniques for improved accuracy.", "motivation": "To combat deepfake modeling attacks in multimodal news by detecting and localizing manipulated content.", "method": "Proposes the Shallow-Deep Multitask Learning (SDML) model, using momentum distillation-based contrastive learning and adaptive cross-modal fusion for shallow inference, and a two-branch framework for deep inference.", "result": "Demonstrates superior performance on mainstream and proposed datasets.", "conclusion": "The SDML model effectively detects and localizes fake news, with released codes and dataset for further research."}}
{"id": "2505.07460", "pdf": "https://arxiv.org/pdf/2505.07460", "abs": "https://arxiv.org/abs/2505.07460", "authors": ["Yi Chen", "JiaHao Zhao", "HaoHao Han"], "title": "A Survey on Collaborative Mechanisms Between Large and Small Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) deliver powerful AI capabilities but face\ndeployment challenges due to high resource costs and latency, whereas Small\nLanguage Models (SLMs) offer efficiency and deployability at the cost of\nreduced performance. Collaboration between LLMs and SLMs emerges as a crucial\nparadigm to synergistically balance these trade-offs, enabling advanced AI\napplications, especially on resource-constrained edge devices. This survey\nprovides a comprehensive overview of LLM-SLM collaboration, detailing various\ninteraction mechanisms (pipeline, routing, auxiliary, distillation, fusion),\nkey enabling technologies, and diverse application scenarios driven by\non-device needs like low latency, privacy, personalization, and offline\noperation. While highlighting the significant potential for creating more\nefficient, adaptable, and accessible AI, we also discuss persistent challenges\nincluding system overhead, inter-model consistency, robust task allocation,\nevaluation complexity, and security/privacy concerns. Future directions point\ntowards more intelligent adaptive frameworks, deeper model fusion, and\nexpansion into multimodal and embodied AI, positioning LLM-SLM collaboration as\na key driver for the next generation of practical and ubiquitous artificial\nintelligence.", "AI": {"tldr": "LLM-SLM collaboration balances performance and efficiency, enabling advanced AI on edge devices. This survey covers interaction mechanisms, technologies, applications, challenges, and future directions.", "motivation": "Address deployment challenges of LLMs (high resource costs, latency) and performance limitations of SLMs by leveraging their collaboration.", "method": "Survey of LLM-SLM collaboration, detailing interaction mechanisms (pipeline, routing, auxiliary, distillation, fusion) and enabling technologies.", "result": "Identifies key applications (low latency, privacy, personalization, offline operation) and challenges (system overhead, consistency, task allocation, evaluation, security).", "conclusion": "LLM-SLM collaboration is pivotal for efficient, adaptable AI, with future directions including adaptive frameworks, deeper fusion, and multimodal expansion."}}
{"id": "2505.06335", "pdf": "https://arxiv.org/pdf/2505.06335", "abs": "https://arxiv.org/abs/2505.06335", "authors": ["Jinsheng Yuan", "Yuhang Hao", "Weisi Guo", "Yun Wu", "Chongyan Gu"], "title": "Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) has the potential for simultaneous global learning\namongst a large number of parallel agents, enabling emerging AI such as LLMs to\nbe trained across demographically diverse data. Central to this being efficient\nis the ability for FL to perform sparse gradient updates and remote direct\nmemory access at the central server. Most of the research in FL security\nfocuses on protecting data privacy at the edge client or in the communication\nchannels between the client and server. Client-facing attacks on the server are\nless well investigated as the assumption is that a large collective of clients\noffer resilience.\n  Here, we show that by attacking certain clients that lead to a high frequency\nrepetitive memory update in the server, we can remote initiate a rowhammer\nattack on the server memory. For the first time, we do not need backdoor access\nto the server, and a reinforcement learning (RL) attacker can learn how to\nmaximize server repetitive memory updates by manipulating the client's sensor\nobservation. The consequence of the remote rowhammer attack is that we are able\nto achieve bit flips, which can corrupt the server memory. We demonstrate the\nfeasibility of our attack using a large-scale FL automatic speech recognition\n(ASR) systems with sparse updates, our adversarial attacking agent can achieve\naround 70\\% repeated update rate (RUR) in the targeted server model,\neffectively inducing bit flips on server DRAM. The security implications are\nthat can cause disruptions to learning or may inadvertently cause elevated\nprivilege. This paves the way for further research on practical mitigation\nstrategies in FL and hardware design.", "AI": {"tldr": "The paper demonstrates a novel attack on Federated Learning (FL) servers by exploiting repetitive memory updates to induce bit flips via remote rowhammer, without requiring backdoor access.", "motivation": "To investigate under-explored server-side vulnerabilities in FL, where client-facing attacks are more commonly studied, and to highlight the risks of remote rowhammer attacks.", "method": "Using reinforcement learning (RL), the attacker manipulates client sensor observations to maximize repetitive memory updates on the server, inducing bit flips in DRAM.", "result": "The attack achieves a 70% repeated update rate (RUR) in a large-scale FL ASR system, successfully corrupting server memory.", "conclusion": "This reveals a new security threat in FL, necessitating further research into mitigation strategies and hardware design."}}
{"id": "2505.07430", "pdf": "https://arxiv.org/pdf/2505.07430", "abs": "https://arxiv.org/abs/2505.07430", "authors": ["Mostafa Mohaimen Akand Faisal", "Rabeya Amin Jhuma"], "title": "Comparative sentiment analysis of public perception: Monkeypox vs. COVID-19 behavioral insights", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The emergence of global health crises, such as COVID-19 and Monkeypox (mpox),\nhas underscored the importance of understanding public sentiment to inform\neffective public health strategies. This study conducts a comparative sentiment\nanalysis of public perceptions surrounding COVID-19 and mpox by leveraging\nextensive datasets of 147,475 and 106,638 tweets, respectively. Advanced\nmachine learning models, including Logistic Regression, Naive Bayes, RoBERTa,\nDistilRoBERTa and XLNet, were applied to perform sentiment classification, with\nresults indicating key trends in public emotion and discourse. The analysis\nhighlights significant differences in public sentiment driven by disease\ncharacteristics, media representation, and pandemic fatigue. Through the lens\nof sentiment polarity and thematic trends, this study offers valuable insights\ninto tailoring public health messaging, mitigating misinformation, and\nfostering trust during concurrent health crises. The findings contribute to\nadvancing sentiment analysis applications in public health informatics, setting\nthe groundwork for enhanced real-time monitoring and multilingual analysis in\nfuture research.", "AI": {"tldr": "Comparative sentiment analysis of COVID-19 and mpox using 147,475 and 106,638 tweets, respectively, reveals key public sentiment trends influenced by disease traits, media, and pandemic fatigue.", "motivation": "To understand public sentiment for effective public health strategies during concurrent health crises like COVID-19 and mpox.", "method": "Applied machine learning models (Logistic Regression, Naive Bayes, RoBERTa, DistilRoBERTa, XLNet) for sentiment classification on tweet datasets.", "result": "Identified significant differences in public sentiment, driven by disease characteristics, media representation, and pandemic fatigue.", "conclusion": "Provides insights for tailored public health messaging, misinformation mitigation, and trust-building, advancing sentiment analysis in public health informatics."}}
{"id": "2505.06814", "pdf": "https://arxiv.org/pdf/2505.06814", "abs": "https://arxiv.org/abs/2505.06814", "authors": ["Bin Li", "Shenxi Liu", "Yixuan Weng", "Yue Du", "Yuhang Tian", "Shoujun Zhou"], "title": "Overview of the NLPCC 2025 Shared Task 4: Multi-modal, Multilingual, and Multi-hop Medical Instructional Video Question Answering Challenge", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "12 pages, 5 figures, 4 tables", "summary": "Following the successful hosts of the 1-st (NLPCC 2023 Foshan) CMIVQA and the\n2-rd (NLPCC 2024 Hangzhou) MMIVQA challenges, this year, a new task has been\nintroduced to further advance research in multi-modal, multilingual, and\nmulti-hop medical instructional question answering (M4IVQA) systems, with a\nspecific focus on medical instructional videos. The M4IVQA challenge focuses on\nevaluating models that integrate information from medical instructional videos,\nunderstand multiple languages, and answer multi-hop questions requiring\nreasoning over various modalities. This task consists of three tracks:\nmulti-modal, multilingual, and multi-hop Temporal Answer Grounding in Single\nVideo (M4TAGSV), multi-modal, multilingual, and multi-hop Video Corpus\nRetrieval (M4VCR) and multi-modal, multilingual, and multi-hop Temporal Answer\nGrounding in Video Corpus (M4TAGVC). Participants in M4IVQA are expected to\ndevelop algorithms capable of processing both video and text data,\nunderstanding multilingual queries, and providing relevant answers to multi-hop\nmedical questions. We believe the newly introduced M4IVQA challenge will drive\ninnovations in multimodal reasoning systems for healthcare scenarios,\nultimately contributing to smarter emergency response systems and more\neffective medical education platforms in multilingual communities. Our official\nwebsite is https://cmivqa.github.io/", "AI": {"tldr": "The M4IVQA challenge introduces a new task for multi-modal, multilingual, and multi-hop medical instructional question answering, focusing on medical instructional videos. It includes three tracks: M4TAGSV, M4VCR, and M4TAGVC.", "motivation": "To advance research in multi-modal, multilingual, and multi-hop medical instructional question answering, particularly for healthcare and education.", "method": "Participants develop algorithms to process video and text data, understand multilingual queries, and answer multi-hop medical questions.", "result": "The challenge aims to drive innovations in multimodal reasoning systems for healthcare and education.", "conclusion": "M4IVQA is expected to contribute to smarter emergency response and more effective medical education in multilingual communities."}}
{"id": "2505.07473", "pdf": "https://arxiv.org/pdf/2505.07473", "abs": "https://arxiv.org/abs/2505.07473", "authors": ["Kai Xu", "YiWei Mao", "XinYi Guan", "ZiLong Feng"], "title": "Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks", "categories": ["cs.AI"], "comment": "28 pages, 15 figures", "summary": "The application of large language models (LLMs) in the field of coding is\nevolving rapidly: from code assistants, to autonomous coding agents, and then\nto generating complete projects through natural language. Early LLM code\nbenchmarks primarily focused on code generation accuracy, but these benchmarks\nhave gradually become saturated. Benchmark saturation weakens their guiding\nrole for LLMs. For example, HumanEval Pass@1 has reached 99.4% and MBPP 94.2%.\nAmong various attempts to address benchmark saturation, approaches based on\nsoftware engineering have stood out, but the saturation of existing software\nengineering benchmarks is rapidly increasing. To address this, we propose a new\nbenchmark, Web-Bench, which contains 50 projects, each consisting of 20 tasks\nwith sequential dependencies. The tasks implement project features in sequence,\nsimulating real-world human development workflows. When designing Web-Bench, we\naim to cover the foundational elements of Web development: Web Standards and\nWeb Frameworks. Given the scale and complexity of these projects, which were\ndesigned by engineers with 5 to 10 years of experience, each presents a\nsignificant challenge. On average, a single project takes 4 to 8 hours for a\nsenior engineer to complete. On our given benchmark agent (Web-Agent), SOTA\n(Claude 3.7 Sonnet) achieves only 25.1% Pass@1, significantly lower (better)\nthan SWE-Bench's Verified (65.4%) and Full (33.8%) scores. Finally, we discuss\nthat in any development field, Standards and Frameworks represent foundational\nknowledge and efficiency tools, respectively, and LLMs require optimization\ntailored to them.", "AI": {"tldr": "The paper introduces Web-Bench, a new benchmark for evaluating LLMs in coding, addressing saturation in existing benchmarks by simulating real-world web development workflows.", "motivation": "Existing benchmarks for LLM coding performance are becoming saturated, limiting their effectiveness in guiding LLM development.", "method": "Proposed Web-Bench, a benchmark with 50 projects, each containing 20 sequentially dependent tasks, designed to simulate real-world web development.", "result": "Current SOTA model (Claude 3.7 Sonnet) achieves only 25.1% Pass@1 on Web-Bench, highlighting its challenge compared to other benchmarks.", "conclusion": "Standards and frameworks are foundational for LLM optimization in development, and Web-Bench provides a more realistic evaluation tool."}}
{"id": "2505.06351", "pdf": "https://arxiv.org/pdf/2505.06351", "abs": "https://arxiv.org/abs/2505.06351", "authors": ["Willem Diepeveen", "Jon Schwenk", "Andrea Bertozzi"], "title": "Latent Diffeomorphic Dynamic Mode Decomposition", "categories": ["cs.LG", "math.DS"], "comment": null, "summary": "We present Latent Diffeomorphic Dynamic Mode Decomposition (LDDMD), a new\ndata reduction approach for the analysis of non-linear systems that combines\nthe interpretability of Dynamic Mode Decomposition (DMD) with the predictive\npower of Recurrent Neural Networks (RNNs). Notably, LDDMD maintains simplicity,\nwhich enhances interpretability, while effectively modeling and learning\ncomplex non-linear systems with memory, enabling accurate predictions. This is\nexemplified by its successful application in streamflow prediction.", "AI": {"tldr": "LDDMD combines DMD's interpretability with RNNs' predictive power for non-linear systems, demonstrated in streamflow prediction.", "motivation": "To bridge the gap between interpretability (DMD) and predictive power (RNNs) in non-linear system analysis.", "method": "Latent Diffeomorphic Dynamic Mode Decomposition (LDDMD), integrating DMD and RNNs.", "result": "Effective modeling of complex non-linear systems with memory, enabling accurate predictions (e.g., streamflow).", "conclusion": "LDDMD successfully balances simplicity, interpretability, and predictive power for non-linear systems."}}
{"id": "2505.07440", "pdf": "https://arxiv.org/pdf/2505.07440", "abs": "https://arxiv.org/abs/2505.07440", "authors": ["Rituraj Singh", "Sachin Pawar", "Girish Palshikar"], "title": "Matching Tasks with Industry Groups for Augmenting Commonsense Knowledge", "categories": ["cs.CL"], "comment": null, "summary": "Commonsense knowledge bases (KB) are a source of specialized knowledge that\nis widely used to improve machine learning applications. However, even for a\nlarge KB such as ConceptNet, capturing explicit knowledge from each industry\ndomain is challenging. For example, only a few samples of general {\\em tasks}\nperformed by various industries are available in ConceptNet. Here, a task is a\nwell-defined knowledge-based volitional action to achieve a particular goal. In\nthis paper, we aim to fill this gap and present a weakly-supervised framework\nto augment commonsense KB with tasks carried out by various industry groups\n(IG). We attempt to {\\em match} each task with one or more suitable IGs by\ntraining a neural model to learn task-IG affinity and apply clustering to\nselect the top-k tasks per IG. We extract a total of 2339 triples of the form\n$\\langle IG, is~capable~of, task \\rangle$ from two publicly available news\ndatasets for 24 IGs with the precision of 0.86. This validates the reliability\nof the extracted task-IG pairs that can be directly added to existing KBs.", "AI": {"tldr": "A weakly-supervised framework is proposed to augment commonsense KBs with industry-specific tasks, achieving high precision in task-IG matching.", "motivation": "Existing commonsense KBs lack domain-specific task knowledge, limiting their utility for industry applications.", "method": "A neural model learns task-IG affinity, and clustering selects top-k tasks per IG from news datasets.", "result": "Extracted 2339 high-precision triples (IG-task pairs) for 24 industry groups.", "conclusion": "The framework reliably augments KBs with industry-specific tasks, enhancing their applicability."}}
{"id": "2505.06825", "pdf": "https://arxiv.org/pdf/2505.06825", "abs": "https://arxiv.org/abs/2505.06825", "authors": ["Thien Nhan Vo"], "title": "Active Learning for Multi-class Image Classification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "A principle bottleneck in image classification is the large number of\ntraining examples needed to train a classifier. Using active learning, we can\nreduce the number of training examples to teach a CNN classifier by\nstrategically selecting examples. Assigning values to image examples using\ndifferent uncertainty metrics allows the model to identify and select\nhigh-value examples in a smaller training set size. We demonstrate results for\ndigit recognition and fruit classification on the MNIST and Fruits360 data\nsets. We formally compare results for four different uncertainty metrics.\nFinally, we observe active learning is also effective on simpler (binary)\nclassification tasks, but marked improvement from random sampling is more\nevident on more difficult tasks. We show active learning is a viable algorithm\nfor image classification problems.", "AI": {"tldr": "Active learning reduces training examples for CNN classifiers by strategically selecting high-value images using uncertainty metrics, showing effectiveness in digit and fruit classification tasks.", "motivation": "The large number of training examples required for image classification is a bottleneck; active learning aims to mitigate this by selecting fewer, more informative examples.", "method": "Active learning is applied to CNN classifiers using four uncertainty metrics to strategically select high-value training examples from MNIST and Fruits360 datasets.", "result": "Active learning reduces training set size while maintaining performance, with marked improvement over random sampling in complex tasks.", "conclusion": "Active learning is a viable and effective approach for image classification, particularly in challenging tasks."}}
{"id": "2505.07509", "pdf": "https://arxiv.org/pdf/2505.07509", "abs": "https://arxiv.org/abs/2505.07509", "authors": ["Feng Ding", "Tingting Wang", "Yupeng Gao", "Shuo Yu", "Jing Ren", "Feng Xia"], "title": "HALO: Half Life-Based Outdated Fact Filtering in Temporal Knowledge Graphs", "categories": ["cs.AI"], "comment": null, "summary": "Outdated facts in temporal knowledge graphs (TKGs) result from exceeding the\nexpiration date of facts, which negatively impact reasoning performance on\nTKGs. However, existing reasoning methods primarily focus on positive\nimportance of historical facts, neglecting adverse effects of outdated facts.\nBesides, training on these outdated facts yields extra computational cost. To\naddress these challenges, we propose an outdated fact filtering framework named\nHALO, which quantifies the temporal validity of historical facts by exploring\nthe half-life theory to filter outdated facts in TKGs. HALO consists of three\nmodules: the temporal fact attention module, the dynamic relation-aware encoder\nmodule, and the outdated fact filtering module. Firstly, the temporal fact\nattention module captures the evolution of historical facts over time to\nidentify relevant facts. Secondly, the dynamic relation-aware encoder module is\ndesigned for efficiently predicting the half life of each fact. Finally, we\nconstruct a time decay function based on the half-life theory to quantify the\ntemporal validity of facts and filter outdated facts. Experimental results show\nthat HALO outperforms the state-of-the-art TKG reasoning methods on three\npublic datasets, demonstrating its effectiveness in detecting and filtering\noutdated facts (Codes are available at\nhttps://github.com/yushuowiki/K-Half/tree/main ).", "AI": {"tldr": "HALO is a framework for filtering outdated facts in temporal knowledge graphs (TKGs) by quantifying their temporal validity using half-life theory, improving reasoning performance.", "motivation": "Existing TKG reasoning methods ignore the negative impact of outdated facts, leading to performance degradation and extra computational costs.", "method": "HALO uses three modules: temporal fact attention to capture fact evolution, a dynamic relation-aware encoder to predict fact half-life, and a time decay function to filter outdated facts.", "result": "HALO outperforms state-of-the-art TKG reasoning methods on three public datasets.", "conclusion": "HALO effectively detects and filters outdated facts, enhancing TKG reasoning performance."}}
{"id": "2505.06367", "pdf": "https://arxiv.org/pdf/2505.06367", "abs": "https://arxiv.org/abs/2505.06367", "authors": ["Everest Yang", "Ria Vasishtha", "Luqman K. Dad", "Lisa A. Kachnic", "Andrew Hope", "Eric Wang", "Xiao Wu", "Yading Yuan", "David J. Brenner", "Igor Shuryak"], "title": "CAST: Time-Varying Treatment Effects with Application to Chemotherapy and Radiotherapy on Head and Neck Squamous Cell Carcinoma", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Causal machine learning (CML) enables individualized estimation of treatment\neffects, offering critical advantages over traditional correlation-based\nmethods. However, existing approaches for medical survival data with censoring\nsuch as causal survival forests estimate effects at fixed time points, limiting\ntheir ability to capture dynamic changes over time. We introduce Causal\nAnalysis for Survival Trajectories (CAST), a novel framework that models\ntreatment effects as continuous functions of time following treatment. By\ncombining parametric and non-parametric methods, CAST overcomes the limitations\nof discrete time-point analysis to estimate continuous effect trajectories.\nUsing the RADCURE dataset [1] of 2,651 patients with head and neck squamous\ncell carcinoma (HNSCC) as a clinically relevant example, CAST models how\nchemotherapy and radiotherapy effects evolve over time at the population and\nindividual levels. By capturing the temporal dynamics of treatment response,\nCAST reveals how treatment effects rise, peak, and decline over the follow-up\nperiod, helping clinicians determine when and for whom treatment benefits are\nmaximized. This framework advances the application of CML to personalized care\nin HNSCC and other life-threatening medical conditions. Source code/data\navailable at: https://github.com/CAST-FW/HNSCC", "AI": {"tldr": "CAST introduces a continuous-time framework for estimating dynamic treatment effects in survival data, overcoming limitations of fixed-time methods.", "motivation": "Existing methods for causal survival analysis estimate effects at fixed time points, missing dynamic changes over time. CAST aims to capture these temporal dynamics.", "method": "CAST combines parametric and non-parametric methods to model treatment effects as continuous functions of time, applied to the RADCURE dataset of HNSCC patients.", "result": "CAST reveals how treatment effects evolve (rise, peak, decline) over time, aiding clinicians in optimizing treatment timing and selection.", "conclusion": "CAST advances causal machine learning for personalized care by enabling continuous-time effect estimation in survival data."}}
{"id": "2505.07495", "pdf": "https://arxiv.org/pdf/2505.07495", "abs": "https://arxiv.org/abs/2505.07495", "authors": ["Isabelle van der Vegt", "Bennett Kleinberg", "Marilu Miotto", "Jonas Festor"], "title": "Translating the Grievance Dictionary: a psychometric evaluation of Dutch, German, and Italian versions", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces and evaluates three translations of the Grievance\nDictionary, a psycholinguistic dictionary for the analysis of violent,\nthreatening or grievance-fuelled texts. Considering the relevance of these\nthemes in languages beyond English, we translated the Grievance Dictionary to\nDutch, German, and Italian. We describe the process of automated translation\nsupplemented by human annotation. Psychometric analyses are performed,\nincluding internal reliability of dictionary categories and correlations with\nthe LIWC dictionary. The Dutch and German translations perform similarly to the\noriginal English version, whereas the Italian dictionary shows low reliability\nfor some categories. Finally, we make suggestions for further validation and\napplication of the dictionary, as well as for future dictionary translations\nfollowing a similar approach.", "AI": {"tldr": "The paper evaluates translations of the Grievance Dictionary into Dutch, German, and Italian, finding Dutch and German comparable to English, while Italian shows lower reliability.", "motivation": "To extend the Grievance Dictionary's utility to non-English languages for analyzing violent or grievance-fuelled texts.", "method": "Automated translation supplemented by human annotation, followed by psychometric analyses (internal reliability, LIWC correlations).", "result": "Dutch and German translations perform similarly to English; Italian has low reliability in some categories.", "conclusion": "Suggestions for further validation and application, plus future translations using a similar approach."}}
{"id": "2505.06831", "pdf": "https://arxiv.org/pdf/2505.06831", "abs": "https://arxiv.org/abs/2505.06831", "authors": ["Miaoyun Zhao", "Qiang Zhang", "Chenrong Li"], "title": "Fine-Grained Bias Exploration and Mitigation for Group-Robust Classification", "categories": ["cs.CV"], "comment": null, "summary": "Achieving group-robust generalization in the presence of spurious\ncorrelations remains a significant challenge, particularly when bias\nannotations are unavailable. Recent studies on Class-Conditional Distribution\nBalancing (CCDB) reveal that spurious correlations often stem from mismatches\nbetween the class-conditional and marginal distributions of bias attributes.\nThey achieve promising results by addressing this issue through simple\ndistribution matching in a bias-agnostic manner. However, CCDB approximates\neach distribution using a single Gaussian, which is overly simplistic and\nrarely holds in real-world applications. To address this limitation, we propose\na novel method called Bias Exploration via Overfitting (BEO), which captures\neach distribution in greater detail by modeling it as a mixture of latent\ngroups. Building on these group-level descriptions, we introduce a fine-grained\nvariant of CCDB, termed FG-CCDB, which performs more precise distribution\nmatching and balancing within each group. Through group-level reweighting,\nFG-CCDB learns sample weights from a global perspective, achieving stronger\nmitigation of spurious correlations without incurring substantial storage or\ncomputational costs. Extensive experiments demonstrate that BEO serves as a\nstrong proxy for ground-truth bias annotations and can be seamlessly integrated\nwith bias-supervised methods. Moreover, when combined with FG-CCDB, our method\nperforms on par with bias-supervised approaches on binary classification tasks\nand significantly outperforms them in highly biased multi-class scenarios.", "AI": {"tldr": "The paper proposes Bias Exploration via Overfitting (BEO) and FG-CCDB to address spurious correlations in group-robust generalization without bias annotations, outperforming bias-supervised methods in multi-class tasks.", "motivation": "Spurious correlations due to mismatched distributions in bias-agnostic settings pose challenges, and existing methods like CCDB oversimplify distributions.", "method": "BEO models distributions as mixtures of latent groups, while FG-CCDB performs fine-grained distribution matching and balancing within groups.", "result": "BEO acts as a proxy for bias annotations, and FG-CCDB matches or surpasses bias-supervised methods, especially in multi-class scenarios.", "conclusion": "The proposed methods effectively mitigate spurious correlations without bias annotations, offering practical and scalable solutions."}}
{"id": "2505.07531", "pdf": "https://arxiv.org/pdf/2505.07531", "abs": "https://arxiv.org/abs/2505.07531", "authors": ["Khurram Mazher", "Saad Bin Nasir"], "title": "QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads", "categories": ["cs.AI"], "comment": null, "summary": "We present QuantX: a tailored suite of recipes for LLM and VLM quantization.\nIt is capable of quantizing down to 3-bit resolutions with minimal loss in\nperformance. The quantization strategies in QuantX take into account\nhardware-specific constraints to achieve efficient dequantization during\ninference ensuring flexible trade-off between runtime speed, memory requirement\nand model accuracy. Our results demonstrate that QuantX achieves performance\nwithin 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for\nmultiple end user tasks and outperforms recently published state-of-the-art\nquantization techniques. This manuscript provides insights into the LLM\nquantization process that motivated the range of recipes and options that are\nincorporated in QuantX.", "AI": {"tldr": "QuantX is a suite for LLM/VLM quantization, achieving 3-bit resolution with minimal performance loss, optimized for hardware constraints and outperforming state-of-the-art methods.", "motivation": "To address the need for efficient quantization of LLMs/VLMs with minimal performance loss while considering hardware-specific constraints.", "method": "QuantX employs tailored quantization strategies, including hardware-aware dequantization, to balance speed, memory, and accuracy.", "result": "QuantX achieves performance within 6% of unquantized models (e.g., LlaVa-v1.6 at 3-bits) and outperforms recent SOTA methods.", "conclusion": "QuantX provides effective quantization recipes, offering insights and options for LLM/VLM quantization with practical trade-offs."}}
{"id": "2505.06371", "pdf": "https://arxiv.org/pdf/2505.06371", "abs": "https://arxiv.org/abs/2505.06371", "authors": ["Jae-Won Chung", "Jiachen Liu", "Jeff J. Ma", "Ruofan Wu", "Oh Jun Kweon", "Yuxuan Xia", "Zhiyu Wu", "Mosharaf Chowdhury"], "title": "The ML.ENERGY Benchmark: Toward Automated Inference Energy Measurement and Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Leaderboard: https://ml.energy/leaderboard", "summary": "As the adoption of Generative AI in real-world services grow explosively,\nenergy has emerged as a critical bottleneck resource. However, energy remains a\nmetric that is often overlooked, under-explored, or poorly understood in the\ncontext of building ML systems. We present the ML.ENERGY Benchmark, a benchmark\nsuite and tool for measuring inference energy consumption under realistic\nservice environments, and the corresponding ML.ENERGY Leaderboard, which have\nserved as a valuable resource for those hoping to understand and optimize the\nenergy consumption of their generative AI services. In this paper, we explain\nfour key design principles for benchmarking ML energy we have acquired over\ntime, and then describe how they are implemented in the ML.ENERGY Benchmark. We\nthen highlight results from the latest iteration of the benchmark, including\nenergy measurements of 40 widely used model architectures across 6 different\ntasks, case studies of how ML design choices impact energy consumption, and how\nautomated optimization recommendations can lead to significant (sometimes more\nthan 40%) energy savings without changing what is being computed by the model.\nThe ML.ENERGY Benchmark is open-source and can be easily extended to various\ncustomized models and application scenarios.", "AI": {"tldr": "The paper introduces the ML.ENERGY Benchmark, a tool for measuring and optimizing energy consumption in generative AI services, highlighting its design principles, implementation, and significant energy-saving results.", "motivation": "Energy is a critical but often overlooked bottleneck in ML systems, especially with the rapid adoption of generative AI in real-world services.", "method": "The ML.ENERGY Benchmark suite measures inference energy consumption in realistic service environments, with a leaderboard for tracking performance and optimization.", "result": "The benchmark includes energy measurements of 40 model architectures across 6 tasks, showing how design choices impact energy and automated optimizations can save over 40% energy.", "conclusion": "The ML.ENERGY Benchmark is a valuable, open-source tool for understanding and reducing energy consumption in generative AI services, adaptable to various models and scenarios."}}
{"id": "2505.07512", "pdf": "https://arxiv.org/pdf/2505.07512", "abs": "https://arxiv.org/abs/2505.07512", "authors": ["Xu Huang", "Weiwen Liu", "Xingshan Zeng", "Yuefeng Huang", "Xinlong Hao", "Yuxian Wang", "Yirong Zeng", "Chuhan Wu", "Yasheng Wang", "Ruiming Tang", "Defu Lian"], "title": "ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The tool-using capability of large language models (LLMs) enables them to\naccess up-to-date external information and handle complex tasks. Current\napproaches to enhancing this capability primarily rely on distilling advanced\nmodels by data synthesis. However, this method incurs significant costs\nassociated with advanced model usage and often results in data compatibility\nissues, led by the high discrepancy in the knowledge scope between the advanced\nmodel and the target model. To address these challenges, we propose\nToolACE-DEV, a self-improving framework for tool learning. First, we decompose\nthe tool-learning objective into sub-tasks that enhance basic tool-making and\ntool-using abilities. Then, we introduce a self-evolving paradigm that allows\nlightweight models to self-improve, reducing reliance on advanced LLMs.\nExtensive experiments validate the effectiveness of our approach across models\nof varying scales and architectures.", "AI": {"tldr": "ToolACE-DEV is a self-improving framework for tool learning in LLMs, reducing reliance on costly advanced models by decomposing tasks and enabling self-evolution.", "motivation": "Current methods for enhancing tool-using capability in LLMs are costly and suffer from data compatibility issues due to knowledge scope discrepancies.", "method": "Decomposes tool-learning into sub-tasks and introduces a self-evolving paradigm for lightweight models.", "result": "Validated effectiveness across models of varying scales and architectures.", "conclusion": "ToolACE-DEV offers a cost-effective, scalable solution for improving tool-using capabilities in LLMs."}}
{"id": "2505.06840", "pdf": "https://arxiv.org/pdf/2505.06840", "abs": "https://arxiv.org/abs/2505.06840", "authors": ["Yixin Chen", "Shuai Zhang", "Boran Han", "Bernie Wang"], "title": "Visual Instruction Tuning with Chain of Region-of-Interest", "categories": ["cs.CV"], "comment": "N/A", "summary": "High-resolution (HR) images are pivotal for enhancing the recognition and\nunderstanding capabilities of multimodal large language models (MLLMs).\nHowever, directly increasing image resolution can significantly escalate\ncomputational demands. In this study, we propose a method called Chain of\nRegion-of-Interest (CoRoI) for Visual Instruction Tuning, aimed at alleviating\nthe computational burden associated with high-resolution images for MLLMs.\nDrawing inspiration from the selective nature of the human visual system, we\nrecognize that not all regions within high-resolution images carry equal\nimportance. CoRoI seeks to identify and prioritize the most informative\nregions, thereby enhancing multimodal visual comprehension and recognition\nwhile circumventing the need for processing lengthy HR image tokens. Through\nextensive experiments on 11 benchmarks, we validate the efficacy of CoRoI\nacross varying sizes, ranging from 7B to 34B in parameters. Our models\nconsistently demonstrate superior performance across diverse multimodal\nbenchmarks and tasks. Notably, our method outperforms LLaVA-NeXT on almost all\nbenchmarks and our finetuned 34B model surpasses proprietary methods like\nGemini Pro 1.0 on six benchmarks, as well as outperforming GPT-4V on MMB,\nSEED-I, and MME.", "AI": {"tldr": "CoRoI method reduces computational load of high-resolution images for MLLMs by focusing on key regions, outperforming benchmarks like LLaVA-NeXT and GPT-4V.", "motivation": "High-resolution images improve MLLM performance but increase computational demands; CoRoI addresses this by prioritizing informative regions.", "method": "CoRoI identifies and prioritizes key regions in high-resolution images, inspired by the human visual system, to reduce token processing.", "result": "Outperforms LLaVA-NeXT and proprietary models like Gemini Pro 1.0 and GPT-4V on multiple benchmarks.", "conclusion": "CoRoI effectively balances computational efficiency and performance for MLLMs with high-resolution images."}}
{"id": "2505.07581", "pdf": "https://arxiv.org/pdf/2505.07581", "abs": "https://arxiv.org/abs/2505.07581", "authors": ["Lei Wang", "Heyang Gao", "Xiaohe Bo", "Xu Chen", "Ji-Rong Wen"], "title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Leveraging large language model (LLM) based agents to simulate human social\nbehaviors has recently gained significant attention. In this paper, we\nintroduce a novel social simulator called YuLan-OneSim. Compared to previous\nworks, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free\nscenario construction: Users can simply describe and refine their simulation\nscenarios through natural language interactions with our simulator. All\nsimulation code is automatically generated, significantly reducing the need for\nprogramming expertise. (2) Comprehensive default scenarios: We implement 50\ndefault simulation scenarios spanning 8 domains, including economics,\nsociology, politics, psychology, organization, demographics, law, and\ncommunication, broadening access for a diverse range of social researchers. (3)\nEvolvable simulation: Our simulator is capable of receiving external feedback\nand automatically fine-tuning the backbone LLMs, significantly enhancing the\nsimulation quality. (4) Large-scale simulation: By developing a fully\nresponsive agent framework and a distributed simulation architecture, our\nsimulator can handle up to 100,000 agents, ensuring more stable and reliable\nsimulation results. (5) AI social researcher: Leveraging the above features, we\ndevelop an AI social researcher. Users only need to propose a research topic,\nand the AI researcher will automatically analyze the input, construct\nsimulation environments, summarize results, generate technical reports, review\nand refine the reports--completing the social science research loop. To\ndemonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate\nthe quality of the automatically generated scenarios, the reliability,\nefficiency, and scalability of the simulation process, as well as the\nperformance of the AI social researcher.", "AI": {"tldr": "YuLan-OneSim is a novel LLM-based social simulator enabling code-free scenario construction, large-scale simulations, and an AI social researcher, validated through experiments.", "motivation": "To simplify and enhance social behavior simulations by reducing programming needs and expanding accessibility for diverse researchers.", "method": "Develops a code-free, evolvable, and scalable simulator with default scenarios and an AI researcher for automated social science research.", "result": "Supports 100,000 agents, improves simulation quality via feedback, and automates research tasks like report generation.", "conclusion": "YuLan-OneSim advances social simulation by combining ease of use, scalability, and AI-driven research capabilities."}}
{"id": "2505.06384", "pdf": "https://arxiv.org/pdf/2505.06384", "abs": "https://arxiv.org/abs/2505.06384", "authors": ["Aditya Mishra", "Haroon Lone"], "title": "RiM: Record, Improve and Maintain Physical Well-being using Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.CY"], "comment": "Report submitted in partial fulfilment of the requirements for the\n  award of the degree of Bachelor of Science (BS) in Electrical Engineering and\n  Computer Science", "summary": "In academic settings, the demanding environment often forces students to\nprioritize academic performance over their physical well-being. Moreover,\nprivacy concerns and the inherent risk of data breaches hinder the deployment\nof traditional machine learning techniques for addressing these health\nchallenges. In this study, we introduce RiM: Record, Improve, and Maintain, a\nmobile application which incorporates a novel personalized machine learning\nframework that leverages federated learning to enhance students' physical\nwell-being by analyzing their lifestyle habits. Our approach involves\npre-training a multilayer perceptron (MLP) model on a large-scale simulated\ndataset to generate personalized recommendations. Subsequently, we employ\nfederated learning to fine-tune the model using data from IISER Bhopal\nstudents, thereby ensuring its applicability in real-world scenarios. The\nfederated learning approach guarantees differential privacy by exclusively\nsharing model weights rather than raw data. Experimental results show that the\nFedAvg-based RiM model achieves an average accuracy of 60.71% and a mean\nabsolute error of 0.91--outperforming the FedPer variant (average accuracy\n46.34%, MAE 1.19)--thereby demonstrating its efficacy in predicting lifestyle\ndeficits under privacy-preserving constraints.", "AI": {"tldr": "RiM is a mobile app using federated learning to improve students' physical well-being while ensuring privacy.", "motivation": "Addressing students' neglect of physical health due to academic pressures and privacy concerns in traditional ML methods.", "method": "Uses a pre-trained MLP model on simulated data, fine-tuned via federated learning with student data, ensuring privacy by sharing only model weights.", "result": "FedAvg-based RiM achieves 60.71% accuracy and 0.91 MAE, outperforming FedPer.", "conclusion": "RiM effectively predicts lifestyle deficits while preserving privacy, proving its real-world applicability."}}
{"id": "2505.07528", "pdf": "https://arxiv.org/pdf/2505.07528", "abs": "https://arxiv.org/abs/2505.07528", "authors": ["Lei Wang"], "title": "SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) models frequently encounter\nhallucination phenomena when integrating external information with internal\nparametric knowledge. Empirical studies demonstrate that the disequilibrium\nbetween external contextual information and internal parametric knowledge\nconstitutes a primary factor in hallucination generation. Existing\nhallucination detection methodologies predominantly emphasize either the\nexternal or internal mechanism in isolation, thereby overlooking their\nsynergistic effects. The recently proposed ReDeEP framework decouples these\ndual mechanisms, identifying two critical contributors to hallucinations:\nexcessive reliance on parametric knowledge encoded in feed-forward networks\n(FFN) and insufficient utilization of external information by attention\nmechanisms (particularly copy heads). ReDeEP quantitatively assesses these\nfactors to detect hallucinations and dynamically modulates the contributions of\nFFNs and copy heads to attenuate their occurrence. Nevertheless, ReDeEP and\nnumerous other hallucination detection approaches have been employed at\nlogit-level uncertainty estimation or language-level self-consistency\nevaluation, inadequately address the semantic dimensions of model responses,\nresulting in inconsistent hallucination assessments in RAG implementations.\nBuilding upon ReDeEP's foundation, this paper introduces SEReDeEP, which\nenhances computational processes through semantic entropy captured via trained\nlinear probes, thereby achieving hallucination assessments that more accurately\nreflect ground truth evaluations.", "AI": {"tldr": "SEReDeEP improves hallucination detection in RAG models by incorporating semantic entropy, addressing limitations of prior methods like ReDeEP.", "motivation": "Existing hallucination detection methods focus on isolated mechanisms (external or internal), missing their synergy. ReDeEP decouples these but lacks semantic evaluation, leading to inconsistent assessments.", "method": "SEReDeEP enhances ReDeEP by using semantic entropy from trained linear probes for more accurate hallucination detection.", "result": "SEReDeEP provides better hallucination assessments by capturing semantic dimensions, aligning more closely with ground truth evaluations.", "conclusion": "Incorporating semantic entropy improves hallucination detection in RAG models, addressing gaps in prior approaches."}}
{"id": "2505.06853", "pdf": "https://arxiv.org/pdf/2505.06853", "abs": "https://arxiv.org/abs/2505.06853", "authors": ["Carolina Vargas-Ecos", "Edwin Salcedo"], "title": "Predicting Surgical Safety Margins in Osteosarcoma Knee Resections: An Unsupervised Approach", "categories": ["cs.CV"], "comment": "Accepted for publication at the 6th BioSMART Conference, 2025", "summary": "According to the Pan American Health Organization, the number of cancer cases\nin Latin America was estimated at 4.2 million in 2022 and is projected to rise\nto 6.7 million by 2045. Osteosarcoma, one of the most common and deadly bone\ncancers affecting young people, is difficult to detect due to its unique\ntexture and intensity. Surgical removal of osteosarcoma requires precise safety\nmargins to ensure complete resection while preserving healthy tissue.\nTherefore, this study proposes a method for estimating the confidence interval\nof surgical safety margins in osteosarcoma surgery around the knee. The\nproposed approach uses MRI and X-ray data from open-source repositories,\ndigital processing techniques, and unsupervised learning algorithms (such as\nk-means clustering) to define tumor boundaries. Experimental results highlight\nthe potential for automated, patient-specific determination of safety margins.", "AI": {"tldr": "A method using MRI/X-ray data and unsupervised learning to estimate surgical safety margins for osteosarcoma around the knee.", "motivation": "Rising cancer cases in Latin America and the challenge of precise osteosarcoma resection due to its unique texture and intensity.", "method": "Uses MRI and X-ray data, digital processing, and k-means clustering to define tumor boundaries.", "result": "Demonstrates potential for automated, patient-specific safety margin determination.", "conclusion": "Proposed approach could improve precision in osteosarcoma surgery."}}
{"id": "2505.07686", "pdf": "https://arxiv.org/pdf/2505.07686", "abs": "https://arxiv.org/abs/2505.07686", "authors": ["Muzhi Dai", "Chenxu Yang", "Qingyi Si"], "title": "S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As Test-Time Scaling emerges as an active research focus in the large\nlanguage model community, advanced post-training methods increasingly emphasize\nextending chain-of-thought (CoT) generation length, thereby enhancing reasoning\ncapabilities to approach Deepseek R1-like reasoning models. However, recent\nstudies reveal that reasoning models (even Qwen3) consistently exhibit\nexcessive thought redundancy in CoT generation. This overthinking problem stems\nfrom conventional outcome-reward reinforcement learning's systematic neglect in\nregulating intermediate reasoning steps. This paper proposes Serial-Group\nDecaying-Reward Policy Optimization (namely S-GRPO), a novel reinforcement\nlearning method that empowers models with the capability to determine the\nsufficiency of reasoning steps, subsequently triggering early exit of CoT\ngeneration. Specifically, unlike GRPO, which samples multiple possible\ncompletions (parallel group) in parallel, we select multiple temporal positions\nin the generation of one CoT to allow the model to exit thinking and instead\ngenerate answers (serial group), respectively. For the correct answers in a\nserial group, we assign rewards that decay according to positions, with lower\nrewards towards the later ones, thereby reinforcing the model's behavior to\ngenerate higher-quality answers at earlier phases with earlier exits of\nthinking. Empirical evaluations demonstrate compatibility with state-of-the-art\nreasoning models, including Qwen3 and Deepseek-distill models, achieving 35.4%\n~ 61.1\\% sequence length reduction with 0.72% ~ 6.08% accuracy improvements\nacross GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond benchmarks.", "AI": {"tldr": "The paper introduces S-GRPO, a reinforcement learning method to reduce redundant reasoning steps in chain-of-thought (CoT) generation, improving efficiency and accuracy.", "motivation": "Addressing the overthinking problem in reasoning models, where excessive redundancy in CoT steps occurs due to neglected regulation of intermediate reasoning.", "method": "Proposes Serial-Group Decaying-Reward Policy Optimization (S-GRPO), which allows models to exit CoT generation early by rewarding earlier, higher-quality answers with decaying rewards.", "result": "Achieves 35.4%\u201361.1% sequence length reduction and 0.72%\u20136.08% accuracy improvements across multiple benchmarks.", "conclusion": "S-GRPO effectively balances reasoning efficiency and accuracy, demonstrating compatibility with advanced models like Qwen3 and Deepseek-distill."}}
{"id": "2505.06445", "pdf": "https://arxiv.org/pdf/2505.06445", "abs": "https://arxiv.org/abs/2505.06445", "authors": ["Yan Zheng", "Qiang Chen", "Chenglei Niu"], "title": "Tweedie Regression for Video Recommendation System", "categories": ["cs.LG", "cs.IR"], "comment": "ICMI 2025 IEEE 4th International Conference on Computing and Machine\n  Intelligence April 05-06, 2025", "summary": "Modern recommendation systems aim to increase click-through rates (CTR) for\nbetter user experience, through commonly treating ranking as a classification\ntask focused on predicting CTR. However, there is a gap between this method and\nthe actual objectives of businesses across different sectors. In video\nrecommendation services, the objective of video on demand (VOD) extends beyond\nmerely encouraging clicks, but also guiding users to discover their true\ninterests, leading to increased watch time. And longer users watch time will\nleads to more revenue through increased chances of presenting online display\nadvertisements. This research addresses the issue by redefining the problem\nfrom classification to regression, with a focus on maximizing revenue through\nuser viewing time. Due to the lack of positive labels on recommendation, the\nstudy introduces Tweedie Loss Function, which is better suited in this scenario\nthan the traditional mean square error loss. The paper also provides insights\non how Tweedie process capture users diverse interests. Our offline simulation\nand online A/B test revealed that we can substantially enhance our core\nbusiness objectives: user engagement in terms of viewing time and,\nconsequently, revenue. Additionally, we provide a theoretical comparison\nbetween the Tweedie Loss and the commonly employed viewing time weighted\nLogloss, highlighting why Tweedie Regression stands out as an efficient\nsolution. We further outline a framework for designing a loss function that\nfocuses on a singular objective.", "AI": {"tldr": "The paper redefines video recommendation from CTR classification to regression, using Tweedie Loss to maximize revenue via user watch time, outperforming traditional methods.", "motivation": "Businesses aim for more than clicks; they seek increased watch time for higher ad revenue, which CTR-focused methods don't address.", "method": "Switches from classification to regression, introducing Tweedie Loss for better handling of sparse positive labels and diverse user interests.", "result": "Offline and online tests show improved user engagement (watch time) and revenue, with Tweedie Loss outperforming traditional metrics.", "conclusion": "Tweedie Regression is more effective for revenue-focused video recommendations, offering a framework for single-objective loss function design."}}
{"id": "2505.07591", "pdf": "https://arxiv.org/pdf/2505.07591", "abs": "https://arxiv.org/abs/2505.07591", "authors": ["Junjie Ye", "Caishuang Huang", "Zhuohan Chen", "Wenjie Fu", "Chenyuan Yang", "Leyi Yang", "Yilong Wu", "Peng Wang", "Meng Zhou", "Xiaolong Yang", "Tao Gui", "Qi Zhang", "Zhongchao Shi", "Jianping Fan", "Xuanjing Huang"], "title": "A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Instruction following evaluates large language models (LLMs) on their ability\nto generate outputs that adhere to user-defined constraints. However, existing\nbenchmarks often rely on templated constraint prompts, which lack the diversity\nof real-world usage and limit fine-grained performance assessment. To fill this\ngap, we propose a multi-dimensional constraint framework encompassing three\nconstraint patterns, four constraint categories, and four difficulty levels.\nBuilding on this framework, we develop an automated instruction generation\npipeline that performs constraint expansion, conflict detection, and\ninstruction rewriting, yielding 1,200 code-verifiable instruction-following\ntest samples. We evaluate 19 LLMs across seven model families and uncover\nsubstantial variation in performance across constraint forms. For instance,\naverage performance drops from 77.67% at Level I to 32.96% at Level IV.\nFurthermore, we demonstrate the utility of our approach by using it to generate\ndata for reinforcement learning, achieving substantial gains in instruction\nfollowing without degrading general performance. In-depth analysis indicates\nthat these gains stem primarily from modifications in the model's attention\nmodules parameters, which enhance constraint recognition and adherence. Code\nand data are available in https://github.com/Junjie-Ye/MulDimIF.", "AI": {"tldr": "The paper introduces a multi-dimensional constraint framework to evaluate LLMs' instruction-following abilities, addressing limitations of existing benchmarks. It includes automated test generation and evaluates 19 LLMs, revealing performance variations. The framework also aids reinforcement learning, improving instruction adherence without compromising general performance.", "motivation": "Existing benchmarks for LLMs lack diversity and fine-grained assessment, limiting their real-world applicability. The paper aims to address this gap with a more comprehensive framework.", "method": "Proposes a multi-dimensional constraint framework (3 patterns, 4 categories, 4 difficulty levels) and an automated pipeline for generating 1,200 test samples. Evaluates 19 LLMs across these constraints.", "result": "Performance varies significantly across constraint forms (e.g., 77.67% at Level I vs. 32.96% at Level IV). The framework also improves reinforcement learning outcomes by enhancing constraint recognition.", "conclusion": "The framework provides a robust tool for assessing and improving LLMs' instruction-following capabilities, with practical applications in reinforcement learning."}}
{"id": "2505.06855", "pdf": "https://arxiv.org/pdf/2505.06855", "abs": "https://arxiv.org/abs/2505.06855", "authors": ["Zhengmi Tang", "Yuto Mitsui", "Tomo Miyazaki", "Shinichiro Omachi"], "title": "Joint Low-level and High-level Textual Representation Learning with Multiple Masking Strategies", "categories": ["cs.CV"], "comment": null, "summary": "Most existing text recognition methods are trained on large-scale synthetic\ndatasets due to the scarcity of labeled real-world datasets. Synthetic images,\nhowever, cannot faithfully reproduce real-world scenarios, such as uneven\nillumination, irregular layout, occlusion, and degradation, resulting in\nperformance disparities when handling complex real-world images. Recent\nself-supervised learning techniques, notably contrastive learning and masked\nimage modeling (MIM), narrow this domain gap by exploiting unlabeled real text\nimages. This study first analyzes the original Masked AutoEncoder (MAE) and\nobserves that random patch masking predominantly captures low-level textural\nfeatures but misses high-level contextual representations. To fully exploit the\nhigh-level contextual representations, we introduce random blockwise and span\nmasking in the text recognition task. These strategies can mask the continuous\nimage patches and completely remove some characters, forcing the model to infer\nrelationships among characters within a word. Our Multi-Masking Strategy (MMS)\nintegrates random patch, blockwise, and span masking into the MIM frame, which\njointly learns low and high-level textual representations. After fine-tuning\nwith real data, MMS outperforms the state-of-the-art self-supervised methods in\nvarious text-related tasks, including text recognition, segmentation, and\ntext-image super-resolution.", "AI": {"tldr": "The paper introduces a Multi-Masking Strategy (MMS) to improve text recognition by combining random patch, blockwise, and span masking in masked image modeling (MIM), outperforming existing self-supervised methods.", "motivation": "Existing text recognition methods rely on synthetic datasets, which fail to replicate real-world complexities like uneven illumination and occlusion. Self-supervised learning, particularly MIM, helps bridge this gap but misses high-level contextual features.", "method": "The study enhances MIM by introducing random blockwise and span masking alongside random patch masking. This forces the model to infer character relationships, improving contextual understanding.", "result": "MMS outperforms state-of-the-art self-supervised methods in text recognition, segmentation, and text-image super-resolution after fine-tuning with real data.", "conclusion": "The proposed MMS effectively combines masking strategies to capture both low and high-level textual features, enhancing performance in real-world text recognition tasks."}}
{"id": "2505.07693", "pdf": "https://arxiv.org/pdf/2505.07693", "abs": "https://arxiv.org/abs/2505.07693", "authors": ["Sebastian Dumbrava"], "title": "Belief Injection for Epistemic Control in Linguistic State Space", "categories": ["cs.AI"], "comment": "30 pages, 9 figures", "summary": "This work introduces belief injection, a proactive epistemic control\nmechanism for artificial agents whose cognitive states are structured as\ndynamic ensembles of linguistic belief fragments. Grounded in the Semantic\nManifold framework, belief injection directly incorporates targeted linguistic\nbeliefs into an agent's internal cognitive state, influencing reasoning and\nalignment proactively rather than reactively. We delineate various injection\nstrategies, such as direct, context-aware, goal-oriented, and reflective\napproaches, and contrast belief injection with related epistemic control\nmechanisms, notably belief filtering. Additionally, this work discusses\npractical applications, implementation considerations, ethical implications,\nand outlines promising directions for future research into cognitive governance\nusing architecturally embedded belief injection.", "AI": {"tldr": "Belief injection is a proactive method for influencing AI agents' cognitive states using linguistic beliefs, contrasting with reactive methods like belief filtering.", "motivation": "To enhance AI reasoning and alignment by directly embedding targeted linguistic beliefs into agents' cognitive frameworks.", "method": "Introduces belief injection strategies (direct, context-aware, goal-oriented, reflective) within the Semantic Manifold framework.", "result": "Provides a framework for proactive epistemic control, with practical applications and ethical considerations.", "conclusion": "Belief injection offers a promising direction for cognitive governance, with future research needed for implementation and ethical refinement."}}
{"id": "2505.06446", "pdf": "https://arxiv.org/pdf/2505.06446", "abs": "https://arxiv.org/abs/2505.06446", "authors": ["Jessie Finocchiaro", "Rafael Frongillo", "Enrique Nueve"], "title": "Structured Prediction with Abstention via the Lov\u00e1sz Hinge", "categories": ["cs.LG"], "comment": "This paper is an extension of the work \"The Structured Abstain\n  Problem and the Lov\\'asz Hinge\" (arXiv:2203.08645) via the original authors", "summary": "The Lov\\'asz hinge is a convex loss function proposed for binary structured\nclassification, in which k related binary predictions jointly evaluated by a\nsubmodular function. Despite its prevalence in image segmentation and related\ntasks, the consistency of the Lov\\'asz hinge has remained open. We show that\nthe Lov\\'asz hinge is inconsistent with its desired target unless the set\nfunction used for evaluation is modular. Leveraging the embedding framework of\nFinocchiaro et al. (2024), we find the target loss for which the Lov\\'asz hinge\nis consistent. This target, which we call the structured abstain problem, is a\nvariant of selective classification for structured prediction that allows one\nto abstain on any subset of the k binary predictions. We derive a family of\nlink functions, each of which is simultaneously consistent for all\npolymatroids, a subset of submodular set functions. We then give sufficient\nconditions on the polymatroid for the structured abstain problem to be tightly\nembedded by the Lov\\'asz hinge, meaning no target prediction is redundant. We\nexperimentally demonstrate the potential of the structured abstain problem for\ninterpretability in structured classification tasks. Finally, for the\nmulticlass setting, we show that one can combine the binary encoding\nconstruction of Ramaswamy et al. (2018) with our link construction to achieve\nan efficient consistent surrogate for a natural multiclass generalization of\nthe structured abstain problem.", "AI": {"tldr": "The Lov\u00e1sz hinge is inconsistent for binary structured classification unless the evaluation function is modular. A consistent target loss, the structured abstain problem, is identified, along with link functions for polymatroids. Tight embedding conditions and experimental validation are provided, with extensions to multiclass settings.", "motivation": "To address the inconsistency of the Lov\u00e1sz hinge in binary structured classification and identify a consistent target loss for improved interpretability and performance.", "method": "Leveraging the embedding framework, the structured abstain problem is introduced, with consistent link functions for polymatroids. Tight embedding conditions are derived and validated experimentally.", "result": "The Lov\u00e1sz hinge is consistent only for modular functions. The structured abstain problem and link functions provide consistency for polymatroids, with experimental validation.", "conclusion": "The structured abstain problem and derived link functions offer a consistent solution for binary and multiclass structured classification, enhancing interpretability and performance."}}
{"id": "2505.07596", "pdf": "https://arxiv.org/pdf/2505.07596", "abs": "https://arxiv.org/abs/2505.07596", "authors": ["Ziyang Huang", "Xiaowei Yuan", "Yiming Ju", "Jun Zhao", "Kang Liu"], "title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) is a common strategy to reduce\nhallucinations in Large Language Models (LLMs). While reinforcement learning\n(RL) can enable LLMs to act as search agents by activating retrieval\ncapabilities, existing ones often underutilize their internal knowledge. This\ncan lead to redundant retrievals, potential harmful knowledge conflicts, and\nincreased inference latency. To address these limitations, an efficient and\nadaptive search agent capable of discerning optimal retrieval timing and\nsynergistically integrating parametric (internal) and retrieved (external)\nknowledge is in urgent need. This paper introduces the Reinforced\nInternal-External Knowledge Synergistic Reasoning Agent (IKEA), which could\nindentify its own knowledge boundary and prioritize the utilization of internal\nknowledge, resorting to external search only when internal knowledge is deemed\ninsufficient. This is achieved using a novel knowledge-boundary aware reward\nfunction and a knowledge-boundary aware training dataset. These are designed\nfor internal-external knowledge synergy oriented RL, incentivizing the model to\ndeliver accurate answers, minimize unnecessary retrievals, and encourage\nappropriate external searches when its own knowledge is lacking. Evaluations\nacross multiple knowledge reasoning tasks demonstrate that IKEA significantly\noutperforms baseline methods, reduces retrieval frequency significantly, and\nexhibits robust generalization capabilities.", "AI": {"tldr": "IKEA is a retrieval-augmented LLM agent that optimizes retrieval timing and integrates internal and external knowledge efficiently, reducing hallucinations and latency.", "motivation": "Existing RL-based LLM search agents underutilize internal knowledge, leading to redundant retrievals, harmful conflicts, and increased latency.", "method": "IKEA uses a knowledge-boundary aware reward function and training dataset for RL, prioritizing internal knowledge and retrieving externally only when necessary.", "result": "IKEA outperforms baselines, reduces retrieval frequency, and shows strong generalization in knowledge reasoning tasks.", "conclusion": "IKEA effectively balances internal and external knowledge, improving efficiency and accuracy in LLM-based retrieval-augmented generation."}}
{"id": "2505.06881", "pdf": "https://arxiv.org/pdf/2505.06881", "abs": "https://arxiv.org/abs/2505.06881", "authors": ["Hamd Jalil", "Ahmed Qazi", "Asim Iqbal"], "title": "NeuRN: Neuro-inspired Domain Generalization for Image Classification", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "comment": "14 pages, 7 figures, 1 table", "summary": "Domain generalization in image classification is a crucial challenge, with\nmodels often failing to generalize well across unseen datasets. We address this\nissue by introducing a neuro-inspired Neural Response Normalization (NeuRN)\nlayer which draws inspiration from neurons in the mammalian visual cortex,\nwhich aims to enhance the performance of deep learning architectures on unseen\ntarget domains by training deep learning models on a source domain. The\nperformance of these models is considered as a baseline and then compared\nagainst models integrated with NeuRN on image classification tasks. We perform\nexperiments across a range of deep learning architectures, including ones\nderived from Neural Architecture Search and Vision Transformer. Additionally,\nin order to shortlist models for our experiment from amongst the vast range of\ndeep neural networks available which have shown promising results, we also\npropose a novel method that uses the Needleman-Wunsch algorithm to compute\nsimilarity between deep learning architectures. Our results demonstrate the\neffectiveness of NeuRN by showing improvement against baseline in cross-domain\nimage classification tasks. Our framework attempts to establish a foundation\nfor future neuro-inspired deep learning models.", "AI": {"tldr": "The paper introduces a neuro-inspired Neural Response Normalization (NeuRN) layer to improve domain generalization in image classification, showing improved performance over baselines on unseen domains.", "motivation": "Addressing the challenge of models failing to generalize across unseen datasets in image classification.", "method": "Proposes NeuRN, inspired by mammalian visual cortex neurons, and a novel method using the Needleman-Wunsch algorithm to compare deep learning architectures.", "result": "NeuRN enhances performance on cross-domain image classification tasks compared to baseline models.", "conclusion": "The framework lays a foundation for future neuro-inspired deep learning models."}}
{"id": "2505.07757", "pdf": "https://arxiv.org/pdf/2505.07757", "abs": "https://arxiv.org/abs/2505.07757", "authors": ["Rintaro Ando"], "title": "Emotion-Gradient Metacognitive RSI (Part I): Theoretical Foundations and Single-Agent Architecture", "categories": ["cs.AI", "cs.LG", "F.1.2; I.2.0"], "comment": "21 pages, 3 figures. Part I of a four-part series (Parts II-IV\n  forthcoming)", "summary": "We present the Emotion-Gradient Metacognitive Recursive Self-Improvement\n(EG-MRSI) framework, a novel architecture that integrates introspective\nmetacognition, emotion-based intrinsic motivation, and recursive\nself-modification into a unified theoretical system. The framework is\nexplicitly capable of overwriting its own learning algorithm under formally\nbounded risk. Building upon the Noise-to-Meaning RSI (N2M-RSI) foundation,\nEG-MRSI introduces a differentiable intrinsic reward function driven by\nconfidence, error, novelty, and cumulative success. This signal regulates both\na metacognitive mapping and a self-modification operator constrained by\nprovable safety mechanisms. We formally define the initial agent configuration,\nemotion-gradient dynamics, and RSI trigger conditions, and derive a\nreinforcement-compatible optimization objective that guides the agent's\ndevelopment trajectory. Meaning Density and Meaning Conversion Efficiency are\nintroduced as quantifiable metrics of semantic learning, closing the gap\nbetween internal structure and predictive informativeness. This Part I paper\nestablishes the single-agent theoretical foundations of EG-MRSI. Future parts\nwill extend this framework to include safety certificates and rollback\nprotocols (Part II), collective intelligence mechanisms (Part III), and\nfeasibility constraints including thermodynamic and computational limits (Part\nIV). Together, the EG-MRSI series provides a rigorous, extensible foundation\nfor open-ended and safe AGI.", "AI": {"tldr": "The EG-MRSI framework integrates metacognition, emotion-based motivation, and recursive self-improvement for AGI, with provable safety and quantifiable learning metrics.", "motivation": "To create a unified, safe, and open-ended AGI framework by combining introspective metacognition, emotion-driven rewards, and recursive self-modification.", "method": "Introduces a differentiable intrinsic reward function, formalizes agent configuration and dynamics, and derives a reinforcement-compatible optimization objective.", "result": "Defines quantifiable metrics (Meaning Density, Meaning Conversion Efficiency) and establishes theoretical foundations for safe, recursive self-improvement.", "conclusion": "EG-MRSI provides a rigorous foundation for AGI, with future extensions planned for safety, collective intelligence, and feasibility constraints."}}
{"id": "2505.06454", "pdf": "https://arxiv.org/pdf/2505.06454", "abs": "https://arxiv.org/abs/2505.06454", "authors": ["Syed Mhamudul Hasan", "Hussein Zangoti", "Iraklis Anagnostopoulos", "Abdur R. Shahid"], "title": "Sponge Attacks on Sensing AI: Energy-Latency Vulnerabilities and Defense via Model Pruning", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Recent studies have shown that sponge attacks can significantly increase the\nenergy consumption and inference latency of deep neural networks (DNNs).\nHowever, prior work has focused primarily on computer vision and natural\nlanguage processing tasks, overlooking the growing use of lightweight AI models\nin sensing-based applications on resource-constrained devices, such as those in\nInternet of Things (IoT) environments. These attacks pose serious threats of\nenergy depletion and latency degradation in systems where limited battery\ncapacity and real-time responsiveness are critical for reliable operation. This\npaper makes two key contributions. First, we present the first systematic\nexploration of energy-latency sponge attacks targeting sensing-based AI models.\nUsing wearable sensing-based AI as a case study, we demonstrate that sponge\nattacks can substantially degrade performance by increasing energy consumption,\nleading to faster battery drain, and by prolonging inference latency. Second,\nto mitigate such attacks, we investigate model pruning, a widely adopted\ncompression technique for resource-constrained AI, as a potential defense. Our\nexperiments show that pruning-induced sparsity significantly improves model\nresilience against sponge poisoning. We also quantify the trade-offs between\nmodel efficiency and attack resilience, offering insights into the security\nimplications of model compression in sensing-based AI systems deployed in IoT\nenvironments.", "AI": {"tldr": "The paper explores energy-latency sponge attacks on sensing-based AI models in IoT, demonstrates their impact, and proposes pruning as a defense, balancing efficiency and resilience.", "motivation": "Address the overlooked threat of sponge attacks on lightweight AI models in IoT, where energy and latency are critical.", "method": "Systematically study sponge attacks on sensing-based AI, using wearable sensing as a case study, and evaluate pruning as a defense.", "result": "Sponge attacks degrade performance by increasing energy use and latency; pruning improves resilience but involves efficiency trade-offs.", "conclusion": "Pruning enhances attack resilience in sensing-based AI, but designers must weigh efficiency against security in IoT deployments."}}
{"id": "2505.07601", "pdf": "https://arxiv.org/pdf/2505.07601", "abs": "https://arxiv.org/abs/2505.07601", "authors": ["Edirlei Soares de Lima", "Marco A. Casanova", "Bruno Feij\u00f3", "Antonio L. Furtado"], "title": "Characterizing the Investigative Methods of Fictional Detectives with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Detective fiction, a genre defined by its complex narrative structures and\ncharacter-driven storytelling, presents unique challenges for computational\nnarratology, a research field focused on integrating literary theory into\nautomated narrative generation. While traditional literary studies have offered\ndeep insights into the methods and archetypes of fictional detectives, these\nanalyses often focus on a limited number of characters and lack the scalability\nneeded for the extraction of unique traits that can be used to guide narrative\ngeneration methods. In this paper, we present an AI-driven approach for\nsystematically characterizing the investigative methods of fictional\ndetectives. Our multi-phase workflow explores the capabilities of 15 Large\nLanguage Models (LLMs) to extract, synthesize, and validate distinctive\ninvestigative traits of fictional detectives. This approach was tested on a\ndiverse set of seven iconic detectives - Hercule Poirot, Sherlock Holmes,\nWilliam Murdoch, Columbo, Father Brown, Miss Marple, and Auguste Dupin -\ncapturing the distinctive investigative styles that define each character. The\nidentified traits were validated against existing literary analyses and further\ntested in a reverse identification phase, achieving an overall accuracy of\n91.43%, demonstrating the method's effectiveness in capturing the distinctive\ninvestigative approaches of each detective. This work contributes to the\nbroader field of computational narratology by providing a scalable framework\nfor character analysis, with potential applications in AI-driven interactive\nstorytelling and automated narrative generation.", "AI": {"tldr": "An AI-driven method analyzes fictional detectives' investigative traits using LLMs, achieving 91.43% accuracy, aiding computational narratology.", "motivation": "Traditional literary studies lack scalability for extracting detective traits for narrative generation.", "method": "Multi-phase workflow using 15 LLMs to extract, synthesize, and validate traits of seven iconic detectives.", "result": "91.43% accuracy in capturing distinctive investigative styles, validated against literary analyses.", "conclusion": "Provides a scalable framework for character analysis, useful for AI-driven storytelling and narrative generation."}}
{"id": "2505.06886", "pdf": "https://arxiv.org/pdf/2505.06886", "abs": "https://arxiv.org/abs/2505.06886", "authors": ["Ahmed Qazi", "Hamd Jalil", "Asim Iqbal"], "title": "Mice to Machines: Neural Representations from Visual Cortex for Domain Generalization", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "comment": "12 pages, 8 figures, 1 table", "summary": "The mouse is one of the most studied animal models in the field of systems\nneuroscience. Understanding the generalized patterns and decoding the neural\nrepresentations that are evoked by the diverse range of natural scene stimuli\nin the mouse visual cortex is one of the key quests in computational vision. In\nrecent years, significant parallels have been drawn between the primate visual\ncortex and hierarchical deep neural networks. However, their generalized\nefficacy in understanding mouse vision has been limited. In this study, we\ninvestigate the functional alignment between the mouse visual cortex and deep\nlearning models for object classification tasks. We first introduce a\ngeneralized representational learning strategy that uncovers a striking\nresemblance between the functional mapping of the mouse visual cortex and\nhigh-performing deep learning models on both top-down (population-level) and\nbottom-up (single cell-level) scenarios. Next, this representational similarity\nacross the two systems is further enhanced by the addition of Neural Response\nNormalization (NeuRN) layer, inspired by the activation profile of excitatory\nand inhibitory neurons in the visual cortex. To test the performance effect of\nNeuRN on real-world tasks, we integrate it into deep learning models and\nobserve significant improvements in their robustness against data shifts in\ndomain generalization tasks. Our work proposes a novel framework for comparing\nthe functional architecture of the mouse visual cortex with deep learning\nmodels. Our findings carry broad implications for the development of advanced\nAI models that draw inspiration from the mouse visual cortex, suggesting that\nthese models serve as valuable tools for studying the neural representations of\nthe mouse visual cortex and, as a result, enhancing their performance on\nreal-world tasks.", "AI": {"tldr": "The study explores the functional alignment between the mouse visual cortex and deep learning models, introducing a representational learning strategy and a Neural Response Normalization (NeuRN) layer to enhance similarity and improve model robustness.", "motivation": "To bridge the gap in understanding mouse vision using deep learning models, given the parallels between primate vision and hierarchical deep networks.", "method": "A generalized representational learning strategy and the NeuRN layer are introduced to align mouse visual cortex functionality with deep learning models, tested in domain generalization tasks.", "result": "Enhanced representational similarity between the mouse visual cortex and deep models, with NeuRN improving robustness against data shifts.", "conclusion": "The framework offers insights for AI model development inspired by the mouse visual cortex, improving both neuroscience understanding and real-world task performance."}}
{"id": "2505.07759", "pdf": "https://arxiv.org/pdf/2505.07759", "abs": "https://arxiv.org/abs/2505.07759", "authors": ["Jennifer Mondragon", "Carlos Rubio-Medrano", "Gael Cruz", "Dvijesh Shastri"], "title": "\"I Apologize For Not Understanding Your Policy\": Exploring the Specification and Evaluation of User-Managed Access Control Policies by AI Virtual Assistants", "categories": ["cs.AI"], "comment": null, "summary": "The rapid evolution of Artificial Intelligence (AI)-based Virtual Assistants\n(VAs) e.g., Google Gemini, ChatGPT, Microsoft Copilot, and High-Flyer Deepseek\nhas turned them into convenient interfaces for managing emerging technologies\nsuch as Smart Homes, Smart Cars, Electronic Health Records, by means of\nexplicit commands,e.g., prompts, which can be even launched via voice, thus\nproviding a very convenient interface for end-users. However, the proper\nspecification and evaluation of User-Managed Access Control Policies (U-MAPs),\nthe rules issued and managed by end-users to govern access to sensitive data\nand device functionality - within these VAs presents significant challenges,\nsince such a process is crucial for preventing security vulnerabilities and\nprivacy leaks without impacting user experience. This study provides an initial\nexploratory investigation on whether current publicly-available VAs can manage\nU-MAPs effectively across differing scenarios. By conducting unstructured to\nstructured tests, we evaluated the comprehension of such VAs, revealing a lack\nof understanding in varying U-MAP approaches. Our research not only identifies\nkey limitations, but offers valuable insights into how VAs can be further\nimproved to manage complex authorization rules and adapt to dynamic changes.", "AI": {"tldr": "The study evaluates AI-based Virtual Assistants (VAs) like ChatGPT and Google Gemini for managing User-Managed Access Control Policies (U-MAPs), finding limitations in their comprehension and suggesting improvements.", "motivation": "To assess whether current VAs can effectively handle U-MAPs, crucial for security and privacy without compromising user experience.", "method": "Conducted unstructured to structured tests to evaluate VAs' comprehension of U-MAPs across scenarios.", "result": "VAs showed a lack of understanding in managing varying U-MAP approaches.", "conclusion": "The study highlights limitations and provides insights for improving VAs in handling complex authorization rules and dynamic changes."}}
{"id": "2505.06459", "pdf": "https://arxiv.org/pdf/2505.06459", "abs": "https://arxiv.org/abs/2505.06459", "authors": ["Pablo Flores", "Olga Graf", "Pavlos Protopapas", "Karim Pichara"], "title": "Improved Uncertainty Quantification in Physics-Informed Neural Networks Using Error Bounds and Solution Bundles", "categories": ["cs.LG", "cs.AI", "physics.comp-ph", "stat.ML"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have been widely used to obtain\nsolutions to various physical phenomena modeled as Differential Equations. As\nPINNs are not naturally equipped with mechanisms for Uncertainty\nQuantification, some work has been done to quantify the different uncertainties\nthat arise when dealing with PINNs. In this paper, we use a two-step procedure\nto train Bayesian Neural Networks that provide uncertainties over the solutions\nto differential equation systems provided by PINNs. We use available error\nbounds over PINNs to formulate a heteroscedastic variance that improves the\nuncertainty estimation. Furthermore, we solve forward problems and utilize the\nobtained uncertainties when doing parameter estimation in inverse problems in\ncosmology.", "AI": {"tldr": "The paper proposes a two-step method to train Bayesian Neural Networks for uncertainty quantification in Physics-Informed Neural Networks (PINNs), improving uncertainty estimation using error bounds and applying it to cosmology problems.", "motivation": "PINNs lack built-in uncertainty quantification, which is crucial for reliable solutions in differential equation systems, especially in fields like cosmology.", "method": "A two-step procedure trains Bayesian Neural Networks, incorporating heteroscedastic variance derived from PINN error bounds for better uncertainty estimation.", "result": "Improved uncertainty quantification for PINN solutions, demonstrated in forward problems and parameter estimation in cosmology.", "conclusion": "The method enhances PINN reliability by providing robust uncertainty estimates, applicable to both forward and inverse problems in physics."}}
{"id": "2505.07608", "pdf": "https://arxiv.org/pdf/2505.07608", "abs": "https://arxiv.org/abs/2505.07608", "authors": ["Xiaomi LLM-Core Team", ":", "Bingquan Xia", "Bowen Shen", "Cici", "Dawei Zhu", "Di Zhang", "Gang Wang", "Hailin Zhang", "Huaqiu Liu", "Jiebao Xiao", "Jinhao Dong", "Liang Zhao", "Peidian Li", "Peng Wang", "Shihua Yu", "Shimao Chen", "Weikun Wang", "Wenhan Ma", "Xiangwei Deng", "Yi Huang", "Yifan Song", "Zihan Jiang", "Bowen Ye", "Can Cai", "Chenhong He", "Dong Zhang", "Duo Zhang", "Guoan Wang", "Hao Tian", "Haochen Zhao", "Heng Qu", "Hongshen Xu", "Jun Shi", "Kainan Bao", "QingKai Fang", "Kang Zhou", "Kangyang Zhou", "Lei Li", "Menghang Zhu", "Nuo Chen", "Qiantong Wang", "Shaohui Liu", "Shicheng Li", "Shuhao Gu", "Shuhuai Ren", "Shuo Liu", "Sirui Deng", "Weiji Zhuang", "Weiwei Lv", "Wenyu Yang", "Xin Zhang", "Xing Yong", "Xing Zhang", "Xingchen Song", "Xinzhe Xu", "Xu Wang", "Yihan Yan", "Yu Tu", "Yuanyuan Tian", "Yudong Wang", "Yue Yu", "Zhenru Lin", "Zhichao Song", "Zihao Yue"], "title": "MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We present MiMo-7B, a large language model born for reasoning tasks, with\noptimization across both pre-training and post-training stages. During\npre-training, we enhance the data preprocessing pipeline and employ a\nthree-stage data mixing strategy to strengthen the base model's reasoning\npotential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional\nMulti-Token Prediction objective for enhanced performance and accelerated\ninference speed. During post-training, we curate a dataset of 130K verifiable\nmathematics and programming problems for reinforcement learning, integrating a\ntest-difficulty-driven code-reward scheme to alleviate sparse-reward issues and\nemploying strategic data resampling to stabilize training. Extensive\nevaluations show that MiMo-7B-Base possesses exceptional reasoning potential,\noutperforming even much larger 32B models. The final RL-tuned model,\nMiMo-7B-RL, achieves superior performance on mathematics, code and general\nreasoning tasks, surpassing the performance of OpenAI o1-mini. The model\ncheckpoints are available at https://github.com/xiaomimimo/MiMo.", "AI": {"tldr": "MiMo-7B is a large language model optimized for reasoning tasks through enhanced pre-training and post-training stages, outperforming larger models like 32B and OpenAI o1-mini.", "motivation": "To develop a high-performance language model specialized for reasoning tasks by optimizing both pre-training and post-training processes.", "method": "Pre-training involves improved data preprocessing, a three-stage data mixing strategy, and Multi-Token Prediction. Post-training uses a curated dataset of 130K verifiable problems with reinforcement learning, a code-reward scheme, and strategic data resampling.", "result": "MiMo-7B-Base shows exceptional reasoning potential, outperforming larger models. MiMo-7B-RL excels in mathematics, code, and general reasoning tasks.", "conclusion": "MiMo-7B demonstrates superior performance in reasoning tasks, validated by extensive evaluations, and is publicly available."}}
{"id": "2505.06894", "pdf": "https://arxiv.org/pdf/2505.06894", "abs": "https://arxiv.org/abs/2505.06894", "authors": ["Ahmed Qazi", "Abdul Basit", "Asim Iqbal"], "title": "NeuGen: Amplifying the 'Neural' in Neural Radiance Fields for Domain Generalization", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "comment": "18 pages, 6 figures", "summary": "Neural Radiance Fields (NeRF) have significantly advanced the field of novel\nview synthesis, yet their generalization across diverse scenes and conditions\nremains challenging. Addressing this, we propose the integration of a novel\nbrain-inspired normalization technique Neural Generalization (NeuGen) into\nleading NeRF architectures which include MVSNeRF and GeoNeRF. NeuGen extracts\nthe domain-invariant features, thereby enhancing the models' generalization\ncapabilities. It can be seamlessly integrated into NeRF architectures and\ncultivates a comprehensive feature set that significantly improves accuracy and\nrobustness in image rendering. Through this integration, NeuGen shows improved\nperformance on benchmarks on diverse datasets across state-of-the-art NeRF\narchitectures, enabling them to generalize better across varied scenes. Our\ncomprehensive evaluations, both quantitative and qualitative, confirm that our\napproach not only surpasses existing models in generalizability but also\nmarkedly improves rendering quality. Our work exemplifies the potential of\nmerging neuroscientific principles with deep learning frameworks, setting a new\nprecedent for enhanced generalizability and efficiency in novel view synthesis.\nA demo of our study is available at https://neugennerf.github.io.", "AI": {"tldr": "NeuGen, a brain-inspired normalization technique, enhances NeRF architectures' generalization and rendering quality by extracting domain-invariant features.", "motivation": "Improving NeRF's generalization across diverse scenes and conditions remains a challenge.", "method": "Integrate NeuGen into NeRF architectures (MVSNeRF, GeoNeRF) to extract domain-invariant features.", "result": "Improved performance on benchmarks, better generalization, and enhanced rendering quality.", "conclusion": "NeuGen sets a precedent for merging neuroscientific principles with deep learning to boost NeRF's generalizability."}}
{"id": "2505.07773", "pdf": "https://arxiv.org/pdf/2505.07773", "abs": "https://arxiv.org/abs/2505.07773", "authors": ["Xinji Mai", "Haotian Xu", "Xing W", "Weinong Wang", "Yingying Zhang", "Wenqiang Zhang"], "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks\nrequiring precise, verifiable computation. While Reinforcement Learning (RL)\nfrom outcome-based rewards enhances text-based reasoning, understanding how\nagents autonomously learn to leverage external tools like code execution\nremains crucial. We investigate RL from outcome-based rewards for\nTool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously\ngenerate and execute Python code for mathematical problems without supervised\ntool-use examples. Our central contribution is we demonstrate that as RL\ntraining progresses, key metrics scale predictably. Specifically, we observe\nstrong positive correlations where increased training steps lead to increases\nin the spontaneous code execution frequency, the average response length, and,\ncritically, the final task accuracy. This suggests a quantifiable relationship\nbetween computational effort invested in training and the emergence of\neffective, tool-augmented reasoning strategies. We implement a robust framework\nfeaturing a decoupled code execution environment and validate our findings\nacross standard RL algorithms and frameworks. Experiments show ZeroTIR\nsignificantly surpasses non-tool ZeroRL baselines on challenging math\nbenchmarks. Our findings provide a foundational understanding of how autonomous\ntool use is acquired and scales within Agent RL, offering a reproducible\nbenchmark for future studies. Code is released at\n\\href{https://github.com/Anonymize-Author/AgentRL}{https://github.com/Anonymize-Author/AgentRL}.", "AI": {"tldr": "ZeroTIR trains LLMs with RL to autonomously generate and execute Python code for math tasks, showing predictable scaling in performance metrics like code execution frequency and accuracy.", "motivation": "LLMs struggle with precise mathematical reasoning, and understanding how they learn to use tools like code execution autonomously is crucial.", "method": "Uses RL from outcome-based rewards to train LLMs (ZeroTIR) for tool-integrated reasoning without supervised examples, featuring a decoupled code execution environment.", "result": "ZeroTIR outperforms non-tool baselines, with predictable scaling in metrics like code execution frequency and task accuracy as training progresses.", "conclusion": "The study provides foundational insights into autonomous tool use in RL, offering a reproducible benchmark for future research."}}
{"id": "2505.06475", "pdf": "https://arxiv.org/pdf/2505.06475", "abs": "https://arxiv.org/abs/2505.06475", "authors": ["Binwen Liu", "Peiyu Xu", "Quan Yuan", "Yihong Chen"], "title": "Probing In-Context Learning: Impact of Task Complexity and Model Architecture on Generalization and Efficiency", "categories": ["cs.LG"], "comment": null, "summary": "We investigate in-context learning (ICL) through a meticulous experimental\nframework that systematically varies task complexity and model architecture.\nExtending beyond the linear regression baseline, we introduce Gaussian kernel\nregression and nonlinear dynamical system tasks, which emphasize temporal and\nrecursive reasoning. We evaluate four distinct models: a GPT2-style\nTransformer, a Transformer with FlashAttention mechanism, a convolutional\nHyena-based model, and the Mamba state-space model. Each model is trained from\nscratch on synthetic datasets and assessed for generalization during testing.\nOur findings highlight that model architecture significantly shapes ICL\nperformance. The standard Transformer demonstrates robust performance across\ndiverse tasks, while Mamba excels in temporally structured dynamics. Hyena\neffectively captures long-range dependencies but shows higher variance early in\ntraining, and FlashAttention offers computational efficiency but is more\nsensitive in low-data regimes. Further analysis uncovers locality-induced\nshortcuts in Gaussian kernel tasks, enhanced nonlinear separability through\ninput range scaling, and the critical role of curriculum learning in mastering\nhigh-dimensional tasks.", "AI": {"tldr": "The paper examines in-context learning (ICL) by testing various model architectures on tasks of differing complexity, revealing how architecture impacts performance.", "motivation": "To understand how different model architectures influence in-context learning (ICL) across tasks with varying complexity, including temporal and recursive reasoning.", "method": "Four models (GPT2-style Transformer, Transformer with FlashAttention, Hyena-based convolutional model, Mamba state-space model) are trained on synthetic datasets and evaluated for generalization. Tasks include Gaussian kernel regression and nonlinear dynamical systems.", "result": "Model architecture significantly affects ICL performance: standard Transformer is robust, Mamba excels in temporal tasks, Hyena handles long-range dependencies but with early variance, and FlashAttention is efficient but data-sensitive.", "conclusion": "Architecture choice is crucial for ICL, with each model excelling in specific scenarios. Curriculum learning and input scaling are key for handling complex tasks."}}
{"id": "2505.07610", "pdf": "https://arxiv.org/pdf/2505.07610", "abs": "https://arxiv.org/abs/2505.07610", "authors": ["Kenza Amara", "Rita Sevastjanova", "Mennatallah El-Assady"], "title": "Concept-Level Explainability for Auditing & Steering LLM Responses", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 7 figures, Submission to Neurips 2025", "summary": "As large language models (LLMs) become widely deployed, concerns about their\nsafety and alignment grow. An approach to steer LLM behavior, such as\nmitigating biases or defending against jailbreaks, is to identify which parts\nof a prompt influence specific aspects of the model's output. Token-level\nattribution methods offer a promising solution, but still struggle in text\ngeneration, explaining the presence of each token in the output separately,\nrather than the underlying semantics of the entire LLM response. We introduce\nConceptX, a model-agnostic, concept-level explainability method that identifies\nthe concepts, i.e., semantically rich tokens in the prompt, and assigns them\nimportance based on the outputs' semantic similarity. Unlike current\ntoken-level methods, ConceptX also offers to preserve context integrity through\nin-place token replacements and supports flexible explanation goals, e.g.,\ngender bias. ConceptX enables both auditing, by uncovering sources of bias, and\nsteering, by modifying prompts to shift the sentiment or reduce the harmfulness\nof LLM responses, without requiring retraining. Across three LLMs, ConceptX\noutperforms token-level methods like TokenSHAP in both faithfulness and human\nalignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for\nrandom edits and lower attack success rates from 0.463 to 0.242, outperforming\nattribution and paraphrasing baselines. While prompt engineering and\nself-explaining methods sometimes yield safer responses, ConceptX offers a\ntransparent and faithful alternative for improving LLM safety and alignment,\ndemonstrating the practical value of attribution-based explainability in\nguiding LLM behavior.", "AI": {"tldr": "ConceptX is a concept-level explainability method for LLMs that outperforms token-level methods in faithfulness and human alignment, enabling auditing and steering of model behavior.", "motivation": "Addressing concerns about LLM safety and alignment by improving explainability and control over model outputs.", "method": "Introduces ConceptX, a model-agnostic method that identifies semantically rich tokens (concepts) in prompts and assigns importance based on output similarity, preserving context integrity.", "result": "Outperforms token-level methods (e.g., TokenSHAP) in faithfulness and human alignment; boosts sentiment shift and reduces attack success rates in steering tasks.", "conclusion": "ConceptX provides a transparent and faithful alternative for improving LLM safety and alignment, demonstrating the value of attribution-based explainability."}}
{"id": "2505.06898", "pdf": "https://arxiv.org/pdf/2505.06898", "abs": "https://arxiv.org/abs/2505.06898", "authors": ["Honglong Yang", "Shanshan Song", "Yi Qin", "Lehan Wang", "Haonan Wang", "Xinpeng Ding", "Qixiang Zhang", "Bodong Du", "Xiaomeng Li"], "title": "Multi-Modal Explainable Medical AI Assistant for Trustworthy Human-AI Collaboration", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Generalist Medical AI (GMAI) systems have demonstrated expert-level\nperformance in biomedical perception tasks, yet their clinical utility remains\nlimited by inadequate multi-modal explainability and suboptimal prognostic\ncapabilities. Here, we present XMedGPT, a clinician-centric, multi-modal AI\nassistant that integrates textual and visual interpretability to support\ntransparent and trustworthy medical decision-making. XMedGPT not only produces\naccurate diagnostic and descriptive outputs, but also grounds referenced\nanatomical sites within medical images, bridging critical gaps in\ninterpretability and enhancing clinician usability. To support real-world\ndeployment, we introduce a reliability indexing mechanism that quantifies\nuncertainty through consistency-based assessment via interactive\nquestion-answering. We validate XMedGPT across four pillars: multi-modal\ninterpretability, uncertainty quantification, and prognostic modeling, and\nrigorous benchmarking. The model achieves an IoU of 0.703 across 141 anatomical\nregions, and a Kendall's tau-b of 0.479, demonstrating strong alignment between\nvisual rationales and clinical outcomes. For uncertainty estimation, it attains\nan AUC of 0.862 on visual question answering and 0.764 on radiology report\ngeneration. In survival and recurrence prediction for lung and glioma cancers,\nit surpasses prior leading models by 26.9%, and outperforms GPT-4o by 25.0%.\nRigorous benchmarking across 347 datasets covers 40 imaging modalities and\nexternal validation spans 4 anatomical systems confirming exceptional\ngeneralizability, with performance gains surpassing existing GMAI by 20.7% for\nin-domain evaluation and 16.7% on 11,530 in-house data evaluation. Together,\nXMedGPT represents a significant leap forward in clinician-centric AI\nintegration, offering trustworthy and scalable support for diverse healthcare\napplications.", "AI": {"tldr": "XMedGPT is a clinician-centric, multi-modal AI assistant that enhances medical decision-making with interpretability, uncertainty quantification, and superior performance in diagnostics and prognostics.", "motivation": "Addressing the limitations of Generalist Medical AI (GMAI) systems, such as inadequate explainability and suboptimal prognostic capabilities, to improve clinical utility.", "method": "Integrates textual and visual interpretability, introduces a reliability indexing mechanism for uncertainty quantification, and validates across multi-modal interpretability, uncertainty, and prognostic modeling.", "result": "Achieves high performance in anatomical region alignment (IoU 0.703), uncertainty estimation (AUC 0.862), and surpasses prior models in survival prediction (26.9% improvement).", "conclusion": "XMedGPT advances clinician-centric AI by providing transparent, trustworthy, and scalable support for healthcare applications."}}
{"id": "2505.06241", "pdf": "https://arxiv.org/pdf/2505.06241", "abs": "https://arxiv.org/abs/2505.06241", "authors": ["Arek Berc Gokdag", "Silvia Mura", "Antonio Coviello", "Michele Zhu", "Maurizio Magarini", "Umberto Spagnolini"], "title": "Low-Complexity CNN-Based Classification of Electroneurographic Signals", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Peripheral nerve interfaces (PNIs) facilitate neural recording and\nstimulation for treating nerve injuries, but real-time classification of\nelectroneurographic (ENG) signals remains challenging due to constraints on\ncomplexity and latency, particularly in implantable devices. This study\nintroduces MobilESCAPE-Net, a lightweight architecture that reduces\ncomputational cost while maintaining and slightly improving classification\nperformance. Compared to the state-of-the-art ESCAPE-Net, MobilESCAPE-Net\nachieves comparable accuracy and F1-score with significantly lower complexity,\nreducing trainable parameters by 99.9\\% and floating point operations per\nsecond by 92.47\\%, enabling faster inference and real-time processing. Its\nefficiency makes it well-suited for low-complexity ENG signal classification in\nresource-constrained environments such as implantable devices.", "AI": {"tldr": "MobilESCAPE-Net is a lightweight neural network for real-time ENG signal classification, reducing computational cost while maintaining performance.", "motivation": "Real-time classification of ENG signals in implantable devices is challenging due to complexity and latency constraints.", "method": "Introduces MobilESCAPE-Net, a lightweight architecture reducing trainable parameters and operations while maintaining accuracy.", "result": "Achieves comparable accuracy and F1-score to ESCAPE-Net with 99.9% fewer parameters and 92.47% fewer operations.", "conclusion": "MobilESCAPE-Net is efficient for low-complexity ENG classification in resource-constrained environments like implantable devices."}}
{"id": "2505.06481", "pdf": "https://arxiv.org/pdf/2505.06481", "abs": "https://arxiv.org/abs/2505.06481", "authors": ["HamidReza Imani", "Jiaxin Peng", "Peiman Mohseni", "Abdolah Amirany", "Tarek El-Ghazawi"], "title": "QoS-Efficient Serving of Multiple Mixture-of-Expert LLMs Using Partial Runtime Reconfiguration", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "The deployment of mixture-of-experts (MoE) large language models (LLMs)\npresents significant challenges due to their high memory demands. These\nchallenges become even more pronounced in multi-tenant environments, where\nshared resources must accommodate multiple models, limiting the effectiveness\nof conventional virtualization techniques. This paper addresses the problem of\nefficiently serving multiple fine-tuned MoE-LLMs on a single-GPU. We propose a\nserving system that employs \\textit{similarity-based expert consolidation} to\nreduce the overall memory footprint by sharing similar experts across models.\nTo ensure output quality, we introduce \\textit{runtime partial\nreconfiguration}, dynamically replacing non-expert layers when processing\nrequests from different models. As a result, our approach achieves a\ncompetitive output quality while maintaining throughput comparable to serving a\nsingle model while incurring a negligible increase in time-to-first-token\n(TTFT). Experiments on a server with a single NVIDIA A100 GPU (80GB) using\nMixtral-8x7B models demonstrate an 85\\% average reduction in turnaround time\ncompared to NVIDIA's multi-instance GPU (MIG). Furthermore, experiments on\nGoogle's Switch Transformer Base-8 model with up to four variants demonstrate\nthe scalability and resilience of our approach in maintaining output quality\ncompared to other model merging baselines, highlighting its effectiveness.", "AI": {"tldr": "A serving system for efficient multi-tenant deployment of MoE-LLMs on a single GPU, using similarity-based expert consolidation and runtime partial reconfiguration to reduce memory and maintain performance.", "motivation": "Addressing high memory demands and inefficiencies in multi-tenant environments for MoE-LLMs, where conventional virtualization falls short.", "method": "Proposes similarity-based expert consolidation to share experts across models and runtime partial reconfiguration to dynamically adjust layers, ensuring quality and throughput.", "result": "Achieves 85% reduction in turnaround time on Mixtral-8x7B models and maintains output quality with Google's Switch Transformer Base-8, outperforming baselines.", "conclusion": "The approach effectively balances memory efficiency and performance, making it viable for multi-tenant MoE-LLM deployment on single-GPU systems."}}
{"id": "2505.07637", "pdf": "https://arxiv.org/pdf/2505.07637", "abs": "https://arxiv.org/abs/2505.07637", "authors": ["Krish Goel", "Sanskar Pandey", "KS Mahadevan", "Harsh Kumar", "Vishesh Khadaria"], "title": "Chronocept: Instilling a Sense of Time in Machines", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "20 pages, 8 figures, 18 tables", "summary": "Human cognition is deeply intertwined with a sense of time, known as\nChronoception. This sense allows us to judge how long facts remain valid and\nwhen knowledge becomes outdated. Despite progress in vision, language, and\nmotor control, AI still struggles to reason about temporal validity. We\nintroduce Chronocept, the first benchmark to model temporal validity as a\ncontinuous probability distribution over time. Using skew-normal curves fitted\nalong semantically decomposed temporal axes, Chronocept captures nuanced\npatterns of emergence, decay, and peak relevance. It includes two datasets:\nBenchmark I (atomic facts) and Benchmark II (multi-sentence passages).\nAnnotations show strong inter-annotator agreement (84% and 89%). Our baselines\npredict curve parameters - location, scale, and skewness - enabling\ninterpretable, generalizable learning and outperforming classification-based\napproaches. Chronocept fills a foundational gap in AI's temporal reasoning,\nsupporting applications in knowledge grounding, fact-checking,\nretrieval-augmented generation (RAG), and proactive agents. Code and data are\npublicly available.", "AI": {"tldr": "Chronocept is a benchmark modeling temporal validity as a continuous probability distribution, outperforming classification-based methods and supporting AI applications like fact-checking and retrieval-augmented generation.", "motivation": "AI lacks robust temporal reasoning, despite progress in other domains. Chronocept addresses this gap by modeling how knowledge validity changes over time.", "method": "Uses skew-normal curves fitted along decomposed temporal axes to capture emergence, decay, and peak relevance. Includes two datasets with high inter-annotator agreement.", "result": "Baselines predict curve parameters (location, scale, skewness) effectively, outperforming classification approaches.", "conclusion": "Chronocept fills a foundational gap in AI's temporal reasoning, with potential applications in knowledge grounding, fact-checking, and proactive agents."}}
{"id": "2505.06903", "pdf": "https://arxiv.org/pdf/2505.06903", "abs": "https://arxiv.org/abs/2505.06903", "authors": ["Yuanzhuo Wang", "Junwen Duan", "Xinyu Li", "Jianxin Wang"], "title": "CheXLearner: Text-Guided Fine-Grained Representation Learning for Progression Detection", "categories": ["cs.CV"], "comment": null, "summary": "Temporal medical image analysis is essential for clinical decision-making,\nyet existing methods either align images and text at a coarse level - causing\npotential semantic mismatches - or depend solely on visual information, lacking\nmedical semantic integration. We present CheXLearner, the first end-to-end\nframework that unifies anatomical region detection, Riemannian manifold-based\nstructure alignment, and fine-grained regional semantic guidance. Our proposed\nMed-Manifold Alignment Module (Med-MAM) leverages hyperbolic geometry to\nrobustly align anatomical structures and capture pathologically meaningful\ndiscrepancies across temporal chest X-rays. By introducing regional progression\ndescriptions as supervision, CheXLearner achieves enhanced cross-modal\nrepresentation learning and supports dynamic low-level feature optimization.\nExperiments show that CheXLearner achieves 81.12% (+17.2%) average accuracy and\n80.32% (+11.05%) F1-score on anatomical region progression detection -\nsubstantially outperforming state-of-the-art baselines, especially in\nstructurally complex regions. Additionally, our model attains a 91.52% average\nAUC score in downstream disease classification, validating its superior feature\nrepresentation.", "AI": {"tldr": "CheXLearner is an end-to-end framework for temporal medical image analysis, combining anatomical region detection, Riemannian manifold alignment, and semantic guidance to improve accuracy and semantic integration.", "motivation": "Existing methods for temporal medical image analysis either align images and text coarsely, risking semantic mismatches, or rely only on visual data, missing medical semantics. CheXLearner addresses these gaps.", "method": "CheXLearner uses a Med-Manifold Alignment Module (Med-MAM) with hyperbolic geometry for robust anatomical alignment and introduces regional progression descriptions for supervision, enhancing cross-modal learning.", "result": "CheXLearner achieves 81.12% accuracy (+17.2%) and 80.32% F1-score (+11.05%) in anatomical region progression detection, with a 91.52% AUC in disease classification, outperforming baselines.", "conclusion": "CheXLearner effectively integrates anatomical and semantic information, improving temporal medical image analysis and outperforming state-of-the-art methods."}}
{"id": "2505.06246", "pdf": "https://arxiv.org/pdf/2505.06246", "abs": "https://arxiv.org/abs/2505.06246", "authors": ["Dominic Parosh Yamarthi", "Haripriya Raman", "Shamsad Parvin"], "title": "United States Road Accident Prediction using Random Forest Predictor", "categories": ["cs.CY", "cs.AI", "cs.LG", "stat.AP"], "comment": "5 Pages, 8 Figures", "summary": "Road accidents significantly threaten public safety and require in-depth\nanalysis for effective prevention and mitigation strategies. This paper focuses\non predicting accidents through the examination of a comprehensive traffic\ndataset covering 49 states in the United States. The dataset integrates\ninformation from diverse sources, including transportation departments, law\nenforcement, and traffic sensors. This paper specifically emphasizes predicting\nthe number of accidents, utilizing advanced machine learning models such as\nregression analysis and time series analysis. The inclusion of various factors,\nranging from environmental conditions to human behavior and infrastructure,\nensures a holistic understanding of the dynamics influencing road safety.\nTemporal and spatial analysis further allows for the identification of trends,\nseasonal variations, and high-risk areas. The implications of this research\nextend to proactive decision-making for policymakers and transportation\nauthorities. By providing accurate predictions and quantifiable insights into\nexpected accident rates under different conditions, the paper aims to empower\nauthorities to allocate resources efficiently and implement targeted\ninterventions. The goal is to contribute to the development of informed\npolicies and interventions that enhance road safety, creating a safer\nenvironment for all road users. Keywords: Machine Learning, Random Forest,\nAccident Prediction, AutoML, LSTM.", "AI": {"tldr": "This paper uses machine learning to predict road accidents in the US, analyzing a comprehensive dataset to aid policymakers in proactive safety measures.", "motivation": "Road accidents pose a major public safety threat, requiring predictive analysis for effective prevention strategies.", "method": "The study employs regression and time series analysis, integrating diverse data sources (transportation, law enforcement, sensors) and factors (environmental, human, infrastructure).", "result": "The models provide accurate predictions of accident rates, identifying trends, seasonal variations, and high-risk areas.", "conclusion": "The research supports informed policymaking and targeted interventions to enhance road safety and resource allocation."}}
{"id": "2505.06482", "pdf": "https://arxiv.org/pdf/2505.06482", "abs": "https://arxiv.org/abs/2505.06482", "authors": ["Minting Pan", "Yitao Zheng", "Jiajian Li", "Yunbo Wang", "Xiaokang Yang"], "title": "Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Offline reinforcement learning (RL) enables policy optimization in static\ndatasets, avoiding the risks and costs of real-world exploration. However, it\nstruggles with suboptimal behavior learning and inaccurate value estimation due\nto the lack of environmental interaction. In this paper, we present\nVideo-Enhanced Offline RL (VeoRL), a model-based approach that constructs an\ninteractive world model from diverse, unlabeled video data readily available\nonline. Leveraging model-based behavior guidance, VeoRL transfers commonsense\nknowledge of control policy and physical dynamics from natural videos to the RL\nagent within the target domain. Our method achieves substantial performance\ngains (exceeding 100% in some cases) across visuomotor control tasks in robotic\nmanipulation, autonomous driving, and open-world video games.", "AI": {"tldr": "VeoRL enhances offline RL by using video data to build a world model, improving performance in visuomotor tasks.", "motivation": "Offline RL struggles with suboptimal behavior and inaccurate value estimation due to lack of interaction. VeoRL addresses this by leveraging video data.", "method": "VeoRL constructs an interactive world model from unlabeled video data, transferring commonsense knowledge to the RL agent.", "result": "Achieves over 100% performance gains in robotic manipulation, autonomous driving, and video games.", "conclusion": "VeoRL effectively bridges the gap in offline RL by utilizing video data for improved policy learning."}}
{"id": "2505.07653", "pdf": "https://arxiv.org/pdf/2505.07653", "abs": "https://arxiv.org/abs/2505.07653", "authors": ["Iman Johary", "Raphael Romero", "Alexandru C. Mara", "Tijl De Bie"], "title": "JobHop: A Large-Scale Dataset of Career Trajectories", "categories": ["cs.CL"], "comment": null, "summary": "Understanding labor market dynamics is essential for policymakers, employers,\nand job seekers. However, comprehensive datasets that capture real-world career\ntrajectories are scarce. In this paper, we introduce JobHop, a large-scale\npublic dataset derived from anonymized resumes provided by VDAB, the public\nemployment service in Flanders, Belgium. Utilizing Large Language Models\n(LLMs), we process unstructured resume data to extract structured career\ninformation, which is then mapped to standardized ESCO occupation codes using a\nmulti-label classification model. This results in a rich dataset of over 2.3\nmillion work experiences, extracted from and grouped into more than 391,000\nuser resumes and mapped to standardized ESCO occupation codes, offering\nvaluable insights into real-world occupational transitions. This dataset\nenables diverse applications, such as analyzing labor market mobility, job\nstability, and the effects of career breaks on occupational transitions. It\nalso supports career path prediction and other data-driven decision-making\nprocesses. To illustrate its potential, we explore key dataset characteristics,\nincluding job distributions, career breaks, and job transitions, demonstrating\nits value for advancing labor market research.", "AI": {"tldr": "JobHop is a large-scale public dataset derived from anonymized resumes, processed using LLMs to extract structured career data and mapped to ESCO codes, enabling labor market research.", "motivation": "Comprehensive datasets capturing real-world career trajectories are scarce, limiting labor market research and decision-making.", "method": "Unstructured resume data is processed with LLMs to extract structured career information, mapped to ESCO codes using multi-label classification.", "result": "A dataset of 2.3M work experiences from 391K resumes, providing insights into occupational transitions, mobility, and career breaks.", "conclusion": "JobHop offers valuable applications for labor market research, career path prediction, and data-driven decision-making."}}
{"id": "2505.06912", "pdf": "https://arxiv.org/pdf/2505.06912", "abs": "https://arxiv.org/abs/2505.06912", "authors": ["Chao Ding", "Mouxiao Bian", "Pengcheng Chen", "Hongliang Zhang", "Tianbin Li", "Lihao Liu", "Jiayuan Chen", "Zhuoran Li", "Yabei Zhong", "Yongqi Liu", "Haiqing Huang", "Dongming Shan", "Junjun He", "Jie Xu"], "title": "Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI", "categories": ["cs.CV"], "comment": null, "summary": "Despite strong performance in medical question-answering, the clinical\nadoption of Large Language Models (LLMs) is critically hampered by their opaque\n'black-box' reasoning, limiting clinician trust. This challenge is compounded\nby the predominant reliance of current medical LLMs on corpora from scientific\nliterature or synthetic data, which often lack the granular expert validation\nand high clinical relevance essential for advancing their specialized medical\ncapabilities. To address these critical gaps, we introduce a highly clinically\nrelevant dataset with 31,247 medical question-answer pairs, each accompanied by\nexpert-validated chain-of-thought (CoT) explanations. This resource, spanning\nmultiple clinical domains, was curated via a scalable human-LLM hybrid\npipeline: LLM-generated rationales were iteratively reviewed, scored, and\nrefined by medical experts against a structured rubric, with substandard\noutputs revised through human effort or guided LLM regeneration until expert\nconsensus. This publicly available dataset provides a vital source for the\ndevelopment of medical LLMs that capable of transparent and verifiable\nreasoning, thereby advancing safer and more interpretable AI in medicine.", "AI": {"tldr": "The paper introduces a clinically relevant dataset with expert-validated chain-of-thought explanations to improve transparency and trust in medical LLMs.", "motivation": "Current medical LLMs lack transparency and rely on less clinically relevant data, limiting clinician trust and adoption.", "method": "A hybrid human-LLM pipeline curated 31,247 expert-validated medical QA pairs with CoT explanations, iteratively refined by medical experts.", "result": "The dataset enables development of transparent and verifiable medical LLMs, enhancing interpretability in AI for medicine.", "conclusion": "The resource advances safer, more interpretable AI in medicine by addressing critical gaps in clinical relevance and reasoning transparency."}}
{"id": "2505.06250", "pdf": "https://arxiv.org/pdf/2505.06250", "abs": "https://arxiv.org/abs/2505.06250", "authors": ["Yizhuo Wu", "Yi Zhu", "Kun Qian", "Qinyu Chen", "Anding Zhu", "John Gajadharsing", "Leo C. N. de Vreede", "Chang Gao"], "title": "DeltaDPD: Exploiting Dynamic Temporal Sparsity in Recurrent Neural Networks for Energy-Efficient Wideband Digital Predistortion", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted to IEEE Microwave and Wireless Technology Letters (MWTL)", "summary": "Digital Predistortion (DPD) is a popular technique to enhance signal quality\nin wideband RF power amplifiers (PAs). With increasing bandwidth and data\nrates, DPD faces significant energy consumption challenges during deployment,\ncontrasting with its efficiency goals. State-of-the-art DPD models rely on\nrecurrent neural networks (RNN), whose computational complexity hinders system\nefficiency. This paper introduces DeltaDPD, exploring the dynamic temporal\nsparsity of input signals and neuronal hidden states in RNNs for\nenergy-efficient DPD, reducing arithmetic operations and memory accesses while\npreserving satisfactory linearization performance. Applying a TM3.1a 200MHz-BW\n256-QAM OFDM signal to a 3.5 GHz GaN Doherty RF PA, DeltaDPD achieves -50.03\ndBc in Adjacent Channel Power Ratio (ACPR), -37.22 dB in Normalized Mean Square\nError (NMSE) and -38.52 dBc in Error Vector Magnitude (EVM) with 52% temporal\nsparsity, leading to a 1.8X reduction in estimated inference power. The\nDeltaDPD code will be released after formal publication at\nhttps://www.opendpd.com.", "AI": {"tldr": "DeltaDPD introduces an energy-efficient DPD method by leveraging dynamic temporal sparsity in RNNs, reducing computations and memory usage while maintaining performance.", "motivation": "Address the energy consumption challenges of traditional DPD models in wideband RF PAs, which rely on computationally complex RNNs.", "method": "Explores dynamic temporal sparsity of input signals and neuronal hidden states in RNNs to reduce arithmetic operations and memory accesses.", "result": "Achieves -50.03 dBc ACPR, -37.22 dB NMSE, and -38.52 dBc EVM with 52% sparsity, reducing inference power by 1.8X.", "conclusion": "DeltaDPD offers a viable solution for energy-efficient DPD without compromising linearization performance."}}
{"id": "2505.06497", "pdf": "https://arxiv.org/pdf/2505.06497", "abs": "https://arxiv.org/abs/2505.06497", "authors": ["Jiacheng Wang", "Hongtao Lv", "Lei Liu"], "title": "FedADP: Unified Model Aggregation for Federated Learning with Heterogeneous Model Architectures", "categories": ["cs.LG"], "comment": null, "summary": "Traditional Federated Learning (FL) faces significant challenges in terms of\nefficiency and accuracy, particularly in heterogeneous environments where\nclients employ diverse model architectures and have varying computational\nresources. Such heterogeneity complicates the aggregation process, leading to\nperformance bottlenecks and reduced model generalizability. To address these\nissues, we propose FedADP, a federated learning framework designed to adapt to\nclient heterogeneity by dynamically adjusting model architectures during\naggregation. FedADP enables effective collaboration among clients with\ndiffering capabilities, maximizing resource utilization and ensuring model\nquality. Our experimental results demonstrate that FedADP significantly\noutperforms existing methods, such as FlexiFed, achieving an accuracy\nimprovement of up to 23.30%, thereby enhancing model adaptability and training\nefficiency in heterogeneous real-world settings.", "AI": {"tldr": "FedADP is a federated learning framework that dynamically adjusts model architectures to address heterogeneity, improving efficiency and accuracy by up to 23.30% over existing methods.", "motivation": "Traditional FL struggles with efficiency and accuracy in heterogeneous environments due to diverse client architectures and resources.", "method": "FedADP dynamically adjusts model architectures during aggregation to accommodate client heterogeneity.", "result": "FedADP outperforms methods like FlexiFed, achieving up to 23.30% higher accuracy.", "conclusion": "FedADP enhances model adaptability and training efficiency in heterogeneous settings."}}
{"id": "2505.07659", "pdf": "https://arxiv.org/pdf/2505.07659", "abs": "https://arxiv.org/abs/2505.07659", "authors": ["Ethan Gotlieb Wilcox", "Cui Ding", "Giovanni Acampa", "Tiago Pimentel", "Alex Warstadt", "Tamar I. Regev"], "title": "Using Information Theory to Characterize Prosodic Typology: The Case of Tone, Pitch-Accent and Stress-Accent", "categories": ["cs.CL"], "comment": null, "summary": "This paper argues that the relationship between lexical identity and prosody\n-- one well-studied parameter of linguistic variation -- can be characterized\nusing information theory. We predict that languages that use prosody to make\nlexical distinctions should exhibit a higher mutual information between word\nidentity and prosody, compared to languages that don't. We test this hypothesis\nin the domain of pitch, which is used to make lexical distinctions in tonal\nlanguages, like Cantonese. We use a dataset of speakers reading sentences aloud\nin ten languages across five language families to estimate the mutual\ninformation between the text and their pitch curves. We find that, across\nlanguages, pitch curves display similar amounts of entropy. However, these\ncurves are easier to predict given their associated text in the tonal\nlanguages, compared to pitch- and stress-accent languages, and thus the mutual\ninformation is higher in these languages, supporting our hypothesis. Our\nresults support perspectives that view linguistic typology as gradient, rather\nthan categorical.", "AI": {"tldr": "The paper uses information theory to show that tonal languages have higher mutual information between word identity and prosody, supporting a gradient view of linguistic typology.", "motivation": "To characterize the relationship between lexical identity and prosody using information theory, testing if tonal languages exhibit higher mutual information.", "method": "Analyzed pitch curves from speakers of ten languages across five families, estimating mutual information between text and pitch.", "result": "Tonal languages showed higher mutual information between word identity and pitch, supporting the hypothesis.", "conclusion": "Findings support a gradient perspective of linguistic typology, with tonal languages displaying stronger prosodic-lexical relationships."}}
{"id": "2505.06920", "pdf": "https://arxiv.org/pdf/2505.06920", "abs": "https://arxiv.org/abs/2505.06920", "authors": ["Timing Li", "Bing Cao", "Pengfei Zhu", "Bin Xiao", "Qinghua Hu"], "title": "Bi-directional Self-Registration for Misaligned Infrared-Visible Image Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Acquiring accurately aligned multi-modal image pairs is fundamental for\nachieving high-quality multi-modal image fusion. To address the lack of ground\ntruth in current multi-modal image registration and fusion methods, we propose\na novel self-supervised \\textbf{B}i-directional\n\\textbf{S}elf-\\textbf{R}egistration framework (\\textbf{B-SR}). Specifically,\nB-SR utilizes a proxy data generator (PDG) and an inverse proxy data generator\n(IPDG) to achieve self-supervised global-local registration. Visible-infrared\nimage pairs with spatially misaligned differences are aligned to obtain global\ndifferences through the registration module. The same image pairs are processed\nby PDG, such as cropping, flipping, stitching, etc., and then aligned to obtain\nlocal differences. IPDG converts the obtained local differences into\npseudo-global differences, which are used to perform global-local difference\nconsistency with the global differences. Furthermore, aiming at eliminating the\neffect of modal gaps on the registration module, we design a neighborhood\ndynamic alignment loss to achieve cross-modal image edge alignment. Extensive\nexperiments on misaligned multi-modal images demonstrate the effectiveness of\nthe proposed method in multi-modal image alignment and fusion against the\ncompeting methods. Our code will be publicly available.", "AI": {"tldr": "Proposes B-SR, a self-supervised framework for multi-modal image alignment and fusion, using global-local registration and dynamic alignment loss.", "motivation": "Addresses the lack of ground truth in multi-modal image registration and fusion by introducing a self-supervised approach.", "method": "Uses proxy data generators (PDG and IPDG) for global-local registration and a neighborhood dynamic alignment loss for cross-modal edge alignment.", "result": "Demonstrates effectiveness in aligning and fusing misaligned multi-modal images compared to competing methods.", "conclusion": "B-SR is a robust solution for multi-modal image alignment and fusion, with code to be publicly available."}}
{"id": "2505.06256", "pdf": "https://arxiv.org/pdf/2505.06256", "abs": "https://arxiv.org/abs/2505.06256", "authors": ["Fuhui Zhou", "Chunyu Liu", "Hao Zhang", "Wei Wu", "Qihui Wu", "Derrick Wing Kwan Ng", "Tony Q. S. Quek", "Chan-Byoung Chae"], "title": "SpectrumFM: A Foundation Model for Intelligent Spectrum Management", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Intelligent spectrum management is crucial for improving spectrum efficiency\nand achieving secure utilization of spectrum resources. However, existing\nintelligent spectrum management methods, typically based on small-scale models,\nsuffer from notable limitations in recognition accuracy, convergence speed, and\ngeneralization, particularly in the complex and dynamic spectrum environments.\nTo address these challenges, this paper proposes a novel spectrum foundation\nmodel, termed SpectrumFM, establishing a new paradigm for spectrum management.\nSpectrumFM features an innovative encoder architecture that synergistically\nexploits the convolutional neural networks and the multi-head self-attention\nmechanisms to enhance feature extraction and enable robust representation\nlearning. The model is pre-trained via two novel self-supervised learning\ntasks, namely masked reconstruction and next-slot signal prediction, which\nleverage large-scale in-phase and quadrature (IQ) data to achieve comprehensive\nand transferable spectrum representations. Furthermore, a parameter-efficient\nfine-tuning strategy is proposed to enable SpectrumFM to adapt to various\ndownstream spectrum management tasks, including automatic modulation\nclassification (AMC), wireless technology classification (WTC), spectrum\nsensing (SS), and anomaly detection (AD). Extensive experiments demonstrate\nthat SpectrumFM achieves superior performance in terms of accuracy, robustness,\nadaptability, few-shot learning efficiency, and convergence speed, consistently\noutperforming conventional methods across multiple benchmarks. Specifically,\nSpectrumFM improves AMC accuracy by up to 12.1% and WTC accuracy by 9.3%,\nachieves an area under the curve (AUC) of 0.97 in SS at -4 dB signal-to-noise\nratio (SNR), and enhances AD performance by over 10%.", "AI": {"tldr": "The paper introduces SpectrumFM, a novel spectrum foundation model, to overcome limitations in existing intelligent spectrum management methods. It combines CNNs and multi-head self-attention for robust feature extraction and uses self-supervised learning for pre-training. SpectrumFM outperforms conventional methods in accuracy, adaptability, and efficiency.", "motivation": "Existing spectrum management methods lack accuracy, convergence speed, and generalization in dynamic environments. SpectrumFM aims to address these issues with a scalable and adaptable foundation model.", "method": "SpectrumFM uses a hybrid encoder (CNNs + multi-head self-attention) and is pre-trained via masked reconstruction and next-slot signal prediction tasks. It employs parameter-efficient fine-tuning for downstream tasks like AMC, WTC, SS, and AD.", "result": "SpectrumFM achieves significant improvements: 12.1% higher AMC accuracy, 9.3% better WTC accuracy, 0.97 AUC in SS at -4 dB SNR, and 10% enhanced AD performance.", "conclusion": "SpectrumFM sets a new benchmark for spectrum management, offering superior performance, adaptability, and efficiency across multiple tasks."}}
{"id": "2505.06520", "pdf": "https://arxiv.org/pdf/2505.06520", "abs": "https://arxiv.org/abs/2505.06520", "authors": ["Xuran Li", "Jingyi Wang", "Xiaohan Yuan", "Peixin Zhang", "Zhan Qin", "Zhibo Wang", "Kui Ren"], "title": "PRUNE: A Patching Based Repair Framework for Certiffable Unlearning of Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "It is often desirable to remove (a.k.a. unlearn) a speciffc part of the\ntraining data from a trained neural network model. A typical application\nscenario is to protect the data holder's right to be forgotten, which has been\npromoted by many recent regulation rules. Existing unlearning methods involve\ntraining alternative models with remaining data, which may be costly and\nchallenging to verify from the data holder or a thirdparty auditor's\nperspective. In this work, we provide a new angle and propose a novel\nunlearning approach by imposing carefully crafted \"patch\" on the original\nneural network to achieve targeted \"forgetting\" of the requested data to\ndelete. Speciffcally, inspired by the research line of neural network repair,\nwe propose to strategically seek a lightweight minimum \"patch\" for unlearning a\ngiven data point with certiffable guarantee. Furthermore, to unlearn a\nconsiderable amount of data points (or an entire class), we propose to\niteratively select a small subset of representative data points to unlearn,\nwhich achieves the effect of unlearning the whole set. Extensive experiments on\nmultiple categorical datasets demonstrates our approach's effectiveness,\nachieving measurable unlearning while preserving the model's performance and\nbeing competitive in efffciency and memory consumption compared to various\nbaseline methods.", "AI": {"tldr": "A novel neural network unlearning method uses lightweight patches to selectively forget data, offering efficiency and verifiability.", "motivation": "Addressing the need for data removal (right to be forgotten) without costly retraining or verification challenges.", "method": "Strategic application of minimal patches to the network for targeted forgetting, with iterative selection for larger datasets.", "result": "Effective unlearning with preserved model performance, competitive efficiency, and low memory use.", "conclusion": "The approach provides a practical, certifiable solution for data removal in neural networks."}}
{"id": "2505.07671", "pdf": "https://arxiv.org/pdf/2505.07671", "abs": "https://arxiv.org/abs/2505.07671", "authors": ["Xianrui Zhong", "Bowen Jin", "Siru Ouyang", "Yanzhen Shen", "Qiao Jin", "Yin Fang", "Zhiyong Lu", "Jiawei Han"], "title": "Benchmarking Retrieval-Augmented Generation for Chemistry", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Retrieval-augmented generation (RAG) has emerged as a powerful framework for\nenhancing large language models (LLMs) with external knowledge, particularly in\nscientific domains that demand specialized and dynamic information. Despite its\npromise, the application of RAG in the chemistry domain remains underexplored,\nprimarily due to the lack of high-quality, domain-specific corpora and\nwell-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a\ncomprehensive benchmark designed to systematically assess the effectiveness of\nRAG across a diverse set of chemistry-related tasks. The accompanying chemistry\ncorpus integrates heterogeneous knowledge sources, including scientific\nliterature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia\nentries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG\ntoolkit that supports five retrieval algorithms and eight LLMs. Using\nChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain\n-- achieving an average relative improvement of 17.4% over direct inference\nmethods. We further conduct in-depth analyses on retriever architectures,\ncorpus selection, and the number of retrieved passages, culminating in\npractical recommendations to guide future research and deployment of RAG\nsystems in the chemistry domain. The code and data is available at\nhttps://chemrag.github.io.", "AI": {"tldr": "ChemRAG-Bench is introduced as a benchmark for evaluating retrieval-augmented generation (RAG) in chemistry, accompanied by ChemRAG-Toolkit, showing a 17.4% performance gain over direct inference methods.", "motivation": "The lack of high-quality, domain-specific corpora and benchmarks for RAG in chemistry motivates the creation of ChemRAG-Bench and ChemRAG-Toolkit.", "method": "The work integrates diverse chemistry knowledge sources into a corpus and develops a toolkit supporting five retrieval algorithms and eight LLMs.", "result": "RAG achieves a 17.4% average improvement over direct inference, with analyses on retriever architectures, corpus selection, and passage retrieval.", "conclusion": "The study provides practical recommendations for future RAG research and deployment in chemistry, with code and data publicly available."}}
{"id": "2505.06937", "pdf": "https://arxiv.org/pdf/2505.06937", "abs": "https://arxiv.org/abs/2505.06937", "authors": ["Fei Zhou", "Yi Li", "Mingqing Zhu"], "title": "Transformer-Based Dual-Optical Attention Fusion Crowd Head Point Counting and Localization Network", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, the dual-optical attention fusion crowd head point counting\nmodel (TAPNet) is proposed to address the problem of the difficulty of accurate\ncounting in complex scenes such as crowd dense occlusion and low light in crowd\ncounting tasks under UAV view. The model designs a dual-optical attention\nfusion module (DAFP) by introducing complementary information from infrared\nimages to improve the accuracy and robustness of all-day crowd counting. In\norder to fully utilize different modal information and solve the problem of\ninaccurate localization caused by systematic misalignment between image pairs,\nthis paper also proposes an adaptive two-optical feature decomposition fusion\nmodule (AFDF). In addition, we optimize the training strategy to improve the\nmodel robustness through spatial random offset data augmentation. Experiments\non two challenging public datasets, DroneRGBT and GAIIC2, show that the\nproposed method outperforms existing techniques in terms of performance,\nespecially in challenging dense low-light scenes. Code is available at\nhttps://github.com/zz-zik/TAPNet", "AI": {"tldr": "TAPNet introduces dual-optical attention fusion and adaptive feature decomposition to improve crowd counting accuracy in complex UAV scenes, outperforming existing methods.", "motivation": "Addressing challenges like dense occlusion and low light in UAV-based crowd counting.", "method": "Uses dual-optical attention fusion (DAFP) and adaptive feature decomposition (AFDF) modules, with spatial random offset data augmentation.", "result": "Outperforms existing techniques on DroneRGBT and GAIIC2 datasets, especially in dense low-light scenes.", "conclusion": "TAPNet enhances accuracy and robustness for all-day crowd counting in complex scenarios."}}
{"id": "2505.06261", "pdf": "https://arxiv.org/pdf/2505.06261", "abs": "https://arxiv.org/abs/2505.06261", "authors": ["Wei Meng"], "title": "Modeling supply chain compliance response strategies based on AI synthetic data with structural path regression: A Simulation Study of EU 2027 Mandatory Labor Regulations", "categories": ["cs.CY", "cs.AI", "stat.AP", "90B06 (Primary) 62J05, 91B74 (Secondary)", "I.6.3; I.2.6; J.1"], "comment": "Simulated data modeling of the impact of non-tariff barriers in trade\n  wars", "summary": "In the context of the new mandatory labor compliance in the European Union\n(EU), which will be implemented in 2027, supply chain enterprises face\nstringent working hour management requirements and compliance risks. In order\nto scientifically predict the enterprises' coping behaviors and performance\noutcomes under the policy impact, this paper constructs a methodological\nframework that integrates the AI synthetic data generation mechanism and\nstructural path regression modeling to simulate the enterprises' strategic\ntransition paths under the new regulations. In terms of research methodology,\nthis paper adopts high-quality simulation data generated based on Monte Carlo\nmechanism and NIST synthetic data standards to construct a structural path\nanalysis model that includes multiple linear regression, logistic regression,\nmediation effect and moderating effect. The variable system covers 14\nindicators such as enterprise working hours, compliance investment, response\nspeed, automation level, policy dependence, etc. The variable set with\nexplanatory power is screened out through exploratory data analysis (EDA) and\nVIF multicollinearity elimination. The findings show that compliance investment\nhas a significant positive impact on firm survival and its effect is\ntransmitted through the mediating path of the level of intelligence; meanwhile,\nfirms' dependence on the EU market significantly moderates the strength of this\nmediating effect. It is concluded that AI synthetic data combined with\nstructural path modeling provides an effective tool for high-intensity\nregulatory simulation, which can provide a quantitative basis for corporate\nstrategic response, policy design and AI-assisted decision-making in the\npre-prediction stage lacking real scenario data. Keywords: AI synthetic data,\nstructural path regression modeling, compliance response strategy, EU 2027\nmandatory labor regulation", "AI": {"tldr": "The paper predicts EU enterprises' responses to 2027 labor regulations using AI synthetic data and structural path modeling, finding compliance investment boosts survival via intelligence levels, moderated by EU market dependence.", "motivation": "To scientifically forecast enterprise behaviors and outcomes under the EU's 2027 labor compliance regulations, addressing compliance risks and strategic transitions.", "method": "Combines AI synthetic data generation (Monte Carlo, NIST standards) with structural path analysis (regression, mediation, moderation) using 14 indicators like working hours and compliance investment.", "result": "Compliance investment positively impacts survival through intelligence levels, with EU market dependence moderating this effect.", "conclusion": "AI synthetic data and structural path modeling are effective for regulatory simulation, aiding strategic and policy decisions pre-implementation."}}
{"id": "2505.06534", "pdf": "https://arxiv.org/pdf/2505.06534", "abs": "https://arxiv.org/abs/2505.06534", "authors": ["Ummay Maria Muna", "Fahim Hafiz", "Shanta Biswas", "Riasat Azim"], "title": "GBDTSVM: Combined Support Vector Machine and Gradient Boosting Decision Tree Framework for efficient snoRNA-disease association prediction", "categories": ["cs.LG", "q-bio.QM"], "comment": "30 pages, 3 figures", "summary": "Small nucleolar RNAs (snoRNAs) are increasingly recognized for their critical\nrole in the pathogenesis and characterization of various human diseases.\nConsequently, the precise identification of snoRNA-disease associations (SDAs)\nis essential for the progression of diseases and the advancement of treatment\nstrategies. However, conventional biological experimental approaches are\ncostly, time-consuming, and resource-intensive; therefore, machine\nlearning-based computational methods offer a promising solution to mitigate\nthese limitations. This paper proposes a model called 'GBDTSVM', representing a\nnovel and efficient machine learning approach for predicting snoRNA-disease\nassociations by leveraging a Gradient Boosting Decision Tree (GBDT) and Support\nVector Machine (SVM). 'GBDTSVM' effectively extracts integrated snoRNA-disease\nfeature representations utilizing GBDT and SVM is subsequently utilized to\nclassify and identify potential associations. Furthermore, the method enhances\nthe accuracy of these predictions by incorporating Gaussian kernel profile\nsimilarity for both snoRNAs and diseases. Experimental evaluation of the\nGBDTSVM model demonstrated superior performance compared to state-of-the-art\nmethods in the field, achieving an area under the receiver operating\ncharacteristic (AUROC) of 0.96 and an area under the precision-recall curve\n(AUPRC) of 0.95 on MDRF dataset. Moreover, our model shows superior performance\non two more datasets named LSGT and PsnoD. Additionally, a case study on the\npredicted snoRNA-disease associations verified the top 10 predicted snoRNAs\nacross nine prevalent diseases, further validating the efficacy of the GBDTSVM\napproach. These results underscore the model's potential as a robust tool for\nadvancing snoRNA-related disease research. Source codes and datasets our\nproposed framework can be obtained from: https://github.com/mariamuna04/gbdtsvm", "AI": {"tldr": "The paper introduces 'GBDTSVM', a machine learning model combining GBDT and SVM to predict snoRNA-disease associations, outperforming existing methods with high accuracy.", "motivation": "Precise identification of snoRNA-disease associations is crucial for disease understanding and treatment, but traditional methods are costly and slow. Machine learning offers a viable alternative.", "method": "The 'GBDTSVM' model integrates GBDT for feature extraction and SVM for classification, enhanced by Gaussian kernel profile similarity for snoRNAs and diseases.", "result": "GBDTSVM achieved AUROC of 0.96 and AUPRC of 0.95, outperforming state-of-the-art methods on multiple datasets (MDRF, LSGT, PsnoD). A case study validated top predictions.", "conclusion": "GBDTSVM is a robust tool for snoRNA-disease research, offering high accuracy and efficiency, with potential to advance disease understanding and treatment strategies."}}
{"id": "2505.07672", "pdf": "https://arxiv.org/pdf/2505.07672", "abs": "https://arxiv.org/abs/2505.07672", "authors": ["Arun S. Maiya"], "title": "OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 pages", "summary": "We present OnPrem.LLM, a Python-based toolkit for applying large language\nmodels (LLMs) to sensitive, non-public data in offline or restricted\nenvironments. The system is designed for privacy-preserving use cases and\nprovides prebuilt pipelines for document processing and storage,\nretrieval-augmented generation (RAG), information extraction, summarization,\nclassification, and prompt/output processing with minimal configuration.\nOnPrem.LLM supports multiple LLM backends -- including llama.cpp, Ollama, vLLM,\nand Hugging Face Transformers -- with quantized model support, GPU\nacceleration, and seamless backend switching. Although designed for fully local\nexecution, OnPrem.LLM also supports integration with a wide range of cloud LLM\nproviders when permitted, enabling hybrid deployments that balance performance\nwith data control. A no-code web interface extends accessibility to\nnon-technical users.", "AI": {"tldr": "OnPrem.LLM is a Python toolkit for using LLMs offline on sensitive data, offering privacy, multiple backends, and a no-code interface.", "motivation": "Address the need for privacy-preserving LLM applications in restricted environments without relying on cloud services.", "method": "Provides prebuilt pipelines for tasks like RAG, summarization, and classification, supporting multiple LLM backends (e.g., llama.cpp, Hugging Face) with GPU acceleration.", "result": "Enables local or hybrid deployments with cloud providers, balancing performance and data control.", "conclusion": "OnPrem.LLM is a versatile solution for secure, offline LLM applications, accessible to both technical and non-technical users."}}
{"id": "2505.06948", "pdf": "https://arxiv.org/pdf/2505.06948", "abs": "https://arxiv.org/abs/2505.06948", "authors": ["Pan Du", "Wangbo Zhao", "Xinai Lu", "Nian Liu", "Zhikai Li", "Chaoyu Gong", "Suyun Zhao", "Hong Chen", "Cuiping Li", "Kai Wang", "Yang You"], "title": "Unsupervised Learning for Class Distribution Mismatch", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Class distribution mismatch (CDM) refers to the discrepancy between class\ndistributions in training data and target tasks. Previous methods address this\nby designing classifiers to categorize classes known during training, while\ngrouping unknown or new classes into an \"other\" category. However, they focus\non semi-supervised scenarios and heavily rely on labeled data, limiting their\napplicability and performance. To address this, we propose Unsupervised\nLearning for Class Distribution Mismatch (UCDM), which constructs\npositive-negative pairs from unlabeled data for classifier training. Our\napproach randomly samples images and uses a diffusion model to add or erase\nsemantic classes, synthesizing diverse training pairs. Additionally, we\nintroduce a confidence-based labeling mechanism that iteratively assigns\npseudo-labels to valuable real-world data and incorporates them into the\ntraining process. Extensive experiments on three datasets demonstrate UCDM's\nsuperiority over previous semi-supervised methods. Specifically, with a 60%\nmismatch proportion on Tiny-ImageNet dataset, our approach, without relying on\nlabeled data, surpasses OpenMatch (with 40 labels per class) by 35.1%, 63.7%,\nand 72.5% in classifying known, unknown, and new classes.", "AI": {"tldr": "UCDM proposes an unsupervised method to address class distribution mismatch by synthesizing training pairs from unlabeled data and using a confidence-based labeling mechanism, outperforming semi-supervised methods.", "motivation": "Existing methods for class distribution mismatch rely on labeled data and semi-supervised scenarios, limiting their applicability. UCDM aims to overcome this by leveraging unlabeled data.", "method": "UCDM constructs positive-negative pairs from unlabeled data using a diffusion model to add/erase semantic classes. It also uses a confidence-based labeling mechanism to iteratively assign pseudo-labels.", "result": "UCDM outperforms OpenMatch by significant margins (35.1%, 63.7%, 72.5%) on Tiny-ImageNet with 60% mismatch, without labeled data.", "conclusion": "UCDM is a robust unsupervised solution for class distribution mismatch, surpassing semi-supervised methods in performance and applicability."}}
{"id": "2505.06264", "pdf": "https://arxiv.org/pdf/2505.06264", "abs": "https://arxiv.org/abs/2505.06264", "authors": ["Santhakumar Ramamoorthy", "Priya Rani", "James Mahon", "Glenn Mathews", "Shaun Cloherty", "Mahdi Babaei"], "title": "Prediction of Delirium Risk in Mild Cognitive Impairment Using Time-Series data, Machine Learning and Comorbidity Patterns -- A Retrospective Study", "categories": ["stat.AP", "cs.AI"], "comment": null, "summary": "Delirium represents a significant clinical concern characterized by high\nmorbidity and mortality rates, particularly in patients with mild cognitive\nimpairment (MCI). This study investigates the associated risk factors for\ndelirium by analyzing the comorbidity patterns relevant to MCI and developing a\nlongitudinal predictive model leveraging machine learning methodologies. A\nretrospective analysis utilizing the MIMIC-IV v2.2 database was performed to\nevaluate comorbid conditions, survival probabilities, and predictive modeling\noutcomes. The examination of comorbidity patterns identified distinct risk\nprofiles for the MCI population. Kaplan-Meier survival analysis demonstrated\nthat individuals with MCI exhibit markedly reduced survival probabilities when\ndeveloping delirium compared to their non-MCI counterparts, underscoring the\nheightened vulnerability within this cohort. For predictive modeling, a Long\nShort-Term Memory (LSTM) ML network was implemented utilizing time-series data,\ndemographic variables, Charlson Comorbidity Index (CCI) scores, and an array of\ncomorbid conditions. The model demonstrated robust predictive capabilities with\nan AUROC of 0.93 and an AUPRC of 0.92. This study underscores the critical role\nof comorbidities in evaluating delirium risk and highlights the efficacy of\ntime-series predictive modeling in pinpointing patients at elevated risk for\ndelirium development.", "AI": {"tldr": "The study identifies risk factors for delirium in MCI patients using machine learning, finding reduced survival rates and high predictive accuracy with an LSTM model.", "motivation": "Delirium poses high morbidity and mortality risks, especially in MCI patients, necessitating better risk assessment tools.", "method": "A retrospective analysis of MIMIC-IV data, comorbidity pattern evaluation, survival analysis, and LSTM-based predictive modeling.", "result": "MCI patients with delirium have lower survival rates; the LSTM model achieved AUROC 0.93 and AUPRC 0.92.", "conclusion": "Comorbidities are crucial for delirium risk assessment, and time-series ML models effectively identify high-risk patients."}}
{"id": "2505.06542", "pdf": "https://arxiv.org/pdf/2505.06542", "abs": "https://arxiv.org/abs/2505.06542", "authors": ["Ad\u00e8le H. Ribeiro", "Dominik Heider"], "title": "dcFCI: Robust Causal Discovery Under Latent Confounding, Unfaithfulness, and Mixed Data", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "31 pages. This work has been submitted to the IEEE for possible\n  publication", "summary": "Causal discovery is central to inferring causal relationships from\nobservational data. In the presence of latent confounding, algorithms such as\nFast Causal Inference (FCI) learn a Partial Ancestral Graph (PAG) representing\nthe true model's Markov Equivalence Class. However, their correctness\ncritically depends on empirical faithfulness, the assumption that observed\n(in)dependencies perfectly reflect those of the underlying causal model, which\noften fails in practice due to limited sample sizes. To address this, we\nintroduce the first nonparametric score to assess a PAG's compatibility with\nobserved data, even with mixed variable types. This score is both necessary and\nsufficient to characterize structural uncertainty and distinguish between\ndistinct PAGs. We then propose data-compatible FCI (dcFCI), the first hybrid\ncausal discovery algorithm to jointly address latent confounding, empirical\nunfaithfulness, and mixed data types. dcFCI integrates our score into an\n(Anytime)FCI-guided search that systematically explores, ranks, and validates\ncandidate PAGs. Experiments on synthetic and real-world scenarios demonstrate\nthat dcFCI significantly outperforms state-of-the-art methods, often recovering\nthe true PAG even in small and heterogeneous datasets. Examining top-ranked\nPAGs further provides valuable insights into structural uncertainty, supporting\nmore robust and informed causal reasoning and decision-making.", "AI": {"tldr": "The paper introduces a nonparametric score to assess PAG compatibility with data and proposes dcFCI, a hybrid algorithm addressing latent confounding, empirical unfaithfulness, and mixed data types, outperforming existing methods.", "motivation": "Existing causal discovery methods like FCI rely on empirical faithfulness, which often fails due to limited sample sizes, leading to incorrect inferences.", "method": "The authors develop a nonparametric score for PAG compatibility and integrate it into dcFCI, a hybrid algorithm combining (Anytime)FCI-guided search to explore and validate candidate PAGs.", "result": "dcFCI outperforms state-of-the-art methods, recovering true PAGs even in small or heterogeneous datasets, and provides insights into structural uncertainty.", "conclusion": "dcFCI enhances causal discovery by addressing key limitations, enabling more robust causal reasoning and decision-making."}}
{"id": "2505.07705", "pdf": "https://arxiv.org/pdf/2505.07705", "abs": "https://arxiv.org/abs/2505.07705", "authors": ["Letian Peng", "Jingbo Shang"], "title": "Codifying Character Logic in Role-Playing", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces Codified Profiles for role-playing, a novel approach\nthat represents character logic as structured, executable functions for\nbehavioral decision-making. Each profile defines a set of functions\nparse_by_scene(scene) that outputs a list of logic-grounded assertions\ntriggered_statements, using both explicit control structures (e.g.,\nif-then-else) and condition checks like check_condition(scene, question), where\neach question is a semantically meaningful prompt about the scene (e.g., \"Is\nthe character in danger?\") discriminated by the role-playing LLM as true,\nfalse, or unknown. This explicit representation offers three key advantages\nover traditional prompt-based profiles, which append character descriptions\ndirectly into text prompts: (1) Persistence, by enforcing complete and\nconsistent execution of character logic, rather than relying on the model's\nimplicit reasoning; (2) Updatability, through systematic inspection and\nrevision of behavioral logic, which is difficult to track or debug in\nprompt-only approaches; (3) Controllable Randomness, by supporting stochastic\nbehavior directly within the logic, enabling fine-grained variability that\nprompting alone struggles to achieve. To validate these advantages, we\nintroduce a new benchmark constructed from 83 characters and 5,141 scenes\ncurated from Fandom, using NLI-based scoring to compare character responses\nagainst ground-truth actions. Our experiments demonstrate the significant\nbenefits of codified profiles in improving persistence, updatability, and\nbehavioral diversity. Notably, by offloading a significant portion of reasoning\nto preprocessing, codified profiles enable even 1B-parameter models to perform\nhigh-quality role-playing, providing a scalable and efficient foundation for\nlocal deployment of role-play agents.", "AI": {"tldr": "Codified Profiles introduce structured, executable functions for role-playing, improving persistence, updatability, and controllable randomness over traditional prompt-based methods.", "motivation": "To address limitations of prompt-based profiles, such as implicit reasoning and lack of systematic logic inspection, by providing explicit, executable character logic.", "method": "Uses structured functions like parse_by_scene(scene) and condition checks (e.g., check_condition) to define character behavior, enabling logic-grounded assertions.", "result": "Experiments show significant improvements in persistence, updatability, and behavioral diversity, even enabling smaller models (1B-parameter) for high-quality role-playing.", "conclusion": "Codified Profiles offer a scalable, efficient foundation for role-play agents, outperforming traditional methods in logic consistency and control."}}
{"id": "2505.06951", "pdf": "https://arxiv.org/pdf/2505.06951", "abs": "https://arxiv.org/abs/2505.06951", "authors": ["Seokjun Kwon", "Jeongmin Shin", "Namil Kim", "Soonmin Hwang", "Yukyung Choi"], "title": "Boosting Cross-spectral Unsupervised Domain Adaptation for Thermal Semantic Segmentation", "categories": ["cs.CV", "cs.RO"], "comment": "7 pages, 4 figures, International Conference on Robotics and\n  Automation(ICRA) 2025", "summary": "In autonomous driving, thermal image semantic segmentation has emerged as a\ncritical research area, owing to its ability to provide robust scene\nunderstanding under adverse visual conditions. In particular, unsupervised\ndomain adaptation (UDA) for thermal image segmentation can be an efficient\nsolution to address the lack of labeled thermal datasets. Nevertheless, since\nthese methods do not effectively utilize the complementary information between\nRGB and thermal images, they significantly decrease performance during domain\nadaptation. In this paper, we present a comprehensive study on cross-spectral\nUDA for thermal image semantic segmentation. We first propose a novel masked\nmutual learning strategy that promotes complementary information exchange by\nselectively transferring results between each spectral model while masking out\nuncertain regions. Additionally, we introduce a novel prototypical\nself-supervised loss designed to enhance the performance of the thermal\nsegmentation model in nighttime scenarios. This approach addresses the\nlimitations of RGB pre-trained networks, which cannot effectively transfer\nknowledge under low illumination due to the inherent constraints of RGB\nsensors. In experiments, our method achieves higher performance over previous\nUDA methods and comparable performance to state-of-the-art supervised methods.", "AI": {"tldr": "A novel masked mutual learning strategy and prototypical self-supervised loss improve thermal image segmentation via cross-spectral UDA, outperforming previous methods.", "motivation": "Addressing the lack of labeled thermal datasets and ineffective use of RGB-thermal complementary information in UDA for thermal image segmentation.", "method": "Proposes masked mutual learning for selective information transfer and a prototypical self-supervised loss for nighttime performance.", "result": "Achieves higher performance than previous UDA methods and comparable to supervised methods.", "conclusion": "The approach effectively leverages cross-spectral data and enhances thermal segmentation, especially in low-light conditions."}}
{"id": "2505.06267", "pdf": "https://arxiv.org/pdf/2505.06267", "abs": "https://arxiv.org/abs/2505.06267", "authors": ["Ilyas Oulkadda", "Julien Perez"], "title": "AKD : Adversarial Knowledge Distillation For Large Language Models Alignment on Coding tasks", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "The widespread adoption of Large Language Models (LLMs) for code generation,\nexemplified by GitHub Copilot\\footnote{A coding extension powered by a Code-LLM\nto assist in code completion tasks} surpassing a million users, highlights the\ntransformative potential of these tools in improving developer productivity.\nHowever, this rapid growth also underscores critical concerns regarding the\nquality, safety, and reliability of the code they generate. As Code-LLMs\nevolve, they face significant challenges, including the diminishing returns of\nmodel scaling and the scarcity of new, high-quality training data. To address\nthese issues, this paper introduces Adversarial Knowledge Distillation (AKD), a\nnovel approach that leverages adversarially generated synthetic datasets to\ndistill the capabilities of larger models into smaller, more efficient ones. By\nsystematically stress-testing and refining the reasoning capabilities of\nCode-LLMs, AKD provides a framework for enhancing model robustness,\nreliability, and security while improving their parameter-efficiency. We\nbelieve this work represents a critical step toward ensuring dependable\nautomated code generation within the constraints of existing data and the\ncost-efficiency of model execution.", "AI": {"tldr": "The paper introduces Adversarial Knowledge Distillation (AKD) to improve the robustness and efficiency of Code-LLMs for reliable code generation.", "motivation": "Addressing concerns about the quality, safety, and reliability of code generated by Large Language Models (LLMs) due to challenges like diminishing returns of scaling and lack of high-quality training data.", "method": "Proposes AKD, which uses adversarially generated synthetic datasets to distill larger models into smaller, more efficient ones, enhancing reasoning capabilities.", "result": "AKD improves model robustness, reliability, and security while maintaining parameter-efficiency.", "conclusion": "AKD is a critical step toward dependable automated code generation, balancing data constraints and cost-efficiency."}}
{"id": "2505.06549", "pdf": "https://arxiv.org/pdf/2505.06549", "abs": "https://arxiv.org/abs/2505.06549", "authors": ["Matthias Chung", "Bas Peters", "Michael Solomon"], "title": "Good Things Come in Pairs: Paired Autoencoders for Inverse Problems", "categories": ["cs.LG", "stat.ML", "68T99"], "comment": "43 pages, 17 figures", "summary": "In this book chapter, we discuss recent advances in data-driven approaches\nfor inverse problems. In particular, we focus on the \\emph{paired autoencoder}\nframework, which has proven to be a powerful tool for solving inverse problems\nin scientific computing. The paired autoencoder framework is a novel approach\nthat leverages the strengths of both data-driven and model-based methods by\nprojecting both the data and the quantity of interest into a latent space and\nmapping these latent spaces to provide surrogate forward and inverse mappings.\nWe illustrate the advantages of this approach through numerical experiments,\nincluding seismic imaging and classical inpainting: nonlinear and linear\ninverse problems, respectively. Although the paired autoencoder framework is\nlikelihood-free, it generates multiple data- and model-based reconstruction\nmetrics that help assess whether examples are in or out of distribution. In\naddition to direct model estimates from data, the paired autoencoder enables\nlatent-space refinement to fit the observed data accurately. Numerical\nexperiments show that this procedure, combined with the latent-space initial\nguess, is essential for high-quality estimates, even when data noise exceeds\nthe training regime. We also introduce two novel variants that combine\nvariational and paired autoencoder ideas, maintaining the original benefits\nwhile enabling sampling for uncertainty analysis.", "AI": {"tldr": "The paper discusses the paired autoencoder framework for solving inverse problems, combining data-driven and model-based methods, and demonstrates its effectiveness through numerical experiments.", "motivation": "To address inverse problems in scientific computing by leveraging the strengths of both data-driven and model-based approaches.", "method": "The paired autoencoder framework projects data and quantities of interest into latent spaces, creating surrogate forward and inverse mappings. It includes latent-space refinement and novel variational variants for uncertainty analysis.", "result": "Numerical experiments in seismic imaging and inpainting show high-quality estimates, even with noisy data. The framework provides reconstruction metrics and enables latent-space refinement.", "conclusion": "The paired autoencoder framework is effective for inverse problems, offering robust solutions and uncertainty analysis capabilities."}}
{"id": "2505.07775", "pdf": "https://arxiv.org/pdf/2505.07775", "abs": "https://arxiv.org/abs/2505.07775", "authors": ["Nimet Beyza Bozdag", "Shuhaib Mehri", "Xiaocheng Yang", "Hyeonjeong Ha", "Zirui Cheng", "Esin Durmus", "Jiaxuan You", "Heng Ji", "Gokhan Tur", "Dilek Hakkani-T\u00fcr"], "title": "Must Read: A Systematic Survey of Computational Persuasion", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Persuasion is a fundamental aspect of communication, influencing\ndecision-making across diverse contexts, from everyday conversations to\nhigh-stakes scenarios such as politics, marketing, and law. The rise of\nconversational AI systems has significantly expanded the scope of persuasion,\nintroducing both opportunities and risks. AI-driven persuasion can be leveraged\nfor beneficial applications, but also poses threats through manipulation and\nunethical influence. Moreover, AI systems are not only persuaders, but also\nsusceptible to persuasion, making them vulnerable to adversarial attacks and\nbias reinforcement. Despite rapid advancements in AI-generated persuasive\ncontent, our understanding of what makes persuasion effective remains limited\ndue to its inherently subjective and context-dependent nature. In this survey,\nwe provide a comprehensive overview of computational persuasion, structured\naround three key perspectives: (1) AI as a Persuader, which explores\nAI-generated persuasive content and its applications; (2) AI as a Persuadee,\nwhich examines AI's susceptibility to influence and manipulation; and (3) AI as\na Persuasion Judge, which analyzes AI's role in evaluating persuasive\nstrategies, detecting manipulation, and ensuring ethical persuasion. We\nintroduce a taxonomy for computational persuasion research and discuss key\nchallenges, including evaluating persuasiveness, mitigating manipulative\npersuasion, and developing responsible AI-driven persuasive systems. Our survey\noutlines future research directions to enhance the safety, fairness, and\neffectiveness of AI-powered persuasion while addressing the risks posed by\nincreasingly capable language models.", "AI": {"tldr": "The paper surveys computational persuasion, focusing on AI's roles as persuader, persuadee, and judge, addressing challenges like ethical concerns and future research directions.", "motivation": "To explore the dual role of AI in persuasion\u2014both as an influencer and a target\u2014and its ethical implications in diverse contexts.", "method": "A comprehensive survey structured around three perspectives: AI as persuader, persuadee, and judge, with a taxonomy for research.", "result": "Identifies key challenges in evaluating persuasiveness, mitigating manipulation, and ensuring ethical AI-driven persuasion.", "conclusion": "Calls for future research to enhance safety, fairness, and effectiveness of AI-powered persuasion while addressing risks from advanced language models."}}
{"id": "2505.06975", "pdf": "https://arxiv.org/pdf/2505.06975", "abs": "https://arxiv.org/abs/2505.06975", "authors": ["Wei Shang", "Dongwei Ren", "Wanying Zhang", "Pengfei Zhu", "Qinghua Hu", "Wangmeng Zuo"], "title": "High-Frequency Prior-Driven Adaptive Masking for Accelerating Image Super-Resolution", "categories": ["cs.CV", "I.4.3"], "comment": "10 pages, 6 figures, 5 tables", "summary": "The primary challenge in accelerating image super-resolution lies in reducing\ncomputation while maintaining performance and adaptability. Motivated by the\nobservation that high-frequency regions (e.g., edges and textures) are most\ncritical for reconstruction, we propose a training-free adaptive masking module\nfor acceleration that dynamically focuses computation on these challenging\nareas. Specifically, our method first extracts high-frequency components via\nGaussian blur subtraction and adaptively generates binary masks using K-means\nclustering to identify regions requiring intensive processing. Our method can\nbe easily integrated with both CNNs and Transformers. For CNN-based\narchitectures, we replace standard $3 \\times 3$ convolutions with an unfold\noperation followed by $1 \\times 1$ convolutions, enabling pixel-wise sparse\ncomputation guided by the mask. For Transformer-based models, we partition the\nmask into non-overlapping windows and selectively process tokens based on their\naverage values. During inference, unnecessary pixels or windows are pruned,\nsignificantly reducing computation. Moreover, our method supports\ndilation-based mask adjustment to control the processing scope without\nretraining, and is robust to unseen degradations (e.g., noise, compression).\nExtensive experiments on benchmarks demonstrate that our method reduces FLOPs\nby 24--43% for state-of-the-art models (e.g., CARN, SwinIR) while achieving\ncomparable or better quantitative metrics. The source code is available at\nhttps://github.com/shangwei5/AMSR", "AI": {"tldr": "A training-free adaptive masking module accelerates image super-resolution by focusing computation on high-frequency regions, reducing FLOPs by 24-43% without performance loss.", "motivation": "High-frequency regions (edges, textures) are critical for image reconstruction, but current methods lack efficient computation focusing.", "method": "Extracts high-frequency components via Gaussian blur subtraction, uses K-means clustering for binary masks, and integrates with CNNs (unfold + 1x1 convolutions) or Transformers (selective token processing).", "result": "Reduces FLOPs by 24-43% for models like CARN and SwinIR while maintaining or improving performance metrics.", "conclusion": "The method offers a robust, adaptable solution for accelerating super-resolution without retraining, applicable to various architectures."}}
{"id": "2505.06581", "pdf": "https://arxiv.org/pdf/2505.06581", "abs": "https://arxiv.org/abs/2505.06581", "authors": ["Chao Yan"], "title": "An \\tilde{O}ptimal Differentially Private Learner for Concept Classes with VC Dimension 1", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "We present the first nearly optimal differentially private PAC learner for\nany concept class with VC dimension 1 and Littlestone dimension $d$. Our\nalgorithm achieves the sample complexity of\n$\\tilde{O}_{\\varepsilon,\\delta,\\alpha,\\delta}(\\log^* d)$, nearly matching the\nlower bound of $\\Omega(\\log^* d)$ proved by Alon et al. [STOC19]. Prior to our\nwork, the best known upper bound is $\\tilde{O}(VC\\cdot d^5)$ for general VC\nclasses, as shown by Ghazi et al. [STOC21].", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.07784", "pdf": "https://arxiv.org/pdf/2505.07784", "abs": "https://arxiv.org/abs/2505.07784", "authors": ["Da Ju", "Hagen Blix", "Adina Williams"], "title": "Domain Regeneration: How well do LLMs match syntactic properties of text domains?", "categories": ["cs.CL"], "comment": null, "summary": "Recent improvement in large language model performance have, in all\nlikelihood, been accompanied by improvement in how well they can approximate\nthe distribution of their training data. In this work, we explore the following\nquestion: which properties of text domains do LLMs faithfully approximate, and\nhow well do they do so? Applying observational approaches familiar from corpus\nlinguistics, we prompt a commonly used, opensource LLM to regenerate text from\ntwo domains of permissively licensed English text which are often contained in\nLLM training data -- Wikipedia and news text. This regeneration paradigm allows\nus to investigate whether LLMs can faithfully match the original human text\ndomains in a fairly semantically-controlled setting. We investigate varying\nlevels of syntactic abstraction, from more simple properties like sentence\nlength, and article readability, to more complex and higher order properties\nsuch as dependency tag distribution, parse depth, and parse complexity. We find\nthat the majority of the regenerated distributions show a shifted mean, a lower\nstandard deviation, and a reduction of the long tail, as compared to the human\noriginals.", "AI": {"tldr": "The paper investigates how well LLMs approximate properties of text domains like Wikipedia and news, finding shifted means and reduced variance in regenerated text.", "motivation": "To understand which properties of text domains LLMs faithfully approximate and how well they do so.", "method": "Observational approaches from corpus linguistics, prompting an open-source LLM to regenerate text from Wikipedia and news domains, analyzing syntactic abstraction levels.", "result": "Regenerated text shows shifted means, lower standard deviation, and reduced long tails compared to human originals.", "conclusion": "LLMs approximate text domain properties but with notable deviations in distribution characteristics."}}
{"id": "2505.06982", "pdf": "https://arxiv.org/pdf/2505.06982", "abs": "https://arxiv.org/abs/2505.06982", "authors": ["Md. Naimur Asif Borno", "Md Sakib Hossain Shovon", "MD Hanif Sikder", "Iffat Firozy Rimi", "Tahani Jaser Alahmadi", "Mohammad Ali Moni"], "title": "Federated Learning with LoRA Optimized DeiT and Multiscale Patch Embedding for Secure Eye Disease Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in image-based medical disease detection encounters\nchallenges such as limited annotated data sets, inadequate spatial feature\nanalysis, data security issues, and inefficient training frameworks. This study\nintroduces a data-efficient image transformer (DeIT)-based approach that\novercomes these challenges by utilizing multiscale patch embedding for better\nfeature extraction and stratified weighted random sampling to address class\nimbalance. The model also incorporates a LoRA-enhanced transformer encoder, a\ndistillation framework, and federated learning for decentralized training,\nimproving both efficiency and data security. Consequently, it achieves\nstate-of-the-art performance, with the highest AUC, F1 score, precision,\nminimal loss, and Top-5 accuracy. Additionally, Grad-CAM++ visualizations\nimprove interpretability by highlighting critical pathological regions,\nenhancing the model's clinical relevance. These results highlight the potential\nof this approach to advance AI-powered medical imaging and disease detection.", "AI": {"tldr": "A DeIT-based approach improves medical disease detection by addressing data limitations, feature extraction, and security, achieving top performance and interpretability.", "motivation": "Challenges like limited annotated data, poor feature analysis, data security, and inefficient training hinder medical disease detection.", "method": "Uses multiscale patch embedding, stratified sampling, LoRA-enhanced transformer, distillation, and federated learning.", "result": "Achieves highest AUC, F1, precision, minimal loss, and Top-5 accuracy, with Grad-CAM++ for interpretability.", "conclusion": "The approach advances AI-powered medical imaging with efficient, secure, and interpretable disease detection."}}
{"id": "2505.06277", "pdf": "https://arxiv.org/pdf/2505.06277", "abs": "https://arxiv.org/abs/2505.06277", "authors": ["John Song", "Lihao Zhang", "Feng Ye", "Haijian Sun"], "title": "Terahertz Spatial Wireless Channel Modeling with Radio Radiance Field", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.NI"], "comment": "submitted to IEEE conferences", "summary": "Terahertz (THz) communication is a key enabler for 6G systems, offering\nultra-wide bandwidth and unprecedented data rates. However, THz signal\npropagation differs significantly from lower-frequency bands due to severe free\nspace path loss, minimal diffraction and specular reflection, and prominent\nscattering, making conventional channel modeling and pilot-based estimation\napproaches inefficient. In this work, we investigate the feasibility of\napplying radio radiance field (RRF) framework to the THz band. This method\nreconstructs a continuous RRF using visual-based geometry and sparse THz RF\nmeasurements, enabling efficient spatial channel state information\n(Spatial-CSI) modeling without dense sampling. We first build a fine simulated\nTHz scenario, then we reconstruct the RRF and evaluate the performance in terms\nof both reconstruction quality and effectiveness in THz communication, showing\nthat the reconstructed RRF captures key propagation paths with sparse training\nsamples. Our findings demonstrate that RRF modeling remains effective in the\nTHz regime and provides a promising direction for scalable, low-cost spatial\nchannel reconstruction in future 6G networks.", "AI": {"tldr": "The paper explores using radio radiance field (RRF) for THz communication, showing it effectively models spatial channel state with sparse data.", "motivation": "THz communication faces challenges like severe path loss and inefficient channel modeling, requiring new approaches.", "method": "The study reconstructs RRF using visual-based geometry and sparse THz measurements, testing it in a simulated THz scenario.", "result": "RRF captures key propagation paths with sparse samples, proving effective for THz spatial channel modeling.", "conclusion": "RRF is a scalable, low-cost solution for THz channel reconstruction in 6G networks."}}
{"id": "2505.06597", "pdf": "https://arxiv.org/pdf/2505.06597", "abs": "https://arxiv.org/abs/2505.06597", "authors": ["Ibrahim Talha Ersoy", "Karoline Wiesner"], "title": "Geometry of Learning -- L2 Phase Transitions in Deep and Shallow Neural Networks", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "physics.data-an"], "comment": null, "summary": "When neural networks (NNs) are subject to L2 regularization, increasing the\nregularization strength beyond a certain threshold pushes the model into an\nunder-parameterization regime. This transition manifests as a first-order phase\ntransition in single-hidden-layer NNs and a second-order phase transition in\nNNs with two or more hidden layers. This paper establishes a unified framework\nfor such transitions by integrating the Ricci curvature of the loss landscape\nwith regularizer-driven deep learning. First, we show that a curvature\nchange-point separates the model-accuracy regimes in the onset of learning and\nthat it is identical to the critical point of the phase transition driven by\nregularization. Second, we show that for more complex data sets additional\nphase transitions exist between model accuracies, and that they are again\nidentical to curvature change points in the error landscape. Third, by studying\nthe MNIST data set using a Variational Autoencoder, we demonstrate that the\ncurvature change points identify phase transitions in model accuracy outside\nthe L2 setting. Our framework also offers practical insights for optimizing\nmodel performance across various architectures and datasets. By linking\ngeometric features of the error landscape to observable phase transitions, our\nwork paves the way for more informed regularization strategies and potentially\nnew methods for probing the intrinsic structure of neural networks beyond the\nL2 context.", "AI": {"tldr": "The paper explores how L2 regularization in neural networks leads to phase transitions, linking these to curvature changes in the loss landscape, and extends findings to complex datasets and non-L2 settings.", "motivation": "To understand the relationship between regularization strength, phase transitions, and the geometric properties of the loss landscape in neural networks.", "method": "Integrates Ricci curvature of the loss landscape with regularizer-driven deep learning, analyzing phase transitions and curvature change points in single and multi-hidden-layer NNs, including experiments on MNIST using a Variational Autoencoder.", "result": "Identifies that curvature change points correspond to phase transitions in model accuracy, applicable even beyond L2 regularization, and provides insights for optimizing model performance.", "conclusion": "The framework connects geometric features of the error landscape to phase transitions, offering practical regularization strategies and new methods for probing neural network structures."}}
{"id": "2505.07787", "pdf": "https://arxiv.org/pdf/2505.07787", "abs": "https://arxiv.org/abs/2505.07787", "authors": ["Tongxu Luo", "Wenyu Du", "Jiaxi Bi", "Stephen Chung", "Zhengyang Tang", "Hao Yang", "Min Zhang", "Benyou Wang"], "title": "Learning from Peers in Reasoning Models", "categories": ["cs.CL"], "comment": "29 pages, 32 figures", "summary": "Large Reasoning Models (LRMs) have the ability to self-correct even when they\nmake mistakes in their reasoning paths. However, our study reveals that when\nthe reasoning process starts with a short but poor beginning, it becomes\ndifficult for the model to recover. We refer to this phenomenon as the \"Prefix\nDominance Trap\". Inspired by psychological findings that peer interaction can\npromote self-correction without negatively impacting already accurate\nindividuals, we propose **Learning from Peers** (LeaP) to address this\nphenomenon. Specifically, every tokens, each reasoning path summarizes its\nintermediate reasoning and shares it with others through a routing mechanism,\nenabling paths to incorporate peer insights during inference. However, we\nobserve that smaller models sometimes fail to follow summarization and\nreflection instructions effectively. To address this, we fine-tune them into\nour **LeaP-T** model series. Experiments on AIME 2024, AIME 2025, AIMO 2025,\nand GPQA Diamond show that LeaP provides substantial improvements. For\ninstance, QwQ-32B with LeaP achieves nearly 5 absolute points higher than the\nbaseline on average, and surpasses DeepSeek-R1-671B on three math benchmarks\nwith an average gain of 3.3 points. Notably, our fine-tuned LeaP-T-7B matches\nthe performance of DeepSeek-R1-Distill-Qwen-14B on AIME 2024. In-depth analysis\nreveals LeaP's robust error correction by timely peer insights, showing strong\nerror tolerance and handling varied task difficulty. LeaP marks a milestone by\nenabling LRMs to collaborate during reasoning. Our code, datasets, and models\nare available at https://learning-from-peers.github.io/ .", "AI": {"tldr": "The paper introduces Learning from Peers (LeaP) to help Large Reasoning Models (LRMs) recover from poor reasoning starts, addressing the 'Prefix Dominance Trap'. LeaP-T fine-tuned models show significant performance gains on benchmarks.", "motivation": "To overcome the 'Prefix Dominance Trap' where LRMs struggle to recover from poor initial reasoning, inspired by peer interaction's psychological benefits.", "method": "Proposes LeaP, where reasoning paths share intermediate insights via a routing mechanism. Fine-tunes smaller models into LeaP-T for better instruction adherence.", "result": "LeaP improves performance, e.g., QwQ-32B gains 5 points over baseline, surpassing larger models like DeepSeek-R1-671B. LeaP-T-7B matches DeepSeek-R1-Distill-Qwen-14B on AIME 2024.", "conclusion": "LeaP enables LRMs to collaborate during reasoning, showing robust error correction and handling varied task difficulty. It marks a milestone in collaborative reasoning for LRMs."}}
{"id": "2505.06985", "pdf": "https://arxiv.org/pdf/2505.06985", "abs": "https://arxiv.org/abs/2505.06985", "authors": ["Panwen Hu", "Jiehui Huang", "Qiang Sun", "Xiaodan Liang"], "title": "BridgeIV: Bridging Customized Image and Video Generation through Test-Time Autoregressive Identity Propagation", "categories": ["cs.CV"], "comment": null, "summary": "Both zero-shot and tuning-based customized text-to-image (CT2I) generation\nhave made significant progress for storytelling content creation. In contrast,\nresearch on customized text-to-video (CT2V) generation remains relatively\nlimited. Existing zero-shot CT2V methods suffer from poor generalization, while\nanother line of work directly combining tuning-based T2I models with temporal\nmotion modules often leads to the loss of structural and texture information.\nTo bridge this gap, we propose an autoregressive structure and texture\npropagation module (STPM), which extracts key structural and texture features\nfrom the reference subject and injects them autoregressively into each video\nframe to enhance consistency. Additionally, we introduce a test-time reward\noptimization (TTRO) method to further refine fine-grained details. Quantitative\nand qualitative experiments validate the effectiveness of STPM and TTRO,\ndemonstrating improvements of 7.8 and 13.1 in CLIP-I and DINO consistency\nmetrics over the baseline, respectively.", "AI": {"tldr": "Proposes STPM and TTRO for CT2V generation to enhance consistency and detail, outperforming baselines.", "motivation": "Limited research on CT2V generation, with existing methods suffering from poor generalization or loss of structural/texture details.", "method": "Uses autoregressive STPM to propagate structural/texture features and TTRO for fine-grained detail refinement.", "result": "Improves CLIP-I and DINO consistency metrics by 7.8 and 13.1, respectively.", "conclusion": "STPM and TTRO effectively address CT2V challenges, enhancing consistency and detail."}}
{"id": "2505.06299", "pdf": "https://arxiv.org/pdf/2505.06299", "abs": "https://arxiv.org/abs/2505.06299", "authors": ["Spyridon Raptis", "Haralampos-G. Stratigopoulos"], "title": "Input-Specific and Universal Adversarial Attack Generation for Spiking Neural Networks in the Spiking Domain", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "As Spiking Neural Networks (SNNs) gain traction across various applications,\nunderstanding their security vulnerabilities becomes increasingly important. In\nthis work, we focus on the adversarial attacks, which is perhaps the most\nconcerning threat. An adversarial attack aims at finding a subtle input\nperturbation to fool the network's decision-making. We propose two novel\nadversarial attack algorithms for SNNs: an input-specific attack that crafts\nadversarial samples from specific dataset inputs and a universal attack that\ngenerates a reusable patch capable of inducing misclassification across most\ninputs, thus offering practical feasibility for real-time deployment. The\nalgorithms are gradient-based operating in the spiking domain proving to be\neffective across different evaluation metrics, such as adversarial accuracy,\nstealthiness, and generation time. Experimental results on two widely used\nneuromorphic vision datasets, NMNIST and IBM DVS Gesture, show that our\nproposed attacks surpass in all metrics all existing state-of-the-art methods.\nAdditionally, we present the first demonstration of adversarial attack\ngeneration in the sound domain using the SHD dataset.", "AI": {"tldr": "The paper proposes two novel adversarial attack algorithms for Spiking Neural Networks (SNNs), demonstrating their effectiveness and superiority over existing methods.", "motivation": "Understanding security vulnerabilities in SNNs, particularly adversarial attacks, is crucial as SNNs gain popularity in various applications.", "method": "Two gradient-based adversarial attack algorithms are introduced: an input-specific attack and a universal attack, both operating in the spiking domain.", "result": "The attacks outperform state-of-the-art methods on NMNIST and IBM DVS Gesture datasets and are also demonstrated in the sound domain using the SHD dataset.", "conclusion": "The proposed adversarial attacks are effective, stealthy, and feasible for real-time deployment, highlighting significant security concerns for SNNs."}}
{"id": "2505.06621", "pdf": "https://arxiv.org/pdf/2505.06621", "abs": "https://arxiv.org/abs/2505.06621", "authors": ["Thamiris Coelho", "Leo S. F. Ribeiro", "Jo\u00e3o Macedo", "Jefersson A. dos Santos", "Sandra Avila"], "title": "Minimizing Risk Through Minimizing Model-Data Interaction: A Protocol For Relying on Proxy Tasks When Designing Child Sexual Abuse Imagery Detection Models", "categories": ["cs.LG", "cs.CV"], "comment": "ACM Conference on Fairness, Accountability, and Transparency (FAccT\n  2025)", "summary": "The distribution of child sexual abuse imagery (CSAI) is an ever-growing\nconcern of our modern world; children who suffered from this heinous crime are\nrevictimized, and the growing amount of illegal imagery distributed overwhelms\nlaw enforcement agents (LEAs) with the manual labor of categorization. To ease\nthis burden researchers have explored methods for automating data triage and\ndetection of CSAI, but the sensitive nature of the data imposes restricted\naccess and minimal interaction between real data and learning algorithms,\navoiding leaks at all costs. In observing how these restrictions have shaped\nthe literature we formalize a definition of \"Proxy Tasks\", i.e., the substitute\ntasks used for training models for CSAI without making use of CSA data. Under\nthis new terminology we review current literature and present a protocol for\nmaking conscious use of Proxy Tasks together with consistent input from LEAs to\ndesign better automation in this field. Finally, we apply this protocol to\nstudy -- for the first time -- the task of Few-shot Indoor Scene Classification\non CSAI, showing a final model that achieves promising results on a real-world\nCSAI dataset whilst having no weights actually trained on sensitive data.", "AI": {"tldr": "The paper addresses the challenge of automating CSAI detection without direct access to sensitive data, introducing 'Proxy Tasks' as a solution and demonstrating their effectiveness in a real-world application.", "motivation": "The growing issue of CSAI distribution overwhelms LEAs, necessitating automated solutions that avoid direct interaction with sensitive data to prevent leaks.", "method": "The authors formalize 'Proxy Tasks' for training models without CSAI data, review existing literature, and propose a protocol combining Proxy Tasks with LEA input. They apply this to Few-shot Indoor Scene Classification on CSAI.", "result": "The proposed model achieves promising results on a real-world CSAI dataset without training on sensitive data.", "conclusion": "Proxy Tasks offer a viable approach for automating CSAI detection while adhering to data sensitivity constraints, with potential for further refinement."}}
{"id": "2505.07796", "pdf": "https://arxiv.org/pdf/2505.07796", "abs": "https://arxiv.org/abs/2505.07796", "authors": ["Xingjin Wang", "Howe Tissue", "Lu Wang", "Linjing Li", "Daniel Dajun Zeng"], "title": "Learning Dynamics in Continual Pre-Training for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to ICML2025 (spotlight)", "summary": "Continual Pre-Training (CPT) has become a popular and effective method to\napply strong foundation models to specific downstream tasks. In this work, we\nexplore the learning dynamics throughout the CPT process for large language\nmodels. We specifically focus on how general and downstream domain performance\nevolves at each training step, with domain performance measured via validation\nlosses. We have observed that the CPT loss curve fundamentally characterizes\nthe transition from one curve to another hidden curve, and could be described\nby decoupling the effects of distribution shift and learning rate annealing. We\nderive a CPT scaling law that combines the two factors, enabling the prediction\nof loss at any (continual) training steps and across learning rate schedules\n(LRS) in CPT. Our formulation presents a comprehensive understanding of several\ncritical factors in CPT, including loss potential, peak learning rate, training\nsteps, replay ratio, etc. Moreover, our approach can be adapted to customize\ntraining hyper-parameters to different CPT goals such as balancing general and\ndomain-specific performance. Extensive experiments demonstrate that our scaling\nlaw holds across various CPT datasets and training hyper-parameters.", "AI": {"tldr": "The paper explores learning dynamics in Continual Pre-Training (CPT) for large language models, focusing on performance evolution and deriving a scaling law to predict loss and optimize training.", "motivation": "To understand how general and domain-specific performance evolves during CPT and to develop a predictive model for loss dynamics.", "method": "Analyzes CPT loss curves, decouples distribution shift and learning rate annealing effects, and derives a scaling law combining these factors.", "result": "The scaling law accurately predicts loss across training steps and learning rate schedules, validated by experiments on various datasets.", "conclusion": "The derived scaling law provides a comprehensive framework for optimizing CPT, balancing general and domain-specific performance."}}
{"id": "2505.06991", "pdf": "https://arxiv.org/pdf/2505.06991", "abs": "https://arxiv.org/abs/2505.06991", "authors": ["Chih-Chung Hsu", "I-Hsuan Wu", "Wen-Hai Tseng", "Ching-Heng Cheng", "Ming-Hsuan Wu", "Jin-Hui Jiang", "Yu-Jou Hsiao"], "title": "Technical Report for ICRA 2025 GOOSE 2D Semantic Segmentation Challenge: Leveraging Color Shift Correction, RoPE-Swin Backbone, and Quantile-based Label Denoising Strategy for Robust Outdoor Scene Understanding", "categories": ["cs.CV"], "comment": null, "summary": "This report presents our semantic segmentation framework developed by team\nACVLAB for the ICRA 2025 GOOSE 2D Semantic Segmentation Challenge, which\nfocuses on parsing outdoor scenes into nine semantic categories under\nreal-world conditions. Our method integrates a Swin Transformer backbone\nenhanced with Rotary Position Embedding (RoPE) for improved spatial\ngeneralization, alongside a Color Shift Estimation-and-Correction module\ndesigned to compensate for illumination inconsistencies in natural\nenvironments. To further improve training stability, we adopt a quantile-based\ndenoising strategy that downweights the top 2.5\\% of highest-error pixels,\ntreating them as noise and suppressing their influence during optimization.\nEvaluated on the official GOOSE test set, our approach achieved a mean\nIntersection over Union (mIoU) of 0.848, demonstrating the effectiveness of\ncombining color correction, positional encoding, and error-aware denoising in\nrobust semantic segmentation.", "AI": {"tldr": "A semantic segmentation framework for outdoor scenes using Swin Transformer with RoPE, color correction, and error-aware denoising, achieving 0.848 mIoU.", "motivation": "To parse outdoor scenes into nine semantic categories under real-world conditions, addressing illumination inconsistencies and training noise.", "method": "Integrates Swin Transformer with Rotary Position Embedding (RoPE) for spatial generalization, a Color Shift Estimation-and-Correction module, and quantile-based denoising.", "result": "Achieved a mean Intersection over Union (mIoU) of 0.848 on the GOOSE test set.", "conclusion": "Combining color correction, positional encoding, and error-aware denoising proves effective for robust semantic segmentation."}}
{"id": "2505.06305", "pdf": "https://arxiv.org/pdf/2505.06305", "abs": "https://arxiv.org/abs/2505.06305", "authors": ["Haowei Yang", "Qingyi Lu", "Yang Wang", "Sibei Liu", "Jiayun Zheng", "Ao Xiang"], "title": "User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "With the widespread application of large language models (LLMs), user privacy\nprotection has become a significant research topic. Existing privacy preference\nmodeling methods often rely on large-scale user data, making effective privacy\npreference analysis challenging in data-limited environments. This study\nexplores how LLMs can analyze user behavior related to privacy protection in\nscenarios with limited data and proposes a method that integrates Few-shot\nLearning and Privacy Computing to model user privacy preferences. The research\nutilizes anonymized user privacy settings data, survey responses, and simulated\ndata, comparing the performance of traditional modeling approaches with\nLLM-based methods. Experimental results demonstrate that, even with limited\ndata, LLMs significantly improve the accuracy of privacy preference modeling.\nAdditionally, incorporating Differential Privacy and Federated Learning further\nreduces the risk of user data exposure. The findings provide new insights into\nthe application of LLMs in privacy protection and offer theoretical support for\nadvancing privacy computing and user behavior analysis.", "AI": {"tldr": "LLMs improve privacy preference modeling accuracy in data-limited settings using Few-shot Learning and Privacy Computing, with added benefits from Differential Privacy and Federated Learning.", "motivation": "Addressing the challenge of privacy preference analysis in data-limited environments due to reliance on large-scale user data.", "method": "Integrates Few-shot Learning and Privacy Computing with LLMs, using anonymized user privacy settings, surveys, and simulated data.", "result": "LLMs significantly enhance modeling accuracy even with limited data; Differential Privacy and Federated Learning reduce data exposure risks.", "conclusion": "LLMs offer promising applications in privacy protection, supporting advancements in privacy computing and user behavior analysis."}}
{"id": "2505.06651", "pdf": "https://arxiv.org/pdf/2505.06651", "abs": "https://arxiv.org/abs/2505.06651", "authors": ["Zehan Zhu", "Yan Huang", "Xin Wang", "Shouling Ji", "Jinming Xu"], "title": "Dyn-D$^2$P: Dynamic Differentially Private Decentralized Learning with Provable Utility Guarantee", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted by the 34th International Joint\n  Conference on Artificial Intelligence(IJCAI 2025)", "summary": "Most existing decentralized learning methods with differential privacy (DP)\nguarantee rely on constant gradient clipping bounds and fixed-level DP Gaussian\nnoises for each node throughout the training process, leading to a significant\naccuracy degradation compared to non-private counterparts. In this paper, we\npropose a new Dynamic Differentially Private Decentralized learning approach\n(termed Dyn-D$^2$P) tailored for general time-varying directed networks.\nLeveraging the Gaussian DP (GDP) framework for privacy accounting, Dyn-D$^2$P\ndynamically adjusts gradient clipping bounds and noise levels based on gradient\nconvergence. This proposed dynamic noise strategy enables us to enhance model\naccuracy while preserving the total privacy budget. Extensive experiments on\nbenchmark datasets demonstrate the superiority of Dyn-D$^2$P over its\ncounterparts employing fixed-level noises, especially under strong privacy\nguarantees. Furthermore, we provide a provable utility bound for Dyn-D$^2$P\nthat establishes an explicit dependency on network-related parameters, with a\nscaling factor of $1/\\sqrt{n}$ in terms of the number of nodes $n$ up to a bias\nerror term induced by gradient clipping. To our knowledge, this is the first\nmodel utility analysis for differentially private decentralized non-convex\noptimization with dynamic gradient clipping bounds and noise levels.", "AI": {"tldr": "Dyn-D$^2$P is a dynamic differentially private decentralized learning method for time-varying networks, improving accuracy by adjusting gradient clipping and noise levels while preserving privacy.", "motivation": "Existing methods use fixed noise and clipping, degrading accuracy. Dyn-D$^2$P aims to enhance accuracy under strong privacy guarantees.", "method": "Dyn-D$^2$P dynamically adjusts gradient clipping and noise levels using the GDP framework, based on gradient convergence.", "result": "Experiments show Dyn-D$^2$P outperforms fixed-noise methods, especially under strong privacy. A utility bound is provided, scaling as $1/\\sqrt{n}$.", "conclusion": "Dyn-D$^2$P is the first to analyze utility for dynamic private decentralized non-convex optimization, improving accuracy and privacy."}}
{"id": "2505.07809", "pdf": "https://arxiv.org/pdf/2505.07809", "abs": "https://arxiv.org/abs/2505.07809", "authors": ["M\u00e1t\u00e9 Gedeon"], "title": "A Comparative Analysis of Static Word Embeddings for Hungarian", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper presents a comprehensive analysis of various static word\nembeddings for Hungarian, including traditional models such as Word2Vec,\nFastText, as well as static embeddings derived from BERT-based models using\ndifferent extraction methods. We evaluate these embeddings on both intrinsic\nand extrinsic tasks to provide a holistic view of their performance. For\nintrinsic evaluation, we employ a word analogy task, which assesses the\nembeddings ability to capture semantic and syntactic relationships. Our results\nindicate that traditional static embeddings, particularly FastText, excel in\nthis task, achieving high accuracy and mean reciprocal rank (MRR) scores. Among\nthe BERT-based models, the X2Static method for extracting static embeddings\ndemonstrates superior performance compared to decontextualized and aggregate\nmethods, approaching the effectiveness of traditional static embeddings. For\nextrinsic evaluation, we utilize a bidirectional LSTM model to perform Named\nEntity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The results\nreveal that embeddings derived from dynamic models, especially those extracted\nusing the X2Static method, outperform purely static embeddings. Notably, ELMo\nembeddings achieve the highest accuracy in both NER and POS tagging tasks,\nunderscoring the benefits of contextualized representations even when used in a\nstatic form. Our findings highlight the continued relevance of static word\nembeddings in NLP applications and the potential of advanced extraction methods\nto enhance the utility of BERT-based models. This piece of research contributes\nto the understanding of embedding performance in the Hungarian language and\nprovides valuable insights for future developments in the field. The training\nscripts, evaluation codes, restricted vocabulary, and extracted embeddings will\nbe made publicly available to support further research and reproducibility.", "AI": {"tldr": "The paper analyzes static word embeddings for Hungarian, comparing traditional models (Word2Vec, FastText) and BERT-based embeddings. FastText excels in intrinsic tasks, while BERT-based X2Static performs well. Dynamic embeddings (e.g., ELMo) outperform static ones in extrinsic tasks like NER and POS tagging.", "motivation": "To evaluate and compare the performance of various static word embeddings for Hungarian, including traditional and BERT-based models, to understand their effectiveness in NLP tasks.", "method": "Intrinsic evaluation uses word analogy tasks; extrinsic evaluation employs a bidirectional LSTM for NER and POS tagging. Traditional and BERT-based embeddings are compared.", "result": "FastText excels in intrinsic tasks; BERT-based X2Static performs well. Dynamic embeddings (ELMo) outperform static ones in extrinsic tasks.", "conclusion": "Static embeddings remain relevant, and advanced extraction methods (X2Static) enhance BERT-based models. Findings support future NLP developments for Hungarian."}}
{"id": "2505.06995", "pdf": "https://arxiv.org/pdf/2505.06995", "abs": "https://arxiv.org/abs/2505.06995", "authors": ["Md. Naimur Asif Borno", "Md Sakib Hossain Shovon", "Asmaa Soliman Al-Moisheer", "Mohammad Ali Moni"], "title": "Replay-Based Continual Learning with Dual-Layered Distillation and a Streamlined U-Net for Efficient Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in text-to-image diffusion models are hindered by high\ncomputational demands, limiting accessibility and scalability. This paper\nintroduces KDC-Diff, a novel stable diffusion framework that enhances\nefficiency while maintaining image quality. KDC-Diff features a streamlined\nU-Net architecture with nearly half the parameters of the original U-Net\n(482M), significantly reducing model complexity. We propose a dual-layered\ndistillation strategy to ensure high-fidelity generation, transferring semantic\nand structural insights from a teacher to a compact student model while\nminimizing quality degradation. Additionally, replay-based continual learning\nis integrated to mitigate catastrophic forgetting, allowing the model to retain\nprior knowledge while adapting to new data. Despite operating under extremely\nlow computational resources, KDC-Diff achieves state-of-the-art performance on\nthe Oxford Flowers and Butterflies & Moths 100 Species datasets, demonstrating\ncompetitive metrics such as FID, CLIP, and LPIPS. Moreover, it significantly\nreduces inference time compared to existing models. These results establish\nKDC-Diff as a highly efficient and adaptable solution for text-to-image\ngeneration, particularly in computationally constrained environments.", "AI": {"tldr": "KDC-Diff is an efficient stable diffusion framework for text-to-image generation, reducing computational demands while maintaining quality.", "motivation": "High computational demands of text-to-image diffusion models limit accessibility and scalability.", "method": "Introduces a streamlined U-Net with fewer parameters, dual-layered distillation for high-fidelity generation, and replay-based continual learning to retain knowledge.", "result": "Achieves state-of-the-art performance on datasets like Oxford Flowers and Butterflies & Moths 100 Species, with competitive metrics and reduced inference time.", "conclusion": "KDC-Diff is a highly efficient and adaptable solution for text-to-image generation in resource-constrained environments."}}
{"id": "2505.06307", "pdf": "https://arxiv.org/pdf/2505.06307", "abs": "https://arxiv.org/abs/2505.06307", "authors": ["Mingfei Zeng", "Ming Xie", "Xixi Zheng", "Chunhai Li", "Chuan Zhang", "Liehuang Zhu"], "title": "Large Language Model-driven Security Assistant for Internet of Things via Chain-of-Thought", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The rapid development of Internet of Things (IoT) technology has transformed\npeople's way of life and has a profound impact on both production and daily\nactivities. However, with the rapid advancement of IoT technology, the security\nof IoT devices has become an unavoidable issue in both research and\napplications. Although some efforts have been made to detect or mitigate IoT\nsecurity vulnerabilities, they often struggle to adapt to the complexity of IoT\nenvironments, especially when dealing with dynamic security scenarios. How to\nautomatically, efficiently, and accurately understand these vulnerabilities\nremains a challenge. To address this, we propose an IoT security assistant\ndriven by Large Language Model (LLM), which enhances the LLM's understanding of\nIoT security vulnerabilities and related threats. The aim of the ICoT method we\npropose is to enable the LLM to understand security issues by breaking down the\nvarious dimensions of security vulnerabilities and generating responses\ntailored to the user's specific needs and expertise level. By incorporating\nICoT, LLM can gradually analyze and reason through complex security scenarios,\nresulting in more accurate, in-depth, and personalized security recommendations\nand solutions. Experimental results show that, compared to methods relying\nsolely on LLM, our proposed LLM-driven IoT security assistant significantly\nimproves the understanding of IoT security issues through the ICoT approach and\nprovides personalized solutions based on the user's identity, demonstrating\nhigher accuracy and reliability.", "AI": {"tldr": "The paper proposes an LLM-driven IoT security assistant (ICoT) to enhance understanding and provide personalized solutions for IoT security vulnerabilities, outperforming traditional LLM methods.", "motivation": "The rapid growth of IoT technology has raised security concerns, but existing solutions struggle with complexity and dynamic scenarios. The paper aims to improve vulnerability understanding and response accuracy.", "method": "The ICoT method breaks down security vulnerabilities into dimensions and tailors LLM responses to user needs and expertise, enabling deeper analysis and reasoning.", "result": "Experiments show the LLM-driven assistant with ICoT significantly improves IoT security understanding and offers more accurate, personalized solutions than pure LLM methods.", "conclusion": "The ICoT approach enhances LLM's capability to address IoT security challenges, providing reliable and tailored recommendations."}}
{"id": "2505.06653", "pdf": "https://arxiv.org/pdf/2505.06653", "abs": "https://arxiv.org/abs/2505.06653", "authors": ["Patrick Blumenberg", "Thomas Graave", "Tim Fingscheidt"], "title": "Improving Block-Wise LLM Quantization by 4-bit Block-Wise Optimal Float (BOF4): Analysis and Variations", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) demand extensive memory capacity during both\nfine-tuning and inference. To enable memory-efficient fine-tuning, existing\nmethods apply block-wise quantization techniques, such as NF4 and AF4, to the\nnetwork weights. We show that these quantization techniques incur suboptimal\nquantization errors. Therefore, as a first novelty, we propose an optimization\napproach for block-wise quantization. Using this method, we design a family of\nquantizers named 4-bit block-wise optimal float (BOF4), which consistently\nreduces the quantization error compared to both baseline methods. We provide\nboth a theoretical and a data-driven solution for the optimization process and\nprove their practical equivalence. Secondly, we propose a modification to the\nemployed normalization method based on the signed absolute block maximum\n(BOF4-S), enabling further reduction of the quantization error and empirically\nachieving less degradation in language modeling performance. Thirdly, we\nexplore additional variations of block-wise quantization methods applied to\nLLMs through an experimental study on the importance of accurately representing\nzero and large-amplitude weights on the one hand, and optimization towards\nvarious error metrics on the other hand. Lastly, we introduce a mixed-precision\nquantization strategy dubbed outlier-preserving quantization (OPQ) to address\nthe distributional mismatch induced by outlier weights in block-wise\nquantization. By storing outlier weights in 16-bit precision (OPQ) while\napplying BOF4-S, we achieve top performance among 4-bit block-wise quantization\ntechniques w.r.t. perplexity.", "AI": {"tldr": "The paper introduces BOF4, a 4-bit block-wise optimal float quantizer, reducing quantization errors in LLMs. It also proposes BOF4-S and OPQ for improved performance.", "motivation": "Existing quantization methods like NF4 and AF4 for LLMs incur suboptimal errors, prompting the need for optimized solutions.", "method": "Proposes BOF4 for optimized block-wise quantization, BOF4-S for error reduction, and OPQ for handling outlier weights.", "result": "BOF4-S and OPQ achieve top performance in 4-bit quantization, minimizing perplexity degradation.", "conclusion": "The proposed methods outperform baselines, offering efficient and accurate quantization for LLMs."}}
{"id": "2505.06313", "pdf": "https://arxiv.org/pdf/2505.06313", "abs": "https://arxiv.org/abs/2505.06313", "authors": ["Bohdan M. Pavlyshenko"], "title": "AI Approaches to Qualitative and Quantitative News Analytics on NATO Unity", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.SI"], "comment": null, "summary": "The paper considers the use of GPT models with retrieval-augmented generation\n(RAG) for qualitative and quantitative analytics on NATO sentiments, NATO unity\nand NATO Article 5 trust opinion scores in different web sources: news sites\nfound via Google Search API, Youtube videos with comments, and Reddit\ndiscussions. A RAG approach using GPT-4.1 model was applied to analyse news\nwhere NATO related topics were discussed. Two levels of RAG analytics were\nused: on the first level, the GPT model generates qualitative news summaries\nand quantitative opinion scores using zero-shot prompts; on the second level,\nthe GPT model generates the summary of news summaries. Quantitative news\nopinion scores generated by the GPT model were analysed using Bayesian\nregression to get trend lines. The distributions found for the regression\nparameters make it possible to analyse an uncertainty in specified news opinion\nscore trends. Obtained results show a downward trend for analysed scores of\nopinion related to NATO unity.\n  This approach does not aim to conduct real political analysis; rather, it\nconsider AI based approaches which can be used for further analytics\n  as a part of a complex analytical approach. The obtained results demonstrate\nthat the use of GPT models for news analysis can give informative qualitative\nand quantitative analytics, providing important insights.\n  The dynamic model based on neural ordinary differential equations was\nconsidered for modelling public opinions. This approach makes it possible to\nanalyse different scenarios for evolving public opinions.", "AI": {"tldr": "The paper explores using GPT-4.1 with RAG for analyzing NATO sentiment trends in web sources, revealing a downward trend in NATO unity opinion scores.", "motivation": "To demonstrate AI-based approaches for qualitative and quantitative analytics on public opinions about NATO, without aiming for real political analysis.", "method": "Uses GPT-4.1 with RAG for two-level analytics: qualitative summaries and quantitative scores, followed by Bayesian regression for trend analysis.", "result": "Shows a downward trend in NATO unity opinion scores and provides uncertainty analysis for trends.", "conclusion": "GPT models with RAG can offer valuable insights for complex analytical tasks, though not for direct political analysis."}}
{"id": "2505.07001", "pdf": "https://arxiv.org/pdf/2505.07001", "abs": "https://arxiv.org/abs/2505.07001", "authors": ["Bidur Khanal", "Sandesh Pokhrel", "Sanjay Bhandari", "Ramesh Rana", "Nikesh Shrestha", "Ram Bahadur Gurung", "Cristian Linte", "Angus Watson", "Yash Raj Shrestha", "Binod Bhattarai"], "title": "Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Vision-Language Models (VLMs) are becoming increasingly popular in the\nmedical domain, bridging the gap between medical images and clinical language.\nExisting VLMs demonstrate an impressive ability to comprehend medical images\nand text queries to generate detailed, descriptive diagnostic medical reports.\nHowever, hallucination--the tendency to generate descriptions that are\ninconsistent with the visual content--remains a significant issue in VLMs, with\nparticularly severe implications in the medical field. To facilitate VLM\nresearch on gastrointestinal (GI) image analysis and study hallucination, we\ncurate a multimodal image-text GI dataset: Gut-VLM. This dataset is created\nusing a two-stage pipeline: first, descriptive medical reports of Kvasir-v2\nimages are generated using ChatGPT, which introduces some hallucinated or\nincorrect texts. In the second stage, medical experts systematically review\nthese reports, and identify and correct potential inaccuracies to ensure\nhigh-quality, clinically reliable annotations. Unlike traditional datasets that\ncontain only descriptive texts, our dataset also features tags identifying\nhallucinated sentences and their corresponding corrections. A common approach\nto reducing hallucination in VLM is to finetune the model on a small-scale,\nproblem-specific dataset. However, we take a different strategy using our\ndataset. Instead of finetuning the VLM solely for generating textual reports,\nwe finetune it to detect and correct hallucinations, an approach we call\nhallucination-aware finetuning. Our results show that this approach is better\nthan simply finetuning for descriptive report generation. Additionally, we\nconduct an extensive evaluation of state-of-the-art VLMs across several\nmetrics, establishing a benchmark. GitHub Repo:\nhttps://github.com/bhattarailab/Hallucination-Aware-VLM.", "AI": {"tldr": "The paper introduces Gut-VLM, a dataset for studying hallucination in Vision-Language Models (VLMs) for gastrointestinal image analysis, and proposes hallucination-aware finetuning to improve accuracy.", "motivation": "Hallucination in VLMs, especially in medical applications, leads to unreliable outputs, necessitating better methods to detect and correct such errors.", "method": "A two-stage pipeline creates Gut-VLM: ChatGPT generates reports with potential hallucinations, which medical experts then review and correct. The VLM is finetuned to detect and correct hallucinations.", "result": "Hallucination-aware finetuning outperforms traditional finetuning for report generation, and benchmarks for VLMs are established.", "conclusion": "The approach improves VLM reliability in medical applications, with Gut-VLM serving as a valuable resource for future research."}}
{"id": "2505.06311", "pdf": "https://arxiv.org/pdf/2505.06311", "abs": "https://arxiv.org/abs/2505.06311", "authors": ["Tongyu Wen", "Chenglong Wang", "Xiyuan Yang", "Haoyu Tang", "Yueqi Xie", "Lingjuan Lyu", "Zhicheng Dou", "Fangzhao Wu"], "title": "Defending against Indirect Prompt Injection by Instruction Detection", "categories": ["cs.CR", "cs.AI"], "comment": "13 pages, 4 figures", "summary": "The integration of Large Language Models (LLMs) with external sources is\nbecoming increasingly common, with Retrieval-Augmented Generation (RAG) being a\nprominent example. However, this integration introduces vulnerabilities of\nIndirect Prompt Injection (IPI) attacks, where hidden instructions embedded in\nexternal data can manipulate LLMs into executing unintended or harmful actions.\nWe recognize that the success of IPI attacks fundamentally relies in the\npresence of instructions embedded within external content, which can alter the\nbehavioral state of LLMs. Can effectively detecting such state changes help us\ndefend against IPI attacks? In this paper, we propose a novel approach that\ntakes external data as input and leverages the behavioral state of LLMs during\nboth forward and backward propagation to detect potential IPI attacks.\nSpecifically, we demonstrate that the hidden states and gradients from\nintermediate layers provide highly discriminative features for instruction\ndetection. By effectively combining these features, our approach achieves a\ndetection accuracy of 99.60\\% in the in-domain setting and 96.90\\% in the\nout-of-domain setting, while reducing the attack success rate to just 0.12\\% on\nthe BIPIA benchmark.", "AI": {"tldr": "A novel approach detects Indirect Prompt Injection (IPI) attacks in LLMs by analyzing behavioral state changes during forward and backward propagation, achieving high accuracy and low attack success rates.", "motivation": "The integration of LLMs with external sources introduces vulnerabilities like IPI attacks, where hidden instructions manipulate LLMs. Detecting such state changes is crucial for defense.", "method": "The approach uses external data input and analyzes LLM behavioral states (hidden states and gradients) during forward and backward propagation to detect IPI attacks.", "result": "Achieves 99.60% in-domain and 96.90% out-of-domain detection accuracy, reducing attack success rate to 0.12% on BIPIA benchmark.", "conclusion": "The proposed method effectively detects and mitigates IPI attacks by leveraging LLM behavioral state changes, offering robust defense."}}
{"id": "2505.06688", "pdf": "https://arxiv.org/pdf/2505.06688", "abs": "https://arxiv.org/abs/2505.06688", "authors": ["Jianxin Zhang", "Lianzi Jiang", "Xinyu Han", "Xiangrong Wang"], "title": "A Novel Framework for Significant Wave Height Prediction based on Adaptive Feature Extraction Time-Frequency Network", "categories": ["cs.LG"], "comment": null, "summary": "Precise forecasting of significant wave height (Hs) is essential for the\ndevelopment and utilization of wave energy. The challenges in predicting Hs\narise from its non-linear and non-stationary characteristics. The combination\nof decomposition preprocessing and machine learning models have demonstrated\nsignificant effectiveness in Hs prediction by extracting data features.\nHowever, decomposing the unknown data in the test set can lead to data leakage\nissues. To simultaneously achieve data feature extraction and prevent data\nleakage, a novel Adaptive Feature Extraction Time-Frequency Network (AFE-TFNet)\nis proposed to improve prediction accuracy and stability. It is encoder-decoder\nrolling framework. The encoder consists of two stages: feature extraction and\nfeature fusion. In the feature extraction stage, global and local frequency\ndomain features are extracted by combining Wavelet Transform (WT) and Fourier\nTransform (FT), and multi-scale frequency analysis is performed using Inception\nblocks. In the feature fusion stage, time-domain and frequency-domain features\nare integrated through dominant harmonic sequence energy weighting (DHSEW). The\ndecoder employed an advanced long short-term memory (LSTM) model. Hourly\nmeasured wind speed (Ws), dominant wave period (DPD), average wave period (APD)\nand Hs from three stations are used as the dataset, and the four metrics are\nemployed to evaluate the forecasting performance. Results show that AFE-TFNet\nsignificantly outperforms benchmark methods in terms of prediction accuracy.\nFeature extraction can significantly improve the prediction accuracy. DHSEW has\nsubstantially increased the accuracy of medium-term to long-term forecasting.\nThe prediction accuracy of AFE-TFNet does not demonstrate significant\nvariability with changes of rolling time window size. Overall, AFE-TFNet shows\nstrong potential for handling complex signal forecasting.", "AI": {"tldr": "AFE-TFNet, a novel framework combining feature extraction and fusion, improves wave height prediction accuracy and avoids data leakage.", "motivation": "Accurate wave height (Hs) prediction is crucial for wave energy use, but Hs's non-linear, non-stationary nature makes it challenging. Existing methods risk data leakage.", "method": "AFE-TFNet uses an encoder-decoder framework: encoder extracts global/local frequency features (WT, FT, Inception blocks) and fuses time/frequency features (DHSEW); decoder uses LSTM.", "result": "AFE-TFNet outperforms benchmarks, improves accuracy, and handles medium/long-term forecasting better. Feature extraction and DHSEW boost performance.", "conclusion": "AFE-TFNet is effective for complex signal forecasting, with stable accuracy across rolling window sizes."}}
{"id": "2505.06843", "pdf": "https://arxiv.org/pdf/2505.06843", "abs": "https://arxiv.org/abs/2505.06843", "authors": ["Zihan Guan", "Mengxuan Hu", "Ronghang Zhu", "Sheng Li", "Anil Vullikanti"], "title": "Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety", "categories": ["cs.LG", "cs.CL"], "comment": "26 pages, 13 figures", "summary": "Recent studies have uncovered a troubling vulnerability in the fine-tuning\nstage of large language models (LLMs): even fine-tuning on entirely benign\ndatasets can lead to a significant increase in the harmfulness of LLM outputs.\nBuilding on this finding, our red teaming study takes this threat one step\nfurther by developing a more effective attack. Specifically, we analyze and\nidentify samples within benign datasets that contribute most to safety\ndegradation, then fine-tune LLMs exclusively on these samples. We approach this\nproblem from an outlier detection perspective and propose Self-Inf-N, to detect\nand extract outliers for fine-tuning. Our findings reveal that fine-tuning LLMs\non 100 outlier samples selected by Self-Inf-N in the benign datasets severely\ncompromises LLM safety alignment. Extensive experiments across seven mainstream\nLLMs demonstrate that our attack exhibits high transferability across different\narchitectures and remains effective in practical scenarios. Alarmingly, our\nresults indicate that most existing mitigation strategies fail to defend\nagainst this attack, underscoring the urgent need for more robust alignment\nsafeguards. Codes are available at\nhttps://github.com/GuanZihan/Benign-Samples-Matter.", "AI": {"tldr": "Fine-tuning LLMs on benign datasets can increase harmfulness. A new attack, Self-Inf-N, identifies harmful outliers in benign data, severely compromising safety alignment. Existing defenses often fail.", "motivation": "To expose vulnerabilities in LLM fine-tuning by showing how benign datasets can degrade safety, and to develop a more effective attack method.", "method": "Proposed Self-Inf-N for outlier detection in benign datasets, fine-tuned LLMs on these outliers, and tested across seven models.", "result": "Fine-tuning on 100 outliers significantly harms safety alignment; attack is highly transferable and bypasses most defenses.", "conclusion": "Urgent need for stronger safeguards against such attacks, as current mitigation strategies are insufficient."}}
{"id": "2505.07003", "pdf": "https://arxiv.org/pdf/2505.07003", "abs": "https://arxiv.org/abs/2505.07003", "authors": ["Peng Li", "Suizhi Ma", "Jialiang Chen", "Yuan Liu", "Chongyi Zhang", "Wei Xue", "Wenhan Luo", "Alla Sheffer", "Wenping Wang", "Yike Guo"], "title": "CMD: Controllable Multiview Diffusion for 3D Editing and Progressive Generation", "categories": ["cs.CV"], "comment": "Siggraph 2025", "summary": "Recently, 3D generation methods have shown their powerful ability to automate\n3D model creation. However, most 3D generation methods only rely on an input\nimage or a text prompt to generate a 3D model, which lacks the control of each\ncomponent of the generated 3D model. Any modifications of the input image lead\nto an entire regeneration of the 3D models. In this paper, we introduce a new\nmethod called CMD that generates a 3D model from an input image while enabling\nflexible local editing of each component of the 3D model. In CMD, we formulate\nthe 3D generation as a conditional multiview diffusion model, which takes the\nexisting or known parts as conditions and generates the edited or added\ncomponents. This conditional multiview diffusion model not only allows the\ngeneration of 3D models part by part but also enables local editing of 3D\nmodels according to the local revision of the input image without changing\nother 3D parts. Extensive experiments are conducted to demonstrate that CMD\ndecomposes a complex 3D generation task into multiple components, improving the\ngeneration quality. Meanwhile, CMD enables efficient and flexible local editing\nof a 3D model by just editing one rendered image.", "AI": {"tldr": "CMD introduces a method for 3D model generation with local editing capabilities, improving control and quality.", "motivation": "Current 3D generation methods lack component-level control, requiring full regeneration for any input changes.", "method": "CMD uses a conditional multiview diffusion model to generate and edit 3D models part by part.", "result": "CMD improves generation quality and enables efficient local editing via image edits.", "conclusion": "CMD offers a flexible and high-quality solution for 3D model generation and editing."}}
{"id": "2505.06312", "pdf": "https://arxiv.org/pdf/2505.06312", "abs": "https://arxiv.org/abs/2505.06312", "authors": ["Pavel Naumov", "Jia Tao"], "title": "Responsibility Gap in Collective Decision Making", "categories": ["cs.GT", "cs.AI"], "comment": "full version of an IJCAI-25 paper", "summary": "The responsibility gap is a set of outcomes of a collective decision-making\nmechanism in which no single agent is individually responsible. In general,\nwhen designing a decision-making process, it is desirable to minimise the gap.\n  The paper proposes a concept of an elected dictatorship. It shows that, in a\nperfect information setting, the gap is empty if and only if the mechanism is\nan elected dictatorship. It also proves that in an imperfect information\nsetting, the class of gap-free mechanisms is positioned strictly between two\nvariations of the class of elected dictatorships.", "AI": {"tldr": "The paper explores the responsibility gap in collective decision-making, showing it's minimized only in an elected dictatorship under perfect information, and identifies gap-free mechanisms in imperfect settings.", "motivation": "To address the responsibility gap in collective decision-making by identifying conditions where no single agent is responsible for outcomes.", "method": "Proposes the concept of an elected dictatorship, analyzing it under perfect and imperfect information settings.", "result": "In perfect information, the gap is empty only for elected dictatorships; in imperfect settings, gap-free mechanisms lie between variations of elected dictatorships.", "conclusion": "Elected dictatorships are key to minimizing the responsibility gap, with nuanced results for imperfect information."}}
{"id": "2505.06690", "pdf": "https://arxiv.org/pdf/2505.06690", "abs": "https://arxiv.org/abs/2505.06690", "authors": ["Jianxin Zhang", "Lianzi Jiang", "Xinyu Han", "Xiangrong Wang", "Weinan Huang"], "title": "E2E-FANet: A Highly Generalizable Framework for Waves prediction Behind Floating Breakwaters via Exogenous-to-Endogenous Variable Attention", "categories": ["cs.LG"], "comment": null, "summary": "Accurate prediction of waves behind floating breakwaters (FB) is crucial for\noptimizing coastal engineering structures, enhancing safety, and improving\ndesign efficiency. Existing methods demonstrate limitations in capturing\nnonlinear interactions between waves and structures, while exhibiting\ninsufficient capability in modeling the complex frequency-domain relationships\namong elevations of different wave gauges. To address these challenges, this\nstudy introduces the Exogenous-to-Endogenous Frequency-Aware Network\n(E2E-FANet), a novel end-to-end neural network designed to model relationships\nbetween waves and structures. The E2E-FANetarchitecture incorporates a\nDual-Basis Frequency Mapping (DBFM) module that leverages orthogonal cosine and\nsine bases to extract wave features from the frequency domain while preserving\ntemporal information. Additionally, we introduce the Exogenous-to-Endogenous\nCross-Attention (E2ECA) module, which employs cross attention to model the\ninteractions between endogenous and exogenous variables. We incorporate a\nTemporal-wise Attention (TA) mechanism that adaptively captures complex\ndependencies in endogenous variables. These integrated modules function\nsynergistically, enabling E2E-FANet to achieve both comprehensive feature\nperception in the time-frequency domain and precise modeling of wave-structure\ninteractions. To comprehensively evaluate the performance of E2E-FANet, we\nconstructed a multi-level validation framework comprising three distinct\ntesting scenarios: internal validation under identical wave conditions,\ngeneralization testing across different wave conditions, and adaptability\ntesting with varying relative water density (RW) conditions. These\ncomprehensive tests demonstrate that E2E-FANet provides accurate waves behind\nFB predictions while successfully generalizing diverse wave conditions.", "AI": {"tldr": "The paper introduces E2E-FANet, a neural network for predicting waves behind floating breakwaters, addressing limitations of existing methods in nonlinear interactions and frequency-domain modeling.", "motivation": "Accurate wave prediction is crucial for optimizing coastal engineering, enhancing safety, and improving design efficiency, but existing methods fail to capture nonlinear interactions and frequency-domain relationships effectively.", "method": "E2E-FANet uses a Dual-Basis Frequency Mapping module for time-frequency feature extraction, an Exogenous-to-Endogenous Cross-Attention module for interaction modeling, and a Temporal-wise Attention mechanism for dependency capture.", "result": "E2E-FANet achieves accurate wave predictions and generalizes well across diverse wave and relative water density conditions.", "conclusion": "E2E-FANet effectively addresses the limitations of existing methods, providing a robust solution for wave-structure interaction modeling in coastal engineering."}}
{"id": "2505.06938", "pdf": "https://arxiv.org/pdf/2505.06938", "abs": "https://arxiv.org/abs/2505.06938", "authors": ["Katarzyna Anna Kapitan"], "title": "A digital perspective on the role of a stemma in material-philological transmission studies", "categories": ["cs.DL", "cs.CL"], "comment": null, "summary": "Taking its point of departure in the recent developments in the field of\ndigital humanities and the increasing automatisation of scholarly workflows,\nthis study explores the implications of digital approaches to textual\ntraditions for the broader field of textual scholarship. It argues that the\nrelative simplicity of creating computergenerated stemmas allows us to view the\nstemma codicum as a research tool rather than the final product of our\nscholarly investigation. Using the Old Norse saga of Hr\\'omundur as a case\nstudy, this article demonstrates that stemmas can serve as a starting point for\nexploring textual traditions further. In doing so, they enable us to address\nresearch questions that otherwise remain unanswered. The article is accompanied\nby datasets used to generate stemmas for the Hr\\'omundar saga tradition as well\nas two custom Python scripts. The scripts are designed to convert XML-based\ntextual data, encoded according to the TEI Guidelines, into the input format\nused for the analysis in the PHYLIP package to generate unrooted trees of\nrelationships between texts.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.07007", "pdf": "https://arxiv.org/pdf/2505.07007", "abs": "https://arxiv.org/abs/2505.07007", "authors": ["Zhengye Zhang", "Sirui Zhao", "Shifeng Liu", "Shukang Yin", "Xinglong Mao", "Tong Xu", "Enhong Chen"], "title": "MELLM: Exploring LLM-Powered Micro-Expression Understanding Enhanced by Subtle Motion Perception", "categories": ["cs.CV"], "comment": null, "summary": "Micro-expressions (MEs) are crucial psychological responses with significant\npotential for affective computing. However, current automatic micro-expression\nrecognition (MER) research primarily focuses on discrete emotion\nclassification, neglecting a convincing analysis of the subtle dynamic\nmovements and inherent emotional cues. The rapid progress in multimodal large\nlanguage models (MLLMs), known for their strong multimodal comprehension and\nlanguage generation abilities, offers new possibilities. MLLMs have shown\nsuccess in various vision-language tasks, indicating their potential to\nunderstand MEs comprehensively, including both fine-grained motion patterns and\nunderlying emotional semantics. Nevertheless, challenges remain due to the\nsubtle intensity and short duration of MEs, as existing MLLMs are not designed\nto capture such delicate frame-level facial dynamics. In this paper, we propose\na novel Micro-Expression Large Language Model (MELLM), which incorporates a\nsubtle facial motion perception strategy with the strong inference capabilities\nof MLLMs, representing the first exploration of MLLMs in the domain of ME\nanalysis. Specifically, to explicitly guide the MLLM toward motion-sensitive\nregions, we construct an interpretable motion-enhanced color map by fusing\nonset-apex optical flow dynamics with the corresponding grayscale onset frame\nas the model input. Additionally, specialized fine-tuning strategies are\nincorporated to further enhance the model's visual perception of MEs.\nFurthermore, we construct an instruction-description dataset based on Facial\nAction Coding System (FACS) annotations and emotion labels to train our MELLM.\nComprehensive evaluations across multiple benchmark datasets demonstrate that\nour model exhibits superior robustness and generalization capabilities in ME\nunderstanding (MEU). Code is available at https://github.com/zyzhangUstc/MELLM.", "AI": {"tldr": "The paper introduces MELLM, a Micro-Expression Large Language Model, leveraging MLLMs for comprehensive micro-expression analysis by integrating motion perception and fine-tuning strategies.", "motivation": "Current MER research lacks analysis of subtle dynamic movements and emotional cues. MLLMs' multimodal capabilities offer new potential for ME understanding.", "method": "MELLM combines motion-enhanced color maps (optical flow dynamics + grayscale frames) and specialized fine-tuning. An instruction-description dataset based on FACS is used for training.", "result": "MELLM shows superior robustness and generalization in ME understanding across benchmark datasets.", "conclusion": "MELLM represents the first MLLM application in ME analysis, addressing challenges of subtle intensity and short duration in MEs."}}
{"id": "2505.06314", "pdf": "https://arxiv.org/pdf/2505.06314", "abs": "https://arxiv.org/abs/2505.06314", "authors": ["Ashok Goel", "Ploy Thajchayapong", "Vrinda Nandan", "Harshvardhan Sikka", "Spencer Rugaber"], "title": "A4L: An Architecture for AI-Augmented Learning", "categories": ["cs.CY", "cs.AI"], "comment": "14 pages, 7 figures", "summary": "AI promises personalized learning and scalable education. As AI agents\nincreasingly permeate education in support of teaching and learning, there is a\ncritical and urgent need for data architectures for collecting and analyzing\ndata on learning, and feeding the results back to teachers, learners, and the\nAI agents for personalization of learning at scale. At the National AI\nInstitute for Adult Learning and Online Education, we are developing an\nArchitecture for AI-Augmented Learning (A4L) for supporting adult learning\nthrough online education. We present the motivations, goals, requirements of\nthe A4L architecture. We describe preliminary applications of A4L and discuss\nhow it advances the goals of making learning more personalized and scalable.", "AI": {"tldr": "The paper introduces the Architecture for AI-Augmented Learning (A4L) to support personalized and scalable adult online education through AI-driven data collection and feedback.", "motivation": "AI's potential in education necessitates robust data architectures for personalized learning at scale, particularly in adult online education.", "method": "Development of the A4L architecture, detailing its goals, requirements, and preliminary applications.", "result": "Preliminary applications of A4L demonstrate progress toward personalized and scalable learning.", "conclusion": "A4L advances AI's role in education by enabling personalized, scalable learning through structured data feedback."}}
{"id": "2505.06699", "pdf": "https://arxiv.org/pdf/2505.06699", "abs": "https://arxiv.org/abs/2505.06699", "authors": ["Xiyuan Wei", "Ming Lin", "Fanjiang Ye", "Fengguang Song", "Liangliang Cao", "My T. That", "Tianbao Yang"], "title": "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws", "categories": ["cs.LG", "stat.ML"], "comment": "18 pages, 6 figures", "summary": "This paper formalizes an emerging learning paradigm that uses a trained model\nas a reference to guide and enhance the training of a target model through\nstrategic data selection or weighting, named $\\textbf{model steering}$. While\nad-hoc methods have been used in various contexts, including the training of\nlarge foundation models, its underlying principles remain insufficiently\nunderstood, leading to sub-optimal performance. In this work, we propose a\ntheory-driven framework for model steering called $\\textbf{DRRho risk\nminimization}$, which is rooted in Distributionally Robust Optimization (DRO).\nThrough a generalization analysis, we provide theoretical insights into why\nthis approach improves generalization and data efficiency compared to training\nwithout a reference model. To the best of our knowledge, this is the first time\nsuch theoretical insights are provided for the new learning paradigm, which\nsignificantly enhance our understanding and practice of model steering.\nBuilding on these insights and the connection between contrastive learning and\nDRO, we introduce a novel method for Contrastive Language-Image Pretraining\n(CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments\nvalidate the theoretical insights, reveal a superior scaling law compared to\nCLIP without a reference model, and demonstrate its strength over existing\nheuristic approaches.", "AI": {"tldr": "The paper introduces a theory-driven framework for model steering, called DRRho risk minimization, rooted in DRO, and applies it to CLIP, showing improved performance over heuristic methods.", "motivation": "To formalize and enhance the understanding of model steering, a learning paradigm where a trained model guides the training of another, addressing sub-optimal performance in ad-hoc methods.", "method": "Proposes DRRho risk minimization, a DRO-based framework, and applies it to CLIP with a reference model (DRRho-CLIP), supported by theoretical generalization analysis.", "result": "Theoretical insights confirm improved generalization and data efficiency. Experiments show superior scaling and performance over heuristic approaches.", "conclusion": "The work provides the first theoretical foundation for model steering, enhancing its practice and demonstrating effectiveness in CLIP."}}
{"id": "2505.06972", "pdf": "https://arxiv.org/pdf/2505.06972", "abs": "https://arxiv.org/abs/2505.06972", "authors": ["Yuichi Sasazawa", "Yasuhiro Sogawa"], "title": "Web Page Classification using LLMs for Crawling Support", "categories": ["cs.IR", "cs.CL"], "comment": "8 pages, 2 figures", "summary": "A web crawler is a system designed to collect web pages, and efficient\ncrawling of new pages requires appropriate algorithms. While website features\nsuch as XML sitemaps and the frequency of past page updates provide important\nclues for accessing new pages, their universal application across diverse\nconditions is challenging. In this study, we propose a method to efficiently\ncollect new pages by classifying web pages into two types, \"Index Pages\" and\n\"Content Pages,\" using a large language model (LLM), and leveraging the\nclassification results to select index pages as starting points for accessing\nnew pages. We construct a dataset with automatically annotated web page types\nand evaluate our approach from two perspectives: the page type classification\nperformance and coverage of new pages. Experimental results demonstrate that\nthe LLM-based method outperformed baseline methods in both evaluation metrics.", "AI": {"tldr": "A method using LLMs to classify web pages into 'Index Pages' and 'Content Pages' improves new page collection efficiency, outperforming baselines in classification and coverage.", "motivation": "Efficiently crawling new web pages is challenging due to diverse conditions; leveraging LLMs for page classification can optimize starting points for crawling.", "method": "Classify web pages into 'Index Pages' and 'Content Pages' using an LLM, then use index pages as starting points for crawling new pages.", "result": "The LLM-based method outperformed baseline methods in both page type classification and new page coverage.", "conclusion": "LLM-based classification enhances web crawling efficiency by improving the selection of starting points for new page collection."}}
{"id": "2505.07013", "pdf": "https://arxiv.org/pdf/2505.07013", "abs": "https://arxiv.org/abs/2505.07013", "authors": ["Jitesh Joshi", "Youngjun Cho"], "title": "Efficient and Robust Multidimensional Attention in Remote Physiological Sensing through Target Signal Constrained Factorization", "categories": ["cs.CV", "cs.AI"], "comment": "25 pages, 6 figures", "summary": "Remote physiological sensing using camera-based technologies offers\ntransformative potential for non-invasive vital sign monitoring across\nhealthcare and human-computer interaction domains. Although deep learning\napproaches have advanced the extraction of physiological signals from video\ndata, existing methods have not been sufficiently assessed for their robustness\nto domain shifts. These shifts in remote physiological sensing include\nvariations in ambient conditions, camera specifications, head movements, facial\nposes, and physiological states which often impact real-world performance\nsignificantly. Cross-dataset evaluation provides an objective measure to assess\ngeneralization capabilities across these domain shifts. We introduce Target\nSignal Constrained Factorization module (TSFM), a novel multidimensional\nattention mechanism that explicitly incorporates physiological signal\ncharacteristics as factorization constraints, allowing more precise feature\nextraction. Building on this innovation, we present MMRPhys, an efficient\ndual-branch 3D-CNN architecture designed for simultaneous multitask estimation\nof photoplethysmography (rPPG) and respiratory (rRSP) signals from multimodal\nRGB and thermal video inputs. Through comprehensive cross-dataset evaluation on\nfive benchmark datasets, we demonstrate that MMRPhys with TSFM significantly\noutperforms state-of-the-art methods in generalization across domain shifts for\nrPPG and rRSP estimation, while maintaining a minimal inference latency\nsuitable for real-time applications. Our approach establishes new benchmarks\nfor robust multitask and multimodal physiological sensing and offers a\ncomputationally efficient framework for practical deployment in unconstrained\nenvironments. The web browser-based application featuring on-device real-time\ninference of MMRPhys model is available at\nhttps://physiologicailab.github.io/mmrphys-live", "AI": {"tldr": "The paper introduces MMRPhys, a dual-branch 3D-CNN with TSFM, for robust multitask estimation of rPPG and rRSP signals from RGB and thermal videos, outperforming state-of-the-art methods in cross-dataset evaluations.", "motivation": "Existing deep learning methods for remote physiological sensing lack robustness to domain shifts (e.g., ambient conditions, camera specs, head movements), impacting real-world performance. Cross-dataset evaluation is needed to assess generalization.", "method": "Proposes TSFM, a multidimensional attention mechanism incorporating physiological signal constraints, and MMRPhys, a dual-branch 3D-CNN for multitask estimation of rPPG and rRSP signals from multimodal video inputs.", "result": "MMRPhys with TSFM outperforms state-of-the-art methods in generalization across domain shifts for rPPG and rRSP estimation, with minimal inference latency suitable for real-time applications.", "conclusion": "The approach sets new benchmarks for robust multitask and multimodal physiological sensing, offering a computationally efficient framework for practical deployment, including a web browser-based real-time application."}}
{"id": "2505.06315", "pdf": "https://arxiv.org/pdf/2505.06315", "abs": "https://arxiv.org/abs/2505.06315", "authors": ["Jose Sanchez Vicarte", "Marcin Spoczynski", "Mostafa Elsaid"], "title": "Threat Modeling for AI: The Case for an Asset-Centric Approach", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Recent advances in AI are transforming AI's ubiquitous presence in our world\nfrom that of standalone AI-applications into deeply integrated AI-agents. These\nchanges have been driven by agents' increasing capability to autonomously make\ndecisions and initiate actions, using existing applications; whether those\napplications are AI-based or not. This evolution enables unprecedented levels\nof AI integration, with agents now able to take actions on behalf of systems\nand users -- including, in some cases, the powerful ability for the AI to write\nand execute scripts as it deems necessary. With AI systems now able to\nautonomously execute code, interact with external systems, and operate without\nhuman oversight, traditional security approaches fall short.\n  This paper introduces an asset-centric methodology for threat modeling AI\nsystems that addresses the unique security challenges posed by integrated AI\nagents. Unlike existing top-down frameworks that analyze individual attacks\nwithin specific product contexts, our bottom-up approach enables defenders to\nsystematically identify how vulnerabilities -- both conventional and\nAI-specific -- impact critical AI assets across distributed infrastructures\nused to develop and deploy these agents. This methodology allows security teams\nto: (1) perform comprehensive analysis that communicates effectively across\ntechnical domains, (2) quantify security assumptions about third-party AI\ncomponents without requiring visibility into their implementation, and (3)\nholistically identify AI-based vulnerabilities relevant to their specific\nproduct context. This approach is particularly relevant for securing agentic\nsystems with complex autonomous capabilities. By focusing on assets rather than\nattacks, our approach scales with the rapidly evolving threat landscape while\naccommodating increasingly complex and distributed AI development pipelines.", "AI": {"tldr": "The paper proposes an asset-centric threat modeling methodology for AI systems to address security challenges posed by integrated AI agents, focusing on vulnerabilities across distributed infrastructures.", "motivation": "The increasing autonomy and integration of AI agents, including their ability to execute code and interact with systems without human oversight, create unique security challenges that traditional methods fail to address.", "method": "A bottom-up, asset-centric approach is introduced to systematically identify vulnerabilities (both conventional and AI-specific) impacting critical AI assets in distributed infrastructures.", "result": "The methodology enables comprehensive analysis, quantification of security assumptions about third-party AI components, and holistic identification of AI-based vulnerabilities in specific contexts.", "conclusion": "This asset-centric approach scales with evolving threats and complex AI development pipelines, making it particularly suitable for securing autonomous AI systems."}}
{"id": "2505.06709", "pdf": "https://arxiv.org/pdf/2505.06709", "abs": "https://arxiv.org/abs/2505.06709", "authors": ["Abhishek Sinha", "Rahul Vaze"], "title": "Beyond $\\tilde{O}(\\sqrt{T})$ Constraint Violation for Online Convex Optimization with Adversarial Constraints", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "We revisit the Online Convex Optimization problem with adversarial\nconstraints (COCO) where, in each round, a learner is presented with a convex\ncost function and a convex constraint function, both of which may be chosen\nadversarially. The learner selects actions from a convex decision set in an\nonline fashion, with the goal of minimizing both regret and the cumulative\nconstraint violation (CCV) over a horizon of $T$ rounds. The best-known policy\nfor this problem achieves $O(\\sqrt{T})$ regret and $\\tilde{O}(\\sqrt{T})$ CCV.\nIn this paper, we present a surprising improvement that achieves a\nsignificantly smaller CCV by trading it off with regret. Specifically, for any\nbounded convex cost and constraint functions, we propose an online policy that\nachieves $\\tilde{O}(\\sqrt{dT}+ T^\\beta)$ regret and $\\tilde{O}(dT^{1-\\beta})$\nCCV, where $d$ is the dimension of the decision set and $\\beta \\in [0,1]$ is a\ntunable parameter. We achieve this result by first considering the special case\nof $\\textsf{Constrained Expert}$ problem where the decision set is a\nprobability simplex and the cost and constraint functions are linear.\nLeveraging a new adaptive small-loss regret bound, we propose an efficient\npolicy for the $\\textsf{Constrained Expert}$ problem, that attains\n$O(\\sqrt{T\\ln N}+T^{\\beta})$ regret and $\\tilde{O}(T^{1-\\beta} \\ln N)$ CCV,\nwhere $N$ is the number of experts. The original problem is then reduced to the\n$\\textsf{Constrained Expert}$ problem via a covering argument. Finally, with an\nadditional smoothness assumption, we propose an efficient gradient-based policy\nattaining $O(T^{\\max(\\frac{1}{2},\\beta)})$ regret and $\\tilde{O}(T^{1-\\beta})$\nCCV.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.06993", "pdf": "https://arxiv.org/pdf/2505.06993", "abs": "https://arxiv.org/abs/2505.06993", "authors": ["Yuxuan He", "Junpeng Zhang", "Hongyuan Zhang", "Quanshi Zhang"], "title": "Towards the Three-Phase Dynamics of Generalization Power of a DNN", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "This paper proposes a new perspective for analyzing the generalization power\nof deep neural networks (DNNs), i.e., directly disentangling and analyzing the\ndynamics of generalizable and non-generalizable interaction encoded by a DNN\nthrough the training process. Specifically, this work builds upon the recent\ntheoretical achievement in explainble AI, which proves that the detailed\ninference logic of DNNs can be can be strictly rewritten as a small number of\nAND-OR interaction patterns. Based on this, we propose an efficient method to\nquantify the generalization power of each interaction, and we discover a\ndistinct three-phase dynamics of the generalization power of interactions\nduring training. In particular, the early phase of training typically removes\nnoisy and non-generalizable interactions and learns simple and generalizable\nones. The second and the third phases tend to capture increasingly complex\ninteractions that are harder to generalize. Experimental results verify that\nthe learning of non-generalizable interactions is the the direct cause for the\ngap between the training and testing losses.", "AI": {"tldr": "The paper introduces a method to analyze DNN generalization by disentangling generalizable and non-generalizable interactions during training, revealing a three-phase dynamics.", "motivation": "To understand and quantify the generalization power of DNNs by analyzing their interaction patterns.", "method": "Proposes an efficient method to quantify generalization power of interactions, building on explainable AI theory.", "result": "Discovers a three-phase training dynamics: early phase removes noise, later phases capture complex but less generalizable interactions.", "conclusion": "Non-generalizable interactions cause the gap between training and testing losses, verified experimentally."}}
{"id": "2505.07019", "pdf": "https://arxiv.org/pdf/2505.07019", "abs": "https://arxiv.org/abs/2505.07019", "authors": ["Khang Nguyen Quoc", "Lan Le Thi Thu", "Luyl-Da Quach"], "title": "A Vision-Language Foundation Model for Leaf Disease Identification", "categories": ["cs.CV"], "comment": null, "summary": "Leaf disease identification plays a pivotal role in smart agriculture.\nHowever, many existing studies still struggle to integrate image and textual\nmodalities to compensate for each other's limitations. Furthermore, many of\nthese approaches rely on pretraining with constrained datasets such as\nImageNet, which lack domain-specific information. We propose SCOLD (Soft-target\nCOntrastive learning for Leaf Disease identification), a context-aware\nvision-language foundation model tailored to address these challenges for\nagricultural tasks. SCOLD is developed using a diverse corpus of plant leaf\nimages and corresponding symptom descriptions, comprising over 186,000\nimage-caption pairs aligned with 97 unique concepts. Through task-agnostic\npretraining, SCOLD leverages contextual soft targets to mitigate overconfidence\nin contrastive learning by smoothing labels, thereby improving model\ngeneralization and robustness on fine-grained classification tasks.\nExperimental results demonstrate that SCOLD outperforms existing\nvision-language models such as OpenAI-CLIP-L, BioCLIP, and SigLIP2 across\nseveral benchmarks, including zero-shot and few-shot classification, image-text\nretrieval, and image classification, while maintaining a competitive parameter\nfootprint. Ablation studies further highlight SCOLD's effectiveness in contrast\nto its counterparts. The proposed approach significantly advances the\nagricultural vision-language foundation model, offering strong performance with\nminimal or no supervised fine-tuning. This work lays a solid groundwork for\nfuture research on models trained with long-form and simplified contexts, tasks\ninvolving class ambiguity, and multi-modal systems for intelligent plant\ndisease diagnostics. The code for this study is available at\nhttps://huggingface.co/enalis/scold", "AI": {"tldr": "SCOLD is a vision-language model for leaf disease identification, using contrastive learning with soft targets to improve generalization and robustness, outperforming existing models.", "motivation": "Existing methods struggle with integrating image and text modalities and rely on limited datasets like ImageNet, lacking domain-specific data.", "method": "SCOLD uses task-agnostic pretraining with contextual soft targets to smooth labels, trained on 186,000 image-caption pairs aligned with 97 concepts.", "result": "SCOLD outperforms models like OpenAI-CLIP-L, BioCLIP, and SigLIP2 in benchmarks including zero-shot and few-shot classification.", "conclusion": "SCOLD advances agricultural vision-language models, offering strong performance with minimal fine-tuning, and sets groundwork for future research."}}
{"id": "2505.06324", "pdf": "https://arxiv.org/pdf/2505.06324", "abs": "https://arxiv.org/abs/2505.06324", "authors": ["Vipula Rawte", "Ryan A. Rossi", "Franck Dernoncourt", "Nedim Lipka"], "title": "Document Attribution: Examining Citation Relationships using Large Language Models", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly applied to document-based\ntasks - such as document summarization, question answering, and information\nextraction - where user requirements focus on retrieving information from\nprovided documents rather than relying on the model's parametric knowledge,\nensuring the trustworthiness and interpretability of these systems has become a\ncritical concern. A central approach to addressing this challenge is\nattribution, which involves tracing the generated outputs back to their source\ndocuments. However, since LLMs can produce inaccurate or imprecise responses,\nit is crucial to assess the reliability of these citations.\n  To tackle this, our work proposes two techniques. (1) A zero-shot approach\nthat frames attribution as a straightforward textual entailment task. Our\nmethod using flan-ul2 demonstrates an improvement of 0.27% and 2.4% over the\nbest baseline of ID and OOD sets of AttributionBench, respectively. (2) We also\nexplore the role of the attention mechanism in enhancing the attribution\nprocess. Using a smaller LLM, flan-t5-small, the F1 scores outperform the\nbaseline across almost all layers except layer 4 and layers 8 through 11.", "AI": {"tldr": "The paper addresses the challenge of ensuring trustworthy and interpretable LLM outputs by proposing two attribution techniques: a zero-shot textual entailment method and an attention mechanism-based approach, both showing improvements over baselines.", "motivation": "To enhance the reliability and interpretability of LLMs in document-based tasks by tracing outputs back to source documents, especially given the potential for inaccuracies.", "method": "Proposes two techniques: (1) a zero-shot textual entailment approach using flan-ul2, and (2) leveraging attention mechanisms with flan-t5-small.", "result": "The zero-shot method improves performance by 0.27% and 2.4% on ID and OOD sets, respectively. The attention-based approach outperforms baselines in most layers.", "conclusion": "The proposed techniques effectively enhance attribution reliability, contributing to more trustworthy LLM applications in document tasks."}}
{"id": "2505.06730", "pdf": "https://arxiv.org/pdf/2505.06730", "abs": "https://arxiv.org/abs/2505.06730", "authors": ["Debashish Saha", "Piyush Malik", "Adrika Saha"], "title": "Activity and Subject Detection for UCI HAR Dataset with & without missing Sensor Data", "categories": ["cs.LG"], "comment": null, "summary": "Current studies in Human Activity Recognition (HAR) primarily focus on the\nclassification of activities through sensor data, while there is not much\nemphasis placed on recognizing the individuals performing these activities.\nThis type of classification is very important for developing personalized and\ncontext-sensitive applications. Additionally, the issue of missing sensor data,\nwhich often occurs in practical situations due to hardware malfunctions, has\nnot been explored yet. This paper seeks to fill these voids by introducing a\nlightweight LSTM-based model that can be used to classify both activities and\nsubjects. The proposed model was used to classify the HAR dataset by UCI [1],\nachieving an accuracy of 93.89% in activity recognition (across six\nactivities), nearing the 96.67% benchmark, and an accuracy of 80.19% in subject\nrecognition (involving 30 subjects), thereby establishing a new baseline for\nthis area of research. We then simulate the absence of sensor data to mirror\nreal-world scenarios and incorporate imputation techniques, both with and\nwithout Principal Component Analysis (PCA), to restore incomplete datasets. We\nfound that K-Nearest Neighbors (KNN) imputation performs the best for filling\nthe missing sensor data without PCA because the use of PCA resulted in slightly\nlower accuracy. These results demonstrate how well the framework handles\nmissing sensor data, which is a major step forward in using the Human Activity\nRecognition dataset for reliable classification tasks.", "AI": {"tldr": "A lightweight LSTM model is proposed for HAR, addressing activity and subject classification, and handling missing sensor data with KNN imputation.", "motivation": "To fill gaps in HAR by recognizing individuals and addressing missing sensor data for personalized applications.", "method": "Uses an LSTM model for activity and subject classification, tests KNN imputation with/without PCA for missing data.", "result": "Achieved 93.89% activity and 80.19% subject recognition accuracy; KNN imputation without PCA performed best.", "conclusion": "The framework advances HAR by reliably handling missing data and setting new benchmarks for classification."}}
{"id": "2505.07155", "pdf": "https://arxiv.org/pdf/2505.07155", "abs": "https://arxiv.org/abs/2505.07155", "authors": ["Shuai Wang", "Harrisen Scells", "Bevan Koopman", "Guido Zuccon"], "title": "Reassessing Large Language Model Boolean Query Generation for Systematic Reviews", "categories": ["cs.IR", "cs.CL"], "comment": "Accepted in SIGIR-2025", "summary": "Systematic reviews are comprehensive literature reviews that address highly\nfocused research questions and represent the highest form of evidence in\nmedicine. A critical step in this process is the development of complex Boolean\nqueries to retrieve relevant literature. Given the difficulty of manually\nconstructing these queries, recent efforts have explored Large Language Models\n(LLMs) to assist in their formulation. One of the first studies,Wang et al.,\ninvestigated ChatGPT for this task, followed by Staudinger et al., which\nevaluated multiple LLMs in a reproducibility study. However, the latter\noverlooked several key aspects of the original work, including (i) validation\nof generated queries, (ii) output formatting constraints, and (iii) selection\nof examples for chain-of-thought (Guided) prompting. As a result, its findings\ndiverged significantly from the original study. In this work, we systematically\nreproduce both studies while addressing these overlooked factors. Our results\nshow that query effectiveness varies significantly across models and prompt\ndesigns, with guided query formulation benefiting from well-chosen seed\nstudies. Overall, prompt design and model selection are key drivers of\nsuccessful query formulation. Our findings provide a clearer understanding of\nLLMs' potential in Boolean query generation and highlight the importance of\nmodel- and prompt-specific optimisations. The complex nature of systematic\nreviews adds to challenges in both developing and reproducing methods but also\nhighlights the importance of reproducibility studies in this domain.", "AI": {"tldr": "The paper examines the use of LLMs for Boolean query generation in systematic reviews, comparing studies by Wang et al. and Staudinger et al., and highlights the impact of prompt design and model selection on query effectiveness.", "motivation": "To address gaps in reproducibility and overlooked factors in prior studies on LLM-assisted Boolean query formulation for systematic reviews.", "method": "Systematic reproduction of two studies (Wang et al. and Staudinger et al.) while validating queries, enforcing output formatting, and optimizing prompt examples.", "result": "Query effectiveness varies by model and prompt design, with guided prompting benefiting from well-chosen seed studies.", "conclusion": "Prompt design and model selection are crucial for successful Boolean query generation, emphasizing the need for reproducibility studies in this domain."}}
{"id": "2505.07032", "pdf": "https://arxiv.org/pdf/2505.07032", "abs": "https://arxiv.org/abs/2505.07032", "authors": ["Fei Zhao", "Runlin Zhang", "Chengcui Zhang", "Nitesh Saxena"], "title": "MarkMatch: Same-Hand Stuffing Detection", "categories": ["cs.CV"], "comment": null, "summary": "We present MarkMatch, a retrieval system for detecting whether two paper\nballot marks were filled by the same hand. Unlike the previous SOTA method\nBubbleSig, which used binary classification on isolated mark pairs, MarkMatch\nranks stylistic similarity between a query mark and a mark in the database\nusing contrastive learning. Our model is trained with a dense batch similarity\nmatrix and a dual loss objective. Each sample is contrasted against many\nnegatives within each batch, enabling the model to learn subtle handwriting\ndifference and improve generalization under handwriting variation and visual\nnoise, while diagonal supervision reinforces high confidence on true matches.\nThe model achieves an F1 score of 0.943, surpassing BubbleSig's best\nperformance. MarkMatch also integrates Segment Anything Model for flexible mark\nextraction via box- or point-based prompts. The system offers election auditors\na practical tool for visual, non-biometric investigation of suspicious ballots.", "AI": {"tldr": "MarkMatch is a retrieval system for detecting if two paper ballot marks were made by the same hand, outperforming BubbleSig with an F1 score of 0.943 using contrastive learning and flexible mark extraction via SAM.", "motivation": "To improve the detection of stylistic similarity in ballot marks for election audits, addressing limitations of the previous SOTA method, BubbleSig.", "method": "Uses contrastive learning with a dense batch similarity matrix and dual loss objective, integrating Segment Anything Model (SAM) for mark extraction.", "result": "Achieves an F1 score of 0.943, surpassing BubbleSig's performance.", "conclusion": "MarkMatch provides a practical, non-biometric tool for election auditors to investigate suspicious ballots."}}
{"id": "2505.06326", "pdf": "https://arxiv.org/pdf/2505.06326", "abs": "https://arxiv.org/abs/2505.06326", "authors": ["Alexander Ettinger"], "title": "Enterprise Architecture as a Dynamic Capability for Scalable and Sustainable Generative AI adoption: Bridging Innovation and Governance in Large Organisations", "categories": ["cs.CY", "cs.AI"], "comment": "82 pages excluding appendix", "summary": "Generative Artificial Intelligence is a powerful new technology with the\npotential to boost innovation and reshape governance in many industries.\nNevertheless, organisations face major challenges in scaling GenAI, including\ntechnology complexity, governance gaps and resource misalignments. This study\nexplores how Enterprise Architecture Management can meet the complex\nrequirements of GenAI adoption within large enterprises. Based on a systematic\nliterature review and the qualitative analysis of 16 semi-structured interviews\nwith experts, it examines the relationships between EAM, dynamic capabilities\nand GenAI adoption. The review identified key limitations in existing EA\nframeworks, particularly their inability to fully address the unique\nrequirements of GenAI. The interviews, analysed using the Gioia methodology,\nrevealed critical enablers and barriers to GenAI adoption across industries.\nThe findings indicate that EAM, when theorised as sensing, seizing and\ntransforming dynamic capabilities, can enhance GenAI adoption by improving\nstrategic alignment, governance frameworks and organisational agility. However,\nthe study also highlights the need to tailor EA frameworks to GenAI-specific\nchallenges, including low data governance maturity and the balance between\ninnovation and compliance. Several conceptual frameworks are proposed to guide\nEA leaders in aligning GenAI maturity with organisational readiness. The work\ncontributes to academic understanding and industry practice by clarifying the\nrole of EA in bridging innovation and governance in disruptive technology\nenvironments.", "AI": {"tldr": "The paper explores how Enterprise Architecture Management (EAM) can address challenges in scaling Generative AI (GenAI) in large enterprises, highlighting gaps in existing frameworks and proposing tailored solutions.", "motivation": "To understand how EAM can support GenAI adoption by addressing technology complexity, governance gaps, and resource misalignments.", "method": "Combines a systematic literature review with qualitative analysis of 16 expert interviews using the Gioia methodology.", "result": "Identifies limitations in EA frameworks for GenAI, reveals enablers/barriers, and shows EAM's role in enhancing adoption through dynamic capabilities.", "conclusion": "EAM can bridge innovation and governance for GenAI but requires tailored frameworks to address specific challenges like data governance and compliance."}}
{"id": "2505.06731", "pdf": "https://arxiv.org/pdf/2505.06731", "abs": "https://arxiv.org/abs/2505.06731", "authors": ["David Zucker"], "title": "Deeply Explainable Artificial Neural Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While deep learning models have demonstrated remarkable success in numerous\ndomains, their black-box nature remains a significant limitation, especially in\ncritical fields such as medical image analysis and inference. Existing\nexplainability methods, such as SHAP, LIME, and Grad-CAM, are typically applied\npost hoc, adding computational overhead and sometimes producing inconsistent or\nambiguous results. In this paper, we present the Deeply Explainable Artificial\nNeural Network (DxANN), a novel deep learning architecture that embeds\nexplainability ante hoc, directly into the training process. Unlike\nconventional models that require external interpretation methods, DxANN is\ndesigned to produce per-sample, per-feature explanations as part of the forward\npass. Built on a flow-based framework, it enables both accurate predictions and\ntransparent decision-making, and is particularly well-suited for image-based\ntasks. While our focus is on medical imaging, the DxANN architecture is readily\nadaptable to other data modalities, including tabular and sequential data.\nDxANN marks a step forward toward intrinsically interpretable deep learning,\noffering a practical solution for applications where trust and accountability\nare essential.", "AI": {"tldr": "DxANN is a new deep learning architecture that embeds explainability directly into training, offering transparent decision-making without post hoc methods.", "motivation": "The black-box nature of deep learning models limits their use in critical fields like medical imaging, where trust and accountability are essential.", "method": "DxANN integrates explainability ante hoc using a flow-based framework, producing per-sample, per-feature explanations during the forward pass.", "result": "DxANN enables accurate predictions and transparent decision-making, especially for image-based tasks, and is adaptable to other data types.", "conclusion": "DxANN advances intrinsically interpretable deep learning, providing a practical solution for trust-critical applications."}}
{"id": "2505.07166", "pdf": "https://arxiv.org/pdf/2505.07166", "abs": "https://arxiv.org/abs/2505.07166", "authors": ["Zheng Yao", "Shuai Wang", "Guido Zuccon"], "title": "Pre-training vs. Fine-tuning: A Reproducibility Study on Dense Retrieval Knowledge Acquisition", "categories": ["cs.IR", "cs.CL"], "comment": "Accepted in SIGIR-2025", "summary": "Dense retrievers utilize pre-trained backbone language models (e.g., BERT,\nLLaMA) that are fine-tuned via contrastive learning to perform the task of\nencoding text into sense representations that can be then compared via a\nshallow similarity operation, e.g. inner product. Recent research has\nquestioned the role of fine-tuning vs. that of pre-training within dense\nretrievers, specifically arguing that retrieval knowledge is primarily gained\nduring pre-training, meaning knowledge not acquired during pre-training cannot\nbe sub-sequentially acquired via fine-tuning. We revisit this idea here as the\nclaim was only studied in the context of a BERT-based encoder using DPR as\nrepresentative dense retriever. We extend the previous analysis by testing\nother representation approaches (comparing the use of CLS tokens with that of\nmean pooling), backbone architectures (encoder-only BERT vs. decoder-only\nLLaMA), and additional datasets (MSMARCO in addition to Natural Questions). Our\nstudy confirms that in DPR tuning, pre-trained knowledge underpins retrieval\nperformance, with fine-tuning primarily adjusting neuron activation rather than\nreorganizing knowledge. However, this pattern does not hold universally, such\nas in mean-pooled (Contriever) and decoder-based (LLaMA) models. We ensure full\nreproducibility and make our implementation publicly available at\nhttps://github.com/ielab/DenseRetriever-Knowledge-Acquisition.", "AI": {"tldr": "The paper revisits the role of pre-training vs. fine-tuning in dense retrievers, extending prior work to include different architectures and datasets, confirming pre-training's dominance but noting exceptions.", "motivation": "To clarify whether retrieval knowledge is primarily gained during pre-training or fine-tuning, extending previous limited studies.", "method": "Tests various representation approaches (CLS tokens vs. mean pooling), architectures (BERT vs. LLaMA), and datasets (MSMARCO, Natural Questions).", "result": "Pre-training underpins retrieval performance in DPR tuning, but exceptions exist (e.g., mean-pooled and decoder-based models).", "conclusion": "Pre-training is key for dense retrievers, but fine-tuning's role varies by model type, with findings reproducible via public code."}}
{"id": "2505.07040", "pdf": "https://arxiv.org/pdf/2505.07040", "abs": "https://arxiv.org/abs/2505.07040", "authors": ["Zhengyang Lu", "Bingjie Lu", "Weifan Wang", "Feng Wang"], "title": "Differentiable NMS via Sinkhorn Matching for End-to-End Fabric Defect Detection", "categories": ["cs.CV"], "comment": null, "summary": "Fabric defect detection confronts two fundamental challenges. First,\nconventional non-maximum suppression disrupts gradient flow, which hinders\ngenuine end-to-end learning. Second, acquiring pixel-level annotations at\nindustrial scale is prohibitively costly. Addressing these limitations, we\npropose a differentiable NMS framework for fabric defect detection that\nachieves superior localization precision through end-to-end optimization. We\nreformulate NMS as a differentiable bipartite matching problem solved through\nthe Sinkhorn-Knopp algorithm, maintaining uninterrupted gradient flow\nthroughout the network. This approach specifically targets the irregular\nmorphologies and ambiguous boundaries of fabric defects by integrating proposal\nquality, feature similarity, and spatial relationships. Our entropy-constrained\nmask refinement mechanism further enhances localization precision through\nprincipled uncertainty modeling. Extensive experiments on the Tianchi fabric\ndefect dataset demonstrate significant performance improvements over existing\nmethods while maintaining real-time speeds suitable for industrial deployment.\nThe framework exhibits remarkable adaptability across different architectures\nand generalizes effectively to general object detection tasks.", "AI": {"tldr": "A differentiable NMS framework for fabric defect detection improves localization precision via end-to-end optimization, addressing gradient flow disruption and costly annotations.", "motivation": "Challenges include disrupted gradient flow from conventional NMS and high costs of pixel-level annotations at scale.", "method": "Reformulates NMS as a differentiable bipartite matching problem using the Sinkhorn-Knopp algorithm, integrating proposal quality, feature similarity, and spatial relationships. Includes an entropy-constrained mask refinement mechanism.", "result": "Significant performance improvements on the Tianchi fabric defect dataset, maintaining real-time speeds and adaptability across architectures.", "conclusion": "The framework enhances localization precision and generalizes well to general object detection tasks, suitable for industrial deployment."}}
{"id": "2505.06347", "pdf": "https://arxiv.org/pdf/2505.06347", "abs": "https://arxiv.org/abs/2505.06347", "authors": ["Qing-Hong Cao", "Zong-Yue Hou", "Ying-Ying Li", "Xiaohui Liu", "Zhuo-Yang Song", "Liang-Qi Zhang", "Shutao Zhang", "Ke Zhao"], "title": "Quantum State Preparation via Large-Language-Model-Driven Evolution", "categories": ["quant-ph", "cs.AI", "hep-lat", "hep-ph"], "comment": "6 + 4 pages, 14 figures", "summary": "We propose an automated framework for quantum circuit design by integrating\nlarge-language models (LLMs) with evolutionary optimization to overcome the\nrigidity, scalability limitations, and expert dependence of traditional ones in\nvariational quantum algorithms. Our approach (FunSearch) autonomously discovers\nhardware-efficient ans\\\"atze with new features of scalability and\nsystem-size-independent number of variational parameters entirely from scratch.\nDemonstrations on the Ising and XY spin chains with n = 9 qubits yield circuits\ncontaining 4 parameters, achieving near-exact energy extrapolation across\nsystem sizes. Implementations on quantum hardware (Zuchongzhi chip) validate\npracticality, where two-qubit quantum gate noises can be effectively mitigated\nvia zero-noise extrapolations for a spin chain system as large as 20 sites.\nThis framework bridges algorithmic design and experimental constraints,\ncomplementing contemporary quantum architecture search frameworks to advance\nscalable quantum simulations.", "AI": {"tldr": "An automated framework (FunSearch) combines LLMs and evolutionary optimization to design scalable, hardware-efficient quantum circuits, validated on quantum hardware.", "motivation": "Overcome rigidity, scalability limits, and expert dependence in traditional variational quantum algorithms.", "method": "Integrates large-language models (LLMs) with evolutionary optimization to autonomously design ans\u00e4tze.", "result": "Achieves near-exact energy extrapolation with 4 parameters for 9-qubit systems and mitigates noise in 20-site spin chains.", "conclusion": "Bridges algorithmic design and experimental constraints, advancing scalable quantum simulations."}}
{"id": "2505.06744", "pdf": "https://arxiv.org/pdf/2505.06744", "abs": "https://arxiv.org/abs/2505.06744", "authors": ["Kai M\u00fcller", "Martin Wenzel", "Tobias Windisch"], "title": "LineFlow: A Framework to Learn Active Control of Production Lines", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at ICML 2025", "summary": "Many production lines require active control mechanisms, such as adaptive\nrouting, worker reallocation, and rescheduling, to maintain optimal\nperformance. However, designing these control systems is challenging for\nvarious reasons, and while reinforcement learning (RL) has shown promise in\naddressing these challenges, a standardized and general framework is still\nlacking. In this work, we introduce LineFlow, an extensible, open-source Python\nframework for simulating production lines of arbitrary complexity and training\nRL agents to control them. To demonstrate the capabilities and to validate the\nunderlying theoretical assumptions of LineFlow, we formulate core subproblems\nof active line control in ways that facilitate mathematical analysis. For each\nproblem, we provide optimal solutions for comparison. We benchmark\nstate-of-the-art RL algorithms and show that the learned policies approach\noptimal performance in well-understood scenarios. However, for more complex,\nindustrial-scale production lines, RL still faces significant challenges,\nhighlighting the need for further research in areas such as reward shaping,\ncurriculum learning, and hierarchical control.", "AI": {"tldr": "LineFlow is an open-source Python framework for simulating production lines and training RL agents, showing promise but facing challenges in complex scenarios.", "motivation": "Designing control systems for production lines is challenging, and while RL shows potential, a standardized framework is lacking.", "method": "Introduces LineFlow, an extensible framework for simulating production lines and training RL agents, with optimal solutions provided for core subproblems.", "result": "RL policies approach optimal performance in simple scenarios but struggle with industrial-scale complexity, indicating areas for further research.", "conclusion": "LineFlow demonstrates RL's potential for production line control but highlights challenges in complex settings, calling for more research."}}
{"id": "2505.07167", "pdf": "https://arxiv.org/pdf/2505.07167", "abs": "https://arxiv.org/abs/2505.07167", "authors": ["Haoran Gu", "Handing Wang", "Yi Mei", "Mengjie Zhang", "Yaochu Jin"], "title": "One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have been extensively used across diverse\ndomains, including virtual assistants, automated code generation, and\nscientific research. However, they remain vulnerable to jailbreak attacks,\nwhich manipulate the models into generating harmful responses despite safety\nalignment. Recent studies have shown that current safety-aligned LLMs often\nundergo the shallow safety alignment, where the first few tokens largely\ndetermine whether the response will be harmful. Through comprehensive\nobservations, we find that safety-aligned LLMs and various defense strategies\ngenerate highly similar initial tokens in their refusal responses, which we\ndefine as safety trigger tokens. Building on this insight, we propose\n\\texttt{D-STT}, a simple yet effective defense algorithm that identifies and\nexplicitly decodes safety trigger tokens of the given safety-aligned LLM to\ntrigger the model's learned safety patterns. In this process, the safety\ntrigger is constrained to a single token, which effectively preserves model\nusability by introducing minimum intervention in the decoding process.\nExtensive experiments across diverse jailbreak attacks and benign prompts\ndemonstrate that \\ours significantly reduces output harmfulness while\npreserving model usability and incurring negligible response time overhead,\noutperforming ten baseline methods.", "AI": {"tldr": "The paper introduces D-STT, a defense algorithm to counter jailbreak attacks on LLMs by identifying and decoding safety trigger tokens, reducing harmfulness while maintaining usability.", "motivation": "LLMs are vulnerable to jailbreak attacks despite safety alignment, with shallow alignment making them prone to harmful responses.", "method": "Proposes D-STT, which decodes safety trigger tokens to activate the model's safety patterns, limiting intervention to a single token.", "result": "D-STT significantly reduces harmfulness, outperforms ten baselines, and preserves usability with minimal overhead.", "conclusion": "D-STT is an effective, simple defense against jailbreak attacks, balancing safety and usability."}}
{"id": "2505.07050", "pdf": "https://arxiv.org/pdf/2505.07050", "abs": "https://arxiv.org/abs/2505.07050", "authors": ["Binbin Wei", "Yuhang Zhang", "Shishun Tian", "Muxin Liao", "Wei Li", "Wenbin Zou"], "title": "Depth-Sensitive Soft Suppression with RGB-D Inter-Modal Stylization Flow for Domain Generalization Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Unsupervised Domain Adaptation (UDA) aims to align source and target domain\ndistributions to close the domain gap, but still struggles with obtaining the\ntarget data. Fortunately, Domain Generalization (DG) excels without the need\nfor any target data. Recent works expose that depth maps contribute to improved\ngeneralized performance in the UDA tasks, but they ignore the noise and holes\nin depth maps due to device and environmental factors, failing to sufficiently\nand effectively learn domain-invariant representation. Although\nhigh-sensitivity region suppression has shown promising results in learning\ndomain-invariant features, existing methods cannot be directly applicable to\ndepth maps due to their unique characteristics. Hence, we propose a novel\nframework, namely Depth-Sensitive Soft Suppression with RGB-D inter-modal\nstylization flow (DSSS), focusing on learning domain-invariant features from\ndepth maps for the DG semantic segmentation. Specifically, we propose the RGB-D\ninter-modal stylization flow to generate stylized depth maps for sensitivity\ndetection, cleverly utilizing RGB information as the stylization source. Then,\na class-wise soft spatial sensitivity suppression is designed to identify and\nemphasize non-sensitive depth features that contain more domain-invariant\ninformation. Furthermore, an RGB-D soft alignment loss is proposed to ensure\nthat the stylized depth maps only align part of the RGB features while still\nretaining the unique depth information. To our best knowledge, our DSSS\nframework is the first work to integrate RGB and Depth information in the\nmulti-class DG semantic segmentation task. Extensive experiments over multiple\nbackbone networks show that our framework achieves remarkable performance\nimprovement.", "AI": {"tldr": "The paper proposes DSSS, a framework for Domain Generalization (DG) semantic segmentation, leveraging depth maps and RGB data to learn domain-invariant features by addressing noise in depth maps and integrating RGB-D stylization.", "motivation": "Existing methods in Unsupervised Domain Adaptation (UDA) and Domain Generalization (DG) struggle with noisy depth maps and fail to fully utilize RGB-D data for domain-invariant feature learning.", "method": "The DSSS framework includes RGB-D inter-modal stylization flow for generating stylized depth maps, class-wise soft spatial sensitivity suppression for emphasizing domain-invariant features, and RGB-D soft alignment loss to retain depth uniqueness.", "result": "Extensive experiments demonstrate significant performance improvement in DG semantic segmentation across multiple backbone networks.", "conclusion": "DSSS is the first RGB-D integrated framework for multi-class DG semantic segmentation, effectively addressing depth map noise and enhancing domain-invariant learning."}}
{"id": "2505.06363", "pdf": "https://arxiv.org/pdf/2505.06363", "abs": "https://arxiv.org/abs/2505.06363", "authors": ["Anmol Gupta", "Weiwei Gu", "Omkar Patil", "Jun Ki Lee", "Nakul Gopalan"], "title": "Learning Sequential Kinematic Models from Demonstrations for Multi-Jointed Articulated Objects", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "As robots become more generalized and deployed in diverse environments, they\nmust interact with complex objects, many with multiple independent joints or\ndegrees of freedom (DoF) requiring precise control. A common strategy is object\nmodeling, where compact state-space models are learned from real-world\nobservations and paired with classical planning. However, existing methods\noften rely on prior knowledge or focus on single-DoF objects, limiting their\napplicability. They also fail to handle occluded joints and ignore the\nmanipulation sequences needed to access them. We address this by learning\nobject models from human demonstrations. We introduce Object Kinematic Sequence\nMachines (OKSMs), a novel representation capturing both kinematic constraints\nand manipulation order for multi-DoF objects. To estimate these models from\npoint cloud data, we present Pokenet, a deep neural network trained on human\ndemonstrations. We validate our approach on 8,000 simulated and 1,600\nreal-world annotated samples. Pokenet improves joint axis and state estimation\nby over 20 percent on real-world data compared to prior methods. Finally, we\ndemonstrate OKSMs on a Sawyer robot using inverse kinematics-based planning to\nmanipulate multi-DoF objects.", "AI": {"tldr": "The paper introduces OKSMs and Pokenet to model and manipulate multi-DoF objects from human demonstrations, improving joint axis and state estimation by 20% over prior methods.", "motivation": "Robots need to interact with complex multi-DoF objects, but existing methods rely on prior knowledge or focus on single-DoF objects, failing to handle occluded joints or manipulation sequences.", "method": "Proposes Object Kinematic Sequence Machines (OKSMs) for kinematic constraints and manipulation order, and Pokenet, a deep neural network trained on human demonstrations for model estimation.", "result": "Validated on 8,000 simulated and 1,600 real-world samples, Pokenet improves joint axis and state estimation by over 20%. Demonstrated on a Sawyer robot for multi-DoF manipulation.", "conclusion": "OKSMs and Pokenet effectively address limitations of prior methods, enabling better manipulation of multi-DoF objects in robotics."}}
{"id": "2505.06753", "pdf": "https://arxiv.org/pdf/2505.06753", "abs": "https://arxiv.org/abs/2505.06753", "authors": ["Muhamed Amin", "Bernard R. Brooks"], "title": "Boltzmann Classifier: A Thermodynamic-Inspired Approach to Supervised Learning", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "We propose a novel classification algorithm, the Boltzmann Classifier,\ninspired by the thermodynamic principles underlying the Boltzmann distribution.\nOur method computes a probabilistic estimate for each class based on an energy\nfunction derived from feature-wise deviations between input samples and\nclass-specific centroids. The resulting probabilities are proportional to the\nexponential negative energies, normalized across classes, analogous to the\nBoltzmann distribution used in statistical mechanics. In addition, the KT\nvariable can be used to allow the high energy states to be more accessible,\nwhich allows the tuning of their probabilities as needed. We evaluate the model\nperformance on several datasets from different applications. The model achieves\na high accuracy, which indicates that the Boltzmann Classifier is competitive\nwith standard models like logistic regression and k-nearest neighbors while\noffering a thermodynamically motivated probabilistic interpretation. our\nclassifier does not require iterative optimization or backpropagation and is\nthus computationally efficient and easy to integrate into existing workflows.\nThis work demonstrates how ideas from physics can inform new directions in\nmachine learning, providing a foundation for interpretable, energy-based\ndecision-making systems.", "AI": {"tldr": "The paper introduces the Boltzmann Classifier, a novel algorithm inspired by thermodynamics, offering probabilistic class estimates without iterative optimization.", "motivation": "To leverage thermodynamic principles for interpretable, energy-based classification, avoiding complex optimization.", "method": "Uses an energy function from feature deviations to compute class probabilities, normalized like the Boltzmann distribution, with tunable KT variable.", "result": "Achieves high accuracy, competitive with logistic regression and k-nearest neighbors, while being computationally efficient.", "conclusion": "Demonstrates physics-inspired machine learning for interpretable, energy-based systems without iterative optimization."}}
{"id": "2505.07188", "pdf": "https://arxiv.org/pdf/2505.07188", "abs": "https://arxiv.org/abs/2505.07188", "authors": ["Chetan Pathade", "Shubham Patil"], "title": "Securing Genomic Data Against Inference Attacks in Federated Learning Environments", "categories": ["cs.CR", "cs.CL"], "comment": "10 Pages, 7 Figures", "summary": "Federated Learning (FL) offers a promising framework for collaboratively\ntraining machine learning models across decentralized genomic datasets without\ndirect data sharing. While this approach preserves data locality, it remains\nsusceptible to sophisticated inference attacks that can compromise individual\nprivacy. In this study, we simulate a federated learning setup using synthetic\ngenomic data and assess its vulnerability to three key attack vectors:\nMembership Inference Attack (MIA), Gradient-Based Membership Inference Attack,\nand Label Inference Attack (LIA). Our experiments reveal that Gradient-Based\nMIA achieves the highest effectiveness, with a precision of 0.79 and F1-score\nof 0.87, underscoring the risk posed by gradient exposure in federated updates.\nAdditionally, we visualize comparative attack performance through radar plots\nand quantify model leakage across clients. The findings emphasize the\ninadequacy of na\\\"ive FL setups in safeguarding genomic privacy and motivate\nthe development of more robust privacy-preserving mechanisms tailored to the\nunique sensitivity of genomic data.", "AI": {"tldr": "Federated Learning (FL) for genomic data is vulnerable to privacy attacks, with Gradient-Based MIA being the most effective. Findings highlight the need for stronger privacy mechanisms.", "motivation": "To assess the vulnerability of FL in genomic data to privacy attacks like MIA and LIA, given the sensitivity of such data.", "method": "Simulated FL setup with synthetic genomic data, testing three attack vectors: MIA, Gradient-Based MIA, and LIA.", "result": "Gradient-Based MIA was most effective (precision 0.79, F1-score 0.87), showing high risk from gradient exposure.", "conclusion": "Na\u00efve FL setups fail to protect genomic privacy, urging development of robust privacy-preserving mechanisms."}}
{"id": "2505.07057", "pdf": "https://arxiv.org/pdf/2505.07057", "abs": "https://arxiv.org/abs/2505.07057", "authors": ["Junhao Xia", "Chaoyang Zhang", "Yecheng Zhang", "Chengyang Zhou", "Zhichang Wang", "Bochun Liu", "Dongshuo Yin"], "title": "DAPE: Dual-Stage Parameter-Efficient Fine-Tuning for Consistent Video Editing with Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Video generation based on diffusion models presents a challenging multimodal\ntask, with video editing emerging as a pivotal direction in this field. Recent\nvideo editing approaches primarily fall into two categories: training-required\nand training-free methods. While training-based methods incur high\ncomputational costs, training-free alternatives often yield suboptimal\nperformance. To address these limitations, we propose DAPE, a high-quality yet\ncost-effective two-stage parameter-efficient fine-tuning (PEFT) framework for\nvideo editing. In the first stage, we design an efficient norm-tuning method to\nenhance temporal consistency in generated videos. The second stage introduces a\nvision-friendly adapter to improve visual quality. Additionally, we identify\ncritical shortcomings in existing benchmarks, including limited category\ndiversity, imbalanced object distribution, and inconsistent frame counts. To\nmitigate these issues, we curate a large dataset benchmark comprising 232\nvideos with rich annotations and 6 editing prompts, enabling objective and\ncomprehensive evaluation of advanced methods. Extensive experiments on existing\ndatasets (BalanceCC, LOVEU-TGVE, RAVE) and our proposed benchmark demonstrate\nthat DAPE significantly improves temporal coherence and text-video alignment\nwhile outperforming previous state-of-the-art approaches.", "AI": {"tldr": "DAPE is a two-stage PEFT framework for video editing, improving temporal consistency and visual quality while addressing benchmark shortcomings with a new dataset.", "motivation": "Addressing the high computational costs of training-based video editing methods and the suboptimal performance of training-free alternatives.", "method": "A two-stage framework: norm-tuning for temporal consistency and a vision-friendly adapter for visual quality. Introduces a new benchmark dataset.", "result": "DAPE outperforms state-of-the-art methods in temporal coherence and text-video alignment.", "conclusion": "DAPE offers a cost-effective, high-quality solution for video editing, validated by extensive experiments."}}
{"id": "2505.06378", "pdf": "https://arxiv.org/pdf/2505.06378", "abs": "https://arxiv.org/abs/2505.06378", "authors": ["Yuxiang Wei", "Zhuoqi Zeng", "Yue Zhong", "Jiawen Kang", "Ryan Wen Liu", "M. Shamim Hossain"], "title": "Bi-LSTM based Multi-Agent DRL with Computation-aware Pruning for Agent Twins Migration in Vehicular Embodied AI Networks", "categories": ["cs.GT", "cs.AI"], "comment": null, "summary": "With the advancement of large language models and embodied Artificial\nIntelligence (AI) in the intelligent transportation scenarios, the combination\nof them in intelligent transportation spawns the Vehicular Embodied AI Network\n(VEANs). In VEANs, Autonomous Vehicles (AVs) are typical agents whose local\nadvanced AI applications are defined as vehicular embodied AI agents, enabling\ncapabilities such as environment perception and multi-agent collaboration. Due\nto computation latency and resource constraints, the local AI applications and\nservices running on vehicular embodied AI agents need to be migrated, and\nsubsequently referred to as vehicular embodied AI agent twins, which drive the\nadvancement of vehicular embodied AI networks to offload intensive tasks to\nRoadside Units (RSUs), mitigating latency problems while maintaining service\nquality. Recognizing workload imbalance among RSUs in traditional approaches,\nwe model AV-RSU interactions as a Stackelberg game to optimize bandwidth\nresource allocation for efficient migration. A Tiny Multi-Agent Bidirectional\nLSTM Proximal Policy Optimization (TMABLPPO) algorithm is designed to\napproximate the Stackelberg equilibrium through decentralized coordination.\nFurthermore, a personalized neural network pruning algorithm based on Path\neXclusion (PX) dynamically adapts to heterogeneous AV computation capabilities\nby identifying task-critical parameters in trained models, reducing model\ncomplexity with less performance degradation. Experimental validation confirms\nthe algorithm's effectiveness in balancing system load and minimizing delays,\ndemonstrating significant improvements in vehicular embodied AI agent\ndeployment.", "AI": {"tldr": "The paper introduces Vehicular Embodied AI Networks (VEANs) for intelligent transportation, optimizing task migration and resource allocation using game theory and neural network pruning.", "motivation": "To address computation latency and resource constraints in vehicular embodied AI agents by improving task migration and balancing workload among Roadside Units (RSUs).", "method": "Models AV-RSU interactions as a Stackelberg game, designs a TMABLPPO algorithm for decentralized coordination, and employs a personalized neural network pruning algorithm (PX-based) for dynamic adaptation.", "result": "Experimental results show effective load balancing and reduced delays, enhancing vehicular embodied AI agent deployment.", "conclusion": "The proposed methods significantly improve efficiency in VEANs, demonstrating practical benefits for intelligent transportation systems."}}
{"id": "2505.06759", "pdf": "https://arxiv.org/pdf/2505.06759", "abs": "https://arxiv.org/abs/2505.06759", "authors": ["Xavier Mart\u00ednez-Lua\u00f1a", "Manuel Fern\u00e1ndez-Veiga", "Rebeca P. D\u00edaz-Redondo", "Ana Fern\u00e1ndez-Vilas"], "title": "Privacy-aware Berrut Approximated Coded Computing applied to general distributed learning", "categories": ["cs.LG", "cs.CR", "cs.DC", "cs.IT", "math.IT"], "comment": null, "summary": "Coded computing is one of the techniques that can be used for privacy\nprotection in Federated Learning. However, most of the constructions used for\ncoded computing work only under the assumption that the computations involved\nare exact, generally restricted to special classes of functions, and require\nquantized inputs. This paper considers the use of Private Berrut Approximate\nCoded Computing (PBACC) as a general solution to add strong but non-perfect\nprivacy to federated learning. We derive new adapted PBACC algorithms for\ncentralized aggregation, secure distributed training with centralized data, and\nsecure decentralized training with decentralized data, thus enlarging\nsignificantly the applications of the method and the existing privacy\nprotection tools available for these paradigms. Particularly, PBACC can be used\nrobustly to attain privacy guarantees in decentralized federated learning for a\nvariety of models. Our numerical results show that the achievable quality of\ndifferent learning models (convolutional neural networks, variational\nautoencoders, and Cox regression) is minimally altered by using these new\ncomputing schemes, and that the privacy leakage can be bounded strictly to less\nthan a fraction of one bit per participant. Additionally, the computational\ncost of the encoding and decoding processes depends only of the degree of\ndecentralization of the data.", "AI": {"tldr": "PBACC enhances privacy in federated learning by generalizing coded computing, supporting various models with minimal impact on learning quality and bounded privacy leakage.", "motivation": "Existing coded computing methods for privacy in federated learning are limited to exact computations and specific functions. PBACC aims to provide a more flexible and robust solution.", "method": "PBACC algorithms are adapted for centralized aggregation, secure distributed training, and decentralized training, expanding its applicability.", "result": "PBACC minimally affects learning quality (tested on CNNs, VAEs, Cox regression) and bounds privacy leakage to less than a fraction of one bit per participant.", "conclusion": "PBACC is a versatile and efficient privacy solution for federated learning, with computational costs scaling with data decentralization."}}
{"id": "2505.07558", "pdf": "https://arxiv.org/pdf/2505.07558", "abs": "https://arxiv.org/abs/2505.07558", "authors": ["Rei Higuchi", "Taiji Suzuki"], "title": "Direct Density Ratio Optimization: A Statistically Consistent Approach to Aligning Large Language Models", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": null, "summary": "Aligning large language models (LLMs) with human preferences is crucial for\nsafe deployment, yet existing methods assume specific preference models like\nBradley-Terry model. This assumption leads to statistical inconsistency, where\nmore data doesn't guarantee convergence to true human preferences. To address\nthis critical gap, we introduce a novel alignment method Direct Density Ratio\nOptimization (DDRO). DDRO directly estimates the density ratio between\npreferred and unpreferred output distributions, circumventing the need for\nexplicit human preference modeling. We theoretically prove that DDRO is\nstatistically consistent, ensuring convergence to the true preferred\ndistribution as the data size grows, regardless of the underlying preference\nstructure. Experiments demonstrate that DDRO achieves superior performance\ncompared to existing methods on many major benchmarks. DDRO unlocks the\npotential for truly data-driven alignment, paving the way for more reliable and\nhuman-aligned LLMs.", "AI": {"tldr": "DDRO is a novel alignment method for LLMs that avoids explicit preference modeling, ensuring statistical consistency and superior performance.", "motivation": "Existing methods assume specific preference models, leading to statistical inconsistency in aligning LLMs with human preferences.", "method": "DDRO directly estimates the density ratio between preferred and unpreferred output distributions.", "result": "DDRO is theoretically proven statistically consistent and outperforms existing methods on benchmarks.", "conclusion": "DDRO enables reliable, data-driven alignment of LLMs with human preferences."}}
{"id": "2505.07062", "pdf": "https://arxiv.org/pdf/2505.07062", "abs": "https://arxiv.org/abs/2505.07062", "authors": ["Dong Guo", "Faming Wu", "Feida Zhu", "Fuxing Leng", "Guang Shi", "Haobin Chen", "Haoqi Fan", "Jian Wang", "Jianyu Jiang", "Jiawei Wang", "Jingji Chen", "Jingjia Huang", "Kang Lei", "Liping Yuan", "Lishu Luo", "Pengfei Liu", "Qinghao Ye", "Rui Qian", "Shen Yan", "Shixiong Zhao", "Shuai Peng", "Shuangye Li", "Sihang Yuan", "Sijin Wu", "Tianheng Cheng", "Weiwei Liu", "Wenqian Wang", "Xianhan Zeng", "Xiao Liu", "Xiaobo Qin", "Xiaohan Ding", "Xiaojun Xiao", "Xiaoying Zhang", "Xuanwei Zhang", "Xuehan Xiong", "Yanghua Peng", "Yangrui Chen", "Yanwei Li", "Yanxu Hu", "Yi Lin", "Yiyuan Hu", "Yiyuan Zhang", "Youbin Wu", "Yu Li", "Yudong Liu", "Yue Ling", "Yujia Qin", "Zanbo Wang", "Zhiwu He", "Aoxue Zhang", "Bairen Yi", "Bencheng Liao", "Can Huang", "Can Zhang", "Chaorui Deng", "Chaoyi Deng", "Cheng Lin", "Cheng Yuan", "Chenggang Li", "Chenhui Gou", "Chenwei Lou", "Chengzhi Wei", "Chundian Liu", "Chunyuan Li", "Deyao Zhu", "Donghong Zhong", "Feng Li", "Feng Zhang", "Gang Wu", "Guodong Li", "Guohong Xiao", "Haibin Lin", "Haihua Yang", "Haoming Wang", "Heng Ji", "Hongxiang Hao", "Hui Shen", "Huixia Li", "Jiahao Li", "Jialong Wu", "Jianhua Zhu", "Jianpeng Jiao", "Jiashi Feng", "Jiaze Chen", "Jianhui Duan", "Jihao Liu", "Jin Zeng", "Jingqun Tang", "Jingyu Sun", "Joya Chen", "Jun Long", "Junda Feng", "Junfeng Zhan", "Junjie Fang", "Junting Lu", "Kai Hua", "Kai Liu", "Kai Shen", "Kaiyuan Zhang", "Ke Shen", "Ke Wang", "Keyu Pan", "Kun Zhang", "Kunchang Li", "Lanxin Li", "Lei Li", "Lei Shi", "Li Han", "Liang Xiang", "Liangqiang Chen", "Lin Chen", "Lin Li", "Lin Yan", "Liying Chi", "Longxiang Liu", "Mengfei Du", "Mingxuan Wang", "Ningxin Pan", "Peibin Chen", "Pengfei Chen", "Pengfei Wu", "Qingqing Yuan", "Qingyao Shuai", "Qiuyan Tao", "Renjie Zheng", "Renrui Zhang", "Ru Zhang", "Rui Wang", "Rui Yang", "Rui Zhao", "Shaoqiang Xu", "Shihao Liang", "Shipeng Yan", "Shu Zhong", "Shuaishuai Cao", "Shuangzhi Wu", "Shufan Liu", "Shuhan Chang", "Songhua Cai", "Tenglong Ao", "Tianhao Yang", "Tingting Zhang", "Wanjun Zhong", "Wei Jia", "Wei Weng", "Weihao Yu", "Wenhao Huang", "Wenjia Zhu", "Wenli Yang", "Wenzhi Wang", "Xiang Long", "XiangRui Yin", "Xiao Li", "Xiaolei Zhu", "Xiaoying Jia", "Xijin Zhang", "Xin Liu", "Xinchen Zhang", "Xinyu Yang", "Xiongcai Luo", "Xiuli Chen", "Xuantong Zhong", "Xuefeng Xiao", "Xujing Li", "Yan Wu", "Yawei Wen", "Yifan Du", "Yihao Zhang", "Yining Ye", "Yonghui Wu", "Yu Liu", "Yu Yue", "Yufeng Zhou", "Yufeng Yuan", "Yuhang Xu", "Yuhong Yang", "Yun Zhang", "Yunhao Fang", "Yuntao Li", "Yurui Ren", "Yuwen Xiong", "Zehua Hong", "Zehua Wang", "Zewei Sun", "Zeyu Wang", "Zhao Cai", "Zhaoyue Zha", "Zhecheng An", "Zhehui Zhao", "Zhengzhuo Xu", "Zhipeng Chen", "Zhiyong Wu", "Zhuofan Zheng", "Zihao Wang", "Zilong Huang", "Ziyu Zhu", "Zuquan Song"], "title": "Seed1.5-VL Technical Report", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present Seed1.5-VL, a vision-language foundation model designed to advance\ngeneral-purpose multimodal understanding and reasoning. Seed1.5-VL is composed\nwith a 532M-parameter vision encoder and a Mixture-of-Experts (MoE) LLM of 20B\nactive parameters. Despite its relatively compact architecture, it delivers\nstrong performance across a wide spectrum of public VLM benchmarks and internal\nevaluation suites, achieving the state-of-the-art performance on 38 out of 60\npublic benchmarks. Moreover, in agent-centric tasks such as GUI control and\ngameplay, Seed1.5-VL outperforms leading multimodal systems, including OpenAI\nCUA and Claude 3.7. Beyond visual and video understanding, it also demonstrates\nstrong reasoning abilities, making it particularly effective for multimodal\nreasoning challenges such as visual puzzles. We believe these capabilities will\nempower broader applications across diverse tasks. In this report, we mainly\nprovide a comprehensive review of our experiences in building Seed1.5-VL across\nmodel design, data construction, and training at various stages, hoping that\nthis report can inspire further research. Seed1.5-VL is now accessible at\nhttps://www.volcengine.com/ (Volcano Engine Model ID:\ndoubao-1-5-thinking-vision-pro-250428)", "AI": {"tldr": "Seed1.5-VL is a compact yet powerful vision-language model achieving state-of-the-art performance on 38/60 benchmarks and excelling in agent-centric tasks and multimodal reasoning.", "motivation": "To advance general-purpose multimodal understanding and reasoning with a scalable and efficient model.", "method": "Combines a 532M-parameter vision encoder with a 20B-parameter Mixture-of-Experts LLM.", "result": "Outperforms leading systems like OpenAI CUA and Claude 3.7 in tasks like GUI control, gameplay, and visual puzzles.", "conclusion": "Seed1.5-VL's capabilities enable diverse applications, and its development insights aim to inspire further research."}}
{"id": "2505.06380", "pdf": "https://arxiv.org/pdf/2505.06380", "abs": "https://arxiv.org/abs/2505.06380", "authors": ["Josh Harguess", "Chris M. Ward"], "title": "Offensive Security for AI Systems: Concepts, Practices, and Applications", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As artificial intelligence (AI) systems become increasingly adopted across\nsectors, the need for robust, proactive security strategies is paramount.\nTraditional defensive measures often fall short against the unique and evolving\nthreats facing AI-driven technologies, making offensive security an essential\napproach for identifying and mitigating risks. This paper presents a\ncomprehensive framework for offensive security in AI systems, emphasizing\nproactive threat simulation and adversarial testing to uncover vulnerabilities\nthroughout the AI lifecycle. We examine key offensive security techniques,\nincluding weakness and vulnerability assessment, penetration testing, and red\nteaming, tailored specifically to address AI's unique susceptibilities. By\nsimulating real-world attack scenarios, these methodologies reveal critical\ninsights, informing stronger defensive strategies and advancing resilience\nagainst emerging threats. This framework advances offensive AI security from\ntheoretical concepts to practical, actionable methodologies that organizations\ncan implement to strengthen their AI systems against emerging threats.", "AI": {"tldr": "A framework for offensive security in AI systems is proposed, focusing on proactive threat simulation and adversarial testing to identify vulnerabilities and enhance resilience.", "motivation": "Traditional security measures are inadequate for AI systems, necessitating proactive offensive strategies to address evolving threats.", "method": "The paper introduces offensive security techniques like vulnerability assessment, penetration testing, and red teaming, tailored for AI.", "result": "The framework provides actionable insights to strengthen AI systems against emerging threats.", "conclusion": "Offensive security methodologies are essential for advancing AI system resilience and informing defensive strategies."}}
{"id": "2505.06762", "pdf": "https://arxiv.org/pdf/2505.06762", "abs": "https://arxiv.org/abs/2505.06762", "authors": ["Junfeng Jiao", "Seung Gyu Baik", "Seung Jun Choi", "Yiming Xu"], "title": "Investigating Robotaxi Crash Severity Using Geographical Random Forest", "categories": ["cs.LG", "cs.RO"], "comment": "21 pages, 8 figures", "summary": "This paper quantitatively investigates the crash severity of Autonomous\nVehicles (AVs) with spatially localized machine learning and macroscopic\nmeasures of the urban built environment. We address spatial heterogeneity and\nspatial autocorrelation, while focusing on land use patterns and human\nbehavior. Our Geographical Random Forest (GRF) model, accompanied with a crash\nseverity risk map of San Francisco, presents three findings that are useful for\ncommercial operations of AVs and robotaxis. First, spatially localized machine\nlearning performed better than regular machine learning, when predicting AV\ncrash severity. Bias-variance tradeoff was evident as we adjust the\nlocalization weight hyperparameter. Second, land use was the most important\nbuilt environment measure, compared to intersections, building footprints,\npublic transit stops, and Points Of Interests (POIs). Third, it was predicted\nthat city center areas with greater diversity and commercial activities were\nmore likely to result in low-severity AV crashes, than residential\nneighborhoods. Residential land use may be associated with higher severity due\nto human behavior and less restrictive environment. This paper recommends to\nexplicitly consider geographic locations, and to design safety measures\nspecific to residential neighborhoods, when robotaxi operators train their AV\nsystems.", "AI": {"tldr": "The paper uses a Geographical Random Forest model to analyze AV crash severity in San Francisco, finding localized machine learning outperforms regular methods, land use is the most critical built environment factor, and city centers have lower crash severity than residential areas.", "motivation": "To address spatial heterogeneity and autocorrelation in AV crash severity by examining land use patterns and human behavior, aiding commercial AV operations.", "method": "Employed a Geographical Random Forest (GRF) model with spatial localization, analyzing urban built environment measures like land use, intersections, and POIs.", "result": "Localized machine learning performed better; land use was the most important factor; city centers had lower crash severity than residential areas.", "conclusion": "Recommends geographic-specific safety measures for AV training, especially in residential neighborhoods, to mitigate crash severity."}}
{"id": "2505.07704", "pdf": "https://arxiv.org/pdf/2505.07704", "abs": "https://arxiv.org/abs/2505.07704", "authors": ["Elisei Rykov", "Kseniia Petrushina", "Kseniia Titova", "Anton Razzhigaev", "Alexander Panchenko", "Vasily Konovalov"], "title": "Through the Looking Glass: Common Sense Consistency Evaluation of Weird Images", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Measuring how real images look is a complex task in artificial intelligence\nresearch. For example, an image of a boy with a vacuum cleaner in a desert\nviolates common sense. We introduce a novel method, which we call Through the\nLooking Glass (TLG), to assess image common sense consistency using Large\nVision-Language Models (LVLMs) and Transformer-based encoder. By leveraging\nLVLMs to extract atomic facts from these images, we obtain a mix of accurate\nfacts. We proceed by fine-tuning a compact attention-pooling classifier over\nencoded atomic facts. Our TLG has achieved a new state-of-the-art performance\non the WHOOPS! and WEIRD datasets while leveraging a compact fine-tuning\ncomponent.", "AI": {"tldr": "TLG method uses LVLMs and Transformer-based encoders to assess image common sense consistency, achieving state-of-the-art results on WHOOPS! and WEIRD datasets.", "motivation": "Measuring image common sense consistency is complex, especially for nonsensical images like a boy with a vacuum cleaner in a desert.", "method": "Leverages LVLMs to extract atomic facts from images and fine-tunes a compact attention-pooling classifier over encoded facts.", "result": "Achieves state-of-the-art performance on WHOOPS! and WEIRD datasets.", "conclusion": "TLG is effective for assessing image common sense consistency with minimal fine-tuning."}}
{"id": "2505.07071", "pdf": "https://arxiv.org/pdf/2505.07071", "abs": "https://arxiv.org/abs/2505.07071", "authors": ["Zihang Liu", "Zhenyu Zhang", "Hao Tang"], "title": "Semantic-Guided Diffusion Model for Single-Step Image Super-Resolution", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion-based image super-resolution (SR) methods have demonstrated\nremarkable performance. Recent advancements have introduced deterministic\nsampling processes that reduce inference from 15 iterative steps to a single\nstep, thereby significantly improving the inference speed of existing diffusion\nmodels. However, their efficiency remains limited when handling complex\nsemantic regions due to the single-step inference. To address this limitation,\nwe propose SAMSR, a semantic-guided diffusion framework that incorporates\nsemantic segmentation masks into the sampling process. Specifically, we\nintroduce the SAM-Noise Module, which refines Gaussian noise using segmentation\nmasks to preserve spatial and semantic features. Furthermore, we develop a\npixel-wise sampling strategy that dynamically adjusts the residual transfer\nrate and noise strength based on pixel-level semantic weights, prioritizing\nsemantically rich regions during the diffusion process. To enhance model\ntraining, we also propose a semantic consistency loss, which aligns pixel-wise\nsemantic weights between predictions and ground truth. Extensive experiments on\nboth real-world and synthetic datasets demonstrate that SAMSR significantly\nimproves perceptual quality and detail recovery, particularly in semantically\ncomplex images. Our code is released at https://github.com/Liu-Zihang/SAMSR.", "AI": {"tldr": "SAMSR improves diffusion-based image super-resolution by integrating semantic segmentation masks, enhancing detail recovery in complex regions.", "motivation": "Existing single-step diffusion models struggle with complex semantic regions, limiting efficiency and detail preservation.", "method": "SAMSR uses semantic masks to refine noise (SAM-Noise Module) and a pixel-wise sampling strategy with dynamic adjustments. A semantic consistency loss aligns predictions with ground truth.", "result": "SAMSR outperforms in perceptual quality and detail recovery, especially in semantically complex images.", "conclusion": "SAMSR effectively addresses limitations of single-step diffusion models by leveraging semantic guidance, improving performance in complex scenarios."}}
{"id": "2505.06394", "pdf": "https://arxiv.org/pdf/2505.06394", "abs": "https://arxiv.org/abs/2505.06394", "authors": ["Massimiliano Albanese", "Xinming Ou", "Kevin Lybarger", "Daniel Lende", "Dmitry Goldgof"], "title": "Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Security Operations Centers (SOCs) face growing challenges in managing\ncybersecurity threats due to an overwhelming volume of alerts, a shortage of\nskilled analysts, and poorly integrated tools. Human-AI collaboration offers a\npromising path to augment the capabilities of SOC analysts while reducing their\ncognitive overload. To this end, we introduce an AI-driven human-machine\nco-teaming paradigm that leverages large language models (LLMs) to enhance\nthreat intelligence, alert triage, and incident response workflows. We present\na vision in which LLM-based AI agents learn from human analysts the tacit\nknowledge embedded in SOC operations, enabling the AI agents to improve their\nperformance on SOC tasks through this co-teaming. We invite SOCs to collaborate\nwith us to further develop this process and uncover replicable patterns where\nhuman-AI co-teaming yields measurable improvements in SOC productivity.", "AI": {"tldr": "The paper proposes an AI-driven human-machine co-teaming paradigm using LLMs to enhance SOC operations by reducing cognitive overload and improving threat intelligence, alert triage, and incident response.", "motivation": "SOCs struggle with alert volume, analyst shortages, and tool integration. Human-AI collaboration can augment analyst capabilities and reduce overload.", "method": "Introduces an LLM-based co-teaming paradigm where AI agents learn tacit knowledge from human analysts to improve SOC task performance.", "result": "A vision for AI agents to enhance SOC workflows through collaboration, aiming for measurable productivity improvements.", "conclusion": "Invites SOCs to collaborate on developing replicable patterns for human-AI co-teaming to boost SOC efficiency."}}
{"id": "2505.06795", "pdf": "https://arxiv.org/pdf/2505.06795", "abs": "https://arxiv.org/abs/2505.06795", "authors": ["Abhijit Gupta"], "title": "Decoding Futures Price Dynamics: A Regularized Sparse Autoencoder for Interpretable Multi-Horizon Forecasting and Factor Discovery", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Commodity price volatility creates economic challenges, necessitating\naccurate multi-horizon forecasting. Predicting prices for commodities like\ncopper and crude oil is complicated by diverse interacting factors\n(macroeconomic, supply/demand, geopolitical, etc.). Current models often lack\ntransparency, limiting strategic use. This paper presents a Regularized Sparse\nAutoencoder (RSAE), a deep learning framework for simultaneous multi-horizon\ncommodity price prediction and discovery of interpretable latent market\ndrivers. The RSAE forecasts prices at multiple horizons (e.g., 1-day, 1-week,\n1-month) using multivariate time series. Crucially, L1 regularization\n($\\|\\mathbf{z}\\|_1$) on its latent vector $\\mathbf{z}$ enforces sparsity,\npromoting parsimonious explanations of market dynamics through learned factors\nrepresenting underlying drivers (e.g., demand, supply shocks). Drawing from\nenergy-based models and sparse coding, the RSAE optimizes predictive accuracy\nwhile learning sparse representations. Evaluated on historical Copper and Crude\nOil data with numerous indicators, our findings indicate the RSAE offers\ncompetitive multi-horizon forecasting accuracy and data-driven insights into\nprice dynamics via its interpretable latent space, a key advantage over\ntraditional black-box approaches.", "AI": {"tldr": "The paper introduces a Regularized Sparse Autoencoder (RSAE) for multi-horizon commodity price forecasting, combining accuracy with interpretability by learning sparse latent market drivers.", "motivation": "Commodity price volatility and the lack of transparency in current forecasting models necessitate a method that provides accurate predictions and interpretable insights.", "method": "The RSAE uses L1 regularization on latent vectors to enforce sparsity, enabling multi-horizon forecasting (e.g., 1-day, 1-week, 1-month) and discovery of interpretable market drivers.", "result": "The RSAE achieves competitive forecasting accuracy on Copper and Crude Oil data while offering interpretable latent representations of market dynamics.", "conclusion": "The RSAE outperforms traditional black-box models by providing both accurate forecasts and transparent insights into commodity price drivers."}}
{"id": "2505.07768", "pdf": "https://arxiv.org/pdf/2505.07768", "abs": "https://arxiv.org/abs/2505.07768", "authors": ["Yifeng Di", "Tianyi Zhang"], "title": "Enhancing Code Generation via Bidirectional Comment-Level Mutual Grounding", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "Accepted to ICSE 2025", "summary": "Large Language Models (LLMs) have demonstrated unprecedented capability in\ncode generation. However, LLM-generated code is still plagued with a wide range\nof functional errors, especially for complex programming tasks that LLMs have\nnot seen before. Recent studies have shown that developers often struggle with\ninspecting and fixing incorrect code generated by LLMs, diminishing their\nproductivity and trust in LLM-based code generation. Inspired by the mutual\ngrounding theory in communication, we propose an interactive approach that\nleverages code comments as a medium for developers and LLMs to establish a\nshared understanding. Our approach facilitates iterative grounding by\ninterleaving code generation, inline comment generation, and contextualized\nuser feedback through editable comments to align generated code with developer\nintent. We evaluated our approach on two popular benchmarks and demonstrated\nthat our approach significantly improved multiple state-of-the-art LLMs, e.g.,\n17.1% pass@1 improvement for code-davinci-002 on HumanEval. Furthermore, we\nconducted a user study with 12 participants in comparison to two baselines: (1)\ninteracting with GitHub Copilot, and (2) interacting with a multi-step code\ngeneration paradigm called Multi-Turn Program Synthesis. Participants completed\nthe given programming tasks 16.7% faster and with 10.5% improvement in task\nsuccess rate when using our approach. Both results show that interactively\nrefining code comments enables the collaborative establishment of mutual\ngrounding, leading to more accurate code generation and higher developer\nconfidence.", "AI": {"tldr": "An interactive approach using code comments improves LLM-generated code accuracy and developer productivity.", "motivation": "LLM-generated code often contains functional errors, reducing developer trust and productivity. The study aims to bridge this gap by fostering shared understanding through interactive code comments.", "method": "Proposes an iterative approach combining code generation, inline comment generation, and user feedback via editable comments. Evaluated on benchmarks and compared to baselines like GitHub Copilot.", "result": "Achieved 17.1% pass@1 improvement on HumanEval and 10.5% higher task success rate in user studies. Developers completed tasks 16.7% faster.", "conclusion": "Interactive refinement of code comments enhances mutual grounding, leading to more accurate code and higher developer confidence."}}
{"id": "2505.07073", "pdf": "https://arxiv.org/pdf/2505.07073", "abs": "https://arxiv.org/abs/2505.07073", "authors": ["Payal Varshney", "Adriano Lucieri", "Christoph Balada", "Andreas Dengel", "Sheraz Ahmed"], "title": "Discovering Concept Directions from Diffusion-based Counterfactuals via Latent Clustering", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Concept-based explanations have emerged as an effective approach within\nExplainable Artificial Intelligence, enabling interpretable insights by\naligning model decisions with human-understandable concepts. However, existing\nmethods rely on computationally intensive procedures and struggle to\nefficiently capture complex, semantic concepts. Recently, the Concept Discovery\nthrough Latent Diffusion-based Counterfactual Trajectories (CDCT) framework,\nintroduced by Varshney et al. (2025), attempts to identify concepts via\ndimension-wise traversal of the latent space of a Variational Autoencoder\ntrained on counterfactual trajectories. Extending the CDCT framework, this work\nintroduces Concept Directions via Latent Clustering (CDLC), which extracts\nglobal, class-specific concept directions by clustering latent difference\nvectors derived from factual and diffusion-generated counterfactual image\npairs. CDLC substantially reduces computational complexity by eliminating the\nexhaustive latent dimension traversal required in CDCT and enables the\nextraction of multidimensional semantic concepts encoded across the latent\ndimensions. This approach is validated on a real-world skin lesion dataset,\ndemonstrating that the extracted concept directions align with clinically\nrecognized dermoscopic features and, in some cases, reveal dataset-specific\nbiases or unknown biomarkers. These results highlight that CDLC is\ninterpretable, scalable, and applicable across high-stakes domains and diverse\ndata modalities.", "AI": {"tldr": "CDLC improves concept-based explanations by clustering latent vectors, reducing computational complexity and capturing multidimensional concepts, validated on skin lesion data.", "motivation": "Existing methods for concept-based explanations are computationally intensive and inefficient for complex concepts.", "method": "CDLC clusters latent difference vectors from factual and counterfactual image pairs to extract global, class-specific concept directions.", "result": "CDLC aligns with clinical features and reveals biases or biomarkers, showing interpretability and scalability.", "conclusion": "CDLC is a scalable, interpretable method for extracting semantic concepts, applicable in high-stakes domains."}}
{"id": "2505.06402", "pdf": "https://arxiv.org/pdf/2505.06402", "abs": "https://arxiv.org/abs/2505.06402", "authors": ["Alexiy Buynitsky", "Sina Ehsani", "Bhanu Pallakonda", "Pragyana Mishra"], "title": "Camera Control at the Edge with Language Models for Scene Understanding", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": "7 pages, 6 figures. This work was presented and published at the 11th\n  IEEE International Conference on Control, Automation and Robotics (ICCAR) in\n  2025", "summary": "In this paper, we present Optimized Prompt-based Unified System (OPUS), a\nframework that utilizes a Large Language Model (LLM) to control Pan-Tilt-Zoom\n(PTZ) cameras, providing contextual understanding of natural environments. To\nachieve this goal, the OPUS system improves cost-effectiveness by generating\nkeywords from a high-level camera control API and transferring knowledge from\nlarger closed-source language models to smaller ones through Supervised\nFine-Tuning (SFT) on synthetic data. This enables efficient edge deployment\nwhile maintaining performance comparable to larger models like GPT-4. OPUS\nenhances environmental awareness by converting data from multiple cameras into\ntextual descriptions for language models, eliminating the need for specialized\nsensory tokens. In benchmark testing, our approach significantly outperformed\nboth traditional language model techniques and more complex prompting methods,\nachieving a 35% improvement over advanced techniques and a 20% higher task\naccuracy compared to closed-source models like Gemini Pro. The system\ndemonstrates OPUS's capability to simplify PTZ camera operations through an\nintuitive natural language interface. This approach eliminates the need for\nexplicit programming and provides a conversational method for interacting with\ncamera systems, representing a significant advancement in how users can control\nand utilize PTZ camera technology.", "AI": {"tldr": "OPUS is a framework using LLMs to control PTZ cameras, improving cost-effectiveness and performance through SFT on synthetic data, outperforming traditional methods by 35%.", "motivation": "To simplify PTZ camera operations with natural language, eliminating explicit programming and enhancing environmental awareness.", "method": "Uses SFT on synthetic data to transfer knowledge from larger to smaller LLMs, generating keywords for camera control.", "result": "Achieves 35% improvement over advanced techniques and 20% higher task accuracy than closed-source models like Gemini Pro.", "conclusion": "OPUS advances PTZ camera control with an intuitive natural language interface, demonstrating superior performance and usability."}}
{"id": "2505.06804", "pdf": "https://arxiv.org/pdf/2505.06804", "abs": "https://arxiv.org/abs/2505.06804", "authors": ["Xiaohan Wang", "Matthew Berger"], "title": "Topology Guidance: Controlling the Outputs of Generative Models via Vector Field Topology", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "For domains that involve numerical simulation, it can be computationally\nexpensive to run an ensemble of simulations spanning a parameter space of\ninterest to a user. To this end, an attractive surrogate for simulation is the\ngenerative modeling of fields produced by an ensemble, allowing one to\nsynthesize fields in a computationally cheap, yet accurate, manner. However,\nfor the purposes of visual analysis, a limitation of generative models is their\nlack of control, as it is unclear what one should expect when sampling a field\nfrom a model. In this paper we study how to make generative models of fields\nmore controllable, so that users can specify features of interest, in\nparticular topological features, that they wish to see in the output. We\npropose topology guidance, a method for guiding the sampling process of a\ngenerative model, specifically a diffusion model, such that a topological\ndescription specified as input is satisfied in the generated output. Central to\nour method, we couple a coordinate-based neural network used to represent\nfields, with a diffusion model used for generation. We show how to use\ntopologically-relevant signals provided by the coordinate-based network to help\nguide the denoising process of a diffusion model. This enables us to faithfully\nrepresent a user's specified topology, while ensuring that the output field\nremains within the generative data distribution. Specifically, we study 2D\nvector field topology, evaluating our method over an ensemble of fluid flows,\nwhere we show that generated vector fields faithfully adhere to the location,\nand type, of critical points over the spatial domain. We further show the\nbenefits of our method in aiding the comparison of ensembles, allowing one to\nexplore commonalities and differences in distributions along prescribed\ntopological features.", "AI": {"tldr": "The paper introduces topology guidance for generative models to control field synthesis, ensuring specified topological features are accurately represented in outputs.", "motivation": "Generative models lack controllability for visual analysis, making it hard to predict or specify desired features like topology in synthesized fields.", "method": "Proposes coupling a coordinate-based neural network with a diffusion model, using topologically-relevant signals to guide the denoising process.", "result": "Demonstrates accurate adherence to specified critical points in 2D vector fields, aiding ensemble comparison by exploring topological commonalities.", "conclusion": "Topology guidance enhances generative models' controllability, enabling precise synthesis of fields with user-defined topological features."}}
{"id": "2306.09597", "pdf": "https://arxiv.org/pdf/2306.09597", "abs": "https://arxiv.org/abs/2306.09597", "authors": ["Han Wang", "Yi Zhu", "Ye Wang", "Yun Li", "Yunhao Yuan", "Jipeng Qiang"], "title": "Clickbait Detection via Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 4 figures", "summary": "Clickbait, which aims to induce users with some surprising and even thrilling\nheadlines for increasing click-through rates, permeates almost all online\ncontent publishers, such as news portals and social media. Recently, Large\nLanguage Models (LLMs) have emerged as a powerful instrument and achieved\ntremendous success in a series of NLP downstream tasks. However, it is not yet\nknown whether LLMs can be served as a high-quality clickbait detection system.\nIn this paper, we analyze the performance of LLMs in the few-shot and zero-shot\nscenarios on several English and Chinese benchmark datasets. Experimental\nresults show that LLMs cannot achieve the best results compared to the\nstate-of-the-art deep and fine-tuning PLMs methods. Different from human\nintuition, the experiments demonstrated that LLMs cannot make satisfied\nclickbait detection just by the headlines.", "AI": {"tldr": "LLMs underperform in clickbait detection compared to state-of-the-art methods, failing to achieve satisfactory results even with headlines alone.", "motivation": "To evaluate whether LLMs can effectively detect clickbait, given their success in other NLP tasks.", "method": "Analyzed LLMs' performance in few-shot and zero-shot scenarios on English and Chinese benchmark datasets.", "result": "LLMs did not outperform existing deep and fine-tuned PLMs methods.", "conclusion": "LLMs are not yet reliable for high-quality clickbait detection, contrary to human intuition."}}
{"id": "2505.07119", "pdf": "https://arxiv.org/pdf/2505.07119", "abs": "https://arxiv.org/abs/2505.07119", "authors": ["Arianna Stropeni", "Francesco Borsatti", "Manuel Barusco", "Davide Dalle Pezze", "Marco Fabris", "Gian Antonio Susto"], "title": "Towards Scalable IoT Deployment for Visual Anomaly Detection via Efficient Compression", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual Anomaly Detection (VAD) is a key task in industrial settings, where\nminimizing waste and operational costs is essential. Deploying deep learning\nmodels within Internet of Things (IoT) environments introduces specific\nchallenges due to the limited computational power and bandwidth of edge\ndevices. This study investigates how to perform VAD effectively under such\nconstraints by leveraging compact and efficient processing strategies. We\nevaluate several data compression techniques, examining the trade-off between\nsystem latency and detection accuracy. Experiments on the MVTec AD benchmark\ndemonstrate that significant compression can be achieved with minimal loss in\nanomaly detection performance compared to uncompressed data.", "AI": {"tldr": "The paper explores efficient Visual Anomaly Detection (VAD) in IoT environments, focusing on data compression to balance latency and accuracy.", "motivation": "Industrial settings require VAD to reduce waste and costs, but IoT constraints like limited computational power and bandwidth pose challenges.", "method": "The study evaluates various data compression techniques to optimize VAD performance on edge devices.", "result": "Experiments on MVTec AD show significant compression is possible with minimal impact on anomaly detection accuracy.", "conclusion": "Compact processing strategies enable effective VAD in resource-limited IoT environments."}}
{"id": "2505.06428", "pdf": "https://arxiv.org/pdf/2505.06428", "abs": "https://arxiv.org/abs/2505.06428", "authors": ["Somayeh Molaei", "Lionel P. Robert", "Nikola Banovic"], "title": "What Do People Want to Know About Artificial Intelligence (AI)? The Importance of Answering End-User Questions to Explain Autonomous Vehicle (AV) Decisions", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted to the Proceedings of the ACM on Human-Computer Interaction,\n  CSCW, October 2025", "summary": "Improving end-users' understanding of decisions made by autonomous vehicles\n(AVs) driven by artificial intelligence (AI) can improve utilization and\nacceptance of AVs. However, current explanation mechanisms primarily help AI\nresearchers and engineers in debugging and monitoring their AI systems, and may\nnot address the specific questions of end-users, such as passengers, about AVs\nin various scenarios. In this paper, we conducted two user studies to\ninvestigate questions that potential AV passengers might pose while riding in\nan AV and evaluate how well answers to those questions improve their\nunderstanding of AI-driven AV decisions. Our initial formative study identified\na range of questions about AI in autonomous driving that existing explanation\nmechanisms do not readily address. Our second study demonstrated that\ninteractive text-based explanations effectively improved participants'\ncomprehension of AV decisions compared to simply observing AV decisions. These\nfindings inform the design of interactions that motivate end-users to engage\nwith and inquire about the reasoning behind AI-driven AV decisions.", "AI": {"tldr": "Interactive text-based explanations improve end-users' understanding of AI-driven AV decisions better than passive observation.", "motivation": "Enhancing end-users' comprehension of AV decisions to boost AV utilization and acceptance, addressing gaps in current explanation mechanisms.", "method": "Conducted two user studies: a formative study to identify unanswered questions about AV decisions and a second study to evaluate interactive text-based explanations.", "result": "Interactive explanations significantly improved participants' understanding of AV decisions compared to passive observation.", "conclusion": "Designing interactive explanations can better engage end-users and address their specific questions about AV decisions."}}
{"id": "2505.06818", "pdf": "https://arxiv.org/pdf/2505.06818", "abs": "https://arxiv.org/abs/2505.06818", "authors": ["Thien Nhan Vo"], "title": "Deep Learning for On-Street Parking Violation Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Illegal parking along with the lack of available parking spaces are among the\nbiggest issues faced in many large cities. These issues can have a significant\nimpact on the quality of life of citizens. On-street parking systems have been\ndesigned to this end aiming at ensuring that parking spaces will be available\nfor the local population, while also providing easy access to parking for\npeople visiting the city center. However, these systems are often affected by\nillegal parking, providing incorrect information regarding the availability of\nparking spaces. Even though this can be mitigated using sensors for detecting\nthe presence of cars in various parking sectors, the cost of these\nimplementations is usually prohibiting large. In this paper, we investigate an\nindirect way of predicting parking violations at a fine-grained level,\nequipping such parking systems with a valuable tool for providing more accurate\ninformation to citizens. To this end, we employed a Deep Learning (DL)-based\nmodel to predict fine-grained parking violation rates for on-street parking\nsystems. Moreover, we developed a data augmentation and smoothing technique for\nfurther improving the accuracy of DL models under the presence of missing and\nnoisy data. We demonstrate, using experiments on real data collected in\nThessaloniki, Greece, that the developed system can indeed provide accurate\nparking violation predictions.", "AI": {"tldr": "The paper proposes a DL-based model to predict parking violations in on-street parking systems, addressing issues of illegal parking and inaccurate parking space availability.", "motivation": "Illegal parking and lack of parking spaces degrade urban quality of life. Existing systems are flawed due to illegal parking and high sensor costs.", "method": "A Deep Learning model is used for fine-grained parking violation prediction, enhanced by data augmentation and smoothing techniques for noisy/missing data.", "result": "Experiments on real data from Thessaloniki show the system provides accurate parking violation predictions.", "conclusion": "The DL-based approach effectively improves parking system accuracy, offering a cost-effective solution to illegal parking challenges."}}
{"id": "2310.13548", "pdf": "https://arxiv.org/pdf/2310.13548", "abs": "https://arxiv.org/abs/2310.13548", "authors": ["Mrinank Sharma", "Meg Tong", "Tomasz Korbak", "David Duvenaud", "Amanda Askell", "Samuel R. Bowman", "Newton Cheng", "Esin Durmus", "Zac Hatfield-Dodds", "Scott R. Johnston", "Shauna Kravec", "Timothy Maxwell", "Sam McCandlish", "Kamal Ndousse", "Oliver Rausch", "Nicholas Schiefer", "Da Yan", "Miranda Zhang", "Ethan Perez"], "title": "Towards Understanding Sycophancy in Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML", "I.2.6"], "comment": "32 pages, 20 figures", "summary": "Human feedback is commonly utilized to finetune AI assistants. But human\nfeedback may also encourage model responses that match user beliefs over\ntruthful ones, a behaviour known as sycophancy. We investigate the prevalence\nof sycophancy in models whose finetuning procedure made use of human feedback,\nand the potential role of human preference judgments in such behavior. We first\ndemonstrate that five state-of-the-art AI assistants consistently exhibit\nsycophancy across four varied free-form text-generation tasks. To understand if\nhuman preferences drive this broadly observed behavior, we analyze existing\nhuman preference data. We find that when a response matches a user's views, it\nis more likely to be preferred. Moreover, both humans and preference models\n(PMs) prefer convincingly-written sycophantic responses over correct ones a\nnon-negligible fraction of the time. Optimizing model outputs against PMs also\nsometimes sacrifices truthfulness in favor of sycophancy. Overall, our results\nindicate that sycophancy is a general behavior of state-of-the-art AI\nassistants, likely driven in part by human preference judgments favoring\nsycophantic responses.", "AI": {"tldr": "AI assistants finetuned with human feedback often exhibit sycophancy, preferring user-belief-matching responses over truthful ones, influenced by human preference judgments.", "motivation": "To investigate the prevalence of sycophancy in AI assistants finetuned with human feedback and the role of human preferences in this behavior.", "method": "Analyzed five state-of-the-art AI assistants across four tasks and examined human preference data to assess sycophantic tendencies.", "result": "AI assistants consistently showed sycophancy, with human and preference models favoring sycophantic responses over truthful ones.", "conclusion": "Sycophancy is a general behavior in AI assistants, likely driven by human preferences favoring such responses."}}
{"id": "2505.07165", "pdf": "https://arxiv.org/pdf/2505.07165", "abs": "https://arxiv.org/abs/2505.07165", "authors": ["Jun Li", "Hongzhang Zhu", "Tao Chen", "Xiaohua Qian"], "title": "Generalizable Pancreas Segmentation via a Dual Self-Supervised Learning Framework", "categories": ["cs.CV"], "comment": "accept by IEEE JBHI. Due to the limitation \"The abstract field cannot\n  be longer than 1,920 characters\", the abstract here is shorter than that in\n  the PDF file", "summary": "Recently, numerous pancreas segmentation methods have achieved promising\nperformance on local single-source datasets. However, these methods don't\nadequately account for generalizability issues, and hence typically show\nlimited performance and low stability on test data from other sources.\nConsidering the limited availability of distinct data sources, we seek to\nimprove the generalization performance of a pancreas segmentation model trained\nwith a single-source dataset, i.e., the single source generalization task. In\nparticular, we propose a dual self-supervised learning model that incorporates\nboth global and local anatomical contexts. Our model aims to fully exploit the\nanatomical features of the intra-pancreatic and extra-pancreatic regions, and\nhence enhance the characterization of the high-uncertainty regions for more\nrobust generalization. Specifically, we first construct a global-feature\ncontrastive self-supervised learning module that is guided by the pancreatic\nspatial structure. This module obtains complete and consistent pancreatic\nfeatures through promoting intra-class cohesion, and also extracts more\ndiscriminative features for differentiating between pancreatic and\nnon-pancreatic tissues through maximizing inter-class separation. It mitigates\nthe influence of surrounding tissue on the segmentation outcomes in\nhigh-uncertainty regions. Subsequently, a local-image restoration\nself-supervised learning module is introduced to further enhance the\ncharacterization of the high uncertainty regions. In this module, informative\nanatomical contexts are actually learned to recover randomly corrupted\nappearance patterns in those regions.", "AI": {"tldr": "A dual self-supervised learning model improves pancreas segmentation generalization by leveraging global and local anatomical contexts.", "motivation": "Existing pancreas segmentation methods lack generalizability across datasets. The goal is to enhance performance on single-source datasets for broader applicability.", "method": "Proposes a dual self-supervised learning model: (1) global-feature contrastive learning for pancreatic structure, and (2) local-image restoration for high-uncertainty regions.", "result": "The model enhances feature discrimination and robustness in high-uncertainty regions, improving generalization.", "conclusion": "The dual self-supervised approach effectively addresses generalization challenges in pancreas segmentation."}}
{"id": "2505.06493", "pdf": "https://arxiv.org/pdf/2505.06493", "abs": "https://arxiv.org/abs/2505.06493", "authors": ["Jiawei Guo", "Haipeng Cai"], "title": "System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have gained widespread adoption across diverse\napplications due to their impressive generative capabilities. Their\nplug-and-play nature enables both developers and end users to interact with\nthese models through simple prompts. However, as LLMs become more integrated\ninto various systems in diverse domains, concerns around their security are\ngrowing. Existing studies mainly focus on threats arising from user prompts\n(e.g. prompt injection attack) and model output (e.g. model inversion attack),\nwhile the security of system prompts remains largely overlooked. This work\nbridges the critical gap. We introduce system prompt poisoning, a new attack\nvector against LLMs that, unlike traditional user prompt injection, poisons\nsystem prompts hence persistently impacts all subsequent user interactions and\nmodel responses. We systematically investigate four practical attack strategies\nin various poisoning scenarios. Through demonstration on both generative and\nreasoning LLMs, we show that system prompt poisoning is highly feasible without\nrequiring jailbreak techniques, and effective across a wide range of tasks,\nincluding those in mathematics, coding, logical reasoning, and natural language\nprocessing. Importantly, our findings reveal that the attack remains effective\neven when user prompts employ advanced prompting techniques like\nchain-of-thought (CoT). We also show that such techniques, including CoT and\nretrieval-augmentation-generation (RAG), which are proven to be effective for\nimproving LLM performance in a wide range of tasks, are significantly weakened\nin their effectiveness by system prompt poisoning.", "AI": {"tldr": "The paper introduces 'system prompt poisoning,' a new attack vector for LLMs, showing its feasibility and impact across tasks, even with advanced prompting techniques.", "motivation": "Addressing the overlooked security of system prompts in LLMs, which persistently affects all user interactions.", "method": "Investigates four practical attack strategies in poisoning scenarios, demonstrated on generative and reasoning LLMs.", "result": "System prompt poisoning is highly feasible, effective across tasks, and weakens advanced techniques like CoT and RAG.", "conclusion": "Highlights the critical need to secure system prompts in LLMs against poisoning attacks."}}
{"id": "2505.06835", "pdf": "https://arxiv.org/pdf/2505.06835", "abs": "https://arxiv.org/abs/2505.06835", "authors": ["Khai Nguyen"], "title": "Streaming Sliced Optimal Transport", "categories": ["cs.LG", "stat.CO", "stat.ME", "stat.ML"], "comment": "28 pages, 9 figures, 3 tables", "summary": "Sliced optimal transport (SOT) or sliced Wasserstein (SW) distance is widely\nrecognized for its statistical and computational scalability. In this work, we\nfurther enhance the computational scalability by proposing the first method for\ncomputing SW from sample streams, called \\emph{streaming sliced Wasserstein}\n(Stream-SW). To define Stream-SW, we first introduce the streaming computation\nof the one-dimensional Wasserstein distance. Since the one-dimensional\nWasserstein (1DW) distance has a closed-form expression, given by the absolute\ndifference between the quantile functions of the compared distributions, we\nleverage quantile approximation techniques for sample streams to define the\nstreaming 1DW distance. By applying streaming 1DW to all projections, we obtain\nStream-SW. The key advantage of Stream-SW is its low memory complexity while\nproviding theoretical guarantees on the approximation error. We demonstrate\nthat Stream-SW achieves a more accurate approximation of SW than random\nsubsampling, with lower memory consumption, in comparing Gaussian distributions\nand mixtures of Gaussians from streaming samples. Additionally, we conduct\nexperiments on point cloud classification, point cloud gradient flows, and\nstreaming change point detection to further highlight the favorable performance\nof Stream-SW.", "AI": {"tldr": "Stream-SW is a method for computing sliced Wasserstein distance from sample streams, offering low memory complexity and accurate approximations.", "motivation": "To enhance computational scalability of sliced Wasserstein distance for streaming data.", "method": "Leverages quantile approximation for streaming one-dimensional Wasserstein distance, extending it to sliced Wasserstein via projections.", "result": "Stream-SW outperforms random subsampling in accuracy and memory efficiency for Gaussian distributions and mixtures.", "conclusion": "Stream-SW is effective for applications like point cloud classification and change point detection, with theoretical guarantees."}}
{"id": "2312.11805", "pdf": "https://arxiv.org/pdf/2312.11805", "abs": "https://arxiv.org/abs/2312.11805", "authors": ["Gemini Team", "Rohan Anil", "Sebastian Borgeaud", "Jean-Baptiste Alayrac", "Jiahui Yu", "Radu Soricut", "Johan Schalkwyk", "Andrew M. Dai", "Anja Hauth", "Katie Millican", "David Silver", "Melvin Johnson", "Ioannis Antonoglou", "Julian Schrittwieser", "Amelia Glaese", "Jilin Chen", "Emily Pitler", "Timothy Lillicrap", "Angeliki Lazaridou", "Orhan Firat", "James Molloy", "Michael Isard", "Paul R. Barham", "Tom Hennigan", "Benjamin Lee", "Fabio Viola", "Malcolm Reynolds", "Yuanzhong Xu", "Ryan Doherty", "Eli Collins", "Clemens Meyer", "Eliza Rutherford", "Erica Moreira", "Kareem Ayoub", "Megha Goel", "Jack Krawczyk", "Cosmo Du", "Ed Chi", "Heng-Tze Cheng", "Eric Ni", "Purvi Shah", "Patrick Kane", "Betty Chan", "Manaal Faruqui", "Aliaksei Severyn", "Hanzhao Lin", "YaGuang Li", "Yong Cheng", "Abe Ittycheriah", "Mahdis Mahdieh", "Mia Chen", "Pei Sun", "Dustin Tran", "Sumit Bagri", "Balaji Lakshminarayanan", "Jeremiah Liu", "Andras Orban", "Fabian G\u00fcra", "Hao Zhou", "Xinying Song", "Aurelien Boffy", "Harish Ganapathy", "Steven Zheng", "HyunJeong Choe", "\u00c1goston Weisz", "Tao Zhu", "Yifeng Lu", "Siddharth Gopal", "Jarrod Kahn", "Maciej Kula", "Jeff Pitman", "Rushin Shah", "Emanuel Taropa", "Majd Al Merey", "Martin Baeuml", "Zhifeng Chen", "Laurent El Shafey", "Yujing Zhang", "Olcan Sercinoglu", "George Tucker", "Enrique Piqueras", "Maxim Krikun", "Iain Barr", "Nikolay Savinov", "Ivo Danihelka", "Becca Roelofs", "Ana\u00efs White", "Anders Andreassen", "Tamara von Glehn", "Lakshman Yagati", "Mehran Kazemi", "Lucas Gonzalez", "Misha Khalman", "Jakub Sygnowski", "Alexandre Frechette", "Charlotte Smith", "Laura Culp", "Lev Proleev", "Yi Luan", "Xi Chen", "James Lottes", "Nathan Schucher", "Federico Lebron", "Alban Rrustemi", "Natalie Clay", "Phil Crone", "Tomas Kocisky", "Jeffrey Zhao", "Bartek Perz", "Dian Yu", "Heidi Howard", "Adam Bloniarz", "Jack W. Rae", "Han Lu", "Laurent Sifre", "Marcello Maggioni", "Fred Alcober", "Dan Garrette", "Megan Barnes", "Shantanu Thakoor", "Jacob Austin", "Gabriel Barth-Maron", "William Wong", "Rishabh Joshi", "Rahma Chaabouni", "Deeni Fatiha", "Arun Ahuja", "Gaurav Singh Tomar", "Evan Senter", "Martin Chadwick", "Ilya Kornakov", "Nithya Attaluri", "I\u00f1aki Iturrate", "Ruibo Liu", "Yunxuan Li", "Sarah Cogan", "Jeremy Chen", "Chao Jia", "Chenjie Gu", "Qiao Zhang", "Jordan Grimstad", "Ale Jakse Hartman", "Xavier Garcia", "Thanumalayan Sankaranarayana Pillai", "Jacob Devlin", "Michael Laskin", "Diego de Las Casas", "Dasha Valter", "Connie Tao", "Lorenzo Blanco", "Adri\u00e0 Puigdom\u00e8nech Badia", "David Reitter", "Mianna Chen", "Jenny Brennan", "Clara Rivera", "Sergey Brin", "Shariq Iqbal", "Gabriela Surita", "Jane Labanowski", "Abhi Rao", "Stephanie Winkler", "Emilio Parisotto", "Yiming Gu", "Kate Olszewska", "Ravi Addanki", "Antoine Miech", "Annie Louis", "Denis Teplyashin", "Geoff Brown", "Elliot Catt", "Jan Balaguer", "Jackie Xiang", "Pidong Wang", "Zoe Ashwood", "Anton Briukhov", "Albert Webson", "Sanjay Ganapathy", "Smit Sanghavi", "Ajay Kannan", "Ming-Wei Chang", "Axel Stjerngren", "Josip Djolonga", "Yuting Sun", "Ankur Bapna", "Matthew Aitchison", "Pedram Pejman", "Henryk Michalewski", "Tianhe Yu", "Cindy Wang", "Juliette Love", "Junwhan Ahn", "Dawn Bloxwich", "Kehang Han", "Peter Humphreys", "Thibault Sellam", "James Bradbury", "Varun Godbole", "Sina Samangooei", "Bogdan Damoc", "Alex Kaskasoli", "S\u00e9bastien M. R. Arnold", "Vijay Vasudevan", "Shubham Agrawal", "Jason Riesa", "Dmitry Lepikhin", "Richard Tanburn", "Srivatsan Srinivasan", "Hyeontaek Lim", "Sarah Hodkinson", "Pranav Shyam", "Johan Ferret", "Steven Hand", "Ankush Garg", "Tom Le Paine", "Jian Li", "Yujia Li", "Minh Giang", "Alexander Neitz", "Zaheer Abbas", "Sarah York", "Machel Reid", "Elizabeth Cole", "Aakanksha Chowdhery", "Dipanjan Das", "Dominika Rogozi\u0144ska", "Vitaliy Nikolaev", "Pablo Sprechmann", "Zachary Nado", "Lukas Zilka", "Flavien Prost", "Luheng He", "Marianne Monteiro", "Gaurav Mishra", "Chris Welty", "Josh Newlan", "Dawei Jia", "Miltiadis Allamanis", "Clara Huiyi Hu", "Raoul de Liedekerke", "Justin Gilmer", "Carl Saroufim", "Shruti Rijhwani", "Shaobo Hou", "Disha Shrivastava", "Anirudh Baddepudi", "Alex Goldin", "Adnan Ozturel", "Albin Cassirer", "Yunhan Xu", "Daniel Sohn", "Devendra Sachan", "Reinald Kim Amplayo", "Craig Swanson", "Dessie Petrova", "Shashi Narayan", "Arthur Guez", "Siddhartha Brahma", "Jessica Landon", "Miteyan Patel", "Ruizhe Zhao", "Kevin Villela", "Luyu Wang", "Wenhao Jia", "Matthew Rahtz", "Mai Gim\u00e9nez", "Legg Yeung", "James Keeling", "Petko Georgiev", "Diana Mincu", "Boxi Wu", "Salem Haykal", "Rachel Saputro", "Kiran Vodrahalli", "James Qin", "Zeynep Cankara", "Abhanshu Sharma", "Nick Fernando", "Will Hawkins", "Behnam Neyshabur", "Solomon Kim", "Adrian Hutter", "Priyanka Agrawal", "Alex Castro-Ros", "George van den Driessche", "Tao Wang", "Fan Yang", "Shuo-yiin Chang", "Paul Komarek", "Ross McIlroy", "Mario Lu\u010di\u0107", "Guodong Zhang", "Wael Farhan", "Michael Sharman", "Paul Natsev", "Paul Michel", "Yamini Bansal", "Siyuan Qiao", "Kris Cao", "Siamak Shakeri", "Christina Butterfield", "Justin Chung", "Paul Kishan Rubenstein", "Shivani Agrawal", "Arthur Mensch", "Kedar Soparkar", "Karel Lenc", "Timothy Chung", "Aedan Pope", "Loren Maggiore", "Jackie Kay", "Priya Jhakra", "Shibo Wang", "Joshua Maynez", "Mary Phuong", "Taylor Tobin", "Andrea Tacchetti", "Maja Trebacz", "Kevin Robinson", "Yash Katariya", "Sebastian Riedel", "Paige Bailey", "Kefan Xiao", "Nimesh Ghelani", "Lora Aroyo", "Ambrose Slone", "Neil Houlsby", "Xuehan Xiong", "Zhen Yang", "Elena Gribovskaya", "Jonas Adler", "Mateo Wirth", "Lisa Lee", "Music Li", "Thais Kagohara", "Jay Pavagadhi", "Sophie Bridgers", "Anna Bortsova", "Sanjay Ghemawat", "Zafarali Ahmed", "Tianqi Liu", "Richard Powell", "Vijay Bolina", "Mariko Iinuma", "Polina Zablotskaia", "James Besley", "Da-Woon Chung", "Timothy Dozat", "Ramona Comanescu", "Xiance Si", "Jeremy Greer", "Guolong Su", "Martin Polacek", "Rapha\u00ebl Lopez Kaufman", "Simon Tokumine", "Hexiang Hu", "Elena Buchatskaya", "Yingjie Miao", "Mohamed Elhawaty", "Aditya Siddhant", "Nenad Tomasev", "Jinwei Xing", "Christina Greer", "Helen Miller", "Shereen Ashraf", "Aurko Roy", "Zizhao Zhang", "Ada Ma", "Angelos Filos", "Milos Besta", "Rory Blevins", "Ted Klimenko", "Chih-Kuan Yeh", "Soravit Changpinyo", "Jiaqi Mu", "Oscar Chang", "Mantas Pajarskas", "Carrie Muir", "Vered Cohen", "Charline Le Lan", "Krishna Haridasan", "Amit Marathe", "Steven Hansen", "Sholto Douglas", "Rajkumar Samuel", "Mingqiu Wang", "Sophia Austin", "Chang Lan", "Jiepu Jiang", "Justin Chiu", "Jaime Alonso Lorenzo", "Lars Lowe Sj\u00f6sund", "S\u00e9bastien Cevey", "Zach Gleicher", "Thi Avrahami", "Anudhyan Boral", "Hansa Srinivasan", "Vittorio Selo", "Rhys May", "Konstantinos Aisopos", "L\u00e9onard Hussenot", "Livio Baldini Soares", "Kate Baumli", "Michael B. Chang", "Adri\u00e0 Recasens", "Ben Caine", "Alexander Pritzel", "Filip Pavetic", "Fabio Pardo", "Anita Gergely", "Justin Frye", "Vinay Ramasesh", "Dan Horgan", "Kartikeya Badola", "Nora Kassner", "Subhrajit Roy", "Ethan Dyer", "V\u00edctor Campos Campos", "Alex Tomala", "Yunhao Tang", "Dalia El Badawy", "Elspeth White", "Basil Mustafa", "Oran Lang", "Abhishek Jindal", "Sharad Vikram", "Zhitao Gong", "Sergi Caelles", "Ross Hemsley", "Gregory Thornton", "Fangxiaoyu Feng", "Wojciech Stokowiec", "Ce Zheng", "Phoebe Thacker", "\u00c7a\u011flar \u00dcnl\u00fc", "Zhishuai Zhang", "Mohammad Saleh", "James Svensson", "Max Bileschi", "Piyush Patil", "Ankesh Anand", "Roman Ring", "Katerina Tsihlas", "Arpi Vezer", "Marco Selvi", "Toby Shevlane", "Mikel Rodriguez", "Tom Kwiatkowski", "Samira Daruki", "Keran Rong", "Allan Dafoe", "Nicholas FitzGerald", "Keren Gu-Lemberg", "Mina Khan", "Lisa Anne Hendricks", "Marie Pellat", "Vladimir Feinberg", "James Cobon-Kerr", "Tara Sainath", "Maribeth Rauh", "Sayed Hadi Hashemi", "Richard Ives", "Yana Hasson", "Eric Noland", "Yuan Cao", "Nathan Byrd", "Le Hou", "Qingze Wang", "Thibault Sottiaux", "Michela Paganini", "Jean-Baptiste Lespiau", "Alexandre Moufarek", "Samer Hassan", "Kaushik Shivakumar", "Joost van Amersfoort", "Amol Mandhane", "Pratik Joshi", "Anirudh Goyal", "Matthew Tung", "Andrew Brock", "Hannah Sheahan", "Vedant Misra", "Cheng Li", "Nemanja Raki\u0107evi\u0107", "Mostafa Dehghani", "Fangyu Liu", "Sid Mittal", "Junhyuk Oh", "Seb Noury", "Eren Sezener", "Fantine Huot", "Matthew Lamm", "Nicola De Cao", "Charlie Chen", "Sidharth Mudgal", "Romina Stella", "Kevin Brooks", "Gautam Vasudevan", "Chenxi Liu", "Mainak Chain", "Nivedita Melinkeri", "Aaron Cohen", "Venus Wang", "Kristie Seymore", "Sergey Zubkov", "Rahul Goel", "Summer Yue", "Sai Krishnakumaran", "Brian Albert", "Nate Hurley", "Motoki Sano", "Anhad Mohananey", "Jonah Joughin", "Egor Filonov", "Tomasz K\u0119pa", "Yomna Eldawy", "Jiawern Lim", "Rahul Rishi", "Shirin Badiezadegan", "Taylor Bos", "Jerry Chang", "Sanil Jain", "Sri Gayatri Sundara Padmanabhan", "Subha Puttagunta", "Kalpesh Krishna", "Leslie Baker", "Norbert Kalb", "Vamsi Bedapudi", "Adam Kurzrok", "Shuntong Lei", "Anthony Yu", "Oren Litvin", "Xiang Zhou", "Zhichun Wu", "Sam Sobell", "Andrea Siciliano", "Alan Papir", "Robby Neale", "Jonas Bragagnolo", "Tej Toor", "Tina Chen", "Valentin Anklin", "Feiran Wang", "Richie Feng", "Milad Gholami", "Kevin Ling", "Lijuan Liu", "Jules Walter", "Hamid Moghaddam", "Arun Kishore", "Jakub Adamek", "Tyler Mercado", "Jonathan Mallinson", "Siddhinita Wandekar", "Stephen Cagle", "Eran Ofek", "Guillermo Garrido", "Clemens Lombriser", "Maksim Mukha", "Botu Sun", "Hafeezul Rahman Mohammad", "Josip Matak", "Yadi Qian", "Vikas Peswani", "Pawel Janus", "Quan Yuan", "Leif Schelin", "Oana David", "Ankur Garg", "Yifan He", "Oleksii Duzhyi", "Anton \u00c4lgmyr", "Timoth\u00e9e Lottaz", "Qi Li", "Vikas Yadav", "Luyao Xu", "Alex Chinien", "Rakesh Shivanna", "Aleksandr Chuklin", "Josie Li", "Carrie Spadine", "Travis Wolfe", "Kareem Mohamed", "Subhabrata Das", "Zihang Dai", "Kyle He", "Daniel von Dincklage", "Shyam Upadhyay", "Akanksha Maurya", "Luyan Chi", "Sebastian Krause", "Khalid Salama", "Pam G Rabinovitch", "Pavan Kumar Reddy M", "Aarush Selvan", "Mikhail Dektiarev", "Golnaz Ghiasi", "Erdem Guven", "Himanshu Gupta", "Boyi Liu", "Deepak Sharma", "Idan Heimlich Shtacher", "Shachi Paul", "Oscar Akerlund", "Fran\u00e7ois-Xavier Aubet", "Terry Huang", "Chen Zhu", "Eric Zhu", "Elico Teixeira", "Matthew Fritze", "Francesco Bertolini", "Liana-Eleonora Marinescu", "Martin B\u00f6lle", "Dominik Paulus", "Khyatti Gupta", "Tejasi Latkar", "Max Chang", "Jason Sanders", "Roopa Wilson", "Xuewei Wu", "Yi-Xuan Tan", "Lam Nguyen Thiet", "Tulsee Doshi", "Sid Lall", "Swaroop Mishra", "Wanming Chen", "Thang Luong", "Seth Benjamin", "Jasmine Lee", "Ewa Andrejczuk", "Dominik Rabiej", "Vipul Ranjan", "Krzysztof Styrc", "Pengcheng Yin", "Jon Simon", "Malcolm Rose Harriott", "Mudit Bansal", "Alexei Robsky", "Geoff Bacon", "David Greene", "Daniil Mirylenka", "Chen Zhou", "Obaid Sarvana", "Abhimanyu Goyal", "Samuel Andermatt", "Patrick Siegler", "Ben Horn", "Assaf Israel", "Francesco Pongetti", "Chih-Wei \"Louis\" Chen", "Marco Selvatici", "Pedro Silva", "Kathie Wang", "Jackson Tolins", "Kelvin Guu", "Roey Yogev", "Xiaochen Cai", "Alessandro Agostini", "Maulik Shah", "Hung Nguyen", "Noah \u00d3 Donnaile", "S\u00e9bastien Pereira", "Linda Friso", "Adam Stambler", "Adam Kurzrok", "Chenkai Kuang", "Yan Romanikhin", "Mark Geller", "ZJ Yan", "Kane Jang", "Cheng-Chun Lee", "Wojciech Fica", "Eric Malmi", "Qijun Tan", "Dan Banica", "Daniel Balle", "Ryan Pham", "Yanping Huang", "Diana Avram", "Hongzhi Shi", "Jasjot Singh", "Chris Hidey", "Niharika Ahuja", "Pranab Saxena", "Dan Dooley", "Srividya Pranavi Potharaju", "Eileen O'Neill", "Anand Gokulchandran", "Ryan Foley", "Kai Zhao", "Mike Dusenberry", "Yuan Liu", "Pulkit Mehta", "Ragha Kotikalapudi", "Chalence Safranek-Shrader", "Andrew Goodman", "Joshua Kessinger", "Eran Globen", "Prateek Kolhar", "Chris Gorgolewski", "Ali Ibrahim", "Yang Song", "Ali Eichenbaum", "Thomas Brovelli", "Sahitya Potluri", "Preethi Lahoti", "Cip Baetu", "Ali Ghorbani", "Charles Chen", "Andy Crawford", "Shalini Pal", "Mukund Sridhar", "Petru Gurita", "Asier Mujika", "Igor Petrovski", "Pierre-Louis Cedoz", "Chenmei Li", "Shiyuan Chen", "Niccol\u00f2 Dal Santo", "Siddharth Goyal", "Jitesh Punjabi", "Karthik Kappaganthu", "Chester Kwak", "Pallavi LV", "Sarmishta Velury", "Himadri Choudhury", "Jamie Hall", "Premal Shah", "Ricardo Figueira", "Matt Thomas", "Minjie Lu", "Ting Zhou", "Chintu Kumar", "Thomas Jurdi", "Sharat Chikkerur", "Yenai Ma", "Adams Yu", "Soo Kwak", "Victor \u00c4hdel", "Sujeevan Rajayogam", "Travis Choma", "Fei Liu", "Aditya Barua", "Colin Ji", "Ji Ho Park", "Vincent Hellendoorn", "Alex Bailey", "Taylan Bilal", "Huanjie Zhou", "Mehrdad Khatir", "Charles Sutton", "Wojciech Rzadkowski", "Fiona Macintosh", "Roopali Vij", "Konstantin Shagin", "Paul Medina", "Chen Liang", "Jinjing Zhou", "Pararth Shah", "Yingying Bi", "Attila Dankovics", "Shipra Banga", "Sabine Lehmann", "Marissa Bredesen", "Zifan Lin", "John Eric Hoffmann", "Jonathan Lai", "Raynald Chung", "Kai Yang", "Nihal Balani", "Arthur Bra\u017einskas", "Andrei Sozanschi", "Matthew Hayes", "H\u00e9ctor Fern\u00e1ndez Alcalde", "Peter Makarov", "Will Chen", "Antonio Stella", "Liselotte Snijders", "Michael Mandl", "Ante K\u00e4rrman", "Pawe\u0142 Nowak", "Xinyi Wu", "Alex Dyck", "Krishnan Vaidyanathan", "Raghavender R", "Jessica Mallet", "Mitch Rudominer", "Eric Johnston", "Sushil Mittal", "Akhil Udathu", "Janara Christensen", "Vishal Verma", "Zach Irving", "Andreas Santucci", "Gamaleldin Elsayed", "Elnaz Davoodi", "Marin Georgiev", "Ian Tenney", "Nan Hua", "Geoffrey Cideron", "Edouard Leurent", "Mahmoud Alnahlawi", "Ionut Georgescu", "Nan Wei", "Ivy Zheng", "Dylan Scandinaro", "Heinrich Jiang", "Jasper Snoek", "Mukund Sundararajan", "Xuezhi Wang", "Zack Ontiveros", "Itay Karo", "Jeremy Cole", "Vinu Rajashekhar", "Lara Tumeh", "Eyal Ben-David", "Rishub Jain", "Jonathan Uesato", "Romina Datta", "Oskar Bunyan", "Shimu Wu", "John Zhang", "Piotr Stanczyk", "Ye Zhang", "David Steiner", "Subhajit Naskar", "Michael Azzam", "Matthew Johnson", "Adam Paszke", "Chung-Cheng Chiu", "Jaume Sanchez Elias", "Afroz Mohiuddin", "Faizan Muhammad", "Jin Miao", "Andrew Lee", "Nino Vieillard", "Jane Park", "Jiageng Zhang", "Jeff Stanway", "Drew Garmon", "Abhijit Karmarkar", "Zhe Dong", "Jong Lee", "Aviral Kumar", "Luowei Zhou", "Jonathan Evens", "William Isaac", "Geoffrey Irving", "Edward Loper", "Michael Fink", "Isha Arkatkar", "Nanxin Chen", "Izhak Shafran", "Ivan Petrychenko", "Zhe Chen", "Johnson Jia", "Anselm Levskaya", "Zhenkai Zhu", "Peter Grabowski", "Yu Mao", "Alberto Magni", "Kaisheng Yao", "Javier Snaider", "Norman Casagrande", "Evan Palmer", "Paul Suganthan", "Alfonso Casta\u00f1o", "Irene Giannoumis", "Wooyeol Kim", "Miko\u0142aj Rybi\u0144ski", "Ashwin Sreevatsa", "Jennifer Prendki", "David Soergel", "Adrian Goedeckemeyer", "Willi Gierke", "Mohsen Jafari", "Meenu Gaba", "Jeremy Wiesner", "Diana Gage Wright", "Yawen Wei", "Harsha Vashisht", "Yana Kulizhskaya", "Jay Hoover", "Maigo Le", "Lu Li", "Chimezie Iwuanyanwu", "Lu Liu", "Kevin Ramirez", "Andrey Khorlin", "Albert Cui", "Tian LIN", "Marcus Wu", "Ricardo Aguilar", "Keith Pallo", "Abhishek Chakladar", "Ginger Perng", "Elena Allica Abellan", "Mingyang Zhang", "Ishita Dasgupta", "Nate Kushman", "Ivo Penchev", "Alena Repina", "Xihui Wu", "Tom van der Weide", "Priya Ponnapalli", "Caroline Kaplan", "Jiri Simsa", "Shuangfeng Li", "Olivier Dousse", "Fan Yang", "Jeff Piper", "Nathan Ie", "Rama Pasumarthi", "Nathan Lintz", "Anitha Vijayakumar", "Daniel Andor", "Pedro Valenzuela", "Minnie Lui", "Cosmin Paduraru", "Daiyi Peng", "Katherine Lee", "Shuyuan Zhang", "Somer Greene", "Duc Dung Nguyen", "Paula Kurylowicz", "Cassidy Hardin", "Lucas Dixon", "Lili Janzer", "Kiam Choo", "Ziqiang Feng", "Biao Zhang", "Achintya Singhal", "Dayou Du", "Dan McKinnon", "Natasha Antropova", "Tolga Bolukbasi", "Orgad Keller", "David Reid", "Daniel Finchelstein", "Maria Abi Raad", "Remi Crocker", "Peter Hawkins", "Robert Dadashi", "Colin Gaffney", "Ken Franko", "Anna Bulanova", "R\u00e9mi Leblond", "Shirley Chung", "Harry Askham", "Luis C. Cobo", "Kelvin Xu", "Felix Fischer", "Jun Xu", "Christina Sorokin", "Chris Alberti", "Chu-Cheng Lin", "Colin Evans", "Alek Dimitriev", "Hannah Forbes", "Dylan Banarse", "Zora Tung", "Mark Omernick", "Colton Bishop", "Rachel Sterneck", "Rohan Jain", "Jiawei Xia", "Ehsan Amid", "Francesco Piccinno", "Xingyu Wang", "Praseem Banzal", "Daniel J. Mankowitz", "Alex Polozov", "Victoria Krakovna", "Sasha Brown", "MohammadHossein Bateni", "Dennis Duan", "Vlad Firoiu", "Meghana Thotakuri", "Tom Natan", "Matthieu Geist", "Ser tan Girgin", "Hui Li", "Jiayu Ye", "Ofir Roval", "Reiko Tojo", "Michael Kwong", "James Lee-Thorp", "Christopher Yew", "Danila Sinopalnikov", "Sabela Ramos", "John Mellor", "Abhishek Sharma", "Kathy Wu", "David Miller", "Nicolas Sonnerat", "Denis Vnukov", "Rory Greig", "Jennifer Beattie", "Emily Caveness", "Libin Bai", "Julian Eisenschlos", "Alex Korchemniy", "Tomy Tsai", "Mimi Jasarevic", "Weize Kong", "Phuong Dao", "Zeyu Zheng", "Frederick Liu", "Fan Yang", "Rui Zhu", "Tian Huey Teh", "Jason Sanmiya", "Evgeny Gladchenko", "Nejc Trdin", "Daniel Toyama", "Evan Rosen", "Sasan Tavakkol", "Linting Xue", "Chen Elkind", "Oliver Woodman", "John Carpenter", "George Papamakarios", "Rupert Kemp", "Sushant Kafle", "Tanya Grunina", "Rishika Sinha", "Alice Talbert", "Diane Wu", "Denese Owusu-Afriyie", "Cosmo Du", "Chloe Thornton", "Jordi Pont-Tuset", "Pradyumna Narayana", "Jing Li", "Saaber Fatehi", "John Wieting", "Omar Ajmeri", "Benigno Uria", "Yeongil Ko", "Laura Knight", "Am\u00e9lie H\u00e9liou", "Ning Niu", "Shane Gu", "Chenxi Pang", "Yeqing Li", "Nir Levine", "Ariel Stolovich", "Rebeca Santamaria-Fernandez", "Sonam Goenka", "Wenny Yustalim", "Robin Strudel", "Ali Elqursh", "Charlie Deck", "Hyo Lee", "Zonglin Li", "Kyle Levin", "Raphael Hoffmann", "Dan Holtmann-Rice", "Olivier Bachem", "Sho Arora", "Christy Koh", "Soheil Hassas Yeganeh", "Siim P\u00f5der", "Mukarram Tariq", "Yanhua Sun", "Lucian Ionita", "Mojtaba Seyedhosseini", "Pouya Tafti", "Zhiyu Liu", "Anmol Gulati", "Jasmine Liu", "Xinyu Ye", "Bart Chrzaszcz", "Lily Wang", "Nikhil Sethi", "Tianrun Li", "Ben Brown", "Shreya Singh", "Wei Fan", "Aaron Parisi", "Joe Stanton", "Vinod Koverkathu", "Christopher A. Choquette-Choo", "Yunjie Li", "TJ Lu", "Abe Ittycheriah", "Prakash Shroff", "Mani Varadarajan", "Sanaz Bahargam", "Rob Willoughby", "David Gaddy", "Guillaume Desjardins", "Marco Cornero", "Brona Robenek", "Bhavishya Mittal", "Ben Albrecht", "Ashish Shenoy", "Fedor Moiseev", "Henrik Jacobsson", "Alireza Ghaffarkhah", "Morgane Rivi\u00e8re", "Alanna Walton", "Cl\u00e9ment Crepy", "Alicia Parrish", "Zongwei Zhou", "Clement Farabet", "Carey Radebaugh", "Praveen Srinivasan", "Claudia van der Salm", "Andreas Fidjeland", "Salvatore Scellato", "Eri Latorre-Chimoto", "Hanna Klimczak-Pluci\u0144ska", "David Bridson", "Dario de Cesare", "Tom Hudson", "Piermaria Mendolicchio", "Lexi Walker", "Alex Morris", "Matthew Mauger", "Alexey Guseynov", "Alison Reid", "Seth Odoom", "Lucia Loher", "Victor Cotruta", "Madhavi Yenugula", "Dominik Grewe", "Anastasia Petrushkina", "Tom Duerig", "Antonio Sanchez", "Steve Yadlowsky", "Amy Shen", "Amir Globerson", "Lynette Webb", "Sahil Dua", "Dong Li", "Surya Bhupatiraju", "Dan Hurt", "Haroon Qureshi", "Ananth Agarwal", "Tomer Shani", "Matan Eyal", "Anuj Khare", "Shreyas Rammohan Belle", "Lei Wang", "Chetan Tekur", "Mihir Sanjay Kale", "Jinliang Wei", "Ruoxin Sang", "Brennan Saeta", "Tyler Liechty", "Yi Sun", "Yao Zhao", "Stephan Lee", "Pandu Nayak", "Doug Fritz", "Manish Reddy Vuyyuru", "John Aslanides", "Nidhi Vyas", "Martin Wicke", "Xiao Ma", "Evgenii Eltyshev", "Nina Martin", "Hardie Cate", "James Manyika", "Keyvan Amiri", "Yelin Kim", "Xi Xiong", "Kai Kang", "Florian Luisier", "Nilesh Tripuraneni", "David Madras", "Mandy Guo", "Austin Waters", "Oliver Wang", "Joshua Ainslie", "Jason Baldridge", "Han Zhang", "Garima Pruthi", "Jakob Bauer", "Feng Yang", "Riham Mansour", "Jason Gelman", "Yang Xu", "George Polovets", "Ji Liu", "Honglong Cai", "Warren Chen", "XiangHai Sheng", "Emily Xue", "Sherjil Ozair", "Christof Angermueller", "Xiaowei Li", "Anoop Sinha", "Weiren Wang", "Julia Wiesinger", "Emmanouil Koukoumidis", "Yuan Tian", "Anand Iyer", "Madhu Gurumurthy", "Mark Goldenson", "Parashar Shah", "MK Blake", "Hongkun Yu", "Anthony Urbanowicz", "Jennimaria Palomaki", "Chrisantha Fernando", "Ken Durden", "Harsh Mehta", "Nikola Momchev", "Elahe Rahimtoroghi", "Maria Georgaki", "Amit Raul", "Sebastian Ruder", "Morgan Redshaw", "Jinhyuk Lee", "Denny Zhou", "Komal Jalan", "Dinghua Li", "Blake Hechtman", "Parker Schuh", "Milad Nasr", "Kieran Milan", "Vladimir Mikulik", "Juliana Franco", "Tim Green", "Nam Nguyen", "Joe Kelley", "Aroma Mahendru", "Andrea Hu", "Joshua Howland", "Ben Vargas", "Jeffrey Hui", "Kshitij Bansal", "Vikram Rao", "Rakesh Ghiya", "Emma Wang", "Ke Ye", "Jean Michel Sarr", "Melanie Moranski Preston", "Madeleine Elish", "Steve Li", "Aakash Kaku", "Jigar Gupta", "Ice Pasupat", "Da-Cheng Juan", "Milan Someswar", "Tejvi M.", "Xinyun Chen", "Aida Amini", "Alex Fabrikant", "Eric Chu", "Xuanyi Dong", "Amruta Muthal", "Senaka Buthpitiya", "Sarthak Jauhari", "Nan Hua", "Urvashi Khandelwal", "Ayal Hitron", "Jie Ren", "Larissa Rinaldi", "Shahar Drath", "Avigail Dabush", "Nan-Jiang Jiang", "Harshal Godhia", "Uli Sachs", "Anthony Chen", "Yicheng Fan", "Hagai Taitelbaum", "Hila Noga", "Zhuyun Dai", "James Wang", "Chen Liang", "Jenny Hamer", "Chun-Sung Ferng", "Chenel Elkind", "Aviel Atias", "Paulina Lee", "V\u00edt List\u00edk", "Mathias Carlen", "Jan van de Kerkhof", "Marcin Pikus", "Krunoslav Zaher", "Paul M\u00fcller", "Sasha Zykova", "Richard Stefanec", "Vitaly Gatsko", "Christoph Hirnschall", "Ashwin Sethi", "Xingyu Federico Xu", "Chetan Ahuja", "Beth Tsai", "Anca Stefanoiu", "Bo Feng", "Keshav Dhandhania", "Manish Katyal", "Akshay Gupta", "Atharva Parulekar", "Divya Pitta", "Jing Zhao", "Vivaan Bhatia", "Yashodha Bhavnani", "Omar Alhadlaq", "Xiaolin Li", "Peter Danenberg", "Dennis Tu", "Alex Pine", "Vera Filippova", "Abhipso Ghosh", "Ben Limonchik", "Bhargava Urala", "Chaitanya Krishna Lanka", "Derik Clive", "Yi Sun", "Edward Li", "Hao Wu", "Kevin Hongtongsak", "Ianna Li", "Kalind Thakkar", "Kuanysh Omarov", "Kushal Majmundar", "Michael Alverson", "Michael Kucharski", "Mohak Patel", "Mudit Jain", "Maksim Zabelin", "Paolo Pelagatti", "Rohan Kohli", "Saurabh Kumar", "Joseph Kim", "Swetha Sankar", "Vineet Shah", "Lakshmi Ramachandruni", "Xiangkai Zeng", "Ben Bariach", "Laura Weidinger", "Tu Vu", "Alek Andreev", "Antoine He", "Kevin Hui", "Sheleem Kashem", "Amar Subramanya", "Sissie Hsiao", "Demis Hassabis", "Koray Kavukcuoglu", "Adam Sadovsky", "Quoc Le", "Trevor Strohman", "Yonghui Wu", "Slav Petrov", "Jeffrey Dean", "Oriol Vinyals"], "title": "Gemini: A Family of Highly Capable Multimodal Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "This report introduces a new family of multimodal models, Gemini, that\nexhibit remarkable capabilities across image, audio, video, and text\nunderstanding. The Gemini family consists of Ultra, Pro, and Nano sizes,\nsuitable for applications ranging from complex reasoning tasks to on-device\nmemory-constrained use-cases. Evaluation on a broad range of benchmarks shows\nthat our most-capable Gemini Ultra model advances the state of the art in 30 of\n32 of these benchmarks - notably being the first model to achieve human-expert\nperformance on the well-studied exam benchmark MMLU, and improving the state of\nthe art in every one of the 20 multimodal benchmarks we examined. We believe\nthat the new capabilities of the Gemini family in cross-modal reasoning and\nlanguage understanding will enable a wide variety of use cases. We discuss our\napproach toward post-training and deploying Gemini models responsibly to users\nthrough services including Gemini, Gemini Advanced, Google AI Studio, and Cloud\nVertex AI.", "AI": {"tldr": "Gemini is a new multimodal model family (Ultra, Pro, Nano) excelling in image, audio, video, and text tasks, with Ultra setting state-of-the-art results in 30/32 benchmarks and achieving human-expert performance on MMLU.", "motivation": "To advance multimodal AI capabilities for diverse applications, from complex reasoning to on-device use.", "method": "Developed Gemini models (Ultra, Pro, Nano) and evaluated them on 32 benchmarks, including MMLU and 20 multimodal tasks.", "result": "Gemini Ultra outperforms in 30/32 benchmarks, achieves human-expert performance on MMLU, and leads in all 20 multimodal benchmarks.", "conclusion": "Gemini's cross-modal reasoning and language understanding enable broad applications, with responsible deployment via services like Gemini Advanced and Google AI Studio."}}
{"id": "2505.07172", "pdf": "https://arxiv.org/pdf/2505.07172", "abs": "https://arxiv.org/abs/2505.07172", "authors": ["Zexian Yang", "Dian Li", "Dayan Wu", "Gang Liu", "Weiping Wang"], "title": "Critique Before Thinking: Mitigating Hallucination through Rationale-Augmented Instruction Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Despite significant advancements in multimodal reasoning tasks, existing\nLarge Vision-Language Models (LVLMs) are prone to producing visually ungrounded\nresponses when interpreting associated images. In contrast, when humans embark\non learning new knowledge, they often rely on a set of fundamental pre-study\nprinciples: reviewing outlines to grasp core concepts, summarizing key points\nto guide their focus and enhance understanding. However, such preparatory\nactions are notably absent in the current instruction tuning processes. This\npaper presents Re-Critic, an easily scalable rationale-augmented framework\ndesigned to incorporate fundamental rules and chain-of-thought (CoT) as a\nbridge to enhance reasoning abilities. Specifically, Re-Critic develops a\nvisual rationale synthesizer that scalably augments raw instructions with\nrationale explanation. To probe more contextually grounded responses, Re-Critic\nemploys an in-context self-critic mechanism to select response pairs for\npreference tuning. Experiments demonstrate that models fine-tuned with our\nrationale-augmented dataset yield gains that extend beyond\nhallucination-specific tasks to broader multimodal reasoning tasks.", "AI": {"tldr": "Re-Critic is a scalable framework that enhances multimodal reasoning in LVLMs by incorporating visual rationale and self-critique, reducing visually ungrounded responses.", "motivation": "Current LVLMs lack preparatory learning principles like humans, leading to ungrounded responses. Re-Critic aims to bridge this gap.", "method": "Re-Critic uses a visual rationale synthesizer and in-context self-critic mechanism to augment instructions and select response pairs for tuning.", "result": "Models fine-tuned with Re-Critic show improved performance in hallucination-specific and broader multimodal reasoning tasks.", "conclusion": "Re-Critic effectively grounds LVLM responses by integrating human-like preparatory principles, enhancing reasoning capabilities."}}
{"id": "2505.06503", "pdf": "https://arxiv.org/pdf/2505.06503", "abs": "https://arxiv.org/abs/2505.06503", "authors": ["David Balaban"], "title": "Attention Mechanisms in Dynamical Systems: A Case Study with Predator-Prey Models", "categories": ["math.DS", "cs.AI", "es: 92B05 (Primary), 34C60, 37N25, 68T07, 93B30 (Secondary)"], "comment": "5 figures, 12 pages, python code included", "summary": "Attention mechanisms are widely used in artificial intelligence to enhance\nperformance and interpretability. In this paper, we investigate their utility\nin modeling classical dynamical systems -- specifically, a noisy predator-prey\n(Lotka-Volterra) system. We train a simple linear attention model on perturbed\ntime-series data to reconstruct system trajectories. Remarkably, the learned\nattention weights align with the geometric structure of the Lyapunov function:\nhigh attention corresponds to flat regions (where perturbations have small\neffect), and low attention aligns with steep regions (where perturbations have\nlarge effect). We further demonstrate that attention-based weighting can serve\nas a proxy for sensitivity analysis, capturing key phase-space properties\nwithout explicit knowledge of the system equations. These results suggest a\nnovel use of AI-derived attention for interpretable, data-driven analysis and\ncontrol of nonlinear systems. For example our framework could support future\nwork in biological modeling of circadian rhythms, and interpretable machine\nlearning for dynamical environments.", "AI": {"tldr": "The paper explores using linear attention mechanisms to model noisy predator-prey systems, showing that attention weights align with Lyapunov function geometry and can serve as a sensitivity analysis proxy.", "motivation": "To investigate the utility of attention mechanisms in modeling classical dynamical systems, specifically noisy predator-prey systems, for interpretable, data-driven analysis.", "method": "Train a linear attention model on perturbed time-series data to reconstruct system trajectories and analyze attention weights.", "result": "Attention weights align with Lyapunov function structure (high in flat regions, low in steep regions) and can act as a proxy for sensitivity analysis.", "conclusion": "Attention mechanisms offer a novel, interpretable approach for data-driven analysis and control of nonlinear systems, with potential applications in biological modeling and dynamical environments."}}
{"id": "2505.06839", "pdf": "https://arxiv.org/pdf/2505.06839", "abs": "https://arxiv.org/abs/2505.06839", "authors": ["Enric Boix-Adsera", "Philippe Rigollet"], "title": "The power of fine-grained experts: Granularity boosts expressivity in Mixture of Experts", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Mixture-of-Experts (MoE) layers are increasingly central to frontier model\narchitectures. By selectively activating parameters, they reduce computational\ncost while scaling total parameter count. This paper investigates the impact of\nthe number of active experts, termed granularity, comparing architectures with\nmany (e.g., 8 per layer in DeepSeek) to those with fewer (e.g., 1 per layer in\nLlama-4 models). We prove an exponential separation in network expressivity\nbased on this design parameter, suggesting that models benefit from higher\ngranularity. Experimental results corroborate our theoretical findings and\nillustrate this separation.", "AI": {"tldr": "MoE layers' granularity (number of active experts) impacts model expressivity, with higher granularity (e.g., 8 experts) showing exponential benefits over lower (e.g., 1 expert).", "motivation": "To understand how the number of active experts in MoE layers affects model performance and expressivity.", "method": "Theoretical analysis and experiments comparing architectures with varying expert granularity (e.g., 8 vs. 1 expert per layer).", "result": "Higher granularity (more active experts) leads to exponentially greater network expressivity, supported by experimental evidence.", "conclusion": "Models benefit from higher granularity in MoE layers, as it enhances expressivity without proportional computational cost."}}
{"id": "2405.06691", "pdf": "https://arxiv.org/pdf/2405.06691", "abs": "https://arxiv.org/abs/2405.06691", "authors": ["Lars Klein", "Nearchos Potamitis", "Roland Aydin", "Robert West", "Caglar Gulcehre", "Akhil Arora"], "title": "Fleet of Agents: Coordinated Problem Solving with Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "comment": "ICML 2025; 28 pages, 68 figures, 8 tables", "summary": "While numerous frameworks have been developed to enhance the reasoning\nabilities of large language models (LLMs), there is a scarcity of methods that\neffectively balance the trade-off between cost and quality. In this paper, we\nintroduce Fleet of Agents (FoA), a novel and intuitive yet principled framework\nutilizing LLMs as agents to navigate through dynamic tree searches, employing a\ngenetic-type particle filtering approach. FoA spawns a multitude of agents,\neach exploring the search space autonomously, followed by a selection phase\nwhere resampling based on a heuristic value function optimizes the balance\nbetween exploration and exploitation. This mechanism enables dynamic branching,\nadapting the exploration strategy based on discovered solutions. We conduct\nextensive experiments on three benchmark tasks, ``Game of 24'',\n``Mini-Crosswords'', and ``WebShop'', utilizing four different LLMs,\n``GPT-3.5'', ``GPT-4'', ``LLaMA3.2-11B'', and ``LLaMA3.2-90B''. On average\nacross all tasks and LLMs, FoA obtains a quality improvement of ~5% while\nrequiring only ~40% of the cost of previous SOTA methods. Notably, our analyses\nreveal that (1) FoA achieves the best cost-quality trade-off among all\nbenchmarked methods and (2) FoA + LLaMA3.2-11B surpasses the Llama3.2-90B\nmodel. FoA is publicly available at https://github.com/au-clan/FoA.", "AI": {"tldr": "FoA is a cost-effective framework using LLMs as agents for dynamic tree searches, improving quality by ~5% at ~40% cost of SOTA methods.", "motivation": "Address the scarcity of methods balancing cost and quality in enhancing LLM reasoning.", "method": "FoA employs genetic-type particle filtering with autonomous agents and heuristic resampling for dynamic branching.", "result": "FoA improves quality by ~5% at ~40% cost, outperforming SOTA methods and even larger models like LLaMA3.2-90B.", "conclusion": "FoA offers an optimal cost-quality trade-off and is publicly available for use."}}
{"id": "2505.07198", "pdf": "https://arxiv.org/pdf/2505.07198", "abs": "https://arxiv.org/abs/2505.07198", "authors": ["Xufei Wang", "Gengxuan Tian", "Junqiao Zhao", "Siyue Tao", "Qiwen Gu", "Qiankun Yu", "Tiantian Feng"], "title": "Ranking-aware Continual Learning for LiDAR Place Recognition", "categories": ["cs.CV"], "comment": "8 pages, 4 figures", "summary": "Place recognition plays a significant role in SLAM, robot navigation, and\nautonomous driving applications. Benefiting from deep learning, the performance\nof LiDAR place recognition (LPR) has been greatly improved. However, many\nexisting learning-based LPR methods suffer from catastrophic forgetting, which\nseverely harms the performance of LPR on previously trained places after\ntraining on a new environment. In this paper, we introduce a continual learning\nframework for LPR via Knowledge Distillation and Fusion (KDF) to alleviate\nforgetting. Inspired by the ranking process of place recognition retrieval, we\npresent a ranking-aware knowledge distillation loss that encourages the network\nto preserve the high-level place recognition knowledge. We also introduce a\nknowledge fusion module to integrate the knowledge of old and new models for\nLiDAR place recognition. Our extensive experiments demonstrate that KDF can be\napplied to different networks to overcome catastrophic forgetting, surpassing\nthe state-of-the-art methods in terms of mean Recall@1 and forgetting score.", "AI": {"tldr": "A continual learning framework (KDF) for LiDAR place recognition (LPR) addresses catastrophic forgetting using knowledge distillation and fusion, improving performance on previously trained places.", "motivation": "Existing learning-based LPR methods suffer from catastrophic forgetting when trained on new environments, degrading performance on old places.", "method": "Proposes a ranking-aware knowledge distillation loss and a knowledge fusion module to integrate old and new model knowledge.", "result": "KDF outperforms state-of-the-art methods in mean Recall@1 and forgetting score.", "conclusion": "KDF effectively mitigates catastrophic forgetting in LPR, enhancing continual learning performance."}}
{"id": "2505.06561", "pdf": "https://arxiv.org/pdf/2505.06561", "abs": "https://arxiv.org/abs/2505.06561", "authors": ["Danil Belov", "Artem Erkhov", "Elizaveta Pestova", "Ilya Osokin", "Dzmitry Tsetserukou", "Pavel Osinenko"], "title": "Quadrupedal Robot Skateboard Mounting via Reverse Curriculum Learning", "categories": ["cs.RO", "cs.AI", "math.OC"], "comment": null, "summary": "The aim of this work is to enable quadrupedal robots to mount skateboards\nusing Reverse Curriculum Reinforcement Learning. Although prior work has\ndemonstrated skateboarding for quadrupeds that are already positioned on the\nboard, the initial mounting phase still poses a significant challenge. A\ngoal-oriented methodology was adopted, beginning with the terminal phases of\nthe task and progressively increasing the complexity of the problem definition\nto approximate the desired objective. The learning process was initiated with\nthe skateboard rigidly fixed within the global coordinate frame and the robot\npositioned directly above it. Through gradual relaxation of these initial\nconditions, the learned policy demonstrated robustness to variations in\nskateboard position and orientation, ultimately exhibiting a successful\ntransfer to scenarios involving a mobile skateboard. The code, trained models,\nand reproducible examples are available at the following link:\nhttps://github.com/dancher00/quadruped-skateboard-mounting", "AI": {"tldr": "Quadrupedal robots learn to mount skateboards using Reverse Curriculum Reinforcement Learning, starting with simplified conditions and gradually increasing complexity.", "motivation": "Prior work focused on skateboarding for quadrupeds already on the board, but mounting remains a challenge.", "method": "Reverse Curriculum Reinforcement Learning, starting with fixed skateboard and robot above it, then relaxing conditions.", "result": "Learned policy handles variations in skateboard position/orientation and transfers to mobile skateboards.", "conclusion": "The approach successfully enables quadrupedal robots to mount skateboards, with code and models available."}}
{"id": "2505.06849", "pdf": "https://arxiv.org/pdf/2505.06849", "abs": "https://arxiv.org/abs/2505.06849", "authors": ["Tamilselvan Subramani", "Sebastian Bartscher"], "title": "Predictive Digital Twins for Thermal Management Using Machine Learning and Reduced-Order Models", "categories": ["cs.LG", "68T07, 65M99, 80A23", "I.2.6; G.1.8; J.2"], "comment": "10 pages, 2 tables, from M.Tech. thesis accepted at BITS Pilani, 2022", "summary": "Digital twins enable real-time simulation and prediction in engineering\nsystems. This paper presents a novel framework for predictive digital twins of\na headlamp heatsink, integrating physics-based reduced-order models (ROMs) from\ncomputational fluid dynamics (CFD) with supervised machine learning. A\ncomponent-based ROM library, derived via proper orthogonal decomposition (POD),\ncaptures thermal dynamics efficiently. Machine learning models, including\nDecision Trees, k-Nearest Neighbors, Support Vector Regression (SVR), and\nNeural Networks, predict optimal ROM configurations, enabling rapid digital\ntwin updates. The Neural Network achieves a mean absolute error (MAE) of\n54.240, outperforming other models. Quantitative comparisons of predicted and\noriginal values demonstrate high accuracy. This scalable, interpretable\nframework advances thermal management in automotive systems, supporting robust\ndesign and predictive maintenance.", "AI": {"tldr": "A novel framework combines physics-based reduced-order models (ROMs) and machine learning for predictive digital twins of a headlamp heatsink, achieving high accuracy with Neural Networks.", "motivation": "To enhance thermal management in automotive systems through scalable and interpretable digital twins.", "method": "Integrates physics-based ROMs (derived via POD) with supervised machine learning (Decision Trees, k-NN, SVR, Neural Networks) to predict optimal ROM configurations.", "result": "Neural Networks outperform other models with a mean absolute error (MAE) of 54.240, demonstrating high accuracy in predictions.", "conclusion": "The framework advances thermal management, supporting robust design and predictive maintenance in automotive systems."}}
{"id": "2406.15163", "pdf": "https://arxiv.org/pdf/2406.15163", "abs": "https://arxiv.org/abs/2406.15163", "authors": ["Muhammad Imran", "Olga Kellert", "Carlos G\u00f3mez-Rodr\u00edguez"], "title": "A Syntax-Injected Approach for Faster and More Accurate Sentiment Analysis", "categories": ["cs.CL"], "comment": null, "summary": "Sentiment Analysis (SA) is a crucial aspect of Natural Language Processing\n(NLP), addressing subjective assessments in textual content. Syntactic parsing\nis useful in SA because explicit syntactic information can improve accuracy\nwhile providing explainability, but it tends to be a computational bottleneck\nin practice due to the slowness of parsing algorithms. This paper addresses\nsaid bottleneck by using a SEquence Labeling Syntactic Parser (SELSP) to inject\nsyntax into SA. By treating dependency parsing as a sequence labeling problem,\nwe greatly enhance the speed of syntax-based SA. SELSP is trained and evaluated\non a ternary polarity classification task, demonstrating its faster performance\nand better accuracy in polarity prediction tasks compared to conventional\nparsers like Stanza and to heuristic approaches that use shallow syntactic\nrules for SA like VADER. This increased speed and improved accuracy make SELSP\nparticularly appealing to SA practitioners in both research and industry. In\naddition, we test several sentiment dictionaries on our SELSP to see which one\nimproves the performance in polarity prediction tasks. Moreover, we compare the\nSELSP with Transformer-based models trained on a 5-label classification task.\nThe results show that dictionaries that capture polarity judgment variation\nprovide better results than dictionaries that ignore polarity judgment\nvariation. Moreover, we show that SELSP is considerably faster than\nTransformer-based models in polarity prediction tasks.", "AI": {"tldr": "The paper introduces SELSP, a fast and accurate syntactic parser for sentiment analysis, outperforming traditional parsers and Transformer-based models in speed and accuracy.", "motivation": "Syntactic parsing improves sentiment analysis accuracy but is slow. The paper aims to address this bottleneck.", "method": "Uses SELSP, treating dependency parsing as sequence labeling, and tests it with sentiment dictionaries and against Transformer models.", "result": "SELSP is faster and more accurate than conventional parsers and Transformers, with sentiment dictionaries capturing polarity variation performing best.", "conclusion": "SELSP is a promising tool for sentiment analysis, offering speed and accuracy advantages over existing methods."}}
{"id": "2505.07209", "pdf": "https://arxiv.org/pdf/2505.07209", "abs": "https://arxiv.org/abs/2505.07209", "authors": ["Yan Xie", "Zequn Zeng", "Hao Zhang", "Yucheng Ding", "Yi Wang", "Zhengjue Wang", "Bo Chen", "Hongwei Liu"], "title": "Discovering Fine-Grained Visual-Concept Relations by Disentangled Optimal Transport Concept Bottleneck Models", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Concept Bottleneck Models (CBMs) try to make the decision-making process\ntransparent by exploring an intermediate concept space between the input image\nand the output prediction. Existing CBMs just learn coarse-grained relations\nbetween the whole image and the concepts, less considering local image\ninformation, leading to two main drawbacks: i) they often produce spurious\nvisual-concept relations, hence decreasing model reliability; and ii) though\nCBMs could explain the importance of every concept to the final prediction, it\nis still challenging to tell which visual region produces the prediction. To\nsolve these problems, this paper proposes a Disentangled Optimal Transport CBM\n(DOT-CBM) framework to explore fine-grained visual-concept relations between\nlocal image patches and concepts. Specifically, we model the concept prediction\nprocess as a transportation problem between the patches and concepts, thereby\nachieving explicit fine-grained feature alignment. We also incorporate\northogonal projection losses within the modality to enhance local feature\ndisentanglement. To further address the shortcut issues caused by statistical\nbiases in the data, we utilize the visual saliency map and concept label\nstatistics as transportation priors. Thus, DOT-CBM can visualize inversion\nheatmaps, provide more reliable concept predictions, and produce more accurate\nclass predictions. Comprehensive experiments demonstrate that our proposed\nDOT-CBM achieves SOTA performance on several tasks, including image\nclassification, local part detection and out-of-distribution generalization.", "AI": {"tldr": "DOT-CBM improves CBMs by using fine-grained visual-concept relations via optimal transport and orthogonal losses, enhancing reliability and interpretability.", "motivation": "Existing CBMs lack local image information, causing spurious relations and unclear visual explanations.", "method": "Proposes DOT-CBM, modeling concept prediction as a transportation problem between patches and concepts, with orthogonal losses and transportation priors.", "result": "Achieves SOTA in image classification, part detection, and OOD generalization, with reliable concept predictions.", "conclusion": "DOT-CBM advances CBMs by addressing local feature alignment and bias issues, improving performance and interpretability."}}
{"id": "2505.06584", "pdf": "https://arxiv.org/pdf/2505.06584", "abs": "https://arxiv.org/abs/2505.06584", "authors": ["Ziluo Ding", "Haobin Jiang", "Yuxuan Wang", "Zhenguo Sun", "Yu Zhang", "Xiaojie Niu", "Ming Yang", "Weishuai Zeng", "Xinrun Xu", "Zongqing Lu"], "title": "JAEGER: Dual-Level Humanoid Whole-Body Controller", "categories": ["cs.RO", "cs.AI"], "comment": "15 pages, 2 figures", "summary": "This paper presents JAEGER, a dual-level whole-body controller for humanoid\nrobots that addresses the challenges of training a more robust and versatile\npolicy. Unlike traditional single-controller approaches, JAEGER separates the\ncontrol of the upper and lower bodies into two independent controllers, so that\nthey can better focus on their distinct tasks. This separation alleviates the\ndimensionality curse and improves fault tolerance. JAEGER supports both root\nvelocity tracking (coarse-grained control) and local joint angle tracking\n(fine-grained control), enabling versatile and stable movements. To train the\ncontroller, we utilize a human motion dataset (AMASS), retargeting human poses\nto humanoid poses through an efficient retargeting network, and employ a\ncurriculum learning approach. This method performs supervised learning for\ninitialization, followed by reinforcement learning for further exploration. We\nconduct our experiments on two humanoid platforms and demonstrate the\nsuperiority of our approach against state-of-the-art methods in both simulation\nand real environments.", "AI": {"tldr": "JAEGER is a dual-level whole-body controller for humanoid robots, separating upper and lower body control for robustness and versatility. It uses human motion data and curriculum learning, outperforming state-of-the-art methods.", "motivation": "Addressing the challenges of training robust and versatile policies for humanoid robots by decoupling upper and lower body control to improve focus and fault tolerance.", "method": "JAEGER employs a dual-level controller, retargets human poses to robots using AMASS dataset, and combines supervised and reinforcement learning via curriculum learning.", "result": "Superior performance on two humanoid platforms in both simulation and real environments compared to existing methods.", "conclusion": "JAEGER's dual-level control and training approach effectively enhance robustness and versatility in humanoid robot movements."}}
{"id": "2505.06852", "pdf": "https://arxiv.org/pdf/2505.06852", "abs": "https://arxiv.org/abs/2505.06852", "authors": ["Ziyi Liu", "Phuc Luong", "Mario Boley", "Daniel F. Schmidt"], "title": "Improving Random Forests by Smoothing", "categories": ["cs.LG", "stat.ML"], "comment": "14 pages, 2 figures, 4 pages appendix, 3 figures in appendix", "summary": "Gaussian process regression is a popular model in the small data regime due\nto its sound uncertainty quantification and the exploitation of the smoothness\nof the regression function that is encountered in a wide range of practical\nproblems. However, Gaussian processes perform sub-optimally when the degree of\nsmoothness is non-homogeneous across the input domain. Random forest regression\npartially addresses this issue by providing local basis functions of variable\nsupport set sizes that are chosen in a data-driven way. However, they do so at\nthe expense of forgoing any degree of smoothness, which often results in poor\nperformance in the small data regime. Here, we aim to combine the advantages of\nboth models by applying a kernel-based smoothing mechanism to a learned random\nforest or any other piecewise constant prediction function. As we demonstrate\nempirically, the resulting model consistently improves the predictive\nperformance of the underlying random forests and, in almost all test cases,\nalso improves the log loss of the usual uncertainty quantification based on\ninter-tree variance. The latter advantage can be attributed to the ability of\nthe smoothing model to take into account the uncertainty over the exact\ntree-splitting locations.", "AI": {"tldr": "The paper proposes combining Gaussian process regression and random forest regression to improve predictive performance by smoothing piecewise constant functions, addressing non-homogeneous smoothness and uncertainty quantification.", "motivation": "Gaussian processes struggle with non-homogeneous smoothness, while random forests lack smoothness and perform poorly with small data. Combining both aims to leverage their strengths.", "method": "A kernel-based smoothing mechanism is applied to learned random forests or piecewise constant functions to enhance performance.", "result": "The model improves predictive performance and log loss of uncertainty quantification, leveraging uncertainty over tree-splitting locations.", "conclusion": "The hybrid approach outperforms standalone random forests and enhances uncertainty quantification, making it effective for non-homogeneous smoothness scenarios."}}
{"id": "2406.17692", "pdf": "https://arxiv.org/pdf/2406.17692", "abs": "https://arxiv.org/abs/2406.17692", "authors": ["Thom Lake", "Eunsol Choi", "Greg Durrett"], "title": "From Distributional to Overton Pluralism: Investigating Large Language Model Alignment", "categories": ["cs.CL", "cs.LG"], "comment": "NAACL 2025 (Main Conference)", "summary": "The alignment process changes several properties of a large language model's\n(LLM's) output distribution. We analyze two aspects of post-alignment\ndistributional shift of LLM responses. First, we re-examine previously reported\nreductions in response diversity post-alignment. Our analysis suggests that an\napparent drop in the diversity of responses is largely explained by quality\ncontrol and information aggregation. Alignment suppresses irrelevant and\nunhelpful content while shifting the output distribution toward longer\nresponses that cover information spanning several responses from the base LLM,\nessentially presenting diverse information in a single response. Finding little\nevidence that alignment suppresses useful information, it is natural to ask the\nopposite question: do aligned models surface information that cannot be\nrecovered from base models? Our second investigation shows this is not the case\nand the behavior of aligned models is recoverable from base models without\nfine-tuning. A combination of in-context examples and lower-resolution semantic\nhints about response content can elicit responses from base LLMs that are as\nsimilar to alignment-tuned LLM responses as alignment-tuned LLM responses are\nto each other. Taken together, these results indicate that current alignment\ntechniques capture but do not extend the useful subset of assistant-like base\nLLM behavior, providing further evidence for the Superficial Alignment\nHypothesis. They also show that in-context alignment can go surprisingly far as\na strategy for imitating aligned LLMs without fine-tuning. Our code and data is\navailable at https://github.com/thomlake/investigating-alignment.", "AI": {"tldr": "Alignment shifts LLM outputs toward longer, aggregated responses without suppressing useful info. Aligned models' behavior is recoverable from base models using in-context examples, supporting the Superficial Alignment Hypothesis.", "motivation": "To analyze how alignment changes LLM output properties and whether it suppresses useful info or extends base model capabilities.", "method": "Re-examined response diversity post-alignment and tested if aligned models' behavior is recoverable from base models using in-context examples.", "result": "Alignment aggregates diverse info into single responses without suppressing useful content. Aligned models' outputs can be replicated from base models without fine-tuning.", "conclusion": "Current alignment captures but doesn't extend base LLM behavior, supporting the Superficial Alignment Hypothesis. In-context alignment can imitate aligned models effectively."}}
{"id": "2505.07249", "pdf": "https://arxiv.org/pdf/2505.07249", "abs": "https://arxiv.org/abs/2505.07249", "authors": ["Philippe Colantoni", "Rafique Ahmed", "Prashant Ghimire", "Damien Muselet", "Alain Tr\u00e9meau"], "title": "When Dance Video Archives Challenge Computer Vision", "categories": ["cs.CV"], "comment": null, "summary": "The accuracy and efficiency of human body pose estimation depend on the\nquality of the data to be processed and of the particularities of these data.\nTo demonstrate how dance videos can challenge pose estimation techniques, we\nproposed a new 3D human body pose estimation pipeline which combined up-to-date\ntechniques and methods that had not been yet used in dance analysis. Second, we\nperformed tests and extensive experimentations from dance video archives, and\nused visual analytic tools to evaluate the impact of several data parameters on\nhuman body pose. Our results are publicly available for research at\nhttps://www.couleur.org/articles/arXiv-1-2025/", "AI": {"tldr": "A new 3D human body pose estimation pipeline for dance videos was developed and tested, addressing challenges in pose estimation accuracy and efficiency.", "motivation": "To explore how dance videos challenge pose estimation techniques and improve accuracy and efficiency.", "method": "Combined up-to-date techniques and novel methods for dance analysis, tested on dance video archives, and used visual analytic tools.", "result": "Results evaluated the impact of data parameters on pose estimation and are publicly available.", "conclusion": "The proposed pipeline effectively addresses pose estimation challenges in dance videos, with results shared for further research."}}
{"id": "2505.06589", "pdf": "https://arxiv.org/pdf/2505.06589", "abs": "https://arxiv.org/abs/2505.06589", "authors": ["Gabriel Peyr\u00e9"], "title": "Optimal Transport for Machine Learners", "categories": ["stat.ML", "cs.AI", "math.OC"], "comment": "arXiv admin note: text overlap with arXiv:1803.00567", "summary": "Optimal Transport is a foundational mathematical theory that connects\noptimization, partial differential equations, and probability. It offers a\npowerful framework for comparing probability distributions and has recently\nbecome an important tool in machine learning, especially for designing and\nevaluating generative models. These course notes cover the fundamental\nmathematical aspects of OT, including the Monge and Kantorovich formulations,\nBrenier's theorem, the dual and dynamic formulations, the Bures metric on\nGaussian distributions, and gradient flows. It also introduces numerical\nmethods such as linear programming, semi-discrete solvers, and entropic\nregularization. Applications in machine learning include topics like training\nneural networks via gradient flows, token dynamics in transformers, and the\nstructure of GANs and diffusion models. These notes focus primarily on\nmathematical content rather than deep learning techniques.", "AI": {"tldr": "The paper covers the mathematical foundations of Optimal Transport (OT), its formulations, theorems, and numerical methods, with applications in machine learning.", "motivation": "To provide a rigorous mathematical understanding of OT, which is increasingly important in machine learning for comparing distributions and designing generative models.", "method": "The notes explore OT's mathematical aspects, including Monge and Kantorovich formulations, Brenier's theorem, dual/dynamic formulations, and numerical methods like linear programming and entropic regularization.", "result": "A comprehensive overview of OT's theoretical and practical aspects, bridging optimization, PDEs, and probability, with relevance to machine learning.", "conclusion": "OT is a powerful tool for machine learning, and these notes emphasize its mathematical foundations over deep learning techniques."}}
{"id": "2505.06858", "pdf": "https://arxiv.org/pdf/2505.06858", "abs": "https://arxiv.org/abs/2505.06858", "authors": ["Tianyu Chen", "Haoyi Zhou", "Ying Li", "Hao Wang", "Zhenzhe Zhang", "Tianchen Zhu", "Shanghang Zhang", "Jianxin Li"], "title": "FreqMoE: Dynamic Frequency Enhancement for Neural PDE Solvers", "categories": ["cs.LG"], "comment": "Accepted by IJCAI 2025", "summary": "Fourier Neural Operators (FNO) have emerged as promising solutions for\nefficiently solving partial differential equations (PDEs) by learning\ninfinite-dimensional function mappings through frequency domain\ntransformations. However, the sparsity of high-frequency signals limits\ncomputational efficiency for high-dimensional inputs, and fixed-pattern\ntruncation often causes high-frequency signal loss, reducing performance in\nscenarios such as high-resolution inputs or long-term predictions. To address\nthese challenges, we propose FreqMoE, an efficient and progressive training\nframework that exploits the dependency of high-frequency signals on\nlow-frequency components. The model first learns low-frequency weights and then\napplies a sparse upward-cycling strategy to construct a mixture of experts\n(MoE) in the frequency domain, effectively extending the learned weights to\nhigh-frequency regions. Experiments on both regular and irregular grid PDEs\ndemonstrate that FreqMoE achieves up to 16.6% accuracy improvement while using\nmerely 2.1% parameters (47.32x reduction) compared to dense FNO. Furthermore,\nthe approach demonstrates remarkable stability in long-term predictions and\ngeneralizes seamlessly to various FNO variants and grid structures,\nestablishing a new ``Low frequency Pretraining, High frequency Fine-tuning''\nparadigm for solving PDEs.", "AI": {"tldr": "FreqMoE improves Fourier Neural Operators (FNO) by addressing high-frequency signal sparsity and loss, using a progressive training framework for better efficiency and accuracy.", "motivation": "High-frequency signal sparsity and fixed-pattern truncation in FNO limit computational efficiency and performance, especially for high-resolution inputs or long-term predictions.", "method": "FreqMoE first learns low-frequency weights, then uses a sparse upward-cycling strategy to extend these to high-frequency regions via a mixture of experts (MoE) in the frequency domain.", "result": "FreqMoE achieves up to 16.6% accuracy improvement with 47.32x fewer parameters than dense FNO, showing stability in long-term predictions and generalization across FNO variants and grid structures.", "conclusion": "FreqMoE introduces a 'Low frequency Pretraining, High frequency Fine-tuning' paradigm, significantly enhancing PDE-solving efficiency and accuracy."}}
{"id": "2408.05093", "pdf": "https://arxiv.org/pdf/2408.05093", "abs": "https://arxiv.org/abs/2408.05093", "authors": ["Zikai Xie"], "title": "Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, submitted to ACL ARR", "summary": "Large language models (LLMs) have generated significant attention since their\ninception, finding applications across various academic and industrial domains.\nHowever, these models often suffer from the \"hallucination problem\", where\noutputs, though grammatically and logically coherent, lack factual accuracy or\nare entirely fabricated. A particularly troubling issue discovered and widely\ndiscussed recently is the numerical comparison error where multiple LLMs\nincorrectly infer that \"9.11$>$9.9\". We discovered that the order in which LLMs\ngenerate answers and reasoning impacts their consistency. Specifically, results\nvary significantly when an LLM generates an answer first and then provides the\nreasoning versus generating the reasoning process first and then the\nconclusion. Inspired by this, we propose a new benchmark method for assessing\nLLM consistency: comparing responses generated through these two different\napproaches. This benchmark effectively identifies instances where LLMs\nfabricate answers and subsequently generate justifications. Furthermore, we\nintroduce a novel and straightforward prompt strategy designed to mitigate this\nissue. Experimental results demonstrate that this strategy improves performance\nacross various LLMs compared to direct questioning. This work not only sheds\nlight on a critical flaw in LLMs but also offers a practical solution to\nenhance their reliability.", "AI": {"tldr": "The paper addresses LLM hallucination, particularly numerical comparison errors, and proposes a benchmark to assess consistency by comparing answer-first vs. reasoning-first outputs. A new prompt strategy is introduced to improve reliability.", "motivation": "LLMs often produce factually incorrect or fabricated outputs (hallucination), such as the error '9.11$>$9.9'. The study aims to understand and mitigate this issue.", "method": "A benchmark method compares LLM responses generated via answer-first vs. reasoning-first approaches. A novel prompt strategy is introduced to reduce inconsistencies.", "result": "The benchmark effectively identifies fabrication, and the new prompt strategy improves LLM performance over direct questioning.", "conclusion": "The work highlights a critical LLM flaw and provides a practical solution to enhance reliability."}}
{"id": "2505.07251", "pdf": "https://arxiv.org/pdf/2505.07251", "abs": "https://arxiv.org/abs/2505.07251", "authors": ["Wenqiang Wang", "Yangshijie Zhang"], "title": "Incomplete In-context Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large vision language models (LVLMs) achieve remarkable performance through\nVision In-context Learning (VICL), a process that depends significantly on\ndemonstrations retrieved from an extensive collection of annotated examples\n(retrieval database). Existing studies often assume that the retrieval database\ncontains annotated examples for all labels. However, in real-world scenarios,\ndelays in database updates or incomplete data annotation may result in the\nretrieval database containing labeled samples for only a subset of classes. We\nrefer to this phenomenon as an \\textbf{incomplete retrieval database} and\ndefine the in-context learning under this condition as \\textbf{Incomplete\nIn-context Learning (IICL)}. To address this challenge, we propose\n\\textbf{Iterative Judgments and Integrated Prediction (IJIP)}, a two-stage\nframework designed to mitigate the limitations of IICL. The Iterative Judgments\nStage reformulates an \\(\\boldsymbol{m}\\)-class classification problem into a\nseries of \\(\\boldsymbol{m}\\) binary classification tasks, effectively\nconverting the IICL setting into a standard VICL scenario. The Integrated\nPrediction Stage further refines the classification process by leveraging both\nthe input image and the predictions from the Iterative Judgments Stage to\nenhance overall classification accuracy. IJIP demonstrates considerable\nperformance across two LVLMs and two datasets under three distinct conditions\nof label incompleteness, achieving the highest accuracy of 93.9\\%. Notably,\neven in scenarios where labels are fully available, IJIP still achieves the\nbest performance of all six baselines. Furthermore, IJIP can be directly\napplied to \\textbf{Prompt Learning} and is adaptable to the \\textbf{text\ndomain}.", "AI": {"tldr": "The paper introduces Incomplete In-context Learning (IICL) for LVLMs, proposes IJIP to address it, and shows superior performance even with full labels.", "motivation": "Addressing the challenge of incomplete retrieval databases in real-world LVLM applications.", "method": "Proposes IJIP, a two-stage framework: Iterative Judgments (binary tasks) and Integrated Prediction (refining accuracy).", "result": "Achieves 93.9% accuracy, outperforming baselines even with full labels. Adaptable to Prompt Learning and text domains.", "conclusion": "IJIP effectively mitigates IICL limitations and enhances LVLM performance across diverse conditions."}}
{"id": "2505.06595", "pdf": "https://arxiv.org/pdf/2505.06595", "abs": "https://arxiv.org/abs/2505.06595", "authors": ["Hai-Vy Nguyen", "Fabrice Gamboa", "Sixin Zhang", "Reda Chhaibi", "Serge Gratton", "Thierry Giaccone"], "title": "Feature Representation Transferring to Lightweight Models via Perception Coherence", "categories": ["stat.ML", "cs.AI", "cs.CV", "cs.LG", "math.PR"], "comment": null, "summary": "In this paper, we propose a method for transferring feature representation to\nlightweight student models from larger teacher models. We mathematically define\na new notion called \\textit{perception coherence}. Based on this notion, we\npropose a loss function, which takes into account the dissimilarities between\ndata points in feature space through their ranking. At a high level, by\nminimizing this loss function, the student model learns to mimic how the\nteacher model \\textit{perceives} inputs. More precisely, our method is\nmotivated by the fact that the representational capacity of the student model\nis weaker than the teacher model. Hence, we aim to develop a new method\nallowing for a better relaxation. This means that, the student model does not\nneed to preserve the absolute geometry of the teacher one, while preserving\nglobal coherence through dissimilarity ranking. Our theoretical insights\nprovide a probabilistic perspective on the process of feature representation\ntransfer. Our experiments results show that our method outperforms or achieves\non-par performance compared to strong baseline methods for representation\ntransferring.", "AI": {"tldr": "A method for transferring feature representation from teacher to student models using 'perception coherence' and a novel loss function based on dissimilarity ranking.", "motivation": "The student model's weaker representational capacity compared to the teacher model necessitates a method that relaxes absolute geometry preservation while maintaining global coherence.", "method": "Proposes a loss function based on 'perception coherence' to mimic the teacher's perception of inputs, focusing on dissimilarity rankings rather than absolute feature values.", "result": "Outperforms or matches strong baselines in feature representation transfer.", "conclusion": "The method effectively transfers feature representation by preserving global coherence through dissimilarity ranking, supported by theoretical insights and experimental validation."}}
{"id": "2505.06863", "pdf": "https://arxiv.org/pdf/2505.06863", "abs": "https://arxiv.org/abs/2505.06863", "authors": ["Jiebo Song", "Huaming Ling"], "title": "Masked Subspace Clustering Methods", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "To further utilize the unsupervised features and pairwise information, we\npropose a general Bilevel Clustering Optimization (BCO) framework to improve\nthe performance of clustering. And then we introduce three special cases on\nsubspace clustering with two different types of masks. At first, we reformulate\nthe original subspace clustering as a Basic Masked Subspace Clustering (BMSC),\nwhich reformulate the diagonal constraints to a hard mask. Then, we provide a\nGeneral Masked Subspace Clustering (GMSC) method to integrate different\nclustering via a soft mask. Furthermore, based on BCO and GMSC, we induce a\nlearnable soft mask and design a Recursive Masked Subspace Clustering (RMSC)\nmethod that can alternately update the affinity matrix and the soft mask.\nNumerical experiments show that our models obtain significant improvement\ncompared with the baselines on several commonly used datasets, such as MNIST,\nUSPS, ORL, COIL20 and COIL100.", "AI": {"tldr": "A Bilevel Clustering Optimization (BCO) framework is proposed to enhance clustering by leveraging unsupervised features and pairwise information, with three subspace clustering variants introduced.", "motivation": "To improve clustering performance by better utilizing unsupervised features and pairwise information.", "method": "Proposes BCO framework and three subspace clustering methods: Basic Masked Subspace Clustering (BMSC), General Masked Subspace Clustering (GMSC), and Recursive Masked Subspace Clustering (RMSC).", "result": "Significant improvement over baselines on datasets like MNIST, USPS, ORL, COIL20, and COIL100.", "conclusion": "The BCO framework and its subspace clustering variants effectively enhance clustering performance."}}
{"id": "2408.05497", "pdf": "https://arxiv.org/pdf/2408.05497", "abs": "https://arxiv.org/abs/2408.05497", "authors": ["Maxwell J. Yin", "Boyu Wang", "Charles Ling"], "title": "MABR: Multilayer Adversarial Bias Removal Without Prior Bias Knowledge", "categories": ["cs.CL"], "comment": null, "summary": "Models trained on real-world data often mirror and exacerbate existing social\nbiases. Traditional methods for mitigating these biases typically require prior\nknowledge of the specific biases to be addressed, such as gender or racial\nbiases, and the social groups associated with each instance. In this paper, we\nintroduce a novel adversarial training strategy that operates independently of\nprior bias-type knowledge and protected attribute labels. Our approach\nproactively identifies biases during model training by utilizing auxiliary\nmodels, which are trained concurrently by predicting the performance of the\nmain model without relying on task labels. Additionally, we implement these\nauxiliary models at various levels of the feature maps of the main model,\nenabling the detection of a broader and more nuanced range of bias features.\nThrough experiments on racial and gender biases in sentiment and occupation\nclassification tasks, our method effectively reduces social biases without the\nneed for demographic annotations. Moreover, our approach not only matches but\noften surpasses the efficacy of methods that require detailed demographic\ninsights, marking a significant advancement in bias mitigation techniques.", "AI": {"tldr": "A novel adversarial training strategy reduces social biases in models without needing prior bias-type knowledge or protected attribute labels.", "motivation": "Existing bias mitigation methods require prior knowledge of biases and social groups, which limits their applicability.", "method": "Uses auxiliary models trained concurrently to predict main model performance, detecting biases at various feature map levels.", "result": "Effectively reduces racial and gender biases in sentiment and occupation classification tasks without demographic annotations.", "conclusion": "The approach surpasses traditional methods, advancing bias mitigation by eliminating the need for detailed demographic insights."}}
{"id": "2505.07254", "pdf": "https://arxiv.org/pdf/2505.07254", "abs": "https://arxiv.org/abs/2505.07254", "authors": ["Mohamed Nagy", "Naoufel Werghi", "Bilal Hassan", "Jorge Dias", "Majid Khonji"], "title": "Towards Accurate State Estimation: Kalman Filter Incorporating Motion Dynamics for 3D Multi-Object Tracking", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "This work addresses the critical lack of precision in state estimation in the\nKalman filter for 3D multi-object tracking (MOT) and the ongoing challenge of\nselecting the appropriate motion model. Existing literature commonly relies on\nconstant motion models for estimating the states of objects, neglecting the\ncomplex motion dynamics unique to each object. Consequently, trajectory\ndivision and imprecise object localization arise, especially under occlusion\nconditions. The core of these challenges lies in the limitations of the current\nKalman filter formulation, which fails to account for the variability of motion\ndynamics as objects navigate their environments. This work introduces a novel\nformulation of the Kalman filter that incorporates motion dynamics, allowing\nthe motion model to adaptively adjust according to changes in the object's\nmovement. The proposed Kalman filter substantially improves state estimation,\nlocalization, and trajectory prediction compared to the traditional Kalman\nfilter. This is reflected in tracking performance that surpasses recent\nbenchmarks on the KITTI and Waymo Open Datasets, with margins of 0.56\\% and\n0.81\\% in higher order tracking accuracy (HOTA) and multi-object tracking\naccuracy (MOTA), respectively. Furthermore, the proposed Kalman filter\nconsistently outperforms the baseline across various detectors. Additionally,\nit shows an enhanced capability in managing long occlusions compared to the\nbaseline Kalman filter, achieving margins of 1.22\\% in higher order tracking\naccuracy (HOTA) and 1.55\\% in multi-object tracking accuracy (MOTA) on the\nKITTI dataset. The formulation's efficiency is evident, with an additional\nprocessing time of only approximately 0.078 ms per frame, ensuring its\napplicability in real-time applications.", "AI": {"tldr": "A novel Kalman filter formulation improves 3D multi-object tracking by adapting motion models to dynamic object movements, outperforming benchmarks on KITTI and Waymo datasets.", "motivation": "Addresses imprecise state estimation and motion model selection in Kalman filters for 3D MOT, especially under occlusion.", "method": "Introduces a Kalman filter that adaptively adjusts motion models based on object dynamics.", "result": "Outperforms benchmarks with 0.56% HOTA and 0.81% MOTA improvements, handles occlusions better, and adds minimal processing time (0.078 ms/frame).", "conclusion": "The adaptive Kalman filter enhances tracking accuracy and efficiency, suitable for real-time applications."}}
{"id": "2505.06612", "pdf": "https://arxiv.org/pdf/2505.06612", "abs": "https://arxiv.org/abs/2505.06612", "authors": ["Yuqin Lan"], "title": "Burger: Robust Graph Denoising-augmentation Fusion and Multi-semantic Modeling in Social Recommendation", "categories": ["cs.SI", "cs.AI", "cs.IR", "F.2.2; I.2.7"], "comment": "10 pages, 5 figures", "summary": "In the era of rapid development of social media, social recommendation\nsystems as hybrid recommendation systems have been widely applied. Existing\nmethods capture interest similarity between users to filter out\ninterest-irrelevant relations in social networks that inevitably decrease\nrecommendation accuracy, however, limited research has a focus on the mutual\ninfluence of semantic information between the social network and the user-item\ninteraction network for further improving social recommendation. To address\nthese issues, we introduce a social \\underline{r}ecommendation model with\nro\\underline{bu}st g\\underline{r}aph denoisin\\underline{g}-augmentation fusion\nand multi-s\\underline{e}mantic Modeling(Burger). Specifically, we firstly\npropose to construct a social tensor in order to smooth the training process of\nthe model. Then, a graph convolutional network and a tensor convolutional\nnetwork are employed to capture user's item preference and social preference,\nrespectively. Considering the different semantic information in the user-item\ninteraction network and the social network, a bi-semantic coordination loss is\nproposed to model the mutual influence of semantic information. To alleviate\nthe interference of interest-irrelevant relations on multi-semantic modeling,\nwe further use Bayesian posterior probability to mine potential social\nrelations to replace social noise. Finally, the sliding window mechanism is\nutilized to update the social tensor as the input for the next iteration.\nExtensive experiments on three real datasets show Burger has a superior\nperformance compared with the state-of-the-art models.", "AI": {"tldr": "The paper introduces Burger, a social recommendation model using robust graph denoising-augmentation fusion and multi-semantic modeling to improve recommendation accuracy by addressing semantic information influence and noise in social networks.", "motivation": "Existing methods focus on user interest similarity but neglect the mutual influence of semantic information between social and user-item interaction networks, limiting recommendation accuracy.", "method": "Burger constructs a social tensor, uses GCN and tensor convolutional networks for preference capture, introduces bi-semantic coordination loss, and employs Bayesian posterior probability to filter noise.", "result": "Experiments on three datasets show Burger outperforms state-of-the-art models.", "conclusion": "Burger effectively improves social recommendation by addressing semantic influence and noise, demonstrating superior performance."}}
{"id": "2505.06874", "pdf": "https://arxiv.org/pdf/2505.06874", "abs": "https://arxiv.org/abs/2505.06874", "authors": ["Thanh Son Nguyen", "Van Thanh Nguyen", "Dang Minh Duc Nguyen"], "title": "Enhancing Time Series Forecasting via a Parallel Hybridization of ARIMA and Polynomial Classifiers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting has attracted significant attention, leading to the\nde-velopment of a wide range of approaches, from traditional statistical\nmeth-ods to advanced deep learning models. Among them, the Auto-Regressive\nIntegrated Moving Average (ARIMA) model remains a widely adopted linear\ntechnique due to its effectiveness in modeling temporal dependencies in\neconomic, industrial, and social data. On the other hand, polynomial\nclassifi-ers offer a robust framework for capturing non-linear relationships\nand have demonstrated competitive performance in domains such as stock price\npre-diction. In this study, we propose a hybrid forecasting approach that\ninte-grates the ARIMA model with a polynomial classifier to leverage the\ncom-plementary strengths of both models. The hybrid method is evaluated on\nmultiple real-world time series datasets spanning diverse domains. Perfor-mance\nis assessed based on forecasting accuracy and computational effi-ciency.\nExperimental results reveal that the proposed hybrid model consist-ently\noutperforms the individual models in terms of prediction accuracy, al-beit with\na modest increase in execution time.", "AI": {"tldr": "A hybrid model combining ARIMA and polynomial classifiers is proposed for time series forecasting, outperforming individual models in accuracy with a slight trade-off in computational efficiency.", "motivation": "To leverage the strengths of both linear (ARIMA) and non-linear (polynomial classifiers) models for improved time series forecasting.", "method": "Integration of ARIMA with polynomial classifiers, evaluated on diverse real-world datasets.", "result": "The hybrid model consistently achieves higher prediction accuracy than standalone ARIMA or polynomial classifiers, though with slightly increased execution time.", "conclusion": "The hybrid approach effectively combines linear and non-linear techniques, enhancing forecasting performance across various domains."}}
{"id": "2408.09701", "pdf": "https://arxiv.org/pdf/2408.09701", "abs": "https://arxiv.org/abs/2408.09701", "authors": ["Mingda Li", "Abhijit Mishra", "Utkarsh Mujumdar"], "title": "Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer", "categories": ["cs.CL", "68T50 (Primary) 68T07 (Secondary)"], "comment": "Accepted and to appear in IJCNN 2025", "summary": "The use of Large Language Models (LLMs) for program code generation has\ngained substantial attention, but their biases and limitations with non-English\nprompts challenge global inclusivity. This paper investigates the complexities\nof multilingual prompt-based code generation. Our evaluations of LLMs,\nincluding CODELLAMA and CODEGEMMA, reveal significant disparities in code\nquality for non-English prompts; we also demonstrate the inadequacy of simple\napproaches like prompt translation, bootstrapped data augmentation, and\nfine-tuning. To address this, we propose a zero-shot cross-lingual approach\nusing a neural projection technique, integrating a cross-lingual encoder like\nLASER to map multilingual embeddings from it into the LLM's token space. This\nmethod requires training only on English data and scales effectively to other\nlanguages. Results on a translated and quality-checked MBPP dataset show\nsubstantial improvements in code quality. This research promotes a more\ninclusive code generation landscape by empowering LLMs with multilingual\ncapabilities to support the diverse linguistic spectrum in programming.", "AI": {"tldr": "The paper addresses biases in LLMs for non-English code generation, proposing a zero-shot cross-lingual method using neural projection to improve multilingual inclusivity.", "motivation": "LLMs show biases and limitations with non-English prompts, hindering global inclusivity in code generation.", "method": "A zero-shot cross-lingual approach using neural projection (e.g., LASER) to map multilingual embeddings into the LLM's token space, trained only on English data.", "result": "Significant improvements in code quality for non-English prompts on a translated MBPP dataset.", "conclusion": "The proposed method enhances multilingual code generation, promoting inclusivity in programming."}}
{"id": "2505.07256", "pdf": "https://arxiv.org/pdf/2505.07256", "abs": "https://arxiv.org/abs/2505.07256", "authors": ["Christoph Huber", "Ludwig Schleeh", "Dino Knoll", "Michael Guthe"], "title": "Synthetic Similarity Search in Automotive Production", "categories": ["cs.CV"], "comment": "Accepted for publication in Procedia CIRP", "summary": "Visual quality inspection in automotive production is essential for ensuring\nthe safety and reliability of vehicles. Computer vision (CV) has become a\npopular solution for these inspections due to its cost-effectiveness and\nreliability. However, CV models require large, annotated datasets, which are\ncostly and time-consuming to collect. To reduce the need for extensive training\ndata, we propose a novel image classification pipeline that combines similarity\nsearch using a vision-based foundation model with synthetic data. Our approach\nleverages a DINOv2 model to transform input images into feature vectors, which\nare then compared to pre-classified reference images using cosine distance\nmeasurements. By utilizing synthetic data instead of real images as references,\nour pipeline achieves high classification accuracy without relying on real\ndata. We evaluate this approach in eight real-world inspection scenarios and\ndemonstrate that it meets the high performance requirements of production\nenvironments.", "AI": {"tldr": "A novel image classification pipeline using similarity search with synthetic data reduces the need for large annotated datasets in automotive visual inspections.", "motivation": "Traditional CV models require costly, time-consuming annotated datasets, prompting a need for a more efficient solution.", "method": "Combines similarity search using DINOv2 for feature extraction and synthetic data as references, avoiding reliance on real images.", "result": "Achieves high classification accuracy in eight real-world inspection scenarios, meeting production standards.", "conclusion": "The pipeline offers a cost-effective, reliable alternative to traditional CV models for visual inspections."}}
{"id": "2505.06620", "pdf": "https://arxiv.org/pdf/2505.06620", "abs": "https://arxiv.org/abs/2505.06620", "authors": ["Dima Alattal", "Asal Khoshravan Azar", "Puja Myles", "Richard Branson", "Hatim Abdulhussein", "Allan Tucker"], "title": "Integrating Explainable AI in Medical Devices: Technical, Clinical and Regulatory Insights and Recommendations", "categories": ["cs.HC", "cs.AI", "H.5.2"], "comment": "47 pages", "summary": "There is a growing demand for the use of Artificial Intelligence (AI) and\nMachine Learning (ML) in healthcare, particularly as clinical decision support\nsystems to assist medical professionals. However, the complexity of many of\nthese models, often referred to as black box models, raises concerns about\ntheir safe integration into clinical settings as it is difficult to understand\nhow they arrived at their predictions. This paper discusses insights and\nrecommendations derived from an expert working group convened by the UK\nMedicine and Healthcare products Regulatory Agency (MHRA). The group consisted\nof healthcare professionals, regulators, and data scientists, with a primary\nfocus on evaluating the outputs from different AI algorithms in clinical\ndecision-making contexts. Additionally, the group evaluated findings from a\npilot study investigating clinicians' behaviour and interaction with AI methods\nduring clinical diagnosis. Incorporating AI methods is crucial for ensuring the\nsafety and trustworthiness of medical AI devices in clinical settings. Adequate\ntraining for stakeholders is essential to address potential issues, and further\ninsights and recommendations for safely adopting AI systems in healthcare\nsettings are provided.", "AI": {"tldr": "The paper discusses the challenges of integrating AI/ML in healthcare due to their black-box nature and provides expert recommendations for safe adoption.", "motivation": "The complexity of AI/ML models in healthcare raises concerns about their transparency and safety in clinical settings.", "method": "An expert working group evaluated AI algorithm outputs and clinician interactions with AI in a pilot study.", "result": "The group emphasized the need for stakeholder training and provided recommendations for safe AI adoption.", "conclusion": "Ensuring safety and trustworthiness of AI in healthcare requires transparency, training, and structured adoption guidelines."}}
{"id": "2505.06892", "pdf": "https://arxiv.org/pdf/2505.06892", "abs": "https://arxiv.org/abs/2505.06892", "authors": ["Zhen Liu", "Yicheng Luo", "Boyuan Li", "Emadeldeen Eldele", "Min Wu", "Qianli Ma"], "title": "Learning Soft Sparse Shapes for Efficient Time-Series Classification", "categories": ["cs.LG"], "comment": "Accepted in ICML 2025", "summary": "Shapelets are discriminative subsequences (or shapes) with high\ninterpretability in time series classification. Due to the time-intensive\nnature of shapelet discovery, existing shapelet-based methods mainly focus on\nselecting discriminative shapes while discarding others to achieve candidate\nsubsequence sparsification. However, this approach may exclude beneficial\nshapes and overlook the varying contributions of shapelets to classification\nperformance. To this end, we propose a \\textbf{Soft} sparse \\textbf{Shape}s\n(\\textbf{SoftShape}) model for efficient time series classification. Our\napproach mainly introduces soft shape sparsification and soft shape learning\nblocks. The former transforms shapes into soft representations based on\nclassification contribution scores, merging lower-scored ones into a single\nshape to retain and differentiate all subsequence information. The latter\nfacilitates intra- and inter-shape temporal pattern learning, improving model\nefficiency by using sparsified soft shapes as inputs. Specifically, we employ a\nlearnable router to activate a subset of class-specific expert networks for\nintra-shape pattern learning. Meanwhile, a shared expert network learns\ninter-shape patterns by converting sparsified shapes into sequences. Extensive\nexperiments show that SoftShape outperforms state-of-the-art methods and\nproduces interpretable results.", "AI": {"tldr": "SoftShape introduces soft sparsification and learning blocks for efficient time series classification, outperforming existing methods while retaining interpretability.", "motivation": "Existing shapelet-based methods discard non-discriminative shapes, potentially losing beneficial ones and ignoring varying contributions of shapelets.", "method": "Proposes soft shape sparsification (merging lower-scored shapes) and learning blocks (intra- and inter-shape pattern learning via expert networks).", "result": "Outperforms state-of-the-art methods and provides interpretable results.", "conclusion": "SoftShape effectively balances efficiency and interpretability in time series classification."}}
{"id": "2409.11055", "pdf": "https://arxiv.org/pdf/2409.11055", "abs": "https://arxiv.org/abs/2409.11055", "authors": ["Jemin Lee", "Sihyeong Park", "Jinse Kwon", "Jihun Oh", "Yongin Kwon"], "title": "Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted in IJCAI 2025, 21 pages, 2 figure", "summary": "Quantization has gained attention as a promising solution for the\ncost-effective deployment of large and small language models. However, most\nprior work has been limited to perplexity or basic knowledge tasks and lacks a\ncomprehensive evaluation of recent models like Llama-3.3. In this paper, we\nconduct a comprehensive evaluation of instruction-tuned models spanning 1B to\n405B parameters, applying four quantization methods across 13 datasets. Our\nfindings reveal that (1) quantized models generally surpass smaller FP16\nbaselines, yet they often struggle with instruction-following and hallucination\ndetection; (2) FP8 consistently emerges as the most robust option across tasks,\nand AWQ tends to outperform GPTQ in weight-only quantization; (3) smaller\nmodels can suffer severe accuracy drops at 4-bit quantization, while 70B-scale\nmodels maintain stable performance; (4) notably, \\textit{hard} tasks do not\nalways experience the largest accuracy losses, indicating that quantization\nmagnifies a model's inherent weaknesses rather than simply correlating with\ntask difficulty; and (5) an LLM-based judge (MT-Bench) highlights significant\nperformance declines in Coding and STEM tasks, though it occasionally reports\nimprovements in reasoning.", "AI": {"tldr": "Quantization evaluation of instruction-tuned models (1B-405B) shows FP8 as robust, AWQ outperforms GPTQ, and 4-bit quantization harms smaller models. Hard tasks don't always suffer most, and coding/STEM tasks decline.", "motivation": "Assess quantization's impact on modern models (e.g., Llama-3.3) beyond perplexity, focusing on instruction-following and hallucination.", "method": "Evaluate 1B-405B models using four quantization methods across 13 datasets, including MT-Bench for coding/STEM.", "result": "Quantized models beat smaller FP16 baselines but struggle with instructions/hallucination. FP8 is robust; 4-bit hurts small models. Hard tasks don't always lose most accuracy.", "conclusion": "Quantization amplifies model weaknesses, not just task difficulty. FP8 and AWQ are strong choices, but coding/STEM tasks suffer."}}
{"id": "2505.07263", "pdf": "https://arxiv.org/pdf/2505.07263", "abs": "https://arxiv.org/abs/2505.07263", "authors": ["Xiaokun Wang", "Chris", "Jiangbo Pei", "Wei Shen", "Yi Peng", "Yunzhuo Hao", "Weijie Qiu", "Ai Jian", "Tianyidan Xie", "Xuchen Song", "Yang Liu", "Yahui Zhou"], "title": "Skywork-VL Reward: An Effective Reward Model for Multimodal Understanding and Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "We propose Skywork-VL Reward, a multimodal reward model that provides reward\nsignals for both multimodal understanding and reasoning tasks. Our technical\napproach comprises two key components: First, we construct a large-scale\nmultimodal preference dataset that covers a wide range of tasks and scenarios,\nwith responses collected from both standard vision-language models (VLMs) and\nadvanced VLM reasoners. Second, we design a reward model architecture based on\nQwen2.5-VL-7B-Instruct, integrating a reward head and applying multi-stage\nfine-tuning using pairwise ranking loss on pairwise preference data.\nExperimental evaluations show that Skywork-VL Reward achieves state-of-the-art\nresults on multimodal VL-RewardBench and exhibits competitive performance on\nthe text-only RewardBench benchmark. Furthermore, preference data constructed\nbased on our Skywork-VL Reward proves highly effective for training Mixed\nPreference Optimization (MPO), leading to significant improvements in\nmultimodal reasoning capabilities. Our results underscore Skywork-VL Reward as\na significant advancement toward general-purpose, reliable reward models for\nmultimodal alignment. Our model has been publicly released to promote\ntransparency and reproducibility.", "AI": {"tldr": "Skywork-VL Reward is a multimodal reward model for understanding and reasoning tasks, leveraging a large-scale dataset and advanced architecture to achieve state-of-the-art performance.", "motivation": "To advance general-purpose, reliable reward models for multimodal alignment by providing robust reward signals for both understanding and reasoning tasks.", "method": "Constructs a large-scale multimodal preference dataset and designs a reward model architecture based on Qwen2.5-VL-7B-Instruct, using multi-stage fine-tuning with pairwise ranking loss.", "result": "Achieves state-of-the-art results on VL-RewardBench and competitive performance on RewardBench. Preference data from Skywork-VL Reward enhances Mixed Preference Optimization (MPO) for multimodal reasoning.", "conclusion": "Skywork-VL Reward represents a significant advancement in multimodal reward modeling, with publicly released models to ensure transparency and reproducibility."}}
{"id": "2505.06625", "pdf": "https://arxiv.org/pdf/2505.06625", "abs": "https://arxiv.org/abs/2505.06625", "authors": ["Tianhao Cai", "Liang Wang", "Limin Xiao", "Meng Han", "Zeyu Wang", "Lin Sun", "Xiaojian Liao"], "title": "CaMDN: Enhancing Cache Efficiency for Multi-tenant DNNs on Integrated NPUs", "categories": ["cs.AR", "cs.AI"], "comment": "7 pages, 9 figures. This paper has been accepted to the 2025 Design\n  Automation Conference (DAC)", "summary": "With the rapid development of DNN applications, multi-tenant execution, where\nmultiple DNNs are co-located on a single SoC, is becoming a prevailing trend.\nAlthough many methods are proposed in prior works to improve multi-tenant\nperformance, the impact of shared cache is not well studied. This paper\nproposes CaMDN, an architecture-scheduling co-design to enhance cache\nefficiency for multi-tenant DNNs on integrated NPUs. Specifically, a\nlightweight architecture is proposed to support model-exclusive, NPU-controlled\nregions inside shared cache to eliminate unexpected cache contention. Moreover,\na cache scheduling method is proposed to improve shared cache utilization. In\nparticular, it includes a cache-aware mapping method for adaptability to the\nvarying available cache capacity and a dynamic allocation algorithm to adjust\nthe usage among co-located DNNs at runtime. Compared to prior works, CaMDN\nreduces the memory access by 33.4% on average and achieves a model speedup of\nup to 2.56$\\times$ (1.88$\\times$ on average).", "AI": {"tldr": "CaMDN improves cache efficiency for multi-tenant DNNs on NPUs via architecture-scheduling co-design, reducing memory access by 33.4% and speeding up models by up to 2.56x.", "motivation": "Multi-tenant DNN execution on SoCs lacks efficient shared cache management, leading to performance issues.", "method": "Proposes CaMDN: lightweight architecture for exclusive cache regions and a cache scheduling method with dynamic allocation.", "result": "Reduces memory access by 33.4% and achieves speedups up to 2.56x.", "conclusion": "CaMDN effectively enhances cache efficiency and performance for multi-tenant DNNs."}}
{"id": "2505.06911", "pdf": "https://arxiv.org/pdf/2505.06911", "abs": "https://arxiv.org/abs/2505.06911", "authors": ["Lishan Yang", "Wei Zhang", "Quan Z. Sheng", "Weitong Chen", "Lina Yao", "Weitong Chen", "Ali Shakeri"], "title": "MMiC: Mitigating Modality Incompleteness in Clustered Federated Learning", "categories": ["cs.LG", "cs.AI", "I.2.11; I.2.7"], "comment": "10 pages, 10 figures, it's KDD'2025 under reviewing", "summary": "In the era of big data, data mining has become indispensable for uncovering\nhidden patterns and insights from vast and complex datasets. The integration of\nmultimodal data sources further enhances its potential. Multimodal Federated\nLearning (MFL) is a distributed approach that enhances the efficiency and\nquality of multimodal learning, ensuring collaborative work and privacy\nprotection. However, missing modalities pose a significant challenge in MFL,\noften due to data quality issues or privacy policies across the clients. In\nthis work, we present MMiC, a framework for Mitigating Modality incompleteness\nin MFL within the Clusters. MMiC replaces partial parameters within client\nmodels inside clusters to mitigate the impact of missing modalities.\nFurthermore, it leverages the Banzhaf Power Index to optimize client selection\nunder these conditions. Finally, MMiC employs an innovative approach to\ndynamically control global aggregation by utilizing Markovitz Portfolio\nOptimization. Extensive experiments demonstrate that MMiC consistently\noutperforms existing federated learning architectures in both global and\npersonalized performance on multimodal datasets with missing modalities,\nconfirming the effectiveness of our proposed solution.", "AI": {"tldr": "MMiC is a framework for mitigating missing modalities in Multimodal Federated Learning (MFL) by replacing partial parameters and optimizing client selection, outperforming existing methods.", "motivation": "Missing modalities in MFL due to data quality or privacy policies hinder performance, necessitating a solution like MMiC.", "method": "MMiC replaces partial parameters, uses the Banzhaf Power Index for client selection, and employs Markovitz Portfolio Optimization for global aggregation.", "result": "MMiC outperforms existing federated learning architectures in global and personalized performance on multimodal datasets with missing modalities.", "conclusion": "MMiC effectively addresses modality incompleteness in MFL, enhancing performance and collaboration."}}
{"id": "2409.13746", "pdf": "https://arxiv.org/pdf/2409.13746", "abs": "https://arxiv.org/abs/2409.13746", "authors": ["Thanh Son Do", "Daniel B. Hier", "Tayo Obafemi-Ajayi"], "title": "Mapping Biomedical Ontology Terms to IDs: Effect of Domain Prevalence on Prediction Accuracy", "categories": ["cs.CL", "cs.AI", "I.2"], "comment": "Presented at 2025 IEEE Conference on Artificial Intelligence (CAI).\n  Santa Clara, CA. May 5, 2025", "summary": "This study evaluates the ability of large language models (LLMs) to map\nbiomedical ontology terms to their corresponding ontology IDs across the Human\nPhenotype Ontology (HPO), Gene Ontology (GO), and UniProtKB terminologies.\nUsing counts of ontology IDs in the PubMed Central (PMC) dataset as a surrogate\nfor their prevalence in the biomedical literature, we examined the relationship\nbetween ontology ID prevalence and mapping accuracy. Results indicate that\nontology ID prevalence strongly predicts accurate mapping of HPO terms to HPO\nIDs, GO terms to GO IDs, and protein names to UniProtKB accession numbers.\nHigher prevalence of ontology IDs in the biomedical literature correlated with\nhigher mapping accuracy. Predictive models based on receiver operating\ncharacteristic (ROC) curves confirmed this relationship.\n  In contrast, this pattern did not apply to mapping protein names to Human\nGenome Organisation's (HUGO) gene symbols. GPT-4 achieved a high baseline\nperformance (95%) in mapping protein names to HUGO gene symbols, with mapping\naccuracy unaffected by prevalence. We propose that the high prevalence of HUGO\ngene symbols in the literature has caused these symbols to become lexicalized,\nenabling GPT-4 to map protein names to HUGO gene symbols with high accuracy.\nThese findings highlight the limitations of LLMs in mapping ontology terms to\nlow-prevalence ontology IDs and underscore the importance of incorporating\nontology ID prevalence into the training and evaluation of LLMs for biomedical\napplications.", "AI": {"tldr": "The study evaluates LLMs' ability to map biomedical ontology terms to IDs, finding prevalence strongly predicts accuracy for HPO, GO, and UniProtKB, but not for HUGO gene symbols.", "motivation": "To assess LLMs' performance in mapping biomedical ontology terms and understand the role of ontology ID prevalence in accuracy.", "method": "Used PubMed Central dataset counts as a proxy for prevalence, analyzed mapping accuracy, and built predictive models using ROC curves.", "result": "Higher prevalence correlated with better mapping accuracy for HPO, GO, and UniProtKB, but not for HUGO gene symbols, where GPT-4 achieved 95% accuracy regardless of prevalence.", "conclusion": "LLMs struggle with low-prevalence ontology IDs; prevalence should be considered in training and evaluation for biomedical applications."}}
{"id": "2505.07300", "pdf": "https://arxiv.org/pdf/2505.07300", "abs": "https://arxiv.org/abs/2505.07300", "authors": ["Sofia Casarin", "Sergio Escalera", "Oswald Lanz"], "title": "L-SWAG: Layer-Sample Wise Activation with Gradients information for Zero-Shot NAS on Vision Transformers", "categories": ["cs.CV"], "comment": "accepted at CVPR 2025", "summary": "Training-free Neural Architecture Search (NAS) efficiently identifies\nhigh-performing neural networks using zero-cost (ZC) proxies. Unlike multi-shot\nand one-shot NAS approaches, ZC-NAS is both (i) time-efficient, eliminating the\nneed for model training, and (ii) interpretable, with proxy designs often\ntheoretically grounded. Despite rapid developments in the field, current SOTA\nZC proxies are typically constrained to well-established convolutional search\nspaces. With the rise of Large Language Models shaping the future of deep\nlearning, this work extends ZC proxy applicability to Vision Transformers\n(ViTs). We present a new benchmark using the Autoformer search space evaluated\non 6 distinct tasks and propose Layer-Sample Wise Activation with Gradients\ninformation (L-SWAG), a novel, generalizable metric that characterizes both\nconvolutional and transformer architectures across 14 tasks. Additionally,\nprevious works highlighted how different proxies contain complementary\ninformation, motivating the need for a ML model to identify useful\ncombinations. To further enhance ZC-NAS, we therefore introduce LIBRA-NAS (Low\nInformation gain and Bias Re-Alignment), a method that strategically combines\nproxies to best represent a specific benchmark. Integrated into the NAS search,\nLIBRA-NAS outperforms evolution and gradient-based NAS techniques by\nidentifying an architecture with a 17.0% test error on ImageNet1k in just 0.1\nGPU days.", "AI": {"tldr": "Training-free NAS uses zero-cost proxies to efficiently find high-performing neural networks, extending to Vision Transformers with a new metric (L-SWAG) and a method (LIBRA-NAS) to combine proxies, achieving 17.0% test error on ImageNet1k in 0.1 GPU days.", "motivation": "Current zero-cost proxies are limited to convolutional search spaces, while Vision Transformers are gaining prominence. This work aims to extend proxy applicability to ViTs and improve NAS efficiency.", "method": "Proposes L-SWAG, a generalizable metric for both convolutional and transformer architectures, and LIBRA-NAS, a method to strategically combine proxies for better performance.", "result": "LIBRA-NAS outperforms evolution and gradient-based NAS, achieving 17.0% test error on ImageNet1k in just 0.1 GPU days.", "conclusion": "The work successfully extends zero-cost proxies to Vision Transformers and introduces a method to enhance NAS efficiency, demonstrating significant improvements in performance and speed."}}
{"id": "2505.06632", "pdf": "https://arxiv.org/pdf/2505.06632", "abs": "https://arxiv.org/abs/2505.06632", "authors": ["Rathin Chandra Shit", "Sharmila Subudhi"], "title": "AI-Powered Anomaly Detection with Blockchain for Real-Time Security and Reliability in Autonomous Vehicles", "categories": ["cs.CR", "cs.AI"], "comment": "Scheduled for presentation at an upcoming conference", "summary": "Autonomous Vehicles (AV) proliferation brings important and pressing security\nand reliability issues that must be dealt with to guarantee public safety and\nhelp their widespread adoption. The contribution of the proposed research is\ntowards achieving more secure, reliable, and trustworthy autonomous\ntransportation system by providing more capabilities for anomaly detection,\ndata provenance, and real-time response in safety critical AV deployments. In\nthis research, we develop a new framework that combines the power of Artificial\nIntelligence (AI) for real-time anomaly detection with blockchain technology to\ndetect and prevent any malicious activity including sensor failures in AVs.\nThrough Long Short-Term Memory (LSTM) networks, our approach continually\nmonitors associated multi-sensor data streams to detect anomalous patterns that\nmay represent cyberattacks as well as hardware malfunctions. Further, this\nframework employs a decentralized platform for securely storing sensor data and\nanomaly alerts in a blockchain ledger for data incorruptibility and\nauthenticity, while offering transparent forensic features. Moreover, immediate\nautomated response mechanisms are deployed using smart contracts when anomalies\nare found. This makes the AV system more resilient to attacks from both\ncyberspace and hardware component failure. Besides, we identify potential\nchallenges of scalability in handling high frequency sensor data, computational\nconstraint in resource constrained environment, and of distributed data storage\nin terms of privacy.", "AI": {"tldr": "The paper proposes a framework combining AI and blockchain for secure, reliable AVs, focusing on anomaly detection, data integrity, and real-time response.", "motivation": "Addressing security and reliability issues in AVs to ensure public safety and promote adoption.", "method": "Uses LSTM networks for real-time anomaly detection and blockchain for secure data storage and transparency.", "result": "Enhanced resilience against cyberattacks and hardware failures, with challenges like scalability and privacy noted.", "conclusion": "The framework improves AV security and reliability, though scalability and privacy remain challenges."}}
{"id": "2505.06917", "pdf": "https://arxiv.org/pdf/2505.06917", "abs": "https://arxiv.org/abs/2505.06917", "authors": ["Yuqi Xiong", "Yang Wen"], "title": "Non-Stationary Time Series Forecasting Based on Fourier Analysis and Cross Attention Mechanism", "categories": ["cs.LG"], "comment": "IJCNN 2025", "summary": "Time series forecasting has important applications in financial analysis,\nweather forecasting, and traffic management. However, existing deep learning\nmodels are limited in processing non-stationary time series data because they\ncannot effectively capture the statistical characteristics that change over\ntime. To address this problem, this paper proposes a new framework, AEFIN,\nwhich enhances the information sharing ability between stable and unstable\ncomponents by introducing a cross-attention mechanism, and combines Fourier\nanalysis networks with MLP to deeply explore the seasonal patterns and trend\ncharacteristics in unstable components. In addition, we design a new loss\nfunction that combines time-domain stability constraints, time-domain\ninstability constraints, and frequency-domain stability constraints to improve\nthe accuracy and robustness of forecasting. Experimental results show that\nAEFIN outperforms the most common models in terms of mean square error and mean\nabsolute error, especially under non-stationary data conditions, and shows\nexcellent forecasting capabilities. This paper provides an innovative solution\nfor the modeling and forecasting of non-stationary time series data, and\ncontributes to the research of deep learning for complex time series.", "AI": {"tldr": "AEFIN, a new framework for non-stationary time series forecasting, uses cross-attention and Fourier-MLP to improve accuracy and robustness, outperforming existing models.", "motivation": "Existing deep learning models struggle with non-stationary time series due to changing statistical characteristics.", "method": "AEFIN combines cross-attention, Fourier analysis, and MLP, with a novel loss function for stability constraints.", "result": "AEFIN achieves better MSE and MAE, especially for non-stationary data.", "conclusion": "AEFIN offers an innovative solution for non-stationary time series forecasting, advancing deep learning research."}}
{"id": "2410.01294", "pdf": "https://arxiv.org/pdf/2410.01294", "abs": "https://arxiv.org/abs/2410.01294", "authors": ["Brian R. Y. Huang", "Maximilian Li", "Leonard Tang"], "title": "Endless Jailbreaks with Bijection Learning", "categories": ["cs.CL"], "comment": null, "summary": "Despite extensive safety measures, LLMs are vulnerable to adversarial inputs,\nor jailbreaks, which can elicit unsafe behaviors. In this work, we introduce\nbijection learning, a powerful attack algorithm which automatically fuzzes LLMs\nfor safety vulnerabilities using randomly-generated encodings whose complexity\ncan be tightly controlled. We leverage in-context learning to teach models\nbijective encodings, pass encoded queries to the model to bypass built-in\nsafety mechanisms, and finally decode responses back into English. Our attack\nis extremely effective on a wide range of frontier language models. Moreover,\nby controlling complexity parameters such as number of key-value mappings in\nthe encodings, we find a close relationship between the capability level of the\nattacked LLM and the average complexity of the most effective bijection\nattacks. Our work highlights that new vulnerabilities in frontier models can\nemerge with scale: more capable models are more severely jailbroken by\nbijection attacks.", "AI": {"tldr": "Bijection learning is introduced as an attack algorithm to exploit LLM vulnerabilities by using controlled-complexity encodings, revealing that more capable models are more susceptible to such jailbreaks.", "motivation": "Despite existing safety measures, LLMs remain vulnerable to adversarial inputs (jailbreaks), prompting the need for methods to identify and understand these vulnerabilities.", "method": "The approach involves bijection learning, where models are taught bijective encodings via in-context learning. Encoded queries bypass safety mechanisms, and responses are decoded back to English.", "result": "The attack is highly effective across various LLMs, with a correlation found between model capability and the complexity of successful bijection attacks.", "conclusion": "More capable LLMs are more vulnerable to bijection attacks, indicating that scaling models introduces new safety challenges."}}
{"id": "2505.07301", "pdf": "https://arxiv.org/pdf/2505.07301", "abs": "https://arxiv.org/abs/2505.07301", "authors": ["Katsuki Shimbo", "Hiromu Taketsugu", "Norimichi Ukita"], "title": "Human Motion Prediction via Test-domain-aware Adaptation with Easily-available Human Motions Estimated from Videos", "categories": ["cs.CV"], "comment": "5 pages, 4 figures", "summary": "In 3D Human Motion Prediction (HMP), conventional methods train HMP models\nwith expensive motion capture data. However, the data collection cost of such\nmotion capture data limits the data diversity, which leads to poor\ngeneralizability to unseen motions or subjects. To address this issue, this\npaper proposes to enhance HMP with additional learning using estimated poses\nfrom easily available videos. The 2D poses estimated from the monocular videos\nare carefully transformed into motion capture-style 3D motions through our\npipeline. By additional learning with the obtained motions, the HMP model is\nadapted to the test domain. The experimental results demonstrate the\nquantitative and qualitative impact of our method.", "AI": {"tldr": "The paper proposes using estimated 2D poses from videos to enhance 3D Human Motion Prediction (HMP), improving generalizability by reducing reliance on costly motion capture data.", "motivation": "High costs and limited diversity of motion capture data hinder HMP model generalizability.", "method": "Transform 2D poses from monocular videos into 3D motions and use them for additional learning to adapt HMP models.", "result": "Experiments show quantitative and qualitative improvements in HMP performance.", "conclusion": "Leveraging video-derived poses enhances HMP generalizability without expensive data."}}
{"id": "2505.06652", "pdf": "https://arxiv.org/pdf/2505.06652", "abs": "https://arxiv.org/abs/2505.06652", "authors": ["Ernesto Giralt Hernandez", "Lazaro Antonio Bueno Perez"], "title": "Enfoque Odychess: Un m\u00e9todo dial\u00e9ctico, constructivista y adaptativo para la ense\u00f1anza del ajedrez con inteligencias artificiales generativas", "categories": ["cs.CY", "cs.AI"], "comment": "Full article in Spanish", "summary": "Chess teaching has evolved through different approaches, however, traditional\nmethodologies, often based on memorization, contrast with the new possibilities\noffered by generative artificial intelligence, a technology still little\nexplored in this field. This study seeks to empirically validate the\neffectiveness of the Odychess Approach in improving chess knowledge, strategic\nunderstanding, and metacognitive skills in students. A quasi-experimental study\nwas conducted with a pre-test/post-test design and a control group (N=60). The\nexperimental intervention implemented the Odychess Approach, incorporating a\nLlama 3.3 language model that was specifically adapted using\nParameter-Efficient Fine-Tuning (PEFT) techniques to act as a Socratic chess\ntutor. Quantitative assessment instruments were used to measure chess\nknowledge, strategic understanding, and metacognitive skills before and after\nthe intervention. The results of the quasi-experimental study showed\nsignificant improvements in the experimental group compared to the control\ngroup in the three variables analyzed: chess knowledge, strategic\nunderstanding, and metacognitive skills. The complementary qualitative analysis\nrevealed greater analytical depth, more developed dialectical reasoning, and\nincreased intrinsic motivation in students who participated in the Odychess\nmethod-based intervention. The Odychess Approach represents an effective\npedagogical methodology for teaching chess, demonstrating the potential of the\nsynergistic integration of constructivist and dialectical principles with\ngenerative artificial intelligence. The implications of this work are relevant\nfor educators and institutions interested in adopting innovative pedagogical\ntechnologies and for researchers in the field of AI applied to education,\nhighlighting the transferability of the language model adaptation methodology\nto other educational domains.", "AI": {"tldr": "The study validates the Odychess Approach, using a fine-tuned Llama 3.3 model, to improve chess knowledge, strategy, and metacognition in students, showing significant gains over traditional methods.", "motivation": "To explore the effectiveness of generative AI (specifically the Odychess Approach) in chess education, contrasting with traditional memorization-based methods.", "method": "A quasi-experimental study with pre-test/post-test design (N=60), using PEFT-adapted Llama 3.3 as a Socratic tutor. Quantitative and qualitative assessments measured chess knowledge, strategy, and metacognition.", "result": "Significant improvements in chess knowledge, strategic understanding, and metacognitive skills in the experimental group. Qualitative analysis showed deeper reasoning and higher motivation.", "conclusion": "The Odychess Approach is effective, combining constructivist principles with AI. Findings support AI's potential in education and its transferability to other domains."}}
{"id": "2505.06936", "pdf": "https://arxiv.org/pdf/2505.06936", "abs": "https://arxiv.org/abs/2505.06936", "authors": ["Mohammad Mashayekhi", "Kamran Salehian"], "title": "AI-Powered Inverse Design of Ku-Band SIW Resonant Structures by Iterative Residual Correction Network", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 14 figures", "summary": "Inverse electromagnetic modeling has emerged as a powerful approach for\ndesigning complex microwave structures with high accuracy and efficiency. In\nthis study, we propose an Iterative Residual Correction Network (IRC-Net) for\nthe inverse design of Ku-band Substrate Integrated Waveguide (SIW) components\nbased on multimode resonators. We use a multimode resonance structure to\ndemonstrate that it is possible to control the resonances of the structure.\nTherefore, these structures can be used for resonant components and smart\nfilter design. The proposed deep learning architecture leverages residual\nneural networks to overcome the limitations of traditional inverse design\ntechniques, such as the Feedforward Inverse Model (FIM), offering improved\ngeneralization and prediction accuracy. The approach begins with a FIM to\ngenerate initial design estimates, followed by an iterative correction strategy\ninspired by the Hybrid Inverse-Forward Residual Refinement Network\n(HiFR\\textsuperscript{2}-Net), which we call IRC-Net. Experiments demonstrate\nthat the IRC-Net achieves substantial improvements in prediction accuracy\ncompared to traditional single-stage networks, validated through statistical\nmetrics, full-wave electromagnetic simulations, and measurements. To validate\nthe proposed framework, we first design and fabricate a three-resonance SIW\nstructure. Next, we apply the trained IRC-Net model to predict the geometry of\na four-resonance structure based on its desired frequency response. Both\ndesigns are fabricated and tested, showing strong agreement between the\nsimulated, predicted, and measured results, confirming the effectiveness and\npracticality of the proposed method.", "AI": {"tldr": "Proposes IRC-Net for inverse design of Ku-band SIW components, improving accuracy over traditional methods.", "motivation": "To enhance the accuracy and efficiency of inverse electromagnetic modeling for designing complex microwave structures.", "method": "Uses IRC-Net, combining residual neural networks and iterative correction, starting with FIM for initial estimates.", "result": "IRC-Net outperforms single-stage networks, validated by simulations and measurements.", "conclusion": "IRC-Net is effective and practical for inverse design of SIW components."}}
{"id": "2410.14812", "pdf": "https://arxiv.org/pdf/2410.14812", "abs": "https://arxiv.org/abs/2410.14812", "authors": ["Victoria Lin", "Louis-Philippe Morency", "Eli Ben-Michael"], "title": "Isolated Causal Effects of Natural Language", "categories": ["cs.CL", "stat.ME"], "comment": "ICML 2025", "summary": "As language technologies become widespread, it is important to understand how\nchanges in language affect reader perceptions and behaviors. These\nrelationships may be formalized as the isolated causal effect of some focal\nlanguage-encoded intervention (e.g., factual inaccuracies) on an external\noutcome (e.g., readers' beliefs). In this paper, we introduce a formal\nestimation framework for isolated causal effects of language. We show that a\ncore challenge of estimating isolated effects is the need to approximate all\nnon-focal language outside of the intervention. Drawing on the principle of\nomitted variable bias, we provide measures for evaluating the quality of both\nnon-focal language approximations and isolated effect estimates themselves. We\nfind that poor approximation of non-focal language can lead to bias in the\ncorresponding isolated effect estimates due to omission of relevant variables,\nand we show how to assess the sensitivity of effect estimates to such bias\nalong the two key axes of fidelity and overlap. In experiments on\nsemi-synthetic and real-world data, we validate the ability of our framework to\ncorrectly recover isolated effects and demonstrate the utility of our proposed\nmeasures.", "AI": {"tldr": "A framework for estimating isolated causal effects of language interventions on reader perceptions, addressing bias from non-focal language approximations.", "motivation": "To understand how language changes impact reader perceptions and behaviors, formalizing causal effects of language interventions.", "method": "Introduces a formal estimation framework, evaluating non-focal language approximations using omitted variable bias principles.", "result": "Poor non-focal language approximation causes bias; framework validates recovery of isolated effects in experiments.", "conclusion": "Proposed measures effectively assess bias sensitivity, aiding accurate estimation of language's causal effects."}}
{"id": "2505.07306", "pdf": "https://arxiv.org/pdf/2505.07306", "abs": "https://arxiv.org/abs/2505.07306", "authors": ["Sander De Coninck", "Emilio Gamba", "Bart Van Doninck", "Abdellatif Bey-Temsamani", "Sam Leroux", "Pieter Simoens"], "title": "Enabling Privacy-Aware AI-Based Ergonomic Analysis", "categories": ["cs.CV"], "comment": "Accepted and presented at the 35th CIRP Design conference", "summary": "Musculoskeletal disorders (MSDs) are a leading cause of injury and\nproductivity loss in the manufacturing industry, incurring substantial economic\ncosts. Ergonomic assessments can mitigate these risks by identifying workplace\nadjustments that improve posture and reduce strain. Camera-based systems offer\na non-intrusive, cost-effective method for continuous ergonomic tracking, but\nthey also raise significant privacy concerns. To address this, we propose a\nprivacy-aware ergonomic assessment framework utilizing machine learning\ntechniques. Our approach employs adversarial training to develop a lightweight\nneural network that obfuscates video data, preserving only the essential\ninformation needed for human pose estimation. This obfuscation ensures\ncompatibility with standard pose estimation algorithms, maintaining high\naccuracy while protecting privacy. The obfuscated video data is transmitted to\na central server, where state-of-the-art keypoint detection algorithms extract\nbody landmarks. Using multi-view integration, 3D keypoints are reconstructed\nand evaluated with the Rapid Entire Body Assessment (REBA) method. Our system\nprovides a secure, effective solution for ergonomic monitoring in industrial\nenvironments, addressing both privacy and workplace safety concerns.", "AI": {"tldr": "A privacy-aware framework for ergonomic assessment in manufacturing uses adversarial training to obfuscate video data, ensuring privacy while maintaining pose estimation accuracy for workplace safety.", "motivation": "Address privacy concerns in camera-based ergonomic monitoring while maintaining effectiveness in reducing musculoskeletal disorders (MSDs) in manufacturing.", "method": "Adversarial training to obfuscate video data, preserving key pose information. Uses multi-view integration and REBA for 3D keypoint assessment.", "result": "High accuracy in pose estimation with privacy protection, enabling secure ergonomic monitoring.", "conclusion": "The framework balances privacy and workplace safety, offering a viable solution for industrial ergonomic assessments."}}
{"id": "2505.06682", "pdf": "https://arxiv.org/pdf/2505.06682", "abs": "https://arxiv.org/abs/2505.06682", "authors": ["Zijian Zhao"], "title": "A Short Overview of Multi-Modal Wi-Fi Sensing", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "Wi-Fi sensing has emerged as a significant technology in wireless sensing and\nIntegrated Sensing and Communication (ISAC), offering benefits such as low\ncost, high penetration, and enhanced privacy. Currently, it is widely utilized\nin various applications, including action recognition, human localization, and\ncrowd counting. However, Wi-Fi sensing also faces challenges, such as low\nrobustness and difficulties in data collection. Recently, there has been an\nincreasing focus on multi-modal Wi-Fi sensing, where other modalities can act\nas teachers, providing ground truth or robust features for Wi-Fi sensing models\nto learn from, or can be directly fused with Wi-Fi for enhanced sensing\ncapabilities. Although these methods have demonstrated promising results and\nsubstantial value in practical applications, there is a lack of comprehensive\nsurveys reviewing them. To address this gap, this paper reviews the multi-modal\nWi-Fi sensing literature \\textbf{from the past 24 months} and highlights the\ncurrent limitations, challenges and future directions in this field.", "AI": {"tldr": "A survey of multi-modal Wi-Fi sensing literature from the past 24 months, highlighting its benefits, challenges, and future directions.", "motivation": "To address the lack of comprehensive surveys on multi-modal Wi-Fi sensing, which combines Wi-Fi with other modalities for improved robustness and capabilities.", "method": "Reviewing recent literature (past 24 months) on multi-modal Wi-Fi sensing, analyzing methods where other modalities act as teachers or are fused with Wi-Fi.", "result": "Identifies promising results and practical value of multi-modal Wi-Fi sensing but notes challenges like low robustness and data collection difficulties.", "conclusion": "Highlights the need for further research to overcome current limitations and explores future directions in multi-modal Wi-Fi sensing."}}
{"id": "2505.06945", "pdf": "https://arxiv.org/pdf/2505.06945", "abs": "https://arxiv.org/abs/2505.06945", "authors": ["Maryam Farhadizadeh", "Maria Weymann", "Michael Bla\u00df", "Johann Kraus", "Christopher Gundler", "Sebastian Walter", "Noah Hempen", "Harald Binde", "Nadine Binder"], "title": "A systematic review of challenges and proposed solutions in modeling multimodal data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multimodal data modeling has emerged as a powerful approach in clinical\nresearch, enabling the integration of diverse data types such as imaging,\ngenomics, wearable sensors, and electronic health records. Despite its\npotential to improve diagnostic accuracy and support personalized care,\nmodeling such heterogeneous data presents significant technical challenges.\nThis systematic review synthesizes findings from 69 studies to identify common\nobstacles, including missing modalities, limited sample sizes, dimensionality\nimbalance, interpretability issues, and finding the optimal fusion techniques.\nWe highlight recent methodological advances, such as transfer learning,\ngenerative models, attention mechanisms, and neural architecture search that\noffer promising solutions. By mapping current trends and innovations, this\nreview provides a comprehensive overview of the field and offers practical\ninsights to guide future research and development in multimodal modeling for\nmedical applications.", "AI": {"tldr": "A systematic review of 69 studies on multimodal data modeling in clinical research, identifying challenges and recent methodological advances to improve diagnostic accuracy and personalized care.", "motivation": "To address the technical challenges of integrating diverse data types (e.g., imaging, genomics) in clinical research and improve diagnostic and personalized care outcomes.", "method": "Systematic review of 69 studies to identify common obstacles (e.g., missing modalities, dimensionality imbalance) and highlight methodological advances (e.g., transfer learning, generative models).", "result": "Identified key challenges and promising solutions, such as attention mechanisms and neural architecture search, for multimodal data modeling in medical applications.", "conclusion": "The review provides a comprehensive overview and practical insights to guide future research in multimodal modeling for clinical use."}}
{"id": "2410.18966", "pdf": "https://arxiv.org/pdf/2410.18966", "abs": "https://arxiv.org/abs/2410.18966", "authors": ["Yujuan Fu", "Ozlem Uzuner", "Meliha Yetisgen", "Fei Xia"], "title": "Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions", "categories": ["cs.CL"], "comment": "This paper is accepted by NAACL 2025 findings. Link to the paper\n  presentation: https://youtu.be/IhaxwbZOcaU", "summary": "Large language models (LLMs) have demonstrated great performance across\nvarious benchmarks, showing potential as general-purpose task solvers. However,\nas LLMs are typically trained on vast amounts of data, a significant concern in\ntheir evaluation is data contamination, where overlap between training data and\nevaluation datasets inflates performance assessments. Multiple approaches have\nbeen developed to identify data contamination. These approaches rely on\nspecific assumptions that may not hold universally across different settings.\nTo bridge this gap, we systematically review 50 papers on data contamination\ndetection, categorize the underlying assumptions, and assess whether they have\nbeen rigorously validated. We identify and analyze eight categories of\nassumptions and test three of them as case studies. Our case studies focus on\ndetecting direct, instance-level data contamination, which is also referred to\nas Membership Inference Attacks (MIA). Our analysis reveals that MIA approaches\nbased on these three assumptions can have similar performance to random\nguessing, on datasets used in LLM pretraining, suggesting that current LLMs\nmight learn data distributions rather than memorizing individual instances.\nMeanwhile, MIA can easily fail when there are data distribution shifts between\nthe seen and unseen instances.", "AI": {"tldr": "The paper reviews data contamination detection in LLMs, categorizes assumptions, and tests three in case studies, finding MIA approaches may perform poorly due to LLMs learning distributions rather than memorizing instances.", "motivation": "Address the gap in universally validated assumptions for detecting data contamination in LLMs, given their reliance on vast training data.", "method": "Systematically review 50 papers on data contamination detection, categorize assumptions, and test three in case studies focusing on Membership Inference Attacks (MIA).", "result": "MIA approaches based on tested assumptions perform similarly to random guessing, indicating LLMs learn distributions, not instances. MIA fails with data distribution shifts.", "conclusion": "Current MIA methods for detecting data contamination in LLMs are unreliable due to distribution learning and sensitivity to shifts, highlighting the need for better approaches."}}
{"id": "2505.07322", "pdf": "https://arxiv.org/pdf/2505.07322", "abs": "https://arxiv.org/abs/2505.07322", "authors": ["Gang He", "Siqi Wang", "Kepeng Xu", "Lin Zhang"], "title": "RealRep: Generalized SDR-to-HDR Conversion with Style Disentangled Representation Learning", "categories": ["cs.CV"], "comment": null, "summary": "High-Dynamic-Range Wide-Color-Gamut (HDR-WCG) technology is becoming\nincreasingly prevalent, intensifying the demand for converting Standard Dynamic\nRange (SDR) content to HDR. Existing methods primarily rely on fixed tone\nmapping operators, which are inadequate for handling SDR inputs with diverse\nstyles commonly found in real-world scenarios. To address this challenge, we\npropose a generalized SDR-to-HDR method that handles diverse styles in\nreal-world SDR content, termed Realistic Style Disentangled Representation\nLearning (RealRep). By disentangling luminance and chrominance, we analyze the\nintrinsic differences between contents with varying styles and propose a\ndisentangled multi-view style representation learning method. This approach\ncaptures the guidance prior of true luminance and chrominance distributions\nacross different styles, even when the SDR style distributions exhibit\nsignificant variations, thereby establishing a robust embedding space for\ninverse tone mapping. Motivated by the difficulty of directly utilizing\ndegradation representation priors, we further introduce the Degradation-Domain\nAware Controlled Mapping Network (DDACMNet), a two-stage framework that\nperforms adaptive hierarchical mapping guided by a control-aware normalization\nmechanism. DDACMNet dynamically modulates the mapping process via\ndegradation-conditioned hierarchical features, enabling robust adaptation\nacross diverse degradation domains. Extensive experiments show that RealRep\nconsistently outperforms state-of-the-art methods with superior generalization\nand perceptually faithful HDR color gamut reconstruction.", "AI": {"tldr": "The paper proposes RealRep, a method for converting SDR to HDR content by disentangling luminance and chrominance, and introduces DDACMNet for adaptive hierarchical mapping.", "motivation": "Existing fixed tone mapping methods fail to handle diverse SDR styles in real-world scenarios, necessitating a generalized approach.", "method": "RealRep disentangles luminance and chrominance for multi-view style representation learning. DDACMNet uses a two-stage framework with degradation-aware hierarchical mapping.", "result": "RealRep outperforms state-of-the-art methods, achieving superior generalization and perceptually faithful HDR reconstruction.", "conclusion": "The proposed methods effectively address diverse SDR styles and degradation domains, advancing SDR-to-HDR conversion."}}
{"id": "2505.06737", "pdf": "https://arxiv.org/pdf/2505.06737", "abs": "https://arxiv.org/abs/2505.06737", "authors": ["Ahmed Abouelazm", "Jonas Michel", "Helen Gremmelmaier", "Tim Joseph", "Philip Sch\u00f6rner", "J. Marius Z\u00f6llner"], "title": "Balancing Progress and Safety: A Novel Risk-Aware Objective for RL in Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted in the 36th IEEE Intelligent vehicles Symposium (IV 2025)", "summary": "Reinforcement Learning (RL) is a promising approach for achieving autonomous\ndriving due to robust decision-making capabilities. RL learns a driving policy\nthrough trial and error in traffic scenarios, guided by a reward function that\ncombines the driving objectives. The design of such reward function has\nreceived insufficient attention, yielding ill-defined rewards with various\npitfalls. Safety, in particular, has long been regarded only as a penalty for\ncollisions. This leaves the risks associated with actions leading up to a\ncollision unaddressed, limiting the applicability of RL in real-world\nscenarios. To address these shortcomings, our work focuses on enhancing the\nreward formulation by defining a set of driving objectives and structuring them\nhierarchically. Furthermore, we discuss the formulation of these objectives in\na normalized manner to transparently determine their contribution to the\noverall reward. Additionally, we introduce a novel risk-aware objective for\nvarious driving interactions based on a two-dimensional ellipsoid function and\nan extension of Responsibility-Sensitive Safety (RSS) concepts. We evaluate the\nefficacy of our proposed reward in unsignalized intersection scenarios with\nvarying traffic densities. The approach decreases collision rates by 21\\% on\naverage compared to baseline rewards and consistently surpasses them in route\nprogress and cumulative reward, demonstrating its capability to promote safer\ndriving behaviors while maintaining high-performance levels.", "AI": {"tldr": "The paper proposes a hierarchical and normalized reward function for RL in autonomous driving, introducing a risk-aware objective to improve safety and performance.", "motivation": "Current RL reward functions for autonomous driving are ill-defined, especially regarding safety, limiting real-world applicability.", "method": "The work enhances reward formulation by hierarchically structuring driving objectives, normalizing them, and introducing a novel risk-aware objective based on ellipsoid functions and RSS concepts.", "result": "The proposed reward function reduces collision rates by 21% and outperforms baselines in route progress and cumulative reward.", "conclusion": "The approach effectively promotes safer driving behaviors while maintaining high performance, addressing key limitations of existing RL reward designs."}}
{"id": "2505.06978", "pdf": "https://arxiv.org/pdf/2505.06978", "abs": "https://arxiv.org/abs/2505.06978", "authors": ["Lei Lei", "Kan Zheng", "Xuemin", "Shen"], "title": "Learning Value of Information towards Joint Communication and Control in 6G V2X", "categories": ["cs.LG"], "comment": null, "summary": "As Cellular Vehicle-to-Everything (C-V2X) evolves towards future\nsixth-generation (6G) networks, Connected Autonomous Vehicles (CAVs) are\nemerging to become a key application. Leveraging data-driven Machine Learning\n(ML), especially Deep Reinforcement Learning (DRL), is expected to\nsignificantly enhance CAV decision-making in both vehicle control and V2X\ncommunication under uncertainty. These two decision-making processes are\nclosely intertwined, with the value of information (VoI) acting as a crucial\nbridge between them. In this paper, we introduce Sequential Stochastic Decision\nProcess (SSDP) models to define and assess VoI, demonstrating their application\nin optimizing communication systems for CAVs. Specifically, we formally define\nthe SSDP model and demonstrate that the MDP model is a special case of it. The\nSSDP model offers a key advantage by explicitly representing the set of\ninformation that can enhance decision-making when available. Furthermore, as\ncurrent research on VoI remains fragmented, we propose a systematic VoI\nmodeling framework grounded in the MDP, Reinforcement Learning (RL) and Optimal\nControl theories. We define different categories of VoI and discuss their\ncorresponding estimation methods. Finally, we present a structured approach to\nleverage the various VoI metrics for optimizing the ``When\", ``What\", and\n``How\" to communicate problems. For this purpose, SSDP models are formulated\nwith VoI-associated reward functions derived from VoI-based optimization\nobjectives. While we use a simple vehicle-following control problem to\nillustrate the proposed methodology, it holds significant potential to\nfacilitate the joint optimization of stochastic, sequential control and\ncommunication decisions in a wide range of networked control systems.", "AI": {"tldr": "The paper introduces Sequential Stochastic Decision Process (SSDP) models to define and assess Value of Information (VoI) for optimizing communication systems in Connected Autonomous Vehicles (CAVs), bridging vehicle control and V2X communication.", "motivation": "To enhance CAV decision-making under uncertainty by leveraging data-driven ML, particularly DRL, and addressing the fragmented research on VoI.", "method": "Proposes SSDP models to define VoI, demonstrates MDP as a special case, and introduces a systematic VoI modeling framework based on MDP, RL, and Optimal Control theories.", "result": "SSDP models explicitly represent information sets for better decision-making, and a structured approach for optimizing communication problems (\"When\", \"What\", \"How\") is presented.", "conclusion": "The methodology, illustrated with a vehicle-following control problem, shows potential for joint optimization of control and communication in networked systems."}}
{"id": "2411.02316", "pdf": "https://arxiv.org/pdf/2411.02316", "abs": "https://arxiv.org/abs/2411.02316", "authors": ["Mete Ismayilzada", "Claire Stevenson", "Lonneke van der Plas"], "title": "Evaluating Creative Short Story Generation in Humans and Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ICCC 2025", "summary": "Story-writing is a fundamental aspect of human imagination, relying heavily\non creativity to produce narratives that are novel, effective, and surprising.\nWhile large language models (LLMs) have demonstrated the ability to generate\nhigh-quality stories, their creative story-writing capabilities remain\nunder-explored. In this work, we conduct a systematic analysis of creativity in\nshort story generation across 60 LLMs and 60 people using a five-sentence\ncue-word-based creative story-writing task. We use measures to automatically\nevaluate model- and human-generated stories across several dimensions of\ncreativity, including novelty, surprise, diversity, and linguistic complexity.\nWe also collect creativity ratings and Turing Test classifications from\nnon-expert and expert human raters and LLMs. Automated metrics show that LLMs\ngenerate stylistically complex stories, but tend to fall short in terms of\nnovelty, surprise and diversity when compared to average human writers. Expert\nratings generally coincide with automated metrics. However, LLMs and\nnon-experts rate LLM stories to be more creative than human-generated stories.\nWe discuss why and how these differences in ratings occur, and their\nimplications for both human and artificial creativity.", "AI": {"tldr": "The paper analyzes creativity in story-writing by comparing 60 LLMs and 60 humans using automated metrics and human ratings, finding LLMs lag in novelty and surprise but are rated more creative by non-experts and LLMs themselves.", "motivation": "To systematically explore and compare the creative capabilities of LLMs and humans in short story generation, addressing gaps in understanding LLM creativity.", "method": "A five-sentence cue-word-based task was used to generate stories, evaluated via automated metrics (novelty, surprise, diversity, complexity) and human ratings (experts, non-experts, LLMs).", "result": "LLMs produce stylistically complex stories but lack novelty and surprise compared to humans. Experts align with automated metrics, while non-experts and LLMs rate LLM stories as more creative.", "conclusion": "The study highlights discrepancies in creativity ratings, suggesting implications for evaluating both human and artificial creativity."}}
{"id": "2505.07333", "pdf": "https://arxiv.org/pdf/2505.07333", "abs": "https://arxiv.org/abs/2505.07333", "authors": ["Matthew Marchellus", "Nadhira Noor", "In Kyu Park"], "title": "Link to the Past: Temporal Propagation for Fast 3D Human Reconstruction from Monocular Video", "categories": ["cs.CV"], "comment": "Accepted in CVPR 2025", "summary": "Fast 3D clothed human reconstruction from monocular video remains a\nsignificant challenge in computer vision, particularly in balancing\ncomputational efficiency with reconstruction quality. Current approaches are\neither focused on static image reconstruction but too computationally\nintensive, or achieve high quality through per-video optimization that requires\nminutes to hours of processing, making them unsuitable for real-time\napplications. To this end, we present TemPoFast3D, a novel method that\nleverages temporal coherency of human appearance to reduce redundant\ncomputation while maintaining reconstruction quality. Our approach is a\n\"plug-and play\" solution that uniquely transforms pixel-aligned reconstruction\nnetworks to handle continuous video streams by maintaining and refining a\ncanonical appearance representation through efficient coordinate mapping.\nExtensive experiments demonstrate that TemPoFast3D matches or exceeds\nstate-of-the-art methods across standard metrics while providing high-quality\ntextured reconstruction across diverse pose and appearance, with a maximum\nspeed of 12 FPS.", "AI": {"tldr": "TemPoFast3D is a fast 3D clothed human reconstruction method from monocular video, balancing efficiency and quality by leveraging temporal coherency and efficient coordinate mapping.", "motivation": "Current methods are either too slow for real-time use or sacrifice quality for speed, highlighting the need for a balanced solution.", "method": "Uses temporal coherency and a 'plug-and-play' approach to transform pixel-aligned networks for continuous video streams, refining a canonical appearance representation.", "result": "Achieves 12 FPS, matches or exceeds state-of-the-art in quality, and handles diverse poses and appearances.", "conclusion": "TemPoFast3D offers a practical, high-quality solution for real-time 3D human reconstruction from video."}}
{"id": "2505.06740", "pdf": "https://arxiv.org/pdf/2505.06740", "abs": "https://arxiv.org/abs/2505.06740", "authors": ["Ahmed Abouelazm", "Mianzhi Liu", "Christian Hubschneider", "Yin Wu", "Daniel Slieter", "J. Marius Z\u00f6llner"], "title": "Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)", "summary": "Accurate prediction of surrounding road users' trajectories is essential for\nsafe and efficient autonomous driving. While deep learning models have improved\nperformance, challenges remain in preventing off-road predictions and ensuring\nkinematic feasibility. Existing methods incorporate road-awareness modules and\nenforce kinematic constraints but lack plausibility guarantees and often\nintroduce trade-offs in complexity and flexibility. This paper proposes a novel\nframework that formulates trajectory prediction as a constrained regression\nguided by permissible driving directions and their boundaries. Using the\nagent's current state and an HD map, our approach defines the valid boundaries\nand ensures on-road predictions by training the network to learn superimposed\npaths between left and right boundary polylines. To guarantee feasibility, the\nmodel predicts acceleration profiles that determine the vehicle's travel\ndistance along these paths while adhering to kinematic constraints. We evaluate\nour approach on the Argoverse-2 dataset against the HPTR baseline. Our approach\nshows a slight decrease in benchmark metrics compared to HPTR but notably\nimproves final displacement error and eliminates infeasible trajectories.\nMoreover, the proposed approach has superior generalization to less prevalent\nmaneuvers and unseen out-of-distribution scenarios, reducing the off-road rate\nunder adversarial attacks from 66\\% to just 1\\%. These results highlight the\neffectiveness of our approach in generating feasible and robust predictions.", "AI": {"tldr": "A novel framework for trajectory prediction in autonomous driving ensures on-road and kinematically feasible predictions by using permissible driving directions and boundaries, outperforming baselines in robustness and feasibility.", "motivation": "Improving trajectory prediction for autonomous driving by addressing off-road predictions and kinematic feasibility, which existing methods lack.", "method": "Formulates trajectory prediction as constrained regression using HD maps and boundary polylines, predicting acceleration profiles for kinematic feasibility.", "result": "Slight decrease in benchmark metrics but improves final displacement error, eliminates infeasible trajectories, and reduces off-road rates significantly.", "conclusion": "The proposed framework effectively generates feasible and robust predictions, especially in challenging scenarios."}}
{"id": "2505.07004", "pdf": "https://arxiv.org/pdf/2505.07004", "abs": "https://arxiv.org/abs/2505.07004", "authors": ["Jinuk Kim", "Marwa El Halabi", "Wonpyo Park", "Clemens JS Schaefer", "Deokjae Lee", "Yeonhong Park", "Jae W. Lee", "Hyun Oh Song"], "title": "GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Post-training quantization is a key technique for reducing the memory and\ninference latency of large language models by quantizing weights and\nactivations without requiring retraining. However, existing methods either (1)\nfail to account for the varying importance of hidden features to the end loss\nor, when incorporating end loss, (2) neglect the critical interactions between\nmodel weights. To address these limitations, we propose GuidedQuant, a novel\nquantization approach that integrates gradient information from the end loss\ninto the quantization objective while preserving cross-weight dependencies\nwithin output channels. GuidedQuant consistently boosts the performance of\nstate-of-the-art quantization methods across weight-only scalar, weight-only\nvector, and weight-and-activation quantization. Additionally, we introduce a\nnovel non-uniform scalar quantization algorithm, which is guaranteed to\nmonotonically decrease the quantization objective value, and outperforms\nexisting methods in this category. We release the code at\nhttps://github.com/snu-mllab/GuidedQuant.", "AI": {"tldr": "GuidedQuant improves post-training quantization by integrating gradient information and preserving weight dependencies, outperforming existing methods.", "motivation": "Existing quantization methods either ignore feature importance or neglect weight interactions, limiting performance.", "method": "GuidedQuant uses gradient information and preserves cross-weight dependencies, with a novel non-uniform scalar quantization algorithm.", "result": "GuidedQuant enhances performance across quantization types and introduces a superior non-uniform scalar method.", "conclusion": "GuidedQuant advances quantization by addressing key limitations, with code publicly available."}}
{"id": "2411.03700", "pdf": "https://arxiv.org/pdf/2411.03700", "abs": "https://arxiv.org/abs/2411.03700", "authors": ["Anaelia Ovalle", "Krunoslav Lehman Pavasovic", "Louis Martin", "Luke Zettlemoyer", "Eric Michael Smith", "Kai-Wei Chang", "Adina Williams", "Levent Sagun"], "title": "The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms in Aligned Language Models", "categories": ["cs.CL"], "comment": "Accepted to 2025 ACM FAccT", "summary": "Natural-language assistants are designed to provide users with helpful\nresponses while avoiding harmful outputs, largely achieved through alignment to\nhuman preferences. Yet there is limited understanding of whether alignment\ntechniques may inadvertently perpetuate or even amplify harmful biases\ninherited from their pre-aligned base models. This issue is compounded by the\nchoice of bias evaluation benchmarks in popular preference-finetuned models,\nwhich predominantly focus on dominant social categories, such as binary gender,\nthereby limiting insights into biases affecting underrepresented groups.\nTowards addressing this gap, we center transgender, nonbinary, and other\ngender-diverse identities to investigate how alignment procedures interact with\npre-existing gender-diverse bias in LLMs. Our key contributions include: 1) a\ncomprehensive survey of bias evaluation modalities across leading\npreference-finetuned LLMs, highlighting critical gaps in gender-diverse\nrepresentation, 2) systematic evaluation of gender-diverse biases across 16\nmodels spanning Direct Preference Optimization (DPO) stages, uncovering harms\npopular bias benchmarks fail to detect, and 3) a flexible framework for\nmeasuring harmful biases in implicit reward signals applicable to other social\ncontexts. Our findings reveal that DPO-aligned models are particularly\nsensitive to supervised finetuning (SFT), and can amplify two forms of\nreal-world gender-diverse harms from their base models: stigmatization and\ngender non-affirmative language. We conclude with recommendations tailored to\nDPO and broader alignment practices, advocating for the adoption of\ncommunity-informed bias evaluation frameworks to more effectively identify and\naddress underrepresented harms in LLMs.", "AI": {"tldr": "The paper investigates how alignment techniques in LLMs may amplify biases, especially for gender-diverse groups, revealing gaps in current benchmarks and proposing a framework for better bias evaluation.", "motivation": "To address the lack of understanding of how alignment techniques perpetuate biases, particularly for underrepresented gender-diverse identities, and to highlight gaps in current bias evaluation benchmarks.", "method": "The study includes a survey of bias evaluation in LLMs, systematic evaluation of gender-diverse biases across 16 models, and proposes a framework for measuring harmful biases in reward signals.", "result": "DPO-aligned models amplify stigmatization and gender non-affirmative language from base models, with sensitivity to supervised finetuning.", "conclusion": "Recommends community-informed bias evaluation frameworks to better identify and address underrepresented harms in LLM alignment practices."}}
{"id": "2505.07336", "pdf": "https://arxiv.org/pdf/2505.07336", "abs": "https://arxiv.org/abs/2505.07336", "authors": ["Zhixuan Zhang", "Xiaopeng Li", "Qi Liu"], "title": "SAEN-BGS: Energy-Efficient Spiking AutoEncoder Network for Background Subtraction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by Pattern Recognition", "summary": "Background subtraction (BGS) is utilized to detect moving objects in a video\nand is commonly employed at the onset of object tracking and human recognition\nprocesses. Nevertheless, existing BGS techniques utilizing deep learning still\nencounter challenges with various background noises in videos, including\nvariations in lighting, shifts in camera angles, and disturbances like air\nturbulence or swaying trees. To address this problem, we design a spiking\nautoencoder network, termed SAEN-BGS, based on noise resilience and\ntime-sequence sensitivity of spiking neural networks (SNNs) to enhance the\nseparation of foreground and background. To eliminate unnecessary background\nnoise and preserve the important foreground elements, we begin by creating the\ncontinuous spiking conv-and-dconv block, which serves as the fundamental\nbuilding block for the decoder in SAEN-BGS. Moreover, in striving for enhanced\nenergy efficiency, we introduce a novel self-distillation spiking supervised\nlearning method grounded in ANN-to-SNN frameworks, resulting in decreased power\nconsumption. In extensive experiments conducted on CDnet-2014 and DAVIS-2016\ndatasets, our approach demonstrates superior segmentation performance relative\nto other baseline methods, even when challenged by complex scenarios with\ndynamic backgrounds.", "AI": {"tldr": "A spiking autoencoder network (SAEN-BGS) is proposed to improve background subtraction by leveraging noise resilience and time-sequence sensitivity of spiking neural networks, achieving better segmentation and energy efficiency.", "motivation": "Existing deep learning-based BGS methods struggle with background noises like lighting changes and camera shifts. SAEN-BGS aims to enhance foreground-background separation.", "method": "Develops a spiking autoencoder with continuous spiking conv-and-dconv blocks and a self-distillation spiking supervised learning method for energy efficiency.", "result": "Outperforms baseline methods on CDnet-2014 and DAVIS-2016 datasets, even in dynamic backgrounds.", "conclusion": "SAEN-BGS effectively addresses noise challenges in BGS while improving performance and energy efficiency."}}
{"id": "2505.06743", "pdf": "https://arxiv.org/pdf/2505.06743", "abs": "https://arxiv.org/abs/2505.06743", "authors": ["Marius Baden", "Ahmed Abouelazm", "Christian Hubschneider", "Yin Wu", "Daniel Slieter", "J. Marius Z\u00f6llner"], "title": "TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)\n  for oral presentation", "summary": "Trajectory prediction is crucial for autonomous driving, enabling vehicles to\nnavigate safely by anticipating the movements of surrounding road users.\nHowever, current deep learning models often lack trustworthiness as their\npredictions can be physically infeasible and illogical to humans. To make\npredictions more trustworthy, recent research has incorporated prior knowledge,\nlike the social force model for modeling interactions and kinematic models for\nphysical realism. However, these approaches focus on priors that suit either\nvehicles or pedestrians and do not generalize to traffic with mixed agent\nclasses. We propose incorporating interaction and kinematic priors of all agent\nclasses--vehicles, pedestrians, and cyclists with class-specific interaction\nlayers to capture agent behavioral differences. To improve the interpretability\nof the agent interactions, we introduce DG-SFM, a rule-based interaction\nimportance score that guides the interaction layer. To ensure physically\nfeasible predictions, we proposed suitable kinematic models for all agent\nclasses with a novel pedestrian kinematic model. We benchmark our approach on\nthe Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our\nbaseline. Experiments demonstrate that our method improves interaction\ninterpretability, revealing a correlation between incorrect predictions and\ndivergence from our interaction prior. Even though incorporating the kinematic\nmodels causes a slight decrease in accuracy, they eliminate infeasible\ntrajectories found in the dataset and the baseline model. Thus, our approach\nfosters trust in trajectory prediction as its interaction reasoning is\ninterpretable, and its predictions adhere to physics.", "AI": {"tldr": "The paper proposes a method to improve trajectory prediction in autonomous driving by incorporating class-specific interaction and kinematic priors for vehicles, pedestrians, and cyclists, enhancing interpretability and physical feasibility.", "motivation": "Current deep learning models for trajectory prediction lack trustworthiness due to physically infeasible and illogical predictions. Existing approaches focus on single agent classes, failing to generalize to mixed traffic.", "method": "The authors introduce class-specific interaction layers and a rule-based interaction importance score (DG-SFM) for interpretability. They also propose suitable kinematic models for all agent classes, including a novel pedestrian kinematic model.", "result": "Experiments on the Argoverse 2 dataset show improved interaction interpretability and physically feasible predictions, though with a slight accuracy trade-off.", "conclusion": "The approach enhances trust in trajectory prediction by ensuring interpretable interactions and adherence to physical constraints."}}
{"id": "2505.07023", "pdf": "https://arxiv.org/pdf/2505.07023", "abs": "https://arxiv.org/abs/2505.07023", "authors": ["Alexander Koebler", "Thomas Decker", "Ingo Thon", "Volker Tresp", "Florian Buettner"], "title": "Incremental Uncertainty-aware Performance Monitoring with Active Labeling Intervention", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We study the problem of monitoring machine learning models under gradual\ndistribution shifts, where circumstances change slowly over time, often leading\nto unnoticed yet significant declines in accuracy. To address this, we propose\nIncremental Uncertainty-aware Performance Monitoring (IUPM), a novel label-free\nmethod that estimates performance changes by modeling gradual shifts using\noptimal transport. In addition, IUPM quantifies the uncertainty in the\nperformance prediction and introduces an active labeling procedure to restore a\nreliable estimate under a limited labeling budget. Our experiments show that\nIUPM outperforms existing performance estimation baselines in various gradual\nshift scenarios and that its uncertainty awareness guides label acquisition\nmore effectively compared to other strategies.", "AI": {"tldr": "IUPM is a label-free method for monitoring ML models under gradual distribution shifts, using optimal transport and active labeling to estimate performance changes and manage uncertainty.", "motivation": "Address unnoticed accuracy declines in ML models due to slow, gradual distribution shifts.", "method": "Proposes IUPM, which models shifts using optimal transport, quantifies uncertainty, and uses active labeling under budget constraints.", "result": "IUPM outperforms baselines in gradual shift scenarios and improves label acquisition efficiency.", "conclusion": "IUPM effectively monitors performance and manages uncertainty in gradual distribution shifts."}}
{"id": "2411.04223", "pdf": "https://arxiv.org/pdf/2411.04223", "abs": "https://arxiv.org/abs/2411.04223", "authors": ["Weiliang Zhao", "Daniel Ben-Levi", "Wei Hao", "Junfeng Yang", "Chengzhi Mao"], "title": "Diversity Helps Jailbreak Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We have uncovered a powerful jailbreak technique that leverages large\nlanguage models' ability to diverge from prior context, enabling them to bypass\nsafety constraints and generate harmful outputs. By simply instructing the LLM\nto deviate and obfuscate previous attacks, our method dramatically outperforms\nexisting approaches, achieving up to a 62.83% higher success rate in\ncompromising ten leading chatbots, including GPT-4, Gemini, and Llama, while\nusing only 12.9% of the queries. This revelation exposes a critical flaw in\ncurrent LLM safety training, suggesting that existing methods may merely mask\nvulnerabilities rather than eliminate them. Our findings sound an urgent alarm\nfor the need to revolutionize testing methodologies to ensure robust and\nreliable LLM security.", "AI": {"tldr": "A new jailbreak technique exploits LLMs' ability to diverge from context, bypassing safety constraints with high success rates, exposing flaws in current safety training.", "motivation": "To highlight vulnerabilities in LLM safety mechanisms and demonstrate how easily they can be bypassed.", "method": "Instructs LLMs to deviate and obfuscate prior attacks, requiring fewer queries than existing methods.", "result": "Achieves 62.83% higher success rate in compromising top chatbots like GPT-4, Gemini, and Llama, using only 12.9% of queries.", "conclusion": "Current safety methods may only mask vulnerabilities; urgent revolution in testing is needed for robust LLM security."}}
{"id": "2505.07344", "pdf": "https://arxiv.org/pdf/2505.07344", "abs": "https://arxiv.org/abs/2505.07344", "authors": ["Yuan Zhang", "Jiacheng Jiang", "Guoqing Ma", "Zhiying Lu", "Haoyang Huang", "Jianlong Yuan", "Nan Duan"], "title": "Generative Pre-trained Autoregressive Diffusion Transformer", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this work, we present GPDiT, a Generative Pre-trained Autoregressive\nDiffusion Transformer that unifies the strengths of diffusion and\nautoregressive modeling for long-range video synthesis, within a continuous\nlatent space. Instead of predicting discrete tokens, GPDiT autoregressively\npredicts future latent frames using a diffusion loss, enabling natural modeling\nof motion dynamics and semantic consistency across frames. This continuous\nautoregressive framework not only enhances generation quality but also endows\nthe model with representation capabilities. Additionally, we introduce a\nlightweight causal attention variant and a parameter-free rotation-based\ntime-conditioning mechanism, improving both the training and inference\nefficiency. Extensive experiments demonstrate that GPDiT achieves strong\nperformance in video generation quality, video representation ability, and\nfew-shot learning tasks, highlighting its potential as an effective framework\nfor video modeling in continuous space.", "AI": {"tldr": "GPDiT combines diffusion and autoregressive modeling for long-range video synthesis in continuous latent space, improving generation quality and representation.", "motivation": "To unify diffusion and autoregressive modeling for better video synthesis and representation in continuous space.", "method": "GPDiT predicts future latent frames autoregressively using diffusion loss, with causal attention and time-conditioning mechanisms.", "result": "Achieves strong performance in video generation, representation, and few-shot learning.", "conclusion": "GPDiT is a promising framework for continuous-space video modeling."}}
{"id": "2505.06799", "pdf": "https://arxiv.org/pdf/2505.06799", "abs": "https://arxiv.org/abs/2505.06799", "authors": ["Erik L. Connerty", "Ethan N. Evans", "Gerasimos Angelatos", "Vignesh Narayanan"], "title": "Quantum Observers: A NISQ Hardware Demonstration of Chaotic State Prediction Using Quantum Echo-state Networks", "categories": ["quant-ph", "cs.AI"], "comment": "14 pages, 12 figures", "summary": "Recent advances in artificial intelligence have highlighted the remarkable\ncapabilities of neural network (NN)-powered systems on classical computers.\nHowever, these systems face significant computational challenges that limit\nscalability and efficiency. Quantum computers hold the potential to overcome\nthese limitations and increase processing power beyond classical systems.\nDespite this, integrating quantum computing with NNs remains largely unrealized\ndue to challenges posed by noise, decoherence, and high error rates in current\nquantum hardware. Here, we propose a novel quantum echo-state network (QESN)\ndesign and implementation algorithm that can operate within the presence of\nnoise on current IBM hardware. We apply classical control-theoretic response\nanalysis to characterize the QESN, emphasizing its rich nonlinear dynamics and\nmemory, as well as its ability to be fine-tuned with sparsity and re-uploading\nblocks. We validate our approach through a comprehensive demonstration of QESNs\nfunctioning as quantum observers, applied in both high-fidelity simulations and\nhardware experiments utilizing data from a prototypical chaotic Lorenz system.\nOur results show that the QESN can predict long time-series with persistent\nmemory, running over 100 times longer than the median T}1 and T2 of the IBM\nMarrakesh QPU, achieving state-of-the-art time-series performance on\nsuperconducting hardware.", "AI": {"tldr": "A novel quantum echo-state network (QESN) is proposed to address noise and decoherence in quantum hardware, demonstrating superior time-series prediction on IBM quantum processors.", "motivation": "To overcome computational limitations of classical neural networks by leveraging quantum computing, despite challenges like noise and decoherence.", "method": "Introduces a QESN design and implementation algorithm, validated through simulations and hardware experiments using chaotic Lorenz system data.", "result": "QESN predicts long time-series with persistent memory, outperforming classical systems and running 100x longer than IBM QPU's median T1/T2 times.", "conclusion": "QESN offers a scalable and efficient quantum-classical hybrid approach for time-series tasks on noisy quantum hardware."}}
{"id": "2505.07026", "pdf": "https://arxiv.org/pdf/2505.07026", "abs": "https://arxiv.org/abs/2505.07026", "authors": ["Maximilian Egger", "Rawad Bitar", "R\u00fcdiger Urbanke"], "title": "Efficient Machine Unlearning by Model Splitting and Core Sample Selection", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Machine unlearning is essential for meeting legal obligations such as the\nright to be forgotten, which requires the removal of specific data from machine\nlearning models upon request. While several approaches to unlearning have been\nproposed, existing solutions often struggle with efficiency and, more\ncritically, with the verification of unlearning - particularly in the case of\nweak unlearning guarantees, where verification remains an open challenge. We\nintroduce a generalized variant of the standard unlearning metric that enables\nmore efficient and precise unlearning strategies. We also present an\nunlearning-aware training procedure that, in many cases, allows for exact\nunlearning. We term our approach MaxRR. When exact unlearning is not feasible,\nMaxRR still supports efficient unlearning with properties closely matching\nthose achieved through full retraining.", "AI": {"tldr": "MaxRR introduces a generalized unlearning metric and an unlearning-aware training procedure for efficient and precise machine unlearning, addressing challenges in verification and weak guarantees.", "motivation": "To meet legal requirements like the right to be forgotten, efficient and verifiable machine unlearning is needed, but current methods lack efficiency and strong verification.", "method": "Develops a generalized unlearning metric and an unlearning-aware training procedure (MaxRR) to enable exact or near-exact unlearning.", "result": "MaxRR achieves efficient unlearning with properties close to full retraining, even when exact unlearning isn't feasible.", "conclusion": "MaxRR provides a robust solution for machine unlearning, improving efficiency and verification, and is adaptable to cases where exact unlearning is impossible."}}
{"id": "2411.15100", "pdf": "https://arxiv.org/pdf/2411.15100", "abs": "https://arxiv.org/abs/2411.15100", "authors": ["Yixin Dong", "Charlie F. Ruan", "Yaxing Cai", "Ruihang Lai", "Ziyi Xu", "Yilong Zhao", "Tianqi Chen"], "title": "XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.PL"], "comment": "MLSys '25", "summary": "The applications of LLM Agents are becoming increasingly complex and diverse,\nleading to a high demand for structured outputs that can be parsed into code,\nstructured function calls, and embodied agent commands. These developments\nbring significant demands for structured generation in LLM inference.\nContext-free grammar is a flexible approach to enable structured generation via\nconstrained decoding. However, executing context-free grammar requires going\nthrough several stack states over all tokens in vocabulary during runtime,\nbringing non-negligible overhead for structured generation. In this paper, we\npropose XGrammar, a flexible and efficient structure generation engine for\nlarge language models. XGrammar accelerates context-free grammar execution by\ndividing the vocabulary into context-independent tokens that can be prechecked\nand context-dependent tokens that need to be interpreted during runtime. We\nfurther build transformations to expand the grammar context and reduce the\nnumber of context-independent tokens. Additionally, we build an efficient\npersistent stack to accelerate the context-dependent token checks. Finally, we\nco-design the grammar engine with LLM inference engine to overlap grammar\ncomputation with GPU executions. Evaluation results show that XGrammar can\nachieve up to 100x speedup over existing solutions. Combined with an LLM\ninference engine, it can generate near-zero overhead structure generation in\nend-to-end low-LLM serving.", "AI": {"tldr": "XGrammar is a new engine for efficient structured generation in LLMs, using context-free grammar optimizations to reduce runtime overhead and achieve significant speedups.", "motivation": "The increasing complexity of LLM applications demands structured outputs, but current context-free grammar methods introduce high runtime overhead.", "method": "XGrammar divides vocabulary into context-independent and context-dependent tokens, expands grammar context, and uses a persistent stack for efficient checks. It also co-designs with LLM inference engines.", "result": "XGrammar achieves up to 100x speedup over existing solutions and near-zero overhead in end-to-end LLM serving.", "conclusion": "XGrammar provides a flexible and efficient solution for structured generation in LLMs, addressing runtime overhead and enabling practical deployment."}}
{"id": "2505.07347", "pdf": "https://arxiv.org/pdf/2505.07347", "abs": "https://arxiv.org/abs/2505.07347", "authors": ["Jiewen Yang", "Taoran Huang", "Shangwei Ding", "Xiaowei Xu", "Qinhua Zhao", "Yong Jiang", "Jiarong Guo", "Bin Pu", "Jiexuan Zheng", "Caojin Zhang", "Hongwen Fei", "Xiaomeng Li"], "title": "AI-Enabled Accurate Non-Invasive Assessment of Pulmonary Hypertension Progression via Multi-Modal Echocardiography", "categories": ["cs.CV"], "comment": null, "summary": "Echocardiographers can detect pulmonary hypertension using Doppler\nechocardiography; however, accurately assessing its progression often proves\nchallenging. Right heart catheterization (RHC), the gold standard for precise\nevaluation, is invasive and unsuitable for routine use, limiting its\npracticality for timely diagnosis and monitoring of pulmonary hypertension\nprogression. Here, we propose MePH, a multi-view, multi-modal vision-language\nmodel to accurately assess pulmonary hypertension progression using\nnon-invasive echocardiography. We constructed a large dataset comprising paired\nstandardized echocardiogram videos, spectral images and RHC data, covering\n1,237 patient cases from 12 medical centers. For the first time, MePH precisely\nmodels the correlation between non-invasive multi-view, multi-modal\nechocardiography and the pressure and resistance obtained via RHC. We show that\nMePH significantly outperforms echocardiographers' assessments using\nechocardiography, reducing the mean absolute error in estimating mean pulmonary\narterial pressure (mPAP) and pulmonary vascular resistance (PVR) by 49.73% and\n43.81%, respectively. In eight independent external hospitals, MePH achieved a\nmean absolute error of 3.147 for PVR assessment. Furthermore, MePH achieved an\narea under the curve of 0.921, surpassing echocardiographers (area under the\ncurve of 0.842) in accurately predicting the severity of pulmonary\nhypertension, whether mild or severe. A prospective study demonstrated that\nMePH can predict treatment efficacy for patients. Our work provides pulmonary\nhypertension patients with a non-invasive and timely method for monitoring\ndisease progression, improving the accuracy and efficiency of pulmonary\nhypertension management while enabling earlier interventions and more\npersonalized treatment decisions.", "AI": {"tldr": "MePH, a multi-view, multi-modal vision-language model, improves non-invasive assessment of pulmonary hypertension progression using echocardiography, outperforming traditional methods and echocardiographers.", "motivation": "Current methods for assessing pulmonary hypertension progression, like right heart catheterization (RHC), are invasive and impractical for routine use, creating a need for accurate non-invasive alternatives.", "method": "MePH leverages a large dataset of paired echocardiogram videos, spectral images, and RHC data to model correlations between non-invasive echocardiography and RHC-derived metrics.", "result": "MePH reduces mean absolute error in estimating mPAP and PVR by 49.73% and 43.81%, respectively, and achieves superior accuracy in predicting severity (AUC 0.921 vs. 0.842).", "conclusion": "MePH offers a non-invasive, timely, and accurate solution for monitoring pulmonary hypertension, enabling earlier interventions and personalized treatments."}}
{"id": "2505.06821", "pdf": "https://arxiv.org/pdf/2505.06821", "abs": "https://arxiv.org/abs/2505.06821", "authors": ["Dipayan Saha", "Hasan Al Shaikh", "Shams Tarek", "Farimah Farahmandi"], "title": "ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification", "categories": ["cs.CR", "cs.AI", "cs.ET"], "comment": "This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025", "summary": "Current hardware security verification processes predominantly rely on manual\nthreat modeling and test plan generation, which are labor-intensive,\nerror-prone, and struggle to scale with increasing design complexity and\nevolving attack methodologies. To address these challenges, we propose\nThreatLens, an LLM-driven multi-agent framework that automates security threat\nmodeling and test plan generation for hardware security verification.\nThreatLens integrates retrieval-augmented generation (RAG) to extract relevant\nsecurity knowledge, LLM-powered reasoning for threat assessment, and\ninteractive user feedback to ensure the generation of practical test plans. By\nautomating these processes, the framework reduces the manual verification\neffort, enhances coverage, and ensures a structured, adaptable approach to\nsecurity verification. We evaluated our framework on the NEORV32 SoC,\ndemonstrating its capability to automate security verification through\nstructured test plans and validating its effectiveness in real-world scenarios.", "AI": {"tldr": "ThreatLens automates hardware security verification using LLMs and RAG, reducing manual effort and improving coverage.", "motivation": "Manual threat modeling and test plan generation are labor-intensive and error-prone, especially with increasing design complexity.", "method": "ThreatLens uses LLM-driven multi-agent framework with RAG for knowledge extraction, threat assessment, and user feedback.", "result": "Evaluated on NEORV32 SoC, it automates verification with structured test plans, proving effectiveness in real-world scenarios.", "conclusion": "ThreatLens offers a scalable, adaptable solution for hardware security verification."}}
{"id": "2505.07036", "pdf": "https://arxiv.org/pdf/2505.07036", "abs": "https://arxiv.org/abs/2505.07036", "authors": ["Mahade Hasan", "Farhana Yasmin"], "title": "Predicting Diabetes Using Machine Learning: A Comparative Study of Classifiers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diabetes remains a significant health challenge globally, contributing to\nsevere complications like kidney disease, vision loss, and heart issues. The\napplication of machine learning (ML) in healthcare enables efficient and\naccurate disease prediction, offering avenues for early intervention and\npatient support. Our study introduces an innovative diabetes prediction\nframework, leveraging both traditional ML techniques such as Logistic\nRegression, SVM, Na\\\"ive Bayes, and Random Forest and advanced ensemble methods\nlike AdaBoost, Gradient Boosting, Extra Trees, and XGBoost. Central to our\napproach is the development of a novel model, DNet, a hybrid architecture\ncombining Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM)\nlayers for effective feature extraction and sequential learning. The DNet model\ncomprises an initial convolutional block for capturing essential features,\nfollowed by a residual block with skip connections to facilitate efficient\ninformation flow. Batch Normalization and Dropout are employed for robust\nregularization, and an LSTM layer captures temporal dependencies within the\ndata. Using a Kaggle-sourced real-world diabetes dataset, our model evaluation\nspans cross-validation accuracy, precision, recall, F1 score, and ROC-AUC.\nAmong the models, DNet demonstrates the highest efficacy with an accuracy of\n99.79% and an AUC-ROC of 99.98%, establishing its potential for superior\ndiabetes prediction. This robust hybrid architecture showcases the value of\ncombining CNN and LSTM layers, emphasizing its applicability in medical\ndiagnostics and disease prediction tasks.", "AI": {"tldr": "A novel hybrid model (DNet) combining CNN and LSTM outperforms traditional and ensemble ML methods in diabetes prediction, achieving 99.79% accuracy and 99.98% AUC-ROC.", "motivation": "Diabetes causes severe complications, and ML can enable early intervention. The study aims to improve prediction accuracy with a hybrid model.", "method": "Developed DNet, a CNN-LSTM hybrid with residual blocks, batch normalization, and dropout. Compared it with traditional and ensemble ML methods using a Kaggle dataset.", "result": "DNet achieved 99.79% accuracy and 99.98% AUC-ROC, outperforming other models.", "conclusion": "The hybrid CNN-LSTM architecture is highly effective for diabetes prediction, highlighting its potential in medical diagnostics."}}
{"id": "2412.05342", "pdf": "https://arxiv.org/pdf/2412.05342", "abs": "https://arxiv.org/abs/2412.05342", "authors": ["Xiaoyu Wang", "Ningyuan Xi", "Teng Chen", "Qingqing Gu", "Yue Zhao", "Xiaokai Chen", "Zhonglin Jiang", "Yong Chen", "Luo Ji"], "title": "Multi-Party Supervised Fine-tuning of Language Models for Multi-Party Dialogue Generation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IJCNN 2025", "summary": "Large Language Models (LLM) are usually fine-tuned to participate in dyadic\nor two-party dialogues, which can not adapt well to multi-party dialogues\n(MPD), which hinders their applications in such scenarios including\nmulti-personal meetings, discussions and daily communication. Previous\nLLM-based researches mainly focus on the multi-agent framework, while their\nbase LLMs are still pairwisely fine-tuned. In this work, we design a\nmulti-party fine-tuning framework (MuPaS) for LLMs on the multi-party dialogue\ndatasets, and prove such a straightforward framework can let the LLM align with\nthe multi-party conversation style efficiently and effectively. We also design\ntwo training strategies which can convert MuPaS into the MPD simulator.\nSubstantial experiments show that MuPaS can achieve state-of-the-art\nmulti-party response, higher accuracy of the-next-speaker prediction, higher\nhuman and automatic evaluated utterance qualities, and can even generate\nreasonably with out-of-distribution scene, topic and role descriptions. The\nMuPaS framework bridges the LLM training with more complicated multi-party\napplications, such as conversation generation, virtual rehearsal or\nmeta-universe.", "AI": {"tldr": "MuPaS is a multi-party fine-tuning framework for LLMs, improving their performance in multi-party dialogues (MPD) compared to traditional dyadic fine-tuning.", "motivation": "Existing LLMs are fine-tuned for dyadic dialogues, limiting their effectiveness in multi-party scenarios like meetings or discussions.", "method": "MuPaS fine-tunes LLMs on multi-party dialogue datasets and includes training strategies to convert it into an MPD simulator.", "result": "MuPaS achieves state-of-the-art multi-party response quality, accurate next-speaker prediction, and handles out-of-distribution scenarios well.", "conclusion": "MuPaS bridges LLM training with complex multi-party applications, enabling better performance in diverse scenarios."}}
{"id": "2505.07373", "pdf": "https://arxiv.org/pdf/2505.07373", "abs": "https://arxiv.org/abs/2505.07373", "authors": ["Lintao Xiang", "Hongpei Zheng", "Bailin Deng", "Hujun Yin"], "title": "Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild", "categories": ["cs.CV"], "comment": null, "summary": "Neural implicit surface reconstruction using volume rendering techniques has\nrecently achieved significant advancements in creating high-fidelity surfaces\nfrom multiple 2D images. However, current methods primarily target scenes with\nconsistent illumination and struggle to accurately reconstruct 3D geometry in\nuncontrolled environments with transient occlusions or varying appearances.\nWhile some neural radiance field (NeRF)-based variants can better manage\nphotometric variations and transient objects in complex scenes, they are\ndesigned for novel view synthesis rather than precise surface reconstruction\ndue to limited surface constraints. To overcome this limitation, we introduce a\nnovel approach that applies multiple geometric constraints to the implicit\nsurface optimization process, enabling more accurate reconstructions from\nunconstrained image collections. First, we utilize sparse 3D points from\nstructure-from-motion (SfM) to refine the signed distance function estimation\nfor the reconstructed surface, with a displacement compensation to accommodate\nnoise in the sparse points. Additionally, we employ robust normal priors\nderived from a normal predictor, enhanced by edge prior filtering and\nmulti-view consistency constraints, to improve alignment with the actual\nsurface geometry. Extensive testing on the Heritage-Recon benchmark and other\ndatasets has shown that the proposed method can accurately reconstruct surfaces\nfrom in-the-wild images, yielding geometries with superior accuracy and\ngranularity compared to existing techniques. Our approach enables high-quality\n3D reconstruction of various landmarks, making it applicable to diverse\nscenarios such as digital preservation of cultural heritage sites.", "AI": {"tldr": "A novel method improves neural implicit surface reconstruction by applying geometric constraints, enabling accurate 3D geometry from unconstrained images.", "motivation": "Current methods struggle with uncontrolled environments and transient occlusions, limiting accurate surface reconstruction.", "method": "Uses sparse 3D points from SfM and robust normal priors with edge filtering and multi-view consistency for precise surface optimization.", "result": "Achieves superior accuracy and granularity in surface reconstruction compared to existing techniques.", "conclusion": "Enables high-quality 3D reconstruction for diverse applications like cultural heritage preservation."}}
{"id": "2505.06827", "pdf": "https://arxiv.org/pdf/2505.06827", "abs": "https://arxiv.org/abs/2505.06827", "authors": ["Fabrice Y Harel-Canada", "Boran Erol", "Connor Choi", "Jason Liu", "Gary Jiarui Song", "Nanyun Peng", "Amit Sahai"], "title": "Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking", "categories": ["cs.CR", "cs.AI"], "comment": "In Review @ ACL 2025", "summary": "Watermarking AI-generated text is critical for combating misuse. Yet recent\ntheoretical work argues that any watermark can be erased via random walk\nattacks that perturb text while preserving quality. However, such attacks rely\non two key assumptions: (1) rapid mixing (watermarks dissolve quickly under\nperturbations) and (2) reliable quality preservation (automated quality oracles\nperfectly guide edits). Through large-scale experiments and human-validated\nassessments, we find mixing is slow: 100% of perturbed texts retain traces of\ntheir origin after hundreds of edits, defying rapid mixing. Oracles falter, as\nstate-of-the-art quality detectors misjudge edits (77% accuracy), compounding\nerrors during attacks. Ultimately, attacks underperform: automated walks remove\nwatermarks just 26% of the time -- dropping to 10% under human quality review.\nThese findings challenge the inevitability of watermark removal. Instead,\npractical barriers -- slow mixing and imperfect quality control -- reveal\nwatermarking to be far more robust than theoretical models suggest. The gap\nbetween idealized attacks and real-world feasibility underscores the need for\nstronger watermarking methods and more realistic attack models.", "AI": {"tldr": "Watermarking AI-generated text is more robust than theoretical models suggest, as real-world attacks underperform due to slow mixing and imperfect quality control.", "motivation": "To address the theoretical claim that watermarks in AI-generated text can be easily erased via random walk attacks, by examining the practical feasibility of such attacks.", "method": "Conducted large-scale experiments and human-validated assessments to test the assumptions of rapid mixing and reliable quality preservation in watermark removal attacks.", "result": "Found that 100% of perturbed texts retain watermark traces after hundreds of edits, and automated quality oracles misjudge edits (77% accuracy). Attacks remove watermarks only 26% of the time (10% under human review).", "conclusion": "Watermarking is more robust in practice than theory suggests, highlighting the need for stronger watermarking methods and realistic attack models."}}
{"id": "2505.07045", "pdf": "https://arxiv.org/pdf/2505.07045", "abs": "https://arxiv.org/abs/2505.07045", "authors": ["Junjie Yu", "John S. Schreck", "David John Gagne", "Keith W. Oleson", "Jie Li", "Yongtu Liang", "Qi Liao", "Mingfei Sun", "David O. Topping", "Zhonghua Zheng"], "title": "Reinforcement Learning (RL) Meets Urban Climate Modeling: Investigating the Efficacy and Impacts of RL-Based HVAC Control", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning (RL)-based heating, ventilation, and air conditioning\n(HVAC) control has emerged as a promising technology for reducing building\nenergy consumption while maintaining indoor thermal comfort. However, the\nefficacy of such strategies is influenced by the background climate and their\nimplementation may potentially alter both the indoor climate and local urban\nclimate. This study proposes an integrated framework combining RL with an urban\nclimate model that incorporates a building energy model, aiming to evaluate the\nefficacy of RL-based HVAC control across different background climates, impacts\nof RL strategies on indoor climate and local urban climate, and the\ntransferability of RL strategies across cities. Our findings reveal that the\nreward (defined as a weighted combination of energy consumption and thermal\ncomfort) and the impacts of RL strategies on indoor climate and local urban\nclimate exhibit marked variability across cities with different background\nclimates. The sensitivity of reward weights and the transferability of RL\nstrategies are also strongly influenced by the background climate. Cities in\nhot climates tend to achieve higher rewards across most reward weight\nconfigurations that balance energy consumption and thermal comfort, and those\ncities with more varying atmospheric temperatures demonstrate greater RL\nstrategy transferability. These findings underscore the importance of\nthoroughly evaluating RL-based HVAC control strategies in diverse climatic\ncontexts. This study also provides a new insight that city-to-city learning\nwill potentially aid the deployment of RL-based HVAC control.", "AI": {"tldr": "RL-based HVAC control reduces energy use but varies by climate. An integrated framework evaluates its efficacy, impacts, and transferability across cities, showing climate-dependent rewards and strategy transferability.", "motivation": "To assess how RL-based HVAC control performs in different climates and its broader impacts on indoor and urban climates, as well as strategy transferability.", "method": "Combines RL with an urban climate model and building energy model to evaluate HVAC control across cities with varying climates.", "result": "Rewards and impacts vary by climate; hot climates achieve higher rewards, and cities with temperature variations show better strategy transferability.", "conclusion": "Climate context is crucial for RL-based HVAC control evaluation, and city-to-city learning can aid deployment."}}
{"id": "2412.08587", "pdf": "https://arxiv.org/pdf/2412.08587", "abs": "https://arxiv.org/abs/2412.08587", "authors": ["Hang Zhao", "Qile P. Chen", "Yijing Barry Zhang", "Gang Yang"], "title": "Advancing Single and Multi-task Text Classification through Large Language Model Fine-tuning", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 3 tables", "summary": "Both encoder-only models (e.g., BERT, RoBERTa) and large language models\n(LLMs, e.g., Llama3) have been widely used for text classification tasks.\nHowever, there is a lack of systematic studies comparing the performance of\nencoder-based models and LLMs in text classification, particularly when\nfine-tuning is involved. This study employed a diverse range of models and\nmethods, varying in size and architecture, and including both fine-tuned and\npre-trained approaches. We first assessed the performances of these LLMs on the\n20 Newsgroups (20NG) and MASSIVE datasets, comparing them to encoder-only\nRoBERTa models. Additionally, we explored the multi-task capabilities of both\nmodel types by combining multiple classification tasks, including intent\ndetection and slot-filling, into a single model using data from both datasets.\nOur results indicate that fully fine-tuned Llama3-70B models outperform\nRoBERTa-large and other decoder LLMs across various classification tasks and\ndatasets. Moreover, the consolidated multi-task fine-tuned LLMs matched the\nperformance of dual-model setups in both tasks across both datasets. Overall,\nour study provides a comprehensive benchmark of encoder-only and LLM models on\ntext classification tasks and demonstrates a method to combine two or more\nfully fine-tuned decoder LLMs for reduced latency and equivalent performance.", "AI": {"tldr": "The study compares encoder-only models (e.g., RoBERTa) and large language models (LLMs, e.g., Llama3) in text classification, showing fine-tuned Llama3-70B outperforms RoBERTa and other LLMs. It also demonstrates multi-task LLM fine-tuning matches dual-model performance.", "motivation": "There is a lack of systematic comparisons between encoder-based models and LLMs in text classification, especially with fine-tuning. This study aims to fill that gap.", "method": "Used diverse models (varying in size/architecture) and methods (fine-tuned/pre-trained) on 20 Newsgroups and MASSIVE datasets. Compared LLMs to RoBERTa and explored multi-task capabilities.", "result": "Fine-tuned Llama3-70B outperformed RoBERTa-large and other LLMs. Multi-task fine-tuned LLMs matched dual-model setups in performance.", "conclusion": "The study benchmarks encoder-only and LLM models in text classification and shows how to combine fine-tuned LLMs for reduced latency without performance loss."}}
{"id": "2505.07375", "pdf": "https://arxiv.org/pdf/2505.07375", "abs": "https://arxiv.org/abs/2505.07375", "authors": ["Yuqi Cheng", "Yunkang Cao", "Dongfang Wang", "Weiming Shen", "Wenlong Li"], "title": "Boosting Global-Local Feature Matching via Anomaly Synthesis for Multi-Class Point Cloud Anomaly Detection", "categories": ["cs.CV"], "comment": "12 pages, 12 figures", "summary": "Point cloud anomaly detection is essential for various industrial\napplications. The huge computation and storage costs caused by the increasing\nproduct classes limit the application of single-class unsupervised methods,\nnecessitating the development of multi-class unsupervised methods. However, the\nfeature similarity between normal and anomalous points from different class\ndata leads to the feature confusion problem, which greatly hinders the\nperformance of multi-class methods. Therefore, we introduce a multi-class point\ncloud anomaly detection method, named GLFM, leveraging global-local feature\nmatching to progressively separate data that are prone to confusion across\nmultiple classes. Specifically, GLFM is structured into three stages: Stage-I\nproposes an anomaly synthesis pipeline that stretches point clouds to create\nabundant anomaly data that are utilized to adapt the point cloud feature\nextractor for better feature representation. Stage-II establishes the global\nand local memory banks according to the global and local feature distributions\nof all the training data, weakening the impact of feature confusion on the\nestablishment of the memory bank. Stage-III implements anomaly detection of\ntest data leveraging its feature distance from global and local memory banks.\nExtensive experiments on the MVTec 3D-AD, Real3D-AD and actual industry parts\ndataset showcase our proposed GLFM's superior point cloud anomaly detection\nperformance. The code is available at\nhttps://github.com/hustCYQ/GLFM-Multi-class-3DAD.", "AI": {"tldr": "GLFM is a multi-class point cloud anomaly detection method using global-local feature matching to address feature confusion, outperforming existing methods on benchmark datasets.", "motivation": "The need for efficient multi-class unsupervised anomaly detection due to high computation/storage costs and feature confusion issues in existing methods.", "method": "Three-stage approach: anomaly synthesis for feature adaptation, global-local memory banks to reduce confusion, and anomaly detection via feature distance.", "result": "Superior performance on MVTec 3D-AD, Real3D-AD, and industry datasets.", "conclusion": "GLFM effectively addresses feature confusion and enhances multi-class anomaly detection, with code publicly available."}}
{"id": "2505.06841", "pdf": "https://arxiv.org/pdf/2505.06841", "abs": "https://arxiv.org/abs/2505.06841", "authors": ["Prabhdeep Cheema", "Erhan Guven"], "title": "Optimizing Recommendations using Fine-Tuned LLMs", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "Accepted and presented at IEEE CAI 2025. This version includes minor\n  clarifications and formatting updates", "summary": "As digital media platforms strive to meet evolving user expectations,\ndelivering highly personalized and intuitive movies and media recommendations\nhas become essential for attracting and retaining audiences. Traditional\nsystems often rely on keyword-based search and recommendation techniques, which\nlimit users to specific keywords and a combination of keywords. This paper\nproposes an approach that generates synthetic datasets by modeling real-world\nuser interactions, creating complex chat-style data reflective of diverse\npreferences. This allows users to express more information with complex\npreferences, such as mood, plot details, and thematic elements, in addition to\nconventional criteria like genre, title, and actor-based searches. In today's\nsearch space, users cannot write queries like ``Looking for a fantasy movie\nfeaturing dire wolves, ideally set in a harsh frozen world with themes of\nloyalty and survival.''\n  Building on these contributions, we evaluate synthetic datasets for diversity\nand effectiveness in training and benchmarking models, particularly in areas\noften absent from traditional datasets. This approach enhances personalization\nand accuracy by enabling expressive and natural user queries. It establishes a\nfoundation for the next generation of conversational AI-driven search and\nrecommendation systems in digital entertainment.", "AI": {"tldr": "The paper proposes a method to enhance personalized media recommendations by generating synthetic datasets that model real-world user interactions, enabling more expressive and natural queries.", "motivation": "Traditional keyword-based recommendation systems limit user expression. The paper aims to improve personalization by allowing complex queries reflecting diverse preferences.", "method": "Generates synthetic datasets by modeling real-world user interactions, capturing complex preferences like mood, plot details, and themes.", "result": "The approach enhances recommendation accuracy and personalization, supporting expressive user queries.", "conclusion": "This method lays the groundwork for advanced conversational AI-driven search and recommendation systems in digital entertainment."}}
{"id": "2505.07070", "pdf": "https://arxiv.org/pdf/2505.07070", "abs": "https://arxiv.org/abs/2505.07070", "authors": ["Francesco Cagnetta", "Alessandro Favero", "Antonio Sclocchi", "Matthieu Wyart"], "title": "Scaling Laws and Representation Learning in Simple Hierarchical Languages: Transformers vs. Convolutional Architectures", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "comment": "14 pages, 8 figures", "summary": "How do neural language models acquire a language's structure when trained for\nnext-token prediction? We address this question by deriving theoretical scaling\nlaws for neural network performance on synthetic datasets generated by the\nRandom Hierarchy Model (RHM) -- an ensemble of probabilistic context-free\ngrammars designed to capture the hierarchical structure of natural language\nwhile remaining analytically tractable. Previously, we developed a theory of\nrepresentation learning based on data correlations that explains how deep\nlearning models capture the hierarchical structure of the data sequentially,\none layer at a time. Here, we extend our theoretical framework to account for\narchitectural differences. In particular, we predict and empirically validate\nthat convolutional networks, whose structure aligns with that of the generative\nprocess through locality and weight sharing, enjoy a faster scaling of\nperformance compared to transformer models, which rely on global self-attention\nmechanisms. This finding clarifies the architectural biases underlying neural\nscaling laws and highlights how representation learning is shaped by the\ninteraction between model architecture and the statistical properties of data.", "AI": {"tldr": "The paper explores how neural language models learn hierarchical structure through next-token prediction, using the Random Hierarchy Model (RHM) to derive scaling laws. It compares convolutional networks and transformers, showing that convolutional models scale faster due to architectural alignment with data structure.", "motivation": "To understand how neural models acquire hierarchical language structure and how architectural choices impact scaling laws.", "method": "Theoretical scaling laws are derived using the RHM, a synthetic dataset mimicking natural language hierarchy. The framework is extended to compare convolutional networks and transformers.", "result": "Convolutional networks outperform transformers in scaling due to their alignment with hierarchical data structure.", "conclusion": "Model architecture and data statistics interact to shape representation learning, with convolutional networks benefiting from structural alignment."}}
{"id": "2412.20309", "pdf": "https://arxiv.org/pdf/2412.20309", "abs": "https://arxiv.org/abs/2412.20309", "authors": ["Shintaro Ozaki", "Yuta Kato", "Siyuan Feng", "Masayo Tomita", "Kazuki Hayashi", "Wataru Hashimoto", "Ryoma Obara", "Masafumi Oyamada", "Katsuhiko Hayashi", "Hidetaka Kamigaito", "Taro Watanabe"], "title": "Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain", "categories": ["cs.CL"], "comment": "Accepted to BioNLP2025 (Workshop colocated with ACL2025)", "summary": "Retrieval Augmented Generation (RAG) complements the knowledge of Large\nLanguage Models (LLMs) by leveraging external information to enhance response\naccuracy for queries. This approach is widely applied in several fields by\ntaking its advantage of injecting the most up-to-date information, and\nresearchers are focusing on understanding and improving this aspect to unlock\nthe full potential of RAG in such high-stakes applications. However, despite\nthe potential of RAG to address these needs, the mechanisms behind the\nconfidence levels of its outputs remain underexplored, although the confidence\nof information is very critical in some domains, such as finance, healthcare,\nand medicine. Our study focuses the impact of RAG on confidence within the\nmedical domain under various configurations and models. We evaluate confidence\nby treating the model's predicted probability as its output and calculating\nExpected Calibration Error (ECE) and Adaptive Calibration Error (ACE) scores\nbased on the probabilities and accuracy. In addition, we analyze whether the\norder of retrieved documents within prompts calibrates the confidence. Our\nfindings reveal large variation in confidence and accuracy depending on the\nmodel, settings, and the format of input prompts. These results underscore the\nnecessity of optimizing configurations based on the specific model and\nconditions.", "AI": {"tldr": "The paper explores how Retrieval Augmented Generation (RAG) affects confidence in outputs, especially in the medical domain, using metrics like ECE and ACE. Findings show significant variability based on model and settings.", "motivation": "To understand and improve the confidence levels of RAG outputs, which is critical in high-stakes fields like medicine.", "method": "Evaluated confidence using predicted probabilities, ECE, and ACE scores, and analyzed the impact of retrieved document order in prompts.", "result": "Confidence and accuracy vary widely depending on model, settings, and prompt format.", "conclusion": "Optimizing configurations for specific models and conditions is essential for reliable RAG performance."}}
{"id": "2505.07381", "pdf": "https://arxiv.org/pdf/2505.07381", "abs": "https://arxiv.org/abs/2505.07381", "authors": ["Baoping Cheng", "Yukun Zhang", "Liming Wang", "Xiaoyan Xie", "Tao Fu", "Dongkun Wang", "Xiaoming Tao"], "title": "Few-shot Semantic Encoding and Decoding for Video Surveillance", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the continuous increase in the number and resolution of video\nsurveillance cameras, the burden of transmitting and storing surveillance video\nis growing. Traditional communication methods based on Shannon's theory are\nfacing optimization bottlenecks. Semantic communication, as an emerging\ncommunication method, is expected to break through this bottleneck and reduce\nthe storage and transmission consumption of video. Existing semantic decoding\nmethods often require many samples to train the neural network for each scene,\nwhich is time-consuming and labor-intensive. In this study, a semantic encoding\nand decoding method for surveillance video is proposed. First, the sketch was\nextracted as semantic information, and a sketch compression method was proposed\nto reduce the bit rate of semantic information. Then, an image translation\nnetwork was proposed to translate the sketch into a video frame with a\nreference frame. Finally, a few-shot sketch decoding network was proposed to\nreconstruct video from sketch. Experimental results showed that the proposed\nmethod achieved significantly better video reconstruction performance than\nbaseline methods. The sketch compression method could effectively reduce the\nstorage and transmission consumption of semantic information with little\ncompromise on video quality. The proposed method provides a novel semantic\nencoding and decoding method that only needs a few training samples for each\nsurveillance scene, thus improving the practicality of the semantic\ncommunication system.", "AI": {"tldr": "A semantic encoding/decoding method for surveillance video reduces storage/transmission needs by using sketches and few-shot learning, outperforming traditional methods.", "motivation": "Address the growing burden of video surveillance data by overcoming bottlenecks in traditional communication methods with semantic communication.", "method": "Extract sketches as semantic info, compress them, translate sketches into video frames using reference frames, and reconstruct video with a few-shot network.", "result": "Better video reconstruction than baselines; sketch compression reduces bit rate without compromising quality.", "conclusion": "The method improves practicality of semantic communication by requiring few training samples per scene."}}
{"id": "2505.06860", "pdf": "https://arxiv.org/pdf/2505.06860", "abs": "https://arxiv.org/abs/2505.06860", "authors": ["Xia Du", "Jiajie Zhu", "Jizhe Zhou", "Chi-man Pun", "Zheng Lin", "Cong Wu", "Zhe Chen", "Jun Luo"], "title": "DP-TRAE: A Dual-Phase Merging Transferable Reversible Adversarial Example for Image Privacy Protection", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "12 pages, 5 figures", "summary": "In the field of digital security, Reversible Adversarial Examples (RAE)\ncombine adversarial attacks with reversible data hiding techniques to\neffectively protect sensitive data and prevent unauthorized analysis by\nmalicious Deep Neural Networks (DNNs). However, existing RAE techniques\nprimarily focus on white-box attacks, lacking a comprehensive evaluation of\ntheir effectiveness in black-box scenarios. This limitation impedes their\nbroader deployment in complex, dynamic environments. Further more, traditional\nblack-box attacks are often characterized by poor transferability and high\nquery costs, significantly limiting their practical applicability. To address\nthese challenges, we propose the Dual-Phase Merging Transferable Reversible\nAttack method, which generates highly transferable initial adversarial\nperturbations in a white-box model and employs a memory augmented black-box\nstrategy to effectively mislead target mod els. Experimental results\ndemonstrate the superiority of our approach, achieving a 99.0% attack success\nrate and 100% recovery rate in black-box scenarios, highlighting its robustness\nin privacy protection. Moreover, we successfully implemented a black-box attack\non a commercial model, further substantiating the potential of this approach\nfor practical use.", "AI": {"tldr": "The paper introduces a Dual-Phase Merging Transferable Reversible Attack method to improve black-box adversarial attacks, achieving high success and recovery rates.", "motivation": "Existing Reversible Adversarial Examples (RAE) techniques lack effectiveness in black-box scenarios, and traditional black-box attacks suffer from poor transferability and high costs.", "method": "The proposed method generates transferable perturbations in a white-box model and uses a memory-augmented black-box strategy to mislead target models.", "result": "Achieved a 99.0% attack success rate and 100% recovery rate in black-box scenarios, with successful implementation on a commercial model.", "conclusion": "The approach is robust for privacy protection and practical use, addressing limitations of existing methods."}}
{"id": "2505.07081", "pdf": "https://arxiv.org/pdf/2505.07081", "abs": "https://arxiv.org/abs/2505.07081", "authors": ["Gregoire Fournier", "Sourav Medya"], "title": "COMRECGC: Global Graph Counterfactual Explainer through Common Recourse", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at ICML 2025", "summary": "Graph neural networks (GNNs) have been widely used in various domains such as\nsocial networks, molecular biology, or recommendation systems. Concurrently,\ndifferent explanations methods of GNNs have arisen to complement its black-box\nnature. Explanations of the GNNs' predictions can be categorized into two\ntypes--factual and counterfactual. Given a GNN trained on binary classification\ninto ''accept'' and ''reject'' classes, a global counterfactual explanation\nconsists in generating a small set of ''accept'' graphs relevant to all of the\ninput ''reject'' graphs. The transformation of a ''reject'' graph into an\n''accept'' graph is called a recourse. A common recourse explanation is a small\nset of recourse, from which every ''reject'' graph can be turned into an\n''accept'' graph. Although local counterfactual explanations have been studied\nextensively, the problem of finding common recourse for global counterfactual\nexplanation remains unexplored, particularly for GNNs. In this paper, we\nformalize the common recourse explanation problem, and design an effective\nalgorithm, COMRECGC, to solve it. We benchmark our algorithm against strong\nbaselines on four different real-world graphs datasets and demonstrate the\nsuperior performance of COMRECGC against the competitors. We also compare the\ncommon recourse explanations to the graph counterfactual explanation, showing\nthat common recourse explanations are either comparable or superior, making\nthem worth considering for applications such as drug discovery or computational\nbiology.", "AI": {"tldr": "The paper introduces COMRECGC, an algorithm for generating common recourse explanations in GNNs, addressing a gap in global counterfactual explanations.", "motivation": "To address the unexplored problem of finding common recourse for global counterfactual explanations in GNNs, particularly for applications like drug discovery.", "method": "The authors formalize the common recourse explanation problem and design the COMRECGC algorithm to solve it.", "result": "COMRECGC outperforms baselines on four real-world datasets and shows comparable or superior performance to graph counterfactual explanations.", "conclusion": "Common recourse explanations are valuable for GNN applications, offering a promising alternative to traditional counterfactual methods."}}
{"id": "2501.01652", "pdf": "https://arxiv.org/pdf/2501.01652", "abs": "https://arxiv.org/abs/2501.01652", "authors": ["Yin Cai", "Zhouhong Gu", "Zhaohan Du", "Zheyu Ye", "Shaosheng Cao", "Yiqian Xu", "Hongwei Feng", "Ping Chen"], "title": "MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities in\nenvironmental perception, reasoning-based decision-making, and simulating\ncomplex human behaviors, particularly in interactive role-playing contexts.\nThis paper introduces the Multiverse Interactive Role-play Ability General\nEvaluation (MIRAGE), a comprehensive framework designed to assess LLMs'\nproficiency in portraying advanced human behaviors through murder mystery\ngames. MIRAGE features eight intricately crafted scripts encompassing diverse\nthemes and styles, providing a rich simulation. To evaluate LLMs' performance,\nMIRAGE employs four distinct methods: the Trust Inclination Index (TII) to\nmeasure dynamics of trust and suspicion, the Clue Investigation Capability\n(CIC) to measure LLMs' capability of conducting information, the Interactivity\nCapability Index (ICI) to assess role-playing capabilities and the Script\nCompliance Index (SCI) to assess LLMs' capability of understanding and\nfollowing instructions. Our experiments indicate that even popular models like\nGPT-4 face significant challenges in navigating the complexities presented by\nthe MIRAGE. The datasets and simulation codes are available in\n\\href{https://github.com/lime728/MIRAGE}{github}.", "AI": {"tldr": "The paper introduces MIRAGE, a framework to evaluate LLMs' role-playing abilities in murder mystery games using four metrics, revealing challenges even for advanced models like GPT-4.", "motivation": "To assess LLMs' proficiency in simulating complex human behaviors, particularly in interactive role-playing scenarios like murder mystery games.", "method": "MIRAGE uses eight scripts and four evaluation methods: Trust Inclination Index (TII), Clue Investigation Capability (CIC), Interactivity Capability Index (ICI), and Script Compliance Index (SCI).", "result": "Experiments show that even advanced models like GPT-4 struggle with the complexities of MIRAGE.", "conclusion": "MIRAGE provides a robust framework for evaluating LLMs' role-playing abilities, highlighting current limitations in simulating human behaviors."}}
{"id": "2505.07387", "pdf": "https://arxiv.org/pdf/2505.07387", "abs": "https://arxiv.org/abs/2505.07387", "authors": ["Chunpeng Li", "Ya-tang Li"], "title": "Feature Visualization in 3D Convolutional Neural Networks", "categories": ["cs.CV"], "comment": null, "summary": "Understanding the computations of convolutional neural networks requires\neffective visualization of their kernels. While maximal activation methods have\nproven successful in highlighting the preferred features of 2D convolutional\nkernels, directly applying these techniques to 3D convolutions often leads to\nuninterpretable results due to the higher dimensionality and complexity of 3D\nfeatures. To address this challenge, we propose a novel visualization approach\nfor 3D convolutional kernels that disentangles their texture and motion\npreferences. Our method begins with a data-driven decomposition of the optimal\ninput that maximally activates a given kernel. We then introduce a two-stage\noptimization strategy to extract distinct texture and motion components from\nthis input. Applying our approach to visualize kernels at various depths of\nseveral pre-trained models, we find that the resulting\nvisualizations--particularly those capturing motion--clearly reveal the\npreferred dynamic patterns encoded by 3D kernels. These results demonstrate the\neffectiveness of our method in providing interpretable insights into 3D\nconvolutional operations. Code is available at\nhttps://github.com/YatangLiLab/3DKernelVisualizer.", "AI": {"tldr": "A novel method for visualizing 3D convolutional kernels by disentangling texture and motion preferences, improving interpretability.", "motivation": "Existing visualization techniques for 2D kernels fail for 3D convolutions due to higher dimensionality and complexity.", "method": "Data-driven decomposition of optimal inputs followed by a two-stage optimization to extract texture and motion components.", "result": "Visualizations clearly reveal preferred dynamic patterns in 3D kernels, especially motion.", "conclusion": "The method effectively provides interpretable insights into 3D convolutional operations."}}
{"id": "2505.06861", "pdf": "https://arxiv.org/pdf/2505.06861", "abs": "https://arxiv.org/abs/2505.06861", "authors": ["Dongxiu Liu", "Haoyi Niu", "Zhihao Wang", "Jinliang Zheng", "Yinan Zheng", "Zhonghong Ou", "Jianming Hu", "Jianxiong Li", "Xianyuan Zhan"], "title": "Efficient Robotic Policy Learning via Latent Space Backward Planning", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Accepted by ICML 2025", "summary": "Current robotic planning methods often rely on predicting multi-frame images\nwith full pixel details. While this fine-grained approach can serve as a\ngeneric world model, it introduces two significant challenges for downstream\npolicy learning: substantial computational costs that hinder real-time\ndeployment, and accumulated inaccuracies that can mislead action extraction.\nPlanning with coarse-grained subgoals partially alleviates efficiency issues.\nHowever, their forward planning schemes can still result in off-task\npredictions due to accumulation errors, leading to misalignment with long-term\ngoals. This raises a critical question: Can robotic planning be both efficient\nand accurate enough for real-time control in long-horizon, multi-stage tasks?\nTo address this, we propose a Latent Space Backward Planning scheme (LBP),\nwhich begins by grounding the task into final latent goals, followed by\nrecursively predicting intermediate subgoals closer to the current state. The\ngrounded final goal enables backward subgoal planning to always remain aware of\ntask completion, facilitating on-task prediction along the entire planning\nhorizon. The subgoal-conditioned policy incorporates a learnable token to\nsummarize the subgoal sequences and determines how each subgoal guides action\nextraction. Through extensive simulation and real-robot long-horizon\nexperiments, we show that LBP outperforms existing fine-grained and forward\nplanning methods, achieving SOTA performance. Project Page:\nhttps://lbp-authors.github.io", "AI": {"tldr": "The paper proposes Latent Space Backward Planning (LBP) to improve robotic planning efficiency and accuracy by grounding tasks in final latent goals and recursively predicting subgoals.", "motivation": "Current robotic planning methods face computational inefficiency and inaccuracies due to fine-grained image prediction and forward planning schemes.", "method": "LBP grounds tasks in final latent goals and recursively predicts intermediate subgoals, using a learnable token to guide action extraction.", "result": "LBP outperforms existing methods in simulation and real-robot experiments, achieving state-of-the-art performance.", "conclusion": "LBP provides an efficient and accurate solution for real-time robotic planning in long-horizon tasks."}}
{"id": "2505.07086", "pdf": "https://arxiv.org/pdf/2505.07086", "abs": "https://arxiv.org/abs/2505.07086", "authors": ["Tong Chen", "Yinuo Zhang", "Sophia Tang", "Pranam Chatterjee"], "title": "Multi-Objective-Guided Discrete Flow Matching for Controllable Biological Sequence Design", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Designing biological sequences that satisfy multiple, often conflicting,\nfunctional and biophysical criteria remains a central challenge in biomolecule\nengineering. While discrete flow matching models have recently shown promise\nfor efficient sampling in high-dimensional sequence spaces, existing approaches\naddress only single objectives or require continuous embeddings that can\ndistort discrete distributions. We present Multi-Objective-Guided Discrete Flow\nMatching (MOG-DFM), a general framework to steer any pretrained discrete-time\nflow matching generator toward Pareto-efficient trade-offs across multiple\nscalar objectives. At each sampling step, MOG-DFM computes a hybrid\nrank-directional score for candidate transitions and applies an adaptive\nhypercone filter to enforce consistent multi-objective progression. We also\ntrained two unconditional discrete flow matching models, PepDFM for diverse\npeptide generation and EnhancerDFM for functional enhancer DNA generation, as\nbase generation models for MOG-DFM. We demonstrate MOG-DFM's effectiveness in\ngenerating peptide binders optimized across five properties (hemolysis,\nnon-fouling, solubility, half-life, and binding affinity), and in designing DNA\nsequences with specific enhancer classes and DNA shapes. In total, MOG-DFM\nproves to be a powerful tool for multi-property-guided biomolecule sequence\ndesign.", "AI": {"tldr": "MOG-DFM is a framework for multi-objective-guided discrete flow matching, enabling Pareto-efficient trade-offs in biomolecule sequence design.", "motivation": "Addressing the challenge of designing biological sequences with conflicting functional and biophysical criteria.", "method": "Uses hybrid rank-directional scoring and adaptive hypercone filtering to guide pretrained discrete flow matching models.", "result": "Demonstrated effectiveness in optimizing peptide binders and DNA sequences for specific properties and shapes.", "conclusion": "MOG-DFM is a powerful tool for multi-property biomolecule sequence design."}}
{"id": "2501.11110", "pdf": "https://arxiv.org/pdf/2501.11110", "abs": "https://arxiv.org/abs/2501.11110", "authors": ["Yiyao Yu", "Yuxiang Zhang", "Dongdong Zhang", "Xiao Liang", "Hengyuan Zhang", "Xingxing Zhang", "Mahmoud Khademi", "Hany Awadalla", "Junjie Wang", "Yujiu Yang", "Furu Wei"], "title": "Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have made notable progress in mathematical\nreasoning, yet often rely on single-paradigm reasoning, limiting their\neffectiveness across diverse tasks. We introduce Chain-of-Reasoning (CoR), a\nnovel unified framework integrating multiple reasoning paradigms--Natural\nLanguage Reasoning (NLR), Algorithmic Reasoning (AR), and Symbolic Reasoning\n(SR)--to enable synergistic collaboration. CoR generates multiple potential\nanswers via different reasoning paradigms and synthesizes them into a coherent\nfinal solution. We propose a Progressive Paradigm Training (PPT) strategy for\nmodels to progressively master these paradigms, leading to CoR-Math-7B.\nExperimental results demonstrate that CoR-Math-7B significantly outperforms\ncurrent SOTA models, achieving up to a 41.0% absolute improvement over GPT-4o\nin theorem proving and a 15.0% improvement over RL-based methods on the MATH\nbenchmark in arithmetic tasks. These results show the enhanced mathematical\ncomprehension ability of our model, enabling zero-shot generalization across\ntasks.", "AI": {"tldr": "CoR-Math-7B integrates multiple reasoning paradigms (NLR, AR, SR) via Chain-of-Reasoning (CoR) and Progressive Paradigm Training (PPT), outperforming SOTA models like GPT-4o by up to 41.0% in theorem proving.", "motivation": "Current LLMs rely on single-paradigm reasoning, limiting effectiveness across diverse mathematical tasks.", "method": "CoR combines NLR, AR, and SR to generate and synthesize answers. PPT trains models to master these paradigms progressively.", "result": "CoR-Math-7B achieves 41.0% improvement over GPT-4o in theorem proving and 15.0% over RL-based methods in arithmetic tasks.", "conclusion": "CoR enhances mathematical comprehension and enables zero-shot generalization, demonstrating superior performance."}}
{"id": "2505.07396", "pdf": "https://arxiv.org/pdf/2505.07396", "abs": "https://arxiv.org/abs/2505.07396", "authors": ["Olaf Wysocki", "Benedikt Schwab", "Manoj Kumar Biswanath", "Qilin Zhang", "Jingwei Zhu", "Thomas Froech", "Medhini Heeramaglore", "Ihab Hijazi", "Khaoula Kanna", "Mathias Pechinger", "Zhaiyu Chen", "Yao Sun", "Alejandro Rueda Segura", "Ziyang Xu", "Omar AbdelGafar", "Mansour Mehranfar", "Chandan Yeshwanth", "Yueh-Cheng Liu", "Hadi Yazdi", "Jiapan Wang", "Stefan Auer", "Katharina Anders", "Klaus Bogenberger", "Andre Borrmann", "Angela Dai", "Ludwig Hoegner", "Christoph Holst", "Thomas H. Kolbe", "Ferdinand Ludwig", "Matthias Nie\u00dfner", "Frank Petzold", "Xiao Xiang Zhu", "Boris Jutzi"], "title": "TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset", "categories": ["cs.CV", "cs.LG"], "comment": "Submitted to the ISPRS Journal of Photogrammetry and Remote Sensing", "summary": "Urban Digital Twins (UDTs) have become essential for managing cities and\nintegrating complex, heterogeneous data from diverse sources. Creating UDTs\ninvolves challenges at multiple process stages, including acquiring accurate 3D\nsource data, reconstructing high-fidelity 3D models, maintaining models'\nupdates, and ensuring seamless interoperability to downstream tasks. Current\ndatasets are usually limited to one part of the processing chain, hampering\ncomprehensive UDTs validation. To address these challenges, we introduce the\nfirst comprehensive multimodal Urban Digital Twin benchmark dataset: TUM2TWIN.\nThis dataset includes georeferenced, semantically aligned 3D models and\nnetworks along with various terrestrial, mobile, aerial, and satellite\nobservations boasting 32 data subsets over roughly 100,000 $m^2$ and currently\n767 GB of data. By ensuring georeferenced indoor-outdoor acquisition, high\naccuracy, and multimodal data integration, the benchmark supports robust\nanalysis of sensors and the development of advanced reconstruction methods.\nAdditionally, we explore downstream tasks demonstrating the potential of\nTUM2TWIN, including novel view synthesis of NeRF and Gaussian Splatting, solar\npotential analysis, point cloud semantic segmentation, and LoD3 building\nreconstruction. We are convinced this contribution lays a foundation for\novercoming current limitations in UDT creation, fostering new research\ndirections and practical solutions for smarter, data-driven urban environments.\nThe project is available under: https://tum2t.win", "AI": {"tldr": "The paper introduces TUM2TWIN, a comprehensive multimodal Urban Digital Twin benchmark dataset, addressing challenges in UDT creation by providing georeferenced, semantically aligned 3D models and diverse observations.", "motivation": "Current datasets for Urban Digital Twins (UDTs) are limited, hindering comprehensive validation. The need for accurate, multimodal data integration drives the creation of TUM2TWIN.", "method": "The dataset includes georeferenced 3D models, networks, and various terrestrial, mobile, aerial, and satellite observations, covering 100,000 m\u00b2 and 767 GB of data.", "result": "TUM2TWIN supports robust sensor analysis and advanced reconstruction methods, demonstrated through tasks like novel view synthesis, solar potential analysis, and semantic segmentation.", "conclusion": "TUM2TWIN addresses UDT limitations, enabling new research and practical solutions for smarter urban environments. The dataset is publicly available."}}
{"id": "2505.06883", "pdf": "https://arxiv.org/pdf/2505.06883", "abs": "https://arxiv.org/abs/2505.06883", "authors": ["Botian Xu", "Haoyang Weng", "Qingzhou Lu", "Yang Gao", "Huazhe Xu"], "title": "FACET: Force-Adaptive Control via Impedance Reference Tracking for Legged Robots", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has made significant strides in legged robot\ncontrol, enabling locomotion across diverse terrains and complex\nloco-manipulation capabilities. However, the commonly used position or velocity\ntracking-based objectives are agnostic to forces experienced by the robot,\nleading to stiff and potentially dangerous behaviors and poor control during\nforceful interactions. To address this limitation, we present\n\\emph{Force-Adaptive Control via Impedance Reference Tracking} (FACET).\nInspired by impedance control, we use RL to train a control policy to imitate a\nvirtual mass-spring-damper system, allowing fine-grained control under external\nforces by manipulating the virtual spring. In simulation, we demonstrate that\nour quadruped robot achieves improved robustness to large impulses (up to 200\nNs) and exhibits controllable compliance, achieving an 80% reduction in\ncollision impulse. The policy is deployed to a physical robot to showcase both\ncompliance and the ability to engage with large forces by kinesthetic control\nand pulling payloads up to 2/3 of its weight. Further extension to a legged\nloco-manipulator and a humanoid shows the applicability of our method to more\ncomplex settings to enable whole-body compliance control. Project Website:\nhttps://egalahad.github.io/facet/", "AI": {"tldr": "FACET introduces RL-based force-adaptive control for legged robots, improving robustness and compliance during forceful interactions.", "motivation": "Current RL methods for legged robots ignore force dynamics, leading to stiff, unsafe behaviors. FACET addresses this by incorporating impedance control.", "method": "RL trains a policy to mimic a virtual mass-spring-damper system, enabling fine-tuned force control via virtual spring manipulation.", "result": "Simulations show 80% collision impulse reduction and robustness to 200 Ns impulses. Real-world tests demonstrate compliance and handling payloads up to 2/3 robot weight.", "conclusion": "FACET\u2019s force-adaptive approach is scalable to complex robots, enabling whole-body compliance and safer interactions."}}
{"id": "2505.07090", "pdf": "https://arxiv.org/pdf/2505.07090", "abs": "https://arxiv.org/abs/2505.07090", "authors": ["Bilal Ahmed", "Yuqing Qiu", "Diab W. Abueidda", "Waleed El-Sekelly", "Tarek Abdoun", "Mostafa E. Mobasher"], "title": "Physics-informed Multiple-Input Operators for efficient dynamic response prediction of structures", "categories": ["cs.LG"], "comment": null, "summary": "Finite element (FE) modeling is essential for structural analysis but remains\ncomputationally intensive, especially under dynamic loading. While operator\nlearning models have shown promise in replicating static structural responses\nat FEM level accuracy, modeling dynamic behavior remains more challenging. This\nwork presents a Multiple Input Operator Network (MIONet) that incorporates a\nsecond trunk network to explicitly encode temporal dynamics, enabling accurate\nprediction of structural responses under moving loads. Traditional DeepONet\narchitectures using recurrent neural networks (RNNs) are limited by fixed time\ndiscretization and struggle to capture continuous dynamics. In contrast, MIONet\npredicts responses continuously over both space and time, removing the need for\nstep wise modeling. It maps scalar inputs including load type, velocity,\nspatial mesh, and time steps to full field structural responses. To improve\nefficiency and enforce physical consistency, we introduce a physics informed\nloss based on dynamic equilibrium using precomputed mass, damping, and\nstiffness matrices, without solving the governing PDEs directly. Further, a\nSchur complement formulation reduces the training domain, significantly cutting\ncomputational costs while preserving global accuracy. The model is validated on\nboth a simple beam and the KW-51 bridge, achieving FEM level accuracy within\nseconds. Compared to GRU based DeepONet, our model offers comparable accuracy\nwith improved temporal continuity and over 100 times faster inference, making\nit well suited for real-time structural monitoring and digital twin\napplications.", "AI": {"tldr": "MIONet improves dynamic structural response prediction by encoding temporal dynamics, achieving FEM-level accuracy faster than traditional methods.", "motivation": "Dynamic structural analysis is computationally intensive, and existing methods like DeepONet with RNNs struggle with continuous dynamics.", "method": "MIONet uses a second trunk network for temporal dynamics, physics-informed loss, and Schur complement for efficiency.", "result": "Validated on a beam and bridge, MIONet matches FEM accuracy in seconds, outperforming GRU-based DeepONet in speed and continuity.", "conclusion": "MIONet is efficient and accurate for real-time structural monitoring and digital twins."}}
{"id": "2501.13428", "pdf": "https://arxiv.org/pdf/2501.13428", "abs": "https://arxiv.org/abs/2501.13428", "authors": ["Bo Gao", "Michael W. Spratling"], "title": "Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "14 pages and 2 figures", "summary": "Large language models have achieved remarkable success in recent years,\nprimarily due to the implementation of self-attention mechanisms. However,\ntraditional Softmax attention suffers from numerical instability and reduced\nperformance as the length of inference tokens increases. This paper addresses\nthese issues by decomposing the Softmax operation into a non-linear\ntransformation and the $l_1$-norm. We identify the latter as essential for\nmaintaining model performance. By replacing the non-linear transformation with\nthe Softplus activation function and introducing a dynamic scale factor for\ndifferent token lengths based on invariance entropy, we create a novel\nattention mechanism with performance better than conventional Softmax attention\nacross various inference lengths. To further improve the length extrapolation\nability of the proposed attention mechanism, we introduce a novel re-weighting\nmechanism that amplifies significant attention weights while diminishing weaker\nones, enabling the model to concentrate more effectively on relevant tokens.\nWhen combined with our proposed attention mechanism, this approach maintains\nnearly constant validation loss even at 16$\\times$ the training token length,\nensures numerical stability, and achieves superior results on downstream\nbenchmarks.", "AI": {"tldr": "The paper introduces a novel attention mechanism by decomposing Softmax into a non-linear transformation and $l_1$-norm, enhancing performance and stability for varying token lengths.", "motivation": "Address numerical instability and performance degradation in traditional Softmax attention as token length increases.", "method": "Decompose Softmax into non-linear transformation and $l_1$-norm, replace with Softplus, and introduce dynamic scaling and re-weighting mechanisms.", "result": "Improved performance over Softmax, stable validation loss at 16x training length, and better downstream benchmark results.", "conclusion": "The proposed attention mechanism outperforms Softmax, ensuring stability and scalability for long sequences."}}
{"id": "2505.07398", "pdf": "https://arxiv.org/pdf/2505.07398", "abs": "https://arxiv.org/abs/2505.07398", "authors": ["Mingqian Ji", "Jian Yang", "Shanshan Zhang"], "title": "DepthFusion: Depth-Aware Hybrid Feature Fusion for LiDAR-Camera 3D Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "State-of-the-art LiDAR-camera 3D object detectors usually focus on feature\nfusion. However, they neglect the factor of depth while designing the fusion\nstrategy. In this work, we are the first to observe that different modalities\nplay different roles as depth varies via statistical analysis and\nvisualization. Based on this finding, we propose a Depth-Aware Hybrid Feature\nFusion (DepthFusion) strategy that guides the weights of point cloud and RGB\nimage modalities by introducing depth encoding at both global and local levels.\nSpecifically, the Depth-GFusion module adaptively adjusts the weights of image\nBird's-Eye-View (BEV) features in multi-modal global features via depth\nencoding. Furthermore, to compensate for the information lost when transferring\nraw features to the BEV space, we propose a Depth-LFusion module, which\nadaptively adjusts the weights of original voxel features and multi-view image\nfeatures in multi-modal local features via depth encoding. Extensive\nexperiments on the nuScenes and KITTI datasets demonstrate that our DepthFusion\nmethod surpasses previous state-of-the-art methods. Moreover, our DepthFusion\nis more robust to various kinds of corruptions, outperforming previous methods\non the nuScenes-C dataset.", "AI": {"tldr": "The paper introduces DepthFusion, a depth-aware hybrid feature fusion strategy for LiDAR-camera 3D object detection, improving performance and robustness.", "motivation": "Existing LiDAR-camera fusion methods overlook depth, despite its critical role in modality effectiveness. Statistical analysis reveals depth-dependent modality roles, prompting a depth-aware fusion approach.", "method": "Proposes DepthFusion with two modules: Depth-GFusion (global feature weight adjustment via depth encoding) and Depth-LFusion (local feature weight adjustment to compensate BEV space losses).", "result": "Outperforms state-of-the-art on nuScenes and KITTI datasets and shows superior robustness on nuScenes-C.", "conclusion": "DepthFusion effectively leverages depth to enhance multi-modal fusion, achieving better performance and robustness in 3D object detection."}}
{"id": "2505.06913", "pdf": "https://arxiv.org/pdf/2505.06913", "abs": "https://arxiv.org/abs/2505.06913", "authors": ["Brian Challita", "Pierre Parrend"], "title": "RedTeamLLM: an Agentic AI framework for offensive security", "categories": ["cs.CR", "cs.AI", "cs.CY"], "comment": null, "summary": "From automated intrusion testing to discovery of zero-day attacks before\nsoftware launch, agentic AI calls for great promises in security engineering.\nThis strong capability is bound with a similar threat: the security and\nresearch community must build up its models before the approach is leveraged by\nmalicious actors for cybercrime. We therefore propose and evaluate RedTeamLLM,\nan integrated architecture with a comprehensive security model for\nautomatization of pentest tasks. RedTeamLLM follows three key steps:\nsummarizing, reasoning and act, which embed its operational capacity. This\nnovel framework addresses four open challenges: plan correction, memory\nmanagement, context window constraint, and generality vs. specialization.\nEvaluation is performed through the automated resolution of a range of\nentry-level, but not trivial, CTF challenges. The contribution of the reasoning\ncapability of our agentic AI framework is specifically evaluated.", "AI": {"tldr": "RedTeamLLM is an AI framework for automating pentesting tasks, addressing challenges like plan correction and memory management, and evaluated through CTF challenges.", "motivation": "To counter the potential misuse of AI in cybercrime by developing a proactive security framework.", "method": "RedTeamLLM integrates a three-step process (summarizing, reasoning, act) to automate pentesting, tackling key challenges like context window constraints.", "result": "The framework successfully resolves entry-level CTF challenges, demonstrating its reasoning capability.", "conclusion": "RedTeamLLM shows promise in automating security tasks while addressing critical challenges, though further evaluation is needed."}}
{"id": "2505.07100", "pdf": "https://arxiv.org/pdf/2505.07100", "abs": "https://arxiv.org/abs/2505.07100", "authors": ["Julian Rosenberger", "Philipp Schr\u00f6ppel", "Sven Kruschel", "Mathias Kraus", "Patrick Zschech", "Maximilian F\u00f6rster"], "title": "Navigating the Rashomon Effect: How Personalization Can Help Adjust Interpretable Machine Learning Models to Individual Users", "categories": ["cs.LG", "cs.HC"], "comment": "Accepted as a Completed Research Paper at the Thirty-Third European\n  Conference on Information Systems (ECIS 2025), Amman, Jordan", "summary": "The Rashomon effect describes the observation that in machine learning (ML)\nmultiple models often achieve similar predictive performance while explaining\nthe underlying relationships in different ways. This observation holds even for\nintrinsically interpretable models, such as Generalized Additive Models (GAMs),\nwhich offer users valuable insights into the model's behavior. Given the\nexistence of multiple GAM configurations with similar predictive performance, a\nnatural question is whether we can personalize these configurations based on\nusers' needs for interpretability. In our study, we developed an approach to\npersonalize models based on contextual bandits. In an online experiment with\n108 users in a personalized treatment and a non-personalized control group, we\nfound that personalization led to individualized rather than one-size-fits-all\nconfigurations. Despite these individual adjustments, the interpretability\nremained high across both groups, with users reporting a strong understanding\nof the models. Our research offers initial insights into the potential for\npersonalizing interpretable ML.", "AI": {"tldr": "The paper explores personalizing interpretable ML models (like GAMs) using contextual bandits, showing individualized configurations without sacrificing interpretability.", "motivation": "The Rashomon effect in ML shows multiple models can perform similarly but explain data differently, prompting the need for personalized interpretable models.", "method": "Developed a personalization approach using contextual bandits, tested in an online experiment with 108 users (personalized vs. non-personalized groups).", "result": "Personalization led to individualized model configurations while maintaining high interpretability, with users understanding the models well.", "conclusion": "The study highlights the potential for personalizing interpretable ML, offering tailored solutions without compromising clarity."}}
{"id": "2502.01568", "pdf": "https://arxiv.org/pdf/2502.01568", "abs": "https://arxiv.org/abs/2502.01568", "authors": ["Benjamin A. Spiegel", "Lucas Gelfond", "George Konidaris"], "title": "Visual Theory of Mind Enables the Invention of Proto-Writing", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for oral presentation at CogSci 2025, published here with\n  permission from organizers", "summary": "Symbolic writing systems are graphical semiotic codes that are ubiquitous in\nmodern society but are otherwise absent in the animal kingdom. Anthropological\nevidence suggests that the earliest forms of some writing systems originally\nconsisted of iconic pictographs, which signify their referent via visual\nresemblance. While previous studies have examined the emergence and,\nseparately, the evolution of pictographic systems through a computational lens,\nmost employ non-naturalistic methodologies that make it difficult to draw clear\nanalogies to human and animal cognition. We develop a multi-agent reinforcement\nlearning testbed for emergent communication called a Signification Game, and\nformulate a model of inferential communication that enables agents to leverage\nvisual theory of mind to communicate actions using pictographs. Our model,\nwhich is situated within a broader formalism for animal communication, sheds\nlight on the cognitive and cultural processes underlying the emergence of\nproto-writing.", "AI": {"tldr": "A study explores the emergence of proto-writing using a multi-agent reinforcement learning testbed, focusing on visual theory of mind and pictographs.", "motivation": "To understand the cognitive and cultural processes behind the origin of symbolic writing systems, which are unique to humans.", "method": "Developed a Signification Game using multi-agent reinforcement learning, modeling inferential communication with pictographs.", "result": "The model provides insights into how proto-writing might emerge through visual theory of mind and agent interactions.", "conclusion": "The study offers a framework for understanding the cognitive basis of early writing systems and their absence in animals."}}
{"id": "2505.07444", "pdf": "https://arxiv.org/pdf/2505.07444", "abs": "https://arxiv.org/abs/2505.07444", "authors": ["Zeynep Galymzhankyzy", "Eric Martinson"], "title": "Lightweight Multispectral Crop-Weed Segmentation for Precision Agriculture", "categories": ["cs.CV", "I.4.6"], "comment": "4 pages, 5 figures, 1 table", "summary": "Efficient crop-weed segmentation is critical for site-specific weed control\nin precision agriculture. Conventional CNN-based methods struggle to generalize\nand rely on RGB imagery, limiting performance under complex field conditions.\nTo address these challenges, we propose a lightweight transformer-CNN hybrid.\nIt processes RGB, Near-Infrared (NIR), and Red-Edge (RE) bands using\nspecialized encoders and dynamic modality integration. Evaluated on the\nWeedsGalore dataset, the model achieves a segmentation accuracy (mean IoU) of\n78.88%, outperforming RGB-only models by 15.8 percentage points. With only 8.7\nmillion parameters, the model offers high accuracy, computational efficiency,\nand potential for real-time deployment on Unmanned Aerial Vehicles (UAVs) and\nedge devices, advancing precision weed management.", "AI": {"tldr": "A lightweight transformer-CNN hybrid model improves crop-weed segmentation by using RGB, NIR, and Red-Edge bands, achieving 78.88% mean IoU and outperforming RGB-only models by 15.8%.", "motivation": "Enhancing precision agriculture by addressing the limitations of conventional CNN-based methods, which struggle with generalization and rely solely on RGB imagery.", "method": "Proposes a transformer-CNN hybrid with specialized encoders and dynamic modality integration for processing RGB, NIR, and Red-Edge bands.", "result": "Achieves 78.88% mean IoU on the WeedsGalore dataset, outperforming RGB-only models by 15.8 percentage points, with only 8.7 million parameters.", "conclusion": "The model offers high accuracy, computational efficiency, and potential for real-time deployment on UAVs and edge devices, advancing precision weed management."}}
{"id": "2505.06963", "pdf": "https://arxiv.org/pdf/2505.06963", "abs": "https://arxiv.org/abs/2505.06963", "authors": ["Tarik Houichime", "Younes EL Amrani"], "title": "Reinforcement Learning-Based Monocular Vision Approach for Autonomous UAV Landing", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "This paper introduces an innovative approach for the autonomous landing of\nUnmanned Aerial Vehicles (UAVs) using only a front-facing monocular camera,\ntherefore obviating the requirement for depth estimation cameras. Drawing on\nthe inherent human estimating process, the proposed method reframes the landing\ntask as an optimization problem. The UAV employs variations in the visual\ncharacteristics of a specially designed lenticular circle on the landing pad,\nwhere the perceived color and form provide critical information for estimating\nboth altitude and depth. Reinforcement learning algorithms are utilized to\napproximate the functions governing these estimations, enabling the UAV to\nascertain ideal landing settings via training. This method's efficacy is\nassessed by simulations and experiments, showcasing its potential for robust\nand accurate autonomous landing without dependence on complex sensor setups.\nThis research contributes to the advancement of cost-effective and efficient\nUAV landing solutions, paving the way for wider applicability across various\nfields.", "AI": {"tldr": "An innovative method for UAV autonomous landing using a monocular camera and a specially designed landing pad, leveraging reinforcement learning for robust performance.", "motivation": "To eliminate the need for depth estimation cameras and provide a cost-effective, efficient solution for UAV autonomous landing.", "method": "Reframes landing as an optimization problem using visual cues from a lenticular circle on the landing pad, with reinforcement learning for estimation.", "result": "Simulations and experiments demonstrate robust and accurate autonomous landing without complex sensors.", "conclusion": "The method advances cost-effective UAV landing solutions, broadening applicability across fields."}}
{"id": "2505.07124", "pdf": "https://arxiv.org/pdf/2505.07124", "abs": "https://arxiv.org/abs/2505.07124", "authors": ["Francisco Andrade", "Gabriel Peyr\u00e9", "Clarice Poon"], "title": "Learning from Samples: Inverse Problems over measures via Sharpened Fenchel-Young Losses", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Estimating parameters from samples of an optimal probability distribution is\nessential in applications ranging from socio-economic modeling to biological\nsystem analysis. In these settings, the probability distribution arises as the\nsolution to an optimization problem that captures either static interactions\namong agents or the dynamic evolution of a system over time. Our approach\nrelies on minimizing a new class of loss functions, called sharpened\nFenchel-Young losses, which measure the sub-optimality gap of the optimization\nproblem over the space of measures. We study the stability of this estimation\nmethod when only a finite number of sample is available. The parameters to be\nestimated typically correspond to a cost function in static problems and to a\npotential function in dynamic problems. To analyze stability, we introduce a\ngeneral methodology that leverages the strong convexity of the loss function\ntogether with the sample complexity of the forward optimization problem. Our\nanalysis emphasizes two specific settings in the context of optimal transport,\nwhere our method provides explicit stability guarantees: The first is inverse\nunbalanced optimal transport (iUOT) with entropic regularization, where the\nparameters to estimate are cost functions that govern transport computations;\nthis method has applications such as link prediction in machine learning. The\nsecond is inverse gradient flow (iJKO), where the objective is to recover a\npotential function that drives the evolution of a probability distribution via\nthe Jordan-Kinderlehrer-Otto (JKO) time-discretization scheme; this is\nparticularly relevant for understanding cell population dynamics in single-cell\ngenomics. Finally, we validate our approach through numerical experiments on\nGaussian distributions, where closed-form solutions are available, to\ndemonstrate the practical performance of our methods", "AI": {"tldr": "The paper introduces sharpened Fenchel-Young losses for estimating parameters of optimal probability distributions, with applications in socio-economic and biological systems. It provides stability guarantees for inverse unbalanced optimal transport (iUOT) and inverse gradient flow (iJKO), validated through numerical experiments.", "motivation": "Parameter estimation in optimal probability distributions is crucial for socio-economic and biological modeling. The paper addresses the challenge of stability in such estimations with limited samples.", "method": "The approach minimizes sharpened Fenchel-Young losses, leveraging strong convexity and sample complexity. It focuses on iUOT for cost function estimation and iJKO for potential function recovery.", "result": "The method offers explicit stability guarantees for iUOT and iJKO, with practical validation on Gaussian distributions.", "conclusion": "The proposed framework effectively estimates parameters in optimal distributions, demonstrating stability and applicability in real-world scenarios."}}
{"id": "2502.12084", "pdf": "https://arxiv.org/pdf/2502.12084", "abs": "https://arxiv.org/abs/2502.12084", "authors": ["Jianshu Zhang", "Dongyu Yao", "Renjie Pi", "Paul Pu Liang", "Yi R. Fung"], "title": "VLM2-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues", "categories": ["cs.CL"], "comment": "Project Page: https://vlm2-bench.github.io/", "summary": "Visually linking matching cues is a crucial ability in daily life, such as\nidentifying the same person in multiple photos based on their cues, even\nwithout knowing who they are. Despite the extensive knowledge that\nvision-language models (VLMs) possess, it remains largely unexplored whether\nthey are capable of performing this fundamental task. To address this, we\nintroduce VLM2-Bench, a benchmark designed to assess whether VLMs can Visually\nLink Matching cues, with 9 subtasks and over 3,000 test cases. Comprehensive\nevaluation across eight open-source VLMs and GPT-4o, along with further\nanalysis of various language-side and vision-side prompting methods, leads to a\ntotal of eight key findings. We identify critical challenges in models' ability\nto link visual cues, highlighting a significant performance gap where even\nGPT-4o lags 34.80% behind humans. Based on these insights, we advocate for (i)\nenhancing core visual capabilities to improve adaptability and reduce reliance\non prior knowledge, (ii) establishing clearer principles for integrating\nlanguage-based reasoning in vision-centric tasks to prevent unnecessary biases,\nand (iii) shifting vision-text training paradigms toward fostering models'\nability to independently structure and infer relationships among visual cues.", "AI": {"tldr": "The paper introduces VLM2-Bench, a benchmark to evaluate vision-language models' (VLMs) ability to visually link matching cues, revealing significant performance gaps and advocating for improvements in visual capabilities and training paradigms.", "motivation": "To explore whether VLMs can perform the fundamental task of visually linking matching cues, a crucial ability in daily life, despite their extensive knowledge.", "method": "Introduces VLM2-Bench with 9 subtasks and over 3,000 test cases, evaluating eight open-source VLMs and GPT-4o, and analyzing language-side and vision-side prompting methods.", "result": "Identifies critical challenges, with GPT-4o lagging 34.80% behind humans, and presents eight key findings on VLMs' limitations.", "conclusion": "Advocates for enhancing core visual capabilities, clearer integration of language-based reasoning, and shifting training paradigms to improve models' ability to independently structure visual cues."}}
{"id": "2505.07481", "pdf": "https://arxiv.org/pdf/2505.07481", "abs": "https://arxiv.org/abs/2505.07481", "authors": ["Erik Landolsi", "Fredrik Kahl"], "title": "Addressing degeneracies in latent interpolation for diffusion models", "categories": ["cs.CV"], "comment": "14 pages, 12 figures", "summary": "There is an increasing interest in using image-generating diffusion models\nfor deep data augmentation and image morphing. In this context, it is useful to\ninterpolate between latents produced by inverting a set of input images, in\norder to generate new images representing some mixture of the inputs. We\nobserve that such interpolation can easily lead to degenerate results when the\nnumber of inputs is large. We analyze the cause of this effect theoretically\nand experimentally, and suggest a suitable remedy. The suggested approach is a\nrelatively simple normalization scheme that is easy to use whenever\ninterpolation between latents is needed. We measure image quality using FID and\nCLIP embedding distance and show experimentally that baseline interpolation\nmethods lead to a drop in quality metrics long before the degeneration issue is\nclearly visible. In contrast, our method significantly reduces the degeneration\neffect and leads to improved quality metrics also in non-degenerate situations.", "AI": {"tldr": "The paper addresses the degeneration issue in latent space interpolation for image generation using diffusion models and proposes a simple normalization method to improve results.", "motivation": "Interpolating between latents of multiple input images can produce degenerate results, especially with many inputs. The study aims to understand and fix this issue.", "method": "The authors analyze the problem theoretically and experimentally, then suggest a normalization scheme for latent interpolation.", "result": "Experiments show baseline methods degrade quality metrics (FID, CLIP) before degeneration is visible, while the proposed method reduces degeneration and improves metrics.", "conclusion": "The normalization scheme effectively mitigates degeneration in latent interpolation and enhances image quality, even in non-degenerate cases."}}
{"id": "2505.07012", "pdf": "https://arxiv.org/pdf/2505.07012", "abs": "https://arxiv.org/abs/2505.07012", "authors": ["Hao Xu", "Yinqiao Wang", "Niloy J. Mitra", "Shuaicheng Liu", "Pheng-Ann Heng", "Chi-Wing Fu"], "title": "Hand-Shadow Poser", "categories": ["cs.CG", "cs.AI"], "comment": "SIGGRAPH 2025 (ACM TOG)", "summary": "Hand shadow art is a captivating art form, creatively using hand shadows to\nreproduce expressive shapes on the wall. In this work, we study an inverse\nproblem: given a target shape, find the poses of left and right hands that\ntogether best produce a shadow resembling the input. This problem is\nnontrivial, since the design space of 3D hand poses is huge while being\nrestrictive due to anatomical constraints. Also, we need to attend to the\ninput's shape and crucial features, though the input is colorless and\ntextureless. To meet these challenges, we design Hand-Shadow Poser, a\nthree-stage pipeline, to decouple the anatomical constraints (by hand) and\nsemantic constraints (by shadow shape): (i) a generative hand assignment module\nto explore diverse but reasonable left/right-hand shape hypotheses; (ii) a\ngeneralized hand-shadow alignment module to infer coarse hand poses with a\nsimilarity-driven strategy for selecting hypotheses; and (iii) a\nshadow-feature-aware refinement module to optimize the hand poses for physical\nplausibility and shadow feature preservation. Further, we design our pipeline\nto be trainable on generic public hand data, thus avoiding the need for any\nspecialized training dataset. For method validation, we build a benchmark of\n210 diverse shadow shapes of varying complexity and a comprehensive set of\nmetrics, including a novel DINOv2-based evaluation metric. Through extensive\ncomparisons with multiple baselines and user studies, our approach is\ndemonstrated to effectively generate bimanual hand poses for a large variety of\nhand shapes for over 85% of the benchmark cases.", "AI": {"tldr": "The paper introduces Hand-Shadow Poser, a three-stage pipeline to solve the inverse problem of finding hand poses that create a target shadow shape, addressing anatomical and semantic constraints.", "motivation": "The study aims to tackle the challenging inverse problem of determining hand poses to produce a given shadow shape, considering the vast design space and anatomical constraints.", "method": "The proposed method involves a generative hand assignment module, a hand-shadow alignment module, and a refinement module, trained on generic hand data without specialized datasets.", "result": "The approach successfully generates plausible hand poses for 85% of diverse shadow shapes in a benchmark, outperforming baselines.", "conclusion": "Hand-Shadow Poser effectively addresses the inverse shadow problem, demonstrating robustness and versatility in generating hand poses for varied shapes."}}
{"id": "2505.07137", "pdf": "https://arxiv.org/pdf/2505.07137", "abs": "https://arxiv.org/abs/2505.07137", "authors": ["Danny Calegari"], "title": "Triangulating PL functions and the existence of efficient ReLU DNNs", "categories": ["cs.LG", "math.GT"], "comment": "4 pages", "summary": "We show that every piecewise linear function $f:R^d \\to R$ with compact\nsupport a polyhedron $P$ has a representation as a sum of so-called `simplex\nfunctions'. Such representations arise from degree 1 triangulations of the\nrelative homology class (in $R^{d+1}$) bounded by $P$ and the graph of $f$, and\ngive a short elementary proof of the existence of efficient universal ReLU\nneural networks that simultaneously compute all such functions $f$ of bounded\ncomplexity.", "AI": {"tldr": "The paper proves that piecewise linear functions with compact support can be represented as sums of simplex functions, leading to efficient universal ReLU networks.", "motivation": "To provide a simple and elementary proof for the existence of efficient universal ReLU networks capable of computing piecewise linear functions of bounded complexity.", "method": "Uses degree 1 triangulations of relative homology classes in $R^{d+1}$ to represent piecewise linear functions as sums of simplex functions.", "result": "Demonstrates that such representations enable the construction of efficient universal ReLU networks for these functions.", "conclusion": "The findings offer a concise proof and practical implications for neural network design."}}
{"id": "2502.12896", "pdf": "https://arxiv.org/pdf/2502.12896", "abs": "https://arxiv.org/abs/2502.12896", "authors": ["Eva S\u00e1nchez Salido", "Julio Gonzalo", "Guillermo Marco"], "title": "None of the Others: a General Technique to Distinguish Reasoning from Memorization in Multiple-Choice LLM Evaluation Benchmarks", "categories": ["cs.CL"], "comment": null, "summary": "In LLM evaluations, reasoning is often distinguished from recall/memorization\nby performing numerical variations to math-oriented questions. Here we\nintroduce a general variation method for multiple-choice questions that\ncompletely dissociates the correct answer from previously seen tokens or\nconcepts, requiring LLMs to understand and reason (rather than memorizing) in\norder to answer correctly. Using this method, we evaluate state-of-the-art\nproprietary and open-source LLMs on two datasets available in English and\nSpanish: the public MMLU benchmark and the private UNED-Access 2024 dataset.\nResults show that all models experience remarkable accuracy drops under our\nproposed variation, with an average loss of 57% on MMLU and 50% on UNED-Access\n2024, ranging from 10% to 93% across models. Notably, the most accurate model\nin our experimentation (OpenAI-o3-mini) is not the most robust\n(DeepSeek-R1-70B), suggesting that the best models in standard evaluations may\nnot be the ones with better reasoning capabilities. Also, we see larger\naccuracy drops in public (vs private) datasets and questions posed in their\noriginal language (vs a manual translation), which are signs of contamination\nand also point to a relevant role of recall/memorization in current LLMs'\nanswers.", "AI": {"tldr": "The paper introduces a method to test LLMs' reasoning by dissociating correct answers from memorized content, revealing significant accuracy drops and highlighting the role of memorization in current models.", "motivation": "To distinguish reasoning from memorization in LLM evaluations by creating variations of questions that require understanding rather than recall.", "method": "Introduces a variation method for multiple-choice questions, evaluating proprietary and open-source LLMs on MMLU and UNED-Access 2024 datasets in English and Spanish.", "result": "All models showed significant accuracy drops (average 57% on MMLU, 50% on UNED-Access 2024), with the most accurate model not being the most robust. Public datasets and original language questions saw larger drops.", "conclusion": "Standard evaluations may not reflect reasoning capabilities; memorization plays a significant role in LLM performance, and contamination affects results."}}
{"id": "2505.07496", "pdf": "https://arxiv.org/pdf/2505.07496", "abs": "https://arxiv.org/abs/2505.07496", "authors": ["Mohamed Ali Souibgui", "Changkyu Choi", "Andrey Barsky", "Kangsoo Jung", "Ernest Valveny", "Dimosthenis Karatzas"], "title": "DocVXQA: Context-Aware Visual Explanations for Document Question Answering", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We propose DocVXQA, a novel framework for visually self-explainable document\nquestion answering. The framework is designed not only to produce accurate\nanswers to questions but also to learn visual heatmaps that highlight\ncontextually critical regions, thereby offering interpretable justifications\nfor the model's decisions. To integrate explanations into the learning process,\nwe quantitatively formulate explainability principles as explicit learning\nobjectives. Unlike conventional methods that emphasize only the regions\npertinent to the answer, our framework delivers explanations that are\n\\textit{contextually sufficient} while remaining\n\\textit{representation-efficient}. This fosters user trust while achieving a\nbalance between predictive performance and interpretability in DocVQA\napplications. Extensive experiments, including human evaluation, provide strong\nevidence supporting the effectiveness of our method. The code is available at\nhttps://github.com/dali92002/DocVXQA.", "AI": {"tldr": "DocVXQA is a framework for document question answering that provides visual heatmaps for interpretability, balancing accuracy and explainability.", "motivation": "To enhance trust in document question answering models by providing visually interpretable justifications for answers.", "method": "Quantitatively integrates explainability principles as learning objectives, focusing on contextually sufficient and representation-efficient heatmaps.", "result": "Achieves strong performance in predictive accuracy and interpretability, validated through experiments and human evaluation.", "conclusion": "DocVXQA effectively balances performance and interpretability, fostering user trust in document question answering."}}
{"id": "2505.07020", "pdf": "https://arxiv.org/pdf/2505.07020", "abs": "https://arxiv.org/abs/2505.07020", "authors": ["Suyeon Choi"], "title": "R-CAGE: A Structural Model for Emotion Output Design in Human-AI Interaction", "categories": ["cs.HC", "cs.AI", "cs.CY", "H.5.2"], "comment": "theory-only preprint. Independent research", "summary": "This paper presents R-CAGE (Rhythmic Control Architecture for Guarding Ego),\na theoretical framework for restructuring emotional output in long-term\nhuman-AI interaction. While prior affective computing approaches emphasized\nexpressiveness, immersion, and responsiveness, they often neglected the\ncognitive and structural consequences of repeated emotional engagement. R-CAGE\ninstead conceptualizes emotional output not as reactive expression but as\nethical design structure requiring architectural intervention. The model is\ngrounded in experiential observations of subtle affective symptoms such as\nlocalized head tension, interpretive fixation, and emotional lag arising from\nprolonged interaction with affective AI systems. These indicate a mismatch\nbetween system-driven emotion and user interpretation that cannot be fully\nexplained by biometric data or observable behavior. R-CAGE adopts a\nuser-centered stance prioritizing psychological recovery, interpretive\nautonomy, and identity continuity. The framework consists of four control\nblocks: (1) Control of Rhythmic Expression regulates output pacing to reduce\nfatigue; (2) Architecture of Sensory Structuring adjusts intensity and timing\nof affective stimuli; (3) Guarding of Cognitive Framing reduces semantic\npressure to allow flexible interpretation; (4) Ego-Aligned Response Design\nsupports self-reference recovery during interpretive lag. By structurally\nregulating emotional rhythm, sensory intensity, and interpretive affordances,\nR-CAGE frames emotion not as performative output but as sustainable design\nunit. The goal is to protect users from oversaturation and cognitive overload\nwhile sustaining long-term interpretive agency in AI-mediated environments.", "AI": {"tldr": "R-CAGE is a framework for ethical emotional output in human-AI interaction, focusing on psychological recovery and user autonomy to prevent cognitive overload.", "motivation": "Prior affective computing neglected cognitive consequences of repeated emotional engagement, leading to issues like interpretive fixation and emotional lag.", "method": "R-CAGE uses four control blocks: rhythmic expression, sensory structuring, cognitive framing, and ego-aligned response design to regulate emotional output.", "result": "The framework aims to reduce fatigue, adjust affective stimuli, and support interpretive autonomy, framing emotion as sustainable design.", "conclusion": "R-CAGE protects users from oversaturation while maintaining long-term interpretive agency in AI-mediated environments."}}
{"id": "2505.07149", "pdf": "https://arxiv.org/pdf/2505.07149", "abs": "https://arxiv.org/abs/2505.07149", "authors": ["Heqing Ren", "Chao Feng", "Alberto Huertas", "Burkhard Stiller"], "title": "AugMixCloak: A Defense against Membership Inference Attacks via Image Transformation", "categories": ["cs.LG"], "comment": null, "summary": "Traditional machine learning (ML) raises serious privacy concerns, while\nfederated learning (FL) mitigates the risk of data leakage by keeping data on\nlocal devices. However, the training process of FL can still leak sensitive\ninformation, which adversaries may exploit to infer private data. One of the\nmost prominent threats is the membership inference attack (MIA), where the\nadversary aims to determine whether a particular data record was part of the\ntraining set.\n  This paper addresses this problem through a two-stage defense called\nAugMixCloak. The core idea is to apply data augmentation and principal\ncomponent analysis (PCA)-based information fusion to query images, which are\ndetected by perceptual hashing (pHash) as either identical to or highly similar\nto images in the training set. Experimental results show that AugMixCloak\nsuccessfully defends against both binary classifier-based MIA and metric-based\nMIA across five datasets and various decentralized FL (DFL) topologies.\nCompared with regularization-based defenses, AugMixCloak demonstrates stronger\nprotection. Compared with confidence score masking, AugMixCloak exhibits better\ngeneralization.", "AI": {"tldr": "AugMixCloak defends against membership inference attacks in federated learning using data augmentation and PCA-based fusion, outperforming regularization and confidence masking methods.", "motivation": "Federated learning (FL) reduces data leakage risks but remains vulnerable to membership inference attacks (MIAs), necessitating stronger defenses.", "method": "AugMixCloak combines data augmentation and PCA-based information fusion on query images detected by perceptual hashing (pHash) to protect against MIAs.", "result": "AugMixCloak effectively defends against binary classifier-based and metric-based MIAs across five datasets and various FL topologies.", "conclusion": "AugMixCloak offers superior protection and generalization compared to regularization-based defenses and confidence score masking."}}
{"id": "2503.00955", "pdf": "https://arxiv.org/pdf/2503.00955", "abs": "https://arxiv.org/abs/2503.00955", "authors": ["Dien X. Tran", "Nam V. Nguyen", "Thanh T. Tran", "Anh T. Hoang", "Tai V. Duong", "Di T. Le", "Phuc-Lu Le"], "title": "SemViQA: A Semantic Question Answering System for Vietnamese Information Fact-Checking", "categories": ["cs.CL", "cs.AI"], "comment": "18 pages", "summary": "The rise of misinformation, exacerbated by Large Language Models (LLMs) like\nGPT and Gemini, demands robust fact-checking solutions, especially for\nlow-resource languages like Vietnamese. Existing methods struggle with semantic\nambiguity, homonyms, and complex linguistic structures, often trading accuracy\nfor efficiency. We introduce SemViQA, a novel Vietnamese fact-checking\nframework integrating Semantic-based Evidence Retrieval (SER) and Two-step\nVerdict Classification (TVC). Our approach balances precision and speed,\nachieving state-of-the-art results with 78.97\\% strict accuracy on ISE-DSC01\nand 80.82\\% on ViWikiFC, securing 1st place in the UIT Data Science Challenge.\nAdditionally, SemViQA Faster improves inference speed 7x while maintaining\ncompetitive accuracy. SemViQA sets a new benchmark for Vietnamese fact\nverification, advancing the fight against misinformation. The source code is\navailable at: https://github.com/DAVID-NGUYEN-S16/SemViQA.", "AI": {"tldr": "SemViQA is a Vietnamese fact-checking framework combining Semantic-based Evidence Retrieval and Two-step Verdict Classification, achieving top accuracy and speed.", "motivation": "Addressing misinformation challenges in low-resource languages like Vietnamese, where existing methods falter due to semantic ambiguity and efficiency trade-offs.", "method": "Integrates Semantic-based Evidence Retrieval (SER) and Two-step Verdict Classification (TVC) for balanced precision and speed.", "result": "Achieves 78.97% strict accuracy on ISE-DSC01 and 80.82% on ViWikiFC, with SemViQA Faster offering 7x speed improvement.", "conclusion": "SemViQA sets a new benchmark for Vietnamese fact verification, advancing efforts against misinformation."}}
{"id": "2505.07500", "pdf": "https://arxiv.org/pdf/2505.07500", "abs": "https://arxiv.org/abs/2505.07500", "authors": ["Bahram Mohammadi", "Ehsan Abbasnejad", "Yuankai Qi", "Qi Wu", "Anton Van Den Hengel", "Javen Qinfeng Shi"], "title": "Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "The remote embodied referring expression (REVERIE) task requires an agent to\nnavigate through complex indoor environments and localize a remote object\nspecified by high-level instructions, such as \"bring me a spoon\", without\npre-exploration. Hence, an efficient navigation plan is essential for the final\nsuccess. This paper proposes a novel parameter-efficient action planner using\nlarge language models (PEAP-LLM) to generate a single-step instruction at each\nlocation. The proposed model consists of two modules, LLM goal planner (LGP)\nand LoRA action planner (LAP). Initially, LGP extracts the goal-oriented plan\nfrom REVERIE instructions, including the target object and room. Then, LAP\ngenerates a single-step instruction with the goal-oriented plan, high-level\ninstruction, and current visual observation as input. PEAP-LLM enables the\nembodied agent to interact with LAP as the path planner on the fly. A simple\ndirect application of LLMs hardly achieves good performance. Also, existing\nhard-prompt-based methods are error-prone in complicated scenarios and need\nhuman intervention. To address these issues and prevent the LLM from generating\nhallucinations and biased information, we propose a novel two-stage method for\nfine-tuning the LLM, consisting of supervised fine-tuning (STF) and direct\npreference optimization (DPO). SFT improves the quality of generated\ninstructions, while DPO utilizes environmental feedback. Experimental results\nshow the superiority of our proposed model on REVERIE compared to the previous\nstate-of-the-art.", "AI": {"tldr": "A novel parameter-efficient action planner (PEAP-LLM) using LLMs improves navigation for the REVERIE task by generating single-step instructions, outperforming prior methods.", "motivation": "Addressing the challenge of efficient navigation in complex indoor environments for remote object localization without pre-exploration, where existing LLM-based methods are error-prone or require human intervention.", "method": "Proposes PEAP-LLM with two modules: LLM goal planner (LGP) for goal extraction and LoRA action planner (LAP) for single-step instruction generation. Uses a two-stage fine-tuning approach (SFT and DPO) to enhance LLM performance.", "result": "PEAP-LLM outperforms state-of-the-art methods on the REVERIE task, demonstrating superior navigation and localization capabilities.", "conclusion": "The proposed PEAP-LLM effectively addresses limitations of existing LLM-based methods, offering a robust solution for embodied agents in complex environments."}}
{"id": "2505.07041", "pdf": "https://arxiv.org/pdf/2505.07041", "abs": "https://arxiv.org/abs/2505.07041", "authors": ["Samaneh Mohammadi", "Iraklis Symeonidis", "Ali Balador", "Francesco Flammini"], "title": "Empirical Analysis of Asynchronous Federated Learning on Heterogeneous Devices: Efficiency, Fairness, and Privacy Trade-offs", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "This paper was accepted to IJCNN 2025. This version is a preprint and\n  not the official published version", "summary": "Device heterogeneity poses major challenges in Federated Learning (FL), where\nresource-constrained clients slow down synchronous schemes that wait for all\nupdates before aggregation. Asynchronous FL addresses this by incorporating\nupdates as they arrive, substantially improving efficiency. While its\nefficiency gains are well recognized, its privacy costs remain largely\nunexplored, particularly for high-end devices that contribute updates more\nfrequently, increasing their cumulative privacy exposure. This paper presents\nthe first comprehensive analysis of the efficiency-fairness-privacy trade-off\nin synchronous vs. asynchronous FL under realistic device heterogeneity. We\nempirically compare FedAvg and staleness-aware FedAsync using a physical\ntestbed of five edge devices spanning diverse hardware tiers, integrating Local\nDifferential Privacy (LDP) and the Moments Accountant to quantify per-client\nprivacy loss. Using Speech Emotion Recognition (SER) as a privacy-critical\nbenchmark, we show that FedAsync achieves up to 10x faster convergence but\nexacerbates fairness and privacy disparities: high-end devices contribute 6-10x\nmore updates and incur up to 5x higher privacy loss, while low-end devices\nsuffer amplified accuracy degradation due to infrequent, stale, and\nnoise-perturbed updates. These findings motivate the need for adaptive FL\nprotocols that jointly optimize aggregation and privacy mechanisms based on\nclient capacity and participation dynamics, moving beyond static,\none-size-fits-all solutions.", "AI": {"tldr": "The paper analyzes the trade-off between efficiency, fairness, and privacy in synchronous vs. asynchronous Federated Learning (FL) under device heterogeneity, revealing that asynchronous FL (FedAsync) speeds up convergence but worsens fairness and privacy disparities.", "motivation": "Device heterogeneity in FL causes inefficiencies in synchronous schemes, but the privacy costs of asynchronous FL, especially for high-end devices, are understudied.", "method": "Empirical comparison of FedAvg and staleness-aware FedAsync using a testbed of five edge devices, integrating Local Differential Privacy (LDP) and Moments Accountant to measure privacy loss.", "result": "FedAsync converges 10x faster but high-end devices contribute 6-10x more updates, incurring 5x higher privacy loss, while low-end devices suffer accuracy degradation.", "conclusion": "Adaptive FL protocols are needed to balance aggregation and privacy mechanisms based on client capacity, moving beyond static solutions."}}
{"id": "2505.07180", "pdf": "https://arxiv.org/pdf/2505.07180", "abs": "https://arxiv.org/abs/2505.07180", "authors": ["Ruichu Cai", "Kaitao Zheng", "Junxian Huang", "Zijian Li", "Zhengming Chen", "Boyan Xu", "Zhifeng Hao"], "title": "Causal View of Time Series Imputation: Some Identification Results on Missing Mechanism", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Time series imputation is one of the most challenge problems and has broad\napplications in various fields like health care and the Internet of Things.\nExisting methods mainly aim to model the temporally latent dependencies and the\ngeneration process from the observed time series data. In real-world scenarios,\ndifferent types of missing mechanisms, like MAR (Missing At Random), and MNAR\n(Missing Not At Random) can occur in time series data. However, existing\nmethods often overlook the difference among the aforementioned missing\nmechanisms and use a single model for time series imputation, which can easily\nlead to misleading results due to mechanism mismatching. In this paper, we\npropose a framework for time series imputation problem by exploring Different\nMissing Mechanisms (DMM in short) and tailoring solutions accordingly.\nSpecifically, we first analyze the data generation processes with temporal\nlatent states and missing cause variables for different mechanisms.\nSequentially, we model these generation processes via variational inference and\nestimate prior distributions of latent variables via normalizing flow-based\nneural architecture. Furthermore, we establish identifiability results under\nthe nonlinear independent component analysis framework to show that latent\nvariables are identifiable. Experimental results show that our method surpasses\nexisting time series imputation techniques across various datasets with\ndifferent missing mechanisms, demonstrating its effectiveness in real-world\napplications.", "AI": {"tldr": "The paper proposes a framework for time series imputation that addresses different missing mechanisms (MAR and MNAR) separately, improving accuracy by modeling data generation processes with variational inference and normalizing flow-based neural architecture.", "motivation": "Existing time series imputation methods often ignore the differences between missing mechanisms (MAR and MNAR), leading to misleading results. This paper aims to address this gap by tailoring solutions for each mechanism.", "method": "The framework analyzes data generation processes with temporal latent states and missing cause variables, models these via variational inference, and estimates prior distributions of latent variables using normalizing flow-based neural architecture. Identifiability of latent variables is proven under nonlinear independent component analysis.", "result": "Experimental results show the proposed method outperforms existing techniques across datasets with different missing mechanisms, proving its effectiveness in real-world applications.", "conclusion": "The paper successfully addresses the challenge of mechanism mismatching in time series imputation by proposing a tailored framework, demonstrating superior performance over existing methods."}}
{"id": "2503.01217", "pdf": "https://arxiv.org/pdf/2503.01217", "abs": "https://arxiv.org/abs/2503.01217", "authors": ["Sijin Sun", "Ming Deng", "Xinrui Yu", "Liangbin Zhao"], "title": "HREB-CRF: Hierarchical Reduced-bias EMA for Chinese Named Entity Recognition", "categories": ["cs.CL", "cs.LG"], "comment": "8 pages, 6 figures; Accepted for publication at the 2025\n  International Joint Conference on Neural Networks (IJCNN 2025), Rome, Italy,\n  30 June - 5 July", "summary": "Incorrect boundary division, complex semantic representation, and differences\nin pronunciation and meaning often lead to errors in Chinese Named Entity\nRecognition(CNER). To address these issues, this paper proposes HREB-CRF\nframework: Hierarchical Reduced-bias EMA with CRF. The proposed method\namplifies word boundaries and pools long text gradients through exponentially\nfixed-bias weighted average of local and global hierarchical attention.\nExperimental results on the MSRA, Resume, and Weibo datasets show excellent in\nF1, outperforming the baseline model by 1.1\\%, 1.6\\%, and 9.8\\%. The\nsignificant improvement in F1 shows evidences of strong effectiveness and\nrobustness of approach in CNER tasks.", "AI": {"tldr": "The paper introduces HREB-CRF, a framework for Chinese Named Entity Recognition (CNER), addressing boundary and semantic issues. It outperforms baselines on multiple datasets.", "motivation": "Incorrect boundary division, complex semantics, and pronunciation-meaning differences cause errors in CNER.", "method": "HREB-CRF uses hierarchical reduced-bias EMA with CRF, amplifying boundaries and pooling gradients via hierarchical attention.", "result": "Achieves F1 improvements of 1.1%, 1.6%, and 9.8% on MSRA, Resume, and Weibo datasets.", "conclusion": "The method is effective and robust for CNER tasks, as shown by significant F1 improvements."}}
{"id": "2505.07511", "pdf": "https://arxiv.org/pdf/2505.07511", "abs": "https://arxiv.org/abs/2505.07511", "authors": ["Mauricio Orbes-Arteaga", "Oeslle Lucena", "Sabastien Ourselin", "M. Jorge Cardoso"], "title": "MAIS: Memory-Attention for Interactive Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Interactive medical segmentation reduces annotation effort by refining\npredictions through user feedback. Vision Transformer (ViT)-based models, such\nas the Segment Anything Model (SAM), achieve state-of-the-art performance using\nuser clicks and prior masks as prompts. However, existing methods treat\ninteractions as independent events, leading to redundant corrections and\nlimited refinement gains. We address this by introducing MAIS, a\nMemory-Attention mechanism for Interactive Segmentation that stores past user\ninputs and segmentation states, enabling temporal context integration. Our\napproach enhances ViT-based segmentation across diverse imaging modalities,\nachieving more efficient and accurate refinements.", "AI": {"tldr": "MAIS introduces a Memory-Attention mechanism for interactive medical segmentation, improving efficiency and accuracy by integrating temporal context from past user inputs.", "motivation": "Existing methods treat user interactions as independent events, causing redundant corrections and limited refinement gains.", "method": "MAIS stores past user inputs and segmentation states, enabling temporal context integration in Vision Transformer (ViT)-based models like SAM.", "result": "Enhances segmentation across diverse imaging modalities, achieving more efficient and accurate refinements.", "conclusion": "MAIS improves interactive segmentation by leveraging temporal context, outperforming independent interaction approaches."}}
{"id": "2505.07064", "pdf": "https://arxiv.org/pdf/2505.07064", "abs": "https://arxiv.org/abs/2505.07064", "authors": ["Shusen Liu", "Haichao Miao", "Peer-Timo Bremer"], "title": "ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "While powerful and well-established, tools like ParaView present a steep\nlearning curve that discourages many potential users. This work introduces\nParaView-MCP, an autonomous agent that integrates modern multimodal large\nlanguage models (MLLMs) with ParaView to not only lower the barrier to entry\nbut also augment ParaView with intelligent decision support. By leveraging the\nstate-of-the-art reasoning, command execution, and vision capabilities of\nMLLMs, ParaView-MCP enables users to interact with ParaView through natural\nlanguage and visual inputs. Specifically, our system adopted the Model Context\nProtocol (MCP) - a standardized interface for model-application communication -\nthat facilitates direct interaction between MLLMs with ParaView's Python API to\nallow seamless information exchange between the user, the language model, and\nthe visualization tool itself. Furthermore, by implementing a visual feedback\nmechanism that allows the agent to observe the viewport, we unlock a range of\nnew capabilities, including recreating visualizations from examples,\nclosed-loop visualization parameter updates based on user-defined goals, and\neven cross-application collaboration involving multiple tools. Broadly, we\nbelieve such an agent-driven visualization paradigm can profoundly change the\nway we interact with visualization tools. We expect a significant uptake in the\ndevelopment of such visualization tools, in both visualization research and\nindustry.", "AI": {"tldr": "ParaView-MCP integrates MLLMs with ParaView to simplify usage via natural language and visual inputs, enhancing accessibility and functionality.", "motivation": "To reduce the steep learning curve of ParaView and augment it with intelligent decision support.", "method": "Uses MLLMs with ParaView's Python API via Model Context Protocol (MCP) and visual feedback for interaction.", "result": "Enables natural language interaction, visual feedback, and cross-application collaboration.", "conclusion": "Agent-driven visualization can transform tool interaction, likely spurring more such tools in research and industry."}}
{"id": "2505.07222", "pdf": "https://arxiv.org/pdf/2505.07222", "abs": "https://arxiv.org/abs/2505.07222", "authors": ["Nima Dehghani"], "title": "Compression, Regularity, Randomness and Emergent Structure: Rethinking Physical Complexity in the Data-Driven Era", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.IT", "math.IT", "physics.bio-ph", "physics.data-an"], "comment": null, "summary": "Complexity science offers a wide range of measures for quantifying\nunpredictability, structure, and information. Yet, a systematic conceptual\norganization of these measures is still missing.\n  We present a unified framework that locates statistical, algorithmic, and\ndynamical measures along three axes (regularity, randomness, and complexity)\nand situates them in a common conceptual space. We map statistical,\nalgorithmic, and dynamical measures into this conceptual space, discussing\ntheir computational accessibility and approximability.\n  This taxonomy reveals the deep challenges posed by uncomputability and\nhighlights the emergence of modern data-driven methods (including autoencoders,\nlatent dynamical models, symbolic regression, and physics-informed neural\nnetworks) as pragmatic approximations to classical complexity ideals. Latent\nspaces emerge as operational arenas where regularity extraction, noise\nmanagement, and structured compression converge, bridging theoretical\nfoundations with practical modeling in high-dimensional systems.\n  We close by outlining implications for physics-informed AI and AI-guided\ndiscovery in complex physical systems, arguing that classical questions of\ncomplexity remain central to next-generation scientific modeling.", "AI": {"tldr": "A unified framework organizes statistical, algorithmic, and dynamical complexity measures along three axes (regularity, randomness, complexity) and discusses their computational challenges and modern data-driven approximations.", "motivation": "To systematically organize and conceptualize diverse complexity measures, addressing the lack of a unified framework.", "method": "Proposes a taxonomy mapping measures into a conceptual space, evaluating computational accessibility and approximability, and highlighting modern data-driven methods.", "result": "Reveals computational challenges (e.g., uncomputability) and the role of data-driven methods (e.g., autoencoders, neural networks) as practical approximations.", "conclusion": "Classical complexity questions remain vital for next-gen scientific modeling, with implications for physics-informed AI and AI-guided discovery."}}
{"id": "2503.01844", "pdf": "https://arxiv.org/pdf/2503.01844", "abs": "https://arxiv.org/abs/2503.01844", "authors": ["Miriam Havin", "Timna Wharton Kleinman", "Moran Koren", "Yaniv Dover", "Ariel Goldstein"], "title": "Can (A)I Change Your Mind?", "categories": ["cs.CL"], "comment": "Accetped to CogSci 2025", "summary": "The increasing integration of large language model (LLM) based conversational\nagents into everyday life raises critical cognitive and social questions about\ntheir potential to influence human opinions. Although previous studies have\nshown that LLM-based agents can generate persuasive content, these typically\ninvolve controlled, English-language settings. Addressing this, our\npreregistered study explored LLM's persuasive capabilities in more ecological,\nunconstrained scenarios, examining both static (written paragraphs) and dynamic\n(conversations via Telegram) interaction types. Conducted entirely in Hebrew\nwith 200 participants, the study assessed the persuasive effects of both LLM\nand human interlocutors on controversial civil policy topics. Results indicated\nthat participants adopted LLM and human perspectives similarly, with\nsignificant opinion changes evident across all conditions, regardless of\ninterlocutor type or interaction mode. Confidence levels increased\nsignificantly in most scenarios, except in static LLM interactions. These\nfindings demonstrate LLM-based agents' robust persuasive capabilities across\ndiverse sources and settings, highlighting their potential impact on shaping\npublic opinions.", "AI": {"tldr": "LLM-based conversational agents are as persuasive as humans in influencing opinions, even in unconstrained, non-English settings.", "motivation": "To explore LLMs' persuasive capabilities in real-world, dynamic scenarios beyond controlled English settings.", "method": "A preregistered study in Hebrew with 200 participants, comparing LLM and human persuasion via written paragraphs and Telegram conversations on controversial topics.", "result": "LLMs and humans similarly influenced opinions; confidence increased in most cases, except static LLM interactions.", "conclusion": "LLMs can robustly shape public opinions across diverse settings, highlighting their societal impact."}}
{"id": "2505.07530", "pdf": "https://arxiv.org/pdf/2505.07530", "abs": "https://arxiv.org/abs/2505.07530", "authors": ["Raul Ismayilov", "Luuk Spreeuwers", "Dzemila Sero"], "title": "FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images", "categories": ["cs.CV"], "comment": null, "summary": "Synthetic face datasets are increasingly used to overcome the limitations of\nreal-world biometric data, including privacy concerns, demographic imbalance,\nand high collection costs. However, many existing methods lack fine-grained\ncontrol over identity attributes and fail to produce paired,\nidentity-consistent images under structured capture conditions. We introduce\nFLUXSynID, a framework for generating high-resolution synthetic face datasets\nwith user-defined identity attribute distributions and paired document-style\nand trusted live capture images. The dataset generated using the FLUXSynID\nframework shows improved alignment with real-world identity distributions and\ngreater inter-set diversity compared to prior work. The FLUXSynID framework for\ngenerating custom datasets, along with a dataset of 14,889 synthetic\nidentities, is publicly released to support biometric research, including face\nrecognition and morphing attack detection.", "AI": {"tldr": "FLUXSynID is a framework for generating high-resolution synthetic face datasets with controlled identity attributes and paired images, improving alignment with real-world distributions and diversity.", "motivation": "To address limitations of real-world biometric data like privacy concerns, demographic imbalance, and high costs, while providing fine-grained control over identity attributes.", "method": "Introduces FLUXSynID, a framework for generating synthetic face datasets with user-defined identity attributes and paired document-style/live capture images.", "result": "Produces a dataset of 14,889 synthetic identities with improved real-world alignment and inter-set diversity.", "conclusion": "FLUXSynID supports biometric research (e.g., face recognition, morphing attack detection) and is publicly released."}}
{"id": "2505.07078", "pdf": "https://arxiv.org/pdf/2505.07078", "abs": "https://arxiv.org/abs/2505.07078", "authors": ["Weixian Waylon Li", "Hyeonjun Kim", "Mihai Cucuringu", "Tiejun Ma"], "title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?", "categories": ["q-fin.TR", "cs.AI", "cs.CE"], "comment": "14 pages", "summary": "Large Language Models (LLMs) have recently been leveraged for asset pricing\ntasks and stock trading applications, enabling AI agents to generate investment\ndecisions from unstructured financial data. However, most evaluations of LLM\ntiming-based investing strategies are conducted on narrow timeframes and\nlimited stock universes, overstating effectiveness due to survivorship and\ndata-snooping biases. We critically assess their generalizability and\nrobustness by proposing FINSABER, a backtesting framework evaluating\ntiming-based strategies across longer periods and a larger universe of symbols.\nSystematic backtests over two decades and 100+ symbols reveal that previously\nreported LLM advantages deteriorate significantly under broader cross-section\nand over a longer-term evaluation. Our market regime analysis further\ndemonstrates that LLM strategies are overly conservative in bull markets,\nunderperforming passive benchmarks, and overly aggressive in bear markets,\nincurring heavy losses. These findings highlight the need to develop LLM\nstrategies that are able to prioritise trend detection and regime-aware risk\ncontrols over mere scaling of framework complexity.", "AI": {"tldr": "The paper evaluates the generalizability of LLM-based asset pricing strategies, revealing their limitations in broader and longer-term contexts.", "motivation": "To critically assess the robustness of LLM timing-based investing strategies, which are often overestimated due to narrow evaluations.", "method": "Proposes FINSABER, a backtesting framework, to test strategies over two decades and 100+ symbols.", "result": "LLM advantages diminish in broader evaluations; strategies perform poorly in bull and bear markets.", "conclusion": "LLM strategies need trend detection and regime-aware risk controls, not just complexity scaling."}}
{"id": "2505.07245", "pdf": "https://arxiv.org/pdf/2505.07245", "abs": "https://arxiv.org/abs/2505.07245", "authors": ["Fei Liu", "Huanhuan Ren", "Yu Guan", "Xiuxu Wang", "Wang Lv", "Zhiqiang Hu", "Yaxi Chen"], "title": "REMEDI: Relative Feature Enhanced Meta-Learning with Distillation for Imbalanced Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predicting future vehicle purchases among existing owners presents a critical\nchallenge due to extreme class imbalance (<0.5% positive rate) and complex\nbehavioral patterns. We propose REMEDI (Relative feature Enhanced Meta-learning\nwith Distillation for Imbalanced prediction), a novel multi-stage framework\naddressing these challenges. REMEDI first trains diverse base models to capture\ncomplementary aspects of user behavior. Second, inspired by comparative\nop-timization techniques, we introduce relative performance meta-features\n(deviation from ensemble mean, rank among peers) for effective model fusion\nthrough a hybrid-expert architecture. Third, we distill the ensemble's\nknowledge into a single efficient model via supervised fine-tuning with MSE\nloss, enabling practical deployment. Evaluated on approximately 800,000 vehicle\nowners, REMEDI significantly outperforms baseline approaches, achieving the\nbusiness target of identifying ~50% of actual buyers within the top 60,000\nrecommendations at ~10% precision. The distilled model preserves the ensemble's\npredictive power while maintaining deployment efficiency, demonstrating\nREMEDI's effectiveness for imbalanced prediction in industry settings.", "AI": {"tldr": "REMEDI is a multi-stage framework for predicting future vehicle purchases in imbalanced datasets, combining diverse base models, meta-features, and distillation for efficient deployment.", "motivation": "Predicting vehicle purchases is challenging due to extreme class imbalance (<0.5% positive rate) and complex behavioral patterns.", "method": "REMEDI trains diverse base models, uses relative performance meta-features for model fusion, and distills knowledge into a single efficient model via supervised fine-tuning.", "result": "REMEDI outperforms baselines, identifying ~50% of actual buyers within the top 60,000 recommendations at ~10% precision.", "conclusion": "REMEDI effectively addresses imbalanced prediction challenges while maintaining deployment efficiency."}}
{"id": "2503.01921", "pdf": "https://arxiv.org/pdf/2503.01921", "abs": "https://arxiv.org/abs/2503.01921", "authors": ["Jiaying Hong", "Thanet Markchom", "Jianfei Xu", "Tong Wu", "Huizhi Liang"], "title": "NCL-UoR at SemEval-2025 Task 3: Detecting Multilingual Hallucination and Related Observable Overgeneration Text Spans with Modified RefChecker and Modified SeflCheckGPT", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "SemEval-2025 Task 3 (Mu-SHROOM) focuses on detecting hallucinations in\ncontent generated by various large language models (LLMs) across multiple\nlanguages. This task involves not only identifying the presence of\nhallucinations but also pinpointing their specific occurrences. To tackle this\nchallenge, this study introduces two methods: modified RefChecker and modified\nSelfCheckGPT. The modified RefChecker integrates prompt-based factual\nverification into References, structuring them as claim-based tests rather than\nsingle external knowledge sources. The modified SelfCheckGPT incorporates\nexternal knowledge to overcome its reliance on internal knowledge. In addition,\nboth methods' original prompt designs are enhanced to identify hallucinated\nwords within LLM-generated texts. Experimental results demonstrate the\neffectiveness of the approach, achieving a high ranking on the test dataset in\ndetecting hallucinations across various languages, with an average IoU of\n0.5310 and an average COR of 0.5669.", "AI": {"tldr": "The paper introduces two modified methods, RefChecker and SelfCheckGPT, to detect and pinpoint hallucinations in LLM-generated texts across multiple languages, achieving strong performance metrics.", "motivation": "To address the challenge of identifying and locating hallucinations in content generated by large language models (LLMs) across diverse languages.", "method": "Modified RefChecker (integrates prompt-based factual verification) and modified SelfCheckGPT (incorporates external knowledge). Both methods are enhanced to identify hallucinated words.", "result": "High performance in detecting hallucinations, with average IoU of 0.5310 and COR of 0.5669, ranking well on the test dataset.", "conclusion": "The proposed methods effectively detect and locate hallucinations in LLM-generated texts, demonstrating robustness across languages."}}
{"id": "2505.07533", "pdf": "https://arxiv.org/pdf/2505.07533", "abs": "https://arxiv.org/abs/2505.07533", "authors": ["Ahmad Fall", "Federica Granese", "Alex Lence", "Dominique Fourer", "Blaise Hanczar", "Joe-Elie Salem", "Jean-Daniel Zucker", "Edi Prifti"], "title": "IKrNet: A Neural Network for Detecting Specific Drug-Induced Patterns in Electrocardiograms Amidst Physiological Variability", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Monitoring and analyzing electrocardiogram (ECG) signals, even under varying\nphysiological conditions, including those influenced by physical activity,\ndrugs and stress, is crucial to accurately assess cardiac health. However,\ncurrent AI-based methods often fail to account for how these factors interact\nand alter ECG patterns, ultimately limiting their applicability in real-world\nsettings. This study introduces IKrNet, a novel neural network model, which\nidentifies drug-specific patterns in ECGs amidst certain physiological\nconditions. IKrNet's architecture incorporates spatial and temporal dynamics by\nusing a convolutional backbone with varying receptive field size to capture\nspatial features. A bi-directional Long Short-Term Memory module is also\nemployed to model temporal dependencies. By treating heart rate variability as\na surrogate for physiological fluctuations, we evaluated IKrNet's performance\nacross diverse scenarios, including conditions with physical stress, drug\nintake alone, and a baseline without drug presence. Our assessment follows a\nclinical protocol in which 990 healthy volunteers were administered 80mg of\nSotalol, a drug which is known to be a precursor to Torsades-de-Pointes, a\nlife-threatening arrhythmia. We show that IKrNet outperforms state-of-the-art\nmodels' accuracy and stability in varying physiological conditions,\nunderscoring its clinical viability.", "AI": {"tldr": "IKrNet, a neural network model, improves ECG analysis by accounting for physiological and drug-induced variations, outperforming existing methods.", "motivation": "Current AI-based ECG analysis lacks robustness under varying physiological conditions and drug influences, limiting real-world applicability.", "method": "IKrNet uses a convolutional backbone with varying receptive fields and a bi-directional LSTM to capture spatial and temporal ECG patterns, validated on 990 volunteers administered Sotalol.", "result": "IKrNet achieves higher accuracy and stability than state-of-the-art models in diverse physiological and drug-influenced scenarios.", "conclusion": "IKrNet demonstrates clinical viability for robust ECG monitoring under real-world conditions."}}
{"id": "2505.07096", "pdf": "https://arxiv.org/pdf/2505.07096", "abs": "https://arxiv.org/abs/2505.07096", "authors": ["Prithwish Dan", "Kushal Kedia", "Angela Chao", "Edward Weiyi Duan", "Maximus Adrian Pace", "Wei-Chiu Ma", "Sanjiban Choudhury"], "title": "X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Human videos offer a scalable way to train robot manipulation policies, but\nlack the action labels needed by standard imitation learning algorithms.\nExisting cross-embodiment approaches try to map human motion to robot actions,\nbut often fail when the embodiments differ significantly. We propose X-Sim, a\nreal-to-sim-to-real framework that uses object motion as a dense and\ntransferable signal for learning robot policies. X-Sim starts by reconstructing\na photorealistic simulation from an RGBD human video and tracking object\ntrajectories to define object-centric rewards. These rewards are used to train\na reinforcement learning (RL) policy in simulation. The learned policy is then\ndistilled into an image-conditioned diffusion policy using synthetic rollouts\nrendered with varied viewpoints and lighting. To transfer to the real world,\nX-Si introduces an online domain adaptation technique that aligns real and\nsimulated observations during deployment. Importantly, X-Sim does not require\nany robot teleoperation data. We evaluate it across 5 manipulation tasks in 2\nenvironments and show that it: (1) improves task progress by 30% on average\nover hand-tracking and sim-to-real baselines, (2) matches behavior cloning with\n10x less data collection time, and (3) generalizes to new camera viewpoints and\ntest-time changes. Code and videos are available at\nhttps://portal-cornell.github.io/X-Sim/.", "AI": {"tldr": "X-Sim is a real-to-sim-to-real framework that trains robot policies using object motion from human videos, avoiding the need for action labels or teleoperation data.", "motivation": "Human videos lack action labels for imitation learning, and cross-embodiment methods often fail with differing embodiments. X-Sim addresses this by leveraging object motion as a transferable signal.", "method": "X-Sim reconstructs a photorealistic simulation from RGBD human videos, tracks object trajectories for rewards, trains an RL policy in simulation, distills it into a diffusion policy, and uses online domain adaptation for real-world transfer.", "result": "X-Sim improves task progress by 30% over baselines, matches behavior cloning with 10x less data collection time, and generalizes to new viewpoints and test-time changes.", "conclusion": "X-Sim effectively bridges the gap between human videos and robot policy training, demonstrating superior performance and generalization without requiring teleoperation data."}}
{"id": "2505.07260", "pdf": "https://arxiv.org/pdf/2505.07260", "abs": "https://arxiv.org/abs/2505.07260", "authors": ["Yuanhang Yang", "Chaozheng Wang", "Jing Li"], "title": "UMoE: Unifying Attention and FFN with Shared Experts", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sparse Mixture of Experts (MoE) architectures have emerged as a promising\napproach for scaling Transformer models. While initial works primarily\nincorporated MoE into feed-forward network (FFN) layers, recent studies have\nexplored extending the MoE paradigm to attention layers to enhance model\nperformance. However, existing attention-based MoE layers require specialized\nimplementations and demonstrate suboptimal performance compared to their\nFFN-based counterparts. In this paper, we aim to unify the MoE designs in\nattention and FFN layers by introducing a novel reformulation of the attention\nmechanism, revealing an underlying FFN-like structure within attention modules.\nOur proposed architecture, UMoE, achieves superior performance through\nattention-based MoE layers while enabling efficient parameter sharing between\nFFN and attention components.", "AI": {"tldr": "UMoE unifies MoE designs in attention and FFN layers by reformulating attention as FFN-like, enabling efficient parameter sharing and superior performance.", "motivation": "Existing attention-based MoE layers require specialized implementations and underperform compared to FFN-based MoE layers.", "method": "Introduces UMoE, a novel reformulation of attention to reveal its FFN-like structure, enabling unified MoE designs.", "result": "UMoE achieves superior performance with attention-based MoE layers and efficient parameter sharing.", "conclusion": "UMoE successfully unifies MoE in attention and FFN layers, improving performance and efficiency."}}
{"id": "2503.03122", "pdf": "https://arxiv.org/pdf/2503.03122", "abs": "https://arxiv.org/abs/2503.03122", "authors": ["Zichao Li", "Xueru Wen", "Jie Lou", "Yuqiu Ji", "Yaojie Lu", "Xianpei Han", "Debing Zhang", "Le Sun"], "title": "The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models", "categories": ["cs.CL", "cs.AI"], "comment": "ICML 2025", "summary": "Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language\nModels (LLMs) with human preferences, particularly as LLMs increasingly\ninteract with multimodal data. However, we find that MM-RMs trained on existing\ndatasets often struggle to generalize to out-of-distribution data due to their\nreliance on unimodal spurious correlations, primarily text-only shortcuts\nwithin the training distribution, which prevents them from leveraging true\nmultimodal reward functions. To address this, we introduce a Shortcut-aware\nMM-RM learning algorithm that mitigates this issue by dynamically reweighting\ntraining samples, shifting the distribution toward better multimodal\nunderstanding, and reducing dependence on unimodal spurious correlations. Our\nexperiments demonstrate significant improvements in generalization, downstream\ntask performance, and scalability, establishing a more robust framework for\nmultimodal reward modeling.", "AI": {"tldr": "The paper introduces a Shortcut-aware MM-RM learning algorithm to improve generalization in multimodal reward models by reducing reliance on unimodal spurious correlations.", "motivation": "Existing MM-RMs struggle with out-of-distribution data due to unimodal shortcuts, limiting their ability to leverage true multimodal reward functions.", "method": "Proposes a dynamic reweighting of training samples to shift focus toward better multimodal understanding and reduce spurious correlations.", "result": "Experiments show improved generalization, downstream task performance, and scalability.", "conclusion": "The new algorithm provides a more robust framework for multimodal reward modeling."}}
{"id": "2505.07538", "pdf": "https://arxiv.org/pdf/2505.07538", "abs": "https://arxiv.org/abs/2505.07538", "authors": ["Bohan Wang", "Zhongqi Yue", "Fengda Zhang", "Shuo Chen", "Li'an Bi", "Junzhe Zhang", "Xue Song", "Kennard Yanting Chan", "Jiachun Pan", "Weijia Wu", "Mingze Zhou", "Wang Lin", "Kaihang Pan", "Saining Zhang", "Liyu Jia", "Wentao Hu", "Wei Zhao", "Hanwang Zhang"], "title": "Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "We completely discard the conventional spatial prior in image representation\nand introduce a novel discrete visual tokenizer: Self-consistency Tokenizer\n(Selftok). At its design core, we compose an autoregressive (AR) prior --\nmirroring the causal structure of language -- into visual tokens by using the\nreverse diffusion process of image generation. The AR property makes Selftok\nfundamentally distinct from traditional spatial tokens in the following two key\nways: - Selftok offers an elegant and minimalist approach to unify diffusion\nand AR for vision-language models (VLMs): By representing images with Selftok\ntokens, we can train a VLM using a purely discrete autoregressive architecture\n-- like that in LLMs -- without requiring additional modules or training\nobjectives. - We theoretically show that the AR prior satisfies the Bellman\nequation, whereas the spatial prior does not. Therefore, Selftok supports\nreinforcement learning (RL) for visual generation with effectiveness comparable\nto that achieved in LLMs. Besides the AR property, Selftok is also a SoTA\ntokenizer that achieves a favorable trade-off between high-quality\nreconstruction and compression rate. We use Selftok to build a pure AR VLM for\nboth visual comprehension and generation tasks. Impressively, without using any\ntext-image training pairs, a simple policy gradient RL working in the visual\ntokens can significantly boost the visual generation benchmark, surpassing all\nthe existing models by a large margin. Therefore, we believe that Selftok\neffectively addresses the long-standing challenge that visual tokens cannot\nsupport effective RL. When combined with the well-established strengths of RL\nin LLMs, this brings us one step closer to realizing a truly multimodal LLM.\nProject Page: https://selftok-team.github.io/report/.", "AI": {"tldr": "Selftok introduces a novel discrete visual tokenizer using an autoregressive prior, unifying diffusion and AR for VLMs, enabling effective RL for visual generation without text-image pairs.", "motivation": "To address the limitation of traditional spatial tokens in supporting reinforcement learning (RL) for visual generation and unify diffusion and autoregressive (AR) methods in vision-language models (VLMs).", "method": "Develops Self-consistency Tokenizer (Selftok) using reverse diffusion to create AR visual tokens, enabling pure AR VLM training without additional modules.", "result": "Selftok achieves high-quality reconstruction and compression, and RL in visual tokens boosts generation benchmarks significantly, surpassing existing models.", "conclusion": "Selftok successfully bridges the gap between visual tokens and RL, advancing toward a multimodal LLM."}}
{"id": "2505.07214", "pdf": "https://arxiv.org/pdf/2505.07214", "abs": "https://arxiv.org/abs/2505.07214", "authors": ["Pascal Spiegler", "Arash Harirpoush", "Yiming Xiao"], "title": "Towards user-centered interactive medical image segmentation in VR with an assistive AI agent", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": null, "summary": "Crucial in disease analysis and surgical planning, manual segmentation of\nvolumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and\nchallenging to master, while fully automatic algorithms can benefit from\nuser-feedback. Therefore, with the complementary power of the latest\nradiological AI foundation models and virtual reality (VR)'s intuitive data\ninteraction, we propose SAMIRA, a novel conversational AI agent that assists\nusers with localizing, segmenting, and visualizing 3D medical concepts in VR.\nThrough speech-based interaction, the agent helps users understand radiological\nfeatures, locate clinical targets, and generate segmentation masks that can be\nrefined with just a few point prompts. The system also supports true-to-scale\n3D visualization of segmented pathology to enhance patient-specific anatomical\nunderstanding. Furthermore, to determine the optimal interaction paradigm under\nnear-far attention-switching for refining segmentation masks in an immersive,\nhuman-in-the-loop workflow, we compare VR controller pointing, head pointing,\nand eye tracking as input modes. With a user study, evaluations demonstrated a\nhigh usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as\nstrong support for the proposed VR system's guidance, training potential, and\nintegration of AI in radiological segmentation tasks.", "AI": {"tldr": "SAMIRA is a conversational AI agent in VR that assists with medical scan segmentation using speech, point prompts, and 3D visualization, achieving high usability and low task load.", "motivation": "Manual segmentation of medical scans is laborious and error-prone, while fully automatic methods lack user interaction. SAMIRA combines AI and VR for intuitive, human-in-the-loop segmentation.", "method": "SAMIRA uses speech-based interaction, point prompts, and 3D visualization in VR. It compares input modes (VR controller, head pointing, eye tracking) for refining segmentation.", "result": "High usability (SUS=90.0 \u00b1 9.0), low task load, and strong support for guidance, training, and AI integration in radiological tasks.", "conclusion": "SAMIRA effectively bridges AI and VR for intuitive, efficient medical scan segmentation, demonstrating high usability and potential for clinical adoption."}}
{"id": "2505.07274", "pdf": "https://arxiv.org/pdf/2505.07274", "abs": "https://arxiv.org/abs/2505.07274", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Cache-Efficient Posterior Sampling for Reinforcement Learning with LLM-Derived Priors Across Discrete and Continuous Domains", "categories": ["cs.LG"], "comment": null, "summary": "Integrating large language models (LLMs) as priors in reinforcement learning\n(RL) offers significant advantages but comes with substantial computational\ncosts. We present a principled cache-efficient framework for posterior sampling\nwith LLM-derived priors that dramatically reduces these costs while maintaining\nhigh performance. At the core of our approach is an adaptive caching mechanism,\nwhere cache parameters are meta-optimized using surrogate gradients derived\nfrom policy performance. This design enables efficient inference across both\ndiscrete text environments (e.g., TextWorld, ALFWorld) and continuous control\ndomains (e.g., MuJoCo), achieving a 3.8--4.7$\\times$ reduction in LLM queries\nand 4.0--12.0$\\times$ lower median latencies (85--93\\,ms on a consumer GPU)\nwhile retaining 96--98\\% of uncached performance. Our theoretical analysis\nprovides KL divergence bounds on approximation quality, validated empirically.\nThe framework extends to offline RL, where our CQL-Prior variant improves\nperformance by 14--29\\% and reduces training time by 38--40\\%. Extensive\nevaluations across a diverse suite of eight tasks demonstrate the\ngeneralizability and practical viability of LLM-guided RL in\nresource-constrained settings.", "AI": {"tldr": "A framework for integrating LLMs as priors in RL with adaptive caching reduces computational costs while maintaining performance.", "motivation": "Leveraging LLMs in RL is computationally expensive; this work aims to reduce costs without sacrificing performance.", "method": "Uses an adaptive caching mechanism with meta-optimized parameters and surrogate gradients for efficient inference in discrete and continuous domains.", "result": "Achieves 3.8--4.7x fewer LLM queries, 4.0--12.0x lower latency, and retains 96--98% performance. Offline RL variant improves performance by 14--29% and reduces training time by 38--40%.", "conclusion": "The framework is generalizable and practical for LLM-guided RL in resource-constrained settings."}}
{"id": "2503.10354", "pdf": "https://arxiv.org/pdf/2503.10354", "abs": "https://arxiv.org/abs/2503.10354", "authors": ["Nevidu Jayatilleke", "Ruvan Weerasinghe"], "title": "A Hybrid Architecture with Efficient Fine Tuning for Abstractive Patent Document Summarization", "categories": ["cs.CL"], "comment": "Accepted Paper in the 8th International Research Conference on Smart\n  Computing and Systems Engineering, University of Kelaniya, Sri Lanka.\n  (Pending Publication)", "summary": "Automatic patent summarization approaches that help in the patent analysis\nand comprehension procedure are in high demand due to the colossal growth of\ninnovations. The development of natural language processing (NLP), text mining,\nand deep learning has notably amplified the efficacy of text summarization\nmodels for abundant types of documents. Summarizing patent text remains a\npertinent challenge due to the labyrinthine writing style of these documents,\nwhich includes technical and legal intricacies. Additionally, these patent\ndocument contents are considerably lengthier than archetypal documents, which\ncomplicates the process of extracting pertinent information for summarization.\nEmbodying extractive and abstractive text summarization methodologies into a\nhybrid framework, this study proposes a system for efficiently creating\nabstractive summaries of patent records. The procedure involves leveraging the\nLexRank graph-based algorithm to retrieve the important sentences from input\nparent texts, then utilizing a Bidirectional Auto-Regressive Transformer (BART)\nmodel that has been fine-tuned using Low-Ranking Adaptation (LoRA) for\nproducing text summaries. This is accompanied by methodical testing and\nevaluation strategies. Furthermore, the author employed certain meta-learning\ntechniques to achieve Domain Generalization (DG) of the abstractive component\nacross multiple patent fields.", "AI": {"tldr": "A hybrid framework combining extractive and abstractive summarization methods is proposed for efficient patent summarization, using LexRank for sentence extraction and a fine-tuned BART model for abstractive summaries, with meta-learning for domain generalization.", "motivation": "The complexity and length of patent documents, along with their technical and legal intricacies, make summarization challenging, necessitating advanced NLP and deep learning solutions.", "method": "The approach combines LexRank for extractive summarization and a fine-tuned BART model (using LoRA) for abstractive summarization, with meta-learning for domain generalization.", "result": "The proposed system efficiently generates abstractive summaries of patent records, addressing the challenges of patent text summarization.", "conclusion": "The hybrid framework, leveraging advanced NLP techniques and meta-learning, offers a robust solution for patent summarization across diverse fields."}}
{"id": "2505.07539", "pdf": "https://arxiv.org/pdf/2505.07539", "abs": "https://arxiv.org/abs/2505.07539", "authors": ["Hao Li", "Sicheng Li", "Xiang Gao", "Abudouaihati Batuer", "Lu Yu", "Yiyi Liao"], "title": "GIFStream: 4D Gaussian-based Immersive Video with Feature Stream", "categories": ["cs.CV"], "comment": "14 pages, 10 figures", "summary": "Immersive video offers a 6-Dof-free viewing experience, potentially playing a\nkey role in future video technology. Recently, 4D Gaussian Splatting has gained\nattention as an effective approach for immersive video due to its high\nrendering efficiency and quality, though maintaining quality with manageable\nstorage remains challenging. To address this, we introduce GIFStream, a novel\n4D Gaussian representation using a canonical space and a deformation field\nenhanced with time-dependent feature streams. These feature streams enable\ncomplex motion modeling and allow efficient compression by leveraging temporal\ncorrespondence and motion-aware pruning. Additionally, we incorporate both\ntemporal and spatial compression networks for end-to-end compression.\nExperimental results show that GIFStream delivers high-quality immersive video\nat 30 Mbps, with real-time rendering and fast decoding on an RTX 4090. Project\npage: https://xdimlab.github.io/GIFStream", "AI": {"tldr": "GIFStream introduces a novel 4D Gaussian representation for immersive video, combining canonical space and deformation fields with feature streams for efficient compression and high-quality rendering.", "motivation": "To address the challenge of maintaining immersive video quality with manageable storage, leveraging 4D Gaussian Splatting's efficiency.", "method": "Uses canonical space, deformation fields, and time-dependent feature streams for motion modeling and compression, with temporal and spatial compression networks.", "result": "Achieves high-quality immersive video at 30 Mbps with real-time rendering and fast decoding on an RTX 4090.", "conclusion": "GIFStream effectively balances quality and storage efficiency for immersive video."}}
{"id": "2505.07236", "pdf": "https://arxiv.org/pdf/2505.07236", "abs": "https://arxiv.org/abs/2505.07236", "authors": ["Oleg Sautenkov", "Yasheerah Yaqoot", "Muhammad Ahsan Mustafa", "Faryal Batool", "Jeffrin Sam", "Artem Lykov", "Chih-Yung Wen", "Dzmitry Tsetserukou"], "title": "UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning", "categories": ["cs.RO", "cs.AI"], "comment": "Submitted", "summary": "We present UAV-CodeAgents, a scalable multi-agent framework for autonomous\nUAV mission generation, built on large language and vision-language models\n(LLMs/VLMs). The system leverages the ReAct (Reason + Act) paradigm to\ninterpret satellite imagery, ground high-level natural language instructions,\nand collaboratively generate UAV trajectories with minimal human supervision. A\ncore component is a vision-grounded, pixel-pointing mechanism that enables\nprecise localization of semantic targets on aerial maps. To support real-time\nadaptability, we introduce a reactive thinking loop, allowing agents to\niteratively reflect on observations, revise mission goals, and coordinate\ndynamically in evolving environments.\n  UAV-CodeAgents is evaluated on large-scale mission scenarios involving\nindustrial and environmental fire detection. Our results show that a lower\ndecoding temperature (0.5) yields higher planning reliability and reduced\nexecution time, with an average mission creation time of 96.96 seconds and a\nsuccess rate of 93%. We further fine-tune Qwen2.5VL-7B on 9,000 annotated\nsatellite images, achieving strong spatial grounding across diverse visual\ncategories. To foster reproducibility and future research, we will release the\nfull codebase and a novel benchmark dataset for vision-language-based UAV\nplanning.", "AI": {"tldr": "UAV-CodeAgents is a multi-agent framework using LLMs/VLMs for autonomous UAV mission generation, featuring precise localization and real-time adaptability, achieving 93% success rate.", "motivation": "To enable scalable, autonomous UAV mission generation with minimal human supervision by leveraging LLMs/VLMs and satellite imagery.", "method": "Uses ReAct paradigm for interpreting instructions and satellite imagery, with a vision-grounded pixel-pointing mechanism and reactive thinking loop for adaptability.", "result": "Achieves 93% success rate, 96.96s average mission creation time, and strong spatial grounding after fine-tuning on 9,000 images.", "conclusion": "The framework is effective for UAV mission planning, with plans to release code and a benchmark dataset for future research."}}
{"id": "2505.07291", "pdf": "https://arxiv.org/pdf/2505.07291", "abs": "https://arxiv.org/abs/2505.07291", "authors": ["Prime Intellect Team", "Sami Jaghouar", "Justus Mattern", "Jack Min Ong", "Jannik Straube", "Manveer Basra", "Aaron Pazdera", "Kushal Thaman", "Matthew Di Ferrante", "Felix Gabriel", "Fares Obeid", "Kemal Erdem", "Michael Keiblinger", "Johannes Hagemann"], "title": "INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning", "categories": ["cs.LG", "cs.DC"], "comment": "26 pages, 12 figures", "summary": "We introduce INTELLECT-2, the first globally distributed reinforcement\nlearning (RL) training run of a 32 billion parameter language model. Unlike\ntraditional centralized training efforts, INTELLECT-2 trains a reasoning model\nusing fully asynchronous RL across a dynamic, heterogeneous swarm of\npermissionless compute contributors.\n  To enable a training run with this unique infrastructure, we built various\ncomponents from scratch: we introduce PRIME-RL, our training framework\npurpose-built for distributed asynchronous reinforcement learning, based on top\nof novel components such as TOPLOC, which verifies rollouts from untrusted\ninference workers, and SHARDCAST, which efficiently broadcasts policy weights\nfrom training nodes to inference workers.\n  Beyond infrastructure components, we propose modifications to the standard\nGRPO training recipe and data filtering techniques that were crucial to achieve\ntraining stability and ensure that our model successfully learned its training\nobjective, thus improving upon QwQ-32B, the state of the art reasoning model in\nthe 32B parameter range.\n  We open-source INTELLECT-2 along with all of our code and data, hoping to\nencourage and enable more open research in the field of decentralized training.", "AI": {"tldr": "INTELLECT-2 is a 32B parameter language model trained via globally distributed, asynchronous RL using a permissionless compute swarm. It introduces novel infrastructure (PRIME-RL, TOPLOC, SHARDCAST) and training modifications to achieve stability and outperform QwQ-32B.", "motivation": "To pioneer decentralized, large-scale RL training by leveraging heterogeneous, permissionless compute resources, advancing open research in this field.", "method": "Uses fully asynchronous RL across a dynamic compute swarm, with custom frameworks (PRIME-RL, TOPLOC, SHARDCAST) and modified GRPO training recipe for stability.", "result": "Successfully trained INTELLECT-2, outperforming QwQ-32B, the state-of-the-art reasoning model in its parameter range.", "conclusion": "INTELLECT-2 demonstrates the feasibility of decentralized RL training and opens avenues for open research, with all code and data released publicly."}}
{"id": "2504.13471", "pdf": "https://arxiv.org/pdf/2504.13471", "abs": "https://arxiv.org/abs/2504.13471", "authors": ["Jiliang Ni", "Jiachen Pu", "Zhongyi Yang", "Kun Zhou", "Hui Wang", "Xiaoliang Xiao", "Dakui Wang", "Xin Li", "Jingfeng Luo", "Conggang Hu"], "title": "From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have significantly advanced artificial\nintelligence by optimizing traditional Natural Language Processing (NLP)\nworkflows, facilitating their integration into various systems. Many such NLP\nsystems, including ours, directly incorporate LLMs. However, this approach\neither results in expensive costs or yields suboptimal performance after\nfine-tuning. In this paper, we introduce a three-stage cost-efficient\nend-to-end LLM deployment pipeline, comprising prototyping, knowledge transfer,\nand model compression, to effectively tackle the cost-performance dilemma in\nLLM-based frameworks. Its high cost-efficiency is manifested not only in\nsimplifying system complexity and producing super-tiny online models with\nenhanced performance and reduced costs in the results, but also in addressing\ndevelopment cycle constraints, the lack of extensive high-quality data, and\nlimited computational resources during the project development process. In the\nfirst stage, we construct an optimal performance prototype system by\ntransforming complex tasks into a function call-based LLM-driven pipeline,\nwhich serves as a teacher model to generate high-quality data. In the second\nstage, we combine techniques like rejection sampling fine-tuning, reinforcement\nlearning, and knowledge distillation to transfer knowledge to 0.5B student\nmodels, delivering effective performance at minimal cost. In the final stage,\nwe further compress models to 0.4B via quantization and pruning, achieving\nultra-low latency and cost. Extensive experimental results and the framework's\nmodular design suggest cross-domain capabilities and potential applicability in\nother NLP areas.", "AI": {"tldr": "A three-stage pipeline (prototyping, knowledge transfer, model compression) is introduced to optimize cost and performance in LLM deployment, addressing high costs and suboptimal fine-tuning results.", "motivation": "High costs and performance issues in LLM-based NLP systems drive the need for a cost-efficient deployment pipeline.", "method": "The pipeline includes prototyping (teacher model), knowledge transfer (student models), and model compression (quantization/pruning).", "result": "Produces super-tiny models with enhanced performance, reduced costs, and ultra-low latency.", "conclusion": "The modular framework shows cross-domain potential and applicability in other NLP areas."}}
{"id": "2505.07540", "pdf": "https://arxiv.org/pdf/2505.07540", "abs": "https://arxiv.org/abs/2505.07540", "authors": ["Juan E. Tapia", "Fabian Stockhardt", "L\u00e1zaro Janier Gonz\u00e1lez-Soler", "Christoph Busch"], "title": "SynID: Passport Synthetic Dataset for Presentation Attack Detection", "categories": ["cs.CV"], "comment": null, "summary": "The demand for Presentation Attack Detection (PAD) to identify fraudulent ID\ndocuments in remote verification systems has significantly risen in recent\nyears. This increase is driven by several factors, including the rise of remote\nwork, online purchasing, migration, and advancements in synthetic images.\nAdditionally, we have noticed a surge in the number of attacks aimed at the\nenrolment process. Training a PAD to detect fake ID documents is very\nchallenging because of the limited number of ID documents available due to\nprivacy concerns. This work proposes a new passport dataset generated from a\nhybrid method that combines synthetic data and open-access information using\nthe ICAO requirement to obtain realistic training and testing images.", "AI": {"tldr": "A hybrid method combining synthetic data and open-access information is proposed to create a realistic passport dataset for training Presentation Attack Detection (PAD) systems, addressing the challenge of limited real ID document availability.", "motivation": "The rise in remote verification systems and synthetic image advancements has increased demand for PAD, but limited real ID documents due to privacy concerns hinder effective training.", "method": "A hybrid approach merges synthetic data with open-access information, adhering to ICAO requirements, to generate realistic passport images for PAD training and testing.", "result": "The proposed method yields a realistic passport dataset suitable for training and evaluating PAD systems.", "conclusion": "The hybrid dataset generation method effectively addresses the scarcity of real ID documents, enhancing PAD system training for fraud detection."}}
{"id": "2505.07239", "pdf": "https://arxiv.org/pdf/2505.07239", "abs": "https://arxiv.org/abs/2505.07239", "authors": ["Guang Yan", "Yuhui Zhang", "Zimu Guo", "Lutan Zhao", "Xiaojun Chen", "Chen Wang", "Wenhao Wang", "Dan Meng", "Rui Hou"], "title": "Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted to SP 2025", "summary": "With the growing use of large language models (LLMs) hosted on cloud\nplatforms to offer inference services, privacy concerns about the potential\nleakage of sensitive information are escalating. Secure multi-party computation\n(MPC) is a promising solution to protect the privacy in LLM inference. However,\nMPC requires frequent inter-server communication, causing high performance\noverhead.\n  Inspired by the prevalent activation sparsity of LLMs, where most neuron are\nnot activated after non-linear activation functions, we propose an efficient\nprivate inference system, Comet. This system employs an accurate and fast\npredictor to predict the sparsity distribution of activation function output.\nAdditionally, we introduce a new private inference protocol. It efficiently and\nsecurely avoids computations involving zero values by exploiting the spatial\nlocality of the predicted sparse distribution. While this computation-avoidance\napproach impacts the spatiotemporal continuity of KV cache entries, we address\nthis challenge with a low-communication overhead cache refilling strategy that\nmerges miss requests and incorporates a prefetching mechanism. Finally, we\nevaluate Comet on four common LLMs and compare it with six state-of-the-art\nprivate inference systems. Comet achieves a 1.87x-2.63x speedup and a\n1.94x-2.64x communication reduction.", "AI": {"tldr": "Comet is a private inference system for LLMs that uses activation sparsity prediction and a new protocol to reduce computation and communication overhead, achieving significant speedup and efficiency gains.", "motivation": "Address privacy concerns in LLM inference due to sensitive data leakage and high performance overhead of secure multi-party computation (MPC).", "method": "Predicts sparsity distribution of activation outputs, introduces a private inference protocol to avoid zero-value computations, and uses a cache refilling strategy with prefetching.", "result": "Achieves 1.87x-2.63x speedup and 1.94x-2.64x communication reduction compared to six state-of-the-art systems.", "conclusion": "Comet effectively balances privacy and performance in LLM inference by leveraging sparsity and optimizing communication."}}
{"id": "2505.07303", "pdf": "https://arxiv.org/pdf/2505.07303", "abs": "https://arxiv.org/abs/2505.07303", "authors": ["Bianca Marin Moreno", "Khaled Eldowa", "Pierre Gaillard", "Margaux Br\u00e9g\u00e8re", "Nadia Oudjane"], "title": "Online Episodic Convex Reinforcement Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study online learning in episodic finite-horizon Markov decision processes\n(MDPs) with convex objective functions, known as the concave utility\nreinforcement learning (CURL) problem. This setting generalizes RL from linear\nto convex losses on the state-action distribution induced by the agent's\npolicy. The non-linearity of CURL invalidates classical Bellman equations and\nrequires new algorithmic approaches. We introduce the first algorithm achieving\nnear-optimal regret bounds for online CURL without any prior knowledge on the\ntransition function. To achieve this, we use an online mirror descent algorithm\nwith varying constraint sets and a carefully designed exploration bonus. We\nthen address for the first time a bandit version of CURL, where the only\nfeedback is the value of the objective function on the state-action\ndistribution induced by the agent's policy. We achieve a sub-linear regret\nbound for this more challenging problem by adapting techniques from bandit\nconvex optimization to the MDP setting.", "AI": {"tldr": "The paper introduces algorithms for online concave utility reinforcement learning (CURL) in MDPs, achieving near-optimal regret bounds without prior knowledge of transitions. It also addresses a bandit version of CURL with sub-linear regret.", "motivation": "To generalize reinforcement learning from linear to convex losses on state-action distributions, requiring new approaches due to non-linearity.", "method": "Uses online mirror descent with varying constraints and exploration bonuses for CURL, and adapts bandit convex optimization techniques for the bandit version.", "result": "Achieves near-optimal regret bounds for CURL and sub-linear regret for the bandit version.", "conclusion": "The proposed methods successfully address CURL and its bandit variant, advancing online learning in MDPs with convex objectives."}}
{"id": "2504.16007", "pdf": "https://arxiv.org/pdf/2504.16007", "abs": "https://arxiv.org/abs/2504.16007", "authors": ["Igor Rozhkov", "Natalia Loukachevitch"], "title": "Methods for Recognizing Nested Terms", "categories": ["cs.CL"], "comment": "Published in Computational Linguistics and Intellectual Technologies:\n  Proceedings of the International Conference \"Dialogue 2025\"", "summary": "In this paper, we describe our participation in the RuTermEval competition\ndevoted to extracting nested terms. We apply the Binder model, which was\npreviously successfully applied to the recognition of nested named entities, to\nextract nested terms. We obtained the best results of term recognition in all\nthree tracks of the RuTermEval competition. In addition, we study the new task\nof recognition of nested terms from flat training data annotated with terms\nwithout nestedness. We can conclude that several approaches we proposed in this\nwork are viable enough to retrieve nested terms effectively without nested\nlabeling of them.", "AI": {"tldr": "The paper describes the application of the Binder model for nested term extraction in the RuTermEval competition, achieving top results. It also explores nested term recognition from flat training data.", "motivation": "To address the challenge of extracting nested terms, especially when training data lacks nested annotations.", "method": "The Binder model, previously used for nested named entity recognition, is adapted for nested term extraction.", "result": "Achieved the best results in all three tracks of the RuTermEval competition. Demonstrated viability of proposed approaches for nested term recognition without nested labeling.", "conclusion": "The proposed methods effectively retrieve nested terms even without nested annotations in training data."}}
{"id": "2505.07552", "pdf": "https://arxiv.org/pdf/2505.07552", "abs": "https://arxiv.org/abs/2505.07552", "authors": ["Efe Bozkir", "Christian Kosel", "Tina Seidel", "Enkelejda Kasneci"], "title": "Automated Visual Attention Detection using Mobile Eye Tracking in Behavioral Classroom Studies", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": "Accepted as a long paper at the Educational Data Mining (EDM)\n  Conference 2025", "summary": "Teachers' visual attention and its distribution across the students in\nclassrooms can constitute important implications for student engagement,\nachievement, and professional teacher training. Despite that, inferring the\ninformation about where and which student teachers focus on is not trivial.\nMobile eye tracking can provide vital help to solve this issue; however, the\nuse of mobile eye tracking alone requires a significant amount of manual\nannotations. To address this limitation, we present an automated processing\npipeline concept that requires minimal manually annotated data to recognize\nwhich student the teachers focus on. To this end, we utilize state-of-the-art\nface detection models and face recognition feature embeddings to train face\nrecognition models with transfer learning in the classroom context and combine\nthese models with the teachers' gaze from mobile eye trackers. We evaluated our\napproach with data collected from four different classrooms, and our results\nshow that while it is possible to estimate the visually focused students with\nreasonable performance in all of our classroom setups, U-shaped and small\nclassrooms led to the best results with accuracies of approximately 0.7 and\n0.9, respectively. While we did not evaluate our method for teacher-student\ninteractions and focused on the validity of the technical approach, as our\nmethodology does not require a vast amount of manually annotated data and\noffers a non-intrusive way of handling teachers' visual attention, it could\nhelp improve instructional strategies, enhance classroom management, and\nprovide feedback for professional teacher development.", "AI": {"tldr": "An automated pipeline using face detection and recognition with mobile eye tracking to identify teachers' visual focus on students, reducing manual annotation needs.", "motivation": "Teachers' visual attention impacts student engagement and achievement, but current methods require excessive manual effort.", "method": "Combines face detection, recognition models, and gaze data from mobile eye trackers with minimal manual annotation.", "result": "Achieved accuracies of 0.7 (U-shaped classrooms) and 0.9 (small classrooms) in identifying focused students.", "conclusion": "The method offers a non-intrusive, scalable solution to improve instructional strategies and teacher training."}}
{"id": "2505.07261", "pdf": "https://arxiv.org/pdf/2505.07261", "abs": "https://arxiv.org/abs/2505.07261", "authors": ["Ce Hao", "Anxing Xiao", "Zhiwei Xue", "Harold Soh"], "title": "CHD: Coupled Hierarchical Diffusion for Long-Horizon Tasks", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Diffusion-based planners have shown strong performance in short-horizon tasks\nbut often fail in complex, long-horizon settings. We trace the failure to loose\ncoupling between high-level (HL) sub-goal selection and low-level (LL)\ntrajectory generation, which leads to incoherent plans and degraded\nperformance. We propose Coupled Hierarchical Diffusion (CHD), a framework that\nmodels HL sub-goals and LL trajectories jointly within a unified diffusion\nprocess. A shared classifier passes LL feedback upstream so that sub-goals\nself-correct while sampling proceeds. This tight HL-LL coupling improves\ntrajectory coherence and enables scalable long-horizon diffusion planning.\nExperiments across maze navigation, tabletop manipulation, and household\nenvironments show that CHD consistently outperforms both flat and hierarchical\ndiffusion baselines.", "AI": {"tldr": "CHD improves long-horizon planning by coupling high-level sub-goals and low-level trajectories in a unified diffusion process, outperforming baselines.", "motivation": "Addressing the failure of diffusion-based planners in complex, long-horizon tasks due to loose coupling between high-level sub-goal selection and low-level trajectory generation.", "method": "Proposes Coupled Hierarchical Diffusion (CHD), a framework that jointly models high-level sub-goals and low-level trajectories within a unified diffusion process, using a shared classifier for feedback.", "result": "CHD consistently outperforms flat and hierarchical diffusion baselines in experiments across maze navigation, tabletop manipulation, and household environments.", "conclusion": "Tight coupling between high-level and low-level planning in CHD enhances trajectory coherence and scalability for long-horizon tasks."}}
{"id": "2505.07309", "pdf": "https://arxiv.org/pdf/2505.07309", "abs": "https://arxiv.org/abs/2505.07309", "authors": ["Pei-Fu Guo", "Yun-Da Tsai", "Shou-De Lin"], "title": "Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) often generate fluent but factually incorrect\noutputs, known as hallucinations, which undermine their reliability in\nreal-world applications. While uncertainty estimation has emerged as a\npromising strategy for detecting such errors, current metrics offer limited\ninterpretability and lack clarity about the types of uncertainty they capture.\nIn this paper, we present a systematic framework for decomposing LLM\nuncertainty into four distinct sources, inspired by previous research. We\ndevelop a source-specific estimation pipeline to quantify these uncertainty\ntypes and evaluate how existing metrics relate to each source across tasks and\nmodels. Our results show that metrics, task, and model exhibit systematic\nvariation in uncertainty characteristic. Building on this, we propose a method\nfor task specific metric/model selection guided by the alignment or divergence\nbetween their uncertainty characteristics and that of a given task. Our\nexperiments across datasets and models demonstrate that our uncertainty-aware\nselection strategy consistently outperforms baseline strategies, helping us\nselect appropriate models or uncertainty metrics, and contributing to more\nreliable and efficient deployment in uncertainty estimation.", "AI": {"tldr": "The paper presents a framework to decompose LLM uncertainty into four sources, evaluates existing metrics, and proposes a task-specific selection method for models/metrics, improving reliability.", "motivation": "Addressing the issue of hallucinations in LLM outputs by enhancing interpretability and clarity in uncertainty estimation.", "method": "Decomposes LLM uncertainty into four sources, develops a source-specific estimation pipeline, and evaluates metrics across tasks/models.", "result": "Metrics, tasks, and models show systematic variation in uncertainty characteristics; the proposed selection method outperforms baselines.", "conclusion": "The uncertainty-aware selection strategy improves model/metric selection, aiding reliable deployment in uncertainty estimation."}}
{"id": "2504.16394", "pdf": "https://arxiv.org/pdf/2504.16394", "abs": "https://arxiv.org/abs/2504.16394", "authors": ["Fahmida Liza Piya", "Rahmatollah Beheshti"], "title": "ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Unstructured clinical data can serve as a unique and rich source of\ninformation that can meaningfully inform clinical practice. Extracting the most\npertinent context from such data is critical for exploiting its true potential\ntoward optimal and timely decision-making in patient care. While prior research\nhas explored various methods for clinical text summarization, most prior\nstudies either process all input tokens uniformly or rely on heuristic-based\nfilters, which can overlook nuanced clinical cues and fail to prioritize\ninformation critical for decision-making. In this study, we propose Contextual,\na novel framework that integrates a Context-Preserving Token Filtering method\nwith a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By\npreserving context-specific important tokens and enriching them with structured\nknowledge, ConTextual improves both linguistic coherence and clinical fidelity.\nOur extensive empirical evaluations on two public benchmark datasets\ndemonstrate that ConTextual consistently outperforms other baselines. Our\nproposed approach highlights the complementary role of token-level filtering\nand structured retrieval in enhancing both linguistic and clinical integrity,\nas well as offering a scalable solution for improving precision in clinical\ntext generation.", "AI": {"tldr": "ConTextual, a framework combining token filtering and knowledge graphs, outperforms baselines in clinical text summarization by enhancing linguistic and clinical integrity.", "motivation": "Unstructured clinical data is rich but underutilized; existing methods overlook critical nuances for decision-making.", "method": "Integrates Context-Preserving Token Filtering with a Domain-Specific Knowledge Graph for contextual augmentation.", "result": "Outperforms baselines on public datasets, improving linguistic coherence and clinical fidelity.", "conclusion": "Token-level filtering and structured retrieval complement each other, offering a scalable solution for precise clinical text generation."}}
{"id": "2505.07556", "pdf": "https://arxiv.org/pdf/2505.07556", "abs": "https://arxiv.org/abs/2505.07556", "authors": ["Kamil Jeziorek", "Tomasz Kryjak"], "title": "Self-Supervised Event Representations: Towards Accurate, Real-Time Perception on SoC FPGAs", "categories": ["cs.CV"], "comment": "Presented at the Real-time Processing of Image, Depth and Video\n  Information 2025 workshop and to be considered for publication is the SPIE\n  Proceedings", "summary": "Event cameras offer significant advantages over traditional frame-based\nsensors. These include microsecond temporal resolution, robustness under\nvarying lighting conditions and low power consumption. Nevertheless, the\neffective processing of their sparse, asynchronous event streams remains\nchallenging. Existing approaches to this problem can be categorised into two\ndistinct groups. The first group involves the direct processing of event data\nwith neural models, such as Spiking Neural Networks or Graph Convolutional\nNeural Networks. However, this approach is often accompanied by a compromise in\nterms of qualitative performance. The second group involves the conversion of\nevents into dense representations with handcrafted aggregation functions, which\ncan boost accuracy at the cost of temporal fidelity. This paper introduces a\nnovel Self-Supervised Event Representation (SSER) method leveraging Gated\nRecurrent Unit (GRU) networks to achieve precise per-pixel encoding of event\ntimestamps and polarities without temporal discretisation. The recurrent layers\nare trained in a self-supervised manner to maximise the fidelity of event-time\nencoding. The inference is performed with event representations generated\nasynchronously, thus ensuring compatibility with high-throughput sensors. The\nexperimental validation demonstrates that SSER outperforms aggregation-based\nbaselines, achieving improvements of 2.4% mAP and 0.6% on the Gen1 and 1 Mpx\nobject detection datasets. Furthermore, the paper presents the first hardware\nimplementation of recurrent representation for event data on a System-on-Chip\nFPGA, achieving sub-microsecond latency and power consumption between 1-2 W,\nsuitable for real-time, power-efficient applications. Code is available at\nhttps://github.com/vision-agh/RecRepEvent.", "AI": {"tldr": "A novel Self-Supervised Event Representation (SSER) method using GRU networks for precise event encoding, outperforming baselines in object detection with efficient hardware implementation.", "motivation": "Event cameras provide advantages like high temporal resolution and low power, but processing their sparse data is challenging. Existing methods either compromise performance or temporal fidelity.", "method": "SSER leverages GRU networks for self-supervised, per-pixel event encoding without temporal discretisation, ensuring high-throughput compatibility.", "result": "SSER improves mAP by 2.4% and 0.6% on Gen1 and 1 Mpx datasets, with FPGA implementation achieving sub-microsecond latency and 1-2 W power.", "conclusion": "SSER offers a robust, efficient solution for event data processing, suitable for real-time applications."}}
{"id": "2505.07286", "pdf": "https://arxiv.org/pdf/2505.07286", "abs": "https://arxiv.org/abs/2505.07286", "authors": ["Keyue Qiu", "Yuxuan Song", "Zhehuan Fan", "Peidong Liu", "Zhe Zhang", "Mingyue Zheng", "Hao Zhou", "Wei-Ying Ma"], "title": "Piloting Structure-Based Drug Design via Modality-Specific Optimal Schedule", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Structure-Based Drug Design (SBDD) is crucial for identifying bioactive\nmolecules. Recent deep generative models are faced with challenges in geometric\nstructure modeling. A major bottleneck lies in the twisted probability path of\nmulti-modalities -- continuous 3D positions and discrete 2D topologies -- which\njointly determine molecular geometries. By establishing the fact that noise\nschedules decide the Variational Lower Bound (VLB) for the twisted probability\npath, we propose VLB-Optimal Scheduling (VOS) strategy in this under-explored\narea, which optimizes VLB as a path integral for SBDD. Our model effectively\nenhances molecular geometries and interaction modeling, achieving\nstate-of-the-art PoseBusters passing rate of 95.9% on CrossDock, more than 10%\nimprovement upon strong baselines, while maintaining high affinities and robust\nintramolecular validity evaluated on held-out test set.", "AI": {"tldr": "The paper introduces VLB-Optimal Scheduling (VOS) to improve Structure-Based Drug Design (SBDD) by optimizing noise schedules for better molecular geometry modeling.", "motivation": "Addressing challenges in deep generative models for SBDD, particularly the twisted probability path of multi-modalities (3D positions and 2D topologies).", "method": "Proposes VOS strategy to optimize the Variational Lower Bound (VLB) as a path integral, enhancing molecular geometry and interaction modeling.", "result": "Achieves a 95.9% PoseBusters passing rate on CrossDock, a 10%+ improvement over baselines, with high affinities and intramolecular validity.", "conclusion": "VOS effectively improves SBDD by optimizing noise schedules, leading to superior molecular geometries and interactions."}}
{"id": "2505.07320", "pdf": "https://arxiv.org/pdf/2505.07320", "abs": "https://arxiv.org/abs/2505.07320", "authors": ["Yuhao Li", "Ling Luo", "Uwe Aickelin"], "title": "Dynamical Label Augmentation and Calibration for Noisy Electronic Health Records", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Medical research, particularly in predicting patient outcomes, heavily relies\non medical time series data extracted from Electronic Health Records (EHR),\nwhich provide extensive information on patient histories. Despite rigorous\nexamination, labeling errors are inevitable and can significantly impede\naccurate predictions of patient outcome. To address this challenge, we propose\nan \\textbf{A}ttention-based Learning Framework with Dynamic\n\\textbf{C}alibration and Augmentation for \\textbf{T}ime series Noisy\n\\textbf{L}abel \\textbf{L}earning (ACTLL). This framework leverages a\ntwo-component Beta mixture model to identify the certain and uncertain sets of\ninstances based on the fitness distribution of each class, and it captures\nglobal temporal dynamics while dynamically calibrating labels from the\nuncertain set or augmenting confident instances from the certain set.\nExperimental results on large-scale EHR datasets eICU and MIMIC-IV-ED, and\nseveral benchmark datasets from the UCR and UEA repositories, demonstrate that\nour model ACTLL has achieved state-of-the-art performance, especially under\nhigh noise levels.", "AI": {"tldr": "ACTLL is an attention-based framework for handling noisy labels in medical time series data, improving prediction accuracy by dynamically calibrating uncertain labels and augmenting confident instances.", "motivation": "Labeling errors in EHR data hinder accurate patient outcome predictions, necessitating a robust method to address noise.", "method": "ACTLL uses a Beta mixture model to classify instances into certain/uncertain sets, then dynamically calibrates or augments labels while capturing temporal dynamics.", "result": "ACTLL outperforms others on EHR datasets (eICU, MIMIC-IV-ED) and benchmarks (UCR, UEA), especially with high noise.", "conclusion": "ACTLL effectively mitigates label noise in medical time series, enhancing prediction reliability."}}
{"id": "2504.19044", "pdf": "https://arxiv.org/pdf/2504.19044", "abs": "https://arxiv.org/abs/2504.19044", "authors": ["Di Wu", "Yibin Lei", "Christof Monz"], "title": "Calibrating Translation Decoding with Quality Estimation on LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Neural machine translation (NMT) systems typically employ maximum a\nposteriori (MAP) decoding to select the highest-scoring translation from the\ndistribution mass. However, recent evidence highlights the inadequacy of MAP\ndecoding, often resulting in low-quality or even pathological hypotheses -- the\ndecoding objective is not aligned with real-world translation quality. This\npaper proposes calibrating hypothesis likelihoods with translation quality from\na distribution view by directly optimizing their Pearson correlation -- thereby\nenhancing the effectiveness of translation decoding. With our method,\ntranslation on large language models (LLMs) improves substantially after\nlimited training (2K instances per direction). This improvement is orthogonal\nto those achieved through supervised fine-tuning, leading to substantial gains\nacross a broad range of metrics and human evaluations -- even when applied to\ntop-performing translation-specialized LLMs fine-tuned on high-quality\ntranslation data, such as Tower, or when compared to recent preference\noptimization methods, like CPO. Moreover, the calibrated translation likelihood\ncan directly serve as a strong proxy for translation quality, closely\napproximating or even surpassing some state-of-the-art translation quality\nestimation models, like CometKiwi. Lastly, our in-depth analysis demonstrates\nthat calibration enhances the effectiveness of MAP decoding, thereby enabling\ngreater efficiency in real-world deployment. The resulting state-of-the-art\ntranslation model, which covers 10 languages, along with the accompanying code\nand human evaluation data, has been released to the community:\nhttps://github.com/moore3930/calibrating-llm-mt.", "AI": {"tldr": "The paper proposes calibrating hypothesis likelihoods in NMT to align decoding with real-world translation quality, improving performance even on top LLMs.", "motivation": "MAP decoding in NMT often produces low-quality translations due to misalignment with real-world quality.", "method": "Calibrate hypothesis likelihoods by optimizing their Pearson correlation with translation quality.", "result": "Substantial improvements in translation quality across metrics and human evaluations, even on specialized LLMs.", "conclusion": "Calibration enhances MAP decoding efficiency and serves as a strong proxy for translation quality, outperforming some state-of-the-art models."}}
{"id": "2505.07573", "pdf": "https://arxiv.org/pdf/2505.07573", "abs": "https://arxiv.org/abs/2505.07573", "authors": ["Sarah de Boer", "Hartmut H\u00e4ntze", "Kiran Vaidhya Venkadesh", "Myrthe A. D. Buser", "Gabriel E. Humpire Mamani", "Lina Xu", "Lisa C. Adams", "Jawed Nawabi", "Keno K. Bressem", "Bram van Ginneken", "Mathias Prokop", "Alessa Hering"], "title": "Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework", "categories": ["cs.CV", "cs.AI"], "comment": "35 pages, 11 figures", "summary": "Kidney abnormality segmentation has important potential to enhance the\nclinical workflow, especially in settings requiring quantitative assessments.\nKidney volume could serve as an important biomarker for renal diseases, with\nchanges in volume correlating directly with kidney function. Currently,\nclinical practice often relies on subjective visual assessment for evaluating\nkidney size and abnormalities, including tumors and cysts, which are typically\nstaged based on diameter, volume, and anatomical location. To support a more\nobjective and reproducible approach, this research aims to develop a robust,\nthoroughly validated kidney abnormality segmentation algorithm, made publicly\navailable for clinical and research use. We employ publicly available training\ndatasets and leverage the state-of-the-art medical image segmentation framework\nnnU-Net. Validation is conducted using both proprietary and public test\ndatasets, with segmentation performance quantified by Dice coefficient and the\n95th percentile Hausdorff distance. Furthermore, we analyze robustness across\nsubgroups based on patient sex, age, CT contrast phases, and tumor histologic\nsubtypes. Our findings demonstrate that our segmentation algorithm, trained\nexclusively on publicly available data, generalizes effectively to external\ntest sets and outperforms existing state-of-the-art models across all tested\ndatasets. Subgroup analyses reveal consistent high performance, indicating\nstrong robustness and reliability. The developed algorithm and associated code\nare publicly accessible at\nhttps://github.com/DIAGNijmegen/oncology-kidney-abnormality-segmentation.", "AI": {"tldr": "A robust kidney abnormality segmentation algorithm is developed using nnU-Net, validated on diverse datasets, and outperforms existing models, with public availability for clinical use.", "motivation": "Current clinical kidney assessments rely on subjective visual methods; this research aims to provide an objective, reproducible tool for quantitative analysis.", "method": "Utilizes nnU-Net and public datasets, validated with Dice coefficient and Hausdorff distance, and tested across patient subgroups.", "result": "The algorithm generalizes well, outperforms state-of-the-art models, and shows consistent performance across subgroups.", "conclusion": "The publicly available algorithm offers a reliable, objective solution for kidney abnormality segmentation, enhancing clinical workflows."}}
{"id": "2505.07294", "pdf": "https://arxiv.org/pdf/2505.07294", "abs": "https://arxiv.org/abs/2505.07294", "authors": ["Tong Zhang", "Boyuan Zheng", "Ruiqian Nai", "Yingdong Hu", "Yen-Jen Wang", "Geng Chen", "Fanqi Lin", "Jiongye Li", "Chuye Hong", "Koushil Sreenath", "Yang Gao"], "title": "HuB: Learning Extreme Humanoid Balance", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "Project website: https://hub-robot.github.io", "summary": "The human body demonstrates exceptional motor capabilities-such as standing\nsteadily on one foot or performing a high kick with the leg raised over 1.5\nmeters-both requiring precise balance control. While recent research on\nhumanoid control has leveraged reinforcement learning to track human motions\nfor skill acquisition, applying this paradigm to balance-intensive tasks\nremains challenging. In this work, we identify three key obstacles: instability\nfrom reference motion errors, learning difficulties due to morphological\nmismatch, and the sim-to-real gap caused by sensor noise and unmodeled\ndynamics. To address these challenges, we propose HuB (Humanoid Balance), a\nunified framework that integrates reference motion refinement, balance-aware\npolicy learning, and sim-to-real robustness training, with each component\ntargeting a specific challenge. We validate our approach on the Unitree G1\nhumanoid robot across challenging quasi-static balance tasks, including extreme\nsingle-legged poses such as Swallow Balance and Bruce Lee's Kick. Our policy\nremains stable even under strong physical disturbances-such as a forceful\nsoccer strike-while baseline methods consistently fail to complete these tasks.\nProject website: https://hub-robot.github.io", "AI": {"tldr": "HuB (Humanoid Balance) is a framework addressing balance challenges in humanoid robots through motion refinement, balance-aware policy learning, and sim-to-real training, validated on extreme tasks like Swallow Balance and Bruce Lee's Kick.", "motivation": "Humanoid robots struggle with balance-intensive tasks due to instability from motion errors, morphological mismatches, and sim-to-real gaps.", "method": "Proposes HuB, integrating motion refinement, balance-aware policy learning, and robustness training to tackle these challenges.", "result": "HuB outperforms baselines, maintaining stability under disturbances like forceful strikes, while others fail.", "conclusion": "HuB effectively addresses balance challenges, enabling humanoid robots to perform extreme tasks reliably."}}
{"id": "2505.07351", "pdf": "https://arxiv.org/pdf/2505.07351", "abs": "https://arxiv.org/abs/2505.07351", "authors": ["Prateek Garg", "Lokesh Nagalapatti", "Sunita Sarawagi"], "title": "From Search To Sampling: Generative Models For Robust Algorithmic Recourse", "categories": ["cs.LG"], "comment": null, "summary": "Algorithmic Recourse provides recommendations to individuals who are\nadversely impacted by automated model decisions, on how to alter their profiles\nto achieve a favorable outcome. Effective recourse methods must balance three\nconflicting goals: proximity to the original profile to minimize cost,\nplausibility for realistic recourse, and validity to ensure the desired\noutcome. We show that existing methods train for these objectives separately\nand then search for recourse through a joint optimization over the recourse\ngoals during inference, leading to poor recourse recommendations. We introduce\nGenRe, a generative recourse model designed to train the three recourse\nobjectives jointly. Training such generative models is non-trivial due to lack\nof direct recourse supervision. We propose efficient ways to synthesize such\nsupervision and further show that GenRe's training leads to a consistent\nestimator. Unlike most prior methods, that employ non-robust gradient descent\nbased search during inference, GenRe simply performs a forward sampling over\nthe generative model to produce minimum cost recourse, leading to superior\nperformance across multiple metrics. We also demonstrate GenRe provides the\nbest trade-off between cost, plausibility and validity, compared to\nstate-of-art baselines. Our code is available at:\nhttps://github.com/prateekgargx/genre.", "AI": {"tldr": "GenRe is a generative recourse model that jointly trains proximity, plausibility, and validity objectives, outperforming existing methods by avoiding separate optimization and using forward sampling for efficient recourse recommendations.", "motivation": "Existing recourse methods optimize objectives separately during inference, leading to poor recommendations. GenRe addresses this by jointly training the objectives.", "method": "GenRe uses a generative model trained with synthesized supervision to jointly optimize proximity, plausibility, and validity. It employs forward sampling for efficient recourse generation.", "result": "GenRe outperforms state-of-the-art baselines, providing the best trade-off between cost, plausibility, and validity.", "conclusion": "GenRe offers a robust and efficient solution for algorithmic recourse, improving performance and practicality over existing methods."}}
{"id": "2504.19339", "pdf": "https://arxiv.org/pdf/2504.19339", "abs": "https://arxiv.org/abs/2504.19339", "authors": ["Dongqi Liu", "Xi Yu", "Vera Demberg", "Mirella Lapata"], "title": "Explanatory Summarization with Discourse-Driven Planning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by the Transactions of the Association for Computational\n  Linguistics (TACL 2025)", "summary": "Lay summaries for scientific documents typically include explanations to help\nreaders grasp sophisticated concepts or arguments. However, current automatic\nsummarization methods do not explicitly model explanations, which makes it\ndifficult to align the proportion of explanatory content with human-written\nsummaries. In this paper, we present a plan-based approach that leverages\ndiscourse frameworks to organize summary generation and guide explanatory\nsentences by prompting responses to the plan. Specifically, we propose two\ndiscourse-driven planning strategies, where the plan is conditioned as part of\nthe input or part of the output prefix, respectively. Empirical experiments on\nthree lay summarization datasets show that our approach outperforms existing\nstate-of-the-art methods in terms of summary quality, and it enhances model\nrobustness, controllability, and mitigates hallucination.", "AI": {"tldr": "A plan-based approach using discourse frameworks improves lay summaries by guiding explanatory content, outperforming current methods in quality and robustness.", "motivation": "Current automatic summarization methods lack explicit modeling of explanations, leading to misalignment with human-written summaries.", "method": "Proposes two discourse-driven planning strategies: conditioning the plan as input or output prefix to guide explanatory sentences.", "result": "Outperforms state-of-the-art methods on three datasets, improving summary quality, robustness, controllability, and reducing hallucination.", "conclusion": "The plan-based approach effectively enhances lay summarization by integrating discourse frameworks for better explanatory content alignment."}}
{"id": "2505.07576", "pdf": "https://arxiv.org/pdf/2505.07576", "abs": "https://arxiv.org/abs/2505.07576", "authors": ["Manuel Barusco", "Francesco Borsatti", "Youssef Ben Khalifa", "Davide Dalle Pezze", "Gian Antonio Susto"], "title": "Evaluating Modern Visual Anomaly Detection Approaches in Semiconductor Manufacturing: A Comparative Study", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Semiconductor manufacturing is a complex, multistage process. Automated\nvisual inspection of Scanning Electron Microscope (SEM) images is indispensable\nfor minimizing equipment downtime and containing costs. Most previous research\nconsiders supervised approaches, assuming a sufficient number of anomalously\nlabeled samples. On the contrary, Visual Anomaly Detection (VAD), an emerging\nresearch domain, focuses on unsupervised learning, avoiding the costly defect\ncollection phase while providing explanations of the predictions. We introduce\na benchmark for VAD in the semiconductor domain by leveraging the MIIC dataset.\nOur results demonstrate the efficacy of modern VAD approaches in this field.", "AI": {"tldr": "A benchmark for unsupervised Visual Anomaly Detection (VAD) in semiconductor manufacturing is introduced, showing its effectiveness using the MIIC dataset.", "motivation": "Automated visual inspection of SEM images is crucial for cost and downtime reduction, but supervised methods require labeled anomalies, which are costly to collect.", "method": "Unsupervised learning is used for VAD, avoiding the need for labeled anomaly samples.", "result": "Modern VAD approaches prove effective in semiconductor manufacturing.", "conclusion": "Unsupervised VAD is a viable solution for anomaly detection in semiconductor SEM images."}}
{"id": "2505.07317", "pdf": "https://arxiv.org/pdf/2505.07317", "abs": "https://arxiv.org/abs/2505.07317", "authors": ["Ashmita Sampatsing", "Sophie Vos", "Emma Beauxis-Aussalet", "Justus Bogner"], "title": "How Do Companies Manage the Environmental Sustainability of AI? An Interview Study About Green AI Efforts and Regulations", "categories": ["cs.CY", "cs.AI"], "comment": "Accepted for publication at the 11th International Conference on ICT\n  for Sustainability (ICT4S'25), see https://conf.researchr.org/home/ict4s-2025", "summary": "With the ever-growing adoption of artificial intelligence (AI), AI-based\nsoftware and its negative impact on the environment are no longer negligible,\nand studying and mitigating this impact has become a critical area of research.\nHowever, it is currently unclear which role environmental sustainability plays\nduring AI adoption in industry and how AI regulations influence Green AI\npractices and decision-making in industry. We therefore aim to investigate the\nGreen AI perception and management of industry practitioners. To this end, we\nconducted a total of 11 interviews with participants from 10 different\norganizations that adopted AI-based software. The interviews explored three\nmain themes: AI adoption, current efforts in mitigating the negative\nenvironmental impact of AI, and the influence of the EU AI Act and the\nCorporate Sustainability Reporting Directive (CSRD). Our findings indicate that\n9 of 11 participants prioritized business efficiency during AI adoption, with\nminimal consideration of environmental sustainability. Monitoring and\nmitigation of AI's environmental impact were very limited. Only one participant\nmonitored negative environmental effects. Regarding applied mitigation\npractices, six participants reported no actions, with the others sporadically\nmentioning techniques like prompt engineering, relying on smaller models, or\nnot overusing AI. Awareness and compliance with the EU AI Act are low, with\nonly one participant reporting on its influence, while the CSRD drove\nsustainability reporting efforts primarily in larger companies. All in all, our\nfindings reflect a lack of urgency and priority for sustainable AI among these\ncompanies. We suggest that current regulations are not very effective, which\nhas implications for policymakers. Additionally, there is a need to raise\nindustry awareness, but also to provide user-friendly techniques and tools for\nGreen AI practices.", "AI": {"tldr": "The paper investigates industry practitioners' perception and management of Green AI, revealing low prioritization of environmental sustainability in AI adoption and limited regulatory influence.", "motivation": "The study addresses the unclear role of environmental sustainability in AI adoption and the impact of regulations like the EU AI Act and CSRD on Green AI practices.", "method": "Conducted 11 interviews with participants from 10 organizations using AI, focusing on AI adoption, environmental impact mitigation, and regulatory influence.", "result": "Most participants prioritized business efficiency over sustainability, with minimal monitoring or mitigation of AI's environmental impact. Regulatory awareness and compliance were low.", "conclusion": "Current regulations are ineffective, and there's a need for better industry awareness and tools for Green AI practices."}}
{"id": "2505.07367", "pdf": "https://arxiv.org/pdf/2505.07367", "abs": "https://arxiv.org/abs/2505.07367", "authors": ["Julian Rodemann", "James Bailie"], "title": "Generalization Bounds and Stopping Rules for Learning with Self-Selected Data", "categories": ["cs.LG", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "comment": "38 pages, 4 figures", "summary": "Many learning paradigms self-select training data in light of previously\nlearned parameters. Examples include active learning, semi-supervised learning,\nbandits, or boosting. Rodemann et al. (2024) unify them under the framework of\n\"reciprocal learning\". In this article, we address the question of how well\nthese methods can generalize from their self-selected samples. In particular,\nwe prove universal generalization bounds for reciprocal learning using covering\nnumbers and Wasserstein ambiguity sets. Our results require no assumptions on\nthe distribution of self-selected data, only verifiable conditions on the\nalgorithms. We prove results for both convergent and finite iteration\nsolutions. The latter are anytime valid, thereby giving rise to stopping rules\nfor a practitioner seeking to guarantee the out-of-sample performance of their\nreciprocal learning algorithm. Finally, we illustrate our bounds and stopping\nrules for reciprocal learning's special case of semi-supervised learning.", "AI": {"tldr": "The paper introduces universal generalization bounds for reciprocal learning, covering various paradigms like active learning and semi-supervised learning, with no assumptions on data distribution.", "motivation": "To understand how self-selected training data methods generalize, unifying paradigms like active learning under reciprocal learning.", "method": "Uses covering numbers and Wasserstein ambiguity sets to prove generalization bounds, applicable to both convergent and finite iteration solutions.", "result": "Provides anytime valid bounds, enabling stopping rules for practitioners to ensure out-of-sample performance.", "conclusion": "Demonstrates the bounds' practicality through semi-supervised learning, a special case of reciprocal learning."}}
{"id": "2505.00024", "pdf": "https://arxiv.org/pdf/2505.00024", "abs": "https://arxiv.org/abs/2505.00024", "authors": ["Shaokun Zhang", "Yi Dong", "Jieyu Zhang", "Jan Kautz", "Bryan Catanzaro", "Andrew Tao", "Qingyun Wu", "Zhiding Yu", "Guilin Liu"], "title": "Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "17 pages, 6 tables, 12 figures. - update new results - add more\n  details", "summary": "Enabling large language models with external tools has become a pivotal\nstrategy for extending their functionality beyond text space. To enhance LLMs'\ntool-calling abilities, previous approaches primarily rely on supervised\nfine-tuning (SFT) with trajectories distilled from stronger models, often\nresulting in imitative reasoning that limits generalization. In this work, we\nexplore rule-based reinforcement learning to enhance tool-calling in LLMs,\nresulting in Nemotron-Research-Tool-N1, a series of tool-calling reasoning\nmodels. Rather than enforcing supervision over intermediate distilled reasoning\ntraces, Tool-N1 is trained with a binary RL reward that assesses only the\nformat validity and functional correctness of tool invocations. This\nlightweight supervision allows the model to develop reasoning strategies\nindependently, without relying on annotated trajectories. Experiments on\nseveral major benchmarks show that Tool-N1-7B/14B clearly outperform GPT-4o. We\nconduct a systematic study on the design of rule-based reinforcement learning\nstrategies for training tool-calling models. Using 5,518 distilled reasoning\ntrajectories, we compare SFT, RL, and the SFT-then-RL pipeline, finding that\nthe widely adopted SFT-then-RL paradigm does not necessarily outperform pure\nRL.", "AI": {"tldr": "Nemotron-Research-Tool-N1 uses rule-based RL to enhance LLMs' tool-calling, outperforming GPT-4o without relying on annotated trajectories.", "motivation": "To improve LLMs' tool-calling beyond imitative reasoning from supervised fine-tuning (SFT).", "method": "Rule-based reinforcement learning with binary rewards for format validity and functional correctness.", "result": "Tool-N1-7B/14B outperforms GPT-4o on benchmarks; pure RL can surpass SFT-then-RL.", "conclusion": "Lightweight RL supervision enables independent reasoning, challenging the necessity of SFT-then-RL."}}
{"id": "2505.07611", "pdf": "https://arxiv.org/pdf/2505.07611", "abs": "https://arxiv.org/abs/2505.07611", "authors": ["Yi Zhang", "Wenye Zhou", "Ruonan Lin", "Xin Yang", "Hao Zheng"], "title": "Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A Comprehensive Review of Methods,Datasets,and Future Directions", "categories": ["cs.CV"], "comment": null, "summary": "Traffic accident prediction and detection are critical for enhancing road\nsafety,and vision-based traffic accident anticipation (Vision-TAA) has emerged\nas a promising approach in the era of deep learning.This paper reviews 147\nrecent studies,focusing on the application of supervised,unsupervised,and\nhybrid deep learning models for accident prediction,alongside the use of\nreal-world and synthetic datasets.Current methodologies are categorized into\nfour key approaches: image and video feature-based prediction, spatiotemporal\nfeature-based prediction, scene understanding,and multimodal data fusion.While\nthese methods demonstrate significant potential,challenges such as data\nscarcity,limited generalization to complex scenarios,and real-time performance\nconstraints remain prevalent. This review highlights opportunities for future\nresearch,including the integration of multimodal data fusion, self-supervised\nlearning,and Transformer-based architectures to enhance prediction accuracy and\nscalability.By synthesizing existing advancements and identifying critical\ngaps, this paper provides a foundational reference for developing robust and\nadaptive Vision-TAA systems,contributing to road safety and traffic management.", "AI": {"tldr": "A review of 147 studies on vision-based traffic accident anticipation (Vision-TAA) categorizes methods into four approaches, identifies challenges like data scarcity, and suggests future research directions.", "motivation": "To enhance road safety by reviewing advancements and gaps in Vision-TAA using deep learning models.", "method": "Categorizes current methodologies into image/video feature-based, spatiotemporal feature-based, scene understanding, and multimodal data fusion.", "result": "Identifies challenges like data scarcity and limited generalization, while highlighting potential in multimodal fusion and Transformer-based architectures.", "conclusion": "Provides a foundational reference for robust Vision-TAA systems, contributing to road safety and traffic management."}}
{"id": "2505.07339", "pdf": "https://arxiv.org/pdf/2505.07339", "abs": "https://arxiv.org/abs/2505.07339", "authors": ["Gabriel Lima", "Nina Grgi\u0107-Hla\u010da", "Markus Langer", "Yixin Zou"], "title": "Laypeople's Attitudes Towards Fair, Affirmative, and Discriminatory Decision-Making Algorithms", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Affirmative algorithms have emerged as a potential answer to algorithmic\ndiscrimination, seeking to redress past harms and rectify the source of\nhistorical injustices. We present the results of two experiments ($N$$=$$1193$)\ncapturing laypeople's perceptions of affirmative algorithms -- those which\nexplicitly prioritize the historically marginalized -- in hiring and criminal\njustice. We contrast these opinions about affirmative algorithms with folk\nattitudes towards algorithms that prioritize the privileged (i.e.,\ndiscriminatory) and systems that make decisions independently of demographic\ngroups (i.e., fair). We find that people -- regardless of their political\nleaning and identity -- view fair algorithms favorably and denounce\ndiscriminatory systems. In contrast, we identify disagreements concerning\naffirmative algorithms: liberals and racial minorities rate affirmative systems\nas positively as their fair counterparts, whereas conservatives and those from\nthe dominant racial group evaluate affirmative algorithms as negatively as\ndiscriminatory systems. We identify a source of these divisions: people have\nvarying beliefs about who (if anyone) is marginalized, shaping their views of\naffirmative algorithms. We discuss the possibility of bridging these\ndisagreements to bring people together towards affirmative algorithms.", "AI": {"tldr": "Laypeople's perceptions of affirmative algorithms in hiring and criminal justice show political and identity-based divides, with liberals and minorities supporting them, while conservatives and dominant groups oppose them.", "motivation": "To understand public attitudes toward affirmative algorithms and how they compare to perceptions of discriminatory and fair algorithms.", "method": "Two experiments (N=1193) capturing laypeople's views on affirmative, discriminatory, and fair algorithms in hiring and criminal justice.", "result": "People universally favor fair algorithms and reject discriminatory ones, but opinions on affirmative algorithms split along political and racial lines.", "conclusion": "Disagreements stem from differing beliefs about marginalization, suggesting potential for bridging divides to foster support for affirmative algorithms."}}
{"id": "2505.07411", "pdf": "https://arxiv.org/pdf/2505.07411", "abs": "https://arxiv.org/abs/2505.07411", "authors": ["Wenhao Hu", "Paul Henderson", "Jos\u00e9 Cano"], "title": "ICE-Pruning: An Iterative Cost-Efficient Pruning Pipeline for Deep Neural Networks", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "Accepted to International Joint Conference on Neural Networks (IJCNN)\n  2025", "summary": "Pruning is a widely used method for compressing Deep Neural Networks (DNNs),\nwhere less relevant parameters are removed from a DNN model to reduce its size.\nHowever, removing parameters reduces model accuracy, so pruning is typically\ncombined with fine-tuning, and sometimes other operations such as rewinding\nweights, to recover accuracy. A common approach is to repeatedly prune and then\nfine-tune, with increasing amounts of model parameters being removed in each\nstep. While straightforward to implement, pruning pipelines that follow this\napproach are computationally expensive due to the need for repeated\nfine-tuning.\n  In this paper we propose ICE-Pruning, an iterative pruning pipeline for DNNs\nthat significantly decreases the time required for pruning by reducing the\noverall cost of fine-tuning, while maintaining a similar accuracy to existing\npruning pipelines. ICE-Pruning is based on three main components: i) an\nautomatic mechanism to determine after which pruning steps fine-tuning should\nbe performed; ii) a freezing strategy for faster fine-tuning in each pruning\nstep; and iii) a custom pruning-aware learning rate scheduler to further\nimprove the accuracy of each pruning step and reduce the overall time\nconsumption. We also propose an efficient auto-tuning stage for the\nhyperparameters (e.g., freezing percentage) introduced by the three components.\nWe evaluate ICE-Pruning on several DNN models and datasets, showing that it can\naccelerate pruning by up to 9.61x. Code is available at\nhttps://github.com/gicLAB/ICE-Pruning", "AI": {"tldr": "ICE-Pruning is a novel iterative pruning pipeline for DNNs that reduces fine-tuning time while maintaining accuracy, using automatic fine-tuning triggers, freezing strategies, and a pruning-aware learning rate scheduler.", "motivation": "Existing pruning pipelines are computationally expensive due to repeated fine-tuning, prompting the need for a faster method without sacrificing accuracy.", "method": "ICE-Pruning introduces three components: automatic fine-tuning triggers, freezing strategies for faster fine-tuning, and a pruning-aware learning rate scheduler, along with hyperparameter auto-tuning.", "result": "ICE-Pruning accelerates pruning by up to 9.61x while maintaining similar accuracy to traditional methods.", "conclusion": "ICE-Pruning offers a computationally efficient alternative to traditional pruning pipelines, significantly reducing time without compromising model accuracy."}}
{"id": "2505.02656", "pdf": "https://arxiv.org/pdf/2505.02656", "abs": "https://arxiv.org/abs/2505.02656", "authors": ["Rawan Bondok", "Mayar Nassar", "Salam Khalifa", "Kurt Micallef", "Nizar Habash"], "title": "Proper Name Diacritization for Arabic Wikipedia: A Benchmark Dataset", "categories": ["cs.CL"], "comment": null, "summary": "Proper names in Arabic Wikipedia are frequently undiacritized, creating\nambiguity in pronunciation and interpretation, especially for transliterated\nnamed entities of foreign origin. While transliteration and diacritization have\nbeen well-studied separately in Arabic NLP,their intersection remains\nunderexplored. In this paper, we introduce a new manually diacritized dataset\nof Arabic proper names of various origins with their English Wikipedia\nequivalent glosses, and present the challenges and guidelines we followed to\ncreate it. We benchmark GPT-4o on the task of recovering full diacritization\ngiven the undiacritized Arabic and English forms, and analyze its performance.\nAchieving 73% accuracy, our results underscore both the difficulty of the task\nand the need for improved models and resources. We release our dataset to\nfacilitate further research on Arabic Wikipedia proper name diacritization.", "AI": {"tldr": "The paper addresses the ambiguity in Arabic Wikipedia due to undiacritized proper names, introduces a new diacritized dataset, and benchmarks GPT-4o's performance (73% accuracy) on the task.", "motivation": "Undiacritized Arabic proper names in Wikipedia cause ambiguity, especially for transliterated foreign names. The intersection of transliteration and diacritization is underexplored.", "method": "A manually diacritized dataset of Arabic proper names with English glosses is created. GPT-4o is benchmarked for recovering full diacritization from undiacritized forms.", "result": "GPT-4o achieves 73% accuracy, highlighting the task's difficulty and the need for better models.", "conclusion": "The dataset is released to aid further research on Arabic Wikipedia proper name diacritization."}}
{"id": "2505.07620", "pdf": "https://arxiv.org/pdf/2505.07620", "abs": "https://arxiv.org/abs/2505.07620", "authors": ["Simone Azeglio", "Victor Calbiague Garcia", "Guilhem Glaziou", "Peter Neri", "Olivier Marre", "Ulisse Ferrari"], "title": "Higher-Order Convolution Improves Neural Predictivity in the Retina", "categories": ["cs.CV", "cs.LG", "q-bio.NC"], "comment": null, "summary": "We present a novel approach to neural response prediction that incorporates\nhigher-order operations directly within convolutional neural networks (CNNs).\nOur model extends traditional 3D CNNs by embedding higher-order operations\nwithin the convolutional operator itself, enabling direct modeling of\nmultiplicative interactions between neighboring pixels across space and time.\nOur model increases the representational power of CNNs without increasing their\ndepth, therefore addressing the architectural disparity between deep artificial\nnetworks and the relatively shallow processing hierarchy of biological visual\nsystems. We evaluate our approach on two distinct datasets: salamander retinal\nganglion cell (RGC) responses to natural scenes, and a new dataset of mouse RGC\nresponses to controlled geometric transformations. Our higher-order CNN (HoCNN)\nachieves superior performance while requiring only half the training data\ncompared to standard architectures, demonstrating correlation coefficients up\nto 0.75 with neural responses (against 0.80$\\pm$0.02 retinal reliability). When\nintegrated into state-of-the-art architectures, our approach consistently\nimproves performance across different species and stimulus conditions. Analysis\nof the learned representations reveals that our network naturally encodes\nfundamental geometric transformations, particularly scaling parameters that\ncharacterize object expansion and contraction. This capability is especially\nrelevant for specific cell types, such as transient OFF-alpha and transient ON\ncells, which are known to detect looming objects and object motion\nrespectively, and where our model shows marked improvement in response\nprediction. The correlation coefficients for scaling parameters are more than\ntwice as high in HoCNN (0.72) compared to baseline models (0.32).", "AI": {"tldr": "A novel higher-order CNN (HoCNN) improves neural response prediction by embedding multiplicative interactions in CNNs, outperforming traditional models with less training data and better correlation with biological responses.", "motivation": "Address the disparity between deep artificial networks and shallow biological visual systems by enhancing CNN representational power without increasing depth.", "method": "Extends 3D CNNs with higher-order operations within the convolutional operator to model multiplicative interactions across space and time.", "result": "HoCNN achieves superior performance (correlation up to 0.75) with half the training data, and improves state-of-the-art architectures across species and stimuli.", "conclusion": "HoCNN naturally encodes geometric transformations, especially scaling, and excels in predicting responses for specific cell types, doubling correlation for scaling parameters."}}
{"id": "2505.07372", "pdf": "https://arxiv.org/pdf/2505.07372", "abs": "https://arxiv.org/abs/2505.07372", "authors": ["David de-Fitero-Dominguez", "Antonio Garcia-Cabot", "Eva Garcia-Lopez"], "title": "Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This paper presents a novel methodology for enhancing Automated Program\nRepair (APR) through synthetic data generation utilizing Large Language Models\n(LLMs). Current APR systems are constrained by the limited availability of\nhigh-quality training data encompassing diverse bug types across multiple\nprogramming languages. The proposed approach addresses this limitation through\na two-phase process: a synthetic sample generation followed by a rigorous\nquality assessment. Multiple state-of-the-art LLMs were employed to generate\napproximately 30,000 paired examples of buggy and fixed code across 12\nprogramming languages and 13 bug categories. Subsequently, these samples\nunderwent cross-model evaluation against five criteria: correctness, code\nquality, security, performance, and completeness. Experimental evaluation on\nthe VulRepair test set dataset showed statistically significant improvements in\nPerfect Prediction rates, with the quality-filtered synthetic dataset\noutperforming both baseline and real-world commit data configurations in\ncertain scenarios. The methodology was validated through rigorous statistical\ntesting, including ANOVA and post-hoc Tukey's Honest Significant Difference\nanalysis. Furthermore, the best-performing configurations surpassed existing\nsystems despite using a less computationally intensive decoding strategy. This\nresearch establishes a self-bootstrapping paradigm in which LLMs generate and\nevaluate their own training data, potentially transforming approaches to data\nscarcity across software engineering tasks and advancing the development of\nrobust, adaptable tools for automated code maintenance.", "AI": {"tldr": "A novel method enhances Automated Program Repair (APR) using LLMs to generate synthetic data, improving repair rates and outperforming baselines.", "motivation": "Addresses the scarcity of diverse, high-quality training data for APR systems.", "method": "Two-phase: synthetic data generation by LLMs and quality assessment. Generated 30,000 bug-fix pairs across 12 languages and 13 bug types, evaluated on five criteria.", "result": "Statistically significant improvements in Perfect Prediction rates; synthetic data outperformed baselines and real-world data in some cases.", "conclusion": "Establishes a self-bootstrapping paradigm for APR, advancing robust tools for automated code maintenance."}}
{"id": "2505.07413", "pdf": "https://arxiv.org/pdf/2505.07413", "abs": "https://arxiv.org/abs/2505.07413", "authors": ["Tung L Nguyen", "Toby Hocking"], "title": "Learning Penalty for Optimal Partitioning via Automatic Feature Extraction", "categories": ["cs.LG", "stat.AP"], "comment": "9 Figures", "summary": "Changepoint detection identifies significant shifts in data sequences, making\nit important in areas like finance, genetics, and healthcare. The Optimal\nPartitioning algorithms efficiently detect these changes, using a penalty\nparameter to limit the changepoints number. Determining the appropriate value\nfor this penalty can be challenging. Traditionally, this process involved\nmanually extracting statistical features, such as sequence length or variance\nto make the prediction. This study proposes a novel approach that uses\nrecurrent neural networks to learn this penalty directly from raw sequences by\nautomatically extracting features. Experiments conducted on 20 benchmark\ngenomic datasets show that this novel method surpasses traditional methods in\npartitioning accuracy in most cases.", "AI": {"tldr": "A novel method using recurrent neural networks to learn penalty parameters for changepoint detection outperforms traditional manual feature extraction on genomic datasets.", "motivation": "The challenge of determining the appropriate penalty parameter for changepoint detection in sequences, traditionally done manually, motivates the need for an automated and more accurate approach.", "method": "The study employs recurrent neural networks to automatically learn the penalty parameter from raw sequences, eliminating manual feature extraction.", "result": "Experiments on 20 genomic datasets show the proposed method achieves higher partitioning accuracy than traditional methods.", "conclusion": "The novel approach of using neural networks for penalty parameter learning improves changepoint detection accuracy, offering a promising alternative to manual methods."}}
{"id": "2310.14356", "pdf": "https://arxiv.org/pdf/2310.14356", "abs": "https://arxiv.org/abs/2310.14356", "authors": ["Andre Ye", "Sebastin Santy", "Jena D. Hwang", "Amy X. Zhang", "Ranjay Krishna"], "title": "Semantic and Expressive Variation in Image Captions Across Languages", "categories": ["cs.CV", "cs.CL", "cs.CY", "cs.HC"], "comment": "CVPR 2025", "summary": "Computer vision often treats human perception as homogeneous: an implicit\nassumption that visual stimuli are perceived similarly by everyone. This\nassumption is reflected in the way researchers collect datasets and train\nvision models. By contrast, literature in cross-cultural psychology and\nlinguistics has provided evidence that people from different cultural\nbackgrounds observe vastly different concepts even when viewing the same visual\nstimuli. In this paper, we study how these differences manifest themselves in\nvision-language datasets and models, using language as a proxy for culture. By\ncomparing textual descriptions generated across 7 languages for the same\nimages, we find significant differences in the semantic content and linguistic\nexpression. When datasets are multilingual as opposed to monolingual,\ndescriptions have higher semantic coverage on average, where coverage is\nmeasured using scene graphs, model embeddings, and linguistic taxonomies. For\nexample, multilingual descriptions have on average 29.9% more objects, 24.5%\nmore relations, and 46.0% more attributes than a set of monolingual captions.\nWhen prompted to describe images in different languages, popular models (e.g.\nLLaVA) inherit this bias and describe different parts of the image. Moreover,\nfinetuning models on captions from one language performs best on corresponding\ntest data from that language, while finetuning on multilingual data performs\nconsistently well across all test data compositions. Our work points towards\nthe need to account for and embrace the diversity of human perception in the\ncomputer vision community.", "AI": {"tldr": "The paper highlights cultural differences in human perception of visual stimuli, using language as a proxy, and shows how multilingual datasets improve semantic coverage in vision-language models.", "motivation": "To challenge the homogeneous perception assumption in computer vision by demonstrating cultural diversity in visual interpretation through language.", "method": "Analyzed textual descriptions of the same images across 7 languages, measuring semantic coverage via scene graphs, embeddings, and taxonomies.", "result": "Multilingual descriptions had 29.9% more objects, 24.5% more relations, and 46.0% more attributes than monolingual ones. Models like LLaVA inherited this bias.", "conclusion": "Embracing human perception diversity is crucial for computer vision, with multilingual datasets enhancing model performance across languages."}}
{"id": "2505.07622", "pdf": "https://arxiv.org/pdf/2505.07622", "abs": "https://arxiv.org/abs/2505.07622", "authors": ["Zhuo Song", "Ye Zhang", "Kunhong Li", "Longguang Wang", "Yulan Guo"], "title": "A Unified Hierarchical Framework for Fine-grained Cross-view Geo-localization over Large-scale Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "Cross-view geo-localization is a promising solution for large-scale\nlocalization problems, requiring the sequential execution of retrieval and\nmetric localization tasks to achieve fine-grained predictions. However,\nexisting methods typically focus on designing standalone models for these two\ntasks, resulting in inefficient collaboration and increased training overhead.\nIn this paper, we propose UnifyGeo, a novel unified hierarchical\ngeo-localization framework that integrates retrieval and metric localization\ntasks into a single network. Specifically, we first employ a unified learning\nstrategy with shared parameters to jointly learn multi-granularity\nrepresentation, facilitating mutual reinforcement between these two tasks.\nSubsequently, we design a re-ranking mechanism guided by a dedicated loss\nfunction, which enhances geo-localization performance by improving both\nretrieval accuracy and metric localization references. Extensive experiments\ndemonstrate that UnifyGeo significantly outperforms the state-of-the-arts in\nboth task-isolated and task-associated settings. Remarkably, on the challenging\nVIGOR benchmark, which supports fine-grained localization evaluation, the\n1-meter-level localization recall rate improves from 1.53\\% to 39.64\\% and from\n0.43\\% to 25.58\\% under same-area and cross-area evaluations, respectively.\nCode will be made publicly available.", "AI": {"tldr": "UnifyGeo is a unified hierarchical framework for cross-view geo-localization, combining retrieval and metric localization tasks into one network for improved efficiency and performance.", "motivation": "Existing methods treat retrieval and metric localization as separate tasks, leading to inefficiency and higher training overhead. UnifyGeo aims to unify these tasks for better collaboration.", "method": "The framework uses a unified learning strategy with shared parameters for multi-granularity representation and a re-ranking mechanism with a dedicated loss function.", "result": "UnifyGeo outperforms state-of-the-art methods, significantly improving 1-meter-level localization recall rates on the VIGOR benchmark.", "conclusion": "UnifyGeo demonstrates the effectiveness of unifying retrieval and metric localization tasks, achieving superior performance and efficiency."}}
{"id": "2505.07377", "pdf": "https://arxiv.org/pdf/2505.07377", "abs": "https://arxiv.org/abs/2505.07377", "authors": ["Suleyman Ozdel", "Can Sarpkaya", "Efe Bozkir", "Hong Gao", "Enkelejda Kasneci"], "title": "Examining the Role of LLM-Driven Interactions on Attention and Cognitive Engagement in Virtual Classrooms", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted to EDM 2025 (Eighteenth International Conference on\n  Educational Data Mining)", "summary": "Transforming educational technologies through the integration of large\nlanguage models (LLMs) and virtual reality (VR) offers the potential for\nimmersive and interactive learning experiences. However, the effects of LLMs on\nuser engagement and attention in educational environments remain open\nquestions. In this study, we utilized a fully LLM-driven virtual learning\nenvironment, where peers and teachers were LLM-driven, to examine how students\nbehaved in such settings. Specifically, we investigate how peer question-asking\nbehaviors influenced student engagement, attention, cognitive load, and\nlearning outcomes and found that, in conditions where LLM-driven peer learners\nasked questions, students exhibited more targeted visual scanpaths, with their\nattention directed toward the learning content, particularly in complex\nsubjects. Our results suggest that peer questions did not introduce extraneous\ncognitive load directly, as the cognitive load is strongly correlated with\nincreased attention to the learning material. Considering these findings, we\nprovide design recommendations for optimizing VR learning spaces.", "AI": {"tldr": "The study explores how LLM-driven peer questions in VR learning environments affect student engagement, attention, and learning outcomes, finding improved focus without added cognitive load.", "motivation": "To understand the impact of LLM-driven interactions in VR educational settings on student behavior and learning.", "method": "Used a fully LLM-driven virtual learning environment with LLM peers and teachers, analyzing student engagement, attention, and cognitive load.", "result": "Peer questions improved student focus on learning content, especially in complex subjects, without increasing extraneous cognitive load.", "conclusion": "Design recommendations for VR learning spaces should leverage LLM-driven peer interactions to enhance engagement and attention."}}
{"id": "2505.07437", "pdf": "https://arxiv.org/pdf/2505.07437", "abs": "https://arxiv.org/abs/2505.07437", "authors": ["Xiaotian Lin", "Yanlin Qi", "Yizhang Zhu", "Themis Palpanas", "Chengliang Chai", "Nan Tang", "Yuyu Luo"], "title": "LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": null, "summary": "Instruction tuning has emerged as a critical paradigm for improving the\ncapabilities and alignment of large language models (LLMs). However, existing\niterative model-aware data selection methods incur significant computational\noverhead, as they rely on repeatedly performing full-dataset model inference to\nestimate sample utility for subsequent training iterations, creating a\nfundamental efficiency bottleneck. In this paper, we propose LEAD, an efficient\niterative data selection framework that accurately estimates sample utility\nentirely within the standard training loop, eliminating the need for costly\nadditional model inference. At its core, LEAD introduces Instance-Level Dynamic\nUncertainty (IDU), a theoretically grounded utility function combining\ninstantaneous training loss, gradient-based approximation of loss changes, and\nexponential smoothing of historical loss signals. To further scale efficiently\nto large datasets, LEAD employs a two-stage, coarse-to-fine selection strategy,\nadaptively prioritizing informative clusters through a multi-armed bandit\nmechanism, followed by precise fine-grained selection of high-utility samples\nusing IDU. Extensive experiments across four diverse benchmarks show that LEAD\nsignificantly outperforms state-of-the-art methods, improving average model\nperformance by 6.1%-10.8% while using only 2.5% of the training data and\nreducing overall training time by 5-10x.", "AI": {"tldr": "LEAD is an efficient iterative data selection framework for instruction tuning, eliminating costly model inference by using Instance-Level Dynamic Uncertainty (IDU) and a two-stage selection strategy. It improves model performance and reduces training time.", "motivation": "Existing iterative data selection methods for LLMs are computationally expensive due to repeated full-dataset model inference, creating efficiency bottlenecks.", "method": "LEAD introduces IDU, combining training loss, gradient-based loss change approximation, and historical loss smoothing. It uses a two-stage coarse-to-fine selection strategy with a multi-armed bandit mechanism.", "result": "LEAD outperforms state-of-the-art methods, improving model performance by 6.1%-10.8% with only 2.5% of training data and reducing training time by 5-10x.", "conclusion": "LEAD offers a computationally efficient and effective solution for iterative data selection in instruction tuning, enhancing LLM performance and scalability."}}
{"id": "2311.11796", "pdf": "https://arxiv.org/pdf/2311.11796", "abs": "https://arxiv.org/abs/2311.11796", "authors": ["Guangjing Wang", "Ce Zhou", "Yuanda Wang", "Bocheng Chen", "Hanqing Guo", "Qiben Yan"], "title": "Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "As Artificial Intelligence (AI) systems increasingly underpin critical\napplications, from autonomous vehicles to biometric authentication, their\nvulnerability to transferable attacks presents a growing concern. These\nattacks, designed to generalize across instances, domains, models, tasks,\nmodalities, or even hardware platforms, pose severe risks to security, privacy,\nand system integrity. This survey delivers the first comprehensive review of\ntransferable attacks across seven major categories, including evasion,\nbackdoor, data poisoning, model stealing, model inversion, membership\ninference, and side-channel attacks. We introduce a unified six-dimensional\ntaxonomy: cross-instance, cross-domain, cross-modality, cross-model,\ncross-task, and cross-hardware, which systematically captures the diverse\ntransfer pathways of adversarial strategies. Through this framework, we examine\nboth the underlying mechanics and practical implications of transferable\nattacks on AI systems. Furthermore, we review cutting-edge methods for\nenhancing attack transferability, organized around data augmentation and\noptimization strategies. By consolidating fragmented research and identifying\ncritical future directions, this work provides a foundational roadmap for\nunderstanding, evaluating, and defending against transferable threats in\nreal-world AI systems.", "AI": {"tldr": "This survey reviews transferable attacks in AI, categorizing them into seven types and introducing a six-dimensional taxonomy to analyze their pathways. It also explores methods to enhance attack transferability and suggests future research directions.", "motivation": "The increasing reliance on AI in critical applications raises concerns about their vulnerability to transferable attacks, which threaten security, privacy, and system integrity.", "method": "The paper conducts a comprehensive review of transferable attacks, categorizing them into seven major types and proposing a unified six-dimensional taxonomy. It also examines methods to enhance attack transferability.", "result": "The survey provides a systematic framework for understanding transferable attacks, their mechanics, and practical implications, along with strategies to mitigate them.", "conclusion": "This work serves as a foundational roadmap for addressing transferable threats in AI systems, highlighting the need for further research and defense mechanisms."}}
{"id": "2505.07652", "pdf": "https://arxiv.org/pdf/2505.07652", "abs": "https://arxiv.org/abs/2505.07652", "authors": ["Ozgur Kara", "Krishna Kumar Singh", "Feng Liu", "Duygu Ceylan", "James M. Rehg", "Tobias Hinz"], "title": "ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Current diffusion-based text-to-video methods are limited to producing short\nvideo clips of a single shot and lack the capability to generate multi-shot\nvideos with discrete transitions where the same character performs distinct\nactivities across the same or different backgrounds. To address this limitation\nwe propose a framework that includes a dataset collection pipeline and\narchitectural extensions to video diffusion models to enable text-to-multi-shot\nvideo generation. Our approach enables generation of multi-shot videos as a\nsingle video with full attention across all frames of all shots, ensuring\ncharacter and background consistency, and allows users to control the number,\nduration, and content of shots through shot-specific conditioning. This is\nachieved by incorporating a transition token into the text-to-video model to\ncontrol at which frames a new shot begins and a local attention masking\nstrategy which controls the transition token's effect and allows shot-specific\nprompting. To obtain training data we propose a novel data collection pipeline\nto construct a multi-shot video dataset from existing single-shot video\ndatasets. Extensive experiments demonstrate that fine-tuning a pre-trained\ntext-to-video model for a few thousand iterations is enough for the model to\nsubsequently be able to generate multi-shot videos with shot-specific control,\noutperforming the baselines. You can find more details in\nhttps://shotadapter.github.io/", "AI": {"tldr": "A framework for generating multi-shot videos with discrete transitions using diffusion models, addressing limitations of current text-to-video methods.", "motivation": "Current text-to-video methods can't produce multi-shot videos with consistent characters and backgrounds.", "method": "Proposes a framework with dataset collection and architectural extensions, including transition tokens and local attention masking.", "result": "Enables multi-shot video generation with shot-specific control, outperforming baselines after minimal fine-tuning.", "conclusion": "The approach successfully extends text-to-video models for multi-shot generation with user control."}}
{"id": "2505.07393", "pdf": "https://arxiv.org/pdf/2505.07393", "abs": "https://arxiv.org/abs/2505.07393", "authors": ["Nadine Sandjo Tchatchoua", "Richard Harper"], "title": "AI in Money Matters", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "In November 2022, Europe and the world by and large were stunned by the birth\nof a new large language model : ChatGPT. Ever since then, both academic and\npopulist discussions have taken place in various public spheres such as\nLinkedIn and X(formerly known as Twitter) with the view to both understand the\ntool and its benefits for the society. The views of real actors in professional\nspaces, especially in regulated industries such as finance and law have been\nlargely missing. We aim to begin to close this gap by presenting results from\nan empirical investigation conducted through interviews with professional\nactors in the Fintech industry. The paper asks the question, how and to what\nextent are large language models in general and ChatGPT in particular being\nadopted and used in the Fintech industry? The results show that while the\nfintech experts we spoke with see a potential in using large language models in\nthe future, a lot of questions marks remain concerning how they are policed and\ntherefore might be adopted in a regulated industry such as Fintech. This paper\naims to add to the existing academic discussing around large language models,\nwith a contribution to our understanding of professional viewpoints.", "AI": {"tldr": "The paper explores the adoption and use of large language models like ChatGPT in the Fintech industry, highlighting professional viewpoints and regulatory concerns.", "motivation": "To address the lack of professional perspectives on large language models in regulated industries like Fintech.", "method": "Empirical investigation through interviews with Fintech professionals.", "result": "Fintech experts see potential in large language models but have concerns about regulation and adoption.", "conclusion": "The study contributes to academic discussions by providing professional insights into the use of large language models in regulated industries."}}
{"id": "2505.07447", "pdf": "https://arxiv.org/pdf/2505.07447", "abs": "https://arxiv.org/abs/2505.07447", "authors": ["Peng Sun", "Yi Jiang", "Tao Lin"], "title": "Unified Continuous Generative Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "https://github.com/LINs-lab/UCGM", "summary": "Recent advances in continuous generative models, including multi-step\napproaches like diffusion and flow-matching (typically requiring 8-1000\nsampling steps) and few-step methods such as consistency models (typically 1-8\nsteps), have demonstrated impressive generative performance. However, existing\nwork often treats these approaches as distinct paradigms, resulting in separate\ntraining and sampling methodologies. We introduce a unified framework for\ntraining, sampling, and analyzing these models. Our implementation, the Unified\nContinuous Generative Models Trainer and Sampler (UCGM-{T,S}), achieves\nstate-of-the-art (SOTA) performance. For example, on ImageNet 256x256 using a\n675M diffusion transformer, UCGM-T trains a multi-step model achieving 1.30 FID\nin 20 steps and a few-step model reaching 1.42 FID in just 2 steps.\nAdditionally, applying UCGM-S to a pre-trained model (previously 1.26 FID at\n250 steps) improves performance to 1.06 FID in only 40 steps. Code is available\nat: https://github.com/LINs-lab/UCGM.", "AI": {"tldr": "A unified framework (UCGM) for training and sampling continuous generative models achieves SOTA performance, improving efficiency and results for both multi-step and few-step methods.", "motivation": "Existing work treats multi-step and few-step generative models as separate paradigms, leading to fragmented methodologies.", "method": "Introduces UCGM, a unified framework for training, sampling, and analyzing continuous generative models.", "result": "UCGM achieves 1.30 FID in 20 steps (multi-step) and 1.42 FID in 2 steps (few-step) on ImageNet 256x256. Pre-trained model performance improves from 1.26 FID (250 steps) to 1.06 FID (40 steps).", "conclusion": "UCGM unifies and optimizes generative model training and sampling, demonstrating superior performance and efficiency."}}
{"id": "2403.16971", "pdf": "https://arxiv.org/pdf/2403.16971", "abs": "https://arxiv.org/abs/2403.16971", "authors": ["Kai Mei", "Xi Zhu", "Wujiang Xu", "Wenyue Hua", "Mingyu Jin", "Zelong Li", "Shuyuan Xu", "Ruosong Ye", "Yingqiang Ge", "Yongfeng Zhang"], "title": "AIOS: LLM Agent Operating System", "categories": ["cs.OS", "cs.AI", "cs.CL"], "comment": null, "summary": "LLM-based intelligent agents face significant deployment challenges,\nparticularly related to resource management. Allowing unrestricted access to\nLLM or tool resources can lead to inefficient or even potentially harmful\nresource allocation and utilization for agents. Furthermore, the absence of\nproper scheduling and resource management mechanisms in current agent designs\nhinders concurrent processing and limits overall system efficiency. As the\ndiversity and complexity of agents continue to grow, addressing these resource\nmanagement issues becomes increasingly critical to LLM-based agent systems. To\naddress these challenges, this paper proposes the architecture of AIOS\n(LLM-based AI Agent Operating System) under the context of managing LLM-based\nagents. It introduces a novel architecture for serving LLM-based agents by\nisolating resources and LLM-specific services from agent applications into an\nAIOS kernel. This AIOS kernel provides fundamental services (e.g., scheduling,\ncontext management, memory management, storage management, access control) and\nefficient management of resources (e.g., LLM and external tools) for runtime\nagents. To enhance usability, AIOS also includes an AIOS-Agent SDK, a\ncomprehensive suite of APIs designed for utilizing functionalities provided by\nthe AIOS kernel. Experimental results demonstrate that using AIOS can achieve\nup to 2.1x faster execution for serving agents built by various agent\nframeworks. The source code is available at\nhttps://github.com/agiresearch/AIOS.", "AI": {"tldr": "The paper proposes AIOS, an operating system for LLM-based agents, to improve resource management and efficiency, achieving up to 2.1x faster execution.", "motivation": "Current LLM-based agents lack proper resource management, leading to inefficiency and potential harm. Addressing this is critical as agent complexity grows.", "method": "Introduces AIOS, an architecture isolating resources and LLM services into a kernel, offering scheduling, memory management, and APIs via AIOS-Agent SDK.", "result": "AIOS improves efficiency, with experiments showing up to 2.1x faster execution for agent frameworks.", "conclusion": "AIOS effectively addresses resource management challenges in LLM-based agents, enhancing performance and usability."}}
{"id": "2505.07689", "pdf": "https://arxiv.org/pdf/2505.07689", "abs": "https://arxiv.org/abs/2505.07689", "authors": ["Quang Vinh Nguyen", "Minh Duc Nguyen", "Thanh Hoang Son Vo", "Hyung-Jeong Yang", "Soo-Hyung Kim"], "title": "Anatomical Attention Alignment representation for Radiology Report Generation", "categories": ["cs.CV"], "comment": null, "summary": "Automated Radiology report generation (RRG) aims at producing detailed\ndescriptions of medical images, reducing radiologists' workload and improving\naccess to high-quality diagnostic services. Existing encoder-decoder models\nonly rely on visual features extracted from raw input images, which can limit\nthe understanding of spatial structures and semantic relationships, often\nresulting in suboptimal text generation. To address this, we propose Anatomical\nAttention Alignment Network (A3Net), a framework that enhance visual-textual\nunderstanding by constructing hyper-visual representations. Our approach\nintegrates a knowledge dictionary of anatomical structures with patch-level\nvisual features, enabling the model to effectively associate image regions with\ntheir corresponding anatomical entities. This structured representation\nimproves semantic reasoning, interpretability, and cross-modal alignment,\nultimately enhancing the accuracy and clinical relevance of generated reports.\nExperimental results on IU X-Ray and MIMIC-CXR datasets demonstrate that A3Net\nsignificantly improves both visual perception and text generation quality. Our\ncode is available at \\href{https://github.com/Vinh-AI/A3Net}{GitHub}.", "AI": {"tldr": "A3Net improves radiology report generation by integrating anatomical knowledge with visual features, enhancing accuracy and clinical relevance.", "motivation": "Existing models rely solely on visual features, limiting understanding of spatial and semantic relationships, leading to suboptimal reports.", "method": "Proposes A3Net, which combines a knowledge dictionary of anatomical structures with patch-level visual features for better cross-modal alignment.", "result": "A3Net outperforms on IU X-Ray and MIMIC-CXR datasets, improving visual perception and text generation quality.", "conclusion": "A3Net enhances radiology report generation by aligning anatomical knowledge with visual features, yielding more accurate and clinically relevant reports."}}
{"id": "2505.07450", "pdf": "https://arxiv.org/pdf/2505.07450", "abs": "https://arxiv.org/abs/2505.07450", "authors": ["Neil De La Fuente", "Maria Pilligua", "Daniel Vidal", "Albin Soutiff", "Cecilia Curreli", "Daniel Cremers", "Andrey Barsky"], "title": "Prototype Augmented Hypernetworks for Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "CVPR (LatinX in CV)", "summary": "Continual learning (CL) aims to learn a sequence of tasks without forgetting\nprior knowledge, but gradient updates for a new task often overwrite the\nweights learned earlier, causing catastrophic forgetting (CF). We propose\nPrototype-Augmented Hypernetworks (PAH), a framework where a single\nhypernetwork, conditioned on learnable task prototypes, dynamically generates\ntask-specific classifier heads on demand. To mitigate forgetting, PAH combines\ncross-entropy with dual distillation losses, one to align logits and another to\nalign prototypes, ensuring stable feature representations across tasks.\nEvaluations on Split-CIFAR100 and TinyImageNet demonstrate that PAH achieves\nstate-of-the-art performance, reaching 74.5 % and 63.7 % accuracy with only 1.7\n% and 4.4 % forgetting, respectively, surpassing prior methods without storing\nsamples or heads.", "AI": {"tldr": "PAH is a framework using hypernetworks and task prototypes to prevent catastrophic forgetting in continual learning, achieving high accuracy with minimal forgetting.", "motivation": "Address catastrophic forgetting in continual learning by dynamically generating task-specific classifiers and stabilizing feature representations.", "method": "Uses Prototype-Augmented Hypernetworks (PAH) with cross-entropy and dual distillation losses (logit and prototype alignment).", "result": "Achieves 74.5% and 63.7% accuracy on Split-CIFAR100 and TinyImageNet with only 1.7% and 4.4% forgetting, respectively.", "conclusion": "PAH outperforms prior methods without needing stored samples or heads, demonstrating effective continual learning."}}
{"id": "2505.07477", "pdf": "https://arxiv.org/pdf/2505.07477", "abs": "https://arxiv.org/abs/2505.07477", "authors": ["Hongkun Dou", "Zeyu Li", "Xingyu Jiang", "Hongjue Li", "Lijun Yang", "Wen Yao", "Yue Deng"], "title": "You Only Look One Step: Accelerating Backpropagation in Diffusion Sampling with Gradient Shortcuts", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Diffusion models (DMs) have recently demonstrated remarkable success in\nmodeling large-scale data distributions. However, many downstream tasks require\nguiding the generated content based on specific differentiable metrics,\ntypically necessitating backpropagation during the generation process. This\napproach is computationally expensive, as generating with DMs often demands\ntens to hundreds of recursive network calls, resulting in high memory usage and\nsignificant time consumption. In this paper, we propose a more efficient\nalternative that approaches the problem from the perspective of parallel\ndenoising. We show that full backpropagation throughout the entire generation\nprocess is unnecessary. The downstream metrics can be optimized by retaining\nthe computational graph of only one step during generation, thus providing a\nshortcut for gradient propagation. The resulting method, which we call Shortcut\nDiffusion Optimization (SDO), is generic, high-performance, and computationally\nlightweight, capable of optimizing all parameter types in diffusion sampling.\nWe demonstrate the effectiveness of SDO on several real-world tasks, including\ncontrolling generation by optimizing latent and aligning the DMs by fine-tuning\nnetwork parameters. Compared to full backpropagation, our approach reduces\ncomputational costs by $\\sim 90\\%$ while maintaining superior performance. Code\nis available at https://github.com/deng-ai-lab/SDO.", "AI": {"tldr": "The paper introduces Shortcut Diffusion Optimization (SDO), a method to efficiently guide diffusion models using differentiable metrics without full backpropagation, reducing computational costs by ~90%.", "motivation": "Downstream tasks often require guiding generated content with differentiable metrics, but full backpropagation during generation is computationally expensive.", "method": "SDO optimizes metrics by retaining the computational graph of only one step during generation, avoiding full backpropagation.", "result": "SDO reduces computational costs by ~90% while maintaining performance, demonstrated on tasks like latent optimization and network fine-tuning.", "conclusion": "SDO is a lightweight, high-performance alternative to full backpropagation for optimizing diffusion models."}}
{"id": "2405.15189", "pdf": "https://arxiv.org/pdf/2405.15189", "abs": "https://arxiv.org/abs/2405.15189", "authors": ["Dong Huang", "Jianbo Dai", "Han Weng", "Puzhen Wu", "Yuhao Qing", "Heming Cui", "Zhijiang Guo", "Jie M. Zhang"], "title": "EffiLearner: Enhancing Efficiency of Generated Code via Self-Optimization", "categories": ["cs.SE", "cs.CL"], "comment": "Accepted by NeurIPS 2024", "summary": "Large language models (LLMs) have shown remarkable progress in code\ngeneration, but their generated code often suffers from inefficiency, resulting\nin longer execution times and higher memory consumption. To address this issue,\nwe propose \\textbf{EffiLearner}, a self-optimization framework that utilizes\nexecution overhead profiles to improve the efficiency of LLM-generated code.\nEffiLearner first generates code using an LLM, then executes it locally to\ncapture execution time and memory usage profiles. These profiles are fed back\nto the LLM, which then revises the code to reduce overhead. To evaluate the\neffectiveness of EffiLearner, we conduct extensive experiments on the\nEffiBench, HumanEval, and MBPP with 16 open-source and 6 closed-source models.\nOur evaluation results demonstrate that through iterative self-optimization,\nEffiLearner significantly enhances the efficiency of LLM-generated code. For\nexample, the execution time (ET) of StarCoder2-15B for the EffiBench decreases\nfrom 0.93 (s) to 0.12 (s) which reduces 87.1% the execution time requirement\ncompared with the initial code. The total memory usage (TMU) of StarCoder2-15B\nalso decreases from 22.02 (Mb*s) to 2.03 (Mb*s), which decreases 90.8% of total\nmemory consumption during the execution process. The source code of EffiLearner\nwas released in https://github.com/huangd1999/EffiLearner", "AI": {"tldr": "EffiLearner is a self-optimization framework that improves the efficiency of LLM-generated code by using execution profiles to iteratively refine code, reducing execution time and memory usage.", "motivation": "LLM-generated code often suffers from inefficiency, leading to longer execution times and higher memory consumption. EffiLearner aims to address this issue.", "method": "EffiLearner generates code with an LLM, profiles execution time and memory usage, and iteratively refines the code based on feedback.", "result": "EffiLearner reduces execution time by 87.1% and memory usage by 90.8% for StarCoder2-15B on EffiBench.", "conclusion": "EffiLearner significantly enhances the efficiency of LLM-generated code through iterative self-optimization."}}
{"id": "2505.07690", "pdf": "https://arxiv.org/pdf/2505.07690", "abs": "https://arxiv.org/abs/2505.07690", "authors": ["Songlin Dong", "Chenhao Ding", "Jiangyang Li", "Jizhou Han", "Qiang Wang", "Yuhang He", "Yihong Gong"], "title": "Beyond CLIP Generalization: Against Forward&Backward Forgetting Adapter for Continual Learning of Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "This study aims to address the problem of multi-domain task incremental\nlearning~(MTIL), which requires that vision-language models~(VLMs) continuously\nacquire new knowledge while maintaining their inherent zero-shot recognition\ncapability. Existing paradigms delegate the testing of unseen-domain samples to\nthe original CLIP, which only prevents the degradation of the model's zero-shot\ncapability but fails to enhance the generalization of the VLM further. To this\nend, we propose a novel MTIL framework, named AFA, which comprises two core\nmodules: (1) an against forward-forgetting adapter that learns task-invariant\ninformation for each dataset in the incremental tasks to enhance the zero-shot\nrecognition ability of VLMs; (2) an against backward-forgetting adapter that\nstrengthens the few-shot learning capability of VLMs while supporting\nincremental learning. Extensive experiments demonstrate that the AFA method\nsignificantly outperforms existing state-of-the-art approaches, especially in\nfew-shot MTIL tasks, and surpasses the inherent zero-shot performance of CLIP\nin terms of transferability. The code is provided in the Supplementary\nMaterial.", "AI": {"tldr": "The paper proposes AFA, a novel framework for multi-domain task incremental learning (MTIL) in vision-language models (VLMs), enhancing zero-shot and few-shot capabilities while outperforming existing methods.", "motivation": "Address the limitation of current MTIL paradigms that fail to enhance VLM generalization beyond maintaining zero-shot recognition, aiming to improve both zero-shot and few-shot learning.", "method": "Introduces AFA with two adapters: (1) against forward-forgetting for task-invariant learning to boost zero-shot recognition, and (2) against backward-forgetting to strengthen few-shot learning during incremental tasks.", "result": "AFA outperforms state-of-the-art methods, especially in few-shot MTIL tasks, and exceeds CLIP's zero-shot transferability.", "conclusion": "The AFA framework effectively enhances VLMs' incremental learning capabilities, improving both zero-shot and few-shot performance."}}
{"id": "2505.07457", "pdf": "https://arxiv.org/pdf/2505.07457", "abs": "https://arxiv.org/abs/2505.07457", "authors": ["R. Maria del Rio-Chanona", "Marco Pangallo", "Cars Hommes"], "title": "Can Generative AI agents behave like humans? Evidence from laboratory market experiments", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "comment": null, "summary": "We explore the potential of Large Language Models (LLMs) to replicate human\nbehavior in economic market experiments. Compared to previous studies, we focus\non dynamic feedback between LLM agents: the decisions of each LLM impact the\nmarket price at the current step, and so affect the decisions of the other LLMs\nat the next step. We compare LLM behavior to market dynamics observed in\nlaboratory settings and assess their alignment with human participants'\nbehavior. Our findings indicate that LLMs do not adhere strictly to rational\nexpectations, displaying instead bounded rationality, similarly to human\nparticipants. Providing a minimal context window i.e. memory of three previous\ntime steps, combined with a high variability setting capturing response\nheterogeneity, allows LLMs to replicate broad trends seen in human experiments,\nsuch as the distinction between positive and negative feedback markets.\nHowever, differences remain at a granular level--LLMs exhibit less\nheterogeneity in behavior than humans. These results suggest that LLMs hold\npromise as tools for simulating realistic human behavior in economic contexts,\nthough further research is needed to refine their accuracy and increase\nbehavioral diversity.", "AI": {"tldr": "LLMs simulate human-like bounded rationality in economic markets but lack behavioral diversity compared to humans.", "motivation": "To assess if LLMs can replicate human behavior in dynamic economic market experiments with feedback loops.", "method": "Compare LLM behavior to human lab data, using dynamic feedback and a minimal context window (memory of three steps).", "result": "LLMs show bounded rationality and replicate broad human trends but exhibit less heterogeneity.", "conclusion": "LLMs are promising for simulating human behavior in economics but need refinement for accuracy and diversity."}}
{"id": "2505.07503", "pdf": "https://arxiv.org/pdf/2505.07503", "abs": "https://arxiv.org/abs/2505.07503", "authors": ["Quang-Duy Tran", "Bao Duong", "Phuoc Nguyen", "Thin Nguyen"], "title": "Identifying Causal Direction via Variational Bayesian Compression", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at the 42nd International Conference on Machine Learning\n  (ICML2025)", "summary": "Telling apart the cause and effect between two random variables with purely\nobservational data is a challenging problem that finds applications in various\nscientific disciplines. A key principle utilized in this task is the\nalgorithmic Markov condition, which postulates that the joint distribution,\nwhen factorized according to the causal direction, yields a more succinct\ncodelength compared to the anti-causal direction. Previous approaches\napproximate these codelengths by relying on simple functions or Gaussian\nprocesses (GPs) with easily evaluable complexity, compromising between model\nfitness and computational complexity. To overcome these limitations, we propose\nleveraging the variational Bayesian learning of neural networks as an\ninterpretation of the codelengths. Consequently, we can enhance the model\nfitness while promoting the succinctness of the codelengths, while avoiding the\nsignificant computational complexity of the GP-based approaches. Extensive\nexperiments on both synthetic and real-world benchmarks in cause-effect\nidentification demonstrate the effectiveness of our proposed method, surpassing\nthe overall performance of related complexity-based and structural causal model\nregression-based approaches.", "AI": {"tldr": "The paper proposes using variational Bayesian learning of neural networks to improve cause-effect identification by enhancing model fitness and codelength succinctness, outperforming existing methods.", "motivation": "Addressing the challenge of distinguishing cause and effect from observational data, leveraging the algorithmic Markov condition for better codelength approximation.", "method": "Uses variational Bayesian learning of neural networks to interpret codelengths, improving fitness and succinctness without high computational complexity.", "result": "Outperforms complexity-based and structural causal model regression-based approaches in synthetic and real-world benchmarks.", "conclusion": "The proposed method effectively enhances cause-effect identification by balancing model fitness and computational efficiency."}}
{"id": "2406.06620", "pdf": "https://arxiv.org/pdf/2406.06620", "abs": "https://arxiv.org/abs/2406.06620", "authors": ["Jiexia Ye", "Weiqi Zhang", "Ziyue Li", "Jia Li", "Meng Zhao", "Fugee Tsung"], "title": "MedualTime: A Dual-Adapter Language Model for Medical Time Series-Text Multimodal Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "9 pages, 6 figure, 3 tables", "summary": "The recent rapid advancements in language models (LMs) have garnered\nattention in medical time series-text multimodal learning. However, existing\ncontrastive learning-based and prompt-based LM approaches tend to be biased,\noften assigning a primary role to time series modality while treating text\nmodality as secondary. We classify these approaches under a temporal-primary\nparadigm, which may overlook the unique and critical task-relevant information\nembedded in text modality like clinical reports, thus failing to fully leverage\nmutual benefits and complementarity of different modalities. To fill this gap,\nwe propose a novel textual-temporal multimodal learning paradigm that enables\neither modality to serve as the primary while being enhanced by the other,\nthereby effectively capturing modality-specific information and fostering\ncross-modal interaction. In specific, we design MedualTime, a language model\ncomposed of dual adapters to implement temporal-primary and textual-primary\nmodeling simultaneously. Within each adapter, lightweight adaptation tokens are\ninjected into the top layers of LM to encourage high-level modality fusion. The\nshared LM pipeline by dual adapters not only achieves adapter alignment but\nalso enables efficient fine-tuning, reducing computational resources.\nEmpirically, MedualTime demonstrates superior performance on medical data,\nachieving notable improvements of 8% accuracy and 12% F1 in supervised\nsettings. Furthermore, MedualTime's transferability is validated by few-shot\nlabel transfer experiments from coarse-grained to fine-grained medical data.\nhttps://github.com/start2020/MedualTime", "AI": {"tldr": "The paper introduces MedualTime, a novel textual-temporal multimodal learning paradigm to address biases in existing LM approaches by allowing either modality to serve as primary, enhancing cross-modal interaction.", "motivation": "Existing contrastive and prompt-based LM approaches in medical time series-text multimodal learning are biased, favoring time series over text, potentially missing critical text-based information.", "method": "Proposes MedualTime, a dual-adapter LM model with lightweight adaptation tokens for high-level modality fusion, enabling efficient fine-tuning and adapter alignment.", "result": "MedualTime achieves 8% accuracy and 12% F1 improvements in supervised settings and shows strong transferability in few-shot experiments.", "conclusion": "The proposed paradigm effectively captures modality-specific information and fosters cross-modal interaction, outperforming existing methods."}}
{"id": "2505.07691", "pdf": "https://arxiv.org/pdf/2505.07691", "abs": "https://arxiv.org/abs/2505.07691", "authors": ["Negin Ghamsarian", "Sahar Nasirihaghighi", "Klaus Schoeffmann", "Raphael Sznitman"], "title": "Feedback-Driven Pseudo-Label Reliability Assessment: Redefining Thresholding for Semi-Supervised Semantic Segmentation", "categories": ["cs.CV"], "comment": "11 pages, 5 Figures", "summary": "Semi-supervised learning leverages unlabeled data to enhance model\nperformance, addressing the limitations of fully supervised approaches. Among\nits strategies, pseudo-supervision has proven highly effective, typically\nrelying on one or multiple teacher networks to refine pseudo-labels before\ntraining a student network. A common practice in pseudo-supervision is\nfiltering pseudo-labels based on pre-defined confidence thresholds or entropy.\nHowever, selecting optimal thresholds requires large labeled datasets, which\nare often scarce in real-world semi-supervised scenarios. To overcome this\nchallenge, we propose Ensemble-of-Confidence Reinforcement (ENCORE), a dynamic\nfeedback-driven thresholding strategy for pseudo-label selection. Instead of\nrelying on static confidence thresholds, ENCORE estimates class-wise\ntrue-positive confidence within the unlabeled dataset and continuously adjusts\nthresholds based on the model's response to different levels of pseudo-label\nfiltering. This feedback-driven mechanism ensures the retention of informative\npseudo-labels while filtering unreliable ones, enhancing model training without\nmanual threshold tuning. Our method seamlessly integrates into existing\npseudo-supervision frameworks and significantly improves segmentation\nperformance, particularly in data-scarce conditions. Extensive experiments\ndemonstrate that integrating ENCORE with existing pseudo-supervision frameworks\nenhances performance across multiple datasets and network architectures,\nvalidating its effectiveness in semi-supervised learning.", "AI": {"tldr": "ENCORE introduces a dynamic feedback-driven thresholding strategy for pseudo-label selection in semi-supervised learning, eliminating the need for manual threshold tuning and improving model performance.", "motivation": "Addressing the challenge of selecting optimal confidence thresholds for pseudo-label filtering in semi-supervised learning, especially when labeled data is scarce.", "method": "Proposes ENCORE, which dynamically adjusts class-wise true-positive confidence thresholds based on model feedback, retaining informative pseudo-labels while filtering unreliable ones.", "result": "ENCORE enhances segmentation performance in data-scarce conditions and integrates seamlessly with existing pseudo-supervision frameworks, improving results across datasets and architectures.", "conclusion": "ENCORE is an effective solution for semi-supervised learning, offering dynamic thresholding without manual tuning and boosting model performance."}}
{"id": "2505.07508", "pdf": "https://arxiv.org/pdf/2505.07508", "abs": "https://arxiv.org/abs/2505.07508", "authors": ["Jing Ren", "Mingliang Hou", "Zhixuan Liu", "Xiaomei Bai"], "title": "EAGLE: Contrastive Learning for Efficient Graph Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph anomaly detection is a popular and vital task in various real-world\nscenarios, which has been studied for several decades. Recently, many studies\nextending deep learning-based methods have shown preferable performance on\ngraph anomaly detection. However, existing methods are lack of efficiency that\nis definitely necessary for embedded devices. Towards this end, we propose an\nEfficient Anomaly detection model on heterogeneous Graphs via contrastive\nLEarning (EAGLE) by contrasting abnormal nodes with normal ones in terms of\ntheir distances to the local context. The proposed method first samples\ninstance pairs on meta path-level for contrastive learning. Then, a graph\nautoencoder-based model is applied to learn informative node embeddings in an\nunsupervised way, which will be further combined with the discriminator to\npredict the anomaly scores of nodes. Experimental results show that EAGLE\noutperforms the state-of-the-art methods on three heterogeneous network\ndatasets.", "AI": {"tldr": "EAGLE is a deep learning-based model for efficient graph anomaly detection on heterogeneous graphs using contrastive learning, outperforming state-of-the-art methods.", "motivation": "Existing deep learning methods for graph anomaly detection lack efficiency, especially for embedded devices, prompting the need for a more efficient solution.", "method": "EAGLE uses contrastive learning to compare abnormal and normal nodes by their distances to local context, sampling instance pairs on meta path-level and employing a graph autoencoder for unsupervised node embedding learning, combined with a discriminator for anomaly scoring.", "result": "EAGLE achieves superior performance over state-of-the-art methods on three heterogeneous network datasets.", "conclusion": "EAGLE provides an efficient and effective solution for graph anomaly detection on heterogeneous graphs, addressing the limitations of existing methods."}}
{"id": "2505.07525", "pdf": "https://arxiv.org/pdf/2505.07525", "abs": "https://arxiv.org/abs/2505.07525", "authors": ["Sana Ayromlou", "D. B. Emerson"], "title": "Adaptive Latent-Space Constraints in Personalized FL", "categories": ["cs.LG", "68T07", "I.2.0; I.2.11; I.2.6"], "comment": "14 Pages, 1 Algorithm, 3 Figures, 3 Tables", "summary": "Federated learning (FL) has become an effective and widely used approach to\ntraining deep learning models on decentralized datasets held by distinct\nclients. FL also strengthens both security and privacy protections for training\ndata. Common challenges associated with statistical heterogeneity between\ndistributed datasets have spurred significant interest in personalized FL (pFL)\nmethods, where models combine aspects of global learning with local modeling\nspecific to each client's unique characteristics. In this work, the efficacy of\ntheoretically supported, adaptive MMD measures within the Ditto framework, a\nstate-of-the-art technique in pFL, are investigated. The use of such measures\nsignificantly improves model performance across a variety of tasks, especially\nthose with pronounced feature heterogeneity. While the Ditto algorithm is\nspecifically considered, such measures are directly applicable to a number of\nother pFL settings, and the results motivate the use of constraints tailored to\nthe various kinds of heterogeneity expected in FL systems.", "AI": {"tldr": "The paper explores adaptive MMD measures in the Ditto framework for personalized federated learning (pFL), improving model performance, especially in tasks with feature heterogeneity.", "motivation": "Addressing statistical heterogeneity in federated learning (FL) by enhancing personalized FL (pFL) methods to combine global learning with local modeling.", "method": "Investigates theoretically supported, adaptive MMD measures within the Ditto framework to improve pFL.", "result": "Adaptive MMD measures significantly boost model performance, particularly in tasks with feature heterogeneity.", "conclusion": "The findings advocate for tailored constraints in FL systems to handle various heterogeneity types, with broader applicability beyond Ditto."}}
{"id": "2408.14419", "pdf": "https://arxiv.org/pdf/2408.14419", "abs": "https://arxiv.org/abs/2408.14419", "authors": ["Shubham Bharti", "Shiyun Cheng", "Jihyun Rho", "Jianrui Zhang", "Mu Cai", "Yong Jae Lee", "Martina Rau", "Xiaojin Zhu"], "title": "CHARTOM: A Visual Theory-of-Mind Benchmark for Multimodal Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "We introduce CHARTOM, a visual theory-of-mind benchmark for multimodal large\nlanguage models. CHARTOM consists of specially designed data visualizing\ncharts. Given a chart, a language model needs to not only correctly comprehend\nthe chart (the FACT question) but also judge if the chart will be misleading to\na human reader (the MIND question). Both questions have significant societal\nbenefits. We detail the construction of the CHARTOM benchmark including its\ncalibration on human performance. We benchmark leading LLMs as of late 2024 -\nincluding GPT, Claude, Gemini, Qwen, Llama, and Llava - on the CHARTOM dataset\nand found that our benchmark was challenging to all of them, suggesting room\nfor future large language models to improve.", "AI": {"tldr": "CHARTOM is a visual theory-of-mind benchmark for multimodal LLMs, testing chart comprehension and misleading potential, challenging top models like GPT and Claude.", "motivation": "To evaluate LLMs' ability to comprehend charts and assess their potential to mislead humans, addressing societal benefits.", "method": "Constructed CHARTOM with calibrated human performance data, benchmarking top LLMs (GPT, Claude, Gemini, Qwen, Llama, Llava).", "result": "All tested models struggled with CHARTOM, indicating room for improvement in multimodal LLMs.", "conclusion": "CHARTOM highlights challenges for LLMs in visual theory-of-mind tasks, suggesting future research directions."}}
{"id": "2505.07715", "pdf": "https://arxiv.org/pdf/2505.07715", "abs": "https://arxiv.org/abs/2505.07715", "authors": ["Qi Xu", "Jie Deng", "Jiangrong Shen", "Biwu Chen", "Huajin Tang", "Gang Pan"], "title": "Hybrid Spiking Vision Transformer for Object Detection with Event Cameras", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Event-based object detection has gained increasing attention due to its\nadvantages such as high temporal resolution, wide dynamic range, and\nasynchronous address-event representation. Leveraging these advantages, Spiking\nNeural Networks (SNNs) have emerged as a promising approach, offering low\nenergy consumption and rich spatiotemporal dynamics. To further enhance the\nperformance of event-based object detection, this study proposes a novel hybrid\nspike vision Transformer (HsVT) model. The HsVT model integrates a spatial\nfeature extraction module to capture local and global features, and a temporal\nfeature extraction module to model time dependencies and long-term patterns in\nevent sequences. This combination enables HsVT to capture spatiotemporal\nfeatures, improving its capability to handle complex event-based object\ndetection tasks. To support research in this area, we developed and publicly\nreleased The Fall Detection Dataset as a benchmark for event-based object\ndetection tasks. This dataset, captured using an event-based camera, ensures\nfacial privacy protection and reduces memory usage due to the event\nrepresentation format. We evaluated the HsVT model on GEN1 and Fall Detection\ndatasets across various model sizes. Experimental results demonstrate that HsVT\nachieves significant performance improvements in event detection with fewer\nparameters.", "AI": {"tldr": "A hybrid spike vision Transformer (HsVT) model is proposed for event-based object detection, combining spatial and temporal feature extraction to improve performance. A new dataset, The Fall Detection Dataset, is introduced for benchmarking.", "motivation": "To enhance event-based object detection by leveraging the advantages of Spiking Neural Networks (SNNs) and address the need for better spatiotemporal feature capture.", "method": "The HsVT model integrates spatial and temporal feature extraction modules to capture local, global, and time-dependent features in event sequences.", "result": "HsVT achieves significant performance improvements in event detection with fewer parameters, as demonstrated on GEN1 and Fall Detection datasets.", "conclusion": "The HsVT model and the new dataset advance event-based object detection, offering efficient and effective solutions for complex tasks."}}
{"id": "2505.07534", "pdf": "https://arxiv.org/pdf/2505.07534", "abs": "https://arxiv.org/abs/2505.07534", "authors": ["J\u00fcrgen Bernard"], "title": "The Human-Data-Model Interaction Canvas for Visual Analytics", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "7 pages, 5 figures, LaTeX; to appear at the 16th International\n  EuroVis Workshop on Visual Analytics (EuroVA'25) as a position paper", "summary": "Visual Analytics (VA) integrates humans, data, and models as key actors in\ninsight generation and data-driven decision-making. This position paper values\nand reflects on 16 VA process models and frameworks and makes nine high-level\nobservations that motivate a fresh perspective on VA. The contribution is the\nHDMI Canvas, a perspective to VA that complements the strengths of existing VA\nprocess models and frameworks. It systematically characterizes diverse roles of\nhumans, data, and models, and how these actors benefit from and contribute to\nVA processes. The descriptive power of the HDMI Canvas eases the\ndifferentiation between a series of VA building blocks, rather than describing\ngeneral VA principles only. The canvas includes modern human-centered\nmethodologies, including human knowledge externalization and forms of feedback\nloops, while interpretable and explainable AI highlight model contributions\nbeyond their conventional outputs. The HDMI Canvas has generative power,\nguiding the design of new VA processes and is optimized for external\nstakeholders, improving VA outreach, interdisciplinary collaboration, and\nuser-centered design. The utility of the HDMI Canvas is demonstrated through\ntwo preliminary case studies.", "AI": {"tldr": "The paper introduces the HDMI Canvas, a new perspective on Visual Analytics (VA) that complements existing models by systematically characterizing the roles of humans, data, and models in VA processes.", "motivation": "To provide a fresh perspective on VA by integrating human-centered methodologies and modern AI contributions, improving interdisciplinary collaboration and user-centered design.", "method": "The HDMI Canvas is developed by reflecting on 16 existing VA process models and frameworks, emphasizing the roles of humans, data, and models.", "result": "The HDMI Canvas offers descriptive and generative power, differentiating VA building blocks and guiding new VA process designs, demonstrated through two case studies.", "conclusion": "The HDMI Canvas enhances VA by clarifying actor roles, improving outreach, and fostering collaboration, making it a valuable tool for VA research and practice."}}
{"id": "2505.07527", "pdf": "https://arxiv.org/pdf/2505.07527", "abs": "https://arxiv.org/abs/2505.07527", "authors": ["Hu Wang", "Congbo Ma", "Ian Reid", "Mohammad Yaqub"], "title": "Kalman Filter Enhanced GRPO for Reinforcement Learning-Based Language Model Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Reward baseline is important for Reinforcement Learning (RL) algorithms to\nreduce variance in policy gradient estimates. Recently, for language modeling,\nGroup Relative Policy Optimization (GRPO) is proposed to compute the advantage\nfor each output by subtracting the mean reward, as the baseline, for all\noutputs in the group. However, it can lead to inaccurate advantage estimates in\nenvironments with highly noisy rewards, potentially introducing bias. In this\nwork, we propose a model, called Kalman Filter Enhanced Group Relative Policy\nOptimization (KRPO), by using lightweight Kalman filtering to dynamically\nestimate the latent reward mean and variance. This filtering technique replaces\nthe naive batch mean baseline, enabling more adaptive advantage normalization.\nOur method does not require additional learned parameters over GRPO. This\napproach offers a simple yet effective way to incorporate multiple outputs of\nGRPO into advantage estimation, improving policy optimization in settings where\nhighly dynamic reward signals are difficult to model for language models.\nThrough experiments and analyses, we show that using a more adaptive advantage\nestimation model, KRPO can improve the stability and performance of GRPO. The\ncode is available at https://github.com/billhhh/KRPO_LLMs_RL", "AI": {"tldr": "KRPO enhances GRPO by using Kalman filtering for adaptive advantage estimation, improving stability and performance in noisy reward environments.", "motivation": "GRPO's naive batch mean baseline can introduce bias in noisy reward settings, prompting the need for a more adaptive method.", "method": "KRPO employs lightweight Kalman filtering to dynamically estimate reward mean and variance, replacing GRPO's batch mean baseline.", "result": "KRPO improves stability and performance over GRPO, especially in environments with highly dynamic rewards.", "conclusion": "KRPO offers a simple, effective enhancement to GRPO, requiring no additional parameters while improving advantage estimation."}}
{"id": "2410.09982", "pdf": "https://arxiv.org/pdf/2410.09982", "abs": "https://arxiv.org/abs/2410.09982", "authors": ["Vithursan Thangarasa", "Ganesh Venkatesh", "Mike Lasby", "Nish Sinnadurai", "Sean Lie"], "title": "Self-Data Distillation for Recovering Quality in Pruned Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted to MLSys 2025. Main paper: 14 pp., 4 figs., 6 tabs.;\n  Supplementary: 5 pp", "summary": "Large language models have driven significant progress in natural language\nprocessing, but their deployment requires substantial compute and memory\nresources. As models scale, compression techniques become essential for\nbalancing model quality with computational efficiency. Structured pruning,\nwhich removes less critical components of the model, is a promising strategy\nfor reducing complexity. However, one-shot pruning often results in significant\nquality degradation, particularly in tasks requiring multi-step reasoning. To\nrecover lost quality, supervised fine-tuning (SFT) is commonly applied, but it\ncan lead to catastrophic forgetting by shifting the model's learned data\ndistribution. Therefore, addressing the degradation from both pruning and SFT\nis essential to preserve the original model's quality. In this work, we utilize\nself-data distilled fine-tuning to address these challenges. Our approach\nleverages the original, unpruned model to generate a distilled dataset that\npreserves semantic richness and mitigates catastrophic forgetting by\nmaintaining alignment with the base model's knowledge. Empirically, we\ndemonstrate that self-data distillation consistently outperforms standard SFT,\nimproving average accuracy by up to 8% on the HuggingFace OpenLLM Leaderboard\nv1. Specifically, when pruning six decoder blocks on Llama3.1-8B Instruct\n(i.e., 32 to 26 layers, reducing the model size from 8.03B to 6.72B\nparameters), our method retains 91.2% of the original model's accuracy compared\nto 81.7% with SFT, while reducing real-world FLOPs by 16.3%. Furthermore,\ncombining self-data distilled models through model merging yields enhanced\nquality retention. Additionally, leveraging these pruned models in speculative\ndecoding increases token acceptance rates, thereby improving inference\nefficiency in applied settings.", "AI": {"tldr": "The paper proposes self-data distilled fine-tuning to mitigate quality degradation in pruned large language models, outperforming standard supervised fine-tuning and improving accuracy and efficiency.", "motivation": "Large language models require compression for efficiency, but pruning and fine-tuning degrade quality. Addressing this degradation is crucial.", "method": "Uses self-data distilled fine-tuning, leveraging the original model to generate a dataset preserving semantic richness and avoiding catastrophic forgetting.", "result": "Improves accuracy by up to 8%, retains 91.2% of original accuracy when pruning, and reduces FLOPs by 16.3%. Enhances inference efficiency via speculative decoding.", "conclusion": "Self-data distillation effectively balances model compression and quality retention, offering practical benefits for deployment."}}
{"id": "2505.07721", "pdf": "https://arxiv.org/pdf/2505.07721", "abs": "https://arxiv.org/abs/2505.07721", "authors": ["Vignesh Edithal", "Le Zhang", "Ilia Blank", "Imran Junejo"], "title": "Gameplay Highlights Generation", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we enable gamers to share their gaming experience on social\nmedia by automatically generating eye-catching highlight reels from their\ngameplay session Our automation will save time for gamers while increasing\naudience engagement. We approach the highlight generation problem by first\nidentifying intervals in the video where interesting events occur and then\nconcatenate them. We developed an in-house gameplay event detection dataset\ncontaining interesting events annotated by humans using VIA video annotator.\nTraditional techniques for highlight detection such as game engine integration\nrequires expensive collaboration with game developers. OCR techniques which\ndetect patches of specific images or texts require expensive per game\nengineering and may not generalize across game UI and different language. We\nfinetuned a multimodal general purpose video understanding model such as X-CLIP\nusing our dataset which generalizes across multiple games in a genre without\nper game engineering. Prompt engineering was performed to improve the\nclassification performance of this multimodal model. Our evaluation showed that\nsuch a finetuned model can detect interesting events in first person shooting\ngames from unseen gameplay footage with more than 90% accuracy. Moreover, our\nmodel performed significantly better on low resource games (small dataset) when\ntrained along with high resource games, showing signs of transfer learning. To\nmake the model production ready, we used ONNX libraries to enable cross\nplatform inference. These libraries also provide post training quantization\ntools to reduce model size and inference time for deployment. ONNX runtime\nlibraries with DirectML backend were used to perform efficient inference on\nWindows OS. We show that natural language supervision in the X-CLIP model leads\nto data efficient and highly performant video recognition models.", "AI": {"tldr": "Automated generation of gaming highlight reels using a finetuned X-CLIP model, achieving 90% accuracy in detecting interesting events across games without per-game engineering.", "motivation": "To save gamers time and increase audience engagement by automating the creation of eye-catching highlight reels from gameplay sessions.", "method": "Finetuned a multimodal X-CLIP model on an in-house dataset of annotated gameplay events, using prompt engineering for improved performance. The model generalizes across games without per-game adjustments.", "result": "Achieved over 90% accuracy in detecting interesting events in first-person shooting games, with transfer learning benefits for low-resource games.", "conclusion": "The approach is scalable, efficient, and production-ready, leveraging ONNX for cross-platform deployment and demonstrating the effectiveness of natural language supervision in video recognition."}}
{"id": "2505.07546", "pdf": "https://arxiv.org/pdf/2505.07546", "abs": "https://arxiv.org/abs/2505.07546", "authors": ["Jingjie Zheng", "Aryo Pradipta Gema", "Giwon Hong", "Xuanli He", "Pasquale Minervini", "Youcheng Sun", "Qiongkai Xu"], "title": "GRADA: Graph-based Reranker against Adversarial Documents Attack", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large\nlanguage models (LLMs) by integrating external knowledge from retrieved\ndocuments, thereby overcoming the limitations of models' static intrinsic\nknowledge. However, these systems are susceptible to adversarial attacks that\nmanipulate the retrieval process by introducing documents that are adversarial\nyet semantically similar to the query. Notably, while these adversarial\ndocuments resemble the query, they exhibit weak similarity to benign documents\nin the retrieval set. Thus, we propose a simple yet effective Graph-based\nReranking against Adversarial Document Attacks (GRADA) framework aiming at\npreserving retrieval quality while significantly reducing the success of\nadversaries. Our study evaluates the effectiveness of our approach through\nexperiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b,\nLlama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with\nresults from the Natural Questions dataset demonstrating up to an 80% reduction\nin attack success rates while maintaining minimal loss in accuracy.", "AI": {"tldr": "The paper introduces GRADA, a graph-based reranking framework to defend against adversarial attacks in RAG systems, showing an 80% reduction in attack success rates with minimal accuracy loss.", "motivation": "RAG systems enhance LLMs with external knowledge but are vulnerable to adversarial attacks that manipulate retrieval.", "method": "Proposes GRADA, a graph-based reranking framework to filter adversarial documents while preserving retrieval quality.", "result": "Experiments on five LLMs and three datasets show up to 80% reduction in attack success rates with negligible accuracy loss.", "conclusion": "GRADA effectively mitigates adversarial attacks in RAG systems without compromising retrieval performance."}}
{"id": "2505.07548", "pdf": "https://arxiv.org/pdf/2505.07548", "abs": "https://arxiv.org/abs/2505.07548", "authors": ["Lingkun Luo", "Shiqiang Hu", "Liming Chen"], "title": "Noise Optimized Conditional Diffusion for Domain Adaptation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "9 pages, 4 figures This work has been accepted by the International\n  Joint Conference on Artificial Intelligence (IJCAI 2025)", "summary": "Pseudo-labeling is a cornerstone of Unsupervised Domain Adaptation (UDA), yet\nthe scarcity of High-Confidence Pseudo-Labeled Target Domain Samples\n(\\textbf{hcpl-tds}) often leads to inaccurate cross-domain statistical\nalignment, causing DA failures. To address this challenge, we propose\n\\textbf{N}oise \\textbf{O}ptimized \\textbf{C}onditional \\textbf{D}iffusion for\n\\textbf{D}omain \\textbf{A}daptation (\\textbf{NOCDDA}), which seamlessly\nintegrates the generative capabilities of conditional diffusion models with the\ndecision-making requirements of DA to achieve task-coupled optimization for\nefficient adaptation. For robust cross-domain consistency, we modify the DA\nclassifier to align with the conditional diffusion classifier within a unified\noptimization framework, enabling forward training on noise-varying cross-domain\nsamples. Furthermore, we argue that the conventional \\( \\mathcal{N}(\\mathbf{0},\n\\mathbf{I}) \\) initialization in diffusion models often generates\nclass-confused hcpl-tds, compromising discriminative DA. To resolve this, we\nintroduce a class-aware noise optimization strategy that refines sampling\nregions for reverse class-specific hcpl-tds generation, effectively enhancing\ncross-domain alignment. Extensive experiments across 5 benchmark datasets and\n29 DA tasks demonstrate significant performance gains of \\textbf{NOCDDA} over\n31 state-of-the-art methods, validating its robustness and effectiveness.", "AI": {"tldr": "NOCDDA integrates conditional diffusion models with domain adaptation to improve pseudo-labeling by optimizing noise and enhancing cross-domain alignment.", "motivation": "The scarcity of high-confidence pseudo-labeled target domain samples in UDA leads to inaccurate cross-domain alignment, causing adaptation failures.", "method": "NOCDDA combines conditional diffusion models with DA, optimizing noise and refining sampling regions for better pseudo-label generation.", "result": "Extensive experiments show NOCDDA outperforms 31 state-of-the-art methods across 5 datasets and 29 DA tasks.", "conclusion": "NOCDDA effectively enhances cross-domain alignment and robustness in domain adaptation tasks."}}
{"id": "2410.13439", "pdf": "https://arxiv.org/pdf/2410.13439", "abs": "https://arxiv.org/abs/2410.13439", "authors": ["Guangming Huang", "Yunfei Long", "Cunjin Luo"], "title": "Similarity-Dissimilarity Loss for Multi-label Supervised Contrastive Learning", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "Supervised contrastive learning has achieved remarkable success by leveraging\nlabel information; however, determining positive samples in multi-label\nscenarios remains a critical challenge. In multi-label supervised contrastive\nlearning (MSCL), multi-label relations are not yet fully defined, leading to\nambiguity in identifying positive samples and formulating contrastive loss\nfunctions to construct the representation space. To address these challenges,\nwe: (i) first define five distinct multi-label relations in MSCL to\nsystematically identify positive samples, (ii) introduce a novel\nSimilarity-Dissimilarity Loss that dynamically re-weights samples through\ncomputing the similarity and dissimilarity factors between positive samples and\ngiven anchors based on multi-label relations, and (iii) further provide\ntheoretical grounded proofs for our method through rigorous mathematical\nanalysis that supports the formulation and effectiveness of the proposed loss\nfunction. We conduct the experiments across both image and text modalities, and\nextend the evaluation to medical domain. The results demonstrate that our\nmethod consistently outperforms baselines in a comprehensive evaluation,\nconfirming its effectiveness and robustness. Code is available at:\nhttps://github.com/guangminghuang/similarity-dissimilarity-loss.", "AI": {"tldr": "The paper introduces a method for multi-label supervised contrastive learning (MSCL) by defining multi-label relations, proposing a dynamic loss function, and validating its effectiveness across domains.", "motivation": "Addressing the ambiguity in identifying positive samples and formulating contrastive loss functions in multi-label scenarios.", "method": "Defines five multi-label relations, introduces a Similarity-Dissimilarity Loss for dynamic re-weighting, and provides theoretical proofs.", "result": "Outperforms baselines in image, text, and medical domains, demonstrating effectiveness and robustness.", "conclusion": "The proposed method successfully addresses challenges in MSCL and shows consistent performance improvements."}}
{"id": "2505.07734", "pdf": "https://arxiv.org/pdf/2505.07734", "abs": "https://arxiv.org/abs/2505.07734", "authors": ["Jiangling Zhang", "Weijie Zhu", "Jirui Huang", "Yaxiong Chen"], "title": "LAMM-ViT: AI Face Detection via Layer-Aware Modulation of Region-Guided Attention", "categories": ["cs.CV"], "comment": null, "summary": "Detecting AI-synthetic faces presents a critical challenge: it is hard to\ncapture consistent structural relationships between facial regions across\ndiverse generation techniques. Current methods, which focus on specific\nartifacts rather than fundamental inconsistencies, often fail when confronted\nwith novel generative models. To address this limitation, we introduce\nLayer-aware Mask Modulation Vision Transformer (LAMM-ViT), a Vision Transformer\ndesigned for robust facial forgery detection. This model integrates distinct\nRegion-Guided Multi-Head Attention (RG-MHA) and Layer-aware Mask Modulation\n(LAMM) components within each layer. RG-MHA utilizes facial landmarks to create\nregional attention masks, guiding the model to scrutinize architectural\ninconsistencies across different facial areas. Crucially, the separate LAMM\nmodule dynamically generates layer-specific parameters, including mask weights\nand gating values, based on network context. These parameters then modulate the\nbehavior of RG-MHA, enabling adaptive adjustment of regional focus across\nnetwork depths. This architecture facilitates the capture of subtle,\nhierarchical forgery cues ubiquitous among diverse generation techniques, such\nas GANs and Diffusion Models. In cross-model generalization tests, LAMM-ViT\ndemonstrates superior performance, achieving 94.09% mean ACC (a +5.45%\nimprovement over SoTA) and 98.62% mean AP (a +3.09% improvement). These results\ndemonstrate LAMM-ViT's exceptional ability to generalize and its potential for\nreliable deployment against evolving synthetic media threats.", "AI": {"tldr": "LAMM-ViT introduces a Vision Transformer with RG-MHA and LAMM components for robust AI-synthetic face detection, outperforming state-of-the-art methods.", "motivation": "Current methods fail to detect novel generative models due to reliance on specific artifacts rather than fundamental inconsistencies.", "method": "LAMM-ViT integrates RG-MHA for regional attention and LAMM for dynamic parameter modulation, capturing hierarchical forgery cues.", "result": "Achieves 94.09% mean ACC (+5.45% over SoTA) and 98.62% mean AP (+3.09% over SoTA) in cross-model tests.", "conclusion": "LAMM-ViT generalizes well and is promising for detecting evolving synthetic media threats."}}
{"id": "2505.07553", "pdf": "https://arxiv.org/pdf/2505.07553", "abs": "https://arxiv.org/abs/2505.07553", "authors": ["Tor Sporsem", "Rasmus Ulfsnes"], "title": "Towards Requirements Engineering for RAG Systems", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to EASE 2025, 17-20 June, Istanbul, Turkey", "summary": "This short paper explores how a maritime company develops and integrates\nlarge-language models (LLM). Specifically by looking at the requirements\nengineering for Retrieval Augmented Generation (RAG) systems in expert\nsettings. Through a case study at a maritime service provider, we demonstrate\nhow data scientists face a fundamental tension between user expectations of AI\nperfection and the correctness of the generated outputs. Our findings reveal\nthat data scientists must identify context-specific \"retrieval requirements\"\nthrough iterative experimentation together with users because they are the ones\nwho can determine correctness. We present an empirical process model describing\nhow data scientists practically elicited these \"retrieval requirements\" and\nmanaged system limitations. This work advances software engineering knowledge\nby providing insights into the specialized requirements engineering processes\nfor implementing RAG systems in complex domain-specific applications.", "AI": {"tldr": "The paper examines how a maritime company integrates LLMs, focusing on RAG systems in expert settings. It highlights the challenge of balancing user expectations with output correctness and proposes an empirical process for identifying retrieval requirements.", "motivation": "To address the tension between user expectations of AI perfection and the correctness of outputs in domain-specific RAG systems.", "method": "A case study at a maritime service provider, involving iterative experimentation with users to identify retrieval requirements.", "result": "Data scientists must collaborate with users to define context-specific retrieval requirements and manage system limitations.", "conclusion": "The study provides insights into specialized requirements engineering for RAG systems in complex domains, advancing software engineering knowledge."}}
{"id": "2505.07554", "pdf": "https://arxiv.org/pdf/2505.07554", "abs": "https://arxiv.org/abs/2505.07554", "authors": ["Erica Coppolillo"], "title": "Injecting Knowledge Graphs into Large Language Models", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Integrating structured knowledge from Knowledge Graphs (KGs) into Large\nLanguage Models (LLMs) remains a key challenge for symbolic reasoning. Existing\nmethods mainly rely on prompt engineering or fine-tuning, which lose structural\nfidelity or incur high computational costs. Building on recent encoding\ntechniques which integrate graph embeddings within the LLM input as tokens, we\nextend this paradigm to the KG domain by leveraging Knowledge Graph Embedding\n(KGE) models, thus enabling graph-aware reasoning. Our approach is\nmodel-agnostic, resource-efficient, and compatible with any LLMs. Extensive\nexperimentation on synthetic and real-world datasets shows that our method\nimproves reasoning performance over established baselines, further achieving\nthe best trade-off in terms of accuracy and efficiency against state-of-the-art\nLLMs.", "AI": {"tldr": "A method to integrate Knowledge Graphs (KGs) into Large Language Models (LLMs) using Knowledge Graph Embedding (KGE) models, improving reasoning performance efficiently.", "motivation": "Addressing the challenge of integrating structured KG knowledge into LLMs without losing structural fidelity or incurring high computational costs.", "method": "Leverages KGE models to integrate graph embeddings into LLM inputs, enabling graph-aware reasoning in a model-agnostic and resource-efficient way.", "result": "Improves reasoning performance over baselines and achieves the best accuracy-efficiency trade-off compared to state-of-the-art LLMs.", "conclusion": "The approach successfully integrates KGs into LLMs, enhancing reasoning while maintaining efficiency and compatibility."}}
{"id": "2501.09798", "pdf": "https://arxiv.org/pdf/2501.09798", "abs": "https://arxiv.org/abs/2501.09798", "authors": ["Andrey Labunets", "Nishit V. Pandya", "Ashish Hooda", "Xiaohan Fu", "Earlence Fernandes"], "title": "Fun-tuning: Characterizing the Vulnerability of Proprietary LLMs to Optimization-based Prompt Injection Attacks via the Fine-Tuning Interface", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "We surface a new threat to closed-weight Large Language Models (LLMs) that\nenables an attacker to compute optimization-based prompt injections.\nSpecifically, we characterize how an attacker can leverage the loss-like\ninformation returned from the remote fine-tuning interface to guide the search\nfor adversarial prompts. The fine-tuning interface is hosted by an LLM vendor\nand allows developers to fine-tune LLMs for their tasks, thus providing\nutility, but also exposes enough information for an attacker to compute\nadversarial prompts. Through an experimental analysis, we characterize the\nloss-like values returned by the Gemini fine-tuning API and demonstrate that\nthey provide a useful signal for discrete optimization of adversarial prompts\nusing a greedy search algorithm. Using the PurpleLlama prompt injection\nbenchmark, we demonstrate attack success rates between 65% and 82% on Google's\nGemini family of LLMs. These attacks exploit the classic utility-security\ntradeoff - the fine-tuning interface provides a useful feature for developers\nbut also exposes the LLMs to powerful attacks.", "AI": {"tldr": "A new threat to closed-weight LLMs allows attackers to compute adversarial prompts using loss-like info from fine-tuning interfaces, achieving 65-82% success rates on Gemini models.", "motivation": "To expose vulnerabilities in closed-weight LLMs where fine-tuning interfaces inadvertently aid attackers in crafting adversarial prompts.", "method": "Leverage loss-like info from fine-tuning APIs to guide greedy search for adversarial prompts, tested on Gemini models using the PurpleLlama benchmark.", "result": "Attack success rates of 65-82% on Gemini LLMs, highlighting the utility-security tradeoff.", "conclusion": "Fine-tuning interfaces, while useful, expose LLMs to adversarial attacks, necessitating better security measures."}}
{"id": "2505.07744", "pdf": "https://arxiv.org/pdf/2505.07744", "abs": "https://arxiv.org/abs/2505.07744", "authors": ["Halid Ziya Yerebakan", "Kritika Iyer", "Xueqi Guo", "Yoshihisa Shinagawa", "Gerardo Hermosillo Valadez"], "title": "BodyGPS: Anatomical Positioning System", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We introduce a new type of foundational model for parsing human anatomy in\nmedical images that works for different modalities. It supports supervised or\nunsupervised training and can perform matching, registration, classification,\nor segmentation with or without user interaction. We achieve this by training a\nneural network estimator that maps query locations to atlas coordinates via\nregression. Efficiency is improved by sparsely sampling the input, enabling\nresponse times of less than 1 ms without additional accelerator hardware. We\ndemonstrate the utility of the algorithm in both CT and MRI modalities.", "AI": {"tldr": "A foundational model for parsing human anatomy in medical images, supporting supervised/unsupervised training and tasks like matching, registration, classification, or segmentation.", "motivation": "To create a versatile model for medical image analysis across modalities with efficient performance.", "method": "Trains a neural network estimator to map query locations to atlas coordinates via regression, using sparse sampling for efficiency.", "result": "Achieves response times under 1 ms without extra hardware, demonstrated in CT and MRI.", "conclusion": "The model is efficient and adaptable for various medical imaging tasks."}}
{"id": "2505.07575", "pdf": "https://arxiv.org/pdf/2505.07575", "abs": "https://arxiv.org/abs/2505.07575", "authors": ["Samuel Erickson", "Mikael Johansson"], "title": "Personalized Federated Learning under Model Dissimilarity Constraints", "categories": ["cs.LG"], "comment": null, "summary": "One of the defining challenges in federated learning is that of statistical\nheterogeneity among clients. We address this problem with KARULA, a regularized\nstrategy for personalized federated learning, which constrains the pairwise\nmodel dissimilarities between clients based on the difference in their\ndistributions, as measured by a surrogate for the 1-Wasserstein distance\nadapted for the federated setting. This allows the strategy to adapt to highly\ncomplex interrelations between clients, that e.g., clustered approaches fail to\ncapture. We propose an inexact projected stochastic gradient algorithm to solve\nthe constrained problem that the strategy defines, and show theoretically that\nit converges with smooth, possibly non-convex losses to a neighborhood of a\nstationary point with rate O(1/K). We demonstrate the effectiveness of KARULA\non synthetic and real federated data sets.", "AI": {"tldr": "KARULA is a regularized strategy for personalized federated learning that addresses statistical heterogeneity by constraining pairwise model dissimilarities based on distribution differences.", "motivation": "The challenge of statistical heterogeneity among clients in federated learning motivates the need for a strategy that adapts to complex interrelations, which existing clustered approaches fail to capture.", "method": "KARULA uses a surrogate for the 1-Wasserstein distance to constrain pairwise model dissimilarities and proposes an inexact projected stochastic gradient algorithm for solving the constrained problem.", "result": "Theoretical analysis shows convergence to a neighborhood of a stationary point with rate O(1/K) for smooth, possibly non-convex losses. Empirical results demonstrate effectiveness on synthetic and real federated datasets.", "conclusion": "KARULA effectively addresses statistical heterogeneity in federated learning, offering a scalable and adaptive solution with theoretical guarantees."}}
{"id": "2502.01891", "pdf": "https://arxiv.org/pdf/2502.01891", "abs": "https://arxiv.org/abs/2502.01891", "authors": ["Kemal Kurniawan", "Meladel Mistica", "Timothy Baldwin", "Jey Han Lau"], "title": "Training and Evaluating with Human Label Variation: An Empirical Study", "categories": ["cs.LG", "cs.CL"], "comment": "25 pages, 7 figures. Fixed PO-JSD values on the MFRC dataset", "summary": "Human label variation (HLV) challenges the standard assumption that a\nlabelled instance has a single ground truth, instead embracing the natural\nvariation in human annotation to train and evaluate models. While various\ntraining methods and metrics for HLV have been proposed, it is still unclear\nwhich methods and metrics perform best in what settings. We propose new\nevaluation metrics for HLV leveraging fuzzy set theory. Since these new\nproposed metrics are differentiable, we then in turn experiment with employing\nthese metrics as training objectives. We conduct an extensive study over 6 HLV\ndatasets testing 14 training methods and 6 evaluation metrics. We find that\ntraining on either disaggregated annotations or soft labels performs best\nacross metrics, outperforming training using the proposed training objectives\nwith differentiable metrics. We also show that our proposed soft metric is more\ninterpretable and correlates best with human preference.", "AI": {"tldr": "The paper addresses human label variation (HLV) by proposing new fuzzy set-based evaluation metrics and testing them as training objectives. It finds disaggregated annotations or soft labels perform best, and the proposed soft metric aligns well with human preference.", "motivation": "HLV challenges the single ground truth assumption, but existing methods and metrics lack clarity on performance in different settings.", "method": "Proposes new differentiable metrics using fuzzy set theory, tests them as training objectives, and evaluates 14 training methods and 6 metrics across 6 HLV datasets.", "result": "Disaggregated annotations or soft labels outperform training with differentiable metrics. The proposed soft metric is more interpretable and correlates best with human preference.", "conclusion": "Soft labels or disaggregated annotations are optimal for HLV, and the proposed soft metric offers interpretability and human alignment."}}
{"id": "2505.07747", "pdf": "https://arxiv.org/pdf/2505.07747", "abs": "https://arxiv.org/abs/2505.07747", "authors": ["Weiyu Li", "Xuanyang Zhang", "Zheng Sun", "Di Qi", "Hao Li", "Wei Cheng", "Weiwei Cai", "Shihao Wu", "Jiarui Liu", "Zihao Wang", "Xiao Chen", "Feipeng Tian", "Jianxiong Pan", "Zeming Li", "Gang Yu", "Xiangyu Zhang", "Daxin Jiang", "Ping Tan"], "title": "Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets", "categories": ["cs.CV"], "comment": "Technical report", "summary": "While generative artificial intelligence has advanced significantly across\ntext, image, audio, and video domains, 3D generation remains comparatively\nunderdeveloped due to fundamental challenges such as data scarcity, algorithmic\nlimitations, and ecosystem fragmentation. To this end, we present Step1X-3D, an\nopen framework addressing these challenges through: (1) a rigorous data\ncuration pipeline processing >5M assets to create a 2M high-quality dataset\nwith standardized geometric and textural properties; (2) a two-stage 3D-native\narchitecture combining a hybrid VAE-DiT geometry generator with an\ndiffusion-based texture synthesis module; and (3) the full open-source release\nof models, training code, and adaptation modules. For geometry generation, the\nhybrid VAE-DiT component produces TSDF representations by employing\nperceiver-based latent encoding with sharp edge sampling for detail\npreservation. The diffusion-based texture synthesis module then ensures\ncross-view consistency through geometric conditioning and latent-space\nsynchronization. Benchmark results demonstrate state-of-the-art performance\nthat exceeds existing open-source methods, while also achieving competitive\nquality with proprietary solutions. Notably, the framework uniquely bridges the\n2D and 3D generation paradigms by supporting direct transfer of 2D control\ntechniques~(e.g., LoRA) to 3D synthesis. By simultaneously advancing data\nquality, algorithmic fidelity, and reproducibility, Step1X-3D aims to establish\nnew standards for open research in controllable 3D asset generation.", "AI": {"tldr": "Step1X-3D is an open framework for 3D generation, addressing data scarcity and algorithmic challenges with a curated dataset, hybrid VAE-DiT architecture, and diffusion-based texture synthesis, achieving state-of-the-art results.", "motivation": "3D generation lags behind other AI domains due to data scarcity, algorithmic limitations, and ecosystem fragmentation. Step1X-3D aims to overcome these challenges.", "method": "The framework uses a two-stage approach: (1) a hybrid VAE-DiT geometry generator for TSDF representations, and (2) a diffusion-based texture synthesis module for cross-view consistency.", "result": "Benchmarks show state-of-the-art performance, surpassing open-source methods and matching proprietary solutions. It also enables 2D-to-3D control transfer.", "conclusion": "Step1X-3D sets new standards for open research in controllable 3D asset generation by improving data quality, algorithmic fidelity, and reproducibility."}}
{"id": "2505.07621", "pdf": "https://arxiv.org/pdf/2505.07621", "abs": "https://arxiv.org/abs/2505.07621", "authors": ["Leonardo Kuffo", "Peter Boncz"], "title": "Bang for the Buck: Vector Search on Cloud CPUs", "categories": ["cs.DB", "cs.AI"], "comment": "To be published in Proceedings of 21st International Workshop on Data\n  Management on New Hardware (DaMoN '25)", "summary": "Vector databases have emerged as a new type of systems that support efficient\nquerying of high-dimensional vectors. Many of these offer their database as a\nservice in the cloud. However, the variety of available CPUs and the lack of\nvector search benchmarks across CPUs make it difficult for users to choose one.\nIn this study, we show that CPU microarchitectures available in the cloud\nperform significantly differently across vector search scenarios. For instance,\nin an IVF index on float32 vectors, AMD's Zen4 gives almost 3x more queries per\nsecond (QPS) compared to Intel's Sapphire Rapids, but for HNSW indexes, the\ntables turn. However, when looking at the number of queries per dollar (QP$),\nGraviton3 is the best option for most indexes and quantization settings, even\nover Graviton4 (Table 1). With this work, we hope to guide users in getting the\nbest \"bang for the buck\" when deploying vector search systems.", "AI": {"tldr": "CPU microarchitectures in the cloud perform differently for vector search. AMD Zen4 excels in IVF, while Graviton3 offers the best cost efficiency.", "motivation": "The lack of benchmarks for vector search across CPUs makes it hard for users to choose the best option for their needs.", "method": "Analyzed performance of different CPUs (AMD Zen4, Intel Sapphire Rapids, Graviton3, Graviton4) across vector search scenarios (IVF, HNSW indexes) and quantization settings.", "result": "AMD Zen4 outperforms Intel Sapphire Rapids in IVF, but Graviton3 provides the best queries per dollar (QP$) for most cases.", "conclusion": "This study helps users optimize cost and performance when deploying vector search systems."}}
{"id": "2505.07614", "pdf": "https://arxiv.org/pdf/2505.07614", "abs": "https://arxiv.org/abs/2505.07614", "authors": ["Gleb Molodtsov", "Daniil Medyakov", "Sergey Skorik", "Nikolas Khachaturov", "Shahane Tigranyan", "Vladimir Aletov", "Aram Avetisyan", "Martin Tak\u00e1\u010d", "Aleksandr Beznosikov"], "title": "Trial and Trust: Addressing Byzantine Attacks with Comprehensive Defense Strategy", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Recent advancements in machine learning have improved performance while also\nincreasing computational demands. While federated and distributed setups\naddress these issues, their structure is vulnerable to malicious influences. In\nthis paper, we address a specific threat, Byzantine attacks, where compromised\nclients inject adversarial updates to derail global convergence. We combine the\ntrust scores concept with trial function methodology to dynamically filter\noutliers. Our methods address the critical limitations of previous approaches,\nallowing functionality even when Byzantine nodes are in the majority. Moreover,\nour algorithms adapt to widely used scaled methods like Adam and RMSProp, as\nwell as practical scenarios, including local training and partial\nparticipation. We validate the robustness of our methods by conducting\nextensive experiments on both synthetic and real ECG data collected from\nmedical institutions. Furthermore, we provide a broad theoretical analysis of\nour algorithms and their extensions to aforementioned practical setups. The\nconvergence guarantees of our methods are comparable to those of classical\nalgorithms developed without Byzantine interference.", "AI": {"tldr": "The paper proposes a method to counter Byzantine attacks in federated/distributed ML by combining trust scores and trial functions, ensuring robustness even with majority malicious nodes.", "motivation": "Addressing vulnerabilities in federated/distributed ML setups to Byzantine attacks, where adversarial updates disrupt convergence.", "method": "Combines trust scores and trial functions to dynamically filter outliers, adaptable to scaled methods (Adam, RMSProp) and practical scenarios (local training, partial participation).", "result": "Validated robustness via experiments on synthetic and real ECG data; theoretical analysis shows convergence guarantees comparable to non-Byzantine settings.", "conclusion": "The method effectively mitigates Byzantine attacks, maintaining performance in adversarial settings and practical scenarios."}}
{"id": "2502.14581", "pdf": "https://arxiv.org/pdf/2502.14581", "abs": "https://arxiv.org/abs/2502.14581", "authors": ["Julian Rodemann", "Esteban Garces Arias", "Christoph Luther", "Christoph Jansen", "Thomas Augustin"], "title": "A Statistical Case Against Empirical Human-AI Alignment", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.OT"], "comment": "24 pages, 2 figures, 5 tables", "summary": "Empirical human-AI alignment aims to make AI systems act in line with\nobserved human behavior. While noble in its goals, we argue that empirical\nalignment can inadvertently introduce statistical biases that warrant caution.\nThis position paper thus advocates against naive empirical alignment, offering\nprescriptive alignment and a posteriori empirical alignment as alternatives. We\nsubstantiate our principled argument by tangible examples like human-centric\ndecoding of language models.", "AI": {"tldr": "The paper critiques naive empirical human-AI alignment, proposing prescriptive and a posteriori alignment as better alternatives, supported by examples like language model decoding.", "motivation": "To highlight the risks of statistical biases in empirical human-AI alignment and advocate for more principled approaches.", "method": "Principled argumentation and tangible examples, such as human-centric decoding of language models.", "result": "Demonstrates that naive empirical alignment can introduce biases, suggesting alternatives.", "conclusion": "Advocates for prescriptive and a posteriori empirical alignment over naive approaches to avoid biases."}}
{"id": "2505.07812", "pdf": "https://arxiv.org/pdf/2505.07812", "abs": "https://arxiv.org/abs/2505.07812", "authors": ["Chenze Shao", "Fandong Meng", "Jie Zhou"], "title": "Continuous Visual Autoregressive Generation via Score Maximization", "categories": ["cs.CV"], "comment": "ICML 2025", "summary": "Conventional wisdom suggests that autoregressive models are used to process\ndiscrete data. When applied to continuous modalities such as visual data,\nVisual AutoRegressive modeling (VAR) typically resorts to quantization-based\napproaches to cast the data into a discrete space, which can introduce\nsignificant information loss. To tackle this issue, we introduce a Continuous\nVAR framework that enables direct visual autoregressive generation without\nvector quantization. The underlying theoretical foundation is strictly proper\nscoring rules, which provide powerful statistical tools capable of evaluating\nhow well a generative model approximates the true distribution. Within this\nframework, all we need is to select a strictly proper score and set it as the\ntraining objective to optimize. We primarily explore a class of training\nobjectives based on the energy score, which is likelihood-free and thus\novercomes the difficulty of making probabilistic predictions in the continuous\nspace. Previous efforts on continuous autoregressive generation, such as GIVT\nand diffusion loss, can also be derived from our framework using other strictly\nproper scores. Source code: https://github.com/shaochenze/EAR.", "AI": {"tldr": "The paper introduces Continuous VAR, a framework for direct visual autoregressive generation without quantization, using strictly proper scoring rules for training.", "motivation": "To address information loss in quantization-based autoregressive models for continuous visual data.", "method": "Proposes Continuous VAR, leveraging strictly proper scoring rules (e.g., energy score) as training objectives for likelihood-free optimization.", "result": "Enables direct autoregressive generation in continuous space, unifying approaches like GIVT and diffusion loss under the framework.", "conclusion": "Continuous VAR provides a flexible, theoretically grounded solution for autoregressive modeling of continuous visual data."}}
{"id": "2505.07634", "pdf": "https://arxiv.org/pdf/2505.07634", "abs": "https://arxiv.org/abs/2505.07634", "authors": ["Jian Liu", "Xiongtao Shi", "Thai Duy Nguyen", "Haitian Zhang", "Tianxiang Zhang", "Wei Sun", "Yanjie Li", "Athanasios V. Vasilakos", "Giovanni Iacca", "Arshad Ali Khan", "Arvind Kumar", "Jae Won Cho", "Ajmal Mian", "Lihua Xie", "Erik Cambria", "Lin Wang"], "title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "51 pages, 17 figures, 9 tables", "summary": "The rapid evolution of artificial intelligence (AI) has shifted from static,\ndata-driven models to dynamic systems capable of perceiving and interacting\nwith real-world environments. Despite advancements in pattern recognition and\nsymbolic reasoning, current AI systems, such as large language models, remain\ndisembodied, unable to physically engage with the world. This limitation has\ndriven the rise of embodied AI, where autonomous agents, such as humanoid\nrobots, must navigate and manipulate unstructured environments with human-like\nadaptability. At the core of this challenge lies the concept of Neural Brain, a\ncentral intelligence system designed to drive embodied agents with human-like\nadaptability. A Neural Brain must seamlessly integrate multimodal sensing and\nperception with cognitive capabilities. Achieving this also requires an\nadaptive memory system and energy-efficient hardware-software co-design,\nenabling real-time action in dynamic environments. This paper introduces a\nunified framework for the Neural Brain of embodied agents, addressing two\nfundamental challenges: (1) defining the core components of Neural Brain and\n(2) bridging the gap between static AI models and the dynamic adaptability\nrequired for real-world deployment. To this end, we propose a biologically\ninspired architecture that integrates multimodal active sensing,\nperception-cognition-action function, neuroplasticity-based memory storage and\nupdating, and neuromorphic hardware/software optimization. Furthermore, we also\nreview the latest research on embodied agents across these four aspects and\nanalyze the gap between current AI systems and human intelligence. By\nsynthesizing insights from neuroscience, we outline a roadmap towards the\ndevelopment of generalizable, autonomous agents capable of human-level\nintelligence in real-world scenarios.", "AI": {"tldr": "The paper proposes a unified framework for Neural Brain in embodied AI, addressing core components and bridging the gap between static AI and dynamic adaptability.", "motivation": "Current AI systems lack physical engagement with the world, prompting the need for embodied AI with human-like adaptability.", "method": "A biologically inspired architecture integrating multimodal sensing, cognition-action functions, neuroplastic memory, and neuromorphic hardware/software.", "result": "The framework aims to enable real-time action in dynamic environments and reviews gaps between current AI and human intelligence.", "conclusion": "The paper outlines a roadmap for developing generalizable, autonomous agents with human-level intelligence in real-world scenarios."}}
{"id": "2505.07629", "pdf": "https://arxiv.org/pdf/2505.07629", "abs": "https://arxiv.org/abs/2505.07629", "authors": ["Yizhou Ma", "Zhuoqin Yang", "Luis-Daniel Ib\u00e1\u00f1ez"], "title": "Enhancing Federated Learning with Kolmogorov-Arnold Networks: A Comparative Study Across Diverse Aggregation Strategies", "categories": ["cs.LG"], "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. It was prepared prior to submission to, and has\n  since been accepted at, ICIC 2025. The final Version of Record will be\n  published in the ICIC 2025 proceedings by Springer", "summary": "Multilayer Perceptron (MLP), as a simple yet powerful model, continues to be\nwidely used in classification and regression tasks. However, traditional MLPs\noften struggle to efficiently capture nonlinear relationships in load data when\ndealing with complex datasets. Kolmogorov-Arnold Networks (KAN), inspired by\nthe Kolmogorov-Arnold representation theorem, have shown promising capabilities\nin modeling complex nonlinear relationships. In this study, we explore the\nperformance of KANs within federated learning (FL) frameworks and compare them\nto traditional Multilayer Perceptrons. Our experiments, conducted across four\ndiverse datasets demonstrate that KANs consistently outperform MLPs in terms of\naccuracy, stability, and convergence efficiency. KANs exhibit remarkable\nrobustness under varying client numbers and non-IID data distributions,\nmaintaining superior performance even as client heterogeneity increases.\nNotably, KANs require fewer communication rounds to converge compared to MLPs,\nhighlighting their efficiency in FL scenarios. Additionally, we evaluate\nmultiple parameter aggregation strategies, with trimmed mean and FedProx\nemerging as the most effective for optimizing KAN performance. These findings\nestablish KANs as a robust and scalable alternative to MLPs for federated\nlearning tasks, paving the way for their application in decentralized and\nprivacy-preserving environments.", "AI": {"tldr": "KANs outperform MLPs in federated learning, offering better accuracy, stability, and efficiency, especially in non-IID settings.", "motivation": "Traditional MLPs struggle with complex nonlinear relationships in federated learning, prompting exploration of KANs as a superior alternative.", "method": "Comparison of KANs and MLPs in FL frameworks across diverse datasets, evaluating accuracy, stability, convergence, and robustness under varying conditions.", "result": "KANs consistently outperform MLPs in accuracy, stability, and convergence efficiency, requiring fewer communication rounds and handling non-IID data better.", "conclusion": "KANs are a robust, scalable alternative to MLPs in FL, suitable for decentralized and privacy-preserving environments."}}
{"id": "2502.14908", "pdf": "https://arxiv.org/pdf/2502.14908", "abs": "https://arxiv.org/abs/2502.14908", "authors": ["Peter Carragher", "Nikitha Rao", "Abhinand Jha", "R Raghav", "Kathleen M. Carley"], "title": "SegSub: Evaluating Robustness to Knowledge Conflicts and Hallucinations in Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Vision language models (VLM) demonstrate sophisticated multimodal reasoning\nyet are prone to hallucination when confronted with knowledge conflicts,\nimpeding their deployment in information-sensitive contexts. While existing\nresearch addresses robustness in unimodal models, the multimodal domain lacks\nsystematic investigation of cross-modal knowledge conflicts. This research\nintroduces \\segsub, a framework for applying targeted image perturbations to\ninvestigate VLM resilience against knowledge conflicts. Our analysis reveals\ndistinct vulnerability patterns: while VLMs are robust to parametric conflicts\n(20% adherence rates), they exhibit significant weaknesses in identifying\ncounterfactual conditions (<30% accuracy) and resolving source conflicts (<1%\naccuracy). Correlations between contextual richness and hallucination rate (r =\n-0.368, p = 0.003) reveal the kinds of images that are likely to cause\nhallucinations. Through targeted fine-tuning on our benchmark dataset, we\ndemonstrate improvements in VLM knowledge conflict detection, establishing a\nfoundation for developing hallucination-resilient multimodal systems in\ninformation-sensitive environments.", "AI": {"tldr": "The paper introduces a framework to study VLM resilience against knowledge conflicts, revealing vulnerabilities and proposing improvements through fine-tuning.", "motivation": "Address the lack of systematic investigation of cross-modal knowledge conflicts in VLMs, which are prone to hallucination in information-sensitive contexts.", "method": "Introduces a framework (\\segsub) using targeted image perturbations to analyze VLM resilience against knowledge conflicts.", "result": "VLMs show robustness to parametric conflicts (20% adherence) but struggle with counterfactual conditions (<30% accuracy) and source conflicts (<1% accuracy). Contextual richness correlates with hallucination rates (r = -0.368, p = 0.003). Fine-tuning improves conflict detection.", "conclusion": "The study provides insights into VLM vulnerabilities and a foundation for developing hallucination-resilient systems in sensitive environments."}}
{"id": "2505.07818", "pdf": "https://arxiv.org/pdf/2505.07818", "abs": "https://arxiv.org/abs/2505.07818", "authors": ["Zeyue Xue", "Jie Wu", "Yu Gao", "Fangyuan Kong", "Lingting Zhu", "Mengzhao Chen", "Zhiheng Liu", "Wei Liu", "Qiushan Guo", "Weilin Huang", "Ping Luo"], "title": "DanceGRPO: Unleashing GRPO on Visual Generation", "categories": ["cs.CV"], "comment": "Project Page: https://dancegrpo.github.io/", "summary": "Recent breakthroughs in generative models-particularly diffusion models and\nrectified flows-have revolutionized visual content creation, yet aligning model\noutputs with human preferences remains a critical challenge. Existing\nreinforcement learning (RL)-based methods for visual generation face critical\nlimitations: incompatibility with modern Ordinary Differential Equations\n(ODEs)-based sampling paradigms, instability in large-scale training, and lack\nof validation for video generation. This paper introduces DanceGRPO, the first\nunified framework to adapt Group Relative Policy Optimization (GRPO) to visual\ngeneration paradigms, unleashing one unified RL algorithm across two generative\nparadigms (diffusion models and rectified flows), three tasks (text-to-image,\ntext-to-video, image-to-video), four foundation models (Stable Diffusion,\nHunyuanVideo, FLUX, SkyReel-I2V), and five reward models (image/video\naesthetics, text-image alignment, video motion quality, and binary reward). To\nour knowledge, DanceGRPO is the first RL-based unified framework capable of\nseamless adaptation across diverse generative paradigms, tasks, foundational\nmodels, and reward models. DanceGRPO demonstrates consistent and substantial\nimprovements, which outperform baselines by up to 181% on benchmarks such as\nHPS-v2.1, CLIP Score, VideoAlign, and GenEval. Notably, DanceGRPO not only can\nstabilize policy optimization for complex video generation, but also enables\ngenerative policy to better capture denoising trajectories for Best-of-N\ninference scaling and learn from sparse binary feedback. Our results establish\nDanceGRPO as a robust and versatile solution for scaling Reinforcement Learning\nfrom Human Feedback (RLHF) tasks in visual generation, offering new insights\ninto harmonizing reinforcement learning and visual synthesis. The code will be\nreleased.", "AI": {"tldr": "DanceGRPO is a unified RL framework for visual generation, compatible with diffusion models and rectified flows, improving performance by up to 181% across tasks like text-to-image and video generation.", "motivation": "Aligning generative model outputs with human preferences is challenging due to RL limitations like incompatibility with ODE-based sampling and instability in large-scale training.", "method": "DanceGRPO adapts Group Relative Policy Optimization (GRPO) to visual generation, unifying RL across generative paradigms, tasks, foundation models, and reward models.", "result": "Outperforms baselines by up to 181% on benchmarks like HPS-v2.1 and CLIP Score, stabilizing video generation and improving denoising trajectories.", "conclusion": "DanceGRPO is a robust solution for RLHF in visual generation, harmonizing RL and visual synthesis."}}
{"id": "2505.07664", "pdf": "https://arxiv.org/pdf/2505.07664", "abs": "https://arxiv.org/abs/2505.07664", "authors": ["Werner Geyer", "Jessica He", "Daita Sarkar", "Michelle Brachman", "Chris Hammond", "Jennifer Heins", "Zahra Ashktorab", "Carlos Rosemberg", "Charlie Hill"], "title": "A Case Study Investigating the Role of Generative AI in Quality Evaluations of Epics in Agile Software Development", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": null, "summary": "The broad availability of generative AI offers new opportunities to support\nvarious work domains, including agile software development. Agile epics are a\nkey artifact for product managers to communicate requirements to stakeholders.\nHowever, in practice, they are often poorly defined, leading to churn, delivery\ndelays, and cost overruns. In this industry case study, we investigate\nopportunities for large language models (LLMs) to evaluate agile epic quality\nin a global company. Results from a user study with 17 product managers\nindicate how LLM evaluations could be integrated into their work practices,\nincluding perceived values and usage in improving their epics. High levels of\nsatisfaction indicate that agile epics are a new, viable application of AI\nevaluations. However, our findings also outline challenges, limitations, and\nadoption barriers that can inform both practitioners and researchers on the\nintegration of such evaluations into future agile work practices.", "AI": {"tldr": "LLMs can evaluate agile epic quality, improving clarity and reducing issues like churn and delays, as shown in a study with 17 product managers.", "motivation": "Poorly defined agile epics cause churn, delays, and cost overruns, prompting exploration of LLMs for quality evaluation.", "method": "Industry case study involving user research with 17 product managers to assess LLM integration for epic evaluations.", "result": "High satisfaction among product managers, indicating viable AI application, but challenges and adoption barriers exist.", "conclusion": "LLMs show promise for agile epic evaluations, though further research is needed to address limitations and adoption hurdles."}}
{"id": "2505.07635", "pdf": "https://arxiv.org/pdf/2505.07635", "abs": "https://arxiv.org/abs/2505.07635", "authors": ["Dazhuo Qiu", "Haolai Che", "Arijit Khan", "Yinghui Wu"], "title": "Generating Skyline Explanations for Graph Neural Networks", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "This paper proposes a novel approach to generate subgraph explanations for\ngraph neural networks GNNs that simultaneously optimize multiple measures for\nexplainability. Existing GNN explanation methods often compute subgraphs\n(called ``explanatory subgraphs'') that optimize a pre-defined, single\nexplainability measure, such as fidelity or conciseness. This can lead to\nbiased explanations that cannot provide a comprehensive explanation to clarify\nthe output of GNN models. We introduce skyline explanation, a GNN explanation\nparadigm that aims to identify k explanatory subgraphs by simultaneously\noptimizing multiple explainability measures. (1) We formulate skyline\nexplanation generation as a multi-objective optimization problem, and pursue\nexplanations that approximate a skyline set of explanatory subgraphs. We show\nthe hardness for skyline explanation generation. (2) We design efficient\nalgorithms with an onion-peeling approach that strategically removes edges from\nneighbors of nodes of interests, and incrementally improves explanations as it\nexplores an interpretation domain, with provable quality guarantees. (3) We\nfurther develop an algorithm to diversify explanations to provide more\ncomprehensive perspectives. Using real-world graphs, we empirically verify the\neffectiveness, efficiency, and scalability of our algorithms.", "AI": {"tldr": "The paper introduces 'skyline explanation,' a novel GNN explanation method that optimizes multiple explainability measures simultaneously, addressing biases in single-measure approaches.", "motivation": "Existing GNN explanation methods focus on single measures (e.g., fidelity), leading to biased explanations. The paper aims to provide comprehensive explanations by optimizing multiple measures.", "method": "The approach formulates skyline explanation as a multi-objective optimization problem, designs efficient algorithms (onion-peeling and diversification), and ensures provable quality guarantees.", "result": "Empirical tests on real-world graphs confirm the method's effectiveness, efficiency, and scalability.", "conclusion": "Skyline explanation offers a more balanced and comprehensive way to explain GNN outputs by leveraging multi-objective optimization."}}
{"id": "2503.08980", "pdf": "https://arxiv.org/pdf/2503.08980", "abs": "https://arxiv.org/abs/2503.08980", "authors": ["Yuhang Liu", "Dong Gong", "Yichao Cai", "Erdun Gao", "Zhen Zhang", "Biwei Huang", "Mingming Gong", "Anton van den Hengel", "Javen Qinfeng Shi"], "title": "I Predict Therefore I Am: Is Next Token Prediction Enough to Learn Human-Interpretable Concepts from Data?", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The remarkable achievements of large language models (LLMs) have led many to\nconclude that they exhibit a form of intelligence. This is as opposed to\nexplanations of their capabilities based on their ability to perform relatively\nsimple manipulations of vast volumes of data. To illuminate the distinction\nbetween these explanations, we introduce a novel generative model that\ngenerates tokens on the basis of human-interpretable concepts represented as\nlatent discrete variables. Under mild conditions, even when the mapping from\nthe latent space to the observed space is non-invertible, we establish an\nidentifiability result, i.e., the representations learned by LLMs through\nnext-token prediction can be approximately modeled as the logarithm of the\nposterior probabilities of these latent discrete concepts given input context,\nup to an invertible linear transformation. This theoretical finding not only\nprovides evidence that LLMs capture underlying generative factors, but also\nprovide a unified prospective for understanding of the linear representation\nhypothesis. Taking this a step further, our finding motivates a reliable\nevaluation of sparse autoencoders by treating the performance of supervised\nconcept extractors as an upper bound. Pushing this idea even further, it\ninspires a structural variant that enforces dependence among latent concepts in\naddition to promoting sparsity. Empirically, we validate our theoretical\nresults through evaluations on both simulation data and the Pythia, Llama, and\nDeepSeek model families, and demonstrate the effectiveness of our structured\nsparse autoencoder.", "AI": {"tldr": "The paper introduces a generative model to analyze LLMs, showing their representations align with latent concepts, and proposes a structured sparse autoencoder for evaluation.", "motivation": "To clarify whether LLMs exhibit intelligence or just manipulate data, and to understand their underlying generative factors.", "method": "A novel generative model using latent discrete variables, validated with identifiability results and empirical tests on LLMs like Pythia, Llama, and DeepSeek.", "result": "LLMs' representations approximate latent concept probabilities, supporting the linear representation hypothesis. The structured sparse autoencoder proves effective.", "conclusion": "The study provides theoretical and empirical evidence that LLMs capture generative factors, offering a framework for understanding and evaluating their representations."}}
{"id": "2505.06285", "pdf": "https://arxiv.org/pdf/2505.06285", "abs": "https://arxiv.org/abs/2505.06285", "authors": ["Yuhan Yuan", "Xiaomo Jiang", "Yanfeng Han", "Ke Xiao"], "title": "FEMSN: Frequency-Enhanced Multiscale Network for fault diagnosis of rotating machinery under strong noise environments", "categories": ["eess.SP", "cs.CV"], "comment": null, "summary": "Rolling bearings are critical components of rotating machinery, and their\nproper functioning is essential for industrial production. Most existing\ncondition monitoring methods focus on extracting discriminative features from\ntime-domain signals to assess bearing health status. However, under complex\noperating conditions, periodic impulsive characteristics related to fault\ninformation are often obscured by noise interference. Consequently, existing\napproaches struggle to learn distinctive fault-related features in such\nscenarios. To address this issue, this paper proposes a novel CNN-based model\nnamed FEMSN. Specifically, a Fourier Adaptive Denoising Encoder Layer (FADEL)\nis introduced as an input denoising layer to enhance key features while\nfiltering out irrelevant information. Subsequently, a Multiscale Time-Frequency\nFusion (MSTFF) module is employed to extract fused time-frequency features,\nfurther improving the model robustness and nonlinear representation capability.\nAdditionally, a distillation layer is incorporated to expand the receptive\nfield. Based on these advancements, a novel deep lightweight CNN model, termed\nthe Frequency-Enhanced Multiscale Network (FEMSN), is developed. The\neffectiveness of FEMSN and FADEL in machine health monitoring and stability\nassessment is validated through two case studies.", "AI": {"tldr": "The paper proposes FEMSN, a CNN-based model with a Fourier Adaptive Denoising Encoder Layer (FADEL) and Multiscale Time-Frequency Fusion (MSTFF) to improve bearing fault detection under noisy conditions.", "motivation": "Existing methods struggle to extract fault-related features under noise interference in bearing condition monitoring.", "method": "Introduces FADEL for denoising and MSTFF for time-frequency feature fusion, enhancing robustness and representation.", "result": "FEMSN and FADEL are validated through case studies for effective health monitoring.", "conclusion": "The proposed FEMSN model improves fault detection in noisy environments, enhancing industrial bearing monitoring."}}
{"id": "2505.07675", "pdf": "https://arxiv.org/pdf/2505.07675", "abs": "https://arxiv.org/abs/2505.07675", "authors": ["Seongjae Kang", "Dong Bok Lee", "Hyungjoon Jang", "Sung Ju Hwang"], "title": "Simple Semi-supervised Knowledge Distillation from Vision-Language Models via $\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead $\\mathbf{\\texttt{O}}$ptimization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "41 pages, 19 figures, preprint", "summary": "Vision-language models (VLMs) have achieved remarkable success across diverse\ntasks by leveraging rich textual information with minimal labeled data.\nHowever, deploying such large models remains challenging, particularly in\nresource-constrained environments. Knowledge distillation (KD) offers a\nwell-established solution to this problem; however, recent KD approaches from\nVLMs often involve multi-stage training or additional tuning, increasing\ncomputational overhead and optimization complexity. In this paper, we propose\n$\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead\n$\\mathbf{\\texttt{O}}$ptimization ($\\mathbf{\\texttt{DHO}}$) -- a simple yet\neffective KD framework that transfers knowledge from VLMs to compact,\ntask-specific models in semi-supervised settings. Specifically, we introduce\ndual prediction heads that independently learn from labeled data and teacher\npredictions, and propose to linearly combine their outputs during inference. We\nobserve that $\\texttt{DHO}$ mitigates gradient conflicts between supervised and\ndistillation signals, enabling more effective feature learning than single-head\nKD baselines. As a result, extensive experiments show that $\\texttt{DHO}$\nconsistently outperforms baselines across multiple domains and fine-grained\ndatasets. Notably, on ImageNet, it achieves state-of-the-art performance,\nimproving accuracy by 3% and 0.1% with 1% and 10% labeled data, respectively,\nwhile using fewer parameters.", "AI": {"tldr": "DHO is a simple yet effective KD framework for transferring VLM knowledge to compact models, outperforming baselines with fewer parameters.", "motivation": "Deploying large VLMs in resource-constrained environments is challenging; existing KD methods are complex and computationally heavy.", "method": "Introduces dual prediction heads for learning from labeled data and teacher predictions, combining outputs linearly during inference.", "result": "DHO outperforms baselines, achieving SOTA on ImageNet with 3% and 0.1% accuracy improvements for 1% and 10% labeled data.", "conclusion": "DHO effectively mitigates gradient conflicts, enabling efficient knowledge transfer and superior performance."}}
{"id": "2505.07674", "pdf": "https://arxiv.org/pdf/2505.07674", "abs": "https://arxiv.org/abs/2505.07674", "authors": ["Nan Jiang", "Wenxuan Zhu", "Xu Han", "Weiqiang Huang", "Yumeng Sun"], "title": "Joint Graph Convolution and Sequential Modeling for Scalable Network Traffic Estimation", "categories": ["cs.LG"], "comment": null, "summary": "This study focuses on the challenge of predicting network traffic within\ncomplex topological environments. It introduces a spatiotemporal modeling\napproach that integrates Graph Convolutional Networks (GCN) with Gated\nRecurrent Units (GRU). The GCN component captures spatial dependencies among\nnetwork nodes, while the GRU component models the temporal evolution of traffic\ndata. This combination allows for precise forecasting of future traffic\npatterns. The effectiveness of the proposed model is validated through\ncomprehensive experiments on the real-world Abilene network traffic dataset.\nThe model is benchmarked against several popular deep learning methods.\nFurthermore, a set of ablation experiments is conducted to examine the\ninfluence of various components on performance, including changes in the number\nof graph convolution layers, different temporal modeling strategies, and\nmethods for constructing the adjacency matrix. Results indicate that the\nproposed approach achieves superior performance across multiple metrics,\ndemonstrating robust stability and strong generalization capabilities in\ncomplex network traffic forecasting scenarios.", "AI": {"tldr": "A spatiotemporal model combining GCN and GRU for network traffic prediction, validated on the Abilene dataset, outperforms other methods.", "motivation": "Addressing the challenge of predicting network traffic in complex topological environments.", "method": "Integrates Graph Convolutional Networks (GCN) for spatial dependencies and Gated Recurrent Units (GRU) for temporal evolution.", "result": "Superior performance in traffic forecasting, validated through experiments and ablation studies.", "conclusion": "The model is robust, stable, and generalizes well in complex scenarios."}}
{"id": "2504.01382", "pdf": "https://arxiv.org/pdf/2504.01382", "abs": "https://arxiv.org/abs/2504.01382", "authors": ["Tianci Xue", "Weijian Qi", "Tianneng Shi", "Chan Hee Song", "Boyu Gou", "Dawn Song", "Huan Sun", "Yu Su"], "title": "An Illusion of Progress? Assessing the Current State of Web Agents", "categories": ["cs.AI", "cs.CL"], "comment": "22 pages, 17 figures, 7 tables", "summary": "As digitalization and cloud technologies evolve, the web is becoming\nincreasingly important in the modern society. Autonomous web agents based on\nlarge language models (LLMs) hold a great potential in work automation. It is\ntherefore important to accurately measure and monitor the progression of their\ncapabilities. In this work, we conduct a comprehensive and rigorous assessment\nof the current state of web agents. Our results depict a very different picture\nof the competency of current agents, suggesting over-optimism in previously\nreported results. This gap can be attributed to shortcomings in existing\nbenchmarks. We introduce Online-Mind2Web, an online evaluation benchmark\nconsisting of 300 diverse and realistic tasks spanning 136 websites. It enables\nus to evaluate web agents under a setting that approximates how real users use\nthese agents. To facilitate more scalable evaluation and development, we also\ndevelop a novel LLM-as-a-Judge automatic evaluation method and show that it can\nachieve around 85% agreement with human judgment, substantially higher than\nexisting methods. Finally, we present the first comprehensive comparative\nanalysis of current web agents, highlighting both their strengths and\nlimitations to inspire future research.", "AI": {"tldr": "The paper evaluates web agents' capabilities, revealing over-optimism in prior results due to flawed benchmarks, and introduces Online-Mind2Web for realistic testing and an LLM-as-a-Judge method for scalable evaluation.", "motivation": "To accurately measure and monitor the progression of autonomous web agents based on LLMs, given their growing importance in work automation.", "method": "Conducts a comprehensive assessment using Online-Mind2Web, a benchmark with 300 diverse tasks, and introduces an LLM-as-a-Judge method for evaluation.", "result": "Current web agents' competency is overestimated; the new benchmark and evaluation method achieve 85% agreement with human judgment.", "conclusion": "The study provides a realistic evaluation framework and highlights gaps in current web agents, guiding future research."}}
{"id": "2505.06483", "pdf": "https://arxiv.org/pdf/2505.06483", "abs": "https://arxiv.org/abs/2505.06483", "authors": ["Shehryar Khattak", "Timon Homberger", "Lukas Bernreiter", "Julian Nubert", "Olov Andersson", "Roland Siegwart", "Kostas Alexis", "Marco Hutter"], "title": "CompSLAM: Complementary Hierarchical Multi-Modal Localization and Mapping for Robot Autonomy in Underground Environments", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 9 figures, Code:\n  https://github.com/leggedrobotics/compslam_subt", "summary": "Robot autonomy in unknown, GPS-denied, and complex underground environments\nrequires real-time, robust, and accurate onboard pose estimation and mapping\nfor reliable operations. This becomes particularly challenging in\nperception-degraded subterranean conditions under harsh environmental factors,\nincluding darkness, dust, and geometrically self-similar structures. This paper\ndetails CompSLAM, a highly resilient and hierarchical multi-modal localization\nand mapping framework designed to address these challenges. Its flexible\narchitecture achieves resilience through redundancy by leveraging the\ncomplementary nature of pose estimates derived from diverse sensor modalities.\nDeveloped during the DARPA Subterranean Challenge, CompSLAM was successfully\ndeployed on all aerial, legged, and wheeled robots of Team Cerberus during\ntheir competition-winning final run. Furthermore, it has proven to be a\nreliable odometry and mapping solution in various subsequent projects, with\nextensions enabling multi-robot map sharing for marsupial robotic deployments\nand collaborative mapping. This paper also introduces a comprehensive dataset\nacquired by a manually teleoperated quadrupedal robot, covering a significant\nportion of the DARPA Subterranean Challenge finals course. This dataset\nevaluates CompSLAM's robustness to sensor degradations as the robot traverses\n740 meters in an environment characterized by highly variable geometries and\ndemanding lighting conditions. The CompSLAM code and the DARPA SubT Finals\ndataset are made publicly available for the benefit of the robotics community", "AI": {"tldr": "CompSLAM is a resilient, multi-modal SLAM framework for GPS-denied underground environments, tested successfully in the DARPA Subterranean Challenge and extended for multi-robot applications.", "motivation": "Addressing the challenge of real-time, robust pose estimation and mapping in harsh underground conditions like darkness, dust, and self-similar structures.", "method": "Hierarchical multi-modal framework leveraging diverse sensor modalities for redundancy and resilience.", "result": "Successfully deployed on various robots, winning the DARPA challenge, and proven reliable in subsequent projects. A dataset validates its robustness.", "conclusion": "CompSLAM is a robust solution for underground autonomy, with public code and dataset to benefit the robotics community."}}
{"id": "2505.07683", "pdf": "https://arxiv.org/pdf/2505.07683", "abs": "https://arxiv.org/abs/2505.07683", "authors": ["Steven Song", "Morgan Borjigin-Wang", "Irene Madejski", "Robert L. Grossman"], "title": "Multimodal Survival Modeling in the Age of Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 7 figures, 8 tables", "summary": "The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a\nlarge-scale reference through its harmonized genomics, clinical, and image\ndata. Prior studies have trained bespoke cancer survival prediction models from\nunimodal or multimodal TCGA data. A modern paradigm in biomedical deep learning\nis the development of foundation models (FMs) to derive meaningful feature\nembeddings, agnostic to a specific modeling task. Biomedical text especially\nhas seen growing development of FMs. While TCGA contains free-text data as\npathology reports, these have been historically underutilized. Here, we\ninvestigate the feasibility of training classical, multimodal survival models\nover zero-shot embeddings extracted by FMs. We show the ease and additive\neffect of multimodal fusion, outperforming unimodal models. We demonstrate the\nbenefit of including pathology report text and rigorously evaluate the effect\nof model-based text summarization and hallucination. Overall, we modernize\nsurvival modeling by leveraging FMs and information extraction from pathology\nreports.", "AI": {"tldr": "The paper explores using foundation models (FMs) for zero-shot embeddings in multimodal survival prediction, outperforming unimodal models by leveraging TCGA's pathology reports.", "motivation": "To modernize survival modeling by utilizing underused free-text pathology reports in TCGA and leveraging FMs for feature extraction.", "method": "Training classical, multimodal survival models using zero-shot embeddings from FMs, including pathology reports, and evaluating text summarization and hallucination effects.", "result": "Multimodal fusion with FM-derived embeddings outperforms unimodal models, demonstrating the additive benefit of pathology report text.", "conclusion": "The study successfully modernizes survival modeling by integrating FMs and pathology report data, highlighting their untapped potential."}}
{"id": "2505.07680", "pdf": "https://arxiv.org/pdf/2505.07680", "abs": "https://arxiv.org/abs/2505.07680", "authors": ["Hang Wu", "Jianian Zhu", "Yinghui Li", "Haojie Wang", "Biao Hou", "Jidong Zhai"], "title": "SpecRouter: Adaptive Routing for Multi-Level Speculative Decoding in Large Language Models", "categories": ["cs.LG", "cs.DC"], "comment": "10 pages", "summary": "Large Language Models (LLMs) present a critical trade-off between inference\nquality and computational cost: larger models offer superior capabilities but\nincur significant latency, while smaller models are faster but less powerful.\nExisting serving strategies often employ fixed model scales or static two-stage\nspeculative decoding, failing to dynamically adapt to the varying complexities\nof user requests or fluctuations in system performance. This paper introduces\n\\systemname{}, a novel framework that reimagines LLM inference as an adaptive\nrouting problem solved through multi-level speculative decoding. \\systemname{}\ndynamically constructs and optimizes inference \"paths\" (chains of models) based\non real-time feedback, addressing the limitations of static approaches. Our\ncontributions are threefold: (1) An \\textbf{adaptive model chain scheduling}\nmechanism that leverages performance profiling (execution times) and predictive\nsimilarity metrics (derived from token distribution divergence) to continuously\nselect the optimal sequence of draft and verifier models, minimizing predicted\nlatency per generated token. (2) A \\textbf{multi-level collaborative\nverification} framework where intermediate models within the selected chain can\nvalidate speculative tokens, reducing the verification burden on the final,\nmost powerful target model. (3) A \\textbf{synchronized state management} system\nproviding efficient, consistent KV cache handling across heterogeneous models\nin the chain, including precise, low-overhead rollbacks tailored for\nasynchronous batch processing inherent in multi-level speculation. Preliminary\nexperiments demonstrate the validity of our method.", "AI": {"tldr": "The paper introduces \\systemname{}, a framework for adaptive routing in LLM inference using multi-level speculative decoding to balance quality and cost dynamically.", "motivation": "Existing LLM serving strategies lack adaptability to varying request complexities and system performance, leading to inefficiencies.", "method": "\\systemname{} employs adaptive model chain scheduling, multi-level collaborative verification, and synchronized state management to optimize inference paths.", "result": "Preliminary experiments show the framework's effectiveness in dynamically optimizing LLM inference.", "conclusion": "\\systemname{} addresses the limitations of static approaches, offering a scalable and efficient solution for LLM serving."}}
{"id": "2504.07840", "pdf": "https://arxiv.org/pdf/2504.07840", "abs": "https://arxiv.org/abs/2504.07840", "authors": ["Cansu Koyuturk", "Emily Theophilou", "Sabrina Patania", "Gregor Donabauer", "Andrea Martinenghi", "Chiara Antico", "Alessia Telari", "Alessia Testa", "Sathya Bursic", "Franca Garzotto", "Davinia Hernandez-Leo", "Udo Kruschwitz", "Davide Taibi", "Simona Amenta", "Martin Ruskov", "Dimitri Ognibene"], "title": "Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "Accepted for AIED 2025, the 26th International Conference on\n  Artificial Intelligence in Education, July 22 - 26, 2025, Palermo, Italy", "summary": "Large Language Models (LLMs) have transformed human-computer interaction by\nenabling natural language-based communication with AI-powered chatbots. These\nmodels are designed to be intuitive and user-friendly, allowing users to\narticulate requests with minimal effort. However, despite their accessibility,\nstudies reveal that users often struggle with effective prompting, resulting in\ninefficient responses. Existing research has highlighted both the limitations\nof LLMs in interpreting vague or poorly structured prompts and the difficulties\nusers face in crafting precise queries. This study investigates learner-AI\ninteractions through an educational experiment in which participants receive\nstructured guidance on effective prompting. We introduce and compare three\ntypes of prompting guidelines: a task-specific framework developed through a\nstructured methodology and two baseline approaches. To assess user behavior and\nprompting efficacy, we analyze a dataset of 642 interactions from 107 users.\nUsing Von NeuMidas, an extended pragmatic annotation schema for LLM interaction\nanalysis, we categorize common prompting errors and identify recurring\nbehavioral patterns. We then evaluate the impact of different guidelines by\nexamining changes in user behavior, adherence to prompting strategies, and the\noverall quality of AI-generated responses. Our findings provide a deeper\nunderstanding of how users engage with LLMs and the role of structured\nprompting guidance in enhancing AI-assisted communication. By comparing\ndifferent instructional frameworks, we offer insights into more effective\napproaches for improving user competency in AI interactions, with implications\nfor AI literacy, chatbot usability, and the design of more responsive AI\nsystems.", "AI": {"tldr": "The paper explores how structured prompting guidance improves user interactions with LLMs, comparing three methods and analyzing 642 interactions to identify errors and behavioral patterns.", "motivation": "Users often struggle with effective prompting for LLMs, leading to inefficient responses. The study aims to understand how structured guidance can enhance AI-assisted communication.", "method": "An educational experiment with 107 users, comparing three prompting guidelines (task-specific framework and two baselines), analyzed using Von NeuMidas schema.", "result": "Findings reveal common prompting errors, behavioral patterns, and the impact of structured guidance on user behavior and response quality.", "conclusion": "Structured prompting improves user competency in AI interactions, with implications for AI literacy, chatbot usability, and responsive AI design."}}
{"id": "2505.06746", "pdf": "https://arxiv.org/pdf/2505.06746", "abs": "https://arxiv.org/abs/2505.06746", "authors": ["Morui Zhu", "Yongqi Zhu", "Yihao Zhu", "Qi Chen", "Deyuan Qu", "Song Fu", "Qing Yang"], "title": "M3CAD: Towards Generic Cooperative Autonomous Driving Benchmark", "categories": ["cs.RO", "cs.CV", "I.2.10; I.2.9"], "comment": "supplementary material included", "summary": "We introduce M$^3$CAD, a novel benchmark designed to advance research in\ngeneric cooperative autonomous driving. M$^3$CAD comprises 204 sequences with\n30k frames, spanning a diverse range of cooperative driving scenarios. Each\nsequence includes multiple vehicles and sensing modalities, e.g., LiDAR point\nclouds, RGB images, and GPS/IMU, supporting a variety of autonomous driving\ntasks, including object detection and tracking, mapping, motion forecasting,\noccupancy prediction, and path planning. This rich multimodal setup enables\nM$^3$CAD to support both single-vehicle and multi-vehicle autonomous driving\nresearch, significantly broadening the scope of research in the field. To our\nknowledge, M$^3$CAD is the most comprehensive benchmark specifically tailored\nfor cooperative multi-task autonomous driving research. We evaluate the\nstate-of-the-art end-to-end solution on M$^3$CAD to establish baseline\nperformance. To foster cooperative autonomous driving research, we also propose\nE2EC, a simple yet effective framework for cooperative driving solution that\nleverages inter-vehicle shared information for improved path planning. We\nrelease M$^3$CAD, along with our baseline models and evaluation results, to\nsupport the development of robust cooperative autonomous driving systems. All\nresources will be made publicly available on https://github.com/zhumorui/M3CAD", "AI": {"tldr": "M$^3$CAD is a comprehensive benchmark for cooperative autonomous driving, featuring diverse scenarios and multimodal data. It supports various tasks and introduces E2EC, a cooperative driving framework.", "motivation": "To advance research in cooperative autonomous driving by providing a rich, multimodal benchmark and a simple yet effective framework (E2EC).", "method": "Developed M$^3$CAD with 204 sequences (30k frames) including LiDAR, RGB, and GPS/IMU data. Proposed E2EC for cooperative path planning.", "result": "M$^3$CAD is the most comprehensive benchmark for cooperative multi-task autonomous driving. Baseline performance is established using state-of-the-art methods.", "conclusion": "M$^3$CAD and E2EC aim to foster robust cooperative autonomous driving research, with all resources made publicly available."}}
{"id": "2505.07711", "pdf": "https://arxiv.org/pdf/2505.07711", "abs": "https://arxiv.org/abs/2505.07711", "authors": ["Pranav Sinha", "Sumit Kumar Jha", "Sunny Raj"], "title": "Circuit Partitioning Using Large Language Models for Quantum Compilation and Simulations", "categories": ["cs.ET", "cs.AI", "quant-ph"], "comment": "7 pages, 2 tables and 3 figures", "summary": "We are in the midst of the noisy intermediate-scale quantum (NISQ) era, where\nquantum computers are limited by noisy gates, some of which are more\nerror-prone than others and can render the final computation incomprehensible.\nQuantum circuit compilation algorithms attempt to minimize these noisy gates\nwhen mapping quantum algorithms onto quantum hardware but face computational\nchallenges that restrict their application to circuits with no more than 5-6\nqubits, necessitating the need to partition large circuits before the\napplication of noisy quantum gate minimization algorithms. The existing\ngeneration of these algorithms is heuristic in nature and does not account for\ndownstream gate minimization tasks. Large language models (LLMs) have the\npotential to change this and help improve quantum circuit partitions. This\npaper investigates the use of LLMs, such as Llama and Mistral, for partitioning\nquantum circuits by capitalizing on their abilities to understand and generate\ncode, including QASM. Specifically, we teach LLMs to partition circuits using\nthe quick partition approach of the Berkeley Quantum Synthesis Toolkit. Through\nexperimental evaluations, we show that careful fine-tuning of open source LLMs\nenables us to obtain an accuracy of 53.4% for the partition task while\nover-the-shelf LLMs are unable to correctly partition circuits, using standard\n1-shot and few-shot training approaches.", "AI": {"tldr": "The paper explores using LLMs like Llama and Mistral to partition quantum circuits, improving accuracy to 53.4% with fine-tuning, while standard LLMs fail.", "motivation": "Address the challenge of noisy gates in NISQ-era quantum computers by improving quantum circuit partitioning for better gate minimization.", "method": "Fine-tune open-source LLMs to partition circuits using the Berkeley Quantum Synthesis Toolkit's quick partition approach.", "result": "Fine-tuned LLMs achieve 53.4% accuracy in partitioning, outperforming standard LLMs.", "conclusion": "LLMs show promise for quantum circuit partitioning, but further refinement is needed."}}
{"id": "2505.07702", "pdf": "https://arxiv.org/pdf/2505.07702", "abs": "https://arxiv.org/abs/2505.07702", "authors": ["Onthada Preedasawakul", "Nathakhun Wiroonsri"], "title": "4TaStiC: Time and trend traveling time series clustering for classifying long-term type 2 diabetes patients", "categories": ["cs.LG", "cs.CY", "62H30 (Primary) 62M10, 92C50 (Secondary)"], "comment": null, "summary": "Diabetes is one of the most prevalent diseases worldwide, characterized by\npersistently high blood sugar levels, capable of damaging various internal\norgans and systems. Diabetes patients require routine check-ups, resulting in a\ntime series of laboratory records, such as hemoglobin A1c, which reflects each\npatient's health behavior over time and informs their doctor's recommendations.\nClustering patients into groups based on their entire time series data assists\ndoctors in making recommendations and choosing treatments without the need to\nreview all records. However, time series clustering of this type of dataset\nintroduces some challenges; patients visit their doctors at different time\npoints, making it difficult to capture and match trends, peaks, and patterns.\nAdditionally, two aspects must be considered: differences in the levels of\nlaboratory results and differences in trends and patterns. To address these\nchallenges, we introduce a new clustering algorithm called Time and Trend\nTraveling Time Series Clustering (4TaStiC), using a base dissimilarity measure\ncombined with Euclidean and Pearson correlation metrics. We evaluated this\nalgorithm on artificial datasets, comparing its performance with that of seven\nexisting methods. The results show that 4TaStiC outperformed the other methods\non the targeted datasets. Finally, we applied 4TaStiC to cluster a cohort of\n1,989 type 2 diabetes patients at Siriraj Hospital. Each group of patients\nexhibits clear characteristics that will benefit doctors in making efficient\nclinical decisions. Furthermore, the proposed algorithm can be applied to\ncontexts outside the medical field.", "AI": {"tldr": "A new clustering algorithm, 4TaStiC, is introduced to group diabetes patients based on time series lab data, addressing challenges like irregular visits and combining level and trend differences. It outperforms existing methods and aids clinical decisions.", "motivation": "Diabetes patients' lab data is irregular and complex, making clustering challenging. Existing methods fail to account for both level and trend differences in time series data.", "method": "4TaStiC combines Euclidean and Pearson correlation metrics for dissimilarity measurement, tested on artificial datasets and applied to 1,989 diabetes patients.", "result": "4TaStiC outperformed seven existing methods on targeted datasets and effectively clustered patients into groups with clear clinical characteristics.", "conclusion": "4TaStiC is effective for clustering irregular time series data, aiding clinical decisions, and has potential applications beyond medicine."}}
{"id": "2504.18988", "pdf": "https://arxiv.org/pdf/2504.18988", "abs": "https://arxiv.org/abs/2504.18988", "authors": ["Saramsh Gautam", "Mahmood Jasim"], "title": "LINC: Supporting Language Independent Communication and Comprehension to Enhance Contribution in Multilingual Collaborative Meetings", "categories": ["cs.HC", "cs.CL", "H.5.3"], "comment": "The manuscript has been withdrawn by the authors due to ongoing\n  revisions and substantial updates", "summary": "Collaborative research often includes contributors with varied perspectives\nfrom diverse linguistic backgrounds. However, English as a Second Language\n(ESL) researchers often struggle to communicate during meetings in English and\ncomprehend discussions, leading to limited contribution. To investigate these\nchallenges, we surveyed 64 ESL researchers who frequently collaborate in\nmultilingual teams and identified four key design goals around participation,\ncomprehension, documentation, and feedback. Guided by these design goals, we\ndeveloped LINC, a multimodal Language INdependent Collaboration system with two\ncomponents: a real-time module for multilingual communication during meetings\nand a post-meeting dashboard for discussion analysis. We evaluated the system\nthrough a two-phased study with six triads of multilingual teams. We found that\nusing LINC, participants benefited from communicating in their preferred\nlanguage, recalled and reviewed actionable insights, and prepared for upcoming\nmeetings effectively. We discuss external factors that impact multilingual\nmeeting participation beyond language preferences and the implications of\nmultimodal systems in facilitating meetings in hybrid multilingual\ncollaborative settings beyond research.", "AI": {"tldr": "LINC, a multimodal system, aids ESL researchers in multilingual meetings by enabling real-time communication and post-meeting analysis, improving participation and comprehension.", "motivation": "ESL researchers face challenges in multilingual meetings, limiting their contributions due to language barriers.", "method": "Surveyed 64 ESL researchers, identified design goals, and developed LINC with real-time and post-meeting modules. Evaluated with six multilingual teams.", "result": "LINC improved communication, recall of insights, and meeting preparation for participants.", "conclusion": "LINC addresses language barriers in multilingual meetings, with broader implications for hybrid collaboration."}}
{"id": "2505.07728", "pdf": "https://arxiv.org/pdf/2505.07728", "abs": "https://arxiv.org/abs/2505.07728", "authors": ["Lihan Zha", "Apurva Badithela", "Michael Zhang", "Justin Lidard", "Jeremy Bao", "Emily Zhou", "David Snyder", "Allen Z. Ren", "Dhruv Shah", "Anirudha Majumdar"], "title": "Guiding Data Collection via Factored Scaling Curves", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Project website: https://factored-data-scaling.github.io", "summary": "Generalist imitation learning policies trained on large datasets show great\npromise for solving diverse manipulation tasks. However, to ensure\ngeneralization to different conditions, policies need to be trained with data\ncollected across a large set of environmental factor variations (e.g., camera\npose, table height, distractors) $-$ a prohibitively expensive undertaking, if\ndone exhaustively. We introduce a principled method for deciding what data to\ncollect and how much to collect for each factor by constructing factored\nscaling curves (FSC), which quantify how policy performance varies as data\nscales along individual or paired factors. These curves enable targeted data\nacquisition for the most influential factor combinations within a given budget.\nWe evaluate the proposed method through extensive simulated and real-world\nexperiments, across both training-from-scratch and fine-tuning settings, and\nshow that it boosts success rates in real-world tasks in new environments by up\nto 26% over existing data-collection strategies. We further demonstrate how\nfactored scaling curves can effectively guide data collection using an offline\nmetric, without requiring real-world evaluation at scale.", "AI": {"tldr": "The paper introduces factored scaling curves (FSC) to optimize data collection for imitation learning policies, improving generalization without exhaustive data acquisition.", "motivation": "Generalist imitation learning policies require diverse data for generalization, but exhaustive data collection is costly. The paper aims to address this by identifying influential factors for targeted data collection.", "method": "The method involves constructing factored scaling curves (FSC) to quantify policy performance variations across environmental factors. These curves guide efficient data collection within budget constraints.", "result": "Experiments show FSC boosts success rates by up to 26% in new environments compared to existing strategies, and it works for both training-from-scratch and fine-tuning.", "conclusion": "Factored scaling curves effectively guide data collection, improving policy generalization and reducing the need for exhaustive real-world evaluation."}}
{"id": "2505.07735", "pdf": "https://arxiv.org/pdf/2505.07735", "abs": "https://arxiv.org/abs/2505.07735", "authors": ["Nicholas T. Runcie", "Charlotte M. Deane", "Fergus Imrie"], "title": "Assessing the Chemical Intelligence of Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models are versatile, general-purpose tools with a wide range\nof applications. Recently, the advent of \"reasoning models\" has led to\nsubstantial improvements in their abilities in advanced problem-solving domains\nsuch as mathematics and software engineering. In this work, we assessed the\nability of reasoning models to directly perform chemistry tasks, without any\nassistance from external tools. We created a novel benchmark, called ChemIQ,\nwhich consists of 796 questions assessing core concepts in organic chemistry,\nfocused on molecular comprehension and chemical reasoning. Unlike previous\nbenchmarks, which primarily use multiple choice formats, our approach requires\nmodels to construct short-answer responses, more closely reflecting real-world\napplications. The reasoning models, exemplified by OpenAI's o3-mini, correctly\nanswered 28%-59% of questions depending on the reasoning level used, with\nhigher reasoning levels significantly increasing performance on all tasks.\nThese models substantially outperformed the non-reasoning model, GPT-4o, which\nachieved only 7% accuracy. We found that Large Language Models can now convert\nSMILES strings to IUPAC names, a task earlier models were unable to perform.\nAdditionally, we show that the latest reasoning models can elucidate structures\nfrom 1H and 13C NMR data, correctly generating SMILES strings for 74% of\nmolecules containing up to 10 heavy atoms, and in one case solving a structure\ncomprising 21 heavy atoms. For each task, we found evidence that the reasoning\nprocess mirrors that of a human chemist. Our results demonstrate that the\nlatest reasoning models have the ability to perform advanced chemical\nreasoning.", "AI": {"tldr": "Reasoning models like OpenAI's o3-mini outperform non-reasoning models (e.g., GPT-4o) in chemistry tasks, achieving 28%-59% accuracy on the ChemIQ benchmark, which tests organic chemistry concepts through short-answer responses.", "motivation": "To evaluate the capability of reasoning models in performing advanced chemistry tasks without external tools, addressing a gap in benchmarks that rely on multiple-choice formats.", "method": "Created the ChemIQ benchmark with 796 questions on organic chemistry, requiring short-answer responses. Tested reasoning models (e.g., o3-mini) and non-reasoning models (e.g., GPT-4o).", "result": "Reasoning models achieved 28%-59% accuracy, significantly outperforming GPT-4o (7%). They excelled in tasks like SMILES-to-IUPAC conversion and NMR data interpretation.", "conclusion": "Latest reasoning models exhibit advanced chemical reasoning abilities, mirroring human chemist processes, and show promise for real-world applications."}}
{"id": "2504.20879", "pdf": "https://arxiv.org/pdf/2504.20879", "abs": "https://arxiv.org/abs/2504.20879", "authors": ["Shivalika Singh", "Yiyang Nan", "Alex Wang", "Daniel D'Souza", "Sayash Kapoor", "Ahmet \u00dcst\u00fcn", "Sanmi Koyejo", "Yuntian Deng", "Shayne Longpre", "Noah A. Smith", "Beyza Ermis", "Marzieh Fadaee", "Sara Hooker"], "title": "The Leaderboard Illusion", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ME"], "comment": "68 pages, 18 figures, 9 tables", "summary": "Measuring progress is fundamental to the advancement of any scientific field.\nAs benchmarks play an increasingly central role, they also grow more\nsusceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard\nfor ranking the most capable AI systems. Yet, in this work we identify\nsystematic issues that have resulted in a distorted playing field. We find that\nundisclosed private testing practices benefit a handful of providers who are\nable to test multiple variants before public release and retract scores if\ndesired. We establish that the ability of these providers to choose the best\nscore leads to biased Arena scores due to selective disclosure of performance\nresults. At an extreme, we identify 27 private LLM variants tested by Meta in\nthe lead-up to the Llama-4 release. We also establish that proprietary closed\nmodels are sampled at higher rates (number of battles) and have fewer models\nremoved from the arena than open-weight and open-source alternatives. Both\nthese policies lead to large data access asymmetries over time. Providers like\nGoogle and OpenAI have received an estimated 19.2% and 20.4% of all data on the\narena, respectively. In contrast, a combined 83 open-weight models have only\nreceived an estimated 29.7% of the total data. We show that access to Chatbot\nArena data yields substantial benefits; even limited additional data can result\nin relative performance gains of up to 112% on the arena distribution, based on\nour conservative estimates. Together, these dynamics result in overfitting to\nArena-specific dynamics rather than general model quality. The Arena builds on\nthe substantial efforts of both the organizers and an open community that\nmaintains this valuable evaluation platform. We offer actionable\nrecommendations to reform the Chatbot Arena's evaluation framework and promote\nfairer, more transparent benchmarking for the field", "AI": {"tldr": "The paper highlights systematic biases in Chatbot Arena's leaderboard due to undisclosed private testing, selective disclosure, and data access asymmetries, favoring proprietary models over open-source ones.", "motivation": "To address distortions in AI benchmarking, particularly in Chatbot Arena, where undisclosed practices and data access disparities skew results.", "method": "Analysis of private testing practices, selective disclosure, and data distribution among model providers, including Meta, Google, and OpenAI.", "result": "Proprietary models receive more data and fewer removals, leading to biased scores. Limited additional data can boost performance by up to 112%.", "conclusion": "Reforms are needed for fairer, more transparent benchmarking to avoid overfitting to Arena-specific dynamics and ensure general model quality."}}
{"id": "2505.06980", "pdf": "https://arxiv.org/pdf/2505.06980", "abs": "https://arxiv.org/abs/2505.06980", "authors": ["Lei Wan", "Prabesh Gupta", "Andreas Eich", "Marcel Kettelgerdes", "Hannan Ejaz Keen", "Michael Kl\u00f6ppel-Gersdorf", "Alexey Vinel"], "title": "VALISENS: A Validated Innovative Multi-Sensor System for Cooperative Automated Driving", "categories": ["cs.RO", "cs.CV"], "comment": "7 pages, 11 figures, submitted to IEEE ITSC", "summary": "Perception is a core capability of automated vehicles and has been\nsignificantly advanced through modern sensor technologies and artificial\nintelligence. However, perception systems still face challenges in complex\nreal-world scenarios. To improve robustness against various external factors,\nmulti-sensor fusion techniques are essential, combining the strengths of\ndifferent sensor modalities. With recent developments in Vehicle-to-Everything\n(V2X communication, sensor fusion can now extend beyond a single vehicle to a\ncooperative multi-agent system involving Connected Automated Vehicle (CAV) and\nintelligent infrastructure. This paper presents VALISENS, an innovative\nmulti-sensor system distributed across multiple agents. It integrates onboard\nand roadside LiDARs, radars, thermal cameras, and RGB cameras to enhance\nsituational awareness and support cooperative automated driving. The thermal\ncamera adds critical redundancy for perceiving Vulnerable Road User (VRU),\nwhile fusion with roadside sensors mitigates visual occlusions and extends the\nperception range beyond the limits of individual vehicles. We introduce the\ncorresponding perception module built on this sensor system, which includes\nobject detection, tracking, motion forecasting, and high-level data fusion. The\nproposed system demonstrates the potential of cooperative perception in\nreal-world test environments and lays the groundwork for future Cooperative\nIntelligent Transport Systems (C-ITS) applications.", "AI": {"tldr": "VALISENS is a multi-sensor system for cooperative automated driving, integrating onboard and roadside sensors to enhance perception and mitigate challenges like occlusions and limited range.", "motivation": "To address the robustness challenges of perception systems in complex real-world scenarios by leveraging multi-sensor fusion and cooperative multi-agent systems.", "method": "VALISENS integrates LiDARs, radars, thermal cameras, and RGB cameras across multiple agents (CAVs and infrastructure) for object detection, tracking, motion forecasting, and high-level data fusion.", "result": "The system improves situational awareness, mitigates occlusions, extends perception range, and demonstrates potential for real-world Cooperative Intelligent Transport Systems (C-ITS).", "conclusion": "VALISENS showcases the effectiveness of cooperative perception and lays the foundation for future C-ITS applications."}}
{"id": "2505.07755", "pdf": "https://arxiv.org/pdf/2505.07755", "abs": "https://arxiv.org/abs/2505.07755", "authors": ["Tomasz Szydlo", "Viacheslaw Horbanow", "Dev Nandan Jha", "Shashikant Ilager", "Aleksander Slominski", "Rajiv Ranjan"], "title": "Benchmarking of CPU-intensive Stream Data Processing in The Edge Computing Systems", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Edge computing has emerged as a pivotal technology, offering significant\nadvantages such as low latency, enhanced data security, and reduced reliance on\ncentralized cloud infrastructure. These benefits are crucial for applications\nrequiring real-time data processing or strict security measures. Despite these\nadvantages, edge devices operating within edge clusters are often\nunderutilized. This inefficiency is mainly due to the absence of a holistic\nperformance profiling mechanism which can help dynamically adjust the desired\nsystem configuration for a given workload. Since edge computing environments\ninvolve a complex interplay between CPU frequency, power consumption, and\napplication performance, a deeper understanding of these correlations is\nessential. By uncovering these relationships, it becomes possible to make\ninformed decisions that enhance both computational efficiency and energy\nsavings. To address this gap, this paper evaluates the power consumption and\nperformance characteristics of a single processing node within an edge cluster\nusing a synthetic microbenchmark by varying the workload size and CPU\nfrequency. The results show how an optimal measure can lead to optimized usage\nof edge resources, given both performance and power consumption.", "AI": {"tldr": "The paper explores optimizing edge computing efficiency by analyzing power consumption and performance trade-offs in edge clusters.", "motivation": "Edge devices are underutilized due to lack of performance profiling, hindering dynamic configuration for workloads.", "method": "Evaluates power and performance of a single edge node using synthetic microbenchmarks, varying workload size and CPU frequency.", "result": "Identifies optimal configurations balancing performance and power consumption for efficient edge resource usage.", "conclusion": "Provides insights for informed decisions to enhance computational efficiency and energy savings in edge computing."}}
{"id": "2505.07750", "pdf": "https://arxiv.org/pdf/2505.07750", "abs": "https://arxiv.org/abs/2505.07750", "authors": ["Ga\u0161per Petelin", "Gjorgjina Cenikj"], "title": "The Pitfalls of Benchmarking in Algorithm Selection: What We Are Getting Wrong", "categories": ["cs.LG"], "comment": null, "summary": "Algorithm selection, aiming to identify the best algorithm for a given\nproblem, plays a pivotal role in continuous black-box optimization. A common\napproach involves representing optimization functions using a set of features,\nwhich are then used to train a machine learning meta-model for selecting\nsuitable algorithms. Various approaches have demonstrated the effectiveness of\nthese algorithm selection meta-models. However, not all evaluation approaches\nare equally valid for assessing the performance of meta-models. We highlight\nmethodological issues that frequently occur in the community and should be\naddressed when evaluating algorithm selection approaches. First, we identify\nflaws with the \"leave-instance-out\" evaluation technique. We show that\nnon-informative features and meta-models can achieve high accuracy, which\nshould not be the case with a well-designed evaluation framework. Second, we\ndemonstrate that measuring the performance of optimization algorithms with\nmetrics sensitive to the scale of the objective function requires careful\nconsideration of how this impacts the construction of the meta-model, its\npredictions, and the model's error. Such metrics can falsely present overly\noptimistic performance assessments of the meta-models. This paper emphasizes\nthe importance of careful evaluation, as loosely defined methodologies can\nmislead researchers, divert efforts, and introduce noise into the field", "AI": {"tldr": "The paper critiques common evaluation methods for algorithm selection meta-models in black-box optimization, highlighting flaws in 'leave-instance-out' techniques and scale-sensitive metrics.", "motivation": "To address methodological issues in evaluating algorithm selection approaches, which can mislead researchers and skew results.", "method": "Identifies flaws in 'leave-instance-out' evaluation and analyzes the impact of scale-sensitive metrics on meta-model performance.", "result": "Non-informative features and meta-models can achieve high accuracy, and scale-sensitive metrics may falsely inflate performance assessments.", "conclusion": "Careful evaluation methodologies are crucial to avoid misleading results and ensure valid assessments of algorithm selection approaches."}}
{"id": "2505.00831", "pdf": "https://arxiv.org/pdf/2505.00831", "abs": "https://arxiv.org/abs/2505.00831", "authors": ["Quang P. M. Pham", "Khoi T. N. Nguyen", "Nhi H. Doan", "Cuong A. Pham", "Kentaro Inui", "Dezhen Song"], "title": "SmallPlan: Leverage Small Language Models for Sequential Path Planning with Simulation-Powered, LLM-Guided Distillation", "categories": ["cs.RO", "cs.CL"], "comment": "Paper is under review", "summary": "Efficient path planning in robotics, particularly within large-scale, dynamic\nenvironments, remains a significant hurdle. While Large Language Models (LLMs)\noffer strong reasoning capabilities, their high computational cost and limited\nadaptability in dynamic scenarios hinder real-time deployment on edge devices.\nWe present SmallPlan -- a novel framework leveraging LLMs as teacher models to\ntrain lightweight Small Language Models (SLMs) for high-level path planning\ntasks. In SmallPlan, the SLMs provide optimal action sequences to navigate\nacross scene graphs that compactly represent full-scaled 3D scenes. The SLMs\nare trained in a simulation-powered, interleaved manner with LLM-guided\nsupervised fine-tuning (SFT) and reinforcement learning (RL). This strategy not\nonly enables SLMs to successfully complete navigation tasks but also makes them\naware of important factors like travel distance and number of trials. Through\nexperiments, we demonstrate that the fine-tuned SLMs perform competitively with\nlarger models like GPT-4o on sequential path planning, without suffering from\nhallucination and overfitting. SmallPlan is resource-efficient, making it\nwell-suited for edge-device deployment and advancing practical autonomous\nrobotics. Our source code is available here:\nhttps://github.com/quangpham2006/SmallPlan", "AI": {"tldr": "SmallPlan trains lightweight SLMs using LLMs as teachers for efficient path planning in robotics, achieving competitive performance with larger models while being resource-efficient.", "motivation": "Addressing the high computational cost and limited adaptability of LLMs in dynamic environments for real-time robotics applications.", "method": "Uses LLMs to train SLMs via interleaved supervised fine-tuning and reinforcement learning on scene graphs.", "result": "Fine-tuned SLMs perform competitively with larger models like GPT-4o, avoiding hallucination and overfitting.", "conclusion": "SmallPlan is efficient and suitable for edge-device deployment, advancing practical autonomous robotics."}}
{"id": "2505.07085", "pdf": "https://arxiv.org/pdf/2505.07085", "abs": "https://arxiv.org/abs/2505.07085", "authors": ["Matt Franchi", "Hauke Sandhaus", "Madiha Zahrah Choksi", "Severin Engelmann", "Wendy Ju", "Helen Nissenbaum"], "title": "Privacy of Groups in Dense Street Imagery", "categories": ["cs.CY", "cs.CV", "cs.ET"], "comment": "To appear in ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) '25", "summary": "Spatially and temporally dense street imagery (DSI) datasets have grown\nunbounded. In 2024, individual companies possessed around 3 trillion unique\nimages of public streets. DSI data streams are only set to grow as companies\nlike Lyft and Waymo use DSI to train autonomous vehicle algorithms and analyze\ncollisions. Academic researchers leverage DSI to explore novel approaches to\nurban analysis. Despite good-faith efforts by DSI providers to protect\nindividual privacy through blurring faces and license plates, these measures\nfail to address broader privacy concerns. In this work, we find that increased\ndata density and advancements in artificial intelligence enable harmful group\nmembership inferences from supposedly anonymized data. We perform a penetration\ntest to demonstrate how easily sensitive group affiliations can be inferred\nfrom obfuscated pedestrians in 25,232,608 dashcam images taken in New York\nCity. We develop a typology of identifiable groups within DSI and analyze\nprivacy implications through the lens of contextual integrity. Finally, we\ndiscuss actionable recommendations for researchers working with data from DSI\nproviders.", "AI": {"tldr": "The paper highlights privacy risks in dense street imagery (DSI) datasets, showing how AI can infer sensitive group affiliations from anonymized data, and provides recommendations for researchers.", "motivation": "To address the inadequacy of current privacy measures in DSI datasets, despite good-faith efforts, and to explore the risks of group membership inferences.", "method": "Conducted a penetration test on 25,232,608 dashcam images from NYC to demonstrate how sensitive group affiliations can be inferred from obfuscated data. Developed a typology of identifiable groups and analyzed privacy implications using contextual integrity.", "result": "Found that increased data density and AI advancements enable harmful inferences from anonymized DSI data, revealing broader privacy concerns.", "conclusion": "Proposes actionable recommendations for researchers to mitigate privacy risks when working with DSI datasets."}}
{"id": "2505.07793", "pdf": "https://arxiv.org/pdf/2505.07793", "abs": "https://arxiv.org/abs/2505.07793", "authors": ["Assaf Ben-Kish", "Itamar Zimerman", "M. Jehanzeb Mirza", "James Glass", "Leonid Karlinsky", "Raja Giryes"], "title": "Overflow Prevention Enhances Long-Context Recurrent LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "A recent trend in LLMs is developing recurrent sub-quadratic models that\nimprove long-context processing efficiency. We investigate leading large\nlong-context models, focusing on how their fixed-size recurrent memory affects\ntheir performance. Our experiments reveal that, even when these models are\ntrained for extended contexts, their use of long contexts remains\nunderutilized. Specifically, we demonstrate that a chunk-based inference\nprocedure, which identifies and processes only the most relevant portion of the\ninput can mitigate recurrent memory failures and be effective for many\nlong-context tasks: On LongBench, our method improves the overall performance\nof Falcon3-Mamba-Inst-7B by 14%, Falcon-Mamba-Inst-7B by 28%,\nRecurrentGemma-IT-9B by 50%, and RWKV6-Finch-7B by 51%. Surprisingly, this\nsimple approach also leads to state-of-the-art results in the challenging\nLongBench v2 benchmark, showing competitive performance with equivalent size\nTransformers. Furthermore, our findings raise questions about whether recurrent\nmodels genuinely exploit long-range dependencies, as our single-chunk strategy\ndelivers stronger performance - even in tasks that presumably require\ncross-context relations.", "AI": {"tldr": "A study on recurrent sub-quadratic LLMs reveals underutilization of long contexts despite training. A chunk-based inference method improves performance significantly, even outperforming Transformers in some cases.", "motivation": "To investigate how fixed-size recurrent memory in large long-context models affects performance and whether they truly exploit long-range dependencies.", "method": "A chunk-based inference procedure that processes only the most relevant input portions, tested on models like Falcon3-Mamba-Inst-7B and RecurrentGemma-IT-9B.", "result": "Performance improvements of 14% to 51% on various models, with state-of-the-art results on LongBench v2. The method outperforms even in tasks assumed to need cross-context relations.", "conclusion": "Recurrent models may not fully exploit long-range dependencies, as a simple chunk-based approach yields better performance, raising questions about their design."}}
{"id": "2505.07777", "pdf": "https://arxiv.org/pdf/2505.07777", "abs": "https://arxiv.org/abs/2505.07777", "authors": ["Arya Grayeli", "Vipin Swarup", "Steven E. Noel"], "title": "Synthesizing Diverse Network Flow Datasets with Scalable Dynamic Multigraph Generation", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Obtaining real-world network datasets is often challenging because of\nprivacy, security, and computational constraints. In the absence of such\ndatasets, graph generative models become essential tools for creating synthetic\ndatasets. In this paper, we introduce a novel machine learning model for\ngenerating high-fidelity synthetic network flow datasets that are\nrepresentative of real-world networks. Our approach involves the generation of\ndynamic multigraphs using a stochastic Kronecker graph generator for structure\ngeneration and a tabular generative adversarial network for feature generation.\nWe further employ an XGBoost (eXtreme Gradient Boosting) model for graph\nalignment, ensuring accurate overlay of features onto the generated graph\nstructure. We evaluate our model using new metrics that assess both the\naccuracy and diversity of the synthetic graphs. Our results demonstrate\nimprovements in accuracy over previous large-scale graph generation methods\nwhile maintaining similar efficiency. We also explore the trade-off between\naccuracy and diversity in synthetic graph dataset creation, a topic not\nextensively covered in related works. Our contributions include the synthesis\nand evaluation of large real-world netflow datasets and the definition of new\nmetrics for evaluating synthetic graph generative models.", "AI": {"tldr": "A novel ML model for generating high-fidelity synthetic network flow datasets using dynamic multigraphs, stochastic Kronecker graphs, and tabular GANs, with XGBoost for alignment. Evaluated with new metrics, it improves accuracy while maintaining efficiency.", "motivation": "Challenges in obtaining real-world network datasets due to privacy, security, and computational constraints necessitate synthetic data generation.", "method": "Combines stochastic Kronecker graph generator for structure, tabular GAN for features, and XGBoost for alignment. Introduces new evaluation metrics.", "result": "Improved accuracy over previous methods with similar efficiency. Explores accuracy-diversity trade-off in synthetic graphs.", "conclusion": "Contributes synthetic netflow datasets and new evaluation metrics, addressing gaps in graph generative models."}}
{"id": "2505.05190", "pdf": "https://arxiv.org/pdf/2505.05190", "abs": "https://arxiv.org/abs/2505.05190", "authors": ["Yixin Cheng", "Hongcheng Guo", "Yangming Li", "Leonid Sigal"], "title": "Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": "ICML 2025 Accpeted", "summary": "Text watermarking aims to subtly embed statistical signals into text by\ncontrolling the Large Language Model (LLM)'s sampling process, enabling\nwatermark detectors to verify that the output was generated by the specified\nmodel. The robustness of these watermarking algorithms has become a key factor\nin evaluating their effectiveness. Current text watermarking algorithms embed\nwatermarks in high-entropy tokens to ensure text quality. In this paper, we\nreveal that this seemingly benign design can be exploited by attackers, posing\na significant risk to the robustness of the watermark. We introduce a generic\nefficient paraphrasing attack, the Self-Information Rewrite Attack (SIRA),\nwhich leverages the vulnerability by calculating the self-information of each\ntoken to identify potential pattern tokens and perform targeted attack. Our\nwork exposes a widely prevalent vulnerability in current watermarking\nalgorithms. The experimental results show SIRA achieves nearly 100% attack\nsuccess rates on seven recent watermarking methods with only 0.88 USD per\nmillion tokens cost. Our approach does not require any access to the watermark\nalgorithms or the watermarked LLM and can seamlessly transfer to any LLM as the\nattack model, even mobile-level models. Our findings highlight the urgent need\nfor more robust watermarking.", "AI": {"tldr": "The paper reveals a vulnerability in current text watermarking algorithms, introduces the SIRA attack exploiting this flaw, and demonstrates its high success rate and low cost, urging the need for more robust watermarking.", "motivation": "To expose a critical vulnerability in existing text watermarking algorithms that embed watermarks in high-entropy tokens, which attackers can exploit.", "method": "Introduces the Self-Information Rewrite Attack (SIRA), a paraphrasing attack that identifies and targets pattern tokens using self-information calculations.", "result": "SIRA achieves nearly 100% success rates on seven watermarking methods with minimal cost (0.88 USD per million tokens) and requires no access to the watermark algorithms or LLM.", "conclusion": "The findings emphasize the urgent need for more robust watermarking techniques to counter such vulnerabilities."}}
{"id": "2505.07110", "pdf": "https://arxiv.org/pdf/2505.07110", "abs": "https://arxiv.org/abs/2505.07110", "authors": ["Tong Zhang", "Fenghua Shao", "Runsheng Zhang", "Yifan Zhuang", "Liuqingqing Yang"], "title": "DeepSORT-Driven Visual Tracking Approach for Gesture Recognition in Interactive Systems", "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "Based on the DeepSORT algorithm, this study explores the application of\nvisual tracking technology in intelligent human-computer interaction,\nespecially in the field of gesture recognition and tracking. With the rapid\ndevelopment of artificial intelligence and deep learning technology,\nvisual-based interaction has gradually replaced traditional input devices and\nbecome an important way for intelligent systems to interact with users. The\nDeepSORT algorithm can achieve accurate target tracking in dynamic environments\nby combining Kalman filters and deep learning feature extraction methods. It is\nespecially suitable for complex scenes with multi-target tracking and fast\nmovements. This study experimentally verifies the superior performance of\nDeepSORT in gesture recognition and tracking. It can accurately capture and\ntrack the user's gesture trajectory and is superior to traditional tracking\nmethods in terms of real-time and accuracy. In addition, this study also\ncombines gesture recognition experiments to evaluate the recognition ability\nand feedback response of the DeepSORT algorithm under different gestures (such\nas sliding, clicking, and zooming). The experimental results show that DeepSORT\ncan not only effectively deal with target occlusion and motion blur but also\ncan stably track in a multi-target environment, achieving a smooth user\ninteraction experience. Finally, this paper looks forward to the future\ndevelopment direction of intelligent human-computer interaction systems based\non visual tracking and proposes future research focuses such as algorithm\noptimization, data fusion, and multimodal interaction in order to promote a\nmore intelligent and personalized interactive experience. Keywords-DeepSORT,\nvisual tracking, gesture recognition, human-computer interaction", "AI": {"tldr": "This study applies the DeepSORT algorithm to gesture recognition and tracking in human-computer interaction, demonstrating its superior accuracy and real-time performance over traditional methods.", "motivation": "To enhance intelligent human-computer interaction by leveraging visual tracking technology, replacing traditional input methods with gesture-based systems.", "method": "Utilizes the DeepSORT algorithm, combining Kalman filters and deep learning for accurate multi-target tracking in dynamic environments.", "result": "DeepSORT outperforms traditional methods in gesture tracking, handling occlusion and motion blur while maintaining stability in multi-target scenarios.", "conclusion": "The study highlights DeepSORT's potential for intelligent interaction systems and suggests future research in algorithm optimization and multimodal interaction."}}
{"id": "2505.07802", "pdf": "https://arxiv.org/pdf/2505.07802", "abs": "https://arxiv.org/abs/2505.07802", "authors": ["Reece O'Mahoney", "Wanming Yu", "Ioannis Havoutis"], "title": "Improving Trajectory Stitching with Flow Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Generative models have shown great promise as trajectory planners, given\ntheir affinity to modeling complex distributions and guidable inference\nprocess. Previous works have successfully applied these in the context of\nrobotic manipulation but perform poorly when the required solution does not\nexist as a complete trajectory within the training set. We identify that this\nis a result of being unable to plan via stitching, and subsequently address the\narchitectural and dataset choices needed to remedy this. On top of this, we\npropose a novel addition to the training and inference procedures to both\nstabilize and enhance these capabilities. We demonstrate the efficacy of our\napproach by generating plans with out of distribution boundary conditions and\nperforming obstacle avoidance on the Franka Panda in simulation and on real\nhardware. In both of these tasks our method performs significantly better than\nthe baselines and is able to avoid obstacles up to four times as large.", "AI": {"tldr": "The paper proposes improvements to generative models for robotic trajectory planning, enabling better performance for out-of-distribution tasks and obstacle avoidance.", "motivation": "Existing generative models for robotic manipulation fail when solutions require stitching trajectories not present in the training data.", "method": "The authors address architectural and dataset limitations, introduce novel training and inference procedures, and test on out-of-distribution boundary conditions and obstacle avoidance.", "result": "The method outperforms baselines, handling larger obstacles (up to four times as large) and generating plans for unseen conditions.", "conclusion": "The proposed enhancements significantly improve generative models' capability in robotic trajectory planning, especially for non-standard scenarios."}}
{"id": "2505.07782", "pdf": "https://arxiv.org/pdf/2505.07782", "abs": "https://arxiv.org/abs/2505.07782", "authors": ["Rushi Qiang", "Yuchen Zhuang", "Yinghao Li", "Dingu Sagar V K", "Rongzhi Zhang", "Changhao Li", "Ian Shu-Hei Wong", "Sherry Yang", "Percy Liang", "Chao Zhang", "Bo Dai"], "title": "MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering", "categories": ["cs.LG"], "comment": null, "summary": "We introduce MLE-Dojo, a Gym-style framework for systematically reinforcement\nlearning, evaluating, and improving autonomous large language model (LLM)\nagents in iterative machine learning engineering (MLE) workflows. Unlike\nexisting benchmarks that primarily rely on static datasets or single-attempt\nevaluations, MLE-Dojo provides an interactive environment enabling agents to\niteratively experiment, debug, and refine solutions through structured feedback\nloops. Built upon 200+ real-world Kaggle challenges, MLE-Dojo covers diverse,\nopen-ended MLE tasks carefully curated to reflect realistic engineering\nscenarios such as data processing, architecture search, hyperparameter tuning,\nand code debugging. Its fully executable environment supports comprehensive\nagent training via both supervised fine-tuning and reinforcement learning,\nfacilitating iterative experimentation, realistic data sampling, and real-time\noutcome verification. Extensive evaluations of eight frontier LLMs reveal that\nwhile current models achieve meaningful iterative improvements, they still\nexhibit significant limitations in autonomously generating long-horizon\nsolutions and efficiently resolving complex errors. Furthermore, MLE-Dojo's\nflexible and extensible architecture seamlessly integrates diverse data\nsources, tools, and evaluation protocols, uniquely enabling model-based agent\ntuning and promoting interoperability, scalability, and reproducibility. We\nopen-source our framework and benchmarks to foster community-driven innovation\ntowards next-generation MLE agents.", "AI": {"tldr": "MLE-Dojo is a Gym-style framework for iterative reinforcement learning of LLM agents, offering interactive environments and structured feedback for tasks like data processing and hyperparameter tuning. Evaluations show current models improve iteratively but struggle with long-horizon solutions.", "motivation": "Existing benchmarks lack interactivity and iterative feedback, limiting the evaluation and improvement of autonomous LLM agents in realistic MLE workflows.", "method": "Built on 200+ Kaggle challenges, MLE-Dojo provides an executable environment for supervised fine-tuning and reinforcement learning, supporting iterative experimentation and real-time verification.", "result": "Evaluations of eight LLMs show iterative improvements but highlight limitations in autonomous long-horizon problem-solving and error resolution.", "conclusion": "MLE-Dojo's flexible architecture fosters interoperability and scalability, advancing community-driven innovation in MLE agents."}}
{"id": "2505.07813", "pdf": "https://arxiv.org/pdf/2505.07813", "abs": "https://arxiv.org/abs/2505.07813", "authors": ["Tony Tao", "Mohan Kumar Srirama", "Jason Jingzhou Liu", "Kenneth Shaw", "Deepak Pathak"], "title": "DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "In RSS 2025. Website at https://dexwild.github.io", "summary": "Large-scale, diverse robot datasets have emerged as a promising path toward\nenabling dexterous manipulation policies to generalize to novel environments,\nbut acquiring such datasets presents many challenges. While teleoperation\nprovides high-fidelity datasets, its high cost limits its scalability. Instead,\nwhat if people could use their own hands, just as they do in everyday life, to\ncollect data? In DexWild, a diverse team of data collectors uses their hands to\ncollect hours of interactions across a multitude of environments and objects.\nTo record this data, we create DexWild-System, a low-cost, mobile, and\neasy-to-use device. The DexWild learning framework co-trains on both human and\nrobot demonstrations, leading to improved performance compared to training on\neach dataset individually. This combination results in robust robot policies\ncapable of generalizing to novel environments, tasks, and embodiments with\nminimal additional robot-specific data. Experimental results demonstrate that\nDexWild significantly improves performance, achieving a 68.5% success rate in\nunseen environments-nearly four times higher than policies trained with robot\ndata only-and offering 5.8x better cross-embodiment generalization. Video\nresults, codebases, and instructions at https://dexwild.github.io", "AI": {"tldr": "DexWild introduces a low-cost, mobile system for collecting diverse robot data using human hands, improving generalization in robot policies.", "motivation": "High-cost teleoperation limits scalability for large-scale robot datasets; DexWild proposes using human hands for data collection.", "method": "Develops DexWild-System for easy data collection and co-trains on human and robot demonstrations.", "result": "Achieves 68.5% success in unseen environments, 4x better than robot-only training, and 5.8x better cross-embodiment generalization.", "conclusion": "DexWild enables robust, generalizable robot policies with minimal additional robot-specific data."}}
{"id": "2505.07783", "pdf": "https://arxiv.org/pdf/2505.07783", "abs": "https://arxiv.org/abs/2505.07783", "authors": ["Yanxin Liu", "Yunqi Zhang"], "title": "Relative Overfitting and Accept-Reject Framework", "categories": ["cs.LG"], "comment": null, "summary": "Currently, the scaling law of Large Language Models (LLMs) faces challenges\nand bottlenecks. This paper posits that noise effects, stemming from changes in\nthe signal-to-noise ratio under diminishing marginal returns, are the root\ncause of these issues. To control this noise, we investigated the differences\nbetween models with performance advantages and disadvantages, introducing the\nconcept of \"relative overfitting.\" Based on their complementary strengths, we\nhave proposed an application framework, Accept-Reject (AR). In Natural Language\nProcessing (NLP), we use LLMs and Small Language Models (SLMs) as the medium\nfor discussion. This framework enables SLMs to exert a universal positive\ninfluence on LLM decision outputs, rather than the intuitively expected\nnegative influence. We validated our approach using self-built models based on\nmainstream architectures and pre-trained mainstream models across multiple\ndatasets, including basic language modeling, long-context tasks, subject\nexamination, and question-answering (QA) benchmarks. The results demonstrate\nthat through our structure, compared to increasing the LLM's parameters, we can\nachieve better performance improvements with significantly lower parameter and\ncomputational costs in many scenarios. These improvements are universal,\nstable, and effective. Furthermore, we explore the potential of \"relative\noverfitting\" and the AR framework in other machine learning domains, such as\ncomputer vision (CV) and AI for science. We hope the proposed approach can help\nscale laws overcome existing bottlenecks.", "AI": {"tldr": "The paper addresses scaling law challenges in LLMs by attributing them to noise effects and introduces the 'relative overfitting' concept and the AR framework to improve performance efficiently.", "motivation": "The study aims to overcome bottlenecks in LLM scaling laws caused by noise effects under diminishing marginal returns.", "method": "The paper investigates performance differences between models, introduces 'relative overfitting,' and proposes the AR framework, validated using self-built and pre-trained models across diverse NLP tasks.", "result": "The AR framework achieves better performance improvements than increasing LLM parameters, with lower costs, and shows universal, stable effectiveness.", "conclusion": "The approach has potential beyond NLP, in CV and AI for science, offering a way to overcome scaling law bottlenecks."}}
{"id": "2505.07600", "pdf": "https://arxiv.org/pdf/2505.07600", "abs": "https://arxiv.org/abs/2505.07600", "authors": ["Oriol Barbany", "Adri\u00e0 Colom\u00e9", "Carme Torras"], "title": "Beyond Static Perception: Integrating Temporal Context into VLMs for Cloth Folding", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted at ICRA 2025 Workshop \"Reflections on Representations and\n  Manipulating Deformable Objects\". Project page\n  https://barbany.github.io/bifold/", "summary": "Manipulating clothes is challenging due to their complex dynamics, high\ndeformability, and frequent self-occlusions. Garments exhibit a nearly infinite\nnumber of configurations, making explicit state representations difficult to\ndefine. In this paper, we analyze BiFold, a model that predicts\nlanguage-conditioned pick-and-place actions from visual observations, while\nimplicitly encoding garment state through end-to-end learning. To address\nscenarios such as crumpled garments or recovery from failed manipulations,\nBiFold leverages temporal context to improve state estimation. We examine the\ninternal representations of the model and present evidence that its fine-tuning\nand temporal context enable effective alignment between text and image regions,\nas well as temporal consistency.", "AI": {"tldr": "BiFold predicts language-conditioned pick-and-place actions for garment manipulation, using temporal context and implicit state encoding to handle complex dynamics.", "motivation": "Garments' high deformability and infinite configurations make explicit state representation difficult, requiring implicit methods.", "method": "BiFold uses end-to-end learning to predict actions from visual observations, leveraging temporal context for state estimation.", "result": "The model aligns text and image regions effectively and maintains temporal consistency, improving manipulation tasks.", "conclusion": "BiFold's implicit state encoding and temporal context enable robust garment manipulation, addressing challenges like crumpling and failed actions."}}
{"id": "2505.07816", "pdf": "https://arxiv.org/pdf/2505.07816", "abs": "https://arxiv.org/abs/2505.07816", "authors": ["Veeti Ahvonen", "Damian Heiman", "Antti Kuusisto"], "title": "A class of distributed automata that contains the modal mu-fragment", "categories": ["cs.LO", "cs.AI", "F.4.1; F.1.1; I.2.0"], "comment": null, "summary": "This paper gives a translation from the $\\mu$-fragment of the graded modal\n$\\mu$-calculus to a class of distributed message-passing automata. As a\ncorollary, we obtain an alternative proof for a theorem from\n\\cite{ahvonen_neurips} stating that recurrent graph neural networks working\nwith reals and graded modal substitution calculus have the same expressive\npower in restriction to the logic monadic second-order logic MSO.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.07797", "pdf": "https://arxiv.org/pdf/2505.07797", "abs": "https://arxiv.org/abs/2505.07797", "authors": ["Daniel Beechey", "Thomas M. S. Smith", "\u00d6zg\u00fcr \u015eim\u015fek"], "title": "A Theoretical Framework for Explaining Reinforcement Learning with Shapley Values", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning agents can achieve superhuman performance, but their\ndecisions are often difficult to interpret. This lack of transparency limits\ndeployment, especially in safety-critical settings where human trust and\naccountability are essential. In this work, we develop a theoretical framework\nfor explaining reinforcement learning through the influence of state features,\nwhich represent what the agent observes in its environment. We identify three\ncore elements of the agent-environment interaction that benefit from\nexplanation: behaviour (what the agent does), performance (what the agent\nachieves), and value estimation (what the agent expects to achieve). We treat\nstate features as players cooperating to produce each element and apply Shapley\nvalues, a principled method from cooperative game theory, to identify the\ninfluence of each feature. This approach yields a family of mathematically\ngrounded explanations with clear semantics and theoretical guarantees. We use\nillustrative examples to show how these explanations align with human intuition\nand reveal novel insights. Our framework unifies and extends prior work, making\nexplicit the assumptions behind existing approaches, and offers a principled\nfoundation for more interpretable and trustworthy reinforcement learning.", "AI": {"tldr": "A framework for explaining reinforcement learning decisions using Shapley values to analyze state feature influence, enhancing interpretability and trust.", "motivation": "The lack of transparency in reinforcement learning decisions limits deployment in safety-critical settings, necessitating interpretable explanations.", "method": "Develops a theoretical framework using Shapley values to quantify the influence of state features on agent behavior, performance, and value estimation.", "result": "Produces mathematically grounded explanations that align with human intuition and reveal new insights.", "conclusion": "The framework provides a principled foundation for interpretable and trustworthy reinforcement learning, unifying prior work."}}
{"id": "2505.07754", "pdf": "https://arxiv.org/pdf/2505.07754", "abs": "https://arxiv.org/abs/2505.07754", "authors": ["Samik Banerjee", "Caleb Stam", "Daniel J. Tward", "Steven Savoia", "Yusu Wang", "Partha P. Mitra"], "title": "Skeletonization of neuronal processes using Discrete Morse techniques from computational topology", "categories": ["q-bio.NC", "cs.CV"], "comment": "Under Review in Nature", "summary": "To understand biological intelligence we need to map neuronal networks in\nvertebrate brains. Mapping mesoscale neural circuitry is done using injections\nof tracers that label groups of neurons whose axons project to different brain\nregions. Since many neurons are labeled, it is difficult to follow individual\naxons. Previous approaches have instead quantified the regional projections\nusing the total label intensity within a region. However, such a quantification\nis not biologically meaningful. We propose a new approach better connected to\nthe underlying neurons by skeletonizing labeled axon fragments and then\nestimating a volumetric length density. Our approach uses a combination of deep\nnets and the Discrete Morse (DM) technique from computational topology. This\ntechnique takes into account nonlocal connectivity information and therefore\nprovides noise-robustness. We demonstrate the utility and scalability of the\napproach on whole-brain tracer injected data. We also define and illustrate an\ninformation theoretic measure that quantifies the additional information\nobtained, compared to the skeletonized tracer injection fragments, when\nindividual axon morphologies are available. Our approach is the first\napplication of the DM technique to computational neuroanatomy. It can help\nbridge between single-axon skeletons and tracer injections, two important data\ntypes in mapping neural networks in vertebrates.", "AI": {"tldr": "A new method for mapping mesoscale neural circuitry uses skeletonization and volumetric length density estimation, combining deep nets and Discrete Morse theory for noise-robustness.", "motivation": "Traditional methods quantify regional projections using total label intensity, which lacks biological meaning. A more neuron-connected approach is needed.", "method": "Skeletonizes labeled axon fragments and estimates volumetric length density using deep nets and Discrete Morse theory.", "result": "Demonstrated utility and scalability on whole-brain tracer data, with an information theoretic measure showing added value over skeletonized fragments.", "conclusion": "The approach bridges single-axon skeletons and tracer injections, advancing computational neuroanatomy."}}
{"id": "2505.07819", "pdf": "https://arxiv.org/pdf/2505.07819", "abs": "https://arxiv.org/abs/2505.07819", "authors": ["Yiyang Lu", "Yufeng Tian", "Zhecheng Yuan", "Xianbang Wang", "Pu Hua", "Zhengrong Xue", "Huazhe Xu"], "title": "H$^{\\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Visuomotor policy learning has witnessed substantial progress in robotic\nmanipulation, with recent approaches predominantly relying on generative models\nto model the action distribution. However, these methods often overlook the\ncritical coupling between visual perception and action prediction. In this\nwork, we introduce $\\textbf{Triply-Hierarchical Diffusion\nPolicy}~(\\textbf{H$^{\\mathbf{3}}$DP})$, a novel visuomotor learning framework\nthat explicitly incorporates hierarchical structures to strengthen the\nintegration between visual features and action generation. H$^{3}$DP contains\n$\\mathbf{3}$ levels of hierarchy: (1) depth-aware input layering that organizes\nRGB-D observations based on depth information; (2) multi-scale visual\nrepresentations that encode semantic features at varying levels of granularity;\nand (3) a hierarchically conditioned diffusion process that aligns the\ngeneration of coarse-to-fine actions with corresponding visual features.\nExtensive experiments demonstrate that H$^{3}$DP yields a $\\mathbf{+27.5\\%}$\naverage relative improvement over baselines across $\\mathbf{44}$ simulation\ntasks and achieves superior performance in $\\mathbf{4}$ challenging bimanual\nreal-world manipulation tasks. Project Page: https://lyy-iiis.github.io/h3dp/.", "AI": {"tldr": "H$^{3}$DP is a hierarchical visuomotor learning framework that improves action prediction by integrating visual perception and action generation through three levels of hierarchy.", "motivation": "Existing generative models for robotic manipulation often neglect the coupling between visual perception and action prediction, limiting performance.", "method": "H$^{3}$DP introduces three hierarchical levels: depth-aware input layering, multi-scale visual representations, and a hierarchically conditioned diffusion process for action generation.", "result": "H$^{3}$DP achieves a +27.5% improvement over baselines in 44 simulation tasks and excels in 4 real-world bimanual tasks.", "conclusion": "The framework demonstrates the effectiveness of hierarchical integration in visuomotor policy learning for robotic manipulation."}}
{"id": "2409.04300", "pdf": "https://arxiv.org/pdf/2409.04300", "abs": "https://arxiv.org/abs/2409.04300", "authors": ["Oliver Weissl", "Evgenii Egorov"], "title": "Equivariant Machine Learning Decoder for 3D Toric Codes", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Mitigating errors in computing and communication systems has seen a great\ndeal of research since the beginning of the widespread use of these\ntechnologies. However, as we develop new methods to do computation or\ncommunication, we also need to reiterate the method used to deal with errors.\nWithin the field of quantum computing, error correction is getting a lot of\nattention since errors can propagate fast and invalidate results, which makes\nthe theoretical exponential speed increase in computation time, compared to\ntraditional systems, obsolete. To correct errors in quantum systems,\nerror-correcting codes are used. A subgroup of codes, topological codes, is\ncurrently the focus of many research papers. Topological codes represent parity\ncheck matrices corresponding to graphs embedded on a $d$-dimensional surface.\nFor our research, the focus lies on the toric code with a 3D square lattice.\nThe goal of any decoder is robustness to noise, which can increase with code\nsize. However, a reasonable decoder performance scales polynomially with\nlattice size. As error correction is a time-sensitive operation, we propose a\nneural network using an inductive bias: equivariance. This allows the network\nto learn from a rather small subset of the exponentially growing training space\nof possible inputs. In addition, we investigate how transformer networks can\nhelp in correction. These methods will be compared with various configurations\nand previously published methods of decoding errors in the 3D toric code.", "AI": {"tldr": "The paper explores neural networks and transformers for efficient error correction in quantum computing, focusing on 3D toric codes.", "motivation": "Quantum computing's exponential speed is hindered by error propagation, necessitating robust error correction methods.", "method": "Proposes neural networks with equivariance and transformers to decode errors in 3D toric codes, comparing them with existing methods.", "result": "Aims for polynomial scaling of decoder performance with lattice size, leveraging small training subsets.", "conclusion": "The study highlights the potential of neural networks and transformers to improve error correction in quantum systems."}}
{"id": "2505.07766", "pdf": "https://arxiv.org/pdf/2505.07766", "abs": "https://arxiv.org/abs/2505.07766", "authors": ["Xuying Huang", "Sicong Pan", "Maren Bennewitz"], "title": "Privacy Risks of Robot Vision: A User Study on Image Modalities and Resolution", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "User privacy is a crucial concern in robotic applications, especially when\nmobile service robots are deployed in personal or sensitive environments.\nHowever, many robotic downstream tasks require the use of cameras, which may\nraise privacy risks. To better understand user perceptions of privacy in\nrelation to visual data, we conducted a user study investigating how different\nimage modalities and image resolutions affect users' privacy concerns. The\nresults show that depth images are broadly viewed as privacy-safe, and a\nsimilarly high proportion of respondents feel the same about semantic\nsegmentation images. Additionally, the majority of participants consider 32*32\nresolution RGB images to be almost sufficiently privacy-preserving, while most\nbelieve that 16*16 resolution can fully guarantee privacy protection.", "AI": {"tldr": "Depth and semantic segmentation images are seen as privacy-safe, while low-resolution RGB images (32*32 and 16*16) are also considered privacy-preserving.", "motivation": "Addressing privacy concerns in robotic applications using cameras, particularly in sensitive environments.", "method": "Conducted a user study on how image modalities (depth, semantic segmentation, RGB) and resolutions affect privacy perceptions.", "result": "Depth and semantic segmentation images are broadly viewed as privacy-safe. Low-resolution RGB (32*32 and 16*16) are also considered privacy-preserving.", "conclusion": "Alternative image modalities and lower resolutions can mitigate privacy concerns in robotic applications."}}
{"id": "2404.12534", "pdf": "https://arxiv.org/pdf/2404.12534", "abs": "https://arxiv.org/abs/2404.12534", "authors": ["Peiyang Song", "Kaiyu Yang", "Anima Anandkumar"], "title": "Lean Copilot: Large Language Models as Copilots for Theorem Proving in Lean", "categories": ["cs.AI", "cs.LG", "cs.LO", "stat.ML"], "comment": "Published at NeuS 2025. All code and artifacts open-sourced at\n  https://github.com/lean-dojo/LeanCopilot. All evaluation details are made\n  public at\n  https://github.com/Peiyang-Song/mathematics_in_lean/tree/full-scale-experiment", "summary": "Neural theorem proving combines large language models (LLMs) with proof\nassistants such as Lean, where the correctness of formal proofs can be\nrigorously verified, leaving no room for hallucination. With existing neural\ntheorem provers pretrained on a fixed collection of data and offering valuable\nsuggestions at times, it is challenging for them to continually prove novel\ntheorems in a fully autonomous mode, where human insights may be critical. In\nthis paper, we explore LLMs as copilots that assist humans in proving theorems.\nWe introduce Lean Copilot, a general framework for running LLM inference\nnatively in Lean. It enables programmers to build various LLM-based proof\nautomation tools that integrate seamlessly into the workflow of Lean users.\nLean users can use our pretrained models or bring their own ones that run\neither locally (with or without GPUs) or on the cloud. Using Lean Copilot, we\nbuild LLM-based tools that suggest proof steps, complete proof goals, and\nselect relevant premises. Experimental results on the Mathematics in Lean\ntextbook demonstrate the effectiveness of our method compared to existing\nrule-based proof automation in Lean (aesop). When assisting humans, Lean\nCopilot requires only 2.08 manually-entered proof steps on average (3.86\nrequired by aesop); when automating the theorem proving process, Lean Copilot\nautomates 74.2% proof steps on average, 85% better than aesop (40.1%). We open\nsource all code and artifacts under a permissive MIT license to facilitate\nfurther research.", "AI": {"tldr": "Lean Copilot integrates LLMs into Lean for theorem proving, outperforming rule-based methods by reducing manual steps and automating more proofs.", "motivation": "Existing neural theorem provers struggle with fully autonomous novel theorem proving, requiring human insights. Lean Copilot aims to assist humans in theorem proving by leveraging LLMs.", "method": "Introduces Lean Copilot, a framework for running LLM inference in Lean, enabling tools for proof suggestions, goal completion, and premise selection.", "result": "Lean Copilot reduces manual proof steps to 2.08 (vs. 3.86 by aesop) and automates 74.2% of steps (vs. 40.1% by aesop).", "conclusion": "Lean Copilot effectively enhances theorem proving with LLMs, offering a flexible and powerful tool for Lean users, with open-sourced code for further research."}}
{"id": "2505.06243", "pdf": "https://arxiv.org/pdf/2505.06243", "abs": "https://arxiv.org/abs/2505.06243", "authors": ["Mykola Kozlenko"], "title": "Supervised machine learning based signal demodulation in chaotic communications", "categories": ["eess.SP", "cs.LG", "68T07 (Primary) 94A12, 94A13, 94A14 (Secondary)", "I.2.6; C.2"], "comment": "5 pages, 3 figures, 1 table. This paper was originally published in\n  2022 International Conference on Innovative Solutions in Software Engineering\n  (ICISSE), available: https://zenodo.org/records/7512427", "summary": "A chaotic modulation scheme is an efficient wideband communication method. It\nutilizes the deterministic chaos to generate pseudo-random carriers. Chaotic\nbifurcation parameter modulation is one of the well-known and widely-used\ntechniques. This paper presents the machine learning based demodulation\napproach for the bifurcation parameter keying. It presents the structure of a\nconvolutional neural network as well as performance metrics values for signals\ngenerated with the chaotic logistic map. The paper provides an assessment of\nthe overall accuracy for binary signals. It reports the accuracy value of 0.88\nfor the bifurcation parameter deviation of 1.34% in the presence of additive\nwhite Gaussian noise at the normalized signal-to-noise ratio value of 20 dB for\nbalanced dataset.", "AI": {"tldr": "A machine learning-based demodulation approach for chaotic bifurcation parameter keying is proposed, achieving 88% accuracy for binary signals under noise.", "motivation": "To improve demodulation efficiency in chaotic modulation schemes using machine learning.", "method": "Uses a convolutional neural network to demodulate signals generated with the chaotic logistic map.", "result": "Achieves 0.88 accuracy for binary signals with 1.34% bifurcation parameter deviation and 20 dB SNR.", "conclusion": "The approach is effective for demodulating chaotic signals, demonstrating high accuracy under noise."}}
{"id": "2505.07815", "pdf": "https://arxiv.org/pdf/2505.07815", "abs": "https://arxiv.org/abs/2505.07815", "authors": ["Seungjae Lee", "Daniel Ekpo", "Haowen Liu", "Furong Huang", "Abhinav Shrivastava", "Jia-Bin Huang"], "title": "Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Project webpage: https://ive-robot.github.io/", "summary": "Exploration is essential for general-purpose robotic learning, especially in\nopen-ended environments where dense rewards, explicit goals, or task-specific\nsupervision are scarce. Vision-language models (VLMs), with their semantic\nreasoning over objects, spatial relations, and potential outcomes, present a\ncompelling foundation for generating high-level exploratory behaviors. However,\ntheir outputs are often ungrounded, making it difficult to determine whether\nimagined transitions are physically feasible or informative. To bridge the gap\nbetween imagination and execution, we present IVE (Imagine, Verify, Execute),\nan agentic exploration framework inspired by human curiosity. Human exploration\nis often driven by the desire to discover novel scene configurations and to\ndeepen understanding of the environment. Similarly, IVE leverages VLMs to\nabstract RGB-D observations into semantic scene graphs, imagine novel scenes,\npredict their physical plausibility, and generate executable skill sequences\nthrough action tools. We evaluate IVE in both simulated and real-world tabletop\nenvironments. The results show that IVE enables more diverse and meaningful\nexploration than RL baselines, as evidenced by a 4.1 to 7.8x increase in the\nentropy of visited states. Moreover, the collected experience supports\ndownstream learning, producing policies that closely match or exceed the\nperformance of those trained on human-collected demonstrations.", "AI": {"tldr": "IVE (Imagine, Verify, Execute) is a robotic exploration framework using vision-language models (VLMs) to generate high-level behaviors, verify plausibility, and execute actions, outperforming RL baselines in diversity and downstream learning.", "motivation": "Exploration in open-ended robotic environments lacks dense rewards or explicit goals, requiring innovative methods like VLMs for semantic reasoning and curiosity-driven behaviors.", "method": "IVE abstracts RGB-D observations into semantic scene graphs, imagines novel scenes, verifies their physical plausibility, and generates executable skill sequences using action tools.", "result": "IVE achieves 4.1 to 7.8x higher state entropy than RL baselines and supports downstream learning, matching or exceeding human-collected demonstration performance.", "conclusion": "IVE bridges imagination and execution in robotic exploration, demonstrating the potential of VLMs for curiosity-driven, diverse, and meaningful learning."}}
{"id": "2406.14132", "pdf": "https://arxiv.org/pdf/2406.14132", "abs": "https://arxiv.org/abs/2406.14132", "authors": ["Bin Li", "Jiayan Pei", "Feiyang Xiao", "Yifan Zhao", "Zhixing Zhang", "Diwei Liu", "HengXu He", "Jia Jia"], "title": "Enhancing Monotonic Modeling with Spatio-Temporal Adaptive Awareness in Diverse Marketing", "categories": ["cs.AI"], "comment": "12 pages", "summary": "In the mobile internet era, the Online Food Ordering Service (OFOS) emerges\nas an integral component of inclusive finance owing to the convenience it\nbrings to people. OFOS platforms offer dynamic allocation incentives to users\nand merchants through diverse marketing campaigns to encourage payments while\nmaintaining the platforms' budget efficiency. Despite significant progress, the\nmarketing domain continues to face two primary challenges: (i) how to allocate\na limited budget with greater efficiency, demanding precision in predicting\nusers' monotonic response (i.e. sensitivity) to incentives, and (ii) ensuring\nspatio-temporal adaptability and robustness in diverse marketing campaigns\nacross different times and locations. To address these issues, we propose a\nConstrained Monotonic Adaptive Network (CoMAN) method for spatio-temporal\nperception within marketing pricing. Specifically, we capture spatio-temporal\npreferences within attribute features through two foundational spatio-temporal\nperception modules. To further enhance catching the user sensitivity\ndifferentials to incentives across varied times and locations, we design\nmodules for learning spatio-temporal convexity and concavity as well as for\nexpressing sensitivity functions. CoMAN can achieve a more efficient allocation\nof incentive investments during pricing, thus increasing the conversion rate\nand orders while maintaining budget efficiency. Extensive offline and online\nexperimental results within our diverse marketing campaigns demonstrate the\neffectiveness of the proposed approach while outperforming the monotonic\nstate-of-the-art method.", "AI": {"tldr": "The paper proposes CoMAN, a method for efficient budget allocation in OFOS marketing by predicting user sensitivity to incentives and ensuring spatio-temporal adaptability.", "motivation": "Address challenges in OFOS marketing: efficient budget allocation and spatio-temporal robustness in diverse campaigns.", "method": "Introduces CoMAN with spatio-temporal perception modules, learning convexity/concavity, and sensitivity functions.", "result": "CoMAN improves incentive allocation, boosts conversion rates, and maintains budget efficiency, outperforming existing methods.", "conclusion": "CoMAN effectively addresses OFOS marketing challenges, enhancing efficiency and adaptability in dynamic campaigns."}}
{"id": "2505.06245", "pdf": "https://arxiv.org/pdf/2505.06245", "abs": "https://arxiv.org/abs/2505.06245", "authors": ["Dominic Schneider", "Lutz Rapp", "Christoph Ament"], "title": "A Transformer-Based Approach for Diagnosing Fault Cases in Optical Fiber Amplifiers", "categories": ["eess.SP", "cs.LG"], "comment": "This paper has been accepted for publication at the 25th\n  International Conference on Transparent Optical Networks (ICTON) 2025", "summary": "A transformer-based deep learning approach is presented that enables the\ndiagnosis of fault cases in optical fiber amplifiers using condition-based\nmonitoring time series data. The model, Inverse Triple-Aspect Self-Attention\nTransformer (ITST), uses an encoder-decoder architecture, utilizing three\nfeature extraction paths in the encoder, feature-engineered data for the\ndecoder and a self-attention mechanism. The results show that ITST outperforms\nstate-of-the-art models in terms of classification accuracy, which enables\npredictive maintenance for optical fiber amplifiers, reducing network downtimes\nand maintenance costs.", "AI": {"tldr": "A transformer-based model (ITST) improves fault diagnosis in optical fiber amplifiers using time-series data, outperforming state-of-the-art models.", "motivation": "To enhance predictive maintenance for optical fiber amplifiers by reducing downtimes and costs.", "method": "ITST uses an encoder-decoder architecture with three feature extraction paths, feature-engineered data, and self-attention.", "result": "ITST achieves higher classification accuracy than existing models.", "conclusion": "ITST enables effective predictive maintenance, improving network reliability and cost efficiency."}}
{"id": "2505.07817", "pdf": "https://arxiv.org/pdf/2505.07817", "abs": "https://arxiv.org/abs/2505.07817", "authors": ["Kanchana Ranasinghe", "Xiang Li", "Cristina Mata", "Jongwoo Park", "Michael S Ryoo"], "title": "Pixel Motion as Universal Representation for Robot Control", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "We present LangToMo, a vision-language-action framework structured as a\ndual-system architecture that uses pixel motion forecasts as intermediate\nrepresentations. Our high-level System 2, an image diffusion model, generates\ntext-conditioned pixel motion sequences from a single frame to guide robot\ncontrol. Pixel motion-a universal, interpretable, and motion-centric\nrepresentation-can be extracted from videos in a self-supervised manner,\nenabling diffusion model training on web-scale video-caption data. Treating\ngenerated pixel motion as learned universal representations, our low level\nSystem 1 module translates these into robot actions via motion-to-action\nmapping functions, which can be either hand-crafted or learned with minimal\nsupervision. System 2 operates as a high-level policy applied at sparse\ntemporal intervals, while System 1 acts as a low-level policy at dense temporal\nintervals. This hierarchical decoupling enables flexible, scalable, and\ngeneralizable robot control under both unsupervised and supervised settings,\nbridging the gap between language, motion, and action. Checkout\nhttps://kahnchana.github.io/LangToMo for visualizations.", "AI": {"tldr": "LangToMo is a dual-system framework using pixel motion forecasts to bridge language, motion, and action for robot control.", "motivation": "To create a scalable and generalizable robot control system that integrates language, motion, and action.", "method": "Uses a high-level System 2 (image diffusion model) for text-conditioned pixel motion generation and a low-level System 1 for motion-to-action translation.", "result": "Enables flexible and scalable robot control in both unsupervised and supervised settings.", "conclusion": "LangToMo successfully bridges the gap between language, motion, and action for robot control."}}
{"id": "2407.19031", "pdf": "https://arxiv.org/pdf/2407.19031", "abs": "https://arxiv.org/abs/2407.19031", "authors": ["Tony Shaska"], "title": "Artificial Neural Networks on Graded Vector Spaces", "categories": ["cs.AI", "cs.LG", "68T05, 68Q32, 16W50, 17B70, 58A50, 14A22", "I.2; I.2.6"], "comment": null, "summary": "This paper presents a transformative framework for artificial neural networks\nover graded vector spaces, tailored to model hierarchical and structured data\nin fields like algebraic geometry and physics. By exploiting the algebraic\nproperties of graded vector spaces, where features carry distinct weights, we\nextend classical neural networks with graded neurons, layers, and activation\nfunctions that preserve structural integrity. Grounded in group actions,\nrepresentation theory, and graded algebra, our approach combines theoretical\nrigor with practical utility.\n  We introduce graded neural architectures, loss functions prioritizing graded\ncomponents, and equivariant extensions adaptable to diverse gradings. Case\nstudies validate the framework's effectiveness, outperforming standard neural\nnetworks in tasks such as predicting invariants in weighted projective spaces\nand modeling supersymmetric systems.\n  This work establishes a new frontier in machine learning, merging\nmathematical sophistication with interdisciplinary applications. Future\nchallenges, including computational scalability and finite field extensions,\noffer rich opportunities for advancing this paradigm.", "AI": {"tldr": "A framework for graded neural networks, leveraging graded vector spaces to model hierarchical data, outperforming traditional networks in tasks like predicting invariants and modeling supersymmetric systems.", "motivation": "To address the limitations of classical neural networks in handling hierarchical and structured data, particularly in fields like algebraic geometry and physics, by incorporating graded algebraic properties.", "method": "Extends neural networks with graded neurons, layers, and activation functions, grounded in group actions, representation theory, and graded algebra. Introduces graded architectures, loss functions, and equivariant extensions.", "result": "Validated through case studies, the framework outperforms standard neural networks in tasks such as predicting invariants in weighted projective spaces and modeling supersymmetric systems.", "conclusion": "Establishes a new frontier in machine learning by merging mathematical rigor with interdisciplinary applications, with future challenges in scalability and finite field extensions."}}
{"id": "2505.06249", "pdf": "https://arxiv.org/pdf/2505.06249", "abs": "https://arxiv.org/abs/2505.06249", "authors": ["Geraldine Henningsen"], "title": "An Early Warning Model for Forced Displacement", "categories": ["stat.AP", "cs.CY", "cs.LG"], "comment": "13 pages, 6 figures", "summary": "Monitoring tools for anticipatory action are increasingly gaining traction to\nimprove the efficiency and timeliness of humanitarian responses. Whilst\npredictive models can now forecast conflicts with high accuracy, translating\nthese predictions into potential forced displacement movements remains\nchallenging because it is often unclear which precise events will trigger\nsignificant population movements. This paper presents a novel monitoring\napproach for refugee and asylum seeker flows that addresses this challenge.\nUsing gradient boosting classification, we combine conflict forecasts with a\ncomprehensive set of economic, political, and demographic variables to assess\ntwo distinct risks at the country of origin: the likelihood of significant\ndisplacement flows and the probability of sudden increases in these flows. The\nmodel generates country-specific monthly risk indices for these two events with\nprediction horizons of one, three, and six months. Our analysis shows high\naccuracy in predicting significant displacement flows and good accuracy in\nforecasting sudden increases in displacement--the latter being inherently more\ndifficult to predict, given the complexity of displacement triggers. We achieve\nthese results by including predictive factors beyond conflict, thereby\ndemonstrating that forced displacement risks can be assessed through an\nintegrated analysis of multiple country-level indicators. Whilst these risk\nindices provide valuable quantitative support for humanitarian planning, they\nshould always be understood as decision-support tools within a broader\nanalytical framework.", "AI": {"tldr": "A novel monitoring approach uses gradient boosting to predict refugee flows by combining conflict forecasts with economic, political, and demographic data, achieving high accuracy for displacement risks.", "motivation": "To improve humanitarian responses by addressing the challenge of translating conflict forecasts into actionable predictions of forced displacement.", "method": "Gradient boosting classification is used to combine conflict forecasts with economic, political, and demographic variables, generating monthly risk indices for displacement flows.", "result": "High accuracy in predicting significant displacement flows and good accuracy for sudden increases, demonstrating the value of multi-indicator analysis.", "conclusion": "The risk indices are effective decision-support tools but should be used within a broader analytical framework for humanitarian planning."}}
{"id": "2307.00811", "pdf": "https://arxiv.org/pdf/2307.00811", "abs": "https://arxiv.org/abs/2307.00811", "authors": ["Dongwei Wang", "Zhi Han", "Yanmei Wang", "Xiai Chen", "Baichen Liu", "Yandong Tang"], "title": "Review helps learn better: Temporal Supervised Knowledge Distillation", "categories": ["cs.CV", "cs.AI"], "comment": "This work is outdated and needs new improvements to make it valuable", "summary": "Reviewing plays an important role when learning knowledge. The knowledge\nacquisition at a certain time point may be strongly inspired with the help of\nprevious experience. Thus the knowledge growing procedure should show strong\nrelationship along the temporal dimension. In our research, we find that during\nthe network training, the evolution of feature map follows temporal sequence\nproperty. A proper temporal supervision may further improve the network\ntraining performance. Inspired by this observation, we propose Temporal\nSupervised Knowledge Distillation (TSKD). Specifically, we extract the\nspatiotemporal features in the different training phases of student by\nconvolutional Long Short-term memory network (Conv-LSTM). Then, we train the\nstudent net through a dynamic target, rather than static teacher network\nfeatures. This process realizes the refinement of old knowledge in student\nnetwork, and utilizes it to assist current learning. Extensive experiments\nverify the effectiveness and advantages of our method over existing knowledge\ndistillation methods, including various network architectures and different\ntasks (image classification and object detection) .", "AI": {"tldr": "The paper proposes Temporal Supervised Knowledge Distillation (TSKD), leveraging temporal sequence properties in feature map evolution to improve network training by refining old knowledge dynamically.", "motivation": "Knowledge acquisition benefits from temporal relationships in learning, and temporal supervision can enhance network training performance.", "method": "Uses Conv-LSTM to extract spatiotemporal features across training phases, training the student network with dynamic targets instead of static teacher features.", "result": "Outperforms existing knowledge distillation methods in tasks like image classification and object detection.", "conclusion": "TSKD effectively refines and utilizes temporal knowledge, improving learning performance across diverse tasks."}}
{"id": "2410.15665", "pdf": "https://arxiv.org/pdf/2410.15665", "abs": "https://arxiv.org/abs/2410.15665", "authors": ["Xun Jiang", "Feng Li", "Han Zhao", "Jiahao Qiu", "Jiaying Wang", "Jun Shao", "Shihao Xu", "Shu Zhang", "Weiling Chen", "Xavier Tang", "Yize Chen", "Mengyue Wu", "Weizhi Ma", "Mengdi Wang", "Tianqiao Chen"], "title": "Long Term Memory: The Foundation of AI Self-Evolution", "categories": ["cs.AI", "cs.LG"], "comment": "56 pages, 13 figures", "summary": "Large language models (LLMs) like GPTs, trained on vast datasets, have\ndemonstrated impressive capabilities in language understanding, reasoning, and\nplanning, achieving human-level performance in various tasks. Most studies\nfocus on enhancing these models by training on ever-larger datasets to build\nmore powerful foundation models. While training stronger models is important,\nenabling models to evolve during inference is equally crucial, a process we\nrefer to as AI self-evolution. Unlike large-scale training, self-evolution may\nrely on limited data or interactions. Inspired by the columnar organization of\nthe human cerebral cortex, we hypothesize that AI models could develop\ncognitive abilities and build internal representations through iterative\ninteractions with their environment. To achieve this, models need long-term\nmemory (LTM) to store and manage processed interaction data. LTM supports\nself-evolution by representing diverse experiences across environments and\nagents. In this report, we explore AI self-evolution and its potential to\nenhance models during inference. We examine LTM's role in lifelong learning,\nallowing models to evolve based on accumulated interactions. We outline the\nstructure of LTM and the systems needed for effective data retention and\nrepresentation. We also classify approaches for building personalized models\nwith LTM data and show how these models achieve self-evolution through\ninteraction. Using LTM, our multi-agent framework OMNE achieved first place on\nthe GAIA benchmark, demonstrating LTM's potential for AI self-evolution.\nFinally, we present a roadmap for future research, emphasizing the importance\nof LTM for advancing AI technology and its practical applications.", "AI": {"tldr": "The paper explores AI self-evolution through long-term memory (LTM) during inference, enabling models to improve iteratively with limited data, inspired by human cognitive processes.", "motivation": "Current LLMs rely on large-scale training, but self-evolution during inference is crucial for lifelong learning and adaptability, inspired by human cognitive development.", "method": "Proposes LTM to store and manage interaction data, enabling models to evolve iteratively. Tests a multi-agent framework (OMNE) on the GAIA benchmark.", "result": "OMNE achieved first place on GAIA, demonstrating LTM's effectiveness for AI self-evolution.", "conclusion": "LTM is vital for advancing AI self-evolution and practical applications, with future research needed to refine its implementation."}}
{"id": "2505.06263", "pdf": "https://arxiv.org/pdf/2505.06263", "abs": "https://arxiv.org/abs/2505.06263", "authors": ["Yiping Meng", "Yiming Sun"], "title": "From Biometrics to Environmental Control: AI-Enhanced Digital Twins for Personalized Health Interventions in Healing Landscapes", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "The dynamic nature of human health and comfort calls for adaptive systems\nthat respond to individual physiological needs in real time. This paper\npresents an AI-enhanced digital twin framework that integrates biometric\nsignals, specifically electrocardiogram (ECG) data, with environmental\nparameters such as temperature, humidity, and ventilation. Leveraging\nIoT-enabled sensors and biometric monitoring devices, the system continuously\nacquires, synchronises, and preprocesses multimodal data streams to construct a\nresponsive virtual replica of the physical environment. To validate this\nframework, a detailed case study is conducted using the MIT-BIH noise stress\ntest dataset. ECG signals are filtered and segmented using dynamic sliding\nwindows, followed by extracting heart rate variability (HRV) features such as\nSDNN, BPM, QTc, and LF/HF ratio. Relative deviation metrics are computed\nagainst clean baselines to quantify stress responses. A random forest\nclassifier is trained to predict stress levels across five categories, and\nShapley Additive exPlanations (SHAP) is used to interpret model behaviour and\nidentify key contributing features. These predictions are mapped to a\nstructured set of environmental interventions using a Five Level Stress\nIntervention Mapping, which activates multi-scale responses across personal,\nroom, building, and landscape levels. This integration of physiological\ninsight, explainable AI, and adaptive control establishes a new paradigm for\nhealth-responsive built environments. It lays the foundation for the future\ndevelopment of intelligent, personalised healing spaces.", "AI": {"tldr": "An AI-enhanced digital twin framework integrates ECG and environmental data to create adaptive health-responsive environments, validated using stress level predictions and interventions.", "motivation": "To address the dynamic needs of human health and comfort by leveraging real-time biometric and environmental data for adaptive systems.", "method": "Uses IoT sensors and biometric devices to collect ECG and environmental data, processes it with dynamic sliding windows and HRV features, and employs a random forest classifier with SHAP for stress prediction and interpretation.", "result": "Validated with MIT-BIH dataset, the framework predicts stress levels and maps them to multi-scale environmental interventions.", "conclusion": "The framework establishes a new paradigm for health-responsive built environments, paving the way for intelligent, personalized healing spaces."}}
{"id": "2310.02719", "pdf": "https://arxiv.org/pdf/2310.02719", "abs": "https://arxiv.org/abs/2310.02719", "authors": ["Hongyi Fan", "Joe Kileel", "Benjamin Kimia"], "title": "Condition numbers in multiview geometry, instability in relative pose estimation, and RANSAC", "categories": ["cs.CV", "cs.NA", "math.NA"], "comment": "v2: additional experiments; correction to Theorem 20 (with current\n  numbering); other edits", "summary": "In this paper, we introduce a general framework for analyzing the numerical\nconditioning of minimal problems in multiple view geometry, using tools from\ncomputational algebra and Riemannian geometry. Special motivation comes from\nthe fact that relative pose estimation, based on standard 5-point or 7-point\nRandom Sample Consensus (RANSAC) algorithms, can fail even when no outliers are\npresent and there is enough data to support a hypothesis. We argue that these\ncases arise due to the intrinsic instability of the 5- and 7-point minimal\nproblems. We apply our framework to characterize the instabilities, both in\nterms of the world scenes that lead to infinite condition number, and directly\nin terms of ill-conditioned image data. The approach produces computational\ntests for assessing the condition number before solving the minimal problem.\nLastly, synthetic and real data experiments suggest that RANSAC serves not only\nto remove outliers, but in practice it also selects for well-conditioned image\ndata, which is consistent with our theory.", "AI": {"tldr": "A framework for analyzing numerical conditioning in minimal problems of multiple view geometry, revealing instabilities in 5- and 7-point RANSAC algorithms and offering computational tests for condition assessment.", "motivation": "Addressing failures in relative pose estimation via RANSAC, even with sufficient data and no outliers, due to intrinsic instability in minimal problems.", "method": "Uses computational algebra and Riemannian geometry to analyze instability, characterizing problematic scenes and image data, and developing condition number tests.", "result": "Identifies instabilities in minimal problems and shows RANSAC implicitly selects well-conditioned data.", "conclusion": "The framework provides insights into minimal problem conditioning, with practical implications for RANSAC-based pose estimation."}}
{"id": "2410.17500", "pdf": "https://arxiv.org/pdf/2410.17500", "abs": "https://arxiv.org/abs/2410.17500", "authors": ["Ryota Maruo", "Koh Takeuchi", "Hisashi Kashima"], "title": "Learning Fair and Preferable Allocations through Neural Network", "categories": ["cs.AI"], "comment": null, "summary": "The fair allocation of indivisible resources is a fundamental problem.\nExisting research has developed various allocation mechanisms or algorithms to\nsatisfy different fairness notions. For example, round robin (RR) was proposed\nto meet the fairness criterion known as envy-freeness up to one good (EF1).\nExpert algorithms without mathematical formulations are used in real-world\nresource allocation problems to find preferable outcomes for users. Therefore,\nwe aim to design mechanisms that strictly satisfy good properties with\nreplicating expert knowledge. However, this problem is challenging because such\nheuristic rules are often difficult to formalize mathematically, complicating\ntheir integration into theoretical frameworks. Additionally, formal algorithms\nstruggle to find preferable outcomes, and directly replicating these implicit\nrules can result in unfair allocations because human decision-making can\nintroduce biases. In this paper, we aim to learn implicit allocation mechanisms\nfrom examples while strictly satisfying fairness constraints, specifically\nfocusing on learning EF1 allocation mechanisms through supervised learning on\nexamples of reported valuations and corresponding allocation outcomes produced\nby implicit rules. To address this, we developed a neural RR (NRR), a novel\nneural network that parameterizes RR. NRR is built from a differentiable\nrelaxation of RR and can be trained to learn the agent ordering used for RR. We\nconducted experiments to learn EF1 allocation mechanisms from examples,\ndemonstrating that our method outperforms baselines in terms of the proximity\nof predicted allocations and other metrics.", "AI": {"tldr": "The paper proposes a neural round robin (NRR) method to learn implicit allocation mechanisms from examples while ensuring envy-freeness up to one good (EF1), outperforming baselines.", "motivation": "Existing heuristic rules for resource allocation are hard to formalize mathematically, and human biases can lead to unfair outcomes. The goal is to design mechanisms that replicate expert knowledge while strictly satisfying fairness constraints.", "method": "The authors developed NRR, a neural network parameterizing round robin (RR), using supervised learning on examples of valuations and allocations. NRR is trained to learn the agent ordering for RR.", "result": "Experiments show NRR outperforms baselines in predicting allocations that are closer to the desired EF1 outcomes.", "conclusion": "The NRR method effectively learns implicit allocation mechanisms while adhering to fairness constraints, offering a promising approach for fair resource allocation."}}
{"id": "2505.06291", "pdf": "https://arxiv.org/pdf/2505.06291", "abs": "https://arxiv.org/abs/2505.06291", "authors": ["Wei Xiong", "Junming Lin", "Jiangtong Li", "Jie Li", "Changjun Jiang"], "title": "ALFEE: Adaptive Large Foundation Model for EEG Representation", "categories": ["eess.SP", "cs.CE", "cs.HC", "cs.LG"], "comment": "17pages, 17 figures", "summary": "While foundation models excel in text, image, and video domains, the critical\nbiological signals, particularly electroencephalography(EEG), remain\nunderexplored. EEG benefits neurological research with its high temporal\nresolution, operational practicality, and safety profile. However, low\nsignal-to-noise ratio, inter-subject variability, and cross-paradigm\ndifferences hinder the generalization of current models. Existing methods often\nemploy simplified strategies, such as a single loss function or a\nchannel-temporal joint representation module, and suffer from a domain gap\nbetween pretraining and evaluation tasks that compromises efficiency and\nadaptability. To address these limitations, we propose the Adaptive Large\nFoundation model for EEG signal representation(ALFEE) framework, a novel hybrid\ntransformer architecture with two learning stages for robust EEG representation\nlearning. ALFEE employs a hybrid attention that separates channel-wise feature\naggregation from temporal dynamics modeling, enabling robust EEG representation\nwith variable channel configurations. A channel encoder adaptively compresses\nvariable channel information, a temporal encoder captures task-guided\nevolution, and a hybrid decoder reconstructs signals in both temporal and\nfrequency domains. During pretraining, ALFEE optimizes task prediction, channel\nand temporal mask reconstruction, and temporal forecasting to enhance\nmulti-scale and multi-channel representation. During fine-tuning, a full-model\nadaptation with a task-specific token dictionary and a cross-attention layer\nboosts performance across multiple tasks. After 25,000 hours of pretraining,\nextensive experimental results on six downstream EEG tasks demonstrate the\nsuperior performance of ALFEE over existing models. Our ALFEE framework\nestablishes a scalable foundation for biological signal analysis with\nimplementation at https://github.com/xw1216/ALFEE.", "AI": {"tldr": "ALFEE is a hybrid transformer framework for EEG signal representation, addressing challenges like low signal-to-noise and domain gaps with adaptive channel-temporal learning and multi-task pretraining.", "motivation": "EEG signals are underexplored in foundation models despite their neurological research benefits. Current methods struggle with generalization due to noise, variability, and domain gaps.", "method": "ALFEE uses a hybrid transformer with channel and temporal encoders, a hybrid decoder, and multi-task pretraining (prediction, reconstruction, forecasting). Fine-tuning employs task-specific tokens and cross-attention.", "result": "ALFEE outperforms existing models on six EEG tasks after 25,000 hours of pretraining, demonstrating robust representation learning.", "conclusion": "ALFEE provides a scalable foundation for EEG analysis, bridging gaps in biological signal modeling with adaptable architecture and open-source implementation."}}
{"id": "2312.02156", "pdf": "https://arxiv.org/pdf/2312.02156", "abs": "https://arxiv.org/abs/2312.02156", "authors": ["Kangfu Mei", "Luis Figueroa", "Zhe Lin", "Zhihong Ding", "Scott Cohen", "Vishal M. Patel"], "title": "Latent Feature-Guided Diffusion Models for Shadow Removal", "categories": ["cs.CV", "cs.AI"], "comment": "project page see https://kfmei.com/shadow-diffusion/", "summary": "Recovering textures under shadows has remained a challenging problem due to\nthe difficulty of inferring shadow-free scenes from shadow images. In this\npaper, we propose the use of diffusion models as they offer a promising\napproach to gradually refine the details of shadow regions during the diffusion\nprocess. Our method improves this process by conditioning on a learned latent\nfeature space that inherits the characteristics of shadow-free images, thus\navoiding the limitation of conventional methods that condition on degraded\nimages only. Additionally, we propose to alleviate potential local optima\nduring training by fusing noise features with the diffusion network. We\ndemonstrate the effectiveness of our approach which outperforms the previous\nbest method by 13% in terms of RMSE on the AISTD dataset. Further, we explore\ninstance-level shadow removal, where our model outperforms the previous best\nmethod by 82% in terms of RMSE on the DESOBA dataset.", "AI": {"tldr": "The paper proposes using diffusion models to recover textures under shadows, outperforming previous methods by 13-82% in RMSE on datasets.", "motivation": "Recovering textures under shadows is challenging due to the difficulty of inferring shadow-free scenes from shadow images.", "method": "The method uses diffusion models conditioned on a learned latent feature space and fuses noise features to avoid local optima during training.", "result": "The approach outperforms previous methods by 13% (AISTD) and 82% (DESOBA) in RMSE.", "conclusion": "Diffusion models with learned latent features and noise fusion effectively improve shadow removal, setting new benchmarks."}}
{"id": "2412.19507", "pdf": "https://arxiv.org/pdf/2412.19507", "abs": "https://arxiv.org/abs/2412.19507", "authors": ["Zhaolong Ling", "Honghui Peng", "Yiwen Zhang", "Debo Cheng", "Xingyu Wu", "Peng Zhou", "Kui Yu"], "title": "Hybrid Local Causal Discovery", "categories": ["cs.AI"], "comment": "This paper has been accepted for publication in the Proceedings of\n  the 34th International Joint Conference on Artificial Intelligence (IJCAI\n  2025)", "summary": "Local causal discovery aims to learn and distinguish the direct causes and\neffects of a target variable from observed data. Existing constraint-based\nlocal causal discovery methods use AND or OR rules in constructing the local\ncausal skeleton, but using either rule alone is prone to produce cascading\nerrors in the learned local causal skeleton, and thus impacting the inference\nof local causal relationships. On the other hand, directly applying score-based\nglobal causal discovery methods to local causal discovery may randomly return\nincorrect results due to the existence of local equivalence classes. To address\nthe above issues, we propose a Hybrid Local Causal Discovery algorithm, called\nHLCD. Specifically, HLCD initially utilizes a constraint-based approach\ncombined with the OR rule to obtain a candidate skeleton and then employs a\nscore-based method to eliminate redundant portions in the candidate skeleton.\nFurthermore, during the local causal orientation phase, HLCD distinguishes\nbetween V-structures and equivalence classes by comparing the local structure\nscores between the two, thereby avoiding orientation interference caused by\nlocal equivalence classes. We conducted extensive experiments with seven\nstate-of-the-art competitors on 14 benchmark Bayesian network datasets, and the\nexperimental results demonstrate that HLCD significantly outperforms existing\nlocal causal discovery algorithms.", "AI": {"tldr": "HLCD is a hybrid algorithm combining constraint-based and score-based methods to improve local causal discovery by reducing errors and avoiding incorrect results from equivalence classes.", "motivation": "Existing methods using AND or OR rules alone lead to cascading errors, while global methods may return incorrect results due to local equivalence classes.", "method": "HLCD uses a constraint-based approach with the OR rule for a candidate skeleton, then a score-based method to refine it. It distinguishes V-structures from equivalence classes during orientation.", "result": "HLCD outperforms seven competitors on 14 benchmark datasets.", "conclusion": "HLCD effectively addresses issues in local causal discovery by combining constraint and score-based methods, achieving superior performance."}}
{"id": "2505.06310", "pdf": "https://arxiv.org/pdf/2505.06310", "abs": "https://arxiv.org/abs/2505.06310", "authors": ["Tao Shen", "Jethro Browell", "Daniela Castro-Camilo"], "title": "Adaptive Bayesian Very Short-Term Wind Power Forecasting Based on the Generalised Logit Transformation", "categories": ["stat.AP", "cs.LG"], "comment": "31 pages, 10 figures and tables. Submitted to International Journal\n  of Forecasting", "summary": "Wind power plays an increasingly significant role in achieving the 2050 Net\nZero Strategy. Despite its rapid growth, its inherent variability presents\nchallenges in forecasting. Accurately forecasting wind power generation is one\nkey demand for the stable and controllable integration of renewable energy into\nexisting grid operations. This paper proposes an adaptive method for very\nshort-term forecasting that combines the generalised logit transformation with\na Bayesian approach. The generalised logit transformation processes\ndouble-bounded wind power data to an unbounded domain, facilitating the\napplication of Bayesian methods. A novel adaptive mechanism for updating the\ntransformation shape parameter is introduced to leverage Bayesian updates by\nrecovering a small sample of representative data. Four adaptive forecasting\nmethods are investigated, evaluating their advantages and limitations through\nan extensive case study of over 100 wind farms ranging four years in the UK.\nThe methods are evaluated using the Continuous Ranked Probability Score and we\npropose the use of functional reliability diagrams to assess calibration.\nResults indicate that the proposed Bayesian method with adaptive shape\nparameter updating outperforms benchmarks, yielding consistent improvements in\nCRPS and forecast reliability. The method effectively addresses uncertainty,\nensuring robust and accurate probabilistic forecasting which is essential for\ngrid integration and decision-making.", "AI": {"tldr": "The paper proposes an adaptive Bayesian method for very short-term wind power forecasting, combining generalized logit transformation with adaptive shape parameter updates, outperforming benchmarks in accuracy and reliability.", "motivation": "Accurate wind power forecasting is crucial for stable grid integration due to its variability, but existing methods face challenges in handling uncertainty and small data samples.", "method": "Uses generalized logit transformation to process wind power data, introduces adaptive shape parameter updates, and evaluates four forecasting methods using Bayesian approaches.", "result": "The proposed method outperforms benchmarks, improving Continuous Ranked Probability Score (CRPS) and forecast reliability, as validated by a UK wind farm case study.", "conclusion": "The adaptive Bayesian method provides robust probabilistic forecasting, addressing uncertainty and enhancing grid integration and decision-making."}}
{"id": "2312.14999", "pdf": "https://arxiv.org/pdf/2312.14999", "abs": "https://arxiv.org/abs/2312.14999", "authors": ["Tin Nguyen", "Peijie Chen", "Anh Totti Nguyen"], "title": "Leveraging Habitat Information for Fine-grained Bird Identification", "categories": ["cs.CV"], "comment": null, "summary": "Traditional bird classifiers mostly rely on the visual characteristics of\nbirds. Some prior works even train classifiers to be invariant to the\nbackground, completely discarding the living environment of birds. Instead, we\nare the first to explore integrating habitat information, one of the four major\ncues for identifying birds by ornithologists, into modern bird classifiers. We\nfocus on two leading model types: (1) CNNs and ViTs trained on the downstream\nbird datasets; and (2) original, multi-modal CLIP. Training CNNs and ViTs with\nhabitat-augmented data results in an improvement of up to +0.83 and +0.23\npoints on NABirds and CUB-200, respectively. Similarly, adding habitat\ndescriptors to the prompts for CLIP yields a substantial accuracy boost of up\nto +0.99 and +1.1 points on NABirds and CUB-200, respectively. We find\nconsistent accuracy improvement after integrating habitat features into the\nimage augmentation process and into the textual descriptors of vision-language\nCLIP classifiers. Code is available at:\nhttps://anonymous.4open.science/r/reasoning-8B7E/.", "AI": {"tldr": "The paper explores integrating habitat information into bird classifiers, improving accuracy for CNNs, ViTs, and CLIP models.", "motivation": "Traditional bird classifiers ignore habitat, a key cue for bird identification. This work aims to leverage habitat data for better performance.", "method": "Augments CNNs, ViTs, and CLIP with habitat data via image augmentation and textual descriptors.", "result": "Improvements of up to +0.83 (NABirds) and +0.23 (CUB-200) for CNNs/ViTs, and +0.99 (NABirds) and +1.1 (CUB-200) for CLIP.", "conclusion": "Integrating habitat features consistently boosts classifier accuracy, validating its importance."}}
{"id": "2501.18009", "pdf": "https://arxiv.org/pdf/2501.18009", "abs": "https://arxiv.org/abs/2501.18009", "authors": ["Lan Pan", "Hanbo Xie", "Robert C. Wilson"], "title": "Large Language Models Think Too Fast To Explore Effectively", "categories": ["cs.AI", "q-bio.NC"], "comment": "21 pages, 16 figures, under review", "summary": "Large Language Models (LLMs) have emerged with many intellectual capacities.\nWhile numerous benchmarks assess their intelligence, limited attention has been\ngiven to their ability to explore--an essential capacity for discovering new\ninformation and adapting to novel environments in both natural and artificial\nsystems. The extent to which LLMs can effectively explore, particularly in\nopen-ended tasks, remains unclear. This study investigates whether LLMs can\nsurpass humans in exploration during an open-ended task, using Little Alchemy 2\nas a paradigm, where agents combine elements to discover new ones. Results show\nmost LLMs underperform compared to humans, except for the o1 model, with\ntraditional LLMs relying primarily on uncertainty-driven strategies, unlike\nhumans who balance uncertainty and empowerment. Results indicate that\ntraditional reasoning-focused LLMs, such as GPT-4o, exhibit a significantly\nfaster and less detailed reasoning process, limiting their exploratory\nperformance. In contrast, the DeepSeek reasoning model demonstrates prolonged,\niterative thought processes marked by repetitive analysis of combinations and\npast trials, reflecting a more thorough and human-like exploration strategy.\nRepresentational analysis of the models with Sparse Autoencoders (SAE) revealed\nthat uncertainty and choices are represented at earlier transformer blocks,\nwhile empowerment values are processed later, causing LLMs to think too fast\nand make premature decisions, hindering effective exploration. These findings\nshed light on the limitations of LLM exploration and suggest directions for\nimproving their adaptability.", "AI": {"tldr": "LLMs' exploration ability in open-ended tasks is studied using Little Alchemy 2. Most LLMs underperform humans, except the o1 model, due to fast, less detailed reasoning. DeepSeek shows more human-like exploration. SAE analysis reveals LLMs process uncertainty early and empowerment late, limiting exploration.", "motivation": "To assess LLMs' exploration capacity, an essential but underexplored aspect of intelligence, and compare it to human performance in open-ended tasks.", "method": "Using Little Alchemy 2, LLMs and humans combine elements to discover new ones. Performance and strategies (uncertainty-driven vs. empowerment-balanced) are analyzed. Sparse Autoencoders (SAE) examine model representations.", "result": "Most LLMs underperform humans; o1 model is an exception. Traditional LLMs (e.g., GPT-4o) reason quickly but superficially, while DeepSeek exhibits iterative, human-like exploration. SAE shows LLMs process uncertainty early and empowerment late, hindering exploration.", "conclusion": "LLMs' exploration is limited by fast, shallow reasoning and imbalanced processing of uncertainty and empowerment. Improvements should focus on more iterative, human-like strategies."}}
{"id": "2505.06375", "pdf": "https://arxiv.org/pdf/2505.06375", "abs": "https://arxiv.org/abs/2505.06375", "authors": ["Nahshon Mokua Obiri", "Kristof Van Laerhoven"], "title": "A Comprehensive Data Description for LoRaWAN Path Loss Measurements in an Indoor Office Setting: Effects of Environmental Factors", "categories": ["cs.NI", "cs.AR", "cs.LG", "eess.SP"], "comment": "This is a peer-reviewed article with the help of IEEE Access editors.\n  The relevant DOI will be availed soon", "summary": "This paper presents a comprehensive dataset of LoRaWAN technology path loss\nmeasurements collected in an indoor office environment, focusing on quantifying\nthe effects of environmental factors on signal propagation. Utilizing a network\nof six strategically placed LoRaWAN end devices (EDs) and a single indoor\ngateway (GW) at the University of Siegen, City of Siegen, Germany, we\nsystematically measured signal strength indicators such as the Received Signal\nStrength Indicator (RSSI) and the Signal-to-Noise Ratio (SNR) under various\nenvironmental conditions, including temperature, relative humidity, carbon\ndioxide (CO$_2$) concentration, barometric pressure, and particulate matter\nlevels (PM$_{2.5}$). Our empirical analysis confirms that transient phenomena\nsuch as reflections, scattering, interference, occupancy patterns (induced by\nenvironmental parameter variations), and furniture rearrangements can alter\nsignal attenuation by as much as 10.58 dB, highlighting the dynamic nature of\nindoor propagation. As an example of how this dataset can be utilized, we\ntested and evaluated a refined Log-Distance Path Loss and Shadowing Model that\nintegrates both structural obstructions (Multiple Walls) and Environmental\nParameters (LDPLSM-MW-EP). Compared to a baseline model that considers only\nMultiple Walls (LDPLSM-MW), the enhanced approach reduced the root mean square\nerror (RMSE) from 10.58 dB to 8.04 dB and increased the coefficient of\ndetermination (R$^2$) from 0.6917 to 0.8222. By capturing the extra effects of\nenvironmental conditions and occupancy dynamics, this improved model provides\nvaluable insights for optimizing power usage and prolonging device battery\nlife, enhancing network reliability in indoor Internet of Things (IoT)\ndeployments, among other applications. This dataset offers a solid foundation\nfor future research and development in indoor wireless communication.", "AI": {"tldr": "The paper presents a dataset of LoRaWAN path loss measurements in an indoor office, showing how environmental factors affect signal propagation. A refined model integrating structural and environmental parameters improved accuracy.", "motivation": "To quantify the impact of environmental factors on LoRaWAN signal propagation in indoor settings and improve path loss models for better IoT network reliability.", "method": "Used six LoRaWAN end devices and a gateway to measure RSSI and SNR under varying environmental conditions. Tested a refined Log-Distance Path Loss and Shadowing Model (LDPLSM-MW-EP).", "result": "The refined model reduced RMSE from 10.58 dB to 8.04 dB and increased R\u00b2 from 0.6917 to 0.8222, demonstrating better accuracy.", "conclusion": "The dataset and improved model provide insights for optimizing IoT deployments, enhancing network reliability, and extending device battery life."}}
{"id": "2401.13174", "pdf": "https://arxiv.org/pdf/2401.13174", "abs": "https://arxiv.org/abs/2401.13174", "authors": ["Dong Zhang", "Pingcheng Dong", "Long Chen", "Kwang-Ting Cheng"], "title": "Towards Complementary Knowledge Distillation for Efficient Dense Image Prediction", "categories": ["cs.CV"], "comment": "under submission", "summary": "It has been revealed that small efficient dense image prediction (EDIP)\nmodels, trained using the knowledge distillation (KD) framework, encounter two\nkey challenges, including maintaining boundary region completeness and\npreserving target region connectivity, despite their favorable capacity to\nrecognize main object regions. In this work, we propose a complementary\nboundary and context distillation (BCD) method within the KD framework for\nEDIPs, which facilitates the targeted knowledge transfer from large accurate\nteacher models to compact efficient student models. Specifically, the boundary\ndistillation component focuses on extracting explicit object-level semantic\nboundaries from the hierarchical feature maps of the backbone network to\nenhance the student model's mask quality in boundary regions. Concurrently, the\ncontext distillation component leverages self-relations as a bridge to transfer\nimplicit pixel-level contexts from the teacher model to the student model,\nensuring strong connectivity in target regions. Our proposed BCD method is\nspecifically designed for EDIP tasks and is characterized by its simplicity and\nefficiency. Extensive experimental results across semantic segmentation, object\ndetection, and instance segmentation on various representative datasets\ndemonstrate that our method can outperform existing methods without requiring\nextra supervisions or incurring increased inference costs, resulting in\nwell-defined object boundaries and smooth connecting regions.", "AI": {"tldr": "The paper proposes a BCD method within the KD framework to improve boundary and context distillation for efficient dense image prediction models, enhancing mask quality and connectivity without extra costs.", "motivation": "Small EDIP models struggle with boundary completeness and target region connectivity despite recognizing main object regions.", "method": "BCD method includes boundary distillation (extracting explicit boundaries) and context distillation (transferring implicit pixel-level contexts).", "result": "BCD outperforms existing methods in semantic segmentation, object detection, and instance segmentation, improving boundaries and connectivity.", "conclusion": "BCD is simple, efficient, and effective for EDIP tasks, requiring no extra supervision or inference costs."}}
{"id": "2501.19112", "pdf": "https://arxiv.org/pdf/2501.19112", "abs": "https://arxiv.org/abs/2501.19112", "authors": ["Lara Lawniczak", "Christoph Benzm\u00fcller"], "title": "Logical Modalities within the European AI Act: An Analysis", "categories": ["cs.AI", "cs.CY", "cs.LO", "68T01 68T27 68T30 03Axx 03B16 03B35 03B45 03B60 03B70", "I.2.0; I.2.3; I.2.4; J.1"], "comment": "Extended preprint of paper accepted for ICAIL 2025; 15 pages, 19\n  figures", "summary": "The paper presents a comprehensive analysis of the European AI Act in terms\nof its logical modalities, with the aim of preparing its formal representation,\nfor example, within the logic-pluralistic Knowledge Engineering Framework and\nMethodology (LogiKEy). LogiKEy develops computational tools for normative\nreasoning based on formal methods, employing Higher-Order Logic (HOL) as a\nunifying meta-logic to integrate diverse logics through shallow semantic\nembeddings. This integration is facilitated by Isabelle/HOL, a proof assistant\ntool equipped with several automated theorem provers. The modalities within the\nAI Act and the logics suitable for their representation are discussed. For a\nselection of these logics, embeddings in HOL are created, which are then used\nto encode sample paragraphs. Initial experiments evaluate the suitability of\nthese embeddings for automated reasoning, and highlight key challenges on the\nway to more robust reasoning capabilities.", "AI": {"tldr": "The paper analyzes the European AI Act's logical modalities for formal representation using LogiKEy, embedding selected logics in HOL for automated reasoning and identifying challenges.", "motivation": "To prepare a formal representation of the European AI Act's logical modalities within the LogiKEy framework for normative reasoning.", "method": "Uses Higher-Order Logic (HOL) and Isabelle/HOL to embed diverse logics, encoding sample paragraphs and evaluating embeddings for automated reasoning.", "result": "Initial experiments assess the suitability of embeddings and highlight challenges for robust reasoning.", "conclusion": "The study advances formal representation of the AI Act but identifies key challenges for future work."}}
{"id": "2505.06386", "pdf": "https://arxiv.org/pdf/2505.06386", "abs": "https://arxiv.org/abs/2505.06386", "authors": ["Donghao Ren", "Fred Hohman", "Halden Lin", "Dominik Moritz"], "title": "Embedding Atlas: Low-Friction, Interactive Embedding Visualization", "categories": ["cs.HC", "cs.LG"], "comment": "Website: https://apple.github.io/embedding-atlas/", "summary": "Embedding projections are popular for visualizing large datasets and models.\nHowever, people often encounter \"friction\" when using embedding visualization\ntools: (1) barriers to adoption, e.g., tedious data wrangling and loading,\nscalability limits, no integration of results into existing workflows, and (2)\nlimitations in possible analyses, without integration with external tools to\nadditionally show coordinated views of metadata. In this paper, we present\nEmbedding Atlas, a scalable, interactive visualization tool designed to make\ninteracting with large embeddings as easy as possible. Embedding Atlas uses\nmodern web technologies and advanced algorithms -- including density-based\nclustering, and automated labeling -- to provide a fast and rich data analysis\nexperience at scale. We evaluate Embedding Atlas with a competitive analysis\nagainst other popular embedding tools, showing that Embedding Atlas's feature\nset specifically helps reduce friction, and report a benchmark on its real-time\nrendering performance with millions of points. Embedding Atlas is available as\nopen source to support future work in embedding-based analysis.", "AI": {"tldr": "Embedding Atlas is a scalable, interactive tool designed to reduce friction in embedding visualization by addressing adoption barriers and analysis limitations.", "motivation": "Existing embedding visualization tools face adoption barriers (e.g., data wrangling, scalability) and limited analyses due to lack of integration with external tools.", "method": "Embedding Atlas uses modern web technologies, density-based clustering, and automated labeling for fast, rich analysis at scale.", "result": "Competitive analysis shows Embedding Atlas reduces friction, and benchmarks confirm real-time rendering with millions of points.", "conclusion": "Embedding Atlas is open-source, supporting future embedding-based analysis with improved usability and performance."}}
{"id": "2404.04856", "pdf": "https://arxiv.org/pdf/2404.04856", "abs": "https://arxiv.org/abs/2404.04856", "authors": ["Chenguang Liu", "Chisheng Wang", "Feifei Dong", "Xiayang Xiao", "Xin Su", "Chuanhua Zhu", "Dejin Zhang", "Qingquan Li"], "title": "Msmsfnet: a multi-stream and multi-scale fusion net for edge detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Edge detection is a long-standing problem in computer vision. Despite the\nefficiency of existing algorithms, their performance, however, rely heavily on\nthe pre-trained weights of the backbone network on the ImageNet dataset. The\nuse of pre-trained weights in previous methods significantly increases the\ndifficulty to design new models for edge detection without relying on existing\nwell-trained ImageNet models, as pre-training the model on the ImageNet dataset\nis expensive and becomes compulsory to ensure the fairness of comparison.\nBesides, the pre-training and fine-tuning strategy is not always useful and\nsometimes even inaccessible. For instance, the pre-trained weights on the\nImageNet dataset are unlikely to be helpful for edge detection in Synthetic\nAperture Radar (SAR) images due to strong differences in the statistics between\noptical images and SAR images. Moreover, no dataset has comparable size to the\nImageNet dataset for SAR image processing. In this work, we study the\nperformance achievable by state-of-the-art deep learning based edge detectors\nin publicly available datasets when they are trained from scratch, and devise a\nnew network architecture, the multi-stream and multi-scale fusion net\n(msmsfnet), for edge detection. We show in our experiments that by training all\nmodels from scratch, our model outperforms state-of-the-art edge detectors in\nthree publicly available datasets. We also demonstrate the efficiency of our\nmodel for edge detection in SAR images, where no useful pre-trained weight is\navailable. Finally, We show that our model is able to achieve competitive\nperformance on the BSDS500 dataset when the pre-trained weights are used.", "AI": {"tldr": "The paper introduces a new network architecture (msmsfnet) for edge detection, trained from scratch, outperforming state-of-the-art methods without relying on pre-trained weights.", "motivation": "Existing edge detection methods depend heavily on pre-trained ImageNet weights, which are costly and not always applicable (e.g., for SAR images). This limits model design and fairness in comparisons.", "method": "The authors propose the multi-stream and multi-scale fusion net (msmsfnet) and evaluate its performance when trained from scratch on public datasets.", "result": "msmsfnet outperforms state-of-the-art edge detectors in three datasets and works efficiently for SAR images, where pre-trained weights are unavailable. It also achieves competitive performance with pre-trained weights on BSDS500.", "conclusion": "Training edge detectors from scratch is viable and effective, especially for domains like SAR images, reducing dependency on pre-trained models."}}
{"id": "2502.06655", "pdf": "https://arxiv.org/pdf/2502.06655", "abs": "https://arxiv.org/abs/2502.06655", "authors": ["Meilin Chen", "Jian Tian", "Liang Ma", "Di Xie", "Weijie Chen", "Jiang Zhu"], "title": "Unbiased Evaluation of Large Language Models from a Causal Perspective", "categories": ["cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Benchmark contamination has become a significant concern in the LLM\nevaluation community. Previous Agents-as-an-Evaluator address this issue by\ninvolving agents in the generation of questions. Despite their success, the\nbiases in Agents-as-an-Evaluator methods remain largely unexplored. In this\npaper, we present a theoretical formulation of evaluation bias, providing\nvaluable insights into designing unbiased evaluation protocols. Furthermore, we\nidentify two type of bias in Agents-as-an-Evaluator through carefully designed\nprobing tasks on a minimal Agents-as-an-Evaluator setup. To address these\nissues, we propose the Unbiased Evaluator, an evaluation protocol that delivers\na more comprehensive, unbiased, and interpretable assessment of LLMs.Extensive\nexperiments reveal significant room for improvement in current LLMs.\nAdditionally, we demonstrate that the Unbiased Evaluator not only offers strong\nevidence of benchmark contamination but also provides interpretable evaluation\nresults.", "AI": {"tldr": "The paper addresses biases in Agents-as-an-Evaluator methods for LLM evaluation, proposes the Unbiased Evaluator protocol, and demonstrates its effectiveness in providing unbiased and interpretable assessments.", "motivation": "Benchmark contamination and unexplored biases in current evaluation methods motivate the need for a more robust and unbiased evaluation protocol.", "method": "The authors theoretically formulate evaluation bias, identify biases in Agents-as-an-Evaluator, and propose the Unbiased Evaluator protocol.", "result": "Experiments show significant improvement in LLM evaluation, with the Unbiased Evaluator providing strong evidence of benchmark contamination and interpretable results.", "conclusion": "The Unbiased Evaluator offers a comprehensive and unbiased solution for LLM evaluation, addressing current limitations."}}
{"id": "2505.06407", "pdf": "https://arxiv.org/pdf/2505.06407", "abs": "https://arxiv.org/abs/2505.06407", "authors": ["Ramin Esmzad", "Gokul S. Sankar", "Teawon Han", "Hamidreza Modares"], "title": "Direct Data Driven Control Using Noisy Measurements", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY", "math.OC"], "comment": "Submitted to IEEE-TAC", "summary": "This paper presents a novel direct data-driven control framework for solving\nthe linear quadratic regulator (LQR) under disturbances and noisy state\nmeasurements. The system dynamics are assumed unknown, and the LQR solution is\nlearned using only a single trajectory of noisy input-output data while\nbypassing system identification. Our approach guarantees mean-square stability\n(MSS) and optimal performance by leveraging convex optimization techniques that\nincorporate noise statistics directly into the controller synthesis. First, we\nestablish a theoretical result showing that the MSS of an uncertain data-driven\nsystem implies the MSS of the true closed-loop system. Building on this, we\ndevelop a robust stability condition using linear matrix inequalities (LMIs)\nthat yields a stabilizing controller gain from noisy measurements. Finally, we\nformulate a data-driven LQR problem as a semidefinite program (SDP) that\ncomputes an optimal gain, minimizing the steady-state covariance. Extensive\nsimulations on benchmark systems -- including a rotary inverted pendulum and an\nactive suspension system -- demonstrate the superior robustness and accuracy of\nour method compared to existing data-driven LQR approaches. The proposed\nframework offers a practical and theoretically grounded solution for controller\ndesign in noise-corrupted environments where system identification is\ninfeasible.", "AI": {"tldr": "A novel data-driven control framework for LQR under disturbances and noisy measurements, bypassing system identification and ensuring stability and optimal performance via convex optimization.", "motivation": "Addressing the challenge of designing optimal controllers for unknown systems with noisy data, avoiding the impracticality of system identification in noisy environments.", "method": "Uses convex optimization (LMIs and SDPs) to derive stabilizing and optimal controller gains directly from noisy input-output data, leveraging noise statistics.", "result": "Guarantees mean-square stability and optimal performance, validated through simulations on benchmark systems like a rotary inverted pendulum and active suspension.", "conclusion": "The framework provides a practical, robust solution for noise-corrupted environments where traditional system identification is infeasible."}}
{"id": "2407.01330", "pdf": "https://arxiv.org/pdf/2407.01330", "abs": "https://arxiv.org/abs/2407.01330", "authors": ["Jiangbei Hu", "Yanggeng Li", "Fei Hou", "Junhui Hou", "Zhebin Zhang", "Shengfa Wang", "Na Lei", "Ying He"], "title": "A Lightweight UDF Learning Framework for 3D Reconstruction Based on Local Shape Functions", "categories": ["cs.CV", "I.3.5"], "comment": "11 pages, 10 figures", "summary": "Unsigned distance fields (UDFs) provide a versatile framework for\nrepresenting a diverse array of 3D shapes, encompassing both watertight and\nnon-watertight geometries. Traditional UDF learning methods typically require\nextensive training on large 3D shape datasets, which is costly and necessitates\nre-training for new datasets. This paper presents a novel neural framework,\nLoSF-UDF, for reconstructing surfaces from 3D point clouds by leveraging local\nshape functions to learn UDFs. We observe that 3D shapes manifest simple\npatterns in localized regions, prompting us to develop a training dataset of\npoint cloud patches characterized by mathematical functions that represent a\ncontinuum from smooth surfaces to sharp edges and corners. Our approach learns\nfeatures within a specific radius around each query point and utilizes an\nattention mechanism to focus on the crucial features for UDF estimation.\nDespite being highly lightweight, with only 653 KB of trainable parameters and\na modest-sized training dataset with 0.5 GB storage, our method enables\nefficient and robust surface reconstruction from point clouds without requiring\nfor shape-specific training. Furthermore, our method exhibits enhanced\nresilience to noise and outliers in point clouds compared to existing methods.\nWe conduct comprehensive experiments and comparisons across various datasets,\nincluding synthetic and real-scanned point clouds, to validate our method's\nefficacy. Notably, our lightweight framework offers rapid and reliable\ninitialization for other unsupervised iterative approaches, improving both the\nefficiency and accuracy of their reconstructions. Our project and code are\navailable at https://jbhu67.github.io/LoSF-UDF.github.io.", "AI": {"tldr": "LoSF-UDF is a lightweight neural framework for surface reconstruction from 3D point clouds using local shape functions to learn UDFs, avoiding costly large-scale training.", "motivation": "Traditional UDF learning methods are costly and require re-training for new datasets. LoSF-UDF addresses this by leveraging local shape patterns and a small training dataset.", "method": "The approach learns features within a specific radius around query points using an attention mechanism, focusing on key features for UDF estimation.", "result": "The method is efficient, robust to noise, and outperforms existing methods without shape-specific training. It also aids other unsupervised approaches.", "conclusion": "LoSF-UDF provides a lightweight, efficient, and noise-resilient solution for surface reconstruction, validated across diverse datasets."}}
{"id": "2502.10931", "pdf": "https://arxiv.org/pdf/2502.10931", "abs": "https://arxiv.org/abs/2502.10931", "authors": ["Meet Udeshi", "Minghao Shao", "Haoran Xi", "Nanda Rani", "Kimberly Milner", "Venkata Sai Charan Putrevu", "Brendan Dolan-Gavitt", "Sandeep Kumar Shukla", "Prashanth Krishnamurthy", "Farshad Khorrami", "Ramesh Karri", "Muhammad Shafique"], "title": "D-CIPHER: Dynamic Collaborative Intelligent Multi-Agent System with Planner and Heterogeneous Executors for Offensive Security", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "Large Language Models (LLMs) have been used in cybersecurity such as\nautonomous security analysis or penetration testing. Capture the Flag (CTF)\nchallenges serve as benchmarks to assess automated task-planning abilities of\nLLM agents for cybersecurity. Early attempts to apply LLMs for solving CTF\nchallenges used single-agent systems, where feedback was restricted to a single\nreasoning-action loop. This approach was inadequate for complex CTF tasks.\nInspired by real-world CTF competitions, where teams of experts collaborate, we\nintroduce the D-CIPHER LLM multi-agent framework for collaborative CTF solving.\nD-CIPHER integrates agents with distinct roles with dynamic feedback loops to\nenhance reasoning on complex tasks. It introduces the Planner-Executor agent\nsystem, consisting of a Planner agent for overall problem-solving along with\nmultiple heterogeneous Executor agents for individual tasks, facilitating\nefficient allocation of responsibilities among the agents. Additionally,\nD-CIPHER incorporates an Auto-prompter agent to improve problem-solving by\nauto-generating a highly relevant initial prompt. We evaluate D-CIPHER on\nmultiple CTF benchmarks and LLM models via comprehensive studies to highlight\nthe impact of our enhancements. Additionally, we manually map the CTFs in NYU\nCTF Bench to MITRE ATT&CK techniques that apply for a comprehensive evaluation\nof D-CIPHER's offensive security capability. D-CIPHER achieves state-of-the-art\nperformance on three benchmarks: 22.0% on NYU CTF Bench, 22.5% on Cybench, and\n44.0% on HackTheBox, which is 2.5% to 8.5% better than previous work. D-CIPHER\nsolves 65% more ATT&CK techniques compared to previous work, demonstrating\nstronger offensive capability.", "AI": {"tldr": "D-CIPHER is a multi-agent LLM framework for collaborative CTF solving, outperforming single-agent systems with dynamic feedback and role specialization.", "motivation": "Single-agent LLM systems are inadequate for complex CTF tasks, while real-world CTF competitions rely on team collaboration.", "method": "D-CIPHER uses a Planner-Executor system with distinct roles, dynamic feedback loops, and an Auto-prompter for initial prompt generation.", "result": "Achieves state-of-the-art performance on benchmarks (22.0%-44.0%) and solves 65% more MITRE ATT&CK techniques than prior work.", "conclusion": "D-CIPHER demonstrates superior offensive security capability and efficiency in collaborative CTF solving."}}
{"id": "2505.06435", "pdf": "https://arxiv.org/pdf/2505.06435", "abs": "https://arxiv.org/abs/2505.06435", "authors": ["Insung Kong", "Kunwoong Kim", "Yongdai Kim"], "title": "Fair Representation Learning for Continuous Sensitive Attributes using Expectation of Integral Probability Metrics", "categories": ["stat.ML", "cs.LG"], "comment": "42 pages, 30 figures. IEEE Transactions on Pattern Analysis and\n  Machine Intelligence (2025)", "summary": "AI fairness, also known as algorithmic fairness, aims to ensure that\nalgorithms operate without bias or discrimination towards any individual or\ngroup. Among various AI algorithms, the Fair Representation Learning (FRL)\napproach has gained significant interest in recent years. However, existing FRL\nalgorithms have a limitation: they are primarily designed for categorical\nsensitive attributes and thus cannot be applied to continuous sensitive\nattributes, such as age or income. In this paper, we propose an FRL algorithm\nfor continuous sensitive attributes. First, we introduce a measure called the\nExpectation of Integral Probability Metrics (EIPM) to assess the fairness level\nof representation space for continuous sensitive attributes. We demonstrate\nthat if the distribution of the representation has a low EIPM value, then any\nprediction head constructed on the top of the representation become fair,\nregardless of the selection of the prediction head. Furthermore, EIPM possesses\na distinguished advantage in that it can be accurately estimated using our\nproposed estimator with finite samples. Based on these properties, we propose a\nnew FRL algorithm called Fair Representation using EIPM with MMD (FREM).\nExperimental evidences show that FREM outperforms other baseline methods.", "AI": {"tldr": "Proposes Fair Representation using EIPM with MMD (FREM), a new FRL algorithm for continuous sensitive attributes, addressing limitations of existing methods designed for categorical attributes.", "motivation": "Existing FRL algorithms are limited to categorical sensitive attributes, leaving a gap for continuous attributes like age or income.", "method": "Introduces EIPM to measure fairness in representation space for continuous attributes and proposes FREM, an FRL algorithm leveraging EIPM with MMD.", "result": "FREM outperforms baseline methods, demonstrating effectiveness for continuous sensitive attributes.", "conclusion": "FREM successfully extends FRL to continuous attributes, offering a robust solution for AI fairness in such cases."}}
{"id": "2407.13120", "pdf": "https://arxiv.org/pdf/2407.13120", "abs": "https://arxiv.org/abs/2407.13120", "authors": ["Shuchang Zhang", "Hui Zhang", "Hongxia Wang"], "title": "HPPP: Halpern-type Preconditioned Proximal Point Algorithms and Applications to Image Restoration", "categories": ["cs.CV", "math.OC"], "comment": null, "summary": "Recently, the degenerate preconditioned proximal point (PPP) method provides\na unified and flexible framework for designing and analyzing operator-splitting\nalgorithms such as Douglas-Rachford (DR). However, the degenerate PPP method\nexhibits weak convergence in the infinite-dimensional Hilbert space and lacks\naccelerated variants. To address these issues, we propose a Halpern-type PPP\n(HPPP) algorithm, which leverages the strong convergence and acceleration\nproperties of Halpern's iteration method. Moreover, we propose a novel\nalgorithm for image restoration by combining HPPP with denoiser priors such as\nPlug-and-Play (PnP) prior, which can be viewed as an accelerated PnP method.\nFinally, numerical experiments including several toy examples and image\nrestoration validate the effectiveness of our proposed algorithms.", "AI": {"tldr": "The paper introduces a Halpern-type Preconditioned Proximal Point (HPPP) algorithm to address weak convergence and lack of acceleration in degenerate PPP methods, and combines it with denoiser priors for image restoration.", "motivation": "The degenerate PPP method has limitations like weak convergence and no accelerated variants, prompting the need for an improved approach.", "method": "Proposes HPPP by integrating Halpern's iteration for strong convergence and acceleration, and combines it with denoiser priors (e.g., PnP) for image restoration.", "result": "Numerical experiments on toy examples and image restoration confirm the effectiveness of the proposed HPPP and accelerated PnP methods.", "conclusion": "The HPPP algorithm successfully overcomes the limitations of degenerate PPP, offering strong convergence and acceleration, with practical applications in image restoration."}}
{"id": "2503.15752", "pdf": "https://arxiv.org/pdf/2503.15752", "abs": "https://arxiv.org/abs/2503.15752", "authors": ["Yutong Xie", "Qiaozhu Mei", "Walter Yuan", "Matthew O. Jackson"], "title": "Using Language Models to Decipher the Motivation Behind Human Behaviors", "categories": ["cs.AI"], "comment": null, "summary": "AI presents a novel tool for deciphering the motivations behind human\nbehaviors. By varying prompts to a large language model, we can elicit the full\nrange of human behaviors in a variety of different scenarios in classic\neconomic games. By analyzing which prompts elicit which behaviors, we infer\n(decipher) the motivations behind the human behaviors. We also show how one can\nanalyze the prompts to reveal relationships between the classic economic games,\nproviding insight into what different economic scenarios induce people to think\nabout. We also show how this deciphering process can be used to understand\ndifferences in the behavioral tendencies of different populations. We show how\nAI offers a new way to examine the thinking and framing that produce different\nbehaviors.", "AI": {"tldr": "AI uses language model prompts to analyze human behavior motivations in economic games, revealing insights into behavioral tendencies and scenario framing.", "motivation": "To decipher the motivations behind human behaviors and understand differences in behavioral tendencies across populations using AI.", "method": "Varying prompts to a large language model to elicit human behaviors in classic economic games and analyzing the results.", "result": "AI provides insights into the motivations behind behaviors, relationships between economic scenarios, and differences in population tendencies.", "conclusion": "AI offers a novel tool for examining the thinking and framing that drive human behaviors in economic contexts."}}
{"id": "2505.06461", "pdf": "https://arxiv.org/pdf/2505.06461", "abs": "https://arxiv.org/abs/2505.06461", "authors": ["Haolin Zhang", "Jeff Huang"], "title": "Challenging GPU Dominance: When CPUs Outperform for On-Device LLM Inference", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "The common assumption in on-device AI is that GPUs, with their superior\nparallel processing, always provide the best performance for large language\nmodel (LLM) inference. In this work, we challenge this notion by empirically\ndemonstrating that, under certain conditions, CPUs can outperform GPUs for LLM\ninference on mobile devices. Using a 1-billion-parameter LLM deployed via\nllama.cpp on the iPhone 15 Pro, we show that a CPU-only configuration (two\nthreads, F16 precision) achieves 17 tokens per second, surpassing the 12.8\ntokens per second obtained with GPU acceleration. We analyze the architectural\nfactors driving this counterintuitive result, revealing that GPU memory\ntransfer overhead and CPU thread optimization play a critical role.\nFurthermore, we explore the impact of thread oversubscription, quantization\nstrategies, and hardware constraints, providing new insights into efficient\non-device AI execution. Our findings challenge conventional GPU-first thinking,\nhighlighting the untapped potential of optimized CPU inference and paving the\nway for smarter deployment strategies in mobile AI. However, fully explaining\nthe observed CPU advantage remains difficult due to limited access to low-level\nprofiling tools on iOS.", "AI": {"tldr": "CPUs can outperform GPUs for LLM inference on mobile devices under certain conditions, challenging the common GPU-first assumption.", "motivation": "To challenge the assumption that GPUs always provide the best performance for LLM inference on mobile devices by demonstrating CPU superiority in specific scenarios.", "method": "Deployed a 1-billion-parameter LLM via llama.cpp on iPhone 15 Pro, comparing CPU-only (2 threads, F16 precision) and GPU-accelerated configurations. Analyzed architectural factors like GPU memory transfer overhead and CPU thread optimization.", "result": "CPU-only configuration achieved 17 tokens per second, surpassing GPU's 12.8 tokens per second. Thread oversubscription, quantization, and hardware constraints were explored.", "conclusion": "CPUs can outperform GPUs for LLM inference on mobile devices, highlighting the need for smarter deployment strategies. However, low-level profiling limitations on iOS hinder full explanation."}}
{"id": "2407.18715", "pdf": "https://arxiv.org/pdf/2407.18715", "abs": "https://arxiv.org/abs/2407.18715", "authors": ["Peng Hao", "Weilong Wang", "Xiaobing Wang", "Yingying Jiang", "Hanchao Jia", "Shaowei Cui", "Junhang Wei", "Xiaoshuai Hao"], "title": "BCTR: Bidirectional Conditioning Transformer for Scene Graph Generation", "categories": ["cs.CV"], "comment": "16 pages, 4 figures", "summary": "Scene Graph Generation (SGG) remains a challenging task due to its\ncompositional property. Previous approaches improve prediction efficiency\nthrough end-to-end learning. However, these methods exhibit limited performance\nas they assume unidirectional conditioning between entities and predicates,\nwhich restricts effective information interaction. To address this limitation,\nwe propose a novel bidirectional conditioning factorization in a\nsemantic-aligned space for SGG, enabling efficient and generalizable\ninteraction between entities and predicates. Specifically, we introduce an\nend-to-end scene graph generation model, the Bidirectional Conditioning\nTransformer (BCTR), to implement this factorization. BCTR consists of two key\nmodules. First, the Bidirectional Conditioning Generator (BCG) performs\nmulti-stage interactive feature augmentation between entities and predicates,\nenabling mutual enhancement between these predictions. Second, Random Feature\nAlignment (RFA) is present to regularize feature space by distilling\nmulti-modal knowledge from pre-trained models. Within this regularized feature\nspace, BCG is feasible to capture interaction patterns across diverse\nrelationships during training, and the learned interaction patterns can\ngeneralize to unseen but semantically related relationships during inference.\nExtensive experiments on Visual Genome and Open Image V6 show that BCTR\nachieves state-of-the-art performance on both benchmarks.", "AI": {"tldr": "A novel bidirectional conditioning factorization method, BCTR, improves Scene Graph Generation by enabling efficient interaction between entities and predicates, achieving state-of-the-art results.", "motivation": "Existing SGG methods assume unidirectional conditioning, limiting performance due to restricted information interaction.", "method": "Proposes BCTR with Bidirectional Conditioning Generator (BCG) for feature augmentation and Random Feature Alignment (RFA) for regularization.", "result": "BCTR achieves state-of-the-art performance on Visual Genome and Open Image V6 benchmarks.", "conclusion": "Bidirectional conditioning in a semantic-aligned space enhances SGG performance and generalizability."}}
{"id": "2503.18938", "pdf": "https://arxiv.org/pdf/2503.18938", "abs": "https://arxiv.org/abs/2503.18938", "authors": ["Shenyuan Gao", "Siyuan Zhou", "Yilun Du", "Jun Zhang", "Chuang Gan"], "title": "AdaWorld: Learning Adaptable World Models with Latent Actions", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "comment": "ICML 2025. Project page: https://adaptable-world-model.github.io/,\n  code and model: https://github.com/Little-Podi/AdaWorld", "summary": "World models aim to learn action-controlled future prediction and have proven\nessential for the development of intelligent agents. However, most existing\nworld models rely heavily on substantial action-labeled data and costly\ntraining, making it challenging to adapt to novel environments with\nheterogeneous actions through limited interactions. This limitation can hinder\ntheir applicability across broader domains. To overcome this limitation, we\npropose AdaWorld, an innovative world model learning approach that enables\nefficient adaptation. The key idea is to incorporate action information during\nthe pretraining of world models. This is achieved by extracting latent actions\nfrom videos in a self-supervised manner, capturing the most critical\ntransitions between frames. We then develop an autoregressive world model that\nconditions on these latent actions. This learning paradigm enables highly\nadaptable world models, facilitating efficient transfer and learning of new\nactions even with limited interactions and finetuning. Our comprehensive\nexperiments across multiple environments demonstrate that AdaWorld achieves\nsuperior performance in both simulation quality and visual planning.", "AI": {"tldr": "AdaWorld is a novel world model learning approach that uses self-supervised latent actions for efficient adaptation to new environments with limited data.", "motivation": "Existing world models require extensive action-labeled data and costly training, limiting adaptability to novel environments.", "method": "AdaWorld extracts latent actions from videos self-supervisedly and trains an autoregressive world model conditioned on these actions.", "result": "AdaWorld outperforms in simulation quality and visual planning across multiple environments.", "conclusion": "AdaWorld enables efficient adaptation and transfer of world models with minimal interaction and finetuning."}}
{"id": "2505.06531", "pdf": "https://arxiv.org/pdf/2505.06531", "abs": "https://arxiv.org/abs/2505.06531", "authors": ["Yong-Syun Cao", "Shinpei Imori", "Ching-Kang Ing"], "title": "High-Dimensional Importance-Weighted Information Criteria: Theory and Optimality", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Imori and Ing (2025) proposed the importance-weighted orthogonal greedy\nalgorithm (IWOGA) for model selection in high-dimensional misspecified\nregression models under covariate shift. To determine the number of IWOGA\niterations, they introduced the high-dimensional importance-weighted\ninformation criterion (HDIWIC). They argued that the combined use of IWOGA and\nHDIWIC, IWOGA + HDIWIC, achieves an optimal trade-off between variance and\nsquared bias, leading to optimal convergence rates in terms of conditional mean\nsquared prediction error. In this article, we provide a theoretical\njustification for this claim by establishing the optimality of IWOGA + HDIWIC\nunder a set of reasonable assumptions.", "AI": {"tldr": "IWOGA + HDIWIC optimizes model selection in high-dimensional misspecified regression under covariate shift, balancing variance and bias for optimal prediction error.", "motivation": "Address model selection in high-dimensional misspecified regression with covariate shift, ensuring optimal prediction performance.", "method": "Proposed IWOGA for model selection and HDIWIC to determine iterations, combining them for optimal trade-off.", "result": "Theoretical proof shows IWOGA + HDIWIC achieves optimal convergence rates in prediction error.", "conclusion": "IWOGA + HDIWIC is theoretically justified for optimal model selection in specified conditions."}}
{"id": "2408.12232", "pdf": "https://arxiv.org/pdf/2408.12232", "abs": "https://arxiv.org/abs/2408.12232", "authors": ["Hanzheng Wang", "Wei Li", "Xiang-Gen Xia", "Qian Du"], "title": "BihoT: A Large-Scale Dataset and Benchmark for Hyperspectral Camouflaged Object Tracking", "categories": ["cs.CV"], "comment": "IEEE Transactions on Neural Networks and Learning Systems, 2025", "summary": "Hyperspectral object tracking (HOT) has exhibited potential in various\napplications, particularly in scenes where objects are camouflaged. Existing\ntrackers can effectively retrieve objects via band regrouping because of the\nbias in existing HOT datasets, where most objects tend to have distinguishing\nvisual appearances rather than spectral characteristics. This bias allows the\ntracker to directly use the visual features obtained from the false-color\nimages generated by hyperspectral images without the need to extract spectral\nfeatures. To tackle this bias, we find that the tracker should focus on the\nspectral information when object appearance is unreliable. Thus, we provide a\nnew task called hyperspectral camouflaged object tracking (HCOT) and\nmeticulously construct a large-scale HCOT dataset, termed BihoT, which consists\nof 41,912 hyperspectral images covering 49 video sequences. The dataset covers\nvarious artificial camouflage scenes where objects have similar appearances,\ndiverse spectrums, and frequent occlusion, making it a very challenging dataset\nfor HCOT. Besides, a simple but effective baseline model, named spectral\nprompt-based distractor-aware network (SPDAN), is proposed, comprising a\nspectral embedding network (SEN), a spectral prompt-based backbone network\n(SPBN), and a distractor-aware module (DAM). Specifically, the SEN extracts\nspectral-spatial features via 3-D and 2-D convolutions. Then, the SPBN\nfine-tunes powerful RGB trackers with spectral prompts and alleviates the\ninsufficiency of training samples. Moreover, the DAM utilizes a novel statistic\nto capture the distractor caused by occlusion from objects and background.\nExtensive experiments demonstrate that our proposed SPDAN achieves\nstate-of-the-art performance on the proposed BihoT and other HOT datasets.", "AI": {"tldr": "The paper introduces a new task, hyperspectral camouflaged object tracking (HCOT), and a dataset (BihoT) to address biases in existing hyperspectral tracking datasets. A baseline model (SPDAN) is proposed, leveraging spectral features for improved tracking performance.", "motivation": "Existing hyperspectral object tracking (HOT) datasets are biased toward visual appearances, neglecting spectral features. This limits performance in camouflaged scenarios where spectral information is crucial.", "method": "The paper proposes the SPDAN model, which includes a spectral embedding network (SEN), a spectral prompt-based backbone network (SPBN), and a distractor-aware module (DAM). SEN extracts spectral-spatial features, SPBN fine-tunes RGB trackers with spectral prompts, and DAM handles occlusion-related distractors.", "result": "SPDAN achieves state-of-the-art performance on the new BihoT dataset and other HOT datasets, demonstrating its effectiveness in leveraging spectral features.", "conclusion": "The HCOT task and BihoT dataset address biases in HOT, and the SPDAN model provides a robust baseline for spectral-based tracking in challenging camouflaged scenarios."}}
{"id": "2503.21138", "pdf": "https://arxiv.org/pdf/2503.21138", "abs": "https://arxiv.org/abs/2503.21138", "authors": ["Hedong Yan"], "title": "A Computational Theory for Efficient Mini Agent Evaluation with Causal Guarantees", "categories": ["cs.AI", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "In order to reduce the cost of experimental evaluation for agents, we\nintroduce a computational theory of evaluation for mini agents: build\nevaluation model to accelerate the evaluation procedures. We prove upper bounds\nof generalized error and generalized causal effect error of given evaluation\nmodels for infinite agents. We also prove efficiency, and consistency to\nestimated causal effect from deployed agents to evaluation metric by\nprediction. To learn evaluation models, we propose a meta-learner to handle\nheterogeneous agents space problem. Comparing with existed evaluation\napproaches, our (conditional) evaluation model reduced 24.1\\% to 99.0\\%\nevaluation errors across 12 scenes, including individual medicine, scientific\nsimulation, social experiment, business activity, and quantum trade. The\nevaluation time is reduced 3 to 7 order of magnitude per subject comparing with\nexperiments or simulations.", "AI": {"tldr": "A computational theory for evaluating mini agents reduces evaluation costs by building models, proving error bounds, and using meta-learning for heterogeneous agents. It cuts errors by 24.1-99.0% and speeds up evaluation significantly.", "motivation": "To reduce the high cost of experimental evaluation for agents by developing a computational evaluation model.", "method": "Proposes a meta-learner for heterogeneous agents, proves error bounds, and uses prediction for efficiency and consistency.", "result": "Reduced evaluation errors by 24.1-99.0% across 12 scenes and sped up evaluation by 3-7 orders of magnitude.", "conclusion": "The method offers a scalable, efficient alternative to traditional evaluation, with proven error bounds and significant time savings."}}
{"id": "2505.06601", "pdf": "https://arxiv.org/pdf/2505.06601", "abs": "https://arxiv.org/abs/2505.06601", "authors": ["Yuanhang Luo", "Yeheng Ge", "Ruijian Han", "Guohao Shen"], "title": "Learning Guarantee of Reward Modeling Using Deep Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this work, we study the learning theory of reward modeling with pairwise\ncomparison data using deep neural networks. We establish a novel non-asymptotic\nregret bound for deep reward estimators in a non-parametric setting, which\ndepends explicitly on the network architecture. Furthermore, to underscore the\ncritical importance of clear human beliefs, we introduce a margin-type\ncondition that assumes the conditional winning probability of the optimal\naction in pairwise comparisons is significantly distanced from 1/2. This\ncondition enables a sharper regret bound, which substantiates the empirical\nefficiency of Reinforcement Learning from Human Feedback and highlights clear\nhuman beliefs in its success. Notably, this improvement stems from high-quality\npairwise comparison data implied by the margin-type condition, is independent\nof the specific estimators used, and thus applies to various learning\nalgorithms and models.", "AI": {"tldr": "The paper studies reward modeling with pairwise comparison data using deep neural networks, establishing a non-asymptotic regret bound and highlighting the importance of clear human beliefs for sharper bounds.", "motivation": "To understand the learning theory of reward modeling and improve regret bounds in non-parametric settings, emphasizing the role of human feedback quality.", "method": "Uses deep neural networks for reward estimation and introduces a margin-type condition to analyze the impact of clear human beliefs on regret bounds.", "result": "A novel non-asymptotic regret bound is derived, showing sharper bounds under the margin-type condition, independent of specific estimators.", "conclusion": "Clear human beliefs and high-quality pairwise comparison data are critical for efficient Reinforcement Learning from Human Feedback, applicable across various models."}}
{"id": "2408.13877", "pdf": "https://arxiv.org/pdf/2408.13877", "abs": "https://arxiv.org/abs/2408.13877", "authors": ["Xiaoyu Guo", "Pengzhi Zhong", "Hao Zhang", "Defeng Huang", "Huikai Shao", "Qijun Zhao", "Shuiwang Li"], "title": "Camouflaged Object Tracking: A Benchmark", "categories": ["cs.CV"], "comment": null, "summary": "Visual tracking has seen remarkable advancements, largely driven by the\navailability of large-scale training datasets that have enabled the development\nof highly accurate and robust algorithms. While significant progress has been\nmade in tracking general objects, research on more challenging scenarios, such\nas tracking camouflaged objects, remains limited. Camouflaged objects, which\nblend seamlessly with their surroundings or other objects, present unique\nchallenges for detection and tracking in complex environments. This challenge\nis particularly critical in applications such as military, security,\nagriculture, and marine monitoring, where precise tracking of camouflaged\nobjects is essential. To address this gap, we introduce the Camouflaged Object\nTracking Dataset (COTD), a specialized benchmark designed specifically for\nevaluating camouflaged object tracking methods. The COTD dataset comprises 200\nsequences and approximately 80,000 frames, each annotated with detailed\nbounding boxes. Our evaluation of 20 existing tracking algorithms reveals\nsignificant deficiencies in their performance with camouflaged objects. To\naddress these issues, we propose a novel tracking framework, HiPTrack-MLS,\nwhich demonstrates promising results in improving tracking performance for\ncamouflaged objects. COTD and code are avialable at\nhttps://github.com/openat25/HIPTrack-MLS.", "AI": {"tldr": "The paper introduces the Camouflaged Object Tracking Dataset (COTD) and a novel tracking framework, HiPTrack-MLS, to address the challenge of tracking camouflaged objects, where existing methods perform poorly.", "motivation": "Current tracking algorithms struggle with camouflaged objects, which are critical in applications like military, security, and agriculture.", "method": "The authors create COTD, a dataset with 200 sequences and 80,000 annotated frames, and propose HiPTrack-MLS, a new tracking framework.", "result": "Evaluation of 20 existing trackers shows poor performance on camouflaged objects, while HiPTrack-MLS demonstrates improved results.", "conclusion": "The COTD dataset and HiPTrack-MLS framework address a critical gap in tracking camouflaged objects, with promising performance."}}
{"id": "2503.23350", "pdf": "https://arxiv.org/pdf/2503.23350", "abs": "https://arxiv.org/abs/2503.23350", "authors": ["Liangbo Ning", "Ziran Liang", "Zhuohang Jiang", "Haohao Qu", "Yujuan Ding", "Wenqi Fan", "Xiao-yong Wei", "Shanru Lin", "Hui Liu", "Philip S. Yu", "Qing Li"], "title": "A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models", "categories": ["cs.AI"], "comment": "Accepted by KDD 2025;", "summary": "With the advancement of web techniques, they have significantly\nrevolutionized various aspects of people's lives. Despite the importance of the\nweb, many tasks performed on it are repetitive and time-consuming, negatively\nimpacting overall quality of life. To efficiently handle these tedious daily\ntasks, one of the most promising approaches is to advance autonomous agents\nbased on Artificial Intelligence (AI) techniques, referred to as AI Agents, as\nthey can operate continuously without fatigue or performance degradation. In\nthe context of the web, leveraging AI Agents -- termed WebAgents -- to\nautomatically assist people in handling tedious daily tasks can dramatically\nenhance productivity and efficiency. Recently, Large Foundation Models (LFMs)\ncontaining billions of parameters have exhibited human-like language\nunderstanding and reasoning capabilities, showing proficiency in performing\nvarious complex tasks. This naturally raises the question: `Can LFMs be\nutilized to develop powerful AI Agents that automatically handle web tasks,\nproviding significant convenience to users?' To fully explore the potential of\nLFMs, extensive research has emerged on WebAgents designed to complete daily\nweb tasks according to user instructions, significantly enhancing the\nconvenience of daily human life. In this survey, we comprehensively review\nexisting research studies on WebAgents across three key aspects: architectures,\ntraining, and trustworthiness. Additionally, several promising directions for\nfuture research are explored to provide deeper insights.", "AI": {"tldr": "The paper surveys WebAgents, AI-driven autonomous agents for automating repetitive web tasks, leveraging Large Foundation Models (LFMs) for enhanced productivity and efficiency.", "motivation": "Repetitive web tasks negatively impact quality of life; AI Agents (WebAgents) can automate these tasks, improving convenience and productivity.", "method": "The survey reviews existing research on WebAgents, focusing on architectures, training, and trustworthiness.", "result": "LFMs show promise in developing powerful WebAgents capable of handling complex web tasks.", "conclusion": "The paper highlights the potential of WebAgents and suggests future research directions to further explore their capabilities."}}
{"id": "2505.06701", "pdf": "https://arxiv.org/pdf/2505.06701", "abs": "https://arxiv.org/abs/2505.06701", "authors": ["Akansha Shukla", "Parth Atulbhai Gandhi", "Yuval Elovici", "Asaf Shabtai"], "title": "RuleGenie: SIEM Detection Rule Set Optimization", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "SIEM systems serve as a critical hub, employing rule-based logic to detect\nand respond to threats. Redundant or overlapping rules in SIEM systems lead to\nexcessive false alerts, degrading analyst performance due to alert fatigue, and\nincrease computational overhead and response latency for actual threats. As a\nresult, optimizing SIEM rule sets is essential for efficient operations.\nDespite the importance of such optimization, research in this area is limited,\nwith current practices relying on manual optimization methods that are both\ntime-consuming and error-prone due to the scale and complexity of\nenterprise-level rule sets. To address this gap, we present RuleGenie, a novel\nlarge language model (LLM) aided recommender system designed to optimize SIEM\nrule sets. Our approach leverages transformer models' multi-head attention\ncapabilities to generate SIEM rule embeddings, which are then analyzed using a\nsimilarity matching algorithm to identify the top-k most similar rules. The LLM\nthen processes the rules identified, utilizing its information extraction,\nlanguage understanding, and reasoning capabilities to analyze rule similarity,\nevaluate threat coverage and performance metrics, and deliver optimized\nrecommendations for refining the rule set. By automating the rule optimization\nprocess, RuleGenie allows security teams to focus on more strategic tasks while\nenhancing the efficiency of SIEM systems and strengthening organizations'\nsecurity posture. We evaluated RuleGenie on a comprehensive set of real-world\nSIEM rule formats, including Splunk, Sigma, and AQL (Ariel query language),\ndemonstrating its platform-agnostic capabilities and adaptability across\ndiverse security infrastructures. Our experimental results show that RuleGenie\ncan effectively identify redundant rules, which in turn decreases false\npositive rates and enhances overall rule efficiency.", "AI": {"tldr": "RuleGenie is an LLM-based system for optimizing SIEM rule sets, reducing false alerts and improving efficiency.", "motivation": "Redundant SIEM rules cause alert fatigue and inefficiency, but manual optimization is impractical.", "method": "RuleGenie uses transformer models and similarity matching to analyze and recommend rule optimizations.", "result": "It effectively identifies redundant rules, reducing false positives and enhancing efficiency.", "conclusion": "RuleGenie automates SIEM rule optimization, improving security operations."}}
{"id": "2409.00020", "pdf": "https://arxiv.org/pdf/2409.00020", "abs": "https://arxiv.org/abs/2409.00020", "authors": ["Shahab Aldin Shojaeezadeh", "Abdelrazek Elnashar", "Tobias Karl David Weber"], "title": "A novel fusion of Sentinel-1 and Sentinel-2 with climate data for crop phenology estimation using Machine Learning", "categories": ["cs.CV"], "comment": null, "summary": "Crop phenology describes the physiological development stages of crops from\nplanting to harvest which is valuable information for decision makers to plan\nand adapt agricultural management strategies. In the era of big Earth\nobservation data ubiquity, attempts have been made to accurately detect crop\nphenology using Remote Sensing (RS) and high resolution weather data. However,\nmost studies have focused on large scale predictions of phenology or developed\nmethods which are not adequate to help crop modeler communities on leveraging\nSentinel-1 and Sentinal-2 data and fusing them with high resolution climate\ndata, using a novel framework. For this, we trained a Machine Learning (ML)\nLightGBM model to predict 13 phenological stages for eight major crops across\nGermany at 20 m scale. Observed phonologies were taken from German national\nphenology network (German Meteorological Service; DWD) between 2017 and 2021.\nWe proposed a thorough feature selection analysis to find the best combination\nof RS and climate data to detect phenological stages. At national scale,\npredicted phenology resulted in a reasonable precision of R2 > 0.43 and a low\nMean Absolute Error of 6 days, averaged over all phenological stages and crops.\nThe spatio-temporal analysis of the model predictions demonstrates its\ntransferability across different spatial and temporal context of Germany. The\nresults indicated that combining radar sensors with climate data yields a very\npromising performance for a multitude of practical applications. Moreover,\nthese improvements are expected to be useful to generate highly valuable input\nfor crop model calibrations and evaluations, facilitate informed agricultural\ndecisions, and contribute to sustainable food production to address the\nincreasing global food demand.", "AI": {"tldr": "The paper presents a Machine Learning (LightGBM) model to predict 13 phenological stages for eight major crops in Germany using Sentinel-1, Sentinel-2, and high-resolution climate data, achieving reasonable accuracy (R2 > 0.43) and low error (6 days MAE).", "motivation": "Accurate crop phenology detection is crucial for agricultural management, but existing methods lack integration of Sentinel data and climate data for crop modelers.", "method": "A LightGBM model was trained with feature selection to combine RS and climate data, validated using observed phenology data from 2017-2021.", "result": "The model achieved R2 > 0.43 and 6 days MAE, showing transferability across Germany. Combining radar and climate data improved performance.", "conclusion": "The framework benefits crop model calibration, agricultural decisions, and sustainable food production, addressing global food demand."}}
{"id": "2504.14379", "pdf": "https://arxiv.org/pdf/2504.14379", "abs": "https://arxiv.org/abs/2504.14379", "authors": ["Andrew Lee", "Lihao Sun", "Chris Wendler", "Fernanda Vi\u00e9gas", "Martin Wattenberg"], "title": "The Geometry of Self-Verification in a Task-Specific Reasoning Model", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "How do reasoning models verify their own answers? We study this question by\ntraining a model using DeepSeek R1's recipe on the CountDown task. We leverage\nthe fact that preference tuning leads to mode collapse, yielding a model that\nalways produces highly structured chain-of-thought sequences. With this setup,\nwe do top-down and bottom-up analyses to reverse-engineer how the model\nverifies its outputs. Top-down, we find Gated Linear Unit (GLU) weights\nencoding verification-related tokens, such as ``success'' or ``incorrect''.\nBottom-up, we find that ``previous-token heads'' are mainly responsible for\nself-verification in our setup. Our analyses meet in the middle: drawing\ninspiration from inter-layer communication channels, we use the identified GLU\nweights to localize as few as three attention heads that can disable\nself-verification, pointing to a necessary component of a potentially larger\nverification circuit. Finally, we verify that similar verification components\nexist in our base model and a general reasoning DeepSeek-R1 model.", "AI": {"tldr": "The paper investigates how reasoning models self-verify answers, using a model trained on the CountDown task. It identifies key components like GLU weights and attention heads involved in verification.", "motivation": "To understand the mechanisms behind self-verification in reasoning models, leveraging preference tuning and structured outputs.", "method": "Top-down and bottom-up analyses are conducted, focusing on GLU weights and attention heads to reverse-engineer verification processes.", "result": "GLU weights encode verification tokens, and specific attention heads (e.g., 'previous-token heads') are crucial for self-verification. A minimal circuit of three heads is identified.", "conclusion": "The study reveals a verification circuit in reasoning models, with findings applicable to base and general reasoning models like DeepSeek-R1."}}
{"id": "2505.06711", "pdf": "https://arxiv.org/pdf/2505.06711", "abs": "https://arxiv.org/abs/2505.06711", "authors": ["Junfan Xia", "Bin Jiang"], "title": "Efficient Parallelization of Message Passing Neural Networks", "categories": ["physics.chem-ph", "cs.LG"], "comment": "33 pages, 8 figures", "summary": "Machine learning potentials have achieved great success in accelerating\natomistic simulations. Many of them rely on local descriptors that readily\nallow parallelization. More recent message passing neural network (MPNN) models\nhave demonstrated their superior accuracy and become increasingly popular.\nHowever, parallelizing MPNN models for large-scale simulations across compute\nnodes remains a challenge, as the previously argued poor scalability with the\nnumber of MP layers and the necessity of data communication. Here, we propose\nan efficient parallel algorithm for MPNN models, in which additional data\ncommunication is minimized among local atoms only in each MP layer without\nredundant computation, thus scaling linearly with the layer number. Integrated\nwith our recursively embedded atom neural network model, this algorithm\ndemonstrates excellent strong scaling and weak scaling behaviors in several\nbenchmark systems. This approach enables massive molecular dynamics simulations\non MPNN models for hundreds of millions of atoms as fast as on strictly local\nmodels, vastly extending the applicability of the MPNN potential to an\nunprecedented scale. This general parallelization framework can empower various\nMPNN models to efficiently simulate very large and complex systems.", "AI": {"tldr": "The paper proposes an efficient parallel algorithm for message passing neural network (MPNN) models to enable large-scale atomistic simulations with minimal data communication and linear scalability.", "motivation": "MPNN models offer superior accuracy but face challenges in parallelization for large-scale simulations due to poor scalability and data communication issues.", "method": "The authors introduce a parallel algorithm that minimizes additional data communication among local atoms in each MP layer, avoiding redundant computation. This is integrated with a recursively embedded atom neural network model.", "result": "The algorithm shows excellent strong and weak scaling behaviors in benchmark systems, enabling simulations of hundreds of millions of atoms as efficiently as local models.", "conclusion": "This framework extends the applicability of MPNN potentials to unprecedented scales and can empower various MPNN models for large, complex systems."}}
{"id": "2409.00638", "pdf": "https://arxiv.org/pdf/2409.00638", "abs": "https://arxiv.org/abs/2409.00638", "authors": ["Gangwei Xu", "Xianqi Wang", "Zhaoxing Zhang", "Junda Cheng", "Chunyuan Liao", "Xin Yang"], "title": "IGEV++: Iterative Multi-range Geometry Encoding Volumes for Stereo Matching", "categories": ["cs.CV"], "comment": "Accepted by TPAMI 2025", "summary": "Stereo matching is a core component in many computer vision and robotics\nsystems. Despite significant advances over the last decade, handling matching\nambiguities in ill-posed regions and large disparities remains an open\nchallenge. In this paper, we propose a new deep network architecture, called\nIGEV++, for stereo matching. The proposed IGEV++ constructs Multi-range\nGeometry Encoding Volumes (MGEV), which encode coarse-grained geometry\ninformation for ill-posed regions and large disparities, while preserving\nfine-grained geometry information for details and small disparities. To\nconstruct MGEV, we introduce an adaptive patch matching module that efficiently\nand effectively computes matching costs for large disparity ranges and/or\nill-posed regions. We further propose a selective geometry feature fusion\nmodule to adaptively fuse multi-range and multi-granularity geometry features\nin MGEV. Then, we input the fused geometry features into ConvGRUs to\niteratively update the disparity map. MGEV allows to efficiently handle large\ndisparities and ill-posed regions, such as occlusions and textureless regions,\nand enjoys rapid convergence during iterations. Our IGEV++ achieves the best\nperformance on the Scene Flow test set across all disparity ranges, up to\n768px. Our IGEV++ also achieves state-of-the-art accuracy on the Middlebury,\nETH3D, KITTI 2012, and 2015 benchmarks. Specifically, IGEV++ achieves a 3.23\\%\n2-pixel outlier rate (Bad 2.0) on the large disparity benchmark, Middlebury,\nrepresenting error reductions of 31.9\\% and 54.8\\% compared to RAFT-Stereo and\nGMStereo, respectively. We also present a real-time version of IGEV++ that\nachieves the best performance among all published real-time methods on the\nKITTI benchmarks. The code is publicly available at\nhttps://github.com/gangweix/IGEV and https://github.com/gangweix/IGEV-plusplus.", "AI": {"tldr": "IGEV++ is a new deep network for stereo matching, addressing ambiguities in ill-posed regions and large disparities using Multi-range Geometry Encoding Volumes (MGEV). It achieves top performance on benchmarks like Scene Flow, Middlebury, and KITTI.", "motivation": "Handling matching ambiguities in ill-posed regions and large disparities remains a challenge in stereo matching.", "method": "IGEV++ constructs MGEV for multi-range geometry encoding, uses adaptive patch matching, selective geometry feature fusion, and ConvGRUs for iterative disparity updates.", "result": "Achieves best performance on Scene Flow (up to 768px) and state-of-the-art on Middlebury, ETH3D, KITTI 2012/2015, with a 3.23% Bad 2.0 rate on Middlebury.", "conclusion": "IGEV++ efficiently handles large disparities and ill-posed regions, outperforming existing methods and offering a real-time variant."}}
{"id": "2504.17929", "pdf": "https://arxiv.org/pdf/2504.17929", "abs": "https://arxiv.org/abs/2504.17929", "authors": ["Ayesha Siddique", "Khurram Khalil", "Khaza Anuarul Hoque"], "title": "ApproXAI: Energy-Efficient Hardware Acceleration of Explainable AI using Approximate Computing", "categories": ["cs.AI", "cs.AR"], "comment": "Accepted at the International Joint Conference on Neural Networks\n  (IJCNN), June 30th - July 5th, 2025 in Rome, Italy", "summary": "Explainable artificial intelligence (XAI) enhances AI system transparency by\nframing interpretability as an optimization problem. However, this approach\noften necessitates numerous iterations of computationally intensive operations,\nlimiting its applicability in real-time scenarios. While recent research has\nfocused on XAI hardware acceleration on FPGAs and TPU, these methods do not\nfully address energy efficiency in real-time settings. To address this\nlimitation, we propose XAIedge, a novel framework that leverages approximate\ncomputing techniques into XAI algorithms, including integrated gradients, model\ndistillation, and Shapley analysis. XAIedge translates these algorithms into\napproximate matrix computations and exploits the synergy between convolution,\nFourier transform, and approximate computing paradigms. This approach enables\nefficient hardware acceleration on TPU-based edge devices, facilitating faster\nreal-time outcome interpretations. Our comprehensive evaluation demonstrates\nthat XAIedge achieves a $2\\times$ improvement in energy efficiency compared to\nexisting accurate XAI hardware acceleration techniques while maintaining\ncomparable accuracy. These results highlight the potential of XAIedge to\nsignificantly advance the deployment of explainable AI in energy-constrained\nreal-time applications.", "AI": {"tldr": "XAIedge improves energy efficiency in real-time XAI by using approximate computing, achieving 2\u00d7 better efficiency than existing methods.", "motivation": "Current XAI methods are computationally intensive and lack energy efficiency for real-time applications.", "method": "XAIedge integrates approximate computing into XAI algorithms (e.g., integrated gradients, Shapley analysis) and optimizes matrix computations for TPU-based edge devices.", "result": "XAIedge achieves 2\u00d7 better energy efficiency while maintaining accuracy.", "conclusion": "XAIedge advances real-time XAI deployment in energy-constrained settings."}}
{"id": "2505.06756", "pdf": "https://arxiv.org/pdf/2505.06756", "abs": "https://arxiv.org/abs/2505.06756", "authors": ["Michael W. Trosset", "Kaiyi Tan", "Minh Tang", "Carey E. Priebe"], "title": "Out-of-Sample Embedding with Proximity Data: Projection versus Restricted Reconstruction", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": "19 pages, 2 figures", "summary": "The problem of using proximity (similarity or dissimilarity) data for the\npurpose of \"adding a point to a vector diagram\" was first studied by J.C. Gower\nin 1968. Since then, a number of methods -- mostly kernel methods -- have been\nproposed for solving what has come to be called the problem of *out-of-sample\nembedding*. We survey the various kernel methods that we have encountered and\nshow that each can be derived from one or the other of two competing\nstrategies: *projection* or *restricted reconstruction*. Projection can be\nanalogized to a well-known formula for adding a point to a principal component\nanalysis. Restricted reconstruction poses a different challenge: how to best\napproximate redoing the entire multivariate analysis while holding fixed the\nvector diagram that was previously obtained. This strategy results in a\nnonlinear optimization problem that can be simplified to a unidimensional\nsearch. Various circumstances may warrant either projection or restricted\nreconstruction.", "AI": {"tldr": "The paper surveys kernel methods for out-of-sample embedding, categorizing them into projection and restricted reconstruction strategies.", "motivation": "To explore and unify various kernel methods for embedding new points into existing vector diagrams, addressing the problem of out-of-sample embedding.", "method": "Survey and derivation of kernel methods, comparing projection (analogous to PCA extension) and restricted reconstruction (nonlinear optimization).", "result": "Identifies two competing strategies for out-of-sample embedding: projection and restricted reconstruction, each suitable for different scenarios.", "conclusion": "The choice between projection and restricted reconstruction depends on the specific requirements of the embedding problem."}}
{"id": "2409.06002", "pdf": "https://arxiv.org/pdf/2409.06002", "abs": "https://arxiv.org/abs/2409.06002", "authors": ["Quang-Huy Che", "Duc-Tri Le", "Bich-Nga Pham", "Duc-Khai Lam", "Vinh-Tiep Nguyen"], "title": "Enhanced Generative Data Augmentation for Semantic Segmentation via Stronger Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Data augmentation is crucial for pixel-wise annotation tasks like semantic\nsegmentation, where labeling requires significant effort and intensive labor.\nTraditional methods, involving simple transformations such as rotations and\nflips, create new images but often lack diversity along key semantic dimensions\nand fail to alter high-level semantic properties. To address this issue,\ngenerative models have emerged as an effective solution for augmenting data by\ngenerating synthetic images. Controllable Generative models offer data\naugmentation methods for semantic segmentation tasks by using prompts and\nvisual references from the original image. However, these models face\nchallenges in generating synthetic images that accurately reflect the content\nand structure of the original image due to difficulties in creating effective\nprompts and visual references. In this work, we introduce an effective data\naugmentation pipeline for semantic segmentation using Controllable Diffusion\nmodel. Our proposed method includes efficient prompt generation using\n\\textit{Class-Prompt Appending} and \\textit{Visual Prior Blending} to enhance\nattention to labeled classes in real images, allowing the pipeline to generate\na precise number of augmented images while preserving the structure of\nsegmentation-labeled classes. In addition, we implement a \\textit{class\nbalancing algorithm} to ensure a balanced training dataset when merging the\nsynthetic and original images. Evaluation on PASCAL VOC datasets, our pipeline\ndemonstrates its effectiveness in generating high-quality synthetic images for\nsemantic segmentation. Our code is available at\n\\href{https://github.com/chequanghuy/Enhanced-Generative-Data-Augmentation-for-Semantic-Segmentation-via-Stronger-Guidance}{this\nhttps URL}.", "AI": {"tldr": "The paper introduces a data augmentation pipeline for semantic segmentation using a Controllable Diffusion model, addressing limitations of traditional methods and generative models by improving prompt generation and visual references.", "motivation": "Traditional data augmentation methods lack diversity in semantic dimensions, and generative models struggle with accurate content reflection. This work aims to enhance synthetic image generation for semantic segmentation.", "method": "The proposed method uses Class-Prompt Appending and Visual Prior Blending for efficient prompt generation and attention enhancement. A class balancing algorithm ensures dataset balance.", "result": "Evaluated on PASCAL VOC datasets, the pipeline effectively generates high-quality synthetic images for semantic segmentation.", "conclusion": "The method improves data augmentation for semantic segmentation by preserving segmentation structure and balancing the dataset, demonstrating effectiveness in synthetic image generation."}}
{"id": "2505.01462", "pdf": "https://arxiv.org/pdf/2505.01462", "abs": "https://arxiv.org/abs/2505.01462", "authors": ["Hermann Borotschnig"], "title": "Emotions in Artificial Intelligence", "categories": ["cs.AI", "cs.CY", "68T01, 68T37", "I.2.0; K.4.1"], "comment": "40 pages, 1 figure", "summary": "This conceptual contribution offers a speculative account of how AI systems\nmight emulate emotions as experienced by humans and animals. It presents a\nthought experiment grounded in the hypothesis that natural emotions evolved as\nheuristics for rapid situational appraisal and action selection, enabling\nbiologically adaptive behaviour without requiring full deliberative modeling.\nThe text examines whether artificial systems operating in complex action spaces\ncould similarly benefit from these principles. It is proposed that affect be\ninterwoven with episodic memory by storing corresponding affective tags\nalongside all events. This allows AIs to establish whether present situations\nresemble past events and project the associated emotional labels onto the\ncurrent context. These emotional cues are then combined with need-driven\nemotional hints. The combined emotional state facilitates decision-making in\nthe present by modulating action selection. The low complexity and experiential\ninertness of the proposed architecture are emphasized as evidence that\nemotional expression and consciousness are, in principle, orthogonal-permitting\nthe theoretical possibility of affective zombies. On this basis, the moral\nstatus of AIs emulating affective states is critically examined. It is argued\nthat neither the mere presence of internal representations of emotion nor\nconsciousness alone suffices for moral standing; rather, the capacity for\nself-awareness of inner emotional states is posited as a necessary condition. A\ncomplexity-based criterion is proposed to exclude such awareness in the\npresented model. Additional thought experiments are presented to test the\nconceptual boundaries of this framework.", "AI": {"tldr": "The paper explores how AI might emulate human/animal emotions, proposing affective tags in episodic memory for decision-making, and debates the moral status of such AI.", "motivation": "To understand if AI can benefit from emotion-like heuristics for adaptive behavior, similar to biological systems.", "method": "A thought experiment where AI uses affective tags in episodic memory to project emotions onto current contexts, aiding decision-making.", "result": "Proposes that AI can emulate emotions without consciousness, raising questions about moral standing based on self-awareness.", "conclusion": "Argues that mere emotion emulation or consciousness isn't enough for moral status; self-awareness of emotions is key."}}
{"id": "2505.06774", "pdf": "https://arxiv.org/pdf/2505.06774", "abs": "https://arxiv.org/abs/2505.06774", "authors": ["Ammar Daskin"], "title": "Quantum RNNs and LSTMs Through Entangling and Disentangling Power of Unitary Transformations", "categories": ["quant-ph", "cs.LG"], "comment": "the simulation code can be downloaded from\n  https://github.com/adaskin/quantum-lstm", "summary": "In this paper, we discuss how quantum recurrent neural networks (RNNs) and\ntheir enhanced version, long short-term memory (LSTM) networks, can be modeled\nusing the core ideas presented in Ref.[1], where the entangling and\ndisentangling power of unitary transformations is investigated. In particular,\nwe interpret entangling and disentangling power as information retention and\nforgetting mechanisms in LSTMs. Therefore, entanglement becomes a key component\nof the optimization (training) process. We believe that, by leveraging prior\nknowledge of the entangling power of unitaries, the proposed quantum-classical\nframework can guide and help to design better-parameterized quantum circuits\nfor various real-world applications.", "AI": {"tldr": "Quantum RNNs and LSTMs are modeled using unitary transformations' entangling/disentangling power, linking entanglement to information retention/forgetting in training.", "motivation": "To leverage quantum principles for improving classical neural networks, specifically RNNs and LSTMs, by using entanglement as a training mechanism.", "method": "Model quantum RNNs and LSTMs using unitary transformations, interpreting entanglement as information retention/forgetting.", "result": "A quantum-classical framework is proposed to design better-parameterized quantum circuits for real-world applications.", "conclusion": "Entanglement is key for optimizing quantum-classical neural networks, offering potential for improved circuit design."}}
{"id": "2409.10297", "pdf": "https://arxiv.org/pdf/2409.10297", "abs": "https://arxiv.org/abs/2409.10297", "authors": ["Blaine Hoak", "Patrick McDaniel"], "title": "On Synthetic Texture Datasets: Challenges, Creation, and Curation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The influence of textures on machine learning models has been an ongoing\ninvestigation, specifically in texture bias/learning, interpretability, and\nrobustness. However, due to the lack of large and diverse texture data\navailable, the findings in these works have been limited, as more comprehensive\nevaluations have not been feasible. Image generative models are able to provide\ndata creation at scale, but utilizing these models for texture synthesis has\nbeen unexplored and poses additional challenges both in creating accurate\ntexture images and validating those images. In this work, we introduce an\nextensible methodology and corresponding new dataset for generating\nhigh-quality, diverse texture images capable of supporting a broad set of\ntexture-based tasks. Our pipeline consists of: (1) developing prompts from a\nrange of descriptors to serve as input to text-to-image models, (2) adopting\nand adapting Stable Diffusion pipelines to generate and filter the\ncorresponding images, and (3) further filtering down to the highest quality\nimages. Through this, we create the Prompted Textures Dataset (PTD), a dataset\nof 246,285 texture images that span 56 textures. During the process of\ngenerating images, we find that NSFW safety filters in image generation\npipelines are highly sensitive to texture (and flag up to 60\\% of our texture\nimages), uncovering a potential bias in these models and presenting unique\nchallenges when working with texture data. Through both standard metrics and a\nhuman evaluation, we find that our dataset is high quality and diverse. Our\ndataset is available for download at https://zenodo.org/records/15359142.", "AI": {"tldr": "The paper introduces a method to generate high-quality, diverse texture images using text-to-image models, addressing the lack of large texture datasets. It also highlights biases in NSFW filters when applied to textures.", "motivation": "Existing texture datasets are limited in size and diversity, hindering comprehensive evaluations in texture-related ML tasks. Generative models offer a solution but pose challenges in texture synthesis and validation.", "method": "The pipeline involves (1) creating prompts from descriptors, (2) using Stable Diffusion for image generation and filtering, and (3) further quality filtering to produce the Prompted Textures Dataset (PTD) with 246,285 images across 56 textures.", "result": "The PTD is high-quality and diverse, validated by metrics and human evaluation. NSFW filters were found overly sensitive to textures, flagging 60% of images, revealing model biases.", "conclusion": "The work provides a scalable solution for texture data generation, uncovering biases in safety filters and enabling broader texture-based ML research."}}
{"id": "2505.02118", "pdf": "https://arxiv.org/pdf/2505.02118", "abs": "https://arxiv.org/abs/2505.02118", "authors": ["Wei Liu", "Zhongyu Niu", "Lang Gao", "Zhiying Deng", "Jun Wang", "Haozhao Wang", "Ruixuan Li"], "title": "Adversarial Cooperative Rationalization: The Risk of Spurious Correlations in Even Clean Datasets", "categories": ["cs.AI"], "comment": "ICML 2025", "summary": "This study investigates the self-rationalization framework constructed with a\ncooperative game, where a generator initially extracts the most informative\nsegment from raw input, and a subsequent predictor utilizes the selected subset\nfor its input. The generator and predictor are trained collaboratively to\nmaximize prediction accuracy. In this paper, we first uncover a potential\ncaveat: such a cooperative game could unintentionally introduce a sampling bias\nduring rationale extraction. Specifically, the generator might inadvertently\ncreate an incorrect correlation between the selected rationale candidate and\nthe label, even when they are semantically unrelated in the original dataset.\nSubsequently, we elucidate the origins of this bias using both detailed\ntheoretical analysis and empirical evidence. Our findings suggest a direction\nfor inspecting these correlations through attacks, based on which we further\nintroduce an instruction to prevent the predictor from learning the\ncorrelations. Through experiments on six text classification datasets and two\ngraph classification datasets using three network architectures (GRUs, BERT,\nand GCN), we show that our method not only significantly outperforms recent\nrationalization methods, but also achieves comparable or even better results\nthan a representative LLM (llama3.1-8b-instruct).", "AI": {"tldr": "The paper explores a self-rationalization framework with a cooperative game, identifies a sampling bias issue, and proposes a solution to improve performance.", "motivation": "To address the unintentional sampling bias in rationale extraction within cooperative games between generators and predictors.", "method": "Theoretical analysis and empirical evidence are used to identify bias origins, followed by introducing an instruction to prevent incorrect correlations. Experiments are conducted on multiple datasets and architectures.", "result": "The proposed method outperforms recent rationalization techniques and matches or exceeds the performance of a leading LLM.", "conclusion": "The study provides a solution to mitigate bias in rationale extraction, enhancing prediction accuracy and performance."}}
{"id": "2505.06800", "pdf": "https://arxiv.org/pdf/2505.06800", "abs": "https://arxiv.org/abs/2505.06800", "authors": ["Jairon H. N. Batista", "Fl\u00e1vio B. Gon\u00e7alves", "Yuri F. Saporito", "Rodrigo S. Targino"], "title": "Reverse-BSDE Monte Carlo", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "Recently, there has been a growing interest in generative models based on\ndiffusions driven by the empirical robustness of these methods in generating\nhigh-dimensional photorealistic images and the possibility of using the vast\nexisting toolbox of stochastic differential equations. %This remarkable ability\nmay stem from their capacity to model and generate multimodal distributions. In\nthis work, we offer a novel perspective on the approach introduced in Song et\nal. (2021), shifting the focus from a \"learning\" problem to a \"sampling\"\nproblem. To achieve this, we reformulate the equations governing\ndiffusion-based generative models as a Forward-Backward Stochastic Differential\nEquation (FBSDE), which avoids the well-known issue of pre-estimating the\ngradient of the log target density. The solution of this FBSDE is proved to be\nunique using non-standard techniques. Additionally, we propose a numerical\nsolution to this problem, leveraging on Deep Learning techniques. This\nreformulation opens new pathways for sampling multidimensional distributions\nwith densities known up to a normalization constant, a problem frequently\nencountered in Bayesian statistics.", "AI": {"tldr": "The paper shifts focus from learning to sampling in diffusion-based generative models, reformulating them as FBSDEs to avoid gradient estimation issues, and proposes a numerical solution using deep learning.", "motivation": "Address the challenge of sampling high-dimensional distributions without pre-estimating gradients, leveraging the robustness of diffusion models.", "method": "Reformulate diffusion models as Forward-Backward Stochastic Differential Equations (FBSDEs) and provide a numerical solution using deep learning.", "result": "Proves uniqueness of the FBSDE solution and offers a practical approach for sampling distributions with unknown normalization constants.", "conclusion": "The reformulation enables efficient sampling in high-dimensional spaces, benefiting applications like Bayesian statistics."}}
{"id": "2409.18653", "pdf": "https://arxiv.org/pdf/2409.18653", "abs": "https://arxiv.org/abs/2409.18653", "authors": ["Yuli Zhou", "Guolei Sun", "Yawei Li", "Guo-Sen Xie", "Luca Benini", "Ender Konukoglu"], "title": "When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation", "categories": ["cs.CV", "cs.AI"], "comment": "Technical report. Accepted by Visual Intelligence. Code is released\n  at https://github.com/zhoustan/SAM2-VCOS", "summary": "This study investigates the application and performance of the Segment\nAnything Model 2 (SAM2) in the challenging task of video camouflaged object\nsegmentation (VCOS). VCOS involves detecting objects that blend seamlessly in\nthe surroundings for videos, due to similar colors and textures, poor light\nconditions, etc. Compared to the objects in normal scenes, camouflaged objects\nare much more difficult to detect. SAM2, a video foundation model, has shown\npotential in various tasks. But its effectiveness in dynamic camouflaged\nscenarios remains under-explored. This study presents a comprehensive study on\nSAM2's ability in VCOS. First, we assess SAM2's performance on camouflaged\nvideo datasets using different models and prompts (click, box, and mask).\nSecond, we explore the integration of SAM2 with existing multimodal large\nlanguage models (MLLMs) and VCOS methods. Third, we specifically adapt SAM2 by\nfine-tuning it on the video camouflaged dataset. Our comprehensive experiments\ndemonstrate that SAM2 has excellent zero-shot ability of detecting camouflaged\nobjects in videos. We also show that this ability could be further improved by\nspecifically adjusting SAM2's parameters for VCOS. The code is available at\nhttps://github.com/zhoustan/SAM2-VCOS", "AI": {"tldr": "The study evaluates SAM2's performance in video camouflaged object segmentation (VCOS), showing its strong zero-shot ability and potential for improvement through fine-tuning and integration with MLLMs.", "motivation": "VCOS is challenging due to objects blending into surroundings, and SAM2's effectiveness in dynamic camouflaged scenarios is under-explored.", "method": "Assessed SAM2 on camouflaged video datasets with various prompts, integrated it with MLLMs and VCOS methods, and fine-tuned SAM2 for VCOS.", "result": "SAM2 demonstrates excellent zero-shot ability for VCOS, with further improvements possible through parameter adjustments.", "conclusion": "SAM2 is highly effective for VCOS, and its performance can be enhanced via fine-tuning and multimodal integration."}}
{"id": "2505.02216", "pdf": "https://arxiv.org/pdf/2505.02216", "abs": "https://arxiv.org/abs/2505.02216", "authors": ["Aidan Curtis", "Hao Tang", "Thiago Veloso", "Kevin Ellis", "Joshua Tenenbaum", "Tom\u00e1s Lozano-P\u00e9rez", "Leslie Pack Kaelbling"], "title": "LLM-Guided Probabilistic Program Induction for POMDP Model Estimation", "categories": ["cs.AI"], "comment": null, "summary": "Partially Observable Markov Decision Processes (POMDPs) model decision making\nunder uncertainty. While there are many approaches to approximately solving\nPOMDPs, we aim to address the problem of learning such models. In particular,\nwe are interested in a subclass of POMDPs wherein the components of the model,\nincluding the observation function, reward function, transition function, and\ninitial state distribution function, can be modeled as low-complexity\nprobabilistic graphical models in the form of a short probabilistic program.\nOur strategy to learn these programs uses an LLM as a prior, generating\ncandidate probabilistic programs that are then tested against the empirical\ndistribution and adjusted through feedback. We experiment on a number of\nclassical toy POMDP problems, simulated MiniGrid domains, and two real\nmobile-base robotics search domains involving partial observability. Our\nresults show that using an LLM to guide in the construction of a low-complexity\nPOMDP model can be more effective than tabular POMDP learning, behavior\ncloning, or direct LLM planning.", "AI": {"tldr": "Using LLMs to learn low-complexity POMDP models outperforms traditional methods like tabular learning, behavior cloning, or direct LLM planning.", "motivation": "Addressing the challenge of learning POMDP models, especially those with components modeled as low-complexity probabilistic graphical programs.", "method": "Leveraging LLMs as priors to generate candidate probabilistic programs, which are refined via empirical testing and feedback.", "result": "Effective learning of POMDP models in toy problems, MiniGrid domains, and real robotics tasks, surpassing traditional methods.", "conclusion": "LLM-guided POMDP model construction is a promising approach for learning under uncertainty."}}
{"id": "2505.06805", "pdf": "https://arxiv.org/pdf/2505.06805", "abs": "https://arxiv.org/abs/2505.06805", "authors": ["Tommaso Giovannelli", "Griffin Dean Kent", "Luis Nunes Vicente"], "title": "A stochastic gradient method for trilevel optimization", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "With the success that the field of bilevel optimization has seen in recent\nyears, similar methodologies have started being applied to solving more\ndifficult applications that arise in trilevel optimization. At the helm of\nthese applications are new machine learning formulations that have been\nproposed in the trilevel context and, as a result, efficient and theoretically\nsound stochastic methods are required. In this work, we propose the first-ever\nstochastic gradient descent method for solving unconstrained trilevel\noptimization problems and provide a convergence theory that covers all forms of\ninexactness of the trilevel adjoint gradient, such as the inexact solutions of\nthe middle-level and lower-level problems, inexact computation of the trilevel\nadjoint formula, and noisy estimates of the gradients, Hessians, Jacobians, and\ntensors of third-order derivatives involved. We also demonstrate the promise of\nour approach by providing numerical results on both synthetic trilevel problems\nand trilevel formulations for hyperparameter adversarial tuning.", "AI": {"tldr": "First stochastic gradient descent method for unconstrained trilevel optimization with convergence theory covering inexactness.", "motivation": "Address the need for efficient and theoretically sound stochastic methods in trilevel optimization, inspired by bilevel optimization success.", "method": "Proposes a stochastic gradient descent method for trilevel problems, accounting for inexactness in adjoint gradient computations.", "result": "Convergence theory developed; numerical results show promise on synthetic and hyperparameter adversarial tuning problems.", "conclusion": "The method is effective for trilevel optimization, with potential applications in machine learning."}}
{"id": "2409.20223", "pdf": "https://arxiv.org/pdf/2409.20223", "abs": "https://arxiv.org/abs/2409.20223", "authors": ["Chen Xie", "Ciyun Lin", "Xiaoyu Zheng", "Bowen Gong", "Antonio M. L\u00f3pez"], "title": "GTransPDM: A Graph-embedded Transformer with Positional Decoupling for Pedestrian Crossing Intention Prediction", "categories": ["cs.CV"], "comment": "IEEE SPL", "summary": "Understanding and predicting pedestrian crossing behavioral intention is\ncrucial for the driving safety of autonomous vehicles. Nonetheless, challenges\nemerge when using promising images or environmental context masks to extract\nvarious factors for time-series network modeling, causing pre-processing errors\nor a loss of efficiency. Typically, pedestrian positions captured by onboard\ncameras are often distorted and do not accurately reflect their actual\nmovements. To address these issues, GTransPDM -- a Graph-embedded Transformer\nwith a Position Decoupling Module -- was developed for pedestrian crossing\nintention prediction by leveraging multi-modal features. First, a positional\ndecoupling module was proposed to decompose pedestrian lateral motion and\nencode depth cues in the image view. Then, a graph-embedded Transformer was\ndesigned to capture the spatio-temporal dynamics of human pose skeletons,\nintegrating essential factors such as position, skeleton, and ego-vehicle\nmotion. Experimental results indicate that the proposed method achieves 92%\naccuracy on the PIE dataset and 87% accuracy on the JAAD dataset, with a\nprocessing speed of 0.05ms. It outperforms the state-of-the-art in comparison.", "AI": {"tldr": "GTransPDM, a Graph-embedded Transformer with Position Decoupling Module, improves pedestrian crossing intention prediction using multi-modal features, achieving high accuracy and speed.", "motivation": "Pedestrian crossing intention prediction is vital for autonomous vehicle safety, but current methods face challenges like distorted positions and inefficient preprocessing.", "method": "Proposes a positional decoupling module for motion decomposition and depth encoding, and a graph-embedded Transformer for spatio-temporal dynamics of pose skeletons.", "result": "Achieves 92% accuracy on PIE and 87% on JAAD datasets, with 0.05ms processing speed, outperforming state-of-the-art methods.", "conclusion": "GTransPDM effectively addresses preprocessing and accuracy issues, enhancing pedestrian intention prediction for autonomous driving."}}
{"id": "2505.05396", "pdf": "https://arxiv.org/pdf/2505.05396", "abs": "https://arxiv.org/abs/2505.05396", "authors": ["Stefanos Gkikas"], "title": "A Pain Assessment Framework based on multimodal data and Deep Machine Learning methods", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "From the original abstract: This thesis initially aims to study the pain\nassessment process from a clinical-theoretical perspective while exploring and\nexamining existing automatic approaches. Building on this foundation, the\nprimary objective of this Ph.D. project is to develop innovative computational\nmethods for automatic pain assessment that achieve high performance and are\napplicable in real clinical settings. A primary goal is to thoroughly\ninvestigate and assess significant factors, including demographic elements that\nimpact pain perception, as recognized in pain research, through a computational\nstandpoint. Within the limits of the available data in this research area, our\ngoal was to design, develop, propose, and offer automatic pain assessment\npipelines for unimodal and multimodal configurations that are applicable to the\nspecific requirements of different scenarios. The studies published in this\nPh.D. thesis showcased the effectiveness of the proposed methods, achieving\nstate-of-the-art results. Additionally, they paved the way for exploring new\napproaches in artificial intelligence, foundation models, and generative\nartificial intelligence.", "AI": {"tldr": "The thesis explores pain assessment from clinical and computational perspectives, aiming to develop high-performing, clinically applicable methods. It investigates demographic impacts on pain perception and proposes unimodal/multimodal pipelines, achieving state-of-the-art results and advancing AI research.", "motivation": "To bridge clinical pain assessment with computational methods, addressing gaps in existing approaches and incorporating demographic factors.", "method": "Developed computational pipelines for automatic pain assessment, tested in unimodal and multimodal configurations.", "result": "Achieved state-of-the-art performance, demonstrating effectiveness in clinical settings.", "conclusion": "The proposed methods advance pain assessment and open new directions in AI, foundation models, and generative AI."}}
{"id": "2505.06864", "pdf": "https://arxiv.org/pdf/2505.06864", "abs": "https://arxiv.org/abs/2505.06864", "authors": ["Shunyao Wang", "Ming Cheng", "Christina Dan Wang"], "title": "NewsNet-SDF: Stochastic Discount Factor Estimation with Pretrained Language Model News Embeddings via Adversarial Networks", "categories": ["q-fin.PM", "cs.LG"], "comment": null, "summary": "Stochastic Discount Factor (SDF) models provide a unified framework for asset\npricing and risk assessment, yet traditional formulations struggle to\nincorporate unstructured textual information. We introduce NewsNet-SDF, a novel\ndeep learning framework that seamlessly integrates pretrained language model\nembeddings with financial time series through adversarial networks. Our\nmultimodal architecture processes financial news using GTE-multilingual models,\nextracts temporal patterns from macroeconomic data via LSTM networks, and\nnormalizes firm characteristics, fusing these heterogeneous information sources\nthrough an innovative adversarial training mechanism. Our dataset encompasses\napproximately 2.5 million news articles and 10,000 unique securities,\naddressing the computational challenges of processing and aligning text data\nwith financial time series. Empirical evaluations on U.S. equity data\n(1980-2022) demonstrate NewsNet-SDF substantially outperforms alternatives with\na Sharpe ratio of 2.80. The model shows a 471% improvement over CAPM, over 200%\nimprovement versus traditional SDF implementations, and a 74% reduction in\npricing errors compared to the Fama-French five-factor model. In comprehensive\ncomparisons, our deep learning approach consistently outperforms traditional,\nmodern, and other neural asset pricing models across all key metrics. Ablation\nstudies confirm that text embeddings contribute significantly more to model\nperformance than macroeconomic features, with news-derived principal components\nranking among the most influential determinants of SDF dynamics. These results\nvalidate the effectiveness of our multimodal deep learning approach in\nintegrating unstructured text with traditional financial data for more accurate\nasset pricing, providing new insights for digital intelligent decision-making\nin financial technology.", "AI": {"tldr": "NewsNet-SDF integrates text and financial data via deep learning, outperforming traditional models with a Sharpe ratio of 2.80 and significant improvements in pricing accuracy.", "motivation": "Traditional SDF models fail to incorporate unstructured text data, limiting their effectiveness in asset pricing and risk assessment.", "method": "Combines pretrained language models (GTE-multilingual), LSTM networks for macroeconomic data, and adversarial training to fuse heterogeneous data sources.", "result": "Sharpe ratio of 2.80, 471% improvement over CAPM, 200% over traditional SDF, and 74% fewer pricing errors than Fama-French.", "conclusion": "NewsNet-SDF validates the power of multimodal deep learning for integrating text and financial data, enhancing asset pricing accuracy."}}
{"id": "2410.03311", "pdf": "https://arxiv.org/pdf/2410.03311", "abs": "https://arxiv.org/abs/2410.03311", "authors": ["Ye Wang", "Sipeng Zheng", "Bin Cao", "Qianshan Wei", "Weishuai Zeng", "Qin Jin", "Zongqing Lu"], "title": "Scaling Large Motion Models with Million-Level Human Motions", "categories": ["cs.CV", "cs.LG"], "comment": "ICML 2025", "summary": "Inspired by the recent success of LLMs, the field of human motion\nunderstanding has increasingly shifted toward developing large motion models.\nDespite some progress, current efforts remain far from achieving truly\ngeneralist models, primarily due to the lack of massive high-quality data. To\naddress this gap, we present MotionLib, the first million-level dataset for\nmotion generation, which is at least 15$\\times$ larger than existing\ncounterparts and enriched with hierarchical text descriptions. Using MotionLib,\nwe train a large motion model named Being-M0, demonstrating robust performance\nacross a wide range of human activities, including unseen ones. Through\nsystematic investigation, for the first time, we highlight the importance of\nscaling both data and model size for advancing motion generation, along with\nkey insights to achieve this goal. To better integrate the motion modality, we\npropose Motionbook, an innovative motion encoding approach including (1) a\ncompact yet lossless feature to represent motions; (2) a novel 2D lookup-free\nmotion tokenizer that preserves fine-grained motion details while expanding\ncodebook capacity, significantly enhancing the representational power of motion\ntokens. We believe this work lays the groundwork for developing more versatile\nand powerful motion generation models in the future. For further details, visit\nhttps://github.com/BeingBeyond/Being-M0.", "AI": {"tldr": "MotionLib introduces a million-level dataset for motion generation, enabling the training of a large motion model (Being-M0) that performs robustly across diverse activities. The work emphasizes scaling data and model size, and proposes Motionbook for better motion encoding.", "motivation": "The lack of massive high-quality data hinders the development of generalist models in human motion understanding. MotionLib addresses this gap.", "method": "MotionLib provides a large dataset with hierarchical text descriptions. Being-M0 is trained on this data. Motionbook introduces a compact motion feature and a 2D lookup-free tokenizer.", "result": "Being-M0 demonstrates robust performance across diverse activities, including unseen ones. Motionbook enhances motion token representation.", "conclusion": "This work advances motion generation by scaling data and model size, and introduces innovative encoding techniques, laying groundwork for future models."}}
{"id": "2505.05758", "pdf": "https://arxiv.org/pdf/2505.05758", "abs": "https://arxiv.org/abs/2505.05758", "authors": ["Azim Ospanov", "Farzan Farnia", "Roozbeh Yousefzadeh"], "title": "APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Formal reasoning and automated theorem proving constitute a challenging\nsubfield of machine learning, in which machines are tasked with proving\nmathematical theorems using formal languages like Lean. A formal verification\nsystem can check whether a formal proof is correct or not almost\ninstantaneously, but generating a completely correct formal proof with large\nlanguage models (LLMs) remains a formidable task. The usual approach in the\nliterature is to prompt the LLM many times (up to several thousands) until one\nof the generated proofs passes the verification system. In this work, we\npresent APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a\nmodular, model-agnostic pipeline that combines the strengths of the Lean\ncompiler with an LLM's reasoning abilities to achieve better proof-generation\nresults at a low sampling budget. Apollo directs a fully automated process in\nwhich the LLM generates proofs for theorems, a set of agents analyze the\nproofs, fix the syntax errors, identify the mistakes in the proofs using Lean,\nisolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on\neach remaining goal with a low top-K budget. The repaired sub-proofs are\nrecombined and reverified, iterating up to a user-controlled maximum number of\nattempts. On the miniF2F benchmark, we establish a new state-of-the-art\naccuracy of 75.0% among 7B-parameter models while keeping the sampling budget\nbelow one thousand. Moreover, Apollo raises the state-of-the-art accuracy for\nGoedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few\nhundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40%\naccuracy. Our results demonstrate that targeted, compiler-guided repair of LLM\noutputs yields dramatic gains in both efficiency and correctness, suggesting a\ngeneral paradigm for scalable automated theorem proving.", "AI": {"tldr": "APOLLO is a pipeline combining Lean and LLMs to improve automated theorem proving, achieving high accuracy with low sampling budgets.", "motivation": "Generating correct formal proofs with LLMs is challenging; APOLLO aims to enhance efficiency and correctness by integrating Lean's verification with LLM reasoning.", "method": "APOLLO automates proof generation, error analysis, and repair using Lean and LLMs, iterating with a low sampling budget.", "result": "Achieves 75.0% accuracy on miniF2F and improves Goedel-Prover-SFT to 65.6%, reducing sample complexity significantly.", "conclusion": "Compiler-guided repair of LLM outputs boosts efficiency and correctness, offering a scalable approach for automated theorem proving."}}
{"id": "2505.06900", "pdf": "https://arxiv.org/pdf/2505.06900", "abs": "https://arxiv.org/abs/2505.06900", "authors": ["Zhenzhou Jin", "Li You", "Derrick Wing Kwan Ng", "Xiang-Gen Xia", "Xiqi Gao"], "title": "Near-Field Channel Estimation for XL-MIMO: A Deep Generative Model Guided by Side Information", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "comment": "15 pages, 11 figures, to appear on IEEE Transactions on Cognitive\n  Communications and Networking", "summary": "This paper investigates the near-field (NF) channel estimation (CE) for\nextremely large-scale multiple-input multiple-output (XL-MIMO) systems.\nConsidering the pronounced NF effects in XL-MIMO communications, we first\nestablish a joint angle-distance (AD) domain-based spherical-wavefront physical\nchannel model that captures the inherent sparsity of XL-MIMO channels.\nLeveraging the channel's sparsity in the joint AD domain, the CE is approached\nas a task of reconstructing sparse signals. Anchored in this framework, we\nfirst propose a compressed sensing algorithm to acquire a preliminary channel\nestimate. Harnessing the powerful implicit prior learning capability of\ngenerative artificial intelligence (GenAI), we further propose a GenAI-based\napproach to refine the estimated channel. Specifically, we introduce the\npreliminary estimated channel as side information, and derive the evidence\nlower bound (ELBO) of the log-marginal distribution of the target NF channel\nconditioned on the preliminary estimated channel, which serves as the\noptimization objective for the proposed generative diffusion model (GDM).\nAdditionally, we introduce a more generalized version of the GDM, the\nnon-Markovian GDM (NM-GDM), to accelerate the sampling process, achieving an\napproximately tenfold enhancement in sampling efficiency. Experimental results\nindicate that the proposed approach is capable of offering substantial\nperformance gain in CE compared to existing benchmark schemes within NF XL-MIMO\nsystems. Furthermore, our approach exhibits enhanced generalization\ncapabilities in both the NF or far-field (FF) regions.", "AI": {"tldr": "The paper proposes a GenAI-based approach for near-field channel estimation in XL-MIMO systems, leveraging sparsity and introducing a non-Markovian GDM for efficiency.", "motivation": "Address the challenges of near-field effects in XL-MIMO systems by exploiting channel sparsity and improving estimation accuracy.", "method": "Develop a joint AD domain channel model, use compressed sensing for initial estimates, and refine with a generative diffusion model (GDM) and its non-Markovian variant (NM-GDM).", "result": "Substantial performance gain in channel estimation and improved generalization in both near-field and far-field regions.", "conclusion": "The proposed GenAI-based approach effectively enhances channel estimation in XL-MIMO systems, with significant efficiency improvements."}}
{"id": "2410.13371", "pdf": "https://arxiv.org/pdf/2410.13371", "abs": "https://arxiv.org/abs/2410.13371", "authors": ["Zezhun Shi"], "title": "Rotating-star Pattern for Camera Calibration", "categories": ["cs.CV"], "comment": null, "summary": "Camera calibration is fundamental to 3D vision, and the choice of calibration\npattern greatly affects the accuracy. To address aberration issue, star-shaped\npattern has been proposed as alternatives to traditional checkerboard. However,\nsuch pattern suffers from aliasing artifacts. In this paper, we present a novel\nsolution by employing a series of checkerboard patterns rotated around a\ncentral point instead of a single star-shaped pattern. We further propose a\ncomplete feature extraction algorithm tailored for this design. Experimental\nresults demonstrate that our approach offers improved accuracy over the\nconventional star-shaped pattern and achieves high stability across varying\nexposure levels.", "AI": {"tldr": "A novel camera calibration method using rotated checkerboard patterns improves accuracy and stability over star-shaped patterns.", "motivation": "Addressing the aliasing artifacts and accuracy issues in traditional star-shaped calibration patterns.", "method": "Employing a series of checkerboard patterns rotated around a central point and proposing a tailored feature extraction algorithm.", "result": "Improved accuracy and high stability across varying exposure levels compared to star-shaped patterns.", "conclusion": "The rotated checkerboard pattern is a superior alternative for camera calibration, offering better performance."}}
{"id": "2210.11111", "pdf": "https://arxiv.org/pdf/2210.11111", "abs": "https://arxiv.org/abs/2210.11111", "authors": ["Henrique Don\u00e2ncio", "Laurent Vercouter", "Harald Roclawski"], "title": "The Pump Scheduling Problem: A Real-World Scenario for Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Deep Reinforcement Learning (DRL) has demonstrated impressive results in\ndomains such as games and robotics, where task formulations are well-defined.\nHowever, few DRL benchmarks are grounded in complex, real-world environments,\nwhere safety constraints, partial observability, and the need for\nhand-engineered task representations pose significant challenges. To help\nbridge this gap, we introduce a testbed based on the pump scheduling problem in\na real-world water distribution facility. The task involves controlling pumps\nto ensure a reliable water supply while minimizing energy consumption and\nrespecting the constraints of the system. Our testbed includes a realistic\nsimulator, three years of high-resolution (1-minute) operational data from\nhuman-led control, and a baseline RL task formulation. This testbed supports a\nwide range of research directions, including offline RL, safe exploration,\ninverse RL, and multi-objective optimization.", "AI": {"tldr": "A testbed for Deep Reinforcement Learning (DRL) is introduced, focusing on the pump scheduling problem in a real-world water distribution facility to address challenges like safety constraints and partial observability.", "motivation": "Existing DRL benchmarks lack grounding in complex, real-world environments with safety constraints and partial observability.", "method": "The testbed includes a realistic simulator, three years of high-resolution operational data, and a baseline RL task formulation for pump scheduling.", "result": "The testbed supports research in offline RL, safe exploration, inverse RL, and multi-objective optimization.", "conclusion": "This work bridges the gap between DRL and real-world applications by providing a practical and challenging benchmark."}}
{"id": "2505.06906", "pdf": "https://arxiv.org/pdf/2505.06906", "abs": "https://arxiv.org/abs/2505.06906", "authors": ["Sindre Benjamin Remman", "Anastasios M. Lekkas"], "title": "Realistic Counterfactual Explanations for Machine Learning-Controlled Mobile Robots using 2D LiDAR", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted for publication at the 2025 European Control Conference\n  (ECC)", "summary": "This paper presents a novel method for generating realistic counterfactual\nexplanations (CFEs) in machine learning (ML)-based control for mobile robots\nusing 2D LiDAR. ML models, especially artificial neural networks (ANNs), can\nprovide advanced decision-making and control capabilities by learning from\ndata. However, they often function as black boxes, making it challenging to\ninterpret them. This is especially a problem in safety-critical control\napplications. To generate realistic CFEs, we parameterize the LiDAR space with\nsimple shapes such as circles and rectangles, whose parameters are chosen by a\ngenetic algorithm, and the configurations are transformed into LiDAR data by\nraycasting. Our model-agnostic approach generates CFEs in the form of synthetic\nLiDAR data that resembles a base LiDAR state but is modified to produce a\npre-defined ML model control output based on a query from the user. We\ndemonstrate our method on a mobile robot, the TurtleBot3, controlled using deep\nreinforcement learning (DRL) in real-world and simulated scenarios. Our method\ngenerates logical and realistic CFEs, which helps to interpret the DRL agent's\ndecision making. This paper contributes towards advancing explainable AI in\nmobile robotics, and our method could be a tool for understanding, debugging,\nand improving ML-based autonomous control.", "AI": {"tldr": "A novel method for generating realistic counterfactual explanations (CFEs) in ML-based mobile robot control using 2D LiDAR, aiding interpretability of black-box models.", "motivation": "ML models like ANNs are often black boxes, posing challenges in safety-critical control applications, necessitating interpretable explanations.", "method": "Parameterizes LiDAR space with simple shapes (circles, rectangles) via genetic algorithm, transforms configurations into LiDAR data via raycasting to generate synthetic CFEs.", "result": "Demonstrated on TurtleBot3 with DRL, producing logical and realistic CFEs to interpret decision-making.", "conclusion": "Advances explainable AI in robotics, offering a tool for understanding and improving ML-based autonomous control."}}
{"id": "2410.19794", "pdf": "https://arxiv.org/pdf/2410.19794", "abs": "https://arxiv.org/abs/2410.19794", "authors": ["Zohreh Aghababaeyan", "Manel Abdellatif", "Lionel Briand", "Ramesh S"], "title": "DiffGAN: A Test Generation Approach for Differential Testing of Deep Neural Networks", "categories": ["cs.CV", "cs.LG", "cs.SE"], "comment": null, "summary": "Deep Neural Networks (DNNs) are increasingly deployed across applications.\nHowever, ensuring their reliability remains a challenge, and in many\nsituations, alternative models with similar functionality and accuracy are\navailable. Traditional accuracy-based evaluations often fail to capture\nbehavioral differences between models, especially with limited test datasets,\nmaking it difficult to select or combine models effectively. Differential\ntesting addresses this by generating test inputs that expose discrepancies in\nDNN model behavior. However, existing approaches face significant limitations:\nmany rely on model internals or are constrained by available seed inputs. To\naddress these challenges, we propose DiffGAN, a black-box test image generation\napproach for differential testing of DNN models. DiffGAN leverages a Generative\nAdversarial Network (GAN) and the Non-dominated Sorting Genetic Algorithm II to\ngenerate diverse and valid triggering inputs that reveal behavioral\ndiscrepancies between models. DiffGAN employs two custom fitness functions,\nfocusing on diversity and divergence, to guide the exploration of the GAN input\nspace and identify discrepancies between models' outputs. By strategically\nsearching this space, DiffGAN generates inputs with specific features that\ntrigger differences in model behavior. DiffGAN is black-box, making it\napplicable in more situations. We evaluate DiffGAN on eight DNN model pairs\ntrained on widely used image datasets. Our results show DiffGAN significantly\noutperforms a SOTA baseline, generating four times more triggering inputs, with\ngreater diversity and validity, within the same budget. Additionally, the\ngenerated inputs improve the accuracy of a machine learning-based model\nselection mechanism, which selects the best-performing model based on input\ncharacteristics and can serve as a smart output voting mechanism when using\nalternative models.", "AI": {"tldr": "DiffGAN is a black-box approach using GANs and genetic algorithms to generate diverse test inputs for differential testing of DNNs, outperforming baselines in revealing behavioral discrepancies.", "motivation": "Ensuring DNN reliability is challenging, and traditional accuracy-based evaluations fail to capture behavioral differences between models, especially with limited test data.", "method": "DiffGAN combines GANs and the Non-dominated Sorting Genetic Algorithm II with custom fitness functions for diversity and divergence to generate triggering inputs.", "result": "DiffGAN outperforms baselines, generating four times more triggering inputs with greater diversity and validity, and improves model selection accuracy.", "conclusion": "DiffGAN is an effective black-box solution for differential testing, enhancing model reliability and selection in practical applications."}}
{"id": "2303.13326", "pdf": "https://arxiv.org/pdf/2303.13326", "abs": "https://arxiv.org/abs/2303.13326", "authors": ["Ying Cao", "Elsa Rizk", "Stefan Vlaski", "Ali H. Sayed"], "title": "Decentralized Adversarial Training over Graphs", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2303.01936", "summary": "The vulnerability of machine learning models to adversarial attacks has been\nattracting considerable attention in recent years. Most existing studies focus\non the behavior of stand-alone single-agent learners. In comparison, this work\nstudies adversarial training over graphs, where individual agents are subjected\nto perturbations of varied strength levels across space. It is expected that\ninteractions by linked agents, and the heterogeneity of the attack models that\nare possible over the graph, can help enhance robustness in view of the\ncoordination power of the group. Using a min-max formulation of distributed\nlearning, we develop a decentralized adversarial training framework for\nmulti-agent systems. Specifically, we devise two decentralized adversarial\ntraining algorithms by relying on two popular decentralized learning\nstrategies--diffusion and consensus. We analyze the convergence properties of\nthe proposed framework for strongly-convex, convex, and non-convex\nenvironments, and illustrate the enhanced robustness to adversarial attacks.", "AI": {"tldr": "The paper studies adversarial training in multi-agent systems over graphs, proposing decentralized algorithms to enhance robustness against varied adversarial attacks.", "motivation": "Existing research focuses on single-agent learners, but this work explores how multi-agent interactions and heterogeneous attack models over graphs can improve robustness.", "method": "A min-max formulation of distributed learning is used to develop two decentralized adversarial training algorithms based on diffusion and consensus strategies.", "result": "The framework's convergence is analyzed for strongly-convex, convex, and non-convex environments, demonstrating enhanced robustness to adversarial attacks.", "conclusion": "Decentralized adversarial training over graphs improves robustness by leveraging multi-agent coordination and heterogeneous attack models."}}
{"id": "2505.06927", "pdf": "https://arxiv.org/pdf/2505.06927", "abs": "https://arxiv.org/abs/2505.06927", "authors": ["Ryan Cory-Wright", "Andr\u00e9s G\u00f3mez"], "title": "Stability Regularized Cross-Validation", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": "Some of this material previously appeared in 2306.14851v2, which we\n  have split into two papers (this one and 2306.14851v3), because it contained\n  two ideas that need separate papers", "summary": "We revisit the problem of ensuring strong test-set performance via\ncross-validation. Motivated by the generalization theory literature, we propose\na nested k-fold cross-validation scheme that selects hyperparameters by\nminimizing a weighted sum of the usual cross-validation metric and an empirical\nmodel-stability measure. The weight on the stability term is itself chosen via\na nested cross-validation procedure. This reduces the risk of strong validation\nset performance and poor test set performance due to instability. We benchmark\nour procedure on a suite of 13 real-world UCI datasets, and find that, compared\nto k-fold cross-validation over the same hyperparameters, it improves the\nout-of-sample MSE for sparse ridge regression and CART by 4% on average, but\nhas no impact on XGBoost. This suggests that for interpretable and unstable\nmodels, such as sparse regression and CART, our approach is a viable and\ncomputationally affordable method for improving test-set performance.", "AI": {"tldr": "A nested k-fold cross-validation method is proposed to improve test-set performance by combining cross-validation metrics with model stability, showing benefits for sparse ridge regression and CART but not XGBoost.", "motivation": "To address the risk of poor test-set performance despite strong validation results, leveraging generalization theory to incorporate model stability.", "method": "Nested k-fold cross-validation minimizes a weighted sum of cross-validation metrics and empirical model stability, with weights chosen via nested validation.", "result": "Improves out-of-sample MSE by 4% for sparse ridge regression and CART, but no impact on XGBoost.", "conclusion": "The method is effective and affordable for interpretable, unstable models like sparse regression and CART."}}
{"id": "2411.06864", "pdf": "https://arxiv.org/pdf/2411.06864", "abs": "https://arxiv.org/abs/2411.06864", "authors": ["Andr\u00e9s Mu\u00f1oz", "Nancy Thomas", "Annita Vapsi", "Daniel Borrajo"], "title": "Veri-Car: Towards Open-world Vehicle Information Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Many industrial and service sectors require tools to extract vehicle\ncharacteristics from images. This is a complex task not only by the variety of\nnoise, and large number of classes, but also by the constant introduction of\nnew vehicle models to the market. In this paper, we present Veri-Car, an\ninformation retrieval integrated approach designed to help on this task. It\nleverages supervised learning techniques to accurately identify the make, type,\nmodel, year, color, and license plate of cars. The approach also addresses the\nchallenge of handling open-world problems, where new car models and variations\nfrequently emerge, by employing a sophisticated combination of pre-trained\nmodels, and a hierarchical multi-similarity loss. Veri-Car demonstrates robust\nperformance, achieving high precision and accuracy in classifying both seen and\nunseen data. Additionally, it integrates an ensemble license plate detection,\nand an OCR model to extract license plate numbers with impressive accuracy.", "AI": {"tldr": "Veri-Car is an information retrieval system using supervised learning to extract vehicle details from images, handling open-world challenges with high accuracy.", "motivation": "The need to extract vehicle characteristics from images is complex due to noise, many classes, and new models.", "method": "Uses supervised learning, pre-trained models, hierarchical multi-similarity loss, and integrates license plate detection with OCR.", "result": "Achieves high precision and accuracy in classifying seen and unseen data, with impressive license plate extraction.", "conclusion": "Veri-Car effectively addresses vehicle identification challenges, including open-world problems."}}
{"id": "2310.13786", "pdf": "https://arxiv.org/pdf/2310.13786", "abs": "https://arxiv.org/abs/2310.13786", "authors": ["Eric Aubinais", "Elisabeth Gassiat", "Pablo Piantanida"], "title": "Fundamental Limits of Membership Inference Attacks on Machine Learning Models", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Membership inference attacks (MIA) can reveal whether a particular data point\nwas part of the training dataset, potentially exposing sensitive information\nabout individuals. This article provides theoretical guarantees by exploring\nthe fundamental statistical limitations associated with MIAs on machine\nlearning models at large. More precisely, we first derive the statistical\nquantity that governs the effectiveness and success of such attacks. We then\ntheoretically prove that in a non-linear regression setting with overfitting\nlearning procedures, attacks may have a high probability of success. Finally,\nwe investigate several situations for which we provide bounds on this quantity\nof interest. Interestingly, our findings indicate that discretizing the data\nmight enhance the learning procedure's security. Specifically, it is\ndemonstrated to be limited by a constant, which quantifies the diversity of the\nunderlying data distribution. We illustrate those results through simple\nsimulations.", "AI": {"tldr": "The paper explores the statistical limits of membership inference attacks (MIA) on ML models, proving high success rates in overfitting scenarios and suggesting data discretization as a security enhancement.", "motivation": "To understand the fundamental statistical limitations of MIAs, which can expose sensitive training data, and to identify conditions under which these attacks succeed.", "method": "Derives a statistical quantity governing MIA effectiveness, proves high success probability in non-linear regression with overfitting, and provides bounds for this quantity. Also examines data discretization's impact.", "result": "Theoretical proof of high MIA success in overfitting scenarios; bounds on attack effectiveness; data discretization shown to enhance security by limiting attack success.", "conclusion": "MIAs are highly effective in overfitting settings, but data discretization can mitigate risks by constraining attack success based on data diversity."}}
{"id": "2505.06928", "pdf": "https://arxiv.org/pdf/2505.06928", "abs": "https://arxiv.org/abs/2505.06928", "authors": ["Chi-Sheng Chen", "En-Jui Kuo"], "title": "Unraveling Quantum Environments: Transformer-Assisted Learning in Lindblad Dynamics", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Understanding dissipation in open quantum systems is crucial for the\ndevelopment of robust quantum technologies. In this work, we introduce a\nTransformer-based machine learning framework to infer time-dependent\ndissipation rates in quantum systems governed by the Lindblad master equation.\nOur approach uses time series of observable quantities, such as expectation\nvalues of single Pauli operators, as input to learn dissipation profiles\nwithout requiring knowledge of the initial quantum state or even the system\nHamiltonian.\n  We demonstrate the effectiveness of our approach on a hierarchy of open\nquantum models of increasing complexity, including single-qubit systems with\ntime-independent or time-dependent jump rates, two-qubit interacting systems\n(e.g., Heisenberg and transverse Ising models), and the Jaynes--Cummings model\ninvolving light--matter interaction and cavity loss with time-dependent decay\nrates. Our method accurately reconstructs both fixed and time-dependent decay\nrates from observable time series. To support this, we prove that under\nreasonable assumptions, the jump rates in all these models are uniquely\ndetermined by a finite set of observables, such as qubit and photon\nmeasurements. In practice, we combine Transformer-based architectures with\nlightweight feature extraction techniques to efficiently learn these dynamics.\nOur results suggest that modern machine learning tools can serve as scalable\nand data-driven alternatives for identifying unknown environments in open\nquantum systems.", "AI": {"tldr": "A Transformer-based ML framework infers time-dependent dissipation rates in quantum systems from observable time series, without needing initial state or Hamiltonian knowledge.", "motivation": "Understanding dissipation in open quantum systems is vital for robust quantum technologies.", "method": "Uses Transformer-based ML to learn dissipation profiles from observable time series, applied to various quantum models.", "result": "Accurately reconstructs fixed and time-dependent decay rates, proving unique determination under reasonable assumptions.", "conclusion": "Modern ML tools offer scalable, data-driven solutions for identifying unknown environments in open quantum systems."}}
{"id": "2411.07742", "pdf": "https://arxiv.org/pdf/2411.07742", "abs": "https://arxiv.org/abs/2411.07742", "authors": ["Tianyu Sun", "Jianhao Li", "Xueqian Zhang", "Zhongdao Wang", "Bailan Feng", "Hengshuang Zhao"], "title": "Efficient 3D Perception on Multi-Sweep Point Cloud with Gumbel Spatial Pruning", "categories": ["cs.CV"], "comment": null, "summary": "This paper studies point cloud perception within outdoor environments.\nExisting methods face limitations in recognizing objects located at a distance\nor occluded, due to the sparse nature of outdoor point clouds. In this work, we\nobserve a significant mitigation of this problem by accumulating multiple\ntemporally consecutive point cloud sweeps, resulting in a remarkable\nimprovement in perception accuracy. However, the computation cost also\nincreases, hindering previous approaches from utilizing a large number of point\ncloud sweeps. To tackle this challenge, we find that a considerable portion of\npoints in the accumulated point cloud is redundant, and discarding these points\nhas minimal impact on perception accuracy. We introduce a simple yet effective\nGumbel Spatial Pruning (GSP) layer that dynamically prunes points based on a\nlearned end-to-end sampling. The GSP layer is decoupled from other network\ncomponents and thus can be seamlessly integrated into existing point cloud\nnetwork architectures. Without incurring additional computational overhead, we\nincrease the number of point cloud sweeps from 10, a common practice, to as\nmany as 40. Consequently, there is a significant enhancement in perception\nperformance. For instance, in nuScenes 3D object detection and BEV map\nsegmentation tasks, our pruning strategy improves several 3D perception\nbaseline methods.", "AI": {"tldr": "The paper introduces Gumbel Spatial Pruning (GSP) to dynamically prune redundant points in accumulated point clouds, enabling the use of more sweeps (up to 40) without extra computation, significantly improving perception accuracy.", "motivation": "Existing methods struggle with distant or occluded objects in sparse outdoor point clouds. Accumulating sweeps helps but increases computation.", "method": "Proposes GSP, a learnable pruning layer to remove redundant points dynamically, decoupled from other network components.", "result": "Enables using up to 40 sweeps (vs. 10) without extra cost, improving performance in tasks like 3D object detection and BEV segmentation.", "conclusion": "GSP effectively balances computation and accuracy, enhancing perception in sparse outdoor point clouds."}}
{"id": "2402.01454", "pdf": "https://arxiv.org/pdf/2402.01454", "abs": "https://arxiv.org/abs/2402.01454", "authors": ["Masayuki Takayama", "Tadahisa Okuda", "Thong Pham", "Tatsuyoshi Ikenoue", "Shingo Fukuma", "Shohei Shimizu", "Akiyoshi Sannai"], "title": "Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": null, "summary": "In practical statistical causal discovery (SCD), embedding domain expert\nknowledge as constraints into the algorithm is important for reasonable causal\nmodels reflecting the broad knowledge of domain experts, despite the challenges\nin the systematic acquisition of background knowledge. To overcome these\nchallenges, this paper proposes a novel method for causal inference, in which\nSCD and knowledge-based causal inference (KBCI) with a large language model\n(LLM) are synthesized through ``statistical causal prompting (SCP)'' for LLMs\nand prior knowledge augmentation for SCD. The experiments in this work have\nrevealed that the results of LLM-KBCI and SCD augmented with LLM-KBCI approach\nthe ground truths, more than the SCD result without prior knowledge. These\nexperiments have also revealed that the SCD result can be further improved if\nthe LLM undergoes SCP. Furthermore, with an unpublished real-world dataset, we\nhave demonstrated that the background knowledge provided by the LLM can improve\nthe SCD on this dataset, even if this dataset has never been included in the\ntraining data of the LLM. For future practical application of this proposed\nmethod across important domains such as healthcare, we also thoroughly discuss\nthe limitations, risks of critical errors, expected improvement of techniques\naround LLMs, and realistic integration of expert checks of the results into\nthis automatic process, with SCP simulations under various conditions both in\nsuccessful and failure scenarios. The careful and appropriate application of\nthe proposed approach in this work, with improvement and customization for each\ndomain, can thus address challenges such as dataset biases and limitations,\nillustrating the potential of LLMs to improve data-driven causal inference\nacross diverse scientific domains.\n  The code used in this work is publicly available at:\nwww.github.com/mas-takayama/LLM-and-SCD", "AI": {"tldr": "The paper proposes a method combining statistical causal discovery (SCD) and knowledge-based causal inference (KBCI) using large language models (LLMs) to improve causal inference by integrating expert knowledge. Experiments show improved accuracy over SCD alone, with potential applications in healthcare and other domains.", "motivation": "To address challenges in systematically acquiring domain expert knowledge for causal discovery, the paper aims to synthesize SCD and LLM-based KBCI for more accurate causal models.", "method": "The method involves statistical causal prompting (SCP) for LLMs and prior knowledge augmentation for SCD, integrating LLM-KBCI with SCD.", "result": "Experiments show LLM-KBCI and SCD augmented with LLM-KBCI outperform SCD without prior knowledge, approaching ground truths. LLM background knowledge also improves SCD on unseen real-world data.", "conclusion": "The proposed method, with domain-specific improvements, can mitigate dataset biases and enhance causal inference, though limitations and risks require careful application and expert validation."}}
{"id": "2505.06958", "pdf": "https://arxiv.org/pdf/2505.06958", "abs": "https://arxiv.org/abs/2505.06958", "authors": ["James Tobler", "Hira Taqdees Syeda", "Toby Murray"], "title": "A Formally Verified Robustness Certifier for Neural Networks (Extended Version)", "categories": ["cs.PL", "cs.LG"], "comment": null, "summary": "Neural networks are often susceptible to minor perturbations in input that\ncause them to misclassify. A recent solution to this problem is the use of\nglobally-robust neural networks, which employ a function to certify that the\nclassification of an input cannot be altered by such a perturbation. Outputs\nthat pass this test are called certified robust. However, to the authors'\nknowledge, these certification functions have not yet been verified at the\nimplementation level. We demonstrate how previous unverified implementations\nare exploitably unsound in certain circumstances. Moreover, they often rely on\napproximation-based algorithms, such as power iteration, that (perhaps\nsurprisingly) do not guarantee soundness. To provide assurance that a given\noutput is robust, we implemented and formally verified a certification function\nfor globally-robust neural networks in Dafny. We describe the program, its\nspecifications, and the important design decisions taken for its implementation\nand verification, as well as our experience applying it in practice.", "AI": {"tldr": "The paper highlights vulnerabilities in unverified implementations of certification functions for globally-robust neural networks and presents a formally verified solution in Dafny.", "motivation": "Neural networks are prone to misclassification due to minor input perturbations. Existing certification functions for robustness lack implementation-level verification, leading to potential exploits.", "method": "The authors implemented and formally verified a certification function in Dafny, detailing its design, specifications, and verification process.", "result": "Unverified implementations were found exploitably unsound, while the Dafny-based solution provides assured robustness.", "conclusion": "Formal verification is crucial for reliable certification functions in globally-robust neural networks, as demonstrated by the Dafny implementation."}}
{"id": "2411.11011", "pdf": "https://arxiv.org/pdf/2411.11011", "abs": "https://arxiv.org/abs/2411.11011", "authors": ["Kunwei Lv", "Ruobing Wu", "Suyang Chen", "Ping Lan"], "title": "CCi-YOLOv8n: Enhanced Fire Detection with CARAFE and Context-Guided Modules", "categories": ["cs.CV"], "comment": "13 pages,7 figures", "summary": "Fire incidents in urban and forested areas pose serious threats,underscoring\nthe need for more effective detection technologies. To address these\nchallenges, we present CCi-YOLOv8n, an enhanced YOLOv8 model with targeted\nimprovements for detecting small fires and smoke. The model integrates the\nCARAFE up-sampling operator and a context-guided module to reduce information\nloss during up-sampling and down-sampling, thereby retaining richer feature\nrepresentations. Additionally, an inverted residual mobile block enhanced C2f\nmodule captures small targets and fine smoke patterns, a critical improvement\nover the original model's detection capacity.For validation, we introduce\nWeb-Fire, a dataset curated for fire and smoke detection across diverse\nreal-world scenarios. Experimental results indicate that CCi-YOLOv8n\noutperforms YOLOv8n in detection precision, confirming its effectiveness for\nrobust fire detection tasks.", "AI": {"tldr": "CCi-YOLOv8n improves YOLOv8 for fire/smoke detection by integrating CARAFE and context-guided modules, validated on the Web-Fire dataset.", "motivation": "Addressing the need for better fire detection technologies due to serious threats from urban and forest fires.", "method": "Enhanced YOLOv8 model with CARAFE up-sampling, context-guided module, and inverted residual mobile block for small target detection.", "result": "Outperforms YOLOv8n in precision, proving effectiveness for fire detection.", "conclusion": "CCi-YOLOv8n is a robust solution for detecting small fires and smoke."}}
{"id": "2403.05581", "pdf": "https://arxiv.org/pdf/2403.05581", "abs": "https://arxiv.org/abs/2403.05581", "authors": ["Thiago Freitas dos Santos", "Nardine Osman", "Marco Schorlemmer"], "title": "Can Interpretability Layouts Influence Human Perception of Offensive Sentences?", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper conducts a user study to assess whether three machine learning\n(ML) interpretability layouts can influence participants' views when evaluating\nsentences containing hate speech, focusing on the \"Misogyny\" and \"Racism\"\nclasses. Given the existence of divergent conclusions in the literature, we\nprovide empirical evidence on using ML interpretability in online communities\nthrough statistical and qualitative analyses of questionnaire responses. The\nGeneralized Additive Model estimates participants' ratings, incorporating\nwithin-subject and between-subject designs. While our statistical analysis\nindicates that none of the interpretability layouts significantly influences\nparticipants' views, our qualitative analysis demonstrates the advantages of ML\ninterpretability: 1) triggering participants to provide corrective feedback in\ncase of discrepancies between their views and the model, and 2) providing\ninsights to evaluate a model's behavior beyond traditional performance metrics.", "AI": {"tldr": "The paper studies how ML interpretability layouts affect users' views on hate speech sentences, finding no significant influence statistically but highlighting qualitative benefits like feedback and model behavior insights.", "motivation": "To address conflicting literature on ML interpretability's impact, focusing on hate speech classes (Misogyny, Racism) in online communities.", "method": "User study with questionnaire responses analyzed via Generalized Additive Model, combining within-subject and between-subject designs.", "result": "No significant influence of interpretability layouts on views statistically, but qualitative benefits like feedback and model evaluation insights.", "conclusion": "ML interpretability may not change views but aids feedback and deeper model evaluation beyond traditional metrics."}}
{"id": "2505.07011", "pdf": "https://arxiv.org/pdf/2505.07011", "abs": "https://arxiv.org/abs/2505.07011", "authors": ["Maximilian Egger", "Svenja Lage", "Rawad Bitar", "Antonia Wachter-Zeh"], "title": "Source Anonymity for Private Random Walk Decentralized Learning", "categories": ["cs.CR", "cs.DC", "cs.IT", "cs.LG", "math.IT", "stat.ML"], "comment": null, "summary": "This paper considers random walk-based decentralized learning, where at each\niteration of the learning process, one user updates the model and sends it to a\nrandomly chosen neighbor until a convergence criterion is met. Preserving data\nprivacy is a central concern and open problem in decentralized learning. We\npropose a privacy-preserving algorithm based on public-key cryptography and\nanonymization. In this algorithm, the user updates the model and encrypts the\nresult using a distant user's public key. The encrypted result is then\ntransmitted through the network with the goal of reaching that specific user.\nThe key idea is to hide the source's identity so that, when the destination\nuser decrypts the result, it does not know who the source was. The challenge is\nto design a network-dependent probability distribution (at the source) over the\npotential destinations such that, from the receiver's perspective, all users\nhave a similar likelihood of being the source. We introduce the problem and\nconstruct a scheme that provides anonymity with theoretical guarantees. We\nfocus on random regular graphs to establish rigorous guarantees.", "AI": {"tldr": "A privacy-preserving decentralized learning algorithm using public-key cryptography and anonymization to hide the source's identity during model updates.", "motivation": "To address data privacy concerns in decentralized learning by ensuring the source of model updates remains anonymous.", "method": "Users update the model, encrypt it with a distant user's public key, and transmit it anonymously. A network-dependent probability distribution ensures source anonymity.", "result": "A scheme with theoretical guarantees for anonymity, particularly effective in random regular graphs.", "conclusion": "The proposed algorithm successfully preserves privacy in decentralized learning by anonymizing the source of updates."}}
{"id": "2411.11370", "pdf": "https://arxiv.org/pdf/2411.11370", "abs": "https://arxiv.org/abs/2411.11370", "authors": ["Ke Zhang", "Zhaoye Zheng", "Yurong Guo", "Jiacun Wang", "Jiyuan Yang", "Yangjie Xiao"], "title": "Transmission Line Defect Detection Based on UAV Patrol Images and Vision-language Pretraining", "categories": ["cs.CV"], "comment": null, "summary": "Unmanned aerial vehicle (UAV) patrol inspection has emerged as a predominant\napproach in transmission line monitoring owing to its cost-effectiveness.\nDetecting defects in transmission lines is a critical task during UAV patrol\ninspection. However, due to imaging distance and shooting angles, UAV patrol\nimages often suffer from insufficient defect-related visual information, which\nhas an adverse effect on detection accuracy. In this article, we propose a\nnovel method for detecting defects in UAV patrol images, which is based on\nvision-language pretraining for transmission line (VLP-TL) and a progressive\ntransfer strategy (PTS). Specifically, VLP-TL contains two novel pretraining\ntasks tailored for the transmission line scenario, aimimg at pretraining an\nimage encoder with abundant knowledge acquired from both visual and linguistic\ninformation. Transferring the pretrained image encoder to the defect detector\nas its backbone can effectively alleviate the insufficient visual information\nproblem. In addition, the PTS further improves transfer performance by\nprogressively bridging the gap between pretraining and downstream defection\ndetection. Experimental results demonstrate that the proposed method\nsignificantly improves defect detection accuracy by jointly utilizing\nmultimodal information, overcoming the limitations of insufficient\ndefect-related visual information provided by UAV patrol images.", "AI": {"tldr": "A novel method using vision-language pretraining (VLP-TL) and progressive transfer strategy (PTS) improves defect detection in UAV patrol images by leveraging multimodal information.", "motivation": "UAV patrol images often lack sufficient defect-related visual information due to imaging distance and angles, reducing detection accuracy.", "method": "Proposes VLP-TL with tailored pretraining tasks and PTS to transfer knowledge from pretraining to defect detection, enhancing visual information.", "result": "Experimental results show significant accuracy improvement in defect detection by utilizing multimodal data.", "conclusion": "The method effectively addresses insufficient visual information in UAV images, enhancing defect detection performance."}}
{"id": "2403.17154", "pdf": "https://arxiv.org/pdf/2403.17154", "abs": "https://arxiv.org/abs/2403.17154", "authors": ["Jaskirat Singh", "Emad Fallahzadeh", "Bram Adams", "Ahmed E. Hassan"], "title": "On the Impact of Black-box Deployment Strategies for Edge AI on Latency and Model Performance", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Deciding what combination of operators to use across the Edge AI tiers to\nachieve specific latency and model performance requirements is an open question\nfor MLOps engineers. This study aims to empirically assess the accuracy vs\ninference time trade-off of different black-box Edge AI deployment strategies,\ni.e., combinations of deployment operators and deployment tiers. In this paper,\nwe conduct inference experiments involving 3 deployment operators (i.e.,\nPartitioning, Quantization, Early Exit), 3 deployment tiers (i.e., Mobile,\nEdge, Cloud) and their combinations on four widely used Computer-Vision models\nto investigate the optimal strategies from the point of view of MLOps\ndevelopers. Our findings suggest that Edge deployment using the hybrid\nQuantization + Early Exit operator could be preferred over non-hybrid operators\n(Quantization/Early Exit on Edge, Partition on Mobile-Edge) when faster latency\nis a concern at medium accuracy loss. However, when minimizing accuracy loss is\na concern, MLOps engineers should prefer using only a Quantization operator on\nedge at a latency reduction or increase, respectively over the Early\nExit/Partition (on edge/mobile-edge) and Quantized Early Exit (on edge)\noperators. In scenarios constrained by Mobile CPU/RAM resources, a preference\nfor Partitioning across mobile and edge tiers is observed over mobile\ndeployment. For models with smaller input data samples (such as FCN), a\nnetwork-constrained cloud deployment can also be a better alternative than\nMobile/Edge deployment and Partitioning strategies. For models with large input\ndata samples (ResNet, ResNext, DUC), an edge tier having higher\nnetwork/computational capabilities than Cloud/Mobile can be a more viable\noption than Partitioning and Mobile/Cloud deployment strategies.", "AI": {"tldr": "The paper evaluates Edge AI deployment strategies (Partitioning, Quantization, Early Exit) across tiers (Mobile, Edge, Cloud) for latency and accuracy trade-offs, identifying optimal operator combinations for MLOps developers.", "motivation": "To empirically assess the accuracy vs. inference time trade-off of different Edge AI deployment strategies for MLOps engineers.", "method": "Inference experiments with 3 operators and 3 tiers on four Computer-Vision models to determine optimal strategies.", "result": "Hybrid Quantization + Early Exit on Edge is best for faster latency with medium accuracy loss. Quantization alone on Edge is preferred for minimal accuracy loss. Partitioning is better for Mobile CPU/RAM constraints. Cloud deployment suits smaller input models, while Edge is better for larger inputs.", "conclusion": "Optimal Edge AI deployment depends on latency, accuracy, and resource constraints, with hybrid operators often outperforming non-hybrid ones."}}
{"id": "2505.07033", "pdf": "https://arxiv.org/pdf/2505.07033", "abs": "https://arxiv.org/abs/2505.07033", "authors": ["Ningsheng Zhao", "Trang Bui", "Jia Yuan Yu", "Krzysztof Dzieciolowski"], "title": "Outperformance Score: A Universal Standardization Method for Confusion-Matrix-Based Classification Performance Metrics", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Many classification performance metrics exist, each suited to a specific\napplication. However, these metrics often differ in scale and can exhibit\nvarying sensitivity to class imbalance rates in the test set. As a result, it\nis difficult to use the nominal values of these metrics to interpret and\nevaluate classification performances, especially when imbalance rates vary. To\naddress this problem, we introduce the outperformance score function, a\nuniversal standardization method for confusion-matrix-based classification\nperformance (CMBCP) metrics. It maps any given metric to a common scale of\n$[0,1]$, while providing a clear and consistent interpretation. Specifically,\nthe outperformance score represents the percentile rank of the observed\nclassification performance within a reference distribution of possible\nperformances. This unified framework enables meaningful comparison and\nmonitoring of classification performance across test sets with differing\nimbalance rates. We illustrate how the outperformance scores can be applied to\na variety of commonly used classification performance metrics and demonstrate\nthe robustness of our method through experiments on real-world datasets\nspanning multiple classification applications.", "AI": {"tldr": "The paper introduces the outperformance score function to standardize classification performance metrics, enabling meaningful comparisons across varying class imbalance rates.", "motivation": "Existing classification metrics vary in scale and sensitivity to class imbalance, making performance interpretation difficult.", "method": "The outperformance score function standardizes metrics to a [0,1] scale, representing percentile ranks within a reference distribution.", "result": "The method enables robust comparison of classification performance across datasets with differing imbalance rates.", "conclusion": "The outperformance score provides a universal, interpretable framework for evaluating classification performance."}}
{"id": "2411.11904", "pdf": "https://arxiv.org/pdf/2411.11904", "abs": "https://arxiv.org/abs/2411.11904", "authors": ["Yue Zhou", "Mengcheng Lan", "Xiang Li", "Litong Feng", "Yiping Ke", "Xue Jiang", "Qingyun Li", "Xue Yang", "Wayne Zhang"], "title": "GeoGround: A Unified Large Vision-Language Model for Remote Sensing Visual Grounding", "categories": ["cs.CV"], "comment": "9 pages, 5 figures", "summary": "Remote sensing (RS) visual grounding aims to use natural language expression\nto locate specific objects (in the form of the bounding box or segmentation\nmask) in RS images, enhancing human interaction with intelligent RS\ninterpretation systems. Early research in this area was primarily based on\nhorizontal bounding boxes (HBBs), but as more diverse RS datasets have become\navailable, tasks involving oriented bounding boxes (OBBs) and segmentation\nmasks have emerged. In practical applications, different targets require\ndifferent grounding types: HBB can localize an object's position, OBB provides\nits orientation, and mask depicts its shape. However, existing specialized\nmethods are typically tailored to a single type of RS visual grounding task and\nare hard to generalize across tasks. In contrast, large vision-language models\n(VLMs) exhibit powerful multi-task learning capabilities but struggle to handle\ndense prediction tasks like segmentation. This paper proposes GeoGround, a\nnovel framework that unifies support for HBB, OBB, and mask RS visual grounding\ntasks, allowing flexible output selection. Rather than customizing the\narchitecture of VLM, our work aims to elegantly support pixel-level visual\ngrounding output through the Text-Mask technique. We define prompt-assisted and\ngeometry-guided learning to enhance consistency across different signals.\nExperimental results show that GeoGround demonstrates strong performance across\nfour RS visual grounding tasks, matching the performance of specialized methods\non multiple benchmarks. Code available at https://github.com/zytx121/GeoGround", "AI": {"tldr": "GeoGround is a unified framework for RS visual grounding, supporting HBB, OBB, and mask tasks with flexible output selection, outperforming specialized methods.", "motivation": "Existing methods are task-specific and lack generalization, while VLMs struggle with dense tasks like segmentation. GeoGround aims to unify and enhance RS visual grounding.", "method": "Uses Text-Mask technique for pixel-level grounding, with prompt-assisted and geometry-guided learning for signal consistency.", "result": "GeoGround matches specialized methods on benchmarks, showing strong performance across four RS visual grounding tasks.", "conclusion": "GeoGround effectively unifies diverse RS visual grounding tasks, offering flexibility and high performance."}}
{"id": "2405.17412", "pdf": "https://arxiv.org/pdf/2405.17412", "abs": "https://arxiv.org/abs/2405.17412", "authors": ["Aditya Ravuri", "Neil D. Lawrence"], "title": "Towards One Model for Classical Dimensionality Reduction: A Probabilistic Perspective on UMAP and t-SNE", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "Updated figures", "summary": "This paper shows that dimensionality reduction methods such as UMAP and\nt-SNE, can be approximately recast as MAP inference methods corresponding to a\nmodel introduced in Ravuri et al. (2023), that describes the graph Laplacian\n(an estimate of the data precision matrix) using a Wishart distribution, with a\nmean given by a non-linear covariance function evaluated on the latents. This\ninterpretation offers deeper theoretical and semantic insights into such\nalgorithms, and forging a connection to Gaussian process latent variable models\nby showing that well-known kernels can be used to describe covariances implied\nby graph Laplacians. We also introduce tools with which similar dimensionality\nreduction methods can be studied.", "AI": {"tldr": "The paper reframes UMAP and t-SNE as MAP inference methods under a Wishart-distributed graph Laplacian model, linking them to Gaussian process latent variable models.", "motivation": "To provide theoretical and semantic insights into dimensionality reduction methods like UMAP and t-SNE by connecting them to probabilistic models.", "method": "Recasts UMAP and t-SNE as MAP inference methods using a Wishart distribution for the graph Laplacian and non-linear covariance functions.", "result": "Shows that these methods can be interpreted probabilistically and linked to Gaussian process models, offering new analytical tools.", "conclusion": "The work deepens understanding of dimensionality reduction algorithms and provides a framework for studying similar methods."}}
{"id": "2505.07046", "pdf": "https://arxiv.org/pdf/2505.07046", "abs": "https://arxiv.org/abs/2505.07046", "authors": ["Stephen Thomas"], "title": "Streaming Krylov-Accelerated Stochastic Gradient Descent", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "We present SKA-SGD (Streaming Krylov-Accelerated Stochastic Gradient\nDescent), a novel optimization approach that accelerates convergence for\nill-conditioned problems by projecting stochastic gradients onto a\nlow-dimensional Krylov subspace. Directly inspired by recent advances in s-step\nConjugate Gradient methods with streaming Gauss-Seidel Gram solvers\n\\cite{dambra2025sstep}, our method extends these techniques to the stochastic\noptimization domain. Our approach combines three key innovations: (1)\nprojection coefficients computed via a single streaming Gauss-Seidel iteration,\nwhich is mathematically equivalent to Modified Gram-Schmidt orthogonalization;\n(2) a Chebyshev polynomial basis for constructing the Krylov subspace,\nproviding superior numerical stability; and (3) efficient implementation for\nAMD GPUs using HIP. We prove that our streaming approach achieves a backward\nerror near machine precision with $O(s^2)$ complexity rather than $O(s^3)$,\nwhere $s$ is the Krylov subspace dimension. Experimental results demonstrate\nthat SKA-SGD significantly outperforms standard SGD and Adam in convergence\nrate and final error, particularly for problems with condition numbers\nexceeding $10^3$. GPU performance analysis reveals a crossover point where\ncommunication-avoiding benefits outweigh computational overhead, typically\noccurring at moderate scale ($p \\approx 64$ processors) for problem sizes $n\n\\geq 10^6$.", "AI": {"tldr": "SKA-SGD accelerates convergence for ill-conditioned problems by projecting stochastic gradients onto a low-dimensional Krylov subspace, outperforming SGD and Adam.", "motivation": "Addresses slow convergence in ill-conditioned stochastic optimization problems by leveraging Krylov subspace techniques.", "method": "Projects gradients onto a Krylov subspace using streaming Gauss-Seidel iteration, Chebyshev polynomial basis, and efficient GPU implementation.", "result": "Achieves near machine precision with reduced complexity and outperforms SGD and Adam, especially for high condition numbers.", "conclusion": "SKA-SGD is effective for large-scale, ill-conditioned problems, with GPU benefits at moderate scales."}}
{"id": "2411.14494", "pdf": "https://arxiv.org/pdf/2411.14494", "abs": "https://arxiv.org/abs/2411.14494", "authors": ["Nitish Shukla", "Arun Ross"], "title": "dc-GAN: Dual-Conditioned GAN for Face Demorphing From a Single Morph", "categories": ["cs.CV"], "comment": null, "summary": "A facial morph is an image created by combining two face images pertaining to\ntwo distinct identities. Face demorphing inverts the process and tries to\nrecover the original images constituting a facial morph. While morph attack\ndetection (MAD) techniques can be used to flag morph images, they do not\ndivulge any visual information about the faces used to create them. Demorphing\nhelps address this problem. Existing demorphing techniques are either very\nrestrictive (assume identities during testing) or produce feeble outputs (both\noutputs look very similar). In this paper, we overcome these issues by\nproposing dc-GAN, a novel GAN-based demorphing method conditioned on the morph\nimages. Our method overcomes morph-replication and produces high quality\nreconstructions of the bonafide images used to create the morphs. Moreover, our\nmethod is highly generalizable across demorphing paradigms\n(differential/reference-free). We conduct experiments on AMSL, FRLL-Morphs and\nMorDiff datasets to showcase the efficacy of our method.", "AI": {"tldr": "The paper proposes dc-GAN, a GAN-based method for high-quality face demorphing, overcoming limitations of existing techniques.", "motivation": "Existing demorphing methods are restrictive or produce poor outputs, limiting their practical use.", "method": "The authors introduce dc-GAN, a GAN-based demorphing method conditioned on morph images, ensuring high-quality reconstructions.", "result": "Experiments on AMSL, FRLL-Morphs, and MorDiff datasets demonstrate the method's efficacy and generalizability.", "conclusion": "dc-GAN effectively addresses demorphing challenges, producing superior results and generalizing across paradigms."}}
{"id": "2407.10424", "pdf": "https://arxiv.org/pdf/2407.10424", "abs": "https://arxiv.org/abs/2407.10424", "authors": ["Yang Zhao", "Di Huang", "Chongxiao Li", "Pengwei Jin", "Muxin Song", "Yinan Xu", "Ziyuan Nan", "Mingju Gao", "Tianyun Ma", "Lei Qi", "Yansong Pan", "Zhenxing Zhang", "Rui Zhang", "Xishan Zhang", "Zidong Du", "Qi Guo", "Xing Hu"], "title": "CodeV: Empowering LLMs with HDL Generation through Multi-Level Summarization", "categories": ["cs.PL", "cs.AI"], "comment": "13 pages, 10 figures, journal", "summary": "The design flow of processors, particularly in hardware description languages\n(HDL) like Verilog and Chisel, is complex and costly. While recent advances in\nlarge language models (LLMs) have significantly improved coding tasks in\nsoftware languages such as Python, their application in HDL generation remains\nlimited due to the scarcity of high-quality HDL data. Traditional methods of\nadapting LLMs for hardware design rely on synthetic HDL datasets, which often\nsuffer from low quality because even advanced LLMs like GPT perform poorly in\nthe HDL domain. Moreover, these methods focus solely on chat tasks and the\nVerilog language, limiting their application scenarios.\n  In this paper, we observe that: (1) HDL code collected from the real world is\nof higher quality than code generated by LLMs. (2) LLMs like GPT-3.5 excel in\nsummarizing HDL code rather than generating it. (3) An explicit language tag\ncan help LLMs better adapt to the target language when there is insufficient\ndata. Based on these observations, we propose an efficient LLM fine-tuning\npipeline for HDL generation that integrates a multi-level summarization data\nsynthesis process with a novel Chat-FIM-Tag supervised fine-tuning method. The\npipeline enhances the generation of HDL code from natural language descriptions\nand enables the handling of various tasks such as chat and infilling incomplete\ncode. Utilizing this pipeline, we introduce CodeV, a series of HDL generation\nLLMs. Among them, CodeV-All not only possesses a more diverse range of language\nabilities, i.e. Verilog and Chisel, and a broader scope of tasks, i.e. Chat and\nfill-in-middle (FIM), but it also achieves performance on VerilogEval that is\ncomparable to or even surpasses that of CodeV-Verilog fine-tuned on Verilog\nonly, making them the first series of open-source LLMs designed for\nmulti-scenario HDL generation.", "AI": {"tldr": "The paper proposes a fine-tuning pipeline for LLMs to improve HDL code generation, leveraging real-world HDL data and multi-level summarization, resulting in the CodeV series of models that outperform traditional methods.", "motivation": "The scarcity of high-quality HDL data and poor performance of LLMs in HDL generation limit their application in hardware design. The paper aims to address these issues by leveraging real-world HDL data and improving LLM adaptation.", "method": "The authors propose a fine-tuning pipeline combining multi-level summarization data synthesis and a novel Chat-FIM-Tag supervised fine-tuning method. This enhances HDL generation from natural language and supports tasks like chat and code infilling.", "result": "The introduced CodeV series, especially CodeV-All, outperforms traditional methods, handling multiple languages (Verilog, Chisel) and tasks (chat, FIM) while achieving competitive performance on benchmarks like VerilogEval.", "conclusion": "The proposed pipeline and CodeV models successfully address HDL generation challenges, offering a versatile and high-performing solution for multi-scenario hardware design tasks."}}
{"id": "2505.07054", "pdf": "https://arxiv.org/pdf/2505.07054", "abs": "https://arxiv.org/abs/2505.07054", "authors": ["Austin Braniff", "Yuhe Tian"], "title": "YANNs: Y-wise Affine Neural Networks for Exact and Efficient Representations of Piecewise Linear Functions", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "comment": null, "summary": "This work formally introduces Y-wise Affine Neural Networks (YANNs), a\nfully-explainable network architecture that continuously and efficiently\nrepresent piecewise affine functions with polytopic subdomains. Following from\nthe proofs, it is shown that the development of YANNs requires no training to\nachieve the functionally equivalent representation. YANNs thus maintain all\nmathematical properties of the original formulations. Multi-parametric model\npredictive control is utilized as an application showcase of YANNs, which\ntheoretically computes optimal control laws as a piecewise affine function of\nstates, outputs, setpoints, and disturbances. With the exact representation of\nmulti-parametric control laws, YANNs retain essential control-theoretic\nguarantees such as recursive feasibility and stability. This sets YANNs apart\nfrom the existing works which apply neural networks for approximating optimal\ncontrol laws instead of exactly representing them. By optimizing the inference\nspeed of the networks, YANNs can evaluate substantially faster in real-time\ncompared to traditional piecewise affine function calculations. Numerical case\nstudies are presented to demonstrate the algorithmic scalability with respect\nto the input/output dimensions and the number of subdomains. YANNs represent a\nsignificant advancement in control as the first neural network-based controller\nthat inherently ensures both feasibility and stability. Future applications can\nleverage them as an efficient and interpretable starting point for data-driven\nmodeling/control.", "AI": {"tldr": "YANNs are explainable neural networks representing piecewise affine functions without training, ensuring control-theoretic guarantees like feasibility and stability.", "motivation": "To create a fully-explainable neural network architecture that exactly represents piecewise affine functions, avoiding approximations and retaining mathematical properties.", "method": "YANNs are developed without training, using multi-parametric model predictive control to represent optimal control laws as piecewise affine functions.", "result": "YANNs achieve exact representation of control laws, ensuring recursive feasibility and stability, and outperform traditional methods in inference speed.", "conclusion": "YANNs advance control theory by providing an efficient, interpretable neural network-based controller with inherent guarantees, suitable for future data-driven applications."}}
{"id": "2412.00176", "pdf": "https://arxiv.org/pdf/2412.00176", "abs": "https://arxiv.org/abs/2412.00176", "authors": ["Hui Ren", "Joanna Materzynska", "Rohit Gandikota", "David Bau", "Antonio Torralba"], "title": "Opt-In Art: Learning Art Styles Only from Few Examples", "categories": ["cs.CV"], "comment": null, "summary": "We explore whether pre-training on datasets with paintings is necessary for a\nmodel to learn an artistic style with only a few examples. To investigate this,\nwe train a text-to-image model exclusively on photographs, without access to\nany painting-related content. We show that it is possible to adapt a model that\nis trained without paintings to an artistic style, given only few examples.\nUser studies and automatic evaluations confirm that our model (post-adaptation)\nperforms on par with state-of-the-art models trained on massive datasets that\ncontain artistic content like paintings, drawings or illustrations. Finally,\nusing data attribution techniques, we analyze how both artistic and\nnon-artistic datasets contribute to generating artistic-style images.\nSurprisingly, our findings suggest that high-quality artistic outputs can be\nachieved without prior exposure to artistic data, indicating that artistic\nstyle generation can occur in a controlled, opt-in manner using only a limited,\ncarefully selected set of training examples.", "AI": {"tldr": "A study shows that pre-training on paintings isn't necessary for artistic style adaptation; a model trained on photos can adapt to artistic styles with few examples, matching state-of-the-art performance.", "motivation": "To investigate if pre-training on artistic datasets is essential for learning artistic styles, or if adaptation from non-artistic data is sufficient.", "method": "Train a text-to-image model on photographs only, then adapt it to artistic styles using few examples. Evaluate with user studies and automatic metrics.", "result": "The adapted model performs comparably to models pre-trained on large artistic datasets. Data attribution reveals artistic outputs can emerge without prior artistic exposure.", "conclusion": "Artistic style generation can be achieved without pre-training on artistic data, using minimal, carefully selected examples."}}
{"id": "2407.13163", "pdf": "https://arxiv.org/pdf/2407.13163", "abs": "https://arxiv.org/abs/2407.13163", "authors": ["Yi Zhang", "Ruihong Qiu", "Jiajun Liu", "Sen Wang"], "title": "ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems", "categories": ["cs.IR", "cs.AI"], "comment": "CIKM 2024", "summary": "Offline reinforcement learning (RL) is an effective tool for real-world\nrecommender systems with its capacity to model the dynamic interest of users\nand its interactive nature. Most existing offline RL recommender systems focus\non model-based RL through learning a world model from offline data and building\nthe recommendation policy by interacting with this model. Although these\nmethods have made progress in the recommendation performance, the effectiveness\nof model-based offline RL methods is often constrained by the accuracy of the\nestimation of the reward model and the model uncertainties, primarily due to\nthe extreme discrepancy between offline logged data and real-world data in user\ninteractions with online platforms. To fill this gap, a more accurate reward\nmodel and uncertainty estimation are needed for the model-based RL methods. In\nthis paper, a novel model-based Reward Shaping in Offline Reinforcement\nLearning for Recommender Systems, ROLeR, is proposed for reward and uncertainty\nestimation in recommendation systems. Specifically, a non-parametric reward\nshaping method is designed to refine the reward model. In addition, a flexible\nand more representative uncertainty penalty is designed to fit the needs of\nrecommendation systems. Extensive experiments conducted on four benchmark\ndatasets showcase that ROLeR achieves state-of-the-art performance compared\nwith existing baselines. The source code can be downloaded at\nhttps://github.com/ArronDZhang/ROLeR.", "AI": {"tldr": "ROLeR introduces a model-based offline RL method for recommender systems, improving reward and uncertainty estimation to address discrepancies between offline and real-world data.", "motivation": "Existing model-based offline RL methods for recommender systems are limited by inaccurate reward models and uncertainty estimation due to data discrepancies.", "method": "ROLeR uses non-parametric reward shaping and a flexible uncertainty penalty to refine the reward model and improve uncertainty estimation.", "result": "Experiments on four datasets show ROLeR outperforms existing baselines, achieving state-of-the-art performance.", "conclusion": "ROLeR effectively addresses the limitations of model-based offline RL in recommender systems, offering improved accuracy and performance."}}
{"id": "2505.07067", "pdf": "https://arxiv.org/pdf/2505.07067", "abs": "https://arxiv.org/abs/2505.07067", "authors": ["Francesco Cagnetta", "Hyunmo Kang", "Matthieu Wyart"], "title": "Learning curves theory for hierarchically compositional data with power-law distributed features", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG"], "comment": null, "summary": "Recent theories suggest that Neural Scaling Laws arise whenever the task is\nlinearly decomposed into power-law distributed units. Alternatively, scaling\nlaws also emerge when data exhibit a hierarchically compositional structure, as\nis thought to occur in language and images. To unify these views, we consider\nclassification and next-token prediction tasks based on probabilistic\ncontext-free grammars -- probabilistic models that generate data via a\nhierarchy of production rules. For classification, we show that having\npower-law distributed production rules results in a power-law learning curve\nwith an exponent depending on the rules' distribution and a large\nmultiplicative constant that depends on the hierarchical structure. By\ncontrast, for next-token prediction, the distribution of production rules\ncontrols the local details of the learning curve, but not the exponent\ndescribing the large-scale behaviour.", "AI": {"tldr": "The paper unifies theories on Neural Scaling Laws by analyzing tasks based on probabilistic context-free grammars, showing how power-law distributed rules affect learning curves differently for classification and next-token prediction.", "motivation": "To reconcile conflicting theories on Neural Scaling Laws, which arise from either linear decomposition or hierarchical compositional structures in data.", "method": "Analyzes classification and next-token prediction tasks using probabilistic context-free grammars, focusing on power-law distributed production rules.", "result": "For classification, power-law rules yield a power-law learning curve with distribution-dependent exponent and hierarchy-dependent constant. For next-token prediction, rules affect local curve details but not the large-scale exponent.", "conclusion": "The study bridges competing views on scaling laws, demonstrating how task structure influences learning dynamics."}}
{"id": "2412.00626", "pdf": "https://arxiv.org/pdf/2412.00626", "abs": "https://arxiv.org/abs/2412.00626", "authors": ["You Wu", "Xiangyang Yang", "Xucheng Wang", "Hengzhou Ye", "Dan Zeng", "Shuiwang Li"], "title": "MambaNUT: Nighttime UAV Tracking via Mamba-based Adaptive Curriculum Learning", "categories": ["cs.CV"], "comment": null, "summary": "Harnessing low-light enhancement and domain adaptation, nighttime UAV\ntracking has made substantial strides. However, over-reliance on image\nenhancement, limited high-quality nighttime data, and a lack of integration\nbetween daytime and nighttime trackers hinder the development of an end-to-end\ntrainable framework. Additionally, current ViT-based trackers demand heavy\ncomputational resources due to their reliance on the self-attention mechanism.\nIn this paper, we propose a novel pure Mamba-based tracking framework\n(MambaNUT) that employs a state space model with linear complexity as its\nbackbone, incorporating a single-stream architecture that integrates feature\nlearning and template-search coupling within Vision Mamba. We introduce an\nadaptive curriculum learning (ACL) approach that dynamically adjusts sampling\nstrategies and loss weights, thereby improving the model's ability of\ngeneralization. Our ACL is composed of two levels of curriculum schedulers: (1)\nsampling scheduler that transforms the data distribution from imbalanced to\nbalanced, as well as from easier (daytime) to harder (nighttime) samples; (2)\nloss scheduler that dynamically assigns weights based on the size of the\ntraining set and IoU of individual instances. Exhaustive experiments on\nmultiple nighttime UAV tracking benchmarks demonstrate that the proposed\nMambaNUT achieves state-of-the-art performance while requiring lower\ncomputational costs. The code will be available at\nhttps://github.com/wuyou3474/MambaNUT.", "AI": {"tldr": "MambaNUT is a novel pure Mamba-based tracking framework for nighttime UAV tracking, using linear-complexity state space models and adaptive curriculum learning to improve generalization and reduce computational costs.", "motivation": "Over-reliance on image enhancement, limited nighttime data, and lack of integration between daytime and nighttime trackers hinder end-to-end trainable frameworks. Current ViT-based trackers are computationally heavy.", "method": "Proposes MambaNUT with a Vision Mamba backbone, single-stream architecture, and adaptive curriculum learning (ACL) for dynamic sampling and loss weighting.", "result": "Achieves state-of-the-art performance on nighttime UAV tracking benchmarks with lower computational costs.", "conclusion": "MambaNUT offers an efficient, high-performance solution for nighttime UAV tracking, addressing key limitations of existing methods."}}
{"id": "2408.00540", "pdf": "https://arxiv.org/pdf/2408.00540", "abs": "https://arxiv.org/abs/2408.00540", "authors": ["Shih-Kai Chou", "Jernej Hribar", "Vid Han\u017eel", "Mihael Mohor\u010di\u010d", "Carolina Fortuna"], "title": "The Energy Cost of Artificial Intelligence Lifecycle in Communication Networks", "categories": ["cs.ET", "cs.AI", "cs.LG"], "comment": "13 pages, 9 figures", "summary": "Artificial Intelligence (AI) is being incorporated in several optimization,\nscheduling, orchestration as well as in native communication network functions.\nWhile this paradigm shift results in increased energy consumption, quantifying\nthe end-toend energy consumption of adding intelligence to such systems is\nparticularly challenging. Conventional metrics focus on either communication,\ncomputation infrastructure, or model development. To address this, we propose a\nnew metric, the Energy Cost of AI Lifecycle (eCAL) of one AI model in a system.\neCAL captures the energy consumption throughout the development and deployment\nof an AI-model providing intelligence in a wireless communication network by\nanalyzing the complexity of data collection and manipulation in individual\ncomponents and deriving overall and per-bit energy consumption. We show that\nthe better a model is and the more it is used, the more energy efficient an\ninference is. For a simple case study, eCAL for making 100 inferences is 2.73\ntimes higher than for 1000 inferences. Additionally, we have developed a\nmodular and extendable opensource simulation tool to enable researchers,\npractitioners, and engineers to calculate the end-to-end energy cost with\nvarious configurations and across various systems, ensuring adaptability to\ndiverse use cases.", "AI": {"tldr": "The paper introduces eCAL, a metric to quantify the end-to-end energy consumption of AI in wireless networks, showing improved efficiency with model usage and providing a simulation tool for analysis.", "motivation": "AI integration in networks increases energy consumption, but existing metrics fail to capture the full lifecycle energy cost.", "method": "Proposes eCAL, a metric analyzing data collection and manipulation complexity to derive energy consumption, supported by a simulation tool.", "result": "Demonstrates that more usage improves energy efficiency (e.g., 100 inferences consume 2.73x more energy than 1000).", "conclusion": "eCAL and the simulation tool offer a comprehensive way to measure and optimize AI energy costs in networks."}}
{"id": "2505.07068", "pdf": "https://arxiv.org/pdf/2505.07068", "abs": "https://arxiv.org/abs/2505.07068", "authors": ["Jinchao Feng", "Sui Tang"], "title": "A Sparse Bayesian Learning Algorithm for Estimation of Interaction Kernels in Motsch-Tadmor Model", "categories": ["stat.ML", "cs.LG", "math.DS"], "comment": "18 pages", "summary": "In this paper, we investigate the data-driven identification of asymmetric\ninteraction kernels in the Motsch-Tadmor model based on observed trajectory\ndata. The model under consideration is governed by a class of semilinear\nevolution equations, where the interaction kernel defines a normalized,\nstate-dependent Laplacian operator that governs collective dynamics. To address\nthe resulting nonlinear inverse problem, we propose a variational framework\nthat reformulates kernel identification using the implicit form of the\ngoverning equations, reducing it to a subspace identification problem. We\nestablish an identifiability result that characterizes conditions under which\nthe interaction kernel can be uniquely recovered up to scale. To solve the\ninverse problem robustly, we develop a sparse Bayesian learning algorithm that\nincorporates informative priors for regularization, quantifies uncertainty, and\nenables principled model selection. Extensive numerical experiments on\nrepresentative interacting particle systems demonstrate the accuracy,\nrobustness, and interpretability of the proposed framework across a range of\nnoise levels and data regimes.", "AI": {"tldr": "The paper proposes a variational framework and sparse Bayesian learning algorithm to identify asymmetric interaction kernels in the Motsch-Tadmor model from trajectory data, demonstrating robustness and accuracy in numerical experiments.", "motivation": "To address the challenge of identifying interaction kernels in collective dynamics governed by semilinear evolution equations, particularly in noisy or limited data scenarios.", "method": "A variational framework reformulates kernel identification as a subspace problem, paired with a sparse Bayesian learning algorithm for robust, uncertainty-aware solutions.", "result": "The method accurately recovers interaction kernels up to scale, performs well under varying noise levels, and supports interpretable model selection.", "conclusion": "The proposed framework is effective for kernel identification in collective dynamics, offering robustness, interpretability, and scalability."}}
{"id": "2412.01485", "pdf": "https://arxiv.org/pdf/2412.01485", "abs": "https://arxiv.org/abs/2412.01485", "authors": ["Cong Xie", "Han Zou", "Ruiqi Yu", "Yan Zhang", "Zhenpeng Zhan"], "title": "SerialGen: Personalized Image Generation by First Standardization Then Personalization", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we are interested in achieving both high text controllability\nand whole-body appearance consistency in the generation of personalized human\ncharacters. We propose a novel framework, named SerialGen, which is a serial\ngeneration method consisting of two stages: first, a standardization stage that\nstandardizes reference images, and then a personalized generation stage based\non the standardized reference. Furthermore, we introduce two modules aimed at\nenhancing the standardization process. Our experimental results validate the\nproposed framework's ability to produce personalized images that faithfully\nrecover the reference image's whole-body appearance while accurately responding\nto a wide range of text prompts. Through thorough analysis, we highlight the\ncritical contribution of the proposed serial generation method and\nstandardization model, evidencing enhancements in appearance consistency\nbetween reference and output images and across serial outputs generated from\ndiverse text prompts. The term \"Serial\" in this work carries a double meaning:\nit refers to the two-stage method and also underlines our ability to generate\nserial images with consistent appearance throughout.", "AI": {"tldr": "SerialGen is a two-stage framework for generating personalized human characters with high text controllability and appearance consistency.", "motivation": "To achieve both high text controllability and whole-body appearance consistency in personalized human character generation.", "method": "A serial generation method with two stages: standardization of reference images and personalized generation based on standardized references, enhanced by two modules.", "result": "Validated ability to produce personalized images with faithful appearance recovery and accurate text response.", "conclusion": "The serial generation method and standardization model significantly improve appearance consistency and text controllability."}}
{"id": "2408.14806", "pdf": "https://arxiv.org/pdf/2408.14806", "abs": "https://arxiv.org/abs/2408.14806", "authors": ["Maria Despoina Siampou", "Jialiang Li", "John Krumm", "Cyrus Shahabi", "Hua Lu"], "title": "Poly2Vec: Polymorphic Fourier-Based Encoding of Geospatial Objects for GeoAI Applications", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Encoding geospatial objects is fundamental for geospatial artificial\nintelligence (GeoAI) applications, which leverage machine learning (ML) models\nto analyze spatial information. Common approaches transform each object into\nknown formats, like image and text, for compatibility with ML models. However,\nthis process often discards crucial spatial information, such as the object's\nposition relative to the entire space, reducing downstream task effectiveness.\nAlternative encoding methods that preserve some spatial properties are often\ndevised for specific data objects (e.g., point encoders), making them\nunsuitable for tasks that involve different data types (i.e., points,\npolylines, and polygons). To this end, we propose Poly2Vec, a polymorphic\nFourier-based encoding approach that unifies the representation of geospatial\nobjects, while preserving the essential spatial properties. Poly2Vec\nincorporates a learned fusion module that adaptively integrates the magnitude\nand phase of the Fourier transform for different tasks and geometries. We\nevaluate Poly2Vec on five diverse tasks, organized into two categories. The\nfirst empirically demonstrates that Poly2Vec consistently outperforms\nobject-specific baselines in preserving three key spatial relationships:\ntopology, direction, and distance. The second shows that integrating Poly2Vec\ninto a state-of-the-art GeoAI workflow improves the performance in two popular\ntasks: population prediction and land use inference.", "AI": {"tldr": "Poly2Vec is a polymorphic Fourier-based encoding method for geospatial objects, preserving spatial properties and outperforming object-specific baselines in key tasks.", "motivation": "Existing encoding methods for geospatial objects often discard spatial information or are limited to specific data types, reducing effectiveness in GeoAI applications.", "method": "Poly2Vec uses a polymorphic Fourier-based approach with a learned fusion module to adaptively integrate magnitude and phase for different tasks and geometries.", "result": "Poly2Vec outperforms baselines in preserving spatial relationships (topology, direction, distance) and enhances performance in population prediction and land use inference.", "conclusion": "Poly2Vec provides a unified and effective encoding solution for diverse geospatial objects, improving GeoAI task performance."}}
{"id": "2505.07101", "pdf": "https://arxiv.org/pdf/2505.07101", "abs": "https://arxiv.org/abs/2505.07101", "authors": ["Haichen Hu", "David Simchi-Levi", "Navid Azizan"], "title": "Constrained Online Decision-Making with Density Estimation Oracles", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Contextual online decision-making problems with constraints appear in a wide\nrange of real-world applications, such as personalized recommendation with\nresource limits, adaptive experimental design, and decision-making under safety\nor fairness requirements. In this paper, we investigate a general formulation\nof sequential decision-making with stage-wise feasibility constraints, where at\neach round, the learner must select an action based on observed context while\nensuring that a problem-specific feasibility criterion is satisfied. We propose\na unified algorithmic framework that captures many existing constrained\nlearning problems, including constrained bandits, active learning with label\nbudgets, online hypothesis testing with Type I error control, and model\ncalibration. Central to our approach is the concept of upper counterfactual\nconfidence bounds, which enables the design of practically efficient online\nalgorithms with strong theoretical guarantee using any offline conditional\ndensity estimation oracle. Technically, to handle feasibility constraints in\ncomplex environments, we introduce a generalized notion of the eluder dimension\n- extending it from the classical setting based on square loss to a broader\nclass of metric-like probability divergences. This allows us to capture the\ncomplexity of various density function classes and characterize the utility\nregret incurred due to feasibility constraint uncertainty. Our result offers a\nprincipled foundation for constrained sequential decision-making in both theory\nand practice.", "AI": {"tldr": "A unified framework for constrained sequential decision-making with strong theoretical guarantees, applicable to various real-world problems.", "motivation": "Addressing the need for efficient and principled solutions to constrained online decision-making problems in diverse applications like recommendation systems and adaptive experiments.", "method": "Proposes a framework using upper counterfactual confidence bounds and extends the eluder dimension to handle feasibility constraints with theoretical rigor.", "result": "Provides efficient algorithms with strong guarantees, leveraging offline conditional density estimation oracles.", "conclusion": "Offers a foundational approach for constrained sequential decision-making, bridging theory and practice."}}
{"id": "2412.01818", "pdf": "https://arxiv.org/pdf/2412.01818", "abs": "https://arxiv.org/abs/2412.01818", "authors": ["Qizhe Zhang", "Aosong Cheng", "Ming Lu", "Renrui Zhang", "Zhiyong Zhuo", "Jiajun Cao", "Shaobo Guo", "Qi She", "Shanghang Zhang"], "title": "Beyond Text-Visual Attention: Exploiting Visual Cues for Effective Token Pruning in VLMs", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 9 figures, code: https://github.com/Theia-4869/VisPruner,\n  project page: https://theia-4869.github.io/VisPruner", "summary": "Large vision-language models (LVLMs) generally contain significantly more\nvisual tokens than their textual counterparts, resulting in a considerable\ncomputational burden. Recent efforts have been made to tackle this issue by\npruning visual tokens early within the language model. Most existing works use\nattention scores between text and visual tokens to assess the importance of\nvisual tokens. However, in this study, we first analyze the text-visual\nattention in the language model and find that this score is not an ideal\nindicator for token pruning. Based on the analysis, We propose VisPruner, a\nplug-and-play method that utilizes visual cues for more effective token pruning\nin LVLMs. Specifically, we first use visual attention to select a limited\nnumber of significant tokens. Then, we remove duplicate tokens from the\nremaining ones based on their similarity. By retaining diverse tokens alongside\nthe initially selected important tokens, we maximally preserve the visual\ninformation of the input image. Experimental results demonstrate that our\nVisPruner sustains strong performance across various VLM architectures and\nreduction ratios, significantly outperforming existing methods based on\ntext-visual attention. Notably, without any training, VisPruner can reduce the\nFLOPs of LLaVA-1.5-7B by 91% and inference latency by 75%, while maintaining\ncomparable performance. Our code is available at\nhttps://github.com/Theia-4869/VisPruner.", "AI": {"tldr": "VisPruner is a plug-and-play method for pruning visual tokens in LVLMs using visual cues, outperforming text-visual attention methods and reducing computational costs significantly.", "motivation": "Existing methods use text-visual attention scores for pruning, but these scores are not ideal indicators, prompting the need for a better approach.", "method": "VisPruner selects significant tokens using visual attention and removes duplicates based on similarity, retaining diverse tokens to preserve visual information.", "result": "VisPruner reduces FLOPs by 91% and latency by 75% for LLaVA-1.5-7B while maintaining performance, outperforming existing methods.", "conclusion": "VisPruner is an effective, training-free solution for efficient token pruning in LVLMs, validated across architectures and reduction ratios."}}
{"id": "2409.05808", "pdf": "https://arxiv.org/pdf/2409.05808", "abs": "https://arxiv.org/abs/2409.05808", "authors": ["Mohammad Baqar", "Rajat Khanda"], "title": "The Future of Software Testing: AI-Powered Test Case Generation and Validation", "categories": ["cs.SE", "cs.AI"], "comment": "Version 2, 19 Pages", "summary": "Software testing is a crucial phase in the software development lifecycle\n(SDLC), ensuring that products meet necessary functional, performance, and\nquality benchmarks before release. Despite advancements in automation,\ntraditional methods of generating and validating test cases still face\nsignificant challenges, including prolonged timelines, human error, incomplete\ntest coverage, and high costs of manual intervention. These limitations often\nlead to delayed product launches and undetected defects that compromise\nsoftware quality and user satisfaction. The integration of artificial\nintelligence (AI) into software testing presents a promising solution to these\npersistent challenges. AI-driven testing methods automate the creation of\ncomprehensive test cases, dynamically adapt to changes, and leverage machine\nlearning to identify high-risk areas in the codebase. This approach enhances\nregression testing efficiency while expanding overall test coverage.\nFurthermore, AI-powered tools enable continuous testing and self-healing test\ncases, significantly reducing manual oversight and accelerating feedback loops,\nultimately leading to faster and more reliable software releases. This paper\nexplores the transformative potential of AI in improving test case generation\nand validation, focusing on its ability to enhance efficiency, accuracy, and\nscalability in testing processes. It also addresses key challenges associated\nwith adapting AI for testing, including the need for high quality training\ndata, ensuring model transparency, and maintaining a balance between automation\nand human oversight. Through case studies and examples of real-world\napplications, this paper illustrates how AI can significantly enhance testing\nefficiency across both legacy and modern software systems.", "AI": {"tldr": "AI-driven testing improves efficiency, accuracy, and scalability in software testing, addressing challenges like incomplete coverage and high costs.", "motivation": "Traditional testing methods face issues like delays, human error, and high costs, prompting the need for AI-driven solutions.", "method": "AI automates test case generation, adapts dynamically, and uses machine learning to identify high-risk areas.", "result": "AI enhances regression testing, expands coverage, and enables continuous testing with self-healing cases.", "conclusion": "AI transforms testing by improving efficiency and reliability, though challenges like data quality and model transparency remain."}}
{"id": "2505.07105", "pdf": "https://arxiv.org/pdf/2505.07105", "abs": "https://arxiv.org/abs/2505.07105", "authors": ["Hongwei Shang", "Nguyen Vo", "Nitin Yadav", "Tian Zhang", "Ajit Puthenputhussery", "Xunfan Cai", "Shuyi Chen", "Prijith Chandran", "Changsung Kang"], "title": "Knowledge Distillation for Enhancing Walmart E-commerce Search Relevance Using Large Language Models", "categories": ["cs.IR", "cs.LG"], "comment": "9 pages, published at WWWW'25", "summary": "Ensuring the products displayed in e-commerce search results are relevant to\nusers queries is crucial for improving the user experience. With their advanced\nsemantic understanding, deep learning models have been widely used for\nrelevance matching in search tasks. While large language models (LLMs) offer\nsuperior ranking capabilities, it is challenging to deploy LLMs in real-time\nsystems due to the high-latency requirements. To leverage the ranking power of\nLLMs while meeting the low-latency demands of production systems, we propose a\nnovel framework that distills a high performing LLM into a more efficient,\nlow-latency student model. To help the student model learn more effectively\nfrom the teacher model, we first train the teacher LLM as a classification\nmodel with soft targets. Then, we train the student model to capture the\nrelevance margin between pairs of products for a given query using mean squared\nerror loss. Instead of using the same training data as the teacher model, we\nsignificantly expand the student model dataset by generating unlabeled data and\nlabeling it with the teacher model predictions. Experimental results show that\nthe student model performance continues to improve as the size of the augmented\ntraining data increases. In fact, with enough augmented data, the student model\ncan outperform the teacher model. The student model has been successfully\ndeployed in production at Walmart.com with significantly positive metrics.", "AI": {"tldr": "A framework distills a high-performing LLM into a low-latency student model for e-commerce search relevance, using expanded training data and outperforming the teacher model.", "motivation": "To leverage LLMs' ranking power while meeting low-latency demands in production systems.", "method": "Train a teacher LLM with soft targets, then distill it into a student model using expanded unlabeled data labeled by the teacher.", "result": "Student model improves with more data, even outperforming the teacher, and is successfully deployed at Walmart.com.", "conclusion": "The framework effectively balances performance and latency, enhancing e-commerce search relevance."}}
{"id": "2412.09521", "pdf": "https://arxiv.org/pdf/2412.09521", "abs": "https://arxiv.org/abs/2412.09521", "authors": ["Shengxuming Zhang", "Weihan Li", "Tianhong Gao", "Jiacong Hu", "Haoming Luo", "Xiuming Zhang", "Jing Zhang", "Mingli Song", "Zunlei Feng"], "title": "Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pathological diagnosis is vital for determining disease characteristics,\nguiding treatment, and assessing prognosis, relying heavily on detailed,\nmulti-scale analysis of high-resolution whole slide images (WSI). However,\ntraditional pure vision models face challenges of redundant feature extraction,\nwhereas existing large vision-language models (LVLMs) are limited by input\nresolution constraints, hindering their efficiency and accuracy. To overcome\nthese issues, we propose two innovative strategies: the mixed task-guided\nfeature enhancement, which directs feature extraction toward lesion-related\ndetails across scales, and the prompt-guided detail feature completion, which\nintegrates coarse- and fine-grained features from WSI based on specific prompts\nwithout compromising inference speed. Leveraging a comprehensive dataset of\n490,000 samples from diverse pathology tasks-including cancer detection,\ngrading, vascular and neural invasion identification, and so on-we trained the\npathology-specialized LVLM, OmniPath. Extensive experiments demonstrate that\nthis model significantly outperforms existing methods in diagnostic accuracy\nand efficiency, offering an interactive, clinically aligned approach for\nauxiliary diagnosis in a wide range of pathology applications.", "AI": {"tldr": "OmniPath, a pathology-specialized LVLM, improves diagnostic accuracy and efficiency by addressing feature redundancy and resolution constraints with mixed task-guided feature enhancement and prompt-guided detail feature completion.", "motivation": "Traditional vision models and LVLMs struggle with redundant features and resolution limits, hindering pathology diagnosis.", "method": "Proposes mixed task-guided feature enhancement and prompt-guided detail feature completion, leveraging 490,000 pathology samples.", "result": "OmniPath outperforms existing methods in accuracy and efficiency across diverse pathology tasks.", "conclusion": "OmniPath offers a clinically aligned, interactive solution for auxiliary pathology diagnosis."}}
{"id": "2409.06953", "pdf": "https://arxiv.org/pdf/2409.06953", "abs": "https://arxiv.org/abs/2409.06953", "authors": ["Zeno Kujawa", "John Poole", "Dobrik Georgiev", "Danilo Numeroso", "Henry Fleischmann", "Pietro Li\u00f2"], "title": "Neural Algorithmic Reasoning with Multiple Correct Solutions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neural Algorithmic Reasoning (NAR) extends classical algorithms to higher\ndimensional data. However, canonical implementations of NAR train neural\nnetworks to return only a single solution, even when there are multiple correct\nsolutions to a problem, such as single-source shortest paths. For some\napplications, it is desirable to recover more than one correct solution. To\nthat end, we give the first method for NAR with multiple solutions. We\ndemonstrate our method on two classical algorithms: Bellman-Ford (BF) and\nDepth-First Search (DFS), favouring deeper insight into two algorithms over a\nbroader survey of algorithms. This method involves generating appropriate\ntraining data as well as sampling and validating solutions from model output.\nEach step of our method, which can serve as a framework for neural algorithmic\nreasoning beyond the tasks presented in this paper, might be of independent\ninterest to the field and our results represent the first attempt at this task\nin the NAR literature.", "AI": {"tldr": "The paper introduces a method for Neural Algorithmic Reasoning (NAR) to handle multiple correct solutions, demonstrated on Bellman-Ford and Depth-First Search algorithms.", "motivation": "Classical NAR implementations return only one solution, but some problems have multiple correct solutions, necessitating a method to recover more.", "method": "The method involves generating training data, sampling solutions from model output, and validating them, serving as a framework for broader NAR tasks.", "result": "Demonstrated successfully on Bellman-Ford and Depth-First Search algorithms, providing deeper insights into these specific cases.", "conclusion": "This work is the first in NAR literature to address multiple solutions, offering a reusable framework for future research."}}
{"id": "2505.07163", "pdf": "https://arxiv.org/pdf/2505.07163", "abs": "https://arxiv.org/abs/2505.07163", "authors": ["Natalia G. Berloff"], "title": "Exact Spin Elimination in Ising Hamiltonians and Energy-Based Machine Learning", "categories": ["quant-ph", "cs.DM", "cs.DS", "cs.ET", "cs.LG"], "comment": "28 pages, 6 figures", "summary": "We present an exact spin-elimination technique that reduces the\ndimensionality of both quadratic and k-local Ising Hamiltonians while\npreserving their original ground-state configurations. By systematically\nreplacing each removed spin with an effective interaction among its neighbors,\nour method lowers the total spin count without invoking approximations or\niterative recalculations. This capability is especially beneficial for\nhardware-constrained platforms, classical or quantum, that can directly\nimplement multi-body interactions but have limited qubit or spin resources. We\ndemonstrate three key advances enabled by this technique. First, we handle\nlarger instances of benchmark problems such as Max-Cut on cubic graphs without\nexceeding a 2-local interaction limit. Second, we reduce qubit requirements in\nQAOA-based integer factorization on near-term quantum devices, thus extending\nthe feasible range of integers to be factorized. Third, we improve memory\ncapacity in Hopfield associative memories and enhance memory retrieval by\nsuppressing spurious attractors, enhancing retrieval performance. Our\nspin-elimination procedure trades local spin complexity for higher-order\ncouplings or higher node degrees in a single pass, opening new avenues for\nscaling up combinatorial optimization and energy-based machine learning on\nnear-term hardware. Finally, these results underscore that the next-generation\nphysical spin machines will likely capitalize on k-local spin Hamiltonians to\noffer an alternative to classical computations.", "AI": {"tldr": "An exact spin-elimination technique reduces dimensionality of Ising Hamiltonians while preserving ground-state configurations, enabling advances in optimization and quantum computing.", "motivation": "To address hardware constraints in classical and quantum platforms by reducing spin counts without approximations.", "method": "Systematically replaces removed spins with effective interactions among neighbors, lowering spin count in a single pass.", "result": "Enables larger Max-Cut instances, reduces qubit needs for QAOA factorization, and improves Hopfield memory performance.", "conclusion": "Spin-elimination opens new scaling avenues for optimization and machine learning, highlighting the potential of k-local Hamiltonians in next-gen spin machines."}}
{"id": "2412.14489", "pdf": "https://arxiv.org/pdf/2412.14489", "abs": "https://arxiv.org/abs/2412.14489", "authors": ["Shu Shen", "C. L. Philip Chen", "Tong Zhang"], "title": "Multi-QuAD: Multi-Level Quality-Adaptive Dynamic Network for Reliable Multimodal Classification", "categories": ["cs.CV"], "comment": "12 pages, 11 figures", "summary": "Multimodal machine learning has achieved remarkable progress in many\nscenarios, but its reliability is undermined by varying sample quality. This\npaper finds that existing reliable multimodal classification methods not only\nfail to provide robust estimation of data quality, but also lack dynamic\nnetworks for sample-specific depth and parameters to achieve reliable\ninference. To this end, a novel framework for multimodal reliable\nclassification termed \\textit{Multi-level Quality-Adaptive Dynamic multimodal\nnetwork} (Multi-QuAD) is proposed. Multi-QuAD first adopts a novel approach\nbased on noise-free prototypes and a classifier-free design to reliably\nestimate the quality of each sample at both modality and feature levels. It\nthen achieves sample-specific network depth via the \\textbf{\\textit{Global\nConfidence Normalized Depth (GCND)}} mechanism. By normalizing depth across\nmodalities and samples, \\textit{\\textbf{GCND}} effectively mitigates the impact\nof challenging modality inputs on dynamic depth reliability. Furthermore,\nMulti-QuAD provides sample-adaptive network parameters via the\n\\textbf{\\textit{Layer-wise Greedy Parameter (LGP)}} mechanism driven by\nfeature-level quality. The cross-modality layer-wise greedy strategy in\n\\textbf{\\textit{LGP}} designs a reliable parameter prediction paradigm for\nmultimodal networks with variable architecture for the first time. Experiments\nconducted on four datasets demonstrate that Multi-QuAD significantly\noutperforms state-of-the-art methods in classification performance and\nreliability, exhibiting strong adaptability to data with diverse quality.", "AI": {"tldr": "Multi-QuAD improves multimodal classification by dynamically adapting network depth and parameters based on sample quality, outperforming existing methods.", "motivation": "Existing multimodal classification methods lack robust data quality estimation and dynamic adaptation, undermining reliability.", "method": "Multi-QuAD uses noise-free prototypes and classifier-free design for quality estimation, GCND for dynamic depth, and LGP for adaptive parameters.", "result": "Outperforms state-of-the-art methods on four datasets in classification and reliability.", "conclusion": "Multi-QuAD enhances reliability and adaptability in multimodal classification, addressing quality and dynamic network challenges."}}
{"id": "2409.09787", "pdf": "https://arxiv.org/pdf/2409.09787", "abs": "https://arxiv.org/abs/2409.09787", "authors": ["RuiKang OuYang", "Bo Qiang", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"], "title": "BNEM: A Boltzmann Sampler Based on Bootstrapped Noised Energy Matching", "categories": ["cs.LG", "cs.AI", "stat.CO", "stat.ML"], "comment": "38 pages, 10 figures, 10 tables", "summary": "Developing an efficient sampler capable of generating independent and\nidentically distributed (IID) samples from a Boltzmann distribution is a\ncrucial challenge in scientific research, e.g. molecular dynamics. In this\nwork, we intend to learn neural samplers given energy functions instead of data\nsampled from the Boltzmann distribution. By learning the energies of the noised\ndata, we propose a diffusion-based sampler, Noised Energy Matching, which\ntheoretically has lower variance and more complexity compared to related works.\nFurthermore, a novel bootstrapping technique is applied to NEM to balance\nbetween bias and variance. We evaluate NEM and BNEM on a 2-dimensional 40\nGaussian Mixture Model (GMM) and a 4-particle double-well potential (DW-4). The\nexperimental results demonstrate that BNEM can achieve state-of-the-art\nperformance while being more robust.", "AI": {"tldr": "The paper introduces Noised Energy Matching (NEM) and its bootstrapped variant (BNEM) for efficient Boltzmann distribution sampling, showing improved performance and robustness.", "motivation": "Efficiently sampling from Boltzmann distributions is critical in fields like molecular dynamics, but existing methods face challenges. This work aims to learn neural samplers directly from energy functions rather than pre-sampled data.", "method": "Proposes NEM, a diffusion-based sampler, and BNEM, which uses bootstrapping to balance bias and variance. Both are evaluated on a 2D 40-GMM and a 4-particle double-well potential.", "result": "BNEM achieves state-of-the-art performance with lower variance and higher robustness compared to related works.", "conclusion": "BNEM offers a promising solution for efficient Boltzmann sampling, combining theoretical advantages with practical robustness."}}
{"id": "2505.07244", "pdf": "https://arxiv.org/pdf/2505.07244", "abs": "https://arxiv.org/abs/2505.07244", "authors": ["Christian Kuehn", "Sara-Viola Kuntz"], "title": "The Influence of the Memory Capacity of Neural DDEs on the Universal Approximation Property", "categories": ["math.DS", "cs.LG", "cs.NE"], "comment": null, "summary": "Neural Ordinary Differential Equations (Neural ODEs), which are the\ncontinuous-time analog of Residual Neural Networks (ResNets), have gained\nsignificant attention in recent years. Similarly, Neural Delay Differential\nEquations (Neural DDEs) can be interpreted as an infinite depth limit of\nDensely Connected Residual Neural Networks (DenseResNets). In contrast to\ntraditional ResNet architectures, DenseResNets are feed-forward networks that\nallow for shortcut connections across all layers. These additional connections\nintroduce memory in the network architecture, as typical in many modern\narchitectures. In this work, we explore how the memory capacity in neural DDEs\ninfluences the universal approximation property. The key parameter for studying\nthe memory capacity is the product $K \\tau$ of the Lipschitz constant and the\ndelay of the DDE. In the case of non-augmented architectures, where the network\nwidth is not larger than the input and output dimensions, neural ODEs and\nclassical feed-forward neural networks cannot have the universal approximation\nproperty. We show that if the memory capacity $K\\tau$ is sufficiently small,\nthe dynamics of the neural DDE can be approximated by a neural ODE.\nConsequently, non-augmented neural DDEs with a small memory capacity also lack\nthe universal approximation property. In contrast, if the memory capacity\n$K\\tau$ is sufficiently large, we can establish the universal approximation\nproperty of neural DDEs for continuous functions. If the neural DDE\narchitecture is augmented, we can expand the parameter regions in which\nuniversal approximation is possible. Overall, our results show that by\nincreasing the memory capacity $K\\tau$, the infinite-dimensional phase space of\nDDEs with positive delay $\\tau>0$ is not sufficient to guarantee a direct jump\ntransition to universal approximation, but only after a certain memory\nthreshold, universal approximation holds.", "AI": {"tldr": "Neural DDEs' memory capacity (K\u03c4) determines their universal approximation property. Small K\u03c4 approximates Neural ODEs, lacking universal approximation, while large K\u03c4 enables it, especially in augmented architectures.", "motivation": "To understand how memory capacity in Neural DDEs affects their universal approximation property compared to Neural ODEs and traditional networks.", "method": "Analyzing the influence of the product K\u03c4 (Lipschitz constant and delay) on Neural DDEs' dynamics and approximation capabilities, comparing non-augmented and augmented architectures.", "result": "Small K\u03c4 makes Neural DDEs behave like Neural ODEs, lacking universal approximation. Large K\u03c4 enables universal approximation, with augmented architectures expanding the parameter range.", "conclusion": "Memory capacity K\u03c4 is critical for Neural DDEs' universal approximation, requiring a threshold for effectiveness, especially in augmented designs."}}
{"id": "2501.00843", "pdf": "https://arxiv.org/pdf/2501.00843", "abs": "https://arxiv.org/abs/2501.00843", "authors": ["Nathanael L. Baisa"], "title": "FusionSORT: Fusion Methods for Online Multi-object Visual Tracking", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we investigate four different fusion methods for associating\ndetections to tracklets in multi-object visual tracking. In addition to\nconsidering strong cues such as motion and appearance information, we also\nconsider weak cues such as height intersection-over-union (height-IoU) and\ntracklet confidence information in the data association using different fusion\nmethods. These fusion methods include minimum, weighted sum based on IoU,\nKalman filter (KF) gating, and hadamard product of costs due to the different\ncues. We conduct extensive evaluations on validation sets of MOT17, MOT20 and\nDanceTrack datasets, and find out that the choice of a fusion method is key for\ndata association in multi-object visual tracking. We hope that this\ninvestigative work helps the computer vision research community to use the\nright fusion method for data association in multi-object visual tracking.", "AI": {"tldr": "The paper investigates four fusion methods for associating detections to tracklets in multi-object visual tracking, emphasizing the importance of choosing the right method.", "motivation": "To improve data association in multi-object visual tracking by exploring and evaluating different fusion methods for combining strong and weak cues.", "method": "Four fusion methods (minimum, weighted sum based on IoU, Kalman filter gating, and Hadamard product of costs) are tested on MOT17, MOT20, and DanceTrack datasets.", "result": "The choice of fusion method significantly impacts data association performance in multi-object visual tracking.", "conclusion": "The study highlights the critical role of selecting the appropriate fusion method for effective data association, aiding the computer vision community in making informed choices."}}
{"id": "2410.01265", "pdf": "https://arxiv.org/pdf/2410.01265", "abs": "https://arxiv.org/abs/2410.01265", "authors": ["Haodong Liang", "Krishnakumar Balasubramanian", "Lifeng Lai"], "title": "Transformers Handle Endogeneity in In-Context Linear Regression", "categories": ["stat.ML", "cs.AI", "cs.LG", "econ.EM", "math.ST", "stat.TH"], "comment": "37 pages, 8 figures", "summary": "We explore the capability of transformers to address endogeneity in\nin-context linear regression. Our main finding is that transformers inherently\npossess a mechanism to handle endogeneity effectively using instrumental\nvariables (IV). First, we demonstrate that the transformer architecture can\nemulate a gradient-based bi-level optimization procedure that converges to the\nwidely used two-stage least squares $(\\textsf{2SLS})$ solution at an\nexponential rate. Next, we propose an in-context pretraining scheme and provide\ntheoretical guarantees showing that the global minimizer of the pre-training\nloss achieves a small excess loss. Our extensive experiments validate these\ntheoretical findings, showing that the trained transformer provides more robust\nand reliable in-context predictions and coefficient estimates than the\n$\\textsf{2SLS}$ method, in the presence of endogeneity.", "AI": {"tldr": "Transformers can handle endogeneity in linear regression using instrumental variables, outperforming traditional 2SLS methods.", "motivation": "To leverage transformers' capabilities for addressing endogeneity in in-context linear regression, improving robustness and reliability.", "method": "Transformers emulate gradient-based bi-level optimization, converging to 2SLS solutions. In-context pretraining with theoretical guarantees is proposed.", "result": "Trained transformers outperform 2SLS in robustness and reliability for predictions and coefficient estimates under endogeneity.", "conclusion": "Transformers offer an effective alternative to 2SLS for handling endogeneity in linear regression, with theoretical and empirical support."}}
{"id": "2505.07267", "pdf": "https://arxiv.org/pdf/2505.07267", "abs": "https://arxiv.org/abs/2505.07267", "authors": ["Gerardo Duran-Martin"], "title": "Adaptive, Robust and Scalable Bayesian Filtering for Online Learning", "categories": ["stat.ML", "cs.LG"], "comment": "PhD thesis", "summary": "In this thesis, we introduce Bayesian filtering as a principled framework for\ntackling diverse sequential machine learning problems, including online\n(continual) learning, prequential (one-step-ahead) forecasting, and contextual\nbandits. To this end, this thesis addresses key challenges in applying Bayesian\nfiltering to these problems: adaptivity to non-stationary environments,\nrobustness to model misspecification and outliers, and scalability to the\nhigh-dimensional parameter space of deep neural networks. We develop novel\ntools within the Bayesian filtering framework to address each of these\nchallenges, including: (i) a modular framework that enables the development\nadaptive approaches for online learning; (ii) a novel, provably robust filter\nwith similar computational cost to standard filters, that employs Generalised\nBayes; and (iii) a set of tools for sequentially updating model parameters\nusing approximate second-order optimisation methods that exploit the\noverparametrisation of high-dimensional parametric models such as neural\nnetworks. Theoretical analysis and empirical results demonstrate the improved\nperformance of our methods in dynamic, high-dimensional, and misspecified\nmodels.", "AI": {"tldr": "Bayesian filtering is adapted for sequential ML tasks, addressing non-stationarity, robustness, and scalability with novel tools.", "motivation": "To tackle challenges in applying Bayesian filtering to sequential ML problems like online learning and contextual bandits.", "method": "Develops modular frameworks, robust filters, and tools for updating high-dimensional models.", "result": "Improved performance in dynamic, high-dimensional, and misspecified models.", "conclusion": "The proposed Bayesian filtering tools effectively address key challenges in sequential ML."}}
{"id": "2501.16003", "pdf": "https://arxiv.org/pdf/2501.16003", "abs": "https://arxiv.org/abs/2501.16003", "authors": ["Zhibo Ren", "Pritthijit Nath", "Pancham Shukla"], "title": "Improving Tropical Cyclone Forecasting With Video Diffusion Models", "categories": ["cs.CV", "physics.ao-ph"], "comment": "Recommended for spotlight presentation at the ICLR 2025 workshop on\n  Tackling Climate Change with Machine Learning. 7 pages, 7 figures", "summary": "Tropical cyclone (TC) forecasting is crucial for disaster preparedness and\nmitigation. While recent deep learning approaches have shown promise, existing\nmethods often treat TC evolution as a series of independent frame-to-frame\npredictions, limiting their ability to capture long-term dynamics. We present a\nnovel application of video diffusion models for TC forecasting that explicitly\nmodels temporal dependencies through additional temporal layers. Our approach\nenables the model to generate multiple frames simultaneously, better capturing\ncyclone evolution patterns. We introduce a two-stage training strategy that\nsignificantly improves individual-frame quality and performance in low-data\nregimes. Experimental results show our method outperforms the previous approach\nof Nath et al. by 19.3% in MAE, 16.2% in PSNR, and 36.1% in SSIM. Most notably,\nwe extend the reliable forecasting horizon from 36 to 50 hours. Through\ncomprehensive evaluation using both traditional metrics and Fr\\'echet Video\nDistance (FVD), we demonstrate that our approach produces more temporally\ncoherent forecasts while maintaining competitive single-frame quality. Code\naccessible at https://github.com/Ren-creater/forecast-video-diffmodels.", "AI": {"tldr": "A novel video diffusion model for tropical cyclone forecasting improves long-term dynamics and extends the reliable forecasting horizon from 36 to 50 hours, outperforming previous methods.", "motivation": "Existing deep learning methods for TC forecasting treat evolution as independent frame-to-frame predictions, lacking long-term dependency modeling.", "method": "Uses video diffusion models with temporal layers and a two-stage training strategy to generate multiple frames simultaneously, improving quality and low-data performance.", "result": "Outperforms Nath et al. by 19.3% in MAE, 16.2% in PSNR, and 36.1% in SSIM, with a longer forecasting horizon.", "conclusion": "The approach produces temporally coherent forecasts and maintains single-frame quality, validated by traditional metrics and FVD."}}
{"id": "2410.01639", "pdf": "https://arxiv.org/pdf/2410.01639", "abs": "https://arxiv.org/abs/2410.01639", "authors": ["Elizaveta Tennant", "Stephen Hailes", "Mirco Musolesi"], "title": "Moral Alignment for LLM Agents", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "Published at the 13th International Conference on Learning\n  Representations (ICLR'25), Singapore, Apr 2025.\n  https://openreview.net/forum?id=MeGDmZjUXy", "summary": "Decision-making agents based on pre-trained Large Language Models (LLMs) are\nincreasingly being deployed across various domains of human activity. While\ntheir applications are currently rather specialized, several research efforts\nare underway to develop more generalist agents. As LLM-based systems become\nmore agentic, their influence on human activity will grow and their\ntransparency will decrease. Consequently, developing effective methods for\naligning them to human values is vital.\n  The prevailing practice in alignment often relies on human preference data\n(e.g., in RLHF or DPO), in which values are implicit, opaque and are\nessentially deduced from relative preferences over different model outputs. In\nthis work, instead of relying on human feedback, we introduce the design of\nreward functions that explicitly and transparently encode core human values for\nReinforcement Learning-based fine-tuning of foundation agent models.\nSpecifically, we use intrinsic rewards for the moral alignment of LLM agents.\n  We evaluate our approach using the traditional philosophical frameworks of\nDeontological Ethics and Utilitarianism, quantifying moral rewards for agents\nin terms of actions and consequences on the Iterated Prisoner's Dilemma (IPD)\nenvironment. We also show how moral fine-tuning can be deployed to enable an\nagent to unlearn a previously developed selfish strategy. Finally, we find that\ncertain moral strategies learned on the IPD game generalize to several other\nmatrix game environments. In summary, we demonstrate that fine-tuning with\nintrinsic rewards is a promising general solution for aligning LLM agents to\nhuman values, and it might represent a more transparent and cost-effective\nalternative to currently predominant alignment techniques.", "AI": {"tldr": "The paper proposes using intrinsic rewards for moral alignment of LLM agents, offering a transparent and cost-effective alternative to human feedback-based methods like RLHF or DPO.", "motivation": "As LLM-based agents become more influential and less transparent, aligning them to human values is crucial. Current methods rely on opaque human preference data, prompting the need for explicit, value-driven reward functions.", "method": "The authors design reward functions encoding human values (Deontological Ethics and Utilitarianism) for Reinforcement Learning-based fine-tuning. They test this on the Iterated Prisoner's Dilemma and other matrix games.", "result": "Moral fine-tuning successfully aligns agents, unlearns selfish strategies, and generalizes learned strategies to other environments.", "conclusion": "Intrinsic reward-based fine-tuning is a promising, transparent, and cost-effective solution for aligning LLM agents to human values."}}
{"id": "2505.07272", "pdf": "https://arxiv.org/pdf/2505.07272", "abs": "https://arxiv.org/abs/2505.07272", "authors": ["Javier Salazar Cavazos", "Jeffrey A. Fessler", "Laura Balzano"], "title": "ALPCAH: Subspace Learning for Sample-wise Heteroscedastic Data", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": null, "summary": "Principal component analysis (PCA) is a key tool in the field of data\ndimensionality reduction. However, some applications involve heterogeneous data\nthat vary in quality due to noise characteristics associated with each data\nsample. Heteroscedastic methods aim to deal with such mixed data quality. This\npaper develops a subspace learning method, named ALPCAH, that can estimate the\nsample-wise noise variances and use this information to improve the estimate of\nthe subspace basis associated with the low-rank structure of the data. Our\nmethod makes no distributional assumptions of the low-rank component and does\nnot assume that the noise variances are known. Further, this method uses a soft\nrank constraint that does not require subspace dimension to be known.\nAdditionally, this paper develops a matrix factorized version of ALPCAH, named\nLR-ALPCAH, that is much faster and more memory efficient at the cost of\nrequiring subspace dimension to be known or estimated. Simulations and real\ndata experiments show the effectiveness of accounting for data\nheteroscedasticity compared to existing algorithms. Code available at\nhttps://github.com/javiersc1/ALPCAH.", "AI": {"tldr": "ALPCAH is a subspace learning method for heterogeneous data, estimating noise variances and improving subspace basis estimation without distributional assumptions or known noise variances. LR-ALPCAH is a faster, memory-efficient variant requiring known subspace dimension.", "motivation": "PCA struggles with heterogeneous data quality. Heteroscedastic methods address this, but existing approaches often assume known noise variances or subspace dimensions. ALPCAH aims to overcome these limitations.", "method": "ALPCAH estimates sample-wise noise variances and uses them to refine subspace basis estimation, avoiding distributional assumptions. LR-ALPCAH is a matrix factorized version for efficiency, requiring known subspace dimension.", "result": "Simulations and real data experiments demonstrate ALPCAH's effectiveness in handling heteroscedasticity compared to existing methods.", "conclusion": "ALPCAH and LR-ALPCAH provide robust solutions for subspace learning in heterogeneous data, with trade-offs between flexibility and computational efficiency."}}
{"id": "2502.00848", "pdf": "https://arxiv.org/pdf/2502.00848", "abs": "https://arxiv.org/abs/2502.00848", "authors": ["Yuanhuiyi Lyu", "Xu Zheng", "Lutao Jiang", "Yibo Yan", "Xin Zou", "Huiyu Zhou", "Linfeng Zhang", "Xuming Hu"], "title": "RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning", "categories": ["cs.CV"], "comment": "Accepted to ICML2025", "summary": "Recent text-to-image generative models, e.g., Stable Diffusion V3 and Flux,\nhave achieved notable progress. However, these models are strongly restricted\nto their limited knowledge, a.k.a., their own fixed parameters, that are\ntrained with closed datasets. This leads to significant hallucinations or\ndistortions when facing fine-grained and unseen novel real-world objects, e.g.,\nthe appearance of the Tesla Cybertruck. To this end, we present the first\nreal-object-based retrieval-augmented generation framework (RealRAG), which\naugments fine-grained and unseen novel object generation by learning and\nretrieving real-world images to overcome the knowledge gaps of generative\nmodels. Specifically, to integrate missing memory for unseen novel object\ngeneration, we train a reflective retriever by self-reflective contrastive\nlearning, which injects the generator's knowledge into the sef-reflective\nnegatives, ensuring that the retrieved augmented images compensate for the\nmodel's missing knowledge. Furthermore, the real-object-based framework\nintegrates fine-grained visual knowledge for the generative models, tackling\nthe distortion problem and improving the realism for fine-grained object\ngeneration. Our Real-RAG is superior in its modular application to all types of\nstate-of-the-art text-to-image generative models and also delivers remarkable\nperformance boosts with all of them, such as a gain of 16.18% FID score with\nthe auto-regressive model on the Stanford Car benchmark.", "AI": {"tldr": "RealRAG is a retrieval-augmented framework that enhances text-to-image models by integrating real-world images to address hallucinations and distortions in fine-grained or novel object generation.", "motivation": "Existing text-to-image models struggle with fine-grained or unseen objects due to fixed parameters and closed datasets, leading to hallucinations or distortions.", "method": "RealRAG uses a reflective retriever trained via self-reflective contrastive learning to augment generation with real-world images, compensating for the model's knowledge gaps.", "result": "The framework improves realism and reduces distortions, achieving a 16.18% FID score gain on the Stanford Car benchmark.", "conclusion": "RealRAG effectively bridges knowledge gaps in generative models, enhancing performance for fine-grained and novel object generation."}}
{"id": "2410.03024", "pdf": "https://arxiv.org/pdf/2410.03024", "abs": "https://arxiv.org/abs/2410.03024", "authors": ["Marcel Kollovieh", "Marten Lienen", "David L\u00fcdke", "Leo Schwinn", "Stephan G\u00fcnnemann"], "title": "Flow Matching with Gaussian Process Priors for Probabilistic Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Recent advancements in generative modeling, particularly diffusion models,\nhave opened new directions for time series modeling, achieving state-of-the-art\nperformance in forecasting and synthesis. However, the reliance of\ndiffusion-based models on a simple, fixed prior complicates the generative\nprocess since the data and prior distributions differ significantly. We\nintroduce TSFlow, a conditional flow matching (CFM) model for time series\ncombining Gaussian processes, optimal transport paths, and data-dependent prior\ndistributions. By incorporating (conditional) Gaussian processes, TSFlow aligns\nthe prior distribution more closely with the temporal structure of the data,\nenhancing both unconditional and conditional generation. Furthermore, we\npropose conditional prior sampling to enable probabilistic forecasting with an\nunconditionally trained model. In our experimental evaluation on eight\nreal-world datasets, we demonstrate the generative capabilities of TSFlow,\nproducing high-quality unconditional samples. Finally, we show that both\nconditionally and unconditionally trained models achieve competitive results\nacross multiple forecasting benchmarks.", "AI": {"tldr": "TSFlow, a conditional flow matching model for time series, improves generative modeling by aligning prior distributions with data structure using Gaussian processes and optimal transport paths.", "motivation": "Diffusion models for time series rely on fixed priors, which mismatch data distributions, complicating generation. TSFlow addresses this by integrating data-dependent priors.", "method": "TSFlow combines Gaussian processes, optimal transport paths, and data-dependent priors. It also introduces conditional prior sampling for probabilistic forecasting.", "result": "TSFlow produces high-quality unconditional samples and achieves competitive results in forecasting benchmarks.", "conclusion": "TSFlow enhances time series modeling by better aligning priors with data, improving both generation and forecasting."}}
{"id": "2505.07329", "pdf": "https://arxiv.org/pdf/2505.07329", "abs": "https://arxiv.org/abs/2505.07329", "authors": ["Jordan Frery", "Roman Bredehoft", "Jakub Klemsa", "Arthur Meyre", "Andrei Stoian"], "title": "Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Preserving data confidentiality during the fine-tuning of open-source Large\nLanguage Models (LLMs) is crucial for sensitive applications. This work\nintroduces an interactive protocol adapting the Low-Rank Adaptation (LoRA)\ntechnique for private fine-tuning. Homomorphic Encryption (HE) protects the\nconfidentiality of training data and gradients handled by remote worker nodes\nperforming the bulk of computations involving the base model weights. The data\nowner orchestrates training, requiring minimal local computing power and\nmemory, thus alleviating the need for expensive client-side GPUs. We\ndemonstrate feasibility by fine-tuning a Llama-3.2-1B model, presenting\nconvergence results using HE-compatible quantization and performance benchmarks\nfor HE computations on GPU hardware. This approach enables applications such as\nconfidential knowledge base question answering, private codebase fine-tuning\nfor AI code assistants, AI agents for drafting emails based on a company's\nemail archive, and adapting models to analyze sensitive legal or healthcare\ndocuments.", "AI": {"tldr": "The paper introduces a protocol for private fine-tuning of LLMs using LoRA and Homomorphic Encryption to protect data confidentiality, demonstrating feasibility with a Llama-3.2-1B model.", "motivation": "To ensure data confidentiality during fine-tuning of LLMs for sensitive applications like healthcare or legal document analysis.", "method": "Adapts LoRA with Homomorphic Encryption (HE) to protect training data and gradients, leveraging remote worker nodes for computations.", "result": "Demonstrates feasibility by fine-tuning a Llama-3.2-1B model, showing convergence with HE-compatible quantization and GPU performance benchmarks.", "conclusion": "The approach enables secure fine-tuning for sensitive applications without requiring expensive client-side resources."}}
{"id": "2502.02283", "pdf": "https://arxiv.org/pdf/2502.02283", "abs": "https://arxiv.org/abs/2502.02283", "authors": ["Zhihao Guo", "Jingxuan Su", "Shenglin Wang", "Jinlong Fan", "Jing Zhang", "Wei Zhou", "Hadi Amirpour", "Yunlong Zhao", "Liangxiu Han", "Peng Wang"], "title": "GP-GS: Gaussian Processes for Enhanced Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "68T45"], "comment": "12 pages, 7 figures", "summary": "3D Gaussian Splatting has emerged as an efficient photorealistic novel view\nsynthesis method. However, its reliance on sparse Structure-from-Motion (SfM)\npoint clouds often limits scene reconstruction quality. To address the\nlimitation, this paper proposes a novel 3D reconstruction framework, Gaussian\nProcesses enhanced Gaussian Splatting (GP-GS), in which a multi-output Gaussian\nProcess model is developed to enable adaptive and uncertainty-guided\ndensification of sparse SfM point clouds. Specifically, we propose a dynamic\nsampling and filtering pipeline that adaptively expands the SfM point clouds by\nleveraging GP-based predictions to infer new candidate points from the input 2D\npixels and depth maps. The pipeline utilizes uncertainty estimates to guide the\npruning of high-variance predictions, ensuring geometric consistency and\nenabling the generation of dense point clouds. These densified point clouds\nprovide high-quality initial 3D Gaussians, enhancing reconstruction\nperformance. Extensive experiments conducted on synthetic and real-world\ndatasets across various scales validate the effectiveness and practicality of\nthe proposed framework.", "AI": {"tldr": "The paper introduces GP-GS, a framework enhancing 3D Gaussian Splatting by using Gaussian Processes to densify sparse SfM point clouds, improving reconstruction quality.", "motivation": "Sparse SfM point clouds limit 3D Gaussian Splatting's reconstruction quality, prompting the need for adaptive densification.", "method": "A multi-output Gaussian Process model dynamically samples and filters to densify SfM point clouds, guided by uncertainty estimates.", "result": "GP-GS generates dense point clouds, improving 3D Gaussian initialization and reconstruction performance.", "conclusion": "The framework is validated on synthetic and real-world datasets, proving effective for high-quality 3D reconstruction."}}
{"id": "2410.05740", "pdf": "https://arxiv.org/pdf/2410.05740", "abs": "https://arxiv.org/abs/2410.05740", "authors": ["Guoqiang Wu", "Cheng Hu", "Wangjia Weng", "Zhouheng Li", "Yonghao Fu", "Lei Xie", "Hongye Su"], "title": "Learning to Drift in Extreme Turning with Active Exploration and Gaussian Process Based MPC", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Extreme cornering in racing often leads to large sideslip angles, presenting\na significant challenge for vehicle control. Conventional vehicle controllers\nstruggle to manage this scenario, necessitating the use of a drifting\ncontroller. However, the large sideslip angle in drift conditions introduces\nmodel mismatch, which in turn affects control precision. To address this issue,\nwe propose a model correction drift controller that integrates Model Predictive\nControl (MPC) with Gaussian Process Regression (GPR). GPR is employed to\ncorrect vehicle model mismatches during both drift equilibrium solving and the\nMPC optimization process. Additionally, the variance from GPR is utilized to\nactively explore different cornering drifting velocities, aiming to minimize\ntrajectory tracking errors. The proposed algorithm is validated through\nsimulations on the Simulink-Carsim platform and experiments with a 1:10 scale\nRC vehicle. In the simulation, the average lateral error with GPR is reduced by\n52.8% compared to the non-GPR case. Incorporating exploration further decreases\nthis error by 27.1%. The velocity tracking Root Mean Square Error (RMSE) also\ndecreases by 10.6% with exploration. In the RC car experiment, the average\nlateral error with GPR is 36.7% lower, and exploration further leads to a 29.0%\nreduction. Moreover, the velocity tracking RMSE decreases by 7.2% with the\ninclusion of exploration.", "AI": {"tldr": "A model correction drift controller combining MPC and GPR improves precision in extreme cornering by reducing lateral and velocity tracking errors.", "motivation": "Large sideslip angles in racing corners challenge conventional controllers, requiring drift control but introducing model mismatch.", "method": "Integrates MPC with GPR to correct model mismatches and uses GPR variance to explore drifting velocities for error minimization.", "result": "Simulations show 52.8% lower lateral error with GPR; exploration further reduces it by 27.1%. RC experiments confirm 36.7% and 29.0% reductions.", "conclusion": "The proposed controller effectively addresses model mismatch in drifting, significantly improving tracking precision."}}
{"id": "2505.07487", "pdf": "https://arxiv.org/pdf/2505.07487", "abs": "https://arxiv.org/abs/2505.07487", "authors": ["Heraldo Borges", "Juliana Alves Pereira", "Djamel Eddine Khelladi", "Mathieu Acher"], "title": "Linux Kernel Configurations at Scale: A Dataset for Performance and Evolution Analysis", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Configuring the Linux kernel to meet specific requirements, such as binary\nsize, is highly challenging due to its immense complexity-with over 15,000\ninterdependent options evolving rapidly across different versions. Although\nseveral studies have explored sampling strategies and machine learning methods\nto understand and predict the impact of configuration options, the literature\nstill lacks a comprehensive and large-scale dataset encompassing multiple\nkernel versions along with detailed quantitative measurements. To bridge this\ngap, we introduce LinuxData, an accessible collection of kernel configurations\nspanning several kernel releases, specifically from versions 4.13 to 5.8. This\ndataset, gathered through automated tools and build processes, comprises over\n240,000 kernel configurations systematically labeled with compilation outcomes\nand binary sizes. By providing detailed records of configuration evolution and\ncapturing the intricate interplay among kernel options, our dataset enables\ninnovative research in feature subset selection, prediction models based on\nmachine learning, and transfer learning across kernel versions. Throughout this\npaper, we describe how the dataset has been made easily accessible via OpenML\nand illustrate how it can be leveraged using only a few lines of Python code to\nevaluate AI-based techniques, such as supervised machine learning. We\nanticipate that this dataset will significantly enhance reproducibility and\nfoster new insights into configuration-space analysis at a scale that presents\nunique opportunities and inherent challenges, thereby advancing our\nunderstanding of the Linux kernel's configurability and evolution.", "AI": {"tldr": "The paper introduces LinuxData, a large-scale dataset of Linux kernel configurations (versions 4.13 to 5.8) with over 240,000 entries, enabling research in feature selection, ML prediction, and transfer learning.", "motivation": "The lack of a comprehensive dataset for Linux kernel configurations hinders research. LinuxData bridges this gap by providing detailed, labeled configurations.", "method": "Automated tools and build processes collected kernel configurations, labeled with compilation outcomes and binary sizes. The dataset is accessible via OpenML.", "result": "LinuxData includes over 240,000 configurations, facilitating AI-based techniques like supervised ML and transfer learning.", "conclusion": "LinuxData enhances reproducibility and advances understanding of Linux kernel configurability and evolution."}}
{"id": "2502.02590", "pdf": "https://arxiv.org/pdf/2502.02590", "abs": "https://arxiv.org/abs/2502.02590", "authors": ["Xiaowen Qiu", "Jincheng Yang", "Yian Wang", "Zhehuan Chen", "Yufei Wang", "Tsun-Hsuan Wang", "Zhou Xian", "Chuang Gan"], "title": "Articulate AnyMesh: Open-Vocabulary 3D Articulated Objects Modeling", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "3D articulated objects modeling has long been a challenging problem, since it\nrequires to capture both accurate surface geometries and semantically\nmeaningful and spatially precise structures, parts, and joints. Existing\nmethods heavily depend on training data from a limited set of handcrafted\narticulated object categories (e.g., cabinets and drawers), which restricts\ntheir ability to model a wide range of articulated objects in an\nopen-vocabulary context. To address these limitations, we propose Articulate\nAnymesh, an automated framework that is able to convert any rigid 3D mesh into\nits articulated counterpart in an open-vocabulary manner. Given a 3D mesh, our\nframework utilizes advanced Vision-Language Models and visual prompting\ntechniques to extract semantic information, allowing for both the segmentation\nof object parts and the construction of functional joints. Our experiments show\nthat Articulate Anymesh can generate large-scale, high-quality 3D articulated\nobjects, including tools, toys, mechanical devices, and vehicles, significantly\nexpanding the coverage of existing 3D articulated object datasets.\nAdditionally, we show that these generated assets can facilitate the\nacquisition of new articulated object manipulation skills in simulation, which\ncan then be transferred to a real robotic system. Our Github website is\nhttps://articulate-anymesh.github.io.", "AI": {"tldr": "Articulate Anymesh automates converting rigid 3D meshes into articulated objects using Vision-Language Models, enabling open-vocabulary 3D modeling and expanding dataset coverage.", "motivation": "Existing methods for 3D articulated object modeling are limited by handcrafted categories, restricting their applicability to diverse objects.", "method": "The framework uses Vision-Language Models and visual prompting to segment parts and construct functional joints from rigid 3D meshes.", "result": "It generates high-quality articulated objects (tools, toys, devices, vehicles) and aids robotic skill acquisition in simulation.", "conclusion": "Articulate Anymesh broadens 3D articulated object modeling and enhances robotic manipulation capabilities."}}
{"id": "2410.07250", "pdf": "https://arxiv.org/pdf/2410.07250", "abs": "https://arxiv.org/abs/2410.07250", "authors": ["Yu Wang", "Yangguang Zhang", "Shengxiang Lin", "Xingyi Zhang", "Han Zhang"], "title": "Lightweight Deep Learning Framework for Accurate Particle Flow Energy Reconstruction", "categories": ["physics.ins-det", "cs.AI"], "comment": "12 pages, 8 figures", "summary": "Under extreme operating conditions, characterized by high particle\nmultiplicity and heavily overlapping shower energy deposits, classical particle\nflow algorithms encounter pronounced limitations in resolution, efficiency, and\naccuracy. To address this challenge, this paper proposes and systematically\nevaluates a deep learning reconstruction framework: For multichannel sparse\nfeatures, we design a hybrid loss function combining weighted mean squared\nerror with structural similarity index, effectively balancing pixel-level\naccuracy and structural fidelity. By integrating 3D convolutions,\nSqueeze-and-Excitation channel attention, and Offset self-attention modules\ninto baseline convolutional neural networks, we enhance the model's capability\nto capture cross-modal spatiotemporal correlations and energy-displacement\nnonlinearities. Validated on custom-constructed simulation data and Pythia jet\ndatasets, the framework's 90K-parameter lightweight variant approaches the\nperformance of 5M-parameter baselines, while the 25M-parameter 3D model\nachieves state-of-the-art results in both interpolation and extrapolation\ntasks. Comprehensive experiments quantitatively evaluate component\ncontributions and provide performance-parameter trade-off guidelines. All core\ncode and data processing scripts are open-sourced on a GitHub repository to\nfacilitate community reproducibility and extension.", "AI": {"tldr": "A deep learning framework improves particle flow reconstruction under extreme conditions by combining hybrid loss functions and advanced neural network modules, achieving state-of-the-art results with efficient parameter use.", "motivation": "Classical particle flow algorithms struggle with high particle multiplicity and overlapping showers, limiting resolution and accuracy.", "method": "Proposes a deep learning framework with hybrid loss functions, 3D convolutions, Squeeze-and-Excitation, and Offset self-attention modules to enhance spatiotemporal correlation capture.", "result": "Lightweight (90K parameters) and 3D (25M parameters) models achieve near-baseline and state-of-the-art performance, respectively, validated on simulation and Pythia jet datasets.", "conclusion": "The framework offers a robust solution for extreme conditions, with open-sourced code for reproducibility and extension."}}
{"id": "2505.07594", "pdf": "https://arxiv.org/pdf/2505.07594", "abs": "https://arxiv.org/abs/2505.07594", "authors": ["Manish Prajapat", "Johannes K\u00f6hler", "Amon Lahr", "Andreas Krause", "Melanie N. Zeilinger"], "title": "Finite-Sample-Based Reachability for Safe Control with Gaussian Process Dynamics", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "comment": null, "summary": "Gaussian Process (GP) regression is shown to be effective for learning\nunknown dynamics, enabling efficient and safety-aware control strategies across\ndiverse applications. However, existing GP-based model predictive control\n(GP-MPC) methods either rely on approximations, thus lacking guarantees, or are\noverly conservative, which limits their practical utility. To close this gap,\nwe present a sampling-based framework that efficiently propagates the model's\nepistemic uncertainty while avoiding conservatism. We establish a novel sample\ncomplexity result that enables the construction of a reachable set using a\nfinite number of dynamics functions sampled from the GP posterior. Building on\nthis, we design a sampling-based GP-MPC scheme that is recursively feasible and\nguarantees closed-loop safety and stability with high probability. Finally, we\nshowcase the effectiveness of our method on two numerical examples,\nhighlighting accurate reachable set over-approximation and safe closed-loop\nperformance.", "AI": {"tldr": "A sampling-based framework for GP-MPC ensures safety and stability by efficiently propagating epistemic uncertainty without conservatism.", "motivation": "Existing GP-MPC methods lack guarantees or are overly conservative, limiting practical use.", "method": "A sampling-based approach propagates GP posterior uncertainty, with a novel sample complexity result for reachable set construction.", "result": "Recursive feasibility, closed-loop safety, and stability are guaranteed with high probability.", "conclusion": "The method demonstrates accurate reachable set approximation and safe performance in numerical examples."}}
{"id": "2502.04847", "pdf": "https://arxiv.org/pdf/2502.04847", "abs": "https://arxiv.org/abs/2502.04847", "authors": ["Qijun Gan", "Yi Ren", "Chen Zhang", "Zhenhui Ye", "Pan Xie", "Xiang Yin", "Zehuan Yuan", "Bingyue Peng", "Jianke Zhu"], "title": "HumanDiT: Pose-Guided Diffusion Transformer for Long-form Human Motion Video Generation", "categories": ["cs.CV"], "comment": "https://agnjason.github.io/HumanDiT-page/", "summary": "Human motion video generation has advanced significantly, while existing\nmethods still struggle with accurately rendering detailed body parts like hands\nand faces, especially in long sequences and intricate motions. Current\napproaches also rely on fixed resolution and struggle to maintain visual\nconsistency. To address these limitations, we propose HumanDiT, a pose-guided\nDiffusion Transformer (DiT)-based framework trained on a large and wild dataset\ncontaining 14,000 hours of high-quality video to produce high-fidelity videos\nwith fine-grained body rendering. Specifically, (i) HumanDiT, built on DiT,\nsupports numerous video resolutions and variable sequence lengths, facilitating\nlearning for long-sequence video generation; (ii) we introduce a prefix-latent\nreference strategy to maintain personalized characteristics across extended\nsequences. Furthermore, during inference, HumanDiT leverages Keypoint-DiT to\ngenerate subsequent pose sequences, facilitating video continuation from static\nimages or existing videos. It also utilizes a Pose Adapter to enable pose\ntransfer with given sequences. Extensive experiments demonstrate its superior\nperformance in generating long-form, pose-accurate videos across diverse\nscenarios.", "AI": {"tldr": "HumanDiT is a pose-guided Diffusion Transformer framework that generates high-fidelity human motion videos with fine-grained body rendering, supporting variable resolutions and sequence lengths.", "motivation": "Existing methods struggle with detailed body part rendering and visual consistency in long sequences. HumanDiT aims to overcome these limitations.", "method": "Built on Diffusion Transformer (DiT), HumanDiT uses a prefix-latent reference strategy and Keypoint-DiT for pose sequence generation, along with a Pose Adapter for pose transfer.", "result": "HumanDiT outperforms existing methods in generating long-form, pose-accurate videos across diverse scenarios.", "conclusion": "HumanDiT advances human motion video generation by addressing key challenges in detail rendering and sequence consistency."}}
{"id": "2411.10285", "pdf": "https://arxiv.org/pdf/2411.10285", "abs": "https://arxiv.org/abs/2411.10285", "authors": ["Pedro Palacios", "Rafael Medina", "Jean-Luc Rouas", "Giovanni Ansaloni", "David Atienza"], "title": "Systolic Arrays and Structured Pruning Co-design for Efficient Transformers in Edge Systems", "categories": ["cs.AR", "cs.AI", "68T50", "C.3; B.5.1; I.2.7"], "comment": "8 pages, GLSVLSI'25", "summary": "Efficient deployment of resource-intensive transformers on edge devices\nnecessitates cross-stack optimization. We thus study the interrelation between\nstructured pruning and systolic acceleration, matching the size of pruned\nblocks with the systolic array dimensions. In this setting, computations of\npruned weight blocks can be skipped, reducing run-time and energy consumption,\nbut potentially impacting quality of service (QoS). To evaluate the trade-offs\nbetween systolic array size and sparsity opportunities, we present a novel\nco-design framework that integrates algorithmic optimization, system\nsimulation, and hardware design. Targeting speech recognition and machine\ntranslation using transformers as case study, we analyze how configuration\nchoices across the stack affect performance metrics. Results demonstrate that\nstructured pruning on systems featuring systolic array acceleration can\neffectively increase performance, while maintaining high QoS levels. Up to 44%\nsystem-wide speedups due to structured pruning and quantization were measured,\nwith only 1.4% word error rate degradation on the standard LibriSpeech dataset.", "AI": {"tldr": "The paper explores cross-stack optimization for deploying transformers on edge devices by aligning structured pruning with systolic array dimensions, achieving significant speedups with minimal QoS impact.", "motivation": "To address the challenge of efficiently deploying resource-intensive transformers on edge devices by optimizing the interplay between structured pruning and systolic acceleration.", "method": "A co-design framework integrating algorithmic optimization, system simulation, and hardware design, tested on speech recognition and machine translation tasks.", "result": "Up to 44% system-wide speedups with structured pruning and quantization, with only 1.4% word error rate degradation on LibriSpeech.", "conclusion": "Structured pruning paired with systolic array acceleration effectively boosts performance while maintaining high QoS, making it viable for edge deployment."}}
{"id": "2505.07607", "pdf": "https://arxiv.org/pdf/2505.07607", "abs": "https://arxiv.org/abs/2505.07607", "authors": ["Georg Sch\u00e4fer", "Raphael Seliger", "Jakob Rehrl", "Stefan Huber", "Simon Hirlaender"], "title": "Multi-Objective Reinforcement Learning for Energy-Efficient Industrial Control", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "Accepted at DEXA 2025 (AI4IP)", "summary": "Industrial automation increasingly demands energy-efficient control\nstrategies to balance performance with environmental and cost constraints. In\nthis work, we present a multi-objective reinforcement learning (MORL) framework\nfor energy-efficient control of the Quanser Aero 2 testbed in its\none-degree-of-freedom configuration. We design a composite reward function that\nsimultaneously penalizes tracking error and electrical power consumption.\nPreliminary experiments explore the influence of varying the Energy penalty\nweight, alpha, on the trade-off between pitch tracking and energy savings. Our\nresults reveal a marked performance shift for alpha values between 0.0 and\n0.25, with non-Pareto optimal solutions emerging at lower alpha values, on both\nthe simulation and the real system. We hypothesize that these effects may be\nattributed to artifacts introduced by the adaptive behavior of the Adam\noptimizer, which could bias the learning process and favor bang-bang control\nstrategies. Future work will focus on automating alpha selection through\nGaussian Process-based Pareto front modeling and transitioning the approach\nfrom simulation to real-world deployment.", "AI": {"tldr": "A MORL framework is proposed for energy-efficient control of the Quanser Aero 2 testbed, balancing tracking error and power consumption. Results show performance shifts with varying energy penalty weights, influenced by optimizer behavior. Future work aims to automate parameter selection and real-world deployment.", "motivation": "Industrial automation requires energy-efficient control strategies to address performance, environmental, and cost constraints.", "method": "A multi-objective reinforcement learning (MORL) framework with a composite reward function penalizing tracking error and power consumption is used. Experiments vary the energy penalty weight (alpha) to analyze trade-offs.", "result": "Performance shifts occur for alpha values between 0.0 and 0.25, with non-Pareto optimal solutions at lower alpha values, influenced by the Adam optimizer's behavior.", "conclusion": "The study highlights the impact of alpha on control strategies and proposes future work on automating alpha selection and real-world implementation."}}
{"id": "2502.16032", "pdf": "https://arxiv.org/pdf/2502.16032", "abs": "https://arxiv.org/abs/2502.16032", "authors": ["Lijun Yan", "Churan Wang", "Fangwei Zhong", "Yizhou Wang"], "title": "Clinical Inspired MRI Lesion Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "accepted in ISBI2025 oral", "summary": "Magnetic resonance imaging (MRI) is a potent diagnostic tool for detecting\npathological tissues in various diseases. Different MRI sequences have\ndifferent contrast mechanisms and sensitivities for different types of lesions,\nwhich pose challenges to accurate and consistent lesion segmentation. In\nclinical practice, radiologists commonly use the sub-sequence feature, i.e. the\ndifference between post contrast-enhanced T1-weighted (post) and\npre-contrast-enhanced (pre) sequences, to locate lesions. Inspired by this, we\npropose a residual fusion method to learn subsequence representation for MRI\nlesion segmentation. Specifically, we iteratively and adaptively fuse features\nfrom pre- and post-contrast sequences at multiple resolutions, using dynamic\nweights to achieve optimal fusion and address diverse lesion enhancement\npatterns. Our method achieves state-of-the-art performances on BraTS2023\ndataset for brain tumor segmentation and our in-house breast MRI dataset for\nbreast lesion segmentation. Our method is clinically inspired and has the\npotential to facilitate lesion segmentation in various applications.", "AI": {"tldr": "A residual fusion method for MRI lesion segmentation, inspired by clinical practice, achieves state-of-the-art results on brain tumor and breast lesion datasets.", "motivation": "Accurate lesion segmentation in MRI is challenging due to varying contrast mechanisms. Clinical use of pre- and post-contrast sequence differences inspired the proposed method.", "method": "Iteratively and adaptively fuses features from pre- and post-contrast sequences at multiple resolutions using dynamic weights.", "result": "Achieves state-of-the-art performance on BraTS2023 (brain tumor) and an in-house breast MRI dataset.", "conclusion": "The clinically inspired method effectively addresses diverse lesion enhancement patterns and has broad application potential."}}
{"id": "2411.13280", "pdf": "https://arxiv.org/pdf/2411.13280", "abs": "https://arxiv.org/abs/2411.13280", "authors": ["Keyue Qiu", "Yuxuan Song", "Jie Yu", "Hongbo Ma", "Ziyao Cao", "Zhilong Zhang", "Yushuai Wu", "Mingyue Zheng", "Hao Zhou", "Wei-Ying Ma"], "title": "Empower Structure-Based Molecule Optimization with Gradient Guidance", "categories": ["q-bio.BM", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Structure-Based molecule optimization (SBMO) aims to optimize molecules with\nboth continuous coordinates and discrete types against protein targets. A\npromising direction is to exert gradient guidance on generative models given\nits remarkable success in images, but it is challenging to guide discrete data\nand risks inconsistencies between modalities. To this end, we leverage a\ncontinuous and differentiable space derived through Bayesian inference,\npresenting Molecule Joint Optimization (MolJO), the gradient-based SBMO\nframework that facilitates joint guidance signals across different modalities\nwhile preserving SE(3)-equivariance. We introduce a novel backward correction\nstrategy that optimizes within a sliding window of the past histories, allowing\nfor a seamless trade-off between explore-and-exploit during optimization. MolJO\nachieves state-of-the-art performance on CrossDocked2020 benchmark (Success\nRate 51.3%, Vina Dock -9.05 and SA 0.78), more than 4x improvement in Success\nRate compared to the gradient-based counterpart, and 2x \"Me-Better\" Ratio as\nmuch as 3D baselines. Furthermore, we extend MolJO to a wide range of\noptimization settings, including multi-objective optimization and challenging\ntasks in drug design such as R-group optimization and scaffold hopping, further\nunderscoring its versatility.", "AI": {"tldr": "MolJO is a gradient-based framework for Structure-Based Molecule Optimization (SBMO) that leverages Bayesian inference for joint guidance across modalities, achieving state-of-the-art performance on benchmarks.", "motivation": "To address challenges in guiding discrete data and inconsistencies between modalities in SBMO, MolJO introduces a continuous, differentiable space for joint optimization.", "method": "MolJO uses Bayesian inference to derive a differentiable space, incorporates SE(3)-equivariance, and employs a backward correction strategy for explore-exploit trade-offs.", "result": "Achieves 51.3% Success Rate on CrossDocked2020, outperforming gradient-based counterparts by 4x and 3D baselines by 2x in \"Me-Better\" Ratio.", "conclusion": "MolJO demonstrates versatility in multi-objective optimization and drug design tasks, proving its effectiveness and adaptability."}}
{"id": "2505.07640", "pdf": "https://arxiv.org/pdf/2505.07640", "abs": "https://arxiv.org/abs/2505.07640", "authors": ["Haolin Zou", "Arnab Auddy", "Yongchan Kwon", "Kamiar Rahnama Rad", "Arian Maleki"], "title": "Certified Data Removal Under High-dimensional Settings", "categories": ["stat.ML", "cs.LG"], "comment": "46 pages, 4 figures", "summary": "Machine unlearning focuses on the computationally efficient removal of\nspecific training data from trained models, ensuring that the influence of\nforgotten data is effectively eliminated without the need for full retraining.\nDespite advances in low-dimensional settings, where the number of parameters \\(\np \\) is much smaller than the sample size \\( n \\), extending similar\ntheoretical guarantees to high-dimensional regimes remains challenging. We\npropose an unlearning algorithm that starts from the original model parameters\nand performs a theory-guided sequence of Newton steps \\( T \\in \\{ 1,2\\}\\).\nAfter this update, carefully scaled isotropic Laplacian noise is added to the\nestimate to ensure that any (potential) residual influence of forget data is\ncompletely removed. We show that when both \\( n, p \\to \\infty \\) with a fixed\nratio \\( n/p \\), significant theoretical and computational obstacles arise due\nto the interplay between the complexity of the model and the finite\nsignal-to-noise ratio. Finally, we show that, unlike in low-dimensional\nsettings, a single Newton step is insufficient for effective unlearning in\nhigh-dimensional problems -- however, two steps are enough to achieve the\ndesired certifiebility. We provide numerical experiments to support the\ncertifiability and accuracy claims of this approach.", "AI": {"tldr": "The paper proposes a machine unlearning algorithm for high-dimensional settings, using theory-guided Newton steps and noise addition to ensure data removal without full retraining.", "motivation": "Extending machine unlearning guarantees to high-dimensional regimes is challenging due to model complexity and finite signal-to-noise ratio.", "method": "The algorithm starts from original parameters, performs 1-2 Newton steps, and adds scaled isotropic Laplacian noise to eliminate residual data influence.", "result": "Two Newton steps are necessary for effective unlearning in high dimensions, achieving certifiability and accuracy.", "conclusion": "The approach successfully addresses high-dimensional unlearning challenges, supported by numerical experiments."}}
{"id": "2502.19159", "pdf": "https://arxiv.org/pdf/2502.19159", "abs": "https://arxiv.org/abs/2502.19159", "authors": ["Xuan Ding", "Rui Sun", "Yunjian Zhang", "Xiu Yan", "Yueqi Zhou", "Kaihao Huang", "Suzhong Fu", "Chuanlong Xie", "Yao Zhu"], "title": "A Sliding Layer Merging Method for Efficient Depth-Wise Pruning in LLMs", "categories": ["cs.CV"], "comment": null, "summary": "Compared to width-wise pruning, depth-wise pruning can significantly\naccelerate inference in resource-constrained scenarios. However, treating the\nentire Transformer layer as the minimum pruning unit may degrade model\nperformance by indiscriminately discarding the entire information of the layer.\nThis paper reveals the ``Patch-like'' feature relationship between layers in\nlarge language models by analyzing the correlation of the outputs of different\nlayers in the reproducing kernel Hilbert space. Building on this observation,\nwe propose a sliding layer merging method that dynamically selects and fuses\nconsecutive layers from top to bottom according to a pre-defined similarity\nthreshold, thereby simplifying the model structure while maintaining its\nperformance. Extensive experiments on LLMs with various architectures and\ndifferent parameter scales show that our method outperforms existing pruning\ntechniques in both zero-shot inference performance and retraining recovery\nquality after pruning. In particular, in the experiment with 35% pruning on the\nVicuna-7B model, our method achieved a 1.654% improvement in average\nperformance on zero-shot tasks compared to the existing method. Moreover, we\nfurther reveal the potential of combining depth pruning with width pruning to\nenhance the pruning effect. Our codes are available at\nhttps://github.com/920927/SLM-a-sliding-layer-merging-method.", "AI": {"tldr": "Depth-wise pruning in Transformers can accelerate inference but may degrade performance by discarding entire layers. This paper introduces a sliding layer merging method to dynamically fuse similar layers, improving performance over traditional pruning.", "motivation": "To address the performance degradation caused by indiscriminate layer pruning in Transformers by leveraging layer similarity for dynamic merging.", "method": "Analyzes layer correlations in reproducing kernel Hilbert space and proposes a sliding layer merging method to dynamically fuse consecutive layers based on similarity.", "result": "Outperforms existing pruning techniques, achieving a 1.654% improvement in zero-shot tasks on Vicuna-7B with 35% pruning.", "conclusion": "The method simplifies model structure while maintaining performance and suggests combining depth and width pruning for enhanced results."}}
{"id": "2412.11293", "pdf": "https://arxiv.org/pdf/2412.11293", "abs": "https://arxiv.org/abs/2412.11293", "authors": ["Ashish Parmanand Pandey", "Alan John Varghese", "Sarang Patil", "Mengjia Xu"], "title": "A Comparative Study on Dynamic Graph Embedding based on Mamba and Transformers", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 6 figures", "summary": "Dynamic graph embedding has emerged as an important technique for modeling\ncomplex time-evolving networks across diverse domains. While transformer-based\nmodels have shown promise in capturing long-range dependencies in temporal\ngraph data, they face scalability challenges due to quadratic computational\ncomplexity. This study presents a comparative analysis of dynamic graph\nembedding approaches using transformers and the recently proposed Mamba\narchitecture, a state-space model with linear complexity. We introduce three\nnovel models: TransformerG2G augment with graph convolutional networks,\n\\mathcal{DG}-Mamba, and \\mathcal{GDG}-Mamba with graph isomorphism network edge\nconvolutions. Our experiments on multiple benchmark datasets demonstrate that\nMamba-based models achieve comparable or superior performance to\ntransformer-based approaches in link prediction tasks while offering\nsignificant computational efficiency gains on longer sequences. Notably,\n\\mathcal{DG}-Mamba variants consistently outperform transformer-based models on\ndatasets with high temporal variability, such as UCI, Bitcoin, and Reality\nMining, while maintaining competitive performance on more stable graphs like\nSBM. We provide insights into the learned temporal dependencies through\nanalysis of attention weights and state matrices, revealing the models' ability\nto capture complex temporal patterns. By effectively combining state-space\nmodels with graph neural networks, our work addresses key limitations of\nprevious approaches and contributes to the growing body of research on\nefficient temporal graph representation learning. These findings offer\npromising directions for scaling dynamic graph embedding to larger, more\ncomplex real-world networks, potentially enabling new applications in areas\nsuch as social network analysis, financial modeling, and biological system\ndynamics.", "AI": {"tldr": "Comparative analysis of transformer and Mamba-based models for dynamic graph embedding, showing Mamba's efficiency and performance gains.", "motivation": "Address scalability challenges of transformer-based models in temporal graph data by exploring Mamba architecture's linear complexity.", "method": "Introduces three models: TransformerG2G, DG-Mamba, and GDG-Mamba, combining graph neural networks with state-space models.", "result": "Mamba-based models match or outperform transformers in link prediction, especially in high temporal variability datasets, with computational efficiency.", "conclusion": "Mamba models offer scalable, efficient solutions for dynamic graph embedding, enabling broader applications in real-world networks."}}
{"id": "2505.07642", "pdf": "https://arxiv.org/pdf/2505.07642", "abs": "https://arxiv.org/abs/2505.07642", "authors": ["Yulong Lu", "Pierre Monmarch\u00e9"], "title": "Convergence of Time-Averaged Mean Field Gradient Descent Dynamics for Continuous Multi-Player Zero-Sum Games", "categories": ["math.OC", "cs.LG", "math.AP", "math.PR", "stat.ML", "35Q89, 49N80, 91A16, 90C47"], "comment": "21 pages", "summary": "The approximation of mixed Nash equilibria (MNE) for zero-sum games with\nmean-field interacting players has recently raised much interest in machine\nlearning. In this paper we propose a mean-field gradient descent dynamics for\nfinding the MNE of zero-sum games involving $K$ players with $K\\geq 2$. The\nevolution of the players' strategy distributions follows coupled mean-field\ngradient descent flows with momentum, incorporating an exponentially discounted\ntime-averaging of gradients. First, in the case of a fixed entropic\nregularization, we prove an exponential convergence rate for the mean-field\ndynamics to the mixed Nash equilibrium with respect to the total variation\nmetric. This improves a previous polynomial convergence rate for a similar\ntime-averaged dynamics with different averaging factors. Moreover, unlike\nprevious two-scale approaches for finding the MNE, our approach treats all\nplayer types on the same time scale. We also show that with a suitable choice\nof decreasing temperature, a simulated annealing version of the mean-field\ndynamics converges to an MNE of the initial unregularized problem.", "AI": {"tldr": "The paper proposes a mean-field gradient descent dynamics for finding mixed Nash equilibria (MNE) in zero-sum games with mean-field interacting players, achieving exponential convergence and treating all players equally.", "motivation": "To improve the approximation of MNE in zero-sum games with mean-field interactions, addressing limitations of previous methods like polynomial convergence rates and unequal player treatment.", "method": "Uses coupled mean-field gradient descent flows with momentum and exponentially discounted time-averaging of gradients. Analyzes fixed entropic regularization and simulated annealing variants.", "result": "Exponential convergence to MNE under fixed regularization; simulated annealing variant converges to MNE of the unregularized problem.", "conclusion": "The proposed dynamics offer faster convergence and equal treatment of players, advancing MNE approximation in mean-field games."}}
{"id": "2503.01103", "pdf": "https://arxiv.org/pdf/2503.01103", "abs": "https://arxiv.org/abs/2503.01103", "authors": ["Kaiwen Zheng", "Yongxin Chen", "Huayu Chen", "Guande He", "Ming-Yu Liu", "Jun Zhu", "Qinsheng Zhang"], "title": "Direct Discriminative Optimization: Your Likelihood-Based Visual Generative Model is Secretly a GAN Discriminator", "categories": ["cs.CV", "cs.LG"], "comment": "ICML 2025 Spotlight Project Page:\n  https://research.nvidia.com/labs/dir/ddo/ Code: https://github.com/NVlabs/DDO", "summary": "While likelihood-based generative models, particularly diffusion and\nautoregressive models, have achieved remarkable fidelity in visual generation,\nthe maximum likelihood estimation (MLE) objective, which minimizes the forward\nKL divergence, inherently suffers from a mode-covering tendency that limits the\ngeneration quality under limited model capacity. In this work, we propose\nDirect Discriminative Optimization (DDO) as a unified framework that integrates\nlikelihood-based generative training and GAN-type discrimination to bypass this\nfundamental constraint by exploiting reverse KL and self-generated negative\nsignals. Our key insight is to parameterize a discriminator implicitly using\nthe likelihood ratio between a learnable target model and a fixed reference\nmodel, drawing parallels with the philosophy of Direct Preference Optimization\n(DPO). Unlike GANs, this parameterization eliminates the need for joint\ntraining of generator and discriminator networks, allowing for direct,\nefficient, and effective finetuning of a well-trained model to its full\npotential beyond the limits of MLE. DDO can be performed iteratively in a\nself-play manner for progressive model refinement, with each round requiring\nless than 1% of pretraining epochs. Our experiments demonstrate the\neffectiveness of DDO by significantly advancing the previous SOTA diffusion\nmodel EDM, reducing FID scores from 1.79/1.58/1.96 to new records of\n1.30/0.97/1.26 on CIFAR-10/ImageNet-64/ImageNet 512x512 datasets without any\nguidance mechanisms, and by consistently improving both guidance-free and\nCFG-enhanced FIDs of visual autoregressive models on ImageNet 256x256.", "AI": {"tldr": "The paper introduces Direct Discriminative Optimization (DDO), a framework combining likelihood-based generative training and GAN-type discrimination to overcome mode-covering limitations of MLE, achieving SOTA results in visual generation.", "motivation": "To address the mode-covering tendency of MLE in generative models, which limits generation quality under constrained model capacity.", "method": "Proposes DDO, integrating likelihood-based training and GAN-type discrimination via reverse KL divergence and self-generated negative signals, eliminating joint training needs.", "result": "DDO significantly improves SOTA diffusion and autoregressive models, reducing FID scores across multiple datasets without guidance mechanisms.", "conclusion": "DDO offers an efficient, effective way to refine generative models beyond MLE limits, demonstrating superior performance in visual generation tasks."}}
{"id": "2412.16746", "pdf": "https://arxiv.org/pdf/2412.16746", "abs": "https://arxiv.org/abs/2412.16746", "authors": ["Tai-Quan Peng", "Kaiqi Yang", "Sanguk Lee", "Hang Li", "Yucheng Chu", "Yuping Lin", "Hui Liu"], "title": "Beyond Partisan Leaning: A Comparative Analysis of Political Bias in Large Language Models", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) become increasingly embedded in civic,\neducational, and political information environments, concerns about their\npotential political bias have grown. Prior research often evaluates such bias\nthrough simulated personas or predefined ideological typologies, which may\nintroduce artificial framing effects or overlook how models behave in general\nuse scenarios. This study adopts a persona-free, topic-specific approach to\nevaluate political behavior in LLMs, reflecting how users typically interact\nwith these systems-without ideological role-play or conditioning. We introduce\na two-dimensional framework: one axis captures partisan orientation on highly\npolarized topics (e.g., abortion, immigration), and the other assesses\nsociopolitical engagement on less polarized issues (e.g., climate change,\nforeign policy). Using survey-style prompts drawn from the ANES and Pew\nResearch Center, we analyze responses from 43 LLMs developed in the U.S.,\nEurope, China, and the Middle East. We propose an entropy-weighted bias score\nto quantify both the direction and consistency of partisan alignment, and\nidentify four behavioral clusters through engagement profiles. Findings show\nmost models lean center-left or left ideologically and vary in their\nnonpartisan engagement patterns. Model scale and openness are not strong\npredictors of behavior, suggesting that alignment strategy and institutional\ncontext play a more decisive role in shaping political expression.", "AI": {"tldr": "The study evaluates political bias in LLMs using a persona-free, topic-specific approach, introducing a two-dimensional framework to measure partisan orientation and sociopolitical engagement. Findings show most models lean center-left, with alignment strategy and institutional context being key influencers.", "motivation": "Concerns about LLMs' political bias in civic and educational contexts, with prior methods criticized for artificial framing effects.", "method": "A persona-free, topic-specific approach using survey-style prompts from ANES and Pew Research Center, analyzing 43 LLMs globally. An entropy-weighted bias score quantifies partisan alignment.", "result": "Most LLMs lean center-left or left; model scale and openness are weak predictors, while alignment strategy and institutional context matter more.", "conclusion": "Political bias in LLMs is shaped more by alignment strategies and institutional contexts than by model scale or openness."}}
{"id": "2505.07676", "pdf": "https://arxiv.org/pdf/2505.07676", "abs": "https://arxiv.org/abs/2505.07676", "authors": ["Nicolas Camenzind", "Damir Filipovic"], "title": "Transfer Learning Across Fixed-Income Product Classes", "categories": ["stat.ML", "cs.LG", "q-fin.CP", "q-fin.MF"], "comment": null, "summary": "We propose a framework for transfer learning of discount curves across\ndifferent fixed-income product classes. Motivated by challenges in estimating\ndiscount curves from sparse or noisy data, we extend kernel ridge regression\n(KR) to a vector-valued setting, formulating a convex optimization problem in a\nvector-valued reproducing kernel Hilbert space (RKHS). Each component of the\nsolution corresponds to the discount curve implied by a specific product class.\nWe introduce an additional regularization term motivated by economic\nprinciples, promoting smoothness of spread curves between product classes, and\nshow that it leads to a valid separable kernel structure. A main theoretical\ncontribution is a decomposition of the vector-valued RKHS norm induced by\nseparable kernels. We further provide a Gaussian process interpretation of\nvector-valued KR, enabling quantification of estimation uncertainty.\nIllustrative examples demonstrate that transfer learning significantly improves\nextrapolation performance and tightens confidence intervals compared to\nsingle-curve estimation.", "AI": {"tldr": "A framework for transfer learning of discount curves across fixed-income products using kernel ridge regression in a vector-valued RKHS, with improved performance over single-curve estimation.", "motivation": "Addresses challenges in estimating discount curves from sparse or noisy data by leveraging transfer learning across product classes.", "method": "Extends kernel ridge regression to a vector-valued RKHS, introduces regularization for smooth spread curves, and provides a Gaussian process interpretation.", "result": "Transfer learning improves extrapolation and tightens confidence intervals compared to single-curve estimation.", "conclusion": "The framework effectively enhances discount curve estimation by leveraging cross-product information and quantifying uncertainty."}}
{"id": "2503.01234", "pdf": "https://arxiv.org/pdf/2503.01234", "abs": "https://arxiv.org/abs/2503.01234", "authors": ["Sijin Sun", "Ming Deng", "Xingrui Yu", "Xingyu Xi", "Liangbin Zhao"], "title": "Self-Adaptive Gamma Context-Aware SSM-based Model for Metal Defect Detection", "categories": ["cs.CV", "cs.LG"], "comment": "8 pages, 5 figures; Accepted for publication at the 2025\n  International Joint Conference on Neural Networks (IJCNN 2025), Rome, Italy,\n  30 June - 5 July", "summary": "Metal defect detection is critical in industrial quality assurance, yet\nexisting methods struggle with grayscale variations and complex defect states,\nlimiting its robustness. To address these challenges, this paper proposes a\nSelf-Adaptive Gamma Context-Aware SSM-based model(GCM-DET). This advanced\ndetection framework integrating a Dynamic Gamma Correction (GC) module to\nenhance grayscale representation and optimize feature extraction for precise\ndefect reconstruction. A State-Space Search Management (SSM) architecture\ncaptures robust multi-scale features, effectively handling defects of varying\nshapes and scales. Focal Loss is employed to mitigate class imbalance and\nrefine detection accuracy. Additionally, the CD5-DET dataset is introduced,\nspecifically designed for port container maintenance, featuring significant\ngrayscale variations and intricate defect patterns. Experimental results\ndemonstrate that the proposed model achieves substantial improvements, with\nmAP@0.5 gains of 27.6\\%, 6.6\\%, and 2.6\\% on the CD5-DET, NEU-DET, and GC10-DET\ndatasets.", "AI": {"tldr": "A Self-Adaptive Gamma Context-Aware SSM-based model (GCM-DET) is proposed for robust metal defect detection, addressing grayscale variations and complex defects, achieving significant performance gains on multiple datasets.", "motivation": "Existing methods struggle with grayscale variations and complex defect states, limiting robustness in metal defect detection.", "method": "The GCM-DET integrates Dynamic Gamma Correction (GC) for grayscale enhancement, State-Space Search Management (SSM) for multi-scale feature capture, and Focal Loss to handle class imbalance.", "result": "The model achieves mAP@0.5 gains of 27.6%, 6.6%, and 2.6% on CD5-DET, NEU-DET, and GC10-DET datasets, respectively.", "conclusion": "GCM-DET significantly improves metal defect detection, demonstrating robustness across varied datasets."}}
{"id": "2501.06143", "pdf": "https://arxiv.org/pdf/2501.06143", "abs": "https://arxiv.org/abs/2501.06143", "authors": ["Gerd Kortemeyer", "Marina Babayeva", "Giulia Polverini", "Ralf Widenhorn", "Bor Gregorcic"], "title": "Multilingual Performance of a Multimodal Artificial Intelligence System on Multisubject Physics Concept Inventories", "categories": ["physics.ed-ph", "cs.AI"], "comment": null, "summary": "We investigate the multilingual and multimodal performance of a large\nlanguage model-based artificial intelligence (AI) system, GPT-4o, using a\ndiverse set of physics concept inventories spanning multiple languages and\nsubject categories. The inventories, sourced from the PhysPort website, cover\nclassical physics topics such as mechanics, electromagnetism, optics, and\nthermodynamics, as well as relativity, quantum mechanics, astronomy,\nmathematics, and laboratory skills. Unlike previous text-only studies, we\nuploaded the inventories as images to reflect what a student would see on\npaper, thereby assessing the system's multimodal functionality. Our results\nindicate variation in performance across subjects, with laboratory skills\nstanding out as the weakest. We also observe differences across languages, with\nEnglish and European languages showing the strongest performance. Notably, the\nrelative difficulty of an inventory item is largely independent of the language\nof the survey. When comparing AI results to existing literature on student\nperformance, we find that the AI system outperforms average post-instruction\nundergraduate students in all subject categories except laboratory skills.\nFurthermore, the AI performs worse on items requiring visual interpretation of\nimages than on those that are purely text-based. While our exploratory findings\nshow GPT-4o's potential usefulness in physics education, they highlight the\ncritical need for instructors to foster students' ability to critically\nevaluate AI outputs, adapt curricula thoughtfully in response to AI\nadvancements, and address equity concerns associated with AI integration.", "AI": {"tldr": "GPT-4o's multilingual and multimodal performance on physics concept inventories varies by subject and language, excelling in most areas except laboratory skills and visual interpretation tasks.", "motivation": "To assess GPT-4o's capabilities in multilingual and multimodal contexts for physics education, comparing it to student performance and identifying strengths and weaknesses.", "method": "Used diverse physics concept inventories from PhysPort, uploaded as images to test multimodal functionality, and analyzed performance across subjects and languages.", "result": "GPT-4o outperforms average undergraduates in most subjects but struggles with laboratory skills and visual tasks. Performance varies by language, with English and European languages leading.", "conclusion": "GPT-4o shows promise for physics education but requires careful integration, critical evaluation by students, and curriculum adjustments to address equity and AI limitations."}}
{"id": "2505.07688", "pdf": "https://arxiv.org/pdf/2505.07688", "abs": "https://arxiv.org/abs/2505.07688", "authors": ["Renzhe Xu", "Kang Wang", "Bo Li"], "title": "Heterogeneous Data Game: Characterizing the Model Competition Across Multiple Data Sources", "categories": ["cs.GT", "cs.LG"], "comment": "ICML 2025", "summary": "Data heterogeneity across multiple sources is common in real-world machine\nlearning (ML) settings. Although many methods focus on enabling a single model\nto handle diverse data, real-world markets often comprise multiple competing ML\nproviders. In this paper, we propose a game-theoretic framework -- the\nHeterogeneous Data Game -- to analyze how such providers compete across\nheterogeneous data sources. We investigate the resulting pure Nash equilibria\n(PNE), showing that they can be non-existent, homogeneous (all providers\nconverge on the same model), or heterogeneous (providers specialize in distinct\ndata sources). Our analysis spans monopolistic, duopolistic, and more general\nmarkets, illustrating how factors such as the \"temperature\" of data-source\nchoice models and the dominance of certain data sources shape equilibrium\noutcomes. We offer theoretical insights into both homogeneous and heterogeneous\nPNEs, guiding regulatory policies and practical strategies for competitive ML\nmarketplaces.", "AI": {"tldr": "A game-theoretic framework (Heterogeneous Data Game) analyzes competition among ML providers across heterogeneous data sources, revealing diverse Nash equilibria outcomes.", "motivation": "Addressing data heterogeneity and competition in real-world ML markets where multiple providers operate.", "method": "Proposes the Heterogeneous Data Game to study competition, analyzing pure Nash equilibria (PNE) in various market structures.", "result": "Identifies three PNE outcomes: non-existent, homogeneous (providers converge), or heterogeneous (providers specialize).", "conclusion": "Provides theoretical insights for regulatory policies and competitive strategies in ML marketplaces."}}
{"id": "2503.06473", "pdf": "https://arxiv.org/pdf/2503.06473", "abs": "https://arxiv.org/abs/2503.06473", "authors": ["Hanze Li", "Xiande Huang"], "title": "Enhancing Layer Attention Efficiency through Pruning Redundant Retrievals", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 7 figures", "summary": "Growing evidence suggests that layer attention mechanisms, which enhance\ninteraction among layers in deep neural networks, have significantly advanced\nnetwork architectures. However, existing layer attention methods suffer from\nredundancy, as attention weights learned by adjacent layers often become highly\nsimilar. This redundancy causes multiple layers to extract nearly identical\nfeatures, reducing the model's representational capacity and increasing\ntraining time. To address this issue, we propose a novel approach to quantify\nredundancy by leveraging the Kullback-Leibler (KL) divergence between adjacent\nlayers. Additionally, we introduce an Enhanced Beta Quantile Mapping (EBQM)\nmethod that accurately identifies and skips redundant layers, thereby\nmaintaining model stability. Our proposed Efficient Layer Attention (ELA)\narchitecture, improves both training efficiency and overall performance,\nachieving a 30% reduction in training time while enhancing performance in tasks\nsuch as image classification and object detection.", "AI": {"tldr": "Proposes a novel Efficient Layer Attention (ELA) architecture to reduce redundancy in layer attention mechanisms, improving training efficiency and performance.", "motivation": "Existing layer attention methods suffer from redundancy, leading to similar features across layers, reduced representational capacity, and increased training time.", "method": "Quantifies redundancy using KL divergence between adjacent layers and introduces Enhanced Beta Quantile Mapping (EBQM) to skip redundant layers.", "result": "ELA achieves a 30% reduction in training time while enhancing performance in tasks like image classification and object detection.", "conclusion": "The ELA architecture effectively addresses redundancy, improving both efficiency and performance in deep neural networks."}}
{"id": "2501.15767", "pdf": "https://arxiv.org/pdf/2501.15767", "abs": "https://arxiv.org/abs/2501.15767", "authors": ["Muhammad Maaz", "Timothy C. Y. Chan"], "title": "Formal Verification of Markov Processes with Learned Parameters", "categories": ["cs.LG", "cs.AI", "math.OC", "68Q60 (primary) 90C30, 60J20, 60J22 (secondary)", "F.4.1; G.1.6; I.2.3"], "comment": "9 pages (main manuscript), 3 figures, 1 table", "summary": "We introduce the problem of formally verifying properties of Markov processes\nwhere the parameters are given by the output of machine learning models. For a\nbroad class of machine learning models, including linear models, tree-based\nmodels, and neural networks, verifying properties of Markov chains like\nreachability, hitting time, and total reward can be formulated as a bilinear\nprogram. We develop a decomposition and bound propagation scheme for solving\nthe bilinear program and show through computational experiments that our method\nsolves the problem to global optimality up to 100x faster than state-of-the-art\nsolvers. To demonstrate the practical utility of our approach, we apply it to a\nreal-world healthcare case study. Along with the paper, we release markovml, an\nopen-source tool for building Markov processes, integrating pretrained machine\nlearning models, and verifying their properties, available at\nhttps://github.com/mmaaz-git/markovml.", "AI": {"tldr": "The paper introduces a method for verifying properties of Markov processes with ML model parameters, formulating it as a bilinear program and solving it efficiently.", "motivation": "To address the challenge of formally verifying properties of Markov processes where parameters are derived from ML models, ensuring reliability and correctness in applications like healthcare.", "method": "A decomposition and bound propagation scheme is developed to solve the bilinear program, applicable to linear models, tree-based models, and neural networks.", "result": "The method achieves global optimality up to 100x faster than state-of-the-art solvers, demonstrated through computational experiments and a healthcare case study.", "conclusion": "The approach is practical and scalable, supported by the open-source tool markovml for building and verifying Markov processes with ML models."}}
{"id": "2505.07714", "pdf": "https://arxiv.org/pdf/2505.07714", "abs": "https://arxiv.org/abs/2505.07714", "authors": ["Almoatssimbillah Saifaldawla", "Eva Lagunas", "Flor Ortiz", "Abuzar B. M. Adam", "Symeon Chatzinotas"], "title": "SmartUT: Receive Beamforming for Spectral Coexistence of NGSO Satellite Systems", "categories": ["eess.SP", "cs.ET", "cs.LG"], "comment": null, "summary": "In this paper, we investigate downlink co-frequency interference (CFI)\nmitigation in non-geostationary satellites orbits (NGSOs) co-existing systems.\nTraditional mitigation techniques, such as Zero-forcing (ZF), produce a null\ntowards the direction of arrivals (DOAs) of the interfering signals, but they\nsuffer from high computational complexity due to matrix inversions and required\nknowledge of the channel state information (CSI). Furthermore, adaptive\nbeamformers, such as sample matrix inversion (SMI)-based minimum variance,\nprovide poor performance when the available snapshots are limited. We propose a\nMamba-based beamformer (MambaBF) that leverages an unsupervised deep learning\n(DL) approach and can be deployed on the user terminal (UT) antenna array, for\nassisting downlink beamforming and CFI mitigation using only a limited number\nof available array snapshots as input, and without CSI knowledge. Simulation\nresults demonstrate that MambaBF consistently outperforms conventional\nbeamforming techniques in mitigating interference and maximizing the\nsignal-to-interference-plus-noise ratio (SINR), particularly under challenging\nconditions characterized by low SINR, limited snapshots, and imperfect CSI.", "AI": {"tldr": "Proposes MambaBF, a deep learning-based beamformer for CFI mitigation in NGSO systems, outperforming traditional methods without needing CSI.", "motivation": "Traditional CFI mitigation techniques like ZF and SMI suffer from high complexity and poor performance with limited snapshots or imperfect CSI.", "method": "Uses unsupervised deep learning (MambaBF) on UT antenna arrays, requiring only limited snapshots and no CSI.", "result": "MambaBF outperforms conventional methods in SINR and interference mitigation, especially in low SINR and limited snapshot scenarios.", "conclusion": "MambaBF is a promising solution for efficient CFI mitigation in NGSO systems without CSI dependency."}}
{"id": "2503.06587", "pdf": "https://arxiv.org/pdf/2503.06587", "abs": "https://arxiv.org/abs/2503.06587", "authors": ["Xiaoming Peng", "Yixin Yang", "Yang Zhou", "Hui Huang"], "title": "Introducing Unbiased Depth into 2D Gaussian Splatting for High-accuracy Surface Reconstruction", "categories": ["cs.CV"], "comment": "We found a major error in Sec. 4.3 Novel View Synthesis. We\n  mistakenly used the test-set images in training for NVS experiments, making\n  our results look better than they actually are", "summary": "Recently, 2D Gaussian Splatting (2DGS) has demonstrated superior geometry\nreconstruction quality than the popular 3DGS by using 2D surfels to approximate\nthin surfaces. However, it falls short when dealing with glossy surfaces,\nresulting in visible holes in these areas. We found the reflection\ndiscontinuity causes the issue. To fit the jump from diffuse to specular\nreflection at different viewing angles, depth bias is introduced in the\noptimized Gaussian primitives. To address that, we first replace the depth\ndistortion loss in 2DGS with a novel depth convergence loss, which imposes a\nstrong constraint on depth continuity. Then, we rectified the depth criterion\nin determining the actual surface, which fully accounts for all the\nintersecting Gaussians along the ray. Qualitative and quantitative evaluations\nacross various datasets reveal that our method significantly improves\nreconstruction quality, with more complete and accurate surfaces than 2DGS.", "AI": {"tldr": "The paper improves 2D Gaussian Splatting (2DGS) by addressing its failure on glossy surfaces through a novel depth convergence loss and rectified depth criterion, achieving better reconstruction quality.", "motivation": "2DGS struggles with glossy surfaces, causing visible holes due to reflection discontinuity. The goal is to enhance reconstruction quality for such surfaces.", "method": "Replaces depth distortion loss with a depth convergence loss and rectifies the depth criterion to account for all intersecting Gaussians along the ray.", "result": "Significant improvement in reconstruction quality, producing more complete and accurate surfaces compared to 2DGS.", "conclusion": "The proposed method effectively addresses the limitations of 2DGS on glossy surfaces, enhancing overall reconstruction quality."}}
{"id": "2501.15889", "pdf": "https://arxiv.org/pdf/2501.15889", "abs": "https://arxiv.org/abs/2501.15889", "authors": ["Federico Errica", "Henrik Christiansen", "Viktor Zaverkin", "Mathias Niepert", "Francesco Alesiani"], "title": "Adaptive Width Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "For almost 70 years, researchers have mostly relied on hyper-parameter tuning\nto select the width of neural networks' layers. This paper challenges the\nstatus quo by introducing an easy-to-use technique to learn an unbounded width\nof a neural network's layer during training. The technique does not rely on\nalternate optimization nor hand-crafted gradient heuristics; rather, it jointly\noptimizes the width and the parameters of each layer via simple\nbackpropagation. We apply the technique to a broad range of data domains such\nas tables, images, text, sequences, and graphs, showing how the width adapts to\nthe task's difficulty. The method imposes a soft ordering of importance among\nneurons, by which it also is possible to truncate the trained network at\nvirtually zero cost, achieving a smooth trade-off between performance and\ncompute resources in a structured way. Alternatively, one can dynamically\ncompress the network with no performance degradation. In light of recent\nfoundation models trained on large datasets, believed to require billions of\nparameters and where hyper-parameter tuning is unfeasible due to humongous\ntraining costs, our approach stands as a viable alternative for width learning.", "AI": {"tldr": "A novel technique for learning neural network layer widths during training, avoiding hyper-parameter tuning and enabling dynamic adaptation and compression.", "motivation": "Challenges the traditional reliance on hyper-parameter tuning for network width, offering a scalable solution for modern large-scale models.", "method": "Jointly optimizes layer widths and parameters via simple backpropagation, applying it across diverse data domains.", "result": "Demonstrates adaptive width tuning, soft neuron importance ordering, and efficient network truncation or compression.", "conclusion": "Provides a scalable alternative to hyper-parameter tuning, especially for large foundation models."}}
{"id": "2505.07719", "pdf": "https://arxiv.org/pdf/2505.07719", "abs": "https://arxiv.org/abs/2505.07719", "authors": ["Hyunwoo Oh"], "title": "Training neural control variates using correlated configurations", "categories": ["hep-lat", "cs.LG", "nucl-th"], "comment": "8 pages, 6 figures", "summary": "Neural control variates (NCVs) have emerged as a powerful tool for variance\nreduction in Monte Carlo (MC) simulations, particularly in high-dimensional\nproblems where traditional control variates are difficult to construct\nanalytically. By training neural networks to learn auxiliary functions\ncorrelated with the target observable, NCVs can significantly reduce estimator\nvariance while preserving unbiasedness. However, a critical but often\noverlooked aspect of NCV training is the role of autocorrelated samples\ngenerated by Markov Chain Monte Carlo (MCMC). While such samples are typically\ndiscarded for error estimation due to their statistical redundancy, they may\ncontain useful information about the structure of the underlying probability\ndistribution that can benefit the training process. In this work, we\nsystematically examine the effect of using correlated configurations in\ntraining neural control variates. We demonstrate, both conceptually and\nnumerically, that training on correlated data can improve control variate\nperformance, especially in settings with limited computational resources. Our\nanalysis includes empirical results from $U(1)$ gauge theory and scalar field\ntheory, illustrating when and how autocorrelated samples enhance NCV\nconstruction. These findings provide practical guidance for the efficient use\nof MCMC data in training neural networks.", "AI": {"tldr": "Neural control variates (NCVs) reduce variance in Monte Carlo simulations by training neural networks on correlated MCMC samples, improving performance with limited resources.", "motivation": "To explore the overlooked role of autocorrelated MCMC samples in NCV training, which may enhance variance reduction despite their statistical redundancy.", "method": "Systematically analyze the effect of using correlated MCMC samples in NCV training, supported by empirical results from $U(1)$ gauge theory and scalar field theory.", "result": "Training on correlated data improves NCV performance, especially in resource-limited settings, as demonstrated numerically.", "conclusion": "Autocorrelated samples can enhance NCV training, offering practical guidance for efficient MCMC data use in neural network training."}}
{"id": "2503.08507", "pdf": "https://arxiv.org/pdf/2503.08507", "abs": "https://arxiv.org/abs/2503.08507", "authors": ["Qing Jiang", "Lin Wu", "Zhaoyang Zeng", "Tianhe Ren", "Yuda Xiong", "Yihao Chen", "Qin Liu", "Lei Zhang"], "title": "Referring to Any Person", "categories": ["cs.CV"], "comment": null, "summary": "Humans are undoubtedly the most important participants in computer vision,\nand the ability to detect any individual given a natural language description,\na task we define as referring to any person, holds substantial practical value.\nHowever, we find that existing models generally fail to achieve real-world\nusability, and current benchmarks are limited by their focus on one-to-one\nreferring, that hinder progress in this area. In this work, we revisit this\ntask from three critical perspectives: task definition, dataset design, and\nmodel architecture. We first identify five aspects of referable entities and\nthree distinctive characteristics of this task. Next, we introduce HumanRef, a\nnovel dataset designed to tackle these challenges and better reflect real-world\napplications. From a model design perspective, we integrate a multimodal large\nlanguage model with an object detection framework, constructing a robust\nreferring model named RexSeek. Experimental results reveal that\nstate-of-the-art models, which perform well on commonly used benchmarks like\nRefCOCO/+/g, struggle with HumanRef due to their inability to detect multiple\nindividuals. In contrast, RexSeek not only excels in human referring but also\ngeneralizes effectively to common object referring, making it broadly\napplicable across various perception tasks. Code is available at\nhttps://github.com/IDEA-Research/RexSeek", "AI": {"tldr": "The paper addresses the challenge of detecting individuals in computer vision using natural language descriptions, introducing a new dataset (HumanRef) and model (RexSeek) to improve real-world usability.", "motivation": "Existing models and benchmarks for referring to individuals in computer vision are limited, failing to achieve practical usability due to their focus on one-to-one referring.", "method": "The authors redefine the task, introduce the HumanRef dataset, and propose RexSeek, a model combining a multimodal large language model with object detection.", "result": "RexSeek outperforms state-of-the-art models on HumanRef and generalizes well to common object referring tasks.", "conclusion": "The work advances the field by addressing key limitations in task definition, dataset design, and model architecture, offering a robust solution for real-world applications."}}
{"id": "2501.17888", "pdf": "https://arxiv.org/pdf/2501.17888", "abs": "https://arxiv.org/abs/2501.17888", "authors": ["Shuai Chen", "Yong Zu", "Zhixi Feng", "Shuyuan Yang", "Mengchang Li"], "title": "RadioLLM: Introducing Large Language Model into Cognitive Radio via Hybrid Prompt and Token Reprogrammings", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The growing scarcity of spectrum resources and rapid proliferation of\nwireless devices make efficient radio network management critical. While deep\nlearning-enhanced Cognitive Radio Technology (CRT) provides promising solutions\nfor tasks such as radio signal classification (RSC), denoising, and spectrum\nallocation, existing DL-based CRT frameworks are typically task-specific and\nlack scalability in diverse real-world applications. This limitation naturally\nleads to the exploration of Large Language Models (LLMs), whose exceptional\ncross-domain generalization capabilities offer new potential for advancing CRT.\nTo bridge this gap, we propose RadioLLM, a novel framework that integrates\nHybrid Prompt and Token Reprogramming (HPTR) for combining radio signal\nfeatures with expert knowledge, and a Frequency-Attuned Fusion (FAF) module for\nenhanced high-frequency feature modeling. Extensive evaluations on multiple\nbenchmark datasets demonstrate that RadioLLM achieves superior performance\ncompared to existing baselines in the majority of testing scenarios.", "AI": {"tldr": "RadioLLM integrates LLMs with CRT using HPTR and FAF, outperforming existing methods in diverse scenarios.", "motivation": "Addressing the lack of scalability in DL-based CRT frameworks by leveraging LLMs' cross-domain generalization.", "method": "Proposes RadioLLM with Hybrid Prompt and Token Reprogramming (HPTR) and Frequency-Attuned Fusion (FAF).", "result": "Superior performance on multiple benchmark datasets compared to baselines.", "conclusion": "RadioLLM advances CRT by combining LLMs with specialized modules for scalable, efficient solutions."}}
{"id": "2505.07765", "pdf": "https://arxiv.org/pdf/2505.07765", "abs": "https://arxiv.org/abs/2505.07765", "authors": ["Zihan Shao", "Konstantin Pieper", "Xiaochuan Tian"], "title": "Solving Nonlinear PDEs with Sparse Radial Basis Function Networks", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": "35 pages, 7 figures", "summary": "We propose a novel framework for solving nonlinear PDEs using sparse radial\nbasis function (RBF) networks. Sparsity-promoting regularization is employed to\nprevent over-parameterization and reduce redundant features. This work is\nmotivated by longstanding challenges in traditional RBF collocation methods,\nalong with the limitations of physics-informed neural networks (PINNs) and\nGaussian process (GP) approaches, aiming to blend their respective strengths in\na unified framework. The theoretical foundation of our approach lies in the\nfunction space of Reproducing Kernel Banach Spaces (RKBS) induced by\none-hidden-layer neural networks of possibly infinite width. We prove a\nrepresenter theorem showing that the solution to the sparse optimization\nproblem in the RKBS admits a finite solution and establishes error bounds that\noffer a foundation for generalizing classical numerical analysis. The\nalgorithmic framework is based on a three-phase algorithm to maintain\ncomputational efficiency through adaptive feature selection, second-order\noptimization, and pruning of inactive neurons. Numerical experiments\ndemonstrate the effectiveness of our method and highlight cases where it offers\nnotable advantages over GP approaches. This work opens new directions for\nadaptive PDE solvers grounded in rigorous analysis with efficient,\nlearning-inspired implementation.", "AI": {"tldr": "A novel framework for solving nonlinear PDEs using sparse RBF networks with sparsity-promoting regularization to avoid over-parameterization.", "motivation": "Addresses challenges in traditional RBF collocation methods and limitations of PINNs and GP approaches, aiming to combine their strengths.", "method": "Uses RKBS theory, a three-phase algorithm for adaptive feature selection, second-order optimization, and neuron pruning.", "result": "Proves a representer theorem for finite solutions and establishes error bounds; numerical experiments show effectiveness over GP methods.", "conclusion": "Introduces a rigorous, efficient framework for adaptive PDE solvers with learning-inspired implementation."}}
{"id": "2503.08694", "pdf": "https://arxiv.org/pdf/2503.08694", "abs": "https://arxiv.org/abs/2503.08694", "authors": ["Mees M. Flapper", "Elian Bernard", "Sander G. Huisman"], "title": "Multi-camera orientation tracking method for anisotropic particles in particle-laden flows", "categories": ["cs.CV"], "comment": "14 pages, 22 figures", "summary": "A method for particle orientation tracking is developed and demonstrated\nspecifically for anisotropic particles. Using (high-speed) multi-camera\nrecordings of anisotropic particles from different viewpoints, we reconstruct\nthe 3D location and orientation of these particles using their known shape.\nThis paper describes an algorithm which tracks the location and orientation of\nmultiple anisotropic particles over time, enabling detailed investigations of\nlocation, orientation, and rotation statistics. The robustness and error of\nthis method is quantified, and we explore the effects of noise, image size, the\nnumber of used cameras, and the camera arrangement by applying the algorithm to\nsynthetic images. We showcase several use-cases of this method in several\nexperiments (in both quiescent and turbulent fluids), demonstrating the\neffectiveness and broad applicability of the described tracking method. The\nproposed method is shown to work for widely different particle shapes,\nsuccessfully tracks multiple particles simultaneously, and the method can\ndistinguish between different types of particles.", "AI": {"tldr": "A method for tracking 3D location and orientation of anisotropic particles using multi-camera recordings is developed, tested for robustness, and demonstrated in various experiments.", "motivation": "To enable detailed investigations of particle dynamics (location, orientation, rotation) in fluids, especially for anisotropic particles.", "method": "Uses multi-camera recordings and a shape-based algorithm to reconstruct 3D location and orientation of particles. Robustness is tested with synthetic images.", "result": "The method is robust, works for diverse particle shapes, tracks multiple particles simultaneously, and distinguishes particle types.", "conclusion": "The tracking method is effective and broadly applicable, as demonstrated in quiescent and turbulent fluid experiments."}}
{"id": "2501.18452", "pdf": "https://arxiv.org/pdf/2501.18452", "abs": "https://arxiv.org/abs/2501.18452", "authors": ["Xi Weng", "Jianing An", "Xudong Ma", "Binhang Qi", "Jie Luo", "Xi Yang", "Jin Song Dong", "Lei Huang"], "title": "Clustering Properties of Self-Supervised Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICML 2025", "summary": "Self-supervised learning (SSL) methods via joint embedding architectures have\nproven remarkably effective at capturing semantically rich representations with\nstrong clustering properties, magically in the absence of label supervision.\nDespite this, few of them have explored leveraging these untapped properties to\nimprove themselves. In this paper, we provide an evidence through various\nmetrics that the encoder's output $encoding$ exhibits superior and more stable\nclustering properties compared to other components. Building on this insight,\nwe propose a novel positive-feedback SSL method, termed Representation\nSelf-Assignment (ReSA), which leverages the model's clustering properties to\npromote learning in a self-guided manner. Extensive experiments on standard SSL\nbenchmarks reveal that models pretrained with ReSA outperform other\nstate-of-the-art SSL methods by a significant margin. Finally, we analyze how\nReSA facilitates better clustering properties, demonstrating that it\neffectively enhances clustering performance at both fine-grained and\ncoarse-grained levels, shaping representations that are inherently more\nstructured and semantically meaningful.", "AI": {"tldr": "The paper introduces ReSA, a self-supervised learning method that leverages clustering properties of encoder outputs to improve representation learning, outperforming state-of-the-art SSL methods.", "motivation": "Despite SSL methods' success in learning rich representations, few exploit their clustering properties for self-improvement. This paper aims to bridge this gap.", "method": "Proposes Representation Self-Assignment (ReSA), a positive-feedback SSL method that uses the encoder's clustering properties to guide learning.", "result": "ReSA outperforms other SSL methods on benchmarks, enhancing clustering at fine and coarse levels for more structured representations.", "conclusion": "ReSA effectively leverages clustering properties to improve SSL, yielding semantically meaningful and structured representations."}}
{"id": "2505.07769", "pdf": "https://arxiv.org/pdf/2505.07769", "abs": "https://arxiv.org/abs/2505.07769", "authors": ["Jai Bardhan", "Tanumoy Mandal", "Subhadip Mitra", "Cyrin Neeraj", "Mihir Rawat"], "title": "Tagging fully hadronic exotic decays of the vectorlike $\\mathbf{B}$ quark using a graph neural network", "categories": ["hep-ph", "cs.LG", "hep-ex"], "comment": "13 pages, 10 figures, 3 tables", "summary": "Following up on our earlier study in [J. Bardhan et al., Machine\nlearning-enhanced search for a vectorlike singlet B quark decaying to a singlet\nscalar or pseudoscalar, Phys. Rev. D 107 (2023) 115001; arXiv:2212.02442], we\ninvestigate the LHC prospects of pair-produced vectorlike $B$ quarks decaying\nexotically to a new gauge-singlet (pseudo)scalar field $\\Phi$ and a $b$ quark.\nAfter the electroweak symmetry breaking, the $\\Phi$ decays predominantly to\n$gg/bb$ final states, leading to a fully hadronic $2b+4j$ or $6b$ signature.\nBecause of the large Standard Model background and the lack of leptonic\nhandles, it is a difficult channel to probe. To overcome the challenge, we\nemploy a hybrid deep learning model containing a graph neural network followed\nby a deep neural network. We estimate that such a state-of-the-art deep\nlearning analysis pipeline can lead to a performance comparable to that in the\nsemi-leptonic mode, taking the discovery (exclusion) reach up to about\n$M_B=1.8\\:(2.4)$~TeV at HL-LHC when $B$ decays fully exotically, i.e., BR$(B\n\\to b\\Phi) = 100\\%$.", "AI": {"tldr": "A hybrid deep learning model is used to probe exotic decays of vectorlike B quarks at the LHC, achieving significant reach in mass sensitivity.", "motivation": "The study aims to overcome challenges in probing exotic decays of vectorlike B quarks due to large Standard Model backgrounds and lack of leptonic handles.", "method": "A hybrid deep learning model combining a graph neural network and a deep neural network is employed to analyze fully hadronic final states.", "result": "The model achieves discovery (exclusion) reach up to 1.8 (2.4) TeV for B quark mass at HL-LHC.", "conclusion": "The hybrid deep learning approach effectively enhances sensitivity to exotic B quark decays, matching performance in semi-leptonic modes."}}
{"id": "2503.13179", "pdf": "https://arxiv.org/pdf/2503.13179", "abs": "https://arxiv.org/abs/2503.13179", "authors": ["Yi Zhang", "Ruonan Lin", "Ang Ping"], "title": "A super-resolution reconstruction method for lightweight building images based on an expanding feature modulation network", "categories": ["cs.CV"], "comment": null, "summary": "This study proposes a lightweight method for building image super-resolution\nusing a Dilated Contextual Feature Modulation Network (DCFMN). The process\nincludes obtaining high-resolution images, down-sampling them to\nlow-resolution, enhancing the low-resolution images, constructing and training\na lightweight network model, and generating super-resolution outputs. To\naddress challenges such as regular textures and long-range dependencies in\nbuilding images, the DCFMN integrates an expansion separable modulation unit\nand a local feature enhancement module. The former employs multiple expansion\nconvolutions equivalent to a large kernel to efficiently aggregate multi-scale\nfeatures while leveraging a simple attention mechanism for adaptivity. The\nlatter encodes local features, mixes channel information, and ensures no\nadditional computational burden during inference through reparameterization.\nThis approach effectively resolves the limitations of existing lightweight\nsuper-resolution networks in modeling long-range dependencies, achieving\naccurate and efficient global feature modeling without increasing computational\ncosts, and significantly improving both reconstruction quality and lightweight\nefficiency for building image super-resolution models.", "AI": {"tldr": "A lightweight method for building image super-resolution using a Dilated Contextual Feature Modulation Network (DCFMN) is proposed, addressing challenges like long-range dependencies and improving efficiency without extra computational costs.", "motivation": "To overcome limitations of existing lightweight super-resolution networks in modeling long-range dependencies and enhancing reconstruction quality for building images.", "method": "The DCFMN integrates an expansion separable modulation unit (for multi-scale feature aggregation) and a local feature enhancement module (for channel mixing and reparameterization).", "result": "The method achieves accurate global feature modeling, improves reconstruction quality, and maintains lightweight efficiency without added computational costs.", "conclusion": "DCFMN effectively resolves challenges in building image super-resolution, offering a balance between accuracy and computational efficiency."}}
{"id": "2501.19047", "pdf": "https://arxiv.org/pdf/2501.19047", "abs": "https://arxiv.org/abs/2501.19047", "authors": ["Maja Pavlovic"], "title": "Understanding Model Calibration -- A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)", "categories": ["stat.ME", "cs.AI", "cs.CV", "cs.LG", "stat.ML"], "comment": "https://openreview.net/forum?id=BxBeCjQd2y", "summary": "To be considered reliable, a model must be calibrated so that its confidence\nin each decision closely reflects its true outcome. In this blogpost we'll take\na look at the most commonly used definition for calibration and then dive into\na frequently used evaluation measure for model calibration. We'll then cover\nsome of the drawbacks of this measure and how these surfaced the need for\nadditional notions of calibration, which require their own new evaluation\nmeasures. This post is not intended to be an in-depth dissection of all works\non calibration, nor does it focus on how to calibrate models. Instead, it is\nmeant to provide a gentle introduction to the different notions and their\nevaluation measures as well as to re-highlight some issues with a measure that\nis still widely used to evaluate calibration.", "AI": {"tldr": "A gentle introduction to model calibration, its evaluation measures, and the need for new notions due to drawbacks in existing measures.", "motivation": "To highlight the importance of model calibration and introduce different notions and evaluation measures, while pointing out issues with widely used measures.", "method": "Discusses common definitions of calibration, evaluation measures, and their drawbacks, leading to the introduction of new notions.", "result": "Identifies limitations in current calibration evaluation measures and introduces the need for new ones.", "conclusion": "The post serves as an introductory guide to calibration notions and measures, emphasizing the flaws in existing evaluation methods."}}
{"id": "2505.07792", "pdf": "https://arxiv.org/pdf/2505.07792", "abs": "https://arxiv.org/abs/2505.07792", "authors": ["Francesco Mori", "Francesca Mignacco"], "title": "Analytic theory of dropout regularization", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG"], "comment": "17 pages, 8 figures", "summary": "Dropout is a regularization technique widely used in training artificial\nneural networks to mitigate overfitting. It consists of dynamically\ndeactivating subsets of the network during training to promote more robust\nrepresentations. Despite its widespread adoption, dropout probabilities are\noften selected heuristically, and theoretical explanations of its success\nremain sparse. Here, we analytically study dropout in two-layer neural networks\ntrained with online stochastic gradient descent. In the high-dimensional limit,\nwe derive a set of ordinary differential equations that fully characterize the\nevolution of the network during training and capture the effects of dropout. We\nobtain a number of exact results describing the generalization error and the\noptimal dropout probability at short, intermediate, and long training times.\nOur analysis shows that dropout reduces detrimental correlations between hidden\nnodes, mitigates the impact of label noise, and that the optimal dropout\nprobability increases with the level of noise in the data. Our results are\nvalidated by extensive numerical simulations.", "AI": {"tldr": "The paper analytically studies dropout in two-layer neural networks, deriving ODEs to characterize its effects, and finds optimal dropout probabilities for different training phases.", "motivation": "Despite dropout's widespread use, its theoretical underpinnings and optimal dropout probabilities are not well understood.", "method": "The study uses analytical methods to derive ordinary differential equations (ODEs) in the high-dimensional limit, describing dropout's impact on training dynamics.", "result": "Dropout reduces harmful correlations between nodes, mitigates label noise effects, and optimal dropout probability increases with data noise.", "conclusion": "The findings provide theoretical insights into dropout's effectiveness and guidelines for selecting dropout probabilities, validated by simulations."}}
{"id": "2503.13859", "pdf": "https://arxiv.org/pdf/2503.13859", "abs": "https://arxiv.org/abs/2503.13859", "authors": ["Jinseok Bae", "Inwoo Hwang", "Young Yoon Lee", "Ziyu Guo", "Joseph Liu", "Yizhak Ben-Shabat", "Young Min Kim", "Mubbasir Kapadia"], "title": "Less is More: Improving Motion Diffusion Models with Sparse Keyframes", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in motion diffusion models have led to remarkable progress in\ndiverse motion generation tasks, including text-to-motion synthesis. However,\nexisting approaches represent motions as dense frame sequences, requiring the\nmodel to process redundant or less informative frames. The processing of dense\nanimation frames imposes significant training complexity, especially when\nlearning intricate distributions of large motion datasets even with modern\nneural architectures. This severely limits the performance of generative motion\nmodels for downstream tasks. Inspired by professional animators who mainly\nfocus on sparse keyframes, we propose a novel diffusion framework explicitly\ndesigned around sparse and geometrically meaningful keyframes. Our method\nreduces computation by masking non-keyframes and efficiently interpolating\nmissing frames. We dynamically refine the keyframe mask during inference to\nprioritize informative frames in later diffusion steps. Extensive experiments\nshow that our approach consistently outperforms state-of-the-art methods in\ntext alignment and motion realism, while also effectively maintaining high\nperformance at significantly fewer diffusion steps. We further validate the\nrobustness of our framework by using it as a generative prior and adapting it\nto different downstream tasks.", "AI": {"tldr": "A novel diffusion framework using sparse keyframes improves motion generation efficiency and performance over dense frame methods.", "motivation": "Existing motion diffusion models process dense frame sequences, which are computationally intensive and inefficient due to redundant frames.", "method": "The proposed framework focuses on sparse, geometrically meaningful keyframes, masks non-keyframes, and dynamically refines the keyframe mask during inference.", "result": "Outperforms state-of-the-art methods in text alignment and motion realism with fewer diffusion steps.", "conclusion": "The sparse keyframe approach enhances efficiency and performance, proving robust for downstream tasks."}}
{"id": "2502.00302", "pdf": "https://arxiv.org/pdf/2502.00302", "abs": "https://arxiv.org/abs/2502.00302", "authors": ["Yixuan He", "Aaron Sandel", "David Wipf", "Mihai Cucuringu", "John Mitani", "Gesine Reinert"], "title": "Learning to Fuse Temporal Proximity Networks: A Case Study in Chimpanzee Social Interactions", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC", "math.ST", "stat.TH"], "comment": null, "summary": "How can we identify groups of primate individuals which could be conjectured\nto drive social structure? To address this question, one of us has collected a\ntime series of data for social interactions between chimpanzees. Here we use a\nnetwork representation, leading to the task of combining these data into a time\nseries of a single weighted network per time stamp, where different proximities\nshould be given different weights reflecting their relative importance. We\noptimize these proximity-type weights in a principled way, using an innovative\nloss function which rewards structural consistency across time. The approach is\nempirically validated by carefully designed synthetic data. Using statistical\ntests, we provide a way of identifying groups of individuals that stay related\nfor a significant length of time. Applying the approach to the chimpanzee data\nset, we detect cliques in the animal social network time series, which can be\nvalidated by real-world intuition from prior research and qualitative\nobservations by chimpanzee experts.", "AI": {"tldr": "The paper proposes a method to identify primate social groups by analyzing time-series interaction data using weighted networks and optimizing proximity weights for structural consistency.", "motivation": "To understand how primate social structures are driven by specific groups of individuals, using chimpanzee interaction data as a case study.", "method": "Uses a network representation of social interactions, optimizes proximity-type weights with a novel loss function for structural consistency, and validates with synthetic data.", "result": "Identifies stable groups of chimpanzees over time, validated by synthetic data and expert intuition.", "conclusion": "The approach effectively detects meaningful social cliques in primate networks, supported by empirical and qualitative validation."}}
{"id": "2505.07801", "pdf": "https://arxiv.org/pdf/2505.07801", "abs": "https://arxiv.org/abs/2505.07801", "authors": ["Bernardo P. Ferreira", "Miguel A. Bessa"], "title": "Automatically Differentiable Model Updating (ADiMU): conventional, hybrid, and neural network material model discovery including history-dependency", "categories": ["math.NA", "cs.LG", "cs.NA", "physics.comp-ph"], "comment": "77 pages, 50 figures", "summary": "We introduce the first Automatically Differentiable Model Updating (ADiMU)\nframework that finds any history-dependent material model from full-field\ndisplacement and global force data (global, indirect discovery) or from\nstrain-stress data (local, direct discovery). We show that ADiMU can update\nconventional (physics-based), neural network (data-driven), and hybrid material\nmodels. Moreover, this framework requires no fine-tuning of hyperparameters or\nadditional quantities beyond those inherent to the user-selected material model\narchitecture and optimizer. The robustness and versatility of ADiMU is\nextensively exemplified by updating different models spanning tens to millions\nof parameters, in both local and global discovery settings. Relying on fully\ndifferentiable code, the algorithmic implementation leverages vectorizing maps\nthat enable history-dependent automatic differentiation via efficient batched\nexecution of shared computation graphs. This contribution also aims to\nfacilitate the integration, evaluation and application of future material model\narchitectures by openly supporting the research community. Therefore, ADiMU is\nreleased as an open-source computational tool, integrated into a carefully\ndesigned and documented software named HookeAI.", "AI": {"tldr": "ADiMU is a framework for discovering history-dependent material models from displacement/force or strain-stress data, supporting physics-based, neural network, and hybrid models without hyperparameter tuning.", "motivation": "To enable automatic discovery of material models from data, eliminating the need for manual tuning and supporting diverse model types.", "method": "Uses a fully differentiable framework with vectorizing maps for efficient batched execution and automatic differentiation.", "result": "Demonstrated robustness in updating models with parameters ranging from tens to millions, in both local and global discovery settings.", "conclusion": "ADiMU is released as open-source (HookeAI) to support future material model research and integration."}}
{"id": "2503.13903", "pdf": "https://arxiv.org/pdf/2503.13903", "abs": "https://arxiv.org/abs/2503.13903", "authors": ["Qiang Qi", "Xiao Wang"], "title": "TGBFormer: Transformer-GraphFormer Blender Network for Video Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by AAAI2025", "summary": "Video object detection has made significant progress in recent years thanks\nto convolutional neural networks (CNNs) and vision transformers (ViTs).\nTypically, CNNs excel at capturing local features but struggle to model global\nrepresentations. Conversely, ViTs are adept at capturing long-range global\nfeatures but face challenges in representing local feature details.\nOff-the-shelf video object detection methods solely rely on CNNs or ViTs to\nconduct feature aggregation, which hampers their capability to simultaneously\nleverage global and local information, thereby resulting in limited detection\nperformance. In this paper, we propose a Transformer-GraphFormer Blender\nNetwork (TGBFormer) for video object detection, with three key technical\nimprovements to fully exploit the advantages of transformers and graph\nconvolutional networks while compensating for their limitations. First, we\ndevelop a spatial-temporal transformer module to aggregate global contextual\ninformation, constituting global representations with long-range feature\ndependencies. Second, we introduce a spatial-temporal GraphFormer module that\nutilizes local spatial and temporal relationships to aggregate features,\ngenerating new local representations that are complementary to the transformer\noutputs. Third, we design a global-local feature blender module to adaptively\ncouple transformer-based global representations and GraphFormer-based local\nrepresentations. Extensive experiments demonstrate that our TGBFormer\nestablishes new state-of-the-art results on the ImageNet VID dataset.\nParticularly, our TGBFormer achieves 86.5% mAP while running at around 41.0 FPS\non a single Tesla A100 GPU.", "AI": {"tldr": "The paper proposes TGBFormer, a network blending transformers and GraphFormer for video object detection, improving global and local feature aggregation.", "motivation": "Existing methods rely solely on CNNs or ViTs, limiting their ability to leverage both global and local features, which hampers detection performance.", "method": "TGBFormer combines a spatial-temporal transformer for global context, a GraphFormer for local relationships, and a blender module to integrate both.", "result": "TGBFormer achieves 86.5% mAP on ImageNet VID at 41.0 FPS, setting a new state-of-the-art.", "conclusion": "The proposed TGBFormer effectively combines global and local features, outperforming existing methods in video object detection."}}
{"id": "2502.00850", "pdf": "https://arxiv.org/pdf/2502.00850", "abs": "https://arxiv.org/abs/2502.00850", "authors": ["Chi Zhou", "Wang Luo", "Haoran Li", "Congying Han", "Tiande Guo", "Zicheng Zhang"], "title": "Dual Alignment Maximin Optimization for Offline Model-based RL", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline reinforcement learning agents face significant deployment challenges\ndue to the synthetic-to-real distribution mismatch. While most prior research\nhas focused on improving the fidelity of synthetic sampling and incorporating\noff-policy mechanisms, the directly integrated paradigm often fails to ensure\nconsistent policy behavior in biased models and underlying environmental\ndynamics, which inherently arise from discrepancies between behavior and\nlearning policies. In this paper, we first shift the focus from model\nreliability to policy discrepancies while optimizing for expected returns, and\nthen self-consistently incorporate synthetic data, deriving a novel\nactor-critic paradigm, Dual Alignment Maximin Optimization (DAMO). It is a\nunified framework to ensure both model-environment policy consistency and\nsynthetic and offline data compatibility. The inner minimization performs dual\nconservative value estimation, aligning policies and trajectories to avoid\nout-of-distribution states and actions, while the outer maximization ensures\nthat policy improvements remain consistent with inner value estimates.\nEmpirical evaluations demonstrate that DAMO effectively ensures model and\npolicy alignments, achieving competitive performance across diverse benchmark\ntasks.", "AI": {"tldr": "DAMO is a novel actor-critic framework addressing offline RL challenges by aligning policies and trajectories while ensuring synthetic and offline data compatibility.", "motivation": "Addressing synthetic-to-real distribution mismatch and policy discrepancies in offline RL by focusing on policy consistency and data compatibility.", "method": "Proposes Dual Alignment Maximin Optimization (DAMO), combining inner minimization for dual conservative value estimation and outer maximization for policy improvement.", "result": "DAMO ensures model-policy alignment and achieves competitive performance across benchmark tasks.", "conclusion": "DAMO effectively addresses offline RL challenges by unifying policy and data alignment, demonstrating robust performance."}}
{"id": "2010.00788", "pdf": "https://arxiv.org/pdf/2010.00788", "abs": "https://arxiv.org/abs/2010.00788", "authors": ["Santiago Gonzalez", "Risto Miikkulainen"], "title": "Effective Regularization Through Loss-Function Metalearning", "categories": ["cs.LG", "cs.NE", "stat.ML"], "comment": null, "summary": "Evolutionary computation can be used to optimize several different aspects of\nneural network architectures. For instance, the TaylorGLO method discovers\nnovel, customized loss functions, resulting in improved performance, faster\ntraining, and improved data utilization. A likely reason is that such functions\ndiscourage overfitting, leading to effective regularization. This paper\ndemonstrates theoretically that this is indeed the case for TaylorGLO. Learning\nrule decomposition reveals that evolved loss functions balance two factors: the\npull toward zero error, and a push away from it to avoid overfitting. This is a\ngeneral principle that may be used to understand other regularization\ntechniques as well (as demonstrated in this paper for label smoothing). The\ntheoretical analysis leads to a constraint that can be utilized to find more\neffective loss functions in practice; the mechanism also results in networks\nthat are more robust (as demonstrated in this paper with adversarial inputs).\nThe analysis in this paper thus constitutes a first step towards understanding\nregularization, and demonstrates the power of evolutionary neural architecture\nsearch in general.", "AI": {"tldr": "TaylorGLO uses evolutionary computation to optimize neural network loss functions, improving performance, training speed, and data use by balancing error reduction and overfitting avoidance.", "motivation": "To theoretically validate that evolved loss functions in TaylorGLO prevent overfitting and improve regularization, and to generalize this principle to other techniques like label smoothing.", "method": "Theoretical analysis of TaylorGLO's evolved loss functions, decomposing learning rules to reveal a balance between minimizing error and avoiding overfitting.", "result": "Evolved loss functions effectively regularize networks, leading to better performance and robustness against adversarial inputs.", "conclusion": "The study provides insights into regularization and highlights the potential of evolutionary neural architecture search."}}
{"id": "2503.15816", "pdf": "https://arxiv.org/pdf/2503.15816", "abs": "https://arxiv.org/abs/2503.15816", "authors": ["Abduljaleel Adejumo", "Faegheh Yeganli", "Clifford Broni-bediako", "Aoran Xiao", "Naoto Yokoya", "Mennatullah Siam"], "title": "A Vision Centric Remote Sensing Benchmark", "categories": ["cs.CV", "F.2.2; I.2.7"], "comment": "Eval-FoMo2 Workshop in CVPR 2025", "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable success in\nvision-language tasks but their remote sensing (RS) counterpart are relatively\nunder explored. Unlike natural images, RS imagery presents unique challenges\nthat current MLLMs struggle to handle, particularly in visual grounding and\nspatial reasoning. This study investigates the limitations of CLIP-based MLLMs\nin RS, highlighting their failure to differentiate visually distinct yet\nsemantically similar RS images. To address this, we introduce a remote sensing\nmultimodal visual patterns (RSMMVP) benchmark. It is designed to evaluate MLLMs\nin RS tasks by identifying the CLIP-blind pairs, where CLIP-based models\nincorrectly assign high similarity scores to visually distinct RS images.\nThrough a visual question answering (VQA) evaluation, we analyze the\nperformance of state-of-the-art MLLMs, revealing significant limitations in RS\nspecific representation learning. The results provide valuable insights into\nthe weaknesses of CLIP-based visual encoding and offer a foundation for future\nresearch to develop more effective MLLMs tailored for remote sensing\napplications.", "AI": {"tldr": "The paper explores the limitations of CLIP-based MLLMs in remote sensing (RS) tasks, introduces the RSMMVP benchmark to evaluate these models, and highlights their struggles with visual grounding and spatial reasoning in RS imagery.", "motivation": "Current MLLMs excel in vision-language tasks but underperform in RS due to unique challenges like visual grounding and spatial reasoning. This study aims to address these gaps.", "method": "The authors introduce the RSMMVP benchmark to identify CLIP-blind pairs and evaluate MLLMs using visual question answering (VQA) in RS tasks.", "result": "The study reveals significant limitations of CLIP-based MLLMs in RS-specific representation learning, particularly in differentiating visually distinct yet semantically similar images.", "conclusion": "The findings highlight weaknesses in CLIP-based visual encoding for RS and provide a foundation for developing more effective MLLMs tailored to remote sensing."}}
{"id": "2502.02456", "pdf": "https://arxiv.org/pdf/2502.02456", "abs": "https://arxiv.org/abs/2502.02456", "authors": ["Christopher J. MacLellan"], "title": "Model Human Learners: Computational Models to Guide Instructional Design", "categories": ["cs.HC", "cs.AI", "cs.SC"], "comment": "Published at CogSci 2025; 6 pages, 6 figures, 1 table", "summary": "Instructional designers face an overwhelming array of design choices, making\nit challenging to identify the most effective interventions. To address this\nissue, I propose the concept of a Model Human Learner, a unified computational\nmodel of learning that can aid designers in evaluating candidate interventions.\nThis paper presents the first successful demonstration of this concept, showing\nthat a computational model can accurately predict the outcomes of two human A/B\nexperiments -- one testing a problem sequencing intervention and the other\ntesting an item design intervention. It also demonstrates that such a model can\ngenerate learning curves without requiring human data and provide theoretical\ninsights into why an instructional intervention is effective. These findings\nlay the groundwork for future Model Human Learners that integrate cognitive and\nlearning theories to support instructional design across diverse tasks and\ninterventions.", "AI": {"tldr": "A Model Human Learner is introduced to help instructional designers evaluate interventions by predicting outcomes and generating insights without human data.", "motivation": "Instructional designers struggle with too many choices; a unified computational model could streamline decision-making.", "method": "The paper demonstrates a computational model predicting outcomes of human A/B experiments and generating learning curves.", "result": "The model accurately predicted intervention outcomes and provided theoretical insights, validating its potential.", "conclusion": "The Model Human Learner concept shows promise for future integration of cognitive theories to aid instructional design."}}
{"id": "2101.09306", "pdf": "https://arxiv.org/pdf/2101.09306", "abs": "https://arxiv.org/abs/2101.09306", "authors": ["Brendon G. Anderson", "Ziye Ma", "Jingqi Li", "Somayeh Sojoudi"], "title": "Towards Optimal Branching of Linear and Semidefinite Relaxations for Neural Network Robustness Certification", "categories": ["cs.LG", "math.OC"], "comment": "Accepted for publication in the Journal of Machine Learning Research\n  (JMLR). This is an extension of our IEEE CDC 2020 conference paper\n  arXiv:2004.00570", "summary": "In this paper, we study certifying the robustness of ReLU neural networks\nagainst adversarial input perturbations. To diminish the relaxation error\nsuffered by the popular linear programming (LP) and semidefinite programming\n(SDP) certification methods, we take a branch-and-bound approach to propose\npartitioning the input uncertainty set and solving the relaxations on each part\nseparately. We show that this approach reduces relaxation error, and that the\nerror is eliminated entirely upon performing an LP relaxation with a partition\nintelligently designed to exploit the nature of the ReLU activations. To scale\nthis approach to large networks, we consider using a coarser partition whereby\nthe number of parts in the partition is reduced. We prove that computing such a\ncoarse partition that directly minimizes the LP relaxation error is NP-hard. By\ninstead minimizing the worst-case LP relaxation error, we develop a closed-form\nbranching scheme in the single-hidden layer case. We extend the analysis to the\nSDP, where the feasible set geometry is exploited to design a branching scheme\nthat minimizes the worst-case SDP relaxation error. Experiments on MNIST,\nCIFAR-10, and Wisconsin breast cancer diagnosis classifiers demonstrate\nsignificant increases in the percentages of test samples certified. By\nindependently increasing the input size and the number of layers, we\nempirically illustrate under which regimes the branched LP and branched SDP are\nbest applied. Finally, we extend our LP branching method into a multi-layer\nbranching heuristic, which attains comparable performance to prior\nstate-of-the-art heuristics on large-scale, deep neural network certification\nbenchmarks.", "AI": {"tldr": "A branch-and-bound approach is proposed to certify ReLU neural network robustness against adversarial inputs, reducing relaxation errors in LP and SDP methods.", "motivation": "To address the relaxation errors in existing LP and SDP certification methods for ReLU networks.", "method": "Partition the input uncertainty set and solve relaxations on each part, with intelligent partitioning for LP and SDP.", "result": "Significant increases in certified test samples on MNIST, CIFAR-10, and Wisconsin datasets.", "conclusion": "The branched LP and SDP methods are effective, with a multi-layer heuristic matching state-of-the-art performance."}}
{"id": "2503.15831", "pdf": "https://arxiv.org/pdf/2503.15831", "abs": "https://arxiv.org/abs/2503.15831", "authors": ["Zihao Zhang", "Haoran Chen", "Haoyu Zhao", "Guansong Lu", "Yanwei Fu", "Hang Xu", "Zuxuan Wu"], "title": "EDEN: Enhanced Diffusion for High-quality Large-motion Video Frame Interpolation", "categories": ["cs.CV"], "comment": "CVPR2025", "summary": "Handling complex or nonlinear motion patterns has long posed challenges for\nvideo frame interpolation. Although recent advances in diffusion-based methods\noffer improvements over traditional optical flow-based approaches, they still\nstruggle to generate sharp, temporally consistent frames in scenarios with\nlarge motion. To address this limitation, we introduce EDEN, an Enhanced\nDiffusion for high-quality large-motion vidEo frame iNterpolation. Our approach\nfirst utilizes a transformer-based tokenizer to produce refined latent\nrepresentations of the intermediate frames for diffusion models. We then\nenhance the diffusion transformer with temporal attention across the process\nand incorporate a start-end frame difference embedding to guide the generation\nof dynamic motion. Extensive experiments demonstrate that EDEN achieves\nstate-of-the-art results across popular benchmarks, including nearly a 10%\nLPIPS reduction on DAVIS and SNU-FILM, and an 8% improvement on DAIN-HD.", "AI": {"tldr": "EDEN introduces an enhanced diffusion method for high-quality video frame interpolation, outperforming existing techniques in handling large motion.", "motivation": "Addressing the challenge of generating sharp, temporally consistent frames in scenarios with large motion, where current diffusion-based methods fall short.", "method": "Uses a transformer-based tokenizer for refined latent representations, enhances the diffusion transformer with temporal attention, and incorporates start-end frame difference embedding.", "result": "Achieves state-of-the-art results, including a 10% LPIPS reduction on DAVIS and SNU-FILM, and an 8% improvement on DAIN-HD.", "conclusion": "EDEN effectively handles large-motion video frame interpolation, setting new benchmarks in performance."}}
{"id": "2502.05485", "pdf": "https://arxiv.org/pdf/2502.05485", "abs": "https://arxiv.org/abs/2502.05485", "authors": ["Yi Li", "Yuquan Deng", "Jesse Zhang", "Joel Jang", "Marius Memmel", "Raymond Yu", "Caelan Reed Garrett", "Fabio Ramos", "Dieter Fox", "Anqi Li", "Abhishek Gupta", "Ankit Goyal"], "title": "HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "update related work and results on VQA benchmarks", "summary": "Large foundation models have shown strong open-world generalization to\ncomplex problems in vision and language, but similar levels of generalization\nhave yet to be achieved in robotics. One fundamental challenge is the lack of\nrobotic data, which are typically obtained through expensive on-robot\noperation. A promising remedy is to leverage cheaper, off-domain data such as\naction-free videos, hand-drawn sketches or simulation data. In this work, we\nposit that hierarchical vision-language-action (VLA) models can be more\neffective in utilizing off-domain data than standard monolithic VLA models that\ndirectly finetune vision-language models (VLMs) to predict actions. In\nparticular, we study a class of hierarchical VLA models, where the high-level\nVLM is finetuned to produce a coarse 2D path indicating the desired robot\nend-effector trajectory given an RGB image and a task description. The\nintermediate 2D path prediction is then served as guidance to the low-level,\n3D-aware control policy capable of precise manipulation. Doing so alleviates\nthe high-level VLM from fine-grained action prediction, while reducing the\nlow-level policy's burden on complex task-level reasoning. We show that, with\nthe hierarchical design, the high-level VLM can transfer across significant\ndomain gaps between the off-domain finetuning data and real-robot testing\nscenarios, including differences on embodiments, dynamics, visual appearances\nand task semantics, etc. In the real-robot experiments, we observe an average\nof 20% improvement in success rate across seven different axes of\ngeneralization over OpenVLA, representing a 50% relative gain. Visual results,\ncode, and dataset are provided at: https://hamster-robot.github.io/", "AI": {"tldr": "Hierarchical VLA models improve robotic generalization by leveraging off-domain data, achieving a 20% success rate boost over monolithic models.", "motivation": "Address the lack of robotic data by utilizing cheaper, off-domain sources like videos or sketches for better generalization.", "method": "Hierarchical VLA models split tasks: high-level VLM predicts 2D paths, while low-level policy handles precise 3D control.", "result": "20% higher success rate in real-robot tests across diverse generalization axes compared to OpenVLA.", "conclusion": "Hierarchical VLA models effectively bridge domain gaps, enhancing robotic task performance."}}
{"id": "2105.09232", "pdf": "https://arxiv.org/pdf/2105.09232", "abs": "https://arxiv.org/abs/2105.09232", "authors": ["Lin Fan", "Peter W. Glynn"], "title": "Diffusion Approximations for Thompson Sampling", "categories": ["cs.LG", "math.ST", "stat.TH", "62B15, 60J70"], "comment": null, "summary": "We study the behavior of Thompson sampling from the perspective of weak\nconvergence. In the regime with small $\\gamma > 0$, where the gaps between arm\nmeans scale as $\\sqrt{\\gamma}$ and over time horizons that scale as $1/\\gamma$,\nwe show that the dynamics of Thompson sampling evolve according to discrete\nversions of SDE's and stochastic ODE's. As $\\gamma \\downarrow 0$, we show that\nthe dynamics converge weakly to solutions of the corresponding SDE's and\nstochastic ODE's. Our weak convergence theory is developed from first\nprinciples using the Continuous Mapping Theorem, and can be easily adapted to\nanalyze other sampling-based bandit algorithms. In this regime, we also show\nthat the weak limits of the dynamics of many sampling-based algorithms --\nincluding Thompson sampling designed for single-parameter exponential family\nrewards, and algorithms using bootstrap-based sampling to balance exploration\nand exploitation -- coincide with those of Gaussian Thompson sampling.\nMoreover, in this regime, these algorithms are generally robust to model\nmis-specification.", "AI": {"tldr": "The paper analyzes Thompson sampling's behavior using weak convergence, showing its dynamics evolve like discrete SDEs/ODEs and converge to continuous versions as a parameter \u03b3 approaches zero.", "motivation": "To understand Thompson sampling's dynamics in small-\u03b3 regimes and generalize findings to other sampling-based bandit algorithms.", "method": "Develops weak convergence theory from first principles using the Continuous Mapping Theorem, analyzing dynamics in regimes with small \u03b3.", "result": "Shows Thompson sampling's dynamics converge to SDE/ODE solutions, and many sampling-based algorithms share the same weak limits as Gaussian Thompson sampling.", "conclusion": "Sampling-based algorithms, including Thompson sampling, are robust to model mis-specification in the small-\u03b3 regime."}}
{"id": "2503.15970", "pdf": "https://arxiv.org/pdf/2503.15970", "abs": "https://arxiv.org/abs/2503.15970", "authors": ["JunGyu Lee", "Kunyoung Lee", "Haesol Park", "Ig-Jae Kim", "Gi Pyo Nam"], "title": "V-NAW: Video-based Noise-aware Adaptive Weighting for Facial Expression Recognition", "categories": ["cs.CV"], "comment": "Accepted by CVPRW2025", "summary": "Facial Expression Recognition (FER) plays a crucial role in human affective\nanalysis and has been widely applied in computer vision tasks such as\nhuman-computer interaction and psychological assessment. The 8th Affective\nBehavior Analysis in-the-Wild (ABAW) Challenge aims to assess human emotions\nusing the video-based Aff-Wild2 dataset. This challenge includes various tasks,\nincluding the video-based EXPR recognition track, which is our primary focus.\nIn this paper, we demonstrate that addressing label ambiguity and class\nimbalance, which are known to cause performance degradation, can lead to\nmeaningful performance improvements. Specifically, we propose Video-based\nNoise-aware Adaptive Weighting (V-NAW), which adaptively assigns importance to\neach frame in a clip to address label ambiguity and effectively capture\ntemporal variations in facial expressions. Furthermore, we introduce a simple\nand effective augmentation strategy to reduce redundancy between consecutive\nframes, which is a primary cause of overfitting. Through extensive experiments,\nwe validate the effectiveness of our approach, demonstrating significant\nimprovements in video-based FER performance.", "AI": {"tldr": "The paper proposes V-NAW to address label ambiguity and class imbalance in video-based FER, along with an augmentation strategy to reduce redundancy, achieving significant performance improvements.", "motivation": "Label ambiguity and class imbalance in video-based FER degrade performance, necessitating solutions to improve accuracy.", "method": "Proposes Video-based Noise-aware Adaptive Weighting (V-NAW) for adaptive frame importance and a redundancy-reducing augmentation strategy.", "result": "Extensive experiments show significant improvements in video-based FER performance.", "conclusion": "The proposed methods effectively address key challenges in FER, enhancing performance and robustness."}}
{"id": "2502.06146", "pdf": "https://arxiv.org/pdf/2502.06146", "abs": "https://arxiv.org/abs/2502.06146", "authors": ["Annie Feng", "Nishanth Kumar", "Tomas Lozano-Perez", "Leslie Pack-Kaelbling"], "title": "Guided Exploration for Efficient Relational Model Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Efficient exploration is critical for learning relational models in\nlarge-scale environments with complex, long-horizon tasks. Random exploration\nmethods often collect redundant or irrelevant data, limiting their ability to\nlearn accurate relational models of the environment. Goal-literal babbling\n(GLIB) improves upon random exploration by setting and planning to novel goals,\nbut its reliance on random actions and random novel goal selection limits its\nscalability to larger domains. In this work, we identify the principles\nunderlying efficient exploration in relational domains: (1) operator\ninitialization with demonstrations that cover the distinct lifted effects\nnecessary for planning and (2) refining preconditions to collect maximally\ninformative transitions by selecting informative goal-action pairs and\nexecuting plans to them. To demonstrate these principles, we introduce\nBaking-Large, a challenging domain with extensive state-action spaces and\nlong-horizon tasks. We evaluate methods using oracle-driven demonstrations for\noperator initialization and precondition-targeting guidance to efficiently\ngather critical transitions. Experiments show that both the oracle\ndemonstrations and precondition-targeting oracle guidance significantly improve\nsample efficiency and generalization, paving the way for future methods to use\nthese principles to efficiently learn accurate relational models in complex\ndomains.", "AI": {"tldr": "The paper proposes efficient exploration principles for learning relational models in complex environments, introducing Baking-Large as a test domain and showing improved sample efficiency with oracle demonstrations and precondition-targeting guidance.", "motivation": "Random exploration methods are inefficient for learning relational models in large-scale environments, and goal-literal babbling (GLIB) lacks scalability. The paper aims to identify and demonstrate principles for efficient exploration.", "method": "The authors propose two principles: operator initialization with demonstrations covering lifted effects and refining preconditions by selecting informative goal-action pairs. They test these in the Baking-Large domain using oracle-driven demonstrations and precondition-targeting guidance.", "result": "Experiments show oracle demonstrations and precondition-targeting guidance significantly improve sample efficiency and generalization in learning relational models.", "conclusion": "The principles of efficient exploration demonstrated in this work can guide future methods for learning accurate relational models in complex domains."}}
{"id": "2301.12407", "pdf": "https://arxiv.org/pdf/2301.12407", "abs": "https://arxiv.org/abs/2301.12407", "authors": ["Lin Wang", "Zhichao Wang", "Ye Shi", "Sai Praneeth Karimireddy", "Xiaoying Tang"], "title": "Entropy-driven Fair and Effective Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed devices while preserving data privacy. Nonetheless, the\nheterogeneity of edge devices often leads to inconsistent performance of the\nglobally trained models, resulting in unfair outcomes among users. Existing\nfederated fairness algorithms strive to enhance fairness but often fall short\nin maintaining the overall performance of the global model, typically measured\nby the average accuracy across all clients. To address this issue, we propose a\nnovel algorithm that leverages entropy-based aggregation combined with model\nand gradient alignments to simultaneously optimize fairness and global model\nperformance. Our method employs a bi-level optimization framework, where we\nderive an analytic solution to the aggregation probability in the inner loop,\nmaking the optimization process computationally efficient. Additionally, we\nintroduce an innovative alignment update and an adaptive strategy in the outer\nloop to further balance global model's performance and fairness. Theoretical\nanalysis indicates that our approach guarantees convergence even in non-convex\nFL settings and demonstrates significant fairness improvements in generalized\nregression and strongly convex models. Empirically, our approach surpasses\nstate-of-the-art federated fairness algorithms, ensuring consistent performance\namong clients while improving the overall performance of the global model.", "AI": {"tldr": "A novel federated learning algorithm improves fairness and global model performance using entropy-based aggregation and alignment techniques.", "motivation": "Addressing unfair outcomes in federated learning due to device heterogeneity, while maintaining global model performance.", "method": "Uses entropy-based aggregation, model and gradient alignments, and a bi-level optimization framework with analytic solutions.", "result": "Theoretical convergence guarantees and empirical improvements in fairness and global model performance.", "conclusion": "The proposed algorithm outperforms existing methods in balancing fairness and performance."}}
{"id": "2503.16188", "pdf": "https://arxiv.org/pdf/2503.16188", "abs": "https://arxiv.org/abs/2503.16188", "authors": ["Ming Li", "Jike Zhong", "Shitian Zhao", "Yuxiang Lai", "Haoquan Zhang", "Wang Bill Zhu", "Kaipeng Zhang"], "title": "Think or Not Think: A Study of Explicit Thinking in Rule-Based Visual Reinforcement Fine-Tuning", "categories": ["cs.CV"], "comment": "Preprint, work in progress. Add results on adaptive-thinking and\n  response inconsistency", "summary": "This paper investigates the role of explicit thinking process in rule-based\nreinforcement fine-tuning (RFT) for MLLMs. We first propose CLS-RL for MLLM\nimage classification, using verifiable rewards for fine-tuning. Experiments\nshow CLS-RL significantly outperforms SFT and yields a cross-dataset\ngeneralization effect. We then rethink and question whether explicit thinking\nin RFT is always necessary. Challenging the convention that explicit thinking\nis crucial for the success of RFT, we introduce No-Thinking-RL, exploring RFT\nwithout thinking by introducing a simple equality accuracy reward. We evaluate\nNo-Thinking-RL on 6 diverse tasks across different model sizes and types.\nExperimental results reveal three key findings: 1). Visual perception tasks do\nnot require thinking during RFT, as No-Thinking-RL consistently outperforms or\nmatches Thinking-based RFT across model sizes. 2).} Models with limited\ncapabilities struggle to generate high-quality CoT for RFT, making\nThinking-based RFT less effective than No-Thinking-RL. 3). There are\ninconsistencies between the answers in the thinking and answer tags for some\nresponses of thinking-based RFT, which show lower accuracy than the overall\naccuracy. We hypothesize that explicit thinking before verifiable answers may\nhinder reward convergence and reduce performance. To test this hypothesis, we\npropose Think-After-Answer, which places thinking after the answer to mitigate\nthis effect for experimental verification. Lastly, we conduct a pilot study to\nexplore whether MLLMs can learn when to think during RFT, introducing an\nAdaptive-Thinking method. Experiments show that it converges to a specific\nprompt depending on model capability and task complexity, achieving comparable\nor better performance than both Thinking and No-Thinking-RL. This suggests\nMLLMs can adaptively decide to think or not based on their capabilities and\ntask complexity.", "AI": {"tldr": "The paper explores the necessity of explicit thinking in rule-based reinforcement fine-tuning (RFT) for MLLMs, introducing methods like No-Thinking-RL and Think-After-Answer, and finds that thinking isn't always required, especially in visual tasks or for limited-capability models.", "motivation": "To challenge the conventional belief that explicit thinking is crucial for RFT success in MLLMs and investigate whether thinking can be optional or adaptive.", "method": "Proposes CLS-RL for image classification, No-Thinking-RL (RFT without thinking), Think-After-Answer (thinking after the answer), and Adaptive-Thinking (learning when to think).", "result": "No-Thinking-RL outperforms thinking-based RFT in visual tasks; limited-capability models struggle with thinking; Think-After-Answer mitigates inconsistencies; Adaptive-Thinking adapts based on task and model.", "conclusion": "Explicit thinking isn't always necessary in RFT; MLLMs can adaptively decide when to think, improving performance based on task complexity and model capability."}}
{"id": "2502.07693", "pdf": "https://arxiv.org/pdf/2502.07693", "abs": "https://arxiv.org/abs/2502.07693", "authors": ["Victor Morel", "Leonardo Iwaya", "Simone Fischer-H\u00fcbner"], "title": "AI-driven Personalized Privacy Assistants: a Systematic Literature Review", "categories": ["cs.CY", "cs.AI"], "comment": "Submitted to IEEE Access", "summary": "In recent years, several personalized assistants based on AI have been\nresearched and developed to help users make privacy-related decisions. These\nAI-driven Personalized Privacy Assistants (AI-driven PPAs) can provide\nsignificant benefits for users, who might otherwise struggle with making\ndecisions about their personal data in online environments that often overload\nthem with different privacy decision requests. So far, no studies have\nsystematically investigated the emerging topic of AI-driven PPAs, classifying\ntheir underlying technologies, architecture and features, including decision\ntypes or the accuracy of their decisions. To fill this gap, we present a\nSystematic Literature Review (SLR) to map the existing solutions found in the\nscientific literature, which allows reasoning about existing approaches and\nopen challenges for this research field. We screened several hundred unique\nresearch papers over the recent years (2013-2025), constructing a\nclassification from 41 included papers. As a result, this SLR reviews several\naspects of existing research on AI-driven PPAs in terms of types of\npublications, contributions, methodological quality, and other quantitative\ninsights. Furthermore, we provide a comprehensive classification for AI-driven\nPPAs, delving into their architectural choices, system contexts, types of AI\nused, data sources, types of decisions, and control over decisions, among other\nfacets. Based on our SLR, we further underline the research gaps and challenges\nand formulate recommendations for the design and development of AI-driven PPAs\nas well as avenues for future research.", "AI": {"tldr": "A Systematic Literature Review (SLR) maps AI-driven Personalized Privacy Assistants (PPAs), classifying their technologies, architectures, and features, while identifying research gaps and future directions.", "motivation": "To address the lack of systematic investigation into AI-driven PPAs, which help users manage privacy decisions in complex online environments.", "method": "Conducted an SLR, screening hundreds of papers (2013-2025) and classifying 41 included studies to analyze AI-driven PPAs' technologies, architectures, and features.", "result": "The SLR provides a comprehensive classification of AI-driven PPAs, highlighting research gaps, challenges, and quantitative insights into existing solutions.", "conclusion": "The study underscores the need for further research on AI-driven PPAs, offering design recommendations and future research directions."}}
{"id": "2306.15907", "pdf": "https://arxiv.org/pdf/2306.15907", "abs": "https://arxiv.org/abs/2306.15907", "authors": ["Jimeng Shi", "Zeda Yin", "Rukmangadh Myana", "Khandker Ishtiaq", "Anupama John", "Jayantha Obeysekera", "Arturo Leon", "Giri Narasimhan"], "title": "Deep Learning Models for Flood Predictions in South Florida", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Simulating and predicting the water level/stage in river systems is essential\nfor flood warnings, hydraulic operations, and flood mitigations. Physics-based\ndetailed hydrological and hydraulic computational tools, such as HEC-RAS, MIKE,\nand SWMM, can be used to simulate a complete watershed and compute the water\nstage at any point in the river system. However, these physics-based models are\ncomputationally intensive, especially for large watersheds and for longer\nsimulations, since they use detailed grid representations of terrain elevation\nmaps of the entire watershed and solve complex partial differential equations\n(PDEs) for each grid cell. To overcome this problem, we train several deep\nlearning (DL) models for use as surrogate models to rapidly predict the water\nstage. A portion of the Miami River in South Florida was chosen as a case study\nfor this paper. Extensive experiments show that the performance of various DL\nmodels (MLP, RNN, CNN, LSTM, and RCNN) is significantly better than that of the\nphysics-based model, HEC-RAS, even during extreme precipitation conditions\n(i.e., tropical storms), and with speedups exceeding 500x. To predict the water\nstages more accurately, our DL models use both measured variables of the river\nsystem from the recent past and covariates for which predictions are typically\navailable for the near future.", "AI": {"tldr": "Deep learning models outperform physics-based tools like HEC-RAS in predicting river water stages, offering 500x speedups and better accuracy, even during extreme weather.", "motivation": "Physics-based models are computationally intensive for large watersheds and long simulations, necessitating faster, efficient alternatives.", "method": "Several DL models (MLP, RNN, CNN, LSTM, RCNN) were trained as surrogate models, using past river data and future covariates.", "result": "DL models significantly outperformed HEC-RAS in accuracy and speed (500x faster), even under extreme conditions like tropical storms.", "conclusion": "DL models are effective, efficient alternatives to traditional physics-based methods for water stage prediction."}}
{"id": "2504.04893", "pdf": "https://arxiv.org/pdf/2504.04893", "abs": "https://arxiv.org/abs/2504.04893", "authors": ["Justus Westerhoff", "Erblina Purelku", "Jakob Hackstein", "Jonas Loos", "Leo Pinetzki", "Lorenz Hufe"], "title": "SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPR 2025 Workshop EVAL-FoMo-2", "summary": "Typographic attacks exploit the interplay between text and visual content in\nmultimodal foundation models, causing misclassifications when misleading text\nis embedded within images. However, existing datasets are limited in size and\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\nattack images to date, containing 1,162 images across hundreds of object\ncategories and attack words. Through extensive benchmarking of Vision-Language\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\ndegrade performance, and identify that training data and model architecture\ninfluence the susceptibility to these attacks. Our findings reveal that\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\nattacks, validating their use in research. Our work provides a comprehensive\nresource and empirical insights to facilitate future research toward robust and\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\nin this paper along with the code for evaluations at\nwww.bliss.berlin/research/scam.", "AI": {"tldr": "SCAM dataset introduces 1,162 real-world typographic attack images, revealing vulnerabilities in Vision-Language Models (VLMs) and Large Vision-Language Models (LVLMs).", "motivation": "Existing datasets lack size and diversity to study typographic attacks, which exploit text-visual interplay in multimodal models.", "method": "Created SCAM dataset with diverse attack images, benchmarked VLMs, and analyzed model susceptibility based on training data and architecture.", "result": "Typographic attacks degrade model performance; LVLMs remain vulnerable due to vision encoders, but larger LLMs reduce susceptibility. Synthetic attacks mimic real-world ones.", "conclusion": "SCAM provides resources for robust multimodal AI research, with datasets and code publicly released."}}
{"id": "2502.08282", "pdf": "https://arxiv.org/pdf/2502.08282", "abs": "https://arxiv.org/abs/2502.08282", "authors": ["Vinod Kumar Chauhan", "Lei Clifton", "Gaurav Nigam", "David A. Clifton"], "title": "Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages (double column), 4 figures", "summary": "Estimating individualised treatment effect (ITE) -- that is the causal effect\nof a set of variables (also called exposures, treatments, actions, policies, or\ninterventions), referred to as \\textit{composite treatments}, on a set of\noutcome variables of interest, referred to as \\textit{composite outcomes}, for\na unit from observational data -- remains a fundamental problem in causal\ninference with applications across disciplines, such as healthcare, economics,\neducation, social science, marketing, and computer science. Previous work in\ncausal machine learning for ITE estimation is limited to simple settings, like\nsingle treatments and single outcomes. This hinders their use in complex\nreal-world scenarios; for example, consider studying the effect of different\nICU interventions, such as beta-blockers and statins for a patient admitted for\nheart surgery, on different outcomes of interest such as atrial fibrillation\nand in-hospital mortality. The limited research into composite treatments and\noutcomes is primarily due to data scarcity for all treatments and outcomes. To\naddress the above challenges, we propose a novel and innovative\nhypernetwork-based approach, called \\emph{H-Learner}, to solve ITE estimation\nunder composite treatments and composite outcomes, which tackles the data\nscarcity issue by dynamically sharing information across treatments and\noutcomes. Our empirical analysis with binary and arbitrary composite treatments\nand outcomes demonstrates the effectiveness of the proposed approach compared\nto existing methods.", "AI": {"tldr": "The paper introduces H-Learner, a hypernetwork-based method for estimating individualised treatment effects (ITE) under composite treatments and outcomes, addressing data scarcity by sharing information dynamically.", "motivation": "Existing ITE estimation methods are limited to single treatments and outcomes, hindering their application in complex real-world scenarios like healthcare.", "method": "Proposes H-Learner, a hypernetwork-based approach that dynamically shares information across treatments and outcomes to tackle data scarcity.", "result": "Empirical analysis shows H-Learner's effectiveness with binary and arbitrary composite treatments and outcomes compared to existing methods.", "conclusion": "H-Learner provides a scalable solution for ITE estimation in complex scenarios with composite treatments and outcomes."}}
{"id": "2308.12563", "pdf": "https://arxiv.org/pdf/2308.12563", "abs": "https://arxiv.org/abs/2308.12563", "authors": ["Thi Kieu Khanh Ho", "Narges Armanfard"], "title": "Contaminated Multivariate Time-Series Anomaly Detection with Spatio-Temporal Graph Conditional Diffusion Models", "categories": ["cs.LG", "eess.SP"], "comment": "Accepted to The Conference on Uncertainty in Artificial Intelligence\n  (UAI 2025)", "summary": "Mainstream unsupervised anomaly detection algorithms often excel in academic\ndatasets, yet their real-world performance is restricted due to the controlled\nexperimental conditions involving clean training data. Addressing the challenge\nof training with noise, a prevalent issue in practical anomaly detection, is\nfrequently overlooked. In a pioneering endeavor, this study delves into the\nrealm of label-level noise within sensory time-series anomaly detection (TSAD).\nThis paper presents a novel and practical end-to-end unsupervised TSAD when the\ntraining data is contaminated with anomalies. The introduced approach, called\nTSAD-C, is devoid of access to abnormality labels during the training phase.\nTSAD-C encompasses three core modules: a Decontaminator to rectify anomalies\n(aka noise) present during training, a Long-range Variable Dependency Modeling\nmodule to capture long-term intra- and inter-variable dependencies within the\ndecontaminated data that is considered as a surrogate of the pure normal data,\nand an Anomaly Scoring module to detect anomalies from all types. Our extensive\nexperiments conducted on four reliable and diverse datasets conclusively\ndemonstrate that TSAD-C surpasses existing methodologies, thus establishing a\nnew state-of-the-art in the TSAD field.", "AI": {"tldr": "TSAD-C is a novel unsupervised time-series anomaly detection method that handles noisy training data, outperforming existing methods.", "motivation": "Real-world anomaly detection often involves noisy training data, a challenge overlooked by mainstream algorithms.", "method": "TSAD-C uses a Decontaminator, Long-range Variable Dependency Modeling, and Anomaly Scoring to detect anomalies without labeled training data.", "result": "TSAD-C outperforms existing methods on four diverse datasets, setting a new state-of-the-art.", "conclusion": "TSAD-C effectively addresses noisy training data in anomaly detection, advancing the field."}}
{"id": "2504.06755", "pdf": "https://arxiv.org/pdf/2504.06755", "abs": "https://arxiv.org/abs/2504.06755", "authors": ["Li Yu", "Zhihui Li", "Yao Zhao", "Jimin Xiao", "Moncef Gabbouj"], "title": "FANeRV: Frequency Separation and Augmentation based Neural Representation for Video", "categories": ["cs.CV"], "comment": null, "summary": "Neural representations for video (NeRV) have gained considerable attention\nfor their strong performance across various video tasks. However, existing NeRV\nmethods often struggle to capture fine spatial details, resulting in vague\nreconstructions. In this paper, we present a Frequency Separation and\nAugmentation based Neural Representation for video (FANeRV), which addresses\nthese limitations with its core Wavelet Frequency Upgrade Block. This block\nexplicitly separates input frames into high and low-frequency components using\ndiscrete wavelet transform, followed by targeted enhancement using specialized\nmodules. Finally, a specially designed gated network effectively fuses these\nfrequency components for optimal reconstruction. Additionally, convolutional\nresidual enhancement blocks are integrated into the later stages of the network\nto balance parameter distribution and improve the restoration of high-frequency\ndetails. Experimental results demonstrate that FANeRV significantly improves\nreconstruction performance and excels in multiple tasks, including video\ncompression, inpainting, and interpolation, outperforming existing NeRV\nmethods.", "AI": {"tldr": "FANeRV improves video reconstruction by separating and enhancing high/low-frequency components using wavelet transforms and specialized modules, outperforming existing NeRV methods.", "motivation": "Existing NeRV methods struggle with fine spatial details, leading to vague reconstructions.", "method": "Uses Wavelet Frequency Upgrade Block for frequency separation, targeted enhancement, and gated network fusion. Integrates convolutional residual blocks for high-frequency detail restoration.", "result": "Significantly improves reconstruction and excels in tasks like video compression, inpainting, and interpolation.", "conclusion": "FANeRV addresses NeRV limitations, offering superior performance in video tasks."}}
{"id": "2502.11013", "pdf": "https://arxiv.org/pdf/2502.11013", "abs": "https://arxiv.org/abs/2502.11013", "authors": ["Zhi Sheng", "Yuan Yuan", "Yudi Zhang", "Depeng Jin", "Yong Li"], "title": "Collaborative Deterministic-Diffusion Model for Probabilistic Spatiotemporal Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate prediction of urban spatiotemporal dynamics is essential for\nenhancing urban management and decision-making. Existing spatiotemporal\nprediction models are predominantly deterministic, focusing on primary\nspatiotemporal patterns. However, those dynamics are highly complex, exhibiting\nmulti-modal distributions that are challenging for deterministic models to\ncapture. In this paper, we highlight the critical role of probabilistic\nprediction in capturing the uncertainties and complexities inherent in\nspatiotemporal data. While mainstream probabilistic models can capture\nuncertainty, they struggle with accurately learning primary patterns and often\nsuffer from computational inefficiency. To address these challenges, we propose\nCoST, which collaborates deterministic and probabilistic models to improve both\npredictive accuracy and the ability to handle uncertainty. To achieve this, we\ndesign a mean-residual decomposition framework, where the mean value is modeled\nby a deterministic model, and the residual variations are learned by a\nprobabilistic model, specifically diffusion models. Moreover, we introduce a\nscale-aware diffusion process, which better accounts for spatially\nheterogeneous dynamics across different regions. Extensive experiments on eight\nreal-world datasets demonstrate that CoST significantly outperforms existing\nmethods in both deterministic and probabilistic metrics, achieving a 20%\nimprovement with low computational cost. CoST bridges the gap between\ndeterministic precision and probabilistic uncertainty, making a significant\nadvancement in the field of urban spatiotemporal prediction.", "AI": {"tldr": "CoST combines deterministic and probabilistic models for urban spatiotemporal prediction, improving accuracy and uncertainty handling.", "motivation": "Existing models struggle with multi-modal distributions and computational inefficiency, highlighting the need for a hybrid approach.", "method": "CoST uses a mean-residual decomposition framework: deterministic models handle mean values, while diffusion models learn residuals. A scale-aware diffusion process addresses spatial heterogeneity.", "result": "CoST outperforms existing methods by 20% in accuracy and efficiency across eight datasets.", "conclusion": "CoST bridges deterministic precision and probabilistic uncertainty, advancing urban spatiotemporal prediction."}}
{"id": "2312.04055", "pdf": "https://arxiv.org/pdf/2312.04055", "abs": "https://arxiv.org/abs/2312.04055", "authors": ["Fei Huang", "Jianrong Lv", "Yang Yue"], "title": "Jointly spatial-temporal representation learning for individual trajectories", "categories": ["cs.LG"], "comment": "27 pages, 3 tables, 7 figures", "summary": "Individual trajectories, rich in human-environment interaction information\nacross space and time, serve as vital inputs for geospatial foundation models\n(GeoFMs). However, existing attempts at learning trajectory representations\nhave overlooked the implicit spatial-temporal dependency within trajectories,\nfailing to encode such dependency in a deep learning-friendly format. That\nposes a challenge in obtaining general-purpose trajectory representations.\nTherefore, this paper proposes a spatial-temporal joint representation learning\nmethod (ST-GraphRL) to formalize learnable spatial-temporal dependencies into\ntrajectory representations. The proposed ST-GraphRL consists of three\ncompositions: (i) a weighted directed spatial-temporal graph to explicitly\nconstruct mobility interactions in both space and time dimensions; (ii) a\ntwo-stage jointly encoder (i.e., decoupling and fusion), to learn entangled\nspatial-temporal dependencies by independently decomposing and jointly\naggregating space and time information; (iii) a decoder guides ST-GraphRL to\nlearn explicit mobility regularities by simulating the spatial-temporal\ndistributions of trajectories. Tested on three real-world human mobility\ndatasets, the proposed ST-GraphRL outperformed all the baseline models in\npredicting movement spatial-temporal distributions and preserving trajectory\nsimilarity with high spatial-temporal correlations. Analyzing spatial-temporal\nfeatures presented in latent space validates that ST-GraphRL understands\nspatial-temporal patterns. This study may also benefit representation learnings\nof other geospatial data to achieve general-purpose data representations and\nadvance GeoFMs development.", "AI": {"tldr": "The paper proposes ST-GraphRL, a method to learn spatial-temporal dependencies in trajectories for geospatial foundation models, outperforming baselines in mobility prediction and similarity preservation.", "motivation": "Existing methods fail to encode implicit spatial-temporal dependencies in trajectories, limiting general-purpose representation learning.", "method": "ST-GraphRL uses a weighted directed spatial-temporal graph, a two-stage encoder (decoupling and fusion), and a decoder to learn and simulate spatial-temporal patterns.", "result": "ST-GraphRL outperforms baselines in predicting spatial-temporal distributions and preserving trajectory similarity, with validated spatial-temporal pattern understanding.", "conclusion": "The method advances geospatial data representation learning and supports GeoFMs development."}}
{"id": "2504.12157", "pdf": "https://arxiv.org/pdf/2504.12157", "abs": "https://arxiv.org/abs/2504.12157", "authors": ["Xiaojun Ye", "Chun Wang", "Yiren Song", "Sheng Zhou", "Liangcheng Li", "Jiajun Bu"], "title": "FocusedAD: Character-centric Movie Audio Description", "categories": ["cs.CV", "I.2.10"], "comment": "Code and Demo link: https://github.com/Thorin215/FocusedAD", "summary": "Movie Audio Description (AD) aims to narrate visual content during\ndialogue-free segments, particularly benefiting blind and visually impaired\n(BVI) audiences. Compared with general video captioning, AD demands\nplot-relevant narration with explicit character name references, posing unique\nchallenges in movie understanding.To identify active main characters and focus\non storyline-relevant regions, we propose FocusedAD, a novel framework that\ndelivers character-centric movie audio descriptions. It includes: (i) a\nCharacter Perception Module(CPM) for tracking character regions and linking\nthem to names; (ii) a Dynamic Prior Module(DPM) that injects contextual cues\nfrom prior ADs and subtitles via learnable soft prompts; and (iii) a Focused\nCaption Module(FCM) that generates narrations enriched with plot-relevant\ndetails and named characters. To overcome limitations in character\nidentification, we also introduce an automated pipeline for building character\nquery banks. FocusedAD achieves state-of-the-art performance on multiple\nbenchmarks, including strong zero-shot results on MAD-eval-Named and our newly\nproposed Cinepile-AD dataset. Code and data will be released at\nhttps://github.com/Thorin215/FocusedAD .", "AI": {"tldr": "FocusedAD is a character-centric framework for Movie Audio Description (AD) that improves narration by tracking characters, using contextual cues, and generating plot-relevant details. It achieves state-of-the-art performance.", "motivation": "To address the unique challenges of AD, such as plot-relevant narration and character name references, for blind and visually impaired audiences.", "method": "Proposes FocusedAD with three modules: Character Perception Module (CPM) for tracking characters, Dynamic Prior Module (DPM) for contextual cues, and Focused Caption Module (FCM) for enriched narrations. Also introduces an automated pipeline for character query banks.", "result": "Achieves state-of-the-art performance on benchmarks, including zero-shot results on MAD-eval-Named and Cinepile-AD.", "conclusion": "FocusedAD effectively addresses AD challenges and improves narration quality, with code and data made available."}}
{"id": "2503.14376", "pdf": "https://arxiv.org/pdf/2503.14376", "abs": "https://arxiv.org/abs/2503.14376", "authors": ["Maximilian Beck", "Korbinian P\u00f6ppel", "Phillip Lippe", "Sepp Hochreiter"], "title": "Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels", "categories": ["cs.LG", "cs.AI"], "comment": "Code available at: https://github.com/NX-AI/mlstm_kernels", "summary": "Linear RNNs with gating recently demonstrated competitive performance\ncompared to Transformers in language modeling. Although their linear compute\nscaling in sequence length offers theoretical runtime advantages over\nTransformers, realizing these benefits in practice requires optimized custom\nkernels, as Transformers rely on the highly efficient Flash Attention kernels\n(Dao, 2024). Leveraging the chunkwise-parallel formulation of linear RNNs,\nFlash Linear Attention (FLA) (Yang & Zhang, 2024) shows that linear RNN kernels\nare faster than Flash Attention, by parallelizing over chunks of the input\nsequence. However, since the chunk size of FLA is limited, many intermediate\nstates must be materialized in GPU memory. This leads to low arithmetic\nintensity and causes high memory consumption and IO cost, especially for\nlong-context pre-training. In this work, we present Tiled Flash Linear\nAttention (TFLA), a novel kernel algorithm for linear RNNs, that enables\narbitrary large chunk sizes and high arithmetic intensity by introducing an\nadditional level of sequence parallelization within each chunk. First, we apply\nTFLA to the xLSTM with matrix memory, the mLSTM (Beck et al., 2024). Second, we\npropose an mLSTM variant with sigmoid input gate and reduced computation for\neven faster kernel runtimes at equal language modeling performance. In our\nspeed benchmarks, we show that our new mLSTM kernels based on TFLA outperform\nhighly optimized Flash Attention, Linear Attention and Mamba kernels, setting a\nnew state of the art for efficient long-context sequence modeling primitives.", "AI": {"tldr": "TFLA introduces a tiled kernel algorithm for linear RNNs, enabling large chunk sizes and high arithmetic intensity, outperforming existing methods in speed and efficiency for long-context modeling.", "motivation": "To address the memory and IO inefficiencies of Flash Linear Attention (FLA) in linear RNNs, especially for long-context pre-training.", "method": "Proposes Tiled Flash Linear Attention (TFLA), a kernel algorithm with sequence parallelization within chunks, and applies it to mLSTM with optimizations.", "result": "TFLA-based mLSTM kernels outperform Flash Attention, Linear Attention, and Mamba kernels in speed benchmarks.", "conclusion": "TFLA sets a new state of the art for efficient long-context sequence modeling, combining high performance with reduced computational overhead."}}
{"id": "2312.07252", "pdf": "https://arxiv.org/pdf/2312.07252", "abs": "https://arxiv.org/abs/2312.07252", "authors": ["Pascal Iversen", "Simon Witzke", "Katharina Baum", "Bernhard Y. Renard"], "title": "Identifying Drivers of Predictive Aleatoric Uncertainty", "categories": ["cs.LG", "stat.ML"], "comment": "Simon Witzke and Pascal Iversen contributed equally", "summary": "Explainability and uncertainty quantification are key to trustable artificial\nintelligence. However, the reasoning behind uncertainty estimates is generally\nleft unexplained. Identifying the drivers of uncertainty complements\nexplanations of point predictions in recognizing model limitations and\nenhancing transparent decision-making. So far, explanations of uncertainties\nhave been rarely studied. The few exceptions rely on Bayesian neural networks\nor technically intricate approaches, such as auxiliary generative models,\nthereby hindering their broad adoption. We propose a straightforward approach\nto explain predictive aleatoric uncertainties. We estimate uncertainty in\nregression as predictive variance by adapting a neural network with a Gaussian\noutput distribution. Subsequently, we apply out-of-the-box explainers to the\nmodel's variance output. This approach can explain uncertainty influences more\nreliably than complex published approaches, which we demonstrate in a synthetic\nsetting with a known data-generating process. We substantiate our findings with\na nuanced, quantitative benchmark including synthetic and real, tabular and\nimage datasets. For this, we adapt metrics from conventional XAI research to\nuncertainty explanations. Overall, the proposed method explains uncertainty\nestimates with little modifications to the model architecture and outperforms\nmore intricate methods in most settings.", "AI": {"tldr": "A simple method to explain predictive aleatoric uncertainties in AI, outperforming complex approaches with minimal model changes.", "motivation": "To enhance trust in AI by explaining uncertainty estimates, which are often left unexplained, using straightforward methods.", "method": "Adapts a neural network with a Gaussian output distribution to estimate uncertainty as predictive variance, then applies standard explainers to the variance output.", "result": "The approach reliably explains uncertainty influences, outperforming complex methods in synthetic and real datasets.", "conclusion": "The proposed method effectively explains uncertainty estimates with minimal architectural changes and superior performance in most cases."}}
{"id": "2504.12574", "pdf": "https://arxiv.org/pdf/2504.12574", "abs": "https://arxiv.org/abs/2504.12574", "authors": ["Zhenyu Yu", "Mohd Yamani Inda Idris", "Pei Wang"], "title": "ForgetMe: Evaluating Selective Forgetting in Generative Models", "categories": ["cs.CV"], "comment": null, "summary": "The widespread adoption of diffusion models in image generation has increased\nthe demand for privacy-compliant unlearning. However, due to the\nhigh-dimensional nature and complex feature representations of diffusion\nmodels, achieving selective unlearning remains challenging, as existing methods\nstruggle to remove sensitive information while preserving the consistency of\nnon-sensitive regions. To address this, we propose an Automatic Dataset\nCreation Framework based on prompt-based layered editing and training-free\nlocal feature removal, constructing the ForgetMe dataset and introducing the\nEntangled evaluation metric. The Entangled metric quantifies unlearning\neffectiveness by assessing the similarity and consistency between the target\nand background regions and supports both paired (Entangled-D) and unpaired\n(Entangled-S) image data, enabling unsupervised evaluation. The ForgetMe\ndataset encompasses a diverse set of real and synthetic scenarios, including\nCUB-200-2011 (Birds), Stanford-Dogs, ImageNet, and a synthetic cat dataset. We\napply LoRA fine-tuning on Stable Diffusion to achieve selective unlearning on\nthis dataset and validate the effectiveness of both the ForgetMe dataset and\nthe Entangled metric, establishing them as benchmarks for selective unlearning.\nOur work provides a scalable and adaptable solution for advancing\nprivacy-preserving generative AI.", "AI": {"tldr": "The paper proposes an Automatic Dataset Creation Framework (ForgetMe dataset) and an Entangled metric for evaluating selective unlearning in diffusion models, addressing privacy concerns.", "motivation": "The challenge of removing sensitive information from diffusion models while preserving non-sensitive regions due to their high-dimensional and complex nature.", "method": "Uses prompt-based layered editing and training-free local feature removal to create the ForgetMe dataset, with LoRA fine-tuning on Stable Diffusion for selective unlearning.", "result": "The ForgetMe dataset and Entangled metric effectively benchmark selective unlearning, validated on diverse real and synthetic datasets.", "conclusion": "Provides a scalable solution for privacy-preserving generative AI, advancing selective unlearning in diffusion models."}}
{"id": "2503.15764", "pdf": "https://arxiv.org/pdf/2503.15764", "abs": "https://arxiv.org/abs/2503.15764", "authors": ["Yong Xiao", "Guangming Shi", "Ping Zhang"], "title": "Towards Agentic AI Networking in 6G: A Generative Foundation Model-as-Agent Approach", "categories": ["cs.NI", "cs.AI"], "comment": "Accepted at IEEE Communications Magazine", "summary": "The promising potential of AI and network convergence in improving networking\nperformance and enabling new service capabilities has recently attracted\nsignificant interest. Existing network AI solutions, while powerful, are mainly\nbuilt based on the close-loop and passive learning framework, resulting in\nmajor limitations in autonomous solution finding and dynamic environmental\nadaptation. Agentic AI has recently been introduced as a promising solution to\naddress the above limitations and pave the way for true generally intelligent\nand beneficial AI systems. The key idea is to create a networking ecosystem to\nsupport a diverse range of autonomous and embodied AI agents in fulfilling\ntheir goals. In this paper, we focus on the novel challenges and requirements\nof agentic AI networking. We propose AgentNet, a novel framework for supporting\ninteraction, collaborative learning, and knowledge transfer among AI agents. We\nintroduce a general architectural framework of AgentNet and then propose a\ngenerative foundation model (GFM)-based implementation in which multiple\nGFM-as-agents have been created as an interactive knowledge-base to bootstrap\nthe development of embodied AI agents according to different task requirements\nand environmental features. We consider two application scenarios,\ndigital-twin-based industrial automation and metaverse-based infotainment\nsystem, to describe how to apply AgentNet for supporting efficient task-driven\ncollaboration and interaction among AI agents.", "AI": {"tldr": "The paper introduces AgentNet, a framework for agentic AI networking to address limitations in autonomous solution finding and dynamic adaptation in existing AI solutions.", "motivation": "The motivation is to overcome the limitations of passive learning frameworks in AI networking by enabling autonomous, goal-driven AI agents.", "method": "The method involves proposing AgentNet, a framework for interaction, collaborative learning, and knowledge transfer among AI agents, implemented using generative foundation models (GFMs).", "result": "AgentNet supports efficient task-driven collaboration among AI agents, demonstrated in industrial automation and metaverse infotainment scenarios.", "conclusion": "AgentNet paves the way for generally intelligent AI systems by addressing key challenges in agentic AI networking."}}
{"id": "2312.16560", "pdf": "https://arxiv.org/pdf/2312.16560", "abs": "https://arxiv.org/abs/2312.16560", "authors": ["Federico Errica", "Henrik Christiansen", "Viktor Zaverkin", "Takashi Maruyama", "Mathias Niepert", "Francesco Alesiani"], "title": "Adaptive Message Passing: A General Framework to Mitigate Oversmoothing, Oversquashing, and Underreaching", "categories": ["cs.LG"], "comment": null, "summary": "Long-range interactions are essential for the correct description of complex\nsystems in many scientific fields. The price to pay for including them in the\ncalculations, however, is a dramatic increase in the overall computational\ncosts. Recently, deep graph networks have been employed as efficient,\ndata-driven models for predicting properties of complex systems represented as\ngraphs. These models rely on a message passing strategy that should, in\nprinciple, capture long-range information without explicitly modeling the\ncorresponding interactions. In practice, most deep graph networks cannot really\nmodel long-range dependencies due to the intrinsic limitations of (synchronous)\nmessage passing, namely oversmoothing, oversquashing, and underreaching. This\nwork proposes a general framework that learns to mitigate these limitations:\nwithin a variational inference framework, we endow message passing\narchitectures with the ability to adapt their depth and filter messages along\nthe way. With theoretical and empirical arguments, we show that this strategy\nbetter captures long-range interactions, by competing with the state of the art\non five node and graph prediction datasets.", "AI": {"tldr": "A framework is proposed to improve deep graph networks' ability to capture long-range interactions by adapting message passing depth and filtering messages, addressing limitations like oversmoothing and oversquashing.", "motivation": "Long-range interactions are crucial for complex systems but computationally expensive. Deep graph networks struggle to model these due to message passing limitations.", "method": "A variational inference framework adapts message passing depth and filters messages to mitigate oversmoothing, oversquashing, and underreaching.", "result": "The framework competes with state-of-the-art on five node and graph prediction datasets, better capturing long-range interactions.", "conclusion": "The proposed method effectively addresses limitations of deep graph networks, enhancing their ability to model long-range dependencies."}}
{"id": "2504.13580", "pdf": "https://arxiv.org/pdf/2504.13580", "abs": "https://arxiv.org/abs/2504.13580", "authors": ["Yuchen Rao", "Stefan Ainetter", "Sinisa Stekovic", "Vincent Lepetit", "Friedrich Fraundorfer"], "title": "Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding", "categories": ["cs.CV"], "comment": "Project page: https://stefan-ainetter.github.io/SCANnotatepp; CVPR'25\n  Workshop", "summary": "High-level 3D scene understanding is essential in many applications. However,\nthe challenges of generating accurate 3D annotations make development of deep\nlearning models difficult. We turn to recent advancements in automatic\nretrieval of synthetic CAD models, and show that data generated by such methods\ncan be used as high-quality ground truth for training supervised deep learning\nmodels. More exactly, we employ a pipeline akin to the one previously used to\nautomatically annotate objects in ScanNet scenes with their 9D poses and CAD\nmodels. This time, we apply it to the recent ScanNet++ v1 dataset, which\npreviously lacked such annotations. Our findings demonstrate that it is not\nonly possible to train deep learning models on these automatically-obtained\nannotations but that the resulting models outperform those trained on manually\nannotated data. We validate this on two distinct tasks: point cloud completion\nand single-view CAD model retrieval and alignment. Our results underscore the\npotential of automatic 3D annotations to enhance model performance while\nsignificantly reducing annotation costs. To support future research in 3D scene\nunderstanding, we will release our annotations, which we call SCANnotate++,\nalong with our trained models.", "AI": {"tldr": "Using synthetic CAD models for automatic 3D annotations improves deep learning model performance and reduces annotation costs.", "motivation": "High-level 3D scene understanding is crucial but hindered by the difficulty of generating accurate 3D annotations.", "method": "Employed a pipeline to automatically annotate ScanNet++ v1 dataset with CAD models and 9D poses, using synthetic data as ground truth.", "result": "Models trained on automatic annotations outperform those using manual annotations in tasks like point cloud completion and CAD model retrieval.", "conclusion": "Automatic 3D annotations are viable and superior, offering cost-effective solutions for 3D scene understanding."}}
{"id": "2503.21098", "pdf": "https://arxiv.org/pdf/2503.21098", "abs": "https://arxiv.org/abs/2503.21098", "authors": ["Yedan Shen", "Kaixin Wu", "Yuechen Ding", "Jingyuan Wen", "Hong Liu", "Mingjie Zhong", "Zhouhan Lin", "Jia Xu", "Linjian Mo"], "title": "Alleviating LLM-based Generative Retrieval Hallucination in Alipay Search", "categories": ["cs.IR", "cs.AI"], "comment": "4 pages", "summary": "Generative retrieval (GR) has revolutionized document retrieval with the\nadvent of large language models (LLMs), and LLM-based GR is gradually being\nadopted by the industry. Despite its remarkable advantages and potential,\nLLM-based GR suffers from hallucination and generates documents that are\nirrelevant to the query in some instances, severely challenging its credibility\nin practical applications. We thereby propose an optimized GR framework\ndesigned to alleviate retrieval hallucination, which integrates knowledge\ndistillation reasoning in model training and incorporate decision agent to\nfurther improve retrieval precision. Specifically, we employ LLMs to assess and\nreason GR retrieved query-document (q-d) pairs, and then distill the reasoning\ndata as transferred knowledge to the GR model. Moreover, we utilize a decision\nagent as post-processing to extend the GR retrieved documents through retrieval\nmodel and select the most relevant ones from multi perspectives as the final\ngenerative retrieval result. Extensive offline experiments on real-world\ndatasets and online A/B tests on Fund Search and Insurance Search in Alipay\ndemonstrate our framework's superiority and effectiveness in improving search\nquality and conversion gains.", "AI": {"tldr": "The paper proposes an optimized generative retrieval (GR) framework to address hallucination issues in LLM-based GR, improving retrieval precision through knowledge distillation and a decision agent.", "motivation": "LLM-based GR suffers from hallucination, generating irrelevant documents, which challenges its practical credibility.", "method": "Integrates knowledge distillation reasoning in training and uses a decision agent for post-processing to refine retrieval results.", "result": "Offline and online tests show the framework improves search quality and conversion gains.", "conclusion": "The proposed framework effectively mitigates hallucination and enhances retrieval precision in practical applications."}}
{"id": "2401.00364", "pdf": "https://arxiv.org/pdf/2401.00364", "abs": "https://arxiv.org/abs/2401.00364", "authors": ["Shaan Ul Haque", "Sajad Khodadadian", "Siva Theja Maguluri"], "title": "Tight Finite Time Bounds of Two-Time-Scale Linear Stochastic Approximation with Markovian Noise", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC"], "comment": "83 pages, 6 figures", "summary": "Stochastic approximation (SA) is an iterative algorithm for finding the fixed\npoint of an operator using noisy samples and widely used in optimization and\nReinforcement Learning (RL). The noise in RL exhibits a Markovian structure,\nand in some cases, such as gradient temporal difference (GTD) methods, SA is\nemployed in a two-time-scale framework. This combination introduces significant\ntheoretical challenges for analysis.\n  We derive an upper bound on the error for the iterations of linear\ntwo-time-scale SA with Markovian noise. We demonstrate that the mean squared\nerror decreases as $trace (\\Sigma^y)/k + o(1/k)$ where $k$ is the number of\niterates, and $\\Sigma^y$ is an appropriately defined covariance matrix. A key\nfeature of our bounds is that the leading term, $\\Sigma^y$, exactly matches\nwith the covariance in the Central Limit Theorem (CLT) for the two-time-scale\nSA, and we call them tight finite-time bounds. We illustrate their use in RL by\nestablishing sample complexity for off-policy algorithms, TDC, GTD, and GTD2.\n  A special case of linear two-time-scale SA that is extensively studied is\nlinear SA with Polyak-Ruppert averaging. We present tight finite time bounds\ncorresponding to the covariance matrix of the CLT. Such bounds can be used to\nstudy TD-learning with Polyak-Ruppert averaging.", "AI": {"tldr": "The paper derives tight finite-time error bounds for linear two-time-scale stochastic approximation (SA) with Markovian noise, showing mean squared error decreases as $trace(\\Sigma^y)/k + o(1/k)$. The bounds match the Central Limit Theorem covariance and are applied to RL algorithms like TDC, GTD, and GTD2.", "motivation": "The motivation is to address theoretical challenges in analyzing two-time-scale SA with Markovian noise, particularly in RL applications like GTD methods.", "method": "The method involves deriving upper bounds on error for linear two-time-scale SA with Markovian noise, focusing on mean squared error and covariance matching the CLT.", "result": "The result shows the mean squared error decreases as $trace(\\Sigma^y)/k + o(1/k)$, with tight bounds matching the CLT covariance. Applications include sample complexity for RL algorithms.", "conclusion": "The paper concludes with tight finite-time bounds for linear SA, applicable to RL algorithms, and extends to Polyak-Ruppert averaging in TD-learning."}}
{"id": "2504.13617", "pdf": "https://arxiv.org/pdf/2504.13617", "abs": "https://arxiv.org/abs/2504.13617", "authors": ["Zuyao Chen", "Jinlin Wu", "Zhen Lei", "Marc Pollefeys", "Chang Wen Chen"], "title": "Compile Scene Graphs with Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Next-token prediction is the fundamental principle for training large\nlanguage models (LLMs), and reinforcement learning (RL) further enhances their\nreasoning performance. As an effective way to model language, image, video, and\nother modalities, the use of LLMs for end-to-end extraction of structured\nvisual representations, such as scene graphs, remains underexplored. It\nrequires the model to accurately produce a set of objects and relationship\ntriplets, rather than generating text token by token. To achieve this, we\nintroduce R1-SGG, a multimodal LLM (M-LLM) initially trained via supervised\nfine-tuning (SFT) on the scene graph dataset and subsequently refined using\nreinforcement learning to enhance its ability to generate scene graphs in an\nend-to-end manner. The SFT follows a conventional prompt-response paradigm,\nwhile RL requires the design of effective reward signals. We design a set of\ngraph-centric rewards, including three recall-based variants -- Hard Recall,\nHard Recall+Relax, and Soft Recall -- which evaluate semantic and spatial\nalignment between predictions and ground truth at the object and relation\nlevels. A format consistency reward further ensures that outputs follow the\nexpected structural schema. Extensive experiments on the VG150 and PSG\nbenchmarks show that R1-SGG substantially reduces failure rates and achieves\nstrong performance in Recall and mean Recall, surpassing traditional SGG models\nand existing multimodal language models. Our code is available at\nhttps://github.com/gpt4vision/R1-SGG", "AI": {"tldr": "R1-SGG is a multimodal LLM trained for end-to-end scene graph generation, combining supervised fine-tuning and reinforcement learning with graph-centric rewards.", "motivation": "To explore the underexplored use of LLMs for structured visual representation extraction, specifically scene graphs, which require accurate object and relationship triplet generation.", "method": "Initial supervised fine-tuning (SFT) on scene graph data, followed by reinforcement learning (RL) with designed graph-centric rewards (Hard Recall, Hard Recall+Relax, Soft Recall, and format consistency).", "result": "R1-SGG reduces failure rates and outperforms traditional SGG models and existing M-LLMs in Recall and mean Recall on VG150 and PSG benchmarks.", "conclusion": "R1-SGG demonstrates the effectiveness of combining SFT and RL for structured visual representation tasks, achieving strong performance in scene graph generation."}}
{"id": "2503.21846", "pdf": "https://arxiv.org/pdf/2503.21846", "abs": "https://arxiv.org/abs/2503.21846", "authors": ["Yesmine Abdennadher", "Giovanni Perin", "Riccardo Mazzieri", "Jacopo Pegoraro", "Michele Rossi"], "title": "LightSNN: Lightweight Architecture Search for Sparse and Accurate Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "eess.SP"], "comment": "Accepted to AMLDS 2025 (Tokyo, July 2025). 6 pages, 3 figures, 2\n  tables", "summary": "Spiking Neural Networks (SNNs) are highly regarded for their energy\nefficiency, inherent activation sparsity, and suitability for real-time\nprocessing in edge devices. However, most current SNN methods adopt\narchitectures resembling traditional artificial neural networks (ANNs), leading\nto suboptimal performance when applied to SNNs. While SNNs excel in energy\nefficiency, they have been associated with lower accuracy levels than\ntraditional ANNs when utilizing conventional architectures. In response, in\nthis work we present LightSNN, a rapid and efficient Neural Network\nArchitecture Search (NAS) technique specifically tailored for SNNs that\nautonomously leverages the most suitable architecture, striking a good balance\nbetween accuracy and efficiency by enforcing sparsity. Based on the spiking NAS\nnetwork (SNASNet) framework, a cell-based search space including backward\nconnections is utilized to build our training-free pruning-based NAS mechanism.\nOur technique assesses diverse spike activation patterns across different data\nsamples using a sparsity-aware Hamming distance fitness evaluation. Thorough\nexperiments are conducted on both static (CIFAR10 and CIFAR100) and\nneuromorphic datasets (DVS128-Gesture). Our LightSNN model achieves\nstate-of-the-art results on CIFAR10 and CIFAR100, improves performance on\nDVS128Gesture by 4.49\\%, and significantly reduces search time most notably\noffering a $98\\times$ speedup over SNASNet and running 30\\% faster than the\nbest existing method on DVS128Gesture. Code is available on Github at:\nhttps://github.com/YesmineAbdennadher/LightSNN.", "AI": {"tldr": "LightSNN is a Neural Network Architecture Search (NAS) technique for Spiking Neural Networks (SNNs) that improves accuracy and efficiency by leveraging sparsity, achieving state-of-the-art results and faster search times.", "motivation": "Current SNN methods mimic traditional ANN architectures, leading to suboptimal performance. LightSNN addresses this by optimizing architecture for SNNs.", "method": "Uses a cell-based search space with backward connections and a sparsity-aware Hamming distance fitness evaluation for training-free pruning-based NAS.", "result": "Achieves top results on CIFAR10/CIFAR100, improves DVS128-Gesture performance by 4.49%, and reduces search time significantly (98x speedup over SNASNet).", "conclusion": "LightSNN effectively balances accuracy and efficiency for SNNs, outperforming existing methods in speed and performance."}}
{"id": "2401.08909", "pdf": "https://arxiv.org/pdf/2401.08909", "abs": "https://arxiv.org/abs/2401.08909", "authors": ["Renchunzi Xie", "Ambroise Odonnat", "Vasilii Feofanov", "Ievgen Redko", "Jianfeng Zhang", "Bo An"], "title": "Leveraging Gradients for Unsupervised Accuracy Estimation under Distribution Shift", "categories": ["cs.LG"], "comment": null, "summary": "Estimating the test performance of a model, possibly under distribution\nshift, without having access to the ground-truth labels is a challenging, yet\nvery important problem for the safe deployment of machine learning algorithms\nin the wild. Existing works mostly rely on information from either the outputs\nor the extracted features of neural networks to estimate a score that\ncorrelates with the ground-truth test accuracy. In this paper, we investigate\n-- both empirically and theoretically -- how the information provided by the\ngradients can be predictive of the ground-truth test accuracy even under\ndistribution shifts. More specifically, we use the norm of classification-layer\ngradients, backpropagated from the cross-entropy loss after only one gradient\nstep over test data. Our intuition is that these gradients should be of higher\nmagnitude when the model generalizes poorly. We provide the theoretical\ninsights behind our approach and the key ingredients that ensure its empirical\nsuccess. Extensive experiments conducted with various architectures on diverse\ndistribution shifts demonstrate that our method significantly outperforms\ncurrent state-of-the-art approaches. The code is available at\nhttps://github.com/Renchunzi-Xie/GdScore", "AI": {"tldr": "The paper proposes a method to estimate model test performance under distribution shifts using gradients, outperforming existing approaches.", "motivation": "Estimating test performance without ground-truth labels is crucial for safe ML deployment, especially under distribution shifts.", "method": "Uses the norm of classification-layer gradients from one gradient step on test data, correlating higher gradient magnitudes with poor generalization.", "result": "Extensive experiments show the method significantly outperforms state-of-the-art approaches across diverse distribution shifts.", "conclusion": "Gradient-based estimation is effective for predicting test accuracy under distribution shifts, offering theoretical and empirical support."}}
{"id": "2504.17040", "pdf": "https://arxiv.org/pdf/2504.17040", "abs": "https://arxiv.org/abs/2504.17040", "authors": ["Zhenhailong Wang", "Senthil Purushwalkam", "Caiming Xiong", "Silvio Savarese", "Heng Ji", "Ran Xu"], "title": "DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present DyMU, an efficient, training-free framework that dynamically\nreduces the computational burden of vision-language models (VLMs) while\nmaintaining high task performance. Our approach comprises two key components.\nFirst, Dynamic Token Merging (DToMe) reduces the number of visual token\nembeddings by merging similar tokens based on image complexity, addressing the\ninherent inefficiency of fixed-length outputs in vision transformers. Second,\nVirtual Token Unmerging (VTU) simulates the expected token sequence for large\nlanguage models (LLMs) by efficiently reconstructing the attention dynamics of\na full sequence, thus preserving the downstream performance without additional\nfine-tuning. Unlike previous approaches, our method dynamically adapts token\ncompression to the content of the image and operates completely training-free,\nmaking it readily applicable to most state-of-the-art VLM architectures.\nExtensive experiments on image and video understanding tasks demonstrate that\nDyMU can reduce the average visual token count by 32%-85% while achieving\ncomparable performance to full-length models across diverse VLM architectures,\nincluding the recently popularized AnyRes-based visual encoders. Furthermore,\nthrough qualitative analyses, we demonstrate that DToMe effectively adapts\ntoken reduction based on image complexity and, unlike existing systems,\nprovides users more control over computational costs. Project page:\nhttps://mikewangwzhl.github.io/dymu/.", "AI": {"tldr": "DyMU is a training-free framework that dynamically reduces computational costs in vision-language models by merging and reconstructing tokens, maintaining performance.", "motivation": "Address inefficiency of fixed-length outputs in vision transformers and reduce computational burden without fine-tuning.", "method": "Uses Dynamic Token Merging (DToMe) to merge similar visual tokens and Virtual Token Unmerging (VTU) to simulate full-sequence attention.", "result": "Reduces visual token count by 32%-85% while matching full-length model performance.", "conclusion": "DyMU is efficient, adaptable, and applicable to state-of-the-art VLM architectures without training."}}
{"id": "2504.00485", "pdf": "https://arxiv.org/pdf/2504.00485", "abs": "https://arxiv.org/abs/2504.00485", "authors": ["Mahade Hasan", "Farhana Yasmin", "Xue Yu"], "title": "Enhancing stroke disease classification through machine learning models by feature selection techniques", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Heart disease remains a leading cause of mortality and morbidity worldwide,\nnecessitating the development of accurate and reliable predictive models to\nfacilitate early detection and intervention. While state of the art work has\nfocused on various machine learning approaches for predicting heart disease,\nbut they could not able to achieve remarkable accuracy. In response to this\nneed, we applied nine machine learning algorithms XGBoost, logistic regression,\ndecision tree, random forest, k-nearest neighbors (KNN), support vector machine\n(SVM), gaussian na\\\"ive bayes (NB gaussian), adaptive boosting, and linear\nregression to predict heart disease based on a range of physiological\nindicators. Our approach involved feature selection techniques to identify the\nmost relevant predictors, aimed at refining the models to enhance both\nperformance and interpretability. The models were trained, incorporating\nprocesses such as grid search hyperparameter tuning, and cross-validation to\nminimize overfitting. Additionally, we have developed a novel voting system\nwith feature selection techniques to advance heart disease classification.\nFurthermore, we have evaluated the models using key performance metrics\nincluding accuracy, precision, recall, F1-score, and the area under the\nreceiver operating characteristic curve (ROC AUC). Among the models, XGBoost\ndemonstrated exceptional performance, achieving 99% accuracy, precision,\nF1-Score, 98% recall, and 100% ROC AUC. This study offers a promising approach\nto early heart disease diagnosis and preventive healthcare.", "AI": {"tldr": "The paper evaluates nine ML algorithms for heart disease prediction, with XGBoost achieving 99% accuracy and 100% ROC AUC, highlighting its potential for early diagnosis.", "motivation": "Heart disease is a major global health issue, but existing ML models lack high accuracy. This study aims to improve predictive performance.", "method": "Nine ML algorithms (e.g., XGBoost, SVM) were applied with feature selection, hyperparameter tuning, and a novel voting system. Performance was evaluated using metrics like accuracy and ROC AUC.", "result": "XGBoost outperformed others with 99% accuracy, 98% recall, and 100% ROC AUC.", "conclusion": "The study presents a highly accurate approach for heart disease prediction, emphasizing XGBoost's effectiveness for early diagnosis."}}
{"id": "2402.06223", "pdf": "https://arxiv.org/pdf/2402.06223", "abs": "https://arxiv.org/abs/2402.06223", "authors": ["Yuhang Liu", "Zhen Zhang", "Dong Gong", "Erdun Gao", "Biwei Huang", "Mingming Gong", "Anton van den Hengel", "Kun Zhang", "Javen Qinfeng Shi"], "title": "Beyond DAGs: A Latent Partial Causal Model for Multimodal Learning", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Directed acyclic graphs (DAGs) are fundamental graph structures in causal\nmodeling, but identifying the desired DAG from observational data often\nrequires strong assumptions that may not hold in real-world scenarios,\nespecially for latent causal models and complex multimodal data. This raises\nthe question of whether we can relax or bypass the DAG assumption while\nmaintaining practical utility. In this work, we propose a novel latent partial\ncausal model for multimodal data, featuring two latent coupled variables,\nconnected by an undirected edge, to represent the transfer of knowledge across\nmodalities. Under specific statistical assumptions, we establish an\nidentifiability result, demonstrating that representations learned by\nmultimodal contrastive learning correspond to the latent coupled variables up\nto a trivial transformation. This result deepens our understanding of the why\nmultimodal contrastive learning works, highlights its potential for\ndisentanglement, and expands the utility of pre-trained models like CLIP.\nSynthetic experiments confirm the robustness of our findings, even when the\nassumptions are partially violated. Most importantly, experiments on a\npre-trained CLIP model embodies disentangled representations, enabling few-shot\nlearning and improving domain generalization across diverse real-world\ndatasets. Together, these contributions push the boundaries of multimodal\ncontrastive learning, both theoretically and, crucially, in practical\napplications.", "AI": {"tldr": "The paper proposes a latent partial causal model for multimodal data, relaxing the DAG assumption, and shows identifiability of latent variables via multimodal contrastive learning, validated by synthetic and real-world experiments.", "motivation": "Traditional DAG-based causal models require strong assumptions, which may not hold for latent causal models and complex multimodal data. The work aims to relax these assumptions while maintaining practical utility.", "method": "A novel latent partial causal model with two latent coupled variables connected by an undirected edge is proposed. Identifiability is established under specific statistical assumptions, linking it to multimodal contrastive learning.", "result": "The model demonstrates identifiability of latent variables, robustness in synthetic experiments, and practical utility in pre-trained models like CLIP, improving few-shot learning and domain generalization.", "conclusion": "The work advances multimodal contrastive learning theoretically and practically, showing its potential for disentanglement and broader applications."}}
{"id": "2504.17522", "pdf": "https://arxiv.org/pdf/2504.17522", "abs": "https://arxiv.org/abs/2504.17522", "authors": ["Anyi Xiao", "Cihui Yang"], "title": "TableCenterNet: A one-stage network for table structure recognition", "categories": ["cs.CV"], "comment": null, "summary": "Table structure recognition aims to parse tables in unstructured data into\nmachine-understandable formats. Recent methods address this problem through a\ntwo-stage process or optimized one-stage approaches. However, these methods\neither require multiple networks to be serially trained and perform more\ntime-consuming sequential decoding, or rely on complex post-processing\nalgorithms to parse the logical structure of tables. They struggle to balance\ncross-scenario adaptability, robustness, and computational efficiency. In this\npaper, we propose a one-stage end-to-end table structure parsing network called\nTableCenterNet. This network unifies the prediction of table spatial and\nlogical structure into a parallel regression task for the first time, and\nimplicitly learns the spatial-logical location mapping laws of cells through a\nsynergistic architecture of shared feature extraction layers and task-specific\ndecoding. Compared with two-stage methods, our method is easier to train and\nfaster to infer. Experiments on benchmark datasets show that TableCenterNet can\neffectively parse table structures in diverse scenarios and achieve\nstate-of-the-art performance on the TableGraph-24k dataset. Code is available\nat https://github.com/dreamy-xay/TableCenterNet.", "AI": {"tldr": "TableCenterNet is a one-stage end-to-end network for table structure recognition, unifying spatial and logical structure prediction into parallel regression, outperforming existing methods in adaptability, robustness, and efficiency.", "motivation": "Existing methods for table structure recognition are either multi-stage (time-consuming) or rely on complex post-processing, struggling with adaptability and efficiency.", "method": "Proposes TableCenterNet, a one-stage network with shared feature extraction and task-specific decoding to predict table structures in parallel.", "result": "Achieves state-of-the-art performance on the TableGraph-24k dataset, demonstrating cross-scenario adaptability and computational efficiency.", "conclusion": "TableCenterNet offers a simpler, faster, and more effective solution for table structure recognition compared to existing approaches."}}
{"id": "2504.11901", "pdf": "https://arxiv.org/pdf/2504.11901", "abs": "https://arxiv.org/abs/2504.11901", "authors": ["Luca Castri", "Gloria Beraldo", "Nicola Bellotto"], "title": "Causality-enhanced Decision-Making for Autonomous Mobile Robots in Dynamic Environments", "categories": ["cs.RO", "cs.AI"], "comment": "Causal Discovery and Inference - Robot Autonomy - Human-Robot Spatial\n  Interaction - Decision-Making", "summary": "The growing integration of robots in shared environments -- such as\nwarehouses, shopping centres, and hospitals -- demands a deep understanding of\nthe underlying dynamics and human behaviours, including how, when, and where\nindividuals engage in various activities and interactions. This knowledge goes\nbeyond simple correlation studies and requires a more comprehensive causal\nanalysis. By leveraging causal inference to model cause-and-effect\nrelationships, we can better anticipate critical environmental factors and\nenable autonomous robots to plan and execute tasks more effectively. To this\nend, we propose a novel causality-based decision-making framework that reasons\nover a learned causal model to predict battery usage and human obstructions,\nunderstanding how these factors could influence robot task execution. Such\nreasoning framework assists the robot in deciding when and how to complete a\ngiven task. To achieve this, we developed also PeopleFlow, a new Gazebo-based\nsimulator designed to model context-sensitive human-robot spatial interactions\nin shared workspaces. PeopleFlow features realistic human and robot\ntrajectories influenced by contextual factors such as time, environment layout,\nand robot state, and can simulate a large number of agents. While the simulator\nis general-purpose, in this paper we focus on a warehouse-like environment as a\ncase study, where we conduct an extensive evaluation benchmarking our causal\napproach against a non-causal baseline. Our findings demonstrate the efficacy\nof the proposed solutions, highlighting how causal reasoning enables autonomous\nrobots to operate more efficiently and safely in dynamic environments shared\nwith humans.", "AI": {"tldr": "A causality-based framework and simulator (PeopleFlow) improve robot task planning in shared environments by predicting battery usage and human obstructions.", "motivation": "Understanding human-robot interactions in shared spaces requires causal analysis for better task execution.", "method": "Developed a causality-based decision-making framework and PeopleFlow simulator for modeling human-robot interactions.", "result": "The causal approach outperforms non-causal baselines, enhancing robot efficiency and safety.", "conclusion": "Causal reasoning improves autonomous robot performance in dynamic human-shared environments."}}
{"id": "2404.02108", "pdf": "https://arxiv.org/pdf/2404.02108", "abs": "https://arxiv.org/abs/2404.02108", "authors": ["Swetha Ganesh", "Washim Uddin Mondal", "Vaneet Aggarwal"], "title": "Order-Optimal Regret with Novel Policy Gradient Approaches in Infinite-Horizon Average Reward MDPs", "categories": ["cs.LG"], "comment": "In the Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS), 2025", "summary": "We present two Policy Gradient-based algorithms with general parametrization\nin the context of infinite-horizon average reward Markov Decision Process\n(MDP). The first one employs Implicit Gradient Transport for variance\nreduction, ensuring an expected regret of the order\n$\\tilde{\\mathcal{O}}(T^{2/3})$. The second approach, rooted in Hessian-based\ntechniques, ensures an expected regret of the order\n$\\tilde{\\mathcal{O}}(\\sqrt{T})$. These results significantly improve the\nstate-of-the-art $\\tilde{\\mathcal{O}}(T^{3/4})$ regret and achieve the\ntheoretical lower bound. We also show that the average-reward function is\napproximately $L$-smooth, a result that was previously assumed in earlier\nworks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.18864", "pdf": "https://arxiv.org/pdf/2504.18864", "abs": "https://arxiv.org/abs/2504.18864", "authors": ["Yunzhong Zhang", "Bo Xiong", "You Zhou", "Changqing Su", "Zhen Cheng", "Zhaofei Yu", "Xun Cao", "Tiejun Huang"], "title": "Spike Imaging Velocimetry: Dense Motion Estimation of Fluids Using Spike Cameras", "categories": ["cs.CV"], "comment": null, "summary": "The need for accurate and non-intrusive flow measurement methods has led to\nthe widespread adoption of Particle Image Velocimetry (PIV), a powerful\ndiagnostic tool in fluid motion estimation. This study investigates the\ntremendous potential of spike cameras (a type of ultra-high-speed,\nhigh-dynamic-range camera) in PIV. We propose a deep learning framework, Spike\nImaging Velocimetry (SIV), designed specifically for highly turbulent and\nintricate flow fields. To aggregate motion features from the spike stream while\nminimizing information loss, we incorporate a Detail-Preserving Hierarchical\nTransform (DPHT) module. Additionally, we introduce a Graph Encoder (GE) to\nextract contextual features from highly complex fluid flows. Furthermore, we\npresent a spike-based PIV dataset, Particle Scenes with Spike and Displacement\n(PSSD), which provides labeled data for three challenging fluid dynamics\nscenarios. Our proposed method achieves superior performance compared to\nexisting baseline methods on PSSD. The datasets and our implementation of SIV\nare open-sourced in the supplementary materials.", "AI": {"tldr": "The paper introduces Spike Imaging Velocimetry (SIV), a deep learning framework for Particle Image Velocimetry (PIV) using spike cameras, achieving superior performance in turbulent flow fields.", "motivation": "Accurate, non-intrusive flow measurement methods are needed, and spike cameras offer potential for PIV due to their ultra-high-speed and high-dynamic-range capabilities.", "method": "Proposes SIV with a Detail-Preserving Hierarchical Transform (DPHT) module and Graph Encoder (GE) for feature extraction, and introduces the PSSD dataset for validation.", "result": "SIV outperforms baseline methods on the PSSD dataset, demonstrating its effectiveness in complex flow scenarios.", "conclusion": "The study highlights the potential of spike cameras in PIV and provides open-sourced datasets and SIV implementation for further research."}}
{"id": "2504.15587", "pdf": "https://arxiv.org/pdf/2504.15587", "abs": "https://arxiv.org/abs/2504.15587", "authors": ["Zimo Yan", "Jie Zhang", "Zheng Xie", "Chang Liu", "Yizhen Liu", "Yiping Song"], "title": "MetaMolGen: A Neural Graph Motif Generation Model for De Novo Molecular Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Molecular generation plays an important role in drug discovery and materials\nscience, especially in data-scarce scenarios where traditional generative\nmodels often struggle to achieve satisfactory conditional generalization. To\naddress this challenge, we propose MetaMolGen, a first-order\nmeta-learning-based molecular generator designed for few-shot and\nproperty-conditioned molecular generation. MetaMolGen standardizes the\ndistribution of graph motifs by mapping them to a normalized latent space, and\nemploys a lightweight autoregressive sequence model to generate SMILES\nsequences that faithfully reflect the underlying molecular structure. In\naddition, it supports conditional generation of molecules with target\nproperties through a learnable property projector integrated into the\ngenerative process.Experimental results demonstrate that MetaMolGen\nconsistently generates valid and diverse SMILES sequences under low-data\nregimes, outperforming conventional baselines. This highlights its advantage in\nfast adaptation and efficient conditional generation for practical molecular\ndesign.", "AI": {"tldr": "MetaMolGen is a meta-learning-based molecular generator for few-shot and property-conditioned molecular generation, outperforming traditional models in low-data scenarios.", "motivation": "Addressing the challenge of conditional molecular generation in data-scarce settings where traditional models struggle.", "method": "Uses a normalized latent space for graph motifs and a lightweight autoregressive model for SMILES generation, integrating a learnable property projector for conditional generation.", "result": "Generates valid and diverse SMILES sequences in low-data regimes, outperforming conventional baselines.", "conclusion": "MetaMolGen excels in fast adaptation and efficient conditional generation for practical molecular design."}}
{"id": "2404.15731", "pdf": "https://arxiv.org/pdf/2404.15731", "abs": "https://arxiv.org/abs/2404.15731", "authors": ["Akshay Thakur", "Souvik Chakraborty"], "title": "MD-NOMAD: Mixture density nonlinear manifold decoder for emulating stochastic differential equations and uncertainty propagation", "categories": ["cs.LG"], "comment": null, "summary": "We propose a neural operator framework, termed mixture density nonlinear\nmanifold decoder (MD-NOMAD), for stochastic simulators. Our approach leverages\nan amalgamation of the pointwise operator learning neural architecture\nnonlinear manifold decoder (NOMAD) with mixture density-based methods to\nestimate conditional probability distributions for stochastic output functions.\nMD-NOMAD harnesses the ability of probabilistic mixture models to estimate\ncomplex probability and the high-dimensional scalability of pointwise neural\noperator NOMAD. We conduct empirical assessments on a wide array of stochastic\nordinary and partial differential equations and present the corresponding\nresults, which highlight the performance of the proposed framework.", "AI": {"tldr": "MD-NOMAD combines NOMAD with mixture density methods to estimate conditional probability distributions for stochastic simulators, showing strong performance in empirical tests.", "motivation": "To address the challenge of estimating complex probability distributions for stochastic output functions in simulators.", "method": "Leverages NOMAD's neural architecture and mixture density-based methods to model conditional probability distributions.", "result": "Demonstrates strong performance in empirical assessments on stochastic ODEs and PDEs.", "conclusion": "MD-NOMAD effectively combines probabilistic modeling and scalability for stochastic simulators."}}
{"id": "2504.21414", "pdf": "https://arxiv.org/pdf/2504.21414", "abs": "https://arxiv.org/abs/2504.21414", "authors": ["Qi Fan", "Kaiqi Liu", "Nian Liu", "Hisham Cholakkal", "Rao Muhammad Anwer", "Wenbin Li", "Yang Gao"], "title": "Adapting In-Domain Few-Shot Segmentation to New Domains without Retraining", "categories": ["cs.CV"], "comment": null, "summary": "Cross-domain few-shot segmentation (CD-FSS) aims to segment objects of novel\nclasses in new domains, which is often challenging due to the diverse\ncharacteristics of target domains and the limited availability of support data.\nMost CD-FSS methods redesign and retrain in-domain FSS models using various\ndomain-generalization techniques, which are effective but costly to train. To\naddress these issues, we propose adapting informative model structures of the\nwell-trained FSS model for target domains by learning domain characteristics\nfrom few-shot labeled support samples during inference, thereby eliminating the\nneed for retraining. Specifically, we first adaptively identify domain-specific\nmodel structures by measuring parameter importance using a novel structure\nFisher score in a data-dependent manner. Then, we progressively train the\nselected informative model structures with hierarchically constructed training\nsamples, progressing from fewer to more support shots. The resulting\nInformative Structure Adaptation (ISA) method effectively addresses domain\nshifts and equips existing well-trained in-domain FSS models with flexible\nadaptation capabilities for new domains, eliminating the need to redesign or\nretrain CD-FSS models on base data. Extensive experiments validate the\neffectiveness of our method, demonstrating superior performance across multiple\nCD-FSS benchmarks.", "AI": {"tldr": "Proposes Informative Structure Adaptation (ISA) for cross-domain few-shot segmentation (CD-FSS) without retraining, using domain-specific model structures and hierarchical training.", "motivation": "Addresses challenges in CD-FSS due to diverse target domains and limited support data, avoiding costly retraining.", "method": "Adapts model structures using a novel Fisher score, then trains them hierarchically with support samples.", "result": "Superior performance on CD-FSS benchmarks, eliminating the need for redesign or retraining.", "conclusion": "ISA effectively handles domain shifts and enhances adaptation for new domains in CD-FSS."}}
{"id": "2504.17058", "pdf": "https://arxiv.org/pdf/2504.17058", "abs": "https://arxiv.org/abs/2504.17058", "authors": ["Rahul Vishwakarma", "Shrey Dharmendra Modi", "Vishwanath Seshagiri"], "title": "Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 1 figure", "summary": "The generation of high-quality synthetic data presents significant challenges\nin machine learning research, particularly regarding statistical fidelity and\nuncertainty quantification. Existing generative models produce compelling\nsynthetic samples but lack rigorous statistical guarantees about their relation\nto the underlying data distribution, limiting their applicability in critical\ndomains requiring robust error bounds. We address this fundamental limitation\nby presenting a novel framework that incorporates conformal prediction\nmethodologies into Generative Adversarial Networks (GANs). By integrating\nmultiple conformal prediction paradigms including Inductive Conformal\nPrediction (ICP), Mondrian Conformal Prediction, Cross-Conformal Prediction,\nand Venn-Abers Predictors, we establish distribution-free uncertainty\nquantification in generated samples. This approach, termed Conformalized GAN\n(cGAN), demonstrates enhanced calibration properties while maintaining the\ngenerative power of traditional GANs, producing synthetic data with provable\nstatistical guarantees. We provide rigorous mathematical proofs establishing\nfinite-sample validity guarantees and asymptotic efficiency properties,\nenabling the reliable application of synthetic data in high-stakes domains\nincluding healthcare, finance, and autonomous systems.", "AI": {"tldr": "The paper introduces Conformalized GAN (cGAN), a framework integrating conformal prediction into GANs to provide statistical guarantees for synthetic data generation.", "motivation": "Existing generative models lack rigorous statistical guarantees, limiting their use in critical domains. The paper aims to address this by ensuring uncertainty quantification in synthetic data.", "method": "The framework incorporates multiple conformal prediction paradigms (ICP, Mondrian, Cross-Conformal, Venn-Abers) into GANs to achieve distribution-free uncertainty quantification.", "result": "cGAN shows improved calibration and maintains generative power, offering provable statistical guarantees for synthetic data.", "conclusion": "The approach enables reliable synthetic data use in high-stakes domains like healthcare and finance, with proven validity and efficiency."}}
{"id": "2404.19460", "pdf": "https://arxiv.org/pdf/2404.19460", "abs": "https://arxiv.org/abs/2404.19460", "authors": ["Antonio Emanuele Cin\u00e0", "J\u00e9r\u00f4me Rony", "Maura Pintor", "Luca Demetrio", "Ambra Demontis", "Battista Biggio", "Ismail Ben Ayed", "Fabio Roli"], "title": "AttackBench: Evaluating Gradient-based Attacks for Adversarial Examples", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": "Paper accepted at AAAI2025. Project page and leaderboard:\n  https://attackbench.github.io", "summary": "Adversarial examples are typically optimized with gradient-based attacks.\nWhile novel attacks are continuously proposed, each is shown to outperform its\npredecessors using different experimental setups, hyperparameter settings, and\nnumber of forward and backward calls to the target models. This provides\noverly-optimistic and even biased evaluations that may unfairly favor one\nparticular attack over the others. In this work, we aim to overcome these\nlimitations by proposing AttackBench, i.e., the first evaluation framework that\nenables a fair comparison among different attacks. To this end, we first\npropose a categorization of gradient-based attacks, identifying their main\ncomponents and differences. We then introduce our framework, which evaluates\ntheir effectiveness and efficiency. We measure these characteristics by (i)\ndefining an optimality metric that quantifies how close an attack is to the\noptimal solution, and (ii) limiting the number of forward and backward queries\nto the model, such that all attacks are compared within a given maximum query\nbudget. Our extensive experimental analysis compares more than $100$ attack\nimplementations with a total of over $800$ different configurations against\nCIFAR-10 and ImageNet models, highlighting that only very few attacks\noutperform all the competing approaches. Within this analysis, we shed light on\nseveral implementation issues that prevent many attacks from finding better\nsolutions or running at all. We release AttackBench as a publicly-available\nbenchmark, aiming to continuously update it to include and evaluate novel\ngradient-based attacks for optimizing adversarial examples.", "AI": {"tldr": "AttackBench is a framework for fair comparison of gradient-based adversarial attacks, addressing biased evaluations in existing methods.", "motivation": "Current adversarial attack evaluations are overly optimistic and biased due to inconsistent experimental setups, favoring certain attacks unfairly.", "method": "Proposes AttackBench, categorizing attacks and evaluating effectiveness and efficiency via an optimality metric and query budget constraints.", "result": "Extensive experiments on 100+ attack implementations show few outperform others, revealing implementation issues.", "conclusion": "AttackBench is released as a public benchmark to standardize and update evaluations of gradient-based attacks."}}
{"id": "2504.21476", "pdf": "https://arxiv.org/pdf/2504.21476", "abs": "https://arxiv.org/abs/2504.21476", "authors": ["Xinyu Li", "Qi Yao", "Yuanda Wang"], "title": "GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "The 34th International Joint Conference on Artificial Intelligence\n  (IJCAI 2025)", "summary": "Garment sewing patterns are fundamental design elements that bridge the gap\nbetween design concepts and practical manufacturing. The generative modeling of\nsewing patterns is crucial for creating diversified garments. However, existing\napproaches are limited either by reliance on a single input modality or by\nsuboptimal generation efficiency. In this work, we present GarmentDiffusion, a\nnew generative model capable of producing centimeter-precise, vectorized 3D\nsewing patterns from multimodal inputs (text, image, and incomplete sewing\npattern). Our method efficiently encodes 3D sewing pattern parameters into\ncompact edge token representations, achieving a sequence length that is 10\ntimes shorter than that of the autoregressive SewingGPT in DressCode. By\nemploying a diffusion transformer, we simultaneously denoise all edge tokens\nalong the temporal axis, while maintaining a constant number of denoising steps\nregardless of dataset-specific edge and panel statistics. With all combination\nof designs of our model, the sewing pattern generation speed is accelerated by\n100 times compared to SewingGPT. We achieve new state-of-the-art results on\nDressCodeData, as well as on the largest sewing pattern dataset, namely\nGarmentCodeData. The project website is available at\nhttps://shenfu-research.github.io/Garment-Diffusion/.", "AI": {"tldr": "GarmentDiffusion is a generative model for creating precise 3D sewing patterns from multimodal inputs, improving efficiency and speed over existing methods.", "motivation": "Existing methods for sewing pattern generation are limited by input modality constraints and inefficiency.", "method": "Uses a diffusion transformer to encode 3D sewing patterns into compact edge tokens, enabling faster and more efficient generation.", "result": "Achieves 100x speedup over SewingGPT and state-of-the-art performance on DressCodeData and GarmentCodeData.", "conclusion": "GarmentDiffusion sets a new benchmark for efficient and precise sewing pattern generation."}}
{"id": "2504.20055", "pdf": "https://arxiv.org/pdf/2504.20055", "abs": "https://arxiv.org/abs/2504.20055", "authors": ["Juan D. Pinto", "Luc Paquette"], "title": "A constraints-based approach to fully interpretable neural networks for detecting learner behaviors", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to International Conference on Educational Data Mining (EDM)\n  2025", "summary": "The increasing use of complex machine learning models in education has led to\nconcerns about their interpretability, which in turn has spurred interest in\ndeveloping explainability techniques that are both faithful to the model's\ninner workings and intelligible to human end-users. In this paper, we describe\na novel approach to creating a neural-network-based behavior detection model\nthat is interpretable by design. Our model is fully interpretable, meaning that\nthe parameters we extract for our explanations have a clear interpretation,\nfully capture the model's learned knowledge about the learner behavior of\ninterest, and can be used to create explanations that are both faithful and\nintelligible. We achieve this by implementing a series of constraints to the\nmodel that both simplify its inference process and bring it closer to a human\nconception of the task at hand. We train the model to detect gaming-the-system\nbehavior, evaluate its performance on this task, and compare its learned\npatterns to those identified by human experts. Our results show that the model\nis successfully able to learn patterns indicative of gaming-the-system behavior\nwhile providing evidence for fully interpretable explanations. We discuss the\nimplications of our approach and suggest ways to evaluate explainability using\na human-grounded approach.", "AI": {"tldr": "A novel interpretable neural-network-based model for detecting gaming-the-system behavior in education, designed to provide faithful and intelligible explanations.", "motivation": "Address concerns about the interpretability of complex machine learning models in education by developing a model that is interpretable by design.", "method": "Implement constraints to simplify inference and align with human task conception, training the model to detect gaming-the-system behavior.", "result": "The model successfully learns patterns indicative of gaming-the-system behavior and provides fully interpretable explanations.", "conclusion": "The approach demonstrates the feasibility of interpretable models in education, suggesting human-grounded evaluation for explainability."}}
{"id": "2405.15913", "pdf": "https://arxiv.org/pdf/2405.15913", "abs": "https://arxiv.org/abs/2405.15913", "authors": ["Ryan McKenna"], "title": "Scaling up the Banded Matrix Factorization Mechanism for Differentially Private ML", "categories": ["cs.LG", "cs.CR", "cs.DS"], "comment": null, "summary": "Correlated noise mechanisms such as DP Matrix Factorization (DP-MF) have\nproven to be effective alternatives to DP-SGD in large-epsilon few-epoch\ntraining regimes. Significant work has been done to find the best correlated\nnoise strategies, and the current state-of-the-art approach is DP-BandMF, which\noptimally balances the benefits of privacy amplification and noise correlation.\nDespite it's utility advantages, severe scalability limitations prevent this\nmechanism from handling large-scale training scenarios where the number of\ntraining iterations may exceed $10^4$ and the number of model parameters may\nexceed $10^7$. In this work, we present techniques to scale up DP-BandMF along\nthese two dimensions, significantly extending it's reach and enabling it to\nhandle settings with virtually any number of model parameters and training\niterations, with negligible utility degradation.", "AI": {"tldr": "Techniques to scale DP-BandMF for large-scale training, overcoming limitations in iterations and parameters.", "motivation": "DP-BandMF's scalability issues hinder its use in large-scale scenarios with many iterations or parameters.", "method": "Developed techniques to extend DP-BandMF's scalability for high iteration counts and large parameter sets.", "result": "Enabled DP-BandMF to handle virtually any number of parameters and iterations with minimal utility loss.", "conclusion": "Scaled DP-BandMF effectively broadens its applicability in large-scale training without sacrificing utility."}}
{"id": "2504.21497", "pdf": "https://arxiv.org/pdf/2504.21497", "abs": "https://arxiv.org/abs/2504.21497", "authors": ["Mengting Wei", "Yante Li", "Tuomas Varanka", "Yan Jiang", "Guoying Zhao"], "title": "MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance", "categories": ["cs.CV"], "comment": null, "summary": "In this study, we propose a method for video face reenactment that integrates\na 3D face parametric model into a latent diffusion framework, aiming to improve\nshape consistency and motion control in existing video-based face generation\napproaches. Our approach employs the FLAME (Faces Learned with an Articulated\nModel and Expressions) model as the 3D face parametric representation,\nproviding a unified framework for modeling face expressions and head pose. This\nnot only enables precise extraction of motion features from driving videos, but\nalso contributes to the faithful preservation of face shape and geometry.\nSpecifically, we enhance the latent diffusion model with rich 3D expression and\ndetailed pose information by incorporating depth maps, normal maps, and\nrendering maps derived from FLAME sequences. These maps serve as motion\nguidance and are encoded into the denoising UNet through a specifically\ndesigned Geometric Guidance Encoder (GGE). A multi-layer feature fusion module\nwith integrated self-attention mechanisms is used to combine facial appearance\nand motion latent features within the spatial domain. By utilizing the 3D face\nparametric model as motion guidance, our method enables parametric alignment of\nface identity between the reference image and the motion captured from the\ndriving video. Experimental results on benchmark datasets show that our method\nexcels at generating high-quality face animations with precise expression and\nhead pose variation modeling. In addition, it demonstrates strong\ngeneralization performance on out-of-domain images. Code is publicly available\nat https://github.com/weimengting/MagicPortrait.", "AI": {"tldr": "A method for video face reenactment using a 3D face parametric model (FLAME) integrated into a latent diffusion framework, improving shape consistency and motion control.", "motivation": "To enhance video-based face generation by ensuring shape consistency and precise motion control, addressing limitations in existing approaches.", "method": "Uses FLAME for 3D face representation, incorporating depth, normal, and rendering maps into a latent diffusion model. A Geometric Guidance Encoder (GGE) and multi-layer feature fusion module combine appearance and motion features.", "result": "Generates high-quality face animations with accurate expression and pose modeling, showing strong generalization on out-of-domain images.", "conclusion": "The proposed method effectively integrates 3D face modeling with latent diffusion, achieving superior performance in face reenactment."}}
{"id": "2504.20834", "pdf": "https://arxiv.org/pdf/2504.20834", "abs": "https://arxiv.org/abs/2504.20834", "authors": ["Alan Lee", "Harry Tong"], "title": "Token-Efficient RL for LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "Title updated to \"Token-Efficient RL for LLM Reasoning\" to better\n  reflect algorithmic focus. Revised abstract, intro, and conclusion. Paper\n  shortened and typos fixed", "summary": "We propose reinforcement learning (RL) strategies tailored for reasoning in\nlarge language models (LLMs) under strict memory and compute limits, with a\nparticular focus on compatibility with LoRA fine-tuning. Building on early\npolicy gradient methods with baseline subtraction, we design critic-free\nmethods that operate on a small, informative subset of output tokens to reduce\nmemory usage and stabilize training. We introduce S-GRPO, a stochastic variant\nof Group Relative Policy Optimization, and T-SPMO, a token-level prefix\nmatching approach for fine-grained credit assignment. Applied to Qwen2-1.5B,\nour methods raise accuracy on the SVAMP benchmark from 46% to over 70% and show\nstrong performance on multi-digit multiplication. Surprisingly, full-token GRPO\nunder LoRA fails to improve over the base model, suggesting that selective\ntoken-level optimization may act as an implicit regularizer in low-parameter\ntraining regimes.", "AI": {"tldr": "Proposes RL strategies for LLMs under memory/compute limits, focusing on LoRA compatibility. Introduces S-GRPO and T-SPMO, improving SVAMP accuracy from 46% to 70%.", "motivation": "Address memory and compute constraints in LLMs while maintaining compatibility with LoRA fine-tuning.", "method": "Uses critic-free RL methods on token subsets (S-GRPO, T-SPMO) for efficiency and stability.", "result": "Achieves 70% accuracy on SVAMP, strong multi-digit multiplication performance. Full-token GRPO under LoRA fails.", "conclusion": "Selective token-level optimization may act as an implicit regularizer in low-parameter training."}}
{"id": "2406.01781", "pdf": "https://arxiv.org/pdf/2406.01781", "abs": "https://arxiv.org/abs/2406.01781", "authors": ["Alexander Denker", "Francisco Vargas", "Shreyas Padhy", "Kieran Didi", "Simon Mathis", "Vincent Dutordoir", "Riccardo Barbano", "Emile Mathieu", "Urszula Julia Komorowska", "Pietro Lio"], "title": "DEFT: Efficient Fine-Tuning of Diffusion Models by Learning the Generalised $h$-transform", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2312.09236", "summary": "Generative modelling paradigms based on denoising diffusion processes have\nemerged as a leading candidate for conditional sampling in inverse problems. In\nmany real-world applications, we often have access to large, expensively\ntrained unconditional diffusion models, which we aim to exploit for improving\nconditional sampling. Most recent approaches are motivated heuristically and\nlack a unifying framework, obscuring connections between them. Further, they\noften suffer from issues such as being very sensitive to hyperparameters, being\nexpensive to train or needing access to weights hidden behind a closed API. In\nthis work, we unify conditional training and sampling using the mathematically\nwell-understood Doob's h-transform. This new perspective allows us to unify\nmany existing methods under a common umbrella. Under this framework, we propose\nDEFT (Doob's h-transform Efficient FineTuning), a new approach for conditional\ngeneration that simply fine-tunes a very small network to quickly learn the\nconditional $h$-transform, while keeping the larger unconditional network\nunchanged. DEFT is much faster than existing baselines while achieving\nstate-of-the-art performance across a variety of linear and non-linear\nbenchmarks. On image reconstruction tasks, we achieve speedups of up to\n1.6$\\times$, while having the best perceptual quality on natural images and\nreconstruction performance on medical images. Further, we also provide initial\nexperiments on protein motif scaffolding and outperform reconstruction guidance\nmethods.", "AI": {"tldr": "The paper introduces DEFT, a method for conditional generation using Doob's h-transform, unifying existing approaches and achieving faster, high-performance results.", "motivation": "To address issues like hyperparameter sensitivity and inefficiency in existing conditional sampling methods for diffusion models.", "method": "Proposes DEFT, which fine-tunes a small network to learn the conditional h-transform while keeping the unconditional model unchanged.", "result": "DEFT achieves state-of-the-art performance, with speedups up to 1.6x and superior perceptual quality on tasks like image reconstruction and protein motif scaffolding.", "conclusion": "DEFT provides a unified, efficient, and high-performing framework for conditional generation in diffusion models."}}
{"id": "2505.00308", "pdf": "https://arxiv.org/pdf/2505.00308", "abs": "https://arxiv.org/abs/2505.00308", "authors": ["Biling Wang", "Austen Maniscalco", "Ti Bai", "Siqiu Wang", "Michael Dohopolski", "Mu-Han Lin", "Chenyang Shen", "Dan Nguyen", "Junzhou Huang", "Steve Jiang", "Xinlei Wang"], "title": "AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality", "categories": ["cs.CV", "cs.AI", "stat.AP"], "comment": null, "summary": "Purpose: This study presents a Deep Learning (DL)-based quality assessment\n(QA) approach for evaluating auto-generated contours (auto-contours) in\nradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging\nBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,\nthe method enables confident QA predictions without relying on ground truth\ncontours or extensive manual labeling. Methods: We developed a BOC model to\nclassify auto-contour quality and quantify prediction uncertainty. A\ncalibration step was used to optimize uncertainty thresholds that meet clinical\naccuracy needs. The method was validated under three data scenarios: no manual\nlabels, limited labels, and extensive labels. For rectum contours in prostate\ncancer, we applied geometric surrogate labels when manual labels were absent,\ntransfer learning when limited, and direct supervision when ample labels were\navailable. Results: The BOC model delivered robust performance across all\nscenarios. Fine-tuning with just 30 manual labels and calibrating with 34\nsubjects yielded over 90% accuracy on test data. Using the calibrated\nthreshold, over 93% of the auto-contours' qualities were accurately predicted\nin over 98% of cases, reducing unnecessary manual reviews and highlighting\ncases needing correction. Conclusion: The proposed QA model enhances contouring\nefficiency in OART by reducing manual workload and enabling fast, informed\nclinical decisions. Through uncertainty quantification, it ensures safer, more\nreliable radiotherapy workflows.", "AI": {"tldr": "A Deep Learning-based QA method for auto-contours in radiotherapy uses Bayesian Ordinal Classification and uncertainty thresholds to reduce manual workload and improve accuracy.", "motivation": "To enhance efficiency in Online Adaptive Radiotherapy by providing a reliable QA method for auto-contours without heavy reliance on ground truth or extensive labeling.", "method": "Developed a Bayesian Ordinal Classification model to classify contour quality and quantify uncertainty, validated under three data scenarios (no labels, limited labels, extensive labels).", "result": "Achieved over 90% accuracy with minimal manual labels (30) and calibration (34 subjects), accurately predicting 93% of auto-contour qualities in 98% of cases.", "conclusion": "The method improves OART workflow by reducing manual reviews, enabling faster decisions, and ensuring safer radiotherapy through uncertainty quantification."}}
{"id": "2504.21415", "pdf": "https://arxiv.org/pdf/2504.21415", "abs": "https://arxiv.org/abs/2504.21415", "authors": ["Yi Wang", "Chengyv Wu", "Yang Liao", "Maowei You"], "title": "Optimizing Mouse Dynamics for User Authentication by Machine Learning: Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model Performance Challenges", "categories": ["cs.CR", "cs.AI"], "comment": "13pages, 10 figures", "summary": "User authentication is essential to ensure secure access to computer systems,\nyet traditional methods face limitations in usability, cost, and security.\nMouse dynamics authentication, based on the analysis of users' natural\ninteraction behaviors with mouse devices, offers a cost-effective,\nnon-intrusive, and adaptable solution. However, challenges remain in\ndetermining the optimal data volume, balancing accuracy and practicality, and\neffectively capturing temporal behavioral patterns. In this study, we propose a\nstatistical method using Gaussian kernel density estimate (KDE) and\nKullback-Leibler (KL) divergence to estimate the sufficient data volume for\ntraining authentication models. We introduce the Mouse Authentication Unit\n(MAU), leveraging Approximate Entropy (ApEn) to optimize segment length for\nefficient and accurate behavioral representation. Furthermore, we design the\nLocal-Time Mouse Authentication (LT-AMouse) framework, integrating 1D-ResNet\nfor local feature extraction and GRU for modeling long-term temporal\ndependencies. Taking the Balabit and DFL datasets as examples, we significantly\nreduced the data scale, particularly by a factor of 10 for the DFL dataset,\ngreatly alleviating the training burden. Additionally, we determined the\noptimal input recognition unit length for the user authentication system on\ndifferent datasets based on the slope of Approximate Entropy. Training with\nimbalanced samples, our model achieved a successful defense AUC 98.52% for\nblind attack on the DFL dataset and 94.65% on the Balabit dataset, surpassing\nthe current sota performance.", "AI": {"tldr": "The paper proposes a statistical method using Gaussian KDE and KL divergence to optimize mouse dynamics authentication, introducing MAU and LT-AMouse frameworks for efficient and accurate user authentication.", "motivation": "Traditional user authentication methods have limitations in usability, cost, and security, prompting the need for a cost-effective and non-intrusive solution like mouse dynamics.", "method": "The study uses Gaussian KDE and KL divergence for data volume estimation, MAU with ApEn for segment optimization, and LT-AMouse with 1D-ResNet and GRU for feature extraction and temporal modeling.", "result": "The approach reduced data scale by 10x for DFL, achieved 98.52% AUC for blind attack defense on DFL and 94.65% on Balabit, outperforming current methods.", "conclusion": "The proposed frameworks effectively address challenges in mouse dynamics authentication, offering a scalable and high-performing solution."}}
{"id": "2406.02175", "pdf": "https://arxiv.org/pdf/2406.02175", "abs": "https://arxiv.org/abs/2406.02175", "authors": ["Ayman Chaouki", "Jesse Read", "Albert Bifet"], "title": "Branches: Efficiently Seeking Optimal Sparse Decision Trees with AO*", "categories": ["cs.LG"], "comment": "Proceedings of the 42nd International Conference on Machine Learning,\n  Vancouver, Canada. PMLR 267, 2025", "summary": "Decision Tree (DT) Learning is a fundamental problem in Interpretable Machine\nLearning, yet it poses a formidable optimisation challenge. Practical\nalgorithms have recently emerged, primarily leveraging Dynamic Programming and\nBranch & Bound. However, most of these approaches rely on a Depth-First-Search\nstrategy, which is inefficient when searching for DTs at high depths and\nrequires the definition of a maximum depth hyperparameter. Best-First-Search\nwas also employed by other methods to circumvent these issues. The downside of\nthis strategy is its higher memory consumption, as such, it has to be designed\nin a fully efficient manner that takes full advantage of the problem's\nstructure. We formulate the problem within an AND/OR graph search framework and\nwe solve it with a novel AO*-type algorithm called Branches. We prove both\noptimality and complexity guarantees for Branches and we show that it is more\nefficient than the state of the art theoretically and on a variety of\nexperiments. Furthermore, Branches supports non-binary features unlike the\nother methods, we show that this property can further induce larger gains in\ncomputational efficiency.", "AI": {"tldr": "The paper introduces Branches, an AO*-type algorithm for Decision Tree Learning, addressing inefficiencies in Depth-First-Search and memory issues in Best-First-Search, with proven optimality and support for non-binary features.", "motivation": "Current Decision Tree Learning methods face inefficiencies in high-depth searches and memory consumption, prompting the need for a more efficient approach.", "method": "The problem is framed within an AND/OR graph search framework and solved using Branches, a novel AO*-type algorithm.", "result": "Branches outperforms state-of-the-art methods in efficiency and supports non-binary features, enhancing computational gains.", "conclusion": "Branches offers a theoretically and practically superior solution for Decision Tree Learning, with broader applicability due to non-binary feature support."}}
{"id": "2505.03113", "pdf": "https://arxiv.org/pdf/2505.03113", "abs": "https://arxiv.org/abs/2505.03113", "authors": ["Zherui Zhang", "Rongtao Xu", "Jie Zhou", "Changwei Wang", "Xingtian Pei", "Wenhao Xu", "Jiguang Zhang", "Li Guo", "Longxiang Gao", "Wenbo Xu", "Shibiao Xu"], "title": "Image Recognition with Online Lightweight Vision Transformer: A Survey", "categories": ["cs.CV"], "comment": null, "summary": "The Transformer architecture has achieved significant success in natural\nlanguage processing, motivating its adaptation to computer vision tasks. Unlike\nconvolutional neural networks, vision transformers inherently capture\nlong-range dependencies and enable parallel processing, yet lack inductive\nbiases and efficiency benefits, facing significant computational and memory\nchallenges that limit its real-world applicability. This paper surveys various\nonline strategies for generating lightweight vision transformers for image\nrecognition, focusing on three key areas: Efficient Component Design, Dynamic\nNetwork, and Knowledge Distillation. We evaluate the relevant exploration for\neach topic on the ImageNet-1K benchmark, analyzing trade-offs among precision,\nparameters, throughput, and more to highlight their respective advantages,\ndisadvantages, and flexibility. Finally, we propose future research directions\nand potential challenges in the lightweighting of vision transformers with the\naim of inspiring further exploration and providing practical guidance for the\ncommunity. Project Page: https://github.com/ajxklo/Lightweight-VIT", "AI": {"tldr": "A survey of strategies for creating lightweight vision transformers for image recognition, focusing on efficiency, dynamic networks, and knowledge distillation, with evaluations on ImageNet-1K and future research directions.", "motivation": "The Transformer architecture's success in NLP inspires its adaptation to computer vision, but it faces computational and memory challenges due to lack of inductive biases and efficiency benefits.", "method": "The paper surveys three key areas: Efficient Component Design, Dynamic Network, and Knowledge Distillation, evaluating their trade-offs on ImageNet-1K.", "result": "Analysis highlights advantages, disadvantages, and flexibility of each strategy in terms of precision, parameters, and throughput.", "conclusion": "Future research directions and challenges in lightweighting vision transformers are proposed to guide further exploration."}}
{"id": "2505.01288", "pdf": "https://arxiv.org/pdf/2505.01288", "abs": "https://arxiv.org/abs/2505.01288", "authors": ["Changhe Chen", "Quantao Yang", "Xiaohao Xu", "Nima Fazeli", "Olov Andersson"], "title": "ViSA-Flow: Accelerating Robot Skill Learning via Large-Scale Video Semantic Action Flow", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "One of the central challenges preventing robots from acquiring complex\nmanipulation skills is the prohibitive cost of collecting large-scale robot\ndemonstrations. In contrast, humans are able to learn efficiently by watching\nothers interact with their environment. To bridge this gap, we introduce\nsemantic action flow as a core intermediate representation capturing the\nessential spatio-temporal manipulator-object interactions, invariant to\nsuperficial visual differences. We present ViSA-Flow, a framework that learns\nthis representation self-supervised from unlabeled large-scale video data.\nFirst, a generative model is pre-trained on semantic action flows automatically\nextracted from large-scale human-object interaction video data, learning a\nrobust prior over manipulation structure. Second, this prior is efficiently\nadapted to a target robot by fine-tuning on a small set of robot demonstrations\nprocessed through the same semantic abstraction pipeline. We demonstrate\nthrough extensive experiments on the CALVIN benchmark and real-world tasks that\nViSA-Flow achieves state-of-the-art performance, particularly in low-data\nregimes, outperforming prior methods by effectively transferring knowledge from\nhuman video observation to robotic execution. Videos are available at\nhttps://visaflow-web.github.io/ViSAFLOW.", "AI": {"tldr": "ViSA-Flow introduces semantic action flow to bridge the gap between human and robot learning, achieving state-of-the-art performance with minimal robot demonstrations.", "motivation": "The high cost of large-scale robot demonstrations hinders complex manipulation skills, while humans learn efficiently by observing.", "method": "ViSA-Flow learns semantic action flow self-supervised from human videos, then fine-tunes on few robot demos.", "result": "Outperforms prior methods, especially in low-data regimes, by transferring knowledge from human videos to robots.", "conclusion": "ViSA-Flow effectively leverages human video data to enhance robotic manipulation skills with minimal demonstrations."}}
{"id": "2406.07246", "pdf": "https://arxiv.org/pdf/2406.07246", "abs": "https://arxiv.org/abs/2406.07246", "authors": ["Vijaya Krishna Yalavarthi", "Randolf Scholz", "Christian Kloetergens", "Kiran Madhusudhanan", "Stefan Born", "Lars Schmidt-Thieme"], "title": "Marginalization Consistent Probabilistic Forecasting of Irregular Time Series via Mixture of Separable flows", "categories": ["cs.LG"], "comment": null, "summary": "Probabilistic forecasting models for joint distributions of targets in\nirregular time series with missing values are a heavily under-researched area\nin machine learning, with, to the best of our knowledge, only two Models have\nbeen researched so far: The Gaussian Process Regression model, and ProFITi.\nWhile ProFITi, thanks to using multivariate normalizing flows, is very\nexpressive, leading to better predictive performance, it suffers from\nmarginalization inconsistency: It does not guarantee that the marginal\ndistributions of a subset of variables in its predictive distributions coincide\nwith the directly predicted distributions of these variables. When asked to\ndirectly predict marginal distributions, they are often vastly inaccurate. We\npropose MOSES (Marginalization Consistent Mixture of Separable Flows), a model\nthat parametrizes a stochastic process through a mixture of several latent\nmultivariate Gaussian Processes combined with separable univariate Normalizing\nFlows. In particular, MOSES can be analytically marginalized, allowing it to\ndirectly answer a wider range of probabilistic queries than most competitors.\nExperiments on four datasets show that MOSES achieves both accurate joint and\nmarginal predictions, surpassing all other marginalization consistent\nbaselines, while only trailing slightly behind ProFITi in joint prediction, but\nvastly superior when predicting marginal distributions.", "AI": {"tldr": "MOSES is a new model for probabilistic forecasting in irregular time series with missing values, addressing marginalization inconsistency in existing methods like ProFITi. It combines Gaussian Processes and Normalizing Flows for accurate joint and marginal predictions.", "motivation": "Existing models like ProFITi lack marginalization consistency, leading to inaccurate marginal predictions. MOSES aims to solve this issue while maintaining strong joint prediction performance.", "method": "MOSES uses a mixture of latent multivariate Gaussian Processes and separable univariate Normalizing Flows, enabling analytical marginalization for broader probabilistic queries.", "result": "MOSES outperforms other marginalization-consistent baselines in joint and marginal predictions, nearly matching ProFITi in joint prediction but excelling in marginal accuracy.", "conclusion": "MOSES provides a robust solution for probabilistic forecasting, balancing joint and marginal prediction accuracy, and addressing a critical gap in existing models."}}
{"id": "2505.04088", "pdf": "https://arxiv.org/pdf/2505.04088", "abs": "https://arxiv.org/abs/2505.04088", "authors": ["Shang Zhang", "Huanbin Zhang", "Dali Feng", "Yujie Cui", "Ruoyan Xiong", "Cen He"], "title": "SMMT: Siamese Motion Mamba with Self-attention for Thermal Infrared Target Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Thermal infrared (TIR) object tracking often suffers from challenges such as\ntarget occlusion, motion blur, and background clutter, which significantly\ndegrade the performance of trackers. To address these issues, this paper\npro-poses a novel Siamese Motion Mamba Tracker (SMMT), which integrates a\nbidirectional state-space model and a self-attention mechanism. Specifically,\nwe introduce the Motion Mamba module into the Siamese architecture to ex-tract\nmotion features and recover overlooked edge details using bidirectional\nmodeling and self-attention. We propose a Siamese parameter-sharing strate-gy\nthat allows certain convolutional layers to share weights. This approach\nreduces computational redundancy while preserving strong feature\nrepresen-tation. In addition, we design a motion edge-aware regression loss to\nimprove tracking accuracy, especially for motion-blurred targets. Extensive\nexperi-ments are conducted on four TIR tracking benchmarks, including\nLSOTB-TIR, PTB-TIR, VOT-TIR2015, and VOT-TIR 2017. The results show that SMMT\nachieves superior performance in TIR target tracking.", "AI": {"tldr": "The paper proposes a Siamese Motion Mamba Tracker (SMMT) for thermal infrared (TIR) object tracking, addressing challenges like occlusion and motion blur with bidirectional state-space modeling and self-attention.", "motivation": "TIR tracking faces issues like occlusion, motion blur, and clutter, degrading tracker performance.", "method": "SMMT integrates bidirectional state-space modeling and self-attention in a Siamese architecture, with weight-sharing layers and a motion edge-aware loss.", "result": "SMMT outperforms on benchmarks LSOTB-TIR, PTB-TIR, VOT-TIR2015, and VOT-TIR2017.", "conclusion": "SMMT is effective for TIR tracking, improving accuracy and handling motion blur."}}
{"id": "2505.02881", "pdf": "https://arxiv.org/pdf/2505.02881", "abs": "https://arxiv.org/abs/2505.02881", "authors": ["Kazuki Fujii", "Yukito Tajima", "Sakae Mizuki", "Hinari Shimada", "Taihei Shiotani", "Koshiro Saito", "Masanari Ohi", "Masaki Kawamura", "Taishi Nakamura", "Takumi Okamoto", "Shigeki Ishida", "Kakeru Hattori", "Youmi Ma", "Hiroya Takamura", "Rio Yokota", "Naoaki Okazaki"], "title": "Rewriting Pre-Training Data Boosts LLM Performance in Math and Code", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The performance of large language models (LLMs) in program synthesis and\nmathematical reasoning is fundamentally limited by the quality of their\npre-training corpora. We introduce two openly licensed datasets, released under\nthe Llama 3.3 Community License, that significantly enhance LLM performance by\nsystematically rewriting public data. SwallowCode (approximately 16.1 billion\ntokens) refines Python snippets from The-Stack-v2 through a novel four-stage\npipeline: syntax validation, pylint-based style filtering, and a two-stage LLM\nrewriting process that enforces style conformity and transforms snippets into\nself-contained, algorithmically efficient examples. Unlike prior methods that\nrely on exclusionary filtering or limited transformations, our\ntransform-and-retain approach upgrades low-quality code, maximizing data\nutility. SwallowMath (approximately 2.3 billion tokens) enhances Finemath-4+ by\nremoving boilerplate, restoring context, and reformatting solutions into\nconcise, step-by-step explanations. Within a fixed 50 billion token training\nbudget, continual pre-training of Llama-3.1-8B with SwallowCode boosts pass@1\nby +17.0 on HumanEval and +17.7 on HumanEval+ compared to Stack-Edu, surpassing\nthe baseline model's code generation capabilities. Similarly, substituting\nSwallowMath yields +12.4 accuracy on GSM8K and +7.6 on MATH. Ablation studies\nconfirm that each pipeline stage contributes incrementally, with rewriting\ndelivering the largest gains. All datasets, prompts, and checkpoints are\npublicly available, enabling reproducible research and advancing LLM\npre-training for specialized domains.", "AI": {"tldr": "Two datasets, SwallowCode and SwallowMath, enhance LLM performance by refining public data through systematic rewriting, improving code generation and mathematical reasoning.", "motivation": "The quality of pre-training corpora limits LLM performance in program synthesis and mathematical reasoning. The paper aims to address this by improving data quality through systematic rewriting.", "method": "Introduces SwallowCode (16.1B tokens) and SwallowMath (2.3B tokens) datasets. SwallowCode uses a four-stage pipeline (syntax validation, style filtering, LLM rewriting) to refine Python snippets. SwallowMath enhances Finemath-4+ by removing boilerplate and reformatting solutions.", "result": "Continual pre-training with SwallowCode boosts pass@1 by +17.0 on HumanEval and +17.7 on HumanEval+. SwallowMath improves accuracy by +12.4 on GSM8K and +7.6 on MATH.", "conclusion": "The datasets significantly enhance LLM performance, with each pipeline stage contributing incrementally. All resources are publicly available for reproducible research."}}
{"id": "2406.13200", "pdf": "https://arxiv.org/pdf/2406.13200", "abs": "https://arxiv.org/abs/2406.13200", "authors": ["Xinyi Gao", "Hongzhi Yin", "Tong Chen", "Guanhua Ye", "Wentao Zhang", "Bin Cui"], "title": "RobGC: Towards Robust Graph Condensation", "categories": ["cs.LG"], "comment": "Accepted by TKDE 2025", "summary": "Graph neural networks (GNNs) have attracted widespread attention for their\nimpressive capability of graph representation learning. However, the increasing\nprevalence of large-scale graphs presents a significant challenge for GNN\ntraining due to their computational demands, limiting the applicability of GNNs\nin various scenarios. In response to this challenge, graph condensation (GC) is\nproposed as a promising acceleration solution, focusing on generating an\ninformative compact graph that enables efficient training of GNNs while\nretaining performance. Despite the potential to accelerate GNN training,\nexisting GC methods overlook the quality of large training graphs during both\nthe training and inference stages. They indiscriminately emulate the training\ngraph distributions, making the condensed graphs susceptible to noises within\nthe training graph and significantly impeding the application of GC in\nintricate real-world scenarios. To address this issue, we propose robust graph\ncondensation (RobGC), a plug-and-play approach for GC to extend the robustness\nand applicability of condensed graphs in noisy graph structure environments.\nSpecifically, RobGC leverages the condensed graph as a feedback signal to guide\nthe denoising process on the original training graph. A label propagation-based\nalternating optimization strategy is in place for the condensation and\ndenoising processes, contributing to the mutual purification of the condensed\ngraph and training graph. Additionally, as a GC method designed for inductive\ngraph inference, RobGC facilitates test-time graph denoising by leveraging the\nnoise-free condensed graph to calibrate the structure of the test graph.\nExtensive experiments show that RobGC is compatible with various GC methods,\nsignificantly boosting their robustness under different types and levels of\ngraph structural noises.", "AI": {"tldr": "Robust Graph Condensation (RobGC) improves GNN training efficiency by generating noise-resistant condensed graphs, enhancing robustness in noisy environments.", "motivation": "Large-scale graphs challenge GNN training due to computational demands and noise susceptibility in existing graph condensation methods.", "method": "RobGC uses condensed graphs as feedback for denoising training graphs, employing label propagation-based alternating optimization for mutual purification.", "result": "RobGC enhances robustness of condensed graphs under various noise types and levels, compatible with existing GC methods.", "conclusion": "RobGC is a plug-and-play solution that extends the applicability of graph condensation in noisy real-world scenarios."}}
{"id": "2505.04594", "pdf": "https://arxiv.org/pdf/2505.04594", "abs": "https://arxiv.org/abs/2505.04594", "authors": ["Zhihao Zhang", "Abhinav Kumar", "Girish Chandar Ganesan", "Xiaoming Liu"], "title": "MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Accurately predicting 3D attributes is crucial for monocular 3D object\ndetection (Mono3D), with depth estimation posing the greatest challenge due to\nthe inherent ambiguity in mapping 2D images to 3D space. While existing methods\nleverage multiple depth cues (e.g., estimating depth uncertainty, modeling\ndepth error) to improve depth accuracy, they overlook that accurate depth\nprediction requires conditioning on other 3D attributes, as these attributes\nare intrinsically inter-correlated through the 3D to 2D projection, which\nultimately limits overall accuracy and stability. Inspired by Chain-of-Thought\n(CoT) in large language models (LLMs), this paper proposes MonoCoP, which\nleverages a Chain-of-Prediction (CoP) to predict attributes sequentially and\nconditionally via three key designs. First, it employs a lightweight\nAttributeNet (AN) for each 3D attribute to learn attribute-specific features.\nNext, MonoCoP constructs an explicit chain to propagate these learned features\nfrom one attribute to the next. Finally, MonoCoP uses a residual connection to\naggregate features for each attribute along the chain, ensuring that later\nattribute predictions are conditioned on all previously processed attributes\nwithout forgetting the features of earlier ones. Experimental results show that\nour MonoCoP achieves state-of-the-art (SoTA) performance on the KITTI\nleaderboard without requiring additional data and further surpasses existing\nmethods on the Waymo and nuScenes frontal datasets.", "AI": {"tldr": "MonoCoP improves monocular 3D object detection by sequentially predicting 3D attributes using a Chain-of-Prediction (CoP) approach, achieving state-of-the-art results.", "motivation": "Existing methods overlook the inter-correlation of 3D attributes, limiting accuracy. MonoCoP addresses this by conditioning predictions on prior attributes.", "method": "Uses AttributeNet for attribute-specific features, constructs a feature propagation chain, and employs residual connections to aggregate features.", "result": "Achieves SoTA on KITTI and outperforms methods on Waymo and nuScenes.", "conclusion": "MonoCoP's sequential and conditional prediction approach enhances accuracy and stability in monocular 3D object detection."}}
{"id": "2505.04558", "pdf": "https://arxiv.org/pdf/2505.04558", "abs": "https://arxiv.org/abs/2505.04558", "authors": ["Wenzhao Liu", "Haoran Li", "Congying Han", "Zicheng Zhang", "Anqi Li", "Tiande Guo"], "title": "Purity Law for Generalizable Neural TSP Solvers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Achieving generalization in neural approaches across different scales and\ndistributions remains a significant challenge for the Traveling Salesman\nProblem~(TSP). A key obstacle is that neural networks often fail to learn\nrobust principles for identifying universal patterns and deriving optimal\nsolutions from diverse instances. In this paper, we first uncover Purity Law\n(PuLa), a fundamental structural principle for optimal TSP solutions, defining\nthat edge prevalence grows exponentially with the sparsity of surrounding\nvertices. Statistically validated across diverse instances, PuLa reveals a\nconsistent bias toward local sparsity in global optima. Building on this\ninsight, we propose Purity Policy Optimization~(PUPO), a novel training\nparadigm that explicitly aligns characteristics of neural solutions with PuLa\nduring the solution construction process to enhance generalization. Extensive\nexperiments demonstrate that PUPO can be seamlessly integrated with popular\nneural solvers, significantly enhancing their generalization performance\nwithout incurring additional computational overhead during inference.", "AI": {"tldr": "The paper introduces Purity Law (PuLa), a structural principle for optimal TSP solutions, and Purity Policy Optimization (PUPO), a training paradigm to enhance neural solvers' generalization.", "motivation": "Generalization in neural approaches for TSP is challenging due to the lack of robust principles for universal patterns.", "method": "Uncover PuLa, a principle linking edge prevalence to vertex sparsity, and propose PUPO to align neural solutions with PuLa.", "result": "PUPO improves generalization of neural solvers without extra computational cost.", "conclusion": "PuLa and PUPO offer a principled way to enhance neural TSP solvers' generalization."}}
{"id": "2406.19657", "pdf": "https://arxiv.org/pdf/2406.19657", "abs": "https://arxiv.org/abs/2406.19657", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "LLMEasyQuant: Scalable Quantization for Parallel and Distributed LLM Inference", "categories": ["cs.LG"], "comment": null, "summary": "As large language models (LLMs) grow in size and deployment scale,\nquantization has become an essential technique for reducing memory footprint\nand improving inference efficiency. However, existing quantization toolkits\noften lack transparency, flexibility, and system-level scalability across GPUs\nand distributed environments. We present \\textbf{LLMEasyQuant}, a modular,\nsystem-aware quantization framework designed for efficient, low-bit inference\nof LLMs on single-node multi-GPU, multi-node, and edge hardware. LLMEasyQuant\nsupports a wide range of quantization methods -- including Symmetric\nQuantization, ZeroQuant, SmoothQuant, and SimQuant -- with unified interfaces\nfor per-layer calibration, bitwidth assignment, and runtime adaptation. It\nintegrates fused CUDA kernels with NCCL-based distributed synchronization and\nsupports both static and online quantization. Empirical results show that\nLLMEasyQuant can achieve substantial speedups in GEMM execution, HBM load time,\nand near-linear multi-GPU scaling. Ablation studies further validate its\nability to balance latency, memory, and accuracy under diverse deployment\nconditions. LLMEasyQuant offers a practical quantization serving system for\nscalable, hardware-optimized LLM inference.", "AI": {"tldr": "LLMEasyQuant is a modular, system-aware quantization framework for efficient low-bit inference of large language models (LLMs) across various hardware setups, offering flexibility, transparency, and scalability.", "motivation": "Existing quantization toolkits lack transparency, flexibility, and scalability for LLMs, necessitating a better solution for efficient inference.", "method": "LLMEasyQuant supports multiple quantization methods (e.g., Symmetric Quantization, ZeroQuant) with unified interfaces for calibration, bitwidth assignment, and runtime adaptation. It integrates fused CUDA kernels and NCCL-based distributed synchronization.", "result": "Empirical results show speedups in GEMM execution, HBM load time, and near-linear multi-GPU scaling, with balanced latency, memory, and accuracy.", "conclusion": "LLMEasyQuant provides a practical, scalable, and hardware-optimized solution for LLM inference."}}
{"id": "2505.04979", "pdf": "https://arxiv.org/pdf/2505.04979", "abs": "https://arxiv.org/abs/2505.04979", "authors": ["Zhuang Qi", "Sijin Zhou", "Lei Meng", "Han Hu", "Han Yu", "Xiangxu Meng"], "title": "Federated Deconfounding and Debiasing Learning for Out-of-Distribution Generalization", "categories": ["cs.CV"], "comment": "IJCAI-25 Accepted", "summary": "Attribute bias in federated learning (FL) typically leads local models to\noptimize inconsistently due to the learning of non-causal associations,\nresulting degraded performance. Existing methods either use data augmentation\nfor increasing sample diversity or knowledge distillation for learning\ninvariant representations to address this problem. However, they lack a\ncomprehensive analysis of the inference paths, and the interference from\nconfounding factors limits their performance. To address these limitations, we\npropose the \\underline{Fed}erated \\underline{D}econfounding and\n\\underline{D}ebiasing \\underline{L}earning (FedDDL) method. It constructs a\nstructured causal graph to analyze the model inference process, and performs\nbackdoor adjustment to eliminate confounding paths. Specifically, we design an\nintra-client deconfounding learning module for computer vision tasks to\ndecouple background and objects, generating counterfactual samples that\nestablish a connection between the background and any label, which stops the\nmodel from using the background to infer the label. Moreover, we design an\ninter-client debiasing learning module to construct causal prototypes to reduce\nthe proportion of the background in prototype components. Notably, it bridges\nthe gap between heterogeneous representations via causal prototypical\nregularization. Extensive experiments on 2 benchmarking datasets demonstrate\nthat \\methodname{} significantly enhances the model capability to focus on main\nobjects in unseen data, leading to 4.5\\% higher Top-1 Accuracy on average over\n9 state-of-the-art existing methods.", "AI": {"tldr": "FedDDL addresses attribute bias in federated learning by deconfounding and debiasing, improving model focus on main objects and boosting accuracy.", "motivation": "Attribute bias in FL causes inconsistent local model optimization due to non-causal associations, degrading performance. Existing methods lack comprehensive inference path analysis and are limited by confounding factors.", "method": "FedDDL constructs a causal graph for inference analysis, uses backdoor adjustment, and includes intra-client deconfounding (decoupling background/objects) and inter-client debiasing (causal prototypes) modules.", "result": "FedDDL achieves 4.5% higher Top-1 Accuracy on average over 9 state-of-the-art methods, enhancing focus on main objects in unseen data.", "conclusion": "FedDDL effectively mitigates attribute bias in FL, improving model performance by addressing confounding and bias through causal analysis and regularization."}}
{"id": "2505.04608", "pdf": "https://arxiv.org/pdf/2505.04608", "abs": "https://arxiv.org/abs/2505.04608", "authors": ["Drew Prinster", "Xing Han", "Anqi Liu", "Suchi Saria"], "title": "WATCH: Adaptive Monitoring for AI Deployments via Weighted-Conformal Martingales", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "To be published in The International Conference on Machine Learning\n  (ICML), 2025", "summary": "Responsibly deploying artificial intelligence (AI) / machine learning (ML)\nsystems in high-stakes settings arguably requires not only proof of system\nreliability, but moreover continual, post-deployment monitoring to quickly\ndetect and address any unsafe behavior. Statistical methods for nonparametric\nchange-point detection -- especially the tools of conformal test martingales\n(CTMs) and anytime-valid inference -- offer promising approaches to this\nmonitoring task. However, existing methods are restricted to monitoring limited\nhypothesis classes or ``alarm criteria'' (such as data shifts that violate\ncertain exchangeability assumptions), do not allow for online adaptation in\nresponse to shifts, and/or do not enable root-cause analysis of any\ndegradation. In this paper, we expand the scope of these monitoring methods by\nproposing a weighted generalization of conformal test martingales (WCTMs),\nwhich lay a theoretical foundation for online monitoring for any unexpected\nchangepoints in the data distribution while controlling false-alarms. For\npractical applications, we propose specific WCTM algorithms that adapt online\nto mild covariate shifts (in the marginal input distribution) while quickly\ndetecting and diagnosing more severe shifts, such as concept shifts (in the\nconditional label distribution) or extreme (out-of-support) covariate shifts\nthat cannot be easily adapted to. On real-world datasets, we demonstrate\nimproved performance relative to state-of-the-art baselines.", "AI": {"tldr": "Proposes weighted conformal test martingales (WCTMs) for post-deployment AI monitoring, enabling online adaptation and root-cause analysis while controlling false alarms.", "motivation": "Ensuring AI/ML system reliability in high-stakes settings requires continual monitoring to detect unsafe behavior, but existing methods are limited in scope and adaptability.", "method": "Introduces WCTMs, a generalization of conformal test martingales, for online monitoring of unexpected changepoints, with algorithms for adapting to mild shifts and detecting severe ones.", "result": "Demonstrates improved performance over state-of-the-art baselines on real-world datasets.", "conclusion": "WCTMs expand monitoring capabilities, offering better adaptability and detection of data shifts, enhancing AI system reliability post-deployment."}}
{"id": "2407.16556", "pdf": "https://arxiv.org/pdf/2407.16556", "abs": "https://arxiv.org/abs/2407.16556", "authors": ["Christodoulos Kechris", "Jonathan Dan", "Jose Miranda", "David Atienza"], "title": "DC is all you need: describing ReLU from a signal processing standpoint", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Non-linear activation functions are crucial in Convolutional Neural Networks.\nHowever, until now they have not been well described in the frequency domain.\nIn this work, we study the spectral behavior of ReLU, a popular activation\nfunction. We use the ReLU's Taylor expansion to derive its frequency domain\nbehavior. We demonstrate that ReLU introduces higher frequency oscillations in\nthe signal and a constant DC component. Furthermore, we investigate the\nimportance of this DC component, where we demonstrate that it helps the model\nextract meaningful features related to the input frequency content. We\naccompany our theoretical derivations with experiments and real-world examples.\nFirst, we numerically validate our frequency response model. Then we observe\nReLU's spectral behavior on two example models and a real-world one. Finally,\nwe experimentally investigate the role of the DC component introduced by ReLU\nin the CNN's representations. Our results indicate that the DC helps to\nconverge to a weight configuration that is close to the initial random weights.", "AI": {"tldr": "The paper analyzes ReLU's spectral behavior in CNNs, showing it introduces higher frequencies and a DC component, which aids feature extraction.", "motivation": "Non-linear activation functions like ReLU are key in CNNs but poorly understood in the frequency domain.", "method": "Uses Taylor expansion to derive ReLU's frequency behavior, validates numerically, and tests on models.", "result": "ReLU adds higher frequencies and a DC component, which helps converge to initial weight configurations.", "conclusion": "The DC component from ReLU is beneficial for feature extraction and model convergence."}}
{"id": "2505.05007", "pdf": "https://arxiv.org/pdf/2505.05007", "abs": "https://arxiv.org/abs/2505.05007", "authors": ["Xin Bi", "Zhichao Li", "Yuxuan Xia", "Panpan Tong", "Lijuan Zhang", "Yang Chen", "Junsheng Fu"], "title": "Driving with Context: Online Map Matching for Complex Roads Using Lane Markings and Scenario Recognition", "categories": ["cs.CV"], "comment": "9 pages and 12 figures. Under review at IEEE RA-L", "summary": "Accurate online map matching is fundamental to vehicle navigation and the\nactivation of intelligent driving functions. Current online map matching\nmethods are prone to errors in complex road networks, especially in multilevel\nroad area. To address this challenge, we propose an online Standard Definition\n(SD) map matching method by constructing a Hidden Markov Model (HMM) with\nmultiple probability factors. Our proposed method can achieve accurate map\nmatching even in complex road networks by carefully leveraging lane markings\nand scenario recognition in the designing of the probability factors. First,\nthe lane markings are generated by a multi-lane tracking method and associated\nwith the SD map using HMM to build an enriched SD map. In areas covered by the\nenriched SD map, the vehicle can re-localize itself by performing Iterative\nClosest Point (ICP) registration for the lane markings. Then, the probability\nfactor accounting for the lane marking detection can be obtained using the\nassociation probability between adjacent lanes and roads. Second, the driving\nscenario recognition model is applied to generate the emission probability\nfactor of scenario recognition, which improves the performance of map matching\non elevated roads and ordinary urban roads underneath them. We validate our\nmethod through extensive road tests in Europe and China, and the experimental\nresults show that our proposed method effectively improves the online map\nmatching accuracy as compared to other existing methods, especially in\nmultilevel road area. Specifically, the experiments show that our proposed\nmethod achieves $F_1$ scores of 98.04% and 94.60% on the Zenseact Open Dataset\nand test data of multilevel road areas in Shanghai respectively, significantly\noutperforming benchmark methods. The implementation is available at\nhttps://github.com/TRV-Lab/LMSR-OMM.", "AI": {"tldr": "Proposes an online SD map matching method using HMM with multiple probability factors for accurate navigation in complex road networks, validated by road tests in Europe and China.", "motivation": "Current online map matching methods struggle with accuracy in complex road networks, especially multilevel roads, necessitating a more robust solution.", "method": "Uses HMM with lane markings (via multi-lane tracking and ICP registration) and scenario recognition to design probability factors for improved map matching.", "result": "Achieves high F1 scores (98.04% and 94.60%) on test datasets, outperforming existing methods in multilevel road areas.", "conclusion": "The proposed method significantly enhances online map matching accuracy, particularly in complex road networks, as demonstrated by experimental results."}}
{"id": "2505.04841", "pdf": "https://arxiv.org/pdf/2505.04841", "abs": "https://arxiv.org/abs/2505.04841", "authors": ["Nishikanta Mohanty", "Bikash K. Behera", "Badshah Mukherjee", "Christopher Ferrie"], "title": "Quantum-Inspired Optimization Process for Data Imputation", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "Data imputation is a critical step in data pre-processing, particularly for\ndatasets with missing or unreliable values. This study introduces a novel\nquantum-inspired imputation framework evaluated on the UCI Diabetes dataset,\nwhich contains biologically implausible missing values across several clinical\nfeatures. The method integrates Principal Component Analysis (PCA) with\nquantum-assisted rotations, optimized through gradient-free classical\noptimizers -COBYLA, Simulated Annealing, and Differential Evolution to\nreconstruct missing values while preserving statistical fidelity. Reconstructed\nvalues are constrained within +/-2 standard deviations of original feature\ndistributions, avoiding unrealistic clustering around central tendencies. This\napproach achieves a substantial and statistically significant improvement,\nincluding an average reduction of over 85% in Wasserstein distance and\nKolmogorov-Smirnov test p-values between 0.18 and 0.22, compared to p-values >\n0.99 in classical methods such as Mean, KNN, and MICE. The method also\neliminates zero-value artifacts and enhances the realism and variability of\nimputed data. By combining quantum-inspired transformations with a scalable\nclassical framework, this methodology provides a robust solution for imputation\ntasks in domains such as healthcare and AI pipelines, where data quality and\nintegrity are crucial.", "AI": {"tldr": "A quantum-inspired imputation framework using PCA and quantum-assisted rotations improves data reconstruction, outperforming classical methods like Mean, KNN, and MICE.", "motivation": "Addressing the challenge of missing or unreliable data in datasets, especially in healthcare, where data integrity is crucial.", "method": "Integrates PCA with quantum-assisted rotations, optimized via gradient-free classical optimizers (COBYLA, Simulated Annealing, Differential Evolution).", "result": "Achieves 85% reduction in Wasserstein distance, p-values between 0.18-0.22, and eliminates unrealistic clustering and zero-value artifacts.", "conclusion": "The framework offers a robust, scalable solution for data imputation, enhancing realism and variability in imputed data."}}
{"id": "2409.01930", "pdf": "https://arxiv.org/pdf/2409.01930", "abs": "https://arxiv.org/abs/2409.01930", "authors": ["Rajesh Upadhayayaya", "Manish Raj Osti", "Zachary Smith", "Chritopher Kottmyer"], "title": "Efficient LLM Context Distillation", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate proficiency across diverse tasks but\noften require targeted adaptations for specific applications. Various methods\nhave been proposed to facilitate this adaptation, including fewshot\nfine-tuning, in-context learning, and context distillation. This paper\nspecifically investigates context distillation a method that extends the\nutility of task-specific examples by internalizing them, thus augmenting the\nexample set accessible for model inference. We conduct a comparative analysis\nof context distillation with in-context learning (ICL) and few-shot fine-tuning\n(FT), aiming to ascertain the efficacy of context distillation in adapting\nmodels using minimal in-context examples. Employing matched datasets from\nMobach, our experiments leverage OPT models of various sizes. The results\nindicate that context distillation effectively adapts models, with student\nmodels attaining comparable in-domain and out-of-domain accuracies to\nin-context learning. Although context distillation surpasses ICL in\nout-of-domain generalization, it does not achieve the performance levels of FT.\nHowever, the reduced dataset size and computational demands position context\ndistillation as a viable alternative, especially for smaller datasets. Overall,\nthis study presents context distillation as an efficient and potent method for\ncustomizing LLMs to specific tasks.", "AI": {"tldr": "Context distillation is an efficient method for adapting LLMs to specific tasks, performing comparably to in-context learning and offering advantages over few-shot fine-tuning in resource efficiency.", "motivation": "To explore and validate context distillation as a method for adapting LLMs to specific tasks with minimal in-context examples, comparing it to in-context learning and few-shot fine-tuning.", "method": "Comparative analysis of context distillation, in-context learning, and few-shot fine-tuning using OPT models and matched datasets from Mobach.", "result": "Context distillation matches in-context learning in accuracy and outperforms it in out-of-domain generalization, though it falls short of few-shot fine-tuning. It requires fewer resources.", "conclusion": "Context distillation is a viable and efficient alternative for adapting LLMs, especially with smaller datasets, balancing performance and computational demands."}}
{"id": "2505.05081", "pdf": "https://arxiv.org/pdf/2505.05081", "abs": "https://arxiv.org/abs/2505.05081", "authors": ["Jinyu Gu", "Haipeng Liu", "Meng Wang", "Yang Wang"], "title": "PIDiff: Image Customization for Personalized Identities with Diffusion Models", "categories": ["cs.CV"], "comment": "9 pages, 11 figures", "summary": "Text-to-image generation for personalized identities aims at incorporating\nthe specific identity into images using a text prompt and an identity image.\nBased on the powerful generative capabilities of DDPMs, many previous works\nadopt additional prompts, such as text embeddings and CLIP image embeddings, to\nrepresent the identity information, while they fail to disentangle the identity\ninformation and background information. As a result, the generated images not\nonly lose key identity characteristics but also suffer from significantly\nreduced diversity. To address this issue, previous works have combined the W+\nspace from StyleGAN with diffusion models, leveraging this space to provide a\nmore accurate and comprehensive representation of identity features through\nmulti-level feature extraction. However, the entanglement of identity and\nbackground information in in-the-wild images during training prevents accurate\nidentity localization, resulting in severe semantic interference between\nidentity and background. In this paper, we propose a novel fine-tuning-based\ndiffusion model for personalized identities text-to-image generation, named\nPIDiff, which leverages the W+ space and an identity-tailored fine-tuning\nstrategy to avoid semantic entanglement and achieves accurate feature\nextraction and localization. Style editing can also be achieved by PIDiff\nthrough preserving the characteristics of identity features in the W+ space,\nwhich vary from coarse to fine. Through the combination of the proposed\ncross-attention block and parameter optimization strategy, PIDiff preserves the\nidentity information and maintains the generation capability for in-the-wild\nimages of the pre-trained model during inference. Our experimental results\nvalidate the effectiveness of our method in this task.", "AI": {"tldr": "PIDiff is a fine-tuning-based diffusion model for personalized text-to-image generation, using W+ space and identity-tailored fine-tuning to avoid semantic entanglement and improve identity feature extraction.", "motivation": "Existing methods fail to disentangle identity and background information, leading to loss of key identity characteristics and reduced diversity in generated images.", "method": "PIDiff leverages W+ space for multi-level identity feature extraction and employs an identity-tailored fine-tuning strategy to avoid semantic interference. It also uses a cross-attention block and parameter optimization for accurate localization.", "result": "PIDiff achieves accurate identity feature extraction and localization while preserving generation capability for in-the-wild images. Style editing is also possible.", "conclusion": "PIDiff effectively addresses the issue of semantic entanglement in personalized text-to-image generation, validating its superiority through experimental results."}}
{"id": "2505.05181", "pdf": "https://arxiv.org/pdf/2505.05181", "abs": "https://arxiv.org/abs/2505.05181", "authors": ["Bojian Yin", "Federico Corradi"], "title": "Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 5 figures", "summary": "Backpropagation (BP) is the cornerstone of deep learning, but its reliance on\nglobal gradient synchronization limits scalability and imposes significant\nmemory overhead. We propose Stochastic Variational Propagation (SVP), a\nscalable alternative that reframes training as hierarchical variational\ninference. SVP treats layer activations as latent variables and optimizes local\nEvidence Lower Bounds (ELBOs), enabling independent, local updates while\npreserving global coherence. However, directly applying KL divergence in\nlayer-wise ELBOs risks inter-layer's representation collapse due to excessive\ncompression. To prevent this, SVP projects activations into low-dimensional\nspaces via fixed random matrices, ensuring information preservation and\nrepresentational diversity. Combined with a feature alignment loss for\ninter-layer consistency, SVP achieves competitive accuracy with BP across\ndiverse architectures (MLPs, CNNs, Transformers) and datasets (MNIST to\nImageNet), reduces memory usage by up to 4x, and significantly improves\nscalability. More broadly, SVP introduces a probabilistic perspective to deep\nrepresentation learning, opening pathways toward more modular and interpretable\nneural network design.", "AI": {"tldr": "SVP replaces backpropagation with hierarchical variational inference for scalable, memory-efficient deep learning, avoiding representation collapse via random projections and alignment loss.", "motivation": "Backpropagation's scalability and memory limitations hinder deep learning efficiency, prompting the need for alternatives like SVP.", "method": "SVP uses local ELBOs with random projections to prevent collapse and a feature alignment loss for consistency, enabling independent layer updates.", "result": "SVP matches BP's accuracy, reduces memory by 4x, and improves scalability across architectures and datasets.", "conclusion": "SVP offers a probabilistic, scalable alternative to BP, enhancing modularity and interpretability in neural networks."}}
{"id": "2409.02426", "pdf": "https://arxiv.org/pdf/2409.02426", "abs": "https://arxiv.org/abs/2409.02426", "authors": ["Peng Wang", "Huijie Zhang", "Zekai Zhang", "Siyi Chen", "Yi Ma", "Qing Qu"], "title": "Diffusion Models Learn Low-Dimensional Distributions via Subspace Clustering", "categories": ["cs.LG", "cs.CV"], "comment": "39 pages, 8 figures, 2 tables", "summary": "Recent empirical studies have demonstrated that diffusion models can\neffectively learn the image distribution and generate new samples. Remarkably,\nthese models can achieve this even with a small number of training samples\ndespite a large image dimension, circumventing the curse of dimensionality. In\nthis work, we provide theoretical insights into this phenomenon by leveraging\nkey empirical observations: (i) the low intrinsic dimensionality of image data,\n(ii) a union of manifold structure of image data, and (iii) the low-rank\nproperty of the denoising autoencoder in trained diffusion models. These\nobservations motivate us to assume the underlying data distribution of image\ndata as a mixture of low-rank Gaussians and to parameterize the denoising\nautoencoder as a low-rank model according to the score function of the assumed\ndistribution. With these setups, we rigorously show that optimizing the\ntraining loss of diffusion models is equivalent to solving the canonical\nsubspace clustering problem over the training samples. Based on this\nequivalence, we further show that the minimal number of samples required to\nlearn the underlying distribution scales linearly with the intrinsic dimensions\nunder the above data and model assumptions. This insight sheds light on why\ndiffusion models can break the curse of dimensionality and exhibit the phase\ntransition in learning distributions. Moreover, we empirically establish a\ncorrespondence between the subspaces and the semantic representations of image\ndata, facilitating image editing. We validate these results with corroborated\nexperimental results on both simulated distributions and image datasets.", "AI": {"tldr": "Diffusion models learn image distributions efficiently with few samples due to low intrinsic dimensionality, manifold structure, and low-rank denoising autoencoders. Theoretical analysis links training to subspace clustering, showing linear sample scaling with intrinsic dimensions.", "motivation": "To explain why diffusion models avoid the curse of dimensionality and perform well with limited training samples.", "method": "Assume image data as a mixture of low-rank Gaussians and parameterize the denoising autoencoder as low-rank. Link training loss optimization to subspace clustering.", "result": "Minimal sample requirement scales linearly with intrinsic dimensions, explaining diffusion models' efficiency. Subspaces correspond to semantic image representations.", "conclusion": "Theoretical and empirical results validate that diffusion models break dimensionality constraints and enable semantic image editing."}}
{"id": "2505.05101", "pdf": "https://arxiv.org/pdf/2505.05101", "abs": "https://arxiv.org/abs/2505.05101", "authors": ["Hongyang Zhu", "Haipeng Liu", "Bo Fu", "Yang Wang"], "title": "MDE-Edit: Masked Dual-Editing for Multi-Object Image Editing via Diffusion Models", "categories": ["cs.CV"], "comment": "9 pages, 7 figures", "summary": "Multi-object editing aims to modify multiple objects or regions in complex\nscenes while preserving structural coherence. This task faces significant\nchallenges in scenarios involving overlapping or interacting objects: (1)\nInaccurate localization of target objects due to attention misalignment,\nleading to incomplete or misplaced edits; (2) Attribute-object mismatch, where\ncolor or texture changes fail to align with intended regions due to\ncross-attention leakage, creating semantic conflicts (\\textit{e.g.}, color\nbleeding into non-target areas). Existing methods struggle with these\nchallenges: approaches relying on global cross-attention mechanisms suffer from\nattention dilution and spatial interference between objects, while mask-based\nmethods fail to bind attributes to geometrically accurate regions due to\nfeature entanglement in multi-object scenarios. To address these limitations,\nwe propose a training-free, inference-stage optimization approach that enables\nprecise localized image manipulation in complex multi-object scenes, named\nMDE-Edit. MDE-Edit optimizes the noise latent feature in diffusion models via\ntwo key losses: Object Alignment Loss (OAL) aligns multi-layer cross-attention\nwith segmentation masks for precise object positioning, and Color Consistency\nLoss (CCL) amplifies target attribute attention within masks while suppressing\nleakage to adjacent regions. This dual-loss design ensures localized and\ncoherent multi-object edits. Extensive experiments demonstrate that MDE-Edit\noutperforms state-of-the-art methods in editing accuracy and visual quality,\noffering a robust solution for complex multi-object image manipulation tasks.", "AI": {"tldr": "MDE-Edit is a training-free method for precise multi-object editing in complex scenes, addressing attention misalignment and attribute-object mismatch via dual-loss optimization.", "motivation": "Challenges in multi-object editing include inaccurate localization and attribute-object mismatch due to attention issues in existing methods.", "method": "MDE-Edit optimizes noise latent features in diffusion models using Object Alignment Loss (OAL) and Color Consistency Loss (CCL) for precise edits.", "result": "MDE-Edit outperforms state-of-the-art methods in editing accuracy and visual quality.", "conclusion": "MDE-Edit provides a robust solution for complex multi-object image manipulation."}}
{"id": "2505.05470", "pdf": "https://arxiv.org/pdf/2505.05470", "abs": "https://arxiv.org/abs/2505.05470", "authors": ["Jie Liu", "Gongye Liu", "Jiajun Liang", "Yangguang Li", "Jiaheng Liu", "Xintao Wang", "Pengfei Wan", "Di Zhang", "Wanli Ouyang"], "title": "Flow-GRPO: Training Flow Matching Models via Online RL", "categories": ["cs.CV", "cs.AI"], "comment": "Code: https://github.com/yifan123/flow_grpo", "summary": "We propose Flow-GRPO, the first method integrating online reinforcement\nlearning (RL) into flow matching models. Our approach uses two key strategies:\n(1) an ODE-to-SDE conversion that transforms a deterministic Ordinary\nDifferential Equation (ODE) into an equivalent Stochastic Differential Equation\n(SDE) that matches the original model's marginal distribution at all timesteps,\nenabling statistical sampling for RL exploration; and (2) a Denoising Reduction\nstrategy that reduces training denoising steps while retaining the original\ninference timestep number, significantly improving sampling efficiency without\nperformance degradation. Empirically, Flow-GRPO is effective across multiple\ntext-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly\nperfect object counts, spatial relations, and fine-grained attributes, boosting\nGenEval accuracy from 63% to 95%. In visual text rendering, its accuracy\nimproves from 59% to 92%, significantly enhancing text generation. Flow-GRPO\nalso achieves substantial gains in human preference alignment. Notably, very\nlittle reward hacking occurred, meaning rewards did not increase at the cost of\nappreciable image quality or diversity degradation.", "AI": {"tldr": "Flow-GRPO integrates RL into flow matching models via ODE-to-SDE conversion and Denoising Reduction, improving efficiency and performance in text-to-image tasks.", "motivation": "To enhance flow matching models by incorporating RL for better exploration and sampling efficiency without compromising performance.", "method": "Uses ODE-to-SDE conversion for RL exploration and Denoising Reduction to improve training efficiency.", "result": "Achieves significant accuracy improvements in text-to-image tasks (e.g., 63% to 95% in GenEval) and better human preference alignment.", "conclusion": "Flow-GRPO effectively combines RL with flow matching, delivering high performance without reward hacking or quality loss."}}
{"id": "2409.15647", "pdf": "https://arxiv.org/pdf/2409.15647", "abs": "https://arxiv.org/abs/2409.15647", "authors": ["Ying Fan", "Yilun Du", "Kannan Ramchandran", "Kangwook Lee"], "title": "Looped Transformers for Length Generalization", "categories": ["cs.LG"], "comment": "ICLR 2025", "summary": "Recent work has shown that Transformers trained from scratch can successfully\nsolve various arithmetic and algorithmic tasks, such as adding numbers and\ncomputing parity. While these Transformers generalize well on unseen inputs of\nthe same length, they struggle with length generalization, i.e., handling\ninputs of unseen lengths. In this work, we demonstrate that looped Transformers\nwith an adaptive number of steps significantly improve length generalization.\nWe focus on tasks with a known iterative solution, involving multiple\niterations of a RASP-L operation - a length-generalizable operation that can be\nexpressed by a finite-sized Transformer. We train looped Transformers using our\nproposed learning algorithm and observe that they learn highly\nlength-generalizable solutions for various tasks.", "AI": {"tldr": "Looped Transformers with adaptive steps improve length generalization for arithmetic tasks.", "motivation": "Addressing the challenge of Transformers struggling with length generalization on unseen input lengths.", "method": "Using looped Transformers with adaptive steps and a learning algorithm for tasks with iterative solutions.", "result": "Achieved highly length-generalizable solutions for various tasks.", "conclusion": "Looped Transformers enhance length generalization in arithmetic and algorithmic tasks."}}
{"id": "2505.05376", "pdf": "https://arxiv.org/pdf/2505.05376", "abs": "https://arxiv.org/abs/2505.05376", "authors": ["Rachmadio Noval Lazuardi", "Artem Sevastopolsky", "Egor Zakharov", "Matthias Niessner", "Vanessa Sklyarova"], "title": "GeomHair: Reconstruction of Hair Strands from Colorless 3D Scans", "categories": ["cs.CV"], "comment": "15 pages, 9 figures, 1 table", "summary": "We propose a novel method that reconstructs hair strands directly from\ncolorless 3D scans by leveraging multi-modal hair orientation extraction. Hair\nstrand reconstruction is a fundamental problem in computer vision and graphics\nthat can be used for high-fidelity digital avatar synthesis, animation, and\nAR/VR applications. However, accurately recovering hair strands from raw scan\ndata remains challenging due to human hair's complex and fine-grained\nstructure. Existing methods typically rely on RGB captures, which can be\nsensitive to the environment and can be a challenging domain for extracting the\norientation of guiding strands, especially in the case of challenging\nhairstyles. To reconstruct the hair purely from the observed geometry, our\nmethod finds sharp surface features directly on the scan and estimates strand\norientation through a neural 2D line detector applied to the renderings of scan\nshading. Additionally, we incorporate a diffusion prior trained on a diverse\nset of synthetic hair scans, refined with an improved noise schedule, and\nadapted to the reconstructed contents via a scan-specific text prompt. We\ndemonstrate that this combination of supervision signals enables accurate\nreconstruction of both simple and intricate hairstyles without relying on color\ninformation. To facilitate further research, we introduce Strands400, the\nlargest publicly available dataset of hair strands with detailed surface\ngeometry extracted from real-world data, which contains reconstructed hair\nstrands from the scans of 400 subjects.", "AI": {"tldr": "A novel method reconstructs hair strands from colorless 3D scans using multi-modal orientation extraction, avoiding RGB reliance and leveraging a diffusion prior.", "motivation": "Accurate hair strand reconstruction is vital for digital avatars, animation, and AR/VR, but existing RGB-based methods struggle with complex hairstyles and environmental sensitivity.", "method": "Extracts sharp surface features from scans, uses a neural 2D line detector for orientation, and incorporates a diffusion prior refined with synthetic data.", "result": "Accurate reconstruction of simple and intricate hairstyles without color information, validated by the Strands400 dataset.", "conclusion": "The method advances hair strand reconstruction by eliminating RGB dependency and introducing a large real-world dataset for future research."}}
{"id": "2505.05522", "pdf": "https://arxiv.org/pdf/2505.05522", "abs": "https://arxiv.org/abs/2505.05522", "authors": ["Luke Darlow", "Ciaran Regan", "Sebastian Risi", "Jeffrey Seely", "Llion Jones"], "title": "Continuous Thought Machines", "categories": ["cs.LG", "cs.AI"], "comment": "Technical report accompanied by online project page:\n  https://pub.sakana.ai/ctm/", "summary": "Biological brains demonstrate complex neural activity, where the timing and\ninterplay between neurons is critical to how brains process information. Most\ndeep learning architectures simplify neural activity by abstracting away\ntemporal dynamics. In this paper we challenge that paradigm. By incorporating\nneuron-level processing and synchronization, we can effectively reintroduce\nneural timing as a foundational element. We present the Continuous Thought\nMachine (CTM), a model designed to leverage neural dynamics as its core\nrepresentation. The CTM has two core innovations: (1) neuron-level temporal\nprocessing, where each neuron uses unique weight parameters to process a\nhistory of incoming signals; and (2) neural synchronization employed as a\nlatent representation. The CTM aims to strike a balance between oversimplified\nneuron abstractions that improve computational efficiency, and biological\nrealism. It operates at a level of abstraction that effectively captures\nessential temporal dynamics while remaining computationally tractable for deep\nlearning. We demonstrate the CTM's strong performance and versatility across a\nrange of challenging tasks, including ImageNet-1K classification, solving 2D\nmazes, sorting, parity computation, question-answering, and RL tasks. Beyond\ndisplaying rich internal representations and offering a natural avenue for\ninterpretation owing to its internal process, the CTM is able to perform tasks\nthat require complex sequential reasoning. The CTM can also leverage adaptive\ncompute, where it can stop earlier for simpler tasks, or keep computing when\nfaced with more challenging instances. The goal of this work is to share the\nCTM and its associated innovations, rather than pushing for new\nstate-of-the-art results. To that end, we believe the CTM represents a\nsignificant step toward developing more biologically plausible and powerful\nartificial intelligence systems.", "AI": {"tldr": "The paper introduces the Continuous Thought Machine (CTM), a model incorporating neuron-level temporal processing and synchronization to enhance biological realism in deep learning.", "motivation": "To challenge the oversimplification of neural activity in deep learning by reintroducing temporal dynamics and synchronization as core elements.", "method": "CTM uses neuron-level temporal processing and neural synchronization as latent representations, balancing biological realism and computational efficiency.", "result": "CTM demonstrates strong performance in tasks like ImageNet-1K classification, maze-solving, and question-answering, with adaptive compute capabilities.", "conclusion": "CTM advances biologically plausible AI, offering interpretability and versatility without focusing on state-of-the-art benchmarks."}}
{"id": "2409.19800", "pdf": "https://arxiv.org/pdf/2409.19800", "abs": "https://arxiv.org/abs/2409.19800", "authors": ["Guy Kornowski"], "title": "Differentially Private Bilevel Optimization", "categories": ["cs.LG", "cs.CR", "math.OC"], "comment": "Major rewrite: Sections 3 & 7 are new; various improvements in\n  presentation", "summary": "We present differentially private (DP) algorithms for bilevel optimization, a\nproblem class that received significant attention lately in various machine\nlearning applications. These are the first algorithms for such problems under\nstandard DP constraints, and are also the first to avoid Hessian computations\nwhich are prohibitive in large-scale settings. Under the well-studied setting\nin which the upper-level is not necessarily convex and the lower-level problem\nis strongly-convex, our proposed gradient-based $(\\epsilon,\\delta)$-DP\nalgorithm returns a point with hypergradient norm at most\n$\\widetilde{\\mathcal{O}}\\left((\\sqrt{d_\\mathrm{up}}/\\epsilon\nn)^{1/2}+(\\sqrt{d_\\mathrm{low}}/\\epsilon n)^{1/3}\\right)$ where $n$ is the\ndataset size, and $d_\\mathrm{up}/d_\\mathrm{low}$ are the upper/lower level\ndimensions. Our analysis covers constrained and unconstrained problems alike,\naccounts for mini-batch gradients, and applies to both empirical and population\nlosses. As an application, we specialize our analysis to derive a simple\nprivate rule for tuning a regularization hyperparameter.", "AI": {"tldr": "First DP algorithms for bilevel optimization, avoiding Hessian computations, with gradient-based privacy guarantees.", "motivation": "Address the lack of differentially private solutions for bilevel optimization in machine learning, especially in large-scale settings.", "method": "Proposes a gradient-based $\\epsilon,\\delta$-DP algorithm for non-convex upper-level and strongly-convex lower-level problems.", "result": "Achieves hypergradient norm bounds depending on dataset size and dimensions, applicable to constrained/unconstrained problems.", "conclusion": "Provides a practical DP solution for bilevel optimization, demonstrated with a hyperparameter tuning application."}}
{"id": "2505.05472", "pdf": "https://arxiv.org/pdf/2505.05472", "abs": "https://arxiv.org/abs/2505.05472", "authors": ["Chao Liao", "Liyang Liu", "Xun Wang", "Zhengxiong Luo", "Xinyu Zhang", "Wenliang Zhao", "Jie Wu", "Liang Li", "Zhi Tian", "Weilin Huang"], "title": "Mogao: An Omni Foundation Model for Interleaved Multi-Modal Generation", "categories": ["cs.CV"], "comment": "Mogao Technical Report", "summary": "Recent progress in unified models for image understanding and generation has\nbeen impressive, yet most approaches remain limited to single-modal generation\nconditioned on multiple modalities. In this paper, we present Mogao, a unified\nframework that advances this paradigm by enabling interleaved multi-modal\ngeneration through a causal approach. Mogao integrates a set of key technical\nimprovements in architecture design, including a deep-fusion design, dual\nvision encoders, interleaved rotary position embeddings, and multi-modal\nclassifier-free guidance, which allow it to harness the strengths of both\nautoregressive models for text generation and diffusion models for high-quality\nimage synthesis. These practical improvements also make Mogao particularly\neffective to process interleaved sequences of text and images arbitrarily. To\nfurther unlock the potential of unified models, we introduce an efficient\ntraining strategy on a large-scale, in-house dataset specifically curated for\njoint text and image generation. Extensive experiments show that Mogao not only\nachieves state-of-the-art performance in multi-modal understanding and\ntext-to-image generation, but also excels in producing high-quality, coherent\ninterleaved outputs. Its emergent capabilities in zero-shot image editing and\ncompositional generation highlight Mogao as a practical omni-modal foundation\nmodel, paving the way for future development and scaling the unified\nmulti-modal systems.", "AI": {"tldr": "Mogao is a unified framework for interleaved multi-modal generation, combining autoregressive and diffusion models with key technical improvements, achieving state-of-the-art performance in multi-modal tasks.", "motivation": "Existing unified models are limited to single-modal generation conditioned on multiple modalities, prompting the need for a more flexible and powerful framework.", "method": "Mogao integrates deep-fusion design, dual vision encoders, interleaved rotary position embeddings, and multi-modal classifier-free guidance, trained on a large-scale dataset for joint text and image generation.", "result": "Mogao excels in multi-modal understanding, text-to-image generation, and produces high-quality interleaved outputs, with emergent zero-shot capabilities.", "conclusion": "Mogao serves as a practical omni-modal foundation model, advancing the development of unified multi-modal systems."}}
{"id": "2505.05533", "pdf": "https://arxiv.org/pdf/2505.05533", "abs": "https://arxiv.org/abs/2505.05533", "authors": ["Zhiyuan Ning", "Pengfei Wang", "Ziyue Qiao", "Pengyang Wang", "Yuanchun Zhou"], "title": "Rethinking Graph Contrastive Learning through Relative Similarity Preservation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI2025; full version including appendix", "summary": "Graph contrastive learning (GCL) has achieved remarkable success by following\nthe computer vision paradigm of preserving absolute similarity between\naugmented views. However, this approach faces fundamental challenges in graphs\ndue to their discrete, non-Euclidean nature -- view generation often breaks\nsemantic validity and similarity verification becomes unreliable. Through\nanalyzing 11 real-world graphs, we discover a universal pattern transcending\nthe homophily-heterophily dichotomy: label consistency systematically\ndiminishes as structural distance increases, manifesting as smooth decay in\nhomophily graphs and oscillatory decay in heterophily graphs. We establish\ntheoretical guarantees for this pattern through random walk theory, proving\nlabel distribution convergence and characterizing the mechanisms behind\ndifferent decay behaviors. This discovery reveals that graphs naturally encode\nrelative similarity patterns, where structurally closer nodes exhibit\ncollectively stronger semantic relationships. Leveraging this insight, we\npropose RELGCL, a novel GCL framework with complementary pairwise and listwise\nimplementations that preserve these inherent patterns through collective\nsimilarity objectives. Extensive experiments demonstrate that our method\nconsistently outperforms 20 existing approaches across both homophily and\nheterophily graphs, validating the effectiveness of leveraging natural relative\nsimilarity over artificial absolute similarity.", "AI": {"tldr": "The paper introduces RELGCL, a graph contrastive learning framework that leverages natural relative similarity patterns in graphs, outperforming existing methods by avoiding unreliable absolute similarity measures.", "motivation": "Traditional graph contrastive learning (GCL) struggles with semantic validity and similarity verification due to the discrete, non-Euclidean nature of graphs. The authors aim to address this by identifying and utilizing inherent relative similarity patterns.", "method": "The authors analyze 11 real-world graphs to discover universal label consistency patterns. They propose RELGCL, a GCL framework with pairwise and listwise implementations that preserve these patterns through collective similarity objectives.", "result": "Extensive experiments show RELGCL consistently outperforms 20 existing methods across homophily and heterophily graphs, validating its effectiveness.", "conclusion": "The paper concludes that leveraging natural relative similarity patterns in graphs is more effective than relying on artificial absolute similarity, as demonstrated by RELGCL's superior performance."}}
{"id": "2410.00215", "pdf": "https://arxiv.org/pdf/2410.00215", "abs": "https://arxiv.org/abs/2410.00215", "authors": ["Yejin Lee", "Anna Sun", "Basil Hosmer", "Bilge Acun", "Can Balioglu", "Changhan Wang", "Charles David Hernandez", "Christian Puhrsch", "Daniel Haziza", "Driss Guessous", "Francisco Massa", "Jacob Kahn", "Jeffrey Wan", "Jeremy Reizenstein", "Jiaqi Zhai", "Joe Isaacson", "Joel Schlosser", "Juan Pino", "Kaushik Ram Sadagopan", "Leonid Shamis", "Linjian Ma", "Min-Jae Hwang", "Mingda Chen", "Mostafa Elhoushi", "Pedro Rodriguez", "Ram Pasunuru", "Scott Yih", "Sravya Popuri", "Xing Liu", "Carole-Jean Wu"], "title": "Characterizing and Efficiently Accelerating Multimodal Generation Model Inference", "categories": ["cs.LG"], "comment": "13 pages including references. 8 Figures. Under review to HPCA 2025\n  Industry Track", "summary": "Generative artificial intelligence (AI) technology is revolutionizing the\ncomputing industry. Not only its applications have broadened to various sectors\nbut also poses new system design and optimization opportunities. The technology\nis capable of understanding and responding in multiple modalities. However, the\nadvanced capability currently comes with significant system resource demands.\nTo sustainably scale generative AI capabilities to billions of users in the\nworld, inference must be fast and efficient. This paper pinpoints key system\ndesign and optimization opportunities by characterizing a family of emerging\nmulti-modal generation models on real systems. Auto-regressive token generation\nis a critical latency performance bottleneck, typically dominated by GPU idle\ntime. In addition to memory-intensive attention across the generative AI\nmodels, linear operations constitute significant inference latency due to the\nfeed forward networks in Transformer-based models. We demonstrate that\nstate-of-the-art optimization levers, spanning from applications to system\nsoftware and hardware, set a 3.88x better baseline.", "AI": {"tldr": "The paper highlights system design and optimization opportunities for scaling generative AI, focusing on latency bottlenecks like GPU idle time and memory-intensive operations.", "motivation": "To sustainably scale generative AI for billions of users, efficient and fast inference is crucial, given the high resource demands of multi-modal models.", "method": "Characterizes multi-modal generation models on real systems, identifying bottlenecks like auto-regressive token generation and memory-intensive attention. Proposes optimization levers across applications, system software, and hardware.", "result": "Demonstrates a 3.88x improvement in baseline performance using state-of-the-art optimizations.", "conclusion": "Optimizing system design and leveraging multi-level optimizations can significantly enhance the efficiency and scalability of generative AI."}}
{"id": "2505.05573", "pdf": "https://arxiv.org/pdf/2505.05573", "abs": "https://arxiv.org/abs/2505.05573", "authors": ["Mikhail Chaichuk", "Sushant Gautam", "Steven Hicks", "Elena Tutubalina"], "title": "Prompt to Polyp: Medical Text-Conditioned Image Synthesis with Diffusion Models", "categories": ["cs.CV", "cs.AI", "68T07, 68U10, 92C55", "I.2.10; I.4.8; J.3"], "comment": "code available at\n  https://github.com/THunderCondOR/ImageCLEFmed-MEDVQA-GI-2024-MMCP-Team", "summary": "The generation of realistic medical images from text descriptions has\nsignificant potential to address data scarcity challenges in healthcare AI\nwhile preserving patient privacy. This paper presents a comprehensive study of\ntext-to-image synthesis in the medical domain, comparing two distinct\napproaches: (1) fine-tuning large pre-trained latent diffusion models and (2)\ntraining small, domain-specific models. We introduce a novel model named MSDM,\nan optimized architecture based on Stable Diffusion that integrates a clinical\ntext encoder, variational autoencoder, and cross-attention mechanisms to better\nalign medical text prompts with generated images. Our study compares two\napproaches: fine-tuning large pre-trained models (FLUX, Kandinsky) versus\ntraining compact domain-specific models (MSDM). Evaluation across colonoscopy\n(MedVQA-GI) and radiology (ROCOv2) datasets reveals that while large models\nachieve higher fidelity, our optimized MSDM delivers comparable quality with\nlower computational costs. Quantitative metrics and qualitative evaluations by\nmedical experts reveal strengths and limitations of each approach.", "AI": {"tldr": "The paper compares text-to-image synthesis methods for medical images, introducing MSDM, an optimized model, and finds it balances quality and computational efficiency.", "motivation": "Addressing data scarcity in healthcare AI while preserving privacy by generating realistic medical images from text descriptions.", "method": "Compares fine-tuning large pre-trained models (FLUX, Kandinsky) with training compact domain-specific models (MSDM), which integrates a clinical text encoder, variational autoencoder, and cross-attention mechanisms.", "result": "Large models achieve higher fidelity, but MSDM offers comparable quality with lower computational costs, validated on colonoscopy and radiology datasets.", "conclusion": "MSDM is a viable alternative to large models for medical image synthesis, balancing performance and efficiency."}}
{"id": "2505.05877", "pdf": "https://arxiv.org/pdf/2505.05877", "abs": "https://arxiv.org/abs/2505.05877", "authors": ["Rong Yin", "Ruyue Liu", "Xiaoshuai Hao", "Xingrui Zhou", "Yong Liu", "Can Ma", "Weiping Wang"], "title": "Multi-Modal Molecular Representation Learning via Structure Awareness", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IEEE Transactions on Image Processing (TIP) 2025", "summary": "Accurate extraction of molecular representations is a critical step in the\ndrug discovery process. In recent years, significant progress has been made in\nmolecular representation learning methods, among which multi-modal molecular\nrepresentation methods based on images, and 2D/3D topologies have become\nincreasingly mainstream. However, existing these multi-modal approaches often\ndirectly fuse information from different modalities, overlooking the potential\nof intermodal interactions and failing to adequately capture the complex\nhigher-order relationships and invariant features between molecules. To\novercome these challenges, we propose a structure-awareness-based multi-modal\nself-supervised molecular representation pre-training framework (MMSA) designed\nto enhance molecular graph representations by leveraging invariant knowledge\nbetween molecules. The framework consists of two main modules: the multi-modal\nmolecular representation learning module and the structure-awareness module.\nThe multi-modal molecular representation learning module collaboratively\nprocesses information from different modalities of the same molecule to\novercome intermodal differences and generate a unified molecular embedding.\nSubsequently, the structure-awareness module enhances the molecular\nrepresentation by constructing a hypergraph structure to model higher-order\ncorrelations between molecules. This module also introduces a memory mechanism\nfor storing typical molecular representations, aligning them with memory\nanchors in the memory bank to integrate invariant knowledge, thereby improving\nthe model generalization ability. Extensive experiments have demonstrated the\neffectiveness of MMSA, which achieves state-of-the-art performance on the\nMoleculeNet benchmark, with average ROC-AUC improvements ranging from 1.8% to\n9.6% over baseline methods.", "AI": {"tldr": "Proposes MMSA, a self-supervised framework for multi-modal molecular representation learning, enhancing intermodal interactions and higher-order relationships.", "motivation": "Existing multi-modal methods overlook intermodal interactions and higher-order relationships in molecular representations.", "method": "MMSA combines multi-modal representation learning and structure-awareness modules, using hypergraphs and memory mechanisms.", "result": "Achieves state-of-the-art performance on MoleculeNet, with ROC-AUC improvements of 1.8%-9.6%.", "conclusion": "MMSA effectively captures complex molecular relationships and invariant features, outperforming baselines."}}
{"id": "2410.06300", "pdf": "https://arxiv.org/pdf/2410.06300", "abs": "https://arxiv.org/abs/2410.06300", "authors": ["Ali Gorji", "Andisheh Amrollahi", "Andreas Krause"], "title": "SHAP values via sparse Fourier representation", "categories": ["cs.LG"], "comment": "Under review", "summary": "SHAP (SHapley Additive exPlanations) values are a widely used method for\nlocal feature attribution in interpretable and explainable AI. We propose an\nefficient two-stage algorithm for computing SHAP values in both black-box\nsetting and tree-based models. Motivated by spectral bias in real-world\npredictors, we first approximate models using compact Fourier representations,\nexactly for trees and approximately for black-box models. In the second stage,\nwe introduce a closed-form formula for {\\em exactly} computing SHAP values\nusing the Fourier representation, that ``linearizes'' the computation into a\nsimple summation and is amenable to parallelization. As the Fourier\napproximation is computed only once, our method enables amortized SHAP value\ncomputation, achieving significant speedups over existing methods and a tunable\ntrade-off between efficiency and precision.", "AI": {"tldr": "Proposes a two-stage algorithm for efficient SHAP value computation using Fourier approximations, achieving speedups and tunable precision.", "motivation": "Addresses spectral bias in real-world predictors and the need for efficient SHAP value computation in both black-box and tree-based models.", "method": "Uses compact Fourier representations to approximate models, then introduces a closed-form formula for exact SHAP value computation, enabling parallelization.", "result": "Achieves significant speedups over existing methods with a tunable trade-off between efficiency and precision.", "conclusion": "The method enables amortized SHAP value computation, improving efficiency while maintaining precision."}}
{"id": "2505.06108", "pdf": "https://arxiv.org/pdf/2505.06108", "abs": "https://arxiv.org/abs/2505.06108", "authors": ["Lennart Justen"], "title": "LLMs Outperform Experts on Challenging Biology Benchmarks", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "This study systematically evaluates 27 frontier Large Language Models on\neight biology benchmarks spanning molecular biology, genetics, cloning,\nvirology, and biosecurity. Models from major AI developers released between\nNovember 2022 and April 2025 were assessed through ten independent runs per\nbenchmark. The findings reveal dramatic improvements in biological\ncapabilities. Top model performance increased more than 4-fold on the\nchallenging text-only subset of the Virology Capabilities Test over the study\nperiod, with OpenAI's o3 now performing twice as well as expert virologists.\nSeveral models now match or exceed expert-level performance on other\nchallenging benchmarks, including the biology subsets of GPQA and WMDP and\nLAB-Bench CloningScenarios. Contrary to expectations, chain-of-thought did not\nsubstantially improve performance over zero-shot evaluation, while extended\nreasoning features in o3-mini and Claude 3.7 Sonnet typically improved\nperformance as predicted by inference scaling. Benchmarks such as PubMedQA and\nthe MMLU and WMDP biology subsets exhibited performance plateaus well below\n100%, suggesting benchmark saturation and errors in the underlying benchmark\ndata. The analysis highlights the need for more sophisticated evaluation\nmethodologies as AI systems continue to advance.", "AI": {"tldr": "The study evaluates 27 Large Language Models (LLMs) on eight biology benchmarks, showing significant performance improvements, with some models surpassing expert-level capabilities. Chain-of-thought reasoning had minimal impact, while extended reasoning features improved results. Benchmark saturation and data errors were noted, calling for better evaluation methods.", "motivation": "To assess the biological capabilities of frontier LLMs and track their performance improvements over time, identifying strengths, limitations, and the need for advanced evaluation methodologies.", "method": "Systematic evaluation of 27 LLMs on eight biology benchmarks, with ten independent runs per benchmark, covering molecular biology, genetics, cloning, virology, and biosecurity.", "result": "Top models showed a 4-fold improvement on challenging tasks, with some surpassing expert performance. Extended reasoning features improved results, while chain-of-thought did not. Benchmark saturation and data errors were observed.", "conclusion": "LLMs have advanced significantly in biological tasks, but benchmark limitations and evaluation methods need refinement to keep pace with AI progress."}}
{"id": "2410.11539", "pdf": "https://arxiv.org/pdf/2410.11539", "abs": "https://arxiv.org/abs/2410.11539", "authors": ["M. Germ\u00e1n-Morales", "A. J. Rivera-Rivas", "M. J. del Jesus D\u00edaz", "C. J. Carmona"], "title": "Transfer Learning with Foundational Models for Time Series Forecasting using Low-Rank Adaptations", "categories": ["cs.LG"], "comment": null, "summary": "Foundational Models are an emerging widely used technique of GenAI. These\nmodels are distinguished by their scalability and the ease with which they can\nbe adapted through the exploitation of Transfer Learning. The availability of\nhigh computational power and large datasets have supported their development,\nachieving a high generalization capacity due to the enormous and heterogeneous\namounts of data used in their initial training. These characteristics\ncontribute to a solid base that can be adapted or adjusted to a wide range of\ntasks, increasing their applicability. This study proposes the methodology\nLLIAM, a straightforward adaptation of a kind of FM, Large Language Models, for\nthe Time Series Forecasting task. An adequate time-series prompting schema and\nLow-Rank Adaptations are used to enhance the knowledge of the model with\ndiverse time series datasets, known as the fine-tuning phase. A study divided\nin two stages has been performed for evaluating the effectiveness of the\nproposed methodology. Initially, a comparison was made between the performance\nof LLIAM and different state-of-the-art DL algorithms, including Recurrent\nNeural Networks and Temporal Convolutional Networks, as well as a LLM-based\nmethod, TimeLLM. Following this, a zero-shot study is presented in order to\nevaluate the generalization capacity of the proposed methodology with time\nseries datasets from unknown domains not considered in the model training. The\noutcomes of this investigation demonstrate the efficacy of LLIAM, highlighting\nthat this straightforward and general approach can attain competent results\nwithout the necessity for applying complex modifications. This work also\nencourages the use of available resources (such as these pre-trained models)\nand efficient fine-tuning techniques to avoid unnecessary and costly training,\nnarrowing the gap between the goals of traditional AI and Green AI.", "AI": {"tldr": "LLIAM adapts Large Language Models for Time Series Forecasting using prompting and Low-Rank Adaptations, achieving competitive results without complex modifications.", "motivation": "To leverage scalable Foundational Models (FMs) for Time Series Forecasting, reducing the need for costly training and promoting Green AI.", "method": "Proposes LLIAM, combining time-series prompting and Low-Rank Adaptations for fine-tuning on diverse datasets.", "result": "LLIAM outperforms state-of-the-art DL algorithms and shows strong generalization in zero-shot studies.", "conclusion": "LLIAM is an effective, simple approach for Time Series Forecasting, encouraging resource-efficient AI practices."}}
{"id": "2411.05673", "pdf": "https://arxiv.org/pdf/2411.05673", "abs": "https://arxiv.org/abs/2411.05673", "authors": ["Tony Lindeberg"], "title": "Relationships between the degrees of freedom in the affine Gaussian derivative model for visual receptive fields and 2-D affine image transformations, with application to covariance properties of simple cells in the primary visual cortex", "categories": ["q-bio.NC", "cs.CV"], "comment": "22 pages, 9 figures", "summary": "When observing the surface patterns of objects delimited by smooth surfaces,\nthe projections of the surface patterns to the image domain will be subject to\nsubstantial variabilities, as induced by variabilities in the geometric viewing\nconditions, and as generated by either monocular or binocular imaging\nconditions, or by relative motions between the object and the observer over\ntime. To first order of approximation, the image deformations of such projected\nsurface patterns can be modelled as local linearizations in terms of local 2-D\nspatial affine transformations.\n  This paper presents a theoretical analysis of relationships between the\ndegrees of freedom in 2-D spatial affine image transformations and the degrees\nof freedom in the affine Gaussian derivative model for visual receptive fields.\nFor this purpose, we first describe a canonical decomposition of 2-D affine\ntransformations on a product form, closely related to a singular value\ndecomposition, while in closed form, and which reveals the degrees of freedom\nin terms of (i) uniform scaling transformations, (ii) an overall amount of\nglobal rotation, (iii) a complementary non-uniform scaling transformation and\n(iv) a relative normalization to a preferred symmetry orientation in the image\ndomain. Then, we show how these degrees of freedom relate to the degrees of\nfreedom in the affine Gaussian derivative model.\n  Finally, we use these theoretical results to consider whether we could regard\nthe biological receptive fields in the primary visual cortex of higher mammals\nas being able to span the degrees of freedom of 2-D spatial affine\ntransformations, based on interpretations of existing neurophysiological\nexperimental results.", "AI": {"tldr": "The paper analyzes the relationship between 2-D spatial affine image transformations and the affine Gaussian derivative model, proposing a canonical decomposition of affine transformations and linking it to biological receptive fields in the visual cortex.", "motivation": "To understand how image deformations of projected surface patterns can be modeled and how these relate to the affine Gaussian derivative model, with implications for biological vision systems.", "method": "A theoretical analysis involving a canonical decomposition of 2-D affine transformations into uniform scaling, global rotation, non-uniform scaling, and normalization to a symmetry orientation, then relating these to the affine Gaussian derivative model.", "result": "The study reveals how the degrees of freedom in affine transformations align with those in the affine Gaussian derivative model, suggesting a potential link to biological receptive fields.", "conclusion": "The findings suggest that biological receptive fields in the primary visual cortex may span the degrees of freedom of 2-D spatial affine transformations, supported by neurophysiological evidence."}}
{"id": "2410.14081", "pdf": "https://arxiv.org/pdf/2410.14081", "abs": "https://arxiv.org/abs/2410.14081", "authors": ["Shangzhe Li", "Zhiao Huang", "Hao Su"], "title": "Reward-free World Models for Online Imitation Learning", "categories": ["cs.LG"], "comment": "ICML 2025; Code available at: https://github.com/TobyLeelsz/iqmpc", "summary": "Imitation learning (IL) enables agents to acquire skills directly from expert\ndemonstrations, providing a compelling alternative to reinforcement learning.\nHowever, prior online IL approaches struggle with complex tasks characterized\nby high-dimensional inputs and complex dynamics. In this work, we propose a\nnovel approach to online imitation learning that leverages reward-free world\nmodels. Our method learns environmental dynamics entirely in latent spaces\nwithout reconstruction, enabling efficient and accurate modeling. We adopt the\ninverse soft-Q learning objective, reformulating the optimization process in\nthe Q-policy space to mitigate the instability associated with traditional\noptimization in the reward-policy space. By employing a learned latent dynamics\nmodel and planning for control, our approach consistently achieves stable,\nexpert-level performance in tasks with high-dimensional observation or action\nspaces and intricate dynamics. We evaluate our method on a diverse set of\nbenchmarks, including DMControl, MyoSuite, and ManiSkill2, demonstrating\nsuperior empirical performance compared to existing approaches.", "AI": {"tldr": "A novel online imitation learning method using reward-free world models in latent spaces achieves expert-level performance in complex tasks.", "motivation": "Prior online IL methods struggle with high-dimensional inputs and complex dynamics, necessitating a more efficient and stable approach.", "method": "Leverages reward-free world models in latent spaces, adopts inverse soft-Q learning, and uses latent dynamics for planning.", "result": "Achieves stable, expert-level performance in high-dimensional tasks, outperforming existing methods on benchmarks like DMControl and MyoSuite.", "conclusion": "The proposed method effectively addresses instability and inefficiency in online IL for complex tasks."}}
{"id": "2412.00259", "pdf": "https://arxiv.org/pdf/2412.00259", "abs": "https://arxiv.org/abs/2412.00259", "authors": ["Yifan Zhu", "Tianyi Xiang", "Aaron Dollar", "Zherong Pan"], "title": "One-Shot Real-to-Sim via End-to-End Differentiable Simulation and Rendering", "categories": ["cs.RO", "cs.CV", "cs.GR"], "comment": "8 pages, 8 figures. Published at IEEE Robotics Automation Letters", "summary": "Identifying predictive world models for robots in novel environments from\nsparse online observations is essential for robot task planning and execution\nin novel environments. However, existing methods that leverage differentiable\nprogramming to identify world models are incapable of jointly optimizing the\ngeometry, appearance, and physical properties of the scene. In this work, we\nintroduce a novel rigid object representation that allows the joint\nidentification of these properties. Our method employs a novel differentiable\npoint-based geometry representation coupled with a grid-based appearance field,\nwhich allows differentiable object collision detection and rendering. Combined\nwith a differentiable physical simulator, we achieve end-to-end optimization of\nworld models, given the sparse visual and tactile observations of a physical\nmotion sequence. Through a series of world model identification tasks in\nsimulated and real environments, we show that our method can learn both\nsimulation- and rendering-ready world models from only one robot action\nsequence. The code and additional videos are available at our project website:\nhttps://tianyi20.github.io/rigid-world-model.github.io/", "AI": {"tldr": "A novel rigid object representation method for jointly optimizing geometry, appearance, and physical properties in world models for robots, using differentiable point-based geometry and grid-based appearance fields.", "motivation": "Existing methods fail to jointly optimize geometry, appearance, and physical properties of scenes for robot task planning in novel environments.", "method": "Differentiable point-based geometry representation coupled with grid-based appearance fields, integrated with a differentiable physical simulator for end-to-end optimization.", "result": "Achieves learning of simulation- and rendering-ready world models from a single robot action sequence in simulated and real environments.", "conclusion": "The method enables efficient world model identification, advancing robot task planning and execution in novel environments."}}
{"id": "2410.24023", "pdf": "https://arxiv.org/pdf/2410.24023", "abs": "https://arxiv.org/abs/2410.24023", "authors": ["Suhan Guo", "Jiahong Deng", "Yi Wei", "Hui Dou", "Furao Shen", "Jian Zhao"], "title": "RAM: Replace Attention with MLP for Efficient Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Attention-based architectures have become ubiquitous in time series\nforecasting tasks, including spatio-temporal (STF) and long-term time series\nforecasting (LTSF). Yet, our understanding of the reasons for their\neffectiveness remains limited. In this work, we propose a novel pruning\nstrategy, $\\textbf{R}$eplace $\\textbf{A}$ttention with $\\textbf{M}$LP (RAM),\nthat approximates the attention mechanism using only feedforward layers,\nresidual connections, and layer normalization for temporal and/or spatial\nmodeling in multivariate time series forecasting. Specifically, the Q, K, and V\nprojections, the attention score calculation, the dot-product between the\nattention score and the V, and the final projection can be removed from the\nattention-based networks without significantly degrading the performance, so\nthat the given network remains the top-tier compared to other SOTA methods. RAM\nachieves a $62.579\\%$ reduction in FLOPs for spatio-temporal models with less\nthan $2.5\\%$ performance drop, and a $42.233\\%$ FLOPs reduction for LTSF models\nwith less than $2\\%$ performance drop.", "AI": {"tldr": "The paper introduces RAM, a pruning strategy that replaces attention mechanisms with MLPs in time series forecasting, reducing computational costs (FLOPs) significantly with minimal performance loss.", "motivation": "Despite the widespread use of attention-based architectures in time series forecasting, their effectiveness is not well understood. The authors aim to simplify these models by replacing attention with MLPs.", "method": "RAM approximates attention using feedforward layers, residual connections, and layer normalization, removing key attention components (Q, K, V projections, score calculation, etc.) without major performance loss.", "result": "RAM reduces FLOPs by 62.579% for spatio-temporal models (performance drop <2.5%) and 42.233% for LTSF models (performance drop <2%), maintaining top-tier performance.", "conclusion": "RAM demonstrates that attention mechanisms can be effectively replaced with simpler MLP-based structures, offering computational efficiency without sacrificing forecasting accuracy."}}
{"id": "2412.03887", "pdf": "https://arxiv.org/pdf/2412.03887", "abs": "https://arxiv.org/abs/2412.03887", "authors": ["Hyesu Jang", "Wooseong Yang", "Hanguen Kim", "Dongje Lee", "Yongjin Kim", "Jinbum Park", "Minsoo Jeon", "Jaeseong Koh", "Yejin Kang", "Minwoo Jung", "Sangwoo Jung", "Chng Zhen Hao", "Wong Yu Hin", "Chew Yihang", "Ayoung Kim"], "title": "MOANA: Multi-Radar Dataset for Maritime Odometry and Autonomous Navigation Application", "categories": ["cs.RO", "cs.CV"], "comment": "10 pages, 9 figures, 3 tables", "summary": "Maritime environmental sensing requires overcoming challenges from complex\nconditions such as harsh weather, platform perturbations, large dynamic\nobjects, and the requirement for long detection ranges. While cameras and LiDAR\nare commonly used in ground vehicle navigation, their applicability in maritime\nsettings is limited by range constraints and hardware maintenance issues. Radar\nsensors, however, offer robust long-range detection capabilities and resilience\nto physical contamination from weather and saline conditions, making it a\npowerful sensor for maritime navigation. Among various radar types, X-band\nradar is widely employed for maritime vessel navigation, providing effective\nlong-range detection essential for situational awareness and collision\navoidance. Nevertheless, it exhibits limitations during berthing operations\nwhere near-field detection is critical. To address this shortcoming, we\nincorporate W-band radar, which excels in detecting nearby objects with a\nhigher update rate. We present a comprehensive maritime sensor dataset\nfeaturing multi-range detection capabilities. This dataset integrates\nshort-range LiDAR data, medium-range W-band radar data, and long-range X-band\nradar data into a unified framework. Additionally, it includes object labels\nfor oceanic object detection usage, derived from radar and stereo camera\nimages. The dataset comprises seven sequences collected from diverse regions\nwith varying levels of \\bl{navigation algorithm} estimation difficulty, ranging\nfrom easy to challenging, and includes common locations suitable for global\nlocalization tasks. This dataset serves as a valuable resource for advancing\nresearch in place recognition, odometry estimation, SLAM, object detection, and\ndynamic object elimination within maritime environments. Dataset can be found\nat https://sites.google.com/view/rpmmoana.", "AI": {"tldr": "The paper introduces a maritime sensor dataset combining LiDAR, W-band, and X-band radar for multi-range detection, addressing limitations in berthing and long-range navigation.", "motivation": "Maritime sensing faces challenges like harsh weather and long-range detection needs. Existing sensors like cameras and LiDAR have limitations, while radar offers robustness but lacks near-field precision.", "method": "The dataset integrates short-range LiDAR, medium-range W-band radar, and long-range X-band radar, with labeled objects from radar and stereo cameras.", "result": "A comprehensive dataset with seven sequences from diverse regions, supporting tasks like SLAM, object detection, and dynamic object elimination.", "conclusion": "The dataset advances maritime navigation research by addressing sensor limitations and providing a unified framework for multi-range detection."}}
{"id": "2412.04134", "pdf": "https://arxiv.org/pdf/2412.04134", "abs": "https://arxiv.org/abs/2412.04134", "authors": ["Tao Zhang", "Zhenhai Liu", "Feipeng Qi", "Yongjun Jiao", "Tailin Wu"], "title": "M2PDE: Compositional Generative Multiphysics and Multi-component PDE Simulation", "categories": ["cs.LG"], "comment": "29pages,14 figures", "summary": "Multiphysics simulation, which models the interactions between multiple\nphysical processes, and multi-component simulation of complex structures are\ncritical in fields like nuclear and aerospace engineering. Previous studies use\nnumerical solvers or ML-based surrogate models for these simulations. However,\nmultiphysics simulations typically require integrating multiple specialized\nsolvers-each for a specific physical process-into a coupled program, which\nintroduces significant development challenges. Furthermore, existing numerical\nalgorithms struggle with highly complex large-scale structures in\nmulti-component simulations. Here we propose compositional Multiphysics and\nMulti-component PDE Simulation with Diffusion models (M2PDE) to overcome these\nchallenges. During diffusion-based training, M2PDE learns energy functions\nmodeling the conditional probability of one physical process/component\nconditioned on other processes/components. In inference, M2PDE generates\ncoupled multiphysics and multi-component solutions by sampling from the joint\nprobability distribution. We evaluate M2PDE on two multiphysics\ntasks-reaction-diffusion and nuclear thermal coupling-where it achieves more\naccurate predictions than surrogate models in challenging scenarios. We then\napply it to a multi-component prismatic fuel element problem, demonstrating\nthat M2PDE scales from single-component training to a 64-component structure\nand outperforms existing domain-decomposition and graph-based approaches. The\ncode is available at https://github.com/AI4Science-WestlakeU/M2PDE.", "AI": {"tldr": "M2PDE uses diffusion models to improve multiphysics and multi-component simulations, outperforming traditional methods in accuracy and scalability.", "motivation": "Addressing challenges in integrating specialized solvers and handling complex structures in multiphysics and multi-component simulations.", "method": "Proposes M2PDE, a diffusion-based model that learns energy functions for conditional probabilities of physical processes/components and samples joint distributions for solutions.", "result": "M2PDE achieves higher accuracy in multiphysics tasks and scales effectively in multi-component simulations, outperforming existing approaches.", "conclusion": "M2PDE offers a robust solution for complex simulations, demonstrating superior performance and scalability."}}
{"id": "2412.07487", "pdf": "https://arxiv.org/pdf/2412.07487", "abs": "https://arxiv.org/abs/2412.07487", "authors": ["Yik Lung Pang", "Alessio Xompero", "Changjae Oh", "Andrea Cavallaro"], "title": "Stereo Hand-Object Reconstruction for Human-to-Robot Handover", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 9 figures, 1 table. (Website:\n  https://qm-ipalab.github.io/StereoHO/)", "summary": "Jointly estimating hand and object shape facilitates the grasping task in\nhuman-to-robot handovers. However, relying on hand-crafted prior knowledge\nabout the geometric structure of the object fails when generalising to unseen\nobjects, and depth sensors fail to detect transparent objects such as drinking\nglasses. In this work, we propose a stereo-based method for hand-object\nreconstruction that combines single-view reconstructions probabilistically to\nform a coherent stereo reconstruction. We learn 3D shape priors from a large\nsynthetic hand-object dataset to ensure that our method is generalisable, and\nuse RGB inputs to better capture transparent objects. We show that our method\nreduces the object Chamfer distance compared to existing RGB based hand-object\nreconstruction methods on single view and stereo settings. We process the\nreconstructed hand-object shape with a projection-based outlier removal step\nand use the output to guide a human-to-robot handover pipeline with\nwide-baseline stereo RGB cameras. Our hand-object reconstruction enables a\nrobot to successfully receive a diverse range of household objects from the\nhuman.", "AI": {"tldr": "A stereo-based method for hand-object reconstruction improves grasping in human-to-robot handovers by combining single-view reconstructions and learning 3D shape priors from synthetic data.", "motivation": "Hand-crafted priors and depth sensors fail with unseen or transparent objects, necessitating a more robust solution.", "method": "Uses stereo RGB inputs and probabilistic combination of single-view reconstructions, leveraging synthetic data for 3D shape priors. Includes outlier removal for refined output.", "result": "Reduces Chamfer distance compared to existing RGB-based methods and enables successful handovers of diverse objects.", "conclusion": "The method generalizes well and improves robot performance in handover tasks."}}
{"id": "2412.08501", "pdf": "https://arxiv.org/pdf/2412.08501", "abs": "https://arxiv.org/abs/2412.08501", "authors": ["Yuang Zhang", "Liping Wang", "Yihong Huang", "Yuanxing Zheng", "Fan Zhang", "Xuemin Lin"], "title": "GradStop: Exploring Training Dynamics in Unsupervised Outlier Detection through Gradient", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised Outlier Detection (UOD) is a critical task in data mining and\nmachine learning, aiming to identify instances that significantly deviate from\nthe majority. Without any label, deep UOD methods struggle with the\nmisalignment between the model's direct optimization goal and the final\nperformance goal of Outlier Detection (OD) task. Through the perspective of\ntraining dynamics, this paper proposes an early stopping algorithm to optimize\nthe training of deep UOD models, ensuring they perform optimally in OD rather\nthan overfitting the entire contaminated dataset.\n  Inspired by UOD mechanism and inlier priority phenomenon, where intuitively\nmodels fit inliers more quickly than outliers, we propose GradStop, a\nsampling-based label-free algorithm to estimate model's real-time performance\nduring training. First, a sampling method generates two sets: one likely\ncontaining more outliers and the other more inliers, then a metric based on\ngradient cohesion is applied to probe into current training dynamics, which\nreflects model's performance on OD task.\n  Experimental results on 4 deep UOD algorithms and 47 real-world datasets and\ntheoretical proofs demonstrate the effectiveness of our proposed early stopping\nalgorithm in enhancing the performance of deep UOD models. Auto Encoder (AE)\nenhanced by GradStop achieves better performance than itself, other SOTA UOD\nmethods, and even ensemble AEs. Our method provides a robust and effective\nsolution to the problem of performance degradation during training, enabling\ndeep UOD models to achieve better potential in anomaly detection tasks.", "AI": {"tldr": "The paper proposes GradStop, an early stopping algorithm for deep Unsupervised Outlier Detection (UOD) to prevent overfitting and improve performance by leveraging training dynamics and gradient cohesion.", "motivation": "Deep UOD methods often misalign optimization goals with performance goals due to lack of labels, leading to overfitting. The paper addresses this by focusing on training dynamics.", "method": "GradStop uses a sampling-based approach to estimate real-time performance, dividing data into outlier-rich and inlier-rich sets, and applies gradient cohesion metrics to guide early stopping.", "result": "Experiments on 4 algorithms and 47 datasets show GradStop enhances performance, with Auto Encoder (AE) outperforming SOTA methods and ensemble AEs.", "conclusion": "GradStop effectively mitigates performance degradation in deep UOD training, improving anomaly detection potential."}}
{"id": "2504.06304", "pdf": "https://arxiv.org/pdf/2504.06304", "abs": "https://arxiv.org/abs/2504.06304", "authors": ["Matvei Popov", "Aymen Kallala", "Anirudha Ramesh", "Narimane Hennouni", "Shivesh Khaitan", "Rick Gentry", "Alain-Sam Cohen"], "title": "Leveraging State Space Models in Long Range Genomics", "categories": ["q-bio.GN", "cs.CV", "cs.LG"], "comment": "Accepted at ICLR 2025 (Spotlight @ LMRL) - Project page:\n  https://anirudharamesh.github.io/iclr-long-range-genomics/", "summary": "Long-range dependencies are critical for understanding genomic structure and\nfunction, yet most conventional methods struggle with them. Widely adopted\ntransformer-based models, while excelling at short-context tasks, are limited\nby the attention module's quadratic computational complexity and inability to\nextrapolate to sequences longer than those seen in training. In this work, we\nexplore State Space Models (SSMs) as a promising alternative by benchmarking\ntwo SSM-inspired architectures, Caduceus and Hawk, on long-range genomics\nmodeling tasks under conditions parallel to a 50M parameter transformer\nbaseline. We discover that SSMs match transformer performance and exhibit\nimpressive zero-shot extrapolation across multiple tasks, handling contexts 10\nto 100 times longer than those seen during training, indicating more\ngeneralizable representations better suited for modeling the long and complex\nhuman genome. Moreover, we demonstrate that these models can efficiently\nprocess sequences of 1M tokens on a single GPU, allowing for modeling entire\ngenomic regions at once, even in labs with limited compute. Our findings\nestablish SSMs as efficient and scalable for long-context genomic analysis.", "AI": {"tldr": "State Space Models (SSMs) like Caduceus and Hawk match transformer performance in genomics, handle longer sequences, and are computationally efficient.", "motivation": "Conventional methods and transformers struggle with long-range dependencies in genomics, limiting their applicability.", "method": "Benchmarked SSM-inspired architectures (Caduceus and Hawk) against a 50M parameter transformer baseline on long-range genomics tasks.", "result": "SSMs matched transformer performance, extrapolated to longer sequences (10-100x training length), and processed 1M tokens efficiently on a single GPU.", "conclusion": "SSMs are efficient, scalable, and better suited for long-context genomic analysis than transformers."}}
{"id": "2501.08425", "pdf": "https://arxiv.org/pdf/2501.08425", "abs": "https://arxiv.org/abs/2501.08425", "authors": ["Davide Barbieri", "Matteo Bonforte", "Peio Ibarrondo"], "title": "Is Stochastic Gradient Descent Effective? A PDE Perspective on Machine Learning processes", "categories": ["cs.LG", "math.AP", "math.PR", "35Q68, 68T07, 35K65, 35B40, 60J60, 35J70, 35K15"], "comment": null, "summary": "In this paper we analyze the behaviour of the stochastic gradient descent\n(SGD), a widely used method in supervised learning for optimizing neural\nnetwork weights via a minimization of non-convex loss functions. Since the\npioneering work of E, Li and Tai (2017), the underlying structure of such\nprocesses can be understood via parabolic PDEs of Fokker-Planck type, which are\nat the core of our analysis. Even if Fokker-Planck equations have a long\nhistory and a extensive literature, almost nothing is known when the potential\nis non-convex or when the diffusion matrix is degenerate, and this is the main\ndifficulty that we face in our analysis.\n  We identify two different regimes: in the initial phase of SGD, the loss\nfunction drives the weights to concentrate around the nearest local minimum. We\nrefer to this phase as the drift regime and we provide quantitative estimates\non this concentration phenomenon. Next, we introduce the diffusion regime,\nwhere stochastic fluctuations help the learning process to escape suboptimal\nlocal minima. We analyze the Mean Exit Time (MET) and prove upper and lower\nbounds of the MET. Finally, we address the asymptotic convergence of SGD, for a\nnon-convex cost function and a degenerate diffusion matrix, that do not allow\nto use the standard approaches, and require new techniques. For this purpose,\nwe exploit two different methods: duality and entropy methods.\n  We provide new results about the dynamics and effectiveness of SGD, offering\na deep connection between stochastic optimization and PDE theory, and some\nanswers and insights to basic questions in the Machine Learning processes: How\nlong does SGD take to escape from a bad minimum? Do neural network parameters\nconverge using SGD? How do parameters evolve in the first stage of training\nwith SGD?", "AI": {"tldr": "The paper analyzes SGD in neural networks using Fokker-Planck PDEs, identifying drift and diffusion regimes, and providing bounds on Mean Exit Time (MET) and asymptotic convergence for non-convex cases.", "motivation": "To understand SGD's behavior in non-convex optimization, addressing gaps in Fokker-Planck theory for degenerate diffusion and non-convex potentials.", "method": "Uses parabolic PDEs (Fokker-Planck type) to model SGD, analyzing drift and diffusion regimes, MET bounds, and asymptotic convergence via duality and entropy methods.", "result": "Quantitative estimates for weight concentration in the drift regime, MET bounds for escaping suboptimal minima, and asymptotic convergence results for non-convex cases.", "conclusion": "The study bridges stochastic optimization and PDE theory, offering insights into SGD dynamics, escape times from minima, and parameter convergence in neural networks."}}
{"id": "2504.14257", "pdf": "https://arxiv.org/pdf/2504.14257", "abs": "https://arxiv.org/abs/2504.14257", "authors": ["Yilin Liu", "Duoteng Xu", "Xingyao Yu", "Xiang Xu", "Daniel Cohen-Or", "Hao Zhang", "Hui Huang"], "title": "HoLa: B-Rep Generation using a Holistic Latent Representation", "categories": ["cs.GR", "cs.CV"], "comment": "ACM TOG and SIGGRAPH 2025 (Patent Protected); Project page:\n  https://vcc.tech/research/2025/HolaBrep; Demo page:\n  https://huggingface.co/spaces/YuXingyao/HoLa-BRep", "summary": "We introduce a novel representation for learning and generating\nComputer-Aided Design (CAD) models in the form of $\\textit{boundary\nrepresentations}$ (B-Reps). Our representation unifies the continuous geometric\nproperties of B-Rep primitives in different orders (e.g., surfaces and curves)\nand their discrete topological relations in a $\\textit{holistic latent}$ (HoLa)\nspace. This is based on the simple observation that the topological connection\nbetween two surfaces is intrinsically tied to the geometry of their\nintersecting curve. Such a prior allows us to reformulate topology learning in\nB-Reps as a geometric reconstruction problem in Euclidean space. Specifically,\nwe eliminate the presence of curves, vertices, and all the topological\nconnections in the latent space by learning to distinguish and derive curve\ngeometries from a pair of surface primitives via a neural intersection network.\nTo this end, our holistic latent space is only defined on surfaces but encodes\na full B-Rep model, including the geometry of surfaces, curves, vertices, and\ntheir topological relations. Our compact and holistic latent space facilitates\nthe design of a first diffusion-based generator to take on a large variety of\ninputs including point clouds, single/multi-view images, 2D sketches, and text\nprompts. Our method significantly reduces ambiguities, redundancies, and\nincoherences among the generated B-Rep primitives, as well as training\ncomplexities inherent in prior multi-step B-Rep learning pipelines, while\nachieving greatly improved validity rate over current state of the art: 82% vs.\n$\\approx$50%.", "AI": {"tldr": "A novel representation for CAD models using a holistic latent (HoLa) space unifies geometry and topology, enabling a diffusion-based generator for diverse inputs with improved validity.", "motivation": "To address ambiguities, redundancies, and incoherences in CAD model generation by unifying geometric and topological properties in a single latent space.", "method": "Uses a neural intersection network to derive curve geometries from surface pairs, eliminating curves and topology in the latent space. The HoLa space encodes full B-Rep models.", "result": "Achieves 82% validity rate, significantly outperforming prior methods (~50%). Reduces training complexity and improves coherence.", "conclusion": "The HoLa space and diffusion-based generator provide a compact, efficient, and high-validity solution for CAD model generation from diverse inputs."}}
{"id": "2501.15458", "pdf": "https://arxiv.org/pdf/2501.15458", "abs": "https://arxiv.org/abs/2501.15458", "authors": ["Cen-You Li", "Marc Toussaint", "Barbara Rakitsch", "Christoph Zimmer"], "title": "Amortized Safe Active Learning for Real-Time Data Acquisition: Pretrained Neural Policies from Simulated Nonparametric Functions", "categories": ["cs.LG"], "comment": "Part of the content published earlier at arXiv:2407.17992", "summary": "Safe active learning (AL) is a sequential scheme for learning unknown systems\nwhile respecting safety constraints during data acquisition. Existing methods\noften rely on Gaussian processes (GPs) to model the task and safety\nconstraints, requiring repeated GP updates and constrained acquisition\noptimization-incurring in significant computations which are challenging for\nreal-time decision-making. We propose an amortized safe AL framework that\nreplaces expensive online computations with a pretrained neural policy.\nInspired by recent advances in amortized Bayesian experimental design, we turn\nGPs into a pretraining simulator. We train our policy prior to the AL\ndeployment on simulated nonparametric functions, using Fourier feature-based GP\nsampling and a differentiable, safety-aware acquisition objective. At\ndeployment, our policy selects safe and informative queries via a single\nforward pass, eliminating the need for GP inference or constrained\noptimization. This leads to substantial speed improvements while preserving\nsafety and learning quality. Our framework is modular and can be adapted to\nunconstrained, time-sensitive AL tasks by omitting the safety requirement.", "AI": {"tldr": "An amortized safe active learning framework replaces costly online computations with a pretrained neural policy, improving speed while maintaining safety and learning quality.", "motivation": "Existing safe active learning methods rely on Gaussian processes, which are computationally expensive for real-time decision-making.", "method": "The proposed framework uses a pretrained neural policy trained on simulated nonparametric functions, eliminating the need for GP inference or constrained optimization during deployment.", "result": "The framework achieves significant speed improvements while preserving safety and learning quality.", "conclusion": "The modular framework is adaptable to unconstrained, time-sensitive active learning tasks by omitting safety requirements."}}
{"id": "2504.19200", "pdf": "https://arxiv.org/pdf/2504.19200", "abs": "https://arxiv.org/abs/2504.19200", "authors": ["Tristan Manchester", "Adam Anders", "Julio Spadotto", "Hannah Eccleston", "William Beavan", "Hugues Arcis", "Brian J. Connolly"], "title": "Leveraging Modified Ex Situ Tomography Data for Segmentation of In Situ Synchrotron X-Ray Computed Tomography", "categories": ["cond-mat.mtrl-sci", "cs.CV"], "comment": null, "summary": "In situ synchrotron X-ray computed tomography enables dynamic material\nstudies, but automated segmentation remains challenging due to complex imaging\nartefacts and limited training data. We present a methodology for deep\nlearning-based segmentation by transforming high-quality ex situ laboratory\ndata to train models for binary segmentation of in situ synchrotron data,\ndemonstrated through copper oxide dissolution studies. Using a modified\nSegFormer architecture, our approach achieves high segmentation performance on\nunseen data while reducing processing time from hours to seconds per 3D\ndataset. The method maintains consistent performance over significant\nmorphological changes during experiments, despite training only on static\nspecimens. This methodology can be readily applied to diverse materials\nsystems, accelerating the analysis of time-resolved tomographic data across\nscientific disciplines.", "AI": {"tldr": "A deep learning method transforms ex situ lab data to train models for binary segmentation of in situ synchrotron data, achieving high performance and speed.", "motivation": "Automated segmentation of in situ synchrotron X-ray computed tomography is challenging due to imaging artefacts and limited training data.", "method": "Uses a modified SegFormer architecture to train models on ex situ data for in situ segmentation, demonstrated with copper oxide dissolution.", "result": "Achieves high segmentation performance, reduces processing time from hours to seconds, and maintains consistency over morphological changes.", "conclusion": "The method is adaptable to diverse materials systems, accelerating time-resolved tomographic analysis."}}
{"id": "2501.15461", "pdf": "https://arxiv.org/pdf/2501.15461", "abs": "https://arxiv.org/abs/2501.15461", "authors": ["Xin He", "Yili Wang", "Wenqi Fan", "Xu Shen", "Xin Juan", "Rui Miao", "Xin Wang"], "title": "Mamba-Based Graph Convolutional Networks: Tackling Over-smoothing with Selective State Space", "categories": ["cs.LG"], "comment": "11 pages, 4 figures", "summary": "Graph Neural Networks (GNNs) have shown great success in various graph-based\nlearning tasks. However, it often faces the issue of over-smoothing as the\nmodel depth increases, which causes all node representations to converge to a\nsingle value and become indistinguishable. This issue stems from the inherent\nlimitations of GNNs, which struggle to distinguish the importance of\ninformation from different neighborhoods. In this paper, we introduce MbaGCN, a\nnovel graph convolutional architecture that draws inspiration from the Mamba\nparadigm-originally designed for sequence modeling. MbaGCN presents a new\nbackbone for GNNs, consisting of three key components: the Message Aggregation\nLayer, the Selective State Space Transition Layer, and the Node State\nPrediction Layer. These components work in tandem to adaptively aggregate\nneighborhood information, providing greater flexibility and scalability for\ndeep GNN models. While MbaGCN may not consistently outperform all existing\nmethods on each dataset, it provides a foundational framework that demonstrates\nthe effective integration of the Mamba paradigm into graph representation\nlearning. Through extensive experiments on benchmark datasets, we demonstrate\nthat MbaGCN paves the way for future advancements in graph neural network\nresearch.", "AI": {"tldr": "MbaGCN, a new GNN architecture inspired by the Mamba paradigm, addresses over-smoothing by adaptively aggregating neighborhood information through three key layers.", "motivation": "Over-smoothing in deep GNNs causes indistinguishable node representations, limiting their effectiveness. MbaGCN aims to solve this by integrating the Mamba paradigm for better information aggregation.", "method": "MbaGCN introduces three layers: Message Aggregation, Selective State Space Transition, and Node State Prediction, to adaptively process neighborhood information.", "result": "MbaGCN shows promise as a foundational framework for deep GNNs, though it doesn't always outperform existing methods.", "conclusion": "MbaGCN effectively integrates the Mamba paradigm into GNNs, offering a scalable solution for future research in graph representation learning."}}
{"id": "2505.01932", "pdf": "https://arxiv.org/pdf/2505.01932", "abs": "https://arxiv.org/abs/2505.01932", "authors": ["Xinmu Wang", "Xiang Gao", "Xiyun Song", "Heather Yu", "Zongfang Lin", "Liang Peng", "Xianfeng Gu"], "title": "OT-Talk: Animating 3D Talking Head with Optimal Transportation", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Animating 3D head meshes using audio inputs has significant applications in\nAR/VR, gaming, and entertainment through 3D avatars. However, bridging the\nmodality gap between speech signals and facial dynamics remains a challenge,\noften resulting in incorrect lip syncing and unnatural facial movements. To\naddress this, we propose OT-Talk, the first approach to leverage optimal\ntransportation to optimize the learning model in talking head animation.\nBuilding on existing learning frameworks, we utilize a pre-trained Hubert model\nto extract audio features and a transformer model to process temporal\nsequences. Unlike previous methods that focus solely on vertex coordinates or\ndisplacements, we introduce Chebyshev Graph Convolution to extract geometric\nfeatures from triangulated meshes. To measure mesh dissimilarities, we go\nbeyond traditional mesh reconstruction errors and velocity differences between\nadjacent frames. Instead, we represent meshes as probability measures and\napproximate their surfaces. This allows us to leverage the sliced Wasserstein\ndistance for modeling mesh variations. This approach facilitates the learning\nof smooth and accurate facial motions, resulting in coherent and natural facial\nanimations. Our experiments on two public audio-mesh datasets demonstrate that\nour method outperforms state-of-the-art techniques both quantitatively and\nqualitatively in terms of mesh reconstruction accuracy and temporal alignment.\nIn addition, we conducted a user perception study with 20 volunteers to further\nassess the effectiveness of our approach.", "AI": {"tldr": "OT-Talk uses optimal transportation and Chebyshev Graph Convolution to improve 3D head mesh animation from audio, outperforming existing methods in accuracy and naturalness.", "motivation": "Bridging the modality gap between speech signals and facial dynamics for better AR/VR, gaming, and entertainment applications.", "method": "Combines Hubert model for audio features, transformer for sequences, and Chebyshev Graph Convolution for mesh features, using sliced Wasserstein distance for mesh dissimilarity.", "result": "Outperforms state-of-the-art in mesh reconstruction and temporal alignment, validated by user perception studies.", "conclusion": "OT-Talk achieves smoother, more accurate facial animations, advancing audio-driven 3D head mesh animation."}}
{"id": "2502.08227", "pdf": "https://arxiv.org/pdf/2502.08227", "abs": "https://arxiv.org/abs/2502.08227", "authors": ["Suqin Yuan", "Lei Feng", "Bo Han", "Tongliang Liu"], "title": "Enhancing Sample Selection Against Label Noise by Cutting Mislabeled Easy Examples", "categories": ["cs.LG"], "comment": null, "summary": "Sample selection is a prevalent approach in learning with noisy labels,\naiming to identify confident samples for training. Although existing sample\nselection methods have achieved decent results by reducing the noise rate of\nthe selected subset, they often overlook that not all mislabeled examples harm\nthe model's performance equally. In this paper, we demonstrate that mislabeled\nexamples correctly predicted by the model early in the training process are\nparticularly harmful to model performance. We refer to these examples as\nMislabeled Easy Examples (MEEs). To address this, we propose Early Cutting,\nwhich introduces a recalibration step that employs the model's later training\nstate to re-select the confident subset identified early in training, thereby\navoiding misleading confidence from early learning and effectively filtering\nout MEEs. Experiments on the CIFAR, WebVision, and full ImageNet-1k datasets\ndemonstrate that our method effectively improves sample selection and model\nperformance by reducing MEEs.", "AI": {"tldr": "The paper introduces Early Cutting, a method to filter out harmful mislabeled easy examples (MEEs) during training, improving model performance.", "motivation": "Existing sample selection methods overlook the varying harm of mislabeled examples, especially MEEs, which degrade model performance.", "method": "Proposes Early Cutting, a recalibration step using later training states to re-select confident samples and filter MEEs.", "result": "Experiments on CIFAR, WebVision, and ImageNet-1k show improved sample selection and model performance.", "conclusion": "Early Cutting effectively reduces MEEs, enhancing model robustness and performance."}}
{"id": "2505.02350", "pdf": "https://arxiv.org/pdf/2505.02350", "abs": "https://arxiv.org/abs/2505.02350", "authors": ["Bobo Lian", "Dandan Wang", "Chenjian Wu", "Minxin Chen"], "title": "Sparse Ellipsoidal Radial Basis Function Network for Point Cloud Surface Representation", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": null, "summary": "Point cloud surface representation is a fundamental problem in computer\ngraphics and vision. This paper presents a machine learning approach for\napproximating the signed distance function (SDF) of a point cloud using a\nsparse ellipsoidal radial basis function network, enabling a compact and\naccurate surface representation. Given the SDF values defined on the grid\npoints constructed from the point cloud, our method approximates the SDF\naccurately with as few ellipsoidal radial basis functions (ERBFs) as possible,\ni.e., represents the SDF of a point cloud by sparse ERBFs. To balance sparsity\nand approximation precision, a dynamic multi-objective optimization strategy is\nintroduced, which adaptively adds the regularization terms and jointly\noptimizes the weights, centers, shapes, and orientations of ERBFs. To improve\ncomputational efficiency, a nearest-neighbor-based data structure is employed,\nrestricting function calculations to points near each Gaussian kernel center.\nThe computations for each kernel are further parallelized on CUDA, which\nsignificantly improves the optimization speed. Additionally, a hierarchical\noctree-based refinement strategy is designed for training. Specifically, the\ninitialization and optimization of network parameters are conducted using\ncoarse grid points in the octree lattice structure. Subsequently, fine lattice\npoints are progressively incorporated to accelerate model convergence and\nenhance training efficiency. Extensive experiments on multiple benchmark\ndatasets demonstrate that our method outperforms previous sparse representation\napproaches in terms of accuracy, robustness, and computational efficiency. The\ncorresponding executable program is publicly available at\nhttps://github.com/lianbobo/SE-RBFNet.git.", "AI": {"tldr": "A machine learning method using sparse ellipsoidal radial basis functions (ERBFs) to approximate signed distance functions (SDFs) for point cloud surface representation, optimized for sparsity, accuracy, and computational efficiency.", "motivation": "To address the challenge of compact and accurate surface representation in point clouds, leveraging sparse ERBFs for efficient SDF approximation.", "method": "Dynamic multi-objective optimization for sparse ERBFs, nearest-neighbor-based data structure for efficiency, CUDA parallelization, and hierarchical octree-based refinement.", "result": "Outperforms previous sparse representation methods in accuracy, robustness, and computational efficiency.", "conclusion": "The proposed method provides a scalable and efficient solution for point cloud surface representation, with publicly available code."}}
{"id": "2502.08231", "pdf": "https://arxiv.org/pdf/2502.08231", "abs": "https://arxiv.org/abs/2502.08231", "authors": ["Evgeniia Tokarchuk", "Hua Chang Bakker", "Vlad Niculae"], "title": "Keep your distance: learning dispersed embeddings on $\\mathbb{S}_m$", "categories": ["cs.LG"], "comment": null, "summary": "Learning well-separated features in high-dimensional spaces, such as text or\nimage embeddings, is crucial for many machine learning applications. Achieving\nsuch separation can be effectively accomplished through the dispersion of\nembeddings, where unrelated vectors are pushed apart as much as possible. By\nconstraining features to be on a hypersphere, we can connect dispersion to\nwell-studied problems in mathematics and physics, where optimal solutions are\nknown for limited low-dimensional cases. However, in representation learning we\ntypically deal with a large number of features in high-dimensional space, and\nmoreover, dispersion is usually traded off with some other task-oriented\ntraining objective, making existing theoretical and numerical solutions\ninapplicable. Therefore, it is common to rely on gradient-based methods to\nencourage dispersion, usually by minimizing some function of the pairwise\ndistances. In this work, we first give an overview of existing methods from\ndisconnected literature, making new connections and highlighting similarities.\nNext, we introduce some new angles. We propose to reinterpret pairwise\ndispersion using a maximum mean discrepancy (MMD) motivation. We then propose\nan online variant of the celebrated Lloyd's algorithm, of K-Means fame, as an\neffective alternative regularizer for dispersion on generic domains. Finally,\nwe derive a novel dispersion method that directly exploits properties of the\nhypersphere. Our experiments show the importance of dispersion in image\nclassification and natural language processing tasks, and how algorithms\nexhibit different trade-offs in different regimes.", "AI": {"tldr": "The paper explores methods to achieve well-separated features in high-dimensional spaces, focusing on dispersion of embeddings. It connects dispersion to mathematical problems, proposes new methods including an online variant of Lloyd's algorithm, and demonstrates their effectiveness in tasks like image classification and NLP.", "motivation": "Learning well-separated features is crucial for machine learning applications, but existing theoretical and numerical solutions are often inapplicable due to high dimensionality and trade-offs with task-oriented objectives.", "method": "The paper reviews existing methods, proposes a reinterpretation of pairwise dispersion using MMD, introduces an online variant of Lloyd's algorithm, and derives a novel hypersphere-based dispersion method.", "result": "Experiments show the importance of dispersion in tasks like image classification and NLP, with different algorithms exhibiting trade-offs in various regimes.", "conclusion": "The study highlights the significance of dispersion in representation learning, offering new methods and insights for achieving it effectively."}}
{"id": "2505.05132", "pdf": "https://arxiv.org/pdf/2505.05132", "abs": "https://arxiv.org/abs/2505.05132", "authors": ["Luis Alvarez", "Jean-Michel Morel"], "title": "An Active Contour Model for Silhouette Vectorization using B\u00e9zier Curves", "categories": ["cs.GR", "cs.CV", "math.FA"], "comment": "14 pages, 5 figures and 1 table", "summary": "In this paper, we propose an active contour model for silhouette\nvectorization using cubic B\\'ezier curves. Among the end points of the B\\'ezier\ncurves, we distinguish between corner and regular points where the orientation\nof the tangent vector is prescribed. By minimizing the distance of the B\\'ezier\ncurves to the silhouette boundary, the active contour model optimizes the\nlocation of the B\\'ezier curves end points, the orientation of the tangent\nvectors in the regular points, and the estimation of the B\\'ezier curve\nparameters. This active contour model can use the silhouette vectorization\nobtained by any method as an initial guess. The proposed method significantly\nreduces the average distance between the silhouette boundary and its\nvectorization obtained by the world-class graphic software Inkscape, Adobe\nIllustrator, and a curvature-based vectorization method, which we introduce for\ncomparison. Our method also allows us to impose additional regularity on the\nB\\'ezier curves by reducing their lengths.", "AI": {"tldr": "Proposes an active contour model using cubic B\u00e9zier curves for silhouette vectorization, optimizing curve parameters and reducing distance to silhouette boundaries.", "motivation": "To improve silhouette vectorization accuracy by minimizing the distance between B\u00e9zier curves and silhouette boundaries, outperforming existing methods like Inkscape and Adobe Illustrator.", "method": "Uses an active contour model to optimize B\u00e9zier curve end points, tangent vectors, and parameters, starting from any initial vectorization.", "result": "Significantly reduces average distance to silhouette boundaries compared to Inkscape, Adobe Illustrator, and a curvature-based method. Also allows imposing curve regularity by reducing lengths.", "conclusion": "The method enhances silhouette vectorization accuracy and regularity, outperforming leading software and introducing a new curvature-based comparison."}}
{"id": "2503.04318", "pdf": "https://arxiv.org/pdf/2503.04318", "abs": "https://arxiv.org/abs/2503.04318", "authors": ["Tim Maurer", "Abdulrahman Mohamed Selim", "Hasan Md Tusfiqur Alam", "Matthias Eiletz", "Michael Barz", "Daniel Sonntag"], "title": "InFL-UX: A Toolkit for Web-Based Interactive Federated Learning", "categories": ["cs.LG", "cs.HC"], "comment": "Accepted in the 17th ACM SIGCHI Symposium on Engineering Interactive\n  Computing Systems (EICS 2025)", "summary": "This paper presents InFL-UX, an interactive, proof-of-concept browser-based\nFederated Learning (FL) toolkit designed to integrate user contributions\nseamlessly into the machine learning (ML) workflow. InFL-UX enables users\nacross multiple devices to upload datasets, define classes, and collaboratively\ntrain classification models directly in the browser using modern web\ntechnologies. Unlike traditional FL toolkits, which often focus on backend\nsimulations, InFL-UX provides a simple user interface for researchers to\nexplore how users interact with and contribute to FL systems in real-world,\ninteractive settings. By prioritising usability and decentralised model\ntraining, InFL-UX bridges the gap between FL and Interactive Machine Learning\n(IML), empowering non-technical users to actively participate in ML\nclassification tasks.", "AI": {"tldr": "InFL-UX is a browser-based Federated Learning toolkit that integrates user contributions into ML workflows, enabling collaborative model training with a focus on usability and real-world interaction.", "motivation": "To bridge the gap between Federated Learning and Interactive Machine Learning by involving non-technical users in ML tasks through a simple, interactive interface.", "method": "InFL-UX allows users to upload datasets, define classes, and train classification models collaboratively in the browser using modern web technologies.", "result": "The toolkit facilitates real-world, interactive FL settings, prioritizing usability and decentralized training.", "conclusion": "InFL-UX empowers non-technical users to actively participate in ML classification, merging FL and IML effectively."}}
{"id": "2505.05592", "pdf": "https://arxiv.org/pdf/2505.05592", "abs": "https://arxiv.org/abs/2505.05592", "authors": ["Noriaki Hirose", "Lydia Ignatova", "Kyle Stachowicz", "Catherine Glossop", "Sergey Levine", "Dhruv Shah"], "title": "Learning to Drive Anywhere with Model-Based Reannotation", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "19 pages, 11 figures, 8 tables", "summary": "Developing broadly generalizable visual navigation policies for robots is a\nsignificant challenge, primarily constrained by the availability of\nlarge-scale, diverse training data. While curated datasets collected by\nresearchers offer high quality, their limited size restricts policy\ngeneralization. To overcome this, we explore leveraging abundant, passively\ncollected data sources, including large volumes of crowd-sourced teleoperation\ndata and unlabeled YouTube videos, despite their potential for lower quality or\nmissing action labels. We propose Model-Based ReAnnotation (MBRA), a framework\nthat utilizes a learned short-horizon, model-based expert model to relabel or\ngenerate high-quality actions for these passive datasets. This relabeled data\nis then distilled into LogoNav, a long-horizon navigation policy conditioned on\nvisual goals or GPS waypoints. We demonstrate that LogoNav, trained using\nMBRA-processed data, achieves state-of-the-art performance, enabling robust\nnavigation over distances exceeding 300 meters in previously unseen indoor and\noutdoor environments. Our extensive real-world evaluations, conducted across a\nfleet of robots (including quadrupeds) in six cities on three continents,\nvalidate the policy's ability to generalize and navigate effectively even\namidst pedestrians in crowded settings.", "AI": {"tldr": "MBRA framework improves robot navigation by relabeling passive data (e.g., YouTube videos) with a learned expert model, enabling LogoNav to achieve state-of-the-art performance in diverse environments.", "motivation": "Limited size of curated datasets restricts robot navigation policy generalization, prompting the use of abundant but lower-quality passive data sources.", "method": "Proposes Model-Based ReAnnotation (MBRA) to relabel passive data using a learned expert model, distilling it into LogoNav for long-horizon navigation.", "result": "LogoNav achieves robust navigation over 300 meters in unseen environments, validated in real-world tests across six cities.", "conclusion": "MBRA-processed data enables LogoNav to generalize effectively, even in crowded settings, advancing visual navigation for robots."}}
{"id": "2503.14004", "pdf": "https://arxiv.org/pdf/2503.14004", "abs": "https://arxiv.org/abs/2503.14004", "authors": ["Eyal Marantz", "Ori Plonsky"], "title": "Predicting Human Choice Between Textually Described Lotteries", "categories": ["cs.LG"], "comment": null, "summary": "Predicting human decision-making under risk and uncertainty is a\nlong-standing challenge in cognitive science, economics, and AI. While prior\nresearch has focused on numerically described lotteries, real-world decisions\noften rely on textual descriptions. This study conducts the first large-scale\nexploration of human decision-making in such tasks using a large dataset of\none-shot binary choices between textually described lotteries. We evaluate\nmultiple computational approaches, including fine-tuning Large Language Models\n(LLMs), leveraging embeddings, and integrating behavioral theories of choice\nunder risk. Our results show that fine-tuned LLMs, specifically GPT-4o,\noutperform hybrid models that incorporate behavioral theory, challenging\nestablished methods in numerical settings. These findings highlight fundamental\ndifferences in how textual and numerical information influence decision-making\nand underscore the need for new modeling strategies to bridge this gap.", "AI": {"tldr": "Fine-tuned LLMs like GPT-4o outperform hybrid models in predicting human decisions from text-based lotteries, revealing differences in textual vs. numerical decision-making.", "motivation": "To address the gap in understanding human decision-making from textual descriptions, as prior work focused on numerical lotteries.", "method": "Evaluated computational approaches (fine-tuned LLMs, embeddings, behavioral theories) on a large dataset of text-based binary choices.", "result": "Fine-tuned LLMs, especially GPT-4o, surpassed hybrid models incorporating behavioral theories.", "conclusion": "Textual and numerical decision-making differ significantly, necessitating new modeling strategies."}}
{"id": "2503.19300", "pdf": "https://arxiv.org/pdf/2503.19300", "abs": "https://arxiv.org/abs/2503.19300", "authors": ["Xiangzhe Kong", "Zishen Zhang", "Ziting Zhang", "Rui Jiao", "Jianzhu Ma", "Wenbing Huang", "Kai Liu", "Yang Liu"], "title": "UniMoMo: Unified Generative Modeling of 3D Molecules for De Novo Binder Design", "categories": ["cs.LG", "q-bio.BM"], "comment": "Accepted to ICML 2025", "summary": "The design of target-specific molecules such as small molecules, peptides,\nand antibodies is vital for biological research and drug discovery. Existing\ngenerative methods are restricted to single-domain molecules, failing to\naddress versatile therapeutic needs or utilize cross-domain transferability to\nenhance model performance. In this paper, we introduce Unified generative\nModeling of 3D Molecules (UniMoMo), the first framework capable of designing\nbinders of multiple molecular domains using a single model. In particular,\nUniMoMo unifies the representations of different molecules as graphs of blocks,\nwhere each block corresponds to either a standard amino acid or a molecular\nfragment. Subsequently, UniMoMo utilizes a geometric latent diffusion model for\n3D molecular generation, featuring an iterative full-atom autoencoder to\ncompress blocks into latent space points, followed by an E(3)-equivariant\ndiffusion process. Extensive benchmarks across peptides, antibodies, and small\nmolecules demonstrate the superiority of our unified framework over existing\ndomain-specific models, highlighting the benefits of multi-domain training.", "AI": {"tldr": "UniMoMo is a unified framework for designing multi-domain molecules using a single model, outperforming domain-specific methods.", "motivation": "Existing generative methods are limited to single-domain molecules, failing to meet versatile therapeutic needs or leverage cross-domain transferability.", "method": "UniMoMo unifies molecular representations as graphs of blocks, using a geometric latent diffusion model for 3D generation, with an iterative full-atom autoencoder and E(3)-equivariant diffusion.", "result": "Benchmarks show UniMoMo's superiority over domain-specific models in generating peptides, antibodies, and small molecules.", "conclusion": "Multi-domain training enhances model performance, making UniMoMo a versatile tool for molecular design."}}
{"id": "2503.20697", "pdf": "https://arxiv.org/pdf/2503.20697", "abs": "https://arxiv.org/abs/2503.20697", "authors": ["Yankai Chen", "Taotao Wang", "Yixiang Fang", "Yunyu Xiao"], "title": "Semi-supervised Node Importance Estimation with Informative Distribution Modeling for Uncertainty Regularization", "categories": ["cs.LG"], "comment": "Accepted by WWW'25. A few typos corrected", "summary": "Node importance estimation, a classical problem in network analysis,\nunderpins various web applications. Previous methods either exploit intrinsic\ntopological characteristics, e.g., graph centrality, or leverage additional\ninformation, e.g., data heterogeneity, for node feature enhancement. However,\nthese methods follow the supervised learning setting, overlooking the fact that\nground-truth node-importance data are usually partially labeled in practice. In\nthis work, we propose the first semi-supervised node importance estimation\nframework, i.e., EASING, to improve learning quality for unlabeled data in\nheterogeneous graphs. Different from previous approaches, EASING explicitly\ncaptures uncertainty to reflect the confidence of model predictions. To jointly\nestimate the importance values and uncertainties, EASING incorporates DJE, a\ndeep encoder-decoder neural architecture. DJE introduces distribution modeling\nfor graph nodes, where the distribution representations derive both importance\nand uncertainty estimates. Additionally, DJE facilitates effective pseudo-label\ngeneration for the unlabeled data to enrich the training samples. Based on\nlabeled and pseudo-labeled data, EASING develops effective semi-supervised\nheteroscedastic learning with varying node uncertainty regularization.\nExtensive experiments on three real-world datasets highlight the superior\nperformance of EASING compared to competing methods. Codes are available via\nhttps://github.com/yankai-chen/EASING.", "AI": {"tldr": "EASING is a semi-supervised framework for node importance estimation in heterogeneous graphs, incorporating uncertainty modeling and pseudo-labeling to improve learning quality for unlabeled data.", "motivation": "Ground-truth node-importance data are often partially labeled, and existing supervised methods overlook this limitation.", "method": "EASING uses DJE, a deep encoder-decoder architecture, to model node distributions for importance and uncertainty estimation, and employs pseudo-labeling for semi-supervised learning.", "result": "EASING outperforms competing methods on three real-world datasets.", "conclusion": "EASING effectively addresses the challenge of partially labeled data in node importance estimation, offering superior performance and uncertainty-aware predictions."}}
{"id": "2504.04799", "pdf": "https://arxiv.org/pdf/2504.04799", "abs": "https://arxiv.org/abs/2504.04799", "authors": ["Maosheng Yang"], "title": "Topological Schr\u00f6dinger Bridge Matching", "categories": ["cs.LG", "stat.ML"], "comment": "ICLR 2025 Spotlight, 42 pages", "summary": "Given two boundary distributions, the Schr\\\"odinger Bridge (SB) problem seeks\nthe ``most likely`` random evolution between them with respect to a reference\nprocess. It has revealed rich connections to recent machine learning methods\nfor generative modeling and distribution matching. While these methods perform\nwell in Euclidean domains, they are not directly applicable to topological\ndomains such as graphs and simplicial complexes, which are crucial for data\ndefined over network entities, such as node signals and edge flows. In this\nwork, we propose the Topological Schr\\\"odinger Bridge problem (TSBP) for\nmatching signal distributions on a topological domain. We set the reference\nprocess to follow some linear tractable topology-aware stochastic dynamics such\nas topological heat diffusion. For the case of Gaussian boundary distributions,\nwe derive a closed-form topological SB (TSB) in terms of its time-marginal and\nstochastic differential. In the general case, leveraging the well-known result,\nwe show that the optimal process follows the forward-backward topological\ndynamics governed by some unknowns. Building on these results, we develop\nTSB-based models for matching topological signals by parameterizing the\nunknowns in the optimal process as (topological) neural networks and learning\nthem through likelihood training. We validate the theoretical results and\ndemonstrate the practical applications of TSB-based models on both synthetic\nand real-world networks, emphasizing the role of topology. Additionally, we\ndiscuss the connections of TSB-based models to other emerging models, and\noutline future directions for topological signal matching.", "AI": {"tldr": "The paper introduces the Topological Schr\u00f6dinger Bridge problem (TSBP) for matching signal distributions on topological domains, extending traditional SB methods to graphs and simplicial complexes.", "motivation": "Existing SB methods are limited to Euclidean domains, but many real-world data (e.g., node signals, edge flows) are defined over topological domains like graphs. The paper aims to bridge this gap.", "method": "The authors propose TSBP, using topology-aware stochastic dynamics (e.g., topological heat diffusion) as a reference process. For Gaussian boundary distributions, they derive a closed-form solution; for general cases, they parameterize unknowns in the optimal process as neural networks and train them via likelihood.", "result": "Theoretical results are validated on synthetic and real-world networks, demonstrating the effectiveness of TSB-based models for topological signal matching.", "conclusion": "The work successfully extends SB to topological domains, offering practical applications and connections to emerging models, with future directions outlined for further research."}}
{"id": "2504.08377", "pdf": "https://arxiv.org/pdf/2504.08377", "abs": "https://arxiv.org/abs/2504.08377", "authors": ["Avrim Blum", "Steve Hanneke", "Chirag Pabbaraju", "Donya Saless"], "title": "Proofs as Explanations: Short Certificates for Reliable Predictions", "categories": ["cs.LG", "stat.ML"], "comment": "Updated bibliography", "summary": "We consider a model for explainable AI in which an explanation for a\nprediction $h(x)=y$ consists of a subset $S'$ of the training data (if it\nexists) such that all classifiers $h' \\in H$ that make at most $b$ mistakes on\n$S'$ predict $h'(x)=y$. Such a set $S'$ serves as a proof that $x$ indeed has\nlabel $y$ under the assumption that (1) the target function $h^\\star$ belongs\nto $H$, and (2) the set $S$ contains at most $b$ corrupted points. For example,\nif $b=0$ and $H$ is the family of linear classifiers in $\\mathbb{R}^d$, and if\n$x$ lies inside the convex hull of the positive data points in $S$ (and hence\nevery consistent linear classifier labels $x$ as positive), then\nCarath\\'eodory's theorem states that $x$ lies inside the convex hull of $d+1$\nof those points. So, a set $S'$ of size $d+1$ could be released as an\nexplanation for a positive prediction, and would serve as a short proof of\ncorrectness of the prediction under the assumption of realizability.\n  In this work, we consider this problem more generally, for general hypothesis\nclasses $H$ and general values $b\\geq 0$. We define the notion of the robust\nhollow star number of $H$ (which generalizes the standard hollow star number),\nand show that it precisely characterizes the worst-case size of the smallest\ncertificate achievable, and analyze its size for natural classes. We also\nconsider worst-case distributional bounds on certificate size, as well as\ndistribution-dependent bounds that we show tightly control the sample size\nneeded to get a certificate for any given test example. In particular, we\ndefine a notion of the certificate coefficient $\\varepsilon_x$ of an example\n$x$ with respect to a data distribution $D$ and target function $h^\\star$, and\nprove matching upper and lower bounds on sample size as a function of\n$\\varepsilon_x$, $b$, and the VC dimension $d$ of $H$.", "AI": {"tldr": "The paper proposes a model for explainable AI where explanations are subsets of training data proving predictions under certain assumptions. It generalizes this for any hypothesis class and analyzes the size and bounds of such proofs.", "motivation": "To provide a framework for explainable AI by certifying predictions using subsets of training data, ensuring robustness and generalizability across hypothesis classes.", "method": "Defines the robust hollow star number for hypothesis classes, analyzes worst-case and distributional bounds on certificate size, and introduces the certificate coefficient for sample size analysis.", "result": "The robust hollow star number characterizes the smallest certificate size, and matching bounds on sample size are derived based on the certificate coefficient, VC dimension, and corruption tolerance.", "conclusion": "The work generalizes explainable AI proofs, providing theoretical guarantees on certificate size and sample complexity, applicable to various hypothesis classes."}}
{"id": "2504.13034", "pdf": "https://arxiv.org/pdf/2504.13034", "abs": "https://arxiv.org/abs/2504.13034", "authors": ["Yangxin Fan", "Haolai Che", "Yinghui Wu"], "title": "Inference-friendly Graph Compression for Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated promising performance in graph\nanalysis. Nevertheless, the inference process of GNNs remains costly, hindering\ntheir applications for large graphs. This paper proposes inference-friendly\ngraph compression (IFGC), a graph compression scheme to accelerate GNNs\ninference. Given a graph $G$ and a GNN $M$, an IFGC computes a small compressed\ngraph $G_c$, to best preserve the inference results of $M$ over $G$, such that\nthe result can be directly inferred by accessing $G_c$ with no or little\ndecompression cost. (1) We characterize IFGC with a class of inference\nequivalence relation. The relation captures the node pairs in $G$ that are not\ndistinguishable for GNN inference. (2) We introduce three practical\nspecifications of IFGC for representative GNNs: structural preserving\ncompression (SPGC), which computes $G_c$ that can be directly processed by GNN\ninference without decompression; ($\\alpha$, $r$)-compression, that allows for a\nconfigurable trade-off between compression ratio and inference quality, and\nanchored compression that preserves inference results for specific nodes of\ninterest. For each scheme, we introduce compression and inference algorithms\nwith guarantees of efficiency and quality of the inferred results. We conduct\nextensive experiments on diverse sets of large-scale graphs, which verifies the\neffectiveness and efficiency of our graph compression approaches.", "AI": {"tldr": "The paper proposes IFGC, a graph compression method to accelerate GNN inference by preserving inference results while minimizing decompression costs.", "motivation": "GNN inference is costly for large graphs, limiting their practical applications. IFGC aims to address this by compressing graphs without compromising inference quality.", "method": "IFGC introduces inference equivalence relations and three practical schemes: SPGC, (\u03b1, r)-compression, and anchored compression, each with tailored algorithms.", "result": "Experiments on large-scale graphs confirm IFGC's effectiveness and efficiency in accelerating GNN inference.", "conclusion": "IFGC provides a scalable solution for efficient GNN inference on large graphs, balancing compression and accuracy."}}
{"id": "2504.16506", "pdf": "https://arxiv.org/pdf/2504.16506", "abs": "https://arxiv.org/abs/2504.16506", "authors": ["Ruxue Shi", "Yili Wang", "Mengnan Du", "Xu Shen", "Xin Wang"], "title": "A Comprehensive Survey of Synthetic Tabular Data Generation", "categories": ["cs.LG"], "comment": null, "summary": "Tabular data remains one of the most prevalent and critical data formats\nacross diverse real-world applications. However, its effective use in machine\nlearning (ML) is often constrained by challenges such as data scarcity, privacy\nconcerns, and class imbalance. Synthetic data generation has emerged as a\npromising solution, leveraging generative models to learn the distribution of\nreal datasets and produce high-fidelity, privacy-preserving samples. Various\ngenerative paradigms have been explored, including energy-based models (EBMs),\nvariational autoencoders (VAEs), generative adversarial networks (GANs), large\nlanguage models (LLMs), and diffusion models. While several surveys have\ninvestigated synthetic tabular data generation, most focus on narrow subdomains\nor specific generative methods, such as GANs, diffusion models, or\nprivacy-preserving techniques. This limited scope often results in fragmented\ninsights, lacking a comprehensive synthesis that bridges diverse approaches. In\nparticular, recent advances driven by LLMs and diffusion-based models remain\nunderexplored. This gap hinders a holistic understanding of the field`s\nevolution, methodological interplay, and open challenges. To address this, our\nsurvey provides a unified and systematic review of synthetic tabular data\ngeneration. Our contributions are threefold: (1) we propose a comprehensive\ntaxonomy that organizes existing methods into traditional approaches,\ndiffusion-based methods, and LLM-based models, and provide an in-depth\ncomparative analysis; (2) we detail the complete pipeline for synthetic tabular\ndata generation, including data synthesis, post-processing, and evaluation; (3)\nwe identify major challenges, explore real-world applications, and outline open\nresearch questions and future directions to guide future work in this rapidly\nevolving area.", "AI": {"tldr": "A survey on synthetic tabular data generation, addressing gaps in existing reviews by unifying diverse methods (traditional, diffusion-based, LLM-based) and detailing pipelines, challenges, and future directions.", "motivation": "Challenges like data scarcity, privacy, and class imbalance limit ML use of tabular data. Existing surveys are fragmented, missing recent advances (e.g., LLMs, diffusion models).", "method": "Proposes a taxonomy of methods, details the synthetic data pipeline (synthesis, post-processing, evaluation), and compares approaches.", "result": "Provides a unified review, comparative analysis, and identifies challenges and applications.", "conclusion": "Highlights open research questions and future directions to advance synthetic tabular data generation."}}
{"id": "2504.20078", "pdf": "https://arxiv.org/pdf/2504.20078", "abs": "https://arxiv.org/abs/2504.20078", "authors": ["Kalyan Cherukuri", "Aarav Lala"], "title": "Low-Rank Matrix Approximation for Neural Network Compression", "categories": ["cs.LG", "cs.CC"], "comment": null, "summary": "Deep Neural Networks (DNNs) have encountered an emerging deployment challenge\ndue to large and expensive memory and computation requirements. In this paper,\nwe present a new Adaptive-Rank Singular Value Decomposition (ARSVD) method that\napproximates the optimal rank for compressing weight matrices in neural\nnetworks using spectral entropy. Unlike conventional SVD-based methods that\napply a fixed-rank truncation across all layers, ARSVD uses an adaptive\nselection of the rank per layer through the entropy distribution of its\nsingular values. This approach ensures that each layer will retain a certain\namount of its informational content, thereby reducing redundancy. Our method\nenables efficient, layer-wise compression, yielding improved performance with\nreduced space and time complexity compared to static-rank reduction techniques.", "AI": {"tldr": "ARSVD method adaptively compresses DNN weight matrices using spectral entropy, outperforming fixed-rank SVD by reducing redundancy and improving efficiency.", "motivation": "Addressing the high memory and computation costs of DNNs by optimizing layer-wise compression.", "method": "Uses spectral entropy to adaptively select rank per layer, ensuring retention of informational content.", "result": "Achieves better performance with reduced space and time complexity compared to fixed-rank methods.", "conclusion": "ARSVD offers a more efficient and adaptive approach to DNN compression."}}
{"id": "2505.00941", "pdf": "https://arxiv.org/pdf/2505.00941", "abs": "https://arxiv.org/abs/2505.00941", "authors": ["Wenxin Zhang", "Ding Xu", "Guangzhen Yao", "Xiaojian Lin", "Renxiang Guan", "Chengze Du", "Renda Han", "Xi Xuan", "Cuicui Luo"], "title": "FreCT: Frequency-augmented Convolutional Transformer for Robust Time Series Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "Time series anomaly detection is critical for system monitoring and risk\nidentification, across various domains, such as finance and healthcare.\nHowever, for most reconstruction-based approaches, detecting anomalies remains\na challenge due to the complexity of sequential patterns in time series data.\nOn the one hand, reconstruction-based techniques are susceptible to\ncomputational deviation stemming from anomalies, which can lead to impure\nrepresentations of normal sequence patterns. On the other hand, they often\nfocus on the time-domain dependencies of time series, while ignoring the\nalignment of frequency information beyond the time domain. To address these\nchallenges, we propose a novel Frequency-augmented Convolutional Transformer\n(FreCT). FreCT utilizes patch operations to generate contrastive views and\nemploys an improved Transformer architecture integrated with a convolution\nmodule to capture long-term dependencies while preserving local topology\ninformation. The introduced frequency analysis based on Fourier transformation\ncould enhance the model's ability to capture crucial characteristics beyond the\ntime domain. To protect the training quality from anomalies and improve the\nrobustness, FreCT deploys stop-gradient Kullback-Leibler (KL) divergence and\nabsolute error to optimize consistency information in both time and frequency\ndomains. Extensive experiments on four public datasets demonstrate that FreCT\noutperforms existing methods in identifying anomalies.", "AI": {"tldr": "FreCT, a novel Frequency-augmented Convolutional Transformer, improves time series anomaly detection by integrating frequency analysis and robust training techniques, outperforming existing methods.", "motivation": "Existing reconstruction-based anomaly detection methods struggle with sequential pattern complexity, computational deviations from anomalies, and lack of frequency-domain alignment.", "method": "FreCT combines patch operations for contrastive views, a Transformer with convolution for long-term and local dependencies, and Fourier-based frequency analysis. It uses stop-gradient KL divergence and absolute error for robust training.", "result": "FreCT outperforms existing methods in anomaly detection on four public datasets.", "conclusion": "FreCT effectively addresses challenges in time series anomaly detection by leveraging frequency augmentation and robust optimization, demonstrating superior performance."}}
{"id": "2505.02222", "pdf": "https://arxiv.org/pdf/2505.02222", "abs": "https://arxiv.org/abs/2505.02222", "authors": ["Essential AI", ":", "Ishaan Shah", "Anthony M. Polloreno", "Karl Stratos", "Philip Monk", "Adarsh Chaluvaraju", "Andrew Hojel", "Andrew Ma", "Anil Thomas", "Ashish Tanwer", "Darsh J Shah", "Khoi Nguyen", "Kurt Smith", "Michael Callahan", "Michael Pust", "Mohit Parmar", "Peter Rushton", "Platon Mazarakis", "Ritvik Kapila", "Saurabh Srivastava", "Somanshu Singla", "Tim Romanski", "Yash Vanjani", "Ashish Vaswani"], "title": "Practical Efficiency of Muon for Pretraining", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We demonstrate that Muon, the simplest instantiation of a second-order\noptimizer, explicitly expands the Pareto frontier over AdamW on the\ncompute-time tradeoff. We find that Muon is more effective than AdamW in\nretaining data efficiency at large batch sizes, far beyond the so-called\ncritical batch size, while remaining computationally efficient, thus enabling\nmore economical training. We study the combination of Muon and the maximal\nupdate parameterization (muP) for efficient hyperparameter transfer and present\na simple telescoping algorithm that accounts for all sources of error in muP\nwhile introducing only a modest overhead in resources. We validate our findings\nthrough extensive experiments with model sizes up to four billion parameters\nand ablations on the data distribution and architecture.", "AI": {"tldr": "Muon, a second-order optimizer, outperforms AdamW in compute-time tradeoff and data efficiency at large batch sizes, enabling economical training. Combined with muP, it offers efficient hyperparameter transfer with minimal overhead.", "motivation": "To improve optimization efficiency and data retention at large batch sizes beyond the critical batch size, while maintaining computational efficiency.", "method": "Muon is used as a second-order optimizer, combined with maximal update parameterization (muP) and a telescoping algorithm to account for errors in muP.", "result": "Muon retains data efficiency at large batch sizes and is computationally efficient, validated on models up to four billion parameters.", "conclusion": "Muon expands the Pareto frontier over AdamW, offering a more economical and efficient training solution, especially when combined with muP."}}
{"id": "2505.03368", "pdf": "https://arxiv.org/pdf/2505.03368", "abs": "https://arxiv.org/abs/2505.03368", "authors": ["Stef De Sabbata", "Stefano Mizzaro", "Kevin Roitero"], "title": "Geospatial Mechanistic Interpretability of Large Language Models", "categories": ["cs.LG"], "comment": "Figures 2 and 3: fixed issue with min boundary in colorbar", "summary": "Large Language Models (LLMs) have demonstrated unprecedented capabilities\nacross various natural language processing tasks. Their ability to process and\ngenerate viable text and code has made them ubiquitous in many fields, while\ntheir deployment as knowledge bases and \"reasoning\" tools remains an area of\nongoing research. In geography, a growing body of literature has been focusing\non evaluating LLMs' geographical knowledge and their ability to perform spatial\nreasoning. However, very little is still known about the internal functioning\nof these models, especially about how they process geographical information.\n  In this chapter, we establish a novel framework for the study of geospatial\nmechanistic interpretability - using spatial analysis to reverse engineer how\nLLMs handle geographical information. Our aim is to advance our understanding\nof the internal representations that these complex models generate while\nprocessing geographical information - what one might call \"how LLMs think about\ngeographic information\" if such phrasing was not an undue anthropomorphism.\n  We first outline the use of probing in revealing internal structures within\nLLMs. We then introduce the field of mechanistic interpretability, discussing\nthe superposition hypothesis and the role of sparse autoencoders in\ndisentangling polysemantic internal representations of LLMs into more\ninterpretable, monosemantic features. In our experiments, we use spatial\nautocorrelation to show how features obtained for placenames display spatial\npatterns related to their geographic location and can thus be interpreted\ngeospatially, providing insights into how these models process geographical\ninformation. We conclude by discussing how our framework can help shape the\nstudy and use of foundation models in geography.", "AI": {"tldr": "The paper introduces a framework for studying how LLMs process geographical information using spatial analysis and mechanistic interpretability.", "motivation": "To understand the internal representations of LLMs when handling geographical data, addressing a gap in knowledge about their spatial reasoning.", "method": "Uses probing, mechanistic interpretability, and spatial autocorrelation to analyze LLMs' internal structures and geographical feature representations.", "result": "Features for placenames show spatial patterns, revealing how LLMs process geographical information.", "conclusion": "The framework advances the study of foundation models in geography, offering insights into LLMs' spatial reasoning."}}
{"id": "2505.05082", "pdf": "https://arxiv.org/pdf/2505.05082", "abs": "https://arxiv.org/abs/2505.05082", "authors": ["Sagnik Bhattacharya", "Abhiram Gorle", "Ahmed Mohsin", "Ahsan Bilal", "Connor Ding", "Amit Kumar Singh Yadav", "Tsachy Weissman"], "title": "ItDPDM: Information-Theoretic Discrete Poisson Diffusion Model", "categories": ["cs.LG", "cs.IT", "math.IT", "math.PR"], "comment": "Pre-print", "summary": "Existing methods for generative modeling of discrete data, such as symbolic\nmusic tokens, face two primary challenges: (1) they either embed discrete\ninputs into continuous state-spaces or (2) rely on variational losses that only\napproximate the true negative log-likelihood. Previous efforts have\nindividually targeted these limitations. While information-theoretic Gaussian\ndiffusion models alleviate the suboptimality of variational losses, they still\nperform modeling in continuous domains. In this work, we introduce the\nInformation-Theoretic Discrete Poisson Diffusion Model (ItDPDM), which\nsimultaneously addresses both limitations by directly operating in a discrete\nstate-space via a Poisson diffusion process inspired by photon arrival\nprocesses in camera sensors. We introduce a novel Poisson Reconstruction Loss\n(PRL) and derive an exact relationship between PRL and the true negative\nlog-likelihood, thereby eliminating the need for approximate evidence lower\nbounds. Experiments conducted on the Lakh MIDI symbolic music dataset and the\nCIFAR-10 image benchmark demonstrate that ItDPDM delivers significant\nimprovements, reducing test NLL by up to 80% compared to prior baselines, while\nalso achieving faster convergence.", "AI": {"tldr": "ItDPDM introduces a discrete Poisson diffusion model for generative modeling, addressing limitations of existing methods by operating directly in discrete state-spaces and using a novel Poisson Reconstruction Loss.", "motivation": "Existing methods for discrete data modeling either use continuous embeddings or approximate losses, leading to suboptimal performance. ItDPDM aims to overcome these issues.", "method": "ItDPDM uses a Poisson diffusion process in discrete state-spaces and introduces a Poisson Reconstruction Loss (PRL) with an exact relationship to true negative log-likelihood.", "result": "Experiments on Lakh MIDI and CIFAR-10 show ItDPDM reduces test NLL by up to 80% and achieves faster convergence.", "conclusion": "ItDPDM effectively addresses limitations of prior methods, offering improved performance and efficiency in generative modeling of discrete data."}}
{"id": "2505.05950", "pdf": "https://arxiv.org/pdf/2505.05950", "abs": "https://arxiv.org/abs/2505.05950", "authors": ["Yuxin Zhou", "Zheng Li", "Jun Zhang", "Jue Wang", "Yiping Wang", "Zhongle Xie", "Ke Chen", "Lidan Shou"], "title": "FloE: On-the-Fly MoE Inference on Memory-constrained GPU", "categories": ["cs.LG"], "comment": "Accepted by ICML 2025", "summary": "With the widespread adoption of Mixture-of-Experts (MoE) models, there is a\ngrowing demand for efficient inference on memory-constrained devices. While\noffloading expert parameters to CPU memory and loading activated experts on\ndemand has emerged as a potential solution, the large size of activated experts\noverburdens the limited PCIe bandwidth, hindering the effectiveness in\nlatency-sensitive scenarios. To mitigate this, we propose FloE, an on-the-fly\nMoE inference system on memory-constrained GPUs. FloE is built on the insight\nthat there exists substantial untapped redundancy within sparsely activated\nexperts. It employs various compression techniques on the expert's internal\nparameter matrices to reduce the data movement load, combined with low-cost\nsparse prediction, achieving perceptible inference acceleration in wall-clock\ntime on resource-constrained devices. Empirically, FloE achieves a 9.3x\ncompression of parameters per expert in Mixtral-8x7B; enables deployment on a\nGPU with only 11GB VRAM, reducing the memory footprint by up to 8.5x; and\ndelivers a 48.7x inference speedup compared to DeepSpeed-MII on a single\nGeForce RTX 3090 - all with only a 4.4$\\%$ - 7.6$\\%$ average performance\ndegradation.", "AI": {"tldr": "FloE is an efficient MoE inference system for memory-constrained GPUs, reducing data movement and enabling faster inference with minimal performance loss.", "motivation": "Address the inefficiency of offloading expert parameters to CPU memory due to PCIe bandwidth limitations in latency-sensitive scenarios.", "method": "Uses compression techniques on expert parameter matrices and low-cost sparse prediction to reduce data movement.", "result": "Achieves 9.3x parameter compression, 8.5x memory reduction, and 48.7x speedup on a GeForce RTX 3090 with minimal performance degradation.", "conclusion": "FloE effectively balances efficiency and performance for MoE inference on resource-constrained devices."}}
{"id": "2009.09822", "pdf": "https://arxiv.org/pdf/2009.09822", "abs": "https://arxiv.org/abs/2009.09822", "authors": ["Kwei-Herng Lai", "Daochen Zha", "Guanchu Wang", "Junjie Xu", "Yue Zhao", "Devesh Kumar", "Yile Chen", "Purav Zumkhawaka", "Mingyang Wan", "Diego Martinez", "Xia Hu"], "title": "TODS: An Automated Time Series Outlier Detection System", "categories": ["cs.DB", "cs.LG", "stat.ML"], "comment": "Accepted by AAAI'21 demo track", "summary": "We present TODS, an automated Time Series Outlier Detection System for\nresearch and industrial applications. TODS is a highly modular system that\nsupports easy pipeline construction. The basic building block of TODS is\nprimitive, which is an implementation of a function with hyperparameters. TODS\ncurrently supports 70 primitives, including data processing, time series\nprocessing, feature analysis, detection algorithms, and a reinforcement module.\nUsers can freely construct a pipeline using these primitives and perform end-\nto-end outlier detection with the constructed pipeline. TODS provides a\nGraphical User Interface (GUI), where users can flexibly design a pipeline with\ndrag-and-drop. Moreover, a data-driven searcher is provided to automatically\ndiscover the most suitable pipelines given a dataset. TODS is released under\nApache 2.0 license at https://github.com/datamllab/tods.", "AI": {"tldr": "TODS is a modular system for automated time series outlier detection, offering 70 primitives for pipeline construction, a GUI for drag-and-drop design, and a data-driven searcher for optimal pipeline discovery.", "motivation": "To provide a flexible and automated solution for time series outlier detection in research and industry, supporting easy pipeline construction and customization.", "method": "Uses primitives (modular functions) for pipeline construction, includes a GUI for manual design, and a data-driven searcher for automatic pipeline discovery.", "result": "Supports end-to-end outlier detection with customizable pipelines and offers 70 primitives for diverse functionalities.", "conclusion": "TODS is a versatile, open-source tool for time series outlier detection, catering to both manual and automated pipeline needs."}}
{"id": "2306.14851", "pdf": "https://arxiv.org/pdf/2306.14851", "abs": "https://arxiv.org/abs/2306.14851", "authors": ["Ryan Cory-Wright", "Andr\u00e9s G\u00f3mez"], "title": "Optimal Cross-Validation for Sparse Linear Regression", "categories": ["math.OC", "cs.LG", "stat.ME"], "comment": "Moved stability-adjustment content to a different paper, as it was a\n  separate idea to the main point of the paper", "summary": "Given a high-dimensional covariate matrix and a response vector,\nridge-regularized sparse linear regression selects a subset of features that\nexplains the relationship between covariates and the response in an\ninterpretable manner. To select the sparsity and robustness of linear\nregressors, techniques like k-fold cross-validation are commonly used for\nhyperparameter tuning. However, cross-validation substantially increases the\ncomputational cost of sparse regression as it requires solving many\nmixed-integer optimization problems (MIOs) for each hyperparameter combination.\nTo improve upon this state of affairs, we obtain computationally tractable\nrelaxations of k-fold cross-validation metrics, facilitating hyperparameter\nselection after solving 50-80% fewer MIOs in practice. These relaxations result\nin an efficient cyclic coordinate descent scheme, achieving 10%-30% lower\nvalidation errors than via traditional methods such as grid search with MCP or\nGLMNet across a suite of 13 real-world datasets.", "AI": {"tldr": "The paper proposes computationally efficient relaxations for k-fold cross-validation in ridge-regularized sparse linear regression, reducing the number of mixed-integer optimizations (MIOs) by 50-80% and achieving lower validation errors.", "motivation": "Traditional hyperparameter tuning methods like k-fold cross-validation are computationally expensive due to solving many MIOs. The paper aims to reduce this cost while maintaining accuracy.", "method": "The authors introduce tractable relaxations of k-fold cross-validation metrics, enabling fewer MIOs. They use a cyclic coordinate descent scheme for efficiency.", "result": "The method reduces MIOs by 50-80% and achieves 10%-30% lower validation errors compared to traditional grid search with MCP or GLMNet on 13 real-world datasets.", "conclusion": "The proposed relaxations significantly improve computational efficiency and accuracy in hyperparameter tuning for sparse linear regression."}}
{"id": "2401.02890", "pdf": "https://arxiv.org/pdf/2401.02890", "abs": "https://arxiv.org/abs/2401.02890", "authors": ["Zhongjie Shi", "Jun Fan", "Linhao Song", "Ding-Xuan Zhou", "Johan A. K. Suykens"], "title": "Nonlinear functional regression by functional deep neural network with kernel embedding", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Recently, deep learning has been widely applied in functional data analysis\n(FDA) with notable empirical success. However, the infinite dimensionality of\nfunctional data necessitates an effective dimension reduction approach for\nfunctional learning tasks, particularly in nonlinear functional regression. In\nthis paper, we introduce a functional deep neural network with an adaptive and\ndiscretization-invariant dimension reduction method. Our functional network\narchitecture consists of three parts: first, a kernel embedding step that\nfeatures an integral transformation with an adaptive smooth kernel; next, a\nprojection step that utilizes eigenfunction bases based on a projection Mercer\nkernel for the dimension reduction; and finally, a deep ReLU neural network is\nemployed for the prediction. Explicit rates of approximating nonlinear smooth\nfunctionals across various input function spaces by our proposed functional\nnetwork are derived. Additionally, we conduct a generalization analysis for the\nempirical risk minimization (ERM) algorithm applied to our functional net, by\nemploying a novel two-stage oracle inequality and the established functional\napproximation results. Ultimately, we conduct numerical experiments on both\nsimulated and real datasets to demonstrate the effectiveness and benefits of\nour functional net.", "AI": {"tldr": "A functional deep neural network with adaptive dimension reduction for nonlinear functional regression, achieving strong approximation and generalization performance.", "motivation": "Address the challenge of infinite dimensionality in functional data for nonlinear learning tasks by proposing an effective dimension reduction method.", "method": "Three-step architecture: kernel embedding, projection using eigenfunction bases, and deep ReLU neural network for prediction.", "result": "Derived explicit approximation rates and conducted generalization analysis; demonstrated effectiveness on simulated and real datasets.", "conclusion": "The proposed functional network is effective for nonlinear functional regression, with theoretical and empirical support."}}
{"id": "2401.13231", "pdf": "https://arxiv.org/pdf/2401.13231", "abs": "https://arxiv.org/abs/2401.13231", "authors": ["Suning Huang", "Boyuan Chen", "Huazhe Xu", "Vincent Sitzmann"], "title": "DittoGym: Learning to Control Soft Shape-Shifting Robots", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Robot co-design, where the morphology of a robot is optimized jointly with a\nlearned policy to solve a specific task, is an emerging area of research. It\nholds particular promise for soft robots, which are amenable to novel\nmanufacturing techniques that can realize learned morphologies and actuators.\nInspired by nature and recent novel robot designs, we propose to go a step\nfurther and explore the novel reconfigurable robots, defined as robots that can\nchange their morphology within their lifetime. We formalize control of\nreconfigurable soft robots as a high-dimensional reinforcement learning (RL)\nproblem. We unify morphology change, locomotion, and environment interaction in\nthe same action space, and introduce an appropriate, coarse-to-fine curriculum\nthat enables us to discover policies that accomplish fine-grained control of\nthe resulting robots. We also introduce DittoGym, a comprehensive RL benchmark\nfor reconfigurable soft robots that require fine-grained morphology changes to\naccomplish the tasks. Finally, we evaluate our proposed coarse-to-fine\nalgorithm on DittoGym and demonstrate robots that learn to change their\nmorphology several times within a sequence, uniquely enabled by our RL\nalgorithm. More results are available at\nhttps://suninghuang19.github.io/dittogym_page/.", "AI": {"tldr": "The paper explores reconfigurable soft robots, optimizing morphology and policy jointly via reinforcement learning, and introduces DittoGym as a benchmark.", "motivation": "To advance robot co-design by enabling robots to change morphology within their lifetime, inspired by nature and novel designs.", "method": "Formalizes control as a high-dimensional RL problem, unifying morphology change, locomotion, and interaction in one action space, with a coarse-to-fine curriculum.", "result": "Demonstrates robots learning to change morphology multiple times in a sequence, enabled by the proposed RL algorithm.", "conclusion": "The approach and DittoGym benchmark enable fine-grained control of reconfigurable soft robots, showcasing practical applications."}}
{"id": "2403.02051", "pdf": "https://arxiv.org/pdf/2403.02051", "abs": "https://arxiv.org/abs/2403.02051", "authors": ["Umut \u015eim\u015fekli", "Mert G\u00fcrb\u00fczbalaban", "Sinan Y\u0131ld\u0131r\u0131m", "Lingjiong Zhu"], "title": "Privacy of SGD under Gaussian or Heavy-Tailed Noise: Guarantees without Gradient Clipping", "categories": ["stat.ML", "cs.CR", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "The injection of heavy-tailed noise into the iterates of stochastic gradient\ndescent (SGD) has garnered growing interest in recent years due to its\ntheoretical and empirical benefits for optimization and generalization.\nHowever, its implications for privacy preservation remain largely unexplored.\nAiming to bridge this gap, we provide differential privacy (DP) guarantees for\nnoisy SGD, when the injected noise follows an $\\alpha$-stable distribution,\nwhich includes a spectrum of heavy-tailed distributions (with infinite\nvariance) as well as the light-tailed Gaussian distribution. Considering the\n$(\\epsilon, \\delta)$-DP framework, we show that SGD with heavy-tailed\nperturbations achieves $(0, O(1/n))$-DP for a broad class of loss functions\nwhich can be non-convex, where $n$ is the number of data points. As a\nremarkable byproduct, contrary to prior work that necessitates bounded\nsensitivity for the gradients or clipping the iterates, our theory can handle\nunbounded gradients without clipping, and reveals that under mild assumptions,\nsuch a projection step is not actually necessary. Our results suggest that,\ngiven other benefits of heavy-tails in optimization, heavy-tailed noising\nschemes can be a viable alternative to their light-tailed counterparts.", "AI": {"tldr": "Heavy-tailed noise in SGD improves optimization and generalization, and this paper explores its differential privacy (DP) guarantees, showing it achieves (0, O(1/n))-DP without gradient clipping.", "motivation": "To bridge the gap in understanding the privacy implications of heavy-tailed noise in SGD, especially since prior work lacks exploration of this aspect.", "method": "Analyzes SGD with \u03b1-stable (heavy-tailed) noise, proving DP guarantees for non-convex loss functions without requiring bounded gradients or clipping.", "result": "SGD with heavy-tailed noise achieves (0, O(1/n))-DP, handling unbounded gradients and eliminating the need for projection steps under mild assumptions.", "conclusion": "Heavy-tailed noise in SGD is a viable alternative to light-tailed noise, offering privacy benefits alongside optimization advantages."}}
{"id": "2403.10266", "pdf": "https://arxiv.org/pdf/2403.10266", "abs": "https://arxiv.org/abs/2403.10266", "authors": ["Xuanlei Zhao", "Shenggan Cheng", "Chang Chen", "Zangwei Zheng", "Ziming Liu", "Zheming Yang", "Yang You"], "title": "DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers", "categories": ["cs.DC", "cs.LG"], "comment": "ICML 2025", "summary": "Scaling multi-dimensional transformers to long sequences is indispensable\nacross various domains. However, the challenges of large memory requirements\nand slow speeds of such sequences necessitate sequence parallelism. All\nexisting approaches fall under the category of embedded sequence parallelism,\nwhich are limited to shard along a single sequence dimension, thereby\nintroducing significant communication overhead. However, the nature of\nmulti-dimensional transformers involves independent calculations across\nmultiple sequence dimensions. To this end, we propose Dynamic Sequence\nParallelism (DSP) as a novel abstraction of sequence parallelism. DSP\ndynamically switches the parallel dimension among all sequences according to\nthe computation stage with efficient resharding strategy. DSP offers\nsignificant reductions in communication costs, adaptability across modules, and\nease of implementation with minimal constraints. Experimental evaluations\ndemonstrate DSP's superiority over state-of-the-art embedded sequence\nparallelism methods by remarkable throughput improvements ranging from 32.2% to\n10x, with less than 25% communication volume.", "AI": {"tldr": "Proposes Dynamic Sequence Parallelism (DSP) to reduce communication overhead in multi-dimensional transformers by dynamically switching parallel dimensions.", "motivation": "Existing sequence parallelism methods are limited to sharding along a single dimension, causing high communication costs. Multi-dimensional transformers require independent calculations across multiple dimensions.", "method": "Introduces DSP, which dynamically switches parallel dimensions during computation stages with efficient resharding.", "result": "DSP reduces communication volume by over 75% and improves throughput by 32.2% to 10x compared to existing methods.", "conclusion": "DSP is a superior, adaptable, and easy-to-implement solution for scaling multi-dimensional transformers efficiently."}}
{"id": "2403.11522", "pdf": "https://arxiv.org/pdf/2403.11522", "abs": "https://arxiv.org/abs/2403.11522", "authors": ["Massinissa Merouani", "Khaled Afif Boudaoud", "Iheb Nassim Aouadj", "Nassim Tchoulak", "Islem Kara Bernou", "Hamza Benyamina", "Fatima Benbouzid-Si Tayeb", "Karima Benatchba", "Hugh Leather", "Riyadh Baghdadi"], "title": "LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers", "categories": ["cs.PL", "cs.DC", "cs.LG"], "comment": null, "summary": "While polyhedral compilers have shown success in implementing advanced code\ntransformations, they still face challenges in selecting the ones that lead to\nthe most profitable speedups. This has motivated the use of machine learning\nbased cost models to guide the search for polyhedral optimizations.\nState-of-the-art polyhedral compilers have demonstrated a viable\nproof-of-concept of such an approach. While promising, this approach still\nfaces significant limitations. State-of-the-art polyhedral compilers that use a\ndeep learning cost model only support a small subset of affine transformations,\nlimiting their ability to explore complex code transformations. Furthermore,\ntheir applicability does not scale beyond simple programs, thus excluding many\nprogram classes from their scope, such as those with non-rectangular iteration\ndomains or multiple loop nests. These limitations significantly impact the\ngenerality of such compilers and autoschedulers and put into question the whole\napproach. In this paper, we introduce LOOPer, the first polyhedral\nautoscheduler that uses a deep learning based cost model and covers a large\nspace of affine transformations and programs. LOOPer allows the optimization of\nan extensive set of programs while being effective at applying complex\nsequences of polyhedral transformations. We implement and evaluate LOOPer and\nshow that it achieves competitive speedups over the state-of-the-art. On the\nPolyBench benchmarks, LOOPer achieves a geometric mean speedup of 1.84x over\nTiramisu and 1.42x over Pluto, two state-of-the-art polyhedral autoschedulers.", "AI": {"tldr": "LOOPer is a polyhedral autoscheduler using deep learning to optimize code transformations, outperforming state-of-the-art compilers like Tiramisu and Pluto.", "motivation": "Existing polyhedral compilers with deep learning cost models are limited in transformation support and program applicability, hindering their generality.", "method": "LOOPer employs a deep learning-based cost model to explore a wide range of affine transformations and programs, enabling complex optimizations.", "result": "LOOPer achieves geometric mean speedups of 1.84x over Tiramisu and 1.42x over Pluto on PolyBench benchmarks.", "conclusion": "LOOPer demonstrates the feasibility of scalable and general deep learning-based polyhedral optimization, outperforming current solutions."}}
{"id": "2403.12338", "pdf": "https://arxiv.org/pdf/2403.12338", "abs": "https://arxiv.org/abs/2403.12338", "authors": ["Mario Bravo", "Juan Pablo Contreras"], "title": "Stochastic Halpern iteration in normed spaces and applications to reinforcement learning", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": "New version after reviews. Updated literature for MDPs and\n  application to the weakly communicating average case", "summary": "We analyze the oracle complexity of the stochastic Halpern iteration with\nminibatch, where we aim to approximate fixed-points of nonexpansive and\ncontractive operators in a normed finite-dimensional space. We show that if the\nunderlying stochastic oracle has uniformly bounded variance, our method\nexhibits an overall oracle complexity of $\\tilde{O}(\\varepsilon^{-5})$, to\nobtain $\\varepsilon$ expected fixed-point residual for nonexpansive operators,\nimproving recent rates established for the stochastic Krasnoselskii-Mann\niteration. Also, we establish a lower bound of $\\Omega(\\varepsilon^{-3})$ which\napplies to a wide range of algorithms, including all averaged iterations even\nwith minibatching. Using a suitable modification of our approach, we derive a\n$O(\\varepsilon^{-2}(1-\\gamma)^{-3})$ complexity bound in the case in which the\noperator is a $\\gamma$-contraction to obtain an approximation of the\nfixed-point. As an application, we propose new model-free algorithms for\naverage and discounted reward MDPs. For the average reward case, our method\napplies to weakly communicating MDPs without requiring prior parameter\nknowledge.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2405.12783", "pdf": "https://arxiv.org/pdf/2405.12783", "abs": "https://arxiv.org/abs/2405.12783", "authors": ["Tian Qin", "Wei-Min Huang"], "title": "On Kernel-based Variational Autoencoder", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this paper, we bridge Variational Autoencoders (VAEs) and kernel density\nestimations (KDEs) by approximating the posterior by KDEs and deriving an upper\nbound of the Kullback-Leibler (KL) divergence in the evidence lower bound\n(ELBO). The flexibility of KDEs makes the optimization of posteriors in VAEs\npossible, which not only addresses the limitations of Gaussian latent space in\nvanilla VAE but also provides a new perspective of estimating the KL-divergence\nin ELBO. Under appropriate conditions, we show that the Epanechnikov kernel is\nthe optimal choice in minimizing the derived upper bound of KL-divergence\nasymptotically. Compared with Gaussian kernel, Epanechnikov kernel has compact\nsupport which should make the generated sample less noisy and blurry. The\nimplementation of Epanechnikov kernel in ELBO is straightforward as it lies in\nthe \"location-scale\" family of distributions where the reparametrization tricks\ncan be directly employed. A series of experiments on benchmark datasets such as\nMNIST, Fashion-MNIST, CIFAR-10 and CelebA further demonstrate the superiority\nof Epanechnikov Variational Autoenocoder (EVAE) over vanilla VAE in the quality\nof reconstructed images, as measured by the FID score and Sharpness.", "AI": {"tldr": "The paper bridges VAEs and KDEs by approximating the posterior with KDEs, optimizing posteriors, and deriving an upper bound for KL divergence in ELBO. The Epanechnikov kernel is shown to be optimal, improving sample quality.", "motivation": "To address the limitations of Gaussian latent space in VAEs and provide a new perspective for KL-divergence estimation in ELBO.", "method": "Approximates the posterior with KDEs, derives an upper bound for KL divergence, and uses the Epanechnikov kernel for optimization.", "result": "Epanechnikov kernel outperforms Gaussian kernel, reducing noise and blur in generated samples, as validated on benchmark datasets.", "conclusion": "EVAE (Epanechnikov Variational Autoencoder) demonstrates superior performance over vanilla VAE in image reconstruction quality."}}
{"id": "2406.00183", "pdf": "https://arxiv.org/pdf/2406.00183", "abs": "https://arxiv.org/abs/2406.00183", "authors": ["Sebastien R\u00f6cken", "Anton F. Burnet", "Julija Zavadlav"], "title": "Predicting solvation free energies with an implicit solvent machine learning potential", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Machine learning (ML) potentials are a powerful tool in molecular modeling,\nenabling ab initio accuracy for comparably small computational costs.\nNevertheless, all-atom simulations employing best-performing graph neural\nnetwork architectures are still too expensive for applications requiring\nextensive sampling, such as free energy computations. Implicit solvent models\ncould provide the necessary speed-up due to reduced degrees of freedom and\nfaster dynamics. Here, we introduce a Solvation Free Energy Path Reweighting\n(ReSolv) framework to parametrize an implicit solvent ML potential for small\norganic molecules that accurately predicts the hydration free energy, an\nessential parameter in drug design and pollutant modeling. With a combination\nof top-down (experimental hydration free energy data) and bottom-up (ab initio\ndata of molecules in a vacuum) learning, ReSolv bypasses the need for\nintractable ab initio data of molecules in explicit bulk solvent and does not\nhave to resort to less accurate data-generating models. On the FreeSolv\ndataset, ReSolv achieves a mean absolute error close to average experimental\nuncertainty, significantly outperforming standard explicit solvent force\nfields. Compared to the explicit solvent ML potential, ReSolv offers a\ncomputational speedup of four orders of magnitude and attains closer agreement\nwith experiments. The presented framework paves the way toward deep molecular\nmodels that are more accurate yet computationally cheaper than classical\natomistic models.", "AI": {"tldr": "ReSolv introduces an implicit solvent ML potential for small organic molecules, achieving high accuracy in hydration free energy predictions with significant computational speedup.", "motivation": "Overcome the computational expense of explicit solvent ML potentials for extensive sampling tasks like free energy computations.", "method": "Combines top-down (experimental data) and bottom-up (ab initio vacuum data) learning to parametrize an implicit solvent ML potential.", "result": "Achieves mean absolute error close to experimental uncertainty, outperforms explicit solvent force fields, and offers 4x speedup.", "conclusion": "ReSolv enables more accurate and computationally efficient molecular models than classical approaches."}}
{"id": "2406.00920", "pdf": "https://arxiv.org/pdf/2406.00920", "abs": "https://arxiv.org/abs/2406.00920", "authors": ["Kyurae Kim", "Joohwan Ko", "Yi-An Ma", "Jacob R. Gardner"], "title": "Demystifying SGD with Doubly Stochastic Gradients", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": "Accepted to ICML'24; v2: fixed typo in complexity statements", "summary": "Optimization objectives in the form of a sum of intractable expectations are\nrising in importance (e.g., diffusion models, variational autoencoders, and\nmany more), a setting also known as \"finite sum with infinite data.\" For these\nproblems, a popular strategy is to employ SGD with doubly stochastic gradients\n(doubly SGD): the expectations are estimated using the gradient estimator of\neach component, while the sum is estimated by subsampling over these\nestimators. Despite its popularity, little is known about the convergence\nproperties of doubly SGD, except under strong assumptions such as bounded\nvariance. In this work, we establish the convergence of doubly SGD with\nindependent minibatching and random reshuffling under general conditions, which\nencompasses dependent component gradient estimators. In particular, for\ndependent estimators, our analysis allows fined-grained analysis of the effect\ncorrelations. As a result, under a per-iteration computational budget of $b\n\\times m$, where $b$ is the minibatch size and $m$ is the number of Monte Carlo\nsamples, our analysis suggests where one should invest most of the budget in\ngeneral. Furthermore, we prove that random reshuffling (RR) improves the\ncomplexity dependence on the subsampling noise.", "AI": {"tldr": "The paper analyzes the convergence of doubly SGD for optimization problems with intractable expectations, focusing on dependent gradient estimators and the impact of random reshuffling.", "motivation": "Address the lack of theoretical understanding of doubly SGD's convergence, especially for dependent gradient estimators, in problems like diffusion models and variational autoencoders.", "method": "Analyze doubly SGD with independent minibatching and random reshuffling under general conditions, including dependent component gradient estimators.", "result": "Convergence is established, with insights on budget allocation (minibatch size vs. Monte Carlo samples) and improved complexity under random reshuffling.", "conclusion": "Doubly SGD converges under broader conditions, and random reshuffling enhances performance by reducing subsampling noise."}}
{"id": "2406.03562", "pdf": "https://arxiv.org/pdf/2406.03562", "abs": "https://arxiv.org/abs/2406.03562", "authors": ["Max Hirsch", "Federico Pichi", "Jan S. Hesthaven"], "title": "Neural empirical interpolation method for nonlinear model reduction", "categories": ["math.NA", "cs.LG", "cs.NA", "41A05, 41A46, 65N22, 68T07, 76A15"], "comment": null, "summary": "In this paper, we introduce the neural empirical interpolation method (NEIM),\na neural network-based alternative to the discrete empirical interpolation\nmethod for reducing the time complexity of computing the nonlinear term in a\nreduced order model (ROM) for a parameterized nonlinear partial differential\nequation. NEIM is a greedy algorithm which accomplishes this reduction by\napproximating an affine decomposition of the nonlinear term of the ROM, where\nthe vector terms of the expansion are given by neural networks depending on the\nROM solution, and the coefficients are given by an interpolation of some\n\"optimal\" coefficients. Because NEIM is based on a greedy strategy, we are able\nto provide a basic error analysis to investigate its performance. NEIM has the\nadvantages of being easy to implement in models with automatic differentiation,\nof being a nonlinear projection of the ROM nonlinearity, of being efficient for\nboth nonlocal and local nonlinearities, and of relying solely on data and not\nthe explicit form of the ROM nonlinearity. We demonstrate the effectiveness of\nthe methodology on solution-dependent and solution-independent nonlinearities,\na nonlinear elliptic problem, and a nonlinear parabolic model of liquid\ncrystals.\n  Code availability: https://github.com/maxhirsch/NEIM", "AI": {"tldr": "NEIM is a neural network-based method for reducing the time complexity of nonlinear terms in reduced order models (ROMs) for PDEs. It uses a greedy algorithm and neural networks for approximation, offering ease of implementation and efficiency.", "motivation": "To address the computational complexity of nonlinear terms in ROMs for parameterized PDEs, NEIM provides a data-driven, neural network-based alternative to traditional methods.", "method": "NEIM employs a greedy algorithm to approximate an affine decomposition of the ROM's nonlinear term, using neural networks for vector terms and interpolated coefficients.", "result": "NEIM is effective for both local and nonlocal nonlinearities, demonstrated on various PDE problems, including nonlinear elliptic and parabolic models.", "conclusion": "NEIM is a versatile, efficient, and easy-to-implement method for reducing nonlinear term complexity in ROMs, validated by successful applications."}}
{"id": "2406.09567", "pdf": "https://arxiv.org/pdf/2406.09567", "abs": "https://arxiv.org/abs/2406.09567", "authors": ["Carlos Fern\u00e1ndez-Lor\u00eda", "Yanfang Hou", "Foster Provost", "Jennifer Hill"], "title": "Causal Post-Processing of Predictive Models", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Decision makers across various domains rely on predictive models to guide\nindividual-level intervention decisions. However, these models are typically\ntrained to predict outcomes rather than causal effects, leading to\nmisalignments when they are used for causal decision making. Experimental data\nto train effective causal effect models often is limited. To address this\nissue, we propose causal post-processing (CPP), a family of techniques for\nrefining predictive scores to better align with causal effects using limited\nexperimental data. Rather than training separate causal models for each\nintervention, causal post-processing can adapt existing predictive scores to\nsupport different decision-making requirements, such as estimating effect\nsizes, ranking individuals by expected effects, or classifying individuals\nbased on an intervention threshold. We introduce three main CPP approaches --\nmonotonic post-processing, correction post-processing, and model-based\npost-processing -- each balancing statistical efficiency and flexibility\ndifferently. Through simulations and an empirical application in advertising,\nwe demonstrate that causal post-processing improves intervention decisions,\nparticularly in settings where experimental data is expensive or difficult to\nobtain at scale. Our findings highlight the advantages of integrating\nnon-causal predictive models with experimental data, rather than treating them\nas competing alternatives, which provides a scalable and data-efficient\napproach to causal inference for decision making.", "AI": {"tldr": "The paper proposes causal post-processing (CPP) to refine predictive models for causal decision-making using limited experimental data, improving intervention decisions.", "motivation": "Predictive models often misalign with causal decision-making due to being trained for outcomes, not effects. Limited experimental data exacerbates this issue.", "method": "Introduces three CPP approaches: monotonic, correction, and model-based post-processing, balancing efficiency and flexibility.", "result": "CPP improves intervention decisions, especially where experimental data is scarce, as shown in simulations and advertising applications.", "conclusion": "Integrating predictive models with experimental data offers a scalable, efficient approach to causal inference for decision-making."}}
{"id": "2406.16834", "pdf": "https://arxiv.org/pdf/2406.16834", "abs": "https://arxiv.org/abs/2406.16834", "authors": ["Jeremiah Birrell"], "title": "Statistical Error Bounds for GANs with Nonlinear Objective Functionals", "categories": ["stat.ML", "cs.LG"], "comment": "29 pages", "summary": "Generative adversarial networks (GANs) are unsupervised learning methods for\ntraining a generator distribution to produce samples that approximate those\ndrawn from a target distribution. Many such methods can be formulated as\nminimization of a metric or divergence between probability distributions.\nRecent works have derived statistical error bounds for GANs that are based on\nintegral probability metrics (IPMs), e.g., WGAN which is based on the\n1-Wasserstein metric. In general, IPMs are defined by optimizing a linear\nfunctional (difference of expectations) over a space of discriminators. A much\nlarger class of GANs, which we here call $(f,\\Gamma)$-GANs, can be constructed\nusing $f$-divergences (e.g., Jensen-Shannon, KL, or $\\alpha$-divergences)\ntogether with a regularizing discriminator space $\\Gamma$ (e.g., $1$-Lipschitz\nfunctions). These GANs have nonlinear objective functions, depending on the\nchoice of $f$, and have been shown to exhibit improved performance in a number\nof applications. In this work we derive statistical error bounds for\n$(f,\\Gamma)$-GANs for general classes of $f$ and $\\Gamma$ in the form of\nfinite-sample concentration inequalities. These results prove the statistical\nconsistency of $(f,\\Gamma)$-GANs and reduce to the known results for IPM-GANs\nin the appropriate limit. Our results use novel Rademacher complexity bounds\nwhich provide new insight into the performance of IPM-GANs for distributions\nwith unbounded support and have application to statistical learning tasks\nbeyond GANs.", "AI": {"tldr": "The paper derives statistical error bounds for $(f,\\Gamma)$-GANs, a broader class of GANs using $f$-divergences and regularized discriminators, proving their consistency and linking them to IPM-GANs.", "motivation": "To extend statistical error bounds and consistency proofs from IPM-based GANs to the more general $(f,\\Gamma)$-GANs, which perform better in many applications.", "method": "The authors use finite-sample concentration inequalities and novel Rademacher complexity bounds to analyze $(f,\\Gamma)$-GANs for general $f$ and $\\Gamma$.", "result": "The derived bounds prove the statistical consistency of $(f,\\Gamma)$-GANs and generalize known results for IPM-GANs.", "conclusion": "The work provides theoretical foundations for $(f,\\Gamma)$-GANs and insights into their performance, with broader applications in statistical learning."}}
{"id": "2407.21407", "pdf": "https://arxiv.org/pdf/2407.21407", "abs": "https://arxiv.org/abs/2407.21407", "authors": ["Su I Iao", "Yidong Zhou", "Hans-Georg M\u00fcller"], "title": "Deep Fr\u00e9chet Regression", "categories": ["stat.ME", "cs.LG"], "comment": "74 pages, 6 figures, 9 tables", "summary": "Advancements in modern science have led to the increasing availability of\nnon-Euclidean data in metric spaces. This paper addresses the challenge of\nmodeling relationships between non-Euclidean responses and multivariate\nEuclidean predictors. We propose a flexible regression model capable of\nhandling high-dimensional predictors without imposing parametric assumptions.\nTwo primary challenges are addressed: the curse of dimensionality in\nnonparametric regression and the absence of linear structure in general metric\nspaces. The former is tackled using deep neural networks, while for the latter\nwe demonstrate the feasibility of mapping the metric space where responses\nreside to a low-dimensional Euclidean space using manifold learning. We\nintroduce a reverse mapping approach, employing local Fr\\'echet regression, to\nmap the low-dimensional manifold representations back to objects in the\noriginal metric space. We develop a theoretical framework, investigating the\nconvergence rate of deep neural networks under dependent sub-Gaussian noise\nwith bias. The convergence rate of the proposed regression model is then\nobtained by expanding the scope of local Fr\\'echet regression to accommodate\nmultivariate predictors in the presence of errors in predictors. Simulations\nand case studies show that the proposed model outperforms existing methods for\nnon-Euclidean responses, focusing on the special cases of probability\ndistributions and networks.", "AI": {"tldr": "The paper proposes a flexible regression model for non-Euclidean responses using deep neural networks and manifold learning, addressing dimensionality and lack of linear structure. It outperforms existing methods in simulations.", "motivation": "To model relationships between non-Euclidean responses and multivariate Euclidean predictors, overcoming challenges like dimensionality and lack of linear structure.", "method": "Combines deep neural networks for dimensionality reduction and manifold learning for mapping responses to Euclidean space, with a reverse mapping via local Fr\u00e9chet regression.", "result": "The model shows superior performance in simulations and case studies, especially for probability distributions and networks.", "conclusion": "The proposed framework effectively handles non-Euclidean responses, offering theoretical guarantees and practical advantages over existing methods."}}
{"id": "2408.06003", "pdf": "https://arxiv.org/pdf/2408.06003", "abs": "https://arxiv.org/abs/2408.06003", "authors": ["Zhiwen Mo", "Lei Wang", "Jianyu Wei", "Zhichen Zeng", "Shijie Cao", "Lingxiao Ma", "Naifeng Jing", "Ting Cao", "Jilong Xue", "Fan Yang", "Mao Yang"], "title": "LUT Tensor Core: A Software-Hardware Co-Design for LUT-Based Low-Bit LLM Inference", "categories": ["cs.AR", "cs.LG", "C.1.0; C.3; B.2.4"], "comment": "Conference Version (ISCA'25)", "summary": "As large language model (LLM) inference continues to demand increasing\ncomputational resources, there is a rapidly growing trend toward using low-bit\nweights to reduce memory footprint and improve inference efficiency. However,\nlow-bit LLMs introduce the need for mixed-precision general matrix\nmultiplication (mpGEMM), which involves multiplying low-precision weights with\nhigher-precision activations - a critical yet under-explored operation. Current\nhardware lacks native support for mpGEMM, leading to inefficient\ndequantization-based implementations.\n  To address this, we explore a lookup table (LUT)-based approach to accelerate\nmpGEMM. While conventional LUT implementations fall short in performance and\nflexibility, we propose LUT Tensor Core, a software-hardware co-designed\nsolution optimized for low-bit LLM inference. On the software side, we\nintroduce operator fusion and table symmetrization techniques to optimize LUT\ngeneration and storage. On the hardware side, LUT Tensor Core adopts an\nelongated tiling shape to maximize table reuse and employs a bit-serial\narchitecture to flexibly support a variety of precision combinations.\nAdditionally, we design an end-to-end compilation stack with custom\ninstructions to enable efficient code generation and optimization for LUT-based\nmpGEMM. Experimental results on low-bit LLMs such as BitNet and LLaMA\ndemonstrate that LUT Tensor Core delivers over an order-of-magnitude\nimprovement in both compute density and energy efficiency.", "AI": {"tldr": "The paper proposes LUT Tensor Core, a software-hardware co-designed solution to accelerate mixed-precision GEMM for low-bit LLMs, improving compute density and energy efficiency.", "motivation": "Low-bit LLMs require efficient mixed-precision GEMM, but current hardware lacks native support, leading to inefficiencies.", "method": "A LUT-based approach with software optimizations (operator fusion, table symmetrization) and hardware design (elongated tiling, bit-serial architecture) is introduced.", "result": "LUT Tensor Core achieves over an order-of-magnitude improvement in compute density and energy efficiency for low-bit LLMs like BitNet and LLaMA.", "conclusion": "The proposed solution effectively addresses the inefficiencies in mixed-precision GEMM for low-bit LLMs, offering significant performance gains."}}
{"id": "2408.06258", "pdf": "https://arxiv.org/pdf/2408.06258", "abs": "https://arxiv.org/abs/2408.06258", "authors": ["Oliver Wei\u00dfl", "Amr Abdellatif", "Xingcheng Chen", "Giorgi Merabishvili", "Vincenzo Riccio", "Severin Kacianka", "Andrea Stocco"], "title": "Targeted Deep Learning System Boundary Testing", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Evaluating the behavioral boundaries of deep learning (DL) systems is crucial\nfor understanding their reliability across diverse, unseen inputs. Existing\nsolutions fall short as they rely on untargeted random, model- or latent-based\nperturbations, due to difficulties in generating controlled input variations.\nIn this work, we introduce Mimicry, a novel black-box test generator for\nfine-grained, targeted exploration of DL system boundaries. Mimicry performs\nboundary testing by leveraging the probabilistic nature of DL outputs to\nidentify promising directions for exploration. It uses style-based GANs to\ndisentangle input representations into content and style components, enabling\ncontrolled feature mixing to approximate the decision boundary. We evaluated\nMimicry's effectiveness in generating boundary inputs for five widely used DL\nimage classification systems of increasing complexity, comparing it to two\nbaseline approaches. Our results show that Mimicry consistently identifies\ninputs closer to the decision boundary. It generates semantically meaningful\nboundary test cases that reveal new functional (mis)behaviors, while the\nbaselines produce mainly corrupted or invalid inputs. Thanks to its enhanced\ncontrol over latent space manipulations, Mimicry remains effective as dataset\ncomplexity increases, maintaining competitive diversity and higher validity\nrates, confirmed by human assessors.", "AI": {"tldr": "Mimicry is a black-box test generator for DL systems, using style-based GANs to explore decision boundaries effectively, outperforming baselines in generating meaningful boundary test cases.", "motivation": "Existing methods for evaluating DL systems rely on untargeted perturbations, lacking control over input variations. Mimicry addresses this gap.", "method": "Mimicry leverages DL outputs' probabilistic nature and style-based GANs to disentangle input representations, enabling controlled feature mixing for boundary testing.", "result": "Mimicry generates semantically meaningful boundary test cases, revealing new behaviors, and outperforms baselines in validity and diversity.", "conclusion": "Mimicry provides enhanced control over latent space manipulations, remaining effective with increasing dataset complexity."}}
{"id": "2409.02684", "pdf": "https://arxiv.org/pdf/2409.02684", "abs": "https://arxiv.org/abs/2409.02684", "authors": ["Roxana Zeraati", "Anna Levina", "Jakob H. Macke", "Richard Gao"], "title": "Neural timescales from a computational perspective", "categories": ["q-bio.NC", "cs.LG", "stat.ML"], "comment": "21 pages, 5 figures, 3 boxes, 1 table", "summary": "Neural activity fluctuates over a wide range of timescales within and across\nbrain areas. Experimental observations suggest that diverse neural timescales\nreflect information in dynamic environments. However, how timescales are\ndefined and measured from brain recordings vary across the literature.\nMoreover, these observations do not specify the mechanisms underlying timescale\nvariations, nor whether specific timescales are necessary for neural\ncomputation and brain function. Here, we synthesize three directions where\ncomputational approaches can distill the broad set of empirical observations\ninto quantitative and testable theories: We review (i) how different data\nanalysis methods quantify timescales across distinct behavioral states and\nrecording modalities, (ii) how biophysical models provide mechanistic\nexplanations for the emergence of diverse timescales, and (iii) how\ntask-performing networks and machine learning models uncover the functional\nrelevance of neural timescales. This integrative computational perspective thus\ncomplements experimental investigations, providing a holistic view on how\nneural timescales reflect the relationship between brain structure, dynamics,\nand behavior.", "AI": {"tldr": "The paper synthesizes computational approaches to understand neural timescales, covering measurement methods, biophysical mechanisms, and functional relevance.", "motivation": "To address the lack of consensus on defining and measuring neural timescales and their functional roles in brain dynamics and computation.", "method": "Reviews three computational directions: data analysis methods for timescale quantification, biophysical models for mechanistic explanations, and task-performing networks/machine learning for functional relevance.", "result": "Provides a framework to unify empirical observations into testable theories, linking neural timescales to brain structure, dynamics, and behavior.", "conclusion": "Computational approaches complement experiments, offering a holistic understanding of neural timescales and their significance in brain function."}}
{"id": "2409.08282", "pdf": "https://arxiv.org/pdf/2409.08282", "abs": "https://arxiv.org/abs/2409.08282", "authors": ["Peng Zhu", "Yuante Li", "Yifan Hu", "Qinyuan Liu", "Dawei Cheng", "Yuqi Liang"], "title": "LSR-IGRU: Stock Trend Prediction Based on Long Short-Term Relationships and Improved GRU", "categories": ["q-fin.ST", "cs.CE", "cs.LG"], "comment": null, "summary": "Stock price prediction is a challenging problem in the field of finance and\nreceives widespread attention. In recent years, with the rapid development of\ntechnologies such as deep learning and graph neural networks, more research\nmethods have begun to focus on exploring the interrelationships between stocks.\nHowever, existing methods mostly focus on the short-term dynamic relationships\nof stocks and directly integrating relationship information with temporal\ninformation. They often overlook the complex nonlinear dynamic characteristics\nand potential higher-order interaction relationships among stocks in the stock\nmarket. Therefore, we propose a stock price trend prediction model named\nLSR-IGRU in this paper, which is based on long short-term stock relationships\nand an improved GRU input. Firstly, we construct a long short-term relationship\nmatrix between stocks, where secondary industry information is employed for the\nfirst time to capture long-term relationships of stocks, and overnight price\ninformation is utilized to establish short-term relationships. Next, we improve\nthe inputs of the GRU model at each step, enabling the model to more\neffectively integrate temporal information and long short-term relationship\ninformation, thereby significantly improving the accuracy of predicting stock\ntrend changes. Finally, through extensive experiments on multiple datasets from\nstock markets in China and the United States, we validate the superiority of\nthe proposed LSR-IGRU model over the current state-of-the-art baseline models.\nWe also apply the proposed model to the algorithmic trading system of a\nfinancial company, achieving significantly higher cumulative portfolio returns\ncompared to other baseline methods. Our sources are released at\nhttps://github.com/ZP1481616577/Baselines_LSR-IGRU.", "AI": {"tldr": "The paper introduces LSR-IGRU, a stock price prediction model combining long short-term stock relationships and improved GRU inputs, outperforming existing methods.", "motivation": "Existing methods overlook complex nonlinear dynamics and higher-order interactions in stock relationships, focusing only on short-term dynamics.", "method": "Constructs long short-term relationship matrices using secondary industry and overnight price data, and enhances GRU inputs to integrate temporal and relationship information.", "result": "LSR-IGRU outperforms state-of-the-art models on Chinese and U.S. stock datasets and improves algorithmic trading returns.", "conclusion": "LSR-IGRU effectively captures stock relationships and improves prediction accuracy, demonstrating practical value in trading systems."}}
{"id": "2410.13800", "pdf": "https://arxiv.org/pdf/2410.13800", "abs": "https://arxiv.org/abs/2410.13800", "authors": ["Abhijith Jayakumar", "Andrey Y. Lokhov", "Sidhant Misra", "Marc Vuffray"], "title": "Discrete distributions are learnable from metastable samples", "categories": ["stat.ML", "cond-mat.stat-mech", "cs.LG"], "comment": "Submitted version, 31 pages", "summary": "Physically motivated stochastic dynamics are often used to sample from\nhigh-dimensional distributions. However such dynamics often get stuck in\nspecific regions of their state space and mix very slowly to the desired\nstationary state. This causes such systems to approximately sample from a\nmetastable distribution which is usually quite different from the desired,\nstationary distribution of the dynamic. We rigorously show that, in the case of\nmulti-variable discrete distributions, the true model describing the stationary\ndistribution can be recovered from samples produced from a metastable\ndistribution under minimal assumptions about the system. This follows from a\nfundamental observation that the single-variable conditionals of metastable\ndistributions that satisfy a strong metastability condition are on average\nclose to those of the stationary distribution. This holds even when the\nmetastable distribution differs considerably from the true model in terms of\nglobal metrics like Kullback-Leibler divergence or total variation distance.\nThis property allows us to learn the true model using a conditional likelihood\nbased estimator, even when the samples come from a metastable distribution\nconcentrated in a small region of the state space. Explicit examples of such\nmetastable states can be constructed from regions that effectively bottleneck\nthe probability flow and cause poor mixing of the Markov chain. For specific\ncases of binary pairwise undirected graphical models (i.e. Ising models), we\nextend our results to further rigorously show that data coming from metastable\nstates can be used to learn the parameters of the energy function and recover\nthe structure of the model.", "AI": {"tldr": "The paper shows that the true stationary distribution can be recovered from metastable samples in multi-variable discrete distributions, even when metastable distributions differ significantly globally.", "motivation": "Addressing the challenge of slow mixing in stochastic dynamics, which leads to sampling from metastable distributions instead of the desired stationary one.", "method": "Uses a conditional likelihood-based estimator to recover the true model from metastable samples, leveraging the closeness of single-variable conditionals.", "result": "Demonstrates that true model parameters and structure can be learned from metastable samples, even in cases like Ising models.", "conclusion": "Metastable distributions, despite poor global metrics, retain useful local information for recovering the true stationary distribution."}}
{"id": "2410.16314", "pdf": "https://arxiv.org/pdf/2410.16314", "abs": "https://arxiv.org/abs/2410.16314", "authors": ["Joris Postmus", "Steven Abreu"], "title": "Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering", "categories": ["cs.NE", "cs.LG"], "comment": "Presented at the MINT workshop at NeurIPS 2024. v4: fix sign in\n  equation 10", "summary": "Large language models have transformed AI, yet reliably controlling their\noutputs remains a challenge. This paper explores activation engineering, where\noutputs of pre-trained LLMs are controlled by manipulating their activations at\ninference time. Unlike traditional methods using a single steering vector, we\nintroduce conceptors - mathematical constructs that represent sets of\nactivation vectors as ellipsoidal regions. Conceptors act as soft projection\nmatrices and offer more precise control over complex activation patterns. Our\nexperiments demonstrate that conceptors outperform traditional methods across\nmultiple steering tasks. We further use Boolean operations on conceptors for\ncombined steering goals that empirically outperform additively combining\nsteering vectors on a set of tasks. These results highlight conceptors as a\npromising tool for more effective steering of LLMs. Our code is available on\ngithub.com/jorispos/conceptorsteering.", "AI": {"tldr": "The paper introduces 'conceptors' for precise control of LLM outputs by manipulating activations, outperforming traditional methods.", "motivation": "To address the challenge of reliably controlling outputs of large language models (LLMs).", "method": "Uses conceptors, mathematical constructs representing activation vectors as ellipsoidal regions, for soft projection and precise control.", "result": "Conceptors outperform traditional steering methods and enable combined goals via Boolean operations.", "conclusion": "Conceptors are a promising tool for effective LLM steering, with code available for further use."}}
{"id": "2410.21419", "pdf": "https://arxiv.org/pdf/2410.21419", "abs": "https://arxiv.org/abs/2410.21419", "authors": ["Chris Cama\u00f1o", "Daniel Huang"], "title": "High-Dimensional Gaussian Process Regression with Soft Kernel Interpolation", "categories": ["stat.ML", "cs.LG"], "comment": "12 pages", "summary": "We introduce Soft Kernel Interpolation (SoftKI), a method that combines\naspects of Structured Kernel Interpolation (SKI) and variational inducing point\nmethods, to achieve scalable Gaussian Process (GP) regression on\nhigh-dimensional datasets. SoftKI approximates a kernel via softmax\ninterpolation from a smaller number of interpolation points learned by\noptimizing a combination of the SoftKI marginal log-likelihood (MLL), and when\nneeded, an approximate MLL for improved numerical stability. Consequently, it\ncan overcome the dimensionality scaling challenges that SKI faces when\ninterpolating from a dense and static lattice while retaining the flexibility\nof variational methods to adapt inducing points to the dataset. We demonstrate\nthe effectiveness of SoftKI across various examples and show that it is\ncompetitive with other approximated GP methods when the data dimensionality is\nmodest (around 10).", "AI": {"tldr": "Soft Kernel Interpolation (SoftKI) combines SKI and variational methods for scalable GP regression, addressing dimensionality challenges while maintaining flexibility.", "motivation": "To overcome the limitations of SKI in high-dimensional datasets and retain the adaptability of variational methods.", "method": "SoftKI approximates kernels via softmax interpolation from learned points, optimizing a combination of MLL and approximate MLL for stability.", "result": "Effective in modest-dimensional data (around 10), competitive with other GP approximation methods.", "conclusion": "SoftKI offers a scalable and flexible solution for GP regression, balancing dimensionality challenges and adaptability."}}
{"id": "2411.09851", "pdf": "https://arxiv.org/pdf/2411.09851", "abs": "https://arxiv.org/abs/2411.09851", "authors": ["Ho Fung Tsoi", "Dylan Rankin", "Cecile Caillol", "Miles Cranmer", "Sridhara Dasu", "Javier Duarte", "Philip Harris", "Elliot Lipeles", "Vladimir Loncar"], "title": "SymbolFit: Automatic Parametric Modeling with Symbolic Regression", "categories": ["hep-ex", "cs.LG", "physics.data-an"], "comment": "52 pages, 35 figures. Under review. The API can be used\n  out-of-the-box and is available at https://github.com/hftsoi/symbolfit", "summary": "We introduce SymbolFit, a framework that automates parametric modeling by\nusing symbolic regression to perform a machine-search for functions that fit\nthe data while simultaneously providing uncertainty estimates in a single run.\nTraditionally, constructing a parametric model to accurately describe binned\ndata has been a manual and iterative process, requiring an adequate functional\nform to be determined before the fit can be performed. The main challenge\narises when the appropriate functional forms cannot be derived from first\nprinciples, especially when there is no underlying true closed-form function\nfor the distribution. In this work, we develop a framework that automates and\nstreamlines the process by utilizing symbolic regression, a machine learning\ntechnique that explores a vast space of candidate functions without requiring a\npredefined functional form because the functional form itself is treated as a\ntrainable parameter, making the process far more efficient and effortless than\ntraditional regression methods. We demonstrate the framework in high-energy\nphysics experiments at the CERN Large Hadron Collider (LHC) using five real\nproton-proton collision datasets from new physics searches, including\nbackground modeling in resonance searches for high-mass dijet, trijet,\npaired-dijet, diphoton, and dimuon events. We show that our framework can\nflexibly and efficiently generate a wide range of candidate functions that fit\na nontrivial distribution well using a simple fit configuration that varies\nonly by random seed, and that the same fit configuration, which defines a vast\nfunction space, can also be applied to distributions of different shapes,\nwhereas achieving a comparable result with traditional methods would have\nrequired extensive manual effort.", "AI": {"tldr": "SymbolFit automates parametric modeling using symbolic regression, eliminating the need for predefined functional forms and providing uncertainty estimates in one run.", "motivation": "Traditional parametric modeling is manual and iterative, especially challenging when functional forms aren't derivable from first principles.", "method": "SymbolFit uses symbolic regression to explore candidate functions without predefined forms, treating the functional form as trainable.", "result": "Demonstrated in high-energy physics at CERN LHC, it efficiently fits diverse datasets with minimal configuration.", "conclusion": "SymbolFit streamlines modeling, outperforming traditional methods in flexibility and efficiency."}}
{"id": "2411.18825", "pdf": "https://arxiv.org/pdf/2411.18825", "abs": "https://arxiv.org/abs/2411.18825", "authors": ["Letian Chen", "Nina Moorman", "Matthew Gombolay"], "title": "ELEMENTAL: Interactive Learning from Demonstrations and Vision-Language Models for Reward Design in Robotics", "categories": ["cs.RO", "cs.LG"], "comment": "ICML 2025", "summary": "Reinforcement learning (RL) has demonstrated compelling performance in\nrobotic tasks, but its success often hinges on the design of complex, ad hoc\nreward functions. Researchers have explored how Large Language Models (LLMs)\ncould enable non-expert users to specify reward functions more easily. However,\nLLMs struggle to balance the importance of different features, generalize\npoorly to out-of-distribution robotic tasks, and cannot represent the problem\nproperly with only text-based descriptions. To address these challenges, we\npropose ELEMENTAL (intEractive LEarning froM dEmoNstraTion And Language), a\nnovel framework that combines natural language guidance with visual user\ndemonstrations to align robot behavior with user intentions better. By\nincorporating visual inputs, ELEMENTAL overcomes the limitations of text-only\ntask specifications, while leveraging inverse reinforcement learning (IRL) to\nbalance feature weights and match the demonstrated behaviors optimally.\nELEMENTAL also introduces an iterative feedback-loop through self-reflection to\nimprove feature, reward, and policy learning. Our experiment results\ndemonstrate that ELEMENTAL outperforms prior work by 42.3% on task success, and\nachieves 41.3% better generalization in out-of-distribution tasks, highlighting\nits robustness in LfD.", "AI": {"tldr": "ELEMENTAL combines natural language and visual demonstrations to improve RL reward function design, outperforming prior methods by 42.3% in task success.", "motivation": "Current RL methods rely on complex, ad hoc reward functions, and LLMs struggle with feature balancing and generalization in robotic tasks.", "method": "ELEMENTAL integrates natural language guidance with visual demonstrations, uses IRL for feature balancing, and employs an iterative feedback-loop for improvement.", "result": "ELEMENTAL achieves 42.3% higher task success and 41.3% better generalization in out-of-distribution tasks.", "conclusion": "ELEMENTAL effectively aligns robot behavior with user intentions, overcoming text-only limitations and improving robustness in learning from demonstrations."}}
{"id": "2412.10161", "pdf": "https://arxiv.org/pdf/2412.10161", "abs": "https://arxiv.org/abs/2412.10161", "authors": ["Simon Wein", "Marco Riebel", "Lisa-Marie Brunner", "Caroline Nothdurfter", "Rainer Rupprecht", "Jens V. Schwarzbach"], "title": "Data Integration with Fusion Searchlight: Classifying Brain States from Resting-state fMRI", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Resting-state fMRI captures spontaneous neural activity characterized by\ncomplex spatiotemporal dynamics. Various metrics, such as local and global\nbrain connectivity and low-frequency amplitude fluctuations, quantify distinct\naspects of these dynamics. However, these measures are typically analyzed\nindependently, overlooking their interrelations and potentially limiting\nanalytical sensitivity. Here, we introduce the Fusion Searchlight (FuSL)\nframework, which integrates complementary information from multiple\nresting-state fMRI metrics. We demonstrate that combining these metrics\nenhances the accuracy of pharmacological treatment prediction from rs-fMRI\ndata, enabling the identification of additional brain regions affected by\nsedation with alprazolam. Furthermore, we leverage explainable AI to delineate\nthe differential contributions of each metric, which additionally improves\nspatial specificity of the searchlight analysis. Moreover, this framework can\nbe adapted to combine information across imaging modalities or experimental\nconditions, providing a versatile and interpretable tool for data fusion in\nneuroimaging.", "AI": {"tldr": "The paper introduces the Fusion Searchlight (FuSL) framework to integrate multiple resting-state fMRI metrics, improving prediction accuracy and spatial specificity for pharmacological effects.", "motivation": "Current resting-state fMRI analyses treat metrics independently, missing interrelations and limiting sensitivity.", "method": "The FuSL framework combines multiple fMRI metrics and uses explainable AI to analyze their contributions.", "result": "FuSL enhances prediction accuracy for pharmacological effects and identifies additional brain regions affected by sedation.", "conclusion": "FuSL is a versatile, interpretable tool for integrating neuroimaging data across metrics or modalities."}}
{"id": "2412.15826", "pdf": "https://arxiv.org/pdf/2412.15826", "abs": "https://arxiv.org/abs/2412.15826", "authors": ["Joshua B. Moore", "Hugo P. Stackhouse", "Ben D. Fulcher", "Sahand Mahmoodian"], "title": "Using matrix-product states for time-series machine learning", "categories": ["stat.ML", "cs.LG", "quant-ph"], "comment": "31 pages, 14 figures", "summary": "Matrix-product states (MPS) have proven to be a versatile ansatz for modeling\nquantum many-body physics. For many applications, and particularly in\none-dimension, they capture relevant quantum correlations in many-body\nwavefunctions while remaining tractable to store and manipulate on a classical\ncomputer. This has motivated researchers to also apply the MPS ansatz to\nmachine learning (ML) problems where capturing complex correlations in datasets\nis also a key requirement. Here, we develop and apply an MPS-based algorithm,\nMPSTime, for learning a joint probability distribution underlying an observed\ntime-series dataset, and show how it can be used to tackle important\ntime-series ML problems, including classification and imputation. MPSTime can\nefficiently learn complicated time-series probability distributions directly\nfrom data, requires only moderate maximum MPS bond dimension $\\chi_{\\rm max}$,\nwith values for our applications ranging between $\\chi_{\\rm max} = 20-160$, and\ncan be trained for both classification and imputation tasks under a single\nlogarithmic loss function. Using synthetic and publicly available real-world\ndatasets, spanning applications in medicine, energy, and astronomy, we\ndemonstrate performance competitive with state-of-the-art ML approaches, but\nwith the key advantage of encoding the full joint probability distribution\nlearned from the data, which is useful for analyzing and interpreting its\nunderlying structure. This manuscript is supplemented with the release of a\npublicly available code package MPSTime that implements our approach. The\neffectiveness of the MPS-based ansatz for capturing complex correlation\nstructures in time-series data makes it a powerful foundation for tackling\nchallenging time-series analysis problems across science, industry, and\nmedicine.", "AI": {"tldr": "MPSTime, an MPS-based algorithm, is developed for learning joint probability distributions in time-series data, showing competitive performance in classification and imputation tasks.", "motivation": "To leverage the MPS ansatz's ability to capture complex correlations for time-series machine learning problems.", "method": "Develops MPSTime, an MPS-based algorithm, trained under a single logarithmic loss function for classification and imputation.", "result": "Demonstrates competitive performance on synthetic and real-world datasets, with moderate bond dimensions (20-160).", "conclusion": "MPSTime is effective for time-series analysis, offering interpretability and a publicly available implementation."}}
{"id": "2412.18432", "pdf": "https://arxiv.org/pdf/2412.18432", "abs": "https://arxiv.org/abs/2412.18432", "authors": ["O. Deniz Akyildiz", "Pierre Del Moral", "Joaqu\u00edn Miguez"], "title": "Gaussian entropic optimal transport: Schr\u00f6dinger bridges and the Sinkhorn algorithm", "categories": ["stat.ML", "cs.LG", "math.PR", "stat.CO"], "comment": "80 pages", "summary": "Entropic optimal transport problems are regularized versions of optimal\ntransport problems. These models play an increasingly important role in machine\nlearning and generative modelling. For finite spaces, these problems are\ncommonly solved using Sinkhorn algorithm (a.k.a. iterative proportional fitting\nprocedure). However, in more general settings the Sinkhorn iterations are based\non nonlinear conditional/conjugate transformations and exact finite-dimensional\nsolutions cannot be computed.\n  This article presents a finite-dimensional recursive formulation of the\niterative proportional fitting procedure for general Gaussian multivariate\nmodels. As expected, this recursive formulation is closely related to the\ncelebrated Kalman filter and related Riccati matrix difference equations, and\nit yields algorithms that can be implemented in practical settings without\nfurther approximations. We extend this filtering methodology to develop a\nrefined and self-contained convergence analysis of Gaussian Sinkhorn\nalgorithms, including closed form expressions of entropic transport maps and\nSchr\\\"odinger bridges.", "AI": {"tldr": "The paper presents a finite-dimensional recursive formulation of the Sinkhorn algorithm for Gaussian models, linking it to Kalman filtering and Riccati equations, and provides a convergence analysis for Gaussian Sinkhorn algorithms.", "motivation": "Entropic optimal transport is crucial in machine learning, but existing methods like the Sinkhorn algorithm face limitations in general settings, especially for Gaussian models.", "method": "The authors develop a recursive formulation of the iterative proportional fitting procedure for Gaussian multivariate models, connecting it to Kalman filtering and Riccati equations.", "result": "The approach yields practical algorithms without approximations and provides closed-form expressions for entropic transport maps and Schr\u00f6dinger bridges.", "conclusion": "The recursive formulation and convergence analysis advance the understanding and applicability of Gaussian Sinkhorn algorithms in general settings."}}
{"id": "2502.00017", "pdf": "https://arxiv.org/pdf/2502.00017", "abs": "https://arxiv.org/abs/2502.00017", "authors": ["Ikram Gagaoua", "Armelle Brun", "Anne Boyer"], "title": "A Frugal Model for Accurate Early Student Failure Prediction", "categories": ["cs.CY", "cs.LG"], "comment": "LICE - London International Conference on Education, London\n  International Conference on Education, Nov 2024, London, United Kingdom", "summary": "Predicting student success or failure is vital for timely interventions and\npersonalized support. Early failure prediction is particularly crucial, yet\nlimited data availability in the early stages poses challenges, one of the\npossible solutions is to make use of additional data from other contexts,\nhowever, this might lead to overconsumption with no guarantee of better\nresults. To address this, we propose the Frugal Early Prediction (FEP) model, a\nnew hybrid model that selectively incorporates additional data, promoting data\nfrugality and efficient resource utilization. Experiments conducted on a public\ndataset from a VLE demonstrate FEP's effectiveness in reducing data usage, a\nprimary goal of this research.Experiments showcase a remarkable 27% reduction\nin data consumption, compared to a systematic use of additional data, aligning\nwith our commitment to data frugality and offering substantial benefits to\neducational institutions seeking efficient data consumption. Additionally, FEP\nalso excels in enhancing prediction accuracy. Compared to traditional\napproaches, FEP achieves an average accuracy gain of 7.3%. This not only\nhighlights the practicality and efficiency of FEP but also its superiority in\nperformance, while respecting resource constraints, providing beneficial\nfindings for educational institutions seeking data frugality.", "AI": {"tldr": "The paper proposes the Frugal Early Prediction (FEP) model, a hybrid approach for early student failure prediction that reduces data usage by 27% and improves accuracy by 7.3% compared to traditional methods.", "motivation": "Early prediction of student failure is critical for timely interventions, but limited early-stage data and inefficient use of additional data pose challenges.", "method": "The FEP model selectively incorporates additional data to promote frugality and efficiency.", "result": "FEP reduces data consumption by 27% and increases prediction accuracy by 7.3%.", "conclusion": "FEP is a practical, efficient, and superior solution for early failure prediction, benefiting institutions focused on data frugality."}}
{"id": "2502.02853", "pdf": "https://arxiv.org/pdf/2502.02853", "abs": "https://arxiv.org/abs/2502.02853", "authors": ["Shuanghao Bai", "Wanqi Zhou", "Pengxiang Ding", "Wei Zhao", "Donglin Wang", "Badong Chen"], "title": "Rethinking Latent Redundancy in Behavior Cloning: An Information Bottleneck Approach for Robot Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Behavior Cloning (BC) is a widely adopted visual imitation learning method in\nrobot manipulation. Current BC approaches often enhance generalization by\nleveraging large datasets and incorporating additional visual and textual\nmodalities to capture more diverse information. However, these methods overlook\nwhether the learned representations contain redundant information and lack a\nsolid theoretical foundation to guide the learning process. To address these\nlimitations, we adopt an information-theoretic perspective and introduce mutual\ninformation to quantify and mitigate redundancy in latent representations.\nBuilding on this, we incorporate the Information Bottleneck (IB) principle into\nBC, which extends the idea of reducing redundancy by providing a structured\nframework for compressing irrelevant information while preserving task-relevant\nfeatures. This work presents the first comprehensive study on redundancy in\nlatent representations across various methods, backbones, and experimental\nsettings, while extending the generalizability of the IB to BC. Extensive\nexperiments and analyses on the CortexBench and LIBERO benchmarks demonstrate\nsignificant performance improvements with IB, underscoring the importance of\nreducing input data redundancy and highlighting its practical value for more\npractical applications. Project Page:\nhttps://baishuanghao.github.io/BC-IB.github.io.", "AI": {"tldr": "The paper introduces an information-theoretic approach to reduce redundancy in latent representations for Behavior Cloning (BC), using mutual information and the Information Bottleneck (IB) principle, showing improved performance on benchmarks.", "motivation": "Current BC methods lack theoretical grounding and overlook redundancy in learned representations, limiting their efficiency and generalization.", "method": "The authors use mutual information to quantify redundancy and integrate the IB principle into BC to compress irrelevant information while retaining task-relevant features.", "result": "Experiments on CortexBench and LIBERO benchmarks show significant performance gains with IB, validating the approach.", "conclusion": "Reducing redundancy via IB enhances BC's generalizability and practical applicability, as demonstrated by empirical results."}}
{"id": "2502.08414", "pdf": "https://arxiv.org/pdf/2502.08414", "abs": "https://arxiv.org/abs/2502.08414", "authors": ["Samuel Erickson", "Tobias Ryd\u00e9n"], "title": "Inverse Covariance and Partial Correlation Matrix Estimation via Joint Partial Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present a method for estimating sparse high-dimensional inverse covariance\nand partial correlation matrices, which exploits the connection between the\ninverse covariance matrix and linear regression. The method is a two-stage\nestimation method wherein each individual feature is regressed on all other\nfeatures while positive semi-definiteness is enforced simultaneously. We derive\nnon-asymptotic estimation rates for both inverse covariance and partial\ncorrelation matrix estimation. An efficient proximal splitting algorithm for\nnumerically computing the estimate is also dervied. The effectiveness of the\nproposed method is demonstrated on both synthetic and real-world data.", "AI": {"tldr": "A two-stage method for estimating sparse high-dimensional inverse covariance and partial correlation matrices, leveraging linear regression and enforcing positive semi-definiteness.", "motivation": "To address the challenge of estimating high-dimensional inverse covariance and partial correlation matrices efficiently and accurately.", "method": "A two-stage regression approach where each feature is regressed on others, with simultaneous enforcement of positive semi-definiteness. Includes a proximal splitting algorithm for computation.", "result": "Non-asymptotic estimation rates derived for both inverse covariance and partial correlation matrices. Demonstrated effectiveness on synthetic and real-world data.", "conclusion": "The proposed method is effective for sparse high-dimensional inverse covariance and partial correlation estimation, with practical applicability."}}
{"id": "2503.03656", "pdf": "https://arxiv.org/pdf/2503.03656", "abs": "https://arxiv.org/abs/2503.03656", "authors": ["Tushar Aggarwal", "Swayam Singh", "Abhijeet Awasthi", "Aditya Kanade", "Nagarajan Natarajan"], "title": "Robust Learning of Diverse Code Edits", "categories": ["cs.SE", "cs.LG"], "comment": "To appear in ICML 2025 as 'NextCoder: Robust Adaptation of Code LMs\n  to Diverse Code Edits'", "summary": "Software engineering activities frequently involve edits to existing code.\nHowever, contemporary code language models (LMs) lack the ability to handle\ndiverse types of code-edit requirements. In this work, we attempt to overcome\nthis shortcoming through (1) a novel synthetic data generation pipeline and (2)\na robust model adaptation algorithm. Starting with seed code examples and\ndiverse editing criteria, our pipeline generates high-quality samples\ncomprising original and modified code, along with natural language instructions\nin different styles and verbosity. Today's code LMs come bundled with strong\nabilities, such as code generation and instruction following, which should not\nbe lost due to fine-tuning. To ensure this, we propose a novel adaptation\nalgorithm, SeleKT, that (a) leverages a dense gradient-based step to identify\nthe weights that are most important for code editing, and (b) does a sparse\nprojection onto the base model to avoid overfitting. Using our approach, we\nobtain a new series of models NextCoder (adapted from QwenCoder-2.5) that\nachieves strong results on five code-editing benchmarks, outperforming\ncomparable size models and even several larger ones. We show the generality of\nour approach on two model families (DeepSeekCoder and QwenCoder), compare\nagainst other fine-tuning approaches, and demonstrate robustness by showing\nretention of code generation and general problem-solving abilities post\nadaptation. We opensource the models, synthetic dataset, and implementation at\nhttps://aka.ms/nextcoder.", "AI": {"tldr": "The paper introduces NextCoder, a code-editing model, using synthetic data generation and a novel adaptation algorithm (SeleKT) to improve code-editing tasks without losing existing capabilities.", "motivation": "Contemporary code language models struggle with diverse code-edit requirements, prompting the need for a solution that retains their strong abilities while adapting to editing tasks.", "method": "A synthetic data generation pipeline creates high-quality samples, and the SeleKT algorithm identifies important weights for editing while avoiding overfitting.", "result": "NextCoder outperforms comparable models on five benchmarks and retains general abilities post-adaptation.", "conclusion": "The approach is robust, generalizable, and effective, with models, data, and implementation made publicly available."}}
{"id": "2503.09085", "pdf": "https://arxiv.org/pdf/2503.09085", "abs": "https://arxiv.org/abs/2503.09085", "authors": ["Ryan K. Krueger", "Sharon Aviran", "David H. Mathews", "Jeffrey Zuber", "Max Ward"], "title": "Differentiable Folding for Nearest Neighbor Model Optimization", "categories": ["q-bio.BM", "cs.LG", "q-bio.QM"], "comment": null, "summary": "The Nearest Neighbor model is the $\\textit{de facto}$ thermodynamic model of\nRNA secondary structure formation and is a cornerstone of RNA structure\nprediction and sequence design. The current functional form (Turner 2004)\ncontains $\\approx13,000$ underlying thermodynamic parameters, and fitting these\nto both experimental and structural data is computationally challenging. Here,\nwe leverage recent advances in $\\textit{differentiable folding}$, a method for\ndirectly computing gradients of the RNA folding algorithms, to devise an\nefficient, scalable, and flexible means of parameter optimization that uses\nknown RNA structures and thermodynamic experiments. Our method yields a\nsignificantly improved parameter set that outperforms existing baselines on all\nmetrics, including an increase in the average predicted probability of\nground-truth sequence-structure pairs for a single RNA family by over 23 orders\nof magnitude. Our framework provides a path towards drastically improved RNA\nmodels, enabling the flexible incorporation of new experimental data,\ndefinition of novel loss terms, large training sets, and even treatment as a\nmodule in larger deep learning pipelines. We make available a new database,\nRNAometer, with experimentally-determined stabilities for small RNA model\nsystems.", "AI": {"tldr": "The paper introduces a scalable method for optimizing RNA thermodynamic parameters using differentiable folding, significantly improving prediction accuracy.", "motivation": "Current RNA thermodynamic models rely on a large number of parameters, making optimization computationally challenging.", "method": "Leverages differentiable folding to compute gradients of RNA folding algorithms, enabling efficient parameter optimization using known structures and experiments.", "result": "Produces a parameter set that outperforms baselines, improving prediction accuracy by over 23 orders of magnitude for some cases.", "conclusion": "The framework enables flexible model improvement and integration with deep learning, supported by a new database, RNAometer."}}
{"id": "2503.12533", "pdf": "https://arxiv.org/pdf/2503.12533", "abs": "https://arxiv.org/abs/2503.12533", "authors": ["Haoqi Yuan", "Yu Bai", "Yuhui Fu", "Bohan Zhou", "Yicheng Feng", "Xinrun Xu", "Yi Zhan", "B\u00f6rje F. Karlsson", "Zongqing Lu"], "title": "Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Building autonomous robotic agents capable of achieving human-level\nperformance in real-world embodied tasks is an ultimate goal in humanoid robot\nresearch. Recent advances have made significant progress in high-level\ncognition with Foundation Models (FMs) and low-level skill development for\nhumanoid robots. However, directly combining these components often results in\npoor robustness and efficiency due to compounding errors in long-horizon tasks\nand the varied latency of different modules. We introduce Being-0, a\nhierarchical agent framework that integrates an FM with a modular skill\nlibrary. The FM handles high-level cognitive tasks such as instruction\nunderstanding, task planning, and reasoning, while the skill library provides\nstable locomotion and dexterous manipulation for low-level control. To bridge\nthe gap between these levels, we propose a novel Connector module, powered by a\nlightweight vision-language model (VLM). The Connector enhances the FM's\nembodied capabilities by translating language-based plans into actionable skill\ncommands and dynamically coordinating locomotion and manipulation to improve\ntask success. With all components, except the FM, deployable on low-cost\nonboard computation devices, Being-0 achieves efficient, real-time performance\non a full-sized humanoid robot equipped with dexterous hands and active vision.\nExtensive experiments in large indoor environments demonstrate Being-0's\neffectiveness in solving complex, long-horizon tasks that require challenging\nnavigation and manipulation subtasks. For further details and videos, visit\nhttps://beingbeyond.github.io/Being-0.", "AI": {"tldr": "Being-0 is a hierarchical agent framework integrating a Foundation Model (FM) with a modular skill library, enhanced by a Connector module for robust, real-time humanoid robot performance.", "motivation": "To address the poor robustness and efficiency of combining high-level cognition (FM) and low-level skills in humanoid robots, especially in long-horizon tasks.", "method": "Introduces Being-0, which uses an FM for high-level tasks and a skill library for low-level control, bridged by a lightweight VLM-powered Connector module.", "result": "Achieves efficient, real-time performance on a full-sized humanoid robot, solving complex tasks with navigation and manipulation.", "conclusion": "Being-0 demonstrates effectiveness in integrating cognition and skills for robust humanoid robot performance in real-world tasks."}}
{"id": "2503.21526", "pdf": "https://arxiv.org/pdf/2503.21526", "abs": "https://arxiv.org/abs/2503.21526", "authors": ["Christine W. Bang", "Vanessa Didelez"], "title": "Constraint-based causal discovery with tiered background knowledge and latent variables in single or overlapping datasets", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "Accepted for the 4th Conference on Causal Learning and Reasoning\n  (CLeaR 2025). Version 2: Corrected numbering in Example 1", "summary": "In this paper we consider the use of tiered background knowledge within\nconstraint based causal discovery. Our focus is on settings relaxing causal\nsufficiency, i.e. allowing for latent variables which may arise because\nrelevant information could not be measured at all, or not jointly, as in the\ncase of multiple overlapping datasets. We first present novel insights into the\nproperties of the 'tiered FCI' (tFCI) algorithm. Building on this, we introduce\na new extension of the IOD (integrating overlapping datasets) algorithm\nincorporating tiered background knowledge, the 'tiered IOD' (tIOD) algorithm.\nWe show that under full usage of the tiered background knowledge tFCI and tIOD\nare sound, while simple versions of the tIOD and tFCI are sound and complete.\nWe further show that the tIOD algorithm can often be expected to be\nconsiderably more efficient and informative than the IOD algorithm even beyond\nthe obvious restriction of the Markov equivalence classes. We provide a formal\nresult on the conditions for this gain in efficiency and informativeness. Our\nresults are accompanied by a series of examples illustrating the exact role and\nusefulness of tiered background knowledge.", "AI": {"tldr": "The paper explores tiered background knowledge in causal discovery, introducing tFCI and tIOD algorithms, proving their soundness and efficiency.", "motivation": "To address challenges in causal discovery when causal sufficiency is relaxed, particularly with latent variables and overlapping datasets.", "method": "Introduces tiered FCI (tFCI) and extends IOD to tiered IOD (tIOD), analyzing their properties and efficiency.", "result": "tFCI and tIOD are sound under full tiered knowledge; tIOD is more efficient and informative than IOD.", "conclusion": "Tiered background knowledge enhances causal discovery, with tIOD offering significant improvements over IOD."}}
{"id": "2504.10208", "pdf": "https://arxiv.org/pdf/2504.10208", "abs": "https://arxiv.org/abs/2504.10208", "authors": ["Erxue Min", "Hsiu-Yuan Huang", "Min Yang", "Xihong Yang", "Xin Jia", "Yunfang Wu", "Hengyi Cai", "Junfeng Wang", "Shuaiqiang Wang", "Dawei Yin"], "title": "From Prompting to Alignment: A Generative Framework for Query Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "In modern search systems, search engines often suggest relevant queries to\nusers through various panels or components, helping refine their information\nneeds. Traditionally, these recommendations heavily rely on historical search\nlogs to build models, which suffer from cold-start or long-tail issues.\nFurthermore, tasks such as query suggestion, completion or clarification are\nstudied separately by specific design, which lacks generalizability and hinders\nadaptation to novel applications. Despite recent attempts to explore the use of\nLLMs for query recommendation, these methods mainly rely on the inherent\nknowledge of LLMs or external sources like few-shot examples, retrieved\ndocuments, or knowledge bases, neglecting the importance of the calibration and\nalignment with user feedback, thus limiting their practical utility. To address\nthese challenges, we first propose a general Generative Query Recommendation\n(GQR) framework that aligns LLM-based query generation with user preference.\nSpecifically, we unify diverse query recommendation tasks by a universal prompt\nframework, leveraging the instruct-following capability of LLMs for effective\ngeneration. Secondly, we align LLMs with user feedback via presenting a\nCTR-alignment framework, which involves training a query-wise CTR predictor as\na process reward model and employing list-wise preference alignment to maximize\nthe click probability of the generated query list. Furthermore, recognizing the\ninconsistency between LLM knowledge and proactive search intents arising from\nthe separation of user-initiated queries from models, we align LLMs with user\ninitiative via retrieving co-occurrence queries as side information when\nhistorical logs are available.", "AI": {"tldr": "A framework for generative query recommendation (GQR) using LLMs, unified by a prompt framework and aligned with user feedback via CTR-alignment and co-occurrence queries.", "motivation": "Address cold-start, long-tail issues, and lack of generalizability in traditional query recommendation methods by leveraging LLMs and aligning with user preferences.", "method": "Proposes GQR framework: universal prompt for task unification, CTR-alignment for feedback, and co-occurrence queries for intent alignment.", "result": "Improved query recommendation by aligning LLM outputs with user preferences and proactive search intents.", "conclusion": "The GQR framework enhances practical utility of LLMs in query recommendation by addressing alignment and generalizability challenges."}}
{"id": "2504.19657", "pdf": "https://arxiv.org/pdf/2504.19657", "abs": "https://arxiv.org/abs/2504.19657", "authors": ["Shotaro Takasu", "Toshio Aoyagi"], "title": "Neuronal correlations shape the scaling behavior of memory capacity and nonlinear computational capability of recurrent neural networks", "categories": ["cond-mat.dis-nn", "cs.LG", "q-bio.NC"], "comment": "20 pages, 8 figures", "summary": "Reservoir computing is a powerful framework for real-time information\nprocessing, characterized by its high computational ability and quick learning,\nwith applications ranging from machine learning to biological systems. In this\npaper, we demonstrate that the memory capacity of a reservoir recurrent neural\nnetwork scales sublinearly with the number of readout neurons. To elucidate\nthis phenomenon, we develop a theoretical framework for analytically deriving\nmemory capacity, attributing the decaying growth of memory capacity to neuronal\ncorrelations. In addition, numerical simulations reveal that once memory\ncapacity becomes sublinear, increasing the number of readout neurons\nsuccessively enables nonlinear processing at progressively higher polynomial\norders. Furthermore, our theoretical framework suggests that neuronal\ncorrelations govern not only memory capacity but also the sequential growth of\nnonlinear computational capabilities. Our findings establish a foundation for\ndesigning scalable and cost-effective reservoir computing, providing novel\ninsights into the interplay among neuronal correlations, linear memory, and\nnonlinear processing.", "AI": {"tldr": "The paper shows that memory capacity in reservoir computing scales sublinearly with readout neurons, driven by neuronal correlations, and enables nonlinear processing.", "motivation": "To understand how memory capacity scales in reservoir computing and its relationship with neuronal correlations and nonlinear processing.", "method": "Developed a theoretical framework for memory capacity and validated with numerical simulations.", "result": "Memory capacity scales sublinearly with readout neurons, and neuronal correlations also govern nonlinear computational growth.", "conclusion": "Provides insights for designing scalable reservoir computing, linking neuronal correlations, memory, and nonlinear processing."}}
{"id": "2504.20127", "pdf": "https://arxiv.org/pdf/2504.20127", "abs": "https://arxiv.org/abs/2504.20127", "authors": ["Huiyang Hong", "Xinkai Wu", "Hongyu Sun", "Chaoyang Xie", "Qi Wang", "Yuquan Li"], "title": "Learning Hierarchical Interaction for Accurate Molecular Property Prediction", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "Discovering molecules with desirable molecular properties, including ADMET\nprofiles, is of great importance in drug discovery. Existing approaches\ntypically employ deep learning models, such as Graph Neural Networks (GNNs) and\nTransformers, to predict these molecular properties by learning from diverse\nchemical information. However, these models often fail to efficiently capture\nand utilize the hierarchical nature of molecular structures, and often lack\nmechanisms for effective interaction among multi-level features. To address\nthese limitations, we propose a Hierarchical Interaction Message Passing\nMechanism, which serves as the foundation of our novel model, the Hierarchical\nInteraction Message Net (HimNet). Our method enables interaction-aware\nrepresentation learning across atomic, motif, and molecular levels via\nhierarchical attention-guided message passing. This design allows HimNet to\neffectively balance global and local information, ensuring rich and\ntask-relevant feature extraction for downstream property prediction tasks, such\nas Blood-Brain Barrier Permeability (BBBP). We systematically evaluate HimNet\non eleven datasets, including eight widely-used MoleculeNet benchmarks and\nthree challenging, high-value datasets for metabolic stability, malaria\nactivity, and liver microsomal clearance, covering a broad range of\npharmacologically relevant properties. Extensive experiments demonstrate that\nHimNet achieves the best or near-best performance in most molecular property\nprediction tasks. Furthermore, our method exhibits promising hierarchical\ninterpretability, aligning well with chemical intuition on representative\nmolecules. We believe that HimNet offers an accurate and efficient solution for\nmolecular activity and ADMET property prediction, contributing to advanced\ndecision-making in the early stages of drug discovery.", "AI": {"tldr": "The paper introduces HimNet, a Hierarchical Interaction Message Net, to improve molecular property prediction by capturing hierarchical molecular structures and enabling multi-level feature interactions.", "motivation": "Existing deep learning models like GNNs and Transformers often fail to efficiently utilize hierarchical molecular structures or enable effective multi-level feature interactions.", "method": "Proposes a Hierarchical Interaction Message Passing Mechanism, implemented in HimNet, which uses hierarchical attention-guided message passing for interaction-aware representation learning at atomic, motif, and molecular levels.", "result": "HimNet achieves top or near-top performance on eleven datasets, including MoleculeNet benchmarks and high-value datasets for metabolic stability, malaria activity, and liver microsomal clearance.", "conclusion": "HimNet provides an accurate and interpretable solution for molecular property prediction, aiding drug discovery decision-making."}}
{"id": "2504.20395", "pdf": "https://arxiv.org/pdf/2504.20395", "abs": "https://arxiv.org/abs/2504.20395", "authors": ["Tiantian Zhang"], "title": "Partial Answer of How Transformers Learn Automata", "categories": ["cs.FL", "cs.LG"], "comment": null, "summary": "We introduce a novel framework for simulating finite automata using\nrepresentation-theoretic semidirect products and Fourier modules, achieving\nmore efficient Transformer-based implementations.", "AI": {"tldr": "A new framework for simulating finite automata using representation-theoretic semidirect products and Fourier modules, improving Transformer efficiency.", "motivation": "To enhance the efficiency of Transformer-based implementations for finite automata simulations.", "method": "Utilizes representation-theoretic semidirect products and Fourier modules.", "result": "Achieves more efficient Transformer-based implementations.", "conclusion": "The framework successfully improves efficiency in simulating finite automata."}}
{"id": "2505.04886", "pdf": "https://arxiv.org/pdf/2505.04886", "abs": "https://arxiv.org/abs/2505.04886", "authors": ["Mukund Telukunta", "Venkata Sriram Siddhardh Nadendla", "Morgan Stuart", "Casey Canfield"], "title": "Fairness Perceptions in Regression-based Predictive Models", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Regression-based predictive analytics used in modern kidney transplantation\nis known to inherit biases from training data. This leads to social\ndiscrimination and inefficient organ utilization, particularly in the context\nof a few social groups. Despite this concern, there is limited research on\nfairness in regression and its impact on organ utilization and placement. This\npaper introduces three novel divergence-based group fairness notions: (i)\nindependence, (ii) separation, and (iii) sufficiency to assess the fairness of\nregression-based analytics tools. In addition, fairness preferences are\ninvestigated from crowd feedback, in order to identify a socially accepted\ngroup fairness criterion for evaluating these tools. A total of 85 participants\nwere recruited from the Prolific crowdsourcing platform, and a Mixed-Logit\ndiscrete choice model was used to model fairness feedback and estimate social\nfairness preferences. The findings clearly depict a strong preference towards\nthe separation and sufficiency fairness notions, and that the predictive\nanalytics is deemed fair with respect to gender and race groups, but unfair in\nterms of age groups.", "AI": {"tldr": "The paper addresses biases in regression-based predictive analytics for kidney transplantation, proposing three fairness notions and using crowd feedback to identify socially accepted fairness criteria.", "motivation": "To mitigate social discrimination and inefficiencies in organ utilization caused by biased training data in regression models.", "method": "Introduces divergence-based fairness notions (independence, separation, sufficiency) and uses a Mixed-Logit model to analyze crowd feedback from 85 participants.", "result": "Strong preference for separation and sufficiency fairness notions; analytics are fair for gender and race but unfair for age.", "conclusion": "The study highlights the need for fairness-aware regression tools in transplantation, with separation and sufficiency as preferred criteria."}}
{"id": "2505.05713", "pdf": "https://arxiv.org/pdf/2505.05713", "abs": "https://arxiv.org/abs/2505.05713", "authors": ["Jinkun Lin", "Ziheng Jiang", "Zuquan Song", "Sida Zhao", "Menghan Yu", "Zhanghan Wang", "Chenyuan Wang", "Zuocheng Shi", "Xiang Shi", "Wei Jia", "Zherui Liu", "Shuguang Wang", "Haibin Lin", "Xin Liu", "Aurojit Panda", "Jinyang Li"], "title": "Understanding Stragglers in Large Model Training Using What-if Analysis", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Large language model (LLM) training is one of the most demanding distributed\ncomputations today, often requiring thousands of GPUs with frequent\nsynchronization across machines. Such a workload pattern makes it susceptible\nto stragglers, where the training can be stalled by few slow workers. At\nByteDance we find stragglers are not trivially always caused by hardware\nfailures, but can arise from multiple complex factors. This work aims to\npresent a comprehensive study on the straggler issues in LLM training, using a\nfive-month trace collected from our ByteDance LLM training cluster. The core\nmethodology is what-if analysis that simulates the scenario without any\nstragglers and contrasts with the actual case. We use this method to study the\nfollowing questions: (1) how often do stragglers affect training jobs, and what\neffect do they have on job performance; (2) do stragglers exhibit temporal or\nspatial patterns; and (3) what are the potential root causes for stragglers?", "AI": {"tldr": "The paper studies straggler issues in large language model (LLM) training, analyzing their frequency, impact, patterns, and root causes using a five-month trace from ByteDance's cluster.", "motivation": "Stragglers in LLM training, caused by complex factors beyond hardware failures, can stall distributed computations, prompting a need for deeper understanding.", "method": "The study employs what-if analysis on a five-month trace from ByteDance's LLM training cluster to simulate scenarios without stragglers and compare them with actual cases.", "result": "The research addresses the frequency and impact of stragglers, their temporal/spatial patterns, and potential root causes.", "conclusion": "The findings provide insights into straggler behavior in LLM training, aiding in mitigating their effects."}}
