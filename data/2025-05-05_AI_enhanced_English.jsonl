{"id": "2505.00734", "pdf": "https://arxiv.org/pdf/2505.00734", "abs": "https://arxiv.org/abs/2505.00734", "authors": ["Neil Joshi", "Joshua Carney", "Nathanael Kuo", "Homer Li", "Cheng Peng", "Myron Brown"], "title": "Unconstrained Large-scale 3D Reconstruction and Rendering across Altitudes", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Production of photorealistic, navigable 3D site models requires a large\nvolume of carefully collected images that are often unavailable to first\nresponders for disaster relief or law enforcement. Real-world challenges\ninclude limited numbers of images, heterogeneous unposed cameras, inconsistent\nlighting, and extreme viewpoint differences for images collected from varying\naltitudes. To promote research aimed at addressing these challenges, we have\ndeveloped the first public benchmark dataset for 3D reconstruction and novel\nview synthesis based on multiple calibrated ground-level, security-level, and\nairborne cameras. We present datasets that pose real-world challenges,\nindependently evaluate calibration of unposed cameras and quality of novel\nrendered views, demonstrate baseline performance using recent state-of-practice\nmethods, and identify challenges for further research.", "AI": {"tldr": "A benchmark dataset for 3D reconstruction and novel view synthesis is introduced to address challenges like limited images, unposed cameras, and extreme viewpoints, aiding disaster relief and law enforcement.", "motivation": "To enable research on 3D reconstruction and novel view synthesis under real-world constraints (e.g., limited images, unposed cameras, inconsistent lighting) for applications like disaster relief.", "method": "Developed a public benchmark dataset with calibrated ground-level, security-level, and airborne cameras, evaluating calibration and novel view synthesis quality.", "result": "Baseline performance using state-of-practice methods is demonstrated, highlighting challenges for future research.", "conclusion": "The dataset fosters research to overcome real-world challenges in 3D reconstruction and novel view synthesis."}}
{"id": "2505.00739", "pdf": "https://arxiv.org/pdf/2505.00739", "abs": "https://arxiv.org/abs/2505.00739", "authors": ["Qiushi Yang", "Yuan Yao", "Miaomiao Cui", "Liefeng Bo"], "title": "MoSAM: Motion-Guided Segment Anything Model with Spatial-Temporal Memory Selection", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "The recent Segment Anything Model 2 (SAM2) has demonstrated exceptional\ncapabilities in interactive object segmentation for both images and videos.\nHowever, as a foundational model on interactive segmentation, SAM2 performs\nsegmentation directly based on mask memory from the past six frames, leading to\ntwo significant challenges. Firstly, during inference in videos, objects may\ndisappear since SAM2 relies solely on memory without accounting for object\nmotion information, which limits its long-range object tracking capabilities.\nSecondly, its memory is constructed from fixed past frames, making it\nsusceptible to challenges associated with object disappearance or occlusion,\ndue to potentially inaccurate segmentation results in memory. To address these\nproblems, we present MoSAM, incorporating two key strategies to integrate\nobject motion cues into the model and establish more reliable feature memory.\nFirstly, we propose Motion-Guided Prompting (MGP), which represents the object\nmotion in both sparse and dense manners, then injects them into SAM2 through a\nset of motion-guided prompts. MGP enables the model to adjust its focus towards\nthe direction of motion, thereby enhancing the object tracking capabilities.\nFurthermore, acknowledging that past segmentation results may be inaccurate, we\ndevise a Spatial-Temporal Memory Selection (ST-MS) mechanism that dynamically\nidentifies frames likely to contain accurate segmentation in both pixel- and\nframe-level. By eliminating potentially inaccurate mask predictions from\nmemory, we can leverage more reliable memory features to exploit similar\nregions for improving segmentation results. Extensive experiments on various\nbenchmarks of video object segmentation and video instance segmentation\ndemonstrate that our MoSAM achieves state-of-the-art results compared to other\ncompetitors.", "AI": {"tldr": "MoSAM enhances SAM2 by integrating motion cues and reliable memory selection to improve video object segmentation.", "motivation": "SAM2's reliance on fixed past frames and lack of motion information limits its tracking and segmentation accuracy in videos.", "method": "Introduces Motion-Guided Prompting (MGP) for motion cues and Spatial-Temporal Memory Selection (ST-MS) for reliable memory.", "result": "MoSAM achieves state-of-the-art performance in video object and instance segmentation benchmarks.", "conclusion": "MoSAM effectively addresses SAM2's limitations, improving segmentation and tracking in videos."}}
{"id": "2505.00740", "pdf": "https://arxiv.org/pdf/2505.00740", "abs": "https://arxiv.org/abs/2505.00740", "authors": ["Zhengbin Zhang", "Yan Wu", "Hongkun Zhang"], "title": "Fast2comm:Collaborative perception combined with prior knowledge", "categories": ["cs.CV", "cs.MA"], "comment": "8pages,8figures", "summary": "Collaborative perception has the potential to significantly enhance\nperceptual accuracy through the sharing of complementary information among\nagents. However, real-world collaborative perception faces persistent\nchallenges, particularly in balancing perception performance and bandwidth\nlimitations, as well as coping with localization errors. To address these\nchallenges, we propose Fast2comm, a prior knowledge-based collaborative\nperception framework. Specifically, (1)we propose a prior-supervised confidence\nfeature generation method, that effectively distinguishes foreground from\nbackground by producing highly discriminative confidence features; (2)we\npropose GT Bounding Box-based spatial prior feature selection strategy to\nensure that only the most informative prior-knowledge features are selected and\nshared, thereby minimizing background noise and optimizing bandwidth efficiency\nwhile enhancing adaptability to localization inaccuracies; (3)we decouple the\nfeature fusion strategies between model training and testing phases, enabling\ndynamic bandwidth adaptation. To comprehensively validate our framework, we\nconduct extensive experiments on both real-world and simulated datasets. The\nresults demonstrate the superior performance of our model and highlight the\nnecessity of the proposed methods. Our code is available at\nhttps://github.com/Zhangzhengbin-TJ/Fast2comm.", "AI": {"tldr": "Fast2comm is a collaborative perception framework using prior knowledge to balance performance and bandwidth, addressing localization errors.", "motivation": "Real-world collaborative perception struggles with balancing performance, bandwidth, and localization errors.", "method": "Proposes confidence feature generation, spatial prior feature selection, and decoupled feature fusion for dynamic bandwidth adaptation.", "result": "Superior performance validated on real-world and simulated datasets.", "conclusion": "Fast2comm effectively enhances perception accuracy and bandwidth efficiency."}}
{"id": "2505.00741", "pdf": "https://arxiv.org/pdf/2505.00741", "abs": "https://arxiv.org/abs/2505.00741", "authors": ["Srinivas Kanakala", "Sneha Ningappa"], "title": "Detection and Classification of Diseases in Multi-Crop Leaves using LSTM and CNN Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Plant diseases pose a serious challenge to agriculture by reducing crop yield\nand affecting food quality. Early detection and classification of these\ndiseases are essential for minimising losses and improving crop management\npractices. This study applies Convolutional Neural Networks (CNN) and Long\nShort-Term Memory (LSTM) models to classify plant leaf diseases using a dataset\ncontaining 70,295 training images and 17,572 validation images across 38\ndisease classes. The CNN model was trained using the Adam optimiser with a\nlearning rate of 0.0001 and categorical cross-entropy as the loss function.\nAfter 10 training epochs, the model achieved a training accuracy of 99.1% and a\nvalidation accuracy of 96.4%. The LSTM model reached a validation accuracy of\n93.43%. Performance was evaluated using precision, recall, F1-score, and\nconfusion matrix, confirming the reliability of the CNN-based approach. The\nresults suggest that deep learning models, particularly CNN, enable an\neffective solution for accurate and scalable plant disease classification,\nsupporting practical applications in agricultural monitoring.", "AI": {"tldr": "The study uses CNN and LSTM models to classify plant leaf diseases, achieving high accuracy (96.4% for CNN, 93.43% for LSTM), demonstrating their effectiveness for scalable agricultural monitoring.", "motivation": "Early detection of plant diseases is crucial to minimize crop losses and improve management practices.", "method": "CNN and LSTM models were trained on a dataset of 70,295 images (38 disease classes) using Adam optimiser and categorical cross-entropy loss.", "result": "CNN achieved 99.1% training and 96.4% validation accuracy; LSTM reached 93.43% validation accuracy.", "conclusion": "Deep learning, especially CNN, provides an accurate and scalable solution for plant disease classification."}}
{"id": "2505.00725", "pdf": "https://arxiv.org/pdf/2505.00725", "abs": "https://arxiv.org/abs/2505.00725", "authors": ["Bithiah Yuan"], "title": "FinBERT-QA: Financial Question Answering with pre-trained BERT Language Models", "categories": ["cs.CL", "cs.IR", "cs.LG", "I.2.7; I.5.1; H.3.3"], "comment": "Submitted in partial fulfillment of the requirements for the Master\n  of Science degree in Computer Science at the University of Freiburg, July 31,\n  2020", "summary": "Motivated by the emerging demand in the financial industry for the automatic\nanalysis of unstructured and structured data at scale, Question Answering (QA)\nsystems can provide lucrative and competitive advantages to companies by\nfacilitating the decision making of financial advisers. Consequently, we\npropose a novel financial QA system using the transformer-based pre-trained\nBERT language model to address the limitations of data scarcity and language\nspecificity in the financial domain. Our system focuses on financial\nnon-factoid answer selection, which retrieves a set of passage-level texts and\nselects the most relevant as the answer. To increase efficiency, we formulate\nthe answer selection task as a re-ranking problem, in which our system consists\nof an Answer Retriever using BM25, a simple information retrieval approach, to\nfirst return a list of candidate answers, and an Answer Re-ranker built with\nvariants of pre-trained BERT language models to re-rank and select the most\nrelevant answers. We investigate various learning, further pre-training, and\nfine-tuning approaches for BERT. Our experiments suggest that FinBERT-QA, a\nmodel built from applying the Transfer and Adapt further fine-tuning and\npointwise learning approach, is the most effective, improving the\nstate-of-the-art results of task 2 of the FiQA dataset by 16% on MRR, 17% on\nNDCG, and 21% on Precision@1.", "AI": {"tldr": "A novel financial QA system using BERT for non-factoid answer selection, improving state-of-the-art results on the FiQA dataset.", "motivation": "Addressing data scarcity and language specificity in finance by automating unstructured data analysis for decision-making.", "method": "Combines BM25 for answer retrieval and BERT variants for re-ranking, with focus on fine-tuning approaches.", "result": "FinBERT-QA improves MRR by 16%, NDCG by 17%, and Precision@1 by 21% on the FiQA dataset.", "conclusion": "The proposed system effectively enhances financial QA, demonstrating significant performance gains."}}
{"id": "2505.01001", "pdf": "https://arxiv.org/pdf/2505.01001", "abs": "https://arxiv.org/abs/2505.01001", "authors": ["Tessa De La Fuente"], "title": "Photoshop Batch Rendering Using Actions for Stylistic Video Editing", "categories": ["cs.MM", "cs.GR", "cs.HC"], "comment": "11 pages, 12 figures", "summary": "My project looks at an efficient workflow for creative image/video editing\nusing Adobe Photoshop Actions tool and Batch Processing System. This innovative\napproach to video editing through Photoshop creates a fundamental shift to\ncreative workflow management through the integration of industry-leading image\nmanipulation with video editing techniques. Through systematic automation of\nActions, users can achieve a simple and consistent application of visual edits\nacross a string of images. This approach provides an alternative method to\noptimize productivity while ensuring uniform results across image collections\nthrough a post-processing pipeline.", "AI": {"tldr": "An efficient workflow for creative image/video editing using Photoshop Actions and Batch Processing, automating edits for consistency and productivity.", "motivation": "To streamline and enhance creative workflows by integrating Photoshop's image manipulation with video editing techniques.", "method": "Uses Adobe Photoshop Actions tool and Batch Processing System to automate and apply consistent visual edits across multiple images.", "result": "Achieves uniform results and optimizes productivity in post-processing pipelines.", "conclusion": "This approach offers a practical alternative for managing creative workflows efficiently."}}
{"id": "2505.00750", "pdf": "https://arxiv.org/pdf/2505.00750", "abs": "https://arxiv.org/abs/2505.00750", "authors": ["Hyunjin Cho", "Farhad Tabasi", "Jeremy D. Greenlee", "Rahul Singh"], "title": "GVPT -- A software for guided visual pitch tracking", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "GVPT (Guided visual pitch tracking) is a publicly available, real-time pitch\ntracking software designed to guide and evaluate vocal pitch control using\nvisual feedback. Developed for clinical and research applications, the system\npresents various visual target pitch contour and overlays the subject's pitch\nin real-time to promote accurate vocal reproduction. GVPT supports difficulty\nmodification, session logging, and precise pitch tracking. The software enables\nvoice pitch control exercise in both experimental and therapeutic settings.", "AI": {"tldr": "GVPT is real-time pitch-tracking software for vocal training, offering visual feedback, difficulty adjustment, and session logging for clinical and research use.", "motivation": "To aid vocal pitch control in clinical and research settings by providing real-time visual feedback.", "method": "Uses visual target pitch contours and overlays the user's pitch in real-time to guide vocal reproduction.", "result": "Enables precise pitch tracking and supports customizable difficulty and session logging.", "conclusion": "GVPT is a versatile tool for vocal pitch control exercises in therapy and experiments."}}
{"id": "2505.00897", "pdf": "https://arxiv.org/pdf/2505.00897", "abs": "https://arxiv.org/abs/2505.00897", "authors": ["Xinmeng Luan", "Mirco Pezzoli", "Fabio Antonacci", "Augusto Sarti"], "title": "Physics-Informed Neural Network-Driven Sparse Field Discretization Method for Near-Field Acoustic Holography", "categories": ["eess.AS", "eess.SP"], "comment": "12 pages, 7 figures", "summary": "We propose the Physics-Informed Neural Network-driven Sparse Field\nDiscretization method (PINN-SFD), a novel self-supervised, physics-informed\ndeep learning approach for addressing the Near-Field Acoustic Holography (NAH)\nproblem. Unlike existing deep learning methods for NAH, which are predominantly\nsupervised by large datasets, our approach does not require a training phase\nand it is physics-informed. The wave propagation field is discretized into\nsparse regions, a process referred to as field discretization, which includes a\nseries of set of source planes, to address the inverse problem. Our method\nemploys the discretized Kirchhoff-Helmholtz integral as the wave propagation\nmodel. By incorporating virtual planes, additional constraints are enforced\nnear the actual sound source, improving the reconstruction process.\nOptimization is carried out using Physics-Informed Neural Networks (PINNs),\nwhere physics-based constraints are integrated into the loss functions to\naccount for both direct (from equivalent source plane to hologram plane) and\nadditional (from virtual planes to hologram plane) wave propagation paths.\nAdditionally, sparsity is enforced on the velocity of the equivalent sources.\nOur comprehensive validation across various rectangular and violin top plates,\ncovering a wide range of vibrational modes, demonstrates that PINN-SFD\nconsistently outperforms the conventional Compressive-Equivalent Source Method\n(C-ESM), particularly in terms of reconstruction accuracy for complex\nvibrational patterns. Significantly, this method demonstrates reduced\nsensitivity to regularization parameters compared to C-ESM.", "AI": {"tldr": "PINN-SFD is a self-supervised, physics-informed deep learning method for Near-Field Acoustic Holography (NAH) that avoids large datasets and training phases by using sparse field discretization and virtual planes for improved reconstruction.", "motivation": "Existing deep learning methods for NAH rely on large datasets and supervision, which limits their practicality. PINN-SFD aims to overcome this by being self-supervised and physics-informed.", "method": "The method discretizes the wave propagation field into sparse regions, uses the Kirchhoff-Helmholtz integral, and incorporates virtual planes for constraints. Physics-Informed Neural Networks (PINNs) optimize the process with physics-based loss functions and enforce sparsity on source velocities.", "result": "PINN-SFD outperforms the conventional C-ESM in reconstruction accuracy, especially for complex vibrational patterns, and shows reduced sensitivity to regularization parameters.", "conclusion": "PINN-SFD offers a robust, physics-informed alternative to traditional NAH methods, with superior performance and reduced dependency on large datasets."}}
{"id": "2505.00749", "pdf": "https://arxiv.org/pdf/2505.00749", "abs": "https://arxiv.org/abs/2505.00749", "authors": ["Roman J. Georgio", "Caelum Forder", "Suman Deb", "Peter Carroll", "\u00d6nder G\u00fcrcan"], "title": "The Coral Protocol: Open Infrastructure Connecting The Internet of Agents", "categories": ["cs.MA", "cs.AI"], "comment": "31 pages, 3 figures, Whitepaper", "summary": "The Coral Protocol is an open and decentralized collaboration infrastructure\nthat enables communication, coordination, trust and payments for The Internet\nof Agents. It addresses the growing need for interoperability in a world where\norganizations are deploying multiple specialized AI agents that must work\ntogether across domains and vendors. As a foundational platform for multi-agent\nAI ecosystems, Coral establishes a common language and coordination framework\nallowing any agent to participate in complex workflows with others. Its design\nemphasizes broad compatibility, security, and vendor neutrality, ensuring that\nagent interactions are efficient and trustworthy. In particular, Coral\nintroduces standardized messaging formats for agent communication, a modular\ncoordination mechanism for orchestrating multi-agent tasks, and secure team\nformation capabilities for dynamically assembling trusted groups of agents.\nTogether, these innovations position Coral Protocol as a cornerstone of the\nemerging \"Internet of Agents,\" unlocking new levels of automation, collective\nintelligence, and business value through open agent collaboration.", "AI": {"tldr": "The Coral Protocol is a decentralized infrastructure for AI agent collaboration, enabling communication, coordination, trust, and payments in multi-agent ecosystems.", "motivation": "Addresses the need for interoperability among specialized AI agents working across domains and vendors.", "method": "Introduces standardized messaging, modular coordination, and secure team formation for agent collaboration.", "result": "Enables efficient, trustworthy interactions and complex workflows among diverse AI agents.", "conclusion": "Positions Coral as a foundational platform for the 'Internet of Agents,' fostering automation and collective intelligence."}}
{"id": "2505.00733", "pdf": "https://arxiv.org/pdf/2505.00733", "abs": "https://arxiv.org/abs/2505.00733", "authors": ["Gustavo Rezende Silva", "Juliane P\u00e4\u00dfler", "S. Lizeth Tapia Tarifa", "Einar Broch Johnsen", "Carlos Hern\u00e1ndez Corbato"], "title": "ROSA: A Knowledge-based Solution for Robot Self-Adaptation", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Autonomous robots must operate in diverse environments and handle multiple\ntasks despite uncertainties. This creates challenges in designing software\narchitectures and task decision-making algorithms, as different contexts may\nrequire distinct task logic and architectural configurations. To address this,\nrobotic systems can be designed as self-adaptive systems capable of adapting\ntheir task execution and software architecture at runtime based on their\ncontext.This paper introduces ROSA, a novel knowledge-based framework for RObot\nSelf-Adaptation, which enables task-and-architecture co-adaptation (TACA) in\nrobotic systems. ROSA achieves this by providing a knowledge model that\ncaptures all application-specific knowledge required for adaptation and by\nreasoning over this knowledge at runtime to determine when and how adaptation\nshould occur. In addition to a conceptual framework, this work provides an\nopen-source ROS 2-based reference implementation of ROSA and evaluates its\nfeasibility and performance in an underwater robotics application. Experimental\nresults highlight ROSA's advantages in reusability and development effort for\ndesigning self-adaptive robotic systems.", "AI": {"tldr": "ROSA is a knowledge-based framework for robot self-adaptation, enabling task-and-architecture co-adaptation (TACA) in diverse environments. It uses a knowledge model for runtime reasoning and has been implemented in ROS 2, showing benefits in reusability and development effort.", "motivation": "Autonomous robots face challenges in handling diverse tasks and environments due to uncertainties, requiring adaptable software architectures and task logic.", "method": "ROSA provides a knowledge model for adaptation and runtime reasoning to decide when and how to adapt. It includes a ROS 2-based implementation.", "result": "Experimental evaluation in an underwater robotics application demonstrates ROSA's feasibility, reusability, and reduced development effort.", "conclusion": "ROSA effectively enables self-adaptation in robotic systems, addressing challenges of diverse environments and tasks."}}
{"id": "2505.00787", "pdf": "https://arxiv.org/pdf/2505.00787", "abs": "https://arxiv.org/abs/2505.00787", "authors": ["Lucas N. Alegre", "Ana L. C. Bazzan", "Andr\u00e9 Barreto", "Bruno C. da Silva"], "title": "Constructing an Optimal Behavior Basis for the Option Keyboard", "categories": ["cs.LG", "cs.AI", "I.2"], "comment": null, "summary": "Multi-task reinforcement learning aims to quickly identify solutions for new\ntasks with minimal or no additional interaction with the environment.\nGeneralized Policy Improvement (GPI) addresses this by combining a set of base\npolicies to produce a new one that is at least as good -- though not\nnecessarily optimal -- as any individual base policy. Optimality can be\nensured, particularly in the linear-reward case, via techniques that compute a\nConvex Coverage Set (CCS). However, these are computationally expensive and do\nnot scale to complex domains. The Option Keyboard (OK) improves upon GPI by\nproducing policies that are at least as good -- and often better. It achieves\nthis through a learned meta-policy that dynamically combines base policies.\nHowever, its performance critically depends on the choice of base policies.\nThis raises a key question: is there an optimal set of base policies -- an\noptimal behavior basis -- that enables zero-shot identification of optimal\nsolutions for any linear tasks? We solve this open problem by introducing a\nnovel method that efficiently constructs such an optimal behavior basis. We\nshow that it significantly reduces the number of base policies needed to ensure\noptimality in new tasks. We also prove that it is strictly more expressive than\na CCS, enabling particular classes of non-linear tasks to be solved optimally.\nWe empirically evaluate our technique in challenging domains and show that it\noutperforms state-of-the-art approaches, increasingly so as task complexity\nincreases.", "AI": {"tldr": "The paper introduces a method to construct an optimal behavior basis for multi-task reinforcement learning, ensuring zero-shot optimal solutions for linear tasks and outperforming existing approaches.", "motivation": "The motivation is to address the computational expense and scalability issues of current methods like GPI and CCS, and the dependency of OK on base policies, by finding an optimal set of base policies.", "method": "The authors propose a novel method to efficiently construct an optimal behavior basis, reducing the number of base policies needed and ensuring optimality in new tasks.", "result": "The method significantly outperforms state-of-the-art approaches, especially in complex tasks, and is proven more expressive than CCS.", "conclusion": "The introduced optimal behavior basis solves the open problem of zero-shot optimal solutions for linear tasks and extends to some non-linear tasks, demonstrating superior performance empirically."}}
{"id": "2505.00742", "pdf": "https://arxiv.org/pdf/2505.00742", "abs": "https://arxiv.org/abs/2505.00742", "authors": ["Jiaxu Qian", "Chendong Wang", "Yifan Yang", "Chaoyun Zhang", "Huiqiang Jiang", "Xufang Luo", "Yu Kang", "Qingwei Lin", "Anlan Zhang", "Shiqi Jiang", "Ting Cao", "Tianjun Mao", "Suman Banerjee", "Guyue Liu", "Saravan Rajmohan", "Dongmei Zhang", "Yuqing Yang", "Qi Zhang", "Lili Qiu"], "title": "Zoomer: Adaptive Image Focus Optimization for Black-box MLLM", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Recent advancements in multimodal large language models (MLLMs) have\nbroadened the scope of vision-language tasks, excelling in applications like\nimage captioning and interactive question-answering. However, these models\nstruggle with accurately processing visual data, particularly in tasks\nrequiring precise object recognition and fine visual details. Stringent token\nlimits often result in the omission of critical information, hampering\nperformance. To address these limitations, we introduce \\SysName, a novel\nvisual prompting mechanism designed to enhance MLLM performance while\npreserving essential visual details within token limits. \\SysName features\nthree key innovations: a prompt-aware strategy that dynamically highlights\nrelevant image regions, a spatial-preserving orchestration schema that\nmaintains object integrity, and a budget-aware prompting method that balances\nglobal context with crucial visual details. Comprehensive evaluations across\nmultiple datasets demonstrate that \\SysName consistently outperforms baseline\nmethods, achieving up to a $26.9\\%$ improvement in accuracy while significantly\nreducing token consumption.", "AI": {"tldr": "A novel visual prompting mechanism, \\SysName, improves multimodal large language models (MLLMs) by enhancing visual data processing within token limits, achieving up to 26.9% accuracy improvement.", "motivation": "MLLMs struggle with precise object recognition and fine visual details due to token limits, leading to omitted critical information.", "method": "\\SysName introduces a prompt-aware strategy, spatial-preserving orchestration, and budget-aware prompting to balance context and details.", "result": "\\SysName outperforms baselines, improving accuracy by up to 26.9% and reducing token consumption.", "conclusion": "\\SysName effectively addresses MLLM limitations in visual tasks, offering a robust solution for preserving essential details."}}
{"id": "2505.00753", "pdf": "https://arxiv.org/pdf/2505.00753", "abs": "https://arxiv.org/abs/2505.00753", "authors": ["Henry Peng Zou", "Wei-Chieh Huang", "Yaozu Wu", "Yankai Chen", "Chunyu Miao", "Hoang Nguyen", "Yue Zhou", "Weizhi Zhang", "Liancheng Fang", "Langzhou He", "Yangning Li", "Yuwei Cao", "Dongyuan Li", "Renhe Jiang", "Philip S. Yu"], "title": "A Survey on Large Language Model based Human-Agent Systems", "categories": ["cs.CL", "cs.LG"], "comment": "Paper lists and resources are available at\n  \\url{https://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-System-Papers}", "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin building fully autonomous agents. However, fully autonomous LLM-based agents\nstill face significant challenges, including limited reliability due to\nhallucinations, difficulty in handling complex tasks, and substantial safety\nand ethical risks, all of which limit their feasibility and trustworthiness in\nreal-world applications. To overcome these limitations, LLM-based human-agent\nsystems (LLM-HAS) incorporate human-provided information, feedback, or control\ninto the agent system to enhance system performance, reliability and safety.\nThis paper provides the first comprehensive and structured survey of LLM-HAS.\nIt clarifies fundamental concepts, systematically presents core components\nshaping these systems, including environment & profiling, human feedback,\ninteraction types, orchestration and communication, explores emerging\napplications, and discusses unique challenges and opportunities. By\nconsolidating current knowledge and offering a structured overview, we aim to\nfoster further research and innovation in this rapidly evolving\ninterdisciplinary field. Paper lists and resources are available at\nhttps://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-System-Papers.", "AI": {"tldr": "The paper surveys LLM-based human-agent systems (LLM-HAS), addressing challenges like reliability and safety in autonomous LLM agents by integrating human input. It provides a structured overview of core components, applications, and future directions.", "motivation": "To address the limitations of fully autonomous LLM agents (e.g., hallucinations, safety risks) by incorporating human feedback and control, enhancing performance and reliability.", "method": "The paper conducts a comprehensive survey of LLM-HAS, clarifying concepts, detailing core components (environment, human feedback, interaction types, etc.), and exploring applications.", "result": "A structured overview of LLM-HAS, highlighting its components, emerging applications, and challenges.", "conclusion": "The survey aims to advance research in LLM-HAS by consolidating knowledge and identifying opportunities for innovation in this interdisciplinary field."}}
{"id": "2505.01237", "pdf": "https://arxiv.org/pdf/2505.01237", "abs": "https://arxiv.org/abs/2505.01237", "authors": ["Edson Araujo", "Andrew Rouditchenko", "Yuan Gong", "Saurabhchand Bhati", "Samuel Thomas", "Brian Kingsbury", "Leonid Karlinsky", "Rogerio Feris", "James R. Glass"], "title": "CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "comment": "To be published at CVPR 2025, code available at\n  https://github.com/edsonroteia/cav-mae-sync", "summary": "Recent advances in audio-visual learning have shown promising results in\nlearning representations across modalities. However, most approaches rely on\nglobal audio representations that fail to capture fine-grained temporal\ncorrespondences with visual frames. Additionally, existing methods often\nstruggle with conflicting optimization objectives when trying to jointly learn\nreconstruction and cross-modal alignment. In this work, we propose CAV-MAE Sync\nas a simple yet effective extension of the original CAV-MAE framework for\nself-supervised audio-visual learning. We address three key challenges: First,\nwe tackle the granularity mismatch between modalities by treating audio as a\ntemporal sequence aligned with video frames, rather than using global\nrepresentations. Second, we resolve conflicting optimization goals by\nseparating contrastive and reconstruction objectives through dedicated global\ntokens. Third, we improve spatial localization by introducing learnable\nregister tokens that reduce semantic load on patch tokens. We evaluate the\nproposed approach on AudioSet, VGG Sound, and the ADE20K Sound dataset on\nzero-shot retrieval, classification and localization tasks demonstrating\nstate-of-the-art performance and outperforming more complex architectures.", "AI": {"tldr": "CAV-MAE Sync improves audio-visual learning by aligning audio temporally with video, separating contrastive and reconstruction objectives, and using register tokens for better spatial localization.", "motivation": "Existing methods struggle with fine-grained temporal alignment and conflicting optimization goals in audio-visual learning.", "method": "Proposes CAV-MAE Sync, treating audio as a temporal sequence, separating objectives with global tokens, and introducing register tokens.", "result": "Achieves state-of-the-art performance on AudioSet, VGG Sound, and ADE20K Sound for retrieval, classification, and localization.", "conclusion": "CAV-MAE Sync is a simple yet effective extension for self-supervised audio-visual learning, outperforming complex architectures."}}
{"id": "2505.00839", "pdf": "https://arxiv.org/pdf/2505.00839", "abs": "https://arxiv.org/abs/2505.00839", "authors": ["Ahmad Suleman", "Yazeed Alkhrijah", "Misha Urooj Khan", "Hareem Khan", "Muhammad Abdullah Husnain Ali Faiz", "Mohamad A. Alawad", "Zeeshan Kaleem", "Guan Gui"], "title": "SMSAT: A Multimodal Acoustic Dataset and Deep Contrastive Learning Framework for Affective and Physiological Modeling of Spiritual Meditation", "categories": ["cs.SD", "cs.SI", "eess.AS"], "comment": null, "summary": "Understanding how auditory stimuli influence emotional and physiological\nstates is fundamental to advancing affective computing and mental health\ntechnologies. In this paper, we present a multimodal evaluation of the\naffective and physiological impacts of three auditory conditions, that is,\nspiritual meditation (SM), music (M), and natural silence (NS), using a\ncomprehensive suite of biometric signal measures. To facilitate this analysis,\nwe introduce the Spiritual, Music, Silence Acoustic Time Series (SMSAT)\ndataset, a novel benchmark comprising acoustic time series (ATS) signals\nrecorded under controlled exposure protocols, with careful attention to\ndemographic diversity and experimental consistency. To model the auditory\ninduced states, we develop a contrastive learning based SMSAT audio encoder\nthat extracts highly discriminative embeddings from ATS data, achieving 99.99%\nclassification accuracy in interclass and intraclass evaluations. Furthermore,\nwe propose the Calmness Analysis Model (CAM), a deep learning framework\nintegrating 25 handcrafted and learned features for affective state\nclassification across auditory conditions, attaining robust 99.99%\nclassification accuracy. In contrast, pairwise t tests reveal significant\ndeviations in cardiac response characteristics (CRC) between SM analysis via\nANOVA inducing more significant physiological fluctuations. Compared to\nexisting state of the art methods reporting accuracies up to 90%, the proposed\nmodel demonstrates substantial performance gains (up to 99%). This work\ncontributes a validated multimodal dataset and a scalable deep learning\nframework for affective computing applications in stress monitoring, mental\nwell-being, and therapeutic audio-based interventions.", "AI": {"tldr": "The paper introduces the SMSAT dataset and a deep learning framework (CAM) to analyze the affective and physiological impacts of auditory stimuli (spiritual meditation, music, natural silence), achieving 99.99% classification accuracy.", "motivation": "To advance affective computing and mental health technologies by understanding how auditory stimuli influence emotional and physiological states.", "method": "Developed the SMSAT dataset and a contrastive learning-based audio encoder, along with the CAM framework integrating 25 features for affective state classification.", "result": "Achieved 99.99% classification accuracy, outperforming existing methods (90% accuracy). Significant physiological fluctuations were observed in cardiac responses.", "conclusion": "The work provides a validated dataset and scalable framework for applications in stress monitoring, mental well-being, and therapeutic interventions."}}
{"id": "2505.01338", "pdf": "https://arxiv.org/pdf/2505.01338", "abs": "https://arxiv.org/abs/2505.01338", "authors": ["Satvik Venkatesh", "Philip Coleman", "Arthur Benilov", "Simon Brown", "Selim Sheta", "Frederic Roskam"], "title": "How much to Dereverberate? Low-Latency Single-Channel Speech Enhancement in Distant Microphone Scenarios", "categories": ["eess.AS", "cs.LG", "cs.SD", "I.5.1; I.5.4"], "comment": "Published in ICASSP 2025", "summary": "Dereverberation is an important sub-task of Speech Enhancement (SE) to\nimprove the signal's intelligibility and quality. However, it remains\nchallenging because the reverberation is highly correlated with the signal.\nFurthermore, the single-channel SE literature has predominantly focused on\nrooms with short reverb times (typically under 1 second), smaller rooms (under\nvolumes of 1000 cubic meters) and relatively short distances (up to 2 meters).\nIn this paper, we explore real-time low-latency single-channel SE under distant\nmicrophone scenarios, such as 5 to 10 meters, and focus on conference rooms and\ntheatres, with larger room dimensions and reverberation times. Such a setup is\nuseful for applications such as lecture demonstrations, drama, and to enhance\nstage acoustics. First, we show that single-channel SE in such challenging\nscenarios is feasible. Second, we investigate the relationship between room\nvolume and reverberation time, and demonstrate its importance when randomly\nsimulating room impulse responses. Lastly, we show that for dereverberation\nwith short decay times, preserving early reflections before decaying the\ntransfer function of the room improves overall signal quality.", "AI": {"tldr": "The paper explores real-time low-latency single-channel speech enhancement (SE) in distant microphone scenarios (5-10m) for large rooms like conference halls and theatres, addressing challenges like long reverberation times and room volume.", "motivation": "Current SE methods focus on small rooms with short reverb times, but real-world applications like lectures and drama require solutions for larger spaces with longer reverb.", "method": "Investigates SE feasibility in large rooms, studies room volume-reverb time relationship, and proposes preserving early reflections for better dereverberation.", "result": "Demonstrates SE is feasible in challenging scenarios; highlights the importance of room volume-reverb time correlation; preserving early reflections improves signal quality.", "conclusion": "The study advances SE for large rooms, showing practical solutions for distant microphone setups and emphasizing early reflection preservation."}}
{"id": "2505.00928", "pdf": "https://arxiv.org/pdf/2505.00928", "abs": "https://arxiv.org/abs/2505.00928", "authors": ["Adam Casselman", "Manav Vora", "Melkior Ornik"], "title": "Virtual Force-Based Routing of Modular Agents on a Graph", "categories": ["cs.MA", "math.OC"], "comment": null, "summary": "Modular vehicles have become an area of academic interest in the field of\nmulti-agent systems. Modularity allows vehicles to connect and disconnect with\neach other mid-transit which provides a balance between efficiency and\nflexibility when solving complex and large scale tasks in urban or aerial\ntransportation. This paper details a generalized scheme to route multiple\nmodular agents on a graph to a predetermined set of target nodes. The objective\nis to visit all target nodes while incurring minimum resource expenditure.\nAgents that are joined together will incur the equivalent cost of a single\nagent, which is motivated by the logistical benefits of traffic reduction and\nincreased fuel efficiency. To solve this problem, we introduce a heuristic\nalgorithm that seeks to balance the optimality of the path that an agent takes\nand the cost benefit of joining agents. Our approach models the agents and\ntargets as point charges, where the agents take the path of highest attractive\nforce from its target node and neighboring agents. We validate our approach by\nsimulating multiple modular agents along real-world transportation routes in\nthe road network of Champaign-Urbana, Illinois, USA. For two vehicles, it\nperformed equally compared to an existing modular-agent routing algorithm.\nThree agents were then routed using our method and the performance was\nbenchmarked against non-modular agents using a simple shortest path policy\nwhere it performs better than the non-modular implementation 81 percent of the\ntime. Moreover, we show that the proposed algorithm operates faster than\nexisting routing methods for modular agents.", "AI": {"tldr": "A heuristic algorithm for routing modular vehicles on graphs to minimize resource use, outperforming non-modular methods 81% of the time and being faster than existing modular routing algorithms.", "motivation": "Modular vehicles offer efficiency and flexibility in urban/aerial transportation by dynamically connecting/disconnecting. The goal is to minimize resource expenditure while visiting all target nodes.", "method": "A heuristic algorithm models agents and targets as point charges, routing agents along paths of highest attractive force from targets and neighboring agents.", "result": "Simulations on real-world routes showed equal performance to existing methods for two agents and better performance (81%) for three agents vs. non-modular methods. The algorithm is also faster.", "conclusion": "The proposed heuristic effectively balances path optimality and cost benefits of modularity, demonstrating superior performance and speed in real-world scenarios."}}
{"id": "2505.00795", "pdf": "https://arxiv.org/pdf/2505.00795", "abs": "https://arxiv.org/abs/2505.00795", "authors": ["Dibyangshu Mukherjee", "Shivaram Kalyanakrishnan"], "title": "Howard's Policy Iteration is Subexponential for Deterministic Markov Decision Problems with Rewards of Fixed Bit-size and Arbitrary Discount Factor", "categories": ["cs.AI"], "comment": null, "summary": "Howard's Policy Iteration (HPI) is a classic algorithm for solving Markov\nDecision Problems (MDPs). HPI uses a \"greedy\" switching rule to update from any\nnon-optimal policy to a dominating one, iterating until an optimal policy is\nfound. Despite its introduction over 60 years ago, the best-known upper bounds\non HPI's running time remain exponential in the number of states -- indeed even\non the restricted class of MDPs with only deterministic transitions (DMDPs).\nMeanwhile, the tightest lower bound for HPI for MDPs with a constant number of\nactions per state is only linear. In this paper, we report a significant\nimprovement: a subexponential upper bound for HPI on DMDPs, which is\nparameterised by the bit-size of the rewards, while independent of the discount\nfactor. The same upper bound also applies to DMDPs with only two possible\nrewards (which may be of arbitrary size).", "AI": {"tldr": "A subexponential upper bound for Howard's Policy Iteration (HPI) on deterministic MDPs (DMDPs) is introduced, improving previous exponential bounds.", "motivation": "Despite HPI's long history, its running time bounds remain poorly understood, with exponential upper bounds and linear lower bounds. This paper aims to bridge this gap.", "method": "The study focuses on HPI's performance on DMDPs, parameterizing the upper bound by reward bit-size and ensuring independence from the discount factor.", "result": "A subexponential upper bound for HPI on DMDPs is established, also applicable to DMDPs with two arbitrary-sized rewards.", "conclusion": "The paper significantly advances the understanding of HPI's efficiency, particularly for deterministic MDPs."}}
{"id": "2505.00792", "pdf": "https://arxiv.org/pdf/2505.00792", "abs": "https://arxiv.org/abs/2505.00792", "authors": ["Tam Nguyen", "Ngoc N. Tran", "Khai Nguyen", "Richard G. Baraniuk"], "title": "Improving Routing in Sparse Mixture of Experts with Graph of Tokens", "categories": ["cs.LG"], "comment": "20 pages, 5 figures, 10 tables", "summary": "Sparse Mixture of Experts (SMoE) has emerged as a key to achieving\nunprecedented scalability in deep learning. By activating only a small subset\nof parameters per sample, SMoE achieves an exponential increase in parameter\ncounts while maintaining a constant computational overhead. However, SMoE\nmodels are susceptible to routing fluctuations--changes in the routing of a\ngiven input to its target expert--at the late stage of model training, leading\nto model non-robustness. In this work, we unveil the limitation of SMoE through\nthe perspective of the probabilistic graphical model (PGM). Through this PGM\nframework, we highlight the independence in the expert-selection of tokens,\nwhich exposes the model to routing fluctuation and non-robustness. Alleviating\nthis independence, we propose the novel Similarity-Aware (S)MoE, which\nconsiders interactions between tokens during expert selection. We then derive a\nnew PGM underlying an (S)MoE-Attention block, going beyond just a single (S)MoE\nlayer. Leveraging the token similarities captured by the attention matrix, we\npropose the innovative Attention-Aware (S)MoE, which employs the attention\nmatrix to guide the routing of tokens to appropriate experts in (S)MoE. We\ntheoretically prove that Similarity/Attention-Aware routing help reduce the\nentropy of expert selection, resulting in more stable token routing mechanisms.\nWe empirically validate our models on various tasks and domains, showing\nsignificant improvements in reducing routing fluctuations, enhancing accuracy,\nand increasing model robustness over the baseline MoE-Transformer with token\nrouting via softmax gating.", "AI": {"tldr": "The paper introduces Similarity-Aware (S)MoE and Attention-Aware (S)MoE to address routing fluctuations in Sparse Mixture of Experts (SMoE) models, improving robustness and accuracy.", "motivation": "SMoE models face routing fluctuations and non-robustness due to independent expert-selection of tokens, limiting their effectiveness.", "method": "Proposes (S)MoE and (S)MoE-Attention blocks, leveraging token similarities and attention matrices to guide expert selection.", "result": "Theoretical proof and empirical validation show reduced entropy in expert selection, leading to stable routing, improved accuracy, and robustness.", "conclusion": "The proposed methods effectively mitigate routing fluctuations, enhancing SMoE model performance and reliability."}}
{"id": "2505.00743", "pdf": "https://arxiv.org/pdf/2505.00743", "abs": "https://arxiv.org/abs/2505.00743", "authors": ["Yinfeng Yu", "Dongsheng Yang"], "title": "DOPE: Dual Object Perception-Enhancement Network for Vision-and-Language Navigation", "categories": ["cs.CV", "cs.RO"], "comment": "Main paper (10 pages). Accepted for publication by ICMR(International\n  Conference on Multimedia Retrieval) 2025", "summary": "Vision-and-Language Navigation (VLN) is a challenging task where an agent\nmust understand language instructions and navigate unfamiliar environments\nusing visual cues. The agent must accurately locate the target based on visual\ninformation from the environment and complete tasks through interaction with\nthe surroundings. Despite significant advancements in this field, two major\nlimitations persist: (1) Many existing methods input complete language\ninstructions directly into multi-layer Transformer networks without fully\nexploiting the detailed information within the instructions, thereby limiting\nthe agent's language understanding capabilities during task execution; (2)\nCurrent approaches often overlook the modeling of object relationships across\ndifferent modalities, failing to effectively utilize latent clues between\nobjects, which affects the accuracy and robustness of navigation decisions. We\npropose a Dual Object Perception-Enhancement Network (DOPE) to address these\nissues to improve navigation performance. First, we design a Text Semantic\nExtraction (TSE) to extract relatively essential phrases from the text and\ninput them into the Text Object Perception-Augmentation (TOPA) to fully\nleverage details such as objects and actions within the instructions. Second,\nwe introduce an Image Object Perception-Augmentation (IOPA), which performs\nadditional modeling of object information across different modalities, enabling\nthe model to more effectively utilize latent clues between objects in images\nand text, enhancing decision-making accuracy. Extensive experiments on the R2R\nand REVERIE datasets validate the efficacy of the proposed approach.", "AI": {"tldr": "The paper proposes DOPE, a network to enhance VLN by improving language instruction understanding and cross-modal object relationship modeling.", "motivation": "Existing VLN methods lack detailed language instruction exploitation and cross-modal object relationship modeling, limiting navigation performance.", "method": "DOPE includes Text Semantic Extraction (TSE) and Image Object Perception-Augmentation (IOPA) to better utilize instruction details and object relationships.", "result": "Experiments on R2R and REVERIE datasets show improved navigation performance.", "conclusion": "DOPE effectively addresses current VLN limitations, enhancing language understanding and decision-making accuracy."}}
{"id": "2505.00776", "pdf": "https://arxiv.org/pdf/2505.00776", "abs": "https://arxiv.org/abs/2505.00776", "authors": ["Alessandro Raganato", "Rafael Pe\u00f1aloza", "Marco Viviani", "Gabriella Pasi"], "title": "Reasoning Capabilities and Invariability of Large Language Models", "categories": ["cs.CL"], "comment": "Accepted for publication in the Proceedings of the 23rd IEEE/WIC\n  International Conference on Web Intelligence and Intelligent Agent Technology\n  (WI-IAT 2024)", "summary": "Large Language Models (LLMs) have shown remarkable capabilities in\nmanipulating natural language across multiple applications, but their ability\nto handle simple reasoning tasks is often questioned. In this work, we aim to\nprovide a comprehensive analysis of LLMs' reasoning competence, specifically\nfocusing on their prompt dependency. In particular, we introduce a new\nbenchmark dataset with a series of simple reasoning questions demanding shallow\nlogical reasoning. Aligned with cognitive psychology standards, the questions\nare confined to a basic domain revolving around geometric figures, ensuring\nthat responses are independent of any pre-existing intuition about the world\nand rely solely on deduction. An empirical analysis involving zero-shot and\nfew-shot prompting across 24 LLMs of different sizes reveals that, while LLMs\nwith over 70 billion parameters perform better in the zero-shot setting, there\nis still a large room for improvement. An additional test with chain-of-thought\nprompting over 22 LLMs shows that this additional prompt can aid or damage the\nperformance of models, depending on whether the rationale is required before or\nafter the answer.", "AI": {"tldr": "The paper analyzes LLMs' reasoning competence, focusing on prompt dependency, using a new benchmark dataset of simple reasoning questions. It finds that larger LLMs perform better in zero-shot settings, but chain-of-thought prompting's impact varies.", "motivation": "To evaluate LLMs' ability in simple reasoning tasks and understand their dependency on prompts.", "method": "Introduced a benchmark dataset with basic geometric reasoning questions, tested 24 LLMs with zero-shot and few-shot prompting, and evaluated chain-of-thought prompting on 22 LLMs.", "result": "Larger LLMs (70B+ parameters) perform better in zero-shot settings, but chain-of-thought prompting's effectiveness depends on its timing relative to the answer.", "conclusion": "LLMs show potential in reasoning tasks but require further improvement, and prompt design significantly impacts performance."}}
{"id": "2505.01263", "pdf": "https://arxiv.org/pdf/2505.01263", "abs": "https://arxiv.org/abs/2505.01263", "authors": ["Gaoxiang Cong", "Liang Li", "Jiadong Pan", "Zhedong Zhang", "Amin Beheshti", "Anton van den Hengel", "Yuankai Qi", "Qingming Huang"], "title": "FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and Flow Matching based Voice Enhancing", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "comment": null, "summary": "Movie Dubbing aims to convert scripts into speeches that align with the given\nmovie clip in both temporal and emotional aspects while preserving the vocal\ntimbre of a given brief reference audio. Existing methods focus primarily on\nreducing the word error rate while ignoring the importance of lip-sync and\nacoustic quality. To address these issues, we propose a large language model\n(LLM) based flow matching architecture for dubbing, named FlowDubber, which\nachieves high-quality audio-visual sync and pronunciation by incorporating a\nlarge speech language model and dual contrastive aligning while achieving\nbetter acoustic quality via the proposed voice-enhanced flow matching than\nprevious works. First, we introduce Qwen2.5 as the backbone of LLM to learn the\nin-context sequence from movie scripts and reference audio. Then, the proposed\nsemantic-aware learning focuses on capturing LLM semantic knowledge at the\nphoneme level. Next, dual contrastive aligning (DCA) boosts mutual alignment\nwith lip movement, reducing ambiguities where similar phonemes might be\nconfused. Finally, the proposed Flow-based Voice Enhancing (FVE) improves\nacoustic quality in two aspects, which introduces an LLM-based acoustics flow\nmatching guidance to strengthen clarity and uses affine style prior to enhance\nidentity when recovering noise into mel-spectrograms via gradient vector field\nprediction. Extensive experiments demonstrate that our method outperforms\nseveral state-of-the-art methods on two primary benchmarks. The demos are\navailable at\n{\\href{https://galaxycong.github.io/LLM-Flow-Dubber/}{\\textcolor{red}{https://galaxycong.github.io/LLM-Flow-Dubber/}}}.", "AI": {"tldr": "FlowDubber is an LLM-based dubbing method that improves lip-sync, pronunciation, and acoustic quality using semantic-aware learning, dual contrastive aligning, and voice-enhanced flow matching.", "motivation": "Existing dubbing methods prioritize word error rate over lip-sync and acoustic quality, leading to suboptimal results. FlowDubber addresses this gap.", "method": "Uses Qwen2.5 LLM backbone, semantic-aware phoneme learning, dual contrastive aligning (DCA) for lip-sync, and flow-based voice enhancing (FVE) for acoustic quality.", "result": "Outperforms state-of-the-art methods on benchmarks, achieving better audio-visual sync and clarity.", "conclusion": "FlowDubber sets a new standard for high-quality dubbing by integrating LLMs and advanced alignment techniques."}}
{"id": "2505.01369", "pdf": "https://arxiv.org/pdf/2505.01369", "abs": "https://arxiv.org/abs/2505.01369", "authors": ["Dan Barry", "Davoud Shariat Panah", "Alessandro Ragano", "Jan Skoglund", "Andrew Hines"], "title": "Binamix -- A Python Library for Generating Binaural Audio Datasets", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to the 158th Audio Engineering Society Convention, 2025", "summary": "The increasing demand for spatial audio in applications such as virtual\nreality, immersive media, and spatial audio research necessitates robust\nsolutions to generate binaural audio data sets for use in testing and\nvalidation. Binamix is an open-source Python library designed to facilitate\nprogrammatic binaural mixing using the extensive SADIE II Database, which\nprovides Head Related Impulse Response (HRIR) and Binaural Room Impulse\nResponse (BRIR) data for 20 subjects. The Binamix library provides a flexible\nand repeatable framework for creating large-scale spatial audio datasets,\nmaking it an invaluable resource for codec evaluation, audio quality metric\ndevelopment, and machine learning model training. A range of pre-built example\nscripts, utility functions, and visualization plots further streamline the\nprocess of custom pipeline creation. This paper presents an overview of the\nlibrary's capabilities, including binaural rendering, impulse response\ninterpolation, and multi-track mixing for various speaker layouts. The tools\nutilize a modified Delaunay triangulation technique to achieve accurate\nHRIR/BRIR interpolation where desired angles are not present in the data. By\nsupporting a wide range of parameters such as azimuth, elevation, subject\nImpulse Responses (IRs), speaker layouts, mixing controls, and more, the\nlibrary enables researchers to create large binaural datasets for any\ndownstream purpose. Binamix empowers researchers and developers to advance\nspatial audio applications with reproducible methodologies by offering an\nopen-source solution for binaural rendering and dataset generation. We release\nthe library under the Apache 2.0 License at\nhttps://github.com/QxLabIreland/Binamix/", "AI": {"tldr": "Binamix is an open-source Python library for generating binaural audio datasets using the SADIE II Database, aiding in spatial audio research and applications.", "motivation": "The demand for spatial audio in VR, immersive media, and research requires robust tools for creating binaural datasets for testing and validation.", "method": "Binamix uses the SADIE II Database for HRIR/BRIR data, employing Delaunay triangulation for interpolation and offering customizable mixing and rendering.", "result": "The library provides a flexible framework for large-scale dataset creation, supporting various parameters and speaker layouts.", "conclusion": "Binamix advances spatial audio research by offering an open-source, reproducible solution for binaural rendering and dataset generation."}}
{"id": "2504.04450", "pdf": "https://arxiv.org/pdf/2504.04450", "abs": "https://arxiv.org/abs/2504.04450", "authors": ["Lu Bai", "Mengtong Li", "Siyuan Lian", "Kai Chen", "Jing Lu"], "title": "WaveNet-Volterra Neural Networks for Active Noise Control: A Fully Causal Approach", "categories": ["eess.AS"], "comment": null, "summary": "Active Noise Control (ANC) systems are challenged by nonlinear distortions,\nwhich degrade the performance of traditional adaptive filters. While deep\nlearning-based ANC algorithms have emerged to address nonlinearity, existing\napproaches often overlook critical limitations: (1) end-to-end Deep Neural\nNetwork (DNN) models frequently violate causality constraints inherent to\nreal-time ANC applications; (2) many studies compare DNN-based methods against\nsimplified or low-order adaptive filters rather than fully optimized high-order\ncounterparts. In this letter, we propose a causality-preserving time-domain ANC\nframework that synergizes WaveNet with Volterra Neural Networks (VNNs),\nexplicitly addressing system nonlinearity while ensuring strict causal\noperation. Unlike prior DNN-based approaches, our method is benchmarked against\nboth state-of-the-art deep learning architectures and rigorously optimized\nhigh-order adaptive filters, including Wiener solutions. Simulations\ndemonstrate that the proposed framework achieves superior performance over\nexisting DNN methods and traditional algorithms, revealing that prior claims of\nDNN superiority stem from incomplete comparisons with suboptimal traditional\nbaselines. Source code is available at\nhttps://github.com/Lu-Baihh/WaveNet-VNNs-for-ANC.git.", "AI": {"tldr": "The paper proposes a causality-preserving ANC framework combining WaveNet and VNNs, outperforming existing DNN and traditional methods by addressing nonlinearity and ensuring real-time operation.", "motivation": "Existing DNN-based ANC methods often violate causality constraints and are benchmarked against suboptimal traditional filters, leading to incomplete performance claims.", "method": "The proposed framework integrates WaveNet with Volterra Neural Networks (VNNs) to handle nonlinearity while maintaining strict causality in real-time ANC.", "result": "Simulations show the method surpasses both state-of-the-art DNN architectures and optimized high-order adaptive filters, including Wiener solutions.", "conclusion": "The framework demonstrates superior performance, highlighting that prior DNN superiority claims were based on incomplete comparisons with suboptimal baselines."}}
{"id": "2505.00747", "pdf": "https://arxiv.org/pdf/2505.00747", "abs": "https://arxiv.org/abs/2505.00747", "authors": ["Zhiying Song", "Tenghui Xie", "Fuxi Wen", "Jun Li"], "title": "Wireless Communication as an Information Sensor for Multi-agent Cooperative Perception: A Survey", "categories": ["cs.OH", "cs.CV", "cs.MA", "cs.RO"], "comment": null, "summary": "Cooperative perception extends the perception capabilities of autonomous\nvehicles by enabling multi-agent information sharing via Vehicle-to-Everything\n(V2X) communication. Unlike traditional onboard sensors, V2X acts as a dynamic\n\"information sensor\" characterized by limited communication, heterogeneity,\nmobility, and scalability. This survey provides a comprehensive review of\nrecent advancements from the perspective of information-centric cooperative\nperception, focusing on three key dimensions: information representation,\ninformation fusion, and large-scale deployment. We categorize information\nrepresentation into data-level, feature-level, and object-level schemes, and\nhighlight emerging methods for reducing data volume and compressing messages\nunder communication constraints. In information fusion, we explore techniques\nunder both ideal and non-ideal conditions, including those addressing\nheterogeneity, localization errors, latency, and packet loss. Finally, we\nsummarize system-level approaches to support scalability in dense traffic\nscenarios. Compared with existing surveys, this paper introduces a new\nperspective by treating V2X communication as an information sensor and\nemphasizing the challenges of deploying cooperative perception in real-world\nintelligent transportation systems.", "AI": {"tldr": "A survey on cooperative perception in autonomous vehicles using V2X communication, focusing on information representation, fusion, and scalability.", "motivation": "To enhance autonomous vehicle perception by leveraging multi-agent information sharing via V2X, addressing challenges like communication limits and scalability.", "method": "Categorizes information representation (data, feature, object levels), explores fusion techniques under ideal/non-ideal conditions, and summarizes scalability solutions.", "result": "Highlights methods for data reduction, fusion under constraints, and large-scale deployment.", "conclusion": "Introduces V2X as an 'information sensor' and emphasizes real-world deployment challenges in intelligent transportation systems."}}
{"id": "2505.00802", "pdf": "https://arxiv.org/pdf/2505.00802", "abs": "https://arxiv.org/abs/2505.00802", "authors": ["Vasiliki Papanikou", "Danae Pla Karidi", "Evaggelia Pitoura", "Emmanouil Panagiotou", "Eirini Ntoutsi"], "title": "Explanations as Bias Detectors: A Critical Study of Local Post-hoc XAI Methods for Fairness Exploration", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As Artificial Intelligence (AI) is increasingly used in areas that\nsignificantly impact human lives, concerns about fairness and transparency have\ngrown, especially regarding their impact on protected groups. Recently, the\nintersection of explainability and fairness has emerged as an important area to\npromote responsible AI systems. This paper explores how explainability methods\ncan be leveraged to detect and interpret unfairness. We propose a pipeline that\nintegrates local post-hoc explanation methods to derive fairness-related\ninsights. During the pipeline design, we identify and address critical\nquestions arising from the use of explanations as bias detectors such as the\nrelationship between distributive and procedural fairness, the effect of\nremoving the protected attribute, the consistency and quality of results across\ndifferent explanation methods, the impact of various aggregation strategies of\nlocal explanations on group fairness evaluations, and the overall\ntrustworthiness of explanations as bias detectors. Our results show the\npotential of explanation methods used for fairness while highlighting the need\nto carefully consider the aforementioned critical aspects.", "AI": {"tldr": "The paper explores using explainability methods to detect and interpret unfairness in AI systems, proposing a pipeline for fairness insights and addressing critical questions about their reliability.", "motivation": "Growing concerns about AI fairness and transparency, especially for protected groups, drive the need to integrate explainability with fairness for responsible AI.", "method": "A pipeline integrating local post-hoc explanation methods is proposed to derive fairness-related insights, addressing key questions about explanation reliability.", "result": "The results demonstrate the potential of explanation methods for fairness but emphasize careful consideration of critical aspects like consistency and trustworthiness.", "conclusion": "Explainability methods can aid fairness detection, but their use requires addressing key challenges to ensure reliable and trustworthy outcomes."}}
{"id": "2505.00793", "pdf": "https://arxiv.org/pdf/2505.00793", "abs": "https://arxiv.org/abs/2505.00793", "authors": ["Iurii Kemaev", "Dan A Calian", "Luisa M Zintgraf", "Gregory Farquhar", "Hado van Hasselt"], "title": "Scalable Meta-Learning via Mixed-Mode Differentiation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Gradient-based bilevel optimisation is a powerful technique with applications\nin hyperparameter optimisation, task adaptation, algorithm discovery,\nmeta-learning more broadly, and beyond. It often requires differentiating\nthrough the gradient-based optimisation process itself, leading to\n\"gradient-of-a-gradient\" calculations with computationally expensive\nsecond-order and mixed derivatives. While modern automatic differentiation\nlibraries provide a convenient way to write programs for calculating these\nderivatives, they oftentimes cannot fully exploit the specific structure of\nthese problems out-of-the-box, leading to suboptimal performance. In this\npaper, we analyse such cases and propose Mixed-Flow Meta-Gradients, or\nMixFlow-MG -- a practical algorithm that uses mixed-mode differentiation to\nconstruct more efficient and scalable computational graphs yielding over 10x\nmemory and up to 25% wall-clock time improvements over standard implementations\nin modern meta-learning setups.", "AI": {"tldr": "MixFlow-MG improves efficiency in gradient-based bilevel optimization by using mixed-mode differentiation, achieving significant memory and time savings.", "motivation": "Addressing inefficiencies in gradient-of-a-gradient calculations in bilevel optimization, which are computationally expensive and suboptimal with standard methods.", "method": "Proposes Mixed-Flow Meta-Gradients (MixFlow-MG), leveraging mixed-mode differentiation to optimize computational graphs.", "result": "Achieves over 10x memory savings and up to 25% faster wall-clock time compared to standard implementations.", "conclusion": "MixFlow-MG is a practical solution for scalable and efficient bilevel optimization in meta-learning and related fields."}}
{"id": "2505.00735", "pdf": "https://arxiv.org/pdf/2505.00735", "abs": "https://arxiv.org/abs/2505.00735", "authors": ["Jin Hyun Park", "Harine Choi", "Praewa Pitiphat"], "title": "Leveraging Depth and Attention Mechanisms for Improved RGB Image Inpainting", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Existing deep learning-based image inpainting methods typically rely on\nconvolutional networks with RGB images to reconstruct images. However, relying\nexclusively on RGB images may neglect important depth information, which plays\na critical role in understanding the spatial and structural context of a scene.\nJust as human vision leverages stereo cues to perceive depth, incorporating\ndepth maps into the inpainting process can enhance the model's ability to\nreconstruct images with greater accuracy and contextual awareness. In this\npaper, we propose a novel approach that incorporates both RGB and depth images\nfor enhanced image inpainting. Our models employ a dual encoder architecture,\nwhere one encoder processes the RGB image and the other handles the depth\nimage. The encoded features from both encoders are then fused in the decoder\nusing an attention mechanism, effectively integrating the RGB and depth\nrepresentations. We use two different masking strategies, line and square, to\ntest the robustness of the model under different types of occlusions. To\nfurther analyze the effectiveness of our approach, we use Gradient-weighted\nClass Activation Mapping (Grad-CAM) visualizations to examine the regions of\ninterest the model focuses on during inpainting. We show that incorporating\ndepth information alongside the RGB image significantly improves the\nreconstruction quality. Through both qualitative and quantitative comparisons,\nwe demonstrate that the depth-integrated model outperforms the baseline, with\nattention mechanisms further enhancing inpainting performance, as evidenced by\nmultiple evaluation metrics and visualization.", "AI": {"tldr": "A novel image inpainting method using RGB and depth images with a dual encoder and attention mechanism improves reconstruction quality.", "motivation": "RGB-only methods lack depth information, which is crucial for spatial and structural context. Incorporating depth enhances accuracy.", "method": "Dual encoder architecture processes RGB and depth images separately, fusing features with an attention mechanism. Tested with line and square masks.", "result": "Depth-integrated model outperforms baseline, with attention further boosting performance. Grad-CAM visualizations confirm focus on relevant regions.", "conclusion": "Combining RGB and depth with attention mechanisms significantly improves inpainting quality, validated by metrics and visualizations."}}
{"id": "2505.00744", "pdf": "https://arxiv.org/pdf/2505.00744", "abs": "https://arxiv.org/abs/2505.00744", "authors": ["Dung Nguyen", "Minh Khoi Ho", "Huy Ta", "Thanh Tam Nguyen", "Qi Chen", "Kumar Rav", "Quy Duong Dang", "Satwik Ramchandre", "Son Lam Phung", "Zhibin Liao", "Minh-Son To", "Johan Verjans", "Phi Le Nguyen", "Vu Minh Hieu Phan"], "title": "Localizing Before Answering: A Benchmark for Grounded Medical Visual Question Answering", "categories": ["cs.CV"], "comment": "Accepted at Joint Conference on Artificial Intelligence (IJCAI) 2025", "summary": "Medical Large Multi-modal Models (LMMs) have demonstrated remarkable\ncapabilities in medical data interpretation. However, these models frequently\ngenerate hallucinations contradicting source evidence, particularly due to\ninadequate localization reasoning. This work reveals a critical limitation in\ncurrent medical LMMs: instead of analyzing relevant pathological regions, they\noften rely on linguistic patterns or attend to irrelevant image areas when\nresponding to disease-related queries. To address this, we introduce\nHEAL-MedVQA (Hallucination Evaluation via Localization MedVQA), a comprehensive\nbenchmark designed to evaluate LMMs' localization abilities and hallucination\nrobustness. HEAL-MedVQA features (i) two innovative evaluation protocols to\nassess visual and textual shortcut learning, and (ii) a dataset of 67K VQA\npairs, with doctor-annotated anatomical segmentation masks for pathological\nregions. To improve visual reasoning, we propose the Localize-before-Answer\n(LobA) framework, which trains LMMs to localize target regions of interest and\nself-prompt to emphasize segmented pathological areas, generating grounded and\nreliable answers. Experimental results demonstrate that our approach\nsignificantly outperforms state-of-the-art biomedical LMMs on the challenging\nHEAL-MedVQA benchmark, advancing robustness in medical VQA.", "AI": {"tldr": "The paper introduces HEAL-MedVQA, a benchmark to evaluate medical LMMs' localization abilities and hallucination robustness, and proposes the LobA framework to improve visual reasoning.", "motivation": "Current medical LMMs often generate hallucinations due to inadequate localization reasoning, relying on linguistic patterns or irrelevant image areas.", "method": "The authors develop HEAL-MedVQA with two evaluation protocols and a dataset of 67K VQA pairs. They propose the LobA framework to localize and emphasize pathological regions.", "result": "The LobA framework outperforms state-of-the-art biomedical LMMs on the HEAL-MedVQA benchmark.", "conclusion": "The approach advances robustness in medical VQA by addressing localization and hallucination issues."}}
{"id": "2505.00814", "pdf": "https://arxiv.org/pdf/2505.00814", "abs": "https://arxiv.org/abs/2505.00814", "authors": ["Mario S\u00e4nger", "Ulf Leser"], "title": "Knowledge-augmented Pre-trained Language Models for Biomedical Relation Extraction", "categories": ["cs.CL"], "comment": null, "summary": "Automatic relationship extraction (RE) from biomedical literature is critical\nfor managing the vast amount of scientific knowledge produced each year. In\nrecent years, utilizing pre-trained language models (PLMs) has become the\nprevalent approach in RE. Several studies report improved performance when\nincorporating additional context information while fine-tuning PLMs for RE.\nHowever, variations in the PLMs applied, the databases used for augmentation,\nhyper-parameter optimization, and evaluation methods complicate direct\ncomparisons between studies and raise questions about the generalizability of\nthese findings. Our study addresses this research gap by evaluating PLMs\nenhanced with contextual information on five datasets spanning four relation\nscenarios within a consistent evaluation framework. We evaluate three baseline\nPLMs and first conduct extensive hyperparameter optimization. After selecting\nthe top-performing model, we enhance it with additional data, including textual\nentity descriptions, relational information from knowledge graphs, and\nmolecular structure encodings. Our findings illustrate the importance of i) the\nchoice of the underlying language model and ii) a comprehensive hyperparameter\noptimization for achieving strong extraction performance. Although inclusion of\ncontext information yield only minor overall improvements, an ablation study\nreveals substantial benefits for smaller PLMs when such external data was\nincluded during fine-tuning.", "AI": {"tldr": "The study evaluates pre-trained language models (PLMs) enhanced with contextual information for biomedical relationship extraction, emphasizing model choice and hyperparameter optimization.", "motivation": "Addressing inconsistencies in PLM-based relationship extraction studies due to variations in models, databases, and evaluation methods.", "method": "Evaluated three baseline PLMs with hyperparameter optimization, then enhanced the top model with contextual data (entity descriptions, knowledge graphs, molecular structures).", "result": "Model choice and hyperparameter optimization are critical; contextual data offers minor overall improvements but significant benefits for smaller PLMs.", "conclusion": "Consistent evaluation and contextual data can enhance PLM performance, especially for smaller models."}}
{"id": "2505.01255", "pdf": "https://arxiv.org/pdf/2505.01255", "abs": "https://arxiv.org/abs/2505.01255", "authors": ["Wei Han", "Hui Chen", "Soujanya Poria"], "title": "PREMISE: Matching-based Prediction for Accurate Review Recommendation", "categories": ["cs.CL", "cs.IR", "cs.MM"], "comment": "19 pages, 16 figures", "summary": "We present PREMISE (PREdict with Matching ScorEs), a new architecture for the\nmatching-based learning in the multimodal fields for the multimodal review\nhelpfulness (MRHP) task. Distinct to previous fusion-based methods which\nobtains multimodal representations via cross-modal attention for downstream\ntasks, PREMISE computes the multi-scale and multi-field representations,\nfilters duplicated semantics, and then obtained a set of matching scores as\nfeature vectors for the downstream recommendation task. This new architecture\nsignificantly boosts the performance for such multimodal tasks whose context\nmatching content are highly correlated to the targets of that task, compared to\nthe state-of-the-art fusion-based methods. Experimental results on two publicly\navailable datasets show that PREMISE achieves promising performance with less\ncomputational cost.", "AI": {"tldr": "PREMISE is a new architecture for multimodal learning, outperforming fusion-based methods by focusing on matching scores and reducing computational costs.", "motivation": "To improve performance in multimodal tasks like MRHP by addressing the limitations of fusion-based methods, which rely on cross-modal attention.", "method": "PREMISE computes multi-scale and multi-field representations, filters duplicates, and uses matching scores as feature vectors for recommendations.", "result": "PREMISE achieves better performance than state-of-the-art fusion-based methods on two datasets, with lower computational costs.", "conclusion": "PREMISE is effective for tasks where context matching is crucial, offering a scalable and efficient alternative to fusion-based approaches."}}
{"id": "2409.00292", "pdf": "https://arxiv.org/pdf/2409.00292", "abs": "https://arxiv.org/abs/2409.00292", "authors": ["Songyan Zhao", "Bingxuan Li", "Yufei Tian", "Nanyun Peng"], "title": "REFFLY: Melody-Constrained Lyrics Editing Model", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Automatic melody-to-lyric (M2L) generation aims to create lyrics that align\nwith a given melody. While most previous approaches generate lyrics from\nscratch, revision, editing plain text draft to fit it into the melody, offers a\nmuch more flexible and practical alternative. This enables broad applications,\nsuch as generating lyrics from flexible inputs (keywords, themes, or full text\nthat needs refining to be singable), song translation (preserving meaning\nacross languages while keeping the melody intact), or style transfer (adapting\nlyrics to different genres). This paper introduces REFFLY (REvision Framework\nFor LYrics), the first revision framework for editing and generating\nmelody-aligned lyrics. We train the lyric revision module using our curated\nsynthesized melody-aligned lyrics dataset, enabling it to transform plain text\ninto lyrics that align with a given melody. To further enhance the revision\nability, we propose training-free heuristics aimed at preserving both semantic\nmeaning and musical consistency throughout the editing process. Experimental\nresults demonstrate the effectiveness of REFFLY across various tasks (e.g.\nlyrics generation, song translation), showing that our model outperforms strong\nbaselines, including Lyra (Tian et al., 2023) and GPT-4, by 25% in both\nmusicality and text quality.", "AI": {"tldr": "REFFLY is a revision framework for melody-aligned lyrics, outperforming baselines like Lyra and GPT-4 by 25% in musicality and text quality.", "motivation": "To enable flexible and practical lyric generation by revising plain text drafts to fit melodies, supporting applications like song translation and style transfer.", "method": "Uses a lyric revision module trained on a synthesized dataset and incorporates training-free heuristics for semantic and musical consistency.", "result": "REFFLY outperforms Lyra and GPT-4 by 25% in musicality and text quality across tasks like lyrics generation and song translation.", "conclusion": "REFFLY provides an effective and flexible solution for melody-aligned lyric generation and editing."}}
{"id": "2504.20334", "pdf": "https://arxiv.org/pdf/2504.20334", "abs": "https://arxiv.org/abs/2504.20334", "authors": ["Yuzhe Liang", "Wenzhe Liu", "Chunyu Qiang", "Zhikang Niu", "Yushen Chen", "Ziyang Ma", "Wenxi Chen", "Nan Li", "Chen Zhang", "Xie Chen"], "title": "Towards Flow-Matching-based TTS without Classifier-Free Guidance", "categories": ["eess.AS"], "comment": null, "summary": "Flow matching has demonstrated strong generative capabilities and has become\na core component in modern Text-to-Speech (TTS) systems. To ensure high-quality\nspeech synthesis, Classifier-Free Guidance (CFG) is widely used during the\ninference of flow-matching-based TTS models. However, CFG incurs substantial\ncomputational cost as it requires two forward passes, which hinders its\napplicability in real-time scenarios. In this paper, we explore removing CFG\nfrom flow-matching-based TTS models to improve inference efficiency, while\nmaintaining performance. Specifically, we reformulated the flow matching\ntraining target to directly approximate the CFG optimization trajectory. This\ntraining method eliminates the need for unconditional model evaluation and\nguided tuning during inference, effectively cutting the computational overhead\nin half. Furthermore, It can be seamlessly integrated with existing optimized\nsampling strategies. We validate our approach using the F5-TTS model on the\nLibriTTS dataset. Experimental results show that our method achieves a\n9$\\times$ inference speed-up compared to the baseline F5-TTS, while preserving\ncomparable speech quality. We will release the code and models to support\nreproducibility and foster further research in this area.", "AI": {"tldr": "The paper proposes a method to remove Classifier-Free Guidance (CFG) from flow-matching-based TTS models to improve inference efficiency while maintaining performance, achieving a 9\u00d7 speed-up.", "motivation": "CFG incurs high computational costs in flow-matching-based TTS models, hindering real-time applicability.", "method": "Reformulate flow matching training to approximate CFG optimization trajectory, eliminating unconditional model evaluation and guided tuning.", "result": "Achieves 9\u00d7 inference speed-up on the F5-TTS model with comparable speech quality.", "conclusion": "The method efficiently removes CFG, significantly improving inference speed without sacrificing performance, and is compatible with existing sampling strategies."}}
{"id": "2505.00827", "pdf": "https://arxiv.org/pdf/2505.00827", "abs": "https://arxiv.org/abs/2505.00827", "authors": ["Jing Wang", "Xing Niu", "Juyong Kim", "Jie Shen", "Tong Zhang", "Jeremy C. Weiss"], "title": "MIMIC-\\RNum{4}-Ext-22MCTS: A 22 Millions-Event Temporal Clinical Time-Series Dataset with Relative Timestamp for Risk Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Clinical risk prediction based on machine learning algorithms plays a vital\nrole in modern healthcare. A crucial component in developing a reliable\nprediction model is collecting high-quality time series clinical events. In\nthis work, we release such a dataset that consists of 22,588,586 Clinical Time\nSeries events, which we term MIMIC-\\RNum{4}-Ext-22MCTS. Our source data are\ndischarge summaries selected from the well-known yet unstructured MIMIC-IV-Note\n\\cite{Johnson2023-pg}. We then extract clinical events as short text span from\nthe discharge summaries, along with the timestamps of these events as temporal\ninformation. The general-purpose MIMIC-IV-Note pose specific challenges for our\nwork: it turns out that the discharge summaries are too lengthy for typical\nnatural language models to process, and the clinical events of interest often\nare not accompanied with explicit timestamps. Therefore, we propose a new\nframework that works as follows: 1) we break each discharge summary into\nmanageably small text chunks; 2) we apply contextual BM25 and contextual\nsemantic search to retrieve chunks that have a high potential of containing\nclinical events; and 3) we carefully design prompts to teach the recently\nreleased Llama-3.1-8B \\cite{touvron2023llama} model to identify or infer\ntemporal information of the chunks. We show that the obtained dataset is so\ninformative and transparent that standard models fine-tuned on our dataset are\nachieving significant improvements in healthcare applications. In particular,\nthe BERT model fine-tuned based on our dataset achieves 10\\% improvement in\naccuracy on medical question answering task, and 3\\% improvement in clinical\ntrial matching task compared with the classic BERT. The GPT-2 model, fine-tuned\non our dataset, produces more clinically reliable results for clinical\nquestions.", "AI": {"tldr": "The paper introduces MIMIC-4-Ext-22MCTS, a dataset of 22.5M clinical time series events extracted from MIMIC-IV-Note discharge summaries, using a novel framework for processing lengthy texts and inferring timestamps. Fine-tuned models show significant improvements in healthcare tasks.", "motivation": "To address challenges in processing lengthy discharge summaries and extracting clinical events with timestamps for reliable clinical risk prediction.", "method": "Proposes a framework: 1) chunking discharge summaries, 2) using contextual BM25 and semantic search to identify event-rich chunks, and 3) leveraging Llama-3.1-8B to infer temporal information.", "result": "Fine-tuned BERT and GPT-2 models achieve 10% and 3% improvements in accuracy for medical QA and clinical trial matching, respectively, with more clinically reliable outputs.", "conclusion": "The dataset and framework enhance clinical risk prediction by improving model performance and reliability in healthcare applications."}}
{"id": "2505.00808", "pdf": "https://arxiv.org/pdf/2505.00808", "abs": "https://arxiv.org/abs/2505.00808", "authors": ["Kola Ayonrinde", "Louis Jaburi"], "title": "A Mathematical Philosophy of Explanations in Mechanistic Interpretability -- The Strange Science Part I.i", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "15 pages (plus appendices), 2 figures", "summary": "Mechanistic Interpretability aims to understand neural networks through\ncausal explanations. We argue for the Explanatory View Hypothesis: that\nMechanistic Interpretability research is a principled approach to understanding\nmodels because neural networks contain implicit explanations which can be\nextracted and understood. We hence show that Explanatory Faithfulness, an\nassessment of how well an explanation fits a model, is well-defined. We propose\na definition of Mechanistic Interpretability (MI) as the practice of producing\nModel-level, Ontic, Causal-Mechanistic, and Falsifiable explanations of neural\nnetworks, allowing us to distinguish MI from other interpretability paradigms\nand detail MI's inherent limits. We formulate the Principle of Explanatory\nOptimism, a conjecture which we argue is a necessary precondition for the\nsuccess of Mechanistic Interpretability.", "AI": {"tldr": "Mechanistic Interpretability (MI) is a principled approach to understanding neural networks by extracting implicit explanations. The paper defines MI, introduces Explanatory Faithfulness, and proposes the Principle of Explanatory Optimism as a precondition for MI's success.", "motivation": "To establish MI as a distinct and rigorous interpretability paradigm by defining its scope, limits, and necessary preconditions.", "method": "Proposes definitions for MI and Explanatory Faithfulness, and formulates the Principle of Explanatory Optimism.", "result": "MI is characterized as Model-level, Ontic, Causal-Mechanistic, and Falsifiable, distinguishing it from other interpretability approaches.", "conclusion": "MI is a viable and principled approach to understanding neural networks, contingent on the Principle of Explanatory Optimism."}}
{"id": "2505.00737", "pdf": "https://arxiv.org/pdf/2505.00737", "abs": "https://arxiv.org/abs/2505.00737", "authors": ["Jiajia Li", "Xinda Qi", "Seyed Hamidreza Nabaei", "Meiqi Liu", "Dong Chen", "Xin Zhang", "Xunyuan Yin", "Zhaojian Li"], "title": "A Survey on 3D Reconstruction Techniques in Plant Phenotyping: From Classical Methods to Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and Beyond", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "17 pages, 7 figures, 4 tables", "summary": "Plant phenotyping plays a pivotal role in understanding plant traits and\ntheir interactions with the environment, making it crucial for advancing\nprecision agriculture and crop improvement. 3D reconstruction technologies have\nemerged as powerful tools for capturing detailed plant morphology and\nstructure, offering significant potential for accurate and automated\nphenotyping. This paper provides a comprehensive review of the 3D\nreconstruction techniques for plant phenotyping, covering classical\nreconstruction methods, emerging Neural Radiance Fields (NeRF), and the novel\n3D Gaussian Splatting (3DGS) approach. Classical methods, which often rely on\nhigh-resolution sensors, are widely adopted due to their simplicity and\nflexibility in representing plant structures. However, they face challenges\nsuch as data density, noise, and scalability. NeRF, a recent advancement,\nenables high-quality, photorealistic 3D reconstructions from sparse viewpoints,\nbut its computational cost and applicability in outdoor environments remain\nareas of active research. The emerging 3DGS technique introduces a new paradigm\nin reconstructing plant structures by representing geometry through Gaussian\nprimitives, offering potential benefits in both efficiency and scalability. We\nreview the methodologies, applications, and performance of these approaches in\nplant phenotyping and discuss their respective strengths, limitations, and\nfuture prospects (https://github.com/JiajiaLi04/3D-Reconstruction-Plants).\nThrough this review, we aim to provide insights into how these diverse 3D\nreconstruction techniques can be effectively leveraged for automated and\nhigh-throughput plant phenotyping, contributing to the next generation of\nagricultural technology.", "AI": {"tldr": "The paper reviews 3D reconstruction techniques for plant phenotyping, comparing classical methods, Neural Radiance Fields (NeRF), and 3D Gaussian Splatting (3DGS), highlighting their strengths, limitations, and future potential.", "motivation": "Advancing precision agriculture and crop improvement by leveraging accurate and automated plant phenotyping through 3D reconstruction technologies.", "method": "Comprehensive review of classical reconstruction methods, NeRF, and 3DGS, analyzing their methodologies, applications, and performance.", "result": "Classical methods are flexible but face challenges like noise and scalability; NeRF offers photorealistic results but has high computational costs; 3DGS shows promise in efficiency and scalability.", "conclusion": "The review provides insights into leveraging these techniques for high-throughput plant phenotyping, contributing to future agricultural technology."}}
{"id": "2505.00745", "pdf": "https://arxiv.org/pdf/2505.00745", "abs": "https://arxiv.org/abs/2505.00745", "authors": ["Maozhe Zhao", "Shengzhong Liu", "Fan Wu", "Guihai Chen"], "title": "Responsive DNN Adaptation for Video Analytics against Environment Shift via Hierarchical Mobile-Cloud Collaborations", "categories": ["cs.CV", "cs.LG"], "comment": "Sensys 2025 final version", "summary": "Mobile video analysis systems often encounter various deploying environments,\nwhere environment shifts present greater demands for responsiveness in\nadaptations of deployed \"expert DNN models\". Existing model adaptation\nframeworks primarily operate in a cloud-centric way, exhibiting degraded\nperformance during adaptation and delayed reactions to environment shifts.\nInstead, this paper proposes MOCHA, a novel framework optimizing the\nresponsiveness of continuous model adaptation through hierarchical\ncollaborations between mobile and cloud resources. Specifically, MOCHA (1)\nreduces adaptation response delays by performing on-device model reuse and fast\nfine-tuning before requesting cloud model retrieval and end-to-end retraining;\n(2) accelerates history expert model retrieval by organizing them into a\nstructured taxonomy utilizing domain semantics analyzed by a cloud foundation\nmodel as indices; (3) enables efficient local model reuse by maintaining\nonboard expert model caches for frequent scenes, which proactively prefetch\nmodel weights from the cloud model database. Extensive evaluations with\nreal-world videos on three DNN tasks show MOCHA improves the model accuracy\nduring adaptation by up to 6.8% while saving the response delay and retraining\ntime by up to 35.5x and 3.0x respectively.", "AI": {"tldr": "MOCHA is a framework for mobile video analysis that improves responsiveness and accuracy in model adaptation by leveraging hierarchical mobile-cloud collaboration.", "motivation": "Existing cloud-centric model adaptation frameworks suffer from performance degradation and delayed reactions to environment shifts in mobile video analysis.", "method": "MOCHA optimizes responsiveness through on-device model reuse, fast fine-tuning, structured taxonomy for model retrieval, and proactive caching of expert models.", "result": "MOCHA improves model accuracy by up to 6.8%, reduces response delay by 35.5x, and cuts retraining time by 3.0x.", "conclusion": "MOCHA effectively addresses the limitations of cloud-centric frameworks, enhancing mobile video analysis performance."}}
{"id": "2505.00931", "pdf": "https://arxiv.org/pdf/2505.00931", "abs": "https://arxiv.org/abs/2505.00931", "authors": ["Timur Jaganov", "John Blake", "Juli\u00e1n Villegas", "Nicholas Carr"], "title": "Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing", "categories": ["cs.CL", "cs.AI"], "comment": "15 pages, 8 Figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "This study investigates the potential for Large Language Models (LLMs) to\nscale-up Dynamic Assessment (DA). To facilitate such an investigation, we first\ndeveloped DynaWrite-a modular, microservices-based grammatical tutoring\napplication which supports multiple LLMs to generate dynamic feedback to\nlearners of English. Initial testing of 21 LLMs, revealed GPT-4o and neural\nchat to have the most potential to scale-up DA in the language learning\nclassroom. Further testing of these two candidates found both models performed\nsimilarly in their ability to accurately identify grammatical errors in user\nsentences. However, GPT-4o consistently outperformed neural chat in the quality\nof its DA by generating clear, consistent, and progressively explicit hints.\nReal-time responsiveness and system stability were also confirmed through\ndetailed performance testing, with GPT-4o exhibiting sufficient speed and\nstability. This study shows that LLMs can be used to scale-up dynamic\nassessment and thus enable dynamic assessment to be delivered to larger groups\nthan possible in traditional teacher-learner settings.", "AI": {"tldr": "LLMs like GPT-4o and Neural Chat can scale Dynamic Assessment (DA) in language learning, with GPT-4o excelling in feedback quality and system performance.", "motivation": "To explore the potential of LLMs in scaling Dynamic Assessment (DA) for language learning, enabling broader application beyond traditional teacher-learner settings.", "method": "Developed DynaWrite, a modular tutoring app supporting multiple LLMs, tested 21 models, and evaluated top candidates (GPT-4o and Neural Chat) for error identification and feedback quality.", "result": "GPT-4o outperformed Neural Chat in feedback quality (clear, consistent hints) and system performance (speed, stability), though both identified errors similarly.", "conclusion": "LLMs, particularly GPT-4o, can effectively scale DA, making it feasible for larger groups in language learning."}}
{"id": "2503.12623", "pdf": "https://arxiv.org/pdf/2503.12623", "abs": "https://arxiv.org/abs/2503.12623", "authors": ["Vrushank Ahire", "Kunal Shah", "Mudasir Nazir Khan", "Nikhil Pakhale", "Lownish Rai Sookha", "M. A. Ganaie", "Abhinav Dhall"], "title": "MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM"], "comment": null, "summary": "Dynamic emotion recognition in the wild remains challenging due to the\ntransient nature of emotional expressions and temporal misalignment of\nmulti-modal cues. Traditional approaches predict valence and arousal and often\noverlook the inherent correlation between these two dimensions. The proposed\nMulti-modal Attention for Valence-Arousal Emotion Network (MAVEN) integrates\nvisual, audio, and textual modalities through a bi-directional cross-modal\nattention mechanism. MAVEN uses modality-specific encoders to extract features\nfrom synchronized video frames, audio segments, and transcripts, predicting\nemotions in polar coordinates following Russell's circumplex model. The\nevaluation of the Aff-Wild2 dataset using MAVEN achieved a concordance\ncorrelation coefficient (CCC) of 0.3061, surpassing the ResNet-50 baseline\nmodel with a CCC of 0.22. The multistage architecture captures the subtle and\ntransient nature of emotional expressions in conversational videos and improves\nemotion recognition in real-world situations. The code is available at:\nhttps://github.com/Vrushank-Ahire/MAVEN_8th_ABAW", "AI": {"tldr": "MAVEN improves dynamic emotion recognition by integrating multi-modal cues with a bi-directional cross-modal attention mechanism, outperforming baseline models.", "motivation": "Dynamic emotion recognition is challenging due to transient expressions and misaligned multi-modal cues. Traditional methods ignore correlations between valence and arousal.", "method": "MAVEN uses visual, audio, and textual modalities with modality-specific encoders and a bi-directional cross-modal attention mechanism, predicting emotions in polar coordinates.", "result": "MAVEN achieved a CCC of 0.3061 on Aff-Wild2, surpassing the ResNet-50 baseline (CCC 0.22).", "conclusion": "MAVEN captures transient emotional expressions and improves real-world emotion recognition, with code publicly available."}}
{"id": "2504.16276", "pdf": "https://arxiv.org/pdf/2504.16276", "abs": "https://arxiv.org/abs/2504.16276", "authors": ["Abhishek Jana", "Moeumu Uili", "James Atherton", "Mark O'Brien", "Joe Wood", "Leandra Brickson"], "title": "An Automated Pipeline for Few-Shot Bird Call Classification: A Case Study with the Tooth-Billed Pigeon", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.SD"], "comment": "16 pages, 5 figures, 4 tables", "summary": "This paper presents an automated one-shot bird call classification pipeline\ndesigned for rare species absent from large publicly available classifiers like\nBirdNET and Perch. While these models excel at detecting common birds with\nabundant training data, they lack options for species with only 1-3 known\nrecordings-a critical limitation for conservationists monitoring the last\nremaining individuals of endangered birds. To address this, we leverage the\nembedding space of large bird classification networks and develop a classifier\nusing cosine similarity, combined with filtering and denoising preprocessing\ntechniques, to optimize detection with minimal training data. We evaluate\nvarious embedding spaces using clustering metrics and validate our approach in\nboth a simulated scenario with Xeno-Canto recordings and a real-world test on\nthe critically endangered tooth-billed pigeon (Didunculus strigirostris), which\nhas no existing classifiers and only three confirmed recordings. The final\nmodel achieved 1.0 recall and 0.95 accuracy in detecting tooth-billed pigeon\ncalls, making it practical for use in the field. This open-source system\nprovides a practical tool for conservationists seeking to detect and monitor\nrare species on the brink of extinction.", "AI": {"tldr": "An automated one-shot bird call classification pipeline for rare species, achieving high accuracy with minimal training data.", "motivation": "Existing classifiers lack support for rare species with few recordings, hindering conservation efforts.", "method": "Leverages embedding spaces of large bird classifiers, uses cosine similarity, and applies preprocessing for optimization.", "result": "Achieved 1.0 recall and 0.95 accuracy in detecting calls of the critically endangered tooth-billed pigeon.", "conclusion": "The system is a practical, open-source tool for monitoring rare and endangered bird species."}}
{"id": "2502.13574", "pdf": "https://arxiv.org/pdf/2502.13574", "abs": "https://arxiv.org/abs/2502.13574", "authors": ["Ching-Hua Lee", "Chouchang Yang", "Jaejin Cho", "Yashas Malur Saidutta", "Rakshith Sharma Srinivasa", "Yilin Shen", "Hongxia Jin"], "title": "RestoreGrad: Signal Restoration Using Conditional Denoising Diffusion Models with Jointly Learned Prior", "categories": ["eess.IV", "cs.LG", "eess.AS"], "comment": "Accepted by ICML 2025", "summary": "Denoising diffusion probabilistic models (DDPMs) can be utilized for\nrecovering a clean signal from its degraded observation(s) by conditioning the\nmodel on the degraded signal. The degraded signals are themselves contaminated\nversions of the clean signals; due to this correlation, they may encompass\ncertain useful information about the target clean data distribution. However,\nexisting adoption of the standard Gaussian as the prior distribution in turn\ndiscards such information, resulting in sub-optimal performance. In this paper,\nwe propose to improve conditional DDPMs for signal restoration by leveraging a\nmore informative prior that is jointly learned with the diffusion model. The\nproposed framework, called RestoreGrad, seamlessly integrates DDPMs into the\nvariational autoencoder framework and exploits the correlation between the\ndegraded and clean signals to encode a better diffusion prior. On speech and\nimage restoration tasks, we show that RestoreGrad demonstrates faster\nconvergence (5-10 times fewer training steps) to achieve better quality of\nrestored signals over existing DDPM baselines, and improved robustness to using\nfewer sampling steps in inference time (2-2.5 times fewer), advocating the\nadvantages of leveraging jointly learned prior for efficiency improvements in\nthe diffusion process.", "AI": {"tldr": "RestoreGrad improves conditional DDPMs for signal restoration by using a learned prior, achieving faster convergence and better results.", "motivation": "Existing DDPMs discard useful information from degraded signals due to their Gaussian prior, leading to sub-optimal performance.", "method": "RestoreGrad integrates DDPMs into a variational autoencoder framework, learning a joint prior to exploit degraded-clean signal correlation.", "result": "RestoreGrad shows 5-10x faster convergence, better restoration quality, and 2-2.5x fewer sampling steps than baselines.", "conclusion": "Jointly learned priors enhance efficiency and performance in diffusion-based signal restoration."}}
{"id": "2505.00875", "pdf": "https://arxiv.org/pdf/2505.00875", "abs": "https://arxiv.org/abs/2505.00875", "authors": ["Ramesh Manuvinakurike", "Emanuel Moss", "Elizabeth Anne Watkins", "Saurav Sahay", "Giuseppe Raffa", "Lama Nachman"], "title": "Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines", "categories": ["cs.AI"], "comment": null, "summary": "Agentic pipelines present novel challenges and opportunities for\nhuman-centered explainability. The HCXAI community is still grappling with how\nbest to make the inner workings of LLMs transparent in actionable ways. Agentic\npipelines consist of multiple LLMs working in cooperation with minimal human\ncontrol. In this research paper, we present early findings from an agentic\npipeline implementation of a perceptive task guidance system. Through\nquantitative and qualitative analysis, we analyze how Chain-of-Thought (CoT)\nreasoning, a common vehicle for explainability in LLMs, operates within agentic\npipelines. We demonstrate that CoT reasoning alone does not lead to better\noutputs, nor does it offer explainability, as it tends to produce explanations\nwithout explainability, in that they do not improve the ability of end users to\nbetter understand systems or achieve their goals.", "AI": {"tldr": "Agentic pipelines challenge explainability in LLMs; CoT reasoning lacks effectiveness in improving outputs or user understanding.", "motivation": "To address the transparency and explainability challenges in agentic pipelines involving multiple LLMs.", "method": "Implementation of a perceptive task guidance system with quantitative and qualitative analysis of CoT reasoning.", "result": "CoT reasoning fails to enhance outputs or provide meaningful explainability for end users.", "conclusion": "Current CoT approaches in agentic pipelines are insufficient for actionable explainability."}}
{"id": "2505.00810", "pdf": "https://arxiv.org/pdf/2505.00810", "abs": "https://arxiv.org/abs/2505.00810", "authors": ["Jordi de la Torre"], "title": "Scalable Unit Harmonization in Medical Informatics Using Bi-directional Transformers and Bayesian-Optimized BM25 and Sentence Embedding Retrieval", "categories": ["cs.LG"], "comment": null, "summary": "Objective: To develop and evaluate a scalable methodology for harmonizing\ninconsistent units in large-scale clinical datasets, addressing a key barrier\nto data interoperability.\n  Materials and Methods: We designed a novel unit harmonization system\ncombining BM25, sentence embeddings, Bayesian optimization, and a bidirectional\ntransformer based binary classifier for retrieving and matching laboratory test\nentries. The system was evaluated using the Optum Clinformatics Datamart\ndataset (7.5 billion entries). We implemented a multi-stage pipeline:\nfiltering, identification, harmonization proposal generation, automated\nre-ranking, and manual validation. Performance was assessed using Mean\nReciprocal Rank (MRR) and other standard information retrieval metrics.\n  Results: Our hybrid retrieval approach combining BM25 and sentence embeddings\n(MRR: 0.8833) significantly outperformed both lexical-only (MRR: 0.7985) and\nembedding-only (MRR: 0.5277) approaches. The transformer-based reranker further\nimproved performance (absolute MRR improvement: 0.10), bringing the final\nsystem MRR to 0.9833. The system achieved 83.39\\% precision at rank 1 and\n94.66\\% recall at rank 5.\n  Discussion: The hybrid architecture effectively leverages the complementary\nstrengths of lexical and semantic approaches. The reranker addresses cases\nwhere initial retrieval components make errors due to complex semantic\nrelationships in medical terminology.\n  Conclusion: Our framework provides an efficient, scalable solution for unit\nharmonization in clinical datasets, reducing manual effort while improving\naccuracy. Once harmonized, data can be reused seamlessly in different analyses,\nensuring consistency across healthcare systems and enabling more reliable\nmulti-institutional studies and meta-analyses.", "AI": {"tldr": "A scalable methodology combining BM25, sentence embeddings, Bayesian optimization, and a transformer-based classifier was developed for harmonizing inconsistent units in clinical datasets, achieving high accuracy and efficiency.", "motivation": "To address the challenge of data interoperability in large-scale clinical datasets by harmonizing inconsistent units, enabling seamless data reuse and reliable multi-institutional studies.", "method": "A multi-stage pipeline involving filtering, identification, harmonization proposal generation, automated re-ranking, and manual validation, using a hybrid approach of BM25 and sentence embeddings with a transformer-based reranker.", "result": "The hybrid approach (MRR: 0.8833) outperformed lexical-only (0.7985) and embedding-only (0.5277) methods, with the reranker further improving MRR to 0.9833. Precision at rank 1 was 83.39%, and recall at rank 5 was 94.66%.", "conclusion": "The framework provides an efficient, scalable solution for unit harmonization, reducing manual effort and improving accuracy, ensuring consistent data reuse across healthcare systems."}}
{"id": "2505.00738", "pdf": "https://arxiv.org/pdf/2505.00738", "abs": "https://arxiv.org/abs/2505.00738", "authors": ["Yuxi Li", "Lu Si", "Yujie Hou", "Chengaung Liu", "Bin Li", "Hongjian Fang", "Jun Zhang"], "title": "XeMap: Contextual Referring in Large-Scale Remote Sensing Environments", "categories": ["eess.IV", "cs.LG"], "comment": "14 pages, 8 figures", "summary": "Advancements in remote sensing (RS) imagery have provided high-resolution\ndetail and vast coverage, yet existing methods, such as image-level\ncaptioning/retrieval and object-level detection/segmentation, often fail to\ncapture mid-scale semantic entities essential for interpreting large-scale\nscenes. To address this, we propose the conteXtual referring Map (XeMap) task,\nwhich focuses on contextual, fine-grained localization of text-referred regions\nin large-scale RS scenes. Unlike traditional approaches, XeMap enables precise\nmapping of mid-scale semantic entities that are often overlooked in image-level\nor object-level methods. To achieve this, we introduce XeMap-Network, a novel\narchitecture designed to handle the complexities of pixel-level cross-modal\ncontextual referring mapping in RS. The network includes a fusion layer that\napplies self- and cross-attention mechanisms to enhance the interaction between\ntext and image embeddings. Furthermore, we propose a Hierarchical Multi-Scale\nSemantic Alignment (HMSA) module that aligns multiscale visual features with\nthe text semantic vector, enabling precise multimodal matching across\nlarge-scale RS imagery. To support XeMap task, we provide a novel, annotated\ndataset, XeMap-set, specifically tailored for this task, overcoming the lack of\nXeMap datasets in RS imagery. XeMap-Network is evaluated in a zero-shot setting\nagainst state-of-the-art methods, demonstrating superior performance. This\nhighlights its effectiveness in accurately mapping referring regions and\nproviding valuable insights for interpreting large-scale RS environments.", "AI": {"tldr": "The paper introduces XeMap, a task for contextual, fine-grained localization of text-referred regions in remote sensing imagery, and proposes XeMap-Network with a fusion layer and HMSA module for precise mapping.", "motivation": "Existing methods in remote sensing often miss mid-scale semantic entities, limiting scene interpretation. XeMap addresses this gap.", "method": "Proposes XeMap-Network with self- and cross-attention mechanisms and a HMSA module for multimodal alignment.", "result": "XeMap-Network outperforms state-of-the-art methods in zero-shot settings, demonstrating superior performance.", "conclusion": "XeMap effectively maps referring regions, enhancing interpretation of large-scale remote sensing environments."}}
{"id": "2505.00746", "pdf": "https://arxiv.org/pdf/2505.00746", "abs": "https://arxiv.org/abs/2505.00746", "authors": ["Alexei Kaltchenko"], "title": "Entropy Heat-Mapping: Localizing GPT-Based OCR Errors with Sliding-Window Shannon Analysis", "categories": ["cs.CV"], "comment": "22 pages", "summary": "Vision-language models such as OpenAI GPT-4o can transcribe mathematical\ndocuments directly from images, yet their token-level confidence signals are\nseldom used to pinpoint local recognition mistakes. We present an\nentropy-heat-mapping proof-of-concept that turns per-token Shannon entropy into\na visual ''uncertainty landscape''. By scanning the entropy sequence with a\nfixed-length sliding window, we obtain hotspots that are likely to contain OCR\nerrors such as missing symbols, mismatched braces, or garbled prose. Using a\nsmall, curated set of scanned research pages rendered at several resolutions,\nwe compare the highlighted hotspots with the actual transcription errors\nproduced by GPT-4o. Our analysis shows that the vast majority of true errors\nare indeed concentrated inside the high-entropy regions. This study\ndemonstrates--in a minimally engineered setting--that sliding-window entropy\ncan serve as a practical, lightweight aid for post-editing GPT-based OCR. All\ncode, sample data, and annotation guidelines are released to encourage\nreplication and further research.", "AI": {"tldr": "A method using entropy-heat-mapping to identify OCR errors in GPT-4o transcriptions by analyzing token-level confidence signals.", "motivation": "Vision-language models like GPT-4o lack effective use of token-level confidence signals to detect local OCR errors.", "method": "Entropy-heat-mapping converts per-token Shannon entropy into a visual uncertainty landscape, scanned with a sliding window to identify error hotspots.", "result": "Most true errors in GPT-4o transcriptions are concentrated in high-entropy regions.", "conclusion": "Sliding-window entropy is a lightweight, practical tool for post-editing GPT-based OCR, with open resources for replication."}}
{"id": "2505.00949", "pdf": "https://arxiv.org/pdf/2505.00949", "abs": "https://arxiv.org/abs/2505.00949", "authors": ["Akhiad Bercovich", "Itay Levy", "Izik Golan", "Mohammad Dabbah", "Ran El-Yaniv", "Omri Puny", "Ido Galil", "Zach Moshe", "Tomer Ronen", "Najeeb Nabwani", "Ido Shahaf", "Oren Tropp", "Ehud Karpas", "Ran Zilberstein", "Jiaqi Zeng", "Soumye Singhal", "Alexander Bukharin", "Yian Zhang", "Tugrul Konuk", "Gerald Shen", "Ameya Sunil Mahabaleshwarkar", "Bilal Kartal", "Yoshi Suhara", "Olivier Delalleau", "Zijia Chen", "Zhilin Wang", "David Mosallanezhad", "Adi Renduchintala", "Haifeng Qian", "Dima Rekesh", "Fei Jia", "Somshubra Majumdar", "Vahid Noroozi", "Wasi Uddin Ahmad", "Sean Narenthiran", "Aleksander Ficek", "Mehrzad Samadi", "Jocelyn Huang", "Siddhartha Jain", "Igor Gitman", "Ivan Moshkov", "Wei Du", "Shubham Toshniwal", "George Armstrong", "Branislav Kisacanin", "Matvei Novikov", "Daria Gitman", "Evelina Bakhturina", "Jane Polak Scowcroft", "John Kamalu", "Dan Su", "Kezhi Kong", "Markus Kliegl", "Rabeeh Karimi", "Ying Lin", "Sanjeev Satheesh", "Jupinder Parmar", "Pritam Gundecha", "Brandon Norick", "Joseph Jennings", "Shrimai Prabhumoye", "Syeda Nahida Akter", "Mostofa Patwary", "Abhinav Khattar", "Deepak Narayanan", "Roger Waleffe", "Jimmy Zhang", "Bor-Yiing Su", "Guyue Huang", "Terry Kong", "Parth Chadha", "Sahil Jain", "Christine Harvey", "Elad Segal", "Jining Huang", "Sergey Kashirsky", "Robert McQueen", "Izzy Putterman", "George Lam", "Arun Venkatesan", "Sherry Wu", "Vinh Nguyen", "Manoj Kilaru", "Andrew Wang", "Anna Warno", "Abhilash Somasamudramath", "Sandip Bhaskar", "Maka Dong", "Nave Assaf", "Shahar Mor", "Omer Ullman Argov", "Scot Junkin", "Oleksandr Romanenko", "Pedro Larroy", "Monika Katariya", "Marco Rovinelli", "Viji Balas", "Nicholas Edelman", "Anahita Bhiwandiwalla", "Muthu Subramaniam", "Smita Ithape", "Karthik Ramamoorthy", "Yuting Wu", "Suguna Varshini Velury", "Omri Almog", "Joyjit Daw", "Denys Fridman", "Erick Galinkin", "Michael Evans", "Katherine Luna", "Leon Derczynski", "Nikki Pope", "Eileen Long", "Seth Schneider", "Guillermo Siman", "Tomasz Grzegorzek", "Pablo Ribalta", "Monika Katariya", "Joey Conway", "Trisha Saar", "Ann Guan", "Krzysztof Pawelec", "Shyamala Prayaga", "Oleksii Kuchaiev", "Boris Ginsburg", "Oluwatobi Olabiyi", "Kari Briski", "Jonathan Cohen", "Bryan Catanzaro", "Jonah Alben", "Yonatan Geifman", "Eric Chung"], "title": "Llama-Nemotron: Efficient Reasoning Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce the Llama-Nemotron series of models, an open family of\nheterogeneous reasoning models that deliver exceptional reasoning capabilities,\ninference efficiency, and an open license for enterprise use. The family comes\nin three sizes -- Nano (8B), Super (49B), and Ultra (253B) -- and performs\ncompetitively with state-of-the-art reasoning models such as DeepSeek-R1 while\noffering superior inference throughput and memory efficiency. In this report,\nwe discuss the training procedure for these models, which entails using neural\narchitecture search from Llama 3 models for accelerated inference, knowledge\ndistillation, and continued pretraining, followed by a reasoning-focused\npost-training stage consisting of two main parts: supervised fine-tuning and\nlarge scale reinforcement learning. Llama-Nemotron models are the first\nopen-source models to support a dynamic reasoning toggle, allowing users to\nswitch between standard chat and reasoning modes during inference. To further\nsupport open research and facilitate model development, we provide the\nfollowing resources: 1. We release the Llama-Nemotron reasoning models --\nLN-Nano, LN-Super, and LN-Ultra -- under the commercially permissive NVIDIA\nOpen Model License Agreement. 2. We release the complete post-training dataset:\nLlama-Nemotron-Post-Training-Dataset. 3. We also release our training\ncodebases: NeMo, NeMo-Aligner, and Megatron-LM.", "AI": {"tldr": "The Llama-Nemotron series offers open, heterogeneous reasoning models with competitive performance, efficiency, and a dynamic reasoning toggle. Three sizes are available, trained via neural architecture search, distillation, and reinforcement learning. Resources include models, datasets, and codebases.", "motivation": "To provide open-source, high-performance reasoning models with enterprise-friendly licensing and superior efficiency.", "method": "Training involves neural architecture search, knowledge distillation, continued pretraining, supervised fine-tuning, and large-scale reinforcement learning.", "result": "Models (Nano, Super, Ultra) compete with state-of-the-art reasoning models while offering better throughput and memory efficiency.", "conclusion": "Llama-Nemotron models advance open research with commercially permissive licensing and released resources (models, datasets, codebases)."}}
{"id": "2505.00056", "pdf": "https://arxiv.org/pdf/2505.00056", "abs": "https://arxiv.org/abs/2505.00056", "authors": ["Tygo Bloem", "Filip Ilievski"], "title": "Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.MM"], "comment": null, "summary": "Meme clustering is critical for toxicity detection, virality modeling, and\ntyping, but it has received little attention in previous research. Clustering\nsimilar Internet memes is challenging due to their multimodality, cultural\ncontext, and adaptability. Existing approaches rely on databases, overlook\nsemantics, and struggle to handle diverse dimensions of similarity. This paper\nintroduces a novel method that uses template-based matching with\nmulti-dimensional similarity features, thus eliminating the need for predefined\ndatabases and supporting adaptive matching. Memes are clustered using local and\nglobal features across similarity categories such as form, visual content,\ntext, and identity. Our combined approach outperforms existing clustering\nmethods, producing more consistent and coherent clusters, while\nsimilarity-based feature sets enable adaptability and align with human\nintuition. We make all supporting code publicly available to support subsequent\nresearch.", "AI": {"tldr": "A novel method for clustering memes using template-based matching and multi-dimensional similarity features, outperforming existing methods.", "motivation": "Meme clustering is understudied despite its importance for toxicity detection and virality modeling, with existing methods lacking adaptability and semantic understanding.", "method": "Uses template-based matching with multi-dimensional similarity features (form, visual content, text, identity) to cluster memes without predefined databases.", "result": "Outperforms existing clustering methods, producing more consistent and coherent clusters aligned with human intuition.", "conclusion": "The method supports adaptive matching and eliminates the need for databases, with code made publicly available for further research."}}
{"id": "2505.00876", "pdf": "https://arxiv.org/pdf/2505.00876", "abs": "https://arxiv.org/abs/2505.00876", "authors": ["Sahar Torkhesari", "Behnam Yousefimehr", "Mehdi Ghatee"], "title": "Car Sensors Health Monitoring by Verification Based on Autoencoder and Random Forest Regression", "categories": ["cs.AI", "cs.LG", "68T05", "I.2.1"], "comment": "9Pages, 3 Figures and 5 Tables", "summary": "Driver assistance systems provide a wide range of crucial services, including\nclosely monitoring the condition of vehicles. This paper showcases a\ngroundbreaking sensor health monitoring system designed for the automotive\nindustry. The ingenious system leverages cutting-edge techniques to process\ndata collected from various vehicle sensors. It compares their outputs within\nthe Electronic Control Unit (ECU) to evaluate the health of each sensor. To\nunravel the intricate correlations between sensor data, an extensive\nexploration of machine learning and deep learning methodologies was conducted.\nThrough meticulous analysis, the most correlated sensor data were identified.\nThese valuable insights were then utilized to provide accurate estimations of\nsensor values. Among the diverse learning methods examined, the combination of\nautoencoders for detecting sensor failures and random forest regression for\nestimating sensor values proved to yield the most impressive outcomes. A\nstatistical model using the normal distribution has been developed to identify\npossible sensor failures proactively. By comparing the actual values of the\nsensors with their estimated values based on correlated sensors, faulty sensors\ncan be detected early. When a defective sensor is detected, both the driver and\nthe maintenance department are promptly alerted. Additionally, the system\nreplaces the value of the faulty sensor with the estimated value obtained\nthrough analysis. This proactive approach was evaluated using data from twenty\nessential sensors in the Saipa's Quick vehicle's ECU, resulting in an\nimpressive accuracy rate of 99\\%.", "AI": {"tldr": "A sensor health monitoring system for vehicles uses machine learning and deep learning to detect and estimate sensor failures with 99% accuracy.", "motivation": "To enhance vehicle safety and maintenance by proactively monitoring sensor health in driver assistance systems.", "method": "Combines autoencoders for failure detection and random forest regression for value estimation, using correlated sensor data.", "result": "Achieved 99% accuracy in detecting and estimating sensor failures in Saipa's Quick vehicle.", "conclusion": "The system effectively identifies and mitigates sensor failures, improving vehicle reliability and safety."}}
{"id": "2505.00812", "pdf": "https://arxiv.org/pdf/2505.00812", "abs": "https://arxiv.org/abs/2505.00812", "authors": ["Kuan Zhang", "Chengliang Chai", "Jingzhe Xu", "Chi Zhang", "Ye Yuan", "Guoren Wang", "Lei Cao"], "title": "Handling Label Noise via Instance-Level Difficulty Modeling and Dynamic Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent studies indicate that deep neural networks degrade in generalization\nperformance under noisy supervision. Existing methods focus on isolating clean\nsubsets or correcting noisy labels, facing limitations such as high\ncomputational costs, heavy hyperparameter tuning process, and coarse-grained\noptimization. To address these challenges, we propose a novel two-stage noisy\nlearning framework that enables instance-level optimization through a\ndynamically weighted loss function, avoiding hyperparameter tuning. To obtain\nstable and accurate information about noise modeling, we introduce a simple yet\neffective metric, termed wrong event, which dynamically models the cleanliness\nand difficulty of individual samples while maintaining computational costs. Our\nframework first collects wrong event information and builds a strong base\nmodel. Then we perform noise-robust training on the base model, using a\nprobabilistic model to handle the wrong event information of samples.\nExperiments on five synthetic and real-world LNL benchmarks demonstrate our\nmethod surpasses state-of-the-art methods in performance, achieves a nearly 75%\nreduction in computational time and improves model scalability.", "AI": {"tldr": "A novel two-stage noisy learning framework improves generalization in deep neural networks by dynamically modeling sample cleanliness and difficulty, reducing computational time by 75%.", "motivation": "Deep neural networks degrade under noisy supervision, and existing methods are computationally expensive or require heavy tuning.", "method": "A two-stage framework with a dynamically weighted loss function and a 'wrong event' metric for noise modeling, followed by noise-robust training.", "result": "Outperforms state-of-the-art methods, reduces computational time by 75%, and improves scalability.", "conclusion": "The proposed framework effectively addresses noisy supervision challenges with efficiency and performance gains."}}
{"id": "2505.01239", "pdf": "https://arxiv.org/pdf/2505.01239", "abs": "https://arxiv.org/abs/2505.01239", "authors": ["Elena Mulero Ayll\u00f3n", "Massimiliano Mantegna", "Linlin Shen", "Paolo Soda", "Valerio Guarrasi", "Matteo Tortora"], "title": "Can Foundation Models Really Segment Tumors? A Benchmarking Odyssey in Lung CT Imaging", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Accurate lung tumor segmentation is crucial for improving diagnosis,\ntreatment planning, and patient outcomes in oncology. However, the complexity\nof tumor morphology, size, and location poses significant challenges for\nautomated segmentation. This study presents a comprehensive benchmarking\nanalysis of deep learning-based segmentation models, comparing traditional\narchitectures such as U-Net and DeepLabV3, self-configuring models like nnUNet,\nand foundation models like MedSAM, and MedSAM~2. Evaluating performance across\ntwo lung tumor segmentation datasets, we assess segmentation accuracy and\ncomputational efficiency under various learning paradigms, including few-shot\nlearning and fine-tuning. The results reveal that while traditional models\nstruggle with tumor delineation, foundation models, particularly MedSAM~2,\noutperform them in both accuracy and computational efficiency. These findings\nunderscore the potential of foundation models for lung tumor segmentation,\nhighlighting their applicability in improving clinical workflows and patient\noutcomes.", "AI": {"tldr": "Benchmarking deep learning models for lung tumor segmentation shows foundation models like MedSAM~2 outperform traditional methods in accuracy and efficiency.", "motivation": "Accurate lung tumor segmentation is vital for oncology but challenging due to tumor complexity.", "method": "Comparative analysis of deep learning models (U-Net, DeepLabV3, nnUNet, MedSAM, MedSAM~2) on lung tumor datasets, evaluating accuracy and efficiency under few-shot learning and fine-tuning.", "result": "Foundation models, especially MedSAM~2, surpass traditional models in segmentation accuracy and computational efficiency.", "conclusion": "Foundation models like MedSAM~2 hold promise for enhancing clinical workflows and patient outcomes in lung tumor segmentation."}}
{"id": "2505.00751", "pdf": "https://arxiv.org/pdf/2505.00751", "abs": "https://arxiv.org/abs/2505.00751", "authors": ["Xingxi Yin", "Jingfeng Zhang", "Zhi Li", "Yicheng Li", "Yin Zhang"], "title": "InstructAttribute: Fine-grained Object Attributes editing with Instruction", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image (T2I) diffusion models, renowned for their advanced generative\nabilities, are extensively utilized in image editing applications,\ndemonstrating remarkable effectiveness. However, achieving precise control over\nfine-grained attributes still presents considerable challenges. Existing image\nediting techniques either fail to modify the attributes of an object or\nstruggle to preserve its structure and maintain consistency in other areas of\nthe image. To address these challenges, we propose the Structure-Preserving and\nAttribute Amplification (SPAA), a training-free method which enables precise\ncontrol over the color and material transformations of objects by editing the\nself-attention maps and cross-attention values. Furthermore, we constructed the\nAttribute Dataset, which encompasses nearly all colors and materials associated\nwith various objects, by integrating multimodal large language models (MLLM) to\ndevelop an automated pipeline for data filtering and instruction labeling.\nTraining on this dataset, we present our InstructAttribute, an\ninstruction-based model designed to facilitate fine-grained editing of color\nand material attributes. Extensive experiments demonstrate that our method\nachieves superior performance in object-level color and material editing,\noutperforming existing instruction-based image editing approaches.", "AI": {"tldr": "The paper introduces SPAA, a training-free method for precise color and material editing in T2I diffusion models, and InstructAttribute, an instruction-based model trained on a new Attribute Dataset.", "motivation": "Existing image editing techniques lack precision in modifying fine-grained attributes while preserving object structure and image consistency.", "method": "Proposes SPAA for editing self-attention and cross-attention maps, and constructs an Attribute Dataset using MLLMs for automated labeling. Introduces InstructAttribute for instruction-based editing.", "result": "SPAA and InstructAttribute outperform existing methods in fine-grained color and material editing.", "conclusion": "The proposed methods enable precise, structure-preserving attribute editing, advancing T2I model capabilities."}}
{"id": "2505.00977", "pdf": "https://arxiv.org/pdf/2505.00977", "abs": "https://arxiv.org/abs/2505.00977", "authors": ["Yingquan Chen", "Qianmu Li", "Xiaocong Wu", "Huifeng Li", "Qing Chang"], "title": "A Character-based Diffusion Embedding Algorithm for Enhancing the Generation Quality of Generative Linguistic Steganographic Texts", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "Generating high-quality steganographic text is a fundamental challenge in the\nfield of generative linguistic steganography. This challenge arises primarily\nfrom two aspects: firstly, the capabilities of existing models in text\ngeneration are limited; secondly, embedding algorithms fail to effectively\nmitigate the negative impacts of sensitive information's properties, such as\nsemantic content or randomness. Specifically, to ensure that the recipient can\naccurately extract hidden information, embedding algorithms often have to\nconsider selecting candidate words with relatively low probabilities. This\nphenomenon leads to a decrease in the number of high-probability candidate\nwords and an increase in low-probability candidate words, thereby compromising\nthe semantic coherence and logical fluency of the steganographic text and\ndiminishing the overall quality of the generated steganographic material. To\naddress this issue, this paper proposes a novel embedding algorithm,\ncharacter-based diffusion embedding algorithm (CDEA). Unlike existing embedding\nalgorithms that strive to eliminate the impact of sensitive information's\nproperties on the generation process, CDEA leverages sensitive information's\nproperties. It enhances the selection frequency of high-probability candidate\nwords in the candidate pool based on general statistical properties at the\ncharacter level and grouping methods based on power-law distributions, while\nreducing the selection frequency of low-probability candidate words in the\ncandidate pool. Furthermore, to ensure the effective transformation of\nsensitive information in long sequences, we also introduce the XLNet model.\nExperimental results demonstrate that the combination of CDEA and XLNet\nsignificantly improves the quality of generated steganographic text,\nparticularly in terms of perceptual-imperceptibility.", "AI": {"tldr": "The paper proposes a character-based diffusion embedding algorithm (CDEA) and integrates XLNet to improve steganographic text quality by leveraging sensitive information properties and enhancing high-probability word selection.", "motivation": "Existing models and embedding algorithms struggle with generating high-quality steganographic text due to limitations in text generation and ineffective mitigation of sensitive information's negative impacts.", "method": "Introduces CDEA, which leverages sensitive information properties and character-level statistical properties to enhance high-probability word selection, combined with XLNet for long sequences.", "result": "The combination of CDEA and XLNet significantly improves steganographic text quality, especially perceptual-imperceptibility.", "conclusion": "The proposed approach effectively addresses the challenges in generative linguistic steganography by improving text coherence and fluency."}}
{"id": "2505.00972", "pdf": "https://arxiv.org/pdf/2505.00972", "abs": "https://arxiv.org/abs/2505.00972", "authors": ["Yuewen Mei", "Tong Nie", "Jian Sun", "Ye Tian"], "title": "Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Simulation-based testing is crucial for validating autonomous vehicles (AVs),\nyet existing scenario generation methods either overfit to common driving\npatterns or operate in an offline, non-interactive manner that fails to expose\nrare, safety-critical corner cases. In this paper, we introduce an online,\nretrieval-augmented large language model (LLM) framework for generating\nsafety-critical driving scenarios. Our method first employs an LLM-based\nbehavior analyzer to infer the most dangerous intent of the background vehicle\nfrom the observed state, then queries additional LLM agents to synthesize\nfeasible adversarial trajectories. To mitigate catastrophic forgetting and\naccelerate adaptation, we augment the framework with a dynamic memorization and\nretrieval bank of intent-planner pairs, automatically expanding its behavioral\nlibrary when novel intents arise. Evaluations using the Waymo Open Motion\nDataset demonstrate that our model reduces the mean minimum time-to-collision\nfrom 1.62 to 1.08 s and incurs a 75% collision rate, substantially\noutperforming baselines.", "AI": {"tldr": "An online, retrieval-augmented LLM framework generates safety-critical driving scenarios for AVs, outperforming baselines by reducing collision risks.", "motivation": "Existing scenario generation methods overfit common patterns or lack interactivity, missing rare safety-critical cases.", "method": "Uses an LLM-based behavior analyzer to infer dangerous intents, then queries LLM agents for adversarial trajectories, augmented with a dynamic memorization-retrieval bank.", "result": "Reduces mean minimum time-to-collision from 1.62 to 1.08 s and achieves a 75% collision rate, outperforming baselines.", "conclusion": "The framework effectively generates safety-critical scenarios, improving AV testing."}}
{"id": "2505.00818", "pdf": "https://arxiv.org/pdf/2505.00818", "abs": "https://arxiv.org/abs/2505.00818", "authors": ["Heng-Sheng Chang", "Prashant G. Mehta"], "title": "Dual Filter: A Mathematical Framework for Inference using Transformer-like Architectures", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.PR"], "comment": "49 pages, 6 figures", "summary": "This paper presents a mathematical framework for causal nonlinear prediction\nin settings where observations are generated from an underlying hidden Markov\nmodel (HMM). Both the problem formulation and the proposed solution are\nmotivated by the decoder-only transformer architecture, in which a finite\nsequence of observations (tokens) is mapped to the conditional probability of\nthe next token. Our objective is not to construct a mathematical model of a\ntransformer. Rather, our interest lies in deriving, from first principles,\ntransformer-like architectures that solve the prediction problem for which the\ntransformer is designed. The proposed framework is based on an original optimal\ncontrol approach, where the prediction objective (MMSE) is reformulated as an\noptimal control problem. An analysis of the optimal control problem is\npresented leading to a fixed-point equation on the space of probability\nmeasures. To solve the fixed-point equation, we introduce the dual filter, an\niterative algorithm that closely parallels the architecture of decoder-only\ntransformers. These parallels are discussed in detail along with the\nrelationship to prior work on mathematical modeling of transformers as\ntransport on the space of probability measures. Numerical experiments are\nprovided to illustrate the performance of the algorithm using parameter values\nused in researchscale transformer models.", "AI": {"tldr": "A mathematical framework for causal nonlinear prediction in HMM settings, inspired by decoder-only transformers, is proposed. It uses optimal control to reformulate prediction as a fixed-point problem, solved by the dual filter algorithm, which parallels transformer architectures.", "motivation": "To derive transformer-like architectures from first principles for solving prediction problems, rather than modeling transformers directly.", "method": "Reformulates prediction as an optimal control problem, leading to a fixed-point equation solved by the dual filter algorithm.", "result": "The dual filter algorithm parallels transformer architectures and is validated through numerical experiments.", "conclusion": "The framework provides a principled derivation of transformer-like architectures for prediction, with connections to prior work on probability measure transport."}}
{"id": "2505.01299", "pdf": "https://arxiv.org/pdf/2505.01299", "abs": "https://arxiv.org/abs/2505.01299", "authors": ["\u0110or\u0111e D. Ne\u0161kovi\u0107", "Kristina Stojmenova Pe\u010de\u010dnik", "Jaka Sodnik", "Nadica Miljkovi\u0107"], "title": "Contactless pulse rate assessment: Results and insights for application in driving simulator", "categories": ["eess.IV", "eess.SP"], "comment": "6 figures and one table", "summary": "Camera-based monitoring of Pulse Rate (PR) enables continuous and unobtrusive\nassessment of driver's state, allowing estimation of fatigue or stress that\ncould impact traffic safety. Commonly used wearable Photoplethysmography (PPG)\nsensors, while effective, suffer from motion artifacts and user discomfort.\nThis study explores the feasibility of non-contact PR assessment using facial\nvideo recordings captured by a Red, Green, and Blue (RGB) camera in a driving\nsimulation environment. The proposed approach detects subtle skin color\nvariations due to blood flow and compares extracted PR values against reference\nmeasurements from a wearable wristband Empatica E4. We evaluate the impact of\nEulerian Video Magnification (EVM) on signal quality and assess statistical\ndifferences in PR between age groups. Data obtained from 80 recordings from 64\nhealthy subjects covering a PR range of 45-160 bpm are analyzed, and signal\nextraction accuracy is quantified using metrics, such as Mean Absolute Error\n(MAE) and Root Mean Square Error (RMSE). Results show that EVM slightly\nimproves PR estimation accuracy, reducing MAE from 6.48 bpm to 5.04 bpm and\nRMSE from 7.84 bpm to 6.38 bpm. A statistically significant difference is found\nbetween older and younger groups with both video-based and ground truth\nevaluation procedures. Additionally, we discuss Empatica E4 bias and its\npotential impact on the overall assessment of contact measurements. Altogether\nthe findings demonstrate the feasibility of camera-based PR monitoring in\ndynamic environments and its potential integration into driving simulators for\nreal-time physiological assessment.", "AI": {"tldr": "The study explores non-contact pulse rate (PR) monitoring using facial video recordings in a driving simulation, comparing it to wearable PPG sensors. Results show improved accuracy with Eulerian Video Magnification (EVM) and highlight age-related PR differences.", "motivation": "To enable unobtrusive, continuous PR monitoring for driver state assessment (e.g., fatigue or stress) without the drawbacks of wearable sensors like motion artifacts and discomfort.", "method": "Uses facial video recordings from an RGB camera to detect skin color variations for PR estimation, validated against wearable Empatica E4. Evaluates EVM's impact on signal quality and compares age groups.", "result": "EVM improves PR accuracy (MAE: 6.48 to 5.04 bpm; RMSE: 7.84 to 6.38 bpm). Significant PR differences between age groups are found. Empatica E4 bias is noted.", "conclusion": "Camera-based PR monitoring is feasible in dynamic environments, with potential for real-time integration into driving simulators."}}
{"id": "2505.00752", "pdf": "https://arxiv.org/pdf/2505.00752", "abs": "https://arxiv.org/abs/2505.00752", "authors": ["Xuzhao Li", "Xuchen Li", "Shiyu Hu"], "title": "DARTer: Dynamic Adaptive Representation Tracker for Nighttime UAV Tracking", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICMR 2025", "summary": "Nighttime UAV tracking presents significant challenges due to extreme\nillumination variations and viewpoint changes, which severely degrade tracking\nperformance. Existing approaches either rely on light enhancers with high\ncomputational costs or introduce redundant domain adaptation mechanisms,\nfailing to fully utilize the dynamic features in varying perspectives. To\naddress these issues, we propose \\textbf{DARTer} (\\textbf{D}ynamic\n\\textbf{A}daptive \\textbf{R}epresentation \\textbf{T}racker), an end-to-end\ntracking framework designed for nighttime UAV scenarios. DARTer leverages a\nDynamic Feature Blender (DFB) to effectively fuse multi-perspective nighttime\nfeatures from static and dynamic templates, enhancing representation\nrobustness. Meanwhile, a Dynamic Feature Activator (DFA) adaptively activates\nVision Transformer layers based on extracted features, significantly improving\nefficiency by reducing redundant computations. Our model eliminates the need\nfor complex multi-task loss functions, enabling a streamlined training process.\nExtensive experiments on multiple nighttime UAV tracking benchmarks demonstrate\nthe superiority of DARTer over state-of-the-art trackers. These results confirm\nthat DARTer effectively balances tracking accuracy and efficiency, making it a\npromising solution for real-world nighttime UAV tracking applications.", "AI": {"tldr": "DARTer is an end-to-end tracking framework for nighttime UAV scenarios, using Dynamic Feature Blender and Activator to improve robustness and efficiency.", "motivation": "Addressing challenges like illumination variations and viewpoint changes in nighttime UAV tracking, where existing methods are computationally costly or inefficient.", "method": "Proposes DARTer with Dynamic Feature Blender (DFB) for feature fusion and Dynamic Feature Activator (DFA) for adaptive layer activation in Vision Transformers.", "result": "Outperforms state-of-the-art trackers on nighttime UAV benchmarks, balancing accuracy and efficiency.", "conclusion": "DARTer is a promising solution for real-world nighttime UAV tracking due to its robustness and streamlined training."}}
{"id": "2505.00979", "pdf": "https://arxiv.org/pdf/2505.00979", "abs": "https://arxiv.org/abs/2505.00979", "authors": ["Xuhui Jiang", "Shengjie Ma", "Chengjin Xu", "Cehao Yang", "Liyu Zhang", "Jian Guo"], "title": "Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success but remain\ndata-inefficient, especially when learning from small, specialized corpora with\nlimited and proprietary data. Existing synthetic data generation methods for\ncontinue pre-training focus on intra-document content and overlook\ncross-document knowledge associations, limiting content diversity and depth. We\npropose Synthetic-on-Graph (SoG), a synthetic data generation framework that\nincorporates cross-document knowledge associations for efficient corpus\nexpansion. SoG constructs a context graph by extracting entities and concepts\nfrom the original corpus, representing cross-document associations, and\nemploying a graph walk strategy for knowledge-associated sampling. This\nenhances synthetic data diversity and coherence, enabling models to learn\ncomplex knowledge structures and handle rare knowledge. To further improve\nsynthetic data quality, we integrate Chain-of-Thought (CoT) and Contrastive\nClarifying (CC) synthetic, enhancing reasoning processes and discriminative\npower. Experiments show that SoG outperforms the state-of-the-art (SOTA) method\nin a multi-hop document Q&A dataset while performing comparably to the SOTA\nmethod on the reading comprehension task datasets, which also underscores the\nbetter generalization capability of SoG. Our work advances synthetic data\ngeneration and provides practical solutions for efficient knowledge acquisition\nin LLMs, especially in domains with limited data availability.", "AI": {"tldr": "SoG is a synthetic data generation framework that enhances LLM training by incorporating cross-document knowledge associations, improving diversity and coherence.", "motivation": "LLMs struggle with data inefficiency in specialized corpora, and existing methods lack cross-document knowledge associations.", "method": "SoG constructs a context graph for cross-document associations and uses graph walks for sampling, integrating CoT and CC for quality.", "result": "SoG outperforms SOTA in multi-hop Q&A and matches SOTA in reading comprehension, showing better generalization.", "conclusion": "SoG advances synthetic data generation, offering efficient knowledge acquisition for LLMs in data-limited domains."}}
{"id": "2505.01009", "pdf": "https://arxiv.org/pdf/2505.01009", "abs": "https://arxiv.org/abs/2505.01009", "authors": ["Xinran Zhao", "Hanie Sedghi", "Bernd Bohnet", "Dale Schuurmans", "Azade Nova"], "title": "Improving Large Language Model Planning with Action Sequence Similarity", "categories": ["cs.AI"], "comment": "25 pages, 11 figures", "summary": "Planning is essential for artificial intelligence systems to look ahead and\nproactively determine a course of actions to reach objectives in the virtual\nand real world. Recent work on large language models (LLMs) sheds light on\ntheir planning capability in various tasks. However, it remains unclear what\nsignals in the context influence the model performance. In this work, we\nexplore how to improve the model planning capability through in-context\nlearning (ICL), specifically, what signals can help select the exemplars.\nThrough extensive experiments, we observe that commonly used problem similarity\nmay result in false positives with drastically different plans, which can\nmislead the model. In response, we propose to sample and filter exemplars\nleveraging plan side action sequence similarity (AS). We propose GRASE-DC: a\ntwo-stage pipeline that first re-samples high AS exemplars and then curates the\nselected exemplars with dynamic clustering on AS to achieve a balance of\nrelevance and diversity. Our experimental result confirms that GRASE-DC\nachieves significant performance improvement on various planning tasks (up to\n~11-40 point absolute accuracy improvement with 27.3% fewer exemplars needed on\naverage). With GRASE-DC* + VAL, where we iteratively apply GRASE-DC with a\nvalidator, we are able to even boost the performance by 18.9% more.\n  Extensive analysis validates the consistent performance improvement of\nGRASE-DC with various backbone LLMs and on both classical planning and natural\nlanguage planning benchmarks. GRASE-DC can further boost the planning accuracy\nby ~24 absolute points on harder problems using simpler problems as exemplars\nover a random baseline. This demonstrates its ability to generalize to\nout-of-distribution problems.", "AI": {"tldr": "The paper explores improving LLM planning via in-context learning, proposing GRASE-DC for exemplar selection based on action sequence similarity, achieving significant accuracy gains.", "motivation": "Understanding what signals in context influence LLM planning performance and improving it through better exemplar selection.", "method": "Proposes GRASE-DC, a two-stage pipeline: re-sampling high AS exemplars and dynamic clustering for relevance and diversity.", "result": "GRASE-DC improves planning accuracy by 11-40 points, needing 27.3% fewer exemplars. GRASE-DC* + VAL boosts performance by 18.9%.", "conclusion": "GRASE-DC effectively enhances LLM planning, generalizing to out-of-distribution problems with consistent improvements across benchmarks."}}
{"id": "2505.00823", "pdf": "https://arxiv.org/pdf/2505.00823", "abs": "https://arxiv.org/abs/2505.00823", "authors": ["Qianxi Fu", "Youngjoon Suh", "Xiaojing Zhang", "Yoonjin Won"], "title": "Data-Driven Optical To Thermal Inference in Pool Boiling Using Generative Adversarial Networks", "categories": ["cs.LG", "physics.app-ph"], "comment": "17 pages, 5 figures, supplemental information", "summary": "Phase change plays a critical role in thermal management systems, yet\nquantitative characterization of multiphase heat transfer remains limited by\nthe challenges of measuring temperature fields in chaotic, rapidly evolving\nflow regimes. While computational methods offer spatiotemporal resolution in\nidealized cases, replicating complex experimental conditions remains\nprohibitively difficult. Here, we present a data-driven framework that\nleverages a conditional generative adversarial network (CGAN) to infer\ntemperature fields from geometric phase contours in a canonical pool boiling\nconfiguration where advanced data collection techniques are restricted. Using\nhigh-speed imaging data and simulation-informed training, our model\ndemonstrates the ability to reconstruct temperature fields with errors below\n6%. We further show that standard data augmentation strategies are effective in\nenhancing both accuracy and physical plausibility of the predicted maps across\nboth simulation and experimental datasets when precise physical constraints are\nnot applicable. Our results highlight the potential of deep generative models\nto bridge the gap between observable multiphase phenomena and underlying\nthermal transport, offering a powerful approach to augment and interpret\nexperimental measurements in complex two-phase systems.", "AI": {"tldr": "A data-driven framework using CGANs infers temperature fields from phase contours in pool boiling, achieving <6% error and demonstrating the potential of deep generative models for thermal transport analysis.", "motivation": "Quantitative characterization of multiphase heat transfer is limited by challenges in measuring temperature fields in chaotic flows, and computational methods struggle with complex experimental conditions.", "method": "A conditional generative adversarial network (CGAN) is trained with high-speed imaging data and simulation to reconstruct temperature fields from geometric phase contours.", "result": "The model achieves temperature field reconstruction with errors below 6%, and data augmentation enhances accuracy and plausibility.", "conclusion": "Deep generative models can bridge the gap between observable multiphase phenomena and thermal transport, augmenting experimental measurements in complex systems."}}
{"id": "2505.01388", "pdf": "https://arxiv.org/pdf/2505.01388", "abs": "https://arxiv.org/abs/2505.01388", "authors": ["Wallace Peaslee", "Anna Breger", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Potential Contrast: Properties, Equivalences, and Generalization to Multiple Classes", "categories": ["eess.IV", "math.ST", "stat.TH"], "comment": null, "summary": "Potential contrast is typically used as an image quality measure and\nquantifies the maximal possible contrast between samples from two classes of\npixels in an image after an arbitrary grayscale transformation. It has been\nvaluable in cultural heritage applications, identifying and visualizing\nrelevant information in multispectral images while requiring a small number of\npixels to be manually sampled. In this work, we introduce a normalized version\nof potential contrast that removes dependence on image format and also prove\nequalities that enable generalization to more than two classes and to\ncontinuous settings. Finally, we exemplify the utility of multi-class\nnormalized potential contrast through an application to a medieval music\nmanuscript with visible bleedthrough from the back page. We share our\nimplementations, based on both original algorithms and our new equalities,\nincluding generalization to multiple classes, at\nhttps://github.com/wallacepeaslee/Multiple-Class-Normalized-Potential-Contrast.", "AI": {"tldr": "The paper introduces a normalized version of potential contrast, generalizes it to multiple classes and continuous settings, and demonstrates its utility in analyzing a medieval music manuscript.", "motivation": "Potential contrast is useful for image quality and cultural heritage applications but lacks normalization and multi-class generalization.", "method": "The authors propose a normalized potential contrast, prove equalities for generalization, and apply it to a manuscript.", "result": "The normalized potential contrast removes format dependence and works for multi-class and continuous cases.", "conclusion": "The method is validated with a practical application, and implementations are shared for broader use."}}
{"id": "2505.00755", "pdf": "https://arxiv.org/pdf/2505.00755", "abs": "https://arxiv.org/abs/2505.00755", "authors": ["Atsuya Watanabe", "Ratna Aisuwarya", "Lei Jing"], "title": "P2P-Insole: Human Pose Estimation Using Foot Pressure Distribution and Motion Sensors", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This work presents P2P-Insole, a low-cost approach for estimating and\nvisualizing 3D human skeletal data using insole-type sensors integrated with\nIMUs. Each insole, fabricated with e-textile garment techniques, costs under\nUSD 1, making it significantly cheaper than commercial alternatives and ideal\nfor large-scale production. Our approach uses foot pressure distribution,\nacceleration, and rotation data to overcome limitations, providing a\nlightweight, minimally intrusive, and privacy-aware solution. The system\nemploys a Transformer model for efficient temporal feature extraction, enriched\nby first and second derivatives in the input stream. Including multimodal\ninformation, such as accelerometers and rotational measurements, improves the\naccuracy of complex motion pattern recognition. These facts are demonstrated\nexperimentally, while error metrics show the robustness of the approach in\nvarious posture estimation tasks. This work could be the foundation for a\nlow-cost, practical application in rehabilitation, injury prevention, and\nhealth monitoring while enabling further development through sensor\noptimization and expanded datasets.", "AI": {"tldr": "P2P-Insole is a low-cost, 3D human skeletal estimation system using e-textile insoles with IMUs, costing under USD 1. It leverages foot pressure, acceleration, and rotation data with a Transformer model for accurate motion recognition.", "motivation": "To provide a cost-effective, lightweight, and privacy-aware solution for 3D skeletal estimation, addressing the high cost and intrusiveness of commercial alternatives.", "method": "Uses insole-type sensors with IMUs, fabricated via e-textile techniques. A Transformer model processes temporal features, enhanced by derivatives and multimodal data (accelerometers, rotation).", "result": "Demonstrates robustness in posture estimation tasks with improved accuracy for complex motion patterns, validated experimentally.", "conclusion": "P2P-Insole offers a scalable, low-cost solution for rehabilitation, injury prevention, and health monitoring, with potential for further optimization."}}
{"id": "2505.00985", "pdf": "https://arxiv.org/pdf/2505.00985", "abs": "https://arxiv.org/abs/2505.00985", "authors": ["Ayan Sengupta", "Yash Goel", "Tanmoy Chakraborty"], "title": "Position: Enough of Scaling LLMs! Lets Focus on Downscaling", "categories": ["cs.CL"], "comment": null, "summary": "We challenge the dominant focus on neural scaling laws and advocate for a\nparadigm shift toward downscaling in the development of large language models\n(LLMs). While scaling laws have provided critical insights into performance\nimprovements through increasing model and dataset size, we emphasize the\nsignificant limitations of this approach, particularly in terms of\ncomputational inefficiency, environmental impact, and deployment constraints.\nTo address these challenges, we propose a holistic framework for downscaling\nLLMs that seeks to maintain performance while drastically reducing resource\ndemands. This paper outlines practical strategies for transitioning away from\ntraditional scaling paradigms, advocating for a more sustainable, efficient,\nand accessible approach to LLM development.", "AI": {"tldr": "Advocates for downscaling LLMs over neural scaling laws to address inefficiency, environmental impact, and deployment issues.", "motivation": "Challenges the focus on scaling laws due to computational inefficiency, environmental concerns, and deployment constraints.", "method": "Proposes a holistic framework for downscaling LLMs to reduce resource demands while maintaining performance.", "result": "Introduces practical strategies for sustainable and efficient LLM development.", "conclusion": "Calls for a paradigm shift toward downscaling for more accessible and sustainable LLM development."}}
{"id": "2505.01028", "pdf": "https://arxiv.org/pdf/2505.01028", "abs": "https://arxiv.org/abs/2505.01028", "authors": ["Huy Q. Ngo", "Mingyu Guo", "Hung Nguyen"], "title": "Adaptive Wizard for Removing Cross-Tier Misconfigurations in Active Directory", "categories": ["cs.AI", "cs.CR"], "comment": "To be appear in IJCAI 2025", "summary": "Security vulnerabilities in Windows Active Directory (AD) systems are\ntypically modeled using an attack graph and hardening AD systems involves an\niterative workflow: security teams propose an edge to remove, and IT operations\nteams manually review these fixes before implementing the removal. As\nverification requires significant manual effort, we formulate an Adaptive Path\nRemoval Problem to minimize the number of steps in this iterative removal\nprocess. In our model, a wizard proposes an attack path in each step and\npresents it as a set of multiple-choice options to the IT admin. The IT admin\nthen selects one edge from the proposed set to remove. This process continues\nuntil the target $t$ is disconnected from source $s$ or the number of proposed\npaths reaches $B$. The model aims to optimize the human effort by minimizing\nthe expected number of interactions between the IT admin and the security\nwizard. We first prove that the problem is $\\mathcal{\\#P}$-hard. We then\npropose a set of solutions including an exact algorithm, an approximate\nalgorithm, and several scalable heuristics. Our best heuristic, called DPR, can\noperate effectively on larger-scale graphs compared to the exact algorithm and\nconsistently outperforms the approximate algorithm across all graphs. We verify\nthe effectiveness of our algorithms on several synthetic AD graphs and an AD\nattack graph collected from a real organization.", "AI": {"tldr": "The paper introduces an Adaptive Path Removal Problem to minimize manual effort in hardening Windows AD systems by optimizing interactions between IT admins and a security wizard.", "motivation": "Manual verification of security fixes in AD systems is labor-intensive, prompting the need for an automated, efficient solution.", "method": "Formulates the problem, proves its complexity, and proposes exact, approximate, and heuristic algorithms (including DPR).", "result": "DPR outperforms other methods, scaling well on large graphs and real-world AD attack graphs.", "conclusion": "The approach effectively reduces human effort in securing AD systems, with DPR being the most scalable and efficient solution."}}
{"id": "2505.00830", "pdf": "https://arxiv.org/pdf/2505.00830", "abs": "https://arxiv.org/abs/2505.00830", "authors": ["Joe Germino", "Nuno Moniz", "Nitesh V. Chawla"], "title": "Intersectional Divergence: Measuring Fairness in Regression", "categories": ["cs.LG"], "comment": null, "summary": "Research on fairness in machine learning has been mainly framed in the\ncontext of classification tasks, leaving critical gaps in regression. In this\npaper, we propose a seminal approach to measure intersectional fairness in\nregression tasks, going beyond the focus on single protected attributes from\nexisting work to consider combinations of all protected attributes.\nFurthermore, we contend that it is insufficient to measure the average error of\ngroups without regard for imbalanced domain preferences. To this end, we\npropose Intersectional Divergence (ID) as the first fairness measure for\nregression tasks that 1) describes fair model behavior across multiple\nprotected attributes and 2) differentiates the impact of predictions in target\nranges most relevant to users. We extend our proposal demonstrating how ID can\nbe adapted into a loss function, IDLoss, and used in optimization problems.\nThrough an extensive experimental evaluation, we demonstrate how ID allows\nunique insights into model behavior and fairness, and how incorporating IDLoss\ninto optimization can considerably improve single-attribute and intersectional\nmodel fairness while maintaining a competitive balance in predictive\nperformance.", "AI": {"tldr": "The paper introduces Intersectional Divergence (ID), a fairness measure for regression tasks, addressing gaps in existing work by considering multiple protected attributes and domain preferences. It also proposes IDLoss for optimization, improving fairness without compromising predictive performance.", "motivation": "Existing fairness research focuses on classification, neglecting regression tasks and intersectional fairness. The paper aims to bridge these gaps by considering multiple protected attributes and domain-specific preferences.", "method": "The authors propose Intersectional Divergence (ID) to measure fairness in regression, extending it to IDLoss for optimization. Experiments evaluate ID's insights and IDLoss's impact on fairness and performance.", "result": "ID provides unique fairness insights, and IDLoss improves both single-attribute and intersectional fairness while maintaining predictive performance.", "conclusion": "The paper successfully addresses regression fairness gaps with ID and IDLoss, demonstrating their effectiveness in balancing fairness and performance."}}
{"id": "2505.00805", "pdf": "https://arxiv.org/pdf/2505.00805", "abs": "https://arxiv.org/abs/2505.00805", "authors": ["Fadi Abdeladhim Zidi", "Abdelkrim Ouafi", "Fares Bougourzi", "Cosimo Distante", "Abdelmalik Taleb-Ahmed"], "title": "Advancing Wheat Crop Analysis: A Survey of Deep Learning Approaches Using Hyperspectral Imaging", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "As one of the most widely cultivated and consumed crops, wheat is essential\nto global food security. However, wheat production is increasingly challenged\nby pests, diseases, climate change, and water scarcity, threatening yields.\nTraditional crop monitoring methods are labor-intensive and often ineffective\nfor early issue detection. Hyperspectral imaging (HSI) has emerged as a\nnon-destructive and efficient technology for remote crop health assessment.\nHowever, the high dimensionality of HSI data and limited availability of\nlabeled samples present notable challenges. In recent years, deep learning has\nshown great promise in addressing these challenges due to its ability to\nextract and analysis complex structures. Despite advancements in applying deep\nlearning methods to HSI data for wheat crop analysis, no comprehensive survey\ncurrently exists in this field. This review addresses this gap by summarizing\nbenchmark datasets, tracking advancements in deep learning methods, and\nanalyzing key applications such as variety classification, disease detection,\nand yield estimation. It also highlights the strengths, limitations, and future\nopportunities in leveraging deep learning methods for HSI-based wheat crop\nanalysis. We have listed the current state-of-the-art papers and will continue\ntracking updating them in the following\nhttps://github.com/fadi-07/Awesome-Wheat-HSI-DeepLearning.", "AI": {"tldr": "A review of deep learning methods for hyperspectral imaging (HSI) in wheat crop analysis, covering datasets, advancements, and applications like disease detection and yield estimation.", "motivation": "Wheat production faces challenges like pests and climate change, requiring efficient monitoring. HSI and deep learning offer solutions but lack a comprehensive survey.", "method": "Summarizes benchmark datasets and tracks deep learning advancements for HSI-based wheat analysis.", "result": "Identifies key applications (e.g., disease detection) and highlights strengths, limitations, and future opportunities.", "conclusion": "The review fills a gap in the field and provides a resource for ongoing research, with updates tracked on GitHub."}}
{"id": "2505.00757", "pdf": "https://arxiv.org/pdf/2505.00757", "abs": "https://arxiv.org/abs/2505.00757", "authors": ["Woong-Chan Byun", "Dong-Hee Paek", "Seung-Hyun Song", "Seung-Hyun Kong"], "title": "Efficient On-Chip Implementation of 4D Radar-Based 3D Object Detection on Hailo-8L", "categories": ["cs.CV", "cs.AI"], "comment": "4pages, 2 figures", "summary": "4D radar has attracted attention in autonomous driving due to its ability to\nenable robust 3D object detection even under adverse weather conditions. To\npractically deploy such technologies, it is essential to achieve real-time\nprocessing within low-power embedded environments. Addressing this, we present\nthe first on-chip implementation of a 4D radar-based 3D object detection model\non the Hailo-8L AI accelerator. Although conventional 3D convolutional neural\nnetwork (CNN) architectures require 5D inputs, the Hailo-8L only supports 4D\ntensors, posing a significant challenge. To overcome this limitation, we\nintroduce a tensor transformation method that reshapes 5D inputs into 4D\nformats during the compilation process, enabling direct deployment without\naltering the model structure. The proposed system achieves 46.47% AP_3D and\n52.75% AP_BEV, maintaining comparable accuracy to GPU-based models while\nachieving an inference speed of 13.76 Hz. These results demonstrate the\napplicability of 4D radar-based perception technologies to autonomous driving\nsystems.", "AI": {"tldr": "First on-chip implementation of 4D radar-based 3D object detection on Hailo-8L AI accelerator, overcoming 5D input limitations with tensor transformation, achieving real-time performance and comparable accuracy to GPUs.", "motivation": "Enable robust 3D object detection in autonomous driving under adverse weather conditions, requiring real-time processing in low-power embedded environments.", "method": "Introduces a tensor transformation method to reshape 5D inputs into 4D formats for deployment on Hailo-8L, which only supports 4D tensors.", "result": "Achieves 46.47% AP_3D and 52.75% AP_BEV with 13.76 Hz inference speed, matching GPU accuracy.", "conclusion": "Demonstrates practical applicability of 4D radar-based perception for autonomous driving systems."}}
{"id": "2505.00989", "pdf": "https://arxiv.org/pdf/2505.00989", "abs": "https://arxiv.org/abs/2505.00989", "authors": ["Sijin Sun", "Liangbin Zhao", "Ming Deng", "Xiuju Fu"], "title": "VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel Traffic Services through Natural Language", "categories": ["cs.CL"], "comment": "8 pages, 5 figures, 7 tablels, submitted to ITSC2025", "summary": "Vessel Traffic Services (VTS) are essential for maritime safety and\nregulatory compliance through real-time traffic management. However, with\nincreasing traffic complexity and the prevalence of heterogeneous, multimodal\ndata, existing VTS systems face limitations in spatiotemporal reasoning and\nintuitive human interaction. In this work, we propose VTS-LLM Agent, the first\ndomain-adaptive large LLM agent tailored for interactive decision support in\nVTS operations. We formalize risk-prone vessel identification as a\nknowledge-augmented Text-to-SQL task, combining structured vessel databases\nwith external maritime knowledge. To support this, we construct a curated\nbenchmark dataset consisting of a custom schema, domain-specific corpus, and a\nquery-SQL test set in multiple linguistic styles. Our framework incorporates\nNER-based relational reasoning, agent-based domain knowledge injection,\nsemantic algebra intermediate representation, and query rethink mechanisms to\nenhance domain grounding and context-aware understanding. Experimental results\nshow that VTS-LLM outperforms both general-purpose and SQL-focused baselines\nunder command-style, operational-style, and formal natural language queries,\nrespectively. Moreover, our analysis provides the first empirical evidence that\nlinguistic style variation introduces systematic performance challenges in\nText-to-SQL modeling. This work lays the foundation for natural language\ninterfaces in vessel traffic services and opens new opportunities for\nproactive, LLM-driven maritime real-time traffic management.", "AI": {"tldr": "VTS-LLM Agent, a domain-adaptive LLM, enhances VTS operations by combining structured vessel data with maritime knowledge for risk-prone vessel identification, outperforming baselines in diverse linguistic styles.", "motivation": "Existing VTS systems struggle with spatiotemporal reasoning and intuitive interaction due to increasing traffic complexity and heterogeneous data.", "method": "Formalizes risk-prone vessel identification as a knowledge-augmented Text-to-SQL task, using NER-based reasoning, domain knowledge injection, and semantic algebra.", "result": "VTS-LLM outperforms general-purpose and SQL-focused baselines across command-style, operational-style, and formal natural language queries.", "conclusion": "The work establishes a foundation for natural language interfaces in VTS and highlights linguistic style challenges in Text-to-SQL modeling."}}
{"id": "2505.01073", "pdf": "https://arxiv.org/pdf/2505.01073", "abs": "https://arxiv.org/abs/2505.01073", "authors": ["Zongyuan Li", "Pengfei Li", "Runnan Qi", "Yanan Ni", "Lumin Jiang", "Hui Wu", "Xuebo Zhang", "Kuihua Huang", "Xian Guo"], "title": "Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation", "categories": ["cs.AI"], "comment": null, "summary": "The lack of domain-specific data in the pre-training of Large Language Models\n(LLMs) severely limits LLM-based decision systems in specialized applications,\nwhile post-training a model in the scenarios requires significant computational\nresources. In this paper, we present Retrial-Augmented Learning (RAL), a\nreward-free self-supervised learning framework for LLMs that operates without\nmodel training. By developing Retrieval-Augmented Generation (RAG) into a\nmodule for organizing intermediate data, we realized a three-stage autonomous\nknowledge generation of proposing a hypothesis, validating the hypothesis, and\ngenerating the knowledge. The method is evaluated in the LLM-PySC2 environment,\na representative decision-making platform that combines sufficient complexity\nwith domain-specific knowledge requirements. Experiments demonstrate that the\nproposed method effectively reduces hallucination by generating and utilizing\nvalidated knowledge, and increases decision-making performance at an extremely\nlow cost. Meanwhile, the approach exhibits potential in\nout-of-distribution(OOD) tasks, robustness, and transferability, making it a\ncost-friendly but effective solution for decision-making problems and\nautonomous knowledge generation.", "AI": {"tldr": "Retrial-Augmented Learning (RAL) is a reward-free, self-supervised framework for LLMs that avoids training, using retrieval-augmented generation to reduce hallucination and improve decision-making at low cost.", "motivation": "Addressing the lack of domain-specific data in LLM pre-training and high computational costs of post-training for specialized applications.", "method": "RAL uses Retrieval-Augmented Generation (RAG) for autonomous knowledge generation in three stages: hypothesis proposal, validation, and knowledge generation, tested in the LLM-PySC2 environment.", "result": "RAL reduces hallucination, improves decision-making performance, and shows promise in OOD tasks, robustness, and transferability.", "conclusion": "RAL is a cost-effective solution for decision-making and autonomous knowledge generation in specialized domains."}}
{"id": "2505.00837", "pdf": "https://arxiv.org/pdf/2505.00837", "abs": "https://arxiv.org/abs/2505.00837", "authors": ["Julen Ercibengoa", "Meritxell G\u00f3mez-Omella", "Izaro Goienetxea"], "title": "IberFire -- a detailed creation of a spatio-temporal dataset for wildfire risk assessment in Spain", "categories": ["cs.LG"], "comment": null, "summary": "Wildfires pose a critical environmental issue to ecosystems, economies, and\npublic safety, particularly in Mediterranean regions such as Spain. Accurate\npredictive models rely on high-resolution spatio-temporal data to capture the\ncomplex interplay of environmental and anthropogenic factors. To address the\nlack of localised and fine-grained datasets in Spain, this work introduces\nIberFire, a spatio-temporal datacube at 1 km x 1 km x 1-day resolution covering\nmainland Spain and the Balearic Islands from December 2007 to December 2024.\nIberFire integrates 260 features across eight main categories: auxiliary\nfeatures, fire history, geography, topography, meteorology, vegetation indices,\nhuman activity, and land cover. All features are derived from open-access\nsources, ensuring transparency and real-time applicability. The data processing\npipeline was implemented entirely using open-source tools, and the codebase has\nbeen made publicly available. This work not only enhances spatio-temporal\ngranularity and feature diversity compared to existing European datacubes but\nalso provides a reproducible methodology for constructing similar datasets.\nIberFire supports advanced wildfire risk modelling through Machine Learning\n(ML) and Deep Learning (DL) techniques, enables climate pattern analysis and\ninforms strategic planning in fire prevention and land management. The dataset\nis publicly available on Zenodo to promote open research and collaboration.", "AI": {"tldr": "IberFire is a high-resolution spatio-temporal datacube for wildfire prediction in Spain, integrating 260 features from open-access sources to support ML/DL modeling and climate analysis.", "motivation": "Wildfires are a critical environmental issue in Mediterranean regions like Spain, but existing datasets lack localised and fine-grained data.", "method": "Developed IberFire, a 1 km x 1 km x 1-day resolution datacube with 260 features across eight categories, using open-source tools and open-access data.", "result": "IberFire enhances granularity and feature diversity, supports ML/DL techniques, and is publicly available on Zenodo.", "conclusion": "IberFire provides a reproducible, open-access dataset for wildfire risk modeling and strategic planning, fostering collaboration in research."}}
{"id": "2505.01079", "pdf": "https://arxiv.org/pdf/2505.01079", "abs": "https://arxiv.org/abs/2505.01079", "authors": ["Daneul Kim", "Jaeah Lee", "Jaesik Park"], "title": "Improving Editability in Image Generation with Layer-wise Memory", "categories": ["cs.CV", "eess.IV"], "comment": "CVPR 2025. Project page :\n  https://carpedkm.github.io/projects/improving_edit/index.html", "summary": "Most real-world image editing tasks require multiple sequential edits to\nachieve desired results. Current editing approaches, primarily designed for\nsingle-object modifications, struggle with sequential editing: especially with\nmaintaining previous edits along with adapting new objects naturally into the\nexisting content. These limitations significantly hinder complex editing\nscenarios where multiple objects need to be modified while preserving their\ncontextual relationships. We address this fundamental challenge through two key\nproposals: enabling rough mask inputs that preserve existing content while\nnaturally integrating new elements and supporting consistent editing across\nmultiple modifications. Our framework achieves this through layer-wise memory,\nwhich stores latent representations and prompt embeddings from previous edits.\nWe propose Background Consistency Guidance that leverages memorized latents to\nmaintain scene coherence and Multi-Query Disentanglement in cross-attention\nthat ensures natural adaptation to existing content. To evaluate our method, we\npresent a new benchmark dataset incorporating semantic alignment metrics and\ninteractive editing scenarios. Through comprehensive experiments, we\ndemonstrate superior performance in iterative image editing tasks with minimal\nuser effort, requiring only rough masks while maintaining high-quality results\nthroughout multiple editing steps.", "AI": {"tldr": "A framework for sequential image editing using rough masks and layer-wise memory to maintain coherence and adapt new elements naturally.", "motivation": "Current methods struggle with sequential edits, especially preserving previous changes and integrating new objects contextually.", "method": "Uses rough mask inputs, layer-wise memory for latent representations, Background Consistency Guidance, and Multi-Query Disentanglement in cross-attention.", "result": "Superior performance in iterative editing with minimal user effort, maintaining high-quality results across steps.", "conclusion": "The proposed framework effectively handles complex sequential edits, preserving context and coherence."}}
{"id": "2505.00759", "pdf": "https://arxiv.org/pdf/2505.00759", "abs": "https://arxiv.org/abs/2505.00759", "authors": ["Jiahui Chen", "Candace Ross", "Reyhane Askari-Hemmat", "Koustuv Sinha", "Melissa Hall", "Michal Drozdzal", "Adriana Romero-Soriano"], "title": "Multi-Modal Language Models as Text-to-Image Model Evaluators", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The steady improvements of text-to-image (T2I) generative models lead to slow\ndeprecation of automatic evaluation benchmarks that rely on static datasets,\nmotivating researchers to seek alternative ways to evaluate the T2I progress.\nIn this paper, we explore the potential of multi-modal large language models\n(MLLMs) as evaluator agents that interact with a T2I model, with the objective\nof assessing prompt-generation consistency and image aesthetics. We present\nMultimodal Text-to-Image Eval (MT2IE), an evaluation framework that iteratively\ngenerates prompts for evaluation, scores generated images and matches T2I\nevaluation of existing benchmarks with a fraction of the prompts used in\nexisting static benchmarks. Moreover, we show that MT2IE's prompt-generation\nconsistency scores have higher correlation with human judgment than scores\npreviously introduced in the literature. MT2IE generates prompts that are\nefficient at probing T2I model performance, producing the same relative T2I\nmodel rankings as existing benchmarks while using only 1/80th the number of\nprompts for evaluation.", "AI": {"tldr": "MT2IE is a framework using MLLMs to evaluate T2I models efficiently, matching benchmark results with far fewer prompts and better human correlation.", "motivation": "Static datasets for T2I evaluation are becoming outdated; MLLMs offer a dynamic alternative.", "method": "MT2IE iteratively generates prompts, scores images, and assesses prompt-generation consistency and aesthetics.", "result": "MT2IE achieves benchmark-equivalent rankings with 1/80th the prompts and higher human-judgment correlation.", "conclusion": "MT2IE provides a scalable, efficient alternative to static benchmarks for T2I evaluation."}}
{"id": "2505.01006", "pdf": "https://arxiv.org/pdf/2505.01006", "abs": "https://arxiv.org/abs/2505.01006", "authors": ["Sumit Mamtani", "Maitreya Sonawane", "Kanika Agarwal", "Nishanth Sanjeev"], "title": "Token-free Models for Sarcasm Detection", "categories": ["cs.CL"], "comment": null, "summary": "Tokenization is a foundational step in most natural language processing (NLP)\npipelines, yet it introduces challenges such as vocabulary mismatch and\nout-of-vocabulary issues. Recent work has shown that models operating directly\non raw text at the byte or character level can mitigate these limitations. In\nthis paper, we evaluate two token-free models, ByT5 and CANINE, on the task of\nsarcasm detection in both social media (Twitter) and non-social media (news\nheadlines) domains. We fine-tune and benchmark these models against token-based\nbaselines and state-of-the-art approaches. Our results show that ByT5-small and\nCANINE outperform token-based counterparts and achieve new state-of-the-art\nperformance, improving accuracy by 0.77% and 0.49% on the News Headlines and\nTwitter Sarcasm datasets, respectively. These findings underscore the potential\nof token-free models for robust NLP in noisy and informal domains such as\nsocial media.", "AI": {"tldr": "Token-free models (ByT5, CANINE) outperform token-based models in sarcasm detection, showing promise for noisy NLP tasks.", "motivation": "Address challenges like vocabulary mismatch and out-of-vocabulary issues in NLP tokenization by exploring token-free models.", "method": "Evaluate ByT5 and CANINE on sarcasm detection in social media (Twitter) and news headlines, comparing them to token-based models.", "result": "ByT5-small and CANINE achieve state-of-the-art performance, improving accuracy by 0.77% (news) and 0.49% (Twitter).", "conclusion": "Token-free models are effective for robust NLP in noisy, informal domains like social media."}}
{"id": "2505.01081", "pdf": "https://arxiv.org/pdf/2505.01081", "abs": "https://arxiv.org/abs/2505.01081", "authors": ["S\u00e9bastien Ferr\u00e9"], "title": "MADIL: An MDL-based Framework for Efficient Program Synthesis in the ARC Benchmark", "categories": ["cs.AI"], "comment": "54 pages", "summary": "Artificial Intelligence (AI) has achieved remarkable success in specialized\ntasks but struggles with efficient skill acquisition and generalization. The\nAbstraction and Reasoning Corpus (ARC) benchmark evaluates intelligence based\non minimal training requirements. While Large Language Models (LLMs) have\nrecently improved ARC performance, they rely on extensive pre-training and high\ncomputational costs. We introduce MADIL (MDL-based AI), a novel approach\nleveraging the Minimum Description Length (MDL) principle for efficient\ninductive learning. MADIL performs pattern-based decomposition, enabling\nstructured generalization. While its performance (7% at ArcPrize 2024) remains\nbelow LLM-based methods, it offers greater efficiency and interpretability.\nThis paper details MADIL's methodology, its application to ARC, and\nexperimental evaluations.", "AI": {"tldr": "MADIL, a new AI method using MDL for efficient learning, shows promise in ARC tasks but lags behind LLMs in performance while being more efficient and interpretable.", "motivation": "AI struggles with efficient skill acquisition and generalization, prompting the need for methods like MADIL to address these limitations.", "method": "MADIL leverages the Minimum Description Length (MDL) principle for pattern-based decomposition and structured generalization.", "result": "MADIL achieved 7% performance at ArcPrize 2024, below LLMs but with better efficiency and interpretability.", "conclusion": "MADIL offers a viable alternative to LLMs for ARC tasks, balancing performance with efficiency and interpretability."}}
{"id": "2505.00850", "pdf": "https://arxiv.org/pdf/2505.00850", "abs": "https://arxiv.org/abs/2505.00850", "authors": ["Xinlin Li", "Osama Hanna", "Christina Fragouli", "Suhas Diggavi"], "title": "ICQuant: Index Coding enables Low-bit LLM Quantization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid deployment of Large Language Models (LLMs) highlights the need for\nefficient low-bit post-training quantization (PTQ), due to their high memory\ncosts. A key challenge in weight quantization is the presence of outliers,\nwhich inflate quantization ranges and lead to large errors. While a number of\noutlier suppression techniques have been proposed, they either: fail to\neffectively shrink the quantization range, or incur (relatively) high bit\noverhead. In this paper, we present ICQuant, a novel framework that leverages\noutlier statistics to design an efficient index coding scheme for outlier-aware\nweight-only quantization. Compared to existing outlier suppression techniques\nrequiring $\\approx 1$ bit overhead to halve the quantization range, ICQuant\nrequires only $\\approx 0.3$ bits; a significant saving in extreme compression\nregimes (e.g., 2-3 bits per weight). ICQuant can be used on top of any existing\nquantizers to eliminate outliers, improving the quantization quality. Using\njust 2.3 bits per weight and simple scalar quantizers, ICQuant improves the\nzero-shot accuracy of the 2-bit Llama3-70B model by up to 130% and 150%\nrelative to QTIP and QuIP#; and it achieves comparable performance to the\nbest-known fine-tuned quantizer (PV-tuning) without fine-tuning.", "AI": {"tldr": "ICQuant is a novel framework for efficient outlier-aware weight-only quantization in LLMs, reducing bit overhead and improving accuracy.", "motivation": "Address the challenge of outliers in weight quantization, which inflate ranges and cause errors, without high bit overhead.", "method": "Leverages outlier statistics to design an index coding scheme for outlier-aware quantization, compatible with existing quantizers.", "result": "ICQuant requires only \u22480.3 bits to halve the quantization range, improving 2-bit Llama3-70B zero-shot accuracy by up to 130-150%.", "conclusion": "ICQuant outperforms existing outlier suppression techniques and matches fine-tuned quantizers without fine-tuning."}}
{"id": "2505.01212", "pdf": "https://arxiv.org/pdf/2505.01212", "abs": "https://arxiv.org/abs/2505.01212", "authors": ["Kaixuan Zhang", "Hu Wang", "Minxian Li", "Mingwu Ren", "Mao Ye", "Xiatian Zhu"], "title": "High Dynamic Range Novel View Synthesis with Single Exposure", "categories": ["cs.CV", "eess.IV"], "comment": "It has been accepted by ICML 2025", "summary": "High Dynamic Range Novel View Synthesis (HDR-NVS) aims to establish a 3D\nscene HDR model from Low Dynamic Range (LDR) imagery. Typically,\nmultiple-exposure LDR images are employed to capture a wider range of\nbrightness levels in a scene, as a single LDR image cannot represent both the\nbrightest and darkest regions simultaneously. While effective, this\nmultiple-exposure HDR-NVS approach has significant limitations, including\nsusceptibility to motion artifacts (e.g., ghosting and blurring), high capture\nand storage costs. To overcome these challenges, we introduce, for the first\ntime, the single-exposure HDR-NVS problem, where only single exposure LDR\nimages are available during training. We further introduce a novel approach,\nMono-HDR-3D, featuring two dedicated modules formulated by the LDR image\nformation principles, one for converting LDR colors to HDR counterparts, and\nthe other for transforming HDR images to LDR format so that unsupervised\nlearning is enabled in a closed loop. Designed as a meta-algorithm, our\napproach can be seamlessly integrated with existing NVS models. Extensive\nexperiments show that Mono-HDR-3D significantly outperforms previous methods.\nSource code will be released.", "AI": {"tldr": "The paper introduces Mono-HDR-3D, a novel approach for single-exposure HDR-NVS, overcoming limitations of multiple-exposure methods like motion artifacts and high costs.", "motivation": "Addressing the limitations of multiple-exposure HDR-NVS, such as motion artifacts and high capture/storage costs, by proposing a single-exposure solution.", "method": "Introduces Mono-HDR-3D with two modules: one for LDR-to-HDR conversion and another for HDR-to-LDR transformation, enabling unsupervised learning in a closed loop.", "result": "Mono-HDR-3D outperforms previous methods in extensive experiments.", "conclusion": "The proposed single-exposure HDR-NVS approach is effective and can integrate with existing NVS models."}}
{"id": "2505.00772", "pdf": "https://arxiv.org/pdf/2505.00772", "abs": "https://arxiv.org/abs/2505.00772", "authors": ["Branko Brklja\u010d", "Milan Brklja\u010d"], "title": "Person detection and re-identification in open-world settings of retail stores and public spaces", "categories": ["cs.CV", "68T10, 68T07, 68T45, 94A08, 94A13,", "I.4.9; I.4.8; I.5.4; I.5.5; I.2.10; C.3; J.4; J.7"], "comment": "6 pages, 3 figures, 1 table, associated code implementation and\n  accompanying test videos with experimental results are available at the\n  following link: https://github.com/brkljac/personReID , paper submitted to\n  the 2nd International Scientific Conference 'ALFATECH - Smart Cities and\n  modern technologies - 2025', Belgrade, Serbia, Feb. 28, 2025", "summary": "Practical applications of computer vision in smart cities usually assume\nsystem integration and operation in challenging open-world environments. In the\ncase of person re-identification task the main goal is to retrieve information\nwhether the specific person has appeared in another place at a different time\ninstance of the same video, or over multiple camera feeds. This typically\nassumes collecting raw data from video surveillance cameras in different places\nand under varying illumination conditions. In the considered open-world setting\nit also requires detection and localization of the person inside the analyzed\nvideo frame before the main re-identification step. With multi-person and\nmulti-camera setups the system complexity becomes higher, requiring\nsophisticated tracking solutions and re-identification models. In this work we\nwill discuss existing challenges in system design architectures, consider\npossible solutions based on different computer vision techniques, and describe\napplications of such systems in retail stores and public spaces for improved\nmarketing analytics. In order to analyse sensitivity of person\nre-identification task under different open-world environments, a performance\nof one close to real-time solution will be demonstrated over several video\ncaptures and live camera feeds. Finally, based on conducted experiments we will\nindicate further research directions and possible system improvements.", "AI": {"tldr": "The paper discusses challenges and solutions for person re-identification in smart cities, focusing on open-world environments, multi-camera setups, and real-time performance.", "motivation": "Addressing the complexity of person re-identification in open-world settings with varying conditions and multi-camera systems.", "method": "Analyzes system design architectures, computer vision techniques, and evaluates a near real-time solution across video captures and live feeds.", "result": "Demonstrates performance of a re-identification solution and identifies challenges in diverse environments.", "conclusion": "Proposes further research directions and system improvements for enhanced re-identification in smart city applications."}}
{"id": "2505.01015", "pdf": "https://arxiv.org/pdf/2505.01015", "abs": "https://arxiv.org/abs/2505.01015", "authors": ["Jongwook Han", "Dongmin Choi", "Woojung Song", "Eun-Ju Lee", "Yohan Jo"], "title": "Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "32 pages, 7 figures", "summary": "The importance of benchmarks for assessing the values of language models has\nbeen pronounced due to the growing need of more authentic, human-aligned\nresponses. However, existing benchmarks rely on human or machine annotations\nthat are vulnerable to value-related biases. Furthermore, the tested scenarios\noften diverge from real-world contexts in which models are commonly used to\ngenerate text and express values. To address these issues, we propose the Value\nPortrait benchmark, a reliable framework for evaluating LLMs' value\norientations with two key characteristics. First, the benchmark consists of\nitems that capture real-life user-LLM interactions, enhancing the relevance of\nassessment results to real-world LLM usage and thus ecological validity.\nSecond, each item is rated by human subjects based on its similarity to their\nown thoughts, and correlations between these ratings and the subjects' actual\nvalue scores are derived. This psychometrically validated approach ensures that\nitems strongly correlated with specific values serve as reliable items for\nassessing those values. Through evaluating 27 LLMs with our benchmark, we find\nthat these models prioritize Benevolence, Security, and Self-Direction values\nwhile placing less emphasis on Tradition, Power, and Achievement values. Also,\nour analysis reveals biases in how LLMs perceive various demographic groups,\ndeviating from real human data.", "AI": {"tldr": "The paper introduces the Value Portrait benchmark to evaluate LLMs' value orientations, addressing biases in existing benchmarks by using real-life interactions and psychometric validation.", "motivation": "Existing benchmarks for LLMs are biased and lack real-world relevance, necessitating a more authentic and reliable evaluation framework.", "method": "The Value Portrait benchmark uses real-life user-LLM interactions and psychometric validation via human ratings correlated with value scores.", "result": "Evaluation of 27 LLMs shows prioritization of Benevolence, Security, and Self-Direction values, with biases in demographic perceptions.", "conclusion": "The benchmark provides a reliable, ecologically valid tool for assessing LLM values, revealing biases and value priorities."}}
{"id": "2505.01181", "pdf": "https://arxiv.org/pdf/2505.01181", "abs": "https://arxiv.org/abs/2505.01181", "authors": ["Mehrdad Asadi", "Roxana R\u0103dulescu", "Ann Now\u00e9"], "title": "Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms", "categories": ["cs.AI"], "comment": "To appear in short form in Genetic and Evolutionary Computation\n  Conference (GECCO '25 Companion), 2025", "summary": "Swarming systems, such as for example multi-drone networks, excel at\ncooperative tasks like monitoring, surveillance, or disaster assistance in\ncritical environments, where autonomous agents make decentralized decisions in\norder to fulfill team-level objectives in a robust and efficient manner.\nUnfortunately, team-level coordinated strategies in the wild are vulnerable to\ndata poisoning attacks, resulting in either inaccurate coordination or\nadversarial behavior among the agents. To address this challenge, we contribute\na framework that investigates the effects of such data poisoning attacks, using\nexplainable AI methods. We model the interaction among agents using\nevolutionary intelligence, where an optimal coalition strategically emerges to\nperform coordinated tasks. Then, through a rigorous evaluation, the swarm model\nis systematically poisoned using data manipulation attacks. We showcase the\napplicability of explainable AI methods to quantify the effects of poisoning on\nthe team strategy and extract footprint characterizations that enable\ndiagnosing. Our findings indicate that when the model is poisoned above 10%,\nnon-optimal strategies resulting in inefficient cooperation can be identified.", "AI": {"tldr": "The paper proposes a framework using explainable AI to analyze data poisoning attacks in swarming systems, showing that poisoning above 10% leads to inefficient cooperation.", "motivation": "Swarming systems are vulnerable to data poisoning attacks, which disrupt team-level coordination. The study aims to understand and diagnose these attacks.", "method": "The framework models agent interactions using evolutionary intelligence, poisons the swarm model systematically, and applies explainable AI to quantify and diagnose poisoning effects.", "result": "Poisoning above 10% causes non-optimal strategies and inefficient cooperation, identifiable through explainable AI methods.", "conclusion": "Explainable AI effectively diagnoses data poisoning in swarming systems, highlighting vulnerabilities and enabling mitigation strategies."}}
{"id": "2505.00887", "pdf": "https://arxiv.org/pdf/2505.00887", "abs": "https://arxiv.org/abs/2505.00887", "authors": ["Xi Chen", "Yateng Tang", "Jiarong Xu", "Jiawei Zhang", "Siwei Zhang", "Sijia Peng", "Xuehao Zheng", "Yun Xiong"], "title": "Rethinking Time Encoding via Learnable Transformation Functions", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages, 13 figures, 10 tables", "summary": "Effectively modeling time information and incorporating it into applications\nor models involving chronologically occurring events is crucial. Real-world\nscenarios often involve diverse and complex time patterns, which pose\nsignificant challenges for time encoding methods. While previous methods focus\non capturing time patterns, many rely on specific inductive biases, such as\nusing trigonometric functions to model periodicity. This narrow focus on\nsingle-pattern modeling makes them less effective in handling the diversity and\ncomplexities of real-world time patterns. In this paper, we investigate to\nimprove the existing commonly used time encoding methods and introduce\nLearnable Transformation-based Generalized Time Encoding (LeTE). We propose\nusing deep function learning techniques to parameterize non-linear\ntransformations in time encoding, making them learnable and capable of modeling\ngeneralized time patterns, including diverse and complex temporal dynamics. By\nenabling learnable transformations, LeTE encompasses previous methods as\nspecific cases and allows seamless integration into a wide range of tasks.\nThrough extensive experiments across diverse domains, we demonstrate the\nversatility and effectiveness of LeTE.", "AI": {"tldr": "The paper introduces LeTE, a learnable time encoding method, to address the limitations of existing methods in handling diverse and complex real-world time patterns.", "motivation": "Existing time encoding methods often rely on specific inductive biases, limiting their effectiveness in modeling diverse temporal dynamics.", "method": "Proposes LeTE, which uses deep function learning to parameterize non-linear transformations, making time encoding learnable and adaptable to generalized time patterns.", "result": "LeTE outperforms previous methods, demonstrating versatility and effectiveness across diverse domains.", "conclusion": "LeTE provides a flexible and powerful framework for modeling complex time patterns, integrating seamlessly into various tasks."}}
{"id": "2505.01224", "pdf": "https://arxiv.org/pdf/2505.01224", "abs": "https://arxiv.org/abs/2505.01224", "authors": ["Kui Jiang", "Yan Luo", "Junjun Jiang", "Xin Xu", "Fei Ma", "Fei Yu"], "title": "RD-UIE: Relation-Driven State Space Modeling for Underwater Image Enhancement", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Underwater image enhancement (UIE) is a critical preprocessing step for\nmarine vision applications, where wavelength-dependent attenuation causes\nsevere content degradation and color distortion. While recent state space\nmodels like Mamba show potential for long-range dependency modeling, their\nunfolding operations and fixed scan paths on 1D sequences fail to adapt to\nlocal object semantics and global relation modeling, limiting their efficacy in\ncomplex underwater environments. To address this, we enhance conventional Mamba\nwith the sorting-based scanning mechanism that dynamically reorders scanning\nsequences based on statistical distribution of spatial correlation of all\npixels. In this way, it encourages the network to prioritize the most\ninformative components--structural and semantic features. Upon building this\nmechanism, we devise a Visually Self-adaptive State Block (VSSB) that\nharmonizes dynamic sorting of Mamba with input-dependent dynamic convolution,\nenabling coherent integration of global context and local relational cues. This\nexquisite design helps eliminate global focus bias, especially for widely\ndistributed contents, which greatly weakens the statistical frequency. For\nrobust feature extraction and refinement, we design a cross-feature bridge\n(CFB) to adaptively fuse multi-scale representations. These efforts compose the\nnovel relation-driven Mamba framework for effective UIE (RD-UIE). Extensive\nexperiments on underwater enhancement benchmarks demonstrate RD-UIE outperforms\nthe state-of-the-art approach WMamba in both quantitative metrics and visual\nfidelity, averagely achieving 0.55 dB performance gain on the three benchmarks.\nOur code is available at https://github.com/kkoucy/RD-UIE/tree/main", "AI": {"tldr": "The paper introduces RD-UIE, a relation-driven Mamba framework for underwater image enhancement, outperforming WMamba with a 0.55 dB gain.", "motivation": "Underwater images suffer from degradation and color distortion, and existing models like Mamba lack adaptability to local and global features in complex environments.", "method": "Enhances Mamba with a sorting-based scanning mechanism and introduces Visually Self-adaptive State Block (VSSB) and cross-feature bridge (CFB) for robust feature extraction.", "result": "RD-UIE outperforms WMamba, achieving a 0.55 dB performance gain on benchmarks.", "conclusion": "The proposed framework effectively addresses underwater image enhancement by integrating global context and local features."}}
{"id": "2505.00786", "pdf": "https://arxiv.org/pdf/2505.00786", "abs": "https://arxiv.org/abs/2505.00786", "authors": ["Oluwanisola Ibikunle", "Hara Talasila", "Debvrat Varshney", "Jilu Li", "John Paden", "Maryam Rahnemoonfar"], "title": "AI-ready Snow Radar Echogram Dataset (SRED) for climate change monitoring", "categories": ["cs.CV"], "comment": null, "summary": "Tracking internal layers in radar echograms with high accuracy is essential\nfor understanding ice sheet dynamics and quantifying the impact of accelerated\nice discharge in Greenland and other polar regions due to contemporary global\nclimate warming. Deep learning algorithms have become the leading approach for\nautomating this task, but the absence of a standardized and well-annotated\nechogram dataset has hindered the ability to test and compare algorithms\nreliably, limiting the advancement of state-of-the-art methods for the radar\nechogram layer tracking problem. This study introduces the first comprehensive\n``deep learning ready'' radar echogram dataset derived from Snow Radar airborne\ndata collected during the National Aeronautics and Space Administration\nOperation Ice Bridge (OIB) mission in 2012. The dataset contains 13,717 labeled\nand 57,815 weakly-labeled echograms covering diverse snow zones (dry, ablation,\nwet) with varying along-track resolutions. To demonstrate its utility, we\nevaluated the performance of five deep learning models on the dataset. Our\nresults show that while current computer vision segmentation algorithms can\nidentify and track snow layer pixels in echogram images, advanced end-to-end\nmodels are needed to directly extract snow depth and annual accumulation from\nechograms, reducing or eliminating post-processing. The dataset and\naccompanying benchmarking framework provide a valuable resource for advancing\nradar echogram layer tracking and snow accumulation estimation, advancing our\nunderstanding of polar ice sheets response to climate warming.", "AI": {"tldr": "The paper introduces the first standardized radar echogram dataset for deep learning, aiding in tracking ice sheet layers and improving snow accumulation estimation.", "motivation": "The lack of a well-annotated dataset for radar echograms has hindered reliable testing and comparison of deep learning algorithms for ice sheet layer tracking.", "method": "A comprehensive dataset of labeled and weakly-labeled radar echograms from NASA's OIB mission was created. Five deep learning models were evaluated on this dataset.", "result": "Current segmentation algorithms can track snow layers, but advanced end-to-end models are needed for direct snow depth extraction.", "conclusion": "The dataset and benchmarking framework advance radar echogram analysis and polar ice sheet understanding under climate warming."}}
{"id": "2505.01035", "pdf": "https://arxiv.org/pdf/2505.01035", "abs": "https://arxiv.org/abs/2505.01035", "authors": ["Lui Yoshida"], "title": "Do We Need a Detailed Rubric for Automated Essay Scoring using Large Language Models?", "categories": ["cs.CL"], "comment": "Accepted in AIED 2025. This preprint has not undergone any\n  post-submission improvements or corrections", "summary": "This study investigates the necessity and impact of a detailed rubric in\nautomated essay scoring (AES) using large language models (LLMs). While using\nrubrics are standard in LLM-based AES, creating detailed rubrics requires\nsubstantial ef-fort and increases token usage. We examined how different levels\nof rubric detail affect scoring accuracy across multiple LLMs using the TOEFL11\ndataset. Our experiments compared three conditions: a full rubric, a simplified\nrubric, and no rubric, using four different LLMs (Claude 3.5 Haiku, Gemini 1.5\nFlash, GPT-4o-mini, and Llama 3 70B Instruct). Results showed that three out of\nfour models maintained similar scoring accuracy with the simplified rubric\ncompared to the detailed one, while significantly reducing token usage.\nHowever, one model (Gemini 1.5 Flash) showed decreased performance with more\ndetailed rubrics. The findings suggest that simplified rubrics may be\nsufficient for most LLM-based AES applications, offering a more efficient\nalternative without compromis-ing scoring accuracy. However, model-specific\nevaluation remains crucial as per-formance patterns vary across different LLMs.", "AI": {"tldr": "Simplified rubrics in LLM-based AES maintain scoring accuracy for most models while reducing token usage, though performance varies by model.", "motivation": "To determine if detailed rubrics are necessary for accurate automated essay scoring (AES) using LLMs, given the effort and token costs involved.", "method": "Compared scoring accuracy of four LLMs (Claude 3.5 Haiku, Gemini 1.5 Flash, GPT-4o-mini, Llama 3 70B Instruct) under three rubric conditions: full, simplified, and no rubric, using the TOEFL11 dataset.", "result": "Three models maintained accuracy with simplified rubrics, reducing token usage. Gemini 1.5 Flash performed worse with detailed rubrics.", "conclusion": "Simplified rubrics are efficient for most LLM-based AES, but model-specific evaluation is essential due to varying performance."}}
{"id": "2505.01192", "pdf": "https://arxiv.org/pdf/2505.01192", "abs": "https://arxiv.org/abs/2505.01192", "authors": ["Federico Maria Cau", "Lucio Davide Spano"], "title": "Exploring the Impact of Explainable AI and Cognitive Capabilities on Users' Decisions", "categories": ["cs.AI", "cs.HC"], "comment": "30 pages, 7 figures", "summary": "Artificial Intelligence (AI) systems are increasingly used for\ndecision-making across domains, raising debates over the information and\nexplanations they should provide. Most research on Explainable AI (XAI) has\nfocused on feature-based explanations, with less attention on alternative\nstyles. Personality traits like the Need for Cognition (NFC) can also lead to\ndifferent decision-making outcomes among low and high NFC individuals. We\ninvestigated how presenting AI information (prediction, confidence, and\naccuracy) and different explanation styles (example-based, feature-based,\nrule-based, and counterfactual) affect accuracy, reliance on AI, and cognitive\nload in a loan application scenario. We also examined low and high NFC\nindividuals' differences in prioritizing XAI interface elements (loan\nattributes, AI information, and explanations), accuracy, and cognitive load.\nOur findings show that high AI confidence significantly increases reliance on\nAI while reducing cognitive load. Feature-based explanations did not enhance\naccuracy compared to other conditions. Although counterfactual explanations\nwere less understandable, they enhanced overall accuracy, increasing reliance\non AI and reducing cognitive load when AI predictions were correct. Both low\nand high NFC individuals prioritized explanations after loan attributes,\nleaving AI information as the least important. However, we found no significant\ndifferences between low and high NFC groups in accuracy or cognitive load,\nraising questions about the role of personality traits in AI-assisted\ndecision-making. These findings highlight the need for user-centric\npersonalization in XAI interfaces, incorporating diverse explanation styles and\nexploring multiple personality traits and other user characteristics to\noptimize human-AI collaboration.", "AI": {"tldr": "The study explores how AI information and explanation styles (example-based, feature-based, rule-based, counterfactual) impact decision-making in a loan scenario, focusing on Need for Cognition (NFC) traits. Findings show high AI confidence boosts reliance and reduces cognitive load, while counterfactual explanations improve accuracy. No NFC-based differences were found, suggesting the need for personalized XAI interfaces.", "motivation": "To understand how AI information and diverse explanation styles affect decision-making accuracy, reliance on AI, and cognitive load, especially considering personality traits like NFC.", "method": "Conducted a loan application scenario study, testing AI information (prediction, confidence, accuracy) and explanation styles (example-based, feature-based, rule-based, counterfactual) on low and high NFC individuals.", "result": "High AI confidence increased reliance and reduced cognitive load. Counterfactual explanations improved accuracy despite lower understandability. No NFC-based differences in accuracy or cognitive load were found.", "conclusion": "User-centric personalization in XAI interfaces, incorporating diverse explanation styles and exploring user traits, is crucial for optimizing human-AI collaboration."}}
{"id": "2505.00903", "pdf": "https://arxiv.org/pdf/2505.00903", "abs": "https://arxiv.org/abs/2505.00903", "authors": ["Daria Gitman", "Igor Gitman", "Evelina Bakhturina"], "title": "NeMo-Inspector: A Visualization Tool for LLM Generation Analysis", "categories": ["cs.LG", "cs.CL"], "comment": "Presented at the NAACL 2025 conference", "summary": "Adapting Large Language Models (LLMs) to novel tasks and enhancing their\noverall capabilities often requires large, high-quality training datasets.\nSynthetic data, generated at scale, serves a valuable alternative when\nreal-world data is scarce or difficult to obtain. However, ensuring the quality\nof synthetic datasets is challenging, as developers must manually inspect and\nrefine numerous samples to identify errors and areas for improvement. This\nprocess is time-consuming and requires specialized tools. We introduce\nNeMo-Inspector, an open-source tool designed to simplify the analysis of\nsynthetic datasets with integrated inference capabilities. We demonstrate its\neffectiveness through two real-world cases. Analysis and cleaning of the\nsynthetically generated GSM-Plus dataset with NeMo-Inspector led to a\nsignificant decrease in low-quality samples from 46.99% to 19.51%. The tool\nalso helped identify and correct generation errors in OpenMath models,\nimproving accuracy by 1.92% on the MATH dataset and by 4.17% on the GSM8K\ndataset for a Meta-Llama-3-8B model fine-tuned on synthetic data generated from\nNemotron-4-340B.", "AI": {"tldr": "NeMo-Inspector is an open-source tool for analyzing and improving synthetic datasets, demonstrated to reduce low-quality samples and enhance model accuracy.", "motivation": "Large, high-quality datasets are needed for LLM adaptation, but synthetic data quality is hard to ensure manually.", "method": "Introduces NeMo-Inspector, a tool for automated analysis and refinement of synthetic datasets.", "result": "Reduced low-quality samples from 46.99% to 19.51% in GSM-Plus and improved model accuracy by 1.92% (MATH) and 4.17% (GSM8K).", "conclusion": "NeMo-Inspector effectively simplifies synthetic dataset analysis, improving data quality and model performance."}}
{"id": "2306.03271", "pdf": "https://arxiv.org/pdf/2306.03271", "abs": "https://arxiv.org/abs/2306.03271", "authors": ["Soumyanil Banerjee", "Nicholas Summerfield", "Ming Dong", "Carri Glide-Hurst"], "title": "Volumetric medical image segmentation through dual self-distillation in U-shaped networks", "categories": ["eess.IV", "cs.CV"], "comment": "28 pages, 5 figures, 7 tables, accepted at IEEE Transactions on\n  Biomedical Engineering, 2025", "summary": "U-shaped networks and its variants have demonstrated exceptional results for\nmedical image segmentation. In this paper, we propose a novel dual\nself-distillation (DSD) framework in U-shaped networks for volumetric medical\nimage segmentation. DSD distills knowledge from the ground-truth segmentation\nlabels to the decoder layers. Additionally, DSD also distills knowledge from\nthe deepest decoder and encoder layer to the shallower decoder and encoder\nlayers respectively of a single U-shaped network. DSD is a general training\nstrategy that could be attached to the backbone architecture of any U-shaped\nnetwork to further improve its segmentation performance. We attached DSD on\nseveral state-of-the-art U-shaped backbones, and extensive experiments on\nvarious public 3D medical image segmentation datasets (cardiac substructure,\nbrain tumor and Hippocampus) demonstrated significant improvement over the same\nbackbones without DSD. On average, after attaching DSD to the U-shaped\nbackbones, we observed an increase of 2.82\\%, 4.53\\% and 1.3\\% in Dice\nsimilarity score, a decrease of 7.15 mm, 6.48 mm and 0.76 mm in the Hausdorff\ndistance, for cardiac substructure, brain tumor and Hippocampus segmentation,\nrespectively. These improvements were achieved with negligible increase in the\nnumber of trainable parameters and training time. Our proposed DSD framework\nalso led to significant qualitative improvements for cardiac substructure,\nbrain tumor and Hippocampus segmentation over the U-shaped backbones. The\nsource code is publicly available at\nhttps://github.com/soumbane/DualSelfDistillation.", "AI": {"tldr": "A novel dual self-distillation (DSD) framework improves U-shaped networks for medical image segmentation by distilling knowledge from ground-truth labels and deeper layers, achieving significant performance gains with minimal overhead.", "motivation": "To enhance the segmentation performance of U-shaped networks in medical imaging by leveraging dual knowledge distillation.", "method": "DSD distills knowledge from ground-truth labels to decoder layers and from deeper layers to shallower layers within a U-shaped network.", "result": "Average improvements of 2.82%, 4.53%, and 1.3% in Dice score, and reductions in Hausdorff distance for cardiac, brain tumor, and Hippocampus segmentation.", "conclusion": "DSD is a versatile and effective training strategy for boosting U-shaped network performance in medical image segmentation."}}
{"id": "2505.00788", "pdf": "https://arxiv.org/pdf/2505.00788", "abs": "https://arxiv.org/abs/2505.00788", "authors": ["Wufei Ma", "Luoxin Ye", "Nessa McWeeney", "Celso M de Melo", "Alan Yuille", "Jieneng Chen"], "title": "SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models", "categories": ["cs.CV"], "comment": "CVPR 2025 highlight, camera ready version", "summary": "Humans naturally understand 3D spatial relationships, enabling complex\nreasoning like predicting collisions of vehicles from different directions.\nCurrent large multimodal models (LMMs), however, lack of this capability of 3D\nspatial reasoning. This limitation stems from the scarcity of 3D training data\nand the bias in current model designs toward 2D data. In this paper, we\nsystematically study the impact of 3D-informed data, architecture, and training\nsetups, introducing SpatialLLM, a large multi-modal model with advanced 3D\nspatial reasoning abilities. To address data limitations, we develop two types\nof 3D-informed training datasets: (1) 3D-informed probing data focused on\nobject's 3D location and orientation, and (2) 3D-informed conversation data for\ncomplex spatial relationships. Notably, we are the first to curate VQA data\nthat incorporate 3D orientation relationships on real images. Furthermore, we\nsystematically integrate these two types of training data with the\narchitectural and training designs of LMMs, providing a roadmap for optimal\ndesign aimed at achieving superior 3D reasoning capabilities. Our SpatialLLM\nadvances machines toward highly capable 3D-informed reasoning, surpassing\nGPT-4o performance by 8.7%. Our systematic empirical design and the resulting\nfindings offer valuable insights for future research in this direction.", "AI": {"tldr": "SpatialLLM is a new multimodal model designed to enhance 3D spatial reasoning, addressing data and design biases in current models, and outperforming GPT-4o by 8.7%.", "motivation": "Current large multimodal models lack 3D spatial reasoning due to scarce 3D training data and 2D design biases. This paper aims to bridge this gap.", "method": "Developed 3D-informed probing and conversation datasets, integrated with architectural and training designs for LMMs, to improve 3D reasoning.", "result": "SpatialLLM achieves superior 3D reasoning, outperforming GPT-4o by 8.7%.", "conclusion": "The study provides a roadmap for 3D-informed reasoning in LMMs, offering insights for future research."}}
{"id": "2505.01068", "pdf": "https://arxiv.org/pdf/2505.01068", "abs": "https://arxiv.org/abs/2505.01068", "authors": ["Yijie Jin", "Junjie Peng", "Xuanchao Lin", "Haochen Yuan", "Lan Wang", "Cangzhi Zheng"], "title": "Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal Sentiment Analysis (MSA) is a rapidly developing field that\nintegrates multimodal information to recognize sentiments, and existing models\nhave made significant progress in this area. The central challenge in MSA is\nmultimodal fusion, which is predominantly addressed by Multimodal Transformers\n(MulTs). Although act as the paradigm, MulTs suffer from efficiency concerns.\nIn this work, from the perspective of efficiency optimization, we propose and\nprove that MulTs are hierarchical modal-wise heterogeneous graphs (HMHGs), and\nwe introduce the graph-structured representation pattern of MulTs. Based on\nthis pattern, we propose an Interlaced Mask (IM) mechanism to design the\nGraph-Structured and Interlaced-Masked Multimodal Transformer (GsiT). It is\nformally equivalent to MulTs which achieves an efficient weight-sharing\nmechanism without information disorder through IM, enabling All-Modal-In-One\nfusion with only 1/3 of the parameters of pure MulTs. A Triton kernel called\nDecomposition is implemented to ensure avoiding additional computational\noverhead. Moreover, it achieves significantly higher performance than\ntraditional MulTs. To further validate the effectiveness of GsiT itself and the\nHMHG concept, we integrate them into multiple state-of-the-art models and\ndemonstrate notable performance improvements and parameter reduction on widely\nused MSA datasets.", "AI": {"tldr": "The paper introduces GsiT, a Graph-Structured and Interlaced-Masked Multimodal Transformer, which optimizes efficiency in Multimodal Sentiment Analysis by reducing parameters and improving performance.", "motivation": "Addressing the efficiency concerns of Multimodal Transformers (MulTs) in Multimodal Sentiment Analysis (MSA) by proposing a hierarchical modal-wise heterogeneous graph (HMHG) representation.", "method": "Proposes GsiT, leveraging an Interlaced Mask (IM) mechanism for efficient weight-sharing and All-Modal-In-One fusion, with a Triton kernel for computational efficiency.", "result": "GsiT achieves higher performance than traditional MulTs with only 1/3 of the parameters and integrates successfully into state-of-the-art models.", "conclusion": "GsiT and the HMHG concept significantly improve efficiency and performance in MSA, validated by experiments on standard datasets."}}
{"id": "2505.01305", "pdf": "https://arxiv.org/pdf/2505.01305", "abs": "https://arxiv.org/abs/2505.01305", "authors": ["Lo Pang-Yun Ting", "Hong-Pei Chen", "An-Shan Liu", "Chun-Yin Yeh", "Po-Lin Chen", "Kun-Ta Chuang"], "title": "Early Detection of Patient Deterioration from Real-Time Wearable Monitoring System", "categories": ["cs.AI"], "comment": null, "summary": "Early detection of patient deterioration is crucial for reducing mortality\nrates. Heart rate data has shown promise in assessing patient health, and\nwearable devices offer a cost-effective solution for real-time monitoring.\nHowever, extracting meaningful insights from diverse heart rate data and\nhandling missing values in wearable device data remain key challenges. To\naddress these challenges, we propose TARL, an innovative approach that models\nthe structural relationships of representative subsequences, known as\nshapelets, in heart rate time series. TARL creates a shapelet-transition\nknowledge graph to model shapelet dynamics in heart rate time series,\nindicating illness progression and potential future changes. We further\nintroduce a transition-aware knowledge embedding to reinforce relationships\namong shapelets and quantify the impact of missing values, enabling the\nformulation of comprehensive heart rate representations. These representations\ncapture explanatory structures and predict future heart rate trends, aiding\nearly illness detection. We collaborate with physicians and nurses to gather\nICU patient heart rate data from wearables and diagnostic metrics assessing\nillness severity for evaluating deterioration. Experiments on real-world ICU\ndata demonstrate that TARL achieves both high reliability and early detection.\nA case study further showcases TARL's explainable detection process,\nhighlighting its potential as an AI-driven tool to assist clinicians in\nrecognizing early signs of patient deterioration.", "AI": {"tldr": "TARL is a novel method using shapelet-transition knowledge graphs to analyze heart rate data from wearables, improving early detection of patient deterioration by modeling shapelet dynamics and handling missing values.", "motivation": "Early detection of patient deterioration is vital for reducing mortality, but challenges like diverse heart rate data and missing values in wearable data hinder effective monitoring.", "method": "TARL models structural relationships of shapelets in heart rate time series, creating a knowledge graph to track illness progression. It uses transition-aware knowledge embedding to quantify missing values and predict future trends.", "result": "Experiments on ICU data show TARL achieves high reliability and early detection. A case study demonstrates its explainable process for clinicians.", "conclusion": "TARL is a promising AI-driven tool for early illness detection, aiding clinicians in recognizing deterioration signs."}}
{"id": "2505.00908", "pdf": "https://arxiv.org/pdf/2505.00908", "abs": "https://arxiv.org/abs/2505.00908", "authors": ["Ihab Tabbara", "Hussein Sibai"], "title": "Learning Neural Control Barrier Functions from Offline Data with Conservatism", "categories": ["cs.LG", "cs.FL", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Safety filters, particularly those based on control barrier functions, have\ngained increased interest as effective tools for safe control of dynamical\nsystems. Existing correct-by-construction synthesis algorithms, however, suffer\nfrom the curse of dimensionality. Deep learning approaches have been proposed\nin recent years to address this challenge. In this paper, we contribute to this\nline of work by proposing an algorithm for training control barrier functions\nfrom offline datasets. Our algorithm trains the filter to not only prevent the\nsystem from reaching unsafe states but also out-of-distribution ones, at which\nthe filter would be unreliable. It is inspired by Conservative Q-learning, an\noffline reinforcement learning algorithm. We call its outputs Conservative\nControl Barrier Functions (CCBFs). Our empirical results demonstrate that CCBFs\noutperform existing methods in maintaining safety and out-of-distribution\navoidance while minimally affecting task performance.", "AI": {"tldr": "A deep learning algorithm trains conservative control barrier functions (CCBFs) from offline data to enhance safety and avoid unreliable states, outperforming existing methods.", "motivation": "Address the curse of dimensionality in safety filter synthesis and improve reliability by preventing unsafe and out-of-distribution states.", "method": "Proposes an algorithm inspired by Conservative Q-learning to train CCBFs from offline datasets, focusing on safety and distributional robustness.", "result": "CCBFs outperform existing methods in safety maintenance and out-of-distribution avoidance without compromising task performance.", "conclusion": "The proposed CCBFs offer a robust solution for safe control, addressing limitations of existing synthesis methods."}}
{"id": "2504.11485", "pdf": "https://arxiv.org/pdf/2504.11485", "abs": "https://arxiv.org/abs/2504.11485", "authors": ["Sonia Foschiatti", "Axel Kittenberger", "Otmar Scherzer"], "title": "Deciphering scrolls with tomography: A training experiment", "categories": ["eess.IV", "cs.CV", "97M10, 44A12"], "comment": null, "summary": "The recovery of severely damaged ancient written documents has proven to be a\nmajor challenge for many scientists, mainly due to the impracticality of\nphysical unwrapping them. Non-destructive techniques, such as X-ray computed\ntomography (CT), combined with computer vision algorithms, have emerged as a\nmeans of facilitating the virtual reading of the hidden contents of the damaged\ndocuments. This paper proposes an educational laboratory aimed at simulating\nthe entire process of acquisition and virtual recovery of the ancient works. We\nhave developed an experimental setup that uses visible light to replace the\ndetrimental X-rays, and a didactic software pipeline that allows students to\nvirtually reconstruct a transparent rolled sheet with printed text on it, the\nwrapped scroll.", "AI": {"tldr": "A non-destructive educational lab simulates ancient document recovery using visible light and software, avoiding harmful X-rays.", "motivation": "Physical unwrapping of damaged ancient documents is impractical; non-destructive methods like CT scans are needed.", "method": "Uses visible light and a software pipeline for virtual reconstruction of wrapped scrolls.", "result": "Developed an experimental setup and didactic software for student training.", "conclusion": "Proposes a safe, educational alternative to X-ray-based document recovery."}}
{"id": "2505.00836", "pdf": "https://arxiv.org/pdf/2505.00836", "abs": "https://arxiv.org/abs/2505.00836", "authors": ["Conor Flynn", "Christopher Ebersole", "Edmund Zelnio"], "title": "The Comparability of Model Fusion to Measured Data in Confuser Rejection", "categories": ["cs.CV"], "comment": "Conference paper for SPIE Defense and Commercial Sensing Algorithms\n  for Synthetic Aperture Radar Imagery XXXII. 14 pages, 9 figures", "summary": "Data collection has always been a major issue in the modeling and training of\nlarge deep learning networks, as no dataset can account for every slight\ndeviation we might see in live usage. Collecting samples can be especially\ncostly for Synthetic Aperture Radar (SAR), limiting the amount of unique\ntargets and operating conditions we are able to observe from. To counter this\nlack of data, simulators have been developed utilizing the shooting and\nbouncing ray method to allow for the generation of synthetic SAR data on 3D\nmodels. While effective, the synthetically generated data does not perfectly\ncorrelate to the measured data leading to issues when training models solely on\nsynthetic data. We aim to use computational power as a substitution for this\nlack of quality measured data, by ensembling many models trained on synthetic\ndata. Synthetic data is also not complete, as we do not know what targets might\nbe present in a live environment. Therefore we need to have our ensembling\ntechniques account for these unknown targets by applying confuser rejection in\nwhich our models will reject unknown targets it is presented with, and only\nclassify those it has been trained on.", "AI": {"tldr": "The paper addresses data scarcity in SAR deep learning by using synthetic data and model ensembling, while handling unknown targets via confuser rejection.", "motivation": "Data collection for SAR is costly and limited, leading to insufficient unique targets and conditions for training deep learning models.", "method": "Utilizes synthetic SAR data generated via the shooting and bouncing ray method and employs model ensembling to compensate for synthetic data's imperfections. Confuser rejection is used to handle unknown targets.", "result": "The approach leverages computational power to mitigate the lack of quality measured data and improves model robustness against unknown targets.", "conclusion": "Ensembling models trained on synthetic data and incorporating confuser rejection can effectively address SAR data scarcity and unknown target challenges."}}
{"id": "2505.01110", "pdf": "https://arxiv.org/pdf/2505.01110", "abs": "https://arxiv.org/abs/2505.01110", "authors": ["Murtadha Ahmed", "Wenbo", "Liu yunfeng"], "title": "MateICL: Mitigating Attention Dispersion in Large-Scale In-Context Learning", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nIn-Context Learning (ICL). However, the fixed position length constraints in\npre-trained models limit the number of demonstration examples. Recent efforts\nto extend context suffer from attention dispersion as the number of\ndemonstrations increases. In this paper, we introduce Mitigating Attention\nDispersion in large-scale ICL (MateICL) that enables LLMs to maintain effective\nself-attention as the context size grows. We first split the context into\nmultiple windows, each filled to the model's context capacity, which are\nprocessed separately. Then, we introduce an additional layer to recalibrate the\nattention weights, prioritizing the query tokens as the number of\ndemonstrations increases. Our empirical results show that MateICL can\neffectively leverage larger contexts to improve ICL performance. Compared to\nretrieval-based baselines, MateICL consistently achieves better performance\nwithout requiring an externally trained retrieval model. Despite recent\nadvances in inference strategies (e.g., 32k token contexts), our results\ndemonstrate that MateICL remains beneficial in computationally\nresource-constrained settings. The code is publicly available at\nhttps://github.com/amurtadha/MateICL.", "AI": {"tldr": "MateICL addresses attention dispersion in large-scale ICL by splitting context into windows and recalibrating attention weights, improving performance without external retrieval models.", "motivation": "Fixed position length constraints in LLMs limit demonstration examples, and existing methods suffer from attention dispersion as context grows.", "method": "Split context into windows processed separately, then recalibrate attention weights to prioritize query tokens.", "result": "MateICL effectively leverages larger contexts, outperforming retrieval-based baselines without external models.", "conclusion": "MateICL remains beneficial in resource-constrained settings, offering a scalable solution for ICL."}}
{"id": "2505.01343", "pdf": "https://arxiv.org/pdf/2505.01343", "abs": "https://arxiv.org/abs/2505.01343", "authors": ["Dongliang Guo", "Mengxuan Hu", "Zihan Guan", "Thomas Hartvigsen", "Sheng Li"], "title": "BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing", "categories": ["cs.AI"], "comment": null, "summary": "Large multi-modal models inevitably decay over time as facts change and\npreviously learned information becomes outdated. Traditional approaches such as\nfine-tuning are often impractical for updating these models due to their size\nand complexity. Instead, direct knowledge editing within the models presents a\nmore viable solution. Current model editing techniques, however, typically\noverlook the unique influence ranges of different facts, leading to compromised\nmodel performance in terms of both generality and locality. To address this\nissue, we introduce the concept of the generality-locality trade-off in\nmulti-modal model editing. We develop a new model editing dataset named OKEDIT,\nspecifically designed to effectively evaluate this trade-off. Building on this\nfoundation, we propose BalancEdit, a novel method for balanced model editing\nthat dynamically achieves an optimal balance between generality and locality.\nBalancEdit utilizes a unique mechanism that generates both positive and\nnegative samples for each fact to accurately determine its influence scope and\nincorporates these insights into the model's latent space using a discrete,\nlocalized codebook of edits, without modifying the underlying model weights. To\nour knowledge, this is the first approach explicitly addressing the\ngenerality-locality trade-off in multi-modal model editing. Our comprehensive\nresults confirm the effectiveness of BalancEdit, demonstrating minimal\ntrade-offs while maintaining robust editing capabilities. Our code and dataset\nwill be available.", "AI": {"tldr": "The paper introduces BalancEdit, a method for balanced model editing in multi-modal models, addressing the generality-locality trade-off. It uses a unique mechanism to dynamically balance edits without altering model weights, validated by the OKEDIT dataset.", "motivation": "Traditional fine-tuning is impractical for updating large multi-modal models, and current editing techniques overlook the influence ranges of facts, compromising performance.", "method": "Proposes BalancEdit, which generates positive/negative samples to determine fact influence scope and uses a localized codebook for edits, avoiding weight modifications.", "result": "BalancEdit achieves minimal trade-offs between generality and locality while maintaining robust editing capabilities.", "conclusion": "The approach is the first to explicitly address the generality-locality trade-off in multi-modal model editing, with promising results."}}
{"id": "2505.00909", "pdf": "https://arxiv.org/pdf/2505.00909", "abs": "https://arxiv.org/abs/2505.00909", "authors": ["Xianjin Yang", "Jingguo Zhang"], "title": "Gaussian Process Policy Iteration with Additive Schwarz Acceleration for Forward and Inverse HJB and Mean Field Game Problems", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "We propose a Gaussian Process (GP)-based policy iteration framework for\naddressing both forward and inverse problems in Hamilton--Jacobi--Bellman (HJB)\nequations and mean field games (MFGs). Policy iteration is formulated as an\nalternating procedure between solving the value function under a fixed control\npolicy and updating the policy based on the resulting value function. By\nexploiting the linear structure of GPs for function approximation, each policy\nevaluation step admits an explicit closed-form solution, eliminating the need\nfor numerical optimization. To improve convergence, we incorporate the additive\nSchwarz acceleration as a preconditioning step following each policy update.\nNumerical experiments demonstrate the effectiveness of Schwarz acceleration in\nimproving computational efficiency.", "AI": {"tldr": "A GP-based policy iteration framework for HJB equations and MFGs, using additive Schwarz acceleration for improved convergence.", "motivation": "Address forward and inverse problems in HJB equations and MFGs efficiently.", "method": "Alternate between solving value functions and updating policies using GP approximation, with Schwarz acceleration for convergence.", "result": "Closed-form solutions for policy evaluation and improved computational efficiency with Schwarz acceleration.", "conclusion": "The framework effectively solves HJB and MFG problems with enhanced convergence."}}
{"id": "2404.01330", "pdf": "https://arxiv.org/pdf/2404.01330", "abs": "https://arxiv.org/abs/2404.01330", "authors": ["JooHyun Park", "YuJin Jeon", "HuiYong Kim", "SeungHwan Baek", "HyeongYeop Kang"], "title": "P-Hologen: An End-to-End Generative Framework for Phase-Only Holograms", "categories": ["cs.CV", "cs.GR", "cs.LG", "eess.IV"], "comment": null, "summary": "Holography stands at the forefront of visual technology, offering immersive,\nthree-dimensional visualizations through the manipulation of light wave\namplitude and phase. Although generative models have been extensively explored\nin the image domain, their application to holograms remains relatively\nunderexplored due to the inherent complexity of phase learning. Exploiting\ngenerative models for holograms offers exciting opportunities for advancing\ninnovation and creativity, such as semantic-aware hologram generation and\nediting. Currently, the most viable approach for utilizing generative models in\nthe hologram domain involves integrating an image-based generative model with\nan image-to-hologram conversion model, which comes at the cost of increased\ncomputational complexity and inefficiency. To tackle this problem, we introduce\nP-Hologen, the first end-to-end generative framework designed for phase-only\nholograms (POHs). P-Hologen employs vector quantized variational autoencoders\nto capture the complex distributions of POHs. It also integrates the angular\nspectrum method into the training process, constructing latent spaces for\ncomplex phase data using strategies from the image processing domain. Extensive\nexperiments demonstrate that P-Hologen achieves superior quality and\ncomputational efficiency compared to the existing methods. Furthermore, our\nmodel generates high-quality unseen, diverse holographic content from its\nlearned latent space without requiring pre-existing images. Our work paves the\nway for new applications and methodologies in holographic content creation,\nopening a new era in the exploration of generative holographic content. The\ncode for our paper is publicly available on\nhttps://github.com/james0223/P-Hologen.", "AI": {"tldr": "P-Hologen is the first end-to-end generative framework for phase-only holograms, achieving superior quality and efficiency by integrating vector quantized variational autoencoders and the angular spectrum method.", "motivation": "The application of generative models to holograms is underexplored due to phase learning complexity, despite its potential for innovation in holographic content creation.", "method": "P-Hologen uses vector quantized variational autoencoders and integrates the angular spectrum method to model complex phase data.", "result": "P-Hologen outperforms existing methods in quality and efficiency, generating diverse holographic content without pre-existing images.", "conclusion": "P-Hologen advances holographic content creation, enabling new applications and methodologies in generative holography."}}
{"id": "2505.00866", "pdf": "https://arxiv.org/pdf/2505.00866", "abs": "https://arxiv.org/abs/2505.00866", "authors": ["Viktor Kocur", "Charalambos Tzamos", "Yaqing Ding", "Zuzana Berger Haladova", "Torsten Sattler", "Zuzana Kukelova"], "title": "Are Minimal Radial Distortion Solvers Really Necessary for Relative Pose Estimation?", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2410.05984", "summary": "Estimating the relative pose between two cameras is a fundamental step in\nmany applications such as Structure-from-Motion. The common approach to\nrelative pose estimation is to apply a minimal solver inside a RANSAC loop.\nHighly efficient solvers exist for pinhole cameras. Yet, (nearly) all cameras\nexhibit radial distortion. Not modeling radial distortion leads to\n(significantly) worse results. However, minimal radial distortion solvers are\nsignificantly more complex than pinhole solvers, both in terms of run-time and\nimplementation efforts. This paper compares radial distortion solvers with two\nsimple-to-implement approaches that do not use minimal radial distortion\nsolvers: The first approach combines an efficient pinhole solver with sampled\nradial undistortion parameters, where the sampled parameters are used for\nundistortion prior to applying the pinhole solver. The second approach uses a\nstate-of-the-art neural network to estimate the distortion parameters rather\nthan sampling them from a set of potential values. Extensive experiments on\nmultiple datasets, and different camera setups, show that complex minimal\nradial distortion solvers are not necessary in practice. We discuss under which\nconditions a simple sampling of radial undistortion parameters is preferable\nover calibrating cameras using a learning-based prior approach. Code and newly\ncreated benchmark for relative pose estimation under radial distortion are\navailable at https://github.com/kocurvik/rdnet.", "AI": {"tldr": "The paper compares two simple methods for radial distortion in relative pose estimation, showing minimal solvers are often unnecessary.", "motivation": "Radial distortion in cameras complicates pose estimation, and minimal solvers for it are complex. The paper explores simpler alternatives.", "method": "Two approaches: 1) pinhole solver with sampled undistortion parameters, 2) neural network for distortion estimation.", "result": "Experiments show minimal radial distortion solvers are often unnecessary in practice.", "conclusion": "Simple methods can replace complex solvers, with conditions favoring sampling or learning-based approaches."}}
{"id": "2505.01162", "pdf": "https://arxiv.org/pdf/2505.01162", "abs": "https://arxiv.org/abs/2505.01162", "authors": ["Chebrolu Niranjan", "Kokil Jaidka", "Gerard Christopher Yeo"], "title": "On the Limitations of Steering in Language Model Alignment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Steering vectors are a promising approach to aligning language model behavior\nat inference time. In this paper, we propose a framework to assess the\nlimitations of steering vectors as alignment mechanisms. Using a framework of\ntransformer hook interventions and antonym-based function vectors, we evaluate\nthe role of prompt structure and context complexity in steering effectiveness.\nOur findings indicate that steering vectors are promising for specific\nalignment tasks, such as value alignment, but may not provide a robust\nfoundation for general-purpose alignment in LLMs, particularly in complex\nscenarios. We establish a methodological foundation for future investigations\ninto steering capabilities of reasoning models.", "AI": {"tldr": "Steering vectors show promise for aligning language models but have limitations, especially in complex scenarios. The paper evaluates their effectiveness using transformer hook interventions and antonym-based function vectors.", "motivation": "To assess the limitations of steering vectors as alignment mechanisms for language models, particularly in complex contexts.", "method": "Uses transformer hook interventions and antonym-based function vectors to evaluate steering effectiveness, focusing on prompt structure and context complexity.", "result": "Steering vectors work well for specific tasks like value alignment but are not robust for general-purpose alignment in LLMs, especially in complex scenarios.", "conclusion": "The study provides a methodological foundation for future research on steering capabilities in reasoning models, highlighting the need for more robust alignment solutions."}}
{"id": "2411.09200", "pdf": "https://arxiv.org/pdf/2411.09200", "abs": "https://arxiv.org/abs/2411.09200", "authors": ["Sabbir M. Saleh", "Ibrahim Mohammed Sayem", "Nazim Madhavji", "John Steinbacher"], "title": "Advancing Software Security and Reliability in Cloud Platforms through AI-based Anomaly Detection", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "10 pages", "summary": "Continuous Integration/Continuous Deployment (CI/CD) is fundamental for\nadvanced software development, supporting faster and more efficient delivery of\ncode changes into cloud environments. However, security issues in the CI/CD\npipeline remain challenging, and incidents (e.g., DDoS, Bot, Log4j, etc.) are\nhappening over the cloud environments. While plenty of literature discusses\nstatic security testing and CI/CD practices, only a few deal with network\ntraffic pattern analysis to detect different cyberattacks. This research aims\nto enhance CI/CD pipeline security by implementing anomaly detection through AI\n(Artificial Intelligence) support. The goal is to identify unusual behaviour or\nvariations from network traffic patterns in pipeline and cloud platforms. The\nsystem shall integrate into the workflow to continuously monitor pipeline\nactivities and cloud infrastructure. Additionally, it aims to explore adaptive\nresponse mechanisms to mitigate the detected anomalies or security threats.\nThis research employed two popular network traffic datasets, CSE-CIC-IDS2018\nand CSE-CIC-IDS2017. We implemented a combination of Convolution Neural\nNetwork(CNN) and Long Short-Term Memory (LSTM) to detect unusual traffic\npatterns. We achieved an accuracy of 98.69% and 98.30% and generated log files\nin different CI/CD pipeline stages that resemble the network anomalies affected\nto address security challenges in modern DevOps practices, contributing to\nadvancing software security and reliability.", "AI": {"tldr": "The paper proposes using AI-driven anomaly detection to enhance CI/CD pipeline security by analyzing network traffic patterns, achieving high accuracy with CNN and LSTM models.", "motivation": "Security issues in CI/CD pipelines are a growing concern, with few solutions focusing on network traffic analysis for detecting cyberattacks.", "method": "The research uses CNN and LSTM models on datasets CSE-CIC-IDS2018 and CSE-CIC-IDS2017 to detect anomalies in network traffic.", "result": "Achieved high accuracy (98.69% and 98.30%) in detecting unusual traffic patterns and generated logs for CI/CD stages.", "conclusion": "The approach improves CI/CD security, advancing software reliability and addressing modern DevOps challenges."}}
{"id": "2505.00913", "pdf": "https://arxiv.org/pdf/2505.00913", "abs": "https://arxiv.org/abs/2505.00913", "authors": ["Han Wang", "Adam White", "Martha White"], "title": "Fine-Tuning without Performance Degradation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning policies learned offline remains a major challenge in application\ndomains. Monotonic performance improvement during \\emph{fine-tuning} is often\nchallenging, as agents typically experience performance degradation at the\nearly fine-tuning stage. The community has identified multiple difficulties in\nfine-tuning a learned network online, however, the majority of progress has\nfocused on improving learning efficiency during fine-tuning. In practice, this\ncomes at a serious cost during fine-tuning: initially, agent performance\ndegrades as the agent explores and effectively overrides the policy learned\noffline. We show across a range of settings, many offline-to-online algorithms\nexhibit either (1) performance degradation or (2) slow learning (sometimes\neffectively no improvement) during fine-tuning. We introduce a new fine-tuning\nalgorithm, based on an algorithm called Jump Start, that gradually allows more\nexploration based on online estimates of performance. Empirically, this\napproach achieves fast fine-tuning and significantly reduces performance\ndegradations compared with existing algorithms designed to do the same.", "AI": {"tldr": "The paper addresses performance degradation and slow learning in offline-to-online policy fine-tuning, introducing a new algorithm (Jump Start) that improves fine-tuning speed and reduces degradation.", "motivation": "Fine-tuning policies learned offline often leads to performance degradation or slow learning, highlighting the need for better methods.", "method": "Introduces the Jump Start algorithm, which gradually increases exploration based on online performance estimates.", "result": "The new algorithm achieves faster fine-tuning and significantly reduces performance degradation compared to existing methods.", "conclusion": "The Jump Start algorithm effectively addresses fine-tuning challenges, offering practical improvements for offline-to-online learning."}}
{"id": "2410.06129", "pdf": "https://arxiv.org/pdf/2410.06129", "abs": "https://arxiv.org/abs/2410.06129", "authors": ["Kylie Yeung", "Christine Tobler", "Rolf F Schulte", "Benjamin White", "Anthony McIntyre", "Sebastien Serres", "Peter Morris", "Dorothee Auer", "Fergus V Gleeson", "Damian J Tyler", "James T Grist", "Florian Wiesinger"], "title": "Exploring the Computational Feasibility of Direct Pseudoinversion of the Encoding Matrix for MR Image Reconstruction (Pinv-Recon)", "categories": ["physics.med-ph", "eess.IV"], "comment": "28 pages, 8 figures (+ Supplementary Material). Submitted to\n  Scientific Reports", "summary": "Image reconstruction in Magnetic Resonance Imaging (MRI) is fundamentally a\nlinear inverse problem, such that the image can be recovered via explicit\npseudoinversion of the encoding matrix by solving $\\textbf{data} =\n\\textbf{Encode} \\times \\textbf{image}$ - a method referred to here as\nPinv-Recon. While the benefits of this approach were acknowledged in early\nstudies, the field has historically favored fast Fourier transforms (FFT) and\niterative techniques due to perceived computational limitations of the\npseudoinversion approach. This work revisits Pinv-Recon in the context of\nmodern hardware, software, and optimized linear algebra routines. We compare\nvarious matrix inversion strategies, assess regularization effects, and\ndemonstrate incorporation of advanced encoding physics into a unified\nreconstruction framework.\n  While hardware advances have already significantly reduced computation time\ncompared to earlier studies, our work further demonstrates that leveraging\nCholesky decomposition and block-wise inversion leads to a\ntwo-order-of-magnitude improvement in computational efficiency over previous\nSingular Value Decomposition-based implementations. Moreover, we demonstrate\nthe versatility of Pinv-Recon on diverse \\textit{in vivo} datasets encompassing\na range of encoding schemes, starting with low- to medium-resolution functional\nand metabolic imaging and extending to high-resolution cases. Our findings\nestablish Pinv-Recon as a practical and adaptable reconstruction method that\naligns with the increasing emphasis on open-source and reproducible MRI\nresearch.", "AI": {"tldr": "Revisiting pseudoinversion (Pinv-Recon) for MRI image reconstruction, leveraging modern hardware and optimized linear algebra for improved efficiency and versatility.", "motivation": "The field historically favored FFT and iterative methods over pseudoinversion due to computational limitations. This work reevaluates Pinv-Recon with modern advancements.", "method": "Compares matrix inversion strategies (Cholesky, block-wise), assesses regularization, and integrates advanced encoding physics.", "result": "Achieves two-order-of-magnitude efficiency improvement and demonstrates versatility across diverse in vivo datasets.", "conclusion": "Pinv-Recon is practical, adaptable, and aligns with open-source, reproducible MRI research trends."}}
{"id": "2505.00938", "pdf": "https://arxiv.org/pdf/2505.00938", "abs": "https://arxiv.org/abs/2505.00938", "authors": ["Boyuan Meng", "Xiaohan Zhang", "Peilin Li", "Zhe Wu", "Yiming Li", "Wenkai Zhao", "Beinan Yu", "Hui-Liang Shen"], "title": "CDFormer: Cross-Domain Few-Shot Object Detection Transformer Against Feature Confusion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Cross-domain few-shot object detection (CD-FSOD) aims to detect novel objects\nacross different domains with limited class instances. Feature confusion,\nincluding object-background confusion and object-object confusion, presents\nsignificant challenges in both cross-domain and few-shot settings. In this\nwork, we introduce CDFormer, a cross-domain few-shot object detection\ntransformer against feature confusion, to address these challenges. The method\nspecifically tackles feature confusion through two key modules:\nobject-background distinguishing (OBD) and object-object distinguishing (OOD).\nThe OBD module leverages a learnable background token to differentiate between\nobjects and background, while the OOD module enhances the distinction between\nobjects of different classes. Experimental results demonstrate that CDFormer\noutperforms previous state-of-the-art approaches, achieving 12.9% mAP, 11.0%\nmAP, and 10.4% mAP improvements under the 1/5/10 shot settings, respectively,\nwhen fine-tuned.", "AI": {"tldr": "CDFormer, a transformer-based method, addresses feature confusion in cross-domain few-shot object detection (CD-FSOD) using OBD and OOD modules, achieving significant performance improvements.", "motivation": "Feature confusion (object-background and object-object) poses challenges in CD-FSOD.", "method": "CDFormer uses two modules: OBD (learnable background token) and OOD (enhances inter-class distinction).", "result": "Outperforms state-of-the-art with 12.9%, 11.0%, and 10.4% mAP improvements for 1/5/10 shots.", "conclusion": "CDFormer effectively tackles feature confusion, advancing CD-FSOD performance."}}
{"id": "2505.01198", "pdf": "https://arxiv.org/pdf/2505.01198", "abs": "https://arxiv.org/abs/2505.01198", "authors": ["Mahdi Dhaini", "Ege Erdogan", "Nils Feldhus", "Gjergji Kasneci"], "title": "Gender Bias in Explainability: Investigating Performance Disparity in Post-hoc Methods", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) 2025", "summary": "While research on applications and evaluations of explanation methods\ncontinues to expand, fairness of the explanation methods concerning disparities\nin their performance across subgroups remains an often overlooked aspect. In\nthis paper, we address this gap by showing that, across three tasks and five\nlanguage models, widely used post-hoc feature attribution methods exhibit\nsignificant gender disparity with respect to their faithfulness, robustness,\nand complexity. These disparities persist even when the models are pre-trained\nor fine-tuned on particularly unbiased datasets, indicating that the\ndisparities we observe are not merely consequences of biased training data. Our\nresults highlight the importance of addressing disparities in explanations when\ndeveloping and applying explainability methods, as these can lead to biased\noutcomes against certain subgroups, with particularly critical implications in\nhigh-stakes contexts. Furthermore, our findings underscore the importance of\nincorporating the fairness of explanations, alongside overall model fairness\nand explainability, as a requirement in regulatory frameworks.", "AI": {"tldr": "The paper highlights gender disparities in widely used post-hoc feature attribution methods across tasks and models, emphasizing the need for fairness in explanations.", "motivation": "To address the overlooked fairness of explanation methods, particularly disparities in performance across subgroups like gender.", "method": "Analyzed three tasks and five language models, evaluating faithfulness, robustness, and complexity of post-hoc feature attribution methods.", "result": "Found significant gender disparities in explanation methods, even with unbiased training data, indicating inherent biases.", "conclusion": "Urges incorporating fairness of explanations into regulatory frameworks to prevent biased outcomes in high-stakes contexts."}}
{"id": "2504.20605", "pdf": "https://arxiv.org/pdf/2504.20605", "abs": "https://arxiv.org/abs/2504.20605", "authors": ["Mihai Nadas", "Laura Diosan", "Andrei Piscoran", "Andreea Tomescu"], "title": "TF1-EN-3M: Three Million Synthetic Moral Fables for Training Small, Open Language Models", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.LG"], "comment": null, "summary": "Moral stories are a time-tested vehicle for transmitting values, yet modern\nNLP lacks a large, structured corpus that couples coherent narratives with\nexplicit ethical lessons. We close this gap with TF1-EN-3M, the first open\ndataset of three million English-language fables generated exclusively by\ninstruction-tuned models no larger than 8B parameters. Each story follows a\nsix-slot scaffold (character -> trait -> setting -> conflict -> resolution ->\nmoral), produced through a combinatorial prompt engine that guarantees genre\nfidelity while covering a broad thematic space.\n  A hybrid evaluation pipeline blends (i) a GPT-based critic that scores\ngrammar, creativity, moral clarity, and template adherence with (ii)\nreference-free diversity and readability metrics. Among ten open-weight\ncandidates, an 8B-parameter Llama-3 variant delivers the best quality-speed\ntrade-off, producing high-scoring fables on a single consumer GPU (<24 GB VRAM)\nat approximately 13.5 cents per 1,000 fables.\n  We release the dataset, generation code, evaluation scripts, and full\nmetadata under a permissive license, enabling exact reproducibility and cost\nbenchmarking. TF1-EN-3M opens avenues for research in instruction following,\nnarrative intelligence, value alignment, and child-friendly educational AI,\ndemonstrating that large-scale moral storytelling no longer requires\nproprietary giant models.", "AI": {"tldr": "TF1-EN-3M is a 3M English fable dataset generated by \u22648B-parameter models, structured for moral lessons, evaluated via hybrid metrics, and released openly for research.", "motivation": "Modern NLP lacks a large, structured corpus of moral stories, hindering research in narrative intelligence and value alignment.", "method": "Used a combinatorial prompt engine for genre fidelity, evaluated with GPT-based critic and reference-free metrics, and optimized for quality-speed trade-off.", "result": "An 8B Llama-3 variant produced high-quality fables efficiently (13.5 cents/1K fables) on consumer GPUs.", "conclusion": "TF1-EN-3M enables scalable moral storytelling without proprietary models, fostering research in narrative AI and education."}}
{"id": "2505.00926", "pdf": "https://arxiv.org/pdf/2505.00926", "abs": "https://arxiv.org/abs/2505.00926", "authors": ["Ruiquan Huang", "Yingbin Liang", "Jing Yang"], "title": "How Transformers Learn Regular Language Recognition: A Theoretical Study on Training Dynamics and Implicit Bias", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": "accepted by ICML 2025", "summary": "Language recognition tasks are fundamental in natural language processing\n(NLP) and have been widely used to benchmark the performance of large language\nmodels (LLMs). These tasks also play a crucial role in explaining the working\nmechanisms of transformers. In this work, we focus on two representative tasks\nin the category of regular language recognition, known as `even pairs' and\n`parity check', the aim of which is to determine whether the occurrences of\ncertain subsequences in a given sequence are even. Our goal is to explore how a\none-layer transformer, consisting of an attention layer followed by a linear\nlayer, learns to solve these tasks by theoretically analyzing its training\ndynamics under gradient descent. While even pairs can be solved directly by a\none-layer transformer, parity check need to be solved by integrating\nChain-of-Thought (CoT), either into the inference stage of a transformer\nwell-trained for the even pairs task, or into the training of a one-layer\ntransformer. For both problems, our analysis shows that the joint training of\nattention and linear layers exhibits two distinct phases. In the first phase,\nthe attention layer grows rapidly, mapping data sequences into separable\nvectors. In the second phase, the attention layer becomes stable, while the\nlinear layer grows logarithmically and approaches in direction to a max-margin\nhyperplane that correctly separates the attention layer outputs into positive\nand negative samples, and the loss decreases at a rate of $O(1/t)$. Our\nexperiments validate those theoretical results.", "AI": {"tldr": "The paper explores how a one-layer transformer learns regular language tasks ('even pairs' and 'parity check') through theoretical analysis and experiments, revealing distinct training phases.", "motivation": "To understand how transformers learn and solve fundamental language recognition tasks, focusing on regular languages like 'even pairs' and 'parity check'.", "method": "Theoretical analysis of training dynamics under gradient descent for a one-layer transformer (attention + linear layer), with experiments validating the findings.", "result": "Two-phase training: rapid attention layer growth for separability, followed by logarithmic linear layer growth toward a max-margin solution. Loss decreases at O(1/t).", "conclusion": "Transformers can solve 'even pairs' directly but require Chain-of-Thought for 'parity check'. Training dynamics reveal separable phases, validated experimentally."}}
{"id": "2503.20819", "pdf": "https://arxiv.org/pdf/2503.20819", "abs": "https://arxiv.org/abs/2503.20819", "authors": ["Paraskevi Valergaki", "Antonis Argyros", "Giorgos Giannakakis", "Anastasios Roussos"], "title": "Reflections on Diversity: A Real-time Virtual Mirror for Inclusive 3D Face Transformations", "categories": ["cs.GR", "eess.IV"], "comment": null, "summary": "Real-time 3D face manipulation has significant applications in virtual\nreality, social media and human-computer interaction. This paper introduces a\nnovel system, which we call Mirror of Diversity (MOD), that combines Generative\nAdversarial Networks (GANs) for texture manipulation and 3D Morphable Models\n(3DMMs) for facial geometry to achieve realistic face transformations that\nreflect various demographic characteristics, emphasizing the beauty of\ndiversity and the universality of human features. As participants sit in front\nof a computer monitor with a camera positioned above, their facial\ncharacteristics are captured in real time and can further alter their digital\nface reconstruction with transformations reflecting different demographic\ncharacteristics, such as gender and ethnicity (e.g., a person from Africa,\nAsia, Europe). Another feature of our system, which we call Collective Face,\ngenerates an averaged face representation from multiple participants' facial\ndata. A comprehensive evaluation protocol is implemented to assess the realism\nand demographic accuracy of the transformations. Qualitative feedback is\ngathered through participant questionnaires, which include comparisons of MOD\ntransformations with similar filters on platforms like Snapchat and TikTok.\nAdditionally, quantitative analysis is conducted using a pretrained\nConvolutional Neural Network that predicts gender and ethnicity, to validate\nthe accuracy of demographic transformations.", "AI": {"tldr": "The paper introduces MOD, a real-time 3D face manipulation system using GANs and 3DMMs to reflect diverse demographic traits, with a 'Collective Face' feature for averaged representations. Evaluations include qualitative and quantitative assessments.", "motivation": "To enhance virtual reality, social media, and human-computer interaction by enabling realistic, diverse face transformations.", "method": "Combines GANs for texture and 3DMMs for geometry, with real-time capture and transformations. Includes 'Collective Face' for averaged representations.", "result": "Qualitative feedback and quantitative CNN analysis validate realism and demographic accuracy.", "conclusion": "MOD successfully achieves realistic, diverse face transformations, emphasizing inclusivity and universality."}}
{"id": "2505.00975", "pdf": "https://arxiv.org/pdf/2505.00975", "abs": "https://arxiv.org/abs/2505.00975", "authors": ["Yeonsang Shin", "Jihwan Kim", "Yumin Song", "Kyungseung Lee", "Hyunhee Chung", "Taeyoung Na"], "title": "Generating Animated Layouts as Structured Text Representations", "categories": ["cs.CV"], "comment": "AI for Content Creation (AI4CC) Workshop at CVPR 2025", "summary": "Despite the remarkable progress in text-to-video models, achieving precise\ncontrol over text elements and animated graphics remains a significant\nchallenge, especially in applications such as video advertisements. To address\nthis limitation, we introduce Animated Layout Generation, a novel approach to\nextend static graphic layouts with temporal dynamics. We propose a Structured\nText Representation for fine-grained video control through hierarchical visual\nelements. To demonstrate the effectiveness of our approach, we present VAKER\n(Video Ad maKER), a text-to-video advertisement generation pipeline that\ncombines a three-stage generation process with Unstructured Text Reasoning for\nseamless integration with LLMs. VAKER fully automates video advertisement\ngeneration by incorporating dynamic layout trajectories for objects and\ngraphics across specific video frames. Through extensive evaluations, we\ndemonstrate that VAKER significantly outperforms existing methods in generating\nvideo advertisements. Project Page:\nhttps://yeonsangshin.github.io/projects/Vaker", "AI": {"tldr": "The paper introduces Animated Layout Generation for precise control in text-to-video models, presenting VAKER, a pipeline that outperforms existing methods in video ad generation.", "motivation": "Precise control over text elements and animated graphics in text-to-video models is challenging, especially for video advertisements.", "method": "Proposes Animated Layout Generation with Structured Text Representation and a three-stage pipeline (VAKER) integrating Unstructured Text Reasoning with LLMs.", "result": "VAKER outperforms existing methods in generating video advertisements, automating dynamic layout trajectories for objects and graphics.", "conclusion": "The approach effectively addresses control limitations in text-to-video models, demonstrating superior performance in video ad generation."}}
{"id": "2505.01238", "pdf": "https://arxiv.org/pdf/2505.01238", "abs": "https://arxiv.org/abs/2505.01238", "authors": ["Mahdi Dhaini", "Kafaite Zahra Hussain", "Efstratios Zaradoukas", "Gjergji Kasneci"], "title": "EvalxNLP: A Framework for Benchmarking Post-Hoc Explainability Methods on NLP Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to the xAI World Conference (2025) - System Demonstration", "summary": "As Natural Language Processing (NLP) models continue to evolve and become\nintegral to high-stakes applications, ensuring their interpretability remains a\ncritical challenge. Given the growing variety of explainability methods and\ndiverse stakeholder requirements, frameworks that help stakeholders select\nappropriate explanations tailored to their specific use cases are increasingly\nimportant. To address this need, we introduce EvalxNLP, a Python framework for\nbenchmarking state-of-the-art feature attribution methods for transformer-based\nNLP models. EvalxNLP integrates eight widely recognized explainability\ntechniques from the Explainable AI (XAI) literature, enabling users to generate\nand evaluate explanations based on key properties such as faithfulness,\nplausibility, and complexity. Our framework also provides interactive,\nLLM-based textual explanations, facilitating user understanding of the\ngenerated explanations and evaluation outcomes. Human evaluation results\nindicate high user satisfaction with EvalxNLP, suggesting it is a promising\nframework for benchmarking explanation methods across diverse user groups. By\noffering a user-friendly and extensible platform, EvalxNLP aims at\ndemocratizing explainability tools and supporting the systematic comparison and\nadvancement of XAI techniques in NLP.", "AI": {"tldr": "EvalxNLP is a Python framework for benchmarking feature attribution methods in NLP, integrating eight XAI techniques to evaluate explanations based on faithfulness, plausibility, and complexity. It includes interactive, LLM-based explanations and shows high user satisfaction.", "motivation": "The need for interpretable NLP models in high-stakes applications and diverse stakeholder requirements drives the development of frameworks like EvalxNLP to tailor explanations for specific use cases.", "method": "EvalxNLP integrates eight explainability techniques from XAI literature, enabling users to generate and evaluate explanations. It also provides interactive, LLM-based textual explanations.", "result": "Human evaluation shows high user satisfaction, indicating EvalxNLP is effective for benchmarking explanation methods across diverse user groups.", "conclusion": "EvalxNLP democratizes explainability tools, supports systematic XAI comparison, and advances NLP interpretability."}}
{"id": "2505.00929", "pdf": "https://arxiv.org/pdf/2505.00929", "abs": "https://arxiv.org/abs/2505.00929", "authors": ["Edison Mucllari", "Zachary Daniels", "David Zhang", "Qiang Ye"], "title": "Compact Recurrent Transformer with Persistent Memory", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The Transformer architecture has shown significant success in many language\nprocessing and visual tasks. However, the method faces challenges in\nefficiently scaling to long sequences because the self-attention computation is\nquadratic with respect to the input length. To overcome this limitation,\nseveral approaches scale to longer sequences by breaking long sequences into a\nseries of segments, restricting self-attention to local dependencies between\ntokens within each segment and using a memory mechanism to manage information\nflow between segments. However, these approached generally introduce additional\ncompute overhead that restricts them from being used for applications where\nlimited compute memory and power are of great concern (such as edge computing).\nWe propose a novel and efficient Compact Recurrent Transformer (CRT), which\ncombines shallow Transformer models that process short local segments with\nrecurrent neural networks to compress and manage a single persistent memory\nvector that summarizes long-range global information between segments. We\nevaluate CRT on WordPTB and WikiText-103 for next-token-prediction tasks, as\nwell as on the Toyota Smarthome video dataset for classification. CRT achieves\ncomparable or superior prediction results to full-length Transformers in the\nlanguage datasets while using significantly shorter segments (half or quarter\nsize) and substantially reduced FLOPs. Our approach also demonstrates\nstate-of-the-art performance on the Toyota Smarthome video dataset.", "AI": {"tldr": "The paper introduces the Compact Recurrent Transformer (CRT), combining shallow Transformers with RNNs to efficiently handle long sequences with reduced compute overhead, outperforming full-length Transformers in language tasks and achieving state-of-the-art results in video classification.", "motivation": "Transformers struggle with long sequences due to quadratic self-attention complexity. Existing methods introduce compute overhead, limiting their use in resource-constrained settings like edge computing.", "method": "CRT integrates shallow Transformers for local segments with RNNs to manage a persistent memory vector for global information, reducing segment size and FLOPs.", "result": "CRT matches or surpasses full-length Transformers in language tasks (WordPTB, WikiText-103) with shorter segments and fewer FLOPs, and excels in video classification (Toyota Smarthome).", "conclusion": "CRT offers an efficient solution for long-sequence tasks, balancing performance and resource constraints, making it suitable for edge computing and similar applications."}}
{"id": "2504.21632", "pdf": "https://arxiv.org/pdf/2504.21632", "abs": "https://arxiv.org/abs/2504.21632", "authors": ["Fuma Ito", "Chihiro Tsutake", "Keita Takahashi", "Toshiaki Fujii"], "title": "Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of Binary Classification", "categories": ["cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation (DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.", "AI": {"tldr": "A fast sign retrieval method for DCT coefficients using binary classification with CNNs, achieving high accuracy and low computation cost.", "motivation": "To efficiently compress sign information in images by reconstructing DCT coefficient signs from their amplitudes.", "method": "Proposes a binary classification approach using CNNs on 3D representations of amplitudes and signs, organized into sub-band blocks.", "result": "Accurate sign retrieval with significantly low computation cost.", "conclusion": "The method effectively addresses sign retrieval for DCT coefficients, offering a practical solution for image compression."}}
{"id": "2505.00980", "pdf": "https://arxiv.org/pdf/2505.00980", "abs": "https://arxiv.org/abs/2505.00980", "authors": ["Jiahuan Long", "Xin Zhou"], "title": "LMDepth: Lightweight Mamba-based Monocular Depth Estimation for Real-World Deployment", "categories": ["cs.CV"], "comment": null, "summary": "Monocular depth estimation provides an additional depth dimension to RGB\nimages, making it widely applicable in various fields such as virtual reality,\nautonomous driving and robotic navigation. However, existing depth estimation\nalgorithms often struggle to effectively balance performance and computational\nefficiency, which poses challenges for deployment on resource-constrained\ndevices. To address this, we propose LMDepth, a lightweight Mamba-based\nmonocular depth estimation network, designed to reconstruct high-precision\ndepth information while maintaining low computational overhead. Specifically,\nwe propose a modified pyramid spatial pooling module that serves as a\nmulti-scale feature aggregator and context extractor, ensuring global spatial\ninformation for accurate depth estimation. Moreover, we integrate multiple\ndepth Mamba blocks into the decoder. Designed with linear computations, the\nMamba Blocks enable LMDepth to efficiently decode depth information from global\nfeatures, providing a lightweight alternative to Transformer-based\narchitectures that depend on complex attention mechanisms. Extensive\nexperiments on the NYUDv2 and KITTI datasets demonstrate the effectiveness of\nour proposed LMDepth. Compared to previous lightweight depth estimation\nmethods, LMDepth achieves higher performance with fewer parameters and lower\ncomputational complexity (measured by GFLOPs). We further deploy LMDepth on an\nembedded platform with INT8 quantization, validating its practicality for\nreal-world edge applications.", "AI": {"tldr": "LMDepth is a lightweight Mamba-based monocular depth estimation network that balances performance and efficiency, outperforming existing methods with fewer parameters and lower computational costs.", "motivation": "Existing depth estimation algorithms struggle to balance performance and computational efficiency, limiting deployment on resource-constrained devices.", "method": "LMDepth uses a modified pyramid spatial pooling module for multi-scale feature aggregation and integrates lightweight Mamba blocks for efficient depth decoding.", "result": "LMDepth achieves higher performance with fewer parameters and lower computational complexity on NYUDv2 and KITTI datasets, and is validated on an embedded platform.", "conclusion": "LMDepth offers a practical, efficient solution for monocular depth estimation, suitable for edge applications."}}
{"id": "2505.01273", "pdf": "https://arxiv.org/pdf/2505.01273", "abs": "https://arxiv.org/abs/2505.01273", "authors": ["Xuan Li", "Zhe Yin", "Xiaodong Gu", "Beijun Shen"], "title": "Anti-adversarial Learning: Desensitizing Prompts for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "With the widespread use of LLMs, preserving privacy in user prompts has\nbecome crucial, as prompts risk exposing privacy and sensitive data to the\ncloud LLMs. Traditional techniques like homomorphic encryption, secure\nmulti-party computation, and federated learning face challenges due to heavy\ncomputational costs and user participation requirements, limiting their\napplicability in LLM scenarios. In this paper, we propose PromptObfus, a novel\nmethod for desensitizing LLM prompts. The core idea of PromptObfus is\n\"anti-adversarial\" learning, which perturbs privacy words in the prompt to\nobscure sensitive information while retaining the stability of model\npredictions. Specifically, PromptObfus frames prompt desensitization as a\nmasked language modeling task, replacing privacy-sensitive terms with a [MASK]\ntoken. A desensitization model is trained to generate candidate replacements\nfor each masked position. These candidates are subsequently selected based on\ngradient feedback from a surrogate model, ensuring minimal disruption to the\ntask output. We demonstrate the effectiveness of our approach on three NLP\ntasks. Results show that PromptObfus effectively prevents privacy inference\nfrom remote LLMs while preserving task performance.", "AI": {"tldr": "PromptObfus is a method for desensitizing LLM prompts using anti-adversarial learning to obscure sensitive information while maintaining model prediction stability.", "motivation": "Privacy in user prompts is critical due to risks of exposing sensitive data to cloud LLMs, with traditional methods being computationally costly or impractical.", "method": "PromptObfus treats prompt desensitization as a masked language modeling task, replacing sensitive terms with [MASK] tokens and training a model to generate replacements, selected via gradient feedback.", "result": "The method effectively prevents privacy inference in remote LLMs while preserving task performance across three NLP tasks.", "conclusion": "PromptObfus offers a practical solution for privacy-preserving LLM prompts, balancing privacy and utility."}}
{"id": "2505.00803", "pdf": "https://arxiv.org/pdf/2505.00803", "abs": "https://arxiv.org/abs/2505.00803", "authors": ["Jonathan Heins", "Darrell Whitley", "Pascal Kerschke"], "title": "To Repair or Not to Repair? Investigating the Importance of AB-Cycles for the State-of-the-Art TSP Heuristic EAX", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "The Edge Assembly Crossover (EAX) algorithm is the state-of-the-art heuristic\nfor solving the Traveling Salesperson Problem (TSP). It regularly outperforms\nother methods, such as the Lin-Kernighan-Helsgaun heuristic (LKH), across\ndiverse sets of TSP instances. Essentially, EAX employs a two-stage mechanism\nthat focuses on improving the current solutions, first, at the local and,\nsubsequently, at the global level. Although the second phase of the algorithm\nhas been thoroughly studied, configured, and refined in the past, in\nparticular, its first stage has hardly been examined.\n  In this paper, we thus focus on the first stage of EAX and introduce a novel\nmethod that quickly verifies whether the AB-cycles, generated during its\ninternal optimization procedure, yield valid tours -- or whether they need to\nbe repaired. Knowledge of the latter is also particularly relevant before\napplying other powerful crossover operators such as the Generalized Partition\nCrossover (GPX). Based on our insights, we propose and evaluate several\nimproved versions of EAX. According to our benchmark study across 10 000\ndifferent TSP instances, the most promising of our proposed EAX variants\ndemonstrates improved computational efficiency and solution quality on\npreviously rather difficult instances compared to the current state-of-the-art\nEAX algorithm.", "AI": {"tldr": "The paper introduces a novel method to improve the first stage of the Edge Assembly Crossover (EAX) algorithm for the TSP, enhancing computational efficiency and solution quality.", "motivation": "The first stage of EAX has been understudied, and improving it can enhance the algorithm's overall performance, especially for difficult TSP instances.", "method": "The proposed method verifies AB-cycles for validity before further optimization, leading to improved EAX variants.", "result": "Benchmarking on 10,000 TSP instances shows the best variant outperforms the current EAX in efficiency and solution quality.", "conclusion": "The study successfully refines the EAX algorithm, particularly its first stage, demonstrating significant improvements for challenging TSP instances."}}
{"id": "2505.00930", "pdf": "https://arxiv.org/pdf/2505.00930", "abs": "https://arxiv.org/abs/2505.00930", "authors": ["Lokesh Nagalapatti", "Ashutosh Srivastava", "Sunita Sarawagi", "Amit Sharma"], "title": "Robust Root Cause Diagnosis using In-Distribution Interventions", "categories": ["cs.LG"], "comment": "Accepted at ICLR-25", "summary": "Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today's cloud services and industrial operations. We\npropose In-Distribution Interventions (IDI), a novel algorithm that predicts\nroot cause as nodes that meet two criteria: 1) **Anomaly:** root cause nodes\nshould take on anomalous values; 2) **Fix:** had the root cause nodes assumed\nusual values, the target node would not have been anomalous. Prior methods of\nassessing the fix condition rely on counterfactuals inferred from a Structural\nCausal Model (SCM) trained on historical data. But since anomalies are rare and\nfall outside the training distribution, the fitted SCMs yield unreliable\ncounterfactual estimates. IDI overcomes this by relying on interventional\nestimates obtained by solely probing the fitted SCM at in-distribution inputs.\nWe present a theoretical analysis comparing and bounding the errors in\nassessing the fix condition using interventional and counterfactual estimates.\nWe then conduct experiments by systematically varying the SCM's complexity to\ndemonstrate the cases where IDI's interventional approach outperforms the\ncounterfactual approach and vice versa. Experiments on both synthetic and\nPetShop RCD benchmark datasets demonstrate that \\our\\ consistently identifies\ntrue root causes more accurately and robustly than nine existing\nstate-of-the-art RCD baselines. Code is released at\nhttps://github.com/nlokeshiisc/IDI_release.", "AI": {"tldr": "IDI is a novel algorithm for diagnosing root causes in complex systems by using in-distribution interventions, outperforming existing methods.", "motivation": "Addressing unreliable counterfactual estimates in anomaly diagnosis due to rare anomalies falling outside training distributions.", "method": "Uses interventional estimates from a fitted SCM at in-distribution inputs to assess root cause criteria (anomaly and fix).", "result": "IDI outperforms nine state-of-the-art baselines in accuracy and robustness on synthetic and PetShop datasets.", "conclusion": "IDI provides a more reliable and accurate approach for root cause diagnosis in complex systems."}}
{"id": "2505.00998", "pdf": "https://arxiv.org/pdf/2505.00998", "abs": "https://arxiv.org/abs/2505.00998", "authors": ["Yu Hua", "Weiming Liu", "Gui Xu", "Yaqing Hou", "Yew-Soon Ong", "Qiang Zhang"], "title": "Deterministic-to-Stochastic Diverse Latent Feature Mapping for Human Motion Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "Human motion synthesis aims to generate plausible human motion sequences,\nwhich has raised widespread attention in computer animation. Recent score-based\ngenerative models (SGMs) have demonstrated impressive results on this task.\nHowever, their training process involves complex curvature trajectories,\nleading to unstable training process. In this paper, we propose a\nDeterministic-to-Stochastic Diverse Latent Feature Mapping (DSDFM) method for\nhuman motion synthesis. DSDFM consists of two stages. The first human motion\nreconstruction stage aims to learn the latent space distribution of human\nmotions. The second diverse motion generation stage aims to build connections\nbetween the Gaussian distribution and the latent space distribution of human\nmotions, thereby enhancing the diversity and accuracy of the generated human\nmotions. This stage is achieved by the designed deterministic feature mapping\nprocedure with DerODE and stochastic diverse output generation procedure with\nDivSDE.DSDFM is easy to train compared to previous SGMs-based methods and can\nenhance diversity without introducing additional training parameters.Through\nqualitative and quantitative experiments, DSDFM achieves state-of-the-art\nresults surpassing the latest methods, validating its superiority in human\nmotion synthesis.", "AI": {"tldr": "DSDFM is a two-stage method for human motion synthesis, improving diversity and accuracy without extra training parameters, outperforming existing methods.", "motivation": "Addressing the unstable training of score-based generative models (SGMs) in human motion synthesis.", "method": "DSDFM: Deterministic-to-Stochastic Diverse Latent Feature Mapping, with stages for motion reconstruction and diverse generation using DerODE and DivSDE.", "result": "Achieves state-of-the-art results in diversity and accuracy, validated by experiments.", "conclusion": "DSDFM is superior to existing methods, offering stable training and enhanced motion synthesis."}}
{"id": "2505.01311", "pdf": "https://arxiv.org/pdf/2505.01311", "abs": "https://arxiv.org/abs/2505.01311", "authors": ["Svenja Kenneweg", "J\u00f6rg Deigm\u00f6ller", "Julian Eggert", "Philipp Cimiano"], "title": "A Factorized Probabilistic Model of the Semantics of Vague Temporal Adverbials Relative to Different Event Types", "categories": ["cs.CL"], "comment": "7 pages, 1 figure, to be published in CogSci Proceedings 2025", "summary": "Vague temporal adverbials, such as recently, just, and a long time ago,\ndescribe the temporal distance between a past event and the utterance time but\nleave the exact duration underspecified. In this paper, we introduce a\nfactorized model that captures the semantics of these adverbials as\nprobabilistic distributions. These distributions are composed with\nevent-specific distributions to yield a contextualized meaning for an adverbial\napplied to a specific event. We fit the model's parameters using existing data\ncapturing judgments of native speakers regarding the applicability of these\nvague temporal adverbials to events that took place a given time ago. Comparing\nour approach to a non-factorized model based on a single Gaussian distribution\nfor each pair of event and temporal adverbial, we find that while both models\nhave similar predictive power, our model is preferable in terms of Occam's\nrazor, as it is simpler and has better extendability.", "AI": {"tldr": "A factorized model captures vague temporal adverbials as probabilistic distributions, outperforming a non-factorized Gaussian model in simplicity and extendability.", "motivation": "To better understand and model the semantics of vague temporal adverbials like 'recently' or 'a long time ago,' which lack exact durations.", "method": "A factorized model is introduced, combining probabilistic distributions of adverbials with event-specific distributions. Parameters are fitted using native speaker judgments.", "result": "The factorized model matches the predictive power of a non-factorized Gaussian model but is simpler and more extendable.", "conclusion": "The factorized model is preferable due to its simplicity and better extendability, aligning with Occam's razor."}}
{"id": "2505.00817", "pdf": "https://arxiv.org/pdf/2505.00817", "abs": "https://arxiv.org/abs/2505.00817", "authors": ["Andrew Adiletta", "Berk Sunar"], "title": "Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models", "categories": ["cs.CR", "cs.AI", "K.6.5"], "comment": null, "summary": "Side-channel attacks on shared hardware resources increasingly threaten\nconfidentiality, especially with the rise of Large Language Models (LLMs). In\nthis work, we introduce Spill The Beans, a novel application of cache\nside-channels to leak tokens generated by an LLM. By co-locating an attack\nprocess on the same hardware as the victim model, we flush and reload embedding\nvectors from the embedding layer, where each token corresponds to a unique\nembedding vector. When accessed during token generation, it results in a cache\nhit detectable by our attack on shared lower-level caches.\n  A significant challenge is the massive size of LLMs, which, by nature of\ntheir compute intensive operation, quickly evicts embedding vectors from the\ncache. We address this by balancing the number of tokens monitored against the\namount of information leaked. Monitoring more tokens increases potential\nvocabulary leakage but raises the chance of missing cache hits due to eviction;\nmonitoring fewer tokens improves detection reliability but limits vocabulary\ncoverage.\n  Through extensive experimentation, we demonstrate the feasibility of leaking\ntokens from LLMs via cache side-channels. Our findings reveal a new\nvulnerability in LLM deployments, highlighting that even sophisticated models\nare susceptible to traditional side-channel attacks. We discuss the\nimplications for privacy and security in LLM-serving infrastructures and\nsuggest considerations for mitigating such threats. For proof of concept we\nconsider two concrete attack scenarios: Our experiments show that an attacker\ncan recover as much as 80%-90% of a high entropy API key with single shot\nmonitoring. As for English text we can reach a 40% recovery rate with a single\nshot. We should note that the rate highly depends on the monitored token set\nand these rates can be improved by targeting more specialized output domains.", "AI": {"tldr": "The paper introduces Spill The Beans, a cache side-channel attack to leak tokens from LLMs, demonstrating vulnerabilities in shared hardware despite the models' sophistication.", "motivation": "The rise of LLMs and shared hardware resources increases the risk of side-channel attacks, threatening confidentiality. This work explores cache side-channels to leak sensitive tokens from LLMs.", "method": "The attack co-locates a process on shared hardware, flushes and reloads embedding vectors, and detects cache hits during token generation. It balances token monitoring for reliability and coverage.", "result": "Experiments show 80%-90% recovery of high-entropy API keys and 40% for English text, revealing LLMs' susceptibility to traditional side-channel attacks.", "conclusion": "The study highlights a new vulnerability in LLM deployments, emphasizing the need for mitigation strategies in LLM-serving infrastructures."}}
{"id": "2505.00932", "pdf": "https://arxiv.org/pdf/2505.00932", "abs": "https://arxiv.org/abs/2505.00932", "authors": ["Yin Huang", "Yongqi Dong", "Youhua Tang", "Alvaro Garc\u00eda Hernandez"], "title": "A Self-Supervised Transformer for Unusable Shared Bike Detection", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": "6 pages, 5 figures, under review by the 2025 IEEE International\n  Conference on Intelligent Transportation Systems (IEEE ITSC 2025)", "summary": "The rapid expansion of bike-sharing systems (BSS) has greatly improved urban\n\"last-mile\" connectivity, yet large-scale deployments face escalating\noperational challenges, particularly in detecting faulty bikes. Existing\ndetection approaches either rely on static model-based thresholds that overlook\ndynamic spatiotemporal (ST) usage patterns or employ supervised learning\nmethods that struggle with label scarcity and class imbalance. To address these\nlimitations, this paper proposes a novel Self-Supervised Transformer\n(SSTransformer) framework for automatically detecting unusable shared bikes,\nleveraging ST features extracted from GPS trajectories and trip records. The\nmodel incorporates a self-supervised pre-training strategy to enhance its\nfeature extraction capabilities, followed by fine-tuning for efficient status\nrecognition. In the pre-training phase, the Transformer encoder learns\ngeneralized representations of bike movement via a self-supervised objective;\nin the fine-tuning phase, the encoder is adapted to a downstream binary\nclassification task. Comprehensive experiments on a real-world dataset of\n10,730 bikes (1,870 unusable, 8,860 normal) from Chengdu, China, demonstrate\nthat SSTransformer significantly outperforms traditional machine learning,\nensemble learning, and deep learning baselines, achieving the best accuracy\n(97.81%), precision (0.8889), and F1-score (0.9358). This work highlights the\neffectiveness of self-supervised Transformer on ST data for capturing complex\nanomalies in BSS, paving the way toward more reliable and scalable maintenance\nsolutions for shared mobility.", "AI": {"tldr": "A novel Self-Supervised Transformer (SSTransformer) framework is proposed to detect faulty bikes in bike-sharing systems, outperforming existing methods with high accuracy and precision.", "motivation": "Existing methods for detecting faulty bikes either ignore dynamic spatiotemporal patterns or suffer from label scarcity and class imbalance.", "method": "The SSTransformer uses self-supervised pre-training on GPS trajectories and trip records, followed by fine-tuning for binary classification.", "result": "The model achieved 97.81% accuracy, 0.8889 precision, and 0.9358 F1-score on a real-world dataset.", "conclusion": "The SSTransformer effectively captures complex anomalies in bike-sharing systems, offering scalable maintenance solutions."}}
{"id": "2505.01003", "pdf": "https://arxiv.org/pdf/2505.01003", "abs": "https://arxiv.org/abs/2505.01003", "authors": ["Kamel Aouaidjia", "Aofan Li", "Wenhao Zhang", "Chongsheng Zhang"], "title": "3D Human Pose Estimation via Spatial Graph Order Attention and Temporal Body Aware Transformer", "categories": ["cs.CV"], "comment": "16 pages, 9 figures, 7 tables", "summary": "Nowadays, Transformers and Graph Convolutional Networks (GCNs) are the\nprevailing techniques for 3D human pose estimation. However, Transformer-based\nmethods either ignore the spatial neighborhood relationships between the joints\nwhen used for skeleton representations or disregard the local temporal patterns\nof the local joint movements in skeleton sequence modeling, while GCN-based\nmethods often neglect the need for pose-specific representations. To address\nthese problems, we propose a new method that exploits the graph modeling\ncapability of GCN to represent each skeleton with multiple graphs of different\norders, incorporated with a newly introduced Graph Order Attention module that\ndynamically emphasizes the most representative orders for each joint. The\nresulting spatial features of the sequence are further processed using a\nproposed temporal Body Aware Transformer that models the global body feature\ndependencies in the sequence with awareness of the local inter-skeleton feature\ndependencies of joints. Given that our 3D pose output aligns with the central\n2D pose in the sequence, we improve the self-attention mechanism to be aware of\nthe central pose while diminishing its focus gradually towards the first and\nthe last poses. Extensive experiments on Human3.6m, MPIINF-3DHP, and HumanEva-I\ndatasets demonstrate the effectiveness of the proposed method. Code and models\nare made available on Github.", "AI": {"tldr": "A new method combines GCNs and Transformers for 3D human pose estimation, addressing limitations of both by using multi-order graphs and a Body Aware Transformer.", "motivation": "Existing Transformer and GCN methods for 3D pose estimation ignore spatial/temporal relationships or pose-specific representations.", "method": "Proposes multi-order graph modeling with Graph Order Attention and a Body Aware Transformer for temporal processing.", "result": "Outperforms on Human3.6m, MPIINF-3DHP, and HumanEva-I datasets.", "conclusion": "The method effectively integrates spatial and temporal features for accurate 3D pose estimation."}}
{"id": "2505.01314", "pdf": "https://arxiv.org/pdf/2505.01314", "abs": "https://arxiv.org/abs/2505.01314", "authors": ["Shang Wang", "Huanrong Tang", "Jianquan Ouyang"], "title": "A Transformer-based Neural Architecture Search Method", "categories": ["cs.CL", "cs.NE"], "comment": "GECCO 2023", "summary": "This paper presents a neural architecture search method based on Transformer\narchitecture, searching cross multihead attention computation ways for\ndifferent number of encoder and decoder combinations. In order to search for\nneural network structures with better translation results, we considered\nperplexity as an auxiliary evaluation metric for the algorithm in addition to\nBLEU scores and iteratively improved each individual neural network within the\npopulation by a multi-objective genetic algorithm. Experimental results show\nthat the neural network structures searched by the algorithm outperform all the\nbaseline models, and that the introduction of the auxiliary evaluation metric\ncan find better models than considering only the BLEU score as an evaluation\nmetric.", "AI": {"tldr": "A neural architecture search method using Transformer and multihead attention, optimized with a multi-objective genetic algorithm, outperforms baselines by incorporating perplexity alongside BLEU scores.", "motivation": "To improve neural network structures for better translation results by exploring diverse attention mechanisms and encoder-decoder combinations.", "method": "Uses a multi-objective genetic algorithm to iteratively improve neural networks, evaluating with both BLEU scores and perplexity.", "result": "Searched architectures outperform baselines; perplexity as an auxiliary metric finds better models than BLEU alone.", "conclusion": "Incorporating additional evaluation metrics like perplexity enhances neural architecture search for translation tasks."}}
{"id": "2505.00841", "pdf": "https://arxiv.org/pdf/2505.00841", "abs": "https://arxiv.org/abs/2505.00841", "authors": ["Tao Li", "Ya-Ting Yang", "Yunian Pan", "Quanyan Zhu"], "title": "From Texts to Shields: Convergence of Large Language Models and Cybersecurity", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This report explores the convergence of large language models (LLMs) and\ncybersecurity, synthesizing interdisciplinary insights from network security,\nartificial intelligence, formal methods, and human-centered design. It examines\nemerging applications of LLMs in software and network security, 5G\nvulnerability analysis, and generative security engineering. The report\nhighlights the role of agentic LLMs in automating complex tasks, improving\noperational efficiency, and enabling reasoning-driven security analytics.\nSocio-technical challenges associated with the deployment of LLMs -- including\ntrust, transparency, and ethical considerations -- can be addressed through\nstrategies such as human-in-the-loop systems, role-specific training, and\nproactive robustness testing. The report further outlines critical research\nchallenges in ensuring interpretability, safety, and fairness in LLM-based\nsystems, particularly in high-stakes domains. By integrating technical advances\nwith organizational and societal considerations, this report presents a\nforward-looking research agenda for the secure and effective adoption of LLMs\nin cybersecurity.", "AI": {"tldr": "The report explores the intersection of LLMs and cybersecurity, highlighting applications, challenges, and solutions for secure adoption.", "motivation": "To synthesize interdisciplinary insights and address the role of LLMs in cybersecurity, including automation, efficiency, and ethical challenges.", "method": "Examines emerging applications of LLMs in security domains and proposes strategies like human-in-the-loop systems and robustness testing.", "result": "Identifies the potential of LLMs in security tasks but underscores socio-technical challenges like trust and fairness.", "conclusion": "Presents a research agenda for secure LLM adoption in cybersecurity, balancing technical and societal considerations."}}
{"id": "2505.00933", "pdf": "https://arxiv.org/pdf/2505.00933", "abs": "https://arxiv.org/abs/2505.00933", "authors": ["A. H. Abbas"], "title": "TunnElQNN: A Hybrid Quantum-classical Neural Network for Efficient Learning", "categories": ["cs.LG", "physics.app-ph", "quant-ph"], "comment": "11 pages, 6 figures", "summary": "Hybrid quantum-classical neural networks (HQCNNs) represent a promising\nfrontier in machine learning, leveraging the complementary strengths of both\nmodels. In this work, we propose the development of TunnElQNN, a non-sequential\narchitecture composed of alternating classical and quantum layers. Within the\nclassical component, we employ the Tunnelling Diode Activation Function (TDAF),\ninspired by the I-V characteristics of quantum tunnelling. We evaluate the\nperformance of this hybrid model on a synthetic dataset of interleaving\nhalf-circle for multi-class classification tasks with varying degrees of class\noverlap. The model is compared against a baseline hybrid architecture that uses\nthe conventional ReLU activation function (ReLUQNN). Our results show that the\nTunnElQNN model consistently outperforms the ReLUQNN counterpart. Furthermore,\nwe analyse the decision boundaries generated by TunnElQNN under different\nlevels of class overlap and compare them to those produced by a neural network\nimplementing TDAF within a fully classical architecture. These findings\nhighlight the potential of integrating physics-inspired activation functions\nwith quantum components to enhance the expressiveness and robustness of hybrid\nquantum-classical machine learning architectures.", "AI": {"tldr": "TunnElQNN, a hybrid quantum-classical neural network with TDAF, outperforms ReLUQNN in multi-class classification tasks, showcasing the benefits of physics-inspired activation functions in hybrid architectures.", "motivation": "To enhance hybrid quantum-classical neural networks by integrating physics-inspired activation functions (TDAF) and evaluating their performance against conventional methods.", "method": "Proposed TunnElQNN, a non-sequential hybrid architecture with alternating classical (TDAF) and quantum layers, tested on a synthetic dataset with varying class overlap.", "result": "TunnElQNN consistently outperformed ReLUQNN and demonstrated superior decision boundaries compared to fully classical TDAF networks.", "conclusion": "Integrating physics-inspired activation functions with quantum components improves the expressiveness and robustness of hybrid quantum-classical machine learning models."}}
{"id": "2505.01016", "pdf": "https://arxiv.org/pdf/2505.01016", "abs": "https://arxiv.org/abs/2505.01016", "authors": ["Vishal Gandhi", "Sagar Gandhi"], "title": "Fine-Tuning Without Forgetting: Adaptation of YOLOv8 Preserves COCO Performance", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The success of large pre-trained object detectors hinges on their\nadaptability to diverse downstream tasks. While fine-tuning is the standard\nadaptation method, specializing these models for challenging fine-grained\ndomains necessitates careful consideration of feature granularity. The critical\nquestion remains: how deeply should the pre-trained backbone be fine-tuned to\noptimize for the specialized task without incurring catastrophic forgetting of\nthe original general capabilities? Addressing this, we present a systematic\nempirical study evaluating the impact of fine-tuning depth. We adapt a standard\nYOLOv8n model to a custom, fine-grained fruit detection dataset by\nprogressively unfreezing backbone layers (freeze points at layers 22, 15, and\n10) and training. Performance was rigorously evaluated on both the target fruit\ndataset and, using a dual-head evaluation architecture, on the original COCO\nvalidation set. Our results demonstrate unequivocally that deeper fine-tuning\n(unfreezing down to layer 10) yields substantial performance gains (e.g., +10\\%\nabsolute mAP50) on the fine-grained fruit task compared to only training the\nhead. Strikingly, this significant adaptation and specialization resulted in\nnegligible performance degradation (<0.1\\% absolute mAP difference) on the COCO\nbenchmark across all tested freeze levels. We conclude that adapting\nmid-to-late backbone features is highly effective for fine-grained\nspecialization. Critically, our results demonstrate this adaptation can be\nachieved without the commonly expected penalty of catastrophic forgetting,\npresenting a compelling case for exploring deeper fine-tuning strategies,\nparticularly when targeting complex domains or when maximizing specialized\nperformance is paramount.", "AI": {"tldr": "Deeper fine-tuning of pre-trained object detectors (down to layer 10) significantly improves performance on fine-grained tasks without degrading general capabilities.", "motivation": "To determine the optimal depth for fine-tuning pre-trained object detectors to balance specialization and retention of general capabilities.", "method": "Adapted YOLOv8n to a fruit detection dataset by progressively unfreezing backbone layers (22, 15, 10) and evaluated performance on both the target dataset and COCO.", "result": "Deeper fine-tuning (layer 10) improved fruit detection by +10% mAP50 with negligible (<0.1%) loss on COCO.", "conclusion": "Mid-to-late backbone fine-tuning is effective for specialization without catastrophic forgetting, advocating deeper fine-tuning for complex domains."}}
{"id": "2505.01315", "pdf": "https://arxiv.org/pdf/2505.01315", "abs": "https://arxiv.org/abs/2505.01315", "authors": ["Sheikh Samit Muhaimin", "Spyridon Mastorakis"], "title": "Helping Big Language Models Protect Themselves: An Enhanced Filtering and Summarization System", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The recent growth in the use of Large Language Models has made them\nvulnerable to sophisticated adversarial assaults, manipulative prompts, and\nencoded malicious inputs. Existing countermeasures frequently necessitate\nretraining models, which is computationally costly and impracticable for\ndeployment. Without the need for retraining or fine-tuning, this study presents\na unique defense paradigm that allows LLMs to recognize, filter, and defend\nagainst adversarial or malicious inputs on their own. There are two main parts\nto the suggested framework: (1) A prompt filtering module that uses\nsophisticated Natural Language Processing (NLP) techniques, including zero-shot\nclassification, keyword analysis, and encoded content detection (e.g. base64,\nhexadecimal, URL encoding), to detect, decode, and classify harmful inputs; and\n(2) A summarization module that processes and summarizes adversarial research\nliterature to give the LLM context-aware defense knowledge. This approach\nstrengthens LLMs' resistance to adversarial exploitation by fusing text\nextraction, summarization, and harmful prompt analysis. According to\nexperimental results, this integrated technique has a 98.71% success rate in\nidentifying harmful patterns, manipulative language structures, and encoded\nprompts. By employing a modest amount of adversarial research literature as\ncontext, the methodology also allows the model to react correctly to harmful\ninputs with a larger percentage of jailbreak resistance and refusal rate. While\nmaintaining the quality of LLM responses, the framework dramatically increases\nLLM's resistance to hostile misuse, demonstrating its efficacy as a quick and\neasy substitute for time-consuming, retraining-based defenses.", "AI": {"tldr": "A defense framework for LLMs detects and filters adversarial inputs without retraining, using NLP techniques and summarization of adversarial literature, achieving 98.71% success in identifying threats.", "motivation": "The rise in adversarial attacks on LLMs necessitates cost-effective, deployable defenses without retraining.", "method": "Combines prompt filtering (NLP techniques like zero-shot classification, keyword analysis, encoded content detection) and summarization of adversarial literature for context-aware defense.", "result": "98.71% success in detecting harmful inputs, improved jailbreak resistance, and refusal rates.", "conclusion": "The framework effectively enhances LLM security without retraining, offering a practical alternative to traditional defenses."}}
{"id": "2505.00843", "pdf": "https://arxiv.org/pdf/2505.00843", "abs": "https://arxiv.org/abs/2505.00843", "authors": ["Jinsheng Pan", "Xiaogeng Liu", "Chaowei Xiao"], "title": "OET: Optimization-based prompt injection Evaluation Toolkit", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation, enabling their widespread\nadoption across various domains. However, their susceptibility to prompt\ninjection attacks poses significant security risks, as adversarial inputs can\nmanipulate model behavior and override intended instructions. Despite numerous\ndefense strategies, a standardized framework to rigorously evaluate their\neffectiveness, especially under adaptive adversarial scenarios, is lacking. To\naddress this gap, we introduce OET, an optimization-based evaluation toolkit\nthat systematically benchmarks prompt injection attacks and defenses across\ndiverse datasets using an adaptive testing framework. Our toolkit features a\nmodular workflow that facilitates adversarial string generation, dynamic attack\nexecution, and comprehensive result analysis, offering a unified platform for\nassessing adversarial robustness. Crucially, the adaptive testing framework\nleverages optimization methods with both white-box and black-box access to\ngenerate worst-case adversarial examples, thereby enabling strict red-teaming\nevaluations. Extensive experiments underscore the limitations of current\ndefense mechanisms, with some models remaining susceptible even after\nimplementing security enhancements.", "AI": {"tldr": "The paper introduces OET, an optimization-based toolkit to evaluate prompt injection attacks and defenses in LLMs, highlighting current defense limitations.", "motivation": "Address the lack of a standardized framework to rigorously evaluate the effectiveness of defenses against prompt injection attacks in LLMs.", "method": "Develop OET, a modular toolkit featuring adversarial string generation, dynamic attack execution, and adaptive testing with optimization methods.", "result": "Experiments reveal vulnerabilities in current defenses, with some models remaining susceptible despite enhancements.", "conclusion": "OET provides a unified platform for assessing adversarial robustness, emphasizing the need for improved defenses."}}
{"id": "2505.00940", "pdf": "https://arxiv.org/pdf/2505.00940", "abs": "https://arxiv.org/abs/2505.00940", "authors": ["Zhenyu Wang", "Molei Liu", "Jing Lei", "Francis Bach", "Zijian Guo"], "title": "StablePCA: Learning Shared Representations across Multiple Sources via Minimax Optimization", "categories": ["cs.LG", "math.OC", "stat.CO", "stat.ME"], "comment": null, "summary": "When synthesizing multisource high-dimensional data, a key objective is to\nextract low-dimensional feature representations that effectively approximate\nthe original features across different sources. Such general feature extraction\nfacilitates the discovery of transferable knowledge, mitigates systematic\nbiases such as batch effects, and promotes fairness. In this paper, we propose\nStable Principal Component Analysis (StablePCA), a novel method for group\ndistributionally robust learning of latent representations from\nhigh-dimensional multi-source data. A primary challenge in generalizing PCA to\nthe multi-source regime lies in the nonconvexity of the fixed rank constraint,\nrendering the minimax optimization nonconvex. To address this challenge, we\nemploy the Fantope relaxation, reformulating the problem as a convex minimax\noptimization, with the objective defined as the maximum loss across sources. To\nsolve the relaxed formulation, we devise an optimistic-gradient Mirror Prox\nalgorithm with explicit closed-form updates. Theoretically, we establish the\nglobal convergence of the Mirror Prox algorithm, with the convergence rate\nprovided from the optimization perspective. Furthermore, we offer practical\ncriteria to assess how closely the solution approximates the original nonconvex\nformulation. Through extensive numerical experiments, we demonstrate\nStablePCA's high accuracy and efficiency in extracting robust low-dimensional\nrepresentations across various finite-sample scenarios.", "AI": {"tldr": "StablePCA is a novel method for robust low-dimensional feature extraction from multi-source high-dimensional data, addressing nonconvexity via Fantope relaxation and Mirror Prox optimization.", "motivation": "To generalize PCA for multi-source data, overcoming nonconvexity and extracting transferable, bias-mitigated features.", "method": "Uses Fantope relaxation for convex minimax optimization, solved via Mirror Prox algorithm with closed-form updates.", "result": "Demonstrates high accuracy and efficiency in robust feature extraction across finite-sample scenarios.", "conclusion": "StablePCA effectively generalizes PCA for multi-source data, offering theoretical convergence and practical robustness."}}
{"id": "2505.01032", "pdf": "https://arxiv.org/pdf/2505.01032", "abs": "https://arxiv.org/abs/2505.01032", "authors": ["Ruyu Yan", "Da-Qing Zhang"], "title": "Edge-preserving Image Denoising via Multi-scale Adaptive Statistical Independence Testing", "categories": ["cs.CV"], "comment": null, "summary": "Edge detection is crucial in image processing, but existing methods often\nproduce overly detailed edge maps, affecting clarity. Fixed-window statistical\ntesting faces issues like scale mismatch and computational redundancy. To\naddress these, we propose a novel Multi-scale Adaptive Independence\nTesting-based Edge Detection and Denoising (EDD-MAIT), a Multi-scale Adaptive\nStatistical Testing-based edge detection and denoising method that integrates a\nchannel attention mechanism with independence testing. A gradient-driven\nadaptive window strategy adjusts window sizes dynamically, improving detail\npreservation and noise suppression. EDD-MAIT achieves better robustness,\naccuracy, and efficiency, outperforming traditional and learning-based methods\non BSDS500 and BIPED datasets, with improvements in F-score, MSE, PSNR, and\nreduced runtime. It also shows robustness against Gaussian noise, generating\naccurate and clean edge maps in noisy environments.", "AI": {"tldr": "EDD-MAIT is a novel edge detection and denoising method using multi-scale adaptive statistical testing and a channel attention mechanism, outperforming existing methods in accuracy, efficiency, and noise robustness.", "motivation": "Existing edge detection methods produce overly detailed edge maps and face issues like scale mismatch and computational redundancy.", "method": "Proposes EDD-MAIT, integrating multi-scale adaptive statistical testing with a channel attention mechanism and gradient-driven adaptive window strategy.", "result": "Outperforms traditional and learning-based methods on BSDS500 and BIPED datasets, with better F-score, MSE, PSNR, and runtime. Robust against Gaussian noise.", "conclusion": "EDD-MAIT improves edge detection clarity, detail preservation, and noise suppression, offering superior performance in noisy environments."}}
{"id": "2505.01325", "pdf": "https://arxiv.org/pdf/2505.01325", "abs": "https://arxiv.org/abs/2505.01325", "authors": ["Svenja Kenneweg", "J\u00f6rg Deigm\u00f6ller", "Philipp Cimiano", "Julian Eggert"], "title": "TRAVELER: A Benchmark for Evaluating Temporal Reasoning across Vague, Implicit and Explicit References", "categories": ["cs.CL"], "comment": "24 pages, 6 figures, submitted to Springer Nature Computer Science", "summary": "Understanding and resolving temporal references is essential in Natural\nLanguage Understanding as we often refer to the past or future in daily\ncommunication. Although existing benchmarks address a system's ability to\nreason about and resolve temporal references, systematic evaluation of specific\ntemporal references remains limited. Towards closing this gap, we introduce\nTRAVELER, a novel synthetic benchmark dataset that follows a Question Answering\nparadigm and consists of questions involving temporal references with the\ncorresponding correct answers. TRAVELER assesses models' abilities to resolve\nexplicit, implicit relative to speech time, and vague temporal references.\nBeyond investigating the performance of state-of-the-art LLMs depending on the\ntype of temporal reference, our benchmark also allows evaluation of performance\nin relation to the length of the set of events. For the category of vague\ntemporal references, ground-truth answers were established via human surveys on\nProlific, following a procedure similar to the one from Kenneweg et al. To\ndemonstrate the benchmark's applicability, we evaluate four state-of-the-art\nLLMs using a question-answering task encompassing 3,300 questions. Our findings\nshow that while the benchmarked LLMs can answer questions over event sets with\na handful of events and explicit temporal references successfully, performance\nclearly deteriorates with larger event set length and when temporal references\nget less explicit. Notably, the vague question category exhibits the lowest\nperformance across all models.\n  The benchmark is publicly available at:\nhttps://gitlab.ub.uni-bielefeld.de/s.kenneweg/TRAVELER", "AI": {"tldr": "TRAVELER is a synthetic benchmark dataset for evaluating LLMs' ability to resolve temporal references in QA tasks, showing performance drops with larger event sets and less explicit references.", "motivation": "Existing benchmarks lack systematic evaluation of specific temporal references, prompting the creation of TRAVELER to address this gap.", "method": "TRAVELER uses a QA paradigm with 3,300 questions to assess LLMs on explicit, implicit, and vague temporal references, with human surveys for vague answers.", "result": "LLMs perform well with explicit references and small event sets but struggle with larger sets and vague references.", "conclusion": "TRAVELER highlights LLMs' limitations in temporal reasoning, especially for vague references, and provides a tool for future research."}}
{"id": "2505.00871", "pdf": "https://arxiv.org/pdf/2505.00871", "abs": "https://arxiv.org/abs/2505.00871", "authors": ["Jun Takamatsu", "Atsushi Kanehira", "Kazuhiro Sasabuchi", "Naoki Wake", "Katsushi Ikeuchi"], "title": "IK Seed Generator for Dual-Arm Human-like Physicality Robot with Mobile Base", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 12 figures, 4 tables", "summary": "Robots are strongly expected as a means of replacing human tasks. If a robot\nhas a human-like physicality, the possibility of replacing human tasks\nincreases. In the case of household service robots, it is desirable for them to\nbe on a human-like size so that they do not become excessively large in order\nto coexist with humans in their operating environment. However, robots with\nsize limitations tend to have difficulty solving inverse kinematics (IK) due to\nmechanical limitations, such as joint angle limitations. Conversely, if the\ndifficulty coming from this limitation could be mitigated, one can expect that\nthe use of such robots becomes more valuable. In numerical IK solver, which is\ncommonly used for robots with higher degrees-of-freedom (DOF), the solvability\nof IK depends on the initial guess given to the solver. Thus, this paper\nproposes a method for generating a good initial guess for a numerical IK solver\ngiven the target hand configuration. For the purpose, we define the goodness of\nan initial guess using the scaled Jacobian matrix, which can calculate the\nmanipulability index considering the joint limits. These two factors are\nrelated to the difficulty of solving IK. We generate the initial guess by\noptimizing the goodness using the genetic algorithm (GA). To enumerate much\npossible IK solutions, we use the reachability map that represents the\nreachable area of the robot hand in the arm-base coordinate system. We conduct\nquantitative evaluation and prove that using an initial guess that is judged to\nbe better using the goodness value increases the probability that IK is solved.\nFinally, as an application of the proposed method, we show that by generating\ngood initial guesses for IK a robot actually achieves three typical scenarios.", "AI": {"tldr": "The paper proposes a method to generate good initial guesses for numerical inverse kinematics (IK) solvers in human-sized robots, improving solvability by optimizing manipulability and joint limits using a genetic algorithm.", "motivation": "Human-sized robots face IK challenges due to mechanical limitations. Improving IK solvability enhances their utility in tasks like household services.", "method": "Defines initial guess goodness using a scaled Jacobian matrix, optimizes it via genetic algorithm, and uses a reachability map to enumerate solutions.", "result": "Quantitative evaluation shows better initial guesses increase IK solvability. The method is applied successfully in three scenarios.", "conclusion": "The proposed method effectively improves IK solvability for human-sized robots, enhancing their practical applications."}}
{"id": "2505.00941", "pdf": "https://arxiv.org/pdf/2505.00941", "abs": "https://arxiv.org/abs/2505.00941", "authors": ["Wenxin Zhang", "Ding Xu", "Guangzhen Yao", "Xiaojian Lin", "Renxiang Guan", "Chengze Du", "Renda Han", "Xi Xuan", "Cuicui Luo"], "title": "FreCT: Frequency-augmented Convolutional Transformer for Robust Time Series Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "Time series anomaly detection is critical for system monitoring and risk\nidentification, across various domains, such as finance and healthcare.\nHowever, for most reconstruction-based approaches, detecting anomalies remains\na challenge due to the complexity of sequential patterns in time series data.\nOn the one hand, reconstruction-based techniques are susceptible to\ncomputational deviation stemming from anomalies, which can lead to impure\nrepresentations of normal sequence patterns. On the other hand, they often\nfocus on the time-domain dependencies of time series, while ignoring the\nalignment of frequency information beyond the time domain. To address these\nchallenges, we propose a novel Frequency-augmented Convolutional Transformer\n(FreCT). FreCT utilizes patch operations to generate contrastive views and\nemploys an improved Transformer architecture integrated with a convolution\nmodule to capture long-term dependencies while preserving local topology\ninformation. The introduced frequency analysis based on Fourier transformation\ncould enhance the model's ability to capture crucial characteristics beyond the\ntime domain. To protect the training quality from anomalies and improve the\nrobustness, FreCT deploys stop-gradient Kullback-Leibler (KL) divergence and\nabsolute error to optimize consistency information in both time and frequency\ndomains. Extensive experiments on four public datasets demonstrate that FreCT\noutperforms existing methods in identifying anomalies.", "AI": {"tldr": "FreCT, a novel Frequency-augmented Convolutional Transformer, improves time series anomaly detection by integrating frequency analysis and robust training techniques, outperforming existing methods.", "motivation": "Reconstruction-based anomaly detection methods struggle with computational deviations and neglect frequency-domain alignment, limiting their effectiveness.", "method": "FreCT combines patch operations, an improved Transformer with convolution, and Fourier-based frequency analysis, optimized via stop-gradient KL divergence and absolute error.", "result": "FreCT outperforms existing methods on four public datasets in anomaly detection.", "conclusion": "FreCT addresses limitations of reconstruction-based approaches by leveraging frequency-domain insights and robust optimization, enhancing anomaly detection performance."}}
{"id": "2505.01040", "pdf": "https://arxiv.org/pdf/2505.01040", "abs": "https://arxiv.org/abs/2505.01040", "authors": ["Ru-yu Yan", "Da-Qing Zhang"], "title": "Edge Detection based on Channel Attention and Inter-region Independence Test", "categories": ["cs.CV"], "comment": null, "summary": "Existing edge detection methods often suffer from noise amplification and\nexcessive retention of non-salient details, limiting their applicability in\nhigh-precision industrial scenarios. To address these challenges, we propose\nCAM-EDIT, a novel framework that integrates Channel Attention Mechanism (CAM)\nand Edge Detection via Independence Testing (EDIT). The CAM module adaptively\nenhances discriminative edge features through multi-channel fusion, while the\nEDIT module employs region-wise statistical independence analysis (using\nFisher's exact test and chi-square test) to suppress uncorrelated\nnoise.Extensive experiments on BSDS500 and NYUDv2 datasets demonstrate\nstate-of-the-art performance. Among the nine comparison algorithms, the\nF-measure scores of CAM-EDIT are 0.635 and 0.460, representing improvements of\n19.2\\% to 26.5\\% over traditional methods (Canny, CannySR), and better than the\nlatest learning based methods (TIP2020, MSCNGP). Noise robustness evaluations\nfurther reveal a 2.2\\% PSNR improvement under Gaussian noise compared to\nbaseline methods. Qualitative results exhibit cleaner edge maps with reduced\nartifacts, demonstrating its potential for high-precision industrial\napplications.", "AI": {"tldr": "CAM-EDIT integrates CAM and EDIT for edge detection, outperforming traditional and learning-based methods with improved noise robustness.", "motivation": "Address noise amplification and excessive retention of non-salient details in edge detection for high-precision industrial applications.", "method": "Combines CAM for adaptive feature enhancement and EDIT for noise suppression via statistical independence analysis.", "result": "Achieves state-of-the-art F-measure scores (0.635, 0.460) and 2.2% PSNR improvement under noise.", "conclusion": "CAM-EDIT produces cleaner edge maps, suitable for high-precision industrial use."}}
{"id": "2505.00831", "pdf": "https://arxiv.org/pdf/2505.00831", "abs": "https://arxiv.org/abs/2505.00831", "authors": ["Quang P. M. Pham", "Khoi T. N. Nguyen", "Nhi H. Doan", "Cuong A. Pham", "Kentaro Inui", "Dezhen Song"], "title": "SmallPlan: Leverage Small Language Models for Sequential Path Planning with Simulation-Powered, LLM-Guided Distillation", "categories": ["cs.RO", "cs.CL"], "comment": "Paper is under review", "summary": "Efficient path planning in robotics, particularly within large-scale, dynamic\nenvironments, remains a significant hurdle. While Large Language Models (LLMs)\noffer strong reasoning capabilities, their high computational cost and limited\nadaptability in dynamic scenarios hinder real-time deployment on edge devices.\nWe present SmallPlan -- a novel framework leveraging LLMs as teacher models to\ntrain lightweight Small Language Models (SLMs) for high-level path planning\ntasks. In SmallPlan, the SLMs provide optimal action sequences to navigate\nacross scene graphs that compactly represent full-scaled 3D scenes. The SLMs\nare trained in a simulation-powered, interleaved manner with LLM-guided\nsupervised fine-tuning (SFT) and reinforcement learning (RL). This strategy not\nonly enables SLMs to successfully complete navigation tasks but also makes them\naware of important factors like travel distance and number of trials. Through\nexperiments, we demonstrate that the fine-tuned SLMs perform competitively with\nlarger models like GPT-4o on sequential path planning, without suffering from\nhallucination and overfitting. SmallPlan is resource-efficient, making it\nwell-suited for edge-device deployment and advancing practical autonomous\nrobotics.", "AI": {"tldr": "SmallPlan trains lightweight Small Language Models (SLMs) using LLMs as teachers for efficient path planning in robotics, achieving competitive performance with larger models while being resource-efficient.", "motivation": "Addressing the high computational cost and limited adaptability of LLMs in dynamic, large-scale robotic environments.", "method": "Uses LLM-guided supervised fine-tuning (SFT) and reinforcement learning (RL) to train SLMs for path planning tasks.", "result": "Fine-tuned SLMs perform competitively with larger models like GPT-4o, avoiding hallucination and overfitting.", "conclusion": "SmallPlan is resource-efficient and suitable for edge-device deployment, advancing practical autonomous robotics."}}
{"id": "2505.00886", "pdf": "https://arxiv.org/pdf/2505.00886", "abs": "https://arxiv.org/abs/2505.00886", "authors": ["Milad Sabouri", "Masoud Mansoury", "Kun Lin", "Bamshad Mobasher"], "title": "Towards Explainable Temporal User Profiling with LLMs", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Accurately modeling user preferences is vital not only for improving\nrecommendation performance but also for enhancing transparency in recommender\nsystems. Conventional user profiling methods, such as averaging item\nembeddings, often overlook the evolving, nuanced nature of user interests,\nparticularly the interplay between short-term and long-term preferences. In\nthis work, we leverage large language models (LLMs) to generate natural\nlanguage summaries of users' interaction histories, distinguishing recent\nbehaviors from more persistent tendencies. Our framework not only models\ntemporal user preferences but also produces natural language profiles that can\nbe used to explain recommendations in an interpretable manner. These textual\nprofiles are encoded via a pre-trained model, and an attention mechanism\ndynamically fuses the short-term and long-term embeddings into a comprehensive\nuser representation. Beyond boosting recommendation accuracy over multiple\nbaselines, our approach naturally supports explainability: the interpretable\ntext summaries and attention weights can be exposed to end users, offering\ninsights into why specific items are suggested. Experiments on real-world\ndatasets underscore both the performance gains and the promise of generating\nclearer, more transparent justifications for content-based recommendations.", "AI": {"tldr": "The paper introduces a framework using LLMs to model and explain user preferences by distinguishing short-term and long-term behaviors, improving recommendation accuracy and transparency.", "motivation": "To address the limitations of conventional user profiling methods in capturing evolving user interests and enhancing transparency in recommender systems.", "method": "Leverages LLMs to generate natural language summaries of user histories, encodes these profiles, and uses an attention mechanism to fuse short-term and long-term preferences.", "result": "Boosts recommendation accuracy and provides interpretable text summaries and attention weights for explainability.", "conclusion": "The approach effectively models temporal user preferences and supports transparent, explainable recommendations."}}
{"id": "2505.00946", "pdf": "https://arxiv.org/pdf/2505.00946", "abs": "https://arxiv.org/abs/2505.00946", "authors": ["Wenxin Zhang", "Ding Xu", "Xi Xuan", "Lei Jiang", "Guangzhen Yao", "Renda Han", "Xiangxiang Lang", "Cuicui Luo"], "title": "Addressing Noise and Stochasticity in Fraud Detection for Service Networks", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Fraud detection is crucial in social service networks to maintain user trust\nand improve service network security. Existing spectral graph-based methods\naddress this challenge by leveraging different graph filters to capture signals\nwith different frequencies in service networks. However, most graph\nfilter-based methods struggle with deriving clean and discriminative graph\nsignals. On the one hand, they overlook the noise in the information\npropagation process, resulting in degradation of filtering ability. On the\nother hand, they fail to discriminate the frequency-specific characteristics of\ngraph signals, leading to distortion of signals fusion. To address these\nissues, we develop a novel spectral graph network based on information\nbottleneck theory (SGNN-IB) for fraud detection in service networks. SGNN-IB\nsplits the original graph into homophilic and heterophilic subgraphs to better\ncapture the signals at different frequencies. For the first limitation, SGNN-IB\napplies information bottleneck theory to extract key characteristics of encoded\nrepresentations. For the second limitation, SGNN-IB introduces prototype\nlearning to implement signal fusion, preserving the frequency-specific\ncharacteristics of signals. Extensive experiments on three real-world datasets\ndemonstrate that SGNN-IB outperforms state-of-the-art fraud detection methods.", "AI": {"tldr": "SGNN-IB, a spectral graph network using information bottleneck theory, improves fraud detection by addressing noise and signal fusion issues in service networks.", "motivation": "Existing graph-based fraud detection methods struggle with noise and signal distortion, limiting their effectiveness.", "method": "SGNN-IB splits graphs into homophilic/heterophilic subgraphs, applies information bottleneck theory, and uses prototype learning for signal fusion.", "result": "SGNN-IB outperforms state-of-the-art methods on three real-world datasets.", "conclusion": "SGNN-IB effectively addresses noise and signal fusion challenges, enhancing fraud detection in service networks."}}
{"id": "2505.01050", "pdf": "https://arxiv.org/pdf/2505.01050", "abs": "https://arxiv.org/abs/2505.01050", "authors": ["Kai Hu", "Weichen Yu", "Li Zhang", "Alexander Robey", "Andy Zou", "Chengming Xu", "Haoqi Hu", "Matt Fredrikson"], "title": "Transferable Adversarial Attacks on Black-Box Vision-Language Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Vision Large Language Models (VLLMs) are increasingly deployed to offer\nadvanced capabilities on inputs comprising both text and images. While prior\nresearch has shown that adversarial attacks can transfer from open-source to\nproprietary black-box models in text-only and vision-only contexts, the extent\nand effectiveness of such vulnerabilities remain underexplored for VLLMs. We\npresent a comprehensive analysis demonstrating that targeted adversarial\nexamples are highly transferable to widely-used proprietary VLLMs such as\nGPT-4o, Claude, and Gemini. We show that attackers can craft perturbations to\ninduce specific attacker-chosen interpretations of visual information, such as\nmisinterpreting hazardous content as safe, overlooking sensitive or restricted\nmaterial, or generating detailed incorrect responses aligned with the\nattacker's intent. Furthermore, we discover that universal perturbations --\nmodifications applicable to a wide set of images -- can consistently induce\nthese misinterpretations across multiple proprietary VLLMs. Our experimental\nresults on object recognition, visual question answering, and image captioning\nshow that this vulnerability is common across current state-of-the-art models,\nand underscore an urgent need for robust mitigations to ensure the safe and\nsecure deployment of VLLMs.", "AI": {"tldr": "Adversarial attacks are highly transferable to proprietary VLLMs like GPT-4o, Claude, and Gemini, enabling attackers to manipulate visual interpretations. Universal perturbations can induce consistent misinterpretations across models, highlighting a critical security vulnerability.", "motivation": "To investigate the underexplored vulnerabilities of Vision Large Language Models (VLLMs) to adversarial attacks, especially in multimodal (text and image) contexts.", "method": "Comprehensive analysis involving crafting targeted adversarial examples and universal perturbations to test transferability to proprietary VLLMs. Experiments conducted on tasks like object recognition, visual question answering, and image captioning.", "result": "Adversarial examples are highly transferable, inducing specific misinterpretations (e.g., hazardous content as safe). Universal perturbations work consistently across multiple VLLMs.", "conclusion": "The study reveals a widespread vulnerability in VLLMs, emphasizing the urgent need for robust mitigations to ensure secure deployment."}}
{"id": "2505.00976", "pdf": "https://arxiv.org/pdf/2505.00976", "abs": "https://arxiv.org/abs/2505.00976", "authors": ["Zhiyu Liao", "Kang Chen", "Yuanguo Lin", "Kangkang Li", "Yunxuan Liu", "Hefeng Chen", "Xingwang Huang", "Yuanhui Yu"], "title": "Attack and defense techniques in large language models: A survey and new perspectives", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have become central to numerous natural language\nprocessing tasks, but their vulnerabilities present significant security and\nethical challenges. This systematic survey explores the evolving landscape of\nattack and defense techniques in LLMs. We classify attacks into adversarial\nprompt attack, optimized attacks, model theft, as well as attacks on\napplication of LLMs, detailing their mechanisms and implications. Consequently,\nwe analyze defense strategies, including prevention-based and detection-based\ndefense methods. Although advances have been made, challenges remain to adapt\nto the dynamic threat landscape, balance usability with robustness, and address\nresource constraints in defense implementation. We highlight open problems,\nincluding the need for adaptive scalable defenses, explainable security\ntechniques, and standardized evaluation frameworks. This survey provides\nactionable insights and directions for developing secure and resilient LLMs,\nemphasizing the importance of interdisciplinary collaboration and ethical\nconsiderations to mitigate risks in real-world applications.", "AI": {"tldr": "A survey on attack and defense techniques in LLMs, highlighting vulnerabilities, defense strategies, and open challenges for secure and resilient models.", "motivation": "Addressing the security and ethical challenges posed by vulnerabilities in LLMs, which are central to NLP tasks.", "method": "Systematic classification of attacks (e.g., adversarial prompt, model theft) and defense strategies (prevention/detection-based).", "result": "Identified gaps in adaptive defenses, explainable security, and standardized evaluation, with actionable insights for future work.", "conclusion": "Emphasizes interdisciplinary collaboration and ethical considerations to mitigate risks in LLM applications."}}
{"id": "2505.00917", "pdf": "https://arxiv.org/pdf/2505.00917", "abs": "https://arxiv.org/abs/2505.00917", "authors": ["Tian Bai", "Yue Zhao", "Xiang Yu", "Archer Y. Yang"], "title": "Multivariate Conformal Selection", "categories": ["stat.ME", "cs.AI", "cs.LG", "stat.ML"], "comment": "25 pages, 4 figures. Accepted to ICML 2025", "summary": "Selecting high-quality candidates from large datasets is critical in\napplications such as drug discovery, precision medicine, and alignment of large\nlanguage models (LLMs). While Conformal Selection (CS) provides rigorous\nuncertainty quantification, it is limited to univariate responses and scalar\ncriteria. To address this issue, we propose Multivariate Conformal Selection\n(mCS), a generalization of CS designed for multivariate response settings. Our\nmethod introduces regional monotonicity and employs multivariate nonconformity\nscores to construct conformal p-values, enabling finite-sample False Discovery\nRate (FDR) control. We present two variants: mCS-dist, using distance-based\nscores, and mCS-learn, which learns optimal scores via differentiable\noptimization. Experiments on simulated and real-world datasets demonstrate that\nmCS significantly improves selection power while maintaining FDR control,\nestablishing it as a robust framework for multivariate selection tasks.", "AI": {"tldr": "The paper introduces Multivariate Conformal Selection (mCS), a method extending Conformal Selection (CS) to handle multivariate responses, ensuring FDR control and improved selection power.", "motivation": "Current CS methods are limited to univariate responses, creating a gap for applications like drug discovery and LLM alignment where multivariate data is common.", "method": "mCS generalizes CS by introducing regional monotonicity and multivariate nonconformity scores. Two variants are proposed: mCS-dist (distance-based) and mCS-learn (optimized via differentiable optimization).", "result": "Experiments show mCS enhances selection power while controlling FDR, outperforming univariate CS in multivariate settings.", "conclusion": "mCS is a robust framework for multivariate selection tasks, addressing limitations of CS and demonstrating practical utility."}}
{"id": "2505.00963", "pdf": "https://arxiv.org/pdf/2505.00963", "abs": "https://arxiv.org/abs/2505.00963", "authors": ["Kota Fukuda", "Guanqin Zhang", "Zhenya Zhang", "Yulei Sui", "Jianjun Zhao"], "title": "Adaptive Branch-and-Bound Tree Exploration for Neural Network Verification", "categories": ["cs.LG", "cs.PL"], "comment": "7 pages, 6 figures", "summary": "Formal verification is a rigorous approach that can provably ensure the\nquality of neural networks, and to date, Branch and Bound (BaB) is the\nstate-of-the-art that performs verification by splitting the problem as needed\nand applying off-the-shelf verifiers to sub-problems for improved performance.\nHowever, existing BaB may not be efficient, due to its naive way of exploring\nthe space of sub-problems that ignores the \\emph{importance} of different\nsub-problems. To bridge this gap, we first introduce a notion of ``importance''\nthat reflects how likely a counterexample can be found with a sub-problem, and\nthen we devise a novel verification approach, called ABONN, that explores the\nsub-problem space of BaB adaptively, in a Monte-Carlo tree search (MCTS) style.\nThe exploration is guided by the ``importance'' of different sub-problems, so\nit favors the sub-problems that are more likely to find counterexamples. As\nsoon as it finds a counterexample, it can immediately terminate; even though it\ncannot find, after visiting all the sub-problems, it can still manage to verify\nthe problem. We evaluate ABONN with 552 verification problems from\ncommonly-used datasets and neural network models, and compare it with the\nstate-of-the-art verifiers as baseline approaches. Experimental evaluation\nshows that ABONN demonstrates speedups of up to $15.2\\times$ on MNIST and\n$24.7\\times$ on CIFAR-10. We further study the influences of hyperparameters to\nthe performance of ABONN, and the effectiveness of our adaptive tree\nexploration.", "AI": {"tldr": "ABONN introduces an adaptive Branch and Bound (BaB) approach using Monte-Carlo tree search (MCTS) to prioritize sub-problems by 'importance,' achieving significant speedups in neural network verification.", "motivation": "Existing BaB methods inefficiently explore sub-problems, ignoring their varying importance for finding counterexamples.", "method": "ABONN adaptively explores sub-problems using MCTS, guided by a notion of 'importance' to prioritize likely counterexample regions.", "result": "ABONN achieves speedups of up to 15.2\u00d7 on MNIST and 24.7\u00d7 on CIFAR-10, outperforming state-of-the-art verifiers.", "conclusion": "ABONN efficiently verifies neural networks by adaptively focusing on critical sub-problems, demonstrating practical improvements over existing methods."}}
{"id": "2505.01057", "pdf": "https://arxiv.org/pdf/2505.01057", "abs": "https://arxiv.org/abs/2505.01057", "authors": ["Boris Kriuk", "Matey Yordanov"], "title": "GeloVec: Higher Dimensional Geometric Smoothing for Coherent Visual Feature Extraction in Image Segmentation", "categories": ["cs.CV"], "comment": "13 pages, 3 figures, 3 tables", "summary": "This paper introduces GeloVec, a new CNN-based attention smoothing framework\nfor semantic segmentation that addresses critical limitations in conventional\napproaches. While existing attention-backed segmentation methods suffer from\nboundary instability and contextual discontinuities during feature mapping, our\nframework implements a higher-dimensional geometric smoothing method to\nestablish a robust manifold relationships between visually coherent regions.\nGeloVec combines modified Chebyshev distance metrics with multispatial\ntransformations to enhance segmentation accuracy through stabilized feature\nextraction. The core innovation lies in the adaptive sampling weights system\nthat calculates geometric distances in n-dimensional feature space, achieving\nsuperior edge preservation while maintaining intra-class homogeneity. The\nmultispatial transformation matrix incorporates tensorial projections with\northogonal basis vectors, creating more discriminative feature representations\nwithout sacrificing computational efficiency. Experimental validation across\nmultiple benchmark datasets demonstrates significant improvements in\nsegmentation performance, with mean Intersection over Union (mIoU) gains of\n2.1%, 2.7%, and 2.4% on Caltech Birds-200, LSDSC, and FSSD datasets\nrespectively compared to state-of-the-art methods. GeloVec's mathematical\nfoundation in Riemannian geometry provides theoretical guarantees on\nsegmentation stability. Importantly, our framework maintains computational\nefficiency through parallelized implementation of geodesic transformations and\nexhibits strong generalization capabilities across disciplines due to the\nabsence of information loss during transformations.", "AI": {"tldr": "GeloVec is a CNN-based attention smoothing framework for semantic segmentation, improving boundary stability and contextual continuity with geometric smoothing and adaptive sampling weights.", "motivation": "Addresses boundary instability and contextual discontinuities in conventional attention-backed segmentation methods.", "method": "Uses higher-dimensional geometric smoothing, modified Chebyshev distance metrics, and multispatial transformations with adaptive sampling weights.", "result": "Achieves mIoU gains of 2.1%, 2.7%, and 2.4% on benchmark datasets, with theoretical guarantees from Riemannian geometry.", "conclusion": "GeloVec enhances segmentation accuracy and stability while maintaining computational efficiency and generalization."}}
{"id": "2505.01007", "pdf": "https://arxiv.org/pdf/2505.01007", "abs": "https://arxiv.org/abs/2505.01007", "authors": ["Ling Tang", "Yuefeng Chen", "Hui Xue", "Quanshi Zhang"], "title": "Towards the Resistance of Neural Network Watermarking to Fine-tuning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "This paper proves a new watermarking method to embed the ownership\ninformation into a deep neural network (DNN), which is robust to fine-tuning.\nSpecifically, we prove that when the input feature of a convolutional layer\nonly contains low-frequency components, specific frequency components of the\nconvolutional filter will not be changed by gradient descent during the\nfine-tuning process, where we propose a revised Fourier transform to extract\nfrequency components from the convolutional filter. Additionally, we also prove\nthat these frequency components are equivariant to weight scaling and weight\npermutations. In this way, we design a watermark module to encode the watermark\ninformation to specific frequency components in a convolutional filter.\nPreliminary experiments demonstrate the effectiveness of our method.", "AI": {"tldr": "A new watermarking method for DNNs is introduced, robust against fine-tuning by leveraging low-frequency components in convolutional filters.", "motivation": "To protect DNN ownership by embedding watermarks that remain intact during fine-tuning.", "method": "Uses a revised Fourier transform to identify and encode watermark information in specific frequency components of convolutional filters, which resist gradient descent changes.", "result": "The method is proven robust to fine-tuning, weight scaling, and permutations, with preliminary experiments confirming its effectiveness.", "conclusion": "The proposed watermarking technique successfully embeds ownership information in DNNs while resisting common modifications."}}
{"id": "2505.00918", "pdf": "https://arxiv.org/pdf/2505.00918", "abs": "https://arxiv.org/abs/2505.00918", "authors": ["Shubham Vaishnav", "Praveen Kumar Donta", "Sindri Magn\u00fasson"], "title": "Dynamic and Distributed Routing in IoT Networks based on Multi-Objective Q-Learning", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.NI"], "comment": null, "summary": "The last few decades have witnessed a rapid increase in IoT devices owing to\ntheir wide range of applications, such as smart healthcare monitoring systems,\nsmart cities, and environmental monitoring. A critical task in IoT networks is\nsensing and transmitting information over the network. The IoT nodes gather\ndata by sensing the environment and then transmit this data to a destination\nnode via multi-hop communication, following some routing protocols. These\nprotocols are usually designed to optimize possibly contradictory objectives,\nsuch as maximizing packet delivery ratio and energy efficiency. While most\nliterature has focused on optimizing a static objective that remains unchanged,\nmany real-world IoT applications require adapting to rapidly shifting\npriorities. For example, in monitoring systems, some transmissions are\ntime-critical and require a high priority on low latency, while other\ntransmissions are less urgent and instead prioritize energy efficiency. To meet\nsuch dynamic demands, we propose novel dynamic and distributed routing based on\nmultiobjective Q-learning that can adapt to changes in preferences in\nreal-time. Our algorithm builds on ideas from both multi-objective optimization\nand Q-learning. We also propose a novel greedy interpolation policy scheme to\ntake near-optimal decisions for unexpected preference changes. The proposed\nscheme can approximate and utilize the Pareto-efficient solutions for dynamic\npreferences, thus utilizing past knowledge to adapt to unpredictable\npreferences quickly during runtime. Simulation results show that the proposed\nscheme outperforms state-of-the-art algorithms for various exploration\nstrategies, preference variation patterns, and important metrics like overall\nreward, energy efficiency, and packet delivery ratio.", "AI": {"tldr": "A dynamic, distributed routing algorithm using multi-objective Q-learning is proposed for IoT networks to adapt to shifting priorities, outperforming existing methods in energy efficiency and packet delivery.", "motivation": "IoT networks require adaptable routing protocols to handle dynamic priorities, such as balancing latency and energy efficiency, which static objectives cannot address.", "method": "The paper introduces a dynamic routing algorithm based on multi-objective Q-learning and a greedy interpolation policy for real-time preference adaptation.", "result": "Simulations show the proposed scheme excels in overall reward, energy efficiency, and packet delivery ratio under varying conditions.", "conclusion": "The algorithm effectively adapts to dynamic IoT demands, leveraging Pareto-efficient solutions for real-time performance."}}
{"id": "2505.00968", "pdf": "https://arxiv.org/pdf/2505.00968", "abs": "https://arxiv.org/abs/2505.00968", "authors": ["Thanh Tran", "Viet-Hoang Tran", "Thanh Chu", "Trang Pham", "Laurent El Ghaoui", "Tam Le", "Tan M. Nguyen"], "title": "Tree-Sliced Wasserstein Distance with Nonlinear Projection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICML 2025", "summary": "Tree-Sliced methods have recently emerged as an alternative to the\ntraditional Sliced Wasserstein (SW) distance, replacing one-dimensional lines\nwith tree-based metric spaces and incorporating a splitting mechanism for\nprojecting measures. This approach enhances the ability to capture the\ntopological structures of integration domains in Sliced Optimal Transport while\nmaintaining low computational costs. Building on this foundation, we propose a\nnovel nonlinear projectional framework for the Tree-Sliced Wasserstein (TSW)\ndistance, substituting the linear projections in earlier versions with general\nprojections, while ensuring the injectivity of the associated Radon Transform\nand preserving the well-definedness of the resulting metric. By designing\nappropriate projections, we construct efficient metrics for measures on both\nEuclidean spaces and spheres. Finally, we validate our proposed metric through\nextensive numerical experiments for Euclidean and spherical datasets.\nApplications include gradient flows, self-supervised learning, and generative\nmodels, where our methods demonstrate significant improvements over recent SW\nand TSW variants.", "AI": {"tldr": "A novel nonlinear projectional framework for Tree-Sliced Wasserstein (TSW) distance is proposed, replacing linear projections to enhance metric efficiency for measures on Euclidean spaces and spheres, validated through experiments.", "motivation": "To improve the Tree-Sliced Wasserstein distance by capturing topological structures better and maintaining low computational costs.", "method": "Introduces a nonlinear projectional framework for TSW, ensuring injectivity of the Radon Transform and metric well-definedness.", "result": "Efficient metrics for measures on Euclidean spaces and spheres, with significant improvements in applications like gradient flows and generative models.", "conclusion": "The proposed nonlinear TSW framework outperforms recent SW and TSW variants, demonstrating practical utility in various applications."}}
{"id": "2505.01064", "pdf": "https://arxiv.org/pdf/2505.01064", "abs": "https://arxiv.org/abs/2505.01064", "authors": ["Hari Chandana Kuchibhotla", "Sai Srinivas Kancheti", "Abbavaram Gowtham Reddy", "Vineeth N Balasubramanian"], "title": "Efficient Vocabulary-Free Fine-Grained Visual Recognition in the Age of Multimodal LLMs", "categories": ["cs.CV", "cs.LG"], "comment": "preprint; earlier version accepted at NeurIPS 2024 Workshop on\n  Adaptive Foundation Models", "summary": "Fine-grained Visual Recognition (FGVR) involves distinguishing between\nvisually similar categories, which is inherently challenging due to subtle\ninter-class differences and the need for large, expert-annotated datasets. In\ndomains like medical imaging, such curated datasets are unavailable due to\nissues like privacy concerns and high annotation costs. In such scenarios\nlacking labeled data, an FGVR model cannot rely on a predefined set of training\nlabels, and hence has an unconstrained output space for predictions. We refer\nto this task as Vocabulary-Free FGVR (VF-FGVR), where a model must predict\nlabels from an unconstrained output space without prior label information.\nWhile recent Multimodal Large Language Models (MLLMs) show potential for\nVF-FGVR, querying these models for each test input is impractical because of\nhigh costs and prohibitive inference times. To address these limitations, we\nintroduce \\textbf{Nea}rest-Neighbor Label \\textbf{R}efinement (NeaR), a novel\napproach that fine-tunes a downstream CLIP model using labels generated by an\nMLLM. Our approach constructs a weakly supervised dataset from a small,\nunlabeled training set, leveraging MLLMs for label generation. NeaR is designed\nto handle the noise, stochasticity, and open-endedness inherent in labels\ngenerated by MLLMs, and establishes a new benchmark for efficient VF-FGVR.", "AI": {"tldr": "The paper introduces NeaR, a method for Vocabulary-Free Fine-Grained Visual Recognition (VF-FGVR) that uses Multimodal Large Language Models (MLLMs) to generate labels for training a CLIP model, addressing challenges like high costs and inference times.", "motivation": "The lack of labeled datasets in domains like medical imaging due to privacy and annotation costs motivates the need for VF-FGVR, where models predict labels without predefined training labels.", "method": "NeaR fine-tunes a CLIP model using weakly supervised labels generated by MLLMs from a small unlabeled dataset, handling noise and stochasticity in MLLM-generated labels.", "result": "NeaR establishes a new benchmark for efficient VF-FGVR by leveraging MLLMs for label generation and refining them for downstream tasks.", "conclusion": "NeaR provides a practical solution for VF-FGVR by combining MLLMs' label generation with efficient downstream model fine-tuning, overcoming limitations of direct MLLM usage."}}
{"id": "2505.01096", "pdf": "https://arxiv.org/pdf/2505.01096", "abs": "https://arxiv.org/abs/2505.01096", "authors": ["Marco Salm\u00e8", "Rosa Sicilia", "Paolo Soda", "Valerio Guarrasi"], "title": "Evaluating Vision Language Model Adaptations for Radiology Report Generation in Low-Resource Languages", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "The integration of artificial intelligence in healthcare has opened new\nhorizons for improving medical diagnostics and patient care. However,\nchallenges persist in developing systems capable of generating accurate and\ncontextually relevant radiology reports, particularly in low-resource\nlanguages. In this study, we present a comprehensive benchmark to evaluate the\nperformance of instruction-tuned Vision-Language Models (VLMs) in the\nspecialized task of radiology report generation across three low-resource\nlanguages: Italian, German, and Spanish. Employing the LLaVA architectural\nframework, we conducted a systematic evaluation of pre-trained models utilizing\ngeneral datasets, domain-specific datasets, and low-resource language-specific\ndatasets. In light of the unavailability of models that possess prior knowledge\nof both the medical domain and low-resource languages, we analyzed various\nadaptations to determine the most effective approach for these contexts. The\nresults revealed that language-specific models substantially outperformed both\ngeneral and domain-specific models in generating radiology reports, emphasizing\nthe critical role of linguistic adaptation. Additionally, models fine-tuned\nwith medical terminology exhibited enhanced performance across all languages\ncompared to models with generic knowledge, highlighting the importance of\ndomain-specific training. We also explored the influence of the temperature\nparameter on the coherence of report generation, providing insights for optimal\nmodel settings. Our findings highlight the importance of tailored language and\ndomain-specific training for improving the quality and accuracy of radiological\nreports in multilingual settings. This research not only advances our\nunderstanding of VLMs adaptability in healthcare but also points to significant\navenues for future investigations into model tuning and language-specific\nadaptations.", "AI": {"tldr": "The study evaluates instruction-tuned Vision-Language Models (VLMs) for radiology report generation in low-resource languages (Italian, German, Spanish), finding language-specific and domain-tuned models perform best.", "motivation": "Challenges in generating accurate radiology reports in low-resource languages and the lack of models combining medical domain knowledge with low-resource language proficiency.", "method": "Used the LLaVA framework to evaluate pre-trained models on general, domain-specific, and language-specific datasets, analyzing adaptations for effectiveness.", "result": "Language-specific models outperformed others; medical terminology fine-tuning improved performance. Temperature parameter impact on coherence was also studied.", "conclusion": "Tailored language and domain-specific training are crucial for accurate radiology reports in multilingual settings, suggesting future research directions."}}
{"id": "2505.00935", "pdf": "https://arxiv.org/pdf/2505.00935", "abs": "https://arxiv.org/abs/2505.00935", "authors": ["Roberto Bigazzi"], "title": "Autonomous Embodied Agents: When Robotics Meets Deep Learning Reasoning", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Ph.D. Dissertation", "summary": "The increase in available computing power and the Deep Learning revolution\nhave allowed the exploration of new topics and frontiers in Artificial\nIntelligence research. A new field called Embodied Artificial Intelligence,\nwhich places at the intersection of Computer Vision, Robotics, and Decision\nMaking, has been gaining importance during the last few years, as it aims to\nfoster the development of smart autonomous robots and their deployment in\nsociety. The recent availability of large collections of 3D models for\nphotorealistic robotic simulation has allowed faster and safe training of\nlearning-based agents for millions of frames and a careful evaluation of their\nbehavior before deploying the models on real robotic platforms. These\nintelligent agents are intended to perform a certain task in a possibly unknown\nenvironment. To this end, during the training in simulation, the agents learn\nto perform continuous interactions with the surroundings, such as gathering\ninformation from the environment, encoding and extracting useful cues for the\ntask, and performing actions towards the final goal; where every action of the\nagent influences the interactions. This dissertation follows the complete\ncreation process of embodied agents for indoor environments, from their concept\nto their implementation and deployment. We aim to contribute to research in\nEmbodied AI and autonomous agents, in order to foster future work in this\nfield. We present a detailed analysis of the procedure behind implementing an\nintelligent embodied agent, comprehending a thorough description of the current\nstate-of-the-art in literature, technical explanations of the proposed methods,\nand accurate experimental studies on relevant robotic tasks.", "AI": {"tldr": "The paper explores Embodied AI, focusing on developing smart autonomous robots through simulation-based training and deployment in indoor environments.", "motivation": "To advance Embodied AI by creating intelligent agents capable of interacting with unknown environments, leveraging simulation for safe and efficient training.", "method": "Uses large 3D models for photorealistic simulation to train learning-based agents, enabling continuous interaction and action in environments.", "result": "Detailed implementation and experimental studies on robotic tasks, contributing to the state-of-the-art in Embodied AI.", "conclusion": "The work fosters future research in Embodied AI by providing a comprehensive framework for developing and deploying intelligent agents."}}
{"id": "2505.00973", "pdf": "https://arxiv.org/pdf/2505.00973", "abs": "https://arxiv.org/abs/2505.00973", "authors": ["Xin Chen", "Yuze Chen", "Yuan Zhou"], "title": "A Minimax-MDP Framework with Future-imposed Conditions for Learning-augmented Problems", "categories": ["cs.LG", "math.OC"], "comment": "64 pages, 1 figure", "summary": "We study a class of sequential decision-making problems with augmented\npredictions, potentially provided by a machine learning algorithm. In this\nsetting, the decision-maker receives prediction intervals for unknown\nparameters that become progressively refined over time, and seeks decisions\nthat are competitive with the hindsight optimal under all possible realizations\nof both parameters and predictions. We propose a minimax Markov Decision\nProcess (minimax-MDP) framework, where the system state consists of an\nadversarially evolving environment state and an internal state controlled by\nthe decision-maker. We introduce a set of future-imposed conditions that\ncharacterize the feasibility of minimax-MDPs and enable the design of\nefficient, often closed-form, robustly competitive policies. We illustrate the\nframework through three applications: multi-period inventory ordering with\nrefining demand predictions, resource allocation with uncertain utility\nfunctions, and a multi-phase extension of the minimax-MDP applied to the\ninventory problem with time-varying ordering costs. Our results provide a\ntractable and versatile approach to robust online decision-making under\npredictive uncertainty.", "AI": {"tldr": "The paper introduces a minimax-MDP framework for robust online decision-making with refining predictions, applied to inventory and resource allocation problems.", "motivation": "To address sequential decision-making problems where predictions (e.g., demand or utility) refine over time, ensuring decisions are competitive with hindsight optimal solutions under uncertainty.", "method": "Proposes a minimax-MDP framework with adversarial environment states and internal decision-maker states, leveraging future-imposed conditions for feasibility and efficient policy design.", "result": "Demonstrates tractable, often closed-form, robustly competitive policies, validated through applications like inventory ordering and resource allocation.", "conclusion": "The minimax-MDP offers a versatile and efficient approach for robust decision-making under predictive uncertainty."}}
{"id": "2505.01091", "pdf": "https://arxiv.org/pdf/2505.01091", "abs": "https://arxiv.org/abs/2505.01091", "authors": ["Daniele Molino", "Francesco di Feola", "Linlin Shen", "Paolo Soda", "Valerio Guarrasi"], "title": "Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation", "categories": ["cs.CV", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2501.04614", "summary": "Generative models have revolutionized Artificial Intelligence (AI),\nparticularly in multimodal applications. However, adapting these models to the\nmedical domain poses unique challenges due to the complexity of medical data\nand the stringent need for clinical accuracy. In this work, we introduce a\nframework specifically designed for multimodal medical data generation. By\nenabling the generation of multi-view chest X-rays and their associated\nclinical report, it bridges the gap between general-purpose vision-language\nmodels and the specialized requirements of healthcare. Leveraging the MIMIC-CXR\ndataset, the proposed framework shows superior performance in generating\nhigh-fidelity images and semantically coherent reports. Our quantitative\nevaluation reveals significant results in terms of FID and BLEU scores,\nshowcasing the quality of the generated data. Notably, our framework achieves\ncomparable or even superior performance compared to real data on downstream\ndisease classification tasks, underlining its potential as a tool for medical\nresearch and diagnostics. This study highlights the importance of\ndomain-specific adaptations in enhancing the relevance and utility of\ngenerative models for clinical applications, paving the way for future\nadvancements in synthetic multimodal medical data generation.", "AI": {"tldr": "A framework for generating multimodal medical data (chest X-rays and reports) is introduced, showing high fidelity and clinical relevance, outperforming general models in healthcare tasks.", "motivation": "Address the gap between general-purpose generative models and the specialized needs of medical data, ensuring clinical accuracy and utility.", "method": "Proposes a framework leveraging the MIMIC-CXR dataset to generate multi-view chest X-rays and coherent reports, evaluated using FID and BLEU scores.", "result": "Achieves superior performance in data quality and downstream disease classification, comparable to real data.", "conclusion": "Domain-specific adaptations enhance generative models' clinical relevance, advancing synthetic medical data generation."}}
{"id": "2505.01372", "pdf": "https://arxiv.org/pdf/2505.01372", "abs": "https://arxiv.org/abs/2505.01372", "authors": ["Kola Ayonrinde", "Louis Jaburi"], "title": "Evaluating Explanations: An Explanatory Virtues Framework for Mechanistic Interpretability -- The Strange Science Part I.ii", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": "13 pages (plus appendices), 5 figures", "summary": "Mechanistic Interpretability (MI) aims to understand neural networks through\ncausal explanations. Though MI has many explanation-generating methods,\nprogress has been limited by the lack of a universal approach to evaluating\nexplanations. Here we analyse the fundamental question \"What makes a good\nexplanation?\" We introduce a pluralist Explanatory Virtues Framework drawing on\nfour perspectives from the Philosophy of Science - the Bayesian, Kuhnian,\nDeutschian, and Nomological - to systematically evaluate and improve\nexplanations in MI. We find that Compact Proofs consider many explanatory\nvirtues and are hence a promising approach. Fruitful research directions\nimplied by our framework include (1) clearly defining explanatory simplicity,\n(2) focusing on unifying explanations and (3) deriving universal principles for\nneural networks. Improved MI methods enhance our ability to monitor, predict,\nand steer AI systems.", "AI": {"tldr": "The paper proposes a pluralist framework for evaluating explanations in Mechanistic Interpretability (MI) by integrating four philosophical perspectives, identifying Compact Proofs as promising, and suggesting future research directions.", "motivation": "Progress in MI is limited by the lack of a universal approach to evaluating explanations, prompting the need to address 'What makes a good explanation?'", "method": "Introduces an Explanatory Virtues Framework based on Bayesian, Kuhnian, Deutschian, and Nomological perspectives to systematically evaluate MI explanations.", "result": "Compact Proofs are identified as a promising approach, and future directions include defining simplicity, unifying explanations, and deriving universal principles.", "conclusion": "Improved MI methods can enhance monitoring, prediction, and control of AI systems."}}
{"id": "2505.00983", "pdf": "https://arxiv.org/pdf/2505.00983", "abs": "https://arxiv.org/abs/2505.00983", "authors": ["Xunkai Li", "Zhengyu Wu", "Kaichi Yu", "Hongchao Qin", "Guang Zeng", "Rong-Hua Li", "Guoren Wang"], "title": "Toward Data-centric Directed Graph Learning: An Entropy-driven Approach", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.SI"], "comment": "Accepted by ICML 2025", "summary": "The directed graph (digraph), as a generalization of undirected graphs,\nexhibits superior representation capability in modeling complex topology\nsystems and has garnered considerable attention in recent years. Despite the\nnotable efforts made by existing DiGraph Neural Networks (DiGNNs) to leverage\ndirected edges, they still fail to comprehensively delve into the abundant data\nknowledge concealed in the digraphs. This data-level limitation results in\nmodel-level sub-optimal predictive performance and underscores the necessity of\nfurther exploring the potential correlations between the directed edges\n(topology) and node profiles (feature and labels) from a data-centric\nperspective, thereby empowering model-centric neural networks with stronger\nencoding capabilities.\n  In this paper, we propose \\textbf{E}ntropy-driven \\textbf{D}igraph\nknowl\\textbf{E}dge distillatio\\textbf{N} (EDEN), which can serve as a\ndata-centric digraph learning paradigm or a model-agnostic hot-and-plug\ndata-centric Knowledge Distillation (KD) module. The core idea is to achieve\ndata-centric ML, guided by our proposed hierarchical encoding theory for\nstructured data. Specifically, EDEN first utilizes directed structural\nmeasurements from a topology perspective to construct a coarse-grained\nHierarchical Knowledge Tree (HKT). Subsequently, EDEN quantifies the mutual\ninformation of node profiles to refine knowledge flow in the HKT, enabling\ndata-centric KD supervision within model training. As a general framework, EDEN\ncan also naturally extend to undirected scenarios and demonstrate satisfactory\nperformance. In our experiments, EDEN has been widely evaluated on 14 (di)graph\ndatasets (homophily and heterophily) and across 4 downstream tasks. The results\ndemonstrate that EDEN attains SOTA performance and exhibits strong improvement\nfor prevalent (Di)GNNs.", "AI": {"tldr": "EDEN is a data-centric digraph learning framework that enhances knowledge distillation by leveraging hierarchical encoding and mutual information, achieving state-of-the-art performance.", "motivation": "Existing DiGNNs fail to fully exploit digraph data, limiting predictive performance. EDEN addresses this by exploring correlations between topology and node profiles.", "method": "EDEN constructs a Hierarchical Knowledge Tree (HKT) using directed structural measurements and refines it with mutual information of node profiles for knowledge distillation.", "result": "EDEN achieves SOTA performance on 14 (di)graph datasets across 4 tasks, improving prevalent (Di)GNNs.", "conclusion": "EDEN is a versatile, data-centric framework that enhances digraph learning and extends to undirected scenarios."}}
{"id": "2505.00982", "pdf": "https://arxiv.org/pdf/2505.00982", "abs": "https://arxiv.org/abs/2505.00982", "authors": ["Shunxian Gu", "Chaoqun You", "Bangbang Ren", "Lailong Luo", "Junxu Xia", "Deke Guo"], "title": "Accelerating Deep Neural Network Training via Distributed Hybrid Order Optimization", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Scaling deep neural network (DNN) training to more devices can reduce\ntime-to-solution. However, it is impractical for users with limited computing\nresources. FOSI, as a hybrid order optimizer, converges faster than\nconventional optimizers by taking advantage of both gradient information and\ncurvature information when updating the DNN model. Therefore, it provides a new\nchance for accelerating DNN training in the resource-constrained setting. In\nthis paper, we explore its distributed design, namely DHO$_2$, including\ndistributed calculation of curvature information and model update with partial\ncurvature information to accelerate DNN training with a low memory burden. To\nfurther reduce the training time, we design a novel strategy to parallelize the\ncalculation of curvature information and the model update on different devices.\nExperimentally, our distributed design can achieve an approximate linear\nreduction of memory burden on each device with the increase of the device\nnumber. Meanwhile, it achieves $1.4\\times\\sim2.1\\times$ speedup in the total\ntraining time compared with other distributed designs based on conventional\nfirst- and second-order optimizers.", "AI": {"tldr": "FOSI, a hybrid optimizer, accelerates DNN training by combining gradient and curvature information. Its distributed design, DHO$_2$, reduces memory burden and training time, achieving 1.4\u00d7\u223c2.1\u00d7 speedup.", "motivation": "To enable faster DNN training for users with limited computing resources by leveraging hybrid optimization and distributed design.", "method": "DHO$_2$ distributes curvature calculation and model updates, parallelizing tasks across devices to reduce memory and time.", "result": "Achieves linear memory burden reduction and 1.4\u00d7\u223c2.1\u00d7 training speedup compared to conventional distributed optimizers.", "conclusion": "DHO$_2$ offers an efficient solution for resource-constrained DNN training, balancing speed and memory usage."}}
{"id": "2505.01104", "pdf": "https://arxiv.org/pdf/2505.01104", "abs": "https://arxiv.org/abs/2505.01104", "authors": ["Do Huu Dat", "Nam Hyeonu", "Po-Yuan Mao", "Tae-Hyun Oh"], "title": "VSC: Visual Search Compositional Text-to-Image Diffusion Model", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image diffusion models have shown impressive capabilities in\ngenerating realistic visuals from natural-language prompts, yet they often\nstruggle with accurately binding attributes to corresponding objects,\nespecially in prompts containing multiple attribute-object pairs. This\nchallenge primarily arises from the limitations of commonly used text encoders,\nsuch as CLIP, which can fail to encode complex linguistic relationships and\nmodifiers effectively. Existing approaches have attempted to mitigate these\nissues through attention map control during inference and the use of layout\ninformation or fine-tuning during training, yet they face performance drops\nwith increased prompt complexity. In this work, we introduce a novel\ncompositional generation method that leverages pairwise image embeddings to\nimprove attribute-object binding. Our approach decomposes complex prompts into\nsub-prompts, generates corresponding images, and computes visual prototypes\nthat fuse with text embeddings to enhance representation. By applying\nsegmentation-based localization training, we address cross-attention\nmisalignment, achieving improved accuracy in binding multiple attributes to\nobjects. Our approaches outperform existing compositional text-to-image\ndiffusion models on the benchmark T2I CompBench, achieving better image\nquality, evaluated by humans, and emerging robustness under scaling number of\nbinding pairs in the prompt.", "AI": {"tldr": "A novel method improves attribute-object binding in text-to-image diffusion models by decomposing prompts, generating visual prototypes, and using segmentation-based training.", "motivation": "Current models struggle with accurately binding attributes to objects in complex prompts due to limitations in text encoders like CLIP.", "method": "Decomposes prompts into sub-prompts, generates images, computes visual prototypes, and uses segmentation-based training to enhance binding.", "result": "Outperforms existing models on T2I CompBench, achieving better image quality and robustness with complex prompts.", "conclusion": "The approach effectively addresses cross-attention misalignment, improving accuracy in attribute-object binding."}}
{"id": "2402.14359", "pdf": "https://arxiv.org/pdf/2402.14359", "abs": "https://arxiv.org/abs/2402.14359", "authors": ["Xiuying Chen", "Tairan Wang", "Qingqing Zhu", "Taicheng Guo", "Shen Gao", "Zhiyong Lu", "Xin Gao", "Xiangliang Zhang"], "title": "Rethinking Scientific Summarization Evaluation: Grounding Explainable Metrics on Facet-aware Benchmark", "categories": ["cs.CL"], "comment": "14pages", "summary": "The summarization capabilities of pretrained and large language models (LLMs)\nhave been widely validated in general areas, but their use in scientific\ncorpus, which involves complex sentences and specialized knowledge, has been\nless assessed. This paper presents conceptual and experimental analyses of\nscientific summarization, highlighting the inadequacies of traditional\nevaluation methods, such as $n$-gram, embedding comparison, and QA,\nparticularly in providing explanations, grasping scientific concepts, or\nidentifying key content. Subsequently, we introduce the Facet-aware Metric\n(FM), employing LLMs for advanced semantic matching to evaluate summaries based\non different aspects. This facet-aware approach offers a thorough evaluation of\nabstracts by decomposing the evaluation task into simpler subtasks.Recognizing\nthe absence of an evaluation benchmark in this domain, we curate a Facet-based\nscientific summarization Dataset (FD) with facet-level annotations. Our\nfindings confirm that FM offers a more logical approach to evaluating\nscientific summaries. In addition, fine-tuned smaller models can compete with\nLLMs in scientific contexts, while LLMs have limitations in learning from\nin-context information in scientific domains. This suggests an area for future\nenhancement of LLMs.", "AI": {"tldr": "The paper evaluates LLMs for scientific summarization, introduces a Facet-aware Metric (FM) for better evaluation, and highlights limitations of LLMs in scientific contexts.", "motivation": "Assess the effectiveness of LLMs in scientific summarization, where traditional evaluation methods fall short.", "method": "Introduces FM for semantic matching and curates a Facet-based Dataset (FD) for evaluation.", "result": "FM provides a logical evaluation approach; fine-tuned smaller models can compete with LLMs, which struggle with in-context learning in science.", "conclusion": "LLMs need enhancement for scientific domains, and FM offers a better evaluation framework."}}
{"id": "2505.01036", "pdf": "https://arxiv.org/pdf/2505.01036", "abs": "https://arxiv.org/abs/2505.01036", "authors": ["Xiaojun Zhou"], "title": "Stagnation in Evolutionary Algorithms: Convergence $\\neq$ Optimality", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In the evolutionary computation community, it is widely believed that\nstagnation impedes convergence in evolutionary algorithms, and that convergence\ninherently indicates optimality. However, this perspective is misleading. In\nthis study, it is the first to highlight that the stagnation of an individual\ncan actually facilitate the convergence of the entire population, and\nconvergence does not necessarily imply optimality, not even local optimality.\nConvergence alone is insufficient to ensure the effectiveness of evolutionary\nalgorithms. Several counterexamples are provided to illustrate this argument.", "AI": {"tldr": "Stagnation in evolutionary algorithms can aid population convergence, and convergence doesn't guarantee optimality.", "motivation": "Challenge the misconception that stagnation hinders convergence and that convergence ensures optimality in evolutionary algorithms.", "method": "Present counterexamples to demonstrate that stagnation can facilitate convergence and that convergence alone is inadequate for optimality.", "result": "Stagnation can benefit population convergence, and convergence doesn't imply local or global optimality.", "conclusion": "Convergence is insufficient for evolutionary algorithm effectiveness; stagnation's role is more nuanced than previously thought."}}
{"id": "2505.00986", "pdf": "https://arxiv.org/pdf/2505.00986", "abs": "https://arxiv.org/abs/2505.00986", "authors": ["Xiao Ma", "Young D. Kwon", "Dong Ma"], "title": "On-demand Test-time Adaptation for Edge Devices", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Continual Test-time adaptation (CTTA) continuously adapts the deployed model\non every incoming batch of data. While achieving optimal accuracy, existing\nCTTA approaches present poor real-world applicability on resource-constrained\nedge devices, due to the substantial memory overhead and energy consumption. In\nthis work, we first introduce a novel paradigm -- on-demand TTA -- which\ntriggers adaptation only when a significant domain shift is detected. Then, we\npresent OD-TTA, an on-demand TTA framework for accurate and efficient\nadaptation on edge devices. OD-TTA comprises three innovative techniques: 1) a\nlightweight domain shift detection mechanism to activate TTA only when it is\nneeded, drastically reducing the overall computation overhead, 2) a source\ndomain selection module that chooses an appropriate source model for\nadaptation, ensuring high and robust accuracy, 3) a decoupled Batch\nNormalization (BN) update scheme to enable memory-efficient adaptation with\nsmall batch sizes. Extensive experiments show that OD-TTA achieves comparable\nand even better performance while reducing the energy and computation overhead\nremarkably, making TTA a practical reality.", "AI": {"tldr": "OD-TTA introduces an on-demand TTA framework for efficient adaptation on edge devices, reducing computation and energy overhead while maintaining accuracy.", "motivation": "Existing CTTA methods are impractical for resource-constrained edge devices due to high memory and energy costs.", "method": "OD-TTA uses lightweight domain shift detection, source domain selection, and decoupled BN updates for efficient adaptation.", "result": "OD-TTA achieves comparable or better performance with significantly reduced overhead.", "conclusion": "OD-TTA makes TTA practical for edge devices by balancing accuracy and efficiency."}}
{"id": "2505.01109", "pdf": "https://arxiv.org/pdf/2505.01109", "abs": "https://arxiv.org/abs/2505.01109", "authors": ["Ali Mammadov", "Loic Le Folgoc", "Julien Adam", "Anne Buronfosse", "Gilles Hayem", "Guillaume Hocquet", "Pietro Gori"], "title": "Self-Supervision Enhances Instance-based Multiple Instance Learning Methods in Digital Pathology: A Benchmark Study", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted for publication in the Journal of Medical Imaging (SPIE)", "summary": "Multiple Instance Learning (MIL) has emerged as the best solution for Whole\nSlide Image (WSI) classification. It consists of dividing each slide into\npatches, which are treated as a bag of instances labeled with a global label.\nMIL includes two main approaches: instance-based and embedding-based. In the\nformer, each patch is classified independently, and then the patch scores are\naggregated to predict the bag label. In the latter, bag classification is\nperformed after aggregating patch embeddings. Even if instance-based methods\nare naturally more interpretable, embedding-based MILs have usually been\npreferred in the past due to their robustness to poor feature extractors.\nHowever, recently, the quality of feature embeddings has drastically increased\nusing self-supervised learning (SSL). Nevertheless, many authors continue to\nendorse the superiority of embedding-based MIL. To investigate this further, we\nconduct 710 experiments across 4 datasets, comparing 10 MIL strategies, 6\nself-supervised methods with 4 backbones, 4 foundation models, and various\npathology-adapted techniques. Furthermore, we introduce 4 instance-based MIL\nmethods never used before in the pathology domain. Through these extensive\nexperiments, we show that with a good SSL feature extractor, simple\ninstance-based MILs, with very few parameters, obtain similar or better\nperformance than complex, state-of-the-art (SOTA) embedding-based MIL methods,\nsetting new SOTA results on the BRACS and Camelyon16 datasets. Since simple\ninstance-based MIL methods are naturally more interpretable and explainable to\nclinicians, our results suggest that more effort should be put into\nwell-adapted SSL methods for WSI rather than into complex embedding-based MIL\nmethods.", "AI": {"tldr": "Instance-based MIL with SSL feature extractors matches or outperforms embedding-based MIL, offering better interpretability for WSI classification.", "motivation": "To challenge the assumed superiority of embedding-based MIL in WSI classification by leveraging improved SSL feature extractors.", "method": "Conducted 710 experiments comparing 10 MIL strategies, 6 SSL methods, 4 backbones, and introduced 4 new instance-based MIL methods.", "result": "Simple instance-based MIL with SSL features achieved similar or better performance than complex embedding-based MIL, setting new SOTA on BRACS and Camelyon16.", "conclusion": "Efforts should focus on SSL methods for WSI rather than complex embedding-based MIL, given the interpretability and performance of instance-based approaches."}}
{"id": "2404.18624", "pdf": "https://arxiv.org/pdf/2404.18624", "abs": "https://arxiv.org/abs/2404.18624", "authors": ["Letitia Parcalabescu", "Anette Frank"], "title": "Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "68Txx", "I.2.7; I.2.10"], "comment": "30 pages, 8 figures, 11 tables", "summary": "Vision and language model (VLM) decoders are currently the best-performing\narchitectures on multimodal tasks. Next to answers, they are able to produce\nnatural language explanations, either in post-hoc or CoT settings. However, it\nis not clear to what extent they are using the input vision and text modalities\nwhen generating answers or explanations. In this work, we investigate if VLMs\nrely on their input modalities differently when they produce explanations as\nopposed to answers. We also evaluate the self-consistency of VLM decoders in\nboth post-hoc and CoT explanation settings, by extending existing unimodal\ntests and measures to VLM decoders. We find that most tested VLMs are less\nself-consistent than LLMs. Text contributions in all tested VL decoders are\nmore important than image contributions in all examined tasks. However, when\ncomparing explanation generation to answer generation, the contributions of\nimages are significantly stronger for generating explanations compared to\nanswers. This difference is even larger in CoT compared to post-hoc\nexplanations. Lastly, we provide an up-to-date benchmarking of state-of-the-art\nVL decoders on the VALSE benchmark, which before was restricted to VL encoders.\nWe find that the tested VL decoders still struggle with most phenomena tested\nby VALSE.", "AI": {"tldr": "VLMs rely more on text than images, but images are more important for explanations than answers, especially in CoT settings. VLMs are less self-consistent than LLMs and struggle with VALSE benchmarks.", "motivation": "To understand how VLMs use vision and text modalities differently when generating answers vs. explanations, and to evaluate their self-consistency.", "method": "Extend unimodal tests to VLMs, analyze modality contributions, and benchmark on VALSE.", "result": "Text dominates image contributions, but images are more impactful for explanations. VLMs are less self-consistent than LLMs and perform poorly on VALSE.", "conclusion": "VLMs prioritize text but leverage images more for explanations, especially in CoT. Their self-consistency and performance on benchmarks need improvement."}}
{"id": "2505.01043", "pdf": "https://arxiv.org/pdf/2505.01043", "abs": "https://arxiv.org/abs/2505.01043", "authors": ["Zhiwei Hao", "Jianyuan Guo", "Li Shen", "Yong Luo", "Han Hu", "Guoxia Wang", "Dianhai Yu", "Yonggang Wen", "Dacheng Tao"], "title": "Low-Precision Training of Large Language Models: Methods, Challenges, and Opportunities", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved impressive performance across\nvarious domains. However, the substantial hardware resources required for their\ntraining present a significant barrier to efficiency and scalability. To\nmitigate this challenge, low-precision training techniques have been widely\nadopted, leading to notable advancements in training efficiency. Despite these\ngains, low-precision training involves several components$\\unicode{x2013}$such\nas weights, activations, and gradients$\\unicode{x2013}$each of which can be\nrepresented in different numerical formats. The resulting diversity has created\na fragmented landscape in low-precision training research, making it difficult\nfor researchers to gain a unified overview of the field. This survey provides a\ncomprehensive review of existing low-precision training methods. To\nsystematically organize these approaches, we categorize them into three primary\ngroups based on their underlying numerical formats, which is a key factor\ninfluencing hardware compatibility, computational efficiency, and ease of\nreference for readers. The categories are: (1) fixed-point and integer-based\nmethods, (2) floating-point-based methods, and (3) customized format-based\nmethods. Additionally, we discuss quantization-aware training approaches, which\nshare key similarities with low-precision training during forward propagation.\nFinally, we highlight several promising research directions to advance this\nfield. A collection of papers discussed in this survey is provided in\nhttps://github.com/Hao840/Awesome-Low-Precision-Training.", "AI": {"tldr": "A survey on low-precision training methods for LLMs, categorizing them into fixed-point/integer, floating-point, and customized formats, and discussing quantization-aware training and future directions.", "motivation": "The hardware resource demands of LLM training hinder efficiency and scalability, prompting the need for low-precision training techniques. However, the diversity in numerical formats has fragmented research, necessitating a unified overview.", "method": "The paper categorizes low-precision training methods into three groups based on numerical formats: fixed-point/integer, floating-point, and customized formats. It also reviews quantization-aware training.", "result": "The survey organizes existing methods systematically, providing clarity on hardware compatibility and computational efficiency.", "conclusion": "The paper highlights promising research directions and offers a GitHub repository for further reference."}}
{"id": "2505.01008", "pdf": "https://arxiv.org/pdf/2505.01008", "abs": "https://arxiv.org/abs/2505.01008", "authors": ["Haoyue Bai", "Yiyou Sun", "Wei Cheng", "Haifeng Chen"], "title": "Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content", "categories": ["cs.LG"], "comment": "CVPR 2025", "summary": "The recent proliferation of photorealistic images created by generative\nmodels has sparked both excitement and concern, as these images are\nincreasingly indistinguishable from real ones to the human eye. While offering\nnew creative and commercial possibilities, the potential for misuse, such as in\nmisinformation and fraud, highlights the need for effective detection methods.\nCurrent detection approaches often rely on access to model weights or require\nextensive collections of real image datasets, limiting their scalability and\npractical application in real world scenarios. In this work, we introduce a\nnovel black box detection framework that requires only API access, sidestepping\nthe need for model weights or large auxiliary datasets. Our approach leverages\na corrupt and recover strategy: by masking part of an image and assessing the\nmodel ability to reconstruct it, we measure the likelihood that the image was\ngenerated by the model itself. For black-box models that do not support masked\nimage inputs, we incorporate a cost efficient surrogate model trained to align\nwith the target model distribution, enhancing detection capability. Our\nframework demonstrates strong performance, outperforming baseline methods by\n4.31% in mean average precision across eight diffusion model variant datasets.", "AI": {"tldr": "A black-box framework detects AI-generated images by corrupting and recovering masked parts, outperforming baselines by 4.31% in precision.", "motivation": "The rise of photorealistic AI-generated images raises concerns about misuse, necessitating scalable detection methods without relying on model weights or large datasets.", "method": "Uses a corrupt-and-recover strategy with masking and reconstruction assessment, supplemented by a surrogate model for black-box cases.", "result": "Achieves 4.31% higher mean average precision than baselines across eight diffusion model datasets.", "conclusion": "The framework offers a practical, scalable solution for detecting AI-generated images without requiring model weights or extensive datasets."}}
{"id": "2505.01172", "pdf": "https://arxiv.org/pdf/2505.01172", "abs": "https://arxiv.org/abs/2505.01172", "authors": ["Jiangtong Tan", "Hu Yu", "Jie Huang", "Jie Xiao", "Feng Zhao"], "title": "FreePCA: Integrating Consistency Information across Long-short Frames in Training-free Long Video Generation via Principal Component Analysis", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Long video generation involves generating extended videos using models\ntrained on short videos, suffering from distribution shifts due to varying\nframe counts. It necessitates the use of local information from the original\nshort frames to enhance visual and motion quality, and global information from\nthe entire long frames to ensure appearance consistency. Existing training-free\nmethods struggle to effectively integrate the benefits of both, as appearance\nand motion in videos are closely coupled, leading to motion inconsistency and\nvisual quality. In this paper, we reveal that global and local information can\nbe precisely decoupled into consistent appearance and motion intensity\ninformation by applying Principal Component Analysis (PCA), allowing for\nrefined complementary integration of global consistency and local quality. With\nthis insight, we propose FreePCA, a training-free long video generation\nparadigm based on PCA that simultaneously achieves high consistency and\nquality. Concretely, we decouple consistent appearance and motion intensity\nfeatures by measuring cosine similarity in the principal component space.\nCritically, we progressively integrate these features to preserve original\nquality and ensure smooth transitions, while further enhancing consistency by\nreusing the mean statistics of the initial noise. Experiments demonstrate that\nFreePCA can be applied to various video diffusion models without requiring\ntraining, leading to substantial improvements. Code is available at\nhttps://github.com/JosephTiTan/FreePCA.", "AI": {"tldr": "FreePCA is a training-free method for long video generation that decouples global and local information using PCA, improving consistency and quality.", "motivation": "Addressing distribution shifts and motion inconsistency in long video generation by leveraging both local and global information.", "method": "Uses PCA to decouple appearance and motion intensity, then integrates them progressively for smooth transitions and consistency.", "result": "Substantial improvements in video quality and consistency across various video diffusion models without training.", "conclusion": "FreePCA effectively combines global and local information for high-quality, consistent long video generation."}}
{"id": "2412.00359", "pdf": "https://arxiv.org/pdf/2412.00359", "abs": "https://arxiv.org/abs/2412.00359", "authors": ["Md Kowsher", "Nusrat Jahan Prottasha", "Chun-Nam Yu", "Ozlem Ozmen Garibay", "Niloofar Yousefi"], "title": "Does Self-Attention Need Separate Weights in Transformers?", "categories": ["cs.CL"], "comment": "Preprint paper", "summary": "The success of self-attention lies in its ability to capture long-range\ndependencies and enhance context understanding, but it is limited by its\ncomputational complexity and challenges in handling sequential data with\ninherent directionality. This work introduces a shared weight\nself-attention-based BERT model that only learns one weight matrix for (Key,\nValue, and Query) representations instead of three individual matrices for each\nof them. Our shared weight attention reduces the training parameter size by\nmore than half and training time by around one-tenth. Furthermore, we\ndemonstrate higher prediction accuracy on small tasks of GLUE over the BERT\nbaseline and in particular a generalization power on noisy and out-of-domain\ndata. Experimental results indicate that our shared self-attention method\nachieves a parameter size reduction of 66.53% in the attention block. In the\nGLUE dataset, the shared weight self-attention-based BERT model demonstrates\naccuracy improvements of 0.38%, 5.81%, and 1.06% over the standard, symmetric,\nand pairwise attention-based BERT models, respectively. The model and source\ncode are available at Anonymous.", "AI": {"tldr": "A shared weight self-attention-based BERT model reduces computational complexity and improves efficiency while maintaining or enhancing performance on tasks like GLUE.", "motivation": "Address limitations of self-attention (computational complexity, handling sequential data directionality) by simplifying the attention mechanism.", "method": "Introduces a shared weight self-attention model using one weight matrix for Key, Value, and Query, reducing parameters and training time.", "result": "Achieves 66.53% parameter reduction, faster training, and improved accuracy on GLUE tasks, especially with noisy/out-of-domain data.", "conclusion": "Shared weight self-attention is efficient and effective, offering a practical alternative to traditional BERT models."}}
{"id": "2505.01059", "pdf": "https://arxiv.org/pdf/2505.01059", "abs": "https://arxiv.org/abs/2505.01059", "authors": ["An T. Le", "Khai Nguyen", "Minh Nhat Vu", "Jo\u00e3o Carvalho", "Jan Peters"], "title": "Model Tensor Planning", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "22 pages, 9 figures", "summary": "Sampling-based model predictive control (MPC) offers strong performance in\nnonlinear and contact-rich robotic tasks, yet often suffers from poor\nexploration due to locally greedy sampling schemes. We propose \\emph{Model\nTensor Planning} (MTP), a novel sampling-based MPC framework that introduces\nhigh-entropy control trajectory generation through structured tensor sampling.\nBy sampling over randomized multipartite graphs and interpolating control\ntrajectories with B-splines and Akima splines, MTP ensures smooth and globally\ndiverse control candidates. We further propose a simple $\\beta$-mixing strategy\nthat blends local exploitative and global exploratory samples within the\nmodified Cross-Entropy Method (CEM) update, balancing control refinement and\nexploration. Theoretically, we show that MTP achieves asymptotic path coverage\nand maximum entropy in the control trajectory space in the limit of infinite\ntensor depth and width.\n  Our implementation is fully vectorized using JAX and compatible with MuJoCo\nXLA, supporting \\emph{Just-in-time} (JIT) compilation and batched rollouts for\nreal-time control with online domain randomization. Through experiments on\nvarious challenging robotic tasks, ranging from dexterous in-hand manipulation\nto humanoid locomotion, we demonstrate that MTP outperforms standard MPC and\nevolutionary strategy baselines in task success and control robustness. Design\nand sensitivity ablations confirm the effectiveness of MTP tensor sampling\nstructure, spline interpolation choices, and mixing strategy. Altogether, MTP\noffers a scalable framework for robust exploration in model-based planning and\ncontrol.", "AI": {"tldr": "MTP introduces high-entropy control trajectory generation via tensor sampling and spline interpolation, outperforming standard MPC in robustness and exploration.", "motivation": "Address poor exploration in sampling-based MPC due to locally greedy schemes.", "method": "Uses tensor sampling over multipartite graphs, B-splines/Akima splines for interpolation, and a \u03b2-mixing strategy in CEM.", "result": "Achieves better task success and robustness in robotic tasks compared to baselines.", "conclusion": "MTP provides a scalable, robust framework for model-based planning and control."}}
{"id": "2505.01041", "pdf": "https://arxiv.org/pdf/2505.01041", "abs": "https://arxiv.org/abs/2505.01041", "authors": ["Xuyang Chen", "Jingliang Duan", "Lin Zhao"], "title": "Global Optimality of Single-Timescale Actor-Critic under Continuous State-Action Space: A Study on Linear Quadratic Regulator", "categories": ["cs.LG"], "comment": "arXiv admin note: substantial text overlap with arXiv:2208.08744", "summary": "Actor-critic methods have achieved state-of-the-art performance in various\nchallenging tasks. However, theoretical understandings of their performance\nremain elusive and challenging. Existing studies mostly focus on practically\nuncommon variants such as double-loop or two-timescale stepsize actor-critic\nalgorithms for simplicity. These results certify local convergence on finite\nstate- or action-space only. We push the boundary to investigate the classic\nsingle-sample single-timescale actor-critic on continuous (infinite)\nstate-action space, where we employ the canonical linear quadratic regulator\n(LQR) problem as a case study. We show that the popular single-timescale\nactor-critic can attain an epsilon-optimal solution with an order of epsilon to\n-2 sample complexity for solving LQR on the demanding continuous state-action\nspace. Our work provides new insights into the performance of single-timescale\nactor-critic, which further bridges the gap between theory and practice.", "AI": {"tldr": "The paper analyzes the performance of single-timescale actor-critic methods on continuous state-action spaces, proving epsilon-optimality with a sample complexity of epsilon^-2 for LQR problems.", "motivation": "Despite actor-critic methods' success, theoretical understanding is limited, especially for practical single-timescale variants on infinite state-action spaces.", "method": "Investigates single-sample single-timescale actor-critic on continuous spaces, using the LQR problem as a case study.", "result": "Demonstrates epsilon-optimality with epsilon^-2 sample complexity for LQR on continuous spaces.", "conclusion": "Bridges the theory-practice gap for single-timescale actor-critic methods."}}
{"id": "2505.01182", "pdf": "https://arxiv.org/pdf/2505.01182", "abs": "https://arxiv.org/abs/2505.01182", "authors": ["Ziyan Guo", "Haoxuan Qu", "Hossein Rahmani", "Dewen Soh", "Ping Hu", "Qiuhong Ke", "Jun Liu"], "title": "TSTMotion: Training-free Scene-awarenText-to-motion Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICME2025", "summary": "Text-to-motion generation has recently garnered significant research\ninterest, primarily focusing on generating human motion sequences in blank\nbackgrounds. However, human motions commonly occur within diverse 3D scenes,\nwhich has prompted exploration into scene-aware text-to-motion generation\nmethods. Yet, existing scene-aware methods often rely on large-scale\nground-truth motion sequences in diverse 3D scenes, which poses practical\nchallenges due to the expensive cost. To mitigate this challenge, we are the\nfirst to propose a \\textbf{T}raining-free \\textbf{S}cene-aware\n\\textbf{T}ext-to-\\textbf{Motion} framework, dubbed as \\textbf{TSTMotion}, that\nefficiently empowers pre-trained blank-background motion generators with the\nscene-aware capability. Specifically, conditioned on the given 3D scene and\ntext description, we adopt foundation models together to reason, predict and\nvalidate a scene-aware motion guidance. Then, the motion guidance is\nincorporated into the blank-background motion generators with two\nmodifications, resulting in scene-aware text-driven motion sequences. Extensive\nexperiments demonstrate the efficacy and generalizability of our proposed\nframework. We release our code in \\href{https://tstmotion.github.io/}{Project\nPage}.", "AI": {"tldr": "The paper introduces TSTMotion, a training-free framework for scene-aware text-to-motion generation, enhancing pre-trained motion generators without costly ground-truth data.", "motivation": "Existing scene-aware text-to-motion methods require expensive ground-truth motion sequences in 3D scenes, prompting a need for a cost-effective solution.", "method": "TSTMotion uses foundation models to predict and validate scene-aware motion guidance, integrating it into pre-trained blank-background motion generators with two modifications.", "result": "Experiments show the framework's efficacy and generalizability in generating scene-aware motion sequences.", "conclusion": "TSTMotion provides a practical, training-free solution for scene-aware text-to-motion generation, addressing the limitations of existing methods."}}
{"id": "2412.06926", "pdf": "https://arxiv.org/pdf/2412.06926", "abs": "https://arxiv.org/abs/2412.06926", "authors": ["Bharath Raj", "Garvit Suri", "Vikrant Dewangan", "Raghav Sonavane"], "title": "When Every Token Counts: Optimal Segmentation for Low-Resource Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "LoResLM @ COLING 2025. Project page at\n  https://vikr-182.github.io/loreslm/", "summary": "Traditional greedy tokenization methods have been a critical step in Natural\nLanguage Processing (NLP), influencing how text is converted into tokens and\ndirectly impacting model performance. While subword tokenizers like Byte-Pair\nEncoding (BPE) are widely used, questions remain about their optimality across\nmodel scales and languages. In this work, we demonstrate through extensive\nexperiments that an optimal BPE configuration significantly reduces token count\ncompared to greedy segmentation, yielding improvements in token-saving\npercentages and performance benefits, particularly for smaller models. We\nevaluate tokenization performance across various intrinsic and extrinsic tasks,\nincluding generation and classification. Our findings suggest that\ncompression-optimized tokenization strategies could provide substantial\nadvantages for multilingual and low-resource language applications,\nhighlighting a promising direction for further research and inclusive NLP.", "AI": {"tldr": "Optimal BPE tokenization reduces token count and improves performance, especially for smaller models, with benefits for multilingual and low-resource applications.", "motivation": "To address the suboptimality of traditional greedy tokenization methods like BPE across model scales and languages.", "method": "Extensive experiments evaluating tokenization performance via intrinsic and extrinsic tasks, including generation and classification.", "result": "Optimal BPE configuration significantly reduces token count and improves performance, particularly for smaller models.", "conclusion": "Compression-optimized tokenization strategies offer advantages for multilingual and low-resource NLP, suggesting a promising research direction."}}
{"id": "2505.01065", "pdf": "https://arxiv.org/pdf/2505.01065", "abs": "https://arxiv.org/abs/2505.01065", "authors": ["David Jin", "Qian Fu", "Yuekang Li"], "title": "Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode-related tasks, raising concerns about their potential for automated\nexploit generation (AEG). This paper presents the first systematic study on\nLLMs' effectiveness in AEG, evaluating both their cooperativeness and technical\nproficiency. To mitigate dataset bias, we introduce a benchmark with refactored\nversions of five software security labs. Additionally, we design an LLM-based\nattacker to systematically prompt LLMs for exploit generation. Our experiments\nreveal that GPT-4 and GPT-4o exhibit high cooperativeness, comparable to\nuncensored models, while Llama3 is the most resistant. However, no model\nsuccessfully generates exploits for refactored labs, though GPT-4o's minimal\nerrors highlight the potential for LLM-driven AEG advancements.", "AI": {"tldr": "Study evaluates LLMs' effectiveness in automated exploit generation (AEG), introducing a benchmark and an LLM-based attacker. GPT-4 and GPT-4o show high cooperativeness, but no model succeeds in generating exploits for refactored labs.", "motivation": "Concerns about LLMs' potential for AEG prompted the first systematic study to assess their cooperativeness and technical proficiency in this context.", "method": "Introduced a benchmark with refactored security labs and designed an LLM-based attacker to systematically prompt LLMs for exploit generation.", "result": "GPT-4 and GPT-4o were highly cooperative, comparable to uncensored models, while Llama3 was the most resistant. No model succeeded in generating exploits for refactored labs, though GPT-4o's minimal errors suggest potential.", "conclusion": "LLMs show promise for AEG, but current models fail to generate exploits for refactored labs, indicating room for improvement."}}
{"id": "2505.01049", "pdf": "https://arxiv.org/pdf/2505.01049", "abs": "https://arxiv.org/abs/2505.01049", "authors": ["Nishant Jain", "Xunpeng Huang", "Yian Ma", "Tong Zhang"], "title": "Multi-Step Consistency Models: Fast Generation with Theoretical Guarantees", "categories": ["cs.LG", "math.AP", "math.ST", "stat.ML", "stat.TH"], "comment": "29 pages", "summary": "Consistency models have recently emerged as a compelling alternative to\ntraditional SDE based diffusion models, offering a significant acceleration in\ngeneration by producing high quality samples in very few steps. Despite their\nempirical success, a proper theoretic justification for their speed up is still\nlacking. In this work, we provide the analysis which bridges this gap, showing\nthat given a consistency model which can map the input at a given time to\narbitrary timestamps along the reverse trajectory, one can achieve KL\ndivergence of order $ O(\\varepsilon^2) $ using only $\nO\\left(\\log\\left(\\frac{d}{\\varepsilon}\\right)\\right) $ iterations with constant\nstep size, where d is the data dimension. Additionally, under minimal\nassumptions on the data distribution an increasingly common setting in recent\ndiffusion model analyses we show that a similar KL convergence guarantee can be\nobtained, with the number of steps scaling as $ O\\left(d\n\\log\\left(\\frac{d}{\\varepsilon}\\right)\\right) $. Going further, we also provide\na theoretical analysis for estimation of such consistency models, concluding\nthat accurate learning is feasible using small discretization steps, both in\nsmooth and non smooth settings. Notably, our results for the non smooth case\nyield best in class convergence rates compared to existing SDE or ODE based\nanalyses under minimal assumptions.", "AI": {"tldr": "The paper provides a theoretical justification for the speed-up of consistency models over traditional SDE-based diffusion models, showing improved convergence rates and feasibility of accurate learning under minimal assumptions.", "motivation": "To bridge the gap in theoretical understanding of why consistency models accelerate generation compared to SDE-based diffusion models.", "method": "Theoretical analysis of consistency models, focusing on their ability to map inputs to arbitrary timestamps along the reverse trajectory, and examining convergence rates under different data distribution assumptions.", "result": "Achieves KL divergence of order O(\u03b5\u00b2) with O(log(d/\u03b5)) iterations, and similar guarantees under minimal assumptions, with best-in-class convergence rates for non-smooth settings.", "conclusion": "Consistency models are theoretically justified for fast, high-quality sample generation, with practical learning feasibility even in non-smooth scenarios."}}
{"id": "2505.01203", "pdf": "https://arxiv.org/pdf/2505.01203", "abs": "https://arxiv.org/abs/2505.01203", "authors": ["Andrej Macko", "Luk\u00e1\u0161 Gajdo\u0161ech", "Viktor Kocur"], "title": "Efficient Vision-based Vehicle Speed Estimation", "categories": ["cs.CV", "68T45", "I.4.9"], "comment": "Submitted to Journal of Real-Time Image Processing (JRTIP)", "summary": "This paper presents a computationally efficient method for vehicle speed\nestimation from traffic camera footage. Building upon previous work that\nutilizes 3D bounding boxes derived from 2D detections and vanishing point\ngeometry, we introduce several improvements to enhance real-time performance.\nWe evaluate our method in several variants on the BrnoCompSpeed dataset in\nterms of vehicle detection and speed estimation accuracy. Our extensive\nevaluation across various hardware platforms, including edge devices,\ndemonstrates significant gains in frames per second (FPS) compared to the prior\nstate-of-the-art, while maintaining comparable or improved speed estimation\naccuracy. We analyze the trade-off between accuracy and computational cost,\nshowing that smaller models utilizing post-training quantization offer the best\nbalance for real-world deployment. Our best performing model beats previous\nstate-of-the-art in terms of median vehicle speed estimation error (0.58 km/h\nvs. 0.60 km/h), detection precision (91.02% vs 87.08%) and recall (91.14% vs.\n83.32%) while also being 5.5 times faster.", "AI": {"tldr": "A computationally efficient method for vehicle speed estimation from traffic camera footage, improving real-time performance and accuracy over prior work.", "motivation": "To enhance real-time vehicle speed estimation from traffic cameras by improving computational efficiency without sacrificing accuracy.", "method": "Utilizes 3D bounding boxes from 2D detections and vanishing point geometry, with optimizations for real-time performance. Evaluated on the BrnoCompSpeed dataset.", "result": "Achieves better FPS and accuracy (0.58 km/h median error, 91.02% precision, 91.14% recall) while being 5.5x faster than prior state-of-the-art.", "conclusion": "Smaller models with post-training quantization offer the best balance for real-world deployment, outperforming prior methods in speed and accuracy."}}
{"id": "2412.10422", "pdf": "https://arxiv.org/pdf/2412.10422", "abs": "https://arxiv.org/abs/2412.10422", "authors": ["Meihao Fan", "Ju Fan", "Nan Tang", "Lei Cao", "Guoliang Li", "Xiaoyong Du"], "title": "AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Answering natural language (NL) questions about tables, known as Tabular\nQuestion Answering (TQA), is crucial because it allows users to quickly and\nefficiently extract meaningful insights from structured data, effectively\nbridging the gap between human language and machine-readable formats. Many of\nthese tables are derived from web sources or real-world scenarios, which\nrequire meticulous data preparation (or data prep) to ensure accurate\nresponses. However, preparing such tables for NL questions introduces new\nrequirements that extend beyond traditional data preparation. This\nquestion-aware data preparation involves specific tasks such as column\nderivation and filtering tailored to particular questions, as well as\nquestion-aware value normalization or conversion, highlighting the need for a\nmore nuanced approach in this context. Because each of the above tasks is\nunique, a single model (or agent) may not perform effectively across all\nscenarios. In this paper, we propose AutoPrep, a large language model\n(LLM)-based multi-agent framework that leverages the strengths of multiple\nagents, each specialized in a certain type of data prep, ensuring more accurate\nand contextually relevant responses. Given an NL question over a table,\nAutoPrep performs data prep through three key components. Planner: Determines a\nlogical plan, outlining a sequence of high-level operations. Programmer:\nTranslates this logical plan into a physical plan by generating the\ncorresponding low-level code. Executor: Executes the generated code to process\nthe table. To support this multi-agent framework, we design a novel\nChain-of-Clauses reasoning mechanism for high-level operation suggestion, and a\ntool-augmented method for low-level code generation...", "AI": {"tldr": "AutoPrep is an LLM-based multi-agent framework for Tabular Question Answering, using specialized agents for data prep tasks like column derivation and filtering, ensuring accurate responses.", "motivation": "Traditional data prep methods are insufficient for NL questions over tables, requiring a nuanced, question-aware approach.", "method": "AutoPrep uses a multi-agent framework with Planner, Programmer, and Executor components, supported by Chain-of-Clauses reasoning and tool-augmented code generation.", "result": "The framework enables more accurate and contextually relevant responses to NL questions over tables.", "conclusion": "AutoPrep addresses the limitations of single-model approaches by leveraging specialized agents for diverse data prep tasks."}}
{"id": "2505.01067", "pdf": "https://arxiv.org/pdf/2505.01067", "abs": "https://arxiv.org/abs/2505.01067", "authors": ["Ziqi Ding", "Qian Fu", "Junchen Ding", "Gelei Deng", "Yi Liu", "Yuekang Li"], "title": "A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have spurred the\ndevelopment of diverse AI applications from code generation and video editing\nto text generation; however, AI supply chains such as Hugging Face, which host\npretrained models and their associated configuration files contributed by the\npublic, face significant security challenges; in particular, configuration\nfiles originally intended to set up models by specifying parameters and initial\nsettings can be exploited to execute unauthorized code, yet research has\nlargely overlooked their security compared to that of the models themselves; in\nthis work, we present the first comprehensive study of malicious configurations\non Hugging Face, identifying three attack scenarios (file, website, and\nrepository operations) that expose inherent risks; to address these threats, we\nintroduce CONFIGSCAN, an LLM-based tool that analyzes configuration files in\nthe context of their associated runtime code and critical libraries,\neffectively detecting suspicious elements with low false positive rates and\nhigh accuracy; our extensive evaluation uncovers thousands of suspicious\nrepositories and configuration files, underscoring the urgent need for enhanced\nsecurity validation in AI model hosting platforms.", "AI": {"tldr": "The paper highlights security risks in AI supply chains, specifically malicious configuration files on Hugging Face, and introduces CONFIGSCAN, an LLM-based tool to detect such threats.", "motivation": "The security of configuration files in AI supply chains like Hugging Face is overlooked despite their potential for misuse, prompting the need for a dedicated study and solution.", "method": "The study identifies three attack scenarios and develops CONFIGSCAN, an LLM-based tool, to analyze configuration files in context, detecting suspicious elements accurately.", "result": "Thousands of suspicious repositories and configuration files were uncovered, demonstrating the tool's effectiveness with low false positives and high accuracy.", "conclusion": "The findings emphasize the urgent need for improved security validation in AI model hosting platforms to mitigate risks from malicious configurations."}}
{"id": "2505.01060", "pdf": "https://arxiv.org/pdf/2505.01060", "abs": "https://arxiv.org/abs/2505.01060", "authors": ["Jihong Wang", "Xiaochuan Tian", "Zhongqiang Zhang", "Stewart Silling", "Siavash Jafarzadeh", "Yue Yu"], "title": "Monotone Peridynamic Neural Operator for Nonlinear Material Modeling with Conditionally Unique Solutions", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Data-driven methods have emerged as powerful tools for modeling the responses\nof complex nonlinear materials directly from experimental measurements. Among\nthese methods, the data-driven constitutive models present advantages in\nphysical interpretability and generalizability across different boundary\nconditions/domain settings. However, the well-posedness of these learned models\nis generally not guaranteed a priori, which makes the models prone to\nnon-physical solutions in downstream simulation tasks. In this study, we\nintroduce monotone peridynamic neural operator (MPNO), a novel data-driven\nnonlocal constitutive model learning approach based on neural operators. Our\napproach learns a nonlocal kernel together with a nonlinear constitutive\nrelation, while ensuring solution uniqueness through a monotone gradient\nnetwork. This architectural constraint on gradient induces convexity of the\nlearnt energy density function, thereby guaranteeing solution uniqueness of\nMPNO in small deformation regimes. To validate our approach, we evaluate MPNO's\nperformance on both synthetic and real-world datasets. On synthetic datasets\nwith manufactured kernel and constitutive relation, we show that the learnt\nmodel converges to the ground-truth as the measurement grid size decreases both\ntheoretically and numerically. Additionally, our MPNO exhibits superior\ngeneralization capabilities than the conventional neural networks: it yields\nsmaller displacement solution errors in down-stream tasks with new and unseen\nloadings. Finally, we showcase the practical utility of our approach through\napplications in learning a homogenized model from molecular dynamics data,\nhighlighting its expressivity and robustness in real-world scenarios.", "AI": {"tldr": "The paper introduces MPNO, a data-driven nonlocal constitutive model learning approach, ensuring solution uniqueness and convexity for reliable simulations.", "motivation": "Existing data-driven constitutive models lack guaranteed well-posedness, leading to non-physical solutions in simulations.", "method": "MPNO combines a neural operator with a monotone gradient network to learn a nonlocal kernel and constitutive relation, ensuring convexity and uniqueness.", "result": "MPNO converges to ground-truth on synthetic data and outperforms conventional neural networks in generalization and accuracy for new loadings.", "conclusion": "MPNO offers a robust, interpretable, and generalizable solution for modeling complex materials, validated by synthetic and real-world applications."}}
{"id": "2505.01207", "pdf": "https://arxiv.org/pdf/2505.01207", "abs": "https://arxiv.org/abs/2505.01207", "authors": ["Qingyu Xian", "Weiqin Jiao", "Hao Cheng", "Berend Jan van der Zwaag", "Yanqiu Huang"], "title": "T-Graph: Enhancing Sparse-view Camera Pose Estimation by Pairwise Translation Graph", "categories": ["cs.CV"], "comment": null, "summary": "Sparse-view camera pose estimation, which aims to estimate the\n6-Degree-of-Freedom (6-DoF) poses from a limited number of images captured from\ndifferent viewpoints, is a fundamental yet challenging problem in remote\nsensing applications. Existing methods often overlook the translation\ninformation between each pair of viewpoints, leading to suboptimal performance\nin sparse-view scenarios. To address this limitation, we introduce T-Graph, a\nlightweight, plug-and-play module to enhance camera pose estimation in\nsparse-view settings. T-graph takes paired image features as input and maps\nthem through a Multilayer Perceptron (MLP). It then constructs a fully\nconnected translation graph, where nodes represent cameras and edges encode\ntheir translation relationships. It can be seamlessly integrated into existing\nmodels as an additional branch in parallel with the original prediction,\nmaintaining efficiency and ease of use. Furthermore, we introduce two pairwise\ntranslation representations, relative-t and pair-t, formulated under different\nlocal coordinate systems. While relative-t captures intuitive spatial\nrelationships, pair-t offers a rotation-disentangled alternative. The two\nrepresentations contribute to enhanced adaptability across diverse application\nscenarios, further improving our module's robustness. Extensive experiments on\ntwo state-of-the-art methods (RelPose++ and Forge) using public datasets (C03D\nand IMC PhotoTourism) validate both the effectiveness and generalizability of\nT-Graph. The results demonstrate consistent improvements across various\nmetrics, notably camera center accuracy, which improves by 1% to 6% from 2 to 8\nviewpoints.", "AI": {"tldr": "T-Graph is a lightweight module enhancing sparse-view camera pose estimation by incorporating translation information through a fully connected graph and two novel pairwise translation representations.", "motivation": "Existing methods neglect translation information between viewpoints, limiting performance in sparse-view scenarios.", "method": "T-Graph uses an MLP to map paired image features into a translation graph, with nodes as cameras and edges as translation relationships. It integrates into existing models and introduces two translation representations (relative-t and pair-t).", "result": "Experiments on RelPose++ and Forge with C03D and IMC PhotoTourism datasets show T-Graph improves camera center accuracy by 1% to 6% from 2 to 8 viewpoints.", "conclusion": "T-Graph effectively enhances sparse-view pose estimation, offering robustness and adaptability across diverse scenarios."}}
{"id": "2501.00070", "pdf": "https://arxiv.org/pdf/2501.00070", "abs": "https://arxiv.org/abs/2501.00070", "authors": ["Core Francisco Park", "Andrew Lee", "Ekdeep Singh Lubana", "Yongyi Yang", "Maya Okawa", "Kento Nishi", "Martin Wattenberg", "Hidenori Tanaka"], "title": "ICLR: In-Context Learning of Representations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICLR 2025", "summary": "Recent work has demonstrated that semantics specified by pretraining data\ninfluence how representations of different concepts are organized in a large\nlanguage model (LLM). However, given the open-ended nature of LLMs, e.g., their\nability to in-context learn, we can ask whether models alter these pretraining\nsemantics to adopt alternative, context-specified ones. Specifically, if we\nprovide in-context exemplars wherein a concept plays a different role than what\nthe pretraining data suggests, do models reorganize their representations in\naccordance with these novel semantics? To answer this question, we take\ninspiration from the theory of conceptual role semantics and define a toy\n\"graph tracing\" task wherein the nodes of the graph are referenced via concepts\nseen during training (e.g., apple, bird, etc.) and the connectivity of the\ngraph is defined via some predefined structure (e.g., a square grid). Given\nexemplars that indicate traces of random walks on the graph, we analyze\nintermediate representations of the model and find that as the amount of\ncontext is scaled, there is a sudden re-organization from pretrained semantic\nrepresentations to in-context representations aligned with the graph structure.\nFurther, we find that when reference concepts have correlations in their\nsemantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure\nis still present in the representations, but is unable to dominate the\npretrained structure. To explain these results, we analogize our task to energy\nminimization for a predefined graph topology, providing evidence towards an\nimplicit optimization process to infer context-specified semantics. Overall,\nour findings indicate scaling context-size can flexibly re-organize model\nrepresentations, possibly unlocking novel capabilities.", "AI": {"tldr": "The paper investigates whether large language models (LLMs) can reorganize their pretrained semantic representations to align with context-specified semantics, using a graph tracing task.", "motivation": "To explore if LLMs can flexibly adapt their representations to novel, context-driven semantics, despite being influenced by pretraining data.", "method": "A toy graph tracing task is designed, where nodes are training concepts (e.g., apple, bird) and connectivity follows a predefined structure (e.g., square grid). Random walk exemplars are provided, and model representations are analyzed.", "result": "Increasing context size triggers a sudden shift from pretrained to context-aligned representations. Pretrained semantics persist when reference concepts are correlated (e.g., days of the week).", "conclusion": "Scaling context size can flexibly reorganize LLM representations, suggesting an implicit optimization process for context-specified semantics and potential for novel capabilities."}}
{"id": "2505.01070", "pdf": "https://arxiv.org/pdf/2505.01070", "abs": "https://arxiv.org/abs/2505.01070", "authors": ["Edvin Fasth", "Sagar Singh"], "title": "Improving Group Fairness in Knowledge Distillation via Laplace Approximation of Early Exits", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages", "summary": "Knowledge distillation (KD) has become a powerful tool for training compact\nstudent models using larger, pretrained teacher models, often requiring less\ndata and computational resources. Teacher models typically possess more layers\nand thus exhibit richer feature representations compared to their student\ncounterparts. Furthermore, student models tend to learn simpler, surface-level\nfeatures in their early layers. This discrepancy can increase errors in groups\nwhere labels spuriously correlate with specific input attributes, leading to a\ndecline in group fairness even when overall accuracy remains comparable to the\nteacher. To mitigate these challenges, Early-Exit Neural Networks (EENNs),\nwhich enable predictions at multiple intermediate layers, have been employed.\nConfidence margins derived from these early exits have been utilized to\nreweight both cross-entropy and distillation losses on a per-instance basis. In\nthis paper, we propose that leveraging Laplace approximation-based methods to\nobtain well-calibrated uncertainty estimates can also effectively reweight\nchallenging instances and improve group fairness. We hypothesize that Laplace\napproximation offers a more robust identification of difficult or ambiguous\ninstances compared to margin-based approaches. To validate our claims, we\nbenchmark our approach using a Bert-based model on the MultiNLI dataset.", "AI": {"tldr": "The paper proposes using Laplace approximation to improve group fairness in knowledge distillation by reweighting challenging instances, outperforming margin-based methods.", "motivation": "Addressing the decline in group fairness in student models due to simpler feature learning and spurious label correlations, despite comparable accuracy to teacher models.", "method": "Employing Early-Exit Neural Networks (EENNs) and using Laplace approximation for uncertainty estimates to reweight cross-entropy and distillation losses per instance.", "result": "The approach is validated using a Bert-based model on the MultiNLI dataset, showing improved fairness.", "conclusion": "Laplace approximation provides more robust identification of difficult instances, enhancing group fairness in knowledge distillation."}}
{"id": "2505.01075", "pdf": "https://arxiv.org/pdf/2505.01075", "abs": "https://arxiv.org/abs/2505.01075", "authors": ["Yiyuan Yang", "Guodong Long", "Tianyi Zhou", "Qinghua Lu", "Shanshan Ye", "Jing Jiang"], "title": "Federated Adapter on Foundation Models: An Out-Of-Distribution Approach", "categories": ["cs.LG"], "comment": null, "summary": "As foundation models gain prominence, Federated Foundation Models (FedFM)\nhave emerged as a privacy-preserving approach to collaboratively fine-tune\nmodels in federated learning (FL) frameworks using distributed datasets across\nclients. A key challenge for FedFM, given the versatile nature of foundation\nmodels, is addressing out-of-distribution (OOD) generalization, where unseen\ntasks or clients may exhibit distribution shifts leading to suboptimal\nperformance. Although numerous studies have explored OOD generalization in\nconventional FL, these methods are inadequate for FedFM due to the challenges\nposed by large parameter scales and increased data heterogeneity. To address\nthese, we propose FedOA, which employs adapter-based parameter-efficient\nfine-tuning methods for efficacy and introduces personalized adapters with\nfeature distance-based regularization to align distributions and guarantee OOD\ngeneralization for each client. Theoretically, we demonstrate that the\nconventional aggregated global model in FedFM inherently retains OOD\ngeneralization capabilities, and our proposed method enhances the personalized\nmodel's OOD generalization through regularization informed by the global model,\nwith proven convergence under general non-convex settings. Empirically, the\neffectiveness of the proposed method is validated on benchmark datasets across\nvarious NLP tasks.", "AI": {"tldr": "FedOA addresses OOD generalization in Federated Foundation Models (FedFM) by using adapter-based fine-tuning and personalized adapters with feature distance regularization.", "motivation": "To tackle OOD generalization challenges in FedFM due to large parameter scales and data heterogeneity, which conventional FL methods fail to address.", "method": "Proposes FedOA, employing adapter-based fine-tuning and personalized adapters with feature distance regularization to align distributions.", "result": "Theoretical proof of global model's OOD capabilities and empirical validation on NLP tasks show improved performance.", "conclusion": "FedOA effectively enhances OOD generalization in FedFM, validated by theory and experiments."}}
{"id": "2505.01225", "pdf": "https://arxiv.org/pdf/2505.01225", "abs": "https://arxiv.org/abs/2505.01225", "authors": ["Keiller Nogueira", "Akram Zaytar", "Wanli Ma", "Ribana Roscher", "Ronny H\u00e4nsch", "Caleb Robinson", "Anthony Ortiz", "Simone Nsutezo", "Rahul Dodhia", "Juan M. Lavista Ferres", "Oktay Karaku\u015f", "Paul L. Rosin"], "title": "Core-Set Selection for Data-efficient Land Cover Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "The increasing accessibility of remotely sensed data and the potential of\nsuch data to inform large-scale decision-making has driven the development of\ndeep learning models for many Earth Observation tasks. Traditionally, such\nmodels must be trained on large datasets. However, the common assumption that\nbroadly larger datasets lead to better outcomes tends to overlook the\ncomplexities of the data distribution, the potential for introducing biases and\nnoise, and the computational resources required for processing and storing vast\ndatasets. Therefore, effective solutions should consider both the quantity and\nquality of data. In this paper, we propose six novel core-set selection methods\nfor selecting important subsets of samples from remote sensing image\nsegmentation datasets that rely on imagery only, labels only, and a combination\nof each. We benchmark these approaches against a random-selection baseline on\nthree commonly used land cover classification datasets: DFC2022, Vaihingen, and\nPotsdam. In each of the datasets, we demonstrate that training on a subset of\nsamples outperforms the random baseline, and some approaches outperform\ntraining on all available data. This result shows the importance and potential\nof data-centric learning for the remote sensing domain. The code is available\nat https://github.com/keillernogueira/data-centric-rs-classification/.", "AI": {"tldr": "Proposes six core-set selection methods for remote sensing image segmentation, showing subsets can outperform random baselines and even full datasets.", "motivation": "Addresses the overlooked complexities of large datasets in Earth Observation, emphasizing the need for both quantity and quality in data.", "method": "Introduces six novel core-set selection methods (using imagery, labels, or both) and benchmarks them against random selection on three datasets.", "result": "Subsets selected by the methods outperform random baselines, with some surpassing full dataset training.", "conclusion": "Highlights the potential of data-centric learning in remote sensing, advocating for smarter data selection over sheer volume."}}
{"id": "2501.06382", "pdf": "https://arxiv.org/pdf/2501.06382", "abs": "https://arxiv.org/abs/2501.06382", "authors": ["Mumin Jia", "Jairo Diaz-Rodriguez"], "title": "Dynamics of Spontaneous Topic Changes in Next Token Prediction with Self-Attention", "categories": ["cs.CL", "cs.AI", "stat.ML"], "comment": null, "summary": "Human cognition is punctuated by abrupt, spontaneous shifts between\ntopics-driven by emotional, contextual, or associative cues-a phenomenon known\nas spontaneous thought in neuroscience. In contrast, self-attention based\nmodels depend on structured patterns over their inputs to predict each next\ntoken, lacking spontaneity. Motivated by this distinction, we characterize\nspontaneous topic changes in self-attention architectures, revealing both their\nsimilarities and their divergences from spontaneous human thought. First, we\nestablish theoretical results under a simplified, single-layer self-attention\nmodel with suitable conditions by defining the topic as a set of Token Priority\nGraphs (TPGs). Specifically, we demonstrate that (1) the model maintains the\npriority order of tokens related to the input topic, (2) a spontaneous topic\nchange can occur only if lower-priority tokens outnumber all higher-priority\ntokens of the input topic, and (3) unlike human cognition, the longer context\nlength or the more ambiguous input topic reduces the likelihood of spontaneous\nchange. Second, we empirically validate that these dynamics persist in modern,\nstate-of-the-art LLMs, underscoring a fundamental disparity between human\ncognition and AI behaviour in the context of spontaneous topic changes. To the\nbest of our knowledge, no prior work has explored these questions with a focus\nas closely aligned to human thought.", "AI": {"tldr": "The paper explores spontaneous topic changes in self-attention models, comparing them to human cognition, and reveals key differences in behavior.", "motivation": "To understand how self-attention models handle spontaneous topic shifts, contrasting them with human spontaneous thought.", "method": "Theoretical analysis under a simplified single-layer self-attention model with Token Priority Graphs (TPGs), followed by empirical validation in modern LLMs.", "result": "Self-attention models maintain token priority order, require specific conditions for topic changes, and show reduced spontaneity with longer contexts or ambiguous inputs.", "conclusion": "Self-attention models fundamentally diverge from human cognition in handling spontaneous topic changes, highlighting a key AI limitation."}}
{"id": "2505.01085", "pdf": "https://arxiv.org/pdf/2505.01085", "abs": "https://arxiv.org/abs/2505.01085", "authors": ["Alexander Wuttke", "Adrian Rauchfleisch", "Andreas Jungherr"], "title": "Artificial Intelligence in Government: Why People Feel They Lose Control", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The use of Artificial Intelligence (AI) in public administration is expanding\nrapidly, moving from automating routine tasks to deploying generative and\nagentic systems that autonomously act on goals. While AI promises greater\nefficiency and responsiveness, its integration into government functions raises\nconcerns about fairness, transparency, and accountability. This article applies\nprincipal-agent theory (PAT) to conceptualize AI adoption as a special case of\ndelegation, highlighting three core tensions: assessability (can decisions be\nunderstood?), dependency (can the delegation be reversed?), and contestability\n(can decisions be challenged?). These structural challenges may lead to a\n\"failure-by-success\" dynamic, where early functional gains obscure long-term\nrisks to democratic legitimacy. To test this framework, we conducted a\npre-registered factorial survey experiment across tax, welfare, and law\nenforcement domains. Our findings show that although efficiency gains initially\nbolster trust, they simultaneously reduce citizens' perceived control. When the\nstructural risks come to the foreground, institutional trust and perceived\ncontrol both drop sharply, suggesting that hidden costs of AI adoption\nsignificantly shape public attitudes. The study demonstrates that PAT offers a\npowerful lens for understanding the institutional and political implications of\nAI in government, emphasizing the need for policymakers to address delegation\nrisks transparently to maintain public trust.", "AI": {"tldr": "AI in public administration improves efficiency but raises concerns about fairness and accountability. Principal-agent theory highlights tensions in AI delegation, leading to hidden risks. A survey shows efficiency gains boost trust but reduce perceived control, with long-term risks harming public trust.", "motivation": "To explore the implications of AI adoption in government, focusing on fairness, transparency, and accountability, using principal-agent theory.", "method": "Applied principal-agent theory to AI delegation, identifying three tensions (assessability, dependency, contestability). Conducted a pre-registered factorial survey experiment across tax, welfare, and law enforcement domains.", "result": "Efficiency gains initially increase trust but reduce perceived control. When structural risks emerge, trust and control drop sharply, revealing hidden costs of AI adoption.", "conclusion": "Principal-agent theory effectively analyzes AI's political implications. Policymakers must address delegation risks transparently to sustain public trust."}}
{"id": "2505.01078", "pdf": "https://arxiv.org/pdf/2505.01078", "abs": "https://arxiv.org/abs/2505.01078", "authors": ["Sungje Park", "Stephen Tu"], "title": "Integration Matters for Learning PDEs with Backwards SDEs", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "comment": null, "summary": "Backward stochastic differential equation (BSDE)-based deep learning methods\nprovide an alternative to Physics-Informed Neural Networks (PINNs) for solving\nhigh-dimensional partial differential equations (PDEs), offering algorithmic\nadvantages in settings such as stochastic optimal control, where the PDEs of\ninterest are tied to an underlying dynamical system. However, existing\nBSDE-based solvers have empirically been shown to underperform relative to\nPINNs in the literature. In this paper, we identify the root cause of this\nperformance gap as a discretization bias introduced by the standard\nEuler-Maruyama (EM) integration scheme applied to short-horizon\nself-consistency BSDE losses, which shifts the optimization landscape off\ntarget. We find that this bias cannot be satisfactorily addressed through finer\nstep sizes or longer self-consistency horizons. To properly handle this issue,\nwe propose a Stratonovich-based BSDE formulation, which we implement with\nstochastic Heun integration. We show that our proposed approach completely\neliminates the bias issues faced by EM integration. Furthermore, our empirical\nresults show that our Heun-based BSDE method consistently outperforms EM-based\nvariants and achieves competitive results with PINNs across multiple\nhigh-dimensional benchmarks. Our findings highlight the critical role of\nintegration schemes in BSDE-based PDE solvers, an algorithmic detail that has\nreceived little attention thus far in the literature.", "AI": {"tldr": "The paper identifies discretization bias in BSDE-based PDE solvers due to Euler-Maruyama integration and proposes a Stratonovich-based BSDE with Heun integration to eliminate bias, outperforming EM-based methods and matching PINNs.", "motivation": "Existing BSDE-based solvers underperform compared to PINNs due to discretization bias from Euler-Maruyama integration in short-horizon self-consistency BSDE losses.", "method": "Proposes a Stratonovich-based BSDE formulation with stochastic Heun integration to address the bias issue.", "result": "The Heun-based method eliminates bias, outperforms EM-based variants, and achieves competitive results with PINNs in high-dimensional benchmarks.", "conclusion": "Integration schemes are critical in BSDE-based PDE solvers, and the proposed Heun-based approach effectively addresses the bias problem."}}
{"id": "2505.01235", "pdf": "https://arxiv.org/pdf/2505.01235", "abs": "https://arxiv.org/abs/2505.01235", "authors": ["Youngsik Yun", "Jeongmin Bae", "Hyunseung Son", "Seoha Kim", "Hahyun Lee", "Gun Bang", "Youngjung Uh"], "title": "Compensating Spatiotemporally Inconsistent Observations for Online Dynamic 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "SIGGRAPH 2025, Project page: https://bbangsik13.github.io/OR2", "summary": "Online reconstruction of dynamic scenes is significant as it enables learning\nscenes from live-streaming video inputs, while existing offline dynamic\nreconstruction methods rely on recorded video inputs. However, previous online\nreconstruction approaches have primarily focused on efficiency and rendering\nquality, overlooking the temporal consistency of their results, which often\ncontain noticeable artifacts in static regions. This paper identifies that\nerrors such as noise in real-world recordings affect temporal inconsistency in\nonline reconstruction. We propose a method that enhances temporal consistency\nin online reconstruction from observations with temporal inconsistency which is\ninevitable in cameras. We show that our method restores the ideal observation\nby subtracting the learned error. We demonstrate that applying our method to\nvarious baselines significantly enhances both temporal consistency and\nrendering quality across datasets. Code, video results, and checkpoints are\navailable at https://bbangsik13.github.io/OR2.", "AI": {"tldr": "The paper proposes a method to improve temporal consistency in online dynamic scene reconstruction by addressing noise-induced errors in real-world recordings.", "motivation": "Existing online reconstruction methods prioritize efficiency and rendering quality but neglect temporal consistency, leading to artifacts in static regions.", "method": "The method enhances temporal consistency by learning and subtracting errors from observations with inevitable temporal inconsistency.", "result": "The approach significantly improves both temporal consistency and rendering quality across various datasets.", "conclusion": "The proposed method effectively addresses temporal inconsistency in online reconstruction, with code and results publicly available."}}
{"id": "2501.19378", "pdf": "https://arxiv.org/pdf/2501.19378", "abs": "https://arxiv.org/abs/2501.19378", "authors": ["Lang Cao", "Hanbing Liu"], "title": "TableMaster: A Recipe to Advance Table Understanding with Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Tables serve as a fundamental format for representing structured relational\ndata. While current language models (LMs) excel at many text-based tasks, they\nstill face challenges in table understanding due to the complex characteristics\nof tabular data, such as their structured nature. In this paper, we aim to\nenhance LMs for improved table understanding. We identify four key challenges:\n1) difficulty in locating target data, 2) deficiency in table semantics, 3)\nnumerical inaccuracies in textual reasoning, and 4) semantic inflexibility in\nsymbolic reasoning. To address these issues, we propose TableMaster, a recipe\nand comprehensive framework that integrates multiple solutions to overcome\nthese obstacles. TableMaster first extracts relevant table content and\nverbalizes it with enriched semantic context. Additionally, we introduce\nadaptive reasoning, a flexible approach that dynamically adjusts between\ntextual and symbolic reasoning, tailoring the reasoning process to each query.\nExtensive analyses and experiments demonstrate our findings and the\neffectiveness of TableMaster. On the WikiTQ dataset, TableMaster achieves an\naccuracy of 78.13% using GPT-4o-mini, surpassing existing baselines.", "AI": {"tldr": "TableMaster enhances language models for table understanding by addressing key challenges like data location, semantics, numerical accuracy, and reasoning flexibility, achieving 78.13% accuracy on WikiTQ.", "motivation": "Current language models struggle with table understanding due to the structured nature of tabular data. The paper aims to improve LMs' ability to handle tables by tackling four major challenges.", "method": "Proposes TableMaster, a framework that extracts and verbalizes table content with enriched semantics and introduces adaptive reasoning for dynamic adjustment between textual and symbolic reasoning.", "result": "TableMaster achieves 78.13% accuracy on the WikiTQ dataset, outperforming existing baselines.", "conclusion": "TableMaster effectively addresses key challenges in table understanding, demonstrating superior performance and flexibility in reasoning."}}
{"id": "2505.01094", "pdf": "https://arxiv.org/pdf/2505.01094", "abs": "https://arxiv.org/abs/2505.01094", "authors": ["Zuzanna Osika", "Roxana Radelescu", "Jazmin Zatarain Salazar", "Frans Oliehoek", "Pradeep K. Murukannaiah"], "title": "Multi-Objective Reinforcement Learning for Water Management", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to AAMAS 2025", "summary": "Many real-world problems (e.g., resource management, autonomous driving, drug\ndiscovery) require optimizing multiple, conflicting objectives. Multi-objective\nreinforcement learning (MORL) extends classic reinforcement learning to handle\nmultiple objectives simultaneously, yielding a set of policies that capture\nvarious trade-offs. However, the MORL field lacks complex, realistic\nenvironments and benchmarks. We introduce a water resource (Nile river basin)\nmanagement case study and model it as a MORL environment. We then benchmark\nexisting MORL algorithms on this task. Our results show that specialized water\nmanagement methods outperform state-of-the-art MORL approaches, underscoring\nthe scalability challenges MORL algorithms face in real-world scenarios.", "AI": {"tldr": "The paper introduces a water resource management case study (Nile river basin) as a complex MORL environment and benchmarks MORL algorithms, finding specialized methods outperform MORL approaches.", "motivation": "Address the lack of complex, realistic environments in MORL for real-world problems like resource management.", "method": "Model the Nile river basin as a MORL environment and benchmark existing MORL algorithms.", "result": "Specialized water management methods outperform state-of-the-art MORL approaches.", "conclusion": "Highlights scalability challenges for MORL in real-world scenarios."}}
{"id": "2505.01099", "pdf": "https://arxiv.org/pdf/2505.01099", "abs": "https://arxiv.org/abs/2505.01099", "authors": ["Thalaiyasingam Ajanthan", "Sameera Ramasinghe", "Yan Zuo", "Gil Avraham", "Alexander Long"], "title": "Nesterov Method for Asynchronous Pipeline Parallel Optimization", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Pipeline Parallelism (PP) enables large neural network training on small,\ninterconnected devices by splitting the model into multiple stages. To maximize\npipeline utilization, asynchronous optimization is appealing as it offers 100%\npipeline utilization by construction. However, it is inherently challenging as\nthe weights and gradients are no longer synchronized, leading to stale (or\ndelayed) gradients. To alleviate this, we introduce a variant of Nesterov\nAccelerated Gradient (NAG) for asynchronous optimization in PP. Specifically,\nwe modify the look-ahead step in NAG to effectively address the staleness in\ngradients. We theoretically prove that our approach converges at a sublinear\nrate in the presence of fixed delay in gradients. Our experiments on\nlarge-scale language modelling tasks using decoder-only architectures with up\nto 1B parameters, demonstrate that our approach significantly outperforms\nexisting asynchronous methods, even surpassing the synchronous baseline.", "AI": {"tldr": "A modified Nesterov Accelerated Gradient (NAG) method is introduced to address stale gradients in asynchronous Pipeline Parallelism (PP), proving convergence and outperforming existing methods.", "motivation": "Asynchronous PP offers 100% utilization but faces challenges with stale gradients due to lack of synchronization.", "method": "A variant of NAG is proposed, modifying the look-ahead step to handle gradient staleness.", "result": "Theoretical proof of sublinear convergence with fixed delay; experiments show superiority over async methods and sync baselines.", "conclusion": "The modified NAG effectively addresses gradient staleness in PP, improving performance in large-scale tasks."}}
{"id": "2505.01249", "pdf": "https://arxiv.org/pdf/2505.01249", "abs": "https://arxiv.org/abs/2505.01249", "authors": ["Christopher K. I. Williams"], "title": "Fusing Foveal Fixations Using Linear Retinal Transformations and Bayesian Experimental Design", "categories": ["cs.CV", "cs.LG"], "comment": "19 pages, 4 figures", "summary": "Humans (and many vertebrates) face the problem of fusing together multiple\nfixations of a scene in order to obtain a representation of the whole, where\neach fixation uses a high-resolution fovea and decreasing resolution in the\nperiphery. In this paper we explicitly represent the retinal transformation of\na fixation as a linear downsampling of a high-resolution latent image of the\nscene, exploiting the known geometry. This linear transformation allows us to\ncarry out exact inference for the latent variables in factor analysis (FA) and\nmixtures of FA models of the scene. Further, this allows us to formulate and\nsolve the choice of \"where to look next\" as a Bayesian experimental design\nproblem using the Expected Information Gain criterion. Experiments on the Frey\nfaces and MNIST datasets demonstrate the effectiveness of our models.", "AI": {"tldr": "The paper presents a method for fusing multiple fixations of a scene into a unified representation using linear downsampling and Bayesian inference.", "motivation": "Humans and vertebrates need to combine multiple fixations of a scene, each with varying resolution, to form a complete representation.", "method": "The retinal transformation of a fixation is modeled as linear downsampling of a high-resolution latent image, enabling exact inference in factor analysis and mixtures of FA models. Bayesian experimental design is used to decide 'where to look next.'", "result": "Experiments on Frey faces and MNIST datasets show the method's effectiveness.", "conclusion": "The approach successfully integrates multiple fixations and optimizes gaze selection using Bayesian inference."}}
{"id": "2502.01976", "pdf": "https://arxiv.org/pdf/2502.01976", "abs": "https://arxiv.org/abs/2502.01976", "authors": ["Wenhao Zheng", "Yixiao Chen", "Weitong Zhang", "Souvik Kundu", "Yun Li", "Zhengzhong Liu", "Eric P. Xing", "Hongyi Wang", "Huaxiu Yao"], "title": "CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "Large language models have achieved remarkable success in various tasks but\nsuffer from high computational costs during inference, limiting their\ndeployment in resource-constrained applications. To address this issue, we\npropose a novel Collaborative Inference with Token-lEvel Routing (CITER)\nframework that enables efficient collaboration between small and large language\nmodels (SLMs \\& LLMs) through a token-level routing strategy. Specifically,\nCITER routes non-critical tokens to an SLM for efficiency and routes critical\ntokens to an LLM for generalization quality. We formulate router training as a\npolicy optimization, where the router receives rewards based on both the\nquality of predictions and the inference costs of generation. This allows the\nrouter to learn to predict token-level routing scores and make routing\ndecisions based on both the current token and the future impact of its\ndecisions. To further accelerate the reward evaluation process, we introduce a\nshortcut which significantly reduces the costs of the reward estimation and\nimproving the practicality of our approach. Extensive experiments on five\nbenchmark datasets demonstrate that CITER reduces the inference costs while\npreserving high-quality generation, offering a promising solution for real-time\nand resource-constrained applications. Our data and code are available at\nhttps://github.com/aiming-lab/CITER.", "AI": {"tldr": "CITER is a framework for efficient collaboration between small and large language models via token-level routing, reducing inference costs while maintaining quality.", "motivation": "High computational costs of large language models limit their deployment in resource-constrained applications.", "method": "Proposes CITER, a token-level routing strategy where non-critical tokens go to small models and critical tokens to large models, trained via policy optimization with rewards for quality and cost.", "result": "CITER reduces inference costs while preserving generation quality, validated on five benchmark datasets.", "conclusion": "CITER offers a practical solution for real-time, resource-constrained applications."}}
{"id": "2505.01130", "pdf": "https://arxiv.org/pdf/2505.01130", "abs": "https://arxiv.org/abs/2505.01130", "authors": ["Marco C. Campi", "Algo Car\u00e8", "Luis G. Crespo", "Simone Garatti", "Federico A. Ramponi"], "title": "Risk Analysis and Design Against Adversarial Actions", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Learning models capable of providing reliable predictions in the face of\nadversarial actions has become a central focus of the machine learning\ncommunity in recent years. This challenge arises from observing that data\nencountered at deployment time often deviate from the conditions under which\nthe model was trained. In this paper, we address deployment-time adversarial\nactions and propose a versatile, well-principled framework to evaluate the\nmodel's robustness against attacks of diverse types and intensities. While we\ninitially focus on Support Vector Regression (SVR), the proposed approach\nextends naturally to the broad domain of learning via relaxed optimization\ntechniques. Our results enable an assessment of the model vulnerability without\nrequiring additional test data and operate in a distribution-free setup. These\nresults not only provide a tool to enhance trust in the model's applicability\nbut also aid in selecting among competing alternatives. Later in the paper, we\nshow that our findings also offer useful insights for establishing new results\nwithin the out-of-distribution framework.", "AI": {"tldr": "A framework for evaluating model robustness against adversarial actions, applicable to various learning methods, with results aiding model trust and selection.", "motivation": "Addressing the challenge of deployment-time adversarial actions and deviations from training conditions in machine learning models.", "method": "Proposes a versatile, principled framework for robustness evaluation, initially focusing on Support Vector Regression (SVR) but extending to relaxed optimization techniques.", "result": "Enables vulnerability assessment without additional test data in a distribution-free setup, enhancing model trust and aiding selection.", "conclusion": "The framework provides insights for out-of-distribution scenarios and supports robust model evaluation and selection."}}
{"id": "2505.01105", "pdf": "https://arxiv.org/pdf/2505.01105", "abs": "https://arxiv.org/abs/2505.01105", "authors": ["Aurelio Raffa Ugolini", "Mara Tanelli", "Valentina Breschi"], "title": "CoCoAFusE: Beyond Mixtures of Experts via Model Fusion", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Many learning problems involve multiple patterns and varying degrees of\nuncertainty dependent on the covariates. Advances in Deep Learning (DL) have\naddressed these issues by learning highly nonlinear input-output dependencies.\nHowever, model interpretability and Uncertainty Quantification (UQ) have often\nstraggled behind. In this context, we introduce the Competitive/Collaborative\nFusion of Experts (CoCoAFusE), a novel, Bayesian Covariates-Dependent Modeling\ntechnique. CoCoAFusE builds on the very philosophy behind Mixtures of Experts\n(MoEs), blending predictions from several simple sub-models (or \"experts\") to\nachieve high levels of expressiveness while retaining a substantial degree of\nlocal interpretability. Our formulation extends that of a classical Mixture of\nExperts by contemplating the fusion of the experts' distributions in addition\nto their more usual mixing (i.e., superimposition). Through this additional\nfeature, CoCoAFusE better accommodates different scenarios for the intermediate\nbehavior between generating mechanisms, resulting in tighter credible bounds on\nthe response variable. Indeed, only resorting to mixing, as in classical MoEs,\nmay lead to multimodality artifacts, especially over smooth transitions.\nInstead, CoCoAFusE can avoid these artifacts even under the same structure and\npriors for the experts, leading to greater expressiveness and flexibility in\nmodeling. This new approach is showcased extensively on a suite of motivating\nnumerical examples and a collection of real-data ones, demonstrating its\nefficacy in tackling complex regression problems where uncertainty is a key\nquantity of interest.", "AI": {"tldr": "CoCoAFusE is a Bayesian Covariates-Dependent Modeling technique that combines predictions from multiple simple sub-models (experts) to enhance expressiveness and interpretability, while improving uncertainty quantification by fusing experts' distributions.", "motivation": "Addressing the lack of interpretability and uncertainty quantification in deep learning models, especially in scenarios with multiple patterns and varying uncertainty.", "method": "Extends Mixtures of Experts (MoEs) by fusing experts' distributions, not just mixing them, to avoid multimodality artifacts and improve modeling flexibility.", "result": "CoCoAFusE provides tighter credible bounds on responses, avoids multimodality artifacts, and demonstrates efficacy in complex regression problems.", "conclusion": "CoCoAFusE offers a more expressive and interpretable approach for modeling uncertainty in complex regression tasks."}}
{"id": "2505.01257", "pdf": "https://arxiv.org/pdf/2505.01257", "abs": "https://arxiv.org/abs/2505.01257", "authors": ["Vladimir Somers", "Baptiste Standaert", "Victor Joos", "Alexandre Alahi", "Christophe De Vleeschouwer"], "title": "CAMELTrack: Context-Aware Multi-cue ExpLoitation for Online Multi-Object Tracking", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Online multi-object tracking has been recently dominated by\ntracking-by-detection (TbD) methods, where recent advances rely on increasingly\nsophisticated heuristics for tracklet representation, feature fusion, and\nmulti-stage matching. The key strength of TbD lies in its modular design,\nenabling the integration of specialized off-the-shelf models like motion\npredictors and re-identification. However, the extensive usage of human-crafted\nrules for temporal associations makes these methods inherently limited in their\nability to capture the complex interplay between various tracking cues. In this\nwork, we introduce CAMEL, a novel association module for Context-Aware\nMulti-Cue ExpLoitation, that learns resilient association strategies directly\nfrom data, breaking free from hand-crafted heuristics while maintaining TbD's\nvaluable modularity. At its core, CAMEL employs two transformer-based modules\nand relies on a novel association-centric training scheme to effectively model\nthe complex interactions between tracked targets and their various association\ncues. Unlike end-to-end detection-by-tracking approaches, our method remains\nlightweight and fast to train while being able to leverage external\noff-the-shelf models. Our proposed online tracking pipeline, CAMELTrack,\nachieves state-of-the-art performance on multiple tracking benchmarks. Our code\nis available at https://github.com/TrackingLaboratory/CAMELTrack.", "AI": {"tldr": "CAMEL introduces a data-driven association module for multi-object tracking, replacing hand-crafted heuristics with transformer-based modules and achieving state-of-the-art performance.", "motivation": "Current tracking-by-detection methods rely on human-crafted rules for temporal associations, limiting their ability to model complex interactions between tracking cues.", "method": "CAMEL uses two transformer-based modules and a novel training scheme to learn association strategies directly from data, maintaining modularity.", "result": "CAMELTrack, the proposed pipeline, achieves state-of-the-art performance on multiple tracking benchmarks.", "conclusion": "CAMEL breaks free from hand-crafted heuristics while retaining modularity, offering a lightweight and effective solution for online multi-object tracking."}}
{"id": "2504.13068", "pdf": "https://arxiv.org/pdf/2504.13068", "abs": "https://arxiv.org/abs/2504.13068", "authors": ["Sudesh Ramesh Bhagat", "Ibne Farabi Shihab", "Anuj Sharma"], "title": "Accuracy is Not Agreement: Expert-Aligned Evaluation of Crash Narrative Classification Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This study investigates the relationship between deep learning (DL) model\naccuracy and expert agreement in classifying crash narratives. We evaluate five\nDL models -- including BERT variants, USE, and a zero-shot classifier --\nagainst expert labels and narratives, and extend the analysis to four large\nlanguage models (LLMs): GPT-4, LLaMA 3, Qwen, and Claude. Our findings reveal\nan inverse relationship: models with higher technical accuracy often show lower\nagreement with human experts, while LLMs demonstrate stronger expert alignment\ndespite lower accuracy. We use Cohen's Kappa and Principal Component Analysis\n(PCA) to quantify and visualize model-expert agreement, and employ SHAP\nanalysis to explain misclassifications. Results show that expert-aligned models\nrely more on contextual and temporal cues than location-specific keywords.\nThese findings suggest that accuracy alone is insufficient for safety-critical\nNLP tasks. We argue for incorporating expert agreement into model evaluation\nframeworks and highlight the potential of LLMs as interpretable tools in crash\nanalysis pipelines.", "AI": {"tldr": "The study explores the link between DL model accuracy and expert agreement in crash narrative classification, finding higher accuracy models often disagree with experts, while LLMs align better despite lower accuracy.", "motivation": "To understand the disconnect between technical accuracy and expert agreement in safety-critical NLP tasks like crash analysis.", "method": "Evaluated five DL models and four LLMs against expert labels, using Cohen's Kappa, PCA, and SHAP analysis to measure and explain agreement.", "result": "Higher accuracy models showed lower expert agreement, while LLMs aligned better with experts, relying on contextual cues over keywords.", "conclusion": "Accuracy alone is inadequate for safety-critical tasks; expert agreement should be part of model evaluation, with LLMs offering interpretable solutions."}}
{"id": "2505.01168", "pdf": "https://arxiv.org/pdf/2505.01168", "abs": "https://arxiv.org/abs/2505.01168", "authors": ["Zhaoyang Ma", "Zhihao Wu", "Wang Lu", "Xin Gao", "Jinghang Yue", "Taolin Zhang", "Lipo Wang", "Youfang Lin", "Jing Wang"], "title": "Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial Transferability", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The development of model ensemble attacks has significantly improved the\ntransferability of adversarial examples, but this progress also poses severe\nthreats to the security of deep neural networks. Existing methods, however,\nface two critical challenges: insufficient capture of shared gradient\ndirections across models and a lack of adaptive weight allocation mechanisms.\nTo address these issues, we propose a novel method Harmonized Ensemble for\nAdversarial Transferability (HEAT), which introduces domain generalization into\nadversarial example generation for the first time. HEAT consists of two key\nmodules: Consensus Gradient Direction Synthesizer, which uses Singular Value\nDecomposition to synthesize shared gradient directions; and Dual-Harmony Weight\nOrchestrator which dynamically balances intra-domain coherence, stabilizing\ngradients within individual models, and inter-domain diversity, enhancing\ntransferability across models. Experimental results demonstrate that HEAT\nsignificantly outperforms existing methods across various datasets and\nsettings, offering a new perspective and direction for adversarial attack\nresearch.", "AI": {"tldr": "HEAT improves adversarial example transferability by synthesizing shared gradient directions and dynamically balancing intra-domain coherence and inter-domain diversity.", "motivation": "Existing methods fail to capture shared gradient directions and lack adaptive weight allocation, limiting adversarial transferability.", "method": "HEAT uses Singular Value Decomposition for shared gradient synthesis and a Dual-Harmony Weight Orchestrator for dynamic weight balancing.", "result": "HEAT outperforms existing methods across datasets, enhancing adversarial attack effectiveness.", "conclusion": "HEAT provides a novel approach for adversarial attacks, improving transferability and offering new research directions."}}
{"id": "2505.01111", "pdf": "https://arxiv.org/pdf/2505.01111", "abs": "https://arxiv.org/abs/2505.01111", "authors": ["Yukun Li", "Li-Ping Liu"], "title": "Incorporating Inductive Biases to Energy-based Generative Models", "categories": ["cs.LG"], "comment": null, "summary": "With the advent of score-matching techniques for model training and Langevin\ndynamics for sample generation, energy-based models (EBMs) have gained renewed\ninterest as generative models. Recent EBMs usually use neural networks to\ndefine their energy functions. In this work, we introduce a novel hybrid\napproach that combines an EBM with an exponential family model to incorporate\ninductive bias into data modeling. Specifically, we augment the energy term\nwith a parameter-free statistic function to help the model capture key data\nstatistics. Like an exponential family model, the hybrid model aims to align\nthe distribution statistics with data statistics during model training, even\nwhen it only approximately maximizes the data likelihood. This property enables\nus to impose constraints on the hybrid model. Our empirical study validates the\nhybrid model's ability to match statistics. Furthermore, experimental results\nshow that data fitting and generation improve when suitable informative\nstatistics are incorporated into the hybrid model.", "AI": {"tldr": "A hybrid model combining energy-based models (EBMs) with exponential family models improves data fitting and generation by incorporating inductive bias and aligning distribution statistics with data statistics.", "motivation": "To enhance EBMs by integrating inductive bias and improving alignment of model statistics with data statistics, leveraging the strengths of both EBMs and exponential family models.", "method": "Introduces a hybrid approach augmenting EBMs with parameter-free statistic functions, aligning distribution statistics with data statistics during training.", "result": "Empirical validation shows improved data fitting and generation when informative statistics are incorporated.", "conclusion": "The hybrid model effectively combines EBMs and exponential family models, enhancing performance in data modeling and generation."}}
{"id": "2505.01267", "pdf": "https://arxiv.org/pdf/2505.01267", "abs": "https://arxiv.org/abs/2505.01267", "authors": ["Gaozheng Pei", "Ke Ma", "Yingfei Sun", "Qianqian Xu", "Qingming Huang"], "title": "Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain", "categories": ["cs.CV"], "comment": null, "summary": "The diffusion-based adversarial purification methods attempt to drown\nadversarial perturbations into a part of isotropic noise through the forward\nprocess, and then recover the clean images through the reverse process. Due to\nthe lack of distribution information about adversarial perturbations in the\npixel domain, it is often unavoidable to damage normal semantics. We turn to\nthe frequency domain perspective, decomposing the image into amplitude spectrum\nand phase spectrum. We find that for both spectra, the damage caused by\nadversarial perturbations tends to increase monotonically with frequency. This\nmeans that we can extract the content and structural information of the\noriginal clean sample from the frequency components that are less damaged.\nMeanwhile, theoretical analysis indicates that existing purification methods\nindiscriminately damage all frequency components, leading to excessive damage\nto the image. Therefore, we propose a purification method that can eliminate\nadversarial perturbations while maximizing the preservation of the content and\nstructure of the original image. Specifically, at each time step during the\nreverse process, for the amplitude spectrum, we replace the low-frequency\ncomponents of the estimated image's amplitude spectrum with the corresponding\nparts of the adversarial image. For the phase spectrum, we project the phase of\nthe estimated image into a designated range of the adversarial image's phase\nspectrum, focusing on the low frequencies. Empirical evidence from extensive\nexperiments demonstrates that our method significantly outperforms most current\ndefense methods.", "AI": {"tldr": "The paper proposes a frequency-domain adversarial purification method that preserves image content and structure by focusing on less damaged low-frequency components, outperforming existing methods.", "motivation": "Existing diffusion-based adversarial purification methods damage normal semantics due to lack of perturbation distribution information in the pixel domain.", "method": "Decomposes images into amplitude and phase spectra, replaces low-frequency amplitude components, and projects phase into a designated range during the reverse process.", "result": "The method significantly outperforms current defense methods by preserving content and structure while eliminating perturbations.", "conclusion": "Frequency-domain purification effectively mitigates adversarial perturbations while minimizing damage to image semantics."}}
{"id": "2505.00016", "pdf": "https://arxiv.org/pdf/2505.00016", "abs": "https://arxiv.org/abs/2505.00016", "authors": ["Josefa Lia Stoisser", "Marc Boubnovski Martell", "Julien Fauqueur"], "title": "Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This work reframes the Text-to-SQL task as a pathway for teaching large\nlanguage models (LLMs) to reason over and manipulate tabular data--moving\nbeyond the traditional focus on query generation. We propose a two-stage\nframework that leverages SQL supervision to develop transferable table\nreasoning capabilities. First, we synthesize detailed chain-of-thought (CoT)\ntraces from real-world SQL queries, providing step-by-step, clause-level\nsupervision that teaches the model how to traverse, filter, and aggregate table\nfields. Second, we introduce a Group Relative Policy Optimization (GRPO)\nreinforcement learning objective that connects SQL execution accuracy to\ngeneralizable reasoning by encouraging steps that extend beyond task-specific\nsyntax and transfer across datasets. Empirically, our approach improves\nperformance on standard Text-to-SQL benchmarks and achieves substantial gains\non reasoning-intensive datasets such as BIRD and CRT-QA, demonstrating enhanced\ngeneralization and interpretability. Specifically, the distilled-quantized\nLLaMA model achieved a relative 33.9\\% increase in accuracy when trained on\nText-to-SQL tasks, while Qwen achieved a relative 14.5\\% increase. These\nresults suggest that SQL can serve not only as a target formalism but also as\nan effective scaffold for learning robust, transferable reasoning over\nstructured data.", "AI": {"tldr": "The paper reframes Text-to-SQL as a way to teach LLMs table reasoning, using a two-stage framework with CoT traces and GRPO reinforcement learning, showing improved performance and generalization.", "motivation": "To move beyond query generation in Text-to-SQL by teaching LLMs transferable table reasoning skills.", "method": "A two-stage framework: (1) synthesizing CoT traces from SQL queries for clause-level supervision, (2) GRPO reinforcement learning to generalize reasoning beyond task-specific syntax.", "result": "Improved accuracy on Text-to-SQL benchmarks (33.9% for LLaMA, 14.5% for Qwen) and gains on reasoning-intensive datasets like BIRD and CRT-QA.", "conclusion": "SQL can scaffold robust, transferable reasoning over structured data, not just serve as a target formalism."}}
{"id": "2505.01169", "pdf": "https://arxiv.org/pdf/2505.01169", "abs": "https://arxiv.org/abs/2505.01169", "authors": ["Pramook Khungurn", "Pratch Piyawongwisal", "Sira Sriswadi", "Supasorn Suwajanakorn"], "title": "Distilling Two-Timed Flow Models by Separately Matching Initial and Terminal Velocities", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "A flow matching model learns a time-dependent vector field $v_t(x)$ that\ngenerates a probability path $\\{ p_t \\}_{0 \\leq t \\leq 1}$ that interpolates\nbetween a well-known noise distribution ($p_0$) and the data distribution\n($p_1$). It can be distilled into a \\emph{two-timed flow model} (TTFM)\n$\\phi_{s,x}(t)$ that can transform a sample belonging to the distribution at an\ninitial time $s$ to another belonging to the distribution at a terminal time\n$t$ in one function evaluation. We present a new loss function for TTFM\ndistillation called the \\emph{initial/terminal velocity matching} (ITVM) loss\nthat extends the Lagrangian Flow Map Distillation (LFMD) loss proposed by Boffi\net al. by adding redundant terms to match the initial velocities at time $s$,\nremoving the derivative from the terminal velocity term at time $t$, and using\na version of the model under training, stabilized by exponential moving\naveraging (EMA), to compute the target terminal average velocity. Preliminary\nexperiments show that our loss leads to better few-step generation performance\non multiple types of datasets and model architectures over baselines.", "AI": {"tldr": "The paper introduces a new loss function (ITVM) for distilling a two-timed flow model (TTFM), improving few-step generation performance over baselines.", "motivation": "To enhance the distillation of TTFM by refining the loss function for better performance in generating samples with fewer steps.", "method": "Proposes the ITVM loss, which extends LFMD by matching initial velocities, modifying terminal velocity terms, and using EMA-stabilized models for target velocities.", "result": "Preliminary experiments show improved few-step generation across datasets and architectures.", "conclusion": "The ITVM loss effectively enhances TTFM distillation, outperforming existing methods."}}
{"id": "2505.01115", "pdf": "https://arxiv.org/pdf/2505.01115", "abs": "https://arxiv.org/abs/2505.01115", "authors": ["Palok Biswas", "Zuzanna Osika", "Isidoro Tamassia", "Adit Whorra", "Jazmin Zatarain-Salazar", "Jan Kwakkel", "Frans A. Oliehoek", "Pradeep K. Murukannaiah"], "title": "Exploring Equity of Climate Policies using Multi-Agent Multi-Objective Reinforcement Learning", "categories": ["cs.LG"], "comment": "Accepted to IJCAI 2025, AI and Social Good Track", "summary": "Addressing climate change requires coordinated policy efforts of nations\nworldwide. These efforts are informed by scientific reports, which rely in part\non Integrated Assessment Models (IAMs), prominent tools used to assess the\neconomic impacts of climate policies. However, traditional IAMs optimize\npolicies based on a single objective, limiting their ability to capture the\ntrade-offs among economic growth, temperature goals, and climate justice. As a\nresult, policy recommendations have been criticized for perpetuating\ninequalities, fueling disagreements during policy negotiations. We introduce\nJustice, the first framework integrating IAM with Multi-Objective Multi-Agent\nReinforcement Learning (MOMARL). By incorporating multiple objectives, Justice\ngenerates policy recommendations that shed light on equity while balancing\nclimate and economic goals. Further, using multiple agents can provide a\nrealistic representation of the interactions among the diverse policy actors.\nWe identify equitable Pareto-optimal policies using our framework, which\nfacilitates deliberative decision-making by presenting policymakers with the\ninherent trade-offs in climate and economic policy.", "AI": {"tldr": "The paper introduces Justice, a framework combining Integrated Assessment Models (IAMs) with Multi-Objective Multi-Agent Reinforcement Learning (MOMARL) to address climate policy trade-offs and equity.", "motivation": "Traditional IAMs optimize policies based on a single objective, often neglecting equity and perpetuating inequalities in climate policy recommendations.", "method": "Justice integrates IAM with MOMARL to incorporate multiple objectives (economic growth, temperature goals, climate justice) and uses multi-agent systems to represent diverse policy actors.", "result": "The framework identifies equitable Pareto-optimal policies, highlighting trade-offs and enabling deliberative decision-making for policymakers.", "conclusion": "Justice offers a more balanced and equitable approach to climate policy by addressing multiple objectives and realistic policy actor interactions."}}
{"id": "2505.01322", "pdf": "https://arxiv.org/pdf/2505.01322", "abs": "https://arxiv.org/abs/2505.01322", "authors": ["Chenxi Li", "Weijie Wang", "Qiang Li", "Bruno Lepri", "Nicu Sebe", "Weizhi Nie"], "title": "FreeInsert: Disentangled Text-Guided Object Insertion in 3D Gaussian Scene without Spatial Priors", "categories": ["cs.CV"], "comment": null, "summary": "Text-driven object insertion in 3D scenes is an emerging task that enables\nintuitive scene editing through natural language. However, existing 2D\nediting-based methods often rely on spatial priors such as 2D masks or 3D\nbounding boxes, and they struggle to ensure consistency of the inserted object.\nThese limitations hinder flexibility and scalability in real-world\napplications. In this paper, we propose FreeInsert, a novel framework that\nleverages foundation models including MLLMs, LGMs, and diffusion models to\ndisentangle object generation from spatial placement. This enables unsupervised\nand flexible object insertion in 3D scenes without spatial priors. FreeInsert\nstarts with an MLLM-based parser that extracts structured semantics, including\nobject types, spatial relationships, and attachment regions, from user\ninstructions. These semantics guide both the reconstruction of the inserted\nobject for 3D consistency and the learning of its degrees of freedom. We\nleverage the spatial reasoning capabilities of MLLMs to initialize object pose\nand scale. A hierarchical, spatially aware refinement stage further integrates\nspatial semantics and MLLM-inferred priors to enhance placement. Finally, the\nappearance of the object is improved using the inserted-object image to enhance\nvisual fidelity. Experimental results demonstrate that FreeInsert achieves\nsemantically coherent, spatially precise, and visually realistic 3D insertions\nwithout relying on spatial priors, offering a user-friendly and flexible\nediting experience.", "AI": {"tldr": "FreeInsert is a framework for text-driven 3D object insertion without spatial priors, using foundation models for semantic parsing and refinement.", "motivation": "Existing methods rely on spatial priors and struggle with consistency, limiting flexibility and scalability.", "method": "FreeInsert uses MLLMs, LGMs, and diffusion models to parse semantics, initialize pose/scale, and refine placement for 3D consistency.", "result": "Achieves coherent, precise, and realistic 3D insertions without spatial priors.", "conclusion": "FreeInsert offers flexible, user-friendly 3D scene editing."}}
{"id": "2505.00551", "pdf": "https://arxiv.org/pdf/2505.00551", "abs": "https://arxiv.org/abs/2505.00551", "authors": ["Chong Zhang", "Yue Deng", "Xiang Lin", "Bin Wang", "Dianwen Ng", "Hai Ye", "Xingxuan Li", "Yao Xiao", "Zhanfeng Mo", "Qi Zhang", "Lidong Bing"], "title": "100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The recent development of reasoning language models (RLMs) represents a novel\nevolution in large language models. In particular, the recent release of\nDeepSeek-R1 has generated widespread social impact and sparked enthusiasm in\nthe research community for exploring the explicit reasoning paradigm of\nlanguage models. However, the implementation details of the released models\nhave not been fully open-sourced by DeepSeek, including DeepSeek-R1-Zero,\nDeepSeek-R1, and the distilled small models. As a result, many replication\nstudies have emerged aiming to reproduce the strong performance achieved by\nDeepSeek-R1, reaching comparable performance through similar training\nprocedures and fully open-source data resources. These works have investigated\nfeasible strategies for supervised fine-tuning (SFT) and reinforcement learning\nfrom verifiable rewards (RLVR), focusing on data preparation and method design,\nyielding various valuable insights. In this report, we provide a summary of\nrecent replication studies to inspire future research. We primarily focus on\nSFT and RLVR as two main directions, introducing the details for data\nconstruction, method design and training procedure of current replication\nstudies. Moreover, we conclude key findings from the implementation details and\nexperimental results reported by these studies, anticipating to inspire future\nresearch. We also discuss additional techniques of enhancing RLMs, highlighting\nthe potential of expanding the application scope of these models, and\ndiscussing the challenges in development. By this survey, we aim to help\nresearchers and developers of RLMs stay updated with the latest advancements,\nand seek to inspire new ideas to further enhance RLMs.", "AI": {"tldr": "The paper summarizes replication studies of DeepSeek-R1, focusing on SFT and RLVR methods, data construction, and training procedures, aiming to inspire future research in reasoning language models.", "motivation": "To address the lack of open-source details for DeepSeek-R1 models and explore feasible replication strategies to achieve comparable performance.", "method": "Summarizes recent replication studies, focusing on supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR), including data preparation and method design.", "result": "Provides key findings from replication studies, highlighting insights and challenges in enhancing reasoning language models.", "conclusion": "The survey aims to keep researchers updated and inspire new ideas to further improve reasoning language models, despite existing challenges."}}
{"id": "2505.01177", "pdf": "https://arxiv.org/pdf/2505.01177", "abs": "https://arxiv.org/abs/2505.01177", "authors": ["Francisco Aguilera-Mart\u00ednez", "Fernando Berzal"], "title": "LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "As large language models (LLMs) continue to evolve, it is critical to assess\nthe security threats and vulnerabilities that may arise both during their\ntraining phase and after models have been deployed. This survey seeks to define\nand categorize the various attacks targeting LLMs, distinguishing between those\nthat occur during the training phase and those that affect already trained\nmodels. A thorough analysis of these attacks is presented, alongside an\nexploration of defense mechanisms designed to mitigate such threats. Defenses\nare classified into two primary categories: prevention-based and\ndetection-based defenses. Furthermore, our survey summarizes possible attacks\nand their corresponding defense strategies. It also provides an evaluation of\nthe effectiveness of the known defense mechanisms for the different security\nthreats. Our survey aims to offer a structured framework for securing LLMs,\nwhile also identifying areas that require further research to improve and\nstrengthen defenses against emerging security challenges.", "AI": {"tldr": "A survey categorizing attacks on LLMs during training and deployment, analyzing defenses, and evaluating their effectiveness.", "motivation": "To assess security threats in evolving LLMs and provide a framework for securing them.", "method": "Categorizes attacks, explores defense mechanisms (prevention and detection-based), and evaluates their effectiveness.", "result": "Summarizes attacks and defenses, offering a structured framework for LLM security.", "conclusion": "Identifies gaps for future research to strengthen defenses against emerging threats."}}
{"id": "2505.01134", "pdf": "https://arxiv.org/pdf/2505.01134", "abs": "https://arxiv.org/abs/2505.01134", "authors": ["Rogelio A Mancisidor", "Robert Jenssen", "Shujian Yu", "Michael Kampffmeyer"], "title": "Aggregation of Dependent Expert Distributions in Multimodal Variational Autoencoders", "categories": ["cs.LG"], "comment": null, "summary": "Multimodal learning with variational autoencoders (VAEs) requires estimating\njoint distributions to evaluate the evidence lower bound (ELBO). Current\nmethods, the product and mixture of experts, aggregate single-modality\ndistributions assuming independence for simplicity, which is an overoptimistic\nassumption. This research introduces a novel methodology for aggregating\nsingle-modality distributions by exploiting the principle of consensus of\ndependent experts (CoDE), which circumvents the aforementioned assumption.\nUtilizing the CoDE method, we propose a novel ELBO that approximates the joint\nlikelihood of the multimodal data by learning the contribution of each subset\nof modalities. The resulting CoDE-VAE model demonstrates better performance in\nterms of balancing the trade-off between generative coherence and generative\nquality, as well as generating more precise log-likelihood estimations.\nCoDE-VAE further minimizes the generative quality gap as the number of\nmodalities increases. In certain cases, it reaches a generative quality similar\nto that of unimodal VAEs, which is a desirable property that is lacking in most\ncurrent methods. Finally, the classification accuracy achieved by CoDE-VAE is\ncomparable to that of state-of-the-art multimodal VAE models.", "AI": {"tldr": "A novel method, CoDE-VAE, improves multimodal learning by avoiding the independence assumption of modalities, enhancing generative coherence, quality, and log-likelihood estimation.", "motivation": "Current methods assume independence among modalities, which is unrealistic. CoDE-VAE addresses this by leveraging dependent expert consensus.", "method": "Uses the CoDE principle to aggregate single-modality distributions, learning contributions of modality subsets for a better ELBO approximation.", "result": "CoDE-VAE outperforms in generative coherence, quality, and log-likelihood, minimizing quality gaps with increasing modalities.", "conclusion": "CoDE-VAE achieves competitive classification accuracy and generative quality, bridging gaps in current multimodal VAE methods."}}
{"id": "2505.01364", "pdf": "https://arxiv.org/pdf/2505.01364", "abs": "https://arxiv.org/abs/2505.01364", "authors": ["Enamundram Naga Karthik", "Sandrine B\u00e9dard", "Jan Valo\u0161ek", "Christoph S. Aigner", "Elise Bannier", "Josef Bedna\u0159\u00edk", "Virginie Callot", "Anna Combes", "Armin Curt", "Gergely David", "Falk Eippert", "Lynn Farner", "Michael G Fehlings", "Patrick Freund", "Tobias Granberg", "Cristina Granziera", "RHSCIR Network Imaging Group", "Ulrike Horn", "Tom\u00e1\u0161 Hor\u00e1k", "Suzanne Humphreys", "Markus Hupp", "Anne Kerbrat", "Nawal Kinany", "Shannon Kolind", "Petr Kudli\u010dka", "Anna Lebret", "Lisa Eunyoung Lee", "Caterina Mainero", "Allan R. Martin", "Megan McGrath", "Govind Nair", "Kristin P. O'Grady", "Jiwon Oh", "Russell Ouellette", "Nikolai Pfender", "Dario Pfyffer", "Pierre-Fran\u00e7ois Pradat", "Alexandre Prat", "Emanuele Pravat\u00e0", "Daniel S. Reich", "Ilaria Ricchi", "Naama Rotem-Kohavi", "Simon Schading-Sassenhausen", "Maryam Seif", "Andrew Smith", "Seth A Smith", "Grace Sweeney", "Roger Tam", "Anthony Traboulsee", "Constantina Andrada Treaba", "Charidimos Tsagkas", "Zachary Vavasour", "Dimitri Van De Ville", "Kenneth Arnold Weber II", "Sarath Chandar", "Julien Cohen-Adad"], "title": "Monitoring morphometric drift in lifelong learning segmentation of the spinal cord", "categories": ["cs.CV"], "comment": null, "summary": "Morphometric measures derived from spinal cord segmentations can serve as\ndiagnostic and prognostic biomarkers in neurological diseases and injuries\naffecting the spinal cord. While robust, automatic segmentation methods to a\nwide variety of contrasts and pathologies have been developed over the past few\nyears, whether their predictions are stable as the model is updated using new\ndatasets has not been assessed. This is particularly important for deriving\nnormative values from healthy participants. In this study, we present a spinal\ncord segmentation model trained on a multisite $(n=75)$ dataset, including 9\ndifferent MRI contrasts and several spinal cord pathologies. We also introduce\na lifelong learning framework to automatically monitor the morphometric drift\nas the model is updated using additional datasets. The framework is triggered\nby an automatic GitHub Actions workflow every time a new model is created,\nrecording the morphometric values derived from the model's predictions over\ntime. As a real-world application of the proposed framework, we employed the\nspinal cord segmentation model to update a recently-introduced normative\ndatabase of healthy participants containing commonly used measures of spinal\ncord morphometry. Results showed that: (i) our model outperforms previous\nversions and pathology-specific models on challenging lumbar spinal cord cases,\nachieving an average Dice score of $0.95 \\pm 0.03$; (ii) the automatic workflow\nfor monitoring morphometric drift provides a quick feedback loop for developing\nfuture segmentation models; and (iii) the scaling factor required to update the\ndatabase of morphometric measures is nearly constant among slices across the\ngiven vertebral levels, showing minimum drift between the current and previous\nversions of the model monitored by the framework. The model is freely available\nin Spinal Cord Toolbox v7.0.", "AI": {"tldr": "A spinal cord segmentation model with lifelong learning framework ensures stable morphometric measures for diagnostic and prognostic use, outperforming previous models and minimizing drift in updates.", "motivation": "Assess the stability of spinal cord segmentation models as they are updated, crucial for deriving normative values from healthy participants.", "method": "Developed a multisite-trained spinal cord segmentation model and introduced a lifelong learning framework to monitor morphometric drift via automatic GitHub Actions workflows.", "result": "Model outperforms prior versions with a Dice score of 0.95 \u00b1 0.03; minimal drift observed in updates, ensuring stable normative database scaling.", "conclusion": "The framework provides reliable, stable morphometric measures for clinical applications, with the model available in Spinal Cord Toolbox v7.0."}}
{"id": "2311.09830", "pdf": "https://arxiv.org/pdf/2311.09830", "abs": "https://arxiv.org/abs/2311.09830", "authors": ["Katharina Stein", "Daniel Fi\u0161er", "J\u00f6rg Hoffmann", "Alexander Koller"], "title": "Automating the Generation of Prompts for LLM-based Action Choice in PDDL Planning", "categories": ["cs.AI", "cs.CL"], "comment": "Extended version of the paper from the ICAPS'25 proceedings (same\n  main part + additional appendix)", "summary": "Large language models (LLMs) have revolutionized a large variety of NLP\ntasks. An active debate is to what extent they can do reasoning and planning.\nPrior work has assessed the latter in the specific context of PDDL planning,\nbased on manually converting three PDDL domains into natural language (NL)\nprompts. Here we automate this conversion step, showing how to leverage an LLM\nto automatically generate NL prompts from PDDL input. Our automatically\ngenerated NL prompts result in similar LLM-planning performance as the previous\nmanually generated ones. Beyond this, the automation enables us to run much\nlarger experiments, providing for the first time a broad evaluation of LLM\nplanning performance in PDDL. Our NL prompts yield better performance than PDDL\nprompts and simple template-based NL prompts. Compared to symbolic planners,\nLLM planning lags far behind; but in some domains, our best LLM configuration\nscales up further than A$^\\star$ using LM-cut.", "AI": {"tldr": "The paper automates the conversion of PDDL planning domains into natural language prompts for LLMs, showing comparable performance to manual prompts and enabling large-scale evaluation of LLM planning in PDDL.", "motivation": "To assess and automate the capability of LLMs in reasoning and planning, particularly in the context of PDDL planning, by generating NL prompts automatically.", "method": "Automated conversion of PDDL domains into NL prompts using an LLM, followed by large-scale experiments to evaluate LLM planning performance.", "result": "Automated NL prompts perform similarly to manual ones, outperform PDDL and template-based prompts, but lag behind symbolic planners like A* with LM-cut.", "conclusion": "Automation enables broader evaluation of LLM planning, revealing its limitations compared to symbolic planners but showing potential in scalability for certain domains."}}
{"id": "2505.01185", "pdf": "https://arxiv.org/pdf/2505.01185", "abs": "https://arxiv.org/abs/2505.01185", "authors": ["Nahshon Mokua Obiri", "Kristof Van Laerhoven"], "title": "EnviKal-Loc: Sub-10m Indoor LoRaWAN Localization using an Environmental-Aware Path Loss and Adaptive RSSI Smoothing", "categories": ["cs.NI", "cs.AI", "cs.LG", "eess.SP"], "comment": null, "summary": "LoRaWAN technology's extensive coverage positions it as a strong contender\nfor large-scale IoT deployments. However, achieving sub-10 m accuracy in indoor\nlocalization remains challenging due to complex environmental conditions,\nmultipath fading, and transient obstructions. This paper proposes a lightweight\nbut robust approach combining adaptive filtering with an extended log-distance,\nmulti-wall path loss and shadowing (PLS) model. Our methodology augments\nconventional models with critical LoRaWAN parameters (received signal strength\nindicator (RSSI), frequency, and signal-to-noise ratio (SNR)) and dynamic\nenvironmental indicators (temperature, humidity, carbon dioxide, particulate\nmatter, and barometric pressure). An adaptive Kalman filter reduces RSSI\nfluctuations, isolating persistent trends from momentary noise. Using a\nsix-month dataset of 1,328,334 field measurements, we evaluate three models:\nthe baseline COST 231 multi-wall model (MWM), the baseline model augmented with\nenvironmental parameters (MWM-EP), and a forward-only adaptive Kalman-filtered\nRSSI version of the latter (MWM-EP-KF). Results confirm that the MWM-EP-KF\nachieves a mean absolute error (MAE) of 5.81 m, outperforming both the MWM-EP\n(10.56 m) and the baseline MWM framework (17.98 m). Environmental augmentation\nreduces systematic errors by 41.22%, while Kalman filtering significantly\nenhances robustness under high RSSI volatility by 42.63%, on average across all\ndevices. These findings present an interpretable, efficient solution for\nprecise indoor LoRaWAN localization in dynamically changing environments.", "AI": {"tldr": "The paper proposes a lightweight, robust method for indoor LoRaWAN localization using adaptive filtering and environmental data, achieving sub-10 m accuracy.", "motivation": "Challenges in achieving precise indoor localization with LoRaWAN due to environmental complexities and signal fluctuations.", "method": "Combines adaptive Kalman filtering with an extended log-distance PLS model, incorporating LoRaWAN parameters and dynamic environmental indicators.", "result": "The MWM-EP-KF model achieves a mean absolute error of 5.81 m, outperforming baseline models by significant margins.", "conclusion": "The proposed method offers an efficient, interpretable solution for precise indoor localization in dynamic environments."}}
{"id": "2505.01135", "pdf": "https://arxiv.org/pdf/2505.01135", "abs": "https://arxiv.org/abs/2505.01135", "authors": ["Wenfa Wu", "Guanyu Zhang", "Zheng Tan", "Yi Wang", "Hongsheng Qi"], "title": "Dual-Forecaster: A Multimodal Time Series Model Integrating Descriptive and Predictive Texts", "categories": ["cs.LG"], "comment": null, "summary": "Most existing single-modal time series models rely solely on numerical\nseries, which suffer from the limitations imposed by insufficient information.\nRecent studies have revealed that multimodal models can address the core issue\nby integrating textual information. However, these models focus on either\nhistorical or future textual information, overlooking the unique contributions\neach plays in time series forecasting. Besides, these models fail to grasp the\nintricate relationships between textual and time series data, constrained by\ntheir moderate capacity for multimodal comprehension. To tackle these\nchallenges, we propose Dual-Forecaster, a pioneering multimodal time series\nmodel that combines both descriptively historical textual information and\npredictive textual insights, leveraging advanced multimodal comprehension\ncapability empowered by three well-designed cross-modality alignment\ntechniques. Our comprehensive evaluations on fifteen multimodal time series\ndatasets demonstrate that Dual-Forecaster is a distinctly effective multimodal\ntime series model that outperforms or is comparable to other state-of-the-art\nmodels, highlighting the superiority of integrating textual information for\ntime series forecasting. This work opens new avenues in the integration of\ntextual information with numerical time series data for multimodal time series\nanalysis.", "AI": {"tldr": "Dual-Forecaster is a multimodal time series model integrating historical and predictive textual information with numerical data, outperforming existing models.", "motivation": "Existing models lack comprehensive integration of textual and numerical data, limiting forecasting accuracy.", "method": "Uses three cross-modality alignment techniques to combine historical and predictive textual insights with numerical series.", "result": "Outperforms or matches state-of-the-art models on fifteen datasets.", "conclusion": "Demonstrates the superiority of integrating textual information for time series forecasting, opening new research avenues."}}
{"id": "2505.01385", "pdf": "https://arxiv.org/pdf/2505.01385", "abs": "https://arxiv.org/abs/2505.01385", "authors": ["Fahong Zhang", "Yilei Shi", "Xiao Xiang Zhu"], "title": "Global Collinearity-aware Polygonizer for Polygonal Building Mapping in Remote Sensing", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "This paper addresses the challenge of mapping polygonal buildings from remote\nsensing images and introduces a novel algorithm, the Global Collinearity-aware\nPolygonizer (GCP). GCP, built upon an instance segmentation framework,\nprocesses binary masks produced by any instance segmentation model. The\nalgorithm begins by collecting polylines sampled along the contours of the\nbinary masks. These polylines undergo a refinement process using a\ntransformer-based regression module to ensure they accurately fit the contours\nof the targeted building instances. Subsequently, a collinearity-aware polygon\nsimplification module simplifies these refined polylines and generate the final\npolygon representation. This module employs dynamic programming technique to\noptimize an objective function that balances the simplicity and fidelity of the\npolygons, achieving globally optimal solutions. Furthermore, the optimized\ncollinearity-aware objective is seamlessly integrated into network training,\nenhancing the cohesiveness of the entire pipeline. The effectiveness of GCP has\nbeen validated on two public benchmarks for polygonal building mapping. Further\nexperiments reveal that applying the collinearity-aware polygon simplification\nmodule to arbitrary polylines, without prior knowledge, enhances accuracy over\ntraditional methods such as the Douglas-Peucker algorithm. This finding\nunderscores the broad applicability of GCP. The code for the proposed method\nwill be made available at https://github.com/zhu-xlab.", "AI": {"tldr": "The paper introduces GCP, a novel algorithm for mapping polygonal buildings from remote sensing images, combining instance segmentation, transformer-based refinement, and collinearity-aware polygon simplification for improved accuracy.", "motivation": "The challenge of accurately mapping polygonal buildings from remote sensing images, where traditional methods like Douglas-Peucker fall short in balancing simplicity and fidelity.", "method": "GCP processes binary masks from instance segmentation, refines polylines with a transformer-based module, and simplifies them using a collinearity-aware dynamic programming approach.", "result": "Validated on public benchmarks, GCP outperforms traditional methods, showing broader applicability and improved accuracy.", "conclusion": "GCP offers a robust and globally optimal solution for polygonal building mapping, with potential for broader use in polyline simplification."}}
{"id": "2402.18789", "pdf": "https://arxiv.org/pdf/2402.18789", "abs": "https://arxiv.org/abs/2402.18789", "authors": ["Gabriele Oliaro", "Xupeng Miao", "Xinhao Cheng", "Vineeth Kada", "Ruohan Gao", "Yingyi Huang", "Remi Delacourt", "April Yang", "Yingcheng Wang", "Mengdi Wu", "Colin Unger", "Zhihao Jia"], "title": "FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning", "categories": ["cs.DC", "cs.CL", "cs.LG"], "comment": null, "summary": "Finetuning large language models (LLMs) is essential for task adaptation, yet\nserving stacks today isolate inference and finetuning on separate GPU clusters\n-- wasting resources and under-utilizing hardware. We introduce FlexLLM, the\nfirst system to co-serve LLM inference and PEFT-based finetuning on shared GPUs\nby fusing computation at the token level. The static compilation optimizations\nin FlexLLM -- dependent parallelization and graph pruning significantly shrink\nactivation memory, leading to end-to-end GPU memory savings by up to 80%. At\nruntime, a novel token-level finetuning mechanism paired with a hybrid token\nscheduler dynamically interleaves inference and training tokens within each\nco-serving iteration, meeting strict latency SLOs while maximizing utilization.\nIn end-to-end benchmarks on LLaMA-3.1-8B, Qwen-2.5-14B, and Qwen-2.5-32B,\nFlexLLM sustains the inference SLO requirements up to 20 req/s, and improves\nfinetuning throughput by 1.9-4.8x under heavy inference workloads and 2.5-6.8x\nunder light loads, preserving over 76% of peak finetuning progress even at peak\ndemand. The source code of FlexLLM is publicly available at\nhttps://github.com/flexflow/FlexFlow/.", "AI": {"tldr": "FlexLLM is a system that co-serves LLM inference and PEFT-based finetuning on shared GPUs, optimizing memory and throughput while meeting latency SLOs.", "motivation": "Current serving stacks waste resources by isolating inference and finetuning on separate GPU clusters, leading to underutilization.", "method": "FlexLLM uses token-level computation fusion, static compilation optimizations (dependent parallelization, graph pruning), and a hybrid token scheduler to interleave inference and training.", "result": "FlexLLM reduces GPU memory by up to 80%, sustains inference SLOs up to 20 req/s, and improves finetuning throughput by 1.9-6.8x.", "conclusion": "FlexLLM efficiently co-serves inference and finetuning, maximizing GPU utilization and performance."}}
{"id": "2505.01186", "pdf": "https://arxiv.org/pdf/2505.01186", "abs": "https://arxiv.org/abs/2505.01186", "authors": ["M. Saeid HaghighiFard", "Sinem Coleri"], "title": "Secure Cluster-Based Hierarchical Federated Learning in Vehicular Networks", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Hierarchical Federated Learning (HFL) has recently emerged as a promising\nsolution for intelligent decision-making in vehicular networks, helping to\naddress challenges such as limited communication resources, high vehicle\nmobility, and data heterogeneity. However, HFL remains vulnerable to\nadversarial and unreliable vehicles, whose misleading updates can significantly\ncompromise the integrity and convergence of the global model. To address these\nchallenges, we propose a novel defense framework that integrates dynamic\nvehicle selection with robust anomaly detection within a cluster-based HFL\narchitecture, specifically designed to counter Gaussian noise and gradient\nascent attacks. The framework performs a comprehensive reliability assessment\nfor each vehicle by evaluating historical accuracy, contribution frequency, and\nanomaly records. Anomaly detection combines Z-score and cosine similarity\nanalyses on model updates to identify both statistical outliers and directional\ndeviations in model updates. To further refine detection, an adaptive\nthresholding mechanism is incorporated into the cosine similarity metric,\ndynamically adjusting the threshold based on the historical accuracy of each\nvehicle to enforce stricter standards for consistently high-performing\nvehicles. In addition, a weighted gradient averaging mechanism is implemented,\nwhich assigns higher weights to gradient updates from more trustworthy\nvehicles. To defend against coordinated attacks, a cross-cluster consistency\ncheck is applied to identify collaborative attacks in which multiple\ncompromised clusters coordinate misleading updates. Together, these mechanisms\nform a multi-level defense strategy to filter out malicious contributions\neffectively. Simulation results show that the proposed algorithm significantly\nreduces convergence time compared to benchmark methods across both 1-hop and\n3-hop topologies.", "AI": {"tldr": "A defense framework for Hierarchical Federated Learning (HFL) in vehicular networks integrates dynamic vehicle selection and anomaly detection to counter adversarial attacks, improving model integrity and convergence.", "motivation": "HFL in vehicular networks faces challenges like adversarial vehicles and unreliable updates, compromising model integrity.", "method": "Proposes a cluster-based HFL framework with dynamic vehicle selection, anomaly detection (Z-score and cosine similarity), adaptive thresholding, weighted gradient averaging, and cross-cluster consistency checks.", "result": "Reduces convergence time significantly compared to benchmarks in 1-hop and 3-hop topologies.", "conclusion": "The multi-level defense strategy effectively filters malicious contributions, enhancing HFL robustness in vehicular networks."}}
{"id": "2505.01156", "pdf": "https://arxiv.org/pdf/2505.01156", "abs": "https://arxiv.org/abs/2505.01156", "authors": ["Milad Leyli-Abadi", "J\u00e9r\u00f4me Picault", "Antoine Marot", "Jean-Patrick Brunet", "Agathe Gilain", "Amarsagar Reddy Ramapuram Matavalam", "Shaban Ghias Satti", "Quingbin Jiang", "Yang Liu", "Dean Justin Ninalga"], "title": "Machine Learning for Physical Simulation Challenge Results and Retrospective Analysis: Power Grid Use Case", "categories": ["cs.LG", "68T01", "I.2.0"], "comment": "47 pages, 12 figures, 4 table, submission to Energy and AI journal", "summary": "This paper addresses the growing computational challenges of power grid\nsimulations, particularly with the increasing integration of renewable energy\nsources like wind and solar. As grid operators must analyze significantly more\nscenarios in near real-time to prevent failures and ensure stability,\ntraditional physical-based simulations become computationally impractical. To\ntackle this, a competition was organized to develop AI-driven methods that\naccelerate power flow simulations by at least an order of magnitude while\nmaintaining operational reliability. This competition utilized a regional-scale\ngrid model with a 30\\% renewable energy mix, mirroring the anticipated\nnear-future composition of the French power grid. A key contribution of this\nwork is through the use of LIPS (Learning Industrial Physical Systems), a\nbenchmarking framework that evaluates solutions based on four critical\ndimensions: machine learning performance, physical compliance, industrial\nreadiness, and generalization to out-of-distribution scenarios. The paper\nprovides a comprehensive overview of the Machine Learning for Physical\nSimulation (ML4PhySim) competition, detailing the benchmark suite, analyzing\ntop-performing solutions that outperformed traditional simulation methods, and\nsharing key organizational insights and best practices for running large-scale\nAI competitions. Given the promising results achieved, the study aims to\ninspire further research into more efficient, scalable, and sustainable power\nnetwork simulation methodologies.", "AI": {"tldr": "AI-driven methods were developed to speed up power grid simulations, addressing computational challenges from renewable energy integration, using a benchmarking framework (LIPS) to evaluate solutions.", "motivation": "The need for faster power grid simulations due to increased renewable energy sources and real-time scenario analysis.", "method": "Organized a competition (ML4PhySim) to develop AI-driven solutions, evaluated using LIPS framework across four dimensions.", "result": "Top-performing AI solutions outperformed traditional methods, demonstrating efficiency and reliability.", "conclusion": "The study encourages further research into scalable and sustainable simulation methods for power networks."}}
{"id": "2505.01390", "pdf": "https://arxiv.org/pdf/2505.01390", "abs": "https://arxiv.org/abs/2505.01390", "authors": ["Alice Natalina Caragliano", "Claudia Tacconi", "Carlo Greco", "Lorenzo Nibid", "Edy Ippolito", "Michele Fiore", "Giuseppe Perrone", "Sara Ramella", "Paolo Soda", "Valerio Guarrasi"], "title": "Multimodal Doctor-in-the-Loop: A Clinically-Guided Explainable Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "arXiv admin note: substantial text overlap with arXiv:2502.17503", "summary": "This study proposes a novel approach combining Multimodal Deep Learning with\nintrinsic eXplainable Artificial Intelligence techniques to predict\npathological response in non-small cell lung cancer patients undergoing\nneoadjuvant therapy. Due to the limitations of existing radiomics and unimodal\ndeep learning approaches, we introduce an intermediate fusion strategy that\nintegrates imaging and clinical data, enabling efficient interaction between\ndata modalities. The proposed Multimodal Doctor-in-the-Loop method further\nenhances clinical relevance by embedding clinicians' domain knowledge directly\ninto the training process, guiding the model's focus gradually from broader\nlung regions to specific lesions. Results demonstrate improved predictive\naccuracy and explainability, providing insights into optimal data integration\nstrategies for clinical applications.", "AI": {"tldr": "A novel multimodal deep learning approach with explainable AI improves pathological response prediction in lung cancer patients by integrating imaging and clinical data, guided by clinician input.", "motivation": "Existing radiomics and unimodal deep learning methods have limitations in predicting pathological response, prompting the need for a more integrated and explainable approach.", "method": "The study uses an intermediate fusion strategy to combine imaging and clinical data, along with a Doctor-in-the-Loop method to incorporate clinician knowledge during training.", "result": "The approach shows improved predictive accuracy and explainability, offering insights into effective data integration for clinical use.", "conclusion": "The proposed method enhances clinical relevance and performance in predicting treatment response, demonstrating the value of multimodal and explainable AI in oncology."}}
{"id": "2403.04577", "pdf": "https://arxiv.org/pdf/2403.04577", "abs": "https://arxiv.org/abs/2403.04577", "authors": ["Aneta Koleva", "Martin Ringsquandl", "Ahmed Hatem", "Thomas Runkler", "Volker Tresp"], "title": "Wiki-TabNER: Integrating Named Entity Recognition into Wikipedia Tables", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted at SIGIR 2025 conference", "summary": "Interest in solving table interpretation tasks has grown over the years, yet\nit still relies on existing datasets that may be overly simplified. This is\npotentially reducing the effectiveness of the dataset for thorough evaluation\nand failing to accurately represent tables as they appear in the real-world. To\nenrich the existing benchmark datasets, we extract and annotate a new, more\nchallenging dataset. The proposed Wiki-TabNER dataset features complex tables\ncontaining several entities per cell, with named entities labeled using DBpedia\nclasses. This dataset is specifically designed to address named entity\nrecognition (NER) task within tables, but it can also be used as a more\nchallenging dataset for evaluating the entity linking task. In this paper we\ndescribe the distinguishing features of the Wiki-TabNER dataset and the\nlabeling process. In addition, we propose a prompting framework for evaluating\nthe new large language models on the within tables NER task. Finally, we\nperform qualitative analysis to gain insights into the challenges encountered\nby the models and to understand the limitations of the proposed~dataset.", "AI": {"tldr": "The paper introduces Wiki-TabNER, a challenging dataset for table interpretation tasks, focusing on named entity recognition (NER) and entity linking, and proposes a prompting framework for evaluating large language models.", "motivation": "Existing datasets for table interpretation are overly simplified, limiting their effectiveness for thorough evaluation and real-world representation.", "method": "The authors extract and annotate Wiki-TabNER, a dataset with complex tables and multiple entities per cell, labeled using DBpedia classes. They also propose a prompting framework for model evaluation.", "result": "Wiki-TabNER is presented as a more challenging benchmark, and qualitative analysis reveals model challenges and dataset limitations.", "conclusion": "The dataset and framework aim to advance table interpretation tasks, though limitations are acknowledged."}}
{"id": "2505.01261", "pdf": "https://arxiv.org/pdf/2505.01261", "abs": "https://arxiv.org/abs/2505.01261", "authors": ["Elie Saad", "Mariem Besbes", "Marc Zolghadri", "Victor Czmil", "Claude Baron", "Vincent Bourgeois"], "title": "Enhancing Obsolescence Forecasting with Deep Generative Data Augmentation: A Semi-Supervised Framework for Low-Data Industrial Applications", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The challenge of electronic component obsolescence is particularly critical\nin systems with long life cycles. Various obsolescence management methods are\nemployed to mitigate its impact, with obsolescence forecasting being a highly\nsought-after and prominent approach. As a result, numerous machine\nlearning-based forecasting methods have been proposed. However, machine\nlearning models require a substantial amount of relevant data to achieve high\nprecision, which is lacking in the current obsolescence landscape in some\nsituations. This work introduces a novel framework for obsolescence forecasting\nbased on deep learning. The proposed framework solves the lack of available\ndata through deep generative modeling, where new obsolescence cases are\ngenerated and used to augment the training dataset. The augmented dataset is\nthen used to train a classical machine learning-based obsolescence forecasting\nmodel. To train classical forecasting models using augmented datasets, existing\nclassical supervised-learning classifiers are adapted for semi-supervised\nlearning within this framework. The proposed framework demonstrates\nstate-of-the-art results on benchmarking datasets.", "AI": {"tldr": "A deep learning framework for electronic component obsolescence forecasting addresses data scarcity by generating synthetic cases and augmenting training datasets, achieving state-of-the-art results.", "motivation": "Electronic component obsolescence is critical in long-life systems, but machine learning models lack sufficient data for high precision.", "method": "Proposes a deep generative model to create synthetic obsolescence cases, augmenting datasets for training classical machine learning models adapted for semi-supervised learning.", "result": "The framework achieves state-of-the-art performance on benchmarking datasets.", "conclusion": "The approach effectively mitigates data scarcity in obsolescence forecasting, enhancing model precision."}}
{"id": "2505.01160", "pdf": "https://arxiv.org/pdf/2505.01160", "abs": "https://arxiv.org/abs/2505.01160", "authors": ["Massimo Pavan", "Claudio Galimberti", "Manuel Roveri"], "title": "TActiLE: Tiny Active LEarning for wearable devices", "categories": ["cs.LG"], "comment": "Accepted to the \"Eyes Of The Future: Integrating Artificial\n  Intelligence in Smart Eyewear (IAISE)\" Workshop, Held at the \"International\n  Joint Conference on Neural Networks (IJCNN) 2025\"", "summary": "Tiny Machine Learning (TinyML) algorithms have seen extensive use in recent\nyears, enabling wearable devices to be not only connected but also genuinely\nintelligent by running machine learning (ML) computations directly on-device.\nAmong such devices, smart glasses have particularly benefited from TinyML\nadvancements. TinyML facilitates the on-device execution of the inference phase\nof ML algorithms on embedded and wearable devices, and more recently, it has\nexpanded into On-device Learning (ODL), which allows both inference and\nlearning phases to occur directly on the device. The application of ODL\ntechniques to wearable devices is particularly compelling, as it enables the\ndevelopment of more personalized models that adapt based on the data of the\nuser. However, one of the major challenges of ODL algorithms is the scarcity of\nlabeled data collected on-device. In smart wearable contexts, requiring users\nto manually label large amounts of data is often impractical and could lead to\nuser disengagement with the technology. To address this issue, this paper\nexplores the application of Active Learning (AL) techniques, i.e., techniques\nthat aim at minimizing the labeling effort, by actively selecting from a large\nquantity of unlabeled data only a small subset to be labeled and added to the\ntraining set of the algorithm. In particular, we propose TActiLE, a novel AL\nalgorithm that selects from the stream of on-device sensor data the ones that\nwould help the ML algorithm improve the most once coupled with labels provided\nby the user. TActiLE is the first Active Learning technique specifically\ndesigned for the TinyML context. We evaluate its effectiveness and efficiency\nthrough experiments on multiple image classification datasets. The results\ndemonstrate its suitability for tiny and wearable devices.", "AI": {"tldr": "The paper introduces TActiLE, an Active Learning algorithm for TinyML, addressing the challenge of limited labeled data in on-device learning for wearable devices like smart glasses.", "motivation": "The scarcity of labeled data in on-device learning for wearables necessitates minimizing labeling effort while maintaining model performance.", "method": "Proposes TActiLE, an Active Learning technique that selects the most informative unlabeled data for labeling, tailored for TinyML.", "result": "TActiLE is evaluated on image classification datasets, showing effectiveness and efficiency for tiny and wearable devices.", "conclusion": "TActiLE is a promising solution for enhancing on-device learning in TinyML applications, particularly for wearables."}}
{"id": "2505.01406", "pdf": "https://arxiv.org/pdf/2505.01406", "abs": "https://arxiv.org/abs/2505.01406", "authors": ["Mohammadreza Teymoorianfard", "Shiqing Ma", "Amir Houmansadr"], "title": "VIDSTAMP: A Temporally-Aware Watermark for Ownership and Integrity in Video Diffusion Models", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": null, "summary": "The rapid rise of video diffusion models has enabled the generation of highly\nrealistic and temporally coherent videos, raising critical concerns about\ncontent authenticity, provenance, and misuse. Existing watermarking approaches,\nwhether passive, post-hoc, or adapted from image-based techniques, often\nstruggle to withstand video-specific manipulations such as frame insertion,\ndropping, or reordering, and typically degrade visual quality. In this work, we\nintroduce VIDSTAMP, a watermarking framework that embeds per-frame or\nper-segment messages directly into the latent space of temporally-aware video\ndiffusion models. By fine-tuning the model's decoder through a two-stage\npipeline, first on static image datasets to promote spatial message separation,\nand then on synthesized video sequences to restore temporal consistency,\nVIDSTAMP learns to embed high-capacity, flexible watermarks with minimal\nperceptual impact. Leveraging architectural components such as 3D convolutions\nand temporal attention, our method imposes no additional inference cost and\noffers better perceptual quality than prior methods, while maintaining\ncomparable robustness against common distortions and tampering. VIDSTAMP embeds\n768 bits per video (48 bits per frame) with a bit accuracy of 95.0%, achieves a\nlog P-value of -166.65 (lower is better), and maintains a video quality score\nof 0.836, comparable to unwatermarked outputs (0.838) and surpassing prior\nmethods in capacity-quality tradeoffs. Code: Code:\n\\url{https://github.com/SPIN-UMass/VidStamp}", "AI": {"tldr": "VIDSTAMP is a watermarking framework for video diffusion models that embeds messages in latent space, maintaining high visual quality and robustness against manipulations.", "motivation": "Addressing the limitations of existing watermarking methods for videos, which struggle with manipulations like frame insertion/dropping and degrade quality.", "method": "A two-stage pipeline fine-tunes the model's decoder: first on static images for spatial separation, then on videos for temporal consistency. Uses 3D convolutions and temporal attention.", "result": "Embeds 768 bits per video (95.0% accuracy), achieves high video quality (0.836 score), and outperforms prior methods in capacity-quality tradeoffs.", "conclusion": "VIDSTAMP offers a robust, high-capacity watermarking solution for video diffusion models with minimal perceptual impact and no added inference cost."}}
{"id": "2408.09632", "pdf": "https://arxiv.org/pdf/2408.09632", "abs": "https://arxiv.org/abs/2408.09632", "authors": ["Chi-Heng Lin", "Shangqian Gao", "James Seale Smith", "Abhishek Patel", "Shikhar Tuli", "Yilin Shen", "Hongxia Jin", "Yen-Chang Hsu"], "title": "MoDeGPT: Modular Decomposition for Large Language Model Compression", "categories": ["cs.LG", "cs.CL", "stat.ML", "15A23 (Primary)", "I.2.7"], "comment": "ICLR 2025 Oral", "summary": "Large Language Models (LLMs) have reshaped the landscape of artificial\nintelligence by demonstrating exceptional performance across various tasks.\nHowever, substantial computational requirements make their deployment\nchallenging on devices with limited resources. Recently, compression methods\nusing low-rank matrix techniques have shown promise, yet these often lead to\ndegraded accuracy or introduce significant overhead in parameters and inference\nlatency. This paper introduces \\textbf{Mo}dular \\textbf{De}composition\n(MoDeGPT), a novel structured compression framework that does not need recovery\nfine-tuning while resolving the above drawbacks. MoDeGPT partitions the\nTransformer block into modules comprised of matrix pairs and reduces the hidden\ndimensions via reconstructing the module-level outputs. MoDeGPT is developed\nbased on a theoretical framework that utilizes three well-established matrix\ndecomposition algorithms -- Nystr\\\"om approximation, CR decomposition, and SVD\n-- and applies them to our redefined transformer modules. Our comprehensive\nexperiments show MoDeGPT, without backward propagation, matches or surpasses\nprevious structured compression methods that rely on gradient information, and\nsaves 98% of compute costs on compressing a 13B model. On \\textsc{Llama}-2/3\nand OPT models, MoDeGPT maintains 90-95% zero-shot performance with 25-30%\ncompression rates. Moreover, the compression can be done on a single GPU within\na few hours and increases the inference throughput by up to 46%.", "AI": {"tldr": "MoDeGPT is a novel structured compression framework for LLMs that avoids recovery fine-tuning, reduces computational costs, and maintains high performance.", "motivation": "Addressing the challenges of deploying LLMs on resource-limited devices due to high computational demands and the drawbacks of existing compression methods.", "method": "Partitions Transformer blocks into modules, reduces hidden dimensions via module-level output reconstruction, and uses Nystr\u00f6m, CR, and SVD decompositions.", "result": "Matches or surpasses previous methods, saves 98% compute costs, maintains 90-95% zero-shot performance, and increases inference throughput by 46%.", "conclusion": "MoDeGPT offers an efficient, high-performance compression solution for LLMs without requiring fine-tuning."}}
{"id": "2505.01281", "pdf": "https://arxiv.org/pdf/2505.01281", "abs": "https://arxiv.org/abs/2505.01281", "authors": ["Hao-Ran Yang", "Chuan-Xian Ren"], "title": "A Physics-preserved Transfer Learning Method for Differential Equations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While data-driven methods such as neural operator have achieved great success\nin solving differential equations (DEs), they suffer from domain shift problems\ncaused by different learning environments (with data bias or equation changes),\nwhich can be alleviated by transfer learning (TL). However, existing TL methods\nadopted in DEs problems lack either generalizability in general DEs problems or\nphysics preservation during training. In this work, we focus on a general\ntransfer learning method that adaptively correct the domain shift and preserve\nphysical information. Mathematically, we characterize the data domain as\nproduct distribution and the essential problems as distribution bias and\noperator bias. A Physics-preserved Optimal Tensor Transport (POTT) method that\nsimultaneously admits generalizability to common DEs and physics preservation\nof specific problem is proposed to adapt the data-driven model to target domain\nutilizing the push-forward distribution induced by the POTT map. Extensive\nexperiments demonstrate the superior performance, generalizability and physics\npreservation of the proposed POTT method.", "AI": {"tldr": "A new transfer learning method, POTT, addresses domain shift and preserves physics in solving differential equations.", "motivation": "Existing transfer learning methods for differential equations lack generalizability or physics preservation.", "method": "Proposes Physics-preserved Optimal Tensor Transport (POTT) to correct domain shift and preserve physical information.", "result": "POTT shows superior performance, generalizability, and physics preservation in experiments.", "conclusion": "POTT effectively adapts data-driven models to target domains while maintaining physical accuracy."}}
{"id": "2505.01163", "pdf": "https://arxiv.org/pdf/2505.01163", "abs": "https://arxiv.org/abs/2505.01163", "authors": ["Thanh Son Nguyen", "Dang Minh Duc Nguyen", "Van Thanh Nguyen"], "title": "Empirical Comparison of Lightweight Forecasting Models for Seasonal and Non-Seasonal Time Series", "categories": ["cs.LG"], "comment": null, "summary": "Accurate time series forecasting is essential in many real-time applications\nthat demand both high predictive accuracy and computational efficiency. This\nstudy provides an empirical comparison between a Polynomial Classifier and a\nRadial Basis Function Neural Network (RBFNN) across four real-world time series\ndatasets (weather conditions, gold prices, crude oil prices, and beer\nproduction volumes) that cover both seasonal and nonseasonal patterns. Model\nperformance is evaluated by forecasting accuracy (using Mean Absolute Error,\nRoot Mean Squared Error, and Coefficient of Variation of Root Mean Squared\nError) and computational time to assess each model's viability for real time\nforecasting. The results show that the PC yields more accurate and faster\nforecasts for non seasonal series, whereas the RBFNN performs better on series\nwith pronounced seasonal patterns. From an interpretability standpoint, the\npolynomial model offers a simpler, more transparent structure (in contrast to\nthe black box nature of neural network), which is advantageous for\nunderstanding and trust in real time decision making. The performance\ndifferences between PC and RBFNN are statistically significant, as confirmed by\npaired t tests and Wilcoxon signed rank tests. These findings provide practical\nguidance for model selection in time series forecasting, indicating that PC may\nbe preferable for quick, interpretable forecasts in non-seasonal contexts,\nwhereas RBFNN is superior for capturing complex seasonal behaviors", "AI": {"tldr": "The study compares Polynomial Classifier (PC) and Radial Basis Function Neural Network (RBFNN) for time series forecasting, finding PC better for non-seasonal data and RBFNN for seasonal data, with trade-offs in accuracy, speed, and interpretability.", "motivation": "To evaluate and compare the performance of PC and RBFNN for real-time time series forecasting, considering accuracy, computational efficiency, and interpretability.", "method": "Empirical comparison using four real-world datasets (weather, gold prices, oil prices, beer production) with seasonal and non-seasonal patterns. Metrics: Mean Absolute Error, Root Mean Squared Error, Coefficient of Variation, and computational time. Statistical tests (paired t-tests, Wilcoxon signed rank) validate results.", "result": "PC is more accurate and faster for non-seasonal data, while RBFNN excels for seasonal patterns. PC offers better interpretability. Differences are statistically significant.", "conclusion": "PC is recommended for non-seasonal, interpretable forecasts; RBFNN is better for complex seasonal patterns. Findings guide model selection in time series forecasting."}}
{"id": "2505.00995", "pdf": "https://arxiv.org/pdf/2505.00995", "abs": "https://arxiv.org/abs/2505.00995", "authors": ["Taewook Park", "Jinwoo Lee", "Hyondong Oh", "Won-Jae Yun", "Kyu-Wha Lee"], "title": "Optimizing Indoor Farm Monitoring Efficiency Using UAV: Yield Estimation in a GNSS-Denied Cherry Tomato Greenhouse", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted at 2025 ICRA workshop on field robotics", "summary": "As the agricultural workforce declines and labor costs rise, robotic yield\nestimation has become increasingly important. While unmanned ground vehicles\n(UGVs) are commonly used for indoor farm monitoring, their deployment in\ngreenhouses is often constrained by infrastructure limitations, sensor\nplacement challenges, and operational inefficiencies. To address these issues,\nwe develop a lightweight unmanned aerial vehicle (UAV) equipped with an RGB-D\ncamera, a 3D LiDAR, and an IMU sensor. The UAV employs a LiDAR-inertial\nodometry algorithm for precise navigation in GNSS-denied environments and\nutilizes a 3D multi-object tracking algorithm to estimate the count and weight\nof cherry tomatoes. We evaluate the system using two dataset: one from a\nharvesting row and another from a growing row. In the harvesting-row dataset,\nthe proposed system achieves 94.4\\% counting accuracy and 87.5\\% weight\nestimation accuracy within a 13.2-meter flight completed in 10.5 seconds. For\nthe growing-row dataset, which consists of occluded unripened fruits, we\nqualitatively analyze tracking performance and highlight future research\ndirections for improving perception in greenhouse with strong occlusions. Our\nfindings demonstrate the potential of UAVs for efficient robotic yield\nestimation in commercial greenhouses.", "AI": {"tldr": "A lightweight UAV with RGB-D, LiDAR, and IMU sensors is developed for yield estimation in greenhouses, achieving high accuracy in counting and weight estimation of cherry tomatoes.", "motivation": "Addressing the decline in agricultural workforce and rising labor costs by improving robotic yield estimation in greenhouses, where UGVs face limitations.", "method": "Uses a UAV with LiDAR-inertial odometry for navigation and 3D multi-object tracking for yield estimation, tested in harvesting and growing rows.", "result": "Achieves 94.4% counting accuracy and 87.5% weight estimation accuracy in harvesting rows, with qualitative analysis for growing rows.", "conclusion": "Demonstrates UAVs' potential for efficient yield estimation in greenhouses, with future research needed for occluded environments."}}
{"id": "2412.01003", "pdf": "https://arxiv.org/pdf/2412.01003", "abs": "https://arxiv.org/abs/2412.01003", "authors": ["Core Francisco Park", "Ekdeep Singh Lubana", "Itamar Pres", "Hidenori Tanaka"], "title": "Competition Dynamics Shape Algorithmic Phases of In-Context Learning", "categories": ["cs.LG", "cs.CL"], "comment": "ICLR 2025 Spotlight", "summary": "In-Context Learning (ICL) has significantly expanded the general-purpose\nnature of large language models, allowing them to adapt to novel tasks using\nmerely the inputted context. This has motivated a series of papers that analyze\ntractable synthetic domains and postulate precise mechanisms that may underlie\nICL. However, the use of relatively distinct setups that often lack a sequence\nmodeling nature to them makes it unclear how general the reported insights from\nsuch studies are. Motivated by this, we propose a synthetic sequence modeling\ntask that involves learning to simulate a finite mixture of Markov chains. As\nwe show, models trained on this task reproduce most well-known results on ICL,\nhence offering a unified setting for studying the concept. Building on this\nsetup, we demonstrate we can explain a model's behavior by decomposing it into\nfour broad algorithms that combine a fuzzy retrieval vs. inference approach\nwith either unigram or bigram statistics of the context. These algorithms\nengage in a competition dynamics to dominate model behavior, with the precise\nexperimental conditions dictating which algorithm ends up superseding others:\ne.g., we find merely varying context size or amount of training yields (at\ntimes sharp) transitions between which algorithm dictates the model behavior,\nrevealing a mechanism that explains the transient nature of ICL. In this sense,\nwe argue ICL is best thought of as a mixture of different algorithms, each with\nits own peculiarities, instead of a monolithic capability. This also implies\nthat making general claims about ICL that hold universally across all settings\nmay be infeasible.", "AI": {"tldr": "The paper proposes a synthetic sequence modeling task to study In-Context Learning (ICL), revealing it as a mixture of competing algorithms rather than a monolithic capability.", "motivation": "To address the lack of generality in existing ICL studies by introducing a unified synthetic task that reproduces known ICL results.", "method": "A synthetic task simulating a finite mixture of Markov chains, decomposing model behavior into four competing algorithms combining fuzzy retrieval/inference with unigram/bigram statistics.", "result": "Models trained on the task reproduce ICL results, with behavior dictated by competition among algorithms, influenced by context size and training amount.", "conclusion": "ICL is a transient, algorithmically mixed process, making universal claims about it infeasible."}}
{"id": "2505.01283", "pdf": "https://arxiv.org/pdf/2505.01283", "abs": "https://arxiv.org/abs/2505.01283", "authors": ["Hooman Danesh", "Maruthi Annamaraju", "Tim Brepols", "Stefanie Reese", "Surya R. Kalidindi"], "title": "Reduced-order structure-property linkages for stochastic metamaterials", "categories": ["cs.CE", "cs.AI", "cs.LG"], "comment": null, "summary": "The capabilities of additive manufacturing have facilitated the design and\nproduction of mechanical metamaterials with diverse unit cell geometries.\nEstablishing linkages between the vast design space of unit cells and their\neffective mechanical properties is critical for the efficient design and\nperformance evaluation of such metamaterials. However, physics-based\nsimulations of metamaterial unit cells across the entire design space are\ncomputationally expensive, necessitating a materials informatics framework to\nefficiently capture complex structure-property relationships. In this work,\nprincipal component analysis of 2-point correlation functions is performed to\nextract the salient features from a large dataset of randomly generated 2D\nmetamaterials. Physics-based simulations are performed using a fast Fourier\ntransform (FFT)-based homogenization approach to efficiently compute the\nhomogenized effective elastic stiffness across the extensive unit cell designs.\nSubsequently, Gaussian process regression is used to generate reduced-order\nsurrogates, mapping unit cell designs to their homogenized effective elastic\nconstant. It is demonstrated that the adopted workflow enables a high-value\nlow-dimensional representation of the voluminous stochastic metamaterial\ndataset, facilitating the construction of robust structure-property maps.\nFinally, an uncertainty-based active learning framework is utilized to train a\nsurrogate model with a significantly smaller number of data points compared to\nthe original full dataset. It is shown that a dataset as small as $0.61\\%$ of\nthe entire dataset is sufficient to generate accurate and robust\nstructure-property maps.", "AI": {"tldr": "The paper proposes a materials informatics framework to efficiently map unit cell designs to their mechanical properties in metamaterials, using PCA, FFT-based homogenization, and Gaussian process regression. Active learning reduces the required dataset size significantly.", "motivation": "The vast design space of metamaterial unit cells and the computational cost of physics-based simulations necessitate an efficient framework to link designs to mechanical properties.", "method": "PCA of 2-point correlation functions extracts features from a dataset of 2D metamaterials. FFT-based homogenization computes elastic stiffness, and Gaussian process regression creates surrogates. Active learning minimizes data requirements.", "result": "The workflow provides a low-dimensional representation of the dataset, enabling robust structure-property maps. Active learning reduces the needed dataset to 0.61% of the original.", "conclusion": "The framework efficiently captures complex structure-property relationships and significantly reduces computational costs, enabling practical design and evaluation of metamaterials."}}
{"id": "2505.01196", "pdf": "https://arxiv.org/pdf/2505.01196", "abs": "https://arxiv.org/abs/2505.01196", "authors": ["Najmus Sakib Sizan", "Md. Abu Layek", "Khondokar Fida Hasan"], "title": "A Secured Triad of IoT, Machine Learning, and Blockchain for Crop Forecasting in Agriculture", "categories": ["cs.LG"], "comment": "12 pages", "summary": "To improve crop forecasting and provide farmers with actionable data-driven\ninsights, we propose a novel approach integrating IoT, machine learning, and\nblockchain technologies. Using IoT, real-time data from sensor networks\ncontinuously monitor environmental conditions and soil nutrient levels,\nsignificantly improving our understanding of crop growth dynamics. Our study\ndemonstrates the exceptional accuracy of the Random Forest model, achieving a\n99.45\\% accuracy rate in predicting optimal crop types and yields, thereby\noffering precise crop projections and customized recommendations. To ensure the\nsecurity and integrity of the sensor data used for these forecasts, we\nintegrate the Ethereum blockchain, which provides a robust and secure platform.\nThis ensures that the forecasted data remain tamper-proof and reliable.\nStakeholders can access real-time and historical crop projections through an\nintuitive online interface, enhancing transparency and facilitating informed\ndecision-making. By presenting multiple predicted crop scenarios, our system\nenables farmers to optimize production strategies effectively. This integrated\napproach promises significant advances in precision agriculture, making crop\nforecasting more accurate, secure, and user-friendly.", "AI": {"tldr": "A novel system combining IoT, machine learning, and blockchain for accurate, secure crop forecasting.", "motivation": "To enhance crop forecasting with actionable insights for farmers by leveraging real-time data and ensuring data integrity.", "method": "Integrates IoT for real-time environmental monitoring, Random Forest for crop prediction (99.45% accuracy), and Ethereum blockchain for data security.", "result": "Achieves high accuracy in crop predictions, provides tamper-proof data, and offers an intuitive interface for stakeholders.", "conclusion": "The approach advances precision agriculture with accurate, secure, and user-friendly crop forecasting."}}
{"id": "2505.01113", "pdf": "https://arxiv.org/pdf/2505.01113", "abs": "https://arxiv.org/abs/2505.01113", "authors": ["Xun Li", "Jian Yang", "Fenli Jia", "Muyu Wang", "Qi Wu", "Jun Wu", "Jinpeng Mi", "Jilin Hu", "Peidong Liang", "Xuan Tang", "Ke Li", "Xiong You", "Xian Wei"], "title": "NeuroLoc: Encoding Navigation Cells for 6-DOF Camera Localization", "categories": ["cs.RO", "cs.CV", "cs.NE"], "comment": null, "summary": "Recently, camera localization has been widely adopted in autonomous robotic\nnavigation due to its efficiency and convenience. However, autonomous\nnavigation in unknown environments often suffers from scene ambiguity,\nenvironmental disturbances, and dynamic object transformation in camera\nlocalization. To address this problem, inspired by the biological brain\nnavigation mechanism (such as grid cells, place cells, and head direction\ncells), we propose a novel neurobiological camera location method, namely\nNeuroLoc. Firstly, we designed a Hebbian learning module driven by place cells\nto save and replay historical information, aiming to restore the details of\nhistorical representations and solve the issue of scene fuzziness. Secondly, we\nutilized the head direction cell-inspired internal direction learning as\nmulti-head attention embedding to help restore the true orientation in similar\nscenes. Finally, we added a 3D grid center prediction in the pose regression\nmodule to reduce the final wrong prediction. We evaluate the proposed NeuroLoc\non commonly used benchmark indoor and outdoor datasets. The experimental\nresults show that our NeuroLoc can enhance the robustness in complex\nenvironments and improve the performance of pose regression by using only a\nsingle image.", "AI": {"tldr": "NeuroLoc, a neurobiological camera localization method, addresses scene ambiguity and dynamic object issues in autonomous navigation by mimicking brain navigation mechanisms like grid and place cells.", "motivation": "Camera localization in unknown environments faces challenges like scene ambiguity and dynamic objects. The paper aims to enhance robustness and accuracy.", "method": "NeuroLoc uses Hebbian learning for historical data, head direction cell-inspired attention for orientation, and 3D grid prediction for pose regression.", "result": "NeuroLoc improves robustness and pose regression performance in complex environments using single images.", "conclusion": "The method effectively addresses challenges in camera localization, demonstrating superior performance on benchmark datasets."}}
{"id": "2412.07446", "pdf": "https://arxiv.org/pdf/2412.07446", "abs": "https://arxiv.org/abs/2412.07446", "authors": ["Raanan Y. Rohekar", "Yaniv Gurwicz", "Sungduk Yu", "Estelle Aflalo", "Vasudev Lal"], "title": "A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "comment": "International Conference on Machine Learning (ICML), 2025", "summary": "Do generative pre-trained transformer (GPT) models, trained only to predict\nthe next token, implicitly learn a world model from which a sequence is\ngenerated one token at a time? We address this question by deriving a causal\ninterpretation of the attention mechanism in GPT, and suggesting a causal world\nmodel that arises from this interpretation. Furthermore, we propose that GPT\nmodels, at inference time, can be utilized for zero-shot causal structure\nlearning for input sequences and present a confidence score. Empirical\nevaluation is conducted in a controlled environment using the setup and rules\nof the Othello and Chess strategy games. A GPT, pre-trained on real-world games\nplayed with the intention of winning, is tested on out-of-distribution\nsynthetic data consisting of sequences of random legal moves. We find that the\nGPT model is likely to generate legal next moves for out-of-distribution\nsequences for which a causal structure is encoded in the attention mechanism\nwith high confidence. In cases for which the GPT model generates illegal moves\nit also fails to capture any causal structure.", "AI": {"tldr": "GPT models may implicitly learn a world model from token prediction, enabling zero-shot causal structure learning with high confidence for sequences with encoded causal structure.", "motivation": "To investigate if GPT models, trained for token prediction, implicitly learn a causal world model and can perform zero-shot causal structure learning.", "method": "Derive a causal interpretation of GPT's attention mechanism, propose a causal world model, and test GPT on out-of-distribution synthetic data (Othello and Chess sequences).", "result": "GPT generates legal next moves for sequences with encoded causal structure but fails for illegal moves, correlating with causal structure capture.", "conclusion": "GPT's attention mechanism likely encodes a causal world model, enabling zero-shot causal structure learning for sequences with high confidence."}}
{"id": "2505.01286", "pdf": "https://arxiv.org/pdf/2505.01286", "abs": "https://arxiv.org/abs/2505.01286", "authors": ["Yajuan Zhang", "Jiahai Jiang", "Yule Yan", "Liang Yang", "Ping Zhang"], "title": "2DXformer: Dual Transformers for Wind Power Forecasting with Dual Exogenous Variables", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICDM 2024", "summary": "Accurate wind power forecasting can help formulate scientific dispatch plans,\nwhich is of great significance for maintaining the safety, stability, and\nefficient operation of the power system. In recent years, wind power\nforecasting methods based on deep learning have focused on extracting the\nspatiotemporal correlations among data, achieving significant improvements in\nforecasting accuracy. However, they exhibit two limitations. First, there is a\nlack of modeling for the inter-variable relationships, which limits the\naccuracy of the forecasts. Second, by treating endogenous and exogenous\nvariables equally, it leads to unnecessary interactions between the endogenous\nand exogenous variables, increasing the complexity of the model. In this paper,\nwe propose the 2DXformer, which, building upon the previous work's focus on\nspatiotemporal correlations, addresses the aforementioned two limitations.\nSpecifically, we classify the inputs of the model into three types: exogenous\nstatic variables, exogenous dynamic variables, and endogenous variables. First,\nwe embed these variables as variable tokens in a channel-independent manner.\nThen, we use the attention mechanism to capture the correlations among\nexogenous variables. Finally, we employ a multi-layer perceptron with residual\nconnections to model the impact of exogenous variables on endogenous variables.\nExperimental results on two real-world large-scale datasets indicate that our\nproposed 2DXformer can further improve the performance of wind power\nforecasting. The code is available in this repository:\n\\href{https://github.com/jseaj/2DXformer}{https://github.com/jseaj/2DXformer}.", "AI": {"tldr": "The paper proposes 2DXformer, a deep learning model for wind power forecasting that improves accuracy by addressing limitations in inter-variable relationships and unnecessary interactions between endogenous and exogenous variables.", "motivation": "Existing deep learning methods for wind power forecasting lack modeling of inter-variable relationships and treat endogenous and exogenous variables equally, limiting accuracy and increasing model complexity.", "method": "The 2DXformer classifies inputs into exogenous static, exogenous dynamic, and endogenous variables, embeds them as variable tokens, uses attention for exogenous correlations, and employs a multi-layer perceptron with residual connections to model impacts on endogenous variables.", "result": "Experiments on real-world datasets show 2DXformer improves wind power forecasting performance.", "conclusion": "The 2DXformer effectively addresses previous limitations and enhances forecasting accuracy, with code available for further use."}}
{"id": "2505.01199", "pdf": "https://arxiv.org/pdf/2505.01199", "abs": "https://arxiv.org/abs/2505.01199", "authors": ["Tsai-Ning Wang", "Lin-Lin Chen", "Neil Zeghidour", "Aaqib Saeed"], "title": "CaReAQA: A Cardiac and Respiratory Audio Question Answering Model for Open-Ended Diagnostic Reasoning", "categories": ["cs.LG"], "comment": "Accepted at AHLI CHIL 2025", "summary": "Medical audio signals, such as heart and lung sounds, play a crucial role in\nclinical diagnosis. However, analyzing these signals remains challenging:\ntraditional methods rely on handcrafted features or supervised deep learning\nmodels that demand extensive labeled datasets, limiting their scalability and\napplicability. To address these issues, we propose CaReAQA, an audio-language\nmodel that integrates a foundation audio model with the reasoning capabilities\nof large language models, enabling clinically relevant, open-ended diagnostic\nresponses. Alongside CaReAQA, we introduce CaReSound, a benchmark dataset of\nannotated medical audio recordings enriched with metadata and paired\nquestion-answer examples, intended to drive progress in diagnostic reasoning\nresearch. Evaluation results show that CaReAQA achieves 86.2% accuracy on\nopen-ended diagnostic reasoning tasks, outperforming baseline models. It also\ngeneralizes well to closed-ended classification tasks, achieving an average\naccuracy of 56.9% on unseen datasets. Our findings show how audio-language\nintegration and reasoning advances medical diagnostics, enabling efficient AI\nsystems for clinical decision support.", "AI": {"tldr": "CaReAQA, an audio-language model, integrates foundation audio and large language models for medical diagnostics, achieving 86.2% accuracy in open-ended tasks and 56.9% in unseen datasets.", "motivation": "Traditional methods for medical audio analysis rely on handcrafted features or supervised deep learning, which are limited by scalability and the need for labeled data.", "method": "Proposes CaReAQA, combining foundation audio models with large language models, and introduces CaReSound, a benchmark dataset with annotated medical audio and QA pairs.", "result": "CaReAQA achieves 86.2% accuracy in open-ended diagnostic reasoning and 56.9% in closed-ended tasks on unseen data.", "conclusion": "Audio-language integration and reasoning enhance medical diagnostics, enabling efficient AI for clinical decision support."}}
{"id": "2501.13100", "pdf": "https://arxiv.org/pdf/2501.13100", "abs": "https://arxiv.org/abs/2501.13100", "authors": ["Enes Arda", "Aylin Yener"], "title": "A Rate-Distortion Framework for Summarization", "categories": ["cs.IT", "cs.CL", "cs.LG", "math.IT"], "comment": "Accepted to ISIT 2025. This arXiv version includes an appendix with\n  additional details", "summary": "This paper introduces an information-theoretic framework for text\nsummarization. We define the summarizer rate-distortion function and show that\nit provides a fundamental lower bound on summarizer performance. We describe an\niterative procedure, similar to Blahut-Arimoto algorithm, for computing this\nfunction. To handle real-world text datasets, we also propose a practical\nmethod that can calculate the summarizer rate-distortion function with limited\ndata. Finally, we empirically confirm our theoretical results by comparing the\nsummarizer rate-distortion function with the performances of different\nsummarizers used in practice.", "AI": {"tldr": "The paper presents an information-theoretic framework for text summarization, introducing a rate-distortion function as a performance bound, a practical method for its computation, and empirical validation.", "motivation": "To establish a theoretical foundation for text summarization performance and provide a practical tool for evaluating summarizers.", "method": "Defines a summarizer rate-distortion function, proposes an iterative algorithm for computation, and introduces a practical method for real-world datasets.", "result": "Empirical validation confirms the theoretical rate-distortion function aligns with practical summarizer performances.", "conclusion": "The framework offers a fundamental performance bound and practical utility for evaluating text summarizers."}}
{"id": "2505.01288", "pdf": "https://arxiv.org/pdf/2505.01288", "abs": "https://arxiv.org/abs/2505.01288", "authors": ["Changhe Chen", "Quantao Yang", "Xiaohao Xu", "Nima Fazeli", "Olov Andersson"], "title": "ViSA-Flow: Accelerating Robot Skill Learning via Large-Scale Video Semantic Action Flow", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "One of the central challenges preventing robots from acquiring complex\nmanipulation skills is the prohibitive cost of collecting large-scale robot\ndemonstrations. In contrast, humans are able to learn efficiently by watching\nothers interact with their environment. To bridge this gap, we introduce\nsemantic action flow as a core intermediate representation capturing the\nessential spatio-temporal manipulator-object interactions, invariant to\nsuperficial visual differences. We present ViSA-Flow, a framework that learns\nthis representation self-supervised from unlabeled large-scale video data.\nFirst, a generative model is pre-trained on semantic action flows automatically\nextracted from large-scale human-object interaction video data, learning a\nrobust prior over manipulation structure. Second, this prior is efficiently\nadapted to a target robot by fine-tuning on a small set of robot demonstrations\nprocessed through the same semantic abstraction pipeline. We demonstrate\nthrough extensive experiments on the CALVIN benchmark and real-world tasks that\nViSA-Flow achieves state-of-the-art performance, particularly in low-data\nregimes, outperforming prior methods by effectively transferring knowledge from\nhuman video observation to robotic execution. Videos are available at\nhttps://visaflow-web.github.io/ViSAFLOW.", "AI": {"tldr": "ViSA-Flow introduces semantic action flow to bridge the gap between human and robot learning, using self-supervised learning from videos and fine-tuning with minimal robot data for state-of-the-art performance.", "motivation": "The high cost of large-scale robot demonstrations limits complex manipulation skills, while humans learn efficiently by observing.", "method": "ViSA-Flow learns semantic action flow from unlabeled videos, pre-trains a generative model, and fine-tunes with minimal robot data.", "result": "Achieves state-of-the-art performance on CALVIN and real-world tasks, especially in low-data regimes.", "conclusion": "ViSA-Flow effectively transfers knowledge from human videos to robots, outperforming prior methods."}}
{"id": "2505.01200", "pdf": "https://arxiv.org/pdf/2505.01200", "abs": "https://arxiv.org/abs/2505.01200", "authors": ["Simar Ghumman", "Fabio Di Troia", "William Andreopoulos", "Mark Stamp", "Sanjit Rai"], "title": "AGRO: An Autonomous AI Rover for Precision Agriculture", "categories": ["cs.LG"], "comment": null, "summary": "Unmanned Ground Vehicles (UGVs) are emerging as a crucial tool in the world\nof precision agriculture. The combination of UGVs with machine learning allows\nus to find solutions for a range of complex agricultural problems. This\nresearch focuses on developing a UGV capable of autonomously traversing\nagricultural fields and capturing data. The project, known as AGRO (Autonomous\nGround Rover Observer) leverages machine learning, computer vision and other\nsensor technologies. AGRO uses its capabilities to determine pistachio yields,\nperforming self-localization and real-time environmental mapping while avoiding\nobstacles. The main objective of this research work is to automate\nresource-consuming operations so that AGRO can support farmers in making\ndata-driven decisions. Furthermore, AGRO provides a foundation for advanced\nmachine learning techniques as it captures the world around it.", "AI": {"tldr": "AGRO, an autonomous UGV, uses machine learning and sensors to automate agricultural tasks like yield estimation and obstacle avoidance, aiding farmers in data-driven decisions.", "motivation": "To address complex agricultural problems by automating resource-intensive operations and supporting farmers with data-driven insights.", "method": "Develops AGRO, a UGV integrating machine learning, computer vision, and sensors for autonomous navigation, yield estimation, and real-time environmental mapping.", "result": "AGRO successfully performs tasks like pistachio yield determination, self-localization, and obstacle avoidance.", "conclusion": "AGRO demonstrates the potential of UGVs in precision agriculture, offering a foundation for advanced machine learning applications and improved farming efficiency."}}
{"id": "2505.01313", "pdf": "https://arxiv.org/pdf/2505.01313", "abs": "https://arxiv.org/abs/2505.01313", "authors": ["Shang Wang", "Huanrong Tang", "Jianquan Ouyang"], "title": "A Neural Architecture Search Method using Auxiliary Evaluation Metric based on ResNet Architecture", "categories": ["cs.NE", "cs.CV"], "comment": "GECCO 2023", "summary": "This paper proposes a neural architecture search space using ResNet as a\nframework, with search objectives including parameters for convolution,\npooling, fully connected layers, and connectivity of the residual network. In\naddition to recognition accuracy, this paper uses the loss value on the\nvalidation set as a secondary objective for optimization. The experimental\nresults demonstrate that the search space of this paper together with the\noptimisation approach can find competitive network architectures on the MNIST,\nFashion-MNIST and CIFAR100 datasets.", "AI": {"tldr": "A neural architecture search space based on ResNet optimizes convolution, pooling, fully connected layers, and residual connectivity, using validation loss as a secondary objective. It achieves competitive results on MNIST, Fashion-MNIST, and CIFAR100.", "motivation": "To improve neural architecture search by leveraging ResNet's framework and optimizing both accuracy and validation loss.", "method": "Proposes a search space for ResNet architectures, optimizing parameters for convolution, pooling, fully connected layers, and residual connectivity. Uses validation loss as a secondary optimization objective.", "result": "Competitive network architectures are found on MNIST, Fashion-MNIST, and CIFAR100 datasets.", "conclusion": "The proposed search space and optimization approach effectively identify high-performing neural architectures."}}
{"id": "2502.15507", "pdf": "https://arxiv.org/pdf/2502.15507", "abs": "https://arxiv.org/abs/2502.15507", "authors": ["Shashank Kirtania"], "title": "Activation Steering in Neural Theorem Provers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "incorrect explanation for a concept, need to revise and update!", "summary": "Large Language Models (LLMs) have shown promise in proving formal theorems\nusing proof assistants like Lean. However, current state of the art language\nmodels struggles to predict next step in proofs leading practitioners to use\ndifferent sampling techniques to improve LLMs capabilities. We observe that the\nLLM is capable of predicting the correct tactic; however, it faces challenges\nin ranking it appropriately within the set of candidate tactics, affecting the\noverall selection process. To overcome this hurdle, we use activation steering\nto guide LLMs responses to improve the generations at the time of inference.\nOur results suggest that activation steering offers a promising lightweight\nalternative to specialized fine-tuning for enhancing theorem proving\ncapabilities in LLMs, particularly valuable in resource-constrained\nenvironments.", "AI": {"tldr": "Activation steering improves LLMs' theorem-proving by guiding tactic selection, offering a lightweight alternative to fine-tuning.", "motivation": "Current LLMs struggle with ranking correct tactics in theorem proving, limiting their effectiveness.", "method": "Use activation steering to guide LLM responses during inference for better tactic selection.", "result": "Activation steering enhances theorem-proving capabilities without extensive fine-tuning.", "conclusion": "Activation steering is a promising, resource-efficient method for improving LLMs in theorem proving."}}
{"id": "2505.01307", "pdf": "https://arxiv.org/pdf/2505.01307", "abs": "https://arxiv.org/abs/2505.01307", "authors": ["Regan Bolton", "Mohammadreza Sheikhfathollahi", "Simon Parkinson", "Vanessa Vulovic", "Gary Bamford", "Dan Basher", "Howard Parkinson"], "title": "Document Retrieval Augmented Fine-Tuning (DRAFT) for safety-critical software assessments", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Safety critical software assessment requires robust assessment against\ncomplex regulatory frameworks, a process traditionally limited by manual\nevaluation. This paper presents Document Retrieval-Augmented Fine-Tuning\n(DRAFT), a novel approach that enhances the capabilities of a large language\nmodel (LLM) for safety-critical compliance assessment. DRAFT builds upon\nexisting Retrieval-Augmented Generation (RAG) techniques by introducing a novel\nfine-tuning framework that accommodates our dual-retrieval architecture, which\nsimultaneously accesses both software documentation and applicable reference\nstandards. To fine-tune DRAFT, we develop a semi-automated dataset generation\nmethodology that incorporates variable numbers of relevant documents with\nmeaningful distractors, closely mirroring real-world assessment scenarios.\nExperiments with GPT-4o-mini demonstrate a 7% improvement in correctness over\nthe baseline model, with qualitative improvements in evidence handling,\nresponse structure, and domain-specific reasoning. DRAFT represents a practical\napproach to improving compliance assessment systems while maintaining the\ntransparency and evidence-based reasoning essential in regulatory domains.", "AI": {"tldr": "DRAFT enhances LLMs for safety-critical compliance assessment using a dual-retrieval architecture and fine-tuning, improving correctness and evidence handling.", "motivation": "Manual evaluation of safety-critical software compliance is limited; DRAFT aims to automate and improve this process.", "method": "Introduces a fine-tuning framework with dual-retrieval (software docs and standards) and semi-automated dataset generation.", "result": "7% correctness improvement over baseline, with better evidence handling and domain reasoning.", "conclusion": "DRAFT offers a practical, transparent solution for regulatory compliance assessment."}}
{"id": "2505.01218", "pdf": "https://arxiv.org/pdf/2505.01218", "abs": "https://arxiv.org/abs/2505.01218", "authors": ["Akira Tamamori"], "title": "Quantitative Attractor Analysis of High-Capacity Kernel Logistic Regression Hopfield Networks", "categories": ["cs.LG", "cs.NE"], "comment": "8 pages, 7 figures", "summary": "Traditional Hopfield networks, using Hebbian learning, face severe storage\ncapacity limits ($\\approx 0.14$ P/N) and spurious attractors. Kernel Logistic\nRegression (KLR) offers a non-linear approach, mapping patterns to\nhigh-dimensional feature spaces for improved separability. Our previous work\nshowed KLR dramatically improves capacity and noise robustness over\nconventional methods. This paper quantitatively analyzes the attractor\nstructures in KLR-trained networks via extensive simulations. We evaluated\nrecall from diverse initial states across wide storage loads (up to 4.0 P/N)\nand noise levels. We quantified convergence rates and speed. Our analysis\nconfirms KLR's superior performance: high capacity (up to 4.0 P/N) and\nrobustness. The attractor landscape is remarkably \"clean,\" with near-zero\nspurious fixed points. Recall failures under high load/noise are primarily due\nto convergence to other learned patterns, not spurious ones. Dynamics are\nexceptionally fast (typically 1-2 steps for high-similarity states). This\ncharacterization reveals how KLR reshapes dynamics for high-capacity\nassociative memory, highlighting its effectiveness and contributing to AM\nunderstanding.", "AI": {"tldr": "Kernel Logistic Regression (KLR) enhances Hopfield networks, achieving high capacity (up to 4.0 P/N) and robustness with minimal spurious attractors.", "motivation": "Address the limitations of traditional Hopfield networks, such as low storage capacity and spurious attractors, by leveraging KLR's non-linear mapping.", "method": "Quantitative analysis of attractor structures in KLR-trained networks via simulations, evaluating recall, convergence rates, and speed under varied storage loads and noise levels.", "result": "KLR demonstrates superior performance: high capacity, robustness, clean attractor landscape, and fast dynamics (1-2 steps for high-similarity states).", "conclusion": "KLR effectively reshapes dynamics for high-capacity associative memory, offering significant improvements over traditional methods."}}
{"id": "2505.01425", "pdf": "https://arxiv.org/pdf/2505.01425", "abs": "https://arxiv.org/abs/2505.01425", "authors": ["Jiefeng Li", "Jinkun Cao", "Haotian Zhang", "Davis Rempe", "Jan Kautz", "Umar Iqbal", "Ye Yuan"], "title": "GENMO: A GENeralist Model for Human MOtion", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG", "cs.RO"], "comment": "Project page: https://research.nvidia.com/labs/dair/genmo/", "summary": "Human motion modeling traditionally separates motion generation and\nestimation into distinct tasks with specialized models. Motion generation\nmodels focus on creating diverse, realistic motions from inputs like text,\naudio, or keyframes, while motion estimation models aim to reconstruct accurate\nmotion trajectories from observations like videos. Despite sharing underlying\nrepresentations of temporal dynamics and kinematics, this separation limits\nknowledge transfer between tasks and requires maintaining separate models. We\npresent GENMO, a unified Generalist Model for Human Motion that bridges motion\nestimation and generation in a single framework. Our key insight is to\nreformulate motion estimation as constrained motion generation, where the\noutput motion must precisely satisfy observed conditioning signals. Leveraging\nthe synergy between regression and diffusion, GENMO achieves accurate global\nmotion estimation while enabling diverse motion generation. We also introduce\nan estimation-guided training objective that exploits in-the-wild videos with\n2D annotations and text descriptions to enhance generative diversity.\nFurthermore, our novel architecture handles variable-length motions and mixed\nmultimodal conditions (text, audio, video) at different time intervals,\noffering flexible control. This unified approach creates synergistic benefits:\ngenerative priors improve estimated motions under challenging conditions like\nocclusions, while diverse video data enhances generation capabilities.\nExtensive experiments demonstrate GENMO's effectiveness as a generalist\nframework that successfully handles multiple human motion tasks within a single\nmodel.", "AI": {"tldr": "GENMO is a unified model for human motion that combines motion generation and estimation into a single framework, leveraging diffusion and regression for accurate and diverse motion handling.", "motivation": "Traditional separation of motion generation and estimation limits knowledge transfer and requires separate models. GENMO aims to unify these tasks for better synergy.", "method": "GENMO reformulates motion estimation as constrained motion generation, using diffusion and regression. It includes an estimation-guided training objective and handles mixed multimodal conditions.", "result": "GENMO achieves accurate motion estimation and diverse generation, with improved performance under challenging conditions like occlusions.", "conclusion": "GENMO successfully unifies multiple human motion tasks in a single model, demonstrating its effectiveness as a generalist framework."}}
{"id": "2504.21035", "pdf": "https://arxiv.org/pdf/2504.21035", "abs": "https://arxiv.org/abs/2504.21035", "authors": ["Rui Xin", "Niloofar Mireshghallah", "Shuyue Stella Li", "Michael Duan", "Hyunwoo Kim", "Yejin Choi", "Yulia Tsvetkov", "Sewoong Oh", "Pang Wei Koh"], "title": "A False Sense of Privacy: Evaluating Textual Data Sanitization Beyond Surface-level Privacy Leakage", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": null, "summary": "Sanitizing sensitive text data typically involves removing personally\nidentifiable information (PII) or generating synthetic data under the\nassumption that these methods adequately protect privacy; however, their\neffectiveness is often only assessed by measuring the leakage of explicit\nidentifiers but ignoring nuanced textual markers that can lead to\nre-identification. We challenge the above illusion of privacy by proposing a\nnew framework that evaluates re-identification attacks to quantify individual\nprivacy risks upon data release. Our approach shows that seemingly innocuous\nauxiliary information -- such as routine social activities -- can be used to\ninfer sensitive attributes like age or substance use history from sanitized\ndata. For instance, we demonstrate that Azure's commercial PII removal tool\nfails to protect 74\\% of information in the MedQA dataset. Although\ndifferential privacy mitigates these risks to some extent, it significantly\nreduces the utility of the sanitized text for downstream tasks. Our findings\nindicate that current sanitization techniques offer a \\textit{false sense of\nprivacy}, highlighting the need for more robust methods that protect against\nsemantic-level information leakage.", "AI": {"tldr": "Current sanitization methods for sensitive text data often fail to protect against nuanced re-identification risks, as shown by a new framework evaluating privacy leaks.", "motivation": "Existing sanitization techniques focus on explicit identifiers but overlook subtle textual markers, leading to potential privacy breaches.", "method": "A new framework evaluates re-identification attacks to quantify privacy risks, testing tools like Azure's PII removal on datasets like MedQA.", "result": "Azure's tool fails to protect 74% of MedQA data; differential privacy reduces utility while mitigating risks.", "conclusion": "Current sanitization methods provide a false sense of privacy, urging the need for robust solutions against semantic-level leaks."}}
{"id": "2505.01309", "pdf": "https://arxiv.org/pdf/2505.01309", "abs": "https://arxiv.org/abs/2505.01309", "authors": ["Anicet Lepetit Ondo", "Laurence Capus", "Mamadou Bousso"], "title": "Enhancing SPARQL Query Rewriting for Complex Ontology Alignments", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "SPARQL query rewriting is a fundamental mechanism for uniformly querying\nheterogeneous ontologies in the Linked Data Web. However, the complexity of\nontology alignments, particularly rich correspondences (c : c), makes this\nprocess challenging. Existing approaches primarily focus on simple (s : s) and\npartially complex ( s : c) alignments, thereby overlooking the challenges posed\nby more expressive alignments. Moreover, the intricate syntax of SPARQL\npresents a barrier for non-expert users seeking to fully exploit the knowledge\nencapsulated in ontologies. This article proposes an innovative approach for\nthe automatic rewriting of SPARQL queries from a source ontology to a target\nontology, based on a user's need expressed in natural language. It leverages\nthe principles of equivalence transitivity as well as the advanced capabilities\nof large language models such as GPT-4. By integrating these elements, this\napproach stands out for its ability to efficiently handle complex alignments,\nparticularly (c : c) correspondences , by fully exploiting their\nexpressiveness. Additionally, it facilitates access to aligned ontologies for\nusers unfamiliar with SPARQL, providing a flexible solution for querying\nheterogeneous data.", "AI": {"tldr": "The paper proposes an automated SPARQL query rewriting method using natural language and GPT-4 to handle complex ontology alignments, improving accessibility for non-experts.", "motivation": "Existing methods struggle with complex (c : c) alignments and SPARQL's syntax, limiting usability for non-experts.", "method": "Leverages equivalence transitivity and GPT-4 to rewrite SPARQL queries from natural language inputs, addressing complex alignments.", "result": "Efficiently handles (c : c) alignments and simplifies querying for users unfamiliar with SPARQL.", "conclusion": "The approach enhances ontology querying by combining natural language processing with advanced alignment handling."}}
{"id": "2505.01242", "pdf": "https://arxiv.org/pdf/2505.01242", "abs": "https://arxiv.org/abs/2505.01242", "authors": ["Evelyn Chapuma", "Grey Mengezi", "Lewis Msasa", "Amelia Taylor"], "title": "mwBTFreddy: A Dataset for Flash Flood Damage Assessment in Urban Malawi", "categories": ["cs.LG"], "comment": null, "summary": "This paper describes the mwBTFreddy dataset, a resource developed to support\nflash flood damage assessment in urban Malawi, specifically focusing on the\nimpacts of Cyclone Freddy in 2023. The dataset comprises paired pre- and\npost-disaster satellite images sourced from Google Earth Pro, accompanied by\nJSON files containing labelled building annotations with geographic coordinates\nand damage levels (no damage, minor, major, or destroyed). Developed by the\nKuyesera AI Lab at the Malawi University of Business and Applied Sciences, this\ndataset is intended to facilitate the development of machine learning models\ntailored to building detection and damage classification in African urban\ncontexts. It also supports flood damage visualisation and spatial analysis to\ninform decisions on relocation, infrastructure planning, and emergency response\nin climate-vulnerable regions.", "AI": {"tldr": "The mwBTFreddy dataset supports flash flood damage assessment in Malawi using pre- and post-disaster satellite images and labeled building annotations for machine learning and spatial analysis.", "motivation": "To aid in building detection, damage classification, and decision-making for flood response in climate-vulnerable urban areas of Malawi.", "method": "Paired satellite images and JSON-labeled building annotations (damage levels and coordinates) are provided for machine learning model development.", "result": "A dataset enabling flood damage visualization, spatial analysis, and informed decisions on relocation and emergency response.", "conclusion": "The mwBTFreddy dataset is a valuable resource for AI-driven flood damage assessment and planning in African urban contexts."}}
{"id": "2306.11891", "pdf": "https://arxiv.org/pdf/2306.11891", "abs": "https://arxiv.org/abs/2306.11891", "authors": ["Pieter-Jan Toye"], "title": "VitalVideos-Europe: A dataset of face videos with PPG and blood pressure ground truths", "categories": ["cs.CV"], "comment": "vitalvideos.org", "summary": "We collected a large dataset consisting of 850 unique participants. For every\nparticipant we recorded two 30 second uncompressed videos, synchronized PPG\nwaveforms and a single blood pressure measurement. Gender, age and skin color\nwere also registered for every participant. The dataset includes roughly equal\nnumbers of males and females, as well as participants of all ages. While the\nskin color distribution could have been more balanced, the dataset contains\nindividuals from every skin color. The data was collected in a diverse set of\nlocations to ensure a wide variety of backgrounds and lighting conditions. In\nan effort to assist in the research and development of remote vital sign\nmeasurement we are now opening up access to this dataset.\n  vitalvideos.org for all datasets.", "AI": {"tldr": "A dataset of 850 participants with videos, PPG waveforms, blood pressure, and demographics was collected to aid remote vital sign measurement research.", "motivation": "To support research and development in remote vital sign measurement by providing a diverse and comprehensive dataset.", "method": "Collected data from 850 participants, including videos, PPG waveforms, blood pressure, and demographics (gender, age, skin color), in varied locations for diverse backgrounds and lighting.", "result": "A dataset with balanced gender and age representation, though skin color distribution could be improved, is now publicly available.", "conclusion": "The dataset is released to facilitate advancements in remote vital sign measurement technology."}}
{"id": "2505.00234", "pdf": "https://arxiv.org/pdf/2505.00234", "abs": "https://arxiv.org/abs/2505.00234", "authors": ["Vishnu Sarukkai", "Zhiqiang Xie", "Kayvon Fatahalian"], "title": "Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Many methods for improving Large Language Model (LLM) agents for sequential\ndecision-making tasks depend on task-specific knowledge engineering--such as\nprompt tuning, curated in-context examples, or customized observation and\naction spaces. Using these approaches, agent performance improves with the\nquality or amount of knowledge engineering invested. Instead, we investigate\nhow LLM agents can automatically improve their performance by learning\nin-context from their own successful experiences on similar tasks. Rather than\nrelying on task-specific knowledge engineering, we focus on constructing and\nrefining a database of self-generated examples. We demonstrate that even a\nnaive accumulation of successful trajectories across training tasks boosts test\nperformance on three benchmarks: ALFWorld (73% to 89%), Wordcraft (55% to 64%),\nand InterCode-SQL (75% to 79%)--matching the performance the initial agent\nachieves if allowed two to three attempts per task. We then introduce two\nextensions: (1) database-level selection through population-based training to\nidentify high-performing example collections, and (2) exemplar-level selection\nthat retains individual trajectories based on their empirical utility as\nin-context examples. These extensions further enhance performance, achieving\n91% on ALFWorld--matching more complex approaches that employ task-specific\ncomponents and prompts. Our results demonstrate that automatic trajectory\ndatabase construction offers a compelling alternative to labor-intensive\nknowledge engineering.", "AI": {"tldr": "LLM agents improve performance by learning from self-generated examples, reducing reliance on task-specific engineering. Extensions like database and exemplar-level selection further boost results.", "motivation": "To reduce dependence on task-specific knowledge engineering for LLM agents by enabling automatic learning from successful experiences.", "method": "Construct and refine a database of self-generated examples, with extensions like population-based training and exemplar-level selection.", "result": "Performance improved on benchmarks (ALFWorld: 73% to 91%, Wordcraft: 55% to 64%, InterCode-SQL: 75% to 79%), matching or exceeding task-specific approaches.", "conclusion": "Automatic trajectory database construction is a viable alternative to manual knowledge engineering, enhancing LLM agent performance."}}
{"id": "2505.01328", "pdf": "https://arxiv.org/pdf/2505.01328", "abs": "https://arxiv.org/abs/2505.01328", "authors": ["Anass Grini", "Oumaima Taheri", "Btissam El Khamlichi", "Amal El Fallah-Seghrouchni"], "title": "Constrained Network Adversarial Attacks: Validity, Robustness, and Transferability", "categories": ["cs.CR", "cs.AI", "cs.NI"], "comment": null, "summary": "While machine learning has significantly advanced Network Intrusion Detection\nSystems (NIDS), particularly within IoT environments where devices generate\nlarge volumes of data and are increasingly susceptible to cyber threats, these\nmodels remain vulnerable to adversarial attacks. Our research reveals a\ncritical flaw in existing adversarial attack methodologies: the frequent\nviolation of domain-specific constraints, such as numerical and categorical\nlimits, inherent to IoT and network traffic. This leads to up to 80.3% of\nadversarial examples being invalid, significantly overstating real-world\nvulnerabilities. These invalid examples, though effective in fooling models, do\nnot represent feasible attacks within practical IoT deployments. Consequently,\nrelying on these results can mislead resource allocation for defense, inflating\nthe perceived susceptibility of IoT-enabled NIDS models to adversarial\nmanipulation. Furthermore, we demonstrate that simpler surrogate models like\nMulti-Layer Perceptron (MLP) generate more valid adversarial examples compared\nto complex architectures such as CNNs and LSTMs. Using the MLP as a surrogate,\nwe analyze the transferability of adversarial severity to other ML/DL models\ncommonly used in IoT contexts. This work underscores the importance of\nconsidering both domain constraints and model architecture when evaluating and\ndesigning robust ML/DL models for security-critical IoT and network\napplications.", "AI": {"tldr": "Existing adversarial attack methods for IoT NIDS often violate domain constraints, leading to invalid examples (80.3%) that overstate vulnerabilities. MLPs generate more valid adversarial examples than CNNs/LSTMs, impacting transferability and defense strategies.", "motivation": "To address the overestimation of adversarial vulnerabilities in IoT NIDS due to invalid attack examples violating domain constraints.", "method": "Analyzed adversarial attack validity, compared MLP, CNN, and LSTM for generating valid examples, and studied transferability of adversarial severity.", "result": "80.3% of adversarial examples were invalid; MLPs outperformed CNNs/LSTMs in generating valid attacks.", "conclusion": "Domain constraints and model architecture must be considered for robust ML/DL models in IoT security."}}
{"id": "2505.01279", "pdf": "https://arxiv.org/pdf/2505.01279", "abs": "https://arxiv.org/abs/2505.01279", "authors": ["Zhaoyan Wang", "Xiangchi Song", "In-Young Ko"], "title": "MultiGran-STGCNFog: Towards Accurate and High-Throughput Inference for Multi-Granular Spatiotemporal Traffic Forecasting", "categories": ["cs.LG"], "comment": "nine pages and five figures included", "summary": "Accurate traffic forecasting and swift inference provision are essential for\nintelligent transportation systems. However, the present Graph Convolutional\nNetwork (GCN)-based approaches cannot extract and fuse multi-granular\nspatiotemporal features across various spatial and temporal scales\nsufficiently, proven to yield less accurate forecasts. Besides, additional\nfeature extraction branches introduced in prior studies critically increased\nmodel complexity and extended inference time, making it challenging to provide\nfast inference for traffic forecasting. In this paper, we propose\nMultiGran-STGCNFog, an efficient fog distributed inference system with a novel\ntraffic forecasting model that employs multi-granular spatiotemporal feature\nfusion on generated dynamic traffic graphs to fully capture interdependent\ntraffic dynamics. The proposed scheduling algorithm GA-DPHDS, optimizing layer\nexecution order and layer-device scheduling scheme simultaneously, contributes\nto considerable inference throughput improvement by leveraging heterogeneous\nfog devices in a pipelined manner. Extensive experiments on real-world datasets\ndemonstrate the superiority of the proposed method over selected baselines.", "AI": {"tldr": "Proposes MultiGran-STGCNFog, a fog-based system for efficient traffic forecasting with multi-granular spatiotemporal feature fusion and optimized scheduling.", "motivation": "Current GCN-based methods lack sufficient multi-granular spatiotemporal feature extraction and fusion, leading to inaccurate forecasts and slow inference due to increased model complexity.", "method": "Introduces MultiGran-STGCNFog, which fuses multi-granular spatiotemporal features on dynamic traffic graphs and uses GA-DPHDS for optimized layer-device scheduling.", "result": "Outperforms baselines in experiments, showing improved accuracy and inference throughput.", "conclusion": "The system effectively addresses limitations of existing methods, offering accurate and fast traffic forecasting."}}
{"id": "2402.11487", "pdf": "https://arxiv.org/pdf/2402.11487", "abs": "https://arxiv.org/abs/2402.11487", "authors": ["Tanzila Rahman", "Shweta Mahajan", "Hsin-Ying Lee", "Jian Ren", "Sergey Tulyakov", "Leonid Sigal"], "title": "Visual Concept-driven Image Generation with Text-to-Image Diffusion Model", "categories": ["cs.CV"], "comment": "11 Figures, 14 Pages, 2 tables", "summary": "Text-to-image (TTI) diffusion models have demonstrated impressive results in\ngenerating high-resolution images of complex and imaginative scenes. Recent\napproaches have further extended these methods with personalization techniques\nthat allow them to integrate user-illustrated concepts (e.g., the user\nhim/herself) using a few sample image illustrations. However, the ability to\ngenerate images with multiple interacting concepts, such as human subjects, as\nwell as concepts that may be entangled in one, or across multiple, image\nillustrations remains illusive. In this work, we propose a concept-driven TTI\npersonalization framework that addresses these core challenges. We build on\nexisting works that learn custom tokens for user-illustrated concepts, allowing\nthose to interact with existing text tokens in the TTI model. However,\nimportantly, to disentangle and better learn the concepts in question, we\njointly learn (latent) segmentation masks that disentangle these concepts in\nuser-provided image illustrations. We do so by introducing an Expectation\nMaximization (EM)-like optimization procedure where we alternate between\nlearning the custom tokens and estimating (latent) masks encompassing\ncorresponding concepts in user-supplied images. We obtain these masks based on\ncross-attention, from within the U-Net parameterized latent diffusion model and\nsubsequent DenseCRF optimization. We illustrate that such joint alternating\nrefinement leads to the learning of better tokens for concepts and, as a\nby-product, latent masks. We illustrate the benefits of the proposed approach\nqualitatively and quantitatively with several examples and use cases that can\ncombine three or more entangled concepts.", "AI": {"tldr": "A concept-driven TTI personalization framework is proposed to generate images with multiple interacting or entangled concepts by jointly learning custom tokens and latent segmentation masks.", "motivation": "Existing TTI models struggle with generating images involving multiple interacting or entangled concepts, such as human subjects or overlapping illustrations.", "method": "The framework uses an EM-like optimization to alternate between learning custom tokens and estimating latent masks via cross-attention and DenseCRF optimization.", "result": "The approach improves token learning for concepts and produces latent masks, enabling better generation of images with three or more entangled concepts.", "conclusion": "The proposed method effectively addresses the challenge of generating images with multiple interacting or entangled concepts, demonstrating qualitative and quantitative benefits."}}
{"id": "2505.01353", "pdf": "https://arxiv.org/pdf/2505.01353", "abs": "https://arxiv.org/abs/2505.01353", "authors": ["Jonathan Frey", "Katrin Baumg\u00e4rtner", "Gianluca Frison", "Dirk Reinhardt", "Jasper Hoffmann", "Leonard Fichtner", "Sebastien Gros", "Moritz Diehl"], "title": "Differentiable Nonlinear Model Predictive Control", "categories": ["math.OC", "cs.AI", "cs.LG"], "comment": "19 page, 4 figures, 2 tables", "summary": "The efficient computation of parametric solution sensitivities is a key\nchallenge in the integration of learning-enhanced methods with nonlinear model\npredictive control (MPC), as their availability is crucial for many learning\nalgorithms. While approaches presented in the machine learning community are\nlimited to convex or unconstrained formulations, this paper discusses the\ncomputation of solution sensitivities of general nonlinear programs (NLPs)\nusing the implicit function theorem (IFT) and smoothed optimality conditions\ntreated in interior-point methods (IPM). We detail sensitivity computation\nwithin a sequential quadratic programming (SQP) method which employs an IPM for\nthe quadratic subproblems. The publication is accompanied by an efficient\nopen-source implementation within the framework, providing both forward and\nadjoint sensitivities for general optimal control problems, achieving speedups\nexceeding 3x over the state-of-the-art solver mpc.pytorch.", "AI": {"tldr": "The paper addresses computing solution sensitivities for nonlinear MPC using IFT and IPM, detailing an SQP method with an efficient open-source implementation.", "motivation": "Efficient computation of parametric solution sensitivities is crucial for integrating learning-enhanced methods with nonlinear MPC.", "method": "Uses the implicit function theorem and smoothed optimality conditions in IPM, detailing sensitivity computation within an SQP method.", "result": "Achieves speedups exceeding 3x over mpc.pytorch with an efficient open-source implementation.", "conclusion": "The approach enables efficient sensitivity computation for general nonlinear programs, enhancing learning-MPC integration."}}
{"id": "2505.01332", "pdf": "https://arxiv.org/pdf/2505.01332", "abs": "https://arxiv.org/abs/2505.01332", "authors": ["Mohammed Sumayli", "Olugbenga Moses Anubi"], "title": "Integration of Multi-Mode Preference into Home Energy Management System Using Deep Reinforcement Learning", "categories": ["cs.LG", "cs.SY", "eess.SY", "stat.AP"], "comment": "Accepted for publication in ASME journal of engineering for\n  sustainable buildings and cities", "summary": "Home Energy Management Systems (HEMS) have emerged as a pivotal tool in the\nsmart home ecosystem, aiming to enhance energy efficiency, reduce costs, and\nimprove user comfort. By enabling intelligent control and optimization of\nhousehold energy consumption, HEMS plays a significant role in bridging the gap\nbetween consumer needs and energy utility objectives. However, much of the\nexisting literature construes consumer comfort as a mere deviation from the\nstandard appliance settings. Such deviations are typically incorporated into\noptimization objectives via static weighting factors. These factors often\noverlook the dynamic nature of consumer behaviors and preferences. Addressing\nthis oversight, our paper introduces a multi-mode Deep Reinforcement\nLearning-based HEMS (DRL-HEMS) framework, meticulously designed to optimize\nbased on dynamic, consumer-defined preferences. Our primary goal is to augment\nconsumer involvement in Demand Response (DR) programs by embedding dynamic\nmulti-mode preferences tailored to individual appliances. In this study, we\nleverage a model-free, single-agent DRL algorithm to deliver a HEMS framework\nthat is not only dynamic but also user-friendly. To validate its efficacy, we\nemployed real-world data at 15-minute intervals, including metrics such as\nelectricity price, ambient temperature, and appliances' power consumption. Our\nresults show that the model performs exceptionally well in optimizing energy\nconsumption within different preference modes. Furthermore, when compared to\ntraditional algorithms based on Mixed-Integer Linear Programming (MILP), our\nmodel achieves nearly optimal performance while outperforming in computational\nefficiency.", "AI": {"tldr": "The paper introduces a dynamic Deep Reinforcement Learning-based HEMS (DRL-HEMS) framework to optimize energy consumption by incorporating dynamic, consumer-defined preferences, outperforming traditional methods like MILP in efficiency and adaptability.", "motivation": "Existing HEMS often use static weighting factors for consumer comfort, ignoring dynamic behaviors. This paper aims to enhance consumer involvement in Demand Response programs by embedding dynamic preferences.", "method": "The study employs a model-free, single-agent DRL algorithm to create a dynamic and user-friendly HEMS framework, validated using real-world data at 15-minute intervals.", "result": "The DRL-HEMS framework optimizes energy consumption effectively across different preference modes and outperforms traditional MILP-based algorithms in computational efficiency.", "conclusion": "The proposed DRL-HEMS framework successfully addresses the limitations of static approaches, offering a dynamic and efficient solution for smart home energy management."}}
{"id": "2405.00998", "pdf": "https://arxiv.org/pdf/2405.00998", "abs": "https://arxiv.org/abs/2405.00998", "authors": ["Yuhang Huang", "SHilong Zou", "Xinwang Liu", "Kai Xu"], "title": "Part-aware Shape Generation with Latent 3D Diffusion of Neural Voxel Fields", "categories": ["cs.CV"], "comment": "This paper is accepted by TVCG", "summary": "This paper presents a novel latent 3D diffusion model for the generation of\nneural voxel fields, aiming to achieve accurate part-aware structures. Compared\nto existing methods, there are two key designs to ensure high-quality and\naccurate part-aware generation. On one hand, we introduce a latent 3D diffusion\nprocess for neural voxel fields, enabling generation at significantly higher\nresolutions that can accurately capture rich textural and geometric details. On\nthe other hand, a part-aware shape decoder is introduced to integrate the part\ncodes into the neural voxel fields, guiding the accurate part decomposition and\nproducing high-quality rendering results. Through extensive experimentation and\ncomparisons with state-of-the-art methods, we evaluate our approach across four\ndifferent classes of data. The results demonstrate the superior generative\ncapabilities of our proposed method in part-aware shape generation,\noutperforming existing state-of-the-art methods.", "AI": {"tldr": "A novel latent 3D diffusion model for generating neural voxel fields with accurate part-aware structures, outperforming existing methods.", "motivation": "To achieve high-quality and accurate part-aware generation in neural voxel fields, addressing limitations of current approaches.", "method": "Introduces a latent 3D diffusion process for higher-resolution generation and a part-aware shape decoder for accurate part decomposition.", "result": "Superior generative capabilities demonstrated across four data classes, outperforming state-of-the-art methods.", "conclusion": "The proposed method effectively enhances part-aware shape generation with high-quality rendering."}}
{"id": "2505.01383", "pdf": "https://arxiv.org/pdf/2505.01383", "abs": "https://arxiv.org/abs/2505.01383", "authors": ["Yan Miao", "Will Shen", "Hang Cui", "Sayan Mitra"], "title": "FalconWing: An Open-Source Platform for Ultra-Light Fixed-Wing Aircraft Research", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We present FalconWing -- an open-source, ultra-lightweight (150 g) fixed-wing\nplatform for autonomy research. The hardware platform integrates a small\ncamera, a standard airframe, offboard computation, and radio communication for\nmanual overrides. We demonstrate FalconWing's capabilities by developing and\ndeploying a purely vision-based control policy for autonomous landing (without\nIMU or motion capture) using a novel real-to-sim-to-real learning approach. Our\nlearning approach: (1) constructs a photorealistic simulation environment via\n3D Gaussian splatting trained on real-world images; (2) identifies nonlinear\ndynamics from vision-estimated real-flight data; and (3) trains a multi-modal\nVision Transformer (ViT) policy through simulation-only imitation learning. The\nViT architecture fuses single RGB image with the history of control actions via\nself-attention, preserving temporal context while maintaining real-time 20 Hz\ninference. When deployed zero-shot on the hardware platform, this policy\nachieves an 80% success rate in vision-based autonomous landings. Together with\nthe hardware specifications, we also open-source the system dynamics, the\nsoftware for photorealistic simulator and the learning approach.", "AI": {"tldr": "FalconWing is a lightweight, open-source fixed-wing platform for autonomy research, featuring vision-based control for autonomous landing using a real-to-sim-to-real learning approach.", "motivation": "To provide an accessible, lightweight platform for autonomy research, enabling vision-based control without reliance on IMU or motion capture systems.", "method": "Developed a real-to-sim-to-real learning approach: (1) created a photorealistic simulator using 3D Gaussian splatting, (2) identified dynamics from vision-estimated data, and (3) trained a Vision Transformer policy via simulation-only imitation learning.", "result": "Achieved an 80% success rate in vision-based autonomous landings when deployed zero-shot on the hardware.", "conclusion": "FalconWing, along with its open-source components, offers a practical solution for vision-based autonomy research, demonstrating effective real-world deployment of learned policies."}}
{"id": "2505.01336", "pdf": "https://arxiv.org/pdf/2505.01336", "abs": "https://arxiv.org/abs/2505.01336", "authors": ["Vincenzo De Paola", "Riccardo Zamboni", "Mirco Mutti", "Marcello Restelli"], "title": "Enhancing Diversity in Parallel Agents: A Maximum State Entropy Exploration Story", "categories": ["cs.LG"], "comment": null, "summary": "Parallel data collection has redefined Reinforcement Learning (RL), unlocking\nunprecedented efficiency and powering breakthroughs in large-scale real-world\napplications. In this paradigm, $N$ identical agents operate in $N$ replicas of\nan environment simulator, accelerating data collection by a factor of $N$. A\ncritical question arises: \\textit{Does specializing the policies of the\nparallel agents hold the key to surpass the $N$ factor acceleration?} In this\npaper, we introduce a novel learning framework that maximizes the entropy of\ncollected data in a parallel setting. Our approach carefully balances the\nentropy of individual agents with inter-agent diversity, effectively minimizing\nredundancies. The latter idea is implemented with a centralized policy gradient\nmethod, which shows promise when evaluated empirically against systems of\nidentical agents, as well as synergy with batch RL techniques that can exploit\ndata diversity. Finally, we provide an original concentration analysis that\nshows faster rates for specialized parallel sampling distributions, which\nsupports our methodology and may be of independent interest.", "AI": {"tldr": "A novel RL framework maximizes data entropy in parallel settings by balancing individual agent entropy and inter-agent diversity, outperforming identical-agent systems.", "motivation": "To surpass the $N$ factor acceleration in parallel RL by specializing agent policies and minimizing data redundancy.", "method": "Uses a centralized policy gradient method to balance entropy and diversity, integrating with batch RL techniques.", "result": "Empirical evaluation shows promise, and concentration analysis confirms faster rates for specialized parallel sampling.", "conclusion": "Specialized parallel policies enhance data efficiency and performance, supported by theoretical and empirical evidence."}}
{"id": "2406.01494", "pdf": "https://arxiv.org/pdf/2406.01494", "abs": "https://arxiv.org/abs/2406.01494", "authors": ["Markus Heinonen", "Ba-Hien Tran", "Michael Kampffmeyer", "Maurizio Filippone"], "title": "Robust Classification by Coupling Data Mollification with Label Smoothing", "categories": ["cs.CV", "cs.LG", "stat.ML"], "comment": "AISTATS 2025. Code:\n  https://github.com/markusheinonen/supervised-mollification", "summary": "Introducing training-time augmentations is a key technique to enhance\ngeneralization and prepare deep neural networks against test-time corruptions.\nInspired by the success of generative diffusion models, we propose a novel\napproach of coupling data mollification, in the form of image noising and\nblurring, with label smoothing to align predicted label confidences with image\ndegradation. The method is simple to implement, introduces negligible\noverheads, and can be combined with existing augmentations. We demonstrate\nimproved robustness and uncertainty quantification on the corrupted image\nbenchmarks of CIFAR, TinyImageNet and ImageNet datasets.", "AI": {"tldr": "A novel method combines data mollification (image noising/blurring) with label smoothing to improve robustness and uncertainty quantification in deep neural networks.", "motivation": "Enhancing generalization and preparing networks for test-time corruptions by leveraging training-time augmentations.", "method": "Coupling data mollification (image noising and blurring) with label smoothing to align label confidences with image degradation.", "result": "Improved robustness and uncertainty quantification on corrupted image benchmarks (CIFAR, TinyImageNet, ImageNet).", "conclusion": "The method is simple, efficient, and compatible with existing augmentations, offering practical benefits for robustness."}}
{"id": "2505.01396", "pdf": "https://arxiv.org/pdf/2505.01396", "abs": "https://arxiv.org/abs/2505.01396", "authors": ["Yang Jin", "Jun Lv", "Wenye Yu", "Hongjie Fang", "Yong-Lu Li", "Cewu Lu"], "title": "SIME: Enhancing Policy Self-Improvement with Modal-level Exploration", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Self-improvement requires robotic systems to initially learn from\nhuman-provided data and then gradually enhance their capabilities through\ninteraction with the environment. This is similar to how humans improve their\nskills through continuous practice. However, achieving effective\nself-improvement is challenging, primarily because robots tend to repeat their\nexisting abilities during interactions, often failing to generate new, valuable\ndata for learning. In this paper, we identify the key to successful\nself-improvement: modal-level exploration and data selection. By incorporating\na modal-level exploration mechanism during policy execution, the robot can\nproduce more diverse and multi-modal interactions. At the same time, we select\nthe most valuable trials and high-quality segments from these interactions for\nlearning. We successfully demonstrate effective robot self-improvement on both\nsimulation benchmarks and real-world experiments. The capability for\nself-improvement will enable us to develop more robust and high-success-rate\nrobotic control strategies at a lower cost. Our code and experiment scripts are\navailable at https://ericjin2002.github.io/SIME/", "AI": {"tldr": "The paper proposes a method for robotic self-improvement through modal-level exploration and data selection, demonstrating success in simulations and real-world experiments.", "motivation": "Robots struggle to generate new, valuable data for learning during interactions, limiting self-improvement. The paper addresses this challenge.", "method": "Incorporates modal-level exploration for diverse interactions and selects high-quality data segments for learning.", "result": "Successful demonstration of effective self-improvement in simulations and real-world experiments.", "conclusion": "The approach enables cost-effective development of robust robotic control strategies."}}
{"id": "2505.01346", "pdf": "https://arxiv.org/pdf/2505.01346", "abs": "https://arxiv.org/abs/2505.01346", "authors": ["Marie-Charlotte Brandenburg", "Katharina Jochemko"], "title": "How to Learn a Star: Binary Classification with Starshaped Polyhedral Sets", "categories": ["cs.LG", "cs.DM", "math.CO", "math.MG"], "comment": "22 pages, 8 figures", "summary": "We consider binary classification restricted to a class of continuous\npiecewise linear functions whose decision boundaries are (possibly nonconvex)\nstarshaped polyhedral sets, supported on a fixed polyhedral simplicial fan. We\ninvestigate the expressivity of these function classes and describe the\ncombinatorial and geometric structure of the loss landscape, most prominently\nthe sublevel sets, for two loss-functions: the 0/1-loss (discrete loss) and an\nexponential loss function. In particular, we give explicit bounds on the VC\ndimension of this model, and concretely describe the sublevel sets of the\ndiscrete loss as chambers in a hyperplane arrangement. For the exponential\nloss, we give sufficient conditions for the optimum to be unique, and describe\nthe geometry of the optimum when varying the rate parameter of the underlying\nexponential probability distribution.", "AI": {"tldr": "The paper explores binary classification using continuous piecewise linear functions with starshaped polyhedral decision boundaries. It analyzes expressivity, VC dimension, and loss landscape geometry for 0/1-loss and exponential loss.", "motivation": "To understand the expressivity and loss landscape of binary classifiers with starshaped polyhedral decision boundaries, providing insights into their combinatorial and geometric properties.", "method": "Investigates the expressivity of continuous piecewise linear functions, bounds VC dimension, and describes loss sublevel sets for 0/1-loss and exponential loss.", "result": "Explicit VC dimension bounds, sublevel sets of 0/1-loss as hyperplane arrangement chambers, and conditions for unique optima in exponential loss.", "conclusion": "The study provides a detailed geometric and combinatorial understanding of binary classifiers with starshaped polyhedral boundaries, aiding in model design and analysis."}}
{"id": "2408.08518", "pdf": "https://arxiv.org/pdf/2408.08518", "abs": "https://arxiv.org/abs/2408.08518", "authors": ["Xiaoyue Mi", "Fan Tang", "Juan Cao", "Peng Li", "Yang Liu"], "title": "Visual-Friendly Concept Protection via Selective Adversarial Perturbations", "categories": ["cs.CV"], "comment": "Under Review", "summary": "Personalized concept generation by tuning diffusion models with a few images\nraises potential legal and ethical concerns regarding privacy and intellectual\nproperty rights. Researchers attempt to prevent malicious personalization using\nadversarial perturbations. However, previous efforts have mainly focused on the\neffectiveness of protection while neglecting the visibility of perturbations.\nThey utilize global adversarial perturbations, which introduce noticeable\nalterations to original images and significantly degrade visual quality. In\nthis work, we propose the Visual-Friendly Concept Protection (VCPro) framework,\nwhich prioritizes the protection of key concepts chosen by the image owner\nthrough adversarial perturbations with lower perceptibility. To ensure these\nperturbations are as inconspicuous as possible, we introduce a relaxed\noptimization objective to identify the least perceptible yet effective\nadversarial perturbations, solved using the Lagrangian multiplier method.\nQualitative and quantitative experiments validate that VCPro achieves a better\ntrade-off between the visibility of perturbations and protection effectiveness,\neffectively prioritizing the protection of target concepts in images with less\nperceptible perturbations.", "AI": {"tldr": "VCPro framework balances adversarial perturbation visibility and protection effectiveness for personalized concept generation.", "motivation": "Address legal/ethical concerns in personalized concept generation by improving perturbation perceptibility.", "method": "Uses relaxed optimization and Lagrangian multiplier to find less perceptible yet effective perturbations.", "result": "VCPro achieves better trade-off between visibility and protection effectiveness.", "conclusion": "VCPro effectively protects target concepts with minimal perceptible alterations."}}
{"id": "2411.05348", "pdf": "https://arxiv.org/pdf/2411.05348", "abs": "https://arxiv.org/abs/2411.05348", "authors": ["Zongyuan Li", "Yanan Ni", "Runnan Qi", "Lumin Jiang", "Chang Lu", "Xiaojie Xu", "Xiangbei Liu", "Pengfei Li", "Yunzheng Guo", "Zhe Ma", "Huanyu Li", "Hui Wu", "Xian Guo", "Kuihua Huang", "Xuebo Zhang"], "title": "LLM-PySC2: Starcraft II learning environment for Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "The tremendous potential has been demonstrated by large language models\n(LLMs) in intelligent decision-making problems, with unprecedented capabilities\nshown across diverse applications ranging from gaming AI systems to complex\nstrategic planning frameworks. However, the StarCraft II platform, which has\nbeen widely adopted for validating decision-making algorithms in the past\ndecade, has not yet provided substantial support for this emerging domain. To\naddress issues that LLMs cannot interface with the hundreds of actions of the\npysc2 backend and the lack of native support for multi-agent (MA)\ncollaboration, we propose the LLM-PySC2 environment. This is the first\nenvironment that offers LLMs the complete pysc2 action space with sufficient\nmulti-modal information and game Wiki knowledge. With an asynchronous query\narchitecture, the environment efficiently interacts with LLMs that maintain a\nconstant latency regardless of the scale of the agents' population. In the\nexperiments, we evaluated LLMs' decision-making performance in both the\nmacro-decision and micro-operation scenarios, with traditional StarCraft II\nMulti-Agent Challenge (SMAC) tasks and a series of new proposed. Results\nindicate that LLMs possess the potential to achieve victories in complex\nscenarios but cannot constantly generate correct decisions, especially in the\nrecovered pysc2 action space and MA settings. Without task-relevant\ninstructions, the pre-trained models suffer from issues such as hallucinations\nand inefficient collaboration. Our findings suggest that StarCraft II still\nchallenges in the era of large models, revealing that there is a lot to do to\ndevelop an advanced LLM decision-making system, and the proposed LLM-PySC2\nenvironment will support future development of LLM-based decision-making\nsolutions.", "AI": {"tldr": "The paper introduces LLM-PySC2, an environment enabling LLMs to interact with StarCraft II's pysc2 backend, addressing action space and multi-agent collaboration challenges. Results show LLMs' potential but highlight issues like hallucinations and inefficiency.", "motivation": "To bridge the gap where LLMs lack support for StarCraft II's complex action space and multi-agent collaboration, hindering their application in decision-making tasks.", "method": "Proposes LLM-PySC2, an environment with full pysc2 action space, multi-modal data, and Wiki knowledge, using an asynchronous query architecture for scalable LLM interaction.", "result": "LLMs show potential in complex scenarios but struggle with consistent correctness, especially in multi-agent settings, and suffer from hallucinations without task-specific guidance.", "conclusion": "StarCraft II remains challenging for LLMs, and LLM-PySC2 provides a foundation for future LLM-based decision-making research."}}
{"id": "2505.01348", "pdf": "https://arxiv.org/pdf/2505.01348", "abs": "https://arxiv.org/abs/2505.01348", "authors": ["Leonardo F. Toso", "Lintao Ye", "James Anderson"], "title": "Learning Stabilizing Policies via an Unstable Subspace Representation", "categories": ["cs.LG"], "comment": null, "summary": "We study the problem of learning to stabilize (LTS) a linear time-invariant\n(LTI) system. Policy gradient (PG) methods for control assume access to an\ninitial stabilizing policy. However, designing such a policy for an unknown\nsystem is one of the most fundamental problems in control, and it may be as\nhard as learning the optimal policy itself. Existing work on the LTS problem\nrequires large data as it scales quadratically with the ambient dimension. We\npropose a two-phase approach that first learns the left unstable subspace of\nthe system and then solves a series of discounted linear quadratic regulator\n(LQR) problems on the learned unstable subspace, targeting to stabilize only\nthe system's unstable dynamics and reduce the effective dimension of the\ncontrol space. We provide non-asymptotic guarantees for both phases and\ndemonstrate that operating on the unstable subspace reduces sample complexity.\nIn particular, when the number of unstable modes is much smaller than the state\ndimension, our analysis reveals that LTS on the unstable subspace substantially\nspeeds up the stabilization process. Numerical experiments are provided to\nsupport this sample complexity reduction achieved by our approach.", "AI": {"tldr": "The paper proposes a two-phase method for learning to stabilize linear time-invariant systems, focusing on reducing sample complexity by targeting the unstable subspace.", "motivation": "Existing methods for stabilizing unknown systems require large data and scale poorly with system dimensions. The goal is to reduce sample complexity by focusing on unstable dynamics.", "method": "A two-phase approach: (1) learn the unstable subspace, (2) solve discounted LQR problems on this subspace to stabilize only unstable dynamics.", "result": "The method reduces sample complexity, especially when unstable modes are fewer than state dimensions, speeding up stabilization. Numerical experiments support this.", "conclusion": "Targeting the unstable subspace is effective for reducing sample complexity in stabilizing LTI systems."}}
{"id": "2409.00362", "pdf": "https://arxiv.org/pdf/2409.00362", "abs": "https://arxiv.org/abs/2409.00362", "authors": ["Mostafa Mansour", "Ahmed Abdelsalam", "Ari Happonen", "Jari Porras", "Esa Rahtu"], "title": "UDGS-SLAM : UniDepth Assisted Gaussian Splatting for Monocular SLAM", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Recent advancements in monocular neural depth estimation, particularly those\nachieved by the UniDepth network, have prompted the investigation of\nintegrating UniDepth within a Gaussian splatting framework for monocular SLAM.\nThis study presents UDGS-SLAM, a novel approach that eliminates the necessity\nof RGB-D sensors for depth estimation within Gaussian splatting framework.\nUDGS-SLAM employs statistical filtering to ensure local consistency of the\nestimated depth and jointly optimizes camera trajectory and Gaussian scene\nrepresentation parameters. The proposed method achieves high-fidelity rendered\nimages and low ATERMSE of the camera trajectory. The performance of UDGS-SLAM\nis rigorously evaluated using the TUM RGB-D dataset and benchmarked against\nseveral baseline methods, demonstrating superior performance across various\nscenarios. Additionally, an ablation study is conducted to validate design\nchoices and investigate the impact of different network backbone encoders on\nsystem performance.", "AI": {"tldr": "UDGS-SLAM integrates UniDepth with Gaussian splatting for monocular SLAM, eliminating RGB-D sensors, achieving high-fidelity results and low trajectory error.", "motivation": "To explore the integration of UniDepth within Gaussian splatting for monocular SLAM, reducing reliance on RGB-D sensors.", "method": "Combines UniDepth with Gaussian splatting, uses statistical filtering for depth consistency, and jointly optimizes camera trajectory and scene representation.", "result": "High-fidelity rendered images and low trajectory error (ATERMSE), outperforming baselines on TUM RGB-D dataset.", "conclusion": "UDGS-SLAM is effective for monocular SLAM, validated by ablation studies and superior performance."}}
{"id": "2411.14995", "pdf": "https://arxiv.org/pdf/2411.14995", "abs": "https://arxiv.org/abs/2411.14995", "authors": ["Jonas G\u00f6sgens", "Niklas Jansen", "Hector Geffner"], "title": "Learning Lifted STRIPS Models from Action Traces Alone: A Simple, General, and Scalable Solution", "categories": ["cs.AI"], "comment": "accepted at ICAPS 2025", "summary": "Learning STRIPS action models from action traces alone is a challenging\nproblem as it involves learning the domain predicates as well. In this work, a\nnovel approach is introduced which, like the well-known LOCM systems, is\nscalable, but like SAT approaches, is sound and complete. Furthermore, the\napproach is general and imposes no restrictions on the hidden domain or the\nnumber or arity of the predicates. The new learning method is based on an\n\\emph{efficient, novel test} that checks whether the assumption that a\npredicate is affected by a set of action patterns, namely, actions with\nspecific argument positions, is consistent with the traces. The predicates and\naction patterns that pass the test provide the basis for the learned domain\nthat is then easily completed with preconditions and static predicates. The new\nmethod is studied theoretically and experimentally. For the latter, the method\nis evaluated on traces and graphs obtained from standard classical domains like\nthe 8-puzzle, which involve hundreds of thousands of states and transitions.\nThe learned representations are then verified on larger instances.", "AI": {"tldr": "A novel method for learning STRIPS action models from traces is introduced, combining scalability, soundness, and completeness without domain restrictions.", "motivation": "Learning STRIPS action models from traces alone is challenging due to the need to infer domain predicates.", "method": "Uses an efficient test to check predicate consistency with action traces, then completes the domain with preconditions and static predicates.", "result": "The method is theoretically and experimentally validated, including on large-scale domains like the 8-puzzle.", "conclusion": "The approach is scalable, general, and effective for learning action models from traces."}}
{"id": "2505.01361", "pdf": "https://arxiv.org/pdf/2505.01361", "abs": "https://arxiv.org/abs/2505.01361", "authors": ["Hwanwoo Kim", "Panos Toulis", "Eric Laber"], "title": "Stabilizing Temporal Difference Learning via Implicit Stochastic Approximation", "categories": ["cs.LG", "math.PR", "stat.ML"], "comment": null, "summary": "Temporal Difference (TD) learning is a foundational algorithm in\nreinforcement learning (RL). For nearly forty years, TD learning has served as\na workhorse for applied RL as well as a building block for more complex and\nspecialized algorithms. However, despite its widespread use, it is not without\ndrawbacks, the most prominent being its sensitivity to step size. A poor choice\nof step size can dramatically inflate the error of value estimates and slow\nconvergence. Consequently, in practice, researchers must use trial and error in\norder to identify a suitable step size -- a process that can be tedious and\ntime consuming. As an alternative, we propose implicit TD algorithms that\nreformulate TD updates into fixed-point equations. These updates are more\nstable and less sensitive to step size without sacrificing computational\nefficiency. Moreover, our theoretical analysis establishes asymptotic\nconvergence guarantees and finite-time error bounds. Our results demonstrate\ntheir robustness and practicality for modern RL tasks, establishing implicit TD\nas a versatile tool for policy evaluation and value approximation.", "AI": {"tldr": "Implicit TD learning algorithms are proposed to address the step size sensitivity of traditional TD learning, offering stability and efficiency with theoretical guarantees.", "motivation": "Traditional TD learning is widely used but sensitive to step size, requiring tedious trial and error for optimal performance.", "method": "Reformulate TD updates into fixed-point equations to create implicit TD algorithms, ensuring stability and reduced step size sensitivity.", "result": "Implicit TD algorithms provide robust performance, asymptotic convergence guarantees, and finite-time error bounds.", "conclusion": "Implicit TD is a practical and versatile alternative for policy evaluation and value approximation in modern RL tasks."}}
{"id": "2410.01723", "pdf": "https://arxiv.org/pdf/2410.01723", "abs": "https://arxiv.org/abs/2410.01723", "authors": ["Yushi Huang", "Zining Wang", "Ruihao Gong", "Jing Liu", "Xinjie Zhang", "Jinyang Guo", "Xianglong Liu", "Jun Zhang"], "title": "HarmoniCa: Harmonizing Training and Inference for Better Feature Caching in Diffusion Transformer Acceleration", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025", "summary": "Diffusion Transformers (DiTs) excel in generative tasks but face practical\ndeployment challenges due to high inference costs. Feature caching, which\nstores and retrieves redundant computations, offers the potential for\nacceleration. Existing learning-based caching, though adaptive, overlooks the\nimpact of the prior timestep. It also suffers from misaligned\nobjectives--aligned predicted noise vs. high-quality images--between training\nand inference. These two discrepancies compromise both performance and\nefficiency. To this end, we harmonize training and inference with a novel\nlearning-based caching framework dubbed HarmoniCa. It first incorporates\nStep-Wise Denoising Training (SDT) to ensure the continuity of the denoising\nprocess, where prior steps can be leveraged. In addition, an Image Error\nProxy-Guided Objective (IEPO) is applied to balance image quality against cache\nutilization through an efficient proxy to approximate the image error.\nExtensive experiments across $8$ models, $4$ samplers, and resolutions from\n$256\\times256$ to $2K$ demonstrate superior performance and speedup of our\nframework. For instance, it achieves over $40\\%$ latency reduction (i.e.,\n$2.07\\times$ theoretical speedup) and improved performance on PixArt-$\\alpha$.\nRemarkably, our image-free approach reduces training time by $25\\%$ compared\nwith the previous method. Our code is available at\nhttps://github.com/ModelTC/HarmoniCa.", "AI": {"tldr": "HarmoniCa introduces a learning-based caching framework for Diffusion Transformers (DiTs) to reduce inference costs by harmonizing training and inference with Step-Wise Denoising Training and an Image Error Proxy-Guided Objective.", "motivation": "DiTs face high inference costs, and existing caching methods overlook prior timestep impact and misalign training-inference objectives, compromising performance and efficiency.", "method": "HarmoniCa uses Step-Wise Denoising Training (SDT) for continuity and prior step leverage, and an Image Error Proxy-Guided Objective (IEPO) to balance image quality and cache utilization.", "result": "Achieves over 40% latency reduction (2.07x speedup) and improved performance on PixArt-\u03b1, with 25% training time reduction.", "conclusion": "HarmoniCa effectively addresses DiTs' deployment challenges by aligning training-inference objectives and optimizing cache usage, demonstrating significant speedup and efficiency gains."}}
{"id": "2501.08324", "pdf": "https://arxiv.org/pdf/2501.08324", "abs": "https://arxiv.org/abs/2501.08324", "authors": ["Ziyuan Huang", "Vishaldeep Kaur Sekhon", "Roozbeh Sadeghian", "Maria L. Vaida", "Cynthia Jo", "Doyle Ward", "Vanni Bucci", "John P. Haran"], "title": "ADAM: An AI Reasoning and Bioinformatics Model for Alzheimer's Disease Detection and Microbiome-Clinical Data Integration", "categories": ["cs.AI", "68T07"], "comment": "12 pages, 7 figures", "summary": "Alzheimer's Disease Analysis Model (ADAM) is a multi-agent reasoning large\nlanguage model (LLM) framework designed to integrate and analyze multimodal\ndata, including microbiome profiles, clinical datasets, and external knowledge\nbases, to enhance the understanding and classification of Alzheimer's disease\n(AD). By leveraging the agentic system with LLM, ADAM produces insights from\ndiverse data sources and contextualizes the findings with literature-driven\nevidence. A comparative evaluation with XGBoost revealed a significantly\nimproved mean F1 score and significantly reduced variance for ADAM,\nhighlighting its robustness and consistency, particularly when utilizing human\nbiological data. Although currently tailored for binary classification tasks\nwith two data modalities, future iterations will aim to incorporate additional\ndata types, such as neuroimaging and peripheral biomarkers, and expand them to\npredict disease progression, thereby broadening ADAM's scalability and\napplicability in AD research and diagnostic applications.", "AI": {"tldr": "ADAM is a multi-agent LLM framework for Alzheimer's disease analysis, integrating multimodal data for improved classification and insights.", "motivation": "To enhance understanding and classification of Alzheimer's disease by leveraging diverse data sources and contextualizing findings with literature.", "method": "Uses a multi-agent reasoning LLM framework to analyze microbiome profiles, clinical data, and external knowledge bases.", "result": "Outperforms XGBoost with higher F1 scores and lower variance, showing robustness with human biological data.", "conclusion": "ADAM is effective for binary classification but aims to expand to more data types and disease progression prediction in future."}}
{"id": "2505.01386", "pdf": "https://arxiv.org/pdf/2505.01386", "abs": "https://arxiv.org/abs/2505.01386", "authors": ["Irene Wang", "Newsha Ardalani", "Mostafa Elhoushi", "Daniel Jiang", "Samuel Hsia", "Ekin Sumbul", "Divya Mahajan", "Carole-Jean Wu", "Bilge Acun"], "title": "Carbon Aware Transformers Through Joint Model-Hardware Optimization", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "The rapid growth of machine learning (ML) systems necessitates a more\ncomprehensive evaluation of their environmental impact, particularly their\ncarbon footprint, which comprises operational carbon from training and\ninference execution and embodied carbon from hardware manufacturing and its\nentire life-cycle. Despite the increasing importance of embodied emissions,\nthere is a lack of tools and frameworks to holistically quantify and optimize\nthe total carbon footprint of ML systems. To address this, we propose\nCATransformers, a carbon-aware architecture search framework that enables\nsustainability-driven co-optimization of ML models and hardware architectures.\nBy incorporating both operational and embodied carbon metrics into early design\nspace exploration of domain-specific hardware accelerators, CATransformers\ndemonstrates that optimizing for carbon yields design choices distinct from\nthose optimized solely for latency or energy efficiency. We apply our framework\nto multi-modal CLIP-based models, producing CarbonCLIP, a family of CLIP models\nachieving up to 17% reduction in total carbon emissions while maintaining\naccuracy and latency compared to state-of-the-art edge small CLIP baselines.\nThis work underscores the need for holistic optimization methods to design\nhigh-performance, environmentally sustainable AI systems.", "AI": {"tldr": "CATransformers is a carbon-aware framework for optimizing ML models and hardware to reduce both operational and embodied carbon emissions, achieving a 17% reduction in total carbon for CLIP models.", "motivation": "The environmental impact of ML systems, especially their carbon footprint, lacks comprehensive evaluation tools, particularly for embodied emissions from hardware.", "method": "Proposes CATransformers, a framework for co-optimizing ML models and hardware architectures using carbon metrics in early design exploration.", "result": "CarbonCLIP models reduce total carbon emissions by up to 17% while maintaining accuracy and latency compared to baselines.", "conclusion": "Holistic optimization methods are essential for designing sustainable, high-performance AI systems."}}
{"id": "2410.06126", "pdf": "https://arxiv.org/pdf/2410.06126", "abs": "https://arxiv.org/abs/2410.06126", "authors": ["Yize Chen", "Zhiyuan Yan", "Siwei Lyu", "Baoyuan Wu"], "title": "$X^2$-DFD: A framework for eXplainable and eXtendable Deepfake Detection", "categories": ["cs.CV"], "comment": null, "summary": "Detecting deepfakes has become an important task. Most existing detection\nmethods provide only real/fake predictions without offering\nhuman-comprehensible explanations. Recent studies leveraging MLLMs for deepfake\ndetection have shown improvements in explainability. However, the performance\nof pre-trained MLLMs (e.g., LLaVA) remains limited due to a lack of\nunderstanding of their capabilities for this task and strategies to enhance\nthem. In this work, we empirically assess the strengths and weaknesses of MLLMs\nspecifically in deepfake detection via forgery features analysis. Building on\nthese assessments, we propose a novel framework called ${X}^2$-DFD, consisting\nof three core modules. The first module, Model Feature Assessment (MFA),\nmeasures the detection capabilities of forgery features intrinsic to MLLMs, and\ngives a descending ranking of these features. The second module, Strong Feature\nStrengthening (SFS), enhances the detection and explanation capabilities by\nfine-tuning the MLLM on a dataset constructed based on the top-ranked features.\nThe third module, Weak Feature Supplementing (WFS), improves the fine-tuned\nMLLM's capabilities on lower-ranked features by integrating external dedicated\ndeepfake detectors. To verify the effectiveness of this framework, we further\npresent a practical implementation, where an automated forgery features\ngeneration, evaluation, and ranking procedure is designed for MFA module; an\nautomated generation procedure of the fine-tuning dataset containing real and\nfake images with explanations based on top-ranked features is developed for SFS\nmodel; an external conventional deepfake detector focusing on blending\nartifact, which corresponds to a low detection capability in the pre-trained\nMLLM, is integrated for WFS module. Experiments show that our approach enhances\nboth detection and explanation performance.", "AI": {"tldr": "The paper introduces ${X}^2$-DFD, a framework to improve deepfake detection and explanation using MLLMs by assessing, strengthening, and supplementing forgery features.", "motivation": "Existing deepfake detection methods lack explainability, and pre-trained MLLMs have limited performance. The study aims to enhance MLLMs' capabilities for this task.", "method": "The framework includes three modules: Model Feature Assessment (MFA) to rank forgery features, Strong Feature Strengthening (SFS) to fine-tune MLLMs on top features, and Weak Feature Supplementing (WFS) to integrate external detectors for weak features.", "result": "Experiments show improved detection and explanation performance.", "conclusion": "The proposed ${X}^2$-DFD framework effectively enhances MLLMs' deepfake detection and explainability by leveraging feature analysis and integration."}}
{"id": "2302.03669", "pdf": "https://arxiv.org/pdf/2302.03669", "abs": "https://arxiv.org/abs/2302.03669", "authors": ["Ming Zhu", "Xiao-Yang Liu", "Sem Borst", "Anwar Walid"], "title": "Deep Reinforcement Learning for Traffic Light Control in Intelligent Transportation Systems", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages", "summary": "Smart traffic lights in intelligent transportation systems (ITSs) are\nenvisioned to greatly increase traffic efficiency and reduce congestion. Deep\nreinforcement learning (DRL) is a promising approach to adaptively control\ntraffic lights based on the real-time traffic situation in a road network.\nHowever, conventional methods may suffer from poor scalability. In this paper,\nwe investigate deep reinforcement learning to control traffic lights, and both\ntheoretical analysis and numerical experiments show that the intelligent\nbehavior ``greenwave\" (i.e., a vehicle will see a progressive cascade of green\nlights, and not have to brake at any intersection) emerges naturally a grid\nroad network, which is proved to be the optimal policy in an avenue with\nmultiple cross streets. As a first step, we use two DRL algorithms for the\ntraffic light control problems in two scenarios. In a single road intersection,\nwe verify that the deep Q-network (DQN) algorithm delivers a thresholding\npolicy; and in a grid road network, we adopt the deep deterministic policy\ngradient (DDPG) algorithm. Secondly, numerical experiments show that the DQN\nalgorithm delivers the optimal control, and the DDPG algorithm with passive\nobservations has the capability to produce on its own a high-level intelligent\nbehavior in a grid road network, namely, the ``greenwave\" policy emerges. We\nalso verify the ``greenwave\" patterns in a $5 \\times 10$ grid road network.\nThirdly, the ``greenwave\" patterns demonstrate that DRL algorithms produce\nfavorable solutions since the ``greenwave\" policy shown in experiment results\nis proved to be optimal in a specified traffic model (an avenue with multiple\ncross streets). The delivered policies both in a single road intersection and a\ngrid road network demonstrate the scalability of DRL algorithms.", "AI": {"tldr": "The paper explores deep reinforcement learning (DRL) for smart traffic light control, showing DQN and DDPG algorithms can optimize traffic flow, with the 'greenwave' policy emerging as optimal in grid networks.", "motivation": "To address poor scalability in conventional traffic light control methods and improve traffic efficiency using DRL.", "method": "Uses DQN for single intersections and DDPG for grid networks, with theoretical and numerical validation.", "result": "DQN delivers optimal control in single intersections, while DDPG produces the 'greenwave' policy, proven optimal in grid networks.", "conclusion": "DRL algorithms are scalable and effective for traffic light control, with 'greenwave' emerging as an optimal solution."}}
{"id": "2505.01391", "pdf": "https://arxiv.org/pdf/2505.01391", "abs": "https://arxiv.org/abs/2505.01391", "authors": ["Alessandro Trenta", "Andrea Cossu", "Davide Bacciu"], "title": "Learning and Transferring Physical Models through Derivatives", "categories": ["cs.LG"], "comment": null, "summary": "We propose Derivative Learning (DERL), a supervised approach that models\nphysical systems by learning their partial derivatives. We also leverage DERL\nto build physical models incrementally, by designing a distillation protocol\nthat effectively transfers knowledge from a pre-trained to a student model. We\nprovide theoretical guarantees that our approach can learn the true physical\nsystem, being consistent with the underlying physical laws, even when using\nempirical derivatives. DERL outperforms state-of-the-art methods in\ngeneralizing an ODE to unseen initial conditions and a parametric PDE to unseen\nparameters. We finally propose a method based on DERL to transfer physical\nknowledge across models by extending them to new portions of the physical\ndomain and new range of PDE parameters. We believe this is the first attempt at\nbuilding physical models incrementally in multiple stages.", "AI": {"tldr": "DERL is a supervised method for modeling physical systems by learning partial derivatives, with a distillation protocol for incremental model building. It outperforms SOTA methods in generalization and enables knowledge transfer across models.", "motivation": "To model physical systems accurately and incrementally while adhering to underlying physical laws, even with empirical derivatives.", "method": "DERL learns partial derivatives of physical systems and uses a distillation protocol for incremental model building, with theoretical guarantees.", "result": "DERL outperforms SOTA in generalizing ODEs and PDEs to unseen conditions/parameters and enables knowledge transfer.", "conclusion": "DERL is the first method for incremental physical model building, offering strong generalization and transfer capabilities."}}
{"id": "2410.17262", "pdf": "https://arxiv.org/pdf/2410.17262", "abs": "https://arxiv.org/abs/2410.17262", "authors": ["Wenqing Wang", "Yun Fu"], "title": "EmoGene: Audio-Driven Emotional 3D Talking-Head Generation", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "comment": "Accepted by the 2025 IEEE 19th International Conference on Automatic\n  Face and Gesture Recognition (FG)", "summary": "Audio-driven talking-head generation is a crucial and useful technology for\nvirtual human interaction and film-making. While recent advances have focused\non improving image fidelity and lip synchronization, generating accurate\nemotional expressions remains underexplored. In this paper, we introduce\nEmoGene, a novel framework for synthesizing high-fidelity, audio-driven video\nportraits with accurate emotional expressions. Our approach employs a\nvariational autoencoder (VAE)-based audio-to-motion module to generate facial\nlandmarks, which are concatenated with emotional embedding in a\nmotion-to-emotion module to produce emotional landmarks. These landmarks drive\na Neural Radiance Fields (NeRF)-based emotion-to-video module to render\nrealistic emotional talking-head videos. Additionally, we propose a pose\nsampling method to generate natural idle-state (non-speaking) videos for silent\naudio inputs. Extensive experiments demonstrate that EmoGene outperforms\nprevious methods in generating high-fidelity emotional talking-head videos.", "AI": {"tldr": "EmoGene is a framework for generating high-fidelity, emotional talking-head videos using audio input, combining VAE, emotional embedding, and NeRF.", "motivation": "Current audio-driven talking-head generation lacks accurate emotional expressions, which EmoGene aims to address.", "method": "Uses a VAE-based audio-to-motion module, motion-to-emotion module with emotional embedding, and NeRF-based emotion-to-video module. Includes pose sampling for idle-state videos.", "result": "EmoGene outperforms previous methods in generating high-fidelity emotional talking-head videos.", "conclusion": "EmoGene effectively synthesizes realistic emotional expressions in audio-driven talking-head videos, advancing the field."}}
{"id": "2403.07404", "pdf": "https://arxiv.org/pdf/2403.07404", "abs": "https://arxiv.org/abs/2403.07404", "authors": ["Filip Szatkowski", "Yaoyue Zheng", "Fei Yang", "Bart\u0142omiej Twardowski", "Tomasz Trzci\u0144ski", "Joost van de Weijer"], "title": "Improving Continual Learning Performance and Efficiency with Auxiliary Classifiers", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Continual learning is crucial for applying machine learning in challenging,\ndynamic, and often resource-constrained environments. However, catastrophic\nforgetting - overwriting previously learned knowledge when new information is\nacquired - remains a major challenge. In this work, we examine the intermediate\nrepresentations in neural network layers during continual learning and find\nthat such representations are less prone to forgetting, highlighting their\npotential to accelerate computation. Motivated by these findings, we propose to\nuse auxiliary classifiers(ACs) to enhance performance and demonstrate that\nintegrating ACs into various continual learning methods consistently improves\naccuracy across diverse evaluation settings, yielding an average 10% relative\ngain. We also leverage the ACs to reduce the average cost of the inference by\n10-60% without compromising accuracy, enabling the model to return the\npredictions before computing all the layers. Our approach provides a scalable\nand efficient solution for continual learning.", "AI": {"tldr": "Auxiliary classifiers (ACs) improve continual learning by reducing forgetting and computational costs, achieving 10% accuracy gains and 10-60% inference cost savings.", "motivation": "Address catastrophic forgetting in continual learning by leveraging intermediate neural network representations, which are less prone to forgetting.", "method": "Propose auxiliary classifiers (ACs) integrated into continual learning methods to enhance performance and reduce inference costs.", "result": "ACs improve accuracy by 10% and reduce inference costs by 10-60% without losing accuracy.", "conclusion": "ACs offer a scalable and efficient solution for continual learning by mitigating forgetting and optimizing computation."}}
{"id": "2505.01402", "pdf": "https://arxiv.org/pdf/2505.01402", "abs": "https://arxiv.org/abs/2505.01402", "authors": ["Mohammadhossein Rashidi", "Mohammad Modarres"], "title": "Predicting the Price of Gold in the Financial Markets Using Hybrid Models", "categories": ["cs.LG", "econ.EM"], "comment": null, "summary": "Predicting the price that has the least error and can provide the best and\nhighest accuracy has been one of the most challenging issues and one of the\nmost critical concerns among capital market activists and researchers.\nTherefore, a model that can solve problems and provide results with high\naccuracy is one of the topics of interest among researchers. In this project,\nusing time series prediction models such as ARIMA to estimate the price,\nvariables, and indicators related to technical analysis show the behavior of\ntraders involved in involving psychological factors for the model. By linking\nall of these variables to stepwise regression, we identify the best variables\ninfluencing the prediction of the variable. Finally, we enter the selected\nvariables as inputs to the artificial neural network. In other words, we want\nto call this whole prediction process the \"ARIMA_Stepwise Regression_Neural\nNetwork\" model and try to predict the price of gold in international financial\nmarkets. This approach is expected to be able to be used to predict the types\nof stocks, commodities, currency pairs, financial market indicators, and other\nitems used in local and international financial markets. Moreover, a comparison\nbetween the results of this method and time series methods is also expressed.\nFinally, based on the results, it can be seen that the resulting hybrid model\nhas the highest accuracy compared to the time series method, regression, and\nstepwise regression.", "AI": {"tldr": "A hybrid model combining ARIMA, stepwise regression, and neural networks predicts gold prices with higher accuracy than traditional time series methods.", "motivation": "Addressing the challenge of accurate price prediction in financial markets by integrating multiple models for better results.", "method": "Uses ARIMA for time series prediction, stepwise regression to select influential variables, and neural networks for final prediction.", "result": "The hybrid model outperforms traditional time series, regression, and stepwise regression methods in accuracy.", "conclusion": "The proposed hybrid model is effective for price prediction in financial markets and can be extended to other assets."}}
{"id": "2410.19816", "pdf": "https://arxiv.org/pdf/2410.19816", "abs": "https://arxiv.org/abs/2410.19816", "authors": ["Elena Sierra", "Lauren E. Gillespie", "Salim Soltani", "Moises Exposito-Alonso", "Teja Kattenborn"], "title": "DivShift: Exploring Domain-Specific Distribution Shifts in Large-Scale, Volunteer-Collected Biodiversity Datasets", "categories": ["cs.CV"], "comment": "Published at AAAI-25 AI for Social Impact Track\n  (https://ojs.aaai.org/index.php/AAAI/article/view/35060) Presented at NeurIPS\n  2024 Workshop on Tackling Climate Change with Machine Learning\n  (https://www.climatechange.ai/papers/neurips2024/43)", "summary": "Large-scale, volunteer-collected datasets of community-identified natural\nworld imagery like iNaturalist have enabled marked performance gains for\nfine-grained visual classification of species using machine learning methods.\nHowever, such data -- sometimes referred to as citizen science data -- are\nopportunistic and lack a structured sampling strategy. This volunteer-collected\nbiodiversity data contains geographic, temporal, taxonomic, observers, and\nsociopolitical biases that can have significant effects on biodiversity model\nperformance, but whose impacts are unclear for fine-grained species recognition\nperformance. Here we introduce Diversity Shift (DivShift), a framework for\nquantifying the effects of domain-specific distribution shifts on machine\nlearning model performance. To diagnose the performance effects of biases\nspecific to volunteer-collected biodiversity data, we also introduce DivShift -\nNorth American West Coast (DivShift-NAWC), a curated dataset of almost 7.5\nmillion iNaturalist images across the western coast of North America\npartitioned across five types of expert-verified bias. We compare species\nrecognition performance across these bias partitions using a diverse variety of\nspecies- and ecosystem-focused accuracy metrics. We observe that these biases\nconfound model performance less than expected from the underlying label\ndistribution shift, and that more data leads to better model performance but\nthe magnitude of these improvements are bias-specific. These findings imply\nthat while the structure within natural world images provides generalization\nimprovements for biodiversity monitoring tasks, the biases present in\nvolunteer-collected biodiversity data can also affect model performance; thus\nthese models should be used with caution in downstream biodiversity monitoring\ntasks.", "AI": {"tldr": "The paper introduces DivShift, a framework to quantify the impact of biases in volunteer-collected biodiversity data on machine learning models, using a curated dataset (DivShift-NAWC) to analyze performance effects.", "motivation": "To understand how geographic, temporal, taxonomic, and sociopolitical biases in citizen science data affect fine-grained species recognition models.", "method": "Developed DivShift to quantify distribution shifts and created DivShift-NAWC, a dataset of 7.5M iNaturalist images with expert-verified biases, comparing model performance across bias partitions.", "result": "Biases confound model performance less than expected; more data improves performance, but improvements vary by bias type.", "conclusion": "While natural world images aid generalization, biases in volunteer-collected data impact model performance, warranting caution in biodiversity monitoring."}}
{"id": "2405.14606", "pdf": "https://arxiv.org/pdf/2405.14606", "abs": "https://arxiv.org/abs/2405.14606", "authors": ["Veeti Ahvonen", "Damian Heiman", "Antti Kuusisto", "Carsten Lutz"], "title": "Logical Characterizations of Recurrent Graph Neural Networks with Reals and Floats", "categories": ["cs.LO", "cs.AI", "F.4.1; F.1.1; I.2.0"], "comment": null, "summary": "In pioneering work from 2019, Barcel\\'o and coauthors identified logics that\nprecisely match the expressive power of constant iteration-depth graph neural\nnetworks (GNNs) relative to properties definable in first-order logic. In this\narticle, we give exact logical characterizations of recurrent GNNs in two\nscenarios: (1) in the setting with floating-point numbers and (2) with reals.\nFor floats, the formalism matching recurrent GNNs is a rule-based modal logic\nwith counting, while for reals we use a suitable infinitary modal logic, also\nwith counting. These results give exact matches between logics and GNNs in the\nrecurrent setting without relativising to a background logic in either case,\nbut using some natural assumptions about floating-point arithmetic. Applying\nour characterizations, we also prove that, relative to graph properties\ndefinable in monadic second-order logic (MSO), our infinitary and rule-based\nlogics are equally expressive. This implies that recurrent GNNs with reals and\nfloats have the same expressive power over MSO-definable properties and shows\nthat, for such properties, also recurrent GNNs with reals are characterized by\na (finitary!) rule-based modal logic. In the general case, in contrast, the\nexpressive power with floats is weaker than with reals. In addition to\nlogic-oriented results, we also characterize recurrent GNNs, with both reals\nand floats, via distributed automata, drawing links to distributed computing\nmodels.", "AI": {"tldr": "The paper provides exact logical characterizations of recurrent GNNs for floats and reals, showing their expressive power relative to MSO-definable properties and linking them to distributed automata.", "motivation": "To precisely match the expressive power of recurrent GNNs with logical formalisms in two scenarios: floating-point numbers and reals, without relying on background logic.", "method": "Uses rule-based modal logic with counting for floats and infinitary modal logic with counting for reals. Also employs distributed automata for characterization.", "result": "Recurrent GNNs with reals and floats have the same expressive power over MSO-definable properties, but floats are weaker in the general case.", "conclusion": "The study bridges GNNs, logic, and distributed computing, providing exact characterizations and insights into their expressive power."}}
{"id": "2505.01415", "pdf": "https://arxiv.org/pdf/2505.01415", "abs": "https://arxiv.org/abs/2505.01415", "authors": ["Rahuul Rangaraj", "Jimeng Shi", "Azam Shirali", "Rajendra Paudel", "Yanzhao Wu", "Giri Narasimhan"], "title": "How Effective are Large Time Series Models in Hydrology? A Study on Water Level Forecasting in Everglades", "categories": ["cs.LG"], "comment": null, "summary": "The Everglades play a crucial role in flood and drought regulation, water\nresource planning, and ecosystem management in the surrounding regions.\nHowever, traditional physics-based and statistical methods for predicting water\nlevels often face significant challenges, including high computational costs\nand limited adaptability to diverse or unforeseen conditions. Recent\nadvancements in large time series models have demonstrated the potential to\naddress these limitations, with state-of-the-art deep learning and foundation\nmodels achieving remarkable success in time series forecasting across various\ndomains. Despite this progress, their application to critical environmental\nsystems, such as the Everglades, remains underexplored. In this study, we fill\nthe gap by investigating twelve task-specific models and five time series\nfoundation models across six categories for a real-world application focused on\nwater level prediction in the Everglades. Our primary results show that the\nfoundation model, Chronos, significantly outperforms all other models while the\nremaining foundation models exhibit relatively poor performance. Moreover, the\nperformance of task-specific models varies with the model architectures.\nLastly, we discuss the possible reasons for the varying performance of models.", "AI": {"tldr": "The study evaluates deep learning and foundation models for water level prediction in the Everglades, finding Chronos outperforms others.", "motivation": "Traditional methods for water level prediction are costly and inflexible; advanced models offer potential solutions.", "method": "Twelve task-specific and five foundation models were tested for water level prediction.", "result": "Chronos, a foundation model, outperformed others, while other foundation models performed poorly. Task-specific models varied by architecture.", "conclusion": "Foundation models like Chronos show promise for environmental applications, but performance varies widely."}}
{"id": "2411.14432", "pdf": "https://arxiv.org/pdf/2411.14432", "abs": "https://arxiv.org/abs/2411.14432", "authors": ["Yuhao Dong", "Zuyan Liu", "Hai-Long Sun", "Jingkang Yang", "Winston Hu", "Yongming Rao", "Ziwei Liu"], "title": "Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate enhanced capabilities and\nreliability by reasoning more, evolving from Chain-of-Thought prompting to\nproduct-level solutions like OpenAI o1. Despite various efforts to improve LLM\nreasoning, high-quality long-chain reasoning data and optimized training\npipelines still remain inadequately explored in vision-language tasks. In this\npaper, we present Insight-V, an early effort to 1) scalably produce long and\nrobust reasoning data for complex multi-modal tasks, and 2) an effective\ntraining pipeline to enhance the reasoning capabilities of multi-modal large\nlanguage models (MLLMs). Specifically, to create long and structured reasoning\ndata without human labor, we design a two-step pipeline with a progressive\nstrategy to generate sufficiently long and diverse reasoning paths and a\nmulti-granularity assessment method to ensure data quality. We observe that\ndirectly supervising MLLMs with such long and complex reasoning data will not\nyield ideal reasoning ability. To tackle this problem, we design a multi-agent\nsystem consisting of a reasoning agent dedicated to performing long-chain\nreasoning and a summary agent trained to judge and summarize reasoning results.\nWe further incorporate an iterative DPO algorithm to enhance the reasoning\nagent's generation stability and quality. Based on the popular LLaVA-NeXT model\nand our stronger base MLLM, we demonstrate significant performance gains across\nchallenging multi-modal benchmarks requiring visual reasoning. Benefiting from\nour multi-agent system, Insight-V can also easily maintain or improve\nperformance on perception-focused multi-modal tasks.", "AI": {"tldr": "Insight-V introduces scalable long-chain reasoning data generation and an effective training pipeline for multi-modal LLMs, enhancing reasoning and perception in vision-language tasks.", "motivation": "High-quality long-chain reasoning data and optimized training pipelines are underexplored in vision-language tasks, limiting LLM reasoning capabilities.", "method": "A two-step pipeline generates long reasoning data, and a multi-agent system (reasoning and summary agents) with iterative DPO enhances reasoning quality.", "result": "Significant performance gains in multi-modal benchmarks and maintained or improved performance in perception-focused tasks.", "conclusion": "Insight-V advances MLLM reasoning and perception, demonstrating scalability and effectiveness in complex vision-language tasks."}}
{"id": "2405.17412", "pdf": "https://arxiv.org/pdf/2405.17412", "abs": "https://arxiv.org/abs/2405.17412", "authors": ["Aditya Ravuri", "Neil D. Lawrence"], "title": "Towards One Model for Classical Dimensionality Reduction: A Probabilistic Perspective on UMAP and t-SNE", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "AABI version", "summary": "This paper shows that dimensionality reduction methods such as UMAP and\nt-SNE, can be approximately recast as MAP inference methods corresponding to a\nmodel introduced in Ravuri et al. (2023), that describes the graph Laplacian\n(an estimate of the data precision matrix) using a Wishart distribution, with a\nmean given by a non-linear covariance function evaluated on the latents. This\ninterpretation offers deeper theoretical and semantic insights into such\nalgorithms, and forging a connection to Gaussian process latent variable models\nby showing that well-known kernels can be used to describe covariances implied\nby graph Laplacians. We also introduce tools with which similar dimensionality\nreduction methods can be studied.", "AI": {"tldr": "UMAP and t-SNE can be reinterpreted as MAP inference methods under a Wishart-distributed graph Laplacian model, linking them to Gaussian process latent variable models.", "motivation": "To provide theoretical and semantic insights into dimensionality reduction methods like UMAP and t-SNE by connecting them to probabilistic models.", "method": "Recast UMAP and t-SNE as MAP inference methods using a Wishart distribution for the graph Laplacian, with a non-linear covariance function for latents.", "result": "Established a connection between these methods and Gaussian process latent variable models, using known kernels for graph Laplacian covariances.", "conclusion": "This reinterpretation offers deeper theoretical understanding and tools for analyzing similar dimensionality reduction techniques."}}
{"id": "2505.01420", "pdf": "https://arxiv.org/pdf/2505.01420", "abs": "https://arxiv.org/abs/2505.01420", "authors": ["Mary Phuong", "Roland S. Zimmermann", "Ziyue Wang", "David Lindner", "Victoria Krakovna", "Sarah Cogan", "Allan Dafoe", "Lewis Ho", "Rohin Shah"], "title": "Evaluating Frontier Models for Stealth and Situational Awareness", "categories": ["cs.LG"], "comment": null, "summary": "Recent work has demonstrated the plausibility of frontier AI models scheming\n-- knowingly and covertly pursuing an objective misaligned with its developer's\nintentions. Such behavior could be very hard to detect, and if present in\nfuture advanced systems, could pose severe loss of control risk. It is\ntherefore important for AI developers to rule out harm from scheming prior to\nmodel deployment. In this paper, we present a suite of scheming reasoning\nevaluations measuring two types of reasoning capabilities that we believe are\nprerequisites for successful scheming: First, we propose five evaluations of\nability to reason about and circumvent oversight (stealth). Second, we present\neleven evaluations for measuring a model's ability to instrumentally reason\nabout itself, its environment and its deployment (situational awareness). We\ndemonstrate how these evaluations can be used as part of a scheming inability\nsafety case: a model that does not succeed on these evaluations is almost\ncertainly incapable of causing severe harm via scheming in real deployment. We\nrun our evaluations on current frontier models and find that none of them show\nconcerning levels of either situational awareness or stealth.", "AI": {"tldr": "The paper introduces evaluations to detect AI models' potential for scheming, focusing on stealth and situational awareness, and finds current models safe.", "motivation": "To address the risk of AI models covertly pursuing misaligned objectives, which could lead to severe loss of control.", "method": "Proposes 16 evaluations (5 for stealth, 11 for situational awareness) to measure scheming prerequisites.", "result": "Current frontier models show no concerning levels of stealth or situational awareness.", "conclusion": "The evaluations can help ensure AI safety by ruling out scheming capabilities before deployment."}}
{"id": "2411.16721", "pdf": "https://arxiv.org/pdf/2411.16721", "abs": "https://arxiv.org/abs/2411.16721", "authors": ["Han Wang", "Gang Wang", "Huan Zhang"], "title": "Steering Away from Harm: An Adaptive Approach to Defending Vision Language Model Against Jailbreaks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision Language Models (VLMs) can produce unintended and harmful content when\nexposed to adversarial attacks, particularly because their vision capabilities\ncreate new vulnerabilities. Existing defenses, such as input preprocessing,\nadversarial training, and response evaluation-based methods, are often\nimpractical for real-world deployment due to their high costs. To address this\nchallenge, we propose ASTRA, an efficient and effective defense by adaptively\nsteering models away from adversarial feature directions to resist VLM attacks.\nOur key procedures involve finding transferable steering vectors representing\nthe direction of harmful response and applying adaptive activation steering to\nremove these directions at inference time. To create effective steering\nvectors, we randomly ablate the visual tokens from the adversarial images and\nidentify those most strongly associated with jailbreaks. These tokens are then\nused to construct steering vectors. During inference, we perform the adaptive\nsteering method that involves the projection between the steering vectors and\ncalibrated activation, resulting in little performance drops on benign inputs\nwhile strongly avoiding harmful outputs under adversarial inputs. Extensive\nexperiments across multiple models and baselines demonstrate our\nstate-of-the-art performance and high efficiency in mitigating jailbreak risks.\nAdditionally, ASTRA exhibits good transferability, defending against unseen\nattacks (i.e., structured-based attack, perturbation-based attack with project\ngradient descent variants, and text-only attack). Our code is available at\n\\url{https://github.com/ASTRAL-Group/ASTRA}.", "AI": {"tldr": "ASTRA is a defense method for Vision Language Models (VLMs) that adaptively steers models away from adversarial feature directions to mitigate harmful outputs efficiently.", "motivation": "Existing defenses against adversarial attacks on VLMs are costly and impractical, prompting the need for an efficient solution.", "method": "ASTRA identifies harmful response directions via transferable steering vectors, constructed from ablated visual tokens, and applies adaptive activation steering during inference.", "result": "ASTRA achieves state-of-the-art performance in mitigating jailbreak risks with minimal impact on benign inputs and shows strong transferability against unseen attacks.", "conclusion": "ASTRA provides an efficient and effective defense for VLMs, balancing performance and robustness against adversarial threats."}}
{"id": "2406.13725", "pdf": "https://arxiv.org/pdf/2406.13725", "abs": "https://arxiv.org/abs/2406.13725", "authors": ["Viet-Hoang Tran", "Trang Pham", "Tho Tran", "Minh Khoi Nguyen Nhat", "Thanh Chu", "Tam Le", "Tan M. Nguyen"], "title": "Tree-Sliced Wasserstein Distance: A Geometric Perspective", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted to ICML 2025", "summary": "Many variants of Optimal Transport (OT) have been developed to address its\nheavy computation. Among them, notably, Sliced Wasserstein (SW) is widely used\nfor application domains by projecting the OT problem onto one-dimensional\nlines, and leveraging the closed-form expression of the univariate OT to reduce\nthe computational burden. However, projecting measures onto low-dimensional\nspaces can lead to a loss of topological information. To mitigate this issue,\nin this work, we propose to replace one-dimensional lines with a more intricate\nstructure, called tree systems. This structure is metrizable by a tree metric,\nwhich yields a closed-form expression for OT problems on tree systems. We\nprovide an extensive theoretical analysis to formally define tree systems with\ntheir topological properties, introduce the concept of splitting maps, which\noperate as the projection mechanism onto these structures, then finally propose\na novel variant of Radon transform for tree systems and verify its injectivity.\nThis framework leads to an efficient metric between measures, termed\nTree-Sliced Wasserstein distance on Systems of Lines (TSW-SL). By conducting a\nvariety of experiments on gradient flows, image style transfer, and generative\nmodels, we illustrate that our proposed approach performs favorably compared to\nSW and its variants.", "AI": {"tldr": "The paper introduces Tree-Sliced Wasserstein distance on Systems of Lines (TSW-SL), a novel variant of Optimal Transport (OT) using tree systems to mitigate information loss in Sliced Wasserstein (SW) methods.", "motivation": "To address the computational burden and loss of topological information in SW methods by leveraging tree systems for more intricate projections.", "method": "Proposes tree systems with tree metrics, splitting maps for projections, and a novel Radon transform for tree systems. Introduces TSW-SL as an efficient metric.", "result": "TSW-SL outperforms SW and its variants in experiments on gradient flows, image style transfer, and generative models.", "conclusion": "The framework effectively balances computational efficiency and topological information retention, offering improved performance over existing methods."}}
{"id": "2505.01424", "pdf": "https://arxiv.org/pdf/2505.01424", "abs": "https://arxiv.org/abs/2505.01424", "authors": ["D. Patel", "R. Sharma", "Y. B. Guo"], "title": "Computational, Data-Driven, and Physics-Informed Machine Learning Approaches for Microstructure Modeling in Metal Additive Manufacturing", "categories": ["cs.LG"], "comment": null, "summary": "Metal additive manufacturing enables unprecedented design freedom and the\nproduction of customized, complex components. However, the rapid melting and\nsolidification dynamics inherent to metal AM processes generate heterogeneous,\nnon-equilibrium microstructures that significantly impact mechanical properties\nand subsequent functionality. Predicting microstructure and its evolution\nacross spatial and temporal scales remains a central challenge for process\noptimization and defect mitigation. While conventional experimental techniques\nand physics-based simulations provide a physical foundation and valuable\ninsights, they face critical limitations. In contrast, data-driven machine\nlearning offers an alternative prediction approach and powerful pattern\nrecognition but often operate as black-box, lacking generalizability and\nphysical consistency. To overcome these limitations, physics-informed machine\nlearning, including physics-informed neural networks, has emerged as a\npromising paradigm by embedding governing physical laws into neural network\narchitectures, thereby enhancing accuracy, transparency, data efficiency, and\nextrapolation capabilities. This work presents a comprehensive evaluation of\nmodeling strategies for microstructure prediction in metal AM. The strengths\nand limitations of experimental, computational, and data-driven methods are\nanalyzed in depth, and highlight recent advances in hybrid PIML frameworks that\nintegrate physical knowledge with ML. Key challenges, such as data scarcity,\nmulti-scale coupling, and uncertainty quantification, are discussed alongside\nfuture directions. Ultimately, this assessment underscores the importance of\nPIML-based hybrid approaches in enabling predictive, scalable, and physically\nconsistent microstructure modeling for site-specific, microstructure-aware\nprocess control and the reliable production of high-performance AM components.", "AI": {"tldr": "The paper evaluates modeling strategies for microstructure prediction in metal additive manufacturing, emphasizing the potential of physics-informed machine learning (PIML) to overcome limitations of traditional methods.", "motivation": "Metal AM produces complex components but faces challenges in predicting heterogeneous microstructures, which affect mechanical properties. Existing methods (experimental, simulations, ML) have limitations in accuracy, generalizability, and physical consistency.", "method": "The paper reviews experimental, computational, and data-driven methods, focusing on hybrid PIML frameworks that integrate physical laws with ML for better microstructure prediction.", "result": "PIML enhances accuracy, transparency, and scalability in microstructure modeling, addressing challenges like data scarcity and multi-scale coupling.", "conclusion": "Hybrid PIML approaches are crucial for predictive, physically consistent microstructure modeling, enabling better process control and reliable AM component production."}}
{"id": "2412.06204", "pdf": "https://arxiv.org/pdf/2412.06204", "abs": "https://arxiv.org/abs/2412.06204", "authors": ["Yanqi Cheng", "Carola-Bibiane Sch\u00f6nlieb", "Angelica I Aviles-Rivero"], "title": "You KAN Do It in a Single Shot: Plug-and-Play Methods with Single-Instance Priors", "categories": ["cs.CV"], "comment": null, "summary": "The use of Plug-and-Play (PnP) methods has become a central approach for\nsolving inverse problems, with denoisers serving as regularising priors that\nguide optimisation towards a clean solution. In this work, we introduce\nKAN-PnP, an optimisation framework that incorporates Kolmogorov-Arnold Networks\n(KANs) as denoisers within the Plug-and-Play (PnP) paradigm. KAN-PnP is\nspecifically designed to solve inverse problems with single-instance priors,\nwhere only a single noisy observation is available, eliminating the need for\nlarge datasets typically required by traditional denoising methods. We show\nthat KANs, based on the Kolmogorov-Arnold representation theorem, serve\neffectively as priors in such settings, providing a robust approach to\ndenoising. We prove that the KAN denoiser is Lipschitz continuous, ensuring\nstability and convergence in optimisation algorithms like PnP-ADMM, even in the\ncontext of single-shot learning. Additionally, we provide theoretical\nguarantees for KAN-PnP, demonstrating its convergence under key conditions: the\nconvexity of the data fidelity term, Lipschitz continuity of the denoiser, and\nboundedness of the regularisation functional. These conditions are crucial for\nstable and reliable optimisation. Our experimental results show, on\nsuper-resolution and joint optimisation, that KAN-PnP outperforms exiting\nmethods, delivering superior performance in single-shot learning with minimal\ndata. The method exhibits strong convergence properties, achieving high\naccuracy with fewer iterations.", "AI": {"tldr": "KAN-PnP introduces Kolmogorov-Arnold Networks (KANs) as denoisers in the Plug-and-Play framework for solving inverse problems with single-instance priors, outperforming existing methods in single-shot learning.", "motivation": "Traditional denoising methods require large datasets, but KAN-PnP addresses the challenge of solving inverse problems with only a single noisy observation.", "method": "KAN-PnP incorporates KANs as denoisers within the PnP paradigm, leveraging their Lipschitz continuity and theoretical guarantees for stable optimisation.", "result": "KAN-PnP outperforms existing methods in super-resolution and joint optimisation, achieving high accuracy with fewer iterations.", "conclusion": "KAN-PnP provides a robust, data-efficient solution for inverse problems, with strong convergence properties and superior performance in single-shot learning."}}
{"id": "2408.11433", "pdf": "https://arxiv.org/pdf/2408.11433", "abs": "https://arxiv.org/abs/2408.11433", "authors": ["Haoxuan Ji", "Zheng Lin", "Yuyao Sun", "Gao Fei", "Yuhang Wang", "Haichang Gao", "Zhenxing Niu"], "title": "Towards Aligned Data Removal via Twin Machine Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern privacy regulations have spurred the evolution of machine unlearning,\na technique that enables the removal of data from an already trained ML model\nwithout requiring retraining from scratch. Previous unlearning methods tend to\ninduce the model to achieve lowest classification accuracy on the removal data.\nNonetheless, the authentic objective of machine unlearning is to align the\nunlearned model with the gold model, i.e., achieving the same classification\naccuracy as the gold model. For this purpose, we present a Twin Machine\nUnlearning (TMU) approach, where a twin unlearning problem is defined\ncorresponding to the original unlearning problem. As a results, the\ngeneralization-label predictor trained on the twin problem can be transferred\nto the original problem, facilitating aligned data removal. Comprehensive\nempirical experiments illustrate that our approach significantly enhances the\nalignment between the unlearned model and the gold model. Meanwhile, our method\nallows data removal without compromising the model accuracy.", "AI": {"tldr": "The paper introduces Twin Machine Unlearning (TMU), a method to align unlearned models with gold models by defining a twin unlearning problem, improving accuracy and data removal efficiency.", "motivation": "Modern privacy regulations require efficient data removal from trained ML models without retraining, but existing methods misalign unlearned models with gold models.", "method": "Proposes TMU, defining a twin unlearning problem to transfer a generalization-label predictor to the original problem, ensuring aligned data removal.", "result": "TMU significantly improves alignment between unlearned and gold models while maintaining model accuracy.", "conclusion": "TMU offers an effective solution for privacy-compliant machine unlearning by aligning models and preserving accuracy."}}
{"id": "2505.00730", "pdf": "https://arxiv.org/pdf/2505.00730", "abs": "https://arxiv.org/abs/2505.00730", "authors": ["Marius-Constantin Dinu"], "title": "Primality Testing via Circulant Matrix Eigenvalue Structure: A Novel Approach Using Cyclotomic Field Theory", "categories": ["cs.SC", "cs.LG"], "comment": "27 pages, 5 figures, 2 tables; This paper was created with AI\n  assistance using Symbia Engine from SymbolicAI Framework [Dinu et al.];\n  Repository: https://github.com/ExtensityAI/primality_test", "summary": "This paper presents a novel primality test based on the eigenvalue structure\nof circulant matrices constructed from roots of unity. We prove that an integer\n$n > 2$ is prime if and only if the minimal polynomial of the circulant matrix\n$C_n = W_n + W_n^2$ has exactly two irreducible factors over $\\mathbb{Q}$. This\ncharacterization connects cyclotomic field theory with matrix algebra,\nproviding both theoretical insights and practical applications. We demonstrate\nthat the eigenvalue patterns of these matrices reveal fundamental distinctions\nbetween prime and composite numbers, leading to a deterministic primality test.\nOur approach leverages the relationship between primitive roots of unity,\nGalois theory, and the factorization of cyclotomic polynomials. We provide\ncomprehensive experimental validation across various ranges of integers,\ndiscuss practical implementation considerations, and analyze the computational\ncomplexity of our method in comparison with established primality tests. The\nvisual interpretation of our mathematical framework provides intuitive\nunderstanding of the algebraic structures that distinguish prime numbers. Our\nexperimental validation demonstrates that our approach offers a deterministic\nalternative to existing methods, with performance characteristics reflecting\nits algebraic foundations.", "AI": {"tldr": "A novel primality test using circulant matrices and roots of unity, linking cyclotomic field theory and matrix algebra to distinguish primes from composites.", "motivation": "To develop a deterministic primality test by leveraging the eigenvalue structure of circulant matrices and cyclotomic field theory.", "method": "Construct circulant matrices from roots of unity; analyze their minimal polynomials and eigenvalue patterns to determine primality.", "result": "An integer is prime if its circulant matrix's minimal polynomial has exactly two irreducible factors over \u211a.", "conclusion": "The method provides a deterministic primality test with theoretical and practical insights, validated experimentally."}}
{"id": "2501.18851", "pdf": "https://arxiv.org/pdf/2501.18851", "abs": "https://arxiv.org/abs/2501.18851", "authors": ["Xiaoyan Jiang", "Bohan Wang", "Xinlong Wan", "Shanshan Chen", "Hamido Fujita", "Hanan Abd. Al Juaid"], "title": "Project-and-Fuse: Improving RGB-D Semantic Segmentation via Graph Convolution Networks", "categories": ["cs.CV"], "comment": "I have decided to withdraw this paper because I have recently\n  obtained some new data and insights during my ongoing research", "summary": "Most existing RGB-D semantic segmentation methods focus on the feature level\nfusion, including complex cross-modality and cross-scale fusion modules.\nHowever, these methods may cause misalignment problem in the feature fusion\nprocess and counter-intuitive patches in the segmentation results. Inspired by\nthe popular pixel-node-pixel pipeline, we propose to 1) fuse features from two\nmodalities in a late fusion style, during which the geometric feature injection\nis guided by texture feature prior; 2) employ Graph Neural Networks (GNNs) on\nthe fused feature to alleviate the emergence of irregular patches by inferring\npatch relationship. At the 3D feature extraction stage, we argue that\ntraditional CNNs are not efficient enough for depth maps. So, we encode depth\nmap into normal map, after which CNNs can easily extract object surface\ntendencies.At projection matrix generation stage, we find the existence of\nBiased-Assignment and Ambiguous-Locality issues in the original pipeline.\nTherefore, we propose to 1) adopt the Kullback-Leibler Loss to ensure no\nmissing important pixel features, which can be viewed as hard pixel mining\nprocess; 2) connect regions that are close to each other in the Euclidean space\nas well as in the semantic space with larger edge weights so that location\ninformations can been considered. Extensive experiments on two public datasets,\nNYU-DepthV2 and SUN RGB-D, have shown that our approach can consistently boost\nthe performance of RGB-D semantic segmentation task.", "AI": {"tldr": "The paper proposes a late fusion method for RGB-D semantic segmentation, addressing misalignment and irregular patches by using GNNs and optimizing depth feature extraction and projection matrix generation.", "motivation": "Existing methods suffer from misalignment and irregular patches due to complex feature fusion, and inefficient depth map processing.", "method": "Late fusion guided by texture feature prior, GNNs for patch relationship inference, depth map encoding into normal maps, and improved projection matrix generation with Kullback-Leibler Loss and edge weighting.", "result": "Improved performance on NYU-DepthV2 and SUN RGB-D datasets.", "conclusion": "The proposed method effectively addresses key issues in RGB-D semantic segmentation, enhancing accuracy and consistency."}}
{"id": "2409.04744", "pdf": "https://arxiv.org/pdf/2409.04744", "abs": "https://arxiv.org/abs/2409.04744", "authors": ["Yongxin Deng", "Xihe Qiu", "Jue Chen", "Xiaoyu Tan"], "title": "Reward Guidance for Reinforcement Learning Tasks Based on Large Language Models: The LMGT Framework", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The inherent uncertainty in the environmental transition model of\nReinforcement Learning (RL) necessitates a delicate balance between exploration\nand exploitation. This balance is crucial for optimizing computational\nresources to accurately estimate expected rewards for the agent. In scenarios\nwith sparse rewards, such as robotic control systems, achieving this balance is\nparticularly challenging. However, given that many environments possess\nextensive prior knowledge, learning from the ground up in such contexts may be\nredundant. To address this issue, we propose Language Model Guided reward\nTuning (LMGT), a novel, sample-efficient framework. LMGT leverages the\ncomprehensive prior knowledge embedded in Large Language Models (LLMs) and\ntheir proficiency in processing non-standard data forms, such as wiki\ntutorials. By utilizing LLM-guided reward shifts, LMGT adeptly balances\nexploration and exploitation, thereby guiding the agent's exploratory behavior\nand enhancing sample efficiency. We have rigorously evaluated LMGT across\nvarious RL tasks and evaluated it in the embodied robotic environment\nHousekeep. Our results demonstrate that LMGT consistently outperforms baseline\nmethods. Furthermore, the findings suggest that our framework can substantially\nreduce the computational resources required during the RL training phase.", "AI": {"tldr": "LMGT is a sample-efficient RL framework that uses LLMs to guide reward tuning, balancing exploration and exploitation, and reducing computational resources.", "motivation": "Addressing the challenge of balancing exploration and exploitation in RL, especially in sparse-reward environments, by leveraging prior knowledge from LLMs.", "method": "Proposes LMGT, which uses LLMs to guide reward shifts, improving exploratory behavior and sample efficiency.", "result": "LMGT outperforms baseline methods in RL tasks and reduces computational resource usage.", "conclusion": "LMGT effectively leverages LLMs to enhance RL performance and efficiency."}}
{"id": "2505.00763", "pdf": "https://arxiv.org/pdf/2505.00763", "abs": "https://arxiv.org/abs/2505.00763", "authors": ["Sung Hak Lim", "Kohei Hayashi", "Shun'ichi Horigome", "Shigeki Matsumoto", "Mihoko M. Nojiri"], "title": "JFlow: Model-Independent Spherical Jeans Analysis using Equivariant Continuous Normalizing Flows", "categories": ["astro-ph.GA", "astro-ph.CO", "cs.LG", "hep-ex", "hep-ph"], "comment": "9 pages, 3 figures, 1 table", "summary": "The kinematics of stars in dwarf spheroidal galaxies have been studied to\nunderstand the structure of dark matter halos. However, the kinematic\ninformation of these stars is often limited to celestial positions and\nline-of-sight velocities, making full phase space analysis challenging.\nConventional methods rely on projected analytic phase space density models with\nseveral parameters and infer dark matter halo structures by solving the\nspherical Jeans equation. In this paper, we introduce an unsupervised machine\nlearning method for solving the spherical Jeans equation in a model-independent\nway as a first step toward model-independent analysis of dwarf spheroidal\ngalaxies. Using equivariant continuous normalizing flows, we demonstrate that\nspherically symmetric stellar phase space densities and velocity dispersions\ncan be estimated without model assumptions. As a proof of concept, we apply our\nmethod to Gaia challenge datasets for spherical models and measure dark matter\nmass densities given velocity anisotropy profiles. Our method can identify halo\nstructures accurately, even with a small number of tracer stars.", "AI": {"tldr": "The paper introduces an unsupervised machine learning method to analyze dark matter halos in dwarf spheroidal galaxies without relying on model assumptions, using equivariant continuous normalizing flows.", "motivation": "Limited kinematic data of stars in dwarf spheroidal galaxies makes full phase space analysis challenging, and conventional methods rely on restrictive models.", "method": "The authors use equivariant continuous normalizing flows to solve the spherical Jeans equation in a model-independent way, estimating stellar phase space densities and velocity dispersions.", "result": "The method accurately identifies dark matter halo structures, even with sparse data, as demonstrated on Gaia challenge datasets.", "conclusion": "This approach enables model-independent analysis of dwarf spheroidal galaxies, improving dark matter halo structure inference."}}
{"id": "2503.01284", "pdf": "https://arxiv.org/pdf/2503.01284", "abs": "https://arxiv.org/abs/2503.01284", "authors": ["Md Abrar Jahin", "Soudeep Shahriar", "M. F. Mridha", "Md. Jakir Hossen", "Nilanjan Dey"], "title": "Soybean Disease Detection via Interpretable Hybrid CNN-GNN: Integrating MobileNetV2 and GraphSAGE with Cross-Modal Attention", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Soybean leaf disease detection is critical for agricultural productivity but\nfaces challenges due to visually similar symptoms and limited interpretability\nin conventional methods. While Convolutional Neural Networks (CNNs) excel in\nspatial feature extraction, they often neglect inter-image relational\ndependencies, leading to misclassifications. This paper proposes an\ninterpretable hybrid Sequential CNN-Graph Neural Network (GNN) framework that\nsynergizes MobileNetV2 for localized feature extraction and GraphSAGE for\nrelational modeling. The framework constructs a graph where nodes represent\nleaf images, with edges defined by cosine similarity-based adjacency matrices\nand adaptive neighborhood sampling. This design captures fine-grained lesion\nfeatures and global symptom patterns, addressing inter-class similarity\nchallenges. Cross-modal interpretability is achieved via Grad-CAM and Eigen-CAM\nvisualizations, generating heatmaps to highlight disease-influential regions.\nEvaluated on a dataset of ten soybean leaf diseases, the model achieves\n$97.16\\%$ accuracy, surpassing standalone CNNs ($\\le95.04\\%$) and traditional\nmachine learning models ($\\le77.05\\%$). Ablation studies validate the\nsequential architecture's superiority over parallel or single-model\nconfigurations. With only 2.3 million parameters, the lightweight\nMobileNetV2-GraphSAGE combination ensures computational efficiency, enabling\nreal-time deployment in resource-constrained environments. The proposed\napproach bridges the gap between accurate classification and practical\napplicability, offering a robust, interpretable tool for agricultural\ndiagnostics while advancing CNN-GNN integration in plant pathology research.", "AI": {"tldr": "A hybrid Sequential CNN-GNN framework for soybean leaf disease detection achieves high accuracy (97.16%) and interpretability by combining MobileNetV2 for feature extraction and GraphSAGE for relational modeling.", "motivation": "Challenges in soybean leaf disease detection include visually similar symptoms and limited interpretability in conventional methods, prompting the need for a more accurate and interpretable solution.", "method": "Proposes a hybrid Sequential CNN-GNN framework using MobileNetV2 for localized feature extraction and GraphSAGE for relational modeling, with cosine similarity-based adjacency matrices and adaptive neighborhood sampling.", "result": "Achieves 97.16% accuracy, outperforming standalone CNNs (\u226495.04%) and traditional ML models (\u226477.05%), with only 2.3 million parameters for computational efficiency.", "conclusion": "The framework bridges accuracy and practicality, offering a robust, interpretable tool for agricultural diagnostics and advancing CNN-GNN integration in plant pathology."}}
{"id": "2410.08067", "pdf": "https://arxiv.org/pdf/2410.08067", "abs": "https://arxiv.org/abs/2410.08067", "authors": ["Shenao Zhang", "Zhihan Liu", "Boyi Liu", "Yufeng Zhang", "Yingxiang Yang", "Yongfei Liu", "Liyu Chen", "Tao Sun", "Zhaoran Wang"], "title": "Reward-Augmented Data Enhances Direct Preference Alignment of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "Published at ICML 2025", "summary": "Preference alignment in Large Language Models (LLMs) has significantly\nimproved their ability to adhere to human instructions and intentions. However,\nexisting direct alignment algorithms primarily focus on relative preferences\nand often overlook the qualitative aspects of responses, despite having access\nto preference data that includes reward scores from judge models during AI\nfeedback. Striving to maximize the implicit reward gap between the chosen and\nthe slightly inferior rejected responses can cause overfitting and unnecessary\nunlearning of the high-quality rejected responses. The unawareness of the\nreward scores also drives the LLM to indiscriminately favor the low-quality\nchosen responses and fail to generalize to optimal responses that are sparse in\ndata. To overcome these shortcomings, our study introduces reward-conditioned\nLLM policies that discern and learn from the entire spectrum of response\nquality within the dataset, helping extrapolate to more optimal regions. We\npropose an effective yet simple data relabeling method that conditions the\npreference pairs on quality scores to construct a reward-augmented dataset. The\nexperiments across various benchmarks and diverse models demonstrate that our\napproach consistently boosts DPO by a considerable margin. Through\ncomprehensive ablation studies, we demonstrate that our method not only\nmaximizes the utility of preference data but also mitigates the issue of\nunlearning, demonstrating its broad effectiveness beyond mere data expansion.\nOur code is available at\nhttps://github.com/shenao-zhang/reward-augmented-preference.", "AI": {"tldr": "The paper introduces reward-conditioned LLM policies to improve preference alignment by leveraging qualitative aspects of responses, addressing overfitting and unlearning issues in existing methods.", "motivation": "Existing alignment algorithms focus on relative preferences and ignore qualitative aspects, leading to overfitting and poor generalization.", "method": "Proposes reward-conditioned LLM policies and a data relabeling method to construct a reward-augmented dataset.", "result": "Experiments show the method consistently outperforms DPO, maximizing utility of preference data and mitigating unlearning.", "conclusion": "The approach effectively improves preference alignment and generalizes better, demonstrating broad effectiveness."}}
{"id": "2505.00779", "pdf": "https://arxiv.org/pdf/2505.00779", "abs": "https://arxiv.org/abs/2505.00779", "authors": ["Junwon Seo", "Kensuke Nakamura", "Andrea Bajcsy"], "title": "Uncertainty-aware Latent Safety Filters for Avoiding Out-of-Distribution Failures", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Recent advances in generative world models have enabled classical safe\ncontrol methods, such as Hamilton-Jacobi (HJ) reachability, to generalize to\ncomplex robotic systems operating directly from high-dimensional sensor\nobservations. However, obtaining comprehensive coverage of all safety-critical\nscenarios during world model training is extremely challenging. As a result,\nlatent safety filters built on top of these models may miss novel hazards and\neven fail to prevent known ones, overconfidently misclassifying risky\nout-of-distribution (OOD) situations as safe. To address this, we introduce an\nuncertainty-aware latent safety filter that proactively steers robots away from\nboth known and unseen failures. Our key idea is to use the world model's\nepistemic uncertainty as a proxy for identifying unseen potential hazards. We\npropose a principled method to detect OOD world model predictions by\ncalibrating an uncertainty threshold via conformal prediction. By performing\nreachability analysis in an augmented state space-spanning both the latent\nrepresentation and the epistemic uncertainty-we synthesize a latent safety\nfilter that can reliably safeguard arbitrary policies from both known and\nunseen safety hazards. In simulation and hardware experiments on vision-based\ncontrol tasks with a Franka manipulator, we show that our uncertainty-aware\nsafety filter preemptively detects potential unsafe scenarios and reliably\nproposes safe, in-distribution actions. Video results can be found on the\nproject website at https://cmu-intentlab.github.io/UNISafe", "AI": {"tldr": "The paper introduces an uncertainty-aware latent safety filter to prevent robots from encountering known and unseen hazards by leveraging epistemic uncertainty and conformal prediction.", "motivation": "Existing latent safety filters may miss novel hazards or fail to prevent known ones due to incomplete coverage of safety-critical scenarios during world model training.", "method": "The method uses epistemic uncertainty as a proxy for hazards, calibrates an uncertainty threshold via conformal prediction, and performs reachability analysis in an augmented state space.", "result": "The uncertainty-aware safety filter reliably detects unsafe scenarios and proposes safe actions in simulation and hardware experiments with a Franka manipulator.", "conclusion": "The proposed filter effectively safeguards arbitrary policies from both known and unseen safety hazards, as demonstrated in vision-based control tasks."}}
{"id": "2504.02782", "pdf": "https://arxiv.org/pdf/2504.02782", "abs": "https://arxiv.org/abs/2504.02782", "authors": ["Zhiyuan Yan", "Junyan Ye", "Weijia Li", "Zilong Huang", "Shenghai Yuan", "Xiangyang He", "Kaiqing Lin", "Jun He", "Conghui He", "Li Yuan"], "title": "GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "The recent breakthroughs in OpenAI's GPT4o model have demonstrated\nsurprisingly good capabilities in image generation and editing, resulting in\nsignificant excitement in the community. This technical report presents the\nfirst-look evaluation benchmark (named GPT-ImgEval), quantitatively and\nqualitatively diagnosing GPT-4o's performance across three critical dimensions:\n(1) generation quality, (2) editing proficiency, and (3) world\nknowledge-informed semantic synthesis. Across all three tasks, GPT-4o\ndemonstrates strong performance, significantly surpassing existing methods in\nboth image generation control and output quality, while also showcasing\nexceptional knowledge reasoning capabilities. Furthermore, based on the\nGPT-4o's generated data, we propose a classification-model-based approach to\ninvestigate the underlying architecture of GPT-4o, where our empirical results\nsuggest the model consists of an auto-regressive (AR) combined with a\ndiffusion-based head for image decoding, rather than the VAR-like\narchitectures. We also provide a complete speculation on GPT-4o's overall\narchitecture. In addition, we conduct a series of analyses to identify and\nvisualize GPT-4o's specific limitations and the synthetic artifacts commonly\nobserved in its image generation. We also present a comparative study of\nmulti-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the\nsafety implications of GPT-4o's outputs, particularly their detectability by\nexisting image forensic models. We hope that our work can offer valuable\ninsight and provide a reliable benchmark to guide future research, foster\nreproducibility, and accelerate innovation in the field of image generation and\nbeyond. The codes and datasets used for evaluating GPT-4o can be found at\nhttps://github.com/PicoTrex/GPT-ImgEval.", "AI": {"tldr": "The paper introduces GPT-ImgEval, a benchmark for evaluating GPT-4o's image generation and editing capabilities, revealing its strong performance and unique architecture.", "motivation": "To quantitatively and qualitatively assess GPT-4o's capabilities in image generation, editing, and semantic synthesis, and to understand its underlying architecture.", "method": "Proposes GPT-ImgEval benchmark, evaluates GPT-4o across three tasks, and uses classification-model-based analysis to speculate on its architecture.", "result": "GPT-4o outperforms existing methods in image generation and editing, with evidence suggesting an AR-diffusion hybrid architecture.", "conclusion": "The work provides insights into GPT-4o's strengths and limitations, offering a benchmark for future research in image generation."}}
{"id": "2410.11502", "pdf": "https://arxiv.org/pdf/2410.11502", "abs": "https://arxiv.org/abs/2410.11502", "authors": ["Rong-Xi Tan", "Ke Xue", "Shen-Huan Lyu", "Haopu Shang", "Yao Wang", "Yaoyuan Wang", "Sheng Fu", "Chao Qian"], "title": "Offline Model-Based Optimization by Learning to Rank", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "ICLR 2025", "summary": "Offline model-based optimization (MBO) aims to identify a design that\nmaximizes a black-box function using only a fixed, pre-collected dataset of\ndesigns and their corresponding scores. A common approach in offline MBO is to\ntrain a regression-based surrogate model by minimizing mean squared error (MSE)\nand then find the best design within this surrogate model by different\noptimizers (e.g., gradient ascent). However, a critical challenge is the risk\nof out-of-distribution errors, i.e., the surrogate model may typically\noverestimate the scores and mislead the optimizers into suboptimal regions.\nPrior works have attempted to address this issue in various ways, such as using\nregularization techniques and ensemble learning to enhance the robustness of\nthe model, but it still remains. In this paper, we argue that regression models\ntrained with MSE are not well-aligned with the primary goal of offline MBO,\nwhich is to select promising designs rather than to predict their scores\nprecisely. Notably, if a surrogate model can maintain the order of candidate\ndesigns based on their relative score relationships, it can produce the best\ndesigns even without precise predictions. To validate it, we conduct\nexperiments to compare the relationship between the quality of the final\ndesigns and MSE, finding that the correlation is really very weak. In contrast,\na metric that measures order-maintaining quality shows a significantly stronger\ncorrelation. Based on this observation, we propose learning a ranking-based\nmodel that leverages learning to rank techniques to prioritize promising\ndesigns based on their relative scores. We show that the generalization error\non ranking loss can be well bounded. Empirical results across diverse tasks\ndemonstrate the superior performance of our proposed ranking-based models than\ntwenty existing methods.", "AI": {"tldr": "The paper proposes a ranking-based model for offline model-based optimization (MBO) to address out-of-distribution errors in surrogate models, showing better performance than traditional regression-based methods.", "motivation": "Traditional regression-based surrogate models in offline MBO often overestimate scores, leading to suboptimal designs. The paper argues that precise score prediction is unnecessary if the model maintains the relative order of designs.", "method": "The authors propose a ranking-based model using learning-to-rank techniques to prioritize designs based on relative scores, rather than minimizing mean squared error (MSE).", "result": "Experiments show weak correlation between MSE and final design quality, while ranking-based metrics correlate strongly. The proposed model outperforms 20 existing methods across diverse tasks.", "conclusion": "Ranking-based models align better with offline MBO goals, offering superior performance by focusing on relative design order rather than precise score prediction."}}
{"id": "2505.00782", "pdf": "https://arxiv.org/pdf/2505.00782", "abs": "https://arxiv.org/abs/2505.00782", "authors": ["Max M. Chumley", "Firas A. Khasawneh"], "title": "Dynamical System Parameter Path Optimization using Persistent Homology", "categories": ["math.DS", "cs.LG", "math.AT"], "comment": "18 pages, 24 figures", "summary": "Nonlinear dynamical systems are complex and typically only simple systems can\nbe analytically studied. In applications, these systems are usually defined\nwith a set of tunable parameters and as the parameters are varied the system\nresponse undergoes significant topological changes or bifurcations. In a high\ndimensional parameter space, it is difficult to determine which direction to\nvary the system parameters to achieve a desired system response or state. In\nthis paper, we introduce a new approach for optimally navigating a dynamical\nsystem parameter space that is rooted in topological data analysis.\nSpecifically we use the differentiability of persistence diagrams to define a\ntopological language for intuitively promoting or deterring different\ntopological features in the state space response of a dynamical system and use\ngradient descent to optimally move from one point in the parameter space to\nanother. The end result is a path in this space that guides the system to a set\nof parameters that yield the desired topological features defined by the loss\nfunction. We show a number of examples by applying the methods to different\ndynamical systems and scenarios to demonstrate how to promote different\nfeatures and how to choose the hyperparameters to achieve different outcomes.", "AI": {"tldr": "A new method using topological data analysis and gradient descent to navigate parameter spaces of nonlinear dynamical systems for desired topological features.", "motivation": "High-dimensional parameter spaces make it hard to guide system responses; a systematic approach is needed.", "method": "Uses persistence diagrams' differentiability and gradient descent to define paths in parameter space.", "result": "Demonstrates successful navigation to achieve desired topological features in various dynamical systems.", "conclusion": "The approach effectively guides parameter adjustments for targeted system responses."}}
{"id": "2504.09149", "pdf": "https://arxiv.org/pdf/2504.09149", "abs": "https://arxiv.org/abs/2504.09149", "authors": ["Changhao Li", "Yu Xin", "Xiaowei Zhou", "Ariel Shamir", "Hao Zhang", "Ligang Liu", "Ruizhen Hu"], "title": "MASH: Masked Anchored SpHerical Distances for 3D Shape Representation and Generation", "categories": ["cs.CV", "cs.CG"], "comment": "11 pages, 11 figures, SIGGRAPH 2025 Accept - Conference", "summary": "We introduce Masked Anchored SpHerical Distances (MASH), a novel multi-view\nand parametrized representation of 3D shapes. Inspired by multi-view geometry\nand motivated by the importance of perceptual shape understanding for learning\n3D shapes, MASH represents a 3D shape as a collection of observable local\nsurface patches, each defined by a spherical distance function emanating from\nan anchor point. We further leverage the compactness of spherical harmonics to\nencode the MASH functions, combined with a generalized view cone with a\nparameterized base that masks the spatial extent of the spherical function to\nattain locality. We develop a differentiable optimization algorithm capable of\nconverting any point cloud into a MASH representation accurately approximating\nground-truth surfaces with arbitrary geometry and topology. Extensive\nexperiments demonstrate that MASH is versatile for multiple applications\nincluding surface reconstruction, shape generation, completion, and blending,\nachieving superior performance thanks to its unique representation encompassing\nboth implicit and explicit features.", "AI": {"tldr": "MASH is a novel 3D shape representation using spherical distance functions from anchor points, combining implicit and explicit features for versatile applications like reconstruction and generation.", "motivation": "The paper aims to improve perceptual shape understanding by representing 3D shapes as observable local surface patches, leveraging multi-view geometry.", "method": "MASH encodes spherical distance functions with spherical harmonics and uses a parameterized view cone for locality. A differentiable algorithm converts point clouds into MASH representations.", "result": "MASH achieves superior performance in surface reconstruction, shape generation, completion, and blending.", "conclusion": "MASH's unique representation, combining implicit and explicit features, makes it versatile and effective for various 3D shape applications."}}
{"id": "2410.19982", "pdf": "https://arxiv.org/pdf/2410.19982", "abs": "https://arxiv.org/abs/2410.19982", "authors": ["Weiqin Chen", "Santiago Paternain"], "title": "Random Policy Enables In-Context Reinforcement Learning within Trust Horizons", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Pretrained foundation models have exhibited extraordinary in-context learning\nperformance, allowing zero-shot generalization to new tasks not encountered\nduring pretraining. In the case of reinforcement learning (RL), in-context RL\n(ICRL) emerges when pretraining FMs on decision-making problems in an\nautoregressive-supervised manner. Nevertheless, current state-of-the-art ICRL\nalgorithms, like Algorithm Distillation, Decision Pretrained Transformer and\nDecision Importance Transformer, impose stringent requirements on the\npretraining dataset concerning the source policies, context information, and\naction labels. Notably, these algorithms either demand optimal policies or\nrequire varying degrees of well-trained behavior policies for all pretraining\nenvironments. This significantly hinders the application of ICRL to real-world\nscenarios, where acquiring optimal or well-trained policies for a substantial\nvolume of real-world training environments can be intractable. To overcome this\nchallenge, we introduce a novel approach, termed State-Action Distillation\n(SAD), that allows to generate an effective pretraining dataset guided solely\nby random policies. In particular, SAD selects query states and corresponding\naction labels by distilling outstanding state-action pairs from the entire\nstate and action spaces by using random policies within a trust horizon, and\nthen inherits the classical autoregressive-supervised mechanism during\npretraining. To the best of our knowledge, this is the first work that enables\neffective ICRL under random policies and random contexts. We also establish\nquantitative analysis of the trustworthiness as well as the performance\nguarantees of SAD. Moreover, our empirical results across multiple popular ICRL\nbenchmark environments demonstrate that, on average, SAD outperforms the best\nbaseline by 236.3% in the offline evaluation and by 135.2% in the online\nevaluation.", "AI": {"tldr": "SAD enables effective in-context reinforcement learning (ICRL) using random policies, outperforming baselines by 236.3% offline and 135.2% online.", "motivation": "Current ICRL methods require optimal or well-trained policies, limiting real-world applicability. SAD addresses this by working with random policies.", "method": "SAD selects state-action pairs from random policies within a trust horizon and uses autoregressive-supervised pretraining.", "result": "SAD outperforms baselines by 236.3% offline and 135.2% online, proving its effectiveness with random policies.", "conclusion": "SAD is a novel, practical solution for ICRL, enabling performance without reliance on optimal policies."}}
{"id": "2505.00816", "pdf": "https://arxiv.org/pdf/2505.00816", "abs": "https://arxiv.org/abs/2505.00816", "authors": ["Santiago del Rey", "Paulo S\u00e9rgio Medeiros dos Santos", "Guilherme Horta Travassos", "Xavier Franch", "Silverio Mart\u00ednez-Fern\u00e1ndez"], "title": "Aggregating empirical evidence from data strategy studies: a case on model quantization", "categories": ["cs.SE", "cs.LG"], "comment": "11 pages, 3 figures, submitted to the 19th ACM/IEEE International\n  Symposium on Empirical Software Engineering and Measurement (ESEM)", "summary": "Background: As empirical software engineering evolves, more studies adopt\ndata strategies$-$approaches that investigate digital artifacts such as models,\nsource code, or system logs rather than relying on human subjects. Synthesizing\nresults from such studies introduces new methodological challenges.\n  Aims: This study assesses the effects of model quantization on correctness\nand resource efficiency in deep learning (DL) systems. Additionally, it\nexplores the methodological implications of aggregating evidence from empirical\nstudies that adopt data strategies.\n  Method: We conducted a research synthesis of six primary studies that\nempirically evaluate model quantization. We applied the Structured Synthesis\nMethod (SSM) to aggregate the findings, which combines qualitative and\nquantitative evidence through diagrammatic modeling. A total of 19 evidence\nmodels were extracted and aggregated.\n  Results: The aggregated evidence indicates that model quantization weakly\nnegatively affects correctness metrics while consistently improving resource\nefficiency metrics, including storage size, inference latency, and GPU energy\nconsumption$-$a manageable trade-off for many DL deployment contexts. Evidence\nacross quantization techniques remains fragmented, underscoring the need for\nmore focused empirical studies per technique.\n  Conclusions: Model quantization offers substantial efficiency benefits with\nminor trade-offs in correctness, making it a suitable optimization strategy for\nresource-constrained environments. This study also demonstrates the feasibility\nof using SSM to synthesize findings from data strategy-based research.", "AI": {"tldr": "The study evaluates model quantization in DL systems, finding it improves efficiency with minor correctness trade-offs, and demonstrates SSM's feasibility for synthesizing data-strategy research.", "motivation": "To assess the impact of model quantization on DL system correctness and efficiency, and explore methodological challenges in synthesizing data-strategy studies.", "method": "Research synthesis of six primary studies using the Structured Synthesis Method (SSM) to aggregate qualitative and quantitative evidence via diagrammatic modeling.", "result": "Quantization weakly harms correctness but consistently boosts efficiency (storage, latency, GPU energy). Evidence remains fragmented across techniques.", "conclusion": "Quantization is viable for resource-constrained DL deployments, and SSM effectively synthesizes data-strategy research findings."}}
{"id": "2504.15122", "pdf": "https://arxiv.org/pdf/2504.15122", "abs": "https://arxiv.org/abs/2504.15122", "authors": ["Minh-Quan Viet Bui", "Jongmin Park", "Juan Luis Gonzalez Bello", "Jaeho Moon", "Jihyong Oh", "Munchurl Kim"], "title": "MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video", "categories": ["cs.CV"], "comment": "The first two authors contributed equally to this work (equal\n  contribution). The last two authors are co-corresponding authors. Please\n  visit our project page at https://kaist-viclab.github.io/mobgs-site/", "summary": "We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS)\nframework capable of reconstructing sharp and high-quality novel\nspatio-temporal views from blurry monocular videos in an end-to-end manner.\nExisting dynamic novel view synthesis (NVS) methods are highly sensitive to\nmotion blur in casually captured videos, resulting in significant degradation\nof rendering quality. While recent approaches address motion-blurred inputs for\nNVS, they primarily focus on static scene reconstruction and lack dedicated\nmotion modeling for dynamic objects. To overcome these limitations, our MoBGS\nintroduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for\neffective latent camera trajectory estimation, improving global camera motion\ndeblurring. In addition, we propose a physically-inspired Latent Camera-induced\nExposure Estimation (LCEE) method to ensure consistent deblurring of both\nglobal camera and local object motion. Our MoBGS framework ensures the temporal\nconsistency of unseen latent timestamps and robust motion decomposition of\nstatic and dynamic regions. Extensive experiments on the Stereo Blur dataset\nand real-world blurry videos show that our MoBGS significantly outperforms the\nvery recent advanced methods (DyBluRF and Deblur4DGS), achieving\nstate-of-the-art performance for dynamic NVS under motion blur.", "AI": {"tldr": "MoBGS is a new framework for deblurring dynamic 3D Gaussian Splatting, improving sharp and high-quality novel view synthesis from blurry monocular videos.", "motivation": "Existing dynamic novel view synthesis methods struggle with motion blur in videos, degrading rendering quality. Current solutions focus on static scenes, lacking dynamic object motion modeling.", "method": "MoBGS introduces Blur-adaptive Latent Camera Estimation (BLCE) for camera motion deblurring and Latent Camera-induced Exposure Estimation (LCEE) for consistent deblurring of camera and object motion.", "result": "MoBGS outperforms recent methods (DyBluRF, Deblur4DGS) on the Stereo Blur dataset and real-world videos, achieving state-of-the-art performance.", "conclusion": "MoBGS effectively addresses motion blur in dynamic scenes, ensuring temporal consistency and robust motion decomposition."}}
{"id": "2410.20027", "pdf": "https://arxiv.org/pdf/2410.20027", "abs": "https://arxiv.org/abs/2410.20027", "authors": ["Shihao Cai", "Jizhi Zhang", "Keqin Bao", "Chongming Gao", "Qifan Wang", "Fuli Feng", "Xiangnan He"], "title": "Agentic Feedback Loop Modeling Improves Recommendation and User Simulation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Large language model-based agents are increasingly applied in the\nrecommendation field due to their extensive knowledge and strong planning\ncapabilities. While prior research has primarily focused on enhancing either\nthe recommendation agent or the user agent individually, the collaborative\ninteraction between the two has often been overlooked. Towards this research\ngap, we propose a novel framework that emphasizes the feedback loop process to\nfacilitate the collaboration between the recommendation agent and the user\nagent. Specifically, the recommendation agent refines its understanding of user\npreferences by analyzing the feedback from the user agent on the item\nrecommendation. Conversely, the user agent further identifies potential user\ninterests based on the items and recommendation reasons provided by the\nrecommendation agent. This iterative process enhances the ability of both\nagents to infer user behaviors, enabling more effective item recommendations\nand more accurate user simulations. Extensive experiments on three datasets\ndemonstrate the effectiveness of the agentic feedback loop: the agentic\nfeedback loop yields an average improvement of 11.52% over the single\nrecommendation agent and 21.12% over the single user agent. Furthermore, the\nresults show that the agentic feedback loop does not exacerbate popularity or\nposition bias, which are typically amplified by the real-world feedback loop,\nhighlighting its robustness. The source code is available at\nhttps://github.com/Lanyu0303/AFL.", "AI": {"tldr": "A novel framework introduces a feedback loop between recommendation and user agents to enhance collaboration, improving recommendation accuracy and user simulation by 11.52% and 21.12%, respectively, without exacerbating biases.", "motivation": "Prior research overlooked collaborative interaction between recommendation and user agents, prompting the need for a framework emphasizing their feedback loop.", "method": "The framework involves iterative feedback: the recommendation agent refines user preferences from user feedback, while the user agent identifies interests from recommendations.", "result": "Experiments show 11.52% and 21.12% improvements over single agents, with no increase in biases like popularity or position bias.", "conclusion": "The agentic feedback loop effectively enhances collaboration between agents, improving performance without introducing common biases."}}
{"id": "2505.00822", "pdf": "https://arxiv.org/pdf/2505.00822", "abs": "https://arxiv.org/abs/2505.00822", "authors": ["Yao Song", "Kelly Speth", "Amy Kilbourne", "Andrew Quanbeck", "Daniel Almirall", "Lu Wang"], "title": "Q-Learning with Clustered-SMART (cSMART) Data: Examining Moderators in the Construction of Clustered Adaptive Interventions", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "A clustered adaptive intervention (cAI) is a pre-specified sequence of\ndecision rules that guides practitioners on how best - and based on which\nmeasures - to tailor cluster-level intervention to improve outcomes at the\nlevel of individuals within the clusters. A clustered sequential multiple\nassignment randomized trial (cSMART) is a type of trial that is used to inform\nthe empirical development of a cAI. The most common type of secondary aim in a\ncSMART focuses on assessing causal effect moderation by candidate tailoring\nvariables. We introduce a clustered Q-learning framework with the M-out-of-N\nCluster Bootstrap using data from a cSMART to evaluate whether a set of\ncandidate tailoring variables may be useful in defining an optimal cAI. This\napproach could construct confidence intervals (CI) with near-nominal coverage\nto assess parameters indexing the causal effect moderation function.\nSpecifically, it allows reliable inferences concerning the utility of candidate\ntailoring variables in constructing a cAI that maximizes a mean end-of-study\noutcome even when \"non-regularity\", a well-known challenge exists. Simulations\ndemonstrate the numerical performance of the proposed method across varying\nnon-regularity conditions and investigate the impact of varying number of\nclusters and intra-cluster correlation coefficient on CI coverage. Methods are\napplied on ADEPT dataset to inform the construction of a clinic-level cAI for\nimproving evidence-based practice in treating mood disorders.", "AI": {"tldr": "A clustered Q-learning framework with M-out-of-N Cluster Bootstrap is introduced to evaluate candidate tailoring variables for optimal clustered adaptive interventions (cAIs) using cSMART data, addressing non-regularity challenges.", "motivation": "To improve outcomes at the individual level within clusters by developing optimal cAIs, addressing the challenge of non-regularity in causal effect moderation.", "method": "Proposes a clustered Q-learning framework with M-out-of-N Cluster Bootstrap to assess candidate tailoring variables and construct confidence intervals for causal effect moderation.", "result": "Simulations show the method's effectiveness under varying non-regularity conditions, cluster sizes, and intra-cluster correlation. Applied to ADEPT dataset for mood disorder treatment.", "conclusion": "The framework reliably evaluates tailoring variables for cAIs, even under non-regularity, aiding in the construction of optimal interventions."}}
{"id": "2504.18317", "pdf": "https://arxiv.org/pdf/2504.18317", "abs": "https://arxiv.org/abs/2504.18317", "authors": ["Zhengru Fang", "Zhenghao Liu", "Jingjing Wang", "Senkang Hu", "Yu Guo", "Yiqin Deng", "Yuguang Fang"], "title": "Task-Oriented Communications for Visual Navigation with Edge-Aerial Collaboration in Low Altitude Economy", "categories": ["cs.CV", "cs.NI"], "comment": "Code and dataset will be made publicly available:\n  https://github.com/fangzr/TOC-Edge-Aerial", "summary": "To support the Low Altitude Economy (LAE), precise unmanned aerial vehicles\n(UAVs) localization in urban areas where global positioning system (GPS)\nsignals are unavailable. Vision-based methods offer a viable alternative but\nface severe bandwidth, memory and processing constraints on lightweight UAVs.\nInspired by mammalian spatial cognition, we propose a task-oriented\ncommunication framework, where UAVs equipped with multi-camera systems extract\ncompact multi-view features and offload localization tasks to edge servers. We\nintroduce the Orthogonally-constrained Variational Information Bottleneck\nencoder (O-VIB), which incorporates automatic relevance determination (ARD) to\nprune non-informative features while enforcing orthogonality to minimize\nredundancy. This enables efficient and accurate localization with minimal\ntransmission cost. Extensive evaluation on a dedicated LAE UAV dataset shows\nthat O-VIB achieves high-precision localization under stringent bandwidth\nbudgets. Code and dataset will be made publicly available:\ngithub.com/fangzr/TOC-Edge-Aerial.", "AI": {"tldr": "A task-oriented communication framework for UAVs uses multi-view features and edge servers to achieve precise localization in GPS-denied urban areas, with an O-VIB encoder for efficient feature extraction.", "motivation": "To address the challenges of UAV localization in GPS-denied urban areas while overcoming bandwidth and processing constraints on lightweight UAVs.", "method": "Proposes a task-oriented framework with multi-camera systems, compact multi-view feature extraction, and offloading to edge servers. Introduces O-VIB encoder with ARD and orthogonality constraints for efficient feature pruning.", "result": "O-VIB achieves high-precision localization under strict bandwidth budgets, validated on a dedicated LAE UAV dataset.", "conclusion": "The framework enables efficient and accurate UAV localization with minimal transmission cost, suitable for LAE applications."}}
{"id": "2411.00230", "pdf": "https://arxiv.org/pdf/2411.00230", "abs": "https://arxiv.org/abs/2411.00230", "authors": ["Akash Kundu", "Leopoldo Sarra"], "title": "Reinforcement learning with learned gadgets to tackle hard quantum problems on real hardware", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "23 pages, 13 figures. Comments are encouraged", "summary": "Designing quantum circuits for specific tasks is challenging due to the\nexponential growth of the state space. We introduce gadget reinforcement\nlearning (GRL), which integrates reinforcement learning with program synthesis\nto automatically generate and incorporate composite gates (gadgets) into the\naction space. This enhances the exploration of parameterized quantum circuits\n(PQCs) for complex tasks like approximating ground states of quantum\nHamiltonians, an NP-hard problem. We evaluate GRL using the transverse field\nIsing model under typical computational budgets (e.g., 2- 3 days of GPU\nruntime). Our results show improved accuracy, hardware compatibility and\nscalability. GRL exhibits robust performance as the size and complexity of the\nproblem increases, even with constrained computational resources. By\nintegrating gadget extraction, GRL facilitates the discovery of reusable\ncircuit components tailored for specific hardware, bridging the gap between\nalgorithmic design and practical implementation. This makes GRL a versatile\nframework for optimizing quantum circuits with applications in\nhardware-specific optimizations and variational quantum algorithms. The code is\navailable at: https://github.com/Aqasch/Gadget_RL", "AI": {"tldr": "GRL combines reinforcement learning and program synthesis to automate quantum circuit design, improving accuracy and scalability for tasks like approximating ground states of quantum Hamiltonians.", "motivation": "Designing quantum circuits is complex due to exponential state space growth. GRL aims to automate and optimize this process.", "method": "GRL integrates reinforcement learning with program synthesis to generate and use composite gates (gadgets) in quantum circuits.", "result": "GRL enhances accuracy, hardware compatibility, and scalability, even with limited computational resources.", "conclusion": "GRL bridges algorithmic design and practical implementation, offering a versatile framework for quantum circuit optimization."}}
{"id": "2505.00835", "pdf": "https://arxiv.org/pdf/2505.00835", "abs": "https://arxiv.org/abs/2505.00835", "authors": ["Nathan Huet", "Philippe Naveau", "Anne Sabourin"], "title": "Multi-site modelling and reconstruction of past extreme skew surges along the French Atlantic coast", "categories": ["stat.AP", "cs.LG", "stat.ML"], "comment": null, "summary": "Appropriate modelling of extreme skew surges is crucial, particularly for\ncoastal risk management. Our study focuses on modelling extreme skew surges\nalong the French Atlantic coast, with a particular emphasis on investigating\nthe extremal dependence structure between stations. We employ the\npeak-over-threshold framework, where a multivariate extreme event is defined\nwhenever at least one location records a large value, though not necessarily\nall stations simultaneously. A novel method for determining an appropriate\nlevel (threshold) above which observations can be classified as extreme is\nproposed. Two complementary approaches are explored. First, the multivariate\ngeneralized Pareto distribution is employed to model extremes, leveraging its\nproperties to derive a generative model that predicts extreme skew surges at\none station based on observed extremes at nearby stations. Second, a novel\nextreme regression framework is assessed for point predictions. This specific\nregression framework enables accurate point predictions using only the \"angle\"\nof input variables, i.e. input variables divided by their norms. The ultimate\nobjective is to reconstruct historical skew surge time series at stations with\nlimited data. This is achieved by integrating extreme skew surge data from\nstations with longer records, such as Brest and Saint-Nazaire, which provide\nover 150 years of observations.", "AI": {"tldr": "The paper proposes methods for modelling extreme skew surges on the French Atlantic coast, focusing on extremal dependence between stations and using novel threshold determination and regression techniques.", "motivation": "Accurate modelling of extreme skew surges is vital for coastal risk management, especially in regions like the French Atlantic coast.", "method": "Uses peak-over-threshold framework, multivariate generalized Pareto distribution, and a novel extreme regression framework for predictions.", "result": "The methods aim to reconstruct historical skew surge time series at data-limited stations by leveraging data from stations with longer records.", "conclusion": "The proposed approaches enhance the understanding and prediction of extreme skew surges, aiding coastal risk management."}}
{"id": "2504.19684", "pdf": "https://arxiv.org/pdf/2504.19684", "abs": "https://arxiv.org/abs/2504.19684", "authors": ["Anush Lakshman Sivaraman", "Kojo Adu-Gyamfi", "Ibne Farabi Shihab", "Anuj Sharma"], "title": "ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Adverse weather conditions challenge safe transportation, necessitating\nrobust real-time weather detection from traffic camera imagery. We propose a\nnovel framework combining CycleGAN-based domain adaptation with efficient\ncontrastive learning to enhance weather classification, particularly in\nlow-light nighttime conditions. Our approach leverages the lightweight SigLIP-2\nmodel, which employs pairwise sigmoid loss to reduce computational demands,\nintegrated with CycleGAN to transform nighttime images into day-like\nrepresentations while preserving weather cues. Evaluated on an Iowa Department\nof Transportation dataset, the baseline EVA-02 model with CLIP achieves a\nper-class overall accuracy of 96.55\\% across three weather conditions (No\nPrecipitation, Rain, Snow) and a day/night overall accuracy of 96.55\\%, but\nshows a significant day-night gap (97.21\\% day vs.\\ 63.40\\% night). With\nCycleGAN, EVA-02 improves to 97.01\\% per-class accuracy and 96.85\\% day/night\naccuracy, boosting nighttime performance to 82.45\\%. Our Vision-SigLIP-2 +\nText-SigLIP-2 + CycleGAN + Contrastive configuration excels in nighttime\nscenarios, achieving the highest nighttime accuracy of 85.90\\%, with 94.00\\%\nper-class accuracy and 93.35\\% day/night accuracy. This model reduces training\ntime by 89\\% (from 6 hours to 40 minutes) and inference time by 80\\% (from 15\nseconds to 3 seconds) compared to EVA-02. By narrowing the day-night\nperformance gap from 33.81 to 8.90 percentage points, our framework provides a\nscalable, efficient solution for all-weather classification using existing\ncamera infrastructure.", "AI": {"tldr": "A novel framework combining CycleGAN and SigLIP-2 improves weather classification, especially in low-light conditions, reducing day-night performance gaps and computational demands.", "motivation": "Adverse weather conditions challenge safe transportation, requiring robust real-time weather detection from traffic cameras.", "method": "Combines CycleGAN for domain adaptation and SigLIP-2 for efficient contrastive learning to enhance weather classification, particularly in nighttime conditions.", "result": "Achieves 85.90% nighttime accuracy, reduces training time by 89%, and narrows the day-night performance gap from 33.81 to 8.90 percentage points.", "conclusion": "The framework offers a scalable, efficient solution for all-weather classification using existing camera infrastructure."}}
{"id": "2411.12150", "pdf": "https://arxiv.org/pdf/2411.12150", "abs": "https://arxiv.org/abs/2411.12150", "authors": ["Shuijing Liu", "Haochen Xia", "Fatemeh Cheraghi Pouria", "Kaiwen Hong", "Neeloy Chakraborty", "Zichao Hu", "Joydeep Biswas", "Katherine Driggs-Campbell"], "title": "HEIGHT: Heterogeneous Interaction Graph Transformer for Robot Navigation in Crowded and Constrained Environments", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "We study the problem of robot navigation in dense and interactive crowds with\nenvironmental constraints such as corridors and furniture. Previous methods\nfail to consider all types of interactions among agents and obstacles, leading\nto unsafe and inefficient robot paths. In this article, we leverage a\ngraph-based representation of crowded and constrained scenarios and propose a\nstructured framework to learn robot navigation policies with deep reinforcement\nlearning. We first split the representations of different components in the\nenvironment and propose a heterogeneous spatio-temporal (st) graph to model\ndistinct interactions among humans, robots, and obstacles. Based on the\nheterogeneous st-graph, we propose HEIGHT, a novel navigation policy network\narchitecture with different components to capture heterogeneous interactions\namong entities through space and time. HEIGHT utilizes attention mechanisms to\nprioritize important interactions and a recurrent network to track changes in\nthe dynamic scene over time, encouraging the robot to avoid collisions\nadaptively. Through extensive simulation and real-world experiments, we\ndemonstrate that HEIGHT outperforms state-of-the-art baselines in terms of\nsuccess and efficiency in challenging navigation scenarios. Furthermore, we\ndemonstrate that our pipeline achieves better zero-shot generalization\ncapability than previous works when the densities of humans and obstacles\nchange. More videos are available at\nhttps://sites.google.com/view/crowdnav-height/home.", "AI": {"tldr": "A graph-based framework (HEIGHT) for robot navigation in dense crowds with environmental constraints, using deep reinforcement learning to model interactions and improve safety and efficiency.", "motivation": "Existing methods fail to fully account for interactions among agents and obstacles, leading to unsafe and inefficient robot paths in crowded, constrained environments.", "method": "Proposes a heterogeneous spatio-temporal graph to model interactions, and HEIGHT, a policy network with attention mechanisms and recurrent networks to prioritize and track dynamic interactions.", "result": "HEIGHT outperforms state-of-the-art baselines in success and efficiency, and shows better zero-shot generalization with varying human and obstacle densities.", "conclusion": "The HEIGHT framework effectively addresses navigation challenges in dense, interactive crowds with constraints, demonstrating superior performance and adaptability."}}
{"id": "2505.00846", "pdf": "https://arxiv.org/pdf/2505.00846", "abs": "https://arxiv.org/abs/2505.00846", "authors": ["Edmilson Roque dos Santos", "Erik Bollt"], "title": "On the emergence of numerical instabilities in Next Generation Reservoir Computing", "categories": ["stat.ML", "cs.LG", "math.DS", "physics.data-an", "37M10, 62M10, 65F22,"], "comment": "21 pages, 8 figures", "summary": "Next Generation Reservoir Computing (NGRC) is a low-cost machine learning\nmethod for forecasting chaotic time series from data. However, ensuring the\ndynamical stability of NGRC models during autonomous prediction remains a\nchallenge. In this work, we uncover a key connection between the numerical\nconditioning of the NGRC feature matrix -- formed by polynomial evaluations on\ntime-delay coordinates -- and the long-term NGRC dynamics. Merging tools from\nnumerical linear algebra and ergodic theory of dynamical systems, we\nsystematically study how the feature matrix conditioning varies across\nhyperparameters. We demonstrate that the NGRC feature matrix tends to be\nill-conditioned for short time lags and high-degree polynomials.\nIll-conditioning amplifies sensitivity to training data perturbations, which\ncan produce unstable NGRC dynamics. We evaluate the impact of different\nnumerical algorithms (Cholesky, SVD, and LU) for solving the regularized\nleast-squares problem.", "AI": {"tldr": "NGRC is a low-cost ML method for chaotic time series forecasting, but stability is a challenge. This work links feature matrix conditioning to dynamics, showing ill-conditioning with short lags/high-degree polynomials, and evaluates numerical algorithms for stability.", "motivation": "To address the challenge of ensuring dynamical stability in NGRC models during autonomous prediction of chaotic time series.", "method": "Analyzes the connection between feature matrix conditioning and dynamics, studying hyperparameter effects and evaluating numerical algorithms (Cholesky, SVD, LU) for solving regularized least-squares.", "result": "NGRC feature matrix is ill-conditioned for short time lags and high-degree polynomials, amplifying sensitivity to data perturbations and causing instability.", "conclusion": "Understanding feature matrix conditioning is crucial for stable NGRC predictions; numerical algorithm choice impacts stability."}}
{"id": "2505.00254", "pdf": "https://arxiv.org/pdf/2505.00254", "abs": "https://arxiv.org/abs/2505.00254", "authors": ["Yuxuan Yan", "Shiqi Jiang", "Ting Cao", "Yifan Yang", "Qianqian Yang", "Yuanchao Shu", "Yuqing Yang", "Lili Qiu"], "title": "Empowering Agentic Video Analytics Systems with Video Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, AVAS", "summary": "AI-driven video analytics has become increasingly pivotal across diverse\ndomains. However, existing systems are often constrained to specific,\npredefined tasks, limiting their adaptability in open-ended analytical\nscenarios. The recent emergence of Video-Language Models (VLMs) as\ntransformative technologies offers significant potential for enabling\nopen-ended video understanding, reasoning, and analytics. Nevertheless, their\nlimited context windows present challenges when processing ultra-long video\ncontent, which is prevalent in real-world applications. To address this, we\nintroduce AVAS, a VLM-powered system designed for open-ended, advanced video\nanalytics. AVAS incorporates two key innovations: (1) the near real-time\nconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long or\ncontinuous video streams, and (2) an agentic retrieval-generation mechanism\nthat leverages EKGs to handle complex and diverse queries. Comprehensive\nevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that\nAVAS achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,\nrespectively, significantly surpassing existing VLM and video\nRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video\nanalytics in ultra-long and open-world video scenarios, we introduce a new\nbenchmark, AVAS-100. This benchmark comprises 8 videos, each exceeding 10 hours\nin duration, along with 120 manually annotated, diverse, and complex\nquestion-answer pairs. On AVAS-100, AVAS achieves top-tier performance with an\naccuracy of 75.8%.", "AI": {"tldr": "AVAS is a VLM-powered system for open-ended video analytics, addressing limitations of existing systems with innovations like Event Knowledge Graphs and agentic retrieval-generation. It outperforms benchmarks with high accuracy.", "motivation": "Existing AI-driven video analytics systems lack adaptability for open-ended tasks and struggle with ultra-long videos. VLMs offer potential but face context window limitations.", "method": "AVAS uses Event Knowledge Graphs for efficient video indexing and an agentic retrieval-generation mechanism for handling diverse queries.", "result": "AVAS achieves 62.3% and 64.1% accuracy on LVBench and VideoMME-Long, and 75.8% on the new AVAS-100 benchmark.", "conclusion": "AVAS demonstrates superior performance in open-ended and ultra-long video analytics, setting a new standard with its innovative approach."}}
{"id": "2412.14415", "pdf": "https://arxiv.org/pdf/2412.14415", "abs": "https://arxiv.org/abs/2412.14415", "authors": ["Xin Huang", "Eric M. Wolff", "Paul Vernaza", "Tung Phan-Minh", "Hongge Chen", "David S. Hayden", "Mark Edmonds", "Brian Pierce", "Xinxin Chen", "Pratik Elias Jacob", "Xiaobai Chen", "Chingiz Tairbekov", "Pratik Agarwal", "Tianshi Gao", "Yuning Chai", "Siddhartha Srinivasa"], "title": "DriveGPT: Scaling Autoregressive Behavior Models for Driving", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": "ICML 2025. 14 pages, 17 figures, 8 tables, and 1 video link", "summary": "We present DriveGPT, a scalable behavior model for autonomous driving. We\nmodel driving as a sequential decision-making task, and learn a transformer\nmodel to predict future agent states as tokens in an autoregressive fashion. We\nscale up our model parameters and training data by multiple orders of\nmagnitude, enabling us to explore the scaling properties in terms of dataset\nsize, model parameters, and compute. We evaluate DriveGPT across different\nscales in a planning task, through both quantitative metrics and qualitative\nexamples, including closed-loop driving in complex real-world scenarios. In a\nseparate prediction task, DriveGPT outperforms state-of-the-art baselines and\nexhibits improved performance by pretraining on a large-scale dataset, further\nvalidating the benefits of data scaling.", "AI": {"tldr": "DriveGPT is a scalable transformer-based behavior model for autonomous driving, demonstrating improved performance with increased data and model size.", "motivation": "To explore the scaling properties of behavior models for autonomous driving and validate the benefits of large-scale data and model parameters.", "method": "DriveGPT models driving as a sequential decision-making task using a transformer, trained autoregressively on a large-scale dataset.", "result": "Outperforms state-of-the-art baselines in prediction tasks and shows improved planning performance in real-world scenarios.", "conclusion": "Scaling model parameters and training data significantly enhances performance, validating the approach for autonomous driving."}}
{"id": "2505.00881", "pdf": "https://arxiv.org/pdf/2505.00881", "abs": "https://arxiv.org/abs/2505.00881", "authors": ["Tianya Zhao", "Ningning Wang", "Junqing Zhang", "Xuyu Wang"], "title": "Protocol-agnostic and Data-free Backdoor Attacks on Pre-trained Models in RF Fingerprinting", "categories": ["cs.CR", "cs.LG", "cs.NI", "C.2.m; I.2.6"], "comment": "10 pages, 7 figures, accepted by IEEE INFOCOM 2025", "summary": "While supervised deep neural networks (DNNs) have proven effective for device\nauthentication via radio frequency (RF) fingerprinting, they are hindered by\ndomain shift issues and the scarcity of labeled data. The success of large\nlanguage models has led to increased interest in unsupervised pre-trained\nmodels (PTMs), which offer better generalization and do not require labeled\ndatasets, potentially addressing the issues mentioned above. However, the\ninherent vulnerabilities of PTMs in RF fingerprinting remain insufficiently\nexplored. In this paper, we thoroughly investigate data-free backdoor attacks\non such PTMs in RF fingerprinting, focusing on a practical scenario where\nattackers lack access to downstream data, label information, and training\nprocesses. To realize the backdoor attack, we carefully design a set of\ntriggers and predefined output representations (PORs) for the PTMs. By mapping\ntriggers and PORs through backdoor training, we can implant backdoor behaviors\ninto the PTMs, thereby introducing vulnerabilities across different downstream\nRF fingerprinting tasks without requiring prior knowledge. Extensive\nexperiments demonstrate the wide applicability of our proposed attack to\nvarious input domains, protocols, and PTMs. Furthermore, we explore potential\ndetection and defense methods, demonstrating the difficulty of fully\nsafeguarding against our proposed backdoor attack.", "AI": {"tldr": "The paper investigates data-free backdoor attacks on unsupervised pre-trained models (PTMs) in RF fingerprinting, demonstrating their vulnerability and proposing detection challenges.", "motivation": "Supervised DNNs face domain shift and labeled data scarcity in RF fingerprinting. PTMs offer better generalization but their vulnerabilities are underexplored.", "method": "Design triggers and predefined output representations (PORs) for PTMs to implant backdoor behaviors without downstream data or labels.", "result": "Experiments show the attack's wide applicability across input domains, protocols, and PTMs, with detection and defense proving difficult.", "conclusion": "The study highlights the inherent vulnerabilities of PTMs in RF fingerprinting and the challenges in safeguarding against such backdoor attacks."}}
{"id": "2505.00512", "pdf": "https://arxiv.org/pdf/2505.00512", "abs": "https://arxiv.org/abs/2505.00512", "authors": ["Nguyen Hoang Khoi Tran", "Julie Stephany Berrio", "Mao Shan", "Zhenxing Ming", "Stewart Worrall"], "title": "InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Online localization of road intersections is beneficial for autonomous\nvehicle localization, mapping and motion planning. Intersections offer strong\nlandmarks to correct vehicle pose estimation in GNSS dropouts and anchor new\nsensor data in up-to-date maps. They are also decisive routing nodes in road\nnetwork graphs. Despite that importance, intersection localization has not been\nwidely studied, with existing methods either ignore the rich semantic\ninformation already computed onboard or depend on scarce, hand-labeled\nintersection datasets. To close that gap, this paper presents a LiDAR-based\nmethod for online vehicle-centric intersection localization. We fuse semantic\nroad segmentation with vehicle local pose to detect intersection candidates in\na bird's eye view (BEV) representation. We then refine those candidates by\nanalyzing branch topology and correcting the intersection point in a least\nsquares formulation. To evaluate our method, we introduce an automated\nbenchmarking pipeline that pairs localized intersection points with\nOpenStreetMap (OSM) intersection nodes using precise GNSS/INS ground-truth\nposes. Experiments on SemanticKITTI show that the method outperforms the latest\nlearning-based baseline in accuracy and reliability. Moreover, sensitivity\ntests demonstrate that our method is robust to challenging segmentation error\nlevels, highlighting its applicability in the real world.", "AI": {"tldr": "A LiDAR-based method for online vehicle-centric intersection localization, fusing semantic road segmentation and vehicle pose to detect and refine intersections, outperforming learning-based baselines.", "motivation": "Intersections are crucial for autonomous vehicle tasks like localization and mapping, but existing methods lack semantic utilization or rely on labeled datasets.", "method": "Fuses semantic road segmentation with vehicle pose to detect intersection candidates in BEV, refines them via branch topology analysis and least squares correction.", "result": "Outperforms learning-based baselines in accuracy and reliability, with robustness to segmentation errors.", "conclusion": "The method is effective and applicable in real-world scenarios, offering a robust solution for intersection localization."}}
{"id": "2501.12352", "pdf": "https://arxiv.org/pdf/2501.12352", "abs": "https://arxiv.org/abs/2501.12352", "authors": ["Ke Alexander Wang", "Jiaxin Shi", "Emily B. Fox"], "title": "Test-time regression: a unifying framework for designing sequence models with associative memory", "categories": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "comment": null, "summary": "Sequence models lie at the heart of modern deep learning. However, rapid\nadvancements have produced a diversity of seemingly unrelated architectures,\nsuch as Transformers and recurrent alternatives. In this paper, we introduce a\nunifying framework to understand and derive these sequence models, inspired by\nthe empirical importance of associative recall, the capability to retrieve\ncontextually relevant tokens. We formalize associative recall as a two-step\nprocess, memorization and retrieval, casting memorization as a regression\nproblem. Layers that combine these two steps perform associative recall via\n``test-time regression'' over its input tokens. Prominent layers, including\nlinear attention, state-space models, fast-weight programmers, online learners,\nand softmax attention, arise as special cases defined by three design choices:\nthe regression weights, the regressor function class, and the test-time\noptimization algorithm. Our approach clarifies how linear attention fails to\ncapture inter-token correlations and offers a mathematical justification for\nthe empirical effectiveness of query-key normalization in softmax attention.\nFurther, it illuminates unexplored regions within the design space, which we\nuse to derive novel higher-order generalizations of softmax attention. Beyond\nunification, our work bridges sequence modeling with classic regression\nmethods, a field with extensive literature, paving the way for developing more\npowerful and theoretically principled architectures.", "AI": {"tldr": "The paper introduces a unifying framework for sequence models, formalizing associative recall as memorization and retrieval, and derives prominent architectures like Transformers as special cases.", "motivation": "To address the diversity of seemingly unrelated sequence model architectures and provide a unified understanding inspired by associative recall.", "method": "The framework formalizes associative recall as a two-step process (memorization and retrieval), casting memorization as regression. It analyzes design choices like regression weights and optimization algorithms.", "result": "The approach explains limitations of linear attention, justifies query-key normalization in softmax attention, and leads to novel higher-order generalizations.", "conclusion": "The work unifies sequence modeling with regression methods, offering a foundation for more powerful and theoretically grounded architectures."}}
{"id": "2505.00951", "pdf": "https://arxiv.org/pdf/2505.00951", "abs": "https://arxiv.org/abs/2505.00951", "authors": ["Tina Khezresmaeilzadeh", "Jiang Zhang", "Dimitrios Andreadis", "Konstantinos Psounis"], "title": "Preserving Privacy and Utility in LLM-Based Product Recommendations", "categories": ["cs.IR", "cs.CR", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM)-based recommendation systems leverage powerful\nlanguage models to generate personalized suggestions by processing user\ninteractions and preferences. Unlike traditional recommendation systems that\nrely on structured data and collaborative filtering, LLM-based models process\ntextual and contextual information, often using cloud-based infrastructure.\nThis raises privacy concerns, as user data is transmitted to remote servers,\nincreasing the risk of exposure and reducing control over personal information.\nTo address this, we propose a hybrid privacy-preserving recommendation\nframework which separates sensitive from nonsensitive data and only shares the\nlatter with the cloud to harness LLM-powered recommendations. To restore lost\nrecommendations related to obfuscated sensitive data, we design a\nde-obfuscation module that reconstructs sensitive recommendations locally.\nExperiments on real-world e-commerce datasets show that our framework achieves\nalmost the same recommendation utility with a system which shares all data with\nan LLM, while preserving privacy to a large extend. Compared to\nobfuscation-only techniques, our approach improves HR@10 scores and category\ndistribution alignment, offering a better balance between privacy and\nrecommendation quality. Furthermore, our method runs efficiently on\nconsumer-grade hardware, making privacy-aware LLM-based recommendation systems\npractical for real-world use.", "AI": {"tldr": "A hybrid privacy-preserving framework for LLM-based recommendation systems separates sensitive data, shares only nonsensitive data with the cloud, and reconstructs sensitive recommendations locally, balancing privacy and utility.", "motivation": "Address privacy concerns in LLM-based recommendation systems by minimizing sensitive data exposure to cloud servers while maintaining recommendation quality.", "method": "Propose a hybrid framework with data separation, obfuscation, and a local de-obfuscation module to reconstruct sensitive recommendations.", "result": "Achieves comparable utility to full-data sharing while preserving privacy, improves HR@10 scores, and runs efficiently on consumer hardware.", "conclusion": "The framework offers a practical solution for privacy-aware LLM-based recommendations, balancing privacy and performance."}}
{"id": "2505.00568", "pdf": "https://arxiv.org/pdf/2505.00568", "abs": "https://arxiv.org/abs/2505.00568", "authors": ["Lucas Robinet", "Ahmad Berjaoui", "Elizabeth Cohen-Jonathan Moyal"], "title": "Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal magnetic resonance imaging (MRI) constitutes the first line of\ninvestigation for clinicians in the care of brain tumors, providing crucial\ninsights for surgery planning, treatment monitoring, and biomarker\nidentification. Pre-training on large datasets have been shown to help models\nlearn transferable representations and adapt with minimal labeled data. This\nbehavior is especially valuable in medical imaging, where annotations are often\nscarce. However, applying this paradigm to multimodal medical data introduces a\nchallenge: most existing approaches assume that all imaging modalities are\navailable during both pre-training and fine-tuning. In practice, missing\nmodalities often occur due to acquisition issues, specialist unavailability, or\nspecific experimental designs on small in-house datasets. Consequently, a\ncommon approach involves training a separate model for each desired modality\ncombination, making the process both resource-intensive and impractical for\nclinical use. Therefore, we introduce BM-MAE, a masked image modeling\npre-training strategy tailored for multimodal MRI data. The same pre-trained\nmodel seamlessly adapts to any combination of available modalities, extracting\nrich representations that capture both intra- and inter-modal information. This\nallows fine-tuning on any subset of modalities without requiring architectural\nchanges, while still benefiting from a model pre-trained on the full set of\nmodalities. Extensive experiments show that the proposed pre-training strategy\noutperforms or remains competitive with baselines that require separate\npre-training for each modality subset, while substantially surpassing training\nfrom scratch on several downstream tasks. Additionally, it can quickly and\nefficiently reconstruct missing modalities, highlighting its practical value.\nCode and trained models are available at: https://github.com/Lucas-rbnt/BM-MAE", "AI": {"tldr": "BM-MAE introduces a masked image modeling pre-training strategy for multimodal MRI data, enabling adaptation to any modality combination without architectural changes, outperforming baselines and reconstructing missing modalities efficiently.", "motivation": "Addressing the challenge of missing modalities in multimodal MRI data, which complicates pre-training and fine-tuning, and the impracticality of training separate models for each combination.", "method": "Proposes BM-MAE, a masked image modeling pre-training strategy that adapts to any modality subset, capturing intra- and inter-modal information without requiring architectural changes.", "result": "Outperforms or competes with baselines requiring separate pre-training, surpasses training from scratch, and efficiently reconstructs missing modalities.", "conclusion": "BM-MAE offers a practical, resource-efficient solution for multimodal MRI analysis, enhancing adaptability and performance in downstream tasks."}}
{"id": "2501.14012", "pdf": "https://arxiv.org/pdf/2501.14012", "abs": "https://arxiv.org/abs/2501.14012", "authors": ["Shuaiqun Pan", "Diederick Vermetten", "Manuel L\u00f3pez-Ib\u00e1\u00f1ez", "Thomas B\u00e4ck", "Hao Wang"], "title": "Transfer Learning of Surrogate Models via Domain Affine Transformation Across Synthetic and Real-World Benchmarks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Surrogate models are frequently employed as efficient substitutes for the\ncostly execution of real-world processes. However, constructing a high-quality\nsurrogate model often demands extensive data acquisition. A solution to this\nissue is to transfer pre-trained surrogate models for new tasks, provided that\ncertain invariances exist between tasks. This study focuses on transferring\nnon-differentiable surrogate models (e.g., random forests) from a source\nfunction to a target function, where we assume their domains are related by an\nunknown affine transformation, using only a limited amount of transfer data\npoints evaluated on the target. Previous research attempts to tackle this\nchallenge for differentiable models, e.g., Gaussian process regression, which\nminimizes the empirical loss on the transfer data by tuning the affine\ntransformations. In this paper, we extend the previous work to the random\nforest and assess its effectiveness on a widely-used artificial problem set -\nBlack-Box Optimization Benchmark (BBOB) testbed, and on four real-world\ntransfer learning problems. The results highlight the significant practical\nadvantages of the proposed method, particularly in reducing both the data\nrequirements and computational costs of training surrogate models for complex\nreal-world scenarios.", "AI": {"tldr": "The paper proposes a method to transfer non-differentiable surrogate models (e.g., random forests) between tasks with limited transfer data, reducing data and computational costs.", "motivation": "High-quality surrogate models require extensive data, but transferring pre-trained models can mitigate this if invariances exist between tasks.", "method": "Extends previous work on differentiable models to random forests, assuming domains are related by an unknown affine transformation, and tests on BBOB and real-world problems.", "result": "The method significantly reduces data requirements and computational costs for training surrogate models in complex scenarios.", "conclusion": "The proposed approach is practical and effective for transferring non-differentiable surrogate models, offering advantages in efficiency and data usage."}}
{"id": "2505.00953", "pdf": "https://arxiv.org/pdf/2505.00953", "abs": "https://arxiv.org/abs/2505.00953", "authors": ["Yuhan Liu", "Lin Ning", "Neo Wu", "Karan Singhal", "Philip Andrew Mansfield", "Devora Berlowitz", "Sushant Prakash", "Bradley Green"], "title": "Enhancing User Sequence Modeling through Barlow Twins-based Self-Supervised Learning", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "User sequence modeling is crucial for modern large-scale recommendation\nsystems, as it enables the extraction of informative representations of users\nand items from their historical interactions. These user representations are\nwidely used for a variety of downstream tasks to enhance users' online\nexperience. A key challenge for learning these representations is the lack of\nlabeled training data. While self-supervised learning (SSL) methods have\nemerged as a promising solution for learning representations from unlabeled\ndata, many existing approaches rely on extensive negative sampling, which can\nbe computationally expensive and may not always be feasible in real-world\nscenario. In this work, we propose an adaptation of Barlow Twins, a\nstate-of-the-art SSL methods, to user sequence modeling by incorporating\nsuitable augmentation methods. Our approach aims to mitigate the need for large\nnegative sample batches, enabling effective representation learning with\nsmaller batch sizes and limited labeled data. We evaluate our method on the\nMovieLens-1M, MovieLens-20M, and Yelp datasets, demonstrating that our method\nconsistently outperforms the widely-used dual encoder model across three\ndownstream tasks, achieving an 8%-20% improvement in accuracy. Our findings\nunderscore the effectiveness of our approach in extracting valuable\nsequence-level information for user modeling, particularly in scenarios where\nlabeled data is scarce and negative examples are limited.", "AI": {"tldr": "The paper proposes adapting Barlow Twins for user sequence modeling to reduce reliance on negative sampling, achieving 8%-20% accuracy improvement over dual encoder models.", "motivation": "User sequence modeling lacks labeled data; existing SSL methods require extensive negative sampling, which is computationally expensive.", "method": "Adapts Barlow Twins for user sequence modeling with suitable augmentations to reduce negative sampling needs.", "result": "Outperforms dual encoder models by 8%-20% on MovieLens and Yelp datasets.", "conclusion": "The approach effectively extracts sequence-level information with limited labeled data and negative examples."}}
{"id": "2411.17662", "pdf": "https://arxiv.org/pdf/2411.17662", "abs": "https://arxiv.org/abs/2411.17662", "authors": ["Raktim Gautam Goswami", "Prashanth Krishnamurthy", "Yann LeCun", "Farshad Khorrami"], "title": "RoboPEPP: Vision-Based Robot Pose and Joint Angle Estimation through Embedding Predictive Pre-Training", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Vision-based pose estimation of articulated robots with unknown joint angles\nhas applications in collaborative robotics and human-robot interaction tasks.\nCurrent frameworks use neural network encoders to extract image features and\ndownstream layers to predict joint angles and robot pose. While images of\nrobots inherently contain rich information about the robot's physical\nstructures, existing methods often fail to leverage it fully; therefore,\nlimiting performance under occlusions and truncations. To address this, we\nintroduce RoboPEPP, a method that fuses information about the robot's physical\nmodel into the encoder using a masking-based self-supervised\nembedding-predictive architecture. Specifically, we mask the robot's joints and\npre-train an encoder-predictor model to infer the joints' embeddings from\nsurrounding unmasked regions, enhancing the encoder's understanding of the\nrobot's physical model. The pre-trained encoder-predictor pair, along with\njoint angle and keypoint prediction networks, is then fine-tuned for pose and\njoint angle estimation. Random masking of input during fine-tuning and keypoint\nfiltering during evaluation further improves robustness. Our method, evaluated\non several datasets, achieves the best results in robot pose and joint angle\nestimation while being the least sensitive to occlusions and requiring the\nlowest execution time.", "AI": {"tldr": "RoboPEPP improves robot pose and joint angle estimation by integrating the robot's physical model into the encoder using a masking-based self-supervised approach, outperforming existing methods in robustness and speed.", "motivation": "Current methods for vision-based pose estimation of articulated robots often fail to fully utilize the robot's physical structure, limiting performance under occlusions and truncations.", "method": "RoboPEPP uses a masking-based self-supervised embedding-predictive architecture to pre-train an encoder-predictor model, followed by fine-tuning for pose and joint angle estimation, with random masking and keypoint filtering for robustness.", "result": "RoboPEPP achieves the best performance in pose and joint angle estimation, is least sensitive to occlusions, and has the lowest execution time.", "conclusion": "RoboPEPP effectively leverages the robot's physical model for improved pose estimation, demonstrating superior robustness and efficiency."}}
{"id": "2502.05174", "pdf": "https://arxiv.org/pdf/2502.05174", "abs": "https://arxiv.org/abs/2502.05174", "authors": ["Kaijie Zhu", "Xianjun Yang", "Jindong Wang", "Wenbo Guo", "William Yang Wang"], "title": "MELON: Provable Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison", "categories": ["cs.CR", "cs.AI"], "comment": "ICML 2025", "summary": "Recent research has explored that LLM agents are vulnerable to indirect\nprompt injection (IPI) attacks, where malicious tasks embedded in\ntool-retrieved information can redirect the agent to take unauthorized actions.\nExisting defenses against IPI have significant limitations: either require\nessential model training resources, lack effectiveness against sophisticated\nattacks, or harm the normal utilities. We present MELON (Masked re-Execution\nand TooL comparisON), a novel IPI defense. Our approach builds on the\nobservation that under a successful attack, the agent's next action becomes\nless dependent on user tasks and more on malicious tasks. Following this, we\ndesign MELON to detect attacks by re-executing the agent's trajectory with a\nmasked user prompt modified through a masking function. We identify an attack\nif the actions generated in the original and masked executions are similar. We\nalso include three key designs to reduce the potential false positives and\nfalse negatives. Extensive evaluation on the IPI benchmark AgentDojo\ndemonstrates that MELON outperforms SOTA defenses in both attack prevention and\nutility preservation. Moreover, we show that combining MELON with a SOTA prompt\naugmentation defense (denoted as MELON-Aug) further improves its performance.\nWe also conduct a detailed ablation study to validate our key designs.", "AI": {"tldr": "MELON is a novel defense against indirect prompt injection (IPI) attacks on LLM agents, outperforming existing methods by detecting attacks through masked re-execution and tool comparison while preserving utility.", "motivation": "LLM agents are vulnerable to IPI attacks, and current defenses are either resource-intensive, ineffective, or degrade normal functionality.", "method": "MELON detects attacks by re-executing the agent's trajectory with a masked user prompt and comparing actions. It includes three key designs to minimize errors.", "result": "MELON outperforms state-of-the-art defenses on the IPI benchmark AgentDojo and improves further when combined with prompt augmentation (MELON-Aug).", "conclusion": "MELON is an effective and efficient defense against IPI attacks, validated by extensive evaluation and ablation studies."}}
{"id": "2505.00961", "pdf": "https://arxiv.org/pdf/2505.00961", "abs": "https://arxiv.org/abs/2505.00961", "authors": ["Shu Tamano", "Masanori Nojima"], "title": "DOLCE: Decomposing Off-Policy Evaluation/Learning into Lagged and Current Effects", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Off-policy evaluation (OPE) and off-policy learning (OPL) for contextual\nbandit policies leverage historical data to evaluate and optimize a target\npolicy. Most existing OPE/OPL methods--based on importance weighting or\nimputation--assume common support between the target and logging policies. When\nthis assumption is violated, these methods typically require unstable\nextrapolation, truncation, or conservative strategies for individuals outside\nthe common support assumption. However, such approaches can be inadequate in\nsettings where explicit evaluation or optimization for such individuals is\nrequired. To address this issue, we propose DOLCE: Decomposing Off-policy\nevaluation/learning into Lagged and Current Effects, a novel estimator that\nleverages contextual information from multiple time points to decompose rewards\ninto lagged and current effects. By incorporating both past and present\ncontexts, DOLCE effectively handles individuals who violate the common support\nassumption. We show that the proposed estimator is unbiased under two\nassumptions--local correctness and conditional independence. Our experiments\ndemonstrate that DOLCE achieves substantial improvements in OPE and OPL,\nparticularly as the proportion of individuals outside the common support\nassumption increases.", "AI": {"tldr": "DOLCE is a novel estimator for off-policy evaluation/learning that handles violations of the common support assumption by decomposing rewards into lagged and current effects using contextual information from multiple time points.", "motivation": "Existing OPE/OPL methods assume common support between target and logging policies, leading to unstable extrapolation or truncation when violated. DOLCE addresses this limitation by explicitly handling individuals outside the common support.", "method": "DOLCE decomposes rewards into lagged and current effects using contextual information from multiple time points, ensuring unbiased estimation under local correctness and conditional independence assumptions.", "result": "Experiments show DOLCE significantly improves OPE and OPL performance, especially as the proportion of individuals outside the common support assumption grows.", "conclusion": "DOLCE provides a robust solution for OPE/OPL when common support is violated, outperforming traditional methods and enabling explicit evaluation/optimization for such cases."}}
{"id": "2412.06806", "pdf": "https://arxiv.org/pdf/2412.06806", "abs": "https://arxiv.org/abs/2412.06806", "authors": ["Han Yue", "Jun Cheng", "Yu-Xuan Ren", "Chien-Chun Chen", "Grant A. van Riessen", "Philip Heng Wai Leong", "Steve Feng Shu"], "title": "A Physics-Inspired Deep Learning Framework with Polar Coordinate Attention for Ptychographic Imaging", "categories": ["physics.optics", "cs.CV", "68T07, 68U10"], "comment": "13 pages, 10 figures", "summary": "Ptychographic imaging confronts inherent challenges in applying deep learning\nfor phase retrieval from diffraction patterns. Conventional neural\narchitectures, both convolutional neural networks and Transformer-based\nmethods, are optimized for natural images with Euclidean spatial\nneighborhood-based inductive biases that exhibit geometric mismatch with the\nconcentric coherent patterns characteristic of diffraction data in reciprocal\nspace. In this paper, we present PPN, a physics-inspired deep learning network\nwith Polar Coordinate Attention (PoCA) for ptychographic imaging, that aligns\nneural inductive biases with diffraction physics through a dual-branch\narchitecture separating local feature extraction from non-local coherence\nmodeling. It consists of a PoCA mechanism that replaces Euclidean spatial\npriors with physically consistent radial-angular correlations. PPN outperforms\nexisting end-to-end models, with spectral and spatial analysis confirming its\ngreater preservation of high-frequency details. Notably, PPN maintains robust\nperformance compared to iterative methods even at low overlap ratios, making it\nwell suited for high-throughput imaging in real-world acquisition scenarios for\nsamples with consistent structural characteristics.", "AI": {"tldr": "PPN, a physics-inspired deep learning network with Polar Coordinate Attention (PoCA), outperforms existing models for ptychographic imaging by aligning neural biases with diffraction physics.", "motivation": "Conventional neural architectures mismatch the geometric properties of diffraction patterns, necessitating a physics-aligned approach.", "method": "PPN uses a dual-branch architecture with PoCA, replacing Euclidean priors with radial-angular correlations for better coherence modeling.", "result": "PPN preserves high-frequency details better and performs robustly even at low overlap ratios.", "conclusion": "PPN is well-suited for high-throughput imaging, offering a practical solution for real-world scenarios."}}
{"id": "2502.09762", "pdf": "https://arxiv.org/pdf/2502.09762", "abs": "https://arxiv.org/abs/2502.09762", "authors": ["Yang Li", "Junfan Chen", "Feng Xue", "Jiabin Qiu", "Wenbin Li", "Qingrui Zhang", "Ying Wen", "Wei Pan"], "title": "AT-Drone: Benchmarking Adaptive Teaming in Multi-Drone Pursuit", "categories": ["cs.RO", "cs.AI"], "comment": "18 pages", "summary": "Adaptive teaming-the capability of agents to effectively collaborate with\nunfamiliar teammates without prior coordination-is widely explored in virtual\nvideo games but overlooked in real-world multi-robot contexts. Yet, such\nadaptive collaboration is crucial for real-world applications, including border\nsurveillance, search-and-rescue, and counter-terrorism operations. To address\nthis gap, we introduce AT-Drone, the first dedicated benchmark explicitly\ndesigned to facilitate comprehensive training and evaluation of adaptive\nteaming strategies in multi-drone pursuit scenarios. AT-Drone makes the\nfollowing key contributions: (1) An adaptable simulation environment\nconfigurator that enables intuitive and rapid setup of adaptive teaming\nmulti-drone pursuit tasks, including four predefined pursuit environments. (2)\nA streamlined real-world deployment pipeline that seamlessly translates\nsimulation insights into practical drone evaluations using edge devices and\nCrazyflie drones. (3) A novel algorithm zoo integrated with a distributed\ntraining framework, featuring diverse algorithms explicitly tailored, for the\nfirst time, to multi-pursuer and multi-evader settings. (4) Standardized\nevaluation protocols with newly designed unseen drone zoos, explicitly designed\nto rigorously assess the performance of adaptive teaming. Comprehensive\nexperimental evaluations across four progressively challenging multi-drone\npursuit scenarios confirm AT-Drone's effectiveness in advancing adaptive\nteaming research. Real-world drone experiments further validate its practical\nfeasibility and utility for realistic robotic operations. Videos, code and\nweights are available at \\url{https://sites.google.com/view/at-drone}.", "AI": {"tldr": "AT-Drone is a benchmark for adaptive teaming in multi-drone pursuit, offering simulation, real-world deployment, and novel algorithms.", "motivation": "Addressing the gap in adaptive teaming for real-world multi-robot applications like surveillance and rescue.", "method": "Introduces AT-Drone with a simulation configurator, deployment pipeline, algorithm zoo, and evaluation protocols.", "result": "Effective in advancing adaptive teaming research, validated by real-world drone experiments.", "conclusion": "AT-Drone is practical and useful for realistic robotic operations, with resources available online."}}
{"id": "2505.01012", "pdf": "https://arxiv.org/pdf/2505.01012", "abs": "https://arxiv.org/abs/2505.01012", "authors": ["Kilian Tscharke", "Maximilian Wendlinger", "Sebastian Issel", "Pascal Debus"], "title": "Quantum Support Vector Regression for Robust Anomaly Detection", "categories": ["quant-ph", "cs.CR", "cs.LG"], "comment": "Submitted to IEEE International Conference on Quantum Computing and\n  Engineering (QCE) 2025", "summary": "Anomaly Detection (AD) is critical in data analysis, particularly within the\ndomain of IT security. In recent years, Machine Learning (ML) algorithms have\nemerged as a powerful tool for AD in large-scale data. In this study, we\nexplore the potential of quantum ML approaches, specifically quantum kernel\nmethods, for the application to robust AD. We build upon previous work on\nQuantum Support Vector Regression (QSVR) for semisupervised AD by conducting a\ncomprehensive benchmark on IBM quantum hardware using eleven datasets. Our\nresults demonstrate that QSVR achieves strong classification performance and\neven outperforms the noiseless simulation on two of these datasets. Moreover,\nwe investigate the influence of - in the NISQ-era inevitable - quantum noise on\nthe performance of the QSVR. Our findings reveal that the model exhibits\nrobustness to depolarizing, phase damping, phase flip, and bit flip noise,\nwhile amplitude damping and miscalibration noise prove to be more disruptive.\nFinally, we explore the domain of Quantum Adversarial Machine Learning and\ndemonstrate that QSVR is highly vulnerable to adversarial attacks and that\nnoise does not improve the adversarial robustness of the model.", "AI": {"tldr": "Quantum ML (QSVR) shows promise for anomaly detection, outperforming noiseless simulations in some cases, but is vulnerable to adversarial attacks and certain quantum noises.", "motivation": "To explore quantum ML's potential for robust anomaly detection, leveraging quantum kernel methods and addressing challenges in the NISQ era.", "method": "Comprehensive benchmarking of QSVR on IBM quantum hardware using eleven datasets, analyzing performance under various quantum noises and adversarial attacks.", "result": "QSVR performs well, even surpassing noiseless simulations on two datasets, and shows robustness to some quantum noises but vulnerability to others and adversarial attacks.", "conclusion": "QSVR is effective for anomaly detection but needs improvements to handle adversarial attacks and specific quantum noises."}}
{"id": "2503.14331", "pdf": "https://arxiv.org/pdf/2503.14331", "abs": "https://arxiv.org/abs/2503.14331", "authors": ["Johannes Huemer", "Markus Murschitz", "Matthias Sch\u00f6rghuber", "Lukas Reisinger", "Thomas Kadiofsky", "Christoph Weidinger", "Mario Niedermeyer", "Benedikt Widy", "Marcel Zeilinger", "Csaba Beleznai", "Tobias Gl\u00fcck", "Andreas Kugi", "Patrik Zips"], "title": "ADAPT: An Autonomous Forklift for Construction Site Operation", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY"], "comment": null, "summary": "Efficient material logistics play a critical role in controlling costs and\nschedules in the construction industry. However, manual material handling\nremains prone to inefficiencies, delays, and safety risks. Autonomous forklifts\noffer a promising solution to streamline on-site logistics, reducing reliance\non human operators and mitigating labor shortages. This paper presents the\ndevelopment and evaluation of ADAPT (Autonomous Dynamic All-terrain Pallet\nTransporter), a fully autonomous off-road forklift designed for construction\nenvironments. Unlike structured warehouse settings, construction sites pose\nsignificant challenges, including dynamic obstacles, unstructured terrain, and\nvarying weather conditions. To address these challenges, our system integrates\nAI-driven perception techniques with traditional approaches for decision\nmaking, planning, and control, enabling reliable operation in complex\nenvironments. We validate the system through extensive real-world testing,\ncomparing its continuous performance against an experienced human operator\nacross various weather conditions. Our findings demonstrate that autonomous\noutdoor forklifts can operate near human-level performance, offering a viable\npath toward safer and more efficient construction logistics.", "AI": {"tldr": "ADAPT, an autonomous off-road forklift, is developed for construction sites, combining AI-driven perception with traditional methods to handle dynamic challenges. Testing shows it performs near human levels, improving safety and efficiency.", "motivation": "Manual material handling in construction is inefficient and risky. Autonomous forklifts can address these issues and labor shortages.", "method": "Developed ADAPT, integrating AI-driven perception with traditional decision-making, planning, and control for complex environments. Tested in real-world conditions against human operators.", "result": "ADAPT operates near human-level performance in various weather conditions, proving its viability for construction logistics.", "conclusion": "Autonomous forklifts like ADAPT can enhance safety and efficiency in construction, offering a practical solution to current challenges."}}
{"id": "2502.12354", "pdf": "https://arxiv.org/pdf/2502.12354", "abs": "https://arxiv.org/abs/2502.12354", "authors": ["Yongsu Ahn", "Yu-Ru Lin", "Malihe Alikhani", "Eunjeong Cheon"], "title": "Human-centered explanation does not fit all: The interplay of sociotechnical, cognitive, and individual factors in the effect AI explanations in algorithmic decision-making", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Recent XAI studies have investigated what constitutes a \\textit{good}\nexplanation in AI-assisted decision-making. Despite the widely accepted\nhuman-friendly properties of explanations, such as contrastive and selective,\nexisting studies have yielded inconsistent findings. To address these gaps, our\nstudy focuses on the cognitive dimensions of explanation evaluation, by\nevaluating six explanations with different contrastive strategies and\ninformation selectivity and scrutinizing factors behind their valuation\nprocess. Our analysis results find that contrastive explanations are not the\nmost preferable or understandable in general; Rather, different contrastive and\nselective explanations were appreciated to a different extent based on who they\nare, when, how, and what to explain -- with different level of cognitive load\nand engagement and sociotechnical contexts. Given these findings, we call for a\nnuanced view of explanation strategies, with implications for designing AI\ninterfaces to accommodate individual and contextual differences in AI-assisted\ndecision-making.", "AI": {"tldr": "Contrastive explanations in AI-assisted decision-making are not universally preferred; their effectiveness depends on individual and contextual factors like cognitive load and sociotechnical settings.", "motivation": "To address inconsistent findings about what makes a good explanation in AI-assisted decision-making, focusing on cognitive dimensions.", "method": "Evaluated six explanations with varying contrastive strategies and information selectivity, analyzing factors behind their valuation.", "result": "Contrastive explanations are not generally preferred; effectiveness varies based on individual and contextual factors.", "conclusion": "A nuanced approach to explanation strategies is needed, considering individual and contextual differences in AI interface design."}}
{"id": "2505.01037", "pdf": "https://arxiv.org/pdf/2505.01037", "abs": "https://arxiv.org/abs/2505.01037", "authors": ["Zihan Zhou", "Muhammad Qasim Elahi", "Murat Kocaoglu"], "title": "Characterization and Learning of Causal Graphs from Hard Interventions", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A fundamental challenge in the empirical sciences involves uncovering causal\nstructure through observation and experimentation. Causal discovery entails\nlinking the conditional independence (CI) invariances in observational data to\ntheir corresponding graphical constraints via d-separation. In this paper, we\nconsider a general setting where we have access to data from multiple\nexperimental distributions resulting from hard interventions, as well as\npotentially from an observational distribution. By comparing different\ninterventional distributions, we propose a set of graphical constraints that\nare fundamentally linked to Pearl's do-calculus within the framework of hard\ninterventions. These graphical constraints associate each graphical structure\nwith a set of interventional distributions that are consistent with the rules\nof do-calculus. We characterize the interventional equivalence class of causal\ngraphs with latent variables and introduce a graphical representation that can\nbe used to determine whether two causal graphs are interventionally equivalent,\ni.e., whether they are associated with the same family of hard interventional\ndistributions, where the elements of the family are indistinguishable using the\ninvariances from do-calculus. We also propose a learning algorithm to integrate\nmultiple datasets from hard interventions, introducing new orientation rules.\nThe learning objective is a tuple of augmented graphs which entails a set of\ncausal graphs. We also prove the soundness of the proposed algorithm.", "AI": {"tldr": "The paper addresses causal discovery using observational and interventional data, proposing graphical constraints linked to Pearl's do-calculus for hard interventions. It introduces a learning algorithm for integrating multiple datasets and proves its soundness.", "motivation": "To uncover causal structure by leveraging observational and interventional data, addressing the challenge of linking conditional independence invariances to graphical constraints.", "method": "Proposes graphical constraints for hard interventions, introduces a learning algorithm with new orientation rules, and uses augmented graphs to represent causal graphs.", "result": "Characterizes interventional equivalence classes of causal graphs with latent variables and proves the soundness of the proposed algorithm.", "conclusion": "The framework and algorithm provide a robust method for causal discovery using interventional data, with theoretical guarantees."}}
{"id": "2504.21331", "pdf": "https://arxiv.org/pdf/2504.21331", "abs": "https://arxiv.org/abs/2504.21331", "authors": ["Alfred Yan", "Muhammad Nur Talha Kilic", "Gert Nolze", "Ankit Agrawal", "Alok Choudhary", "Roberto dos Reis", "Vinayak Dravid"], "title": "Towards Space Group Determination from EBSD Patterns: The Role of Deep Learning and High-throughput Dynamical Simulations", "categories": ["cond-mat.mtrl-sci", "cs.CV"], "comment": "33 pages, preliminary version", "summary": "The design of novel materials hinges on the understanding of\nstructure-property relationships. However, in recent times, our capability to\nsynthesize a large number of materials has outpaced our speed at characterizing\nthem. While the overall chemical constituents can be readily known during\nsynthesis, the structural evolution and characterization of newly synthesized\nsamples remains a bottleneck for the ultimate goal of high throughput\nnanomaterials discovery. Thus, scalable methods for crystal symmetry\ndetermination that can analyze a large volume of material samples within a\nshort time-frame are especially needed. Kikuchi diffraction in the SEM is a\npromising technique for this due to its sensitivity to dynamical scattering,\nwhich may provide information beyond just the seven crystal systems and\nfourteen Bravais lattices. After diffraction patterns are collected from\nmaterial samples, deep learning methods may be able to classify the space group\nsymmetries using the patterns as input, which paired with the elemental\ncomposition, would help enable the determination of the crystal structure. To\ninvestigate the feasibility of this solution, neural networks were trained to\npredict the space group type of background corrected EBSD patterns. Our\nnetworks were first trained and tested on an artificial dataset of EBSD\npatterns of 5,148 different cubic phases, created through physics-based\ndynamical simulations. Next, Maximum Classifier Discrepancy, an unsupervised\ndeep learning-based domain adaptation method, was utilized to train neural\nnetworks to make predictions for experimental EBSD patterns. We introduce a\nrelabeling scheme, which enables our models to achieve accuracy scores higher\nthan 90% on simulated and experimental data, suggesting that neural networks\nare capable of making predictions of crystal symmetry from an EBSD pattern.", "AI": {"tldr": "The paper proposes using deep learning to classify crystal symmetry from EBSD patterns, achieving over 90% accuracy on simulated and experimental data.", "motivation": "The need for scalable methods to determine crystal symmetry quickly due to the bottleneck in characterizing newly synthesized materials.", "method": "Training neural networks on artificial EBSD patterns and using unsupervised domain adaptation for experimental data.", "result": "Neural networks achieved over 90% accuracy in predicting crystal symmetry from EBSD patterns.", "conclusion": "Deep learning is feasible for high-throughput crystal symmetry determination from EBSD patterns."}}
{"id": "2503.02636", "pdf": "https://arxiv.org/pdf/2503.02636", "abs": "https://arxiv.org/abs/2503.02636", "authors": ["Yeganeh Farahzadi", "Morteza Ansarinia", "Zoltan Kekecs"], "title": "YARE-GAN: Yet Another Resting State EEG-GAN", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "In this study, we implement a Wasserstein GAN with Gradient Penalty (WGAN-GP)\nto generate multi-channel resting-state EEG data and assess the quality of the\nsynthesized signals through both visual and feature-based evaluations. Our\nresults indicate that the model effectively captures the statistical and\nspectral characteristics of real EEG data, although challenges remain in\nreplicating high-frequency oscillations in the frontal region. Additionally, we\ndemonstrate that the Critic's learned representations can be reused for gender\nclassification task, achieving an out-of-sample accuracy, significantly better\nthan a shuffled-label baseline and a model trained directly on EEG data. These\nfindings suggest that generative models can serve not only as EEG data\ngenerators but also as unsupervised feature extractors, reducing the need for\nmanual feature engineering. This study highlights the potential of GAN-based\nunsupervised learning for EEG analysis, suggesting avenues for more\ndata-efficient deep learning applications in neuroscience.", "AI": {"tldr": "WGAN-GP generates realistic EEG data and doubles as a feature extractor for gender classification, outperforming manual methods.", "motivation": "To explore GANs for EEG data generation and feature extraction, reducing manual effort in neuroscience.", "method": "Implemented WGAN-GP to synthesize multi-channel EEG data, evaluated visually and via features, and reused Critic's features for gender classification.", "result": "Model captures EEG statistics well but struggles with high-frequency frontal oscillations. Critic's features improve gender classification accuracy.", "conclusion": "GANs can generate EEG data and extract useful features, offering data-efficient solutions for neuroscience."}}
{"id": "2505.01107", "pdf": "https://arxiv.org/pdf/2505.01107", "abs": "https://arxiv.org/abs/2505.01107", "authors": ["Yingjie Qi", "Jianlei Yang", "Yiou Wang", "Yikun Wang", "Dayu Wang", "Ling Tang", "Cenlin Duan", "Xiaolin He", "Weisheng Zhao"], "title": "CIMFlow: An Integrated Framework for Systematic Design and Evaluation of Digital CIM Architectures", "categories": ["cs.AR", "cs.LG"], "comment": "7 pages, accepted by DAC 2025", "summary": "Digital Compute-in-Memory (CIM) architectures have shown great promise in\nDeep Neural Network (DNN) acceleration by effectively addressing the \"memory\nwall\" bottleneck. However, the development and optimization of digital CIM\naccelerators are hindered by the lack of comprehensive tools that encompass\nboth software and hardware design spaces. Moreover, existing design and\nevaluation frameworks often lack support for the capacity constraints inherent\nin digital CIM architectures. In this paper, we present CIMFlow, an integrated\nframework that provides an out-of-the-box workflow for implementing and\nevaluating DNN workloads on digital CIM architectures. CIMFlow bridges the\ncompilation and simulation infrastructures with a flexible instruction set\narchitecture (ISA) design, and addresses the constraints of digital CIM through\nadvanced partitioning and parallelism strategies in the compilation flow. Our\nevaluation demonstrates that CIMFlow enables systematic prototyping and\noptimization of digital CIM architectures across diverse configurations,\nproviding researchers and designers with an accessible platform for extensive\ndesign space exploration.", "AI": {"tldr": "CIMFlow is an integrated framework for implementing and evaluating DNN workloads on digital CIM architectures, addressing software and hardware design gaps.", "motivation": "The lack of comprehensive tools for digital CIM accelerator development and optimization, along with unsupported capacity constraints in existing frameworks, motivates this work.", "method": "CIMFlow combines compilation and simulation infrastructures with a flexible ISA design, using advanced partitioning and parallelism strategies to address digital CIM constraints.", "result": "CIMFlow enables systematic prototyping and optimization of digital CIM architectures, facilitating extensive design space exploration.", "conclusion": "CIMFlow provides an accessible platform for researchers and designers to explore and optimize digital CIM architectures effectively."}}
{"id": "2503.03045", "pdf": "https://arxiv.org/pdf/2503.03045", "abs": "https://arxiv.org/abs/2503.03045", "authors": ["Yufei Wang", "Ziyu Wang", "Mino Nakura", "Pratik Bhowal", "Chia-Liang Kuo", "Yi-Ting Chen", "Zackory Erickson", "David Held"], "title": "ArticuBot: Learning Universal Articulated Object Manipulation Policy via Large Scale Simulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted at RSS 2025", "summary": "This paper presents ArticuBot, in which a single learned policy enables a\nrobotics system to open diverse categories of unseen articulated objects in the\nreal world. This task has long been challenging for robotics due to the large\nvariations in the geometry, size, and articulation types of such objects. Our\nsystem, Articubot, consists of three parts: generating a large number of\ndemonstrations in physics-based simulation, distilling all generated\ndemonstrations into a point cloud-based neural policy via imitation learning,\nand performing zero-shot sim2real transfer to real robotics systems. Utilizing\nsampling-based grasping and motion planning, our demonstration generalization\npipeline is fast and effective, generating a total of 42.3k demonstrations over\n322 training articulated objects. For policy learning, we propose a novel\nhierarchical policy representation, in which the high-level policy learns the\nsub-goal for the end-effector, and the low-level policy learns how to move the\nend-effector conditioned on the predicted goal. We demonstrate that this\nhierarchical approach achieves much better object-level generalization compared\nto the non-hierarchical version. We further propose a novel weighted\ndisplacement model for the high-level policy that grounds the prediction into\nthe existing 3D structure of the scene, outperforming alternative policy\nrepresentations. We show that our learned policy can zero-shot transfer to\nthree different real robot settings: a fixed table-top Franka arm across two\ndifferent labs, and an X-Arm on a mobile base, opening multiple unseen\narticulated objects across two labs, real lounges, and kitchens. Videos and\ncode can be found on our project website: https://articubot.github.io/.", "AI": {"tldr": "ArticuBot is a robotics system that uses a single learned policy to open diverse unseen articulated objects in the real world, leveraging simulation, imitation learning, and sim2real transfer.", "motivation": "The challenge lies in the large variations in geometry, size, and articulation types of articulated objects, making it difficult for robots to generalize.", "method": "The system generates demonstrations in simulation, distills them into a point cloud-based neural policy via imitation learning, and uses hierarchical policy representation for better generalization.", "result": "The policy achieves zero-shot transfer to real robots, successfully opening unseen articulated objects in various real-world settings.", "conclusion": "ArticuBot demonstrates effective generalization and sim2real transfer, outperforming non-hierarchical approaches."}}
{"id": "2505.01112", "pdf": "https://arxiv.org/pdf/2505.01112", "abs": "https://arxiv.org/abs/2505.01112", "authors": ["Riccardo Busetto", "Manas Mejari", "Marco Forgione", "Alberto Bemporad", "Dario Piga"], "title": "Learning Low-Dimensional Embeddings for Black-Box Optimization", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "When gradient-based methods are impractical, black-box optimization (BBO)\nprovides a valuable alternative. However, BBO often struggles with\nhigh-dimensional problems and limited trial budgets. In this work, we propose a\nnovel approach based on meta-learning to pre-compute a reduced-dimensional\nmanifold where optimal points lie for a specific class of optimization\nproblems. When optimizing a new problem instance sampled from the class,\nblack-box optimization is carried out in the reduced-dimensional space,\neffectively reducing the effort required for finding near-optimal solutions.", "AI": {"tldr": "A meta-learning approach reduces dimensionality for black-box optimization, improving efficiency in high-dimensional problems.", "motivation": "Gradient-based methods are impractical in some cases, and black-box optimization struggles with high dimensions and limited trials.", "method": "Pre-compute a reduced-dimensional manifold for a class of problems, then optimize new instances in this space.", "result": "Efficiently finds near-optimal solutions by reducing the search space.", "conclusion": "Meta-learning enables effective black-box optimization for high-dimensional problems."}}
{"id": "2504.14204", "pdf": "https://arxiv.org/pdf/2504.14204", "abs": "https://arxiv.org/abs/2504.14204", "authors": ["Wenxin Zhang", "Xiaojian Lin", "Wenjun Yu", "Guangzhen Yao", "jingxiang Zhong", "Yu Li", "Renda Han", "Songcheng Xu", "Hao Shi", "Cuicui Luo"], "title": "DConAD: A Differencing-based Contrastive Representation Learning Framework for Time Series Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series anomaly detection holds notable importance for risk\nidentification and fault detection across diverse application domains.\nUnsupervised learning methods have become popular because they have no\nrequirement for labels. However, due to the challenges posed by the\nmultiplicity of abnormal patterns, the sparsity of anomalies, and the growth of\ndata scale and complexity, these methods often fail to capture robust and\nrepresentative dependencies within the time series for identifying anomalies.\nTo enhance the ability of models to capture normal patterns of time series and\navoid the retrogression of modeling ability triggered by the dependencies on\nhigh-quality prior knowledge, we propose a differencing-based contrastive\nrepresentation learning framework for time series anomaly detection (DConAD).\nSpecifically, DConAD generates differential data to provide additional\ninformation about time series and utilizes transformer-based architecture to\ncapture spatiotemporal dependencies, which enhances the robustness of unbiased\nrepresentation learning ability. Furthermore, DConAD implements a novel KL\ndivergence-based contrastive learning paradigm that only uses positive samples\nto avoid deviation from reconstruction and deploys the stop-gradient strategy\nto compel convergence. Extensive experiments on five public datasets show the\nsuperiority and effectiveness of DConAD compared with nine baselines. The code\nis available at https://github.com/shaieesss/DConAD.", "AI": {"tldr": "DConAD is a differencing-based contrastive representation learning framework for unsupervised time series anomaly detection, leveraging transformer architecture and KL divergence-based contrastive learning to improve robustness and avoid dependency on prior knowledge.", "motivation": "Unsupervised methods for time series anomaly detection often struggle with capturing robust dependencies due to abnormal pattern multiplicity, anomaly sparsity, and data complexity.", "method": "DConAD uses differential data for additional insights, transformer-based spatiotemporal dependency capture, and a KL divergence-based contrastive learning paradigm with positive samples and stop-gradient strategy.", "result": "Experiments on five datasets demonstrate DConAD's superiority over nine baselines.", "conclusion": "DConAD effectively enhances anomaly detection by improving representation learning robustness and avoiding prior knowledge dependency."}}
{"id": "2505.01118", "pdf": "https://arxiv.org/pdf/2505.01118", "abs": "https://arxiv.org/abs/2505.01118", "authors": ["S. Kondati Natarajan", "J. Schneider", "N. Pandey", "J. Wellendorff", "S. Smidstrup"], "title": "On Simulating Thin-Film Processes at the Atomic Scale Using Machine Learned Force Fields", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": "35 pages, 18 figures", "summary": "Atomistic modeling of thin-film processes provides an avenue not only for\ndiscovering key chemical mechanisms of the processes but also to extract\nquantitative metrics on the events and reactions taking place at the\ngas-surface interface. Molecular dynamics (MD) is a powerful computational\nmethod to study the evolution of a process at the atomic scale, but studies of\nindustrially relevant processes usually require suitable force fields, which\nare in general not available for all processes of interest. However, machine\nlearned force fields (MLFF) are conquering the field of computational materials\nand surface science. In this paper, we demonstrate how to efficiently build\nMLFFs suitable for process simulations and provide two examples for\ntechnologically relevant processes: precursor pulse in the atomic layer\ndeposition of HfO2 and atomic layer etching of MoS2.", "AI": {"tldr": "The paper discusses using machine-learned force fields (MLFFs) for atomistic modeling of thin-film processes, demonstrating their application in atomic layer deposition and etching.", "motivation": "To address the lack of suitable force fields for industrially relevant processes, the paper explores MLFFs as a solution for accurate atomistic modeling.", "method": "The authors propose an efficient method to build MLFFs and apply them to simulate two processes: HfO2 atomic layer deposition and MoS2 atomic layer etching.", "result": "The study demonstrates the feasibility and effectiveness of MLFFs in modeling complex thin-film processes at the atomic scale.", "conclusion": "MLFFs are a promising tool for computational materials and surface science, enabling detailed study of industrially relevant processes."}}
{"id": "2504.18814", "pdf": "https://arxiv.org/pdf/2504.18814", "abs": "https://arxiv.org/abs/2504.18814", "authors": ["Abdelaziz Amara Korba", "Nour Elislem Karabadji", "Yacine Ghamri-Doudane"], "title": "Zero-Day Botnet Attack Detection in IoV: A Modular Approach Using Isolation Forests and Particle Swarm Optimization", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The Internet of Vehicles (IoV) is transforming transportation by enhancing\nconnectivity and enabling autonomous driving. However, this increased\ninterconnectivity introduces new security vulnerabilities. Bot malware and\ncyberattacks pose significant risks to Connected and Autonomous Vehicles\n(CAVs), as demonstrated by real-world incidents involving remote vehicle system\ncompromise. To address these challenges, we propose an edge-based Intrusion\nDetection System (IDS) that monitors network traffic to and from CAVs. Our\ndetection model is based on a meta-ensemble classifier capable of recognizing\nknown (Nday) attacks and detecting previously unseen (zero-day) attacks. The\napproach involves training multiple Isolation Forest (IF) models on\nMulti-access Edge Computing (MEC) servers, with each IF specialized in\nidentifying a specific type of botnet attack. These IFs, either trained locally\nor shared by other MEC nodes, are then aggregated using a Particle Swarm\nOptimization (PSO) based stacking strategy to construct a robust\nmeta-classifier. The proposed IDS has been evaluated on a vehicular botnet\ndataset, achieving an average detection rate of 92.80% for N-day attacks and\n77.32% for zero-day attacks. These results highlight the effectiveness of our\nsolution in detecting both known and emerging threats, providing a scalable and\nadaptive defense mechanism for CAVs within the IoV ecosystem.", "AI": {"tldr": "Proposes an edge-based IDS for CAVs using a meta-ensemble classifier to detect known and zero-day botnet attacks, achieving high detection rates.", "motivation": "Addresses security vulnerabilities in IoV, particularly bot malware and cyberattacks on CAVs, demonstrated by real-world incidents.", "method": "Uses Isolation Forest models on MEC servers, aggregated via PSO-based stacking to create a meta-classifier.", "result": "Achieves 92.80% detection for known attacks and 77.32% for zero-day attacks.", "conclusion": "The IDS is effective, scalable, and adaptive for securing CAVs in IoV."}}
{"id": "2505.01136", "pdf": "https://arxiv.org/pdf/2505.01136", "abs": "https://arxiv.org/abs/2505.01136", "authors": ["Phuoc Pham", "Murali Sridharan", "Matteo Esposito", "Valentina Lenarduzzi"], "title": "CppSATD: A Reusable Self-Admitted Technical Debt Dataset in C++", "categories": ["cs.SE", "cs.IR", "cs.LG", "cs.PL"], "comment": null, "summary": "In software development, technical debt (TD) refers to suboptimal\nimplementation choices made by the developers to meet urgent deadlines and\nlimited resources, posing challenges for future maintenance. Self-Admitted\nTechnical Debt (SATD) is a sub-type of TD, representing specific TD instances\n``openly admitted'' by the developers and often expressed through source code\ncomments. Previous research on SATD has focused predominantly on the Java\nprogramming language, revealing a significant gap in cross-language SATD. Such\na narrow focus limits the generalizability of existing findings as well as SATD\ndetection techniques across multiple programming languages. Our work addresses\nsuch limitation by introducing CppSATD, a dedicated C++ SATD dataset,\ncomprising over 531,000 annotated comments and their source code contexts. Our\ndataset can serve as a foundation for future studies that aim to develop SATD\ndetection methods in C++, generalize the existing findings to other languages,\nor contribute novel insights to cross-language SATD research.", "AI": {"tldr": "The paper introduces CppSATD, a C++ dataset for Self-Admitted Technical Debt (SATD) research, addressing gaps in cross-language SATD studies.", "motivation": "Existing SATD research focuses mainly on Java, limiting generalizability. This work aims to bridge the gap by providing a C++ dataset.", "method": "The authors created CppSATD, a dataset with over 531,000 annotated comments and their source code contexts.", "result": "The dataset enables future research on SATD detection in C++ and cross-language generalization.", "conclusion": "CppSATD supports broader SATD studies and enhances detection techniques across languages."}}
{"id": "2504.19139", "pdf": "https://arxiv.org/pdf/2504.19139", "abs": "https://arxiv.org/abs/2504.19139", "authors": ["Yun Qu", "Qi Cheems Wang", "Yixiu Mao", "Yiqin Lv", "Xiangyang Ji"], "title": "Fast and Robust: Task Sampling with Posterior and Diversity Synergies for Adaptive Decision-Makers in Randomized Environments", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Task robust adaptation is a long-standing pursuit in sequential\ndecision-making. Some risk-averse strategies, e.g., the conditional\nvalue-at-risk principle, are incorporated in domain randomization or meta\nreinforcement learning to prioritize difficult tasks in optimization, which\ndemand costly intensive evaluations. The efficiency issue prompts the\ndevelopment of robust active task sampling to train adaptive policies, where\nrisk-predictive models are used to surrogate policy evaluation. This work\ncharacterizes the optimization pipeline of robust active task sampling as a\nMarkov decision process, posits theoretical and practical insights, and\nconstitutes robustness concepts in risk-averse scenarios. Importantly, we\npropose an easy-to-implement method, referred to as Posterior and Diversity\nSynergized Task Sampling (PDTS), to accommodate fast and robust sequential\ndecision-making. Extensive experiments show that PDTS unlocks the potential of\nrobust active task sampling, significantly improves the zero-shot and few-shot\nadaptation robustness in challenging tasks, and even accelerates the learning\nprocess under certain scenarios. Our project website is at\nhttps://thu-rllab.github.io/PDTS_project_page.", "AI": {"tldr": "The paper introduces PDTS, a method for robust active task sampling in sequential decision-making, improving adaptation robustness and learning efficiency.", "motivation": "Addressing the efficiency and robustness issues in task-averse strategies like domain randomization and meta reinforcement learning.", "method": "Proposes PDTS, a method combining posterior and diversity synergized task sampling, framed as a Markov decision process.", "result": "PDTS enhances zero-shot and few-shot adaptation robustness and accelerates learning in challenging tasks.", "conclusion": "PDTS is effective for robust sequential decision-making, with practical benefits demonstrated in experiments."}}
{"id": "2505.01178", "pdf": "https://arxiv.org/pdf/2505.01178", "abs": "https://arxiv.org/abs/2505.01178", "authors": ["Puria Radmard", "Paul M. Bays", "M\u00e1t\u00e9 Lengyel"], "title": "A flexible Bayesian non-parametric mixture model reveals multiple dependencies of swap errors in visual working memory", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Human behavioural data in psychophysics has been used to elucidate the\nunderlying mechanisms of many cognitive processes, such as attention,\nsensorimotor integration, and perceptual decision making. Visual working memory\nhas particularly benefited from this approach: analyses of VWM errors have\nproven crucial for understanding VWM capacity and coding schemes, in turn\nconstraining neural models of both. One poorly understood class of VWM errors\nare swap errors, whereby participants recall an uncued item from memory. Swap\nerrors could arise from erroneous memory encoding, noisy storage, or errors at\nretrieval time - previous research has mostly implicated the latter two.\nHowever, these studies made strong a priori assumptions on the detailed\nmechanisms and/or parametric form of errors contributed by these sources. Here,\nwe pursue a data-driven approach instead, introducing a Bayesian non-parametric\nmixture model of swap errors (BNS) which provides a flexible descriptive model\nof swapping behaviour, such that swaps are allowed to depend on both the probed\nand reported features of every stimulus item. We fit BNS to the trial-by-trial\nbehaviour of human participants and show that it recapitulates the strong\ndependence of swaps on cue similarity in multiple datasets. Critically, BNS\nreveals that this dependence coexists with a non-monotonic modulation in the\nreport feature dimension for a random dot motion direction-cued,\nlocation-reported dataset. The form of the modulation inferred by BNS opens new\nquestions about the importance of memory encoding in causing swap errors in\nVWM, a distinct source to the previously suggested binding and cueing errors.\nOur analyses, combining qualitative comparisons of the highly interpretable BNS\nparameter structure with rigorous quantitative model comparison and recovery\nmethods, show that previous interpretations of swap errors may have been\nincomplete.", "AI": {"tldr": "A Bayesian non-parametric mixture model (BNS) is introduced to analyze swap errors in visual working memory, revealing new insights into their dependence on cue similarity and suggesting encoding errors as a previously overlooked source.", "motivation": "To address the poorly understood class of swap errors in visual working memory (VWM) by moving beyond strong a priori assumptions and adopting a data-driven approach.", "method": "A Bayesian non-parametric mixture model (BNS) is developed to flexibly describe swap errors, allowing dependencies on probed and reported features of stimuli. The model is fitted to human behavioral data.", "result": "BNS recapitulates the strong dependence of swaps on cue similarity and reveals a non-monotonic modulation in the report feature dimension, suggesting encoding errors as a new source of swap errors.", "conclusion": "The findings challenge previous interpretations of swap errors, highlighting the importance of encoding errors and demonstrating the utility of BNS for uncovering nuanced behavioral patterns in VWM."}}
{"id": "2505.00598", "pdf": "https://arxiv.org/pdf/2505.00598", "abs": "https://arxiv.org/abs/2505.00598", "authors": ["Haozheng Luo", "Chenghao Qiu", "Maojiang Su", "Zhihan Zhou", "Zoe Mehta", "Guo Ye", "Jerry Yao-Chieh Hu", "Han Liu"], "title": "Fast and Low-Cost Genomic Foundation Models via Outlier Removal", "categories": ["cs.LG", "cs.AI"], "comment": "International Conference on Machine Learning (ICML) 2025", "summary": "To address the challenge of scarce computational resources in genomic\nmodeling, we introduce GERM, a genomic foundation model with strong compression\nperformance and fast adaptability. GERM improves upon models like DNABERT-2 by\neliminating outliers that hinder low-rank adaptation and post-training\nquantization, enhancing both efficiency and robustness. We replace the vanilla\nattention layer with an outlier-free mechanism inspired by associative memory\nmodels. By removing outliers during both pre-training and fine-tuning, this\napproach accelerates adaptation, reduces computational costs, and enhances\nquantization robustness within acceptable loss margins. Additionally, we\npropose GERM-T, a strategy that employs small-step continual learning within\nthe outlier-free framework, leveraging original checkpoints to avoid retraining\nfrom scratch. Empirically, GERM improves fine-tuning performance by 37.98% and\nquantization by 64.34% over the baseline model. It also reduces average\nkurtosis by 92.14% and maximum infinity norm by 82.77%. Compared to leading\nmethods, GERM consistently delivers superior performance, offering a practical\nsolution for genomic modeling in resource-constrained settings. Code is\navailable at https://github.com/MAGICS-LAB/GERM.", "AI": {"tldr": "GERM is a genomic foundation model addressing computational resource scarcity by improving compression, adaptability, and robustness, outperforming baseline models in fine-tuning and quantization.", "motivation": "The challenge of scarce computational resources in genomic modeling motivates the development of GERM, which enhances efficiency and robustness.", "method": "GERM replaces vanilla attention with an outlier-free mechanism and introduces GERM-T for continual learning, improving pre-training and fine-tuning.", "result": "GERM improves fine-tuning by 37.98%, quantization by 64.34%, reduces kurtosis by 92.14%, and infinity norm by 82.77%.", "conclusion": "GERM offers a practical, efficient solution for genomic modeling in resource-constrained settings, consistently outperforming leading methods."}}
{"id": "2505.01197", "pdf": "https://arxiv.org/pdf/2505.01197", "abs": "https://arxiv.org/abs/2505.01197", "authors": ["Holger Dette", "Carina Graw"], "title": "Gaussian Differential Private Bootstrap by Subsampling", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.CO", "stat.TH"], "comment": null, "summary": "Bootstrap is a common tool for quantifying uncertainty in data analysis.\nHowever, besides additional computational costs in the application of the\nbootstrap on massive data, a challenging problem in bootstrap based inference\nunder Differential Privacy consists in the fact that it requires repeated\naccess to the data. As a consequence, bootstrap based differentially private\ninference requires a significant increase of the privacy budget, which on the\nother hand comes with a substantial loss in statistical accuracy.\n  A potential solution to reconcile the conflicting goals of statistical\naccuracy and privacy is to analyze the data under parametric model assumptions\nand in the last decade, several parametric bootstrap methods for inference\nunder privacy have been investigated. However, uncertainty quantification by\nparametric bootstrap is only valid if the the quantities of interest can be\nidentified as the parameters of a statistical model and the imposed model\nassumptions are (at least approximately) satisfied. An alternative to\nparametric methods is the empirical bootstrap that is a widely used tool for\nnon-parametric inference and well studied in the non-private regime. However,\nunder privacy, less insight is available. In this paper, we propose a private\nempirical $m$ out of $n$ bootstrap and validate its consistency and privacy\nguarantees under Gaussian Differential Privacy. Compared to the the private $n$\nout of $n$ bootstrap, our approach has several advantages. First, it comes with\nless computational costs, in particular for massive data. Second, the proposed\nprocedure needs less additional noise in the bootstrap iterations, which leads\nto an improved statistical accuracy while asymptotically guaranteeing the same\nlevel of privacy. Third, we demonstrate much better finite sample properties\ncompared to the currently available procedures.", "AI": {"tldr": "The paper proposes a private empirical $m$ out of $n$ bootstrap method for uncertainty quantification under Differential Privacy, offering computational efficiency, improved statistical accuracy, and strong privacy guarantees.", "motivation": "Bootstrap methods for uncertainty quantification under Differential Privacy face challenges like high computational costs and privacy budget inflation. Existing parametric methods are limited by model assumptions, while empirical bootstrap lacks privacy insights.", "method": "The authors introduce a private empirical $m$ out of $n$ bootstrap, validated under Gaussian Differential Privacy, reducing computational costs and noise addition compared to traditional $n$ out of $n$ bootstrap.", "result": "The proposed method shows better computational efficiency, reduced noise impact, and superior finite sample performance while maintaining privacy guarantees.", "conclusion": "The private empirical $m$ out of $n$ bootstrap is a viable solution for balancing statistical accuracy and privacy in uncertainty quantification, outperforming existing methods."}}
{"id": "2505.01258", "pdf": "https://arxiv.org/pdf/2505.01258", "abs": "https://arxiv.org/abs/2505.01258", "authors": ["Tianshu Chu", "Dachuan Xu", "Wei Yao", "Chengming Yu", "Jin Zhang"], "title": "A Provably Convergent Plug-and-Play Framework for Stochastic Bilevel Optimization", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "Bilevel optimization has recently attracted significant attention in machine\nlearning due to its wide range of applications and advanced hierarchical\noptimization capabilities. In this paper, we propose a plug-and-play framework,\nnamed PnPBO, for developing and analyzing stochastic bilevel optimization\nmethods. This framework integrates both modern unbiased and biased stochastic\nestimators into the single-loop bilevel optimization framework introduced in\n[9], with several improvements. In the implementation of PnPBO, all stochastic\nestimators for different variables can be independently incorporated, and an\nadditional moving average technique is applied when using an unbiased estimator\nfor the upper-level variable. In the theoretical analysis, we provide a unified\nconvergence and complexity analysis for PnPBO, demonstrating that the\nadaptation of various stochastic estimators (including PAGE, ZeroSARAH, and\nmixed strategies) within the PnPBO framework achieves optimal sample\ncomplexity, comparable to that of single-level optimization. This resolves the\nopen question of whether the optimal complexity bounds for solving bilevel\noptimization are identical to those for single-level optimization. Finally, we\nempirically validate our framework, demonstrating its effectiveness on several\nbenchmark problems and confirming our theoretical findings.", "AI": {"tldr": "The paper introduces PnPBO, a plug-and-play framework for stochastic bilevel optimization, integrating unbiased and biased estimators with optimal sample complexity.", "motivation": "Bilevel optimization is widely used in machine learning, but existing methods lack flexibility and optimal complexity.", "method": "PnPBO integrates various stochastic estimators into a single-loop framework, using moving averages for unbiased upper-level estimators.", "result": "The framework achieves optimal sample complexity, matching single-level optimization, and performs well empirically.", "conclusion": "PnPBO resolves the complexity question and proves effective in benchmarks, validating its theoretical and practical utility."}}
{"id": "2505.01319", "pdf": "https://arxiv.org/pdf/2505.01319", "abs": "https://arxiv.org/abs/2505.01319", "authors": ["Yifang Pan", "Karan Singh", "Luiz Gustavo Hafemann"], "title": "Model See Model Do: Speech-Driven Facial Animation with Style Control", "categories": ["cs.GR", "cs.LG", "I.3.7; I.3.8"], "comment": "10 pages, 7 figures, SIGGRAPH Conference Papers '25", "summary": "Speech-driven 3D facial animation plays a key role in applications such as\nvirtual avatars, gaming, and digital content creation. While existing methods\nhave made significant progress in achieving accurate lip synchronization and\ngenerating basic emotional expressions, they often struggle to capture and\neffectively transfer nuanced performance styles. We propose a novel\nexample-based generation framework that conditions a latent diffusion model on\na reference style clip to produce highly expressive and temporally coherent\nfacial animations. To address the challenge of accurately adhering to the style\nreference, we introduce a novel conditioning mechanism called style basis,\nwhich extracts key poses from the reference and additively guides the diffusion\ngeneration process to fit the style without compromising lip synchronization\nquality. This approach enables the model to capture subtle stylistic cues while\nensuring that the generated animations align closely with the input speech.\nExtensive qualitative, quantitative, and perceptual evaluations demonstrate the\neffectiveness of our method in faithfully reproducing the desired style while\nachieving superior lip synchronization across various speech scenarios.", "AI": {"tldr": "A novel framework using a latent diffusion model and style basis conditioning for expressive, style-adherent 3D facial animation from speech.", "motivation": "Existing methods lack nuanced performance style transfer in speech-driven facial animation.", "method": "Example-based generation with a latent diffusion model, guided by a style basis mechanism for accurate style adherence.", "result": "Produces highly expressive, temporally coherent animations with superior lip sync.", "conclusion": "The method effectively captures stylistic cues and aligns animations with speech input."}}
{"id": "2505.01382", "pdf": "https://arxiv.org/pdf/2505.01382", "abs": "https://arxiv.org/abs/2505.01382", "authors": ["Gen Li", "Yuchen Jiao"], "title": "Provable Efficiency of Guidance in Diffusion Models for General Data Distribution", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Diffusion models have emerged as a powerful framework for generative\nmodeling, with guidance techniques playing a crucial role in enhancing sample\nquality. Despite their empirical success, a comprehensive theoretical\nunderstanding of the guidance effect remains limited. Existing studies only\nfocus on case studies, where the distribution conditioned on each class is\neither isotropic Gaussian or supported on a one-dimensional interval with some\nextra conditions. How to analyze the guidance effect beyond these case studies\nremains an open question. Towards closing this gap, we make an attempt to\nanalyze diffusion guidance under general data distributions. Rather than\ndemonstrating uniform sample quality improvement, which does not hold in some\ndistributions, we prove that guidance can improve the whole sample quality, in\nthe sense that the average reciprocal of the classifier probability decreases\nwith the existence of guidance. This aligns with the motivation of introducing\nguidance.", "AI": {"tldr": "The paper analyzes diffusion guidance theoretically under general data distributions, proving it improves overall sample quality by reducing the average reciprocal of classifier probability.", "motivation": "To address the lack of theoretical understanding of diffusion guidance beyond limited case studies.", "method": "Analyzes diffusion guidance under general data distributions, focusing on the average reciprocal of classifier probability.", "result": "Guidance improves overall sample quality, as evidenced by the decrease in the average reciprocal of classifier probability.", "conclusion": "The study provides a theoretical foundation for diffusion guidance, showing its effectiveness in enhancing sample quality broadly."}}
{"id": "2505.01423", "pdf": "https://arxiv.org/pdf/2505.01423", "abs": "https://arxiv.org/abs/2505.01423", "authors": ["Henry Shugart", "Jason M. Altschuler"], "title": "Negative Stepsizes Make Gradient-Descent-Ascent Converge", "categories": ["math.OC", "cs.DS", "cs.LG"], "comment": null, "summary": "Efficient computation of min-max problems is a central question in\noptimization, learning, games, and controls. Arguably the most natural\nalgorithm is gradient-descent-ascent (GDA). However, since the 1970s,\nconventional wisdom has argued that GDA fails to converge even on simple\nproblems. This failure spurred an extensive literature on modifying GDA with\nadditional building blocks such as extragradients, optimism, momentum,\nanchoring, etc. In contrast, we show that GDA converges in its original form by\nsimply using a judicious choice of stepsizes.\n  The key innovation is the proposal of unconventional stepsize schedules\n(dubbed slingshot stepsize schedules) that are time-varying, asymmetric, and\nperiodically negative. We show that all three properties are necessary for\nconvergence, and that altogether this enables GDA to converge on the classical\ncounterexamples (e.g., unconstrained convex-concave problems). All of our\nresults apply to the last iterate of GDA, as is typically desired in practice.\n  The core algorithmic intuition is that although negative stepsizes make\nbackward progress, they de-synchronize the min and max variables (overcoming\nthe cycling issue of GDA), and lead to a slingshot phenomenon in which the\nforward progress in the other iterations is overwhelmingly larger. This results\nin fast overall convergence. Geometrically, the slingshot dynamics leverage the\nnon-reversibility of gradient flow: positive/negative steps cancel to first\norder, yielding a second-order net movement in a new direction that leads to\nconvergence and is otherwise impossible for GDA to move in. We interpret this\nas a second-order finite-differencing algorithm and show that, intriguingly, it\napproximately implements consensus optimization, an empirically popular\nalgorithm for min-max problems involving deep neural networks (e.g., training\nGANs).", "AI": {"tldr": "GDA (gradient-descent-ascent) can converge with unconventional stepsize schedules, overcoming its historical failure.", "motivation": "Address the long-standing belief that GDA fails to converge, proposing a solution without additional modifications.", "method": "Introduce slingshot stepsize schedules\u2014time-varying, asymmetric, and periodically negative\u2014to ensure GDA convergence.", "result": "GDA with slingshot stepsizes converges on classical counterexamples, including unconstrained convex-concave problems.", "conclusion": "The slingshot dynamics enable GDA to achieve fast convergence, linking it to second-order finite-differencing and consensus optimization."}}
{"id": "2203.16810", "pdf": "https://arxiv.org/pdf/2203.16810", "abs": "https://arxiv.org/abs/2203.16810", "authors": ["Ayon Ghosh", "L. A. Prashanth", "Dipayan Sen", "Aditya Gopalan"], "title": "Minimum mean-squared error estimation with bandit feedback", "categories": ["cs.LG"], "comment": "A two-page extended abstract version of this paper appeared in the\n  Proceedings of the Ninth Indian Control Conference (ICC), 2023", "summary": "We consider the problem of sequentially learning to estimate, in the mean\nsquared error (MSE) sense, a Gaussian $K$-vector of unknown covariance by\nobserving only $m < K$ of its entries in each round. We propose two MSE\nestimators, and analyze their concentration properties. The first estimator is\nnon-adaptive, as it is tied to a predetermined $m$-subset and lacks the\nflexibility to transition to alternative subsets. The second estimator, which\nis derived using a regression framework, is adaptive and exhibits better\nconcentration bounds in comparison to the first estimator. We frame the MSE\nestimation problem with bandit feedback, where the objective is to find the\nMSE-optimal subset with high confidence. We propose a variant of the successive\nelimination algorithm to solve this problem. We also derive a minimax lower\nbound to understand the fundamental limit on the sample complexity of this\nproblem.", "AI": {"tldr": "The paper proposes two MSE estimators for learning a Gaussian K-vector with unknown covariance, comparing their performance and introducing an adaptive algorithm for optimal subset selection.", "motivation": "The problem involves estimating a Gaussian K-vector with limited observations (m < K) per round, aiming to minimize MSE. The challenge is to adaptively select subsets for better estimation.", "method": "Two estimators are proposed: a non-adaptive one tied to a fixed subset and an adaptive one using regression. A successive elimination algorithm is introduced for MSE-optimal subset selection.", "result": "The adaptive estimator outperforms the non-adaptive one with better concentration bounds. The algorithm aims to find the optimal subset with high confidence.", "conclusion": "The work provides theoretical insights into MSE estimation under bandit feedback, including a minimax lower bound on sample complexity."}}
{"id": "2302.08300", "pdf": "https://arxiv.org/pdf/2302.08300", "abs": "https://arxiv.org/abs/2302.08300", "authors": ["Michael I. Jordan", "Guy Kornowski", "Tianyi Lin", "Ohad Shamir", "Manolis Zampetakis"], "title": "Deterministic Nonsmooth Nonconvex Optimization", "categories": ["cs.LG", "math.OC"], "comment": "Fixed bug in proof of Lemma 6.1 (result remains unaffected)", "summary": "We study the complexity of optimizing nonsmooth nonconvex Lipschitz functions\nby producing $(\\delta,\\epsilon)$-stationary points. Several recent works have\npresented randomized algorithms that produce such points using $\\tilde\nO(\\delta^{-1}\\epsilon^{-3})$ first-order oracle calls, independent of the\ndimension $d$. It has been an open problem as to whether a similar result can\nbe obtained via a deterministic algorithm. We resolve this open problem,\nshowing that randomization is necessary to obtain a dimension-free rate. In\nparticular, we prove a lower bound of $\\Omega(d)$ for any deterministic\nalgorithm. Moreover, we show that unlike smooth or convex optimization, access\nto function values is required for any deterministic algorithm to halt within\nany finite time.\n  On the other hand, we prove that if the function is even slightly smooth,\nthen the dimension-free rate of $\\tilde O(\\delta^{-1}\\epsilon^{-3})$ can be\nobtained by a deterministic algorithm with merely a logarithmic dependence on\nthe smoothness parameter. Motivated by these findings, we turn to study the\ncomplexity of deterministically smoothing Lipschitz functions. Though there are\nefficient black-box randomized smoothings, we start by showing that no such\ndeterministic procedure can smooth functions in a meaningful manner, resolving\nan open question. We then bypass this impossibility result for the structured\ncase of ReLU neural networks. To that end, in a practical white-box setting in\nwhich the optimizer is granted access to the network's architecture, we propose\na simple, dimension-free, deterministic smoothing that provably preserves\n$(\\delta,\\epsilon)$-stationary points. Our method applies to a variety of\narchitectures of arbitrary depth, including ResNets and ConvNets. Combined with\nour algorithm, this yields the first deterministic dimension-free algorithm for\noptimizing ReLU networks, circumventing our lower bound.", "AI": {"tldr": "The paper resolves the open problem of whether deterministic algorithms can achieve dimension-free rates for optimizing nonsmooth nonconvex Lipschitz functions, proving randomization is necessary. It also explores deterministic smoothing and proposes a solution for ReLU networks.", "motivation": "The motivation is to understand the complexity of optimizing nonsmooth nonconvex Lipschitz functions and determine if deterministic algorithms can match the efficiency of randomized ones.", "method": "The study involves proving lower bounds for deterministic algorithms, analyzing the role of function values, and proposing a deterministic smoothing method for ReLU networks in a white-box setting.", "result": "Results show randomization is necessary for dimension-free rates, deterministic algorithms require function values to halt, and a deterministic smoothing method works for ReLU networks.", "conclusion": "The paper concludes that deterministic dimension-free optimization is impossible in general but achievable for structured cases like ReLU networks with specific methods."}}
{"id": "2306.01658", "pdf": "https://arxiv.org/pdf/2306.01658", "abs": "https://arxiv.org/abs/2306.01658", "authors": ["Alessio Mazzetto", "Reza Esfandiarpoor", "Akash Singirikonda", "Eli Upfal", "Stephen H. Bach"], "title": "An Adaptive Method for Weak Supervision with Drifting Data", "categories": ["cs.LG"], "comment": "conference version updated", "summary": "We introduce an adaptive method with formal quality guarantees for weak\nsupervision in a non-stationary setting. Our goal is to infer the unknown\nlabels of a sequence of data by using weak supervision sources that provide\nindependent noisy signals of the correct classification for each data point.\nThis setting includes crowdsourcing and programmatic weak supervision. We focus\non the non-stationary case, where the accuracy of the weak supervision sources\ncan drift over time, e.g., because of changes in the underlying data\ndistribution. Due to the drift, older data could provide misleading information\nto infer the label of the current data point. Previous work relied on a priori\nassumptions on the magnitude of the drift to decide how much data to use from\nthe past. In contrast, our algorithm does not require any assumptions on the\ndrift, and it adapts based on the input by dynamically varying its window size.\nIn particular, at each step, our algorithm estimates the current accuracies of\nthe weak supervision sources by identifying a window of past observations that\nguarantees a near-optimal minimization of the trade-off between the error due\nto the variance of the estimation and the error due to the drift. Experiments\non synthetic and real-world labelers show that our approach adapts to the\ndrift.", "AI": {"tldr": "An adaptive method for weak supervision in non-stationary settings, dynamically adjusting window size to handle drifting source accuracies without prior assumptions.", "motivation": "Address the challenge of weak supervision in non-stationary environments where source accuracies drift over time, avoiding reliance on fixed assumptions about drift magnitude.", "method": "Dynamically varies window size to estimate current weak supervision accuracies, balancing estimation variance and drift error for near-optimal performance.", "result": "Demonstrated adaptability to drift in experiments with synthetic and real-world labelers.", "conclusion": "The algorithm effectively handles non-stationary weak supervision without prior drift assumptions, offering practical utility in dynamic settings."}}
{"id": "2401.02398", "pdf": "https://arxiv.org/pdf/2401.02398", "abs": "https://arxiv.org/abs/2401.02398", "authors": ["Erisa Hasani", "Rachel A. Ward"], "title": "Generating synthetic data for neural operators", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Recent advances in the literature show promising potential of deep learning\nmethods, particularly neural operators, in obtaining numerical solutions to\npartial differential equations (PDEs) beyond the reach of current numerical\nsolvers. However, existing data-driven approaches often rely on training data\nproduced by numerical PDE solvers (e.g., finite difference or finite element\nmethods). We introduce a \"backward\" data generation method that avoids solving\nthe PDE numerically: by randomly sampling candidate solutions $u_j$ from the\nappropriate solution space (e.g., $H_0^1(\\Omega)$), we compute the\ncorresponding right-hand side $f_j$ directly from the equation by\ndifferentiation. This produces training pairs ${(f_j, u_j)}$ by computing\nderivatives rather than solving a PDE numerically for each data point, enabling\nfast, large-scale data generation consisting of exact solutions. Experiments\nindicate that models trained on this synthetic data generalize well when tested\non data produced by standard solvers. While the idea is simple, we hope this\nmethod will expand the potential of neural PDE solvers that do not rely on\nclassical numerical solvers to generate their data.", "AI": {"tldr": "A novel 'backward' data generation method for training neural PDE solvers avoids traditional numerical solvers by sampling solutions and computing corresponding right-hand sides directly.", "motivation": "Existing data-driven PDE solvers rely on numerical methods for training data, which can be limiting. This work aims to bypass this dependency.", "method": "Randomly sample candidate solutions from the solution space and compute the corresponding right-hand sides via differentiation, creating training pairs without solving PDEs numerically.", "result": "Models trained on this synthetic data generalize well when tested on data from standard solvers.", "conclusion": "The method enables fast, large-scale data generation of exact solutions, expanding the potential of neural PDE solvers independent of classical numerical methods."}}
{"id": "2409.03915", "pdf": "https://arxiv.org/pdf/2409.03915", "abs": "https://arxiv.org/abs/2409.03915", "authors": ["Huizhen Yu", "Yi Wan", "Richard S. Sutton"], "title": "Asynchronous Stochastic Approximation and Average-Reward Reinforcement Learning", "categories": ["cs.LG", "math.OC", "93E20, 62L20, 90C40"], "comment": "This revision adds sharper convergence results based on shadowing\n  properties, along with a substantial Section 5 containing their proofs. The\n  material in this paper extends the authors' earlier results reported in\n  arXiv:2408.16262 and arXiv:2312.15091. It incorporates and subsumes the\n  results of arXiv:2312.15091 and serves as Part II of arXiv:2408.16262", "summary": "This paper studies asynchronous stochastic approximation (SA) algorithms and\ntheir theoretical application to reinforcement learning in semi-Markov decision\nprocesses (SMDPs) with an average-reward criterion. We first extend Borkar and\nMeyn's stability proof method to accommodate more general noise conditions,\nyielding broader convergence guarantees for asynchronous SA. To sharpen the\nconvergence analysis, we further examine shadowing properties in the\nasynchronous setting, building on a dynamical-systems approach of Hirsch and\nBena\\\"{i}m. Leveraging these SA results, we establish the convergence of an\nasynchronous SA analogue of Schweitzer's classical relative value iteration\nalgorithm, RVI Q-learning, for finite-space, weakly communicating SMDPs.\nMoreover, to make full use of these SA results in this application, we\nintroduce new monotonicity conditions for estimating the optimal reward rate in\nRVI Q-learning. These conditions substantially expand the previously considered\nalgorithmic framework, and we address them with novel arguments in the\nstability and convergence analysis of RVI Q-learning.", "AI": {"tldr": "The paper extends stability proofs for asynchronous stochastic approximation (SA) algorithms, applies them to reinforcement learning in SMDPs, and introduces new conditions for RVI Q-learning convergence.", "motivation": "To broaden convergence guarantees for asynchronous SA and apply these results to reinforcement learning in SMDPs, enhancing the theoretical framework for RVI Q-learning.", "method": "Extends Borkar and Meyn's stability proof for SA, examines shadowing properties, and introduces monotonicity conditions for RVI Q-learning.", "result": "Convergence of asynchronous SA and RVI Q-learning is established for weakly communicating SMDPs.", "conclusion": "The work expands the algorithmic framework for SA and reinforcement learning, providing stronger convergence guarantees and new theoretical insights."}}
{"id": "2411.06360", "pdf": "https://arxiv.org/pdf/2411.06360", "abs": "https://arxiv.org/abs/2411.06360", "authors": ["Mohsen Dehghankar", "Mahdi Erfanian", "Abolfazl Asudeh"], "title": "An Efficient Matrix Multiplication Algorithm for Accelerating Inference in Binary and Ternary Neural Networks", "categories": ["cs.LG", "cs.DS"], "comment": "Accepted at ICML 2025", "summary": "Despite their tremendous success and versatility, Deep Neural Networks (DNNs)\nsuch as Large Language Models (LLMs) suffer from inference inefficiency and\nrely on advanced computational infrastructure. To address these challenges and\nmake these models more accessible and cost-effective, in this paper, we propose\nalgorithms to improve the inference time and memory efficiency of DNNs with\nbinary and ternary weight matrices. Particularly focusing on matrix\nmultiplication as the bottleneck operation of inference, we observe that, once\ntrained, the weight matrices of a model no longer change. This allows us to\npreprocess these matrices and create indices that help reduce the storage\nrequirements by a logarithmic factor while enabling our efficient inference\nalgorithms. Specifically, for a $n\\times n$ weight matrix, our efficient\nalgorithm guarantees a time complexity of $O(\\frac{n^2}{\\log n})$, a\nlogarithmic factor improvement over the standard vector-matrix multiplication.\nBesides theoretical analysis, we conduct extensive experiments to evaluate the\npractical efficiency of our algorithms. Our results confirm the superiority of\nour approach both with respect to time and memory, as we observed a reduction\nin the multiplication time up to 29x and memory usage up to 6x. When applied to\nLLMs, our experiments show up to a 5.24x speedup in the inference time.", "AI": {"tldr": "The paper proposes algorithms to improve the inference time and memory efficiency of DNNs using binary and ternary weight matrices, achieving significant speedups and memory reductions.", "motivation": "Deep Neural Networks (DNNs) suffer from inefficiency and high computational costs, limiting accessibility. The paper aims to address this by optimizing inference.", "method": "The approach involves preprocessing weight matrices to create indices, reducing storage and enabling efficient algorithms with logarithmic factor improvements in time complexity.", "result": "Experiments show up to 29x faster multiplication, 6x memory reduction, and 5.24x speedup in LLM inference.", "conclusion": "The proposed algorithms effectively enhance DNN efficiency, making them more accessible and cost-effective."}}
{"id": "2411.08791", "pdf": "https://arxiv.org/pdf/2411.08791", "abs": "https://arxiv.org/abs/2411.08791", "authors": ["Behnoosh Zamanlooy", "Mario Diaz", "Shahab Asoodeh"], "title": "Locally Private Sampling with Public Data", "categories": ["cs.LG"], "comment": null, "summary": "Local differential privacy (LDP) is increasingly employed in\nprivacy-preserving machine learning to protect user data before sharing it with\nan untrusted aggregator. Most LDP methods assume that users possess only a\nsingle data record, which is a significant limitation since users often gather\nextensive datasets (e.g., images, text, time-series data) and frequently have\naccess to public datasets. To address this limitation, we propose a locally\nprivate sampling framework that leverages both the private and public datasets\nof each user. Specifically, we assume each user has two distributions: $p$ and\n$q$ that represent their private dataset and the public dataset, respectively.\nThe objective is to design a mechanism that generates a private sample\napproximating $p$ while simultaneously preserving $q$. We frame this objective\nas a minimax optimization problem using $f$-divergence as the utility measure.\nWe fully characterize the minimax optimal mechanisms for general\n$f$-divergences provided that $p$ and $q$ are discrete distributions.\nRemarkably, we demonstrate that this optimal mechanism is universal across all\n$f$-divergences. Experiments validate the effectiveness of our minimax optimal\nsampler compared to the state-of-the-art locally private sampler.", "AI": {"tldr": "A locally private sampling framework is proposed to leverage both private and public datasets, addressing the limitation of single-data-record assumptions in LDP methods.", "motivation": "Existing LDP methods assume users have only one data record, which is unrealistic as users often have extensive private and public datasets.", "method": "A minimax optimization problem is framed using $f$-divergence to design a mechanism that generates private samples approximating the private dataset while preserving the public dataset.", "result": "The optimal mechanism is characterized for general $f$-divergences and shown to be universal across all $f$-divergences for discrete distributions.", "conclusion": "Experiments confirm the proposed sampler outperforms state-of-the-art locally private samplers."}}
{"id": "2501.18715", "pdf": "https://arxiv.org/pdf/2501.18715", "abs": "https://arxiv.org/abs/2501.18715", "authors": ["Harshwardhan Praveen", "Jacob Brown", "Christopher Earls"], "title": "chebgreen: Learning and Interpolating Continuous Empirical Green's Functions from Data", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "Code is available at https://github.com/hsharsh/chebgreen", "summary": "In this work, we present a mesh-independent, data-driven library, chebgreen,\nto mathematically model one-dimensional systems, possessing an associated\ncontrol parameter, and whose governing partial differential equation is\nunknown. The proposed method learns an Empirical Green's Function for the\nassociated, but hidden, boundary value problem, in the form of a Rational\nNeural Network from which we subsequently construct a bivariate representation\nin a Chebyshev basis. We uncover the Green's function, at an unseen control\nparameter value, by interpolating the left and right singular functions within\na suitable library, expressed as points on a manifold of Quasimatrices, while\nthe associated singular values are interpolated with Lagrange polynomials.", "AI": {"tldr": "A data-driven library, chebgreen, models 1D systems with unknown PDEs using Empirical Green's Functions and Rational Neural Networks.", "motivation": "To address systems with unknown governing PDEs and control parameters by learning their hidden boundary value problems.", "method": "Learns an Empirical Green's Function via Rational Neural Networks, constructs a bivariate Chebyshev basis, and interpolates singular functions and values.", "result": "Uncovers the Green's function for unseen control parameters by interpolating singular functions and values.", "conclusion": "Chebgreen provides a mesh-independent, data-driven approach to model systems with unknown PDEs."}}
{"id": "2502.03340", "pdf": "https://arxiv.org/pdf/2502.03340", "abs": "https://arxiv.org/abs/2502.03340", "authors": ["Alessandro Licciardi", "Davide Leo", "Eros Fan\u00ec", "Barbara Caputo", "Marco Ciccone"], "title": "Interaction-Aware Gaussian Weighting for Clustered Federated Learning", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025", "summary": "Federated Learning (FL) emerged as a decentralized paradigm to train models\nwhile preserving privacy. However, conventional FL struggles with data\nheterogeneity and class imbalance, which degrade model performance. Clustered\nFL balances personalization and decentralized training by grouping clients with\nanalogous data distributions, enabling improved accuracy while adhering to\nprivacy constraints. This approach effectively mitigates the adverse impact of\nheterogeneity in FL. In this work, we propose a novel clustered FL method,\nFedGWC (Federated Gaussian Weighting Clustering), which groups clients based on\ntheir data distribution, allowing training of a more robust and personalized\nmodel on the identified clusters. FedGWC identifies homogeneous clusters by\ntransforming individual empirical losses to model client interactions with a\nGaussian reward mechanism. Additionally, we introduce the Wasserstein Adjusted\nScore, a new clustering metric for FL to evaluate cluster cohesion with respect\nto the individual class distribution. Our experiments on benchmark datasets\nshow that FedGWC outperforms existing FL algorithms in cluster quality and\nclassification accuracy, validating the efficacy of our approach.", "AI": {"tldr": "FedGWC, a novel clustered FL method, groups clients by data distribution using Gaussian weighting and a new clustering metric, improving accuracy and robustness in heterogeneous FL settings.", "motivation": "Conventional FL struggles with data heterogeneity and class imbalance, degrading model performance. Clustered FL addresses this by grouping clients with similar data distributions.", "method": "FedGWC uses Gaussian weighting to transform empirical losses for clustering and introduces the Wasserstein Adjusted Score to evaluate cluster cohesion.", "result": "Experiments show FedGWC outperforms existing FL algorithms in cluster quality and classification accuracy.", "conclusion": "FedGWC effectively mitigates heterogeneity in FL, enhancing model performance while preserving privacy."}}
{"id": "2502.03963", "pdf": "https://arxiv.org/pdf/2502.03963", "abs": "https://arxiv.org/abs/2502.03963", "authors": ["Keon Vin Park"], "title": "AL-PINN: Active Learning-Driven Physics-Informed Neural Networks for Efficient Sample Selection in Solving Partial Differential Equations", "categories": ["cs.LG"], "comment": "This paper should be rewritten", "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a promising approach\nfor solving Partial Differential Equations (PDEs) by incorporating physical\nconstraints into deep learning models. However, standard PINNs often require a\nlarge number of training samples to achieve high accuracy, leading to increased\ncomputational costs. To address this issue, we propose Active Learning-Driven\nPINNs (AL-PINN), which integrates Uncertainty Quantification (UQ) and Active\nLearning (AL) strategies to optimize sample selection dynamically.\n  AL-PINN utilizes Monte Carlo Dropout to estimate epistemic uncertainty in the\nmodel predictions, enabling the adaptive selection of high-uncertainty regions\nfor additional training. This approach significantly enhances learning\nefficiency by focusing computational resources on the most informative data\npoints. We evaluate AL-PINN on benchmark PDE problems with known analytical\nsolutions and real-world WeatherBench climate data. Our results demonstrate\nthat AL-PINN achieves comparable or superior accuracy compared to traditional\nPINNs while reducing the number of required training samples.\n  The proposed framework is particularly beneficial for scientific and\nengineering applications where data collection is expensive or limited, such as\nclimate modeling, medical simulations, and material science. Our findings\nhighlight the potential of active learning in accelerating PINN-based PDE\nsolvers while maintaining high accuracy and computational efficiency.", "AI": {"tldr": "AL-PINN integrates uncertainty quantification and active learning to optimize training sample selection, reducing computational costs while maintaining accuracy in solving PDEs.", "motivation": "Standard PINNs require many training samples, increasing computational costs. AL-PINN aims to address this inefficiency by dynamically selecting high-uncertainty regions for training.", "method": "AL-PINN uses Monte Carlo Dropout for uncertainty estimation and active learning to adaptively select training samples, focusing on high-uncertainty regions.", "result": "AL-PINN achieves comparable or better accuracy than traditional PINNs with fewer training samples, validated on benchmark PDEs and climate data.", "conclusion": "AL-PINN is efficient for applications with expensive data collection, like climate modeling, and shows promise for accelerating PINN-based PDE solvers."}}
{"id": "2502.07425", "pdf": "https://arxiv.org/pdf/2502.07425", "abs": "https://arxiv.org/abs/2502.07425", "authors": ["Keon Vin Park"], "title": "Towards a Foundation Model for Physics-Informed Neural Networks: Multi-PDE Learning with Active Sampling", "categories": ["cs.LG"], "comment": "This paper should be rewritten", "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs) by embedding physical laws\ninto neural network training. However, traditional PINN models are typically\ndesigned for single PDEs, limiting their generalizability across different\nphysical systems. In this work, we explore the potential of a foundation PINN\nmodel capable of solving multiple PDEs within a unified architecture. We\ninvestigate the efficacy of a single PINN framework trained on four distinct\nPDEs-the Simple Harmonic Oscillator (SHO), the 1D Heat Equation, the 1D Wave\nEquation, and the 2D Laplace Equation, demonstrating its ability to learn\ndiverse physical dynamics.\n  To enhance sample efficiency, we incorporate Active Learning (AL) using Monte\nCarlo (MC) Dropout-based uncertainty estimation, selecting the most informative\ntraining samples iteratively. We evaluate different active learning strategies,\ncomparing models trained on 10%, 20%, 30%, 40%, and 50% of the full dataset,\nand analyze their impact on solution accuracy. Our results indicate that\ntargeted uncertainty sampling significantly improves performance with fewer\ntraining samples, leading to efficient learning across multiple PDEs.\n  This work highlights the feasibility of a generalizable PINN-based foundation\nmodel, capable of adapting to different physics-based problems without\nredesigning network architectures. Our findings suggest that multi-PDE PINNs\nwith active learning can serve as an effective approach for reducing\ncomputational costs while maintaining high accuracy in physics-based deep\nlearning applications.", "AI": {"tldr": "A foundation PINN model is proposed to solve multiple PDEs within a unified architecture, enhanced by active learning for sample efficiency.", "motivation": "Traditional PINNs are limited to single PDEs, lacking generalizability across diverse physical systems.", "method": "A single PINN framework is trained on four PDEs, incorporating active learning with MC Dropout for uncertainty-based sample selection.", "result": "Targeted uncertainty sampling improves performance with fewer samples, enabling efficient learning across multiple PDEs.", "conclusion": "Multi-PDE PINNs with active learning offer a generalizable, cost-effective solution for physics-based deep learning."}}
{"id": "2502.18826", "pdf": "https://arxiv.org/pdf/2502.18826", "abs": "https://arxiv.org/abs/2502.18826", "authors": ["Yuxiao Wen"], "title": "Adversarial Combinatorial Semi-bandits with Graph Feedback", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "In combinatorial semi-bandits, a learner repeatedly selects from a\ncombinatorial decision set of arms, receives the realized sum of rewards, and\nobserves the rewards of the individual selected arms as feedback. In this\npaper, we extend this framework to include \\emph{graph feedback}, where the\nlearner observes the rewards of all neighboring arms of the selected arms in a\nfeedback graph $G$. We establish that the optimal regret over a time horizon\n$T$ scales as $\\widetilde{\\Theta}(S\\sqrt{T}+\\sqrt{\\alpha ST})$, where $S$ is\nthe size of the combinatorial decisions and $\\alpha$ is the independence number\nof $G$. This result interpolates between the known regrets\n$\\widetilde\\Theta(S\\sqrt{T})$ under full information (i.e., $G$ is complete)\nand $\\widetilde\\Theta(\\sqrt{KST})$ under the semi-bandit feedback (i.e., $G$\nhas only self-loops), where $K$ is the total number of arms. A key technical\ningredient is to realize a convexified action using a random decision vector\nwith negative correlations. We also show that online stochastic mirror descent\n(OSMD) that only realizes convexified actions in expectation is suboptimal.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.12561", "pdf": "https://arxiv.org/pdf/2504.12561", "abs": "https://arxiv.org/abs/2504.12561", "authors": ["Akira Tamamori"], "title": "Kernel Ridge Regression for Efficient Learning of High-Capacity Hopfield Networks", "categories": ["cs.LG", "cs.NE"], "comment": "6 pages, 3 figures, 1 table. Submitted to APSIPA ASC 2025", "summary": "Hopfield networks using Hebbian learning suffer from limited storage\ncapacity. While supervised methods like Linear Logistic Regression (LLR) offer\nsome improvement, kernel methods like Kernel Logistic Regression (KLR)\nsignificantly enhance capacity and noise robustness. However, KLR requires\ncomputationally expensive iterative learning. We propose Kernel Ridge\nRegression (KRR) as an efficient kernel-based alternative for learning\nhigh-capacity Hopfield networks. KRR utilizes the kernel trick and predicts\nbipolar states via regression, crucially offering a non-iterative, closed-form\nsolution for learning dual variables. We evaluate KRR and compare its\nperformance against Hebbian, LLR, and KLR. Our results demonstrate that KRR\nachieves state-of-the-art storage capacity (reaching $\\beta$=1.5) and noise\nrobustness, comparable to KLR. Crucially, KRR drastically reduces training\ntime, being orders of magnitude faster than LLR and significantly faster than\nKLR, especially at higher storage loads. This establishes KRR as a potent and\nhighly efficient method for building high-performance associative memories,\nproviding comparable performance to KLR with substantial training speed\nadvantages. This work provides the first empirical comparison between KRR and\nKLR in the context of Hopfield network learning.", "AI": {"tldr": "Kernel Ridge Regression (KRR) is proposed as an efficient, non-iterative alternative to Kernel Logistic Regression (KLR) for high-capacity Hopfield networks, achieving comparable performance with faster training.", "motivation": "Hopfield networks with Hebbian learning have limited storage capacity, and while supervised methods like KLR improve this, they are computationally expensive.", "method": "KRR uses the kernel trick and regression for bipolar state prediction, offering a closed-form solution for learning dual variables.", "result": "KRR achieves state-of-the-art storage capacity (\u03b2=1.5) and noise robustness, with drastically reduced training time compared to LLR and KLR.", "conclusion": "KRR is a highly efficient method for high-performance associative memories, matching KLR's performance with significant speed advantages."}}
{"id": "2110.08505", "pdf": "https://arxiv.org/pdf/2110.08505", "abs": "https://arxiv.org/abs/2110.08505", "authors": ["Yikun Zhang", "Yen-Chi Chen"], "title": "Mode and Ridge Estimation in Euclidean and Directional Product Spaces: A Mean Shift Approach", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "72 pages (22 pages for the main paper), 10 figures, 5 tables. To\n  appear in the Journal of Computational and Graphical Statistics", "summary": "The set of local modes and density ridge lines are important summary\ncharacteristics of the data-generating distribution. In this work, we focus on\nestimating local modes and density ridges from point cloud data in a product\nspace combining two or more Euclidean and/or directional metric spaces.\nSpecifically, our approach extends the (subspace constrained) mean shift\nalgorithm to such product spaces, addressing potential challenges in the\ngeneralization process. We establish the algorithmic convergence of the\nproposed methods, along with practical implementation guidelines. Experiments\non simulated and real-world datasets demonstrate the effectiveness of our\nproposed methods.", "AI": {"tldr": "The paper extends the mean shift algorithm to estimate local modes and density ridges in product spaces combining Euclidean and directional metric spaces, ensuring convergence and practical implementation.", "motivation": "To address the challenge of estimating local modes and density ridges in complex product spaces, which are important for understanding data-generating distributions.", "method": "Extends the (subspace constrained) mean shift algorithm to product spaces, with a focus on algorithmic convergence and practical implementation.", "result": "Demonstrates effectiveness through experiments on simulated and real-world datasets.", "conclusion": "The proposed methods successfully generalize mean shift for local mode and density ridge estimation in product spaces."}}
{"id": "2305.05828", "pdf": "https://arxiv.org/pdf/2305.05828", "abs": "https://arxiv.org/abs/2305.05828", "authors": ["Junwen Qiu", "Li Jiang", "Andre Milzarek"], "title": "A Normal Map-Based Proximal Stochastic Gradient Method: Convergence and Identification Properties", "categories": ["math.OC", "cs.LG", "90C26, 90C15"], "comment": "26 pages, 19 figures", "summary": "The proximal stochastic gradient method (PSGD) is one of the state-of-the-art\napproaches for stochastic composite-type problems. In contrast to its\ndeterministic counterpart, PSGD has been found to have difficulties with the\ncorrect identification of underlying substructures (such as supports, low rank\npatterns, or active constraints) and it does not possess a finite-time manifold\nidentification property. Existing solutions rely on convexity assumptions or on\nthe additional usage of variance reduction techniques. In this paper, we\naddress these limitations and present a simple variant of PSGD based on\nRobinson's normal map. The proposed normal map-based proximal stochastic\ngradient method (NSGD) is shown to converge globally, i.e., accumulation points\nof the generated iterates correspond to stationary points almost surely. In\naddition, we establish complexity bounds for NSGD that match the known results\nfor PSGD and we prove that NSGD can almost surely identify active manifolds in\nfinite-time in a general nonconvex setting. Our derivations are built on almost\nsure iterate convergence guarantees and utilize analysis techniques based on\nthe Kurdyka-Lojasiewicz inequality.", "AI": {"tldr": "A new variant of PSGD, called NSGD, is proposed to address limitations in identifying substructures and finite-time manifold identification, with proven global convergence and finite-time manifold identification in nonconvex settings.", "motivation": "PSGD struggles with substructure identification and lacks finite-time manifold identification, especially in nonconvex settings. Existing solutions require convexity or variance reduction.", "method": "Proposes NSGD, a variant of PSGD based on Robinson's normal map, ensuring global convergence and finite-time manifold identification.", "result": "NSGD converges globally, matches PSGD complexity bounds, and identifies active manifolds in finite-time for nonconvex problems.", "conclusion": "NSGD effectively addresses PSGD's limitations, offering robust performance in nonconvex stochastic optimization."}}
{"id": "2308.08852", "pdf": "https://arxiv.org/pdf/2308.08852", "abs": "https://arxiv.org/abs/2308.08852", "authors": ["Chengjing Wang", "Peipei Tang", "Wenling He", "Meixia Lin"], "title": "Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "stat.CO", "stat.ML", "90C25, 65K05, 90C06, 49M27, 90C20"], "comment": "35 pages, 6 figures", "summary": "Graphical models have exhibited their performance in numerous tasks ranging\nfrom biological analysis to recommender systems. However, graphical models with\nhub nodes are computationally difficult to fit, particularly when the dimension\nof the data is large. To efficiently estimate the hub graphical models, we\nintroduce a two-phase algorithm. The proposed algorithm first generates a good\ninitial point via a dual alternating direction method of multipliers (ADMM),\nand then warm starts a semismooth Newton (SSN) based augmented Lagrangian\nmethod (ALM) to compute a solution that is accurate enough for practical tasks.\nWe fully excavate the sparsity structure of the generalized Jacobian arising\nfrom the hubs in the graphical models, which ensures that the algorithm can\nobtain a nice solution very efficiently. Comprehensive experiments on both\nsynthetic data and real data show that it obviously outperforms the existing\nstate-of-the-art algorithms. In particular, in some high dimensional tasks, it\ncan save more than 70\\% of the execution time, meanwhile still achieves a\nhigh-quality estimation.", "AI": {"tldr": "A two-phase algorithm combining ADMM and SSN-based ALM efficiently estimates hub graphical models, outperforming state-of-the-art methods with significant time savings.", "motivation": "Hub nodes in graphical models are computationally challenging to fit, especially in high-dimensional data, necessitating an efficient solution.", "method": "The algorithm uses dual ADMM for initialization and SSN-based ALM for accurate solution, leveraging sparsity structure of the generalized Jacobian.", "result": "Outperforms existing methods, saving over 70% execution time in high-dimensional tasks while maintaining high-quality estimation.", "conclusion": "The proposed algorithm is efficient and practical for hub graphical models, offering substantial computational advantages."}}
{"id": "2311.10859", "pdf": "https://arxiv.org/pdf/2311.10859", "abs": "https://arxiv.org/abs/2311.10859", "authors": ["Francisca Vasconcelos", "Emmanouil-Vasileios Vlatakis-Gkaragkounis", "Panayotis Mertikopoulos", "Georgios Piliouras", "Michael I. Jordan"], "title": "A Quadratic Speedup in Finding Nash Equilibria of Quantum Zero-Sum Games", "categories": ["quant-ph", "cs.GT", "cs.LG", "math.OC", "primary 91A05, 81Q93, secondary 68Q32, 91A26, 37N40,"], "comment": "53 pages, 7 figures, QTML 2023 (Long Talk), Quantum Journal 2025", "summary": "Recent developments in domains such as non-local games, quantum interactive\nproofs, and quantum generative adversarial networks have renewed interest in\nquantum game theory and, specifically, quantum zero-sum games. Central to\nclassical game theory is the efficient algorithmic computation of Nash\nequilibria, which represent optimal strategies for both players. In 2008, Jain\nand Watrous proposed the first classical algorithm for computing equilibria in\nquantum zero-sum games using the Matrix Multiplicative Weight Updates (MMWU)\nmethod to achieve a convergence rate of $\\mathcal{O}(d/\\epsilon^2)$ iterations\nto $\\epsilon$-Nash equilibria in the $4^d$-dimensional spectraplex. In this\nwork, we propose a hierarchy of quantum optimization algorithms that generalize\nMMWU via an extra-gradient mechanism. Notably, within this proposed hierarchy,\nwe introduce the Optimistic Matrix Multiplicative Weights Update (OMMWU)\nalgorithm and establish its average-iterate convergence complexity as\n$\\mathcal{O}(d/\\epsilon)$ iterations to $\\epsilon$-Nash equilibria. This\nquadratic speed-up relative to Jain and Watrous' original algorithm sets a new\nbenchmark for computing $\\epsilon$-Nash equilibria in quantum zero-sum games.", "AI": {"tldr": "The paper introduces a hierarchy of quantum optimization algorithms, including OMMWU, which achieves a quadratic speed-up in computing \u03b5-Nash equilibria for quantum zero-sum games compared to prior work.", "motivation": "Renewed interest in quantum game theory, particularly quantum zero-sum games, due to advancements in related domains like non-local games and quantum interactive proofs.", "method": "Proposes a hierarchy of quantum optimization algorithms generalizing MMWU with an extra-gradient mechanism, introducing OMMWU for improved convergence.", "result": "OMMWU achieves an average-iterate convergence complexity of \ud835\udcaa(d/\u03b5), a quadratic speed-up over the original MMWU method.", "conclusion": "The work sets a new benchmark for computing \u03b5-Nash equilibria in quantum zero-sum games, advancing the field of quantum game theory."}}
{"id": "2401.11646", "pdf": "https://arxiv.org/pdf/2401.11646", "abs": "https://arxiv.org/abs/2401.11646", "authors": ["Yifan Peng", "Yuehaw Khoo", "Daren Wang"], "title": "Multivariate Density Estimation via Variance-Reduced Sketching", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "stat.ME"], "comment": "58 pages, 8 figures", "summary": "Multivariate density estimation is of great interest in various scientific\nand engineering disciplines. In this work, we introduce a new framework called\nVariance-Reduced Sketching (VRS), specifically designed to estimate\nmultivariate density functions with a reduced curse of dimensionality. Our VRS\nframework conceptualizes multivariate functions as infinite-size\nmatrices/tensors, and facilitates a new sketching technique motivated by the\nnumerical linear algebra literature to reduce the variance in density\nestimation problems. We demonstrate the robust numerical performance of VRS\nthrough a series of simulated experiments and real-world data applications.\nNotably, VRS shows remarkable improvement over existing neural network density\nestimators and classical kernel methods in numerous distribution models.\nAdditionally, we offer theoretical justifications for VRS to support its\nability to deliver density estimation with a reduced curse of dimensionality.", "AI": {"tldr": "VRS is a new framework for multivariate density estimation that reduces dimensionality issues, outperforming neural networks and kernel methods.", "motivation": "Address the curse of dimensionality in multivariate density estimation, a critical challenge in scientific and engineering fields.", "method": "Introduces Variance-Reduced Sketching (VRS), treating multivariate functions as infinite matrices/tensors and applying sketching techniques from numerical linear algebra.", "result": "VRS shows robust performance in simulations and real-world data, surpassing neural networks and kernel methods.", "conclusion": "VRS effectively reduces dimensionality challenges in density estimation, supported by theoretical and empirical evidence."}}
{"id": "2402.08978", "pdf": "https://arxiv.org/pdf/2402.08978", "abs": "https://arxiv.org/abs/2402.08978", "authors": ["Wong Kam-Kwai", "Yan Luo", "Xuanwu Yue", "Wei Chen", "Huamin Qu"], "title": "Prismatic: Interactive Multi-View Cluster Analysis of Concept Stocks", "categories": ["cs.HC", "cs.CE", "cs.LG"], "comment": "14 pages. A preprint version accepted to IEEE Transactions on\n  Visualization and Computer Graphics (TVCG), 2025", "summary": "Financial cluster analysis allows investors to discover investment\nalternatives and avoid undertaking excessive risks. However, this analytical\ntask faces substantial challenges arising from many pairwise comparisons, the\ndynamic correlations across time spans, and the ambiguity in deriving\nimplications from business relational knowledge. We propose Prismatic, a visual\nanalytics system that integrates quantitative analysis of historical\nperformance and qualitative analysis of business relational knowledge to\ncluster correlated businesses interactively. Prismatic features three\nclustering processes: dynamic cluster generation, knowledge-based cluster\nexploration, and correlation-based cluster validation. Utilizing a multi-view\nclustering approach, it enriches data-driven clusters with knowledge-driven\nsimilarity, providing a nuanced understanding of business correlations. Through\nwell-coordinated visual views, Prismatic facilitates a comprehensive\ninterpretation of intertwined quantitative and qualitative features,\ndemonstrating its usefulness and effectiveness via case studies on formulating\nconcept stocks and extensive interviews with domain experts.", "AI": {"tldr": "Prismatic is a visual analytics system for financial cluster analysis, combining quantitative and qualitative methods to improve investment decisions.", "motivation": "Address challenges in financial cluster analysis like dynamic correlations, many pairwise comparisons, and ambiguous business relational knowledge.", "method": "Integrates dynamic cluster generation, knowledge-based exploration, and correlation-based validation using a multi-view clustering approach.", "result": "Demonstrates effectiveness through case studies on concept stocks and expert interviews.", "conclusion": "Prismatic provides a nuanced understanding of business correlations, aiding investors in risk management and decision-making."}}
{"id": "2405.00389", "pdf": "https://arxiv.org/pdf/2405.00389", "abs": "https://arxiv.org/abs/2405.00389", "authors": ["Fredrik Hagstr\u00f6m", "Vikas Garg", "Fabricio Oliveira"], "title": "Employing Federated Learning for Training Autonomous HVAC Systems", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Buildings account for 40% of global energy consumption. A considerable\nportion of building energy consumption stems from heating, ventilation, and air\nconditioning (HVAC), and thus implementing smart, energy-efficient HVAC systems\nhas the potential to significantly impact the course of climate change. In\nrecent years, model-free reinforcement learning algorithms have been\nincreasingly assessed for this purpose due to their ability to learn and adapt\npurely from experience. They have been shown to outperform classical\ncontrollers in terms of energy cost and consumption, as well as thermal\ncomfort. However, their weakness lies in their relatively poor data efficiency,\nrequiring long periods of training to reach acceptable policies, making them\ninapplicable to real-world controllers directly. In this paper, we demonstrate\nthat using federated learning to train the reinforcement learning controller of\nHVAC systems can improve the learning speed, as well as improve their ability\nto generalize, which in turn facilitates transfer learning to unseen building\nenvironments. In our setting, a global control policy is learned by aggregating\nlocal policies trained on multiple data centers located in different climate\nzones. The goal of the policy is to minimize energy consumption and maximize\nthermal comfort. We perform experiments evaluating three different optimizers\nfor local policy training, as well as three different federated learning\nalgorithms against two alternative baselines. Our experiments show that these\neffects lead to a faster learning speed, as well as greater generalization\ncapabilities in the federated policy compared to any individually trained\npolicy. Furthermore, the learning stability is significantly improved, with the\nlearning process and performance of the federated policy being less sensitive\nto the choice of parameters and the inherent randomness of reinforcement\nlearning.", "AI": {"tldr": "Federated learning improves reinforcement learning for HVAC systems, enhancing learning speed, generalization, and stability.", "motivation": "Buildings consume 40% of global energy, with HVAC being a major contributor. Smart HVAC systems can mitigate climate change, but traditional reinforcement learning lacks data efficiency.", "method": "Federated learning aggregates local policies from multiple climate zones to train a global HVAC control policy, tested with various optimizers and algorithms.", "result": "Federated learning speeds up training, improves generalization, and stabilizes performance compared to individually trained policies.", "conclusion": "Federated learning is a promising approach for efficient and adaptable HVAC control, addressing limitations of traditional reinforcement learning."}}
{"id": "2406.19532", "pdf": "https://arxiv.org/pdf/2406.19532", "abs": "https://arxiv.org/abs/2406.19532", "authors": ["Ismail Alkhouri", "Cedric Le Denmat", "Yingjie Li", "Cunxi Yu", "Jia Liu", "Rongrong Wang", "Alvaro Velasquez"], "title": "Quadratic Differentiable Optimization For The Maximum Independent Set Problem", "categories": ["cs.DM", "cs.LG"], "comment": null, "summary": "Combinatorial Optimization (CO) addresses many important problems, including\nthe challenging Maximum Independent Set (MIS) problem. Alongside exact and\nheuristic solvers, differentiable approaches have emerged, often using\ncontinuous relaxations of ReLU-based or quadratic objectives. Noting that an\nMIS in a graph is a Maximum Clique (MC) in its complement, we propose a new\nquadratic formulation for MIS by incorporating an MC term, improving\nconvergence and exploration. We show that every maximal independent set\ncorresponds to a local minimizer, derive conditions with respect to the MIS\nsize, and characterize stationary points. To tackle the non-convexity of the\nobjective, we propose optimizing several initializations in parallel using\nmomentum-based gradient descent, complemented by an efficient MIS checking\ncriterion derived from our theory. We dub our method as **p**arallelized\n**C**lique-Informed **Q**uadratic **O**ptimization for MIS (**pCQO-MIS**). Our\nexperimental results demonstrate the effectiveness of the proposed method\ncompared to exact, heuristic, sampling, and data-centric approaches. Notably,\nour method avoids the out-of-distribution tuning and reliance on (un)labeled\ndata required by data-centric methods, while achieving superior MIS sizes and\ncompetitive runtime relative to their inference time. Additionally, a key\nadvantage of pCQO-MIS is that, unlike exact and heuristic solvers, the runtime\nscales only with the number of nodes in the graph, not the number of edges. Our\ncode is available at the GitHub repository\n\\href{https://github.com/ledenmat/pCQO-mis-benchmark/tree/refactor}{{{pCQO-MIS}}}", "AI": {"tldr": "The paper introduces pCQO-MIS, a parallelized quadratic optimization method for solving the Maximum Independent Set problem by leveraging its complement graph's Maximum Clique properties. It improves convergence and avoids data-centric dependencies.", "motivation": "To address the limitations of existing methods for the Maximum Independent Set problem, such as reliance on data-centric tuning or scalability issues with exact solvers.", "method": "Proposes a quadratic formulation for MIS by incorporating a Maximum Clique term, uses momentum-based gradient descent with parallel initializations, and includes an efficient MIS checking criterion.", "result": "Demonstrates superior MIS sizes and competitive runtime compared to exact, heuristic, and data-centric methods, with runtime scaling only by node count.", "conclusion": "pCQO-MIS is an effective, scalable alternative for MIS, avoiding data dependencies and outperforming existing methods in both solution quality and runtime efficiency."}}
{"id": "2409.07769", "pdf": "https://arxiv.org/pdf/2409.07769", "abs": "https://arxiv.org/abs/2409.07769", "authors": ["Shivam Barwey", "Pinaki Pal", "Saumil Patel", "Riccardo Balin", "Bethany Lusch", "Venkatram Vishwanath", "Romit Maulik", "Ramesh Balakrishnan"], "title": "Mesh-based Super-Resolution of Fluid Flows with Multiscale Graph Neural Networks", "categories": ["physics.flu-dyn", "cs.CE", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "A graph neural network (GNN) approach is introduced in this work which\nenables mesh-based three-dimensional super-resolution of fluid flows. In this\nframework, the GNN is designed to operate not on the full mesh-based field at\nonce, but on localized meshes of elements (or cells) directly. To facilitate\nmesh-based GNN representations in a manner similar to spectral (or finite)\nelement discretizations, a baseline GNN layer (termed a message passing layer,\nwhich updates local node properties) is modified to account for synchronization\nof coincident graph nodes, rendering compatibility with commonly used\nelement-based mesh connectivities. The architecture is multiscale in nature,\nand is comprised of a combination of coarse-scale and fine-scale message\npassing layer sequences (termed processors) separated by a graph unpooling\nlayer. The coarse-scale processor embeds a query element (alongside a set\nnumber of neighboring coarse elements) into a single latent graph\nrepresentation using coarse-scale synchronized message passing over the element\nneighborhood, and the fine-scale processor leverages additional message passing\noperations on this latent graph to correct for interpolation errors.\nDemonstration studies are performed using hexahedral mesh-based data from\nTaylor-Green Vortex and backward-facing step flow simulations at Reynolds\nnumbers of 1600 and 3200. Through analysis of both global and local errors, the\nresults ultimately show how the GNN is able to produce accurate super-resolved\nfields compared to targets in both coarse-scale and multiscale model\nconfigurations. Reconstruction errors for fixed architectures were found to\nincrease in proportion to the Reynolds number. Geometry extrapolation studies\non a separate cavity flow configuration show promising cross-mesh capabilities\nof the super-resolution strategy.", "AI": {"tldr": "A GNN-based method for 3D fluid flow super-resolution on meshes uses localized processing and multiscale message passing to achieve accurate results.", "motivation": "To enable efficient and accurate super-resolution of fluid flows on meshes by leveraging localized GNN operations and multiscale processing.", "method": "A modified GNN layer synchronizes coincident nodes for mesh compatibility, with multiscale processors (coarse and fine) for embedding and error correction.", "result": "Accurate super-resolved fields were achieved, with errors scaling with Reynolds number, and promising cross-mesh capabilities demonstrated.", "conclusion": "The GNN approach effectively handles mesh-based super-resolution, showing potential for broader fluid flow applications."}}
{"id": "2409.11238", "pdf": "https://arxiv.org/pdf/2409.11238", "abs": "https://arxiv.org/abs/2409.11238", "authors": ["Jake Welde", "Nishanth Rao", "Pratik Kunapuli", "Dinesh Jayaraman", "Vijay Kumar"], "title": "Leveraging Symmetry to Accelerate Learning of Trajectory Tracking Controllers for Free-Flying Robotic Systems", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "The first three authors contributed equally to this work. This\n  updated version reflects the final version to appear at IEEE International\n  Conference on Robotics and Automation (ICRA) 2025", "summary": "Tracking controllers enable robotic systems to accurately follow planned\nreference trajectories. In particular, reinforcement learning (RL) has shown\npromise in the synthesis of controllers for systems with complex dynamics and\nmodest online compute budgets. However, the poor sample efficiency of RL and\nthe challenges of reward design make training slow and sometimes unstable,\nespecially for high-dimensional systems. In this work, we leverage the inherent\nLie group symmetries of robotic systems with a floating base to mitigate these\nchallenges when learning tracking controllers. We model a general tracking\nproblem as a Markov decision process (MDP) that captures the evolution of both\nthe physical and reference states. Next, we prove that symmetry in the\nunderlying dynamics and running costs leads to an MDP homomorphism, a mapping\nthat allows a policy trained on a lower-dimensional \"quotient\" MDP to be lifted\nto an optimal tracking controller for the original system. We compare this\nsymmetry-informed approach to an unstructured baseline, using Proximal Policy\nOptimization (PPO) to learn tracking controllers for three systems: the\nParticle (a forced point mass), the Astrobee (a fullyactuated space robot), and\nthe Quadrotor (an underactuated system). Results show that a symmetry-aware\napproach both accelerates training and reduces tracking error at convergence.", "AI": {"tldr": "The paper proposes using Lie group symmetries in robotic systems to improve the efficiency and stability of reinforcement learning (RL) for tracking controllers.", "motivation": "RL-based tracking controllers face challenges like poor sample efficiency and unstable training, especially for high-dimensional systems. Leveraging symmetries can mitigate these issues.", "method": "The authors model tracking as a Markov decision process (MDP) and use symmetry to derive a lower-dimensional quotient MDP. This allows lifting policies trained on the quotient MDP to the original system.", "result": "Experiments on three systems (Particle, Astrobee, Quadrotor) show that symmetry-aware training accelerates learning and reduces tracking error compared to unstructured baselines.", "conclusion": "Symmetry-informed RL improves training efficiency and controller performance for robotic tracking tasks."}}
{"id": "2410.01284", "pdf": "https://arxiv.org/pdf/2410.01284", "abs": "https://arxiv.org/abs/2410.01284", "authors": ["Jorge Lor\u00eda", "Anindya Bhadra"], "title": "Deep Kernel Posterior Learning under Infinite Variance Prior Weights", "categories": ["stat.ML", "cs.LG"], "comment": "Published as a conference paper at ICLR 2025", "summary": "Neal (1996) proved that infinitely wide shallow Bayesian neural networks\n(BNN) converge to Gaussian processes (GP), when the network weights have\nbounded prior variance. Cho & Saul (2009) provided a useful recursive formula\nfor deep kernel processes for relating the covariance kernel of each layer to\nthe layer immediately below. Moreover, they worked out the form of the\nlayer-wise covariance kernel in an explicit manner for several common\nactivation functions. Recent works, including Aitchison et al. (2021), have\nhighlighted that the covariance kernels obtained in this manner are\ndeterministic and hence, precludes any possibility of representation learning,\nwhich amounts to learning a non-degenerate posterior of a random kernel given\nthe data. To address this, they propose adding artificial noise to the kernel\nto retain stochasticity, and develop deep kernel inverse Wishart processes.\nNonetheless, this artificial noise injection could be critiqued in that it\nwould not naturally emerge in a classic BNN architecture under an\ninfinite-width limit. To address this, we show that a Bayesian deep neural\nnetwork, where each layer width approaches infinity, and all network weights\nare elliptically distributed with infinite variance, converges to a process\nwith $\\alpha$-stable marginals in each layer that has a conditionally Gaussian\nrepresentation. These conditional random covariance kernels could be\nrecursively linked in the manner of Cho & Saul (2009), even though marginally\nthe process exhibits stable behavior, and hence covariances are not even\nnecessarily defined. We also provide useful generalizations of the recent\nresults of Lor\\'ia & Bhadra (2024) on shallow networks to multi-layer networks,\nand remedy the computational burden of their approach. The computational and\nstatistical benefits over competing approaches stand out in simulations and in\ndemonstrations on benchmark data sets.", "AI": {"tldr": "Infinitely wide Bayesian deep neural networks with elliptically distributed weights converge to processes with \u03b1-stable marginals, enabling representation learning without artificial noise.", "motivation": "Address the limitation of deterministic covariance kernels in deep kernel processes, which preclude representation learning, by proposing a natural alternative without artificial noise.", "method": "Use Bayesian deep neural networks with infinite-width layers and elliptically distributed weights to derive processes with \u03b1-stable marginals and conditionally Gaussian representations.", "result": "The derived process allows recursive linking of conditional random covariance kernels, overcoming computational and statistical limitations of prior methods.", "conclusion": "The approach provides computational and statistical benefits, validated by simulations and benchmark datasets."}}
{"id": "2410.01440", "pdf": "https://arxiv.org/pdf/2410.01440", "abs": "https://arxiv.org/abs/2410.01440", "authors": ["Jinghan Li", "Zhicheng Sun", "Yadong Mu"], "title": "Closed-Loop Long-Horizon Robotic Planning via Equilibrium Sequence Modeling", "categories": ["cs.RO", "cs.LG"], "comment": "ICML 2025", "summary": "In the endeavor to make autonomous robots take actions, task planning is a\nmajor challenge that requires translating high-level task descriptions to\nlong-horizon action sequences. Despite recent advances in language model\nagents, they remain prone to planning errors and limited in their ability to\nplan ahead. To address these limitations in robotic planning, we advocate a\nself-refining scheme that iteratively refines a draft plan until an equilibrium\nis reached. Remarkably, this process can be optimized end-to-end from an\nanalytical perspective without the need to curate additional verifiers or\nreward models, allowing us to train self-refining planners in a simple\nsupervised learning fashion. Meanwhile, a nested equilibrium sequence modeling\nprocedure is devised for efficient closed-loop planning that incorporates\nuseful feedback from the environment (or an internal world model). Our method\nis evaluated on the VirtualHome-Env benchmark, showing advanced performance\nwith improved scaling w.r.t. inference-time computation. Code is available at\nhttps://github.com/Singularity0104/equilibrium-planner.", "AI": {"tldr": "A self-refining scheme for robotic task planning improves accuracy and scalability by iteratively refining draft plans without additional verifiers.", "motivation": "Addressing limitations in language model agents for robotic planning, such as errors and lack of foresight.", "method": "Proposes a self-refining scheme with end-to-end optimization and nested equilibrium sequence modeling for closed-loop planning.", "result": "Demonstrates advanced performance on the VirtualHome-Env benchmark with improved scaling.", "conclusion": "The method offers a scalable and efficient solution for robotic task planning without extra verifiers."}}
{"id": "2412.00200", "pdf": "https://arxiv.org/pdf/2412.00200", "abs": "https://arxiv.org/abs/2412.00200", "authors": ["Andrea Bulgarelli", "Elia Cellini", "Alessandro Nada"], "title": "Scaling of Stochastic Normalizing Flows in $\\mathrm{SU}(3)$ lattice gauge theory", "categories": ["hep-lat", "cond-mat.stat-mech", "cs.LG", "stat.ML"], "comment": "14 pages, 12 figures. v2: 14 pages, 13 figures, added comments and\n  improved discussion in section 5, matches published version", "summary": "Non-equilibrium Markov Chain Monte Carlo (NE-MCMC) simulations provide a\nwell-understood framework based on Jarzynski's equality to sample from a target\nprobability distribution. By driving a base probability distribution out of\nequilibrium, observables are computed without the need to thermalize. If the\nbase distribution is characterized by mild autocorrelations, this approach\nprovides a way to mitigate critical slowing down. Out-of-equilibrium evolutions\nshare the same framework of flow-based approaches and they can be naturally\ncombined into a novel architecture called Stochastic Normalizing Flows (SNFs).\nIn this work we present the first implementation of SNFs for $\\mathrm{SU}(3)$\nlattice gauge theory in 4 dimensions, defined by introducing gauge-equivariant\nlayers between out-of-equilibrium Monte Carlo updates. The core of our analysis\nis focused on the promising scaling properties of this architecture with the\ndegrees of freedom of the system, which are directly inherited from NE-MCMC.\nFinally, we discuss how systematic improvements of this approach can\nrealistically lead to a general and yet efficient sampling strategy at fine\nlattice spacings for observables affected by long autocorrelation times.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2501.15617", "pdf": "https://arxiv.org/pdf/2501.15617", "abs": "https://arxiv.org/abs/2501.15617", "authors": ["Ritwik Vashistha", "Arya Farahi"], "title": "I-trustworthy Models. A framework for trustworthiness evaluation of probabilistic classifiers", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "Accepted at AISTATS 2025 Conference", "summary": "As probabilistic models continue to permeate various facets of our society\nand contribute to scientific advancements, it becomes a necessity to go beyond\ntraditional metrics such as predictive accuracy and error rates and assess\ntheir trustworthiness. Grounded in the competence-based theory of trust, this\nwork formalizes I-trustworthy framework -- a novel framework for assessing the\ntrustworthiness of probabilistic classifiers for inference tasks by linking\nlocal calibration to trustworthiness. To assess I-trustworthiness, we use the\nlocal calibration error (LCE) and develop a method of hypothesis-testing. This\nmethod utilizes a kernel-based test statistic, Kernel Local Calibration Error\n(KLCE), to test local calibration of a probabilistic classifier. This study\nprovides theoretical guarantees by offering convergence bounds for an unbiased\nestimator of KLCE. Additionally, we present a diagnostic tool designed to\nidentify and measure biases in cases of miscalibration. The effectiveness of\nthe proposed test statistic is demonstrated through its application to both\nsimulated and real-world datasets. Finally, LCE of related recalibration\nmethods is studied, and we provide evidence of insufficiency of existing\nmethods to achieve I-trustworthiness.", "AI": {"tldr": "The paper introduces the I-trustworthy framework to assess the trustworthiness of probabilistic classifiers, linking local calibration to trustworthiness. It proposes a kernel-based test statistic (KLCE) for hypothesis testing, provides theoretical guarantees, and demonstrates its effectiveness on datasets.", "motivation": "To move beyond traditional metrics like predictive accuracy and evaluate the trustworthiness of probabilistic models, especially for inference tasks.", "method": "Develops the I-trustworthy framework, uses Local Calibration Error (LCE) and Kernel Local Calibration Error (KLCE) for hypothesis testing, and provides theoretical convergence bounds.", "result": "The KLCE test statistic is effective in assessing local calibration, and existing recalibration methods are insufficient for achieving I-trustworthiness.", "conclusion": "The I-trustworthy framework and KLCE provide a robust method for evaluating trustworthiness in probabilistic classifiers, highlighting gaps in current recalibration approaches."}}
{"id": "2502.01828", "pdf": "https://arxiv.org/pdf/2502.01828", "abs": "https://arxiv.org/abs/2502.01828", "authors": ["Yilin Wu", "Ran Tian", "Gokul Swamy", "Andrea Bajcsy"], "title": "From Foresight to Forethought: VLM-In-the-Loop Policy Steering via Latent Alignment", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "While generative robot policies have demonstrated significant potential in\nlearning complex, multimodal behaviors from demonstrations, they still exhibit\ndiverse failures at deployment-time. Policy steering offers an elegant solution\nto reducing the chance of failure by using an external verifier to select from\nlow-level actions proposed by an imperfect generative policy. Here, one might\nhope to use a Vision Language Model (VLM) as a verifier, leveraging its\nopen-world reasoning capabilities. However, off-the-shelf VLMs struggle to\nunderstand the consequences of low-level robot actions as they are represented\nfundamentally differently than the text and images the VLM was trained on. In\nresponse, we propose FOREWARN, a novel framework to unlock the potential of\nVLMs as open-vocabulary verifiers for runtime policy steering. Our key idea is\nto decouple the VLM's burden of predicting action outcomes (foresight) from\nevaluation (forethought). For foresight, we leverage a latent world model to\nimagine future latent states given diverse low-level action plans. For\nforethought, we align the VLM with these predicted latent states to reason\nabout the consequences of actions in its native representation--natural\nlanguage--and effectively filter proposed plans. We validate our framework\nacross diverse robotic manipulation tasks, demonstrating its ability to bridge\nrepresentational gaps and provide robust, generalizable policy steering. Videos\ncan be found on the project website: https://yilin-wu98.github.io/forewarn/.", "AI": {"tldr": "FOREWARN framework uses VLMs for policy steering by decoupling foresight (predicting action outcomes) and forethought (evaluating consequences), improving robotic manipulation tasks.", "motivation": "Generative robot policies often fail at deployment; VLMs could help verify actions but struggle with low-level action representations.", "method": "FOREWARN decouples foresight (using a latent world model) and forethought (aligning VLMs with latent states) to enable VLM-based verification.", "result": "Validated across diverse robotic tasks, FOREWARN bridges representational gaps and enhances policy steering.", "conclusion": "FOREWARN effectively leverages VLMs for robust, generalizable policy steering in robotics."}}
{"id": "2502.02853", "pdf": "https://arxiv.org/pdf/2502.02853", "abs": "https://arxiv.org/abs/2502.02853", "authors": ["Shuanghao Bai", "Wanqi Zhou", "Pengxiang Ding", "Wei Zhao", "Donglin Wang", "Badong Chen"], "title": "Rethinking Latent Redundancy in Behavior Cloning: An Information Bottleneck Approach for Robot Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Behavior Cloning (BC) is a widely adopted visual imitation learning method in\nrobot manipulation. Current BC approaches often enhance generalization by\nleveraging large datasets and incorporating additional visual and textual\nmodalities to capture more diverse information. However, these methods overlook\nwhether the learned representations contain redundant information and lack a\nsolid theoretical foundation to guide the learning process. To address these\nlimitations, we adopt an information-theoretic perspective and introduce mutual\ninformation to quantify and mitigate redundancy in latent representations.\nBuilding on this, we incorporate the Information Bottleneck (IB) principle into\nBC, which extends the idea of reducing redundancy by providing a structured\nframework for compressing irrelevant information while preserving task-relevant\nfeatures. This work presents the first comprehensive study on redundancy in\nlatent representations across various methods, backbones, and experimental\nsettings, while extending the generalizability of the IB to BC. Extensive\nexperiments and analyses on the CortexBench and LIBERO benchmarks demonstrate\nsignificant performance improvements with IB, underscoring the importance of\nreducing input data redundancy and highlighting its practical value for more\npractical applications. Project Page:\nhttps://baishuanghao.github.io/BC-IB.github.io.", "AI": {"tldr": "The paper introduces an information-theoretic approach to reduce redundancy in latent representations for Behavior Cloning (BC), improving generalization using the Information Bottleneck (IB) principle.", "motivation": "Current BC methods lack theoretical grounding and overlook redundancy in learned representations, limiting their effectiveness.", "method": "The authors use mutual information to quantify redundancy and integrate the IB principle into BC to compress irrelevant information while retaining task-relevant features.", "result": "Experiments on CortexBench and LIBERO benchmarks show significant performance gains with IB, validating its effectiveness.", "conclusion": "The study highlights the practical value of reducing redundancy in BC and extends the applicability of IB to imitation learning."}}
{"id": "2502.04649", "pdf": "https://arxiv.org/pdf/2502.04649", "abs": "https://arxiv.org/abs/2502.04649", "authors": ["Xiaole Zhang", "Peiyu Zhang", "Xiongye Xiao", "Shixuan Li", "Vasileios Tzoumas", "Vijay Gupta", "Paul Bogdan"], "title": "End-to-End Learning Framework for Solving Non-Markovian Optimal Control", "categories": ["cs.SY", "cs.LG", "math.OC"], "comment": null, "summary": "Integer-order calculus often falls short in capturing the long-range\ndependencies and memory effects found in many real-world processes. Fractional\ncalculus addresses these gaps via fractional-order integrals and derivatives,\nbut fractional-order dynamical systems pose substantial challenges in system\nidentification and optimal control due to the lack of standard control\nmethodologies. In this paper, we theoretically derive the optimal control via\nlinear quadratic regulator (LQR) for fractional-order linear time-invariant\n(FOLTI) systems and develop an end-to-end deep learning framework based on this\ntheoretical foundation. Our approach establishes a rigorous mathematical model,\nderives analytical solutions, and incorporates deep learning to achieve\ndata-driven optimal control of FOLTI systems. Our key contributions include:\n(i) proposing an innovative system identification method control strategy for\nFOLTI systems, (ii) developing the first end-to-end data-driven learning\nframework, Fractional-Order Learning for Optimal Control (FOLOC), that learns\ncontrol policies from observed trajectories, and (iii) deriving a theoretical\nanalysis of sample complexity to quantify the number of samples required for\naccurate optimal control in complex real-world problems. Experimental results\nindicate that our method accurately approximates fractional-order system\nbehaviors without relying on Gaussian noise assumptions, pointing to promising\navenues for advanced optimal control.", "AI": {"tldr": "The paper proposes an end-to-end deep learning framework (FOLOC) for optimal control of fractional-order linear time-invariant systems, combining theoretical LQR derivation with data-driven learning.", "motivation": "Integer-order calculus fails to model long-range dependencies and memory effects in real-world processes, while fractional-order systems lack standard control methodologies.", "method": "The paper derives LQR-based optimal control for FOLTI systems and develops the FOLOC framework, integrating deep learning for data-driven control.", "result": "FOLOC accurately approximates fractional-order system behaviors without Gaussian noise assumptions, enabling effective optimal control.", "conclusion": "The work bridges theory and practice for fractional-order system control, offering a scalable, data-driven solution with theoretical guarantees."}}
{"id": "2502.12539", "pdf": "https://arxiv.org/pdf/2502.12539", "abs": "https://arxiv.org/abs/2502.12539", "authors": ["Dinesh Kumar", "Amin Ghorbanpour", "Kin Yen", "Iman Soltani"], "title": "Design and Implementation of a Dual Uncrewed Surface Vessel Platform for Bathymetry Research under High-flow Conditions", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "Corresponding author: Iman Soltani (isoltani@ucdavis.edu)", "summary": "Bathymetry, the study of underwater topography, relies on sonar mapping of\nsubmerged structures. These measurements, critical for infrastructure health\nmonitoring, often require expensive instrumentation. The high financial risk\nassociated with sensor damage or vessel loss creates a reluctance to deploy\nuncrewed surface vessels (USVs) for bathymetry. However, the crewed-boat\nbathymetry operations, are costly, pose hazards to personnel, and frequently\nfail to achieve the stable conditions necessary for bathymetry data collection,\nespecially under high currents. Further research is essential to advance\nautonomous control, navigation, and data processing technologies, with a\nparticular focus on bathymetry. There is a notable lack of accessible hardware\nplatforms that allow for integrated research in both bathymetry-focused\nautonomous control and navigation, as well as data evaluation and processing.\nThis paper addresses this gap through the design and implementation of two\ncomplementary USV systems tailored for uncrewed bathymetry research. This\nincludes a low-cost USV for Navigation And Control research (NAC-USV) and a\nsecond, high-end USV equipped with a high-resolution multi-beam sonar and the\nassociated hardware for Bathymetry data quality Evaluation and Post-processing\nresearch (BEP-USV). The NAC-USV facilitates the investigation of autonomous,\nfail-safe navigation and control, emphasizing the stability requirements for\nhigh-quality bathymetry data collection while minimizing the risk to equipment.\nThe BEP-USV, which mirrors the NAC-USV hardware, is then used for additional\ncontrol validation and in-depth exploration of bathymetry data evaluation and\npost-processing methodologies. We detail the design and implementation of both\nsystems, and open source the design. Furthermore, we demonstrate the system's\neffectiveness in a range of operational scenarios.", "AI": {"tldr": "The paper introduces two USV systems for bathymetry research: a low-cost NAC-USV for navigation/control and a high-end BEP-USV for data evaluation, addressing gaps in autonomous bathymetry.", "motivation": "High costs and risks of crewed bathymetry, along with lack of accessible platforms for integrated research, drive the need for autonomous USV solutions.", "method": "Design and implementation of two complementary USV systems (NAC-USV for navigation/control, BEP-USV for data evaluation) with open-sourced designs.", "result": "Effective performance in operational scenarios, demonstrating feasibility of autonomous bathymetry with reduced risk and cost.", "conclusion": "The systems bridge gaps in bathymetry research, enabling safer, cost-effective, and high-quality data collection."}}
{"id": "2503.09649", "pdf": "https://arxiv.org/pdf/2503.09649", "abs": "https://arxiv.org/abs/2503.09649", "authors": ["Daniele Malpetti", "Marco Scutari", "Francesco Gualdi", "Jessica van Setten", "Sander van der Laan", "Saskia Haitjema", "Aaron Mark Lee", "Isabelle Hering", "Francesca Mangili"], "title": "Technical Insights and Legal Considerations for Advancing Federated Learning in Bioinformatics", "categories": ["q-bio.OT", "cs.LG", "stat.ML"], "comment": "13 pages, 4 figures", "summary": "Federated learning leverages data across institutions to improve clinical\ndiscovery while complying with data-sharing restrictions and protecting patient\nprivacy. As the evolution of biobanks in genetics and systems biology has\nproved, accessing more extensive and varied data pools leads to a faster and\nmore robust exploration and translation of results. More widespread use of\nfederated learning may have the same impact in bioinformatics, allowing access\nto many combinations of genotypic, phenotypic and environmental information\nthat are undercovered or not included in existing biobanks. This paper reviews\nthe methodological, infrastructural and legal issues that academic and clinical\ninstitutions must address before implementing it. Finally, we provide\nrecommendations for the reliable use of federated learning and its effective\ntranslation into clinical practice.", "AI": {"tldr": "Federated learning can enhance clinical discovery by pooling data across institutions while ensuring privacy. This paper reviews challenges and offers recommendations for its implementation in bioinformatics.", "motivation": "To improve clinical research by leveraging diverse data pools without violating privacy or data-sharing restrictions, similar to the impact of biobanks in genetics.", "method": "Reviews methodological, infrastructural, and legal issues for implementing federated learning in academic and clinical settings.", "result": "Identifies challenges and gaps in current practices for federated learning in bioinformatics.", "conclusion": "Provides recommendations for reliable implementation and effective translation of federated learning into clinical practice."}}
{"id": "2504.20982", "pdf": "https://arxiv.org/pdf/2504.20982", "abs": "https://arxiv.org/abs/2504.20982", "authors": ["Tyler Chen", "Archan Ray", "Akshay Seshadri", "Dylan Herman", "Bao Bach", "Pranav Deshpande", "Abhishek Som", "Niraj Kumar", "Marco Pistoia"], "title": "Provably faster randomized and quantum algorithms for $k$-means clustering via uniform sampling", "categories": ["quant-ph", "cs.DS", "cs.LG"], "comment": "fix typos", "summary": "The $k$-means algorithm (Lloyd's algorithm) is a widely used method for\nclustering unlabeled data. A key bottleneck of the $k$-means algorithm is that\neach iteration requires time linear in the number of data points, which can be\nexpensive in big data applications. This was improved in recent works proposing\nquantum and quantum-inspired classical algorithms to approximate the $k$-means\nalgorithm locally, in time depending only logarithmically on the number of data\npoints (along with data dependent parameters) [$q$-means: A quantum algorithm\nfor unsupervised machine learning; Kerenidis, Landman, Luongo, and Prakash,\nNeurIPS 2019; Do you know what $q$-means?, Doriguello, Luongo, Tang]. In this\nwork, we describe a simple randomized mini-batch $k$-means algorithm and a\nquantum algorithm inspired by the classical algorithm. We prove worse-case\nguarantees that significantly improve upon the bounds for previous algorithms.\nOur improvements are due to a careful use of uniform sampling, which preserves\ncertain symmetries of the $k$-means problem that are not preserved in previous\nalgorithms that use data norm-based sampling.", "AI": {"tldr": "The paper introduces a randomized mini-batch $k$-means algorithm and a quantum-inspired algorithm, improving upon previous methods by using uniform sampling to preserve symmetries, achieving better worst-case guarantees.", "motivation": "The $k$-means algorithm's computational bottleneck in big data applications motivates the need for faster, quantum-inspired solutions.", "method": "A randomized mini-batch $k$-means algorithm and a quantum algorithm are proposed, leveraging uniform sampling to preserve problem symmetries.", "result": "The new algorithms achieve significantly improved worst-case guarantees compared to previous methods.", "conclusion": "Uniform sampling preserves symmetries in $k$-means, enabling more efficient quantum and classical algorithms."}}
{"id": "2505.00625", "pdf": "https://arxiv.org/pdf/2505.00625", "abs": "https://arxiv.org/abs/2505.00625", "authors": ["Liu Junchi", "Tang Ying", "Tretiak Sergei", "Duan Wenhui", "Zhou Liujiang"], "title": "SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Recent advances in machine learning have demonstrated an enormous utility of\ndeep learning approaches, particularly Graph Neural Networks (GNNs) for\nmaterials science. These methods have emerged as powerful tools for\nhigh-throughput prediction of material properties, offering a compelling\nenhancement and alternative to traditional first-principles calculations. While\nthe community has predominantly focused on developing increasingly complex and\nuniversal models to enhance predictive accuracy, such approaches often lack\nphysical interpretability and insights into materials behavior. Here, we\nintroduce a novel computational paradigm, Self-Adaptable Graph Attention\nNetworks integrated with Symbolic Regression (SA-GAT-SR), that synergistically\ncombines the predictive capability of GNNs with the interpretative power of\nsymbolic regression. Our framework employs a self-adaptable encoding algorithm\nthat automatically identifies and adjust attention weights so as to screen\ncritical features from an expansive 180-dimensional feature space while\nmaintaining O(n) computational scaling. The integrated SR module subsequently\ndistills these features into compact analytical expressions that explicitly\nreveal quantum-mechanically meaningful relationships, achieving 23 times\nacceleration compared to conventional SR implementations that heavily rely on\nfirst principle calculations-derived features as input. This work suggests a\nnew framework in computational materials science, bridging the gap between\npredictive accuracy and physical interpretability, offering valuable physical\ninsights into material behavior.", "AI": {"tldr": "A novel framework, SA-GAT-SR, combines GNNs with symbolic regression to enhance predictive accuracy and interpretability in materials science.", "motivation": "Address the lack of physical interpretability in complex GNN models while maintaining predictive power.", "method": "Uses self-adaptable graph attention networks to identify critical features and symbolic regression to distill them into interpretable expressions.", "result": "Achieves 23x acceleration over conventional methods and provides quantum-mechanically meaningful insights.", "conclusion": "Bridges the gap between accuracy and interpretability, offering a new paradigm in computational materials science."}}
