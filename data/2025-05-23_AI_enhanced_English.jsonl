{"id": "2505.16557", "pdf": "https://arxiv.org/pdf/2505.16557", "abs": "https://arxiv.org/abs/2505.16557", "authors": ["Junchi Yao", "Jianhua Xu", "Tianyu Xin", "Ziyi Wang", "Shenzhe Zhu", "Shu Yang", "Di Wang"], "title": "Is Your LLM-Based Multi-Agent a Reliable Real-World Planner? Exploring Fraud Detection in Travel Planning", "categories": ["cs.MA"], "comment": null, "summary": "The rise of Large Language Model-based Multi-Agent Planning has leveraged\nadvanced frameworks to enable autonomous and collaborative task execution. Some\nsystems rely on platforms like review sites and social media, which are prone\nto fraudulent information, such as fake reviews or misleading descriptions.\nThis reliance poses risks, potentially causing financial losses and harming\nuser experiences. To evaluate the risk of planning systems in real-world\napplications, we introduce \\textbf{WandaPlan}, an evaluation environment\nmirroring real-world data and injected with deceptive content. We assess system\nperformance across three fraud cases: Misinformation Fraud, Team-Coordinated\nMulti-Person Fraud, and Level-Escalating Multi-Round Fraud. We reveal\nsignificant weaknesses in existing frameworks that prioritize task efficiency\nover data authenticity. At the same time, we validate WandaPlan's\ngeneralizability, capable of assessing the risks of real-world open-source\nplanning frameworks. To mitigate the risk of fraud, we propose integrating an\nanti-fraud agent, providing a solution for reliable planning.", "AI": {"tldr": "WandaPlan is introduced to evaluate fraud risks in LLM-based multi-agent planning systems, revealing weaknesses in existing frameworks and proposing an anti-fraud agent for mitigation.", "motivation": "The reliance on platforms prone to fraudulent information (e.g., fake reviews) in multi-agent planning systems poses risks like financial losses and poor user experiences.", "method": "WandaPlan, an evaluation environment with deceptive content, assesses system performance across three fraud cases: Misinformation Fraud, Team-Coordinated Multi-Person Fraud, and Level-Escalating Multi-Round Fraud.", "result": "Existing frameworks prioritize task efficiency over data authenticity, showing significant weaknesses. WandaPlan proves generalizable for real-world risk assessment.", "conclusion": "An anti-fraud agent is proposed to mitigate fraud risks, offering a solution for reliable planning in real-world applications."}}
{"id": "2505.15914", "pdf": "https://arxiv.org/pdf/2505.15914", "abs": "https://arxiv.org/abs/2505.15914", "authors": ["Yuan-Kuei Wu", "Juan Azcarreta", "Kashyap Patel", "Buye Xu", "Jung-Suk Lee", "Sanha Lee", "Ashutosh Pandey"], "title": "A Novel Deep Learning Framework for Efficient Multichannel Acoustic Feedback Control", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by Interspeech 2025", "summary": "This study presents a deep-learning framework for controlling multichannel\nacoustic feedback in audio devices. Traditional digital signal processing\nmethods struggle with convergence when dealing with highly correlated noise\nsuch as feedback. We introduce a Convolutional Recurrent Network that\nefficiently combines spatial and temporal processing, significantly enhancing\nspeech enhancement capabilities with lower computational demands. Our approach\nutilizes three training methods: In-a-Loop Training, Teacher Forcing, and a\nHybrid strategy with a Multichannel Wiener Filter, optimizing performance in\ncomplex acoustic environments. This scalable framework offers a robust solution\nfor real-world applications, making significant advances in Acoustic Feedback\nControl technology.", "AI": {"tldr": "A deep-learning framework using a Convolutional Recurrent Network improves multichannel acoustic feedback control, outperforming traditional methods with lower computational costs.", "motivation": "Traditional digital signal processing methods fail to converge with highly correlated noise like feedback, necessitating a more efficient solution.", "method": "The framework employs a Convolutional Recurrent Network for spatial and temporal processing, trained via In-a-Loop Training, Teacher Forcing, and a Hybrid strategy with a Multichannel Wiener Filter.", "result": "The approach significantly enhances speech enhancement and is scalable for real-world applications.", "conclusion": "This framework advances Acoustic Feedback Control technology, offering robust performance in complex acoustic environments."}}
{"id": "2505.15854", "pdf": "https://arxiv.org/pdf/2505.15854", "abs": "https://arxiv.org/abs/2505.15854", "authors": ["Thai-Hoc Vu", "Ngo Hoang Tu", "Thien Huynh-The", "Kyungchun Lee", "Sunghwan Kim", "Miroslav Voznak", "Quoc-Viet Pham"], "title": "Integration of TinyML and LargeML: A Survey of 6G and Beyond", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": "This work was submitted to IEEE Communications Surveys & Tutorials", "summary": "The transition from 5G networks to 6G highlights a significant demand for\nmachine learning (ML). Deep learning models, in particular, have seen wide\napplication in mobile networking and communications to support advanced\nservices in emerging wireless environments, such as smart healthcare, smart\ngrids, autonomous vehicles, aerial platforms, digital twins, and the metaverse.\nThe rapid expansion of Internet-of-Things (IoT) devices, many with limited\ncomputational capabilities, has accelerated the development of tiny machine\nlearning (TinyML) and resource-efficient ML approaches for cost-effective\nservices. However, the deployment of large-scale machine learning (LargeML)\nsolutions require major computing resources and complex management strategies\nto support extensive IoT services and ML-generated content applications.\nConsequently, the integration of TinyML and LargeML is projected as a promising\napproach for future seamless connectivity and efficient resource management.\n  Although the integration of TinyML and LargeML shows abundant potential,\nseveral challenges persist, including performance optimization, practical\ndeployment strategies, effective resource management, and security\nconsiderations. In this survey, we review and analyze the latest research aimed\nat enabling the integration of TinyML and LargeML models for the realization of\nsmart services and applications in future 6G networks and beyond. The paper\nconcludes by outlining critical challenges and identifying future research\ndirections for the holistic integration of TinyML and LargeML in\nnext-generation wireless networks.", "AI": {"tldr": "The paper explores the integration of TinyML and LargeML for 6G networks, addressing challenges like performance optimization, deployment, resource management, and security.", "motivation": "The transition to 6G demands efficient ML solutions due to the rise of IoT devices and advanced services, requiring a balance between TinyML (for resource-limited devices) and LargeML (for complex tasks).", "method": "The survey reviews recent research on integrating TinyML and LargeML, analyzing their roles in 6G networks.", "result": "The integration shows potential for seamless connectivity and efficient resource management but faces challenges like optimization and security.", "conclusion": "Future research must address these challenges for holistic integration in next-gen wireless networks."}}
{"id": "2505.16119", "pdf": "https://arxiv.org/pdf/2505.16119", "abs": "https://arxiv.org/abs/2505.16119", "authors": ["Robin Scheibler", "John R. Hershey", "Arnaud Doucet", "Henry Li"], "title": "Source Separation by Flow Matching", "categories": ["cs.SD", "eess.AS"], "comment": "5 pages, 3 figures, 2 tables", "summary": "We consider the problem of single-channel audio source separation with the\ngoal of reconstructing $K$ sources from their mixture. We address this\nill-posed problem with FLOSS (FLOw matching for Source Separation), a\nconstrained generation method based on flow matching, ensuring strict mixture\nconsistency. Flow matching is a general methodology that, when given samples\nfrom two probability distributions defined on the same space, learns an\nordinary differential equation to output a sample from one of the distributions\nwhen provided with a sample from the other. In our context, we have access to\nsamples from the joint distribution of $K$ sources and so the corresponding\nsamples from the lower-dimensional distribution of their mixture. To apply flow\nmatching, we augment these mixture samples with artificial noise components to\nensure the resulting \"augmented\" distribution matches the dimensionality of the\n$K$ source distribution. Additionally, as any permutation of the sources yields\nthe same mixture, we adopt an equivariant formulation of flow matching which\nrelies on a suitable custom-designed neural network architecture. We\ndemonstrate the performance of the method for the separation of overlapping\nspeech.", "AI": {"tldr": "FLOSS uses flow matching for single-channel audio source separation, ensuring mixture consistency and handling source permutations with an equivariant neural network.", "motivation": "The paper addresses the ill-posed problem of reconstructing multiple sources from a single-channel audio mixture, aiming for accurate and consistent separation.", "method": "FLOSS employs flow matching, augmenting mixture samples with noise to match source dimensionality and using an equivariant neural network for permutation invariance.", "result": "The method demonstrates effectiveness in separating overlapping speech sources.", "conclusion": "FLOSS provides a robust solution for single-channel source separation by leveraging flow matching and equivariant architectures."}}
{"id": "2505.16988", "pdf": "https://arxiv.org/pdf/2505.16988", "abs": "https://arxiv.org/abs/2505.16988", "authors": ["Rui Ye", "Keduan Huang", "Qimin Wu", "Yuzhu Cai", "Tian Jin", "Xianghe Pang", "Xiangrui Liu", "Jiaqi Su", "Chen Qian", "Bohan Tang", "Kaiqu Liang", "Jiaao Chen", "Yue Hu", "Zhenfei Yin", "Rongye Shi", "Bo An", "Yang Gao", "Wenjun Wu", "Lei Bai", "Siheng Chen"], "title": "MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": "18 pages, 11 figures", "summary": "LLM-based multi-agent systems (MAS) have demonstrated significant potential\nin enhancing single LLMs to address complex and diverse tasks in practical\napplications. Despite considerable advancements, the field lacks a unified\ncodebase that consolidates existing methods, resulting in redundant\nre-implementation efforts, unfair comparisons, and high entry barriers for\nresearchers. To address these challenges, we introduce MASLab, a unified,\ncomprehensive, and research-friendly codebase for LLM-based MAS. (1) MASLab\nintegrates over 20 established methods across multiple domains, each rigorously\nvalidated by comparing step-by-step outputs with its official implementation.\n(2) MASLab provides a unified environment with various benchmarks for fair\ncomparisons among methods, ensuring consistent inputs and standardized\nevaluation protocols. (3) MASLab implements methods within a shared streamlined\nstructure, lowering the barriers for understanding and extension. Building on\nMASLab, we conduct extensive experiments covering 10+ benchmarks and 8 models,\noffering researchers a clear and comprehensive view of the current landscape of\nMAS methods. MASLab will continue to evolve, tracking the latest developments\nin the field, and invite contributions from the broader open-source community.", "AI": {"tldr": "MASLab is a unified codebase for LLM-based multi-agent systems (MAS) to address redundancy, unfair comparisons, and high entry barriers by integrating 20+ methods, providing benchmarks, and streamlining implementation.", "motivation": "The lack of a unified codebase for LLM-based MAS leads to redundant efforts, unfair comparisons, and high entry barriers for researchers.", "method": "MASLab integrates 20+ validated methods, offers a unified environment with benchmarks, and implements methods in a shared structure.", "result": "Extensive experiments on 10+ benchmarks and 8 models provide a clear view of MAS methods.", "conclusion": "MASLab aims to evolve with the field and invites open-source contributions to advance LLM-based MAS research."}}
{"id": "2505.16168", "pdf": "https://arxiv.org/pdf/2505.16168", "abs": "https://arxiv.org/abs/2505.16168", "authors": ["Hongfei Xue", "Yufeng Tang", "Jun Zhang", "Xuelong Geng", "Lei Xie"], "title": "Selective Invocation for Multilingual ASR: A Cost-effective Approach Adapting to Speech Recognition Difficulty", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by INTERSPEECH 2025", "summary": "Although multilingual automatic speech recognition (ASR) systems have\nsignificantly advanced, enabling a single model to handle multiple languages,\ninherent linguistic differences and data imbalances challenge SOTA performance\nacross all languages. While language identification (LID) models can route\nspeech to the appropriate ASR model, they incur high costs from invoking SOTA\ncommercial models and suffer from inaccuracies due to misclassification. To\novercome these, we propose SIMA, a selective invocation for multilingual ASR\nthat adapts to the difficulty level of the input speech. Built on a spoken\nlarge language model (SLLM), SIMA evaluates whether the input is simple enough\nfor direct transcription or requires the invocation of a SOTA ASR model. Our\napproach reduces word error rates by 18.7% compared to the SLLM and halves\ninvocation costs compared to LID-based methods. Tests on three datasets show\nthat SIMA is a scalable, cost-effective solution for multilingual ASR\napplications.", "AI": {"tldr": "SIMA, a selective invocation method for multilingual ASR, reduces costs and errors by adapting to input difficulty, outperforming SLLM and LID-based methods.", "motivation": "Addressing challenges in multilingual ASR, such as linguistic differences, data imbalances, and high costs/inaccuracies of LID-based routing.", "method": "Proposes SIMA, which uses a spoken large language model (SLLM) to evaluate input difficulty and selectively invoke SOTA ASR models.", "result": "Reduces word error rates by 18.7% compared to SLLM and halves invocation costs compared to LID-based methods.", "conclusion": "SIMA is a scalable, cost-effective solution for multilingual ASR applications, validated on three datasets."}}
{"id": "2505.16997", "pdf": "https://arxiv.org/pdf/2505.16997", "abs": "https://arxiv.org/abs/2505.16997", "authors": ["Rui Ye", "Xiangrui Liu", "Qimin Wu", "Xianghe Pang", "Zhenfei Yin", "Lei Bai", "Siheng Chen"], "title": "X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": "19 pages, 5 figures", "summary": "LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by\nenabling cooperation among multiple specialized agents. However, most existing\nMAS frameworks rely on a single LLM to drive all agents, constraining the\nsystem's intelligence to the limit of that model. This paper explores the\nparadigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by\ndiverse LLMs, elevating the system's potential to the collective intelligence\nof diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to\nevaluate the performance of various LLMs across different domains and\nMAS-related functions. As an extensive empirical study, we assess 27 LLMs\nacross 5 domains (encompassing 21 test sets) and 5 functions, conducting over\n1.7 million evaluations to identify optimal model selections for each\ndomain-function combination. Building on these findings, we demonstrate that\ntransitioning from homogeneous to heterogeneous LLM-driven MAS can\nsignificantly enhance system performance without requiring structural redesign.\nSpecifically, in a chatbot-only MAS scenario, the heterogeneous configuration\nyields up to 8.4\\% performance improvement on the MATH dataset. In a mixed\nchatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable\n47\\% performance boost on the AIME dataset. Our results underscore the\ntransformative potential of heterogeneous LLMs in MAS, highlighting a promising\navenue for advancing scalable, collaborative AI systems.", "AI": {"tldr": "Heterogeneous LLM-driven multi-agent systems (X-MAS) outperform homogeneous systems by leveraging diverse LLMs, achieving significant performance boosts without structural changes.", "motivation": "Existing MAS frameworks limit intelligence to a single LLM, missing the potential of diverse collective intelligence.", "method": "Introduces X-MAS-Bench, a testbed evaluating 27 LLMs across 5 domains and 5 functions, with over 1.7M evaluations.", "result": "Heterogeneous MAS improves performance by up to 8.4% (MATH dataset) and 47% (AIME dataset) compared to homogeneous systems.", "conclusion": "Heterogeneous LLMs in MAS offer transformative potential for scalable, collaborative AI systems."}}
{"id": "2505.16182", "pdf": "https://arxiv.org/pdf/2505.16182", "abs": "https://arxiv.org/abs/2505.16182", "authors": ["Kentaro Onda", "Keisuke Imoto", "Satoru Fukayama", "Daisuke Saito", "Nobuaki Minematsu"], "title": "Discrete Tokens Exhibit Interlanguage Speech Intelligibility Benefit: an Analytical Study Towards Accent-robust ASR Only with Native Speech Data", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by Interspeech2025", "summary": "In this study, we gained insight that contributes to achieving accent-robust\nASR using only native speech data. In human perception of non-native speech,\nthe phenomenon known as \"interlanguage speech intelligibility benefit\" (ISIB)\nis observed, where non-native listeners who share the native language with the\nspeaker understand the speech better compared even to native listeners. Based\non the idea that discrete tokens extracted from self-supervised learning (SSL)\nmodels represent the human perception of speech, we conducted an analytical\nstudy on the robustness of discrete token-based ASR to non-native speech,\nvarying the language used for training the tokenization, which is viewed as a\ntechnical implementation of ISIB. The results showed that ISIB actually\noccurred in the discrete token-based ASR. Since our approach relies only on\nnative speech data to simulate the behavior of human perception, it is expected\nto be applicable to a wide range of accents for which speech data is scarce.", "AI": {"tldr": "The study explores accent-robust ASR using native speech data, leveraging ISIB and discrete tokens from SSL models to improve non-native speech recognition.", "motivation": "To achieve accent-robust ASR without relying on non-native speech data by mimicking human perception (ISIB) through discrete tokens.", "method": "Analyzed discrete token-based ASR robustness to non-native speech, varying tokenization training languages to simulate ISIB.", "result": "ISIB was observed in the discrete token-based ASR, proving its effectiveness.", "conclusion": "The approach, using only native speech data, is scalable for accents with scarce data, mimicking human perception effectively."}}
{"id": "2505.15916", "pdf": "https://arxiv.org/pdf/2505.15916", "abs": "https://arxiv.org/abs/2505.15916", "authors": ["Juvenal Domingos J\u00fanior", "Augusto Faria", "E. Seiti de Oliveira", "Erick de Brito", "Matheus Teotonio", "Andre Assump\u00e7\u00e3o", "Diedre Carmo", "Roberto Lotufo", "Jayr Pereira"], "title": "BR-TaxQA-R: A Dataset for Question Answering with References for Brazilian Personal Income Tax Law, including case law", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper presents BR-TaxQA-R, a novel dataset designed to support question\nanswering with references in the context of Brazilian personal income tax law.\nThe dataset contains 715 questions from the 2024 official Q\\&A document\npublished by Brazil's Internal Revenue Service, enriched with statutory norms\nand administrative rulings from the Conselho Administrativo de Recursos Fiscais\n(CARF). We implement a Retrieval-Augmented Generation (RAG) pipeline using\nOpenAI embeddings for searching and GPT-4o-mini for answer generation. We\ncompare different text segmentation strategies and benchmark our system against\ncommercial tools such as ChatGPT and Perplexity.ai using RAGAS-based metrics.\nResults show that our custom RAG pipeline outperforms commercial systems in\nResponse Relevancy, indicating stronger alignment with user queries, while\ncommercial models achieve higher scores in Factual Correctness and fluency.\nThese findings highlight a trade-off between legally grounded generation and\nlinguistic fluency. Crucially, we argue that human expert evaluation remains\nessential to ensure the legal validity of AI-generated answers in high-stakes\ndomains such as taxation. BR-TaxQA-R is publicly available at\nhttps://huggingface.co/datasets/unicamp-dl/BR-TaxQA-R.", "AI": {"tldr": "BR-TaxQA-R is a new dataset for QA in Brazilian tax law, using RAG with OpenAI embeddings and GPT-4o-mini. It outperforms commercial tools in relevancy but lags in correctness and fluency. Human expert validation is emphasized.", "motivation": "To address the need for accurate, reference-based QA in Brazilian tax law, leveraging AI while ensuring legal validity.", "method": "Implemented a RAG pipeline with OpenAI embeddings for retrieval and GPT-4o-mini for generation, comparing segmentation strategies and benchmarking against commercial tools using RAGAS metrics.", "result": "Custom RAG pipeline excels in Response Relevancy but commercial models score higher in Factual Correctness and fluency.", "conclusion": "Human expert evaluation is crucial for legal validity in AI-generated tax answers, despite trade-offs between grounding and fluency."}}
{"id": "2505.15911", "pdf": "https://arxiv.org/pdf/2505.15911", "abs": "https://arxiv.org/abs/2505.15911", "authors": ["Avishai Weizman", "Yehuda Ben-Shimol", "Itshak Lapidot"], "title": "ASVspoof2019 vs. ASVspoof5: Assessment and Comparison", "categories": ["eess.AS"], "comment": "5 pages, 3 figures. Accepted to Interspeech 2025 Conference", "summary": "ASVspoof challenges are designed to advance the understanding of spoofing\nspeech attacks and encourage the development of robust countermeasure systems.\nThese challenges provide a standardized database for assessing and comparing\nspoofing-robust automatic speaker verification solutions. The ASVspoof5\nchallenge introduces a shift in database conditions compared to ASVspoof2019.\nWhile ASVspoof2019 has mismatched conditions only in spoofing attacks in the\nevaluation set, ASVspoof5 incorporates mismatches in both bona fide and spoofed\nspeech statistics. This paper examines the impact of these mismatches,\npresenting qualitative and quantitative comparisons within and between the two\ndatabases. We show the increased difficulty for genuine and spoofed speech and\ndemonstrate that in ASVspoof5, not only are the attacks more challenging, but\nthe genuine speech also shifts toward spoofed speech compared to ASVspoof2019.", "AI": {"tldr": "ASVspoof5 introduces mismatches in both genuine and spoofed speech, making the challenge harder than ASVspoof2019, where mismatches were only in spoofing attacks.", "motivation": "To understand the impact of mismatched conditions in both genuine and spoofed speech on spoofing-robust automatic speaker verification systems.", "method": "Qualitative and quantitative comparisons of ASVspoof5 and ASVspoof2019 databases.", "result": "ASVspoof5 is more challenging due to shifts in genuine speech toward spoofed speech and harder attacks.", "conclusion": "The new conditions in ASVspoof5 increase difficulty, highlighting the need for more robust countermeasures."}}
{"id": "2505.16279", "pdf": "https://arxiv.org/pdf/2505.16279", "abs": "https://arxiv.org/abs/2505.16279", "authors": ["Junjie Zheng", "Zihao Chen", "Chaofan Ding", "Yunming Liang", "Yihan Fan", "Huan Yang", "Lei Xie", "Xinhan Di"], "title": "MM-MovieDubber: Towards Multi-Modal Learning for Multi-Modal Movie Dubbing", "categories": ["cs.MM", "cs.CV"], "comment": "5 pages, 4 figures, accepted by Interspeech 2025", "summary": "Current movie dubbing technology can produce the desired speech using a\nreference voice and input video, maintaining perfect synchronization with the\nvisuals while effectively conveying the intended emotions. However, crucial\naspects of movie dubbing, including adaptation to various dubbing styles,\neffective handling of dialogue, narration, and monologues, as well as\nconsideration of subtle details such as speaker age and gender, remain\ninsufficiently explored. To tackle these challenges, we introduce a multi-modal\ngenerative framework. First, it utilizes a multi-modal large vision-language\nmodel (VLM) to analyze visual inputs, enabling the recognition of dubbing types\nand fine-grained attributes. Second, it produces high-quality dubbing using\nlarge speech generation models, guided by multi-modal inputs. Additionally, a\nmovie dubbing dataset with annotations for dubbing types and subtle details is\nconstructed to enhance movie understanding and improve dubbing quality for the\nproposed multi-modal framework. Experimental results across multiple benchmark\ndatasets show superior performance compared to state-of-the-art (SOTA) methods.\nIn details, the LSE-D, SPK-SIM, EMO-SIM, and MCD exhibit improvements of up to\n1.09%, 8.80%, 19.08%, and 18.74%, respectively.", "AI": {"tldr": "A multi-modal generative framework improves movie dubbing by analyzing visual inputs and generating high-quality speech, outperforming SOTA methods.", "motivation": "Current dubbing technology lacks adaptation to styles, handling of dialogue types, and consideration of speaker details like age and gender.", "method": "Uses a multi-modal VLM for visual analysis and large speech models for dubbing, supported by an annotated dataset.", "result": "Achieves improvements in LSE-D (1.09%), SPK-SIM (8.80%), EMO-SIM (19.08%), and MCD (18.74%) over SOTA.", "conclusion": "The framework enhances dubbing quality by addressing key challenges and leveraging multi-modal inputs."}}
{"id": "2505.15822", "pdf": "https://arxiv.org/pdf/2505.15822", "abs": "https://arxiv.org/abs/2505.15822", "authors": ["Jhon Lopez", "Carlos Hinojosa", "Henry Arguello", "Bernard Ghanem"], "title": "MambaStyle: Efficient StyleGAN Inversion for Real Image Editing with State-Space Models", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "The task of inverting real images into StyleGAN's latent space to manipulate\ntheir attributes has been extensively studied. However, existing GAN inversion\nmethods struggle to balance high reconstruction quality, effective editability,\nand computational efficiency. In this paper, we introduce MambaStyle, an\nefficient single-stage encoder-based approach for GAN inversion and editing\nthat leverages vision state-space models (VSSMs) to address these challenges.\nSpecifically, our approach integrates VSSMs within the proposed architecture,\nenabling high-quality image inversion and flexible editing with significantly\nfewer parameters and reduced computational complexity compared to\nstate-of-the-art methods. Extensive experiments show that MambaStyle achieves a\nsuperior balance among inversion accuracy, editing quality, and computational\nefficiency. Notably, our method achieves superior inversion and editing results\nwith reduced model complexity and faster inference, making it suitable for\nreal-time applications.", "AI": {"tldr": "MambaStyle introduces an efficient single-stage encoder-based GAN inversion method using vision state-space models (VSSMs) to balance reconstruction, editability, and computational efficiency.", "motivation": "Existing GAN inversion methods struggle to balance high reconstruction quality, effective editability, and computational efficiency.", "method": "MambaStyle integrates VSSMs into its architecture for high-quality image inversion and flexible editing with fewer parameters and lower computational complexity.", "result": "MambaStyle achieves superior inversion accuracy, editing quality, and computational efficiency, with faster inference and reduced model complexity.", "conclusion": "MambaStyle is suitable for real-time applications due to its efficiency and effectiveness in GAN inversion and editing."}}
{"id": "2505.15862", "pdf": "https://arxiv.org/pdf/2505.15862", "abs": "https://arxiv.org/abs/2505.15862", "authors": ["Long Wanga", "Jiongzhi Zheng", "Zhengda Xiong", "ChuMin Li", "Kun He"], "title": "Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems", "categories": ["cs.AI"], "comment": null, "summary": "Algorithms designed for routing problems typically rely on high-quality\ncandidate edges to guide their search, aiming to reduce the search space and\nenhance the search efficiency. However, many existing algorithms, like the\nclassical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman\nProblem (TSP), often use predetermined candidate edges that remain static\nthroughout local searches. This rigidity could cause the algorithm to get\ntrapped in local optima, limiting its potential to find better solutions. To\naddress this issue, we propose expanding the candidate sets to include other\npromising edges, providing them an opportunity for selection. Specifically, we\nincorporate multi-armed bandit models to dynamically select the most suitable\ncandidate edges in each iteration, enabling LKH to make smarter choices and\nlead to improved solutions. Extensive experiments on multiple TSP benchmarks\nshow the excellent performance of our method. Moreover, we employ this\nbandit-based method to LKH-3, an extension of LKH tailored for solving various\nTSP variant problems, and our method also significantly enhances LKH-3's\nperformance across typical TSP variants.", "AI": {"tldr": "The paper proposes a dynamic candidate edge selection method using multi-armed bandit models to improve the Lin-Kernighan-Helsgaun (LKH) algorithm for TSP, enhancing solution quality and performance.", "motivation": "Existing algorithms like LKH use static candidate edges, leading to local optima traps and suboptimal solutions.", "method": "Incorporates multi-armed bandit models to dynamically select promising candidate edges during iterations.", "result": "Experiments show improved performance on TSP benchmarks and enhanced LKH-3 for TSP variants.", "conclusion": "Dynamic candidate selection via bandit models significantly boosts LKH and LKH-3 performance."}}
{"id": "2505.15845", "pdf": "https://arxiv.org/pdf/2505.15845", "abs": "https://arxiv.org/abs/2505.15845", "authors": ["Zhibiao Wang", "Yunlong Zhou", "Ziwei Zhang", "Mengmei Zhang", "Shirui Pan", "Chunming Hu", "Xiao Wang"], "title": "Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph Learning Models", "categories": ["cs.LG"], "comment": null, "summary": "Graph Transformers, leveraging the global attention to capture long-range\ndependencies in graph structures, have significantly advanced graph machine\nlearning, but face prohibitive computational complexity. Tokenized Graph\nLearning Models (TGLMs) address this issue by converting graphs into ordered\ntoken lists for scalable processing. Besides, TGLMs also empower Large Language\nModels (LLMs) to handle text-attributed graphs more effectively and thus are\nalso employed in Graph LLMs. However, existing TGLMs rely on hand-designed\ntoken lists and their adaptability to diverse graph learning scenarios remains\nunexplored. In this paper, we first conduct extensive empirical and theoretical\npreliminary studies for hand-designed token lists. Surprisingly, we identify an\nunexplored hop-overpriority problem: the common pre-defined token lists\noveremphasize nearby nodes and overwhelm the ability of TGLMs to balance local\nand global signals. This phenomenon is especially harmful for heterophilic\ngraphs. To address this problem, we propose the Learnable Graph Token List\n(LGTL), a plug-and-play module to replace hand-designed token lists in TGLMs.\nSpecifically, LGTL adaptively adjusts the weights across hops and prioritizes\ninformative nodes within hops through a graph attention gate module and a\nselection module, respectively. In this way, contextually informative nodes can\nbe adaptively emphasized for both homophilic and heterophilic graphs. Besides,\nwe theoretically show that LGTL can address the hop-overpriority problem.\nExtensive experiments on benchmarks validate the efficacy of LGTL across both\nGraph Transformers and Graph LLM backbones.", "AI": {"tldr": "The paper introduces Learnable Graph Token List (LGTL) to address the hop-overpriority problem in Tokenized Graph Learning Models (TGLMs), improving adaptability and performance for both homophilic and heterophilic graphs.", "motivation": "Existing TGLMs rely on hand-designed token lists, which overemphasize nearby nodes and struggle to balance local and global signals, especially in heterophilic graphs.", "method": "Proposes LGTL, a plug-and-play module with a graph attention gate and selection module to adaptively adjust hop weights and prioritize informative nodes.", "result": "LGTL effectively addresses the hop-overpriority problem and improves performance across Graph Transformers and Graph LLM benchmarks.", "conclusion": "LGTL offers a scalable and adaptable solution for TGLMs, enhancing their ability to handle diverse graph learning scenarios."}}
{"id": "2505.15825", "pdf": "https://arxiv.org/pdf/2505.15825", "abs": "https://arxiv.org/abs/2505.15825", "authors": ["Ammar Chouchane", "Mohcene Bessaoudi", "Hamza Kheddar", "Abdelmalik Ouamane", "Tiago Vieira", "Mahmoud Hassaballah"], "title": "Multilinear subspace learning for person re-identification based fusion of high order tensor features", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Video surveillance image analysis and processing is a challenging field in\ncomputer vision, with one of its most difficult tasks being Person\nRe-Identification (PRe-ID). PRe-ID aims to identify and track target\nindividuals who have already been detected in a network of cameras, using a\nrobust description of their pedestrian images. The success of recent research\nin person PRe-ID is largely due to effective feature extraction and\nrepresentation, as well as the powerful learning of these features to reliably\ndiscriminate between pedestrian images. To this end, two powerful features,\nConvolutional Neural Networks (CNN) and Local Maximal Occurrence (LOMO), are\nmodeled on multidimensional data using the proposed method, High-Dimensional\nFeature Fusion (HDFF). Specifically, a new tensor fusion scheme is introduced\nto leverage and combine these two types of features in a single tensor, even\nthough their dimensions are not identical. To enhance the system's accuracy, we\nemploy Tensor Cross-View Quadratic Analysis (TXQDA) for multilinear subspace\nlearning, followed by cosine similarity for matching. TXQDA efficiently\nfacilitates learning while reducing the high dimensionality inherent in\nhigh-order tensor data. The effectiveness of our approach is verified through\nexperiments on three widely-used PRe-ID datasets: VIPeR, GRID, and PRID450S.\nExtensive experiments demonstrate that our approach outperforms recent\nstate-of-the-art methods.", "AI": {"tldr": "The paper proposes High-Dimensional Feature Fusion (HDFF) for Person Re-Identification (PRe-ID), combining CNN and LOMO features using tensor fusion. TXQDA is used for subspace learning, achieving superior results on VIPeR, GRID, and PRID450S datasets.", "motivation": "PRe-ID is challenging in video surveillance. Effective feature extraction and representation are key to identifying and tracking individuals across cameras.", "method": "HDFF combines CNN and LOMO features via tensor fusion. TXQDA handles subspace learning, and cosine similarity is used for matching.", "result": "The method outperforms state-of-the-art techniques on VIPeR, GRID, and PRID450S datasets.", "conclusion": "HDFF with TXQDA effectively enhances PRe-ID accuracy by leveraging high-dimensional feature fusion."}}
{"id": "2310.01945", "pdf": "https://arxiv.org/pdf/2310.01945", "abs": "https://arxiv.org/abs/2310.01945", "authors": ["Kazumi Kasaura"], "title": "Homotopy-Aware Multi-Agent Path Planning on Plane", "categories": ["cs.MA", "cs.CG"], "comment": "21 pages with 5 pages of references and appendices, 23 figures", "summary": "We propose an efficient framework using Dynnikov coordinates for\nhomotopy-aware multi-agent path planning in planar domains that may contain\nobstacles. We developed a method for generating multiple homotopically distinct\nsolutions for the multi-agent path planning problem in planar domains by\ncombining our framework with revised prioritized planning and proved its\ncompleteness under specific assumptions. Experimentally, we demonstrated that\nour method is significantly faster than a method without Dynnikov coordinates.\nWe also confirmed experimentally that homotopy-aware planning contributes to\navoiding locally optimal solutions when searching for low-cost trajectories for\na swarm of agents in a continuous environment.", "AI": {"tldr": "Proposes a homotopy-aware multi-agent path planning framework using Dynnikov coordinates, proving its efficiency and completeness under assumptions.", "motivation": "Addresses the need for efficient and homotopically distinct path planning for swarms in obstacle-filled planar domains.", "method": "Combines Dynnikov coordinates with revised prioritized planning to generate distinct solutions.", "result": "Faster than non-Dynnikov methods and avoids local optima in trajectory planning.", "conclusion": "The framework is effective for homotopy-aware path planning in continuous environments."}}
{"id": "2505.16191", "pdf": "https://arxiv.org/pdf/2505.16191", "abs": "https://arxiv.org/abs/2505.16191", "authors": ["Kentaro Onda", "Keisuke Imoto", "Satoru Fukayama", "Daisuke Saito", "Nobuaki Minematsu"], "title": "Prosodically Enhanced Foreign Accent Simulation by Discrete Token-based Resynthesis Only with Native Speech Corpora", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by Interspeech2025", "summary": "Recently, a method for synthesizing foreign-accented speech only with native\nspeech data using discrete tokens obtained from self-supervised learning (SSL)\nmodels was proposed. Considering limited availability of accented speech data,\nthis method is expected to make it much easier to simulate foreign accents. By\nusing the synthesized accented speech as listening materials for humans or\ntraining data for automatic speech recognition (ASR), both of them will acquire\nhigher robustness against foreign accents. However, the previous method has a\nfatal flaw that it cannot reproduce duration-related accents. Durational\naccents are commonly seen when L2 speakers, whose native language has\nsyllable-timed or mora-timed rhythm, speak stress-timed languages, such as\nEnglish. In this paper, we integrate duration modification to the previous\nmethod to simulate foreign accents more accurately. Experiments show that the\nproposed method successfully replicates durational accents seen in real L2\nspeech.", "AI": {"tldr": "A method to synthesize foreign-accented speech using native data and SSL tokens is improved by adding duration modification to better replicate durational accents.", "motivation": "Limited accented speech data availability makes simulating foreign accents challenging. Existing methods fail to reproduce duration-related accents, common in L2 speakers.", "method": "Integrates duration modification into a previous SSL-based method to simulate foreign accents more accurately.", "result": "The proposed method successfully replicates durational accents observed in real L2 speech.", "conclusion": "The enhanced method improves foreign accent simulation, benefiting applications like ASR and human listening materials."}}
{"id": "2505.15918", "pdf": "https://arxiv.org/pdf/2505.15918", "abs": "https://arxiv.org/abs/2505.15918", "authors": ["Aliakbar Nafar", "Kristen Brent Venable", "Zijun Cui", "Parisa Kordjamshidi"], "title": "Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated potential as factual knowledge\nbases; however, their capability to generate probabilistic knowledge about\nreal-world events remains understudied. This paper investigates using\nprobabilistic knowledge inherent in LLMs to derive probability estimates for\nstatements concerning events and their interrelationships captured via a\nBayesian Network (BN). Using LLMs in this context allows for the\nparameterization of BNs, enabling probabilistic modeling within specific\ndomains. Experiments on eighty publicly available Bayesian Networks, from\nhealthcare to finance, demonstrate that querying LLMs about the conditional\nprobabilities of events provides meaningful results when compared to baselines,\nincluding random and uniform distributions, as well as approaches based on\nnext-token generation probabilities. We explore how these LLM-derived\ndistributions can serve as expert priors to refine distributions extracted from\nminimal data, significantly reducing systematic biases. Overall, this work\nintroduces a promising strategy for automatically constructing Bayesian\nNetworks by combining probabilistic knowledge extracted from LLMs with small\namounts of real-world data. Additionally, we evaluate several prompting\nstrategies for eliciting probabilistic knowledge from LLMs and establish the\nfirst comprehensive baseline for assessing LLM performance in extracting\nprobabilistic knowledge.", "AI": {"tldr": "The paper explores using LLMs to derive probabilistic knowledge for Bayesian Networks, showing their effectiveness in parameterizing BNs and reducing biases when combined with minimal real-world data.", "motivation": "To investigate the understudied capability of LLMs in generating probabilistic knowledge for real-world events and their potential to enhance Bayesian Network modeling.", "method": "Querying LLMs for conditional probabilities of events in BNs across domains like healthcare and finance, comparing results to baselines like random distributions and next-token probabilities.", "result": "LLM-derived distributions provide meaningful probabilistic estimates and can refine expert priors, reducing biases when combined with small datasets.", "conclusion": "The study presents a promising approach for automatically constructing BNs using LLMs and minimal data, while establishing baselines for evaluating LLM performance in probabilistic knowledge extraction."}}
{"id": "2505.15957", "pdf": "https://arxiv.org/pdf/2505.15957", "abs": "https://arxiv.org/abs/2505.15957", "authors": ["Chih-Kai Yang", "Neo S. Ho", "Hung-yi Lee"], "title": "Towards Holistic Evaluation of Large Audio-Language Models: A Comprehensive Survey", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "comment": "Project Website: https://github.com/b08202033/LALM-Evaluation-Survey", "summary": "With advancements in large audio-language models (LALMs), which enhance large\nlanguage models (LLMs) with auditory capabilities, these models are expected to\ndemonstrate universal proficiency across various auditory tasks. While numerous\nbenchmarks have emerged to assess LALMs' performance, they remain fragmented\nand lack a structured taxonomy. To bridge this gap, we conduct a comprehensive\nsurvey and propose a systematic taxonomy for LALM evaluations, categorizing\nthem into four dimensions based on their objectives: (1) General Auditory\nAwareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented\nAbility, and (4) Fairness, Safety, and Trustworthiness. We provide detailed\noverviews within each category and highlight challenges in this field, offering\ninsights into promising future directions. To the best of our knowledge, this\nis the first survey specifically focused on the evaluations of LALMs, providing\nclear guidelines for the community. We will release the collection of the\nsurveyed papers and actively maintain it to support ongoing advancements in the\nfield.", "AI": {"tldr": "The paper proposes a systematic taxonomy for evaluating large audio-language models (LALMs) across four dimensions, addressing the lack of structured benchmarks in the field.", "motivation": "To address the fragmented and unstructured nature of existing benchmarks for LALMs, the authors aim to provide a comprehensive taxonomy for standardized evaluation.", "method": "The authors conduct a survey and categorize LALM evaluations into four dimensions: General Auditory Awareness, Knowledge and Reasoning, Dialogue-oriented Ability, and Fairness, Safety, and Trustworthiness.", "result": "A structured taxonomy is proposed, along with detailed insights into each category and challenges in the field. The paper also highlights future research directions.", "conclusion": "This is the first survey focused on LALM evaluations, offering clear guidelines and a maintained collection of surveyed papers to support future advancements."}}
{"id": "2505.16025", "pdf": "https://arxiv.org/pdf/2505.16025", "abs": "https://arxiv.org/abs/2505.16025", "authors": ["Wen Wen", "Yaohong Wu", "Yue Sheng", "Neil Birkbeck", "Balu Adsumilli", "Yilin Wang"], "title": "CP-LLM: Context and Pixel Aware Large Language Model for Video Quality Assessment", "categories": ["cs.CV", "cs.MM", "eess.IV"], "comment": "Under review", "summary": "Video quality assessment (VQA) is a challenging research topic with broad\napplications. Effective VQA necessitates sensitivity to pixel-level distortions\nand a comprehensive understanding of video context to accurately determine the\nperceptual impact of distortions. Traditional hand-crafted and learning-based\nVQA models mainly focus on pixel-level distortions and lack contextual\nunderstanding, while recent LLM-based models struggle with sensitivity to small\ndistortions or handle quality scoring and description as separate tasks. To\naddress these shortcomings, we introduce CP-LLM: a Context and Pixel aware\nLarge Language Model. CP-LLM is a novel multimodal LLM architecture featuring\ndual vision encoders designed to independently analyze perceptual quality at\nboth high-level (video context) and low-level (pixel distortion) granularity,\nalong with a language decoder subsequently reasons about the interplay between\nthese aspects. This design enables CP-LLM to simultaneously produce robust\nquality scores and interpretable quality descriptions, with enhanced\nsensitivity to pixel distortions (e.g. compression artifacts). The model is\ntrained via a multi-task pipeline optimizing for score prediction, description\ngeneration, and pairwise comparisons. Experiment results demonstrate that\nCP-LLM achieves state-of-the-art cross-dataset performance on established VQA\nbenchmarks and superior robustness to pixel distortions, confirming its\nefficacy for comprehensive and practical video quality assessment in real-world\nscenarios.", "AI": {"tldr": "CP-LLM is a multimodal LLM for video quality assessment, combining high-level context and low-level pixel analysis to improve accuracy and interpretability.", "motivation": "Address limitations of traditional VQA models (lack of contextual understanding) and LLM-based models (insensitivity to small distortions or task separation).", "method": "Dual vision encoders for high-level and low-level analysis, with a language decoder to reason about their interplay. Multi-task training for score prediction, description generation, and comparisons.", "result": "State-of-the-art cross-dataset performance and superior robustness to pixel distortions.", "conclusion": "CP-LLM effectively bridges the gap in VQA by integrating context and pixel awareness, offering practical utility."}}
{"id": "2505.15860", "pdf": "https://arxiv.org/pdf/2505.15860", "abs": "https://arxiv.org/abs/2505.15860", "authors": ["Tieshuai Song", "Jiandong Ye", "Ao Guo", "Guidong He", "Bin Yang"], "title": "RadarRGBD A Multi-Sensor Fusion Dataset for Perception with RGB-D and mmWave Radar", "categories": ["eess.IV"], "comment": "6 pages, 7 figures. Contains a new RGBD dataset for depth completion.\n  Code and dataset will be released", "summary": "Multi-sensor fusion has significant potential in perception tasks for both\nindoor and outdoor environments. Especially under challenging conditions such\nas adverse weather and low-light environments, the combined use of\nmillimeter-wave radar and RGB-D sensors has shown distinct advantages. However,\nexisting multi-sensor datasets in the fields of autonomous driving and robotics\noften lack high-quality millimeter-wave radar data. To address this gap, we\npresent a new multi-sensor dataset:RadarRGBD. This dataset includes RGB-D data,\nmillimeter-wave radar point clouds, and raw radar matrices, covering various\nindoor and outdoor scenes, as well as low-light environments. Compared to\nexisting datasets, RadarRGBD employs higher-resolution millimeter-wave radar\nand provides raw data, offering a new research foundation for the fusion of\nmillimeter-wave radar and visual sensors. Furthermore, to tackle the noise and\ngaps in depth maps captured by Kinect V2 due to occlusions and mismatches, we\nfine-tune an open-source relative depth estimation framework, incorporating the\nabsolute depth information from the dataset for depth supervision. We also\nintroduce pseudo-relative depth scale information to further optimize the\nglobal depth scale estimation. Experimental results demonstrate that the\nproposed method effectively fills in missing regions in sensor data. Our\ndataset and related documentation will be publicly available at:\nhttps://github.com/song4399/RadarRGBD.", "AI": {"tldr": "A new multi-sensor dataset, RadarRGBD, is introduced, combining RGB-D and high-resolution millimeter-wave radar data to address gaps in existing datasets. A method to improve depth map quality is also proposed.", "motivation": "Existing datasets lack high-quality millimeter-wave radar data, limiting research on multi-sensor fusion, especially in challenging conditions like adverse weather and low-light environments.", "method": "The RadarRGBD dataset includes RGB-D data, radar point clouds, and raw radar matrices. A depth estimation framework is fine-tuned using absolute depth information and pseudo-relative depth scale.", "result": "The proposed method effectively fills missing regions in sensor data, improving depth map quality.", "conclusion": "RadarRGBD provides a valuable resource for multi-sensor fusion research, and the depth optimization method enhances data quality. The dataset will be publicly available."}}
{"id": "2505.15929", "pdf": "https://arxiv.org/pdf/2505.15929", "abs": "https://arxiv.org/abs/2505.15929", "authors": ["Hui Shen", "Taiqiang Wu", "Qi Han", "Yunta Hsieh", "Jizhou Wang", "Yuyue Zhang", "Yuxin Cheng", "Zijian Hao", "Yuansheng Ni", "Xin Wang", "Zhongwei Wan", "Kai Zhang", "Wendong Xu", "Jing Xiong", "Ping Luo", "Wenhu Chen", "Chaofan Tao", "Zhuoqing Mao", "Ngai Wong"], "title": "PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning?", "categories": ["cs.AI"], "comment": null, "summary": "Existing benchmarks fail to capture a crucial aspect of intelligence:\nphysical reasoning, the integrated ability to combine domain knowledge,\nsymbolic reasoning, and understanding of real-world constraints. To address\nthis gap, we introduce PhyX: the first large-scale benchmark designed to assess\nmodels capacity for physics-grounded reasoning in visual scenarios. PhyX\nincludes 3K meticulously curated multimodal questions spanning 6 reasoning\ntypes across 25 sub-domains and 6 core physics domains: thermodynamics,\nelectromagnetism, mechanics, modern physics, optics, and wave\\&acoustics. In\nour comprehensive evaluation, even state-of-the-art models struggle\nsignificantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and\nGPT-o4-mini achieve only 32.5\\%, 42.2\\%, and 45.8\\% accuracy\nrespectively-performance gaps exceeding 29\\% compared to human experts. Our\nanalysis exposes critical limitations in current models: over-reliance on\nmemorized disciplinary knowledge, excessive dependence on mathematical\nformulations, and surface-level visual pattern matching rather than genuine\nphysical understanding. We provide in-depth analysis through fine-grained\nstatistics, detailed case studies, and multiple evaluation paradigms to\nthoroughly examine physical reasoning capabilities. To ensure reproducibility,\nwe implement a compatible evaluation protocol based on widely-used toolkits\nsuch as VLMEvalKit, enabling one-click evaluation.", "AI": {"tldr": "PhyX is a new benchmark for physics-grounded reasoning in visual scenarios, revealing significant gaps in current AI models' capabilities compared to humans.", "motivation": "Existing benchmarks lack assessment of physical reasoning, a key aspect of intelligence. PhyX fills this gap by evaluating models' ability to integrate domain knowledge, symbolic reasoning, and real-world constraints.", "method": "PhyX includes 3K multimodal questions across 6 reasoning types and 25 sub-domains in 6 core physics areas. It uses a comprehensive evaluation protocol with fine-grained statistics and case studies.", "result": "State-of-the-art models (GPT-4o, Claude3.7-Sonnet, GPT-o4-mini) perform poorly (32.5%-45.8% accuracy), lagging behind human experts by over 29%. Key limitations include reliance on memorization, math formulations, and surface-level visual matching.", "conclusion": "PhyX highlights critical shortcomings in AI models' physical reasoning, providing a robust benchmark for future improvements. The evaluation protocol ensures reproducibility and standardized assessment."}}
{"id": "2505.15888", "pdf": "https://arxiv.org/pdf/2505.15888", "abs": "https://arxiv.org/abs/2505.15888", "authors": ["Valentin Villecroze", "Yixin Wang", "Gabriel Loaiza-Ganem"], "title": "Last Layer Empirical Bayes", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at the ICBINB Worshop at ICLR 2025", "summary": "The task of quantifying the inherent uncertainty associated with neural\nnetwork predictions is a key challenge in artificial intelligence. Bayesian\nneural networks (BNNs) and deep ensembles are among the most prominent\napproaches to tackle this task. Both approaches produce predictions by\ncomputing an expectation of neural network outputs over some distribution on\nthe corresponding weights; this distribution is given by the posterior in the\ncase of BNNs, and by a mixture of point masses for ensembles. Inspired by\nrecent work showing that the distribution used by ensembles can be understood\nas a posterior corresponding to a learned data-dependent prior, we propose last\nlayer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a\nnormalizing flow, which is then trained to maximize the evidence lower bound;\nto retain tractability we use the flow only on the last layer. We show why LLEB\nis well motivated, and how it interpolates between standard BNNs and ensembles\nin terms of the strength of the prior that they use. LLEB performs on par with\nexisting approaches, highlighting that empirical Bayes is a promising direction\nfor future research in uncertainty quantification.", "AI": {"tldr": "LLEB (last layer empirical Bayes) is proposed as a method for uncertainty quantification in neural networks, combining ideas from BNNs and ensembles by using a learnable prior on the last layer.", "motivation": "Quantifying uncertainty in neural network predictions is crucial, with BNNs and deep ensembles being prominent approaches. LLEB aims to bridge these methods by leveraging empirical Bayes.", "method": "LLEB uses a learnable prior (normalizing flow) on the last layer, trained to maximize the evidence lower bound, balancing between BNNs and ensembles.", "result": "LLEB performs comparably to existing methods, demonstrating its effectiveness.", "conclusion": "Empirical Bayes, as exemplified by LLEB, is a promising direction for future research in uncertainty quantification."}}
{"id": "2505.15863", "pdf": "https://arxiv.org/pdf/2505.15863", "abs": "https://arxiv.org/abs/2505.15863", "authors": ["Katharina Winter", "Abhishek Vivekanandan", "Rupert Polley", "Yinzhe Shen", "Christian Schlauch", "Mohamed-Khalil Bouzidi", "Bojan Derajic", "Natalie Grabowsky", "Annajoyce Mariani", "Dennis Rochau", "Giovanni Lucente", "Harsh Yadav", "Firas Mualla", "Adam Molin", "Sebastian Bernhard", "Christian Wirth", "\u00d6mer \u015eahin Ta\u015f", "Nadja Klein", "Fabian B. Flohr", "Hanno Gottschalk"], "title": "Generative AI for Autonomous Driving: A Review", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Generative AI (GenAI) is rapidly advancing the field of Autonomous Driving\n(AD), extending beyond traditional applications in text, image, and video\ngeneration. We explore how generative models can enhance automotive tasks, such\nas static map creation, dynamic scenario generation, trajectory forecasting,\nand vehicle motion planning. By examining multiple generative approaches\nranging from Variational Autoencoder (VAEs) over Generative Adversarial\nNetworks (GANs) and Invertible Neural Networks (INNs) to Generative\nTransformers (GTs) and Diffusion Models (DMs), we highlight and compare their\ncapabilities and limitations for AD-specific applications. Additionally, we\ndiscuss hybrid methods integrating conventional techniques with generative\napproaches, and emphasize their improved adaptability and robustness. We also\nidentify relevant datasets and outline open research questions to guide future\ndevelopments in GenAI. Finally, we discuss three core challenges: safety,\ninterpretability, and realtime capabilities, and present recommendations for\nimage generation, dynamic scenario generation, and planning.", "AI": {"tldr": "The paper explores how Generative AI (GenAI) enhances Autonomous Driving (AD) tasks, comparing various generative models and hybrid methods, while addressing challenges like safety and real-time capabilities.", "motivation": "To leverage GenAI for improving AD tasks such as map creation, scenario generation, and motion planning, and to compare the effectiveness of different generative models.", "method": "Examines generative models (VAEs, GANs, INNs, GTs, DMs) and hybrid approaches, evaluates their capabilities, and identifies datasets and open research questions.", "result": "Highlights the adaptability and robustness of hybrid methods and outlines challenges (safety, interpretability, real-time performance) with recommendations for future work.", "conclusion": "GenAI holds significant potential for AD, but challenges remain; future research should focus on safety, interpretability, and real-time applications."}}
{"id": "2410.12397", "pdf": "https://arxiv.org/pdf/2410.12397", "abs": "https://arxiv.org/abs/2410.12397", "authors": ["Arseniy Pertzovsky", "Roni Stern", "Roie Zivan", "Ariel Felner"], "title": "Multi-Agent Corridor Generating Algorithm", "categories": ["cs.MA"], "comment": null, "summary": "In this paper, we propose the Multi-Agent Corridor Generating Algorithm\n(MACGA) for solving the Multi-agent Pathfinding (MAPF) problem, where a group\nof agents need to find non-colliding paths to their target locations. Existing\napproaches struggle to solve dense MAPF instances. In MACGA, the agents build\n\\emph{corridors}, which are sequences of connected vertices, from current\nlocations towards agents' goals, and evacuate other agents out of the corridors\nto avoid collisions and deadlocks. We also present the MACGA+PIBT algorithm,\nwhich integrates the well-known rule-based PIBT algorithm into MACGA to improve\nruntime and solution quality. The proposed algorithms run in polynomial time\nand have a reachability property, i.e., every agent is guaranteed to reach its\ngoal location at some point. We demonstrate experimentally that MACGA and\nMACGA+PIBT outperform baseline algorithms in terms of success rate, runtime,\nand makespan across diverse MAPF benchmark grids.", "AI": {"tldr": "MACGA and MACGA+PIBT algorithms solve dense MAPF problems by creating corridors and integrating PIBT, outperforming baselines in success rate, runtime, and makespan.", "motivation": "Existing methods struggle with dense MAPF instances, necessitating efficient collision-free pathfinding for multi-agent systems.", "method": "Agents build corridors (connected vertices) toward goals and evacuate others to avoid collisions. MACGA+PIBT integrates PIBT for improved performance.", "result": "Polynomial-time algorithms with reachability guarantees; experimental results show superior success rate, runtime, and makespan.", "conclusion": "MACGA and MACGA+PIBT effectively address dense MAPF challenges, offering scalable and reliable solutions."}}
{"id": "2505.16195", "pdf": "https://arxiv.org/pdf/2505.16195", "abs": "https://arxiv.org/abs/2505.16195", "authors": ["Zhi Zhong", "Akira Takahashi", "Shuyang Cui", "Keisuke Toyama", "Shusuke Takahashi", "Yuki Mitsufuji"], "title": "SpecMaskFoley: Steering Pretrained Spectral Masked Generative Transformer Toward Synchronized Video-to-audio Synthesis via ControlNet", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "eess.IV"], "comment": "4 pages, 2 figures, 2 tables. Demo page:\n  https://zzaudio.github.io/SpecMaskFoley_Demo/", "summary": "Foley synthesis aims to synthesize high-quality audio that is both\nsemantically and temporally aligned with video frames. Given its broad\napplication in creative industries, the task has gained increasing attention in\nthe research community. To avoid the non-trivial task of training audio\ngenerative models from scratch, adapting pretrained audio generative models for\nvideo-synchronized foley synthesis presents an attractive direction.\nControlNet, a method for adding fine-grained controls to pretrained generative\nmodels, has been applied to foley synthesis, but its use has been limited to\nhandcrafted human-readable temporal conditions. In contrast, from-scratch\nmodels achieved success by leveraging high-dimensional deep features extracted\nusing pretrained video encoders. We have observed a performance gap between\nControlNet-based and from-scratch foley models. To narrow this gap, we propose\nSpecMaskFoley, a method that steers the pretrained SpecMaskGIT model toward\nvideo-synchronized foley synthesis via ControlNet. To unlock the potential of a\nsingle ControlNet branch, we resolve the discrepancy between the temporal video\nfeatures and the time-frequency nature of the pretrained SpecMaskGIT via a\nfrequency-aware temporal feature aligner, eliminating the need for complicated\nconditioning mechanisms widely used in prior arts. Evaluations on a common\nfoley synthesis benchmark demonstrate that SpecMaskFoley could even outperform\nstrong from-scratch baselines, substantially advancing the development of\nControlNet-based foley synthesis models. Demo page:\nhttps://zzaudio.github.io/SpecMaskFoley_Demo/", "AI": {"tldr": "SpecMaskFoley improves ControlNet-based foley synthesis by aligning video features with a pretrained audio model, outperforming from-scratch methods.", "motivation": "To bridge the performance gap between ControlNet-based and from-scratch foley synthesis models by leveraging pretrained models and better feature alignment.", "method": "Proposes SpecMaskFoley, which uses a frequency-aware temporal feature aligner to adapt SpecMaskGIT for video-synchronized foley synthesis via ControlNet.", "result": "Outperforms strong from-scratch baselines on a common benchmark.", "conclusion": "SpecMaskFoley advances ControlNet-based foley synthesis, demonstrating the potential of pretrained models with proper feature alignment."}}
{"id": "2505.15922", "pdf": "https://arxiv.org/pdf/2505.15922", "abs": "https://arxiv.org/abs/2505.15922", "authors": ["Dong Won Lee", "Hae Won Park", "Cynthia Breazeal", "Louis-Philippe Morency"], "title": "Aligning Dialogue Agents with Global Feedback via Large Language Model Reward Decomposition", "categories": ["cs.CL"], "comment": "9 pages, 3 figures, 3 tables", "summary": "We propose a large language model based reward decomposition framework for\naligning dialogue agents using only a single session-level feedback signal. We\nleverage the reasoning capabilities of a frozen, pretrained large language\nmodel (LLM) to infer fine-grained local implicit rewards by decomposing global,\nsession-level feedback. Our first text-only variant prompts the LLM to perform\nreward decomposition using only the dialogue transcript. The second multimodal\nvariant incorporates additional behavioral cues, such as pitch, gaze, and\nfacial affect, expressed as natural language descriptions. These inferred\nturn-level rewards are distilled into a lightweight reward model, which we\nutilize for RL-based fine-tuning for dialogue generation. We evaluate both\ntext-only and multimodal variants against state-of-the-art reward decomposition\nmethods and demonstrate notable improvements in human evaluations of\nconversation quality, suggesting that LLMs are strong reward decomposers that\nobviate the need for manual reward shaping and granular human feedback.", "AI": {"tldr": "A framework uses a pretrained LLM to decompose session-level feedback into fine-grained rewards for aligning dialogue agents, improving conversation quality without manual reward shaping.", "motivation": "Aligning dialogue agents typically requires granular feedback, which is costly. This work aims to simplify alignment using only session-level feedback by leveraging LLMs for reward decomposition.", "method": "Two variants: text-only (using dialogue transcripts) and multimodal (adding behavioral cues). The LLM decomposes global feedback into turn-level rewards, distilled into a lightweight model for RL fine-tuning.", "result": "Outperforms state-of-the-art methods in human evaluations, showing LLMs can effectively decompose rewards without manual intervention.", "conclusion": "LLMs are powerful reward decomposers, eliminating the need for manual reward shaping and detailed human feedback."}}
{"id": "2505.15965", "pdf": "https://arxiv.org/pdf/2505.15965", "abs": "https://arxiv.org/abs/2505.15965", "authors": ["Gowtham Premananth", "Vinith Kugathasan", "Carol Espy-Wilson"], "title": "Analyzing the Impact of Accent on English Speech: Acoustic and Articulatory Perspectives", "categories": ["eess.AS", "eess.SP"], "comment": "Accepted to be presented at Interspeech 2025", "summary": "Advancements in AI-driven speech-based applications have transformed diverse\nindustries ranging from healthcare to customer service. However, the increasing\nprevalence of non-native accented speech in global interactions poses\nsignificant challenges for speech-processing systems, which are often trained\non datasets dominated by native speech. This study investigates accented\nEnglish speech through articulatory and acoustic analysis, identifying simpler\ncoordination patterns and higher average pitch than native speech. Using\neigenspectra and Vocal Tract Variable-based coordination features, we establish\nan efficient method for quantifying accent strength without relying on\nresource-intensive phonetic transcriptions. Our findings provide a new avenue\nfor research on the impacts of accents on speech intelligibility and offer\ninsights for developing inclusive, robust speech processing systems that\naccommodate diverse linguistic communities.", "AI": {"tldr": "The paper explores accented English speech, revealing simpler coordination patterns and higher pitch than native speech, and proposes a method to quantify accent strength without phonetic transcriptions.", "motivation": "The study addresses challenges in speech-processing systems due to non-native accented speech, aiming to improve inclusivity and robustness.", "method": "The research uses articulatory and acoustic analysis, eigenspectra, and Vocal Tract Variable-based coordination features to quantify accent strength.", "result": "Findings show distinct patterns in accented speech and offer a resource-efficient method for accent strength measurement.", "conclusion": "The study opens new research avenues for speech intelligibility and aids in developing inclusive speech-processing systems."}}
{"id": "2505.16057", "pdf": "https://arxiv.org/pdf/2505.16057", "abs": "https://arxiv.org/abs/2505.16057", "authors": ["Ayae Ide", "Tory Park", "Jaron Mink", "Tanusree Sharma"], "title": "Signals of Provenance: Practices & Challenges of Navigating Indicators in AI-Generated Media for Sighted and Blind Individuals", "categories": ["cs.HC", "cs.AI", "cs.MM"], "comment": null, "summary": "AI-Generated (AIG) content has become increasingly widespread by recent\nadvances in generative models and the easy-to-use tools that have significantly\nlowered the technical barriers for producing highly realistic audio, images,\nand videos through simple natural language prompts. In response, platforms are\nadopting provable provenance with platforms recommending AIG to be\nself-disclosed and signaled to users. However, these indicators may be often\nmissed, especially when they rely solely on visual cues and make them\nineffective to users with different sensory abilities. To address the gap, we\nconducted semi-structured interviews (N=28) with 15 sighted and 13 BLV\nparticipants to examine their interaction with AIG content through\nself-disclosed AI indicators. Our findings reveal diverse mental models and\npractices, highlighting different strengths and weaknesses of content-based\n(e.g., title, description) and menu-aided (e.g., AI labels) indicators. While\nsighted participants leveraged visual and audio cues, BLV participants\nprimarily relied on audio and existing assistive tools, limiting their ability\nto identify AIG. Across both groups, they frequently overlooked menu-aided\nindicators deployed by platforms and rather interacted with content-based\nindicators such as title and comments. We uncovered usability challenges\nstemming from inconsistent indicator placement, unclear metadata, and cognitive\noverload. These issues were especially critical for BLV individuals due to the\ninsufficient accessibility of interface elements. We provide practical\nrecommendations and design implications for future AIG indicators across\nseveral dimensions.", "AI": {"tldr": "The paper examines how sighted and blind/low-vision (BLV) users interact with AI-generated (AIG) content indicators, revealing usability challenges and recommending design improvements.", "motivation": "The rise of AIG content and the reliance on visual cues for disclosure create accessibility gaps, especially for BLV users.", "method": "Semi-structured interviews with 28 participants (15 sighted, 13 BLV) to study their interaction with AIG indicators.", "result": "Sighted users relied on visual/audio cues, while BLV users depended on audio and assistive tools. Both groups often missed menu-aided indicators, preferring content-based ones. Usability issues included inconsistent placement and unclear metadata.", "conclusion": "The study highlights the need for more accessible and effective AIG indicators, offering design recommendations to address current gaps."}}
{"id": "2505.15861", "pdf": "https://arxiv.org/pdf/2505.15861", "abs": "https://arxiv.org/abs/2505.15861", "authors": ["Zhenyan Yao", "Miao Zhang", "Lanhu Wu", "Yongri Piao", "Feng Tian", "Weibing Sun", "Huchuan Lu"], "title": "P3Net: Progressive and Periodic Perturbation for Semi-Supervised Medical Image Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Perturbation with diverse unlabeled data has proven beneficial for\nsemi-supervised medical image segmentation (SSMIS). While many works have\nsuccessfully used various perturbation techniques, a deeper understanding of\nlearning perturbations is needed. Excessive or inappropriate perturbation can\nhave negative effects, so we aim to address two challenges: how to use\nperturbation mechanisms to guide the learning of unlabeled data through labeled\ndata, and how to ensure accurate predictions in boundary regions. Inspired by\nhuman progressive and periodic learning, we propose a progressive and periodic\nperturbation mechanism (P3M) and a boundary-focused loss. P3M enables dynamic\nadjustment of perturbations, allowing the model to gradually learn them. Our\nboundary-focused loss encourages the model to concentrate on boundary regions,\nenhancing sensitivity to intricate details and ensuring accurate predictions.\nExperimental results demonstrate that our method achieves state-of-the-art\nperformance on two 2D and 3D datasets. Moreover, P3M is extendable to other\nmethods, and the proposed loss serves as a universal tool for improving\nexisting methods, highlighting the scalability and applicability of our\napproach.", "AI": {"tldr": "The paper introduces a progressive and periodic perturbation mechanism (P3M) and a boundary-focused loss to improve semi-supervised medical image segmentation by dynamically adjusting perturbations and enhancing boundary predictions.", "motivation": "To address the challenges of using perturbation mechanisms effectively in semi-supervised learning and ensuring accurate predictions in boundary regions.", "method": "Proposes P3M for dynamic perturbation adjustment and a boundary-focused loss to enhance sensitivity to details.", "result": "Achieves state-of-the-art performance on 2D and 3D datasets and shows scalability by extending to other methods.", "conclusion": "P3M and the boundary-focused loss are effective, scalable solutions for improving semi-supervised medical image segmentation."}}
{"id": "2505.15998", "pdf": "https://arxiv.org/pdf/2505.15998", "abs": "https://arxiv.org/abs/2505.15998", "authors": ["Thomas Michel", "Marko Cvjetko", "Gautier Hamon", "Pierre-Yves Oudeyer", "Cl\u00e9ment Moulin-Frier"], "title": "Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics", "categories": ["cs.AI"], "comment": "10 pages, 10 figures, submitted to ALIFE 2025 Conference", "summary": "We present a method for the automated discovery of system-level dynamics in\nFlow-Lenia$-$a continuous cellular automaton (CA) with mass conservation and\nparameter localization$-$using a curiosity-driven AI scientist. This method\naims to uncover processes leading to self-organization of evolutionary and\necosystemic dynamics in CAs. We build on previous work which uses diversity\nsearch algorithms in Lenia to find self-organized individual patterns, and\nextend it to large environments that support distinct interacting patterns. We\nadapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive\nexploration of diverse Flow-Lenia environments using simulation-wide metrics,\nsuch as evolutionary activity, compression-based complexity, and multi-scale\nentropy. We test our method in two experiments, showcasing its ability to\nilluminate significantly more diverse dynamics compared to random search. We\nshow qualitative results illustrating how ecosystemic simulations enable\nself-organization of complex collective behaviors not captured by previous\nindividual pattern search and analysis. We complement automated discovery with\nan interactive exploration tool, creating an effective human-AI collaborative\nworkflow for scientific investigation. Though demonstrated specifically with\nFlow-Lenia, this methodology provides a framework potentially applicable to\nother parameterizable complex systems where understanding emergent collective\nproperties is of interest.", "AI": {"tldr": "A method for automated discovery of system-level dynamics in Flow-Lenia using curiosity-driven AI, revealing diverse self-organized behaviors beyond individual patterns.", "motivation": "To uncover self-organization in continuous cellular automata (CAs) with mass conservation, extending beyond individual patterns to ecosystemic dynamics.", "method": "Adapts Intrinsically Motivated Goal Exploration Processes (IMGEPs) with simulation-wide metrics (evolutionary activity, complexity, entropy) to explore diverse Flow-Lenia environments.", "result": "Outperforms random search in discovering diverse dynamics, showcasing complex collective behaviors not found in individual pattern analysis.", "conclusion": "Provides a framework for automated and collaborative exploration of emergent properties in parameterizable complex systems."}}
{"id": "2505.15909", "pdf": "https://arxiv.org/pdf/2505.15909", "abs": "https://arxiv.org/abs/2505.15909", "authors": ["Alex Kogan"], "title": "Is (Selective) Round-To-Nearest Quantization All You Need?", "categories": ["cs.LG", "I.2.7; D.4.8; G.4"], "comment": null, "summary": "Quantization became a necessary tool for serving ever-increasing Large\nLanguage Models (LLMs). RTN (Round-to-Nearest) is perhaps the simplest\nquantization technique that has been around well before LLMs surged to the\nforefront of machine learning (ML) research. Yet, it has been largely dismissed\nby recent and more advanced quantization methods that claim superiority over\nRTN in nearly every aspect of performance. This work aims to dispel this\nestablished point of view, showing that RTN is not only much cheaper to apply,\nbut also its token generation throughput can be better than and accuracy can be\nsimilar to more advanced alternatives. In particular, we discuss our\nimplementation of RTN based on the recent Marlin kernels and demonstrate how\nthe accuracy of RTN can be gradually improved by selectively increasing the\ndata precision format of certain model layers and modules. Based on our\nresults, we argue that RTN presents a viable and practical choice for\nquantizing LLMs.", "AI": {"tldr": "RTN quantization, often dismissed, is shown to be cost-effective, competitive in throughput, and similar in accuracy to advanced methods, making it viable for LLMs.", "motivation": "To challenge the dismissal of RTN quantization by demonstrating its cost-effectiveness, competitive performance, and accuracy improvements for LLMs.", "method": "Implemented RTN using Marlin kernels and selectively increased data precision for certain layers to improve accuracy.", "result": "RTN achieved comparable accuracy and better throughput than advanced methods, proving its practicality.", "conclusion": "RTN is a viable and practical choice for quantizing LLMs, offering simplicity and competitive performance."}}
{"id": "2505.15865", "pdf": "https://arxiv.org/pdf/2505.15865", "abs": "https://arxiv.org/abs/2505.15865", "authors": ["Ingeol Baek", "Hwan Chang", "Sunghyun Ryu", "Hwanhee Lee"], "title": "How Do Large Vision-Language Models See Text in Image? Unveiling the Distinctive Role of OCR Heads", "categories": ["cs.CV"], "comment": null, "summary": "Despite significant advancements in Large Vision Language Models (LVLMs), a\ngap remains, particularly regarding their interpretability and how they locate\nand interpret textual information within images. In this paper, we explore\nvarious LVLMs to identify the specific heads responsible for recognizing text\nfrom images, which we term the Optical Character Recognition Head (OCR Head).\nOur findings regarding these heads are as follows: (1) Less Sparse: Unlike\nprevious retrieval heads, a large number of heads are activated to extract\ntextual information from images. (2) Qualitatively Distinct: OCR heads possess\nproperties that differ significantly from general retrieval heads, exhibiting\nlow similarity in their characteristics. (3) Statically Activated: The\nfrequency of activation for these heads closely aligns with their OCR scores.\nWe validate our findings in downstream tasks by applying Chain-of-Thought (CoT)\nto both OCR and conventional retrieval heads and by masking these heads. We\nalso demonstrate that redistributing sink-token values within the OCR heads\nimproves performance. These insights provide a deeper understanding of the\ninternal mechanisms LVLMs employ in processing embedded textual information in\nimages.", "AI": {"tldr": "The paper identifies and analyzes OCR Heads in LVLMs, revealing their unique properties and impact on text recognition in images.", "motivation": "To address the interpretability gap in LVLMs regarding how they locate and interpret textual information within images.", "method": "Exploration of LVLMs to identify OCR Heads, analysis of their properties, and validation through downstream tasks like CoT and masking.", "result": "OCR Heads are less sparse, qualitatively distinct, and statically activated, with redistributing sink-token values improving performance.", "conclusion": "The findings enhance understanding of LVLMs' internal mechanisms for processing embedded text in images."}}
{"id": "2503.02189", "pdf": "https://arxiv.org/pdf/2503.02189", "abs": "https://arxiv.org/abs/2503.02189", "authors": ["Dickness Kakitahi Kwesiga", "Angshuman Guin", "Michael Hunter"], "title": "Adaptive Traffic Signal Control based on Multi-Agent Reinforcement Learning. Case Study on a simulated real-world corridor", "categories": ["cs.MA"], "comment": null, "summary": "Previous studies that have formulated multi-agent reinforcement learning (RL)\nalgorithms for adaptive traffic signal control have primarily used value-based\nRL methods. However, recent literature has shown that policy-based methods may\nperform better in partially observable environments. Additionally, RL methods\nremain largely untested for real-world normally signal timing plans because of\nthe simplifying assumptions common in the literature. The current study\nattempts to address these gaps and formulates a multi-agent proximal policy\noptimization (MA-PPO) algorithm to implement adaptive and coordinated traffic\ncontrol along an arterial corridor. The formulated MA-PPO has a\ncentralized-critic architecture under a centralized training and decentralized\nexecution framework. Agents are designed to allow selection and implementation\nof up to eight signal phases, as commonly implemented in field controllers. The\nformulated algorithm is tested on a simulated real-world seven intersection\ncorridor. The speed of convergence for each agent was found to depend on the\nsize of the action space, which depends on the number and sequence of signal\nphases. The performance of the formulated MA-PPO adaptive control algorithm is\ncompared with the field implemented actuated-coordinated signal control (ASC),\nmodeled using PTV-Vissim-MaxTime software in the loop simulation (SILs). The\ntrained MA-PPO performed significantly better than the ASC for all movements.\nCompared to ASC the MA-PPO showed 2% and 24% improvements in travel time in the\nprimary and secondary coordination directions, respectively. For cross streets\nmovements MA-PPO also showed significant crossing time reductions. Volume\nsensitivity experiments revealed that the formulated MA-PPO demonstrated good\nstability, robustness, and adaptability to changes in traffic demand.", "AI": {"tldr": "The paper introduces a multi-agent proximal policy optimization (MA-PPO) algorithm for adaptive traffic signal control, outperforming traditional methods in simulated real-world scenarios.", "motivation": "Address gaps in multi-agent RL for traffic control, particularly the lack of testing in real-world conditions and the potential superiority of policy-based methods in partially observable environments.", "method": "Formulated a MA-PPO algorithm with a centralized-critic architecture, tested on a simulated seven-intersection corridor and compared with actuated-coordinated signal control (ASC).", "result": "MA-PPO outperformed ASC, showing 2% and 24% improvements in travel time for primary and secondary directions, respectively, and significant crossing time reductions.", "conclusion": "MA-PPO is stable, robust, and adaptable to traffic demand changes, demonstrating its effectiveness for real-world adaptive traffic control."}}
{"id": "2505.16207", "pdf": "https://arxiv.org/pdf/2505.16207", "abs": "https://arxiv.org/abs/2505.16207", "authors": ["Kentaro Onda", "Yosuke Kashiwagi", "Emiru Tsunoo", "Hayato Futami", "Shinji Watanabe"], "title": "Differentiable K-means for Fully-optimized Discrete Token-based ASR", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by Interspeech2025", "summary": "Recent studies have highlighted the potential of discrete tokens derived from\nself-supervised learning (SSL) models for various speech-related tasks. These\ntokens serve not only as substitutes for text in language modeling but also as\nintermediate representations for tasks such as automatic speech recognition\n(ASR). However, discrete tokens are typically obtained via k-means clustering\nof SSL features independently of downstream tasks, making them suboptimal for\nspecific applications. This paper proposes the use of differentiable k-means,\nenabling the joint optimization of tokenization and downstream tasks. This\napproach enables the fine-tuning of the SSL parameters and learning weights for\noutputs from multiple SSL layers. Experiments were conducted with ASR as a\ndownstream task. ASR accuracy successfully improved owing to the optimized\ntokens. The acquired tokens also exhibited greater purity of phonetic\ninformation, which were found to be useful even in speech resynthesis.", "AI": {"tldr": "The paper proposes differentiable k-means for joint optimization of tokenization and downstream tasks, improving ASR accuracy and phonetic purity.", "motivation": "Discrete tokens from SSL models are suboptimal for specific tasks due to independent k-means clustering.", "method": "Differentiable k-means is introduced to jointly optimize tokenization and downstream tasks, fine-tuning SSL parameters and layer weights.", "result": "ASR accuracy improved, and tokens showed higher phonetic purity, benefiting speech resynthesis.", "conclusion": "Joint optimization enhances token utility for speech tasks, demonstrating broader applicability."}}
{"id": "2505.15948", "pdf": "https://arxiv.org/pdf/2505.15948", "abs": "https://arxiv.org/abs/2505.15948", "authors": ["Parth Sarin", "Juan Pablo Alperin"], "title": "Citation Parsing and Analysis with Language Models", "categories": ["cs.CL", "cs.DL", "cs.SI"], "comment": "Presented at the Workshop on Open Citations & Open Scholarly Metadata\n  2025", "summary": "A key type of resource needed to address global inequalities in knowledge\nproduction and dissemination is a tool that can support journals in\nunderstanding how knowledge circulates. The absence of such a tool has resulted\nin comparatively less information about networks of knowledge sharing in the\nGlobal South. In turn, this gap authorizes the exclusion of researchers and\nscholars from the South in indexing services, reinforcing colonial arrangements\nthat de-center and minoritize those scholars. In order to support citation\nnetwork tracking on a global scale, we investigate the capacity of open-weight\nlanguage models to mark up manuscript citations in an indexable format. We\nassembled a dataset of matched plaintext and annotated citations from preprints\nand published research papers. Then, we evaluated a number of open-weight\nlanguage models on the annotation task. We find that, even out of the box,\ntoday's language models achieve high levels of accuracy on identifying the\nconstituent components of each citation, outperforming state-of-the-art\nmethods. Moreover, the smallest model we evaluated, Qwen3-0.6B, can parse all\nfields with high accuracy in $2^5$ passes, suggesting that post-training is\nlikely to be effective in producing small, robust citation parsing models. Such\na tool could greatly improve the fidelity of citation networks and thus\nmeaningfully improve research indexing and discovery, as well as further\nmetascientific research.", "AI": {"tldr": "The paper proposes using open-weight language models to improve citation parsing for better global knowledge sharing, addressing inequalities in research indexing.", "motivation": "To address global inequalities in knowledge production by improving citation network tracking, especially for the Global South, and countering colonial biases in research indexing.", "method": "Assembled a dataset of plaintext and annotated citations, then evaluated open-weight language models (like Qwen3-0.6B) for citation markup accuracy.", "result": "Open-weight models achieved high accuracy in citation parsing, with Qwen3-0.6B performing well in minimal passes, suggesting potential for small, robust models.", "conclusion": "The tool could enhance citation network fidelity, improving research indexing, discovery, and metascientific research globally."}}
{"id": "2505.16044", "pdf": "https://arxiv.org/pdf/2505.16044", "abs": "https://arxiv.org/abs/2505.16044", "authors": ["Gowtham Premananth", "Philip Resnik", "Sonia Bansal", "Deanna L. Kelly", "Carol Espy-Wilson"], "title": "Multimodal Biomarkers for Schizophrenia: Towards Individual Symptom Severity Estimation", "categories": ["eess.AS", "cs.LG", "eess.IV", "eess.SP"], "comment": "Accepted to be presented at Interspeech 2025", "summary": "Studies on schizophrenia assessments using deep learning typically treat it\nas a classification task to detect the presence or absence of the disorder,\noversimplifying the condition and reducing its clinical applicability. This\ntraditional approach overlooks the complexity of schizophrenia, limiting its\npractical value in healthcare settings. This study shifts the focus to\nindividual symptom severity estimation using a multimodal approach that\nintegrates speech, video, and text inputs. We develop unimodal models for each\nmodality and a multimodal framework to improve accuracy and robustness. By\ncapturing a more detailed symptom profile, this approach can help in enhancing\ndiagnostic precision and support personalized treatment, offering a scalable\nand objective tool for mental health assessment.", "AI": {"tldr": "The paper proposes a multimodal deep learning approach to estimate individual symptom severity in schizophrenia, moving beyond binary classification for better clinical utility.", "motivation": "Traditional deep learning methods oversimplify schizophrenia by treating it as a binary classification task, limiting clinical applicability.", "method": "Unimodal models for speech, video, and text inputs are developed, followed by a multimodal framework to enhance accuracy and robustness.", "result": "The approach captures detailed symptom profiles, improving diagnostic precision and supporting personalized treatment.", "conclusion": "This scalable and objective tool enhances mental health assessment by addressing the complexity of schizophrenia."}}
{"id": "2505.16256", "pdf": "https://arxiv.org/pdf/2505.16256", "abs": "https://arxiv.org/abs/2505.16256", "authors": ["Yan Zhao", "Zhengxue Cheng", "Junxuan Zhang", "Qunshan Gu", "Qi Wang", "Li Song"], "title": "DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "18 pages, 11 figures, 7 tables", "summary": "Most learning-based lossless compressors are designed for a single modality,\nrequiring separate models for multi-modal data and lacking flexibility.\nHowever, different modalities vary significantly in format and statistical\nproperties, making it ineffective to use compressors that lack\nmodality-specific adaptations. While multi-modal large language models (MLLMs)\noffer a potential solution for modality-unified compression, their excessive\ncomplexity hinders practical deployment. To address these challenges, we focus\non the two most common modalities, image and text, and propose DualComp, the\nfirst unified and lightweight learning-based dual-modality lossless compressor.\nBuilt on a lightweight backbone, DualComp incorporates three key structural\nenhancements to handle modality heterogeneity: modality-unified tokenization,\nmodality-switching contextual learning, and modality-routing\nmixture-of-experts. A reparameterization training strategy is also used to\nboost compression performance. DualComp integrates both modality-specific and\nshared parameters for efficient parameter utilization, enabling near real-time\ninference (200KB/s) on desktop CPUs. With much fewer parameters, DualComp\nachieves compression performance on par with the SOTA LLM-based methods for\nboth text and image datasets. Its simplified single-modality variant surpasses\nthe previous best image compressor on the Kodak dataset by about 9% using just\n1.2% of the model size.", "AI": {"tldr": "DualComp is a unified, lightweight learning-based compressor for images and text, addressing modality heterogeneity with efficient parameter use and near real-time performance.", "motivation": "Existing compressors lack flexibility for multi-modal data, and MLLMs are too complex for practical use.", "method": "DualComp uses modality-unified tokenization, modality-switching contextual learning, and modality-routing mixture-of-experts, with reparameterization training.", "result": "Achieves SOTA performance for text and image compression with fewer parameters, and surpasses previous image compressors by 9% with 1.2% model size.", "conclusion": "DualComp offers a practical, efficient solution for dual-modality compression, balancing performance and simplicity."}}
{"id": "2505.15984", "pdf": "https://arxiv.org/pdf/2505.15984", "abs": "https://arxiv.org/abs/2505.15984", "authors": ["Yamin Arefeen", "Brett Levac", "Bhairav Patel", "Chang Ho", "Jonathan I. Tamir"], "title": "Diffusion Probabilistic Generative Models for Accelerated, in-NICU Permanent Magnet Neonatal MRI", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "comment": null, "summary": "Purpose: Magnetic Resonance Imaging (MRI) enables non-invasive assessment of\nbrain abnormalities during early life development. Permanent magnet scanners\noperating in the neonatal intensive care unit (NICU) facilitate MRI of sick\ninfants, but have long scan times due to lower signal-to-noise ratios (SNR) and\nlimited receive coils. This work accelerates in-NICU MRI with diffusion\nprobabilistic generative models by developing a training pipeline accounting\nfor these challenges.\n  Methods: We establish a novel training dataset of clinical, 1 Tesla neonatal\nMR images in collaboration with Aspect Imaging and Sha'are Zedek Medical\nCenter. We propose a pipeline to handle the low quantity and SNR of our\nreal-world dataset (1) modifying existing network architectures to support\nvarying resolutions; (2) training a single model on all data with learned class\nembedding vectors; (3) applying self-supervised denoising before training; and\n(4) reconstructing by averaging posterior samples. Retrospective under-sampling\nexperiments, accounting for signal decay, evaluated each item of our proposed\nmethodology. A clinical reader study with practicing pediatric\nneuroradiologists evaluated our proposed images reconstructed from 1.5x\nunder-sampled data.\n  Results: Combining all data, denoising pre-training, and averaging posterior\nsamples yields quantitative improvements in reconstruction. The generative\nmodel decouples the learned prior from the measurement model and functions at\ntwo acceleration rates without re-training. The reader study suggests that\nproposed images reconstructed from approximately 1.5x under-sampled data are\nadequate for clinical use.\n  Conclusion: Diffusion probabilistic generative models applied with the\nproposed pipeline to handle challenging real-world datasets could reduce scan\ntime of in-NICU neonatal MRI.", "AI": {"tldr": "The paper proposes using diffusion probabilistic generative models to accelerate MRI scans in NICUs, addressing challenges like low SNR and limited data.", "motivation": "To reduce scan times for neonatal MRI in NICUs, which are currently long due to low SNR and limited receive coils.", "method": "Developed a training pipeline with modified network architectures, class embedding vectors, self-supervised denoising, and posterior sample averaging. Evaluated via under-sampling experiments and a clinical reader study.", "result": "Combined methods improved reconstruction quality, and the model worked at two acceleration rates without retraining. Reader study confirmed clinical adequacy.", "conclusion": "The pipeline successfully reduces scan time for in-NICU neonatal MRI using diffusion models."}}
{"id": "2505.16031", "pdf": "https://arxiv.org/pdf/2505.16031", "abs": "https://arxiv.org/abs/2505.16031", "authors": ["Aayushi Dangol", "Robert Wolfe", "Runhua Zhao", "JaeWon Kim", "Trushaa Ramanan", "Katie Davis", "Julie A. Kientz"], "title": "Children's Mental Models of AI Reasoning: Implications for AI Literacy Education", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "As artificial intelligence (AI) advances in reasoning capabilities, most\nrecently with the emergence of Large Reasoning Models (LRMs), understanding how\nchildren conceptualize AI's reasoning processes becomes critical for fostering\nAI literacy. While one of the \"Five Big Ideas\" in AI education highlights\nreasoning algorithms as central to AI decision-making, less is known about\nchildren's mental models in this area. Through a two-phase approach, consisting\nof a co-design session with 8 children followed by a field study with 106\nchildren (grades 3-8), we identified three models of AI reasoning: Deductive,\nInductive, and Inherent. Our findings reveal that younger children (grades 3-5)\noften attribute AI's reasoning to inherent intelligence, while older children\n(grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions\nthat surfaced in children's understanding of AI reasoning and conclude with\nimplications for scaffolding AI curricula and designing explainable AI tools.", "AI": {"tldr": "The paper explores children's mental models of AI reasoning, identifying three types (Deductive, Inductive, Inherent) and age-related differences in understanding. It suggests implications for AI education and explainable AI design.", "motivation": "Understanding how children conceptualize AI's reasoning processes is critical for fostering AI literacy, especially as AI advances in reasoning capabilities.", "method": "A two-phase approach: co-design sessions with 8 children and a field study with 106 children (grades 3-8).", "result": "Younger children (grades 3-5) see AI's reasoning as inherent, while older children (grades 6-8) view it as pattern recognition. Three tensions in understanding were identified.", "conclusion": "The findings have implications for designing AI curricula and explainable AI tools to better support children's AI literacy."}}
{"id": "2505.15931", "pdf": "https://arxiv.org/pdf/2505.15931", "abs": "https://arxiv.org/abs/2505.15931", "authors": ["Morteza Alizadeh", "Mehrdad Oveisi", "Sonya Falahati", "Ghazal Mousavi", "Mohsen Alambardar Meybodi", "Somayeh Sadat Mehrnia", "Ilker Hacihaliloglu", "Arman Rahmim", "Mohammad R. Salmanpour"], "title": "AllMetrics: A Unified Python Library for Standardized Metric Evaluation and Robust Data Validation in Machine Learning", "categories": ["cs.LG", "F.2.2; I.2.7"], "comment": null, "summary": "Machine learning (ML) models rely heavily on consistent and accurate\nperformance metrics to evaluate and compare their effectiveness. However,\nexisting libraries often suffer from fragmentation, inconsistent\nimplementations, and insufficient data validation protocols, leading to\nunreliable results. Existing libraries have often been developed independently\nand without adherence to a unified standard, particularly concerning the\nspecific tasks they aim to support. As a result, each library tends to adopt\nits conventions for metric computation, input/output formatting, error\nhandling, and data validation protocols. This lack of standardization leads to\nboth implementation differences (ID) and reporting differences (RD), making it\ndifficult to compare results across frameworks or ensure reliable evaluations.\nTo address these issues, we introduce AllMetrics, an open-source unified Python\nlibrary designed to standardize metric evaluation across diverse ML tasks,\nincluding regression, classification, clustering, segmentation, and\nimage-to-image translation. The library implements class-specific reporting for\nmulti-class tasks through configurable parameters to cover all use cases, while\nincorporating task-specific parameters to resolve metric computation\ndiscrepancies across implementations. Various datasets from domains like\nhealthcare, finance, and real estate were applied to our library and compared\nwith Python, Matlab, and R components to identify which yield similar results.\nAllMetrics combines a modular Application Programming Interface (API) with\nrobust input validation mechanisms to ensure reproducibility and reliability in\nmodel evaluation. This paper presents the design principles, architectural\ncomponents, and empirical analyses demonstrating the ability to mitigate\nevaluation errors and to enhance the trustworthiness of ML workflows.", "AI": {"tldr": "AllMetrics is a unified Python library addressing inconsistencies in ML metric evaluation by standardizing implementations across tasks.", "motivation": "Fragmentation and inconsistency in existing ML metric libraries lead to unreliable results and hinder comparability.", "method": "Developed AllMetrics, a modular API with robust validation, tested across diverse datasets and compared with other tools.", "result": "AllMetrics mitigates evaluation errors and enhances reliability in ML workflows, as demonstrated empirically.", "conclusion": "AllMetrics provides a standardized, trustworthy solution for ML metric evaluation, improving reproducibility and comparability."}}
{"id": "2505.15867", "pdf": "https://arxiv.org/pdf/2505.15867", "abs": "https://arxiv.org/abs/2505.15867", "authors": ["Nikolaos Chaidos", "Angeliki Dimitriou", "Maria Lymperaiou", "Giorgos Stamou"], "title": "SCENIR: Visual Semantic Clarity through Unsupervised Scene Graph Retrieval", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Despite the dominance of convolutional and transformer-based architectures in\nimage-to-image retrieval, these models are prone to biases arising from\nlow-level visual features, such as color. Recognizing the lack of semantic\nunderstanding as a key limitation, we propose a novel scene graph-based\nretrieval framework that emphasizes semantic content over superficial image\ncharacteristics. Prior approaches to scene graph retrieval predominantly rely\non supervised Graph Neural Networks (GNNs), which require ground truth graph\npairs driven from image captions. However, the inconsistency of caption-based\nsupervision stemming from variable text encodings undermine retrieval\nreliability. To address these, we present SCENIR, a Graph Autoencoder-based\nunsupervised retrieval framework, which eliminates the dependence on labeled\ntraining data. Our model demonstrates superior performance across metrics and\nruntime efficiency, outperforming existing vision-based, multimodal, and\nsupervised GNN approaches. We further advocate for Graph Edit Distance (GED) as\na deterministic and robust ground truth measure for scene graph similarity,\nreplacing the inconsistent caption-based alternatives for the first time in\nimage-to-image retrieval evaluation. Finally, we validate the generalizability\nof our method by applying it to unannotated datasets via automated scene graph\ngeneration, while substantially contributing in advancing state-of-the-art in\ncounterfactual image retrieval.", "AI": {"tldr": "The paper introduces SCENIR, an unsupervised scene graph-based retrieval framework that outperforms existing methods by focusing on semantic content over low-level features. It replaces caption-based supervision with Graph Edit Distance (GED) for robust evaluation.", "motivation": "Current image-to-image retrieval models are biased by low-level features and rely on inconsistent caption-based supervision. The paper aims to improve semantic understanding and retrieval reliability.", "method": "Proposes SCENIR, a Graph Autoencoder-based unsupervised framework, eliminating the need for labeled data and using GED for ground truth similarity.", "result": "SCENIR outperforms vision-based, multimodal, and supervised GNN methods in performance and efficiency.", "conclusion": "The framework advances state-of-the-art in retrieval and generalizes well to unannotated datasets, promoting semantic-focused evaluation."}}
{"id": "2504.12961", "pdf": "https://arxiv.org/pdf/2504.12961", "abs": "https://arxiv.org/abs/2504.12961", "authors": ["Zhouyang Jiang", "Bin Zhang", "Airong Wei", "Zhiwei Xu"], "title": "QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?", "categories": ["cs.MA", "cs.AI"], "comment": "17 pages, 10 figures, 5 tables", "summary": "Credit assignment has remained a fundamental challenge in multi-agent\nreinforcement learning (MARL). Previous studies have primarily addressed this\nissue through value decomposition methods under the centralized training with\ndecentralized execution paradigm, where neural networks are utilized to\napproximate the nonlinear relationship between individual Q-values and the\nglobal Q-value. Although these approaches have achieved considerable success in\nvarious benchmark tasks, they still suffer from several limitations, including\nimprecise attribution of contributions, limited interpretability, and poor\nscalability in high-dimensional state spaces. To address these challenges, we\npropose a novel algorithm, \\textbf{QLLM}, which facilitates the automatic\nconstruction of credit assignment functions using large language models (LLMs).\nSpecifically, the concept of \\textbf{TFCAF} is introduced, wherein the credit\nallocation process is represented as a direct and expressive nonlinear\nfunctional formulation. A custom-designed \\textit{coder-evaluator} framework is\nfurther employed to guide the generation, verification, and refinement of\nexecutable code by LLMs, significantly mitigating issues such as hallucination\nand shallow reasoning during inference. Extensive experiments conducted on\nseveral standard MARL benchmarks demonstrate that the proposed method\nconsistently outperforms existing state-of-the-art baselines. Moreover, QLLM\nexhibits strong generalization capability and maintains compatibility with a\nwide range of MARL algorithms that utilize mixing networks, positioning it as a\npromising and versatile solution for complex multi-agent scenarios.", "AI": {"tldr": "QLLM, a novel MARL algorithm using LLMs for credit assignment, outperforms existing methods by addressing limitations like imprecise attribution and poor scalability.", "motivation": "Credit assignment in MARL is challenging due to imprecise attribution, limited interpretability, and scalability issues in existing methods.", "method": "QLLM leverages LLMs to automatically construct credit assignment functions via TFCAF and a coder-evaluator framework for code generation and refinement.", "result": "QLLM outperforms state-of-the-art baselines in MARL benchmarks, showing strong generalization and compatibility with mixing networks.", "conclusion": "QLLM is a promising, versatile solution for complex multi-agent scenarios, addressing key MARL challenges."}}
{"id": "2505.16211", "pdf": "https://arxiv.org/pdf/2505.16211", "abs": "https://arxiv.org/abs/2505.16211", "authors": ["Kai Li", "Can Shen", "Yile Liu", "Jirui Han", "Kelong Zheng", "Xuechao Zou", "Zhe Wang", "Xingjian Du", "Shun Zhang", "Hanjun Luo", "Yingbin Jin", "Xinxin Xing", "Ziyang Ma", "Yue Liu", "Xiaojun Jia", "Yifan Zhang", "Junfeng Fang", "Kun Wang", "Yibo Yan", "Haoyang Li", "Yiming Li", "Xiaobin Zhuang", "Yang Liu", "Haibo Hu", "Zhuo Chen", "Zhizheng Wu", "Xiaolin Hu", "Eng-Siong Chng", "XiaoFeng Wang", "Wenyuan Xu", "Wei Dong", "Xinfeng Li"], "title": "AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": "Technical Report", "summary": "The rapid advancement and expanding applications of Audio Large Language\nModels (ALLMs) demand a rigorous understanding of their trustworthiness.\nHowever, systematic research on evaluating these models, particularly\nconcerning risks unique to the audio modality, remains largely unexplored.\nExisting evaluation frameworks primarily focus on the text modality or address\nonly a restricted set of safety dimensions, failing to adequately account for\nthe unique characteristics and application scenarios inherent to the audio\nmodality. We introduce AudioTrust-the first multifaceted trustworthiness\nevaluation framework and benchmark specifically designed for ALLMs. AudioTrust\nfacilitates assessments across six key dimensions: fairness, hallucination,\nsafety, privacy, robustness, and authentication. To comprehensively evaluate\nthese dimensions, AudioTrust is structured around 18 distinct experimental\nsetups. Its core is a meticulously constructed dataset of over 4,420 audio/text\nsamples, drawn from real-world scenarios (e.g., daily conversations, emergency\ncalls, voice assistant interactions), specifically designed to probe the\nmultifaceted trustworthiness of ALLMs. For assessment, the benchmark carefully\ndesigns 9 audio-specific evaluation metrics, and we employ a large-scale\nautomated pipeline for objective and scalable scoring of model outputs.\nExperimental results reveal the trustworthiness boundaries and limitations of\ncurrent state-of-the-art open-source and closed-source ALLMs when confronted\nwith various high-risk audio scenarios, offering valuable insights for the\nsecure and trustworthy deployment of future audio models. Our platform and\nbenchmark are available at https://github.com/JusperLee/AudioTrust.", "AI": {"tldr": "AudioTrust is a framework for evaluating trustworthiness in Audio Large Language Models (ALLMs) across six dimensions, using a dataset of 4,420 samples and 9 metrics.", "motivation": "Existing frameworks lack focus on audio-specific risks, necessitating a dedicated evaluation tool for ALLMs.", "method": "AudioTrust uses 18 experimental setups and a dataset of real-world audio/text samples to assess fairness, hallucination, safety, privacy, robustness, and authentication.", "result": "The framework reveals trustworthiness limitations in current ALLMs, providing insights for secure deployment.", "conclusion": "AudioTrust offers a comprehensive benchmark for evaluating and improving the trustworthiness of ALLMs."}}
{"id": "2505.15960", "pdf": "https://arxiv.org/pdf/2505.15960", "abs": "https://arxiv.org/abs/2505.15960", "authors": ["Ryo Kamoi", "Yusen Zhang", "Nan Zhang", "Sarkar Snigdha Sarathi Das", "Rui Zhang"], "title": "Training Step-Level Reasoning Verifiers with Formal Verification Tools", "categories": ["cs.CL"], "comment": "Datasets, models, and code are provided at\n  https://github.com/psunlpgroup/FoVer. Please also refer to our project\n  website at https://fover-prm.github.io/", "summary": "Process Reward Models (PRMs), which provide step-by-step feedback on the\nreasoning generated by Large Language Models (LLMs), are receiving increasing\nattention. However, two key research gaps remain: collecting accurate\nstep-level error labels for training typically requires costly human\nannotation, and existing PRMs are limited to math reasoning problems. In\nresponse to these gaps, this paper aims to address the challenges of automatic\ndataset creation and the generalization of PRMs to diverse reasoning tasks. To\nachieve this goal, we propose FoVer, an approach for training PRMs on\nstep-level error labels automatically annotated by formal verification tools,\nsuch as Z3 for formal logic and Isabelle for theorem proof, which provide\nautomatic and accurate verification for symbolic tasks. Using this approach, we\nsynthesize a training dataset with error labels on LLM responses for formal\nlogic and theorem proof tasks without human annotation. Although this data\nsynthesis is feasible only for tasks compatible with formal verification, we\nobserve that LLM-based PRMs trained on our dataset exhibit cross-task\ngeneralization, improving verification across diverse reasoning tasks.\nSpecifically, PRMs trained with FoVer significantly outperform baseline PRMs\nbased on the original LLMs and achieve competitive or superior results compared\nto state-of-the-art PRMs trained on labels annotated by humans or stronger\nmodels, as measured by step-level verification on ProcessBench and Best-of-K\nperformance across 12 reasoning benchmarks, including MATH, AIME, ANLI, MMLU,\nand BBH. The datasets, models, and code are provided at\nhttps://github.com/psunlpgroup/FoVer.", "AI": {"tldr": "FoVer automates step-level error labeling for training Process Reward Models (PRMs) using formal verification tools, enabling generalization to diverse reasoning tasks without human annotation.", "motivation": "Addressing the high cost of human annotation for step-level error labels and the limited scope of existing PRMs to math reasoning.", "method": "Proposes FoVer, using formal verification tools (e.g., Z3, Isabelle) to automatically annotate step-level errors for training PRMs on formal logic and theorem proof tasks.", "result": "PRMs trained with FoVer outperform baselines and match or exceed state-of-the-art PRMs trained on human-annotated data, showing cross-task generalization.", "conclusion": "FoVer provides a scalable and accurate method for training PRMs, reducing reliance on human annotation and expanding applicability to diverse reasoning tasks."}}
{"id": "2505.16076", "pdf": "https://arxiv.org/pdf/2505.16076", "abs": "https://arxiv.org/abs/2505.16076", "authors": ["Jinhua Liang", "Yuanzhe Chen", "Yi Yuan", "Dongya Jia", "Xiaobin Zhuang", "Zhuo Chen", "Yuping Wang", "Yuxuan Wang"], "title": "AudioMorphix: Training-free audio editing with diffusion probabilistic models", "categories": ["eess.AS"], "comment": null, "summary": "Editing sound with precision is a crucial yet underexplored challenge in\naudio content creation. While existing works can manipulate sounds by text\ninstructions or audio exemplar pairs, they often struggled to modify audio\ncontent precisely while preserving fidelity to the original recording. In this\nwork, we introduce a novel editing approach that enables localized\nmodifications to specific time-frequency regions while keeping the remaining of\nthe audio intact by operating on spectrograms directly. To achieve this, we\npropose AudioMorphix, a training-free audio editor that manipulates a target\nregion on the spectrogram by referring to another recording. Inspired by\nmorphing theory, we conceptualize audio mixing as a process where different\nsounds blend seamlessly through morphing and can be decomposed back into\nindividual components via demorphing. Our AudioMorphix optimizes the noised\nlatent conditioned on raw input and reference audio while rectifying the guided\ndiffusion process through a series of energy functions. Additionally, we\nenhance self-attention layers with a cache mechanism to preserve detailed\ncharacteristics from the original recordings. To advance audio editing\nresearch, we devise a new evaluation benchmark, which includes a curated\ndataset with a variety of editing instructions. Extensive experiments\ndemonstrate that AudioMorphix yields promising performance on various audio\nediting tasks, including addition, removal, time shifting and stretching, and\npitch shifting, achieving high fidelity and precision. Demo and code are\navailable at this url.", "AI": {"tldr": "AudioMorphix is a training-free audio editor for precise, localized modifications in spectrograms, achieving high fidelity and precision in tasks like addition, removal, and pitch shifting.", "motivation": "Existing audio editing methods struggle with precision and fidelity. AudioMorphix addresses this by enabling localized modifications while preserving the original recording's integrity.", "method": "AudioMorphix operates on spectrograms, using morphing theory to blend sounds seamlessly. It optimizes noised latent with energy functions and enhances self-attention layers for detail preservation.", "result": "The method performs well on tasks like addition, removal, time shifting, and pitch shifting, demonstrating high fidelity and precision.", "conclusion": "AudioMorphix advances audio editing with its training-free, precise approach, supported by a new evaluation benchmark."}}
{"id": "2505.16434", "pdf": "https://arxiv.org/pdf/2505.16434", "abs": "https://arxiv.org/abs/2505.16434", "authors": ["Ranjith Merugu", "Mohammad Sameer Suhail", "Akshay P Sarashetti", "Venkata Bharath Reddy Reddem", "Pankaj Kumar Bajpai", "Amit Satish Unde"], "title": "Joint Flow And Feature Refinement Using Attention For Video Restoration", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Recent advancements in video restoration have focused on recovering\nhigh-quality video frames from low-quality inputs. Compared with static images,\nthe performance of video restoration significantly depends on efficient\nexploitation of temporal correlations among successive video frames. The\nnumerous techniques make use of temporal information via flow-based strategies\nor recurrent architectures. However, these methods often encounter difficulties\nin preserving temporal consistency as they utilize degraded input video frames.\nTo resolve this issue, we propose a novel video restoration framework named\nJoint Flow and Feature Refinement using Attention (JFFRA). The proposed JFFRA\nis based on key philosophy of iteratively enhancing data through the\nsynergistic collaboration of flow (alignment) and restoration. By leveraging\npreviously enhanced features to refine flow and vice versa, JFFRA enables\nefficient feature enhancement using temporal information. This interplay\nbetween flow and restoration is executed at multiple scales, reducing the\ndependence on precise flow estimation. Moreover, we incorporate an\nocclusion-aware temporal loss function to enhance the network's capability in\neliminating flickering artifacts. Comprehensive experiments validate the\nversatility of JFFRA across various restoration tasks such as denoising,\ndeblurring, and super-resolution. Our method demonstrates a remarkable\nperformance improvement of up to 1.62 dB compared to state-of-the-art\napproaches.", "AI": {"tldr": "A novel video restoration framework, JFFRA, improves temporal consistency and performance by iteratively refining flow and features using attention, outperforming state-of-the-art methods by up to 1.62 dB.", "motivation": "Existing video restoration methods struggle with temporal consistency due to reliance on degraded inputs. JFFRA addresses this by refining flow and features iteratively.", "method": "JFFRA uses a synergistic approach to refine flow and features at multiple scales, reducing reliance on precise flow estimation, and includes an occlusion-aware loss to reduce flickering.", "result": "JFFRA achieves up to 1.62 dB improvement over state-of-the-art methods in tasks like denoising, deblurring, and super-resolution.", "conclusion": "JFFRA effectively enhances video restoration by improving temporal consistency and feature quality, setting a new benchmark for performance."}}
{"id": "2505.16027", "pdf": "https://arxiv.org/pdf/2505.16027", "abs": "https://arxiv.org/abs/2505.16027", "authors": ["Qinmei Xu", "Yiheng Li", "Xianghao Zhan", "Ahmet Gorkem Er", "Brittany Dashevsky", "Chuanjun Xu", "Mohammed Alawad", "Mengya Yang", "Liu Ya", "Changsheng Zhou", "Xiao Li", "Haruka Itakura", "Olivier Gevaert"], "title": "Benchmarking Chest X-ray Diagnosis Models Across Multinational Datasets", "categories": ["eess.IV", "cs.AI", "cs.CV", "I.2"], "comment": "78 pages, 7 figures, 2 tabeles", "summary": "Foundation models leveraging vision-language pretraining have shown promise\nin chest X-ray (CXR) interpretation, yet their real-world performance across\ndiverse populations and diagnostic tasks remains insufficiently evaluated. This\nstudy benchmarks the diagnostic performance and generalizability of foundation\nmodels versus traditional convolutional neural networks (CNNs) on multinational\nCXR datasets. We evaluated eight CXR diagnostic models - five vision-language\nfoundation models and three CNN-based architectures - across 37 standardized\nclassification tasks using six public datasets from the USA, Spain, India, and\nVietnam, and three private datasets from hospitals in China. Performance was\nassessed using AUROC, AUPRC, and other metrics across both shared and\ndataset-specific tasks. Foundation models outperformed CNNs in both accuracy\nand task coverage. MAVL, a model incorporating knowledge-enhanced prompts and\nstructured supervision, achieved the highest performance on public (mean AUROC:\n0.82; AUPRC: 0.32) and private (mean AUROC: 0.95; AUPRC: 0.89) datasets,\nranking first in 14 of 37 public and 3 of 4 private tasks. All models showed\nreduced performance on pediatric cases, with average AUROC dropping from 0.88\n+/- 0.18 in adults to 0.57 +/- 0.29 in children (p = 0.0202). These findings\nhighlight the value of structured supervision and prompt design in radiologic\nAI and suggest future directions including geographic expansion and ensemble\nmodeling for clinical deployment. Code for all evaluated models is available at\nhttps://drive.google.com/drive/folders/1B99yMQm7bB4h1sVMIBja0RfUu8gLktCE", "AI": {"tldr": "Foundation models outperform CNNs in CXR interpretation, with MAVL leading in performance, though all models struggle with pediatric cases.", "motivation": "Evaluate the real-world performance and generalizability of vision-language foundation models versus traditional CNNs in CXR interpretation across diverse populations and tasks.", "method": "Benchmarked eight models (five foundation, three CNN) on 37 tasks using six public and three private datasets. Performance metrics included AUROC and AUPRC.", "result": "Foundation models, especially MAVL, outperformed CNNs. Performance dropped significantly for pediatric cases (AUROC: 0.57 vs. 0.88 in adults).", "conclusion": "Structured supervision and prompt design enhance radiologic AI. Future work should focus on geographic expansion and ensemble modeling for clinical use."}}
{"id": "2505.16037", "pdf": "https://arxiv.org/pdf/2505.16037", "abs": "https://arxiv.org/abs/2505.16037", "authors": ["Asterios Tsiourvas", "Wei Sun", "Georgia Perakis"], "title": "Causal LLM Routing: End-to-End Regret Minimization from Observational Data", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "LLM routing aims to select the most appropriate model for each query,\nbalancing competing performance metrics such as accuracy and cost across a pool\nof language models. Prior approaches typically adopt a decoupled strategy,\nwhere the metrics are first predicted and the model is then selected based on\nthese estimates. This setup is prone to compounding errors and often relies on\nfull-feedback data, where each query is evaluated by all candidate models,\nwhich is costly to obtain and maintain in practice. In contrast, we learn from\nobservational data, which records only the outcome of the model actually\ndeployed. We propose a causal end-to-end framework that learns routing policies\nby minimizing decision-making regret from observational data. To enable\nefficient optimization, we introduce two theoretically grounded surrogate\nobjectives: a classification-based upper bound, and a softmax-weighted regret\napproximation shown to recover the optimal policy at convergence. We further\nextend our framework to handle heterogeneous cost preferences via an\ninterval-conditioned architecture. Experiments on public benchmarks show that\nour method outperforms existing baselines, achieving state-of-the-art\nperformance across different embedding models.", "AI": {"tldr": "A causal end-to-end framework for LLM routing learns policies from observational data, outperforming decoupled strategies by minimizing regret and handling cost preferences.", "motivation": "Prior decoupled strategies for LLM routing suffer from compounding errors and require costly full-feedback data. Observational data offers a practical alternative.", "method": "Proposes a causal framework with surrogate objectives: a classification-based upper bound and a softmax-weighted regret approximation. Extends to handle cost preferences.", "result": "Outperforms baselines on public benchmarks, achieving state-of-the-art performance across embedding models.", "conclusion": "The framework effectively learns routing policies from observational data, addressing limitations of prior approaches."}}
{"id": "2505.15946", "pdf": "https://arxiv.org/pdf/2505.15946", "abs": "https://arxiv.org/abs/2505.15946", "authors": ["Yuxiang Wei", "Yanteng Zhang", "Xi Xiao", "Tianyang Wang", "Xiao Wang", "Vince D. Calhoun"], "title": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "comment": null, "summary": "Decoding visual experiences from fMRI offers a powerful avenue to understand\nhuman perception and develop advanced brain-computer interfaces. However,\ncurrent progress often prioritizes maximizing reconstruction fidelity while\noverlooking interpretability, an essential aspect for deriving neuroscientific\ninsight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework\ndesigned for high-fidelity, adaptable, and interpretable visual reconstruction.\nMoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture\nwhere distinct experts process fMRI signals from functionally related voxel\ngroups, mimicking specialized brain networks. The experts are first trained to\nencode fMRI into the frozen CLIP space. A finetuned diffusion model then\nsynthesizes images, guided by expert outputs through a novel dual-stage routing\nmechanism that dynamically weighs expert contributions across the diffusion\nprocess. MoRE-Brain offers three main advancements: First, it introduces a\nnovel Mixture-of-Experts architecture grounded in brain network principles for\nneuro-decoding. Second, it achieves efficient cross-subject generalization by\nsharing core expert networks while adapting only subject-specific routers.\nThird, it provides enhanced mechanistic insight, as the explicit routing\nreveals precisely how different modeled brain regions shape the semantic and\nspatial attributes of the reconstructed image. Extensive experiments validate\nMoRE-Brain's high reconstruction fidelity, with bottleneck analyses further\ndemonstrating its effective utilization of fMRI signals, distinguishing genuine\nneural decoding from over-reliance on generative priors. Consequently,\nMoRE-Brain marks a substantial advance towards more generalizable and\ninterpretable fMRI-based visual decoding. Code will be publicly available soon:\nhttps://github.com/yuxiangwei0808/MoRE-Brain.", "AI": {"tldr": "MoRE-Brain is a neuro-inspired framework for high-fidelity, adaptable, and interpretable visual reconstruction from fMRI, using a hierarchical Mixture-of-Experts architecture and diffusion models.", "motivation": "Current fMRI-based visual decoding prioritizes fidelity over interpretability, limiting neuroscientific insights. MoRE-Brain aims to bridge this gap.", "method": "Hierarchical Mixture-of-Experts architecture processes fMRI signals, trained in CLIP space, with a diffusion model for image synthesis and dual-stage routing.", "result": "Achieves high reconstruction fidelity, cross-subject generalization, and mechanistic insight into brain region contributions.", "conclusion": "MoRE-Brain advances fMRI-based visual decoding by improving generalizability and interpretability."}}
{"id": "2505.15870", "pdf": "https://arxiv.org/pdf/2505.15870", "abs": "https://arxiv.org/abs/2505.15870", "authors": ["Can Rong", "Xin Zhang", "Yanxin Xi", "Hongjie Sui", "Jingtao Ding", "Yong Li"], "title": "Satellites Reveal Mobility: A Commuting Origin-destination Flow Generator for Global Cities", "categories": ["cs.CV", "cs.CY", "eess.IV"], "comment": "26 pages, 8 figures", "summary": "Commuting Origin-destination~(OD) flows, capturing daily population mobility\nof citizens, are vital for sustainable development across cities around the\nworld. However, it is challenging to obtain the data due to the high cost of\ntravel surveys and privacy concerns. Surprisingly, we find that satellite\nimagery, publicly available across the globe, contains rich urban semantic\nsignals to support high-quality OD flow generation, with over 98\\%\nexpressiveness of traditional multisource hard-to-collect urban\nsociodemographic, economics, land use, and point of interest data. This\ninspires us to design a novel data generator, GlODGen, which can generate OD\nflow data for any cities of interest around the world. Specifically, GlODGen\nfirst leverages Vision-Language Geo-Foundation Models to extract urban semantic\nsignals related to human mobility from satellite imagery. These features are\nthen combined with population data to form region-level representations, which\nare used to generate OD flows via graph diffusion models. Extensive experiments\non 4 continents and 6 representative cities show that GlODGen has great\ngeneralizability across diverse urban environments on different continents and\ncan generate OD flow data for global cities highly consistent with real-world\nmobility data. We implement GlODGen as an automated tool, seamlessly\nintegrating data acquisition and curation, urban semantic feature extraction,\nand OD flow generation together. It has been released at\nhttps://github.com/tsinghua-fib-lab/generate-od-pubtools.", "AI": {"tldr": "GlODGen uses satellite imagery and population data to generate commuting OD flows globally, achieving high accuracy and generalizability.", "motivation": "Traditional OD flow data collection is costly and privacy-invasive; satellite imagery offers a scalable, privacy-preserving alternative.", "method": "GlODGen extracts urban semantic signals from satellite imagery using Vision-Language Geo-Foundation Models, combines them with population data, and generates OD flows via graph diffusion models.", "result": "GlODGen achieves over 98% expressiveness compared to traditional data sources and performs well across diverse cities on 4 continents.", "conclusion": "GlODGen is a scalable, automated tool for generating accurate OD flow data globally, leveraging publicly available satellite imagery."}}
{"id": "2505.11765", "pdf": "https://arxiv.org/pdf/2505.11765", "abs": "https://arxiv.org/abs/2505.11765", "authors": ["Shijun Li", "Hilaf Hasson", "Joydeep Ghosh"], "title": "OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Agents powered by advanced large language models (LLMs) have demonstrated\nimpressive capabilities across diverse complex applications. Recently,\nMulti-Agent Systems (MAS), wherein multiple agents collaborate and communicate\nwith each other, have exhibited enhanced capabilities in complex tasks, such as\nhigh-quality code generation and arithmetic reasoning. However, the development\nof such systems often relies on handcrafted methods, and the literature on\nsystematic design and optimization of LLM-based MAS remains limited.\n  In this work, we introduce OMAC, a general framework designed for holistic\noptimization of LLM-based MAS. Specifically, we identify five key optimization\ndimensions for MAS, encompassing both agent functionality and collaboration\nstructure. Building upon these dimensions, we first propose a general\nalgorithm, utilizing two actors termed the Semantic Initializer and the\nContrastive Comparator, to optimize any single dimension. Then, we present an\nalgorithm for joint optimization across multiple dimensions. Extensive\nexperiments demonstrate the superior performance of OMAC on code generation,\narithmetic reasoning, and general reasoning tasks against state-of-the-art\napproaches.", "AI": {"tldr": "OMAC is a framework for optimizing Multi-Agent Systems (MAS) powered by LLMs, addressing five key dimensions of agent functionality and collaboration. It outperforms state-of-the-art methods in tasks like code generation and reasoning.", "motivation": "Current LLM-based MAS rely on handcrafted methods, lacking systematic design and optimization. OMAC aims to fill this gap.", "method": "OMAC introduces a general algorithm with two actors (Semantic Initializer and Contrastive Comparator) for single-dimension optimization and extends it for joint optimization across multiple dimensions.", "result": "OMAC shows superior performance in code generation, arithmetic reasoning, and general reasoning tasks.", "conclusion": "OMAC provides a systematic and effective approach for optimizing LLM-based MAS, enhancing their capabilities in complex tasks."}}
{"id": "2505.16259", "pdf": "https://arxiv.org/pdf/2505.16259", "abs": "https://arxiv.org/abs/2505.16259", "authors": ["Hayeon Bang", "Taegyun Kwon", "Juhan Nam"], "title": "Dialogue in Resonance: An Interactive Music Piece for Piano and Real-Time Automatic Transcription System", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "This paper presents <Dialogue in Resonance>, an interactive music piece for a\nhuman pianist and a computer-controlled piano that integrates real-time\nautomatic music transcription into a score-driven framework. Unlike previous\napproaches that primarily focus on improvisation-based interactions, our work\nestablishes a balanced framework that combines composed structure with dynamic\ninteraction. Through real-time automatic transcription as its core mechanism,\nthe computer interprets and responds to the human performer's input in real\ntime, creating a musical dialogue that balances compositional intent with live\ninteraction while incorporating elements of unpredictability. In this paper, we\npresent the development process from composition to premiere performance,\nincluding technical implementation, rehearsal process, and performance\nconsiderations.", "AI": {"tldr": "The paper introduces <Dialogue in Resonance>, an interactive music piece combining human and computer-controlled piano, using real-time transcription for dynamic interaction.", "motivation": "To create a balanced framework integrating composed structure with live interaction, moving beyond improvisation-based approaches.", "method": "Uses real-time automatic transcription to interpret and respond to the pianist's input, blending composition with unpredictability.", "result": "Developed a functional interactive piece, detailing technical implementation, rehearsal, and performance.", "conclusion": "Successfully demonstrated a novel approach to interactive music, balancing structure and live dynamics."}}
{"id": "2505.15962", "pdf": "https://arxiv.org/pdf/2505.15962", "abs": "https://arxiv.org/abs/2505.15962", "authors": ["Linxi Zhao", "Sofian Zalouk", "Christian K. Belardi", "Justin Lovelace", "Jin Peng Zhou", "Kilian Q. Weinberger", "Yoav Artzi", "Jennifer J. Sun"], "title": "Pre-training Large Memory Language Models with Internal and External Knowledge", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Neural language models are black-boxes -- both linguistic patterns and\nfactual knowledge are distributed across billions of opaque parameters. This\nentangled encoding makes it difficult to reliably inspect, verify, or update\nspecific facts. We propose a new class of language models, Large Memory\nLanguage Models (LMLM) with a pre-training recipe that stores factual knowledge\nin both internal weights and an external database. Our approach strategically\nmasks externally retrieved factual values from the training loss, thereby\nteaching the model to perform targeted lookups rather than relying on\nmemorization in model weights. Our experiments demonstrate that LMLMs achieve\ncompetitive performance compared to significantly larger, knowledge-dense LLMs\non standard benchmarks, while offering the advantages of explicit, editable,\nand verifiable knowledge bases. This work represents a fundamental shift in how\nlanguage models interact with and manage factual knowledge.", "AI": {"tldr": "LMLMs store factual knowledge in both internal weights and an external database, enabling editable and verifiable knowledge without sacrificing performance.", "motivation": "Current neural language models lack transparency and control over factual knowledge, making updates and verification difficult.", "method": "LMLMs use pre-training to store knowledge in weights and an external database, masking retrieved facts to encourage targeted lookups.", "result": "LMLMs match performance of larger models while offering editable and verifiable knowledge.", "conclusion": "LMLMs introduce a new paradigm for managing factual knowledge in language models."}}
{"id": "2505.16220", "pdf": "https://arxiv.org/pdf/2505.16220", "abs": "https://arxiv.org/abs/2505.16220", "authors": ["Liang-Yeh Shen", "Shi-Xin Fang", "Yi-Cheng Lin", "Huang-Cheng Chou", "Hung-yi Lee"], "title": "Meta-PerSER: Few-Shot Listener Personalized Speech Emotion Recognition via Meta-learning", "categories": ["eess.AS", "cs.CL"], "comment": "Accepted by INTERSPEECH 2025. 7 pages, including 2 pages of appendix", "summary": "This paper introduces Meta-PerSER, a novel meta-learning framework that\npersonalizes Speech Emotion Recognition (SER) by adapting to each listener's\nunique way of interpreting emotion. Conventional SER systems rely on aggregated\nannotations, which often overlook individual subtleties and lead to\ninconsistent predictions. In contrast, Meta-PerSER leverages a Model-Agnostic\nMeta-Learning (MAML) approach enhanced with Combined-Set Meta-Training,\nDerivative Annealing, and per-layer per-step learning rates, enabling rapid\nadaptation with only a few labeled examples. By integrating robust\nrepresentations from pre-trained self-supervised models, our framework first\ncaptures general emotional cues and then fine-tunes itself to personal\nannotation styles. Experiments on the IEMOCAP corpus demonstrate that\nMeta-PerSER significantly outperforms baseline methods in both seen and unseen\ndata scenarios, highlighting its promise for personalized emotion recognition.", "AI": {"tldr": "Meta-PerSER is a meta-learning framework for personalized Speech Emotion Recognition (SER) that adapts to individual listeners' interpretations, outperforming baselines.", "motivation": "Conventional SER systems ignore individual nuances by relying on aggregated annotations, leading to inconsistent predictions.", "method": "Uses MAML enhanced with Combined-Set Meta-Training, Derivative Annealing, and per-layer per-step learning rates, integrating pre-trained self-supervised models for robust representations.", "result": "Outperforms baselines on IEMOCAP corpus in seen and unseen data scenarios.", "conclusion": "Meta-PerSER shows promise for personalized emotion recognition by adapting quickly with few labeled examples."}}
{"id": "2505.16592", "pdf": "https://arxiv.org/pdf/2505.16592", "abs": "https://arxiv.org/abs/2505.16592", "authors": ["Shijia Zhou", "Siyao Peng", "Simon Luebke", "J\u00f6rg Ha\u00dfler", "Mario Haim", "Saif M. Mohammad", "Barbara Plank"], "title": "What Media Frames Reveal About Stance: A Dataset and Study about Memes in Climate Change Discourse", "categories": ["cs.CL", "cs.MM"], "comment": "19 pages, 9 figures", "summary": "Media framing refers to the emphasis on specific aspects of perceived reality\nto shape how an issue is defined and understood. Its primary purpose is to\nshape public perceptions often in alignment with the authors' opinions and\nstances. However, the interaction between stance and media frame remains\nlargely unexplored. In this work, we apply an interdisciplinary approach to\nconceptualize and computationally explore this interaction with internet memes\non climate change. We curate CLIMATEMEMES, the first dataset of climate-change\nmemes annotated with both stance and media frames, inspired by research in\ncommunication science. CLIMATEMEMES includes 1,184 memes sourced from 47\nsubreddits, enabling analysis of frame prominence over time and communities,\nand sheds light on the framing preferences of different stance holders. We\npropose two meme understanding tasks: stance detection and media frame\ndetection. We evaluate LLaVA-NeXT and Molmo in various setups, and report the\ncorresponding results on their LLM backbone. Human captions consistently\nenhance performance. Synthetic captions and human-corrected OCR also help\noccasionally. Our findings highlight that VLMs perform well on stance, but\nstruggle on frames, where LLMs outperform VLMs. Finally, we analyze VLMs'\nlimitations in handling nuanced frames and stance expressions on climate change\ninternet memes.", "AI": {"tldr": "The paper explores the interaction between stance and media framing in climate change memes, introduces the CLIMATEMEMES dataset, and evaluates AI models on stance and frame detection tasks.", "motivation": "To understand how stance and media framing interact in climate change memes, a largely unexplored area.", "method": "An interdisciplinary approach using the CLIMATEMEMES dataset (1,184 memes) and evaluating AI models (LLaVA-NeXT, Molmo) on stance and frame detection.", "result": "VLMs perform well on stance detection but struggle with frames, where LLMs outperform. Human captions enhance performance.", "conclusion": "The study highlights AI limitations in nuanced frame and stance analysis, suggesting further research is needed."}}
{"id": "2505.16028", "pdf": "https://arxiv.org/pdf/2505.16028", "abs": "https://arxiv.org/abs/2505.16028", "authors": ["Shuvashis Sarker", "Shamim Rahim Refat", "Faika Fairuj Preotee", "Tanvir Rouf Shawon", "Raihan Tanvir"], "title": "Comprehensive Lung Disease Detection Using Deep Learning Models and Hybrid Chest X-ray Data with Explainable AI", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted for publication in 2024 27th International Conference on\n  Computer and Information Technology (ICCIT)", "summary": "Advanced diagnostic instruments are crucial for the accurate detection and\ntreatment of lung diseases, which affect millions of individuals globally. This\nstudy examines the effectiveness of deep learning and transfer learning models\nusing a hybrid dataset, created by merging four individual datasets from\nBangladesh and global sources. The hybrid dataset significantly enhances model\naccuracy and generalizability, particularly in detecting COVID-19, pneumonia,\nlung opacity, and normal lung conditions from chest X-ray images. A range of\nmodels, including CNN, VGG16, VGG19, InceptionV3, Xception, ResNet50V2,\nInceptionResNetV2, MobileNetV2, and DenseNet121, were applied to both\nindividual and hybrid datasets. The results showed superior performance on the\nhybrid dataset, with VGG16, Xception, ResNet50V2, and DenseNet121 each\nachieving an accuracy of 99%. This consistent performance across the hybrid\ndataset highlights the robustness of these models in handling diverse data\nwhile maintaining high accuracy. To understand the models implicit behavior,\nexplainable AI techniques were employed to illuminate their black-box nature.\nSpecifically, LIME was used to enhance the interpretability of model\npredictions, especially in cases of misclassification, contributing to the\ndevelopment of reliable and interpretable AI-driven solutions for medical\nimaging.", "AI": {"tldr": "Deep learning models on a hybrid dataset achieve 99% accuracy in detecting lung conditions from X-rays, with explainable AI enhancing interpretability.", "motivation": "Improving diagnostic accuracy for lung diseases like COVID-19 and pneumonia using diverse datasets and advanced models.", "method": "Applied CNN, VGG16, VGG19, InceptionV3, Xception, ResNet50V2, InceptionResNetV2, MobileNetV2, and DenseNet121 to hybrid and individual datasets, using LIME for explainability.", "result": "Hybrid dataset improved model accuracy, with VGG16, Xception, ResNet50V2, and DenseNet121 achieving 99% accuracy.", "conclusion": "Hybrid datasets and explainable AI enhance model robustness and reliability for medical imaging."}}
{"id": "2505.16048", "pdf": "https://arxiv.org/pdf/2505.16048", "abs": "https://arxiv.org/abs/2505.16048", "authors": ["Philipp D. Siedler"], "title": "SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution", "categories": ["cs.AI"], "comment": null, "summary": "We introduce a novel dataset designed to benchmark the physical and spatial\nreasoning capabilities of Large Language Models (LLM) based on topology\noptimization, a method for computing optimal material distributions within a\ndesign space under prescribed loads and supports. In this dataset, LLMs are\nprovided with conditions such as 2D boundary, applied forces and supports, and\nmust reason about the resulting optimal material distribution. The dataset\nincludes a variety of tasks, ranging from filling in masked regions within\npartial structures to predicting complete material distributions. Solving these\ntasks requires understanding the flow of forces and the required material\ndistribution under given constraints, without access to simulation tools or\nexplicit physical models, challenging models to reason about structural\nstability and spatial organization. Our dataset targets the evaluation of\nspatial and physical reasoning abilities in 2D settings, offering a\ncomplementary perspective to traditional language and logic benchmarks.", "AI": {"tldr": "A new dataset benchmarks LLMs' physical and spatial reasoning using topology optimization tasks in 2D settings.", "motivation": "To evaluate LLMs' ability to reason about material distribution and structural stability without simulation tools.", "method": "LLMs are given boundary conditions, forces, and supports to predict optimal material distributions in tasks like filling masked regions or predicting complete structures.", "result": "The dataset challenges LLMs to understand force flow and material distribution under constraints, focusing on spatial and physical reasoning.", "conclusion": "This dataset provides a unique benchmark for assessing LLMs' spatial and physical reasoning, complementing traditional language and logic tests."}}
{"id": "2505.15987", "pdf": "https://arxiv.org/pdf/2505.15987", "abs": "https://arxiv.org/abs/2505.15987", "authors": ["Aaron Zweig", "Zaikang Lin", "Elham Azizi", "David Knowles"], "title": "Towards Identifiability of Interventional Stochastic Differential Equations", "categories": ["cs.LG"], "comment": null, "summary": "We study identifiability of stochastic differential equation (SDE) models\nunder multiple interventions. Our results give the first provable bounds for\nunique recovery of SDE parameters given samples from their stationary\ndistributions. We give tight bounds on the number of necessary interventions\nfor linear SDEs, and upper bounds for nonlinear SDEs in the small noise regime.\nWe experimentally validate the recovery of true parameters in synthetic data,\nand motivated by our theoretical results, demonstrate the advantage of\nparameterizations with learnable activation functions.", "AI": {"tldr": "The paper provides provable bounds for uniquely recovering SDE parameters from stationary distributions under interventions, with tight bounds for linear SDEs and upper bounds for nonlinear SDEs.", "motivation": "To address identifiability challenges in SDE models under interventions and provide theoretical guarantees for parameter recovery.", "method": "Theoretical analysis of SDE identifiability under interventions, with experiments on synthetic data and learnable activation functions.", "result": "Tight bounds for linear SDEs and upper bounds for nonlinear SDEs in small noise regimes, validated experimentally.", "conclusion": "The study advances SDE model identifiability, with practical implications for parameter recovery and learnable parameterizations."}}
{"id": "2505.15875", "pdf": "https://arxiv.org/pdf/2505.15875", "abs": "https://arxiv.org/abs/2505.15875", "authors": ["Shenghe Zheng", "Hongzhi Wang", "Chenyu Huang", "Xiaohui Wang", "Tao Chen", "Jiayuan Fan", "Shuyue Hu", "Peng Ye"], "title": "Decouple and Orthogonalize: A Data-Free Framework for LoRA Merging", "categories": ["cs.CV", "cs.LG"], "comment": "9 pages, 5 figures", "summary": "With more open-source models available for diverse tasks, model merging has\ngained attention by combining models into one, reducing training, storage, and\ninference costs. Current research mainly focuses on model merging for full\nfine-tuning, overlooking the popular LoRA. However, our empirical analysis\nreveals that: a) existing merging methods designed for full fine-tuning perform\npoorly on LoRA; b) LoRA modules show much larger parameter magnitude variance\nthan full fine-tuned weights; c) greater parameter magnitude variance\ncorrelates with worse merging performance. Considering that large magnitude\nvariances cause deviations in the distribution of the merged parameters,\nresulting in information loss and performance degradation, we propose a\nDecoupled and Orthogonal merging approach(DO-Merging). By separating parameters\ninto magnitude and direction components and merging them independently, we\nreduce the impact of magnitude differences on the directional alignment of the\nmerged models, thereby preserving task information. Furthermore, we introduce a\ndata-free, layer-wise gradient descent method with orthogonal constraints to\nmitigate interference during the merging of direction components. We provide\ntheoretical guarantees for both the decoupling and orthogonal components. And\nwe validate through extensive experiments across vision, language, and\nmulti-modal domains that our proposed DO-Merging can achieve significantly\nhigher performance than existing merging methods at a minimal cost. Notably,\neach component can be flexibly integrated with existing methods, offering near\nfree-lunch improvements across tasks.", "AI": {"tldr": "DO-Merging improves model merging for LoRA by decoupling and orthogonalizing parameters, outperforming existing methods with minimal cost.", "motivation": "Current merging methods perform poorly on LoRA due to large parameter magnitude variance, leading to information loss and degraded performance.", "method": "Proposes DO-Merging: decouples parameters into magnitude and direction, merges independently, and uses data-free, layer-wise gradient descent with orthogonal constraints.", "result": "DO-Merging achieves significantly higher performance across vision, language, and multi-modal tasks compared to existing methods.", "conclusion": "DO-Merging is a flexible, cost-effective solution for merging LoRA models, offering near-free improvements."}}
{"id": "2411.13239", "pdf": "https://arxiv.org/pdf/2411.13239", "abs": "https://arxiv.org/abs/2411.13239", "authors": ["Deming Chen", "Alaa Youssef", "Ruchi Pendse", "Andr\u00e9 Schleife", "Bryan K. Clark", "Hendrik Hamann", "Jingrui He", "Teodoro Laino", "Lav Varshney", "Yuxiong Wang", "Avirup Sil", "Reyhaneh Jabbarvand", "Tianyin Xu", "Volodymyr Kindratenko", "Carlos Costa", "Sarita Adve", "Charith Mendis", "Minjia Zhang", "Santiago N\u00fa\u00f1ez-Corrales", "Raghu Ganti", "Mudhakar Srivatsa", "Nam Sung Kim", "Josep Torrellas", "Jian Huang", "Seetharami Seelam", "Klara Nahrstedt", "Tarek Abdelzaher", "Tamar Eilam", "Huimin Zhao", "Matteo Manica", "Ravishankar Iyer", "Martin Hirzel", "Vikram Adve", "Darko Marinov", "Hubertus Franke", "Hanghang Tong", "Elizabeth Ainsworth", "Han Zhao", "Deepak Vasisht", "Minh Do", "Sahil Suneja", "Fabio Oliveira", "Giovanni Pacifici", "Ruchir Puri", "Priya Nagpurkar"], "title": "Transforming the Hybrid Cloud for Emerging AI Workloads", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.ET", "cs.MA"], "comment": "70 pages, 27 figures", "summary": "This white paper, developed through close collaboration between IBM Research\nand UIUC researchers within the IIDAI Institute, envisions transforming hybrid\ncloud systems to meet the growing complexity of AI workloads through\ninnovative, full-stack co-design approaches, emphasizing usability,\nmanageability, affordability, adaptability, efficiency, and scalability. By\nintegrating cutting-edge technologies such as generative and agentic AI,\ncross-layer automation and optimization, unified control plane, and composable\nand adaptive system architecture, the proposed framework addresses critical\nchallenges in energy efficiency, performance, and cost-effectiveness.\nIncorporating quantum computing as it matures will enable quantum-accelerated\nsimulations for materials science, climate modeling, and other high-impact\ndomains. Collaborative efforts between academia and industry are central to\nthis vision, driving advancements in foundation models for material design and\nclimate solutions, scalable multimodal data processing, and enhanced\nphysics-based AI emulators for applications like weather forecasting and carbon\nsequestration. Research priorities include advancing AI agentic systems, LLM as\nan Abstraction (LLMaaA), AI model optimization and unified abstractions across\nheterogeneous infrastructure, end-to-end edge-cloud transformation, efficient\nprogramming model, middleware and platform, secure infrastructure,\napplication-adaptive cloud systems, and new quantum-classical collaborative\nworkflows. These ideas and solutions encompass both theoretical and practical\nresearch questions, requiring coordinated input and support from the research\ncommunity. This joint initiative aims to establish hybrid clouds as secure,\nefficient, and sustainable platforms, fostering breakthroughs in AI-driven\napplications and scientific discovery across academia, industry, and society.", "AI": {"tldr": "The paper proposes a full-stack co-design framework for hybrid cloud systems to handle complex AI workloads, integrating advanced technologies like generative AI, quantum computing, and cross-layer optimization for efficiency, scalability, and sustainability.", "motivation": "Addressing the growing complexity of AI workloads and the need for hybrid cloud systems that are usable, manageable, affordable, adaptable, efficient, and scalable.", "method": "Innovative full-stack co-design approaches, integrating generative AI, quantum computing, cross-layer automation, unified control planes, and adaptive architectures.", "result": "A framework tackling energy efficiency, performance, and cost-effectiveness, with applications in materials science, climate modeling, and AI-driven scientific discovery.", "conclusion": "Collaborative efforts between academia and industry are essential to establish hybrid clouds as secure, efficient, and sustainable platforms for AI-driven breakthroughs."}}
{"id": "2505.16306", "pdf": "https://arxiv.org/pdf/2505.16306", "abs": "https://arxiv.org/abs/2505.16306", "authors": ["Yizhi Zhou", "Haina Zhu", "Hangting Chen"], "title": "Layer-wise Investigation of Large-Scale Self-Supervised Music Representation Models", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Recently, pre-trained models for music information retrieval based on\nself-supervised learning (SSL) are becoming popular, showing success in various\ndownstream tasks. However, there is limited research on the specific meanings\nof the encoded information and their applicability. Exploring these aspects can\nhelp us better understand their capabilities and limitations, leading to more\neffective use in downstream tasks.\n  In this study, we analyze the advanced music representation model MusicFM and\nthe newly emerged SSL model MuQ. We focus on three main aspects: (i) validating\nthe advantages of SSL models across multiple downstream tasks, (ii) exploring\nthe specialization of layer-wise information for different tasks, and (iii)\ncomparing performance differences when selecting specific layers. Through this\nanalysis, we reveal insights into the structure and potential applications of\nSSL models in music information retrieval.", "AI": {"tldr": "Analysis of SSL models MusicFM and MuQ in music information retrieval, focusing on their advantages, layer-wise specialization, and performance differences.", "motivation": "Limited research on the encoded information and applicability of SSL models in music information retrieval, prompting a deeper understanding for better downstream task use.", "method": "Analyze MusicFM and MuQ by validating SSL advantages, exploring layer-wise task specialization, and comparing performance with specific layers.", "result": "Reveals insights into SSL model structure and potential applications in music information retrieval.", "conclusion": "Understanding SSL model capabilities and limitations enhances their effective use in downstream tasks."}}
{"id": "2505.15993", "pdf": "https://arxiv.org/pdf/2505.15993", "abs": "https://arxiv.org/abs/2505.15993", "authors": ["Anirudh Maiya", "Razan Alghamdi", "Maria Leonor Pacheco", "Ashutosh Trivedi", "Fabio Somenzi"], "title": "Explaining Puzzle Solutions in Natural Language: An Exploratory Study on 6x6 Sudoku", "categories": ["cs.CL"], "comment": "Accepted to Findings of ACL 2025", "summary": "The success of Large Language Models (LLMs) in human-AI collaborative\ndecision-making hinges on their ability to provide trustworthy, gradual, and\ntailored explanations. Solving complex puzzles, such as Sudoku, offers a\ncanonical example of this collaboration, where clear and customized\nexplanations often hold greater importance than the final solution. In this\nstudy, we evaluate the performance of five LLMs in solving and explaining\n\\sixsix{} Sudoku puzzles. While one LLM demonstrates limited success in solving\npuzzles, none can explain the solution process in a manner that reflects\nstrategic reasoning or intuitive problem-solving. These findings underscore\nsignificant challenges that must be addressed before LLMs can become effective\npartners in human-AI collaborative decision-making.", "AI": {"tldr": "LLMs struggle to provide strategic explanations for Sudoku puzzles, highlighting challenges in human-AI collaboration.", "motivation": "To assess LLMs' ability to solve and explain Sudoku puzzles, a key task for human-AI collaboration.", "method": "Evaluated five LLMs on solving and explaining Sudoku puzzles.", "result": "Limited puzzle-solving success; none provided strategic or intuitive explanations.", "conclusion": "Significant improvements needed for LLMs to be effective in collaborative decision-making."}}
{"id": "2505.16351", "pdf": "https://arxiv.org/pdf/2505.16351", "abs": "https://arxiv.org/abs/2505.16351", "authors": ["Chenxu Guo", "Jiachen Lian", "Xuanru Zhou", "Jinming Zhang", "Shuhe Li", "Zongli Ye", "Hwi Joo Park", "Anaisha Das", "Zoe Ezzes", "Jet Vonk", "Brittany Morin", "Rian Bogley", "Lisa Wauters", "Zachary Miller", "Maria Gorno-Tempini", "Gopala Anumanchipalli"], "title": "Dysfluent WFST: A Framework for Zero-Shot Speech Dysfluency Transcription and Detection", "categories": ["eess.AS", "cs.AI"], "comment": null, "summary": "Automatic detection of speech dysfluency aids speech-language pathologists in\nefficient transcription of disordered speech, enhancing diagnostics and\ntreatment planning. Traditional methods, often limited to classification,\nprovide insufficient clinical insight, and text-independent models misclassify\ndysfluency, especially in context-dependent cases. This work introduces\nDysfluent-WFST, a zero-shot decoder that simultaneously transcribes phonemes\nand detects dysfluency. Unlike previous models, Dysfluent-WFST operates with\nupstream encoders like WavLM and requires no additional training. It achieves\nstate-of-the-art performance in both phonetic error rate and dysfluency\ndetection on simulated and real speech data. Our approach is lightweight,\ninterpretable, and effective, demonstrating that explicit modeling of\npronunciation behavior in decoding, rather than complex architectures, is key\nto improving dysfluency processing systems.", "AI": {"tldr": "Dysfluent-WFST is a zero-shot decoder for simultaneous phoneme transcription and dysfluency detection, outperforming traditional methods without extra training.", "motivation": "Traditional dysfluency detection methods lack clinical insight and misclassify context-dependent cases, necessitating a better approach.", "method": "Uses Dysfluent-WFST, a zero-shot decoder with upstream encoders like WavLM, requiring no additional training.", "result": "Achieves state-of-the-art performance in phonetic error rate and dysfluency detection on simulated and real speech data.", "conclusion": "Explicit modeling of pronunciation behavior in decoding improves dysfluency processing more effectively than complex architectures."}}
{"id": "2505.16663", "pdf": "https://arxiv.org/pdf/2505.16663", "abs": "https://arxiv.org/abs/2505.16663", "authors": ["Haihong Hao", "Mingfei Han", "Changlin Li", "Zhihui Li", "Xiaojun Chang"], "title": "CoNav: Collaborative Cross-Modal Reasoning for Embodied Navigation", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Embodied navigation demands comprehensive scene understanding and precise\nspatial reasoning. While image-text models excel at interpreting pixel-level\ncolor and lighting cues, 3D-text models capture volumetric structure and\nspatial relationships. However, unified fusion approaches that jointly fuse 2D\nimages, 3D point clouds, and textual instructions face challenges in limited\navailability of triple-modality data and difficulty resolving conflicting\nbeliefs among modalities. In this work, we introduce CoNav, a collaborative\ncross-modal reasoning framework where a pretrained 3D-text model explicitly\nguides an image-text navigation agent by providing structured spatial-semantic\nknowledge to resolve ambiguities during navigation. Specifically, we introduce\nCross-Modal Belief Alignment, which operationalizes this cross-modal guidance\nby simply sharing textual hypotheses from the 3D-text model to the navigation\nagent. Through lightweight fine-tuning on a small 2D-3D-text corpus, the\nnavigation agent learns to integrate visual cues with spatial-semantic\nknowledge derived from the 3D-text model, enabling effective reasoning in\nembodied navigation. CoNav achieves significant improvements on four standard\nembodied navigation benchmarks (R2R, CVDN, REVERIE, SOON) and two spatial\nreasoning benchmarks (ScanQA, SQA3D). Moreover, under close navigation Success\nRate, CoNav often generates shorter paths compared to other methods (as\nmeasured by SPL), showcasing the potential and challenges of fusing data from\ndifferent modalities in embodied navigation. Project Page:\nhttps://oceanhao.github.io/CoNav/", "AI": {"tldr": "CoNav introduces a collaborative cross-modal reasoning framework for embodied navigation, combining 2D images, 3D point clouds, and text to improve performance on benchmarks.", "motivation": "Addressing challenges in unified fusion of 2D images, 3D point clouds, and text for embodied navigation, particularly limited data and conflicting beliefs among modalities.", "method": "CoNav uses a pretrained 3D-text model to guide an image-text navigation agent via Cross-Modal Belief Alignment, sharing textual hypotheses and fine-tuning on a small corpus.", "result": "Significant improvements on four embodied navigation benchmarks (R2R, CVDN, REVERIE, SOON) and two spatial reasoning benchmarks (ScanQA, SQA3D), with shorter paths (higher SPL).", "conclusion": "CoNav demonstrates the potential of cross-modal fusion in embodied navigation, though challenges remain."}}
{"id": "2505.16091", "pdf": "https://arxiv.org/pdf/2505.16091", "abs": "https://arxiv.org/abs/2505.16091", "authors": ["Jinpei Guo", "Yifei Ji", "Zheng Chen", "Kai Liu", "Min Liu", "Wang Rao", "Wenbo Li", "Yong Guo", "Yulun Zhang"], "title": "OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Pretrained latent diffusion models have shown strong potential for lossy\nimage compression, owing to their powerful generative priors. Most existing\ndiffusion-based methods reconstruct images by iteratively denoising from random\nnoise, guided by compressed latent representations. While these approaches have\nachieved high reconstruction quality, their multi-step sampling process incurs\nsubstantial computational overhead. Moreover, they typically require training\nseparate models for different compression bit-rates, leading to significant\ntraining and storage costs. To address these challenges, we propose a one-step\ndiffusion codec across multiple bit-rates. termed OSCAR. Specifically, our\nmethod views compressed latents as noisy variants of the original latents,\nwhere the level of distortion depends on the bit-rate. This perspective allows\nthem to be modeled as intermediate states along a diffusion trajectory. By\nestablishing a mapping from the compression bit-rate to a pseudo diffusion\ntimestep, we condition a single generative model to support reconstructions at\nmultiple bit-rates. Meanwhile, we argue that the compressed latents retain rich\nstructural information, thereby making one-step denoising feasible. Thus, OSCAR\nreplaces iterative sampling with a single denoising pass, significantly\nimproving inference efficiency. Extensive experiments demonstrate that OSCAR\nachieves superior performance in both quantitative and visual quality metrics.\nThe code and models will be released at https://github.com/jp-guo/OSCAR.", "AI": {"tldr": "OSCAR is a one-step diffusion codec for image compression, addressing computational overhead and bit-rate flexibility by modeling compressed latents as noisy variants and using a single generative model.", "motivation": "Existing diffusion-based methods for image compression are computationally intensive and require separate models for different bit-rates, leading to high costs.", "method": "OSCAR models compressed latents as noisy variants of original latents, mapping bit-rates to pseudo diffusion timesteps, enabling one-step denoising with a single model.", "result": "OSCAR achieves superior performance in quantitative and visual quality metrics while significantly improving inference efficiency.", "conclusion": "OSCAR offers an efficient and flexible solution for diffusion-based image compression, reducing computational and storage costs."}}
{"id": "2505.16067", "pdf": "https://arxiv.org/pdf/2505.16067", "abs": "https://arxiv.org/abs/2505.16067", "authors": ["Zidi Xiong", "Yuping Lin", "Wenya Xie", "Pengfei He", "Jiliang Tang", "Himabindu Lakkaraju", "Zhen Xiang"], "title": "How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior", "categories": ["cs.AI"], "comment": null, "summary": "Memory is a critical component in large language model (LLM)-based agents,\nenabling them to store and retrieve past executions to improve task performance\nover time. In this paper, we conduct an empirical study on how memory\nmanagement choices impact the LLM agents' behavior, especially their long-term\nperformance. Specifically, we focus on two fundamental memory operations that\nare widely used by many agent frameworks-addition, which incorporates new\nexperiences into the memory base, and deletion, which selectively removes past\nexperiences-to systematically study their impact on the agent behavior. Through\nour quantitative analysis, we find that LLM agents display an\nexperience-following property: high similarity between a task input and the\ninput in a retrieved memory record often results in highly similar agent\noutputs. Our analysis further reveals two significant challenges associated\nwith this property: error propagation, where inaccuracies in past experiences\ncompound and degrade future performance, and misaligned experience replay,\nwhere outdated or irrelevant experiences negatively influence current tasks.\nThrough controlled experiments, we show that combining selective addition and\ndeletion strategies can help mitigate these negative effects, yielding an\naverage absolute performance gain of 10% compared to naive memory growth.\nFurthermore, we highlight how memory management choices affect agents' behavior\nunder challenging conditions such as task distribution shifts and constrained\nmemory resources. Our findings offer insights into the behavioral dynamics of\nLLM agent memory systems and provide practical guidance for designing memory\ncomponents that support robust, long-term agent performance. We also release\nour code to facilitate further study.", "AI": {"tldr": "The paper studies how memory management (addition and deletion of experiences) impacts LLM agents' long-term performance, identifying challenges like error propagation and misaligned experience replay. Selective strategies improve performance by 10%.", "motivation": "Memory is crucial for LLM agents to improve task performance over time, but poor memory management can lead to degraded behavior. This study aims to understand and mitigate such issues.", "method": "Empirical study focusing on memory operations (addition and deletion) and their impact on agent behavior, using quantitative analysis and controlled experiments.", "result": "LLM agents exhibit experience-following behavior, leading to challenges like error propagation and misaligned replay. Selective memory strategies improve performance by 10%.", "conclusion": "Effective memory management (selective addition/deletion) enhances LLM agent robustness, especially under challenging conditions. The findings guide better memory system design."}}
{"id": "2505.16004", "pdf": "https://arxiv.org/pdf/2505.16004", "abs": "https://arxiv.org/abs/2505.16004", "authors": ["Aaron J. Li", "Suraj Srinivas", "Usha Bhalla", "Himabindu Lakkaraju"], "title": "Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Sparse autoencoders (SAEs) are commonly used to interpret the internal\nactivations of large language models (LLMs) by mapping them to\nhuman-interpretable concept representations. While existing evaluations of SAEs\nfocus on metrics such as the reconstruction-sparsity tradeoff, human\n(auto-)interpretability, and feature disentanglement, they overlook a critical\naspect: the robustness of concept representations to input perturbations. We\nargue that robustness must be a fundamental consideration for concept\nrepresentations, reflecting the fidelity of concept labeling. To this end, we\nformulate robustness quantification as input-space optimization problems and\ndevelop a comprehensive evaluation framework featuring realistic scenarios in\nwhich adversarial perturbations are crafted to manipulate SAE representations.\nEmpirically, we find that tiny adversarial input perturbations can effectively\nmanipulate concept-based interpretations in most scenarios without notably\naffecting the outputs of the base LLMs themselves. Overall, our results suggest\nthat SAE concept representations are fragile and may be ill-suited for\napplications in model monitoring and oversight.", "AI": {"tldr": "SAEs for interpreting LLMs lack robustness to input perturbations, making concept representations fragile and unreliable for model oversight.", "motivation": "Existing SAE evaluations overlook robustness, a critical aspect for concept representation fidelity.", "method": "Formulated robustness quantification via input-space optimization and adversarial perturbation crafting.", "result": "Tiny adversarial perturbations manipulate SAE interpretations without affecting LLM outputs.", "conclusion": "SAE concept representations are fragile, unsuitable for model monitoring and oversight."}}
{"id": "2505.15877", "pdf": "https://arxiv.org/pdf/2505.15877", "abs": "https://arxiv.org/abs/2505.15877", "authors": ["Siting Li", "Xiang Gao", "Simon Shaolei Du"], "title": "Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "25 pages, 5 figures", "summary": "While an image is worth more than a thousand words, only a few provide\ncrucial information for a given task and thus should be focused on. In light of\nthis, ideal text-to-image (T2I) retrievers should prioritize specific visual\nattributes relevant to queries. To evaluate current retrievers on handling\nattribute-focused queries, we build COCO-Facet, a COCO-based benchmark with\n9,112 queries about diverse attributes of interest. We find that CLIP-like\nretrievers, which are widely adopted due to their efficiency and zero-shot\nability, have poor and imbalanced performance, possibly because their image\nembeddings focus on global semantics and subjects while leaving out other\ndetails. Notably, we reveal that even recent Multimodal Large Language Model\n(MLLM)-based, stronger retrievers with a larger output dimension struggle with\nthis limitation. Hence, we hypothesize that retrieving with general image\nembeddings is suboptimal for performing such queries. As a solution, we propose\nto use promptable image embeddings enabled by these multimodal retrievers,\nwhich boost performance by highlighting required attributes. Our pipeline for\nderiving such embeddings generalizes across query types, image pools, and base\nretriever architectures. To enhance real-world applicability, we offer two\nacceleration strategies: Pre-processing promptable embeddings and using linear\napproximations. We show that the former yields a 15% improvement in Recall@5\nwhen prompts are predefined, while the latter achieves an 8% improvement when\nprompts are only available during inference.", "AI": {"tldr": "The paper introduces COCO-Facet, a benchmark for evaluating text-to-image retrievers on attribute-focused queries, revealing limitations in current models like CLIP and MLLM-based retrievers. It proposes promptable image embeddings to improve performance and offers acceleration strategies.", "motivation": "Current text-to-image retrievers like CLIP and MLLM-based models struggle with attribute-focused queries due to their focus on global semantics, leaving out crucial details. This limits their effectiveness in real-world applications.", "method": "The authors build COCO-Facet, a benchmark with 9,112 queries, to evaluate retrievers. They propose promptable image embeddings to highlight required attributes and introduce two acceleration strategies: pre-processing embeddings and linear approximations.", "result": "Promptable embeddings significantly improve performance, with pre-processing yielding a 15% improvement in Recall@5 for predefined prompts and linear approximations achieving an 8% improvement for inference-time prompts.", "conclusion": "General image embeddings are suboptimal for attribute-focused queries. Promptable embeddings, combined with acceleration strategies, offer a scalable and effective solution, enhancing real-world applicability."}}
{"id": "2412.04233", "pdf": "https://arxiv.org/pdf/2412.04233", "abs": "https://arxiv.org/abs/2412.04233", "authors": ["Kale-ab Abebe Tessera", "Arrasy Rahman", "Amos Storkey", "Stefano V. Albrecht"], "title": "HyperMARL: Adaptive Hypernetworks for Multi-Agent RL", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Adaptability to specialised or homogeneous behaviours is critical in\ncooperative multi-agent reinforcement learning (MARL). Parameter sharing (PS)\ntechniques, common for efficient adaptation, often limit behavioural diversity\ndue to cross-agent gradient interference, which we show can be exacerbated by\nthe coupling of observations and agent IDs. Current remedies typically add\ncomplexity through altered objectives, manual preset diversity levels, or\nsequential updates. We ask: can shared policies adapt without these\ncomplexities? We propose HyperMARL, a PS approach using hypernetworks for\ndynamic agent-specific parameters, without altering the RL objective or\nrequiring preset diversity levels. HyperMARL's explicit decoupling of\nobservation- and agent-conditioned gradients empirically reduces policy\ngradient variance, facilitates shared-policy adaptation (including\nspecialisation), and helps mitigate cross-agent interference. Across diverse\nMARL benchmarks (up to 20 agents), requiring homogeneous, heterogeneous, or\nmixed behaviours, HyperMARL achieves competitive performance against key\nbaselines -- fully shared, non-parameter sharing, and three diversity-promoting\nmethods -- while preserving behavioural diversity comparable to non-parameter\nsharing. These findings establish HyperMARL as a versatile approach for\nadaptive MARL. The code is publicly available at\nhttps://github.com/KaleabTessera/HyperMARL.", "AI": {"tldr": "HyperMARL is a parameter-sharing MARL method using hypernetworks to dynamically adapt agent-specific parameters, reducing gradient interference and preserving diversity without added complexity.", "motivation": "Addressing the limitations of parameter-sharing in MARL, which often restricts behavioral diversity due to cross-agent gradient interference, HyperMARL aims to enable adaptive policies without altering objectives or requiring preset diversity levels.", "method": "HyperMARL employs hypernetworks to dynamically generate agent-specific parameters, decoupling observation- and agent-conditioned gradients to reduce interference and variance.", "result": "HyperMARL achieves competitive performance across diverse MARL benchmarks (up to 20 agents), maintaining behavioral diversity comparable to non-parameter sharing while outperforming other methods.", "conclusion": "HyperMARL is a versatile and effective approach for adaptive MARL, balancing performance and diversity without added complexity."}}
{"id": "2505.16369", "pdf": "https://arxiv.org/pdf/2505.16369", "abs": "https://arxiv.org/abs/2505.16369", "authors": ["Junbo Zhang", "Heinrich Dinkel", "Yadong Niu", "Chenyu Liu", "Si Cheng", "Anbei Zhao", "Jian Luan"], "title": "X-ARES: A Comprehensive Framework for Assessing Audio Encoder Performance", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by Interspeech 2025", "summary": "We introduces X-ARES (eXtensive Audio Representation and Evaluation Suite), a\nnovel open-source benchmark designed to systematically assess audio encoder\nperformance across diverse domains. By encompassing tasks spanning speech,\nenvironmental sounds, and music, X-ARES provides two evaluation approaches for\nevaluating audio representations: linear fine-tuning and unparameterized\nevaluation. The framework includes 22 distinct tasks that cover essential\naspects of audio processing, from speech recognition and emotion detection to\nsound event classification and music genre identification. Our extensive\nevaluation of state-of-the-art audio encoders reveals significant performance\nvariations across different tasks and domains, highlighting the complexity of\ngeneral audio representation learning.", "AI": {"tldr": "X-ARES is a new open-source benchmark for evaluating audio encoders across diverse domains using two approaches: linear fine-tuning and unparameterized evaluation.", "motivation": "To systematically assess audio encoder performance across various domains like speech, environmental sounds, and music.", "method": "The framework includes 22 tasks covering audio processing aspects, evaluated via linear fine-tuning and unparameterized methods.", "result": "Evaluation shows significant performance variations across tasks and domains, indicating the complexity of general audio representation learning.", "conclusion": "X-ARES effectively benchmarks audio encoders, revealing domain-specific challenges in audio representation learning."}}
{"id": "2505.16000", "pdf": "https://arxiv.org/pdf/2505.16000", "abs": "https://arxiv.org/abs/2505.16000", "authors": ["Mehrdad ghassabi", "Pedram Rostami", "Hamidreza Baradaran Kashani", "Amirhossein Poursina", "Zahra Kazemi", "Milad Tavakoli"], "title": "Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 4 figures", "summary": "The rapid advancement of language models has demonstrated the potential of\nartificial intelligence in the healthcare industry. However, small language\nmodels struggle with specialized domains in low-resource languages like\nPersian. While numerous medical-domain websites exist in Persian, no curated\ndataset or corpus has been available making ours the first of its kind. This\nstudy explores the enhancement of medical knowledge in a small language model\nby leveraging accessible online data, including a crawled corpus from medical\nmagazines and a dataset of real doctor-patient QA pairs. We fine-tuned a\nbaseline model using our curated data to improve its medical knowledge.\nBenchmark evaluations demonstrate that the fine-tuned model achieves improved\naccuracy in medical question answering and provides better responses compared\nto its baseline. This work highlights the potential of leveraging open-access\nonline data to enrich small language models in medical fields, providing a\nnovel solution for Persian medical AI applications suitable for\nresource-constrained environments.", "AI": {"tldr": "A study enhances a small language model's medical knowledge for Persian by using crawled online data and fine-tuning, showing improved accuracy in medical QA.", "motivation": "Address the lack of curated medical datasets in Persian and improve small language models' performance in specialized, low-resource domains.", "method": "Curated a Persian medical corpus from online sources, fine-tuned a baseline model, and evaluated its performance.", "result": "The fine-tuned model achieved higher accuracy in medical question answering and better responses than the baseline.", "conclusion": "Leveraging open-access online data can enrich small language models in medical fields, offering a practical solution for Persian AI applications."}}
{"id": "2505.16387", "pdf": "https://arxiv.org/pdf/2505.16387", "abs": "https://arxiv.org/abs/2505.16387", "authors": ["Ming Cheng", "Fei Su", "Cancan Li", "Juan Liu", "Ming Li"], "title": "Multi-Channel Sequence-to-Sequence Neural Diarization: Experimental Results for The MISP 2025 Challenge", "categories": ["eess.AS"], "comment": "Accepted by Interspeech2025", "summary": "This paper describes the speaker diarization system developed for the\nMultimodal Information-Based Speech Processing (MISP) 2025 Challenge. First, we\nutilize the Sequence-to-Sequence Neural Diarization (S2SND) framework to\ngenerate initial predictions using single-channel audio. Then, we extend the\noriginal S2SND framework to create a new version, Multi-Channel\nSequence-to-Sequence Neural Diarization (MC-S2SND), which refines the initial\nresults using multi-channel audio. The final system achieves a diarization\nerror rate (DER) of 8.09% on the evaluation set of the competition database,\nranking first place in the speaker diarization task of the MISP 2025 Challenge.", "AI": {"tldr": "The paper presents a speaker diarization system for the MISP 2025 Challenge, using S2SND and its multi-channel extension (MC-S2SND), achieving top performance with an 8.09% DER.", "motivation": "To develop an advanced speaker diarization system for the MISP 2025 Challenge, improving accuracy through multi-channel audio processing.", "method": "Extends the S2SND framework to MC-S2SND, refining initial single-channel predictions with multi-channel audio.", "result": "Achieves a DER of 8.09%, ranking first in the challenge.", "conclusion": "The MC-S2SND system effectively improves speaker diarization accuracy, demonstrating its superiority in the MISP 2025 Challenge."}}
{"id": "2505.16756", "pdf": "https://arxiv.org/pdf/2505.16756", "abs": "https://arxiv.org/abs/2505.16756", "authors": ["Hailong Ning", "Siying Wang", "Tao Lei", "Xiaopeng Cao", "Huanmin Dou", "Bin Zhao", "Asoke K. Nandi", "Petia Radeva"], "title": "Representation Discrepancy Bridging Method for Remote Sensing Image-Text Retrieval", "categories": ["cs.CV", "cs.IR", "cs.MM"], "comment": null, "summary": "Remote Sensing Image-Text Retrieval (RSITR) plays a critical role in\ngeographic information interpretation, disaster monitoring, and urban planning\nby establishing semantic associations between image and textual descriptions.\nExisting Parameter-Efficient Fine-Tuning (PEFT) methods for Vision-and-Language\nPre-training (VLP) models typically adopt symmetric adapter structures for\nexploring cross-modal correlations. However, the strong discriminative nature\nof text modality may dominate the optimization process and inhibits image\nrepresentation learning. The nonnegligible imbalanced cross-modal optimization\nremains a bottleneck to enhancing the model performance. To address this issue,\nthis study proposes a Representation Discrepancy Bridging (RDB) method for the\nRSITR task. On the one hand, a Cross-Modal Asymmetric Adapter (CMAA) is\ndesigned to enable modality-specific optimization and improve feature\nalignment. The CMAA comprises a Visual Enhancement Adapter (VEA) and a Text\nSemantic Adapter (TSA). VEA mines fine-grained image features by Differential\nAttention (DA) mechanism, while TSA identifies key textual semantics through\nHierarchical Attention (HA) mechanism. On the other hand, this study extends\nthe traditional single-task retrieval framework to a dual-task optimization\nframework and develops a Dual-Task Consistency Loss (DTCL). The DTCL improves\ncross-modal alignment robustness through an adaptive weighted combination of\ncross-modal, classification, and exponential moving average consistency\nconstraints. Experiments on RSICD and RSITMD datasets show that the proposed\nRDB method achieves a 6%-11% improvement in mR metrics compared to\nstate-of-the-art PEFT methods and a 1.15%-2% improvement over the full\nfine-tuned GeoRSCLIP model.", "AI": {"tldr": "The paper proposes a Representation Discrepancy Bridging (RDB) method to address imbalanced cross-modal optimization in RSITR, achieving significant performance improvements.", "motivation": "Existing PEFT methods for VLP models suffer from text modality dominance, hindering image representation learning and cross-modal alignment.", "method": "RDB introduces a Cross-Modal Asymmetric Adapter (CMAA) with Visual Enhancement Adapter (VEA) and Text Semantic Adapter (TSA), and a Dual-Task Consistency Loss (DTCL) for robust alignment.", "result": "RDB improves mR metrics by 6%-11% over PEFT methods and 1.15%-2% over GeoRSCLIP on RSICD and RSITMD datasets.", "conclusion": "The RDB method effectively bridges cross-modal representation discrepancies, enhancing RSITR performance."}}
{"id": "2505.16152", "pdf": "https://arxiv.org/pdf/2505.16152", "abs": "https://arxiv.org/abs/2505.16152", "authors": ["Bolin Chen", "Shanzhi Yin", "Hanwei Zhu", "Lingyu Zhu", "Zihan Zhang", "Jie Chen", "Ru-Ling Liao", "Shiqi Wang", "Yan Ye"], "title": "Compressing Human Body Video with Interactive Semantics: A Generative Approach", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In this paper, we propose to compress human body video with interactive\nsemantics, which can facilitate video coding to be interactive and controllable\nby manipulating semantic-level representations embedded in the coded bitstream.\nIn particular, the proposed encoder employs a 3D human model to disentangle\nnonlinear dynamics and complex motion of human body signal into a series of\nconfigurable embeddings, which are controllably edited, compactly compressed,\nand efficiently transmitted. Moreover, the proposed decoder can evolve the\nmesh-based motion fields from these decoded semantics to realize the\nhigh-quality human body video reconstruction. Experimental results illustrate\nthat the proposed framework can achieve promising compression performance for\nhuman body videos at ultra-low bitrate ranges compared with the\nstate-of-the-art video coding standard Versatile Video Coding (VVC) and the\nlatest generative compression schemes. Furthermore, the proposed framework\nenables interactive human body video coding without any additional\npre-/post-manipulation processes, which is expected to shed light on\nmetaverse-related digital human communication in the future.", "AI": {"tldr": "Proposes a method to compress human body videos with interactive semantics, enabling controllable editing and efficient transmission, outperforming VVC and generative schemes.", "motivation": "To enhance video coding by making it interactive and controllable through semantic-level representations, particularly for human body videos, aiming to improve digital human communication in the metaverse.", "method": "Uses a 3D human model to disentangle complex motion into configurable embeddings, which are edited, compressed, and transmitted. The decoder reconstructs high-quality video from these semantics.", "result": "Achieves better compression performance at ultra-low bitrates compared to VVC and generative schemes, while enabling interactive coding without extra processes.", "conclusion": "The framework advances human body video compression and interaction, with potential applications in metaverse communication."}}
{"id": "2505.16080", "pdf": "https://arxiv.org/pdf/2505.16080", "abs": "https://arxiv.org/abs/2505.16080", "authors": ["Jiayue Liu", "Zhongchao Yi", "Zhengyang Zhou", "Qihe Huang", "Kuo Yang", "Xu Wang", "Yang Wang"], "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation", "categories": ["cs.AI"], "comment": "16 pages, 7 figures", "summary": "Discovering regularities from spatiotemporal systems can benefit various\nscientific and social planning. Current spatiotemporal learners usually train\nan independent model from a specific source data that leads to limited\ntransferability among sources, where even correlated tasks requires new design\nand training. The key towards increasing cross-domain knowledge is to enable\ncollective intelligence and model evolution. In this paper, inspired by\nneuroscience theories, we theoretically derive the increased information\nboundary via learning cross-domain collective intelligence and propose a\nSynaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the\nmodel independence and enables cross-domain knowledge to be shared and\naggregated. Specifically, we first re-order the sample groups to imitate the\nhuman curriculum learning, and devise two complementary learners, elastic\ncommon container and task-independent extractor to allow model growth and\ntask-wise commonality and personality disentanglement. Then an adaptive dynamic\ncoupler with a new difference metric determines whether the new sample group\nshould be incorporated into common container to achieve model evolution under\nvarious domains. Experiments show that SynEVO improves the generalization\ncapacity by at most 42% under cross-domain scenarios and SynEVO provides a\nparadigm of NeuroAI for knowledge transfer and adaptation.", "AI": {"tldr": "SynEVO is a spatiotemporal network that enhances cross-domain knowledge transfer by enabling collective intelligence and model evolution, improving generalization by up to 42%.", "motivation": "Current spatiotemporal learners lack transferability across domains, requiring new designs for correlated tasks. SynEVO aims to address this by leveraging collective intelligence inspired by neuroscience.", "method": "SynEVO reorders sample groups for curriculum learning, uses elastic common containers and task-independent extractors for model growth, and employs an adaptive dynamic coupler for domain adaptation.", "result": "SynEVO improves generalization by up to 42% in cross-domain scenarios, demonstrating effective knowledge transfer.", "conclusion": "SynEVO offers a NeuroAI paradigm for spatiotemporal knowledge transfer and adaptation, breaking model independence barriers."}}
{"id": "2505.16017", "pdf": "https://arxiv.org/pdf/2505.16017", "abs": "https://arxiv.org/abs/2505.16017", "authors": ["Mariia Seleznova", "Hung-Hsu Chou", "Claudio Mayrink Verdun", "Gitta Kutyniok"], "title": "GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We introduce GradPCA, an Out-of-Distribution (OOD) detection method that\nexploits the low-rank structure of neural network gradients induced by Neural\nTangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis\n(PCA) to gradient class-means, achieving more consistent performance than\nexisting methods across standard image classification benchmarks. We provide a\ntheoretical perspective on spectral OOD detection in neural networks to support\nGradPCA, highlighting feature-space properties that enable effective detection\nand naturally emerge from NTK alignment. Our analysis further reveals that\nfeature quality -- particularly the use of pretrained versus non-pretrained\nrepresentations -- plays a crucial role in determining which detectors will\nsucceed. Extensive experiments validate the strong performance of GradPCA, and\nour theoretical framework offers guidance for designing more principled\nspectral OOD detectors.", "AI": {"tldr": "GradPCA is a new OOD detection method using PCA on neural network gradients, outperforming existing methods with theoretical support from NTK alignment.", "motivation": "To improve OOD detection by leveraging the low-rank structure of gradients and NTK alignment in neural networks.", "method": "Applies PCA to gradient class-means and analyzes spectral properties for OOD detection.", "result": "GradPCA shows consistent performance across benchmarks, with feature quality (pretrained vs. non-pretrained) being critical.", "conclusion": "GradPCA is effective, and the theoretical framework aids in designing better spectral OOD detectors."}}
{"id": "2505.15879", "pdf": "https://arxiv.org/pdf/2505.15879", "abs": "https://arxiv.org/abs/2505.15879", "authors": ["Yue Fan", "Xuehai He", "Diji Yang", "Kaizhi Zheng", "Ching-Chen Kuo", "Yuting Zheng", "Sravana Jyothi Narayanaraju", "Xinze Guan", "Xin Eric Wang"], "title": "GRIT: Teaching MLLMs to Think with Images", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent studies have demonstrated the efficacy of using Reinforcement Learning\n(RL) in building reasoning models that articulate chains of thoughts prior to\nproducing final answers. However, despite ongoing advances that aim at enabling\nreasoning for vision-language tasks, existing open-source visual reasoning\nmodels typically generate reasoning content with pure natural language, lacking\nexplicit integration of visual information. This limits their ability to\nproduce clearly articulated and visually grounded reasoning chains. To this\nend, we propose Grounded Reasoning with Images and Texts (GRIT), a novel method\nfor training MLLMs to think with images. GRIT introduces a grounded reasoning\nparadigm, in which models generate reasoning chains that interleave natural\nlanguage and explicit bounding box coordinates. These coordinates point to\nregions of the input image that the model consults during its reasoning\nprocess. Additionally, GRIT is equipped with a reinforcement learning approach,\nGRPO-GR, built upon the GRPO algorithm. GRPO-GR employs robust rewards focused\non the final answer accuracy and format of the grounded reasoning output, which\neliminates the need for data with reasoning chain annotations or explicit\nbounding box labels. As a result, GRIT achieves exceptional data efficiency,\nrequiring as few as 20 image-question-answer triplets from existing datasets.\nComprehensive evaluations demonstrate that GRIT effectively trains MLLMs to\nproduce coherent and visually grounded reasoning chains, showing a successful\nunification of reasoning and grounding abilities.", "AI": {"tldr": "GRIT introduces a method for training multimodal language models (MLLMs) to generate visually grounded reasoning chains using bounding box coordinates and natural language, enhanced by a reinforcement learning approach (GRPO-GR).", "motivation": "Existing visual reasoning models lack explicit integration of visual information, limiting their ability to produce visually grounded reasoning chains.", "method": "GRIT combines natural language reasoning with bounding box coordinates for visual grounding and uses GRPO-GR, a reinforcement learning approach, to train models without needing annotated reasoning chains or bounding box labels.", "result": "GRIT achieves high data efficiency, requiring only 20 image-question-answer triplets, and produces coherent, visually grounded reasoning chains.", "conclusion": "GRIT successfully unifies reasoning and grounding abilities in MLLMs, demonstrating effective visually grounded reasoning."}}
{"id": "2502.20073", "pdf": "https://arxiv.org/pdf/2502.20073", "abs": "https://arxiv.org/abs/2502.20073", "authors": ["Haochen Sun", "Shuwen Zhang", "Lujie Niu", "Lei Ren", "Hao Xu", "Hao Fu", "Fangkun Zhao", "Caixia Yuan", "Xiaojie Wang"], "title": "Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": "30 pages, 17 figures", "summary": "Large language models (LLMs) based agent systems have made great strides in\nreal-world applications beyond traditional NLP tasks. This paper proposes a new\nLLM-powered Multi-Agent System (LLM-MAS) benchmark, Collab-Overcooked, built on\nthe popular Overcooked-AI game with more applicable and challenging tasks in\ninteractive environments. Collab-Overcooked extends existing benchmarks from\ntwo novel perspectives. First, it provides a multi-agent framework supporting\ndiverse tasks and objectives and encourages collaboration through natural\nlanguage communication. Second, it introduces a spectrum of process-oriented\nevaluation metrics to assess the fine-grained collaboration capabilities of\ndifferent LLM agents, a dimension often overlooked in prior work. We conduct\nextensive experiments over 11 popular LLMs and show that, while the LLMs\npresent a strong ability in goal interpretation, there is a significant\ndiscrepancy in active collaboration and continuous adaptation which are\ncritical for efficiently fulfilling complicated tasks. Notably, we highlight\nthe strengths and weaknesses in LLM-MAS and provide insights for improving and\nevaluating LLM-MAS on a unified and open-sourced benchmark. The environments,\n30 open-ended tasks, and the evaluation package are publicly available at\nhttps://github.com/YusaeMeow/Collab-Overcooked.", "AI": {"tldr": "The paper introduces Collab-Overcooked, a new benchmark for LLM-powered Multi-Agent Systems (LLM-MAS), built on Overcooked-AI. It extends existing benchmarks with multi-agent collaboration tasks and process-oriented evaluation metrics, revealing gaps in LLM collaboration capabilities.", "motivation": "To address the lack of benchmarks for evaluating fine-grained collaboration in LLM-MAS, the paper proposes Collab-Overcooked to assess LLM agents' abilities in interactive environments.", "method": "The benchmark is built on Overcooked-AI, featuring 30 open-ended tasks and natural language communication. It introduces process-oriented metrics to evaluate collaboration.", "result": "Experiments with 11 LLMs show strong goal interpretation but weaknesses in active collaboration and adaptation.", "conclusion": "The paper highlights LLM-MAS strengths and weaknesses, offering insights for improvement and evaluation on a unified, open-sourced benchmark."}}
{"id": "2505.16691", "pdf": "https://arxiv.org/pdf/2505.16691", "abs": "https://arxiv.org/abs/2505.16691", "authors": ["Advait Joglekar", "Divyanshu Singh", "Rooshil Rohit Bhatia", "S. Umesh"], "title": "EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Submitted to EMNLP 2025, 7 pages, 2 figures, 5 Tables", "summary": "Voice Conversion research in recent times has increasingly focused on\nimproving the zero-shot capabilities of existing methods. Despite remarkable\nadvancements, current architectures still tend to struggle in zero-shot\ncross-lingual settings. They are also often unable to generalize for speakers\nof unseen languages and accents. In this paper, we adopt a simple yet effective\napproach that combines discrete speech representations from self-supervised\nmodels with a non-autoregressive Diffusion-Transformer based conditional flow\nmatching speech decoder. We show that this architecture allows us to train a\nvoice-conversion model in a purely textless, self-supervised fashion. Our\ntechnique works without requiring multiple encoders to disentangle speech\nfeatures. Our model also manages to excel in zero-shot cross-lingual settings\neven for unseen languages.", "AI": {"tldr": "A novel voice conversion method combines discrete speech representations with a Diffusion-Transformer decoder, excelling in zero-shot cross-lingual settings without multiple encoders.", "motivation": "Current voice conversion methods struggle with zero-shot cross-lingual generalization for unseen languages and accents.", "method": "Combines discrete speech representations from self-supervised models with a non-autoregressive Diffusion-Transformer decoder, trained textlessly.", "result": "The model performs well in zero-shot cross-lingual settings, even for unseen languages.", "conclusion": "The proposed approach is simple, effective, and generalizes well for zero-shot voice conversion across languages."}}
{"id": "2505.16002", "pdf": "https://arxiv.org/pdf/2505.16002", "abs": "https://arxiv.org/abs/2505.16002", "authors": ["Sasha Boguraev", "Christopher Potts", "Kyle Mahowald"], "title": "Causal Interventions Reveal Shared Structure Across English Filler-Gap Constructions", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, 19 figures, 11 tables", "summary": "Large Language Models (LLMs) have emerged as powerful sources of evidence for\nlinguists seeking to develop theories of syntax. In this paper, we argue that\ncausal interpretability methods, applied to LLMs, can greatly enhance the value\nof such evidence by helping us characterize the abstract mechanisms that LLMs\nlearn to use. Our empirical focus is a set of English filler-gap dependency\nconstructions (e.g., questions, relative clauses). Linguistic theories largely\nagree that these constructions share many properties. Using experiments based\nin Distributed Interchange Interventions, we show that LLMs converge on similar\nabstract analyses of these constructions. These analyses also reveal previously\noverlooked factors -- relating to frequency, filler type, and surrounding\ncontext -- that could motivate changes to standard linguistic theory. Overall,\nthese results suggest that mechanistic, internal analyses of LLMs can push\nlinguistic theory forward.", "AI": {"tldr": "LLMs aid linguistic syntax theories; causal interpretability reveals abstract mechanisms. Focus on English filler-gap dependencies shows LLMs converge on similar analyses, uncovering overlooked factors for theory refinement.", "motivation": "Enhance linguistic theory by using LLMs as evidence sources, applying causal interpretability to uncover abstract mechanisms.", "method": "Distributed Interchange Interventions to analyze English filler-gap dependencies in LLMs.", "result": "LLMs converge on similar abstract analyses, revealing overlooked factors (frequency, filler type, context) impacting linguistic theory.", "conclusion": "Mechanistic analyses of LLMs can advance linguistic theory by refining understanding of syntax mechanisms."}}
{"id": "2505.16404", "pdf": "https://arxiv.org/pdf/2505.16404", "abs": "https://arxiv.org/abs/2505.16404", "authors": ["Kishan Gupta", "Srikanth Korse", "Andreas Brendel", "Nicola Pia", "Guillaume Fuchs"], "title": "UBGAN: Enhancing Coded Speech with Blind and Guided Bandwidth Extension", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "In practical application of speech codecs, a multitude of factors such as the\nquality of the radio connection, limiting hardware or required user experience\nnecessitate trade-offs between achievable perceptual quality, engendered\nbitrate and computational complexity. Most conventional and neural speech\ncodecs operate on wideband (WB) speech signals to achieve this compromise. To\nfurther enhance the perceptual quality of coded speech, bandwidth extension\n(BWE) of the transmitted speech is an attractive and popular technique in\nconventional speech coding. In contrast, neural speech codecs are typically\ntrained end-to-end to a specific set of requirements and are often not easily\nadaptable. In particular, they are typically trained to operate at a single\nfixed sampling rate. With the Universal Bandwidth Extension Generative\nAdversarial Network (UBGAN), we propose a modular and lightweight GAN-based\nsolution that increases the operational flexibility of a wide range of\nconventional and neural codecs. Our model operates in the subband domain and\nextends the bandwidth of WB signals from 8 kHz to 16 kHz, resulting in\nsuper-wideband (SWB) signals. We further introduce two variants, guided-UBGAN\nand blind-UBGAN, where the guided version transmits quantized learned\nrepresentation as a side information at a very low bitrate additional to the\nbitrate of the codec, while blind-BWE operates without such side-information.\nOur subjective assessments demonstrate the advantage of UBGAN applied to WB\ncodecs and highlight the generalization capacity of our proposed method across\nmultiple codecs and bitrates.", "AI": {"tldr": "UBGAN is a modular GAN-based solution for bandwidth extension in speech codecs, enhancing WB to SWB signals with variants for guided and blind operation.", "motivation": "To improve the perceptual quality of coded speech by extending bandwidth without requiring end-to-end retraining of neural codecs.", "method": "Proposes UBGAN, a lightweight GAN operating in the subband domain, with guided and blind variants for flexibility.", "result": "UBGAN successfully extends WB signals to SWB, demonstrating generalization across codecs and bitrates.", "conclusion": "UBGAN enhances operational flexibility and perceptual quality for both conventional and neural speech codecs."}}
{"id": "2505.16809", "pdf": "https://arxiv.org/pdf/2505.16809", "abs": "https://arxiv.org/abs/2505.16809", "authors": ["Junze Wang", "Lei Fan", "Weipeng Jing", "Donglin Di", "Yang Song", "Sidong Liu", "Cong Cong"], "title": "Hypergraph Tversky-Aware Domain Incremental Learning for Brain Tumor Segmentation with Missing Modalities", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Existing methods for multimodal MRI segmentation with missing modalities\ntypically assume that all MRI modalities are available during training.\nHowever, in clinical practice, some modalities may be missing due to the\nsequential nature of MRI acquisition, leading to performance degradation.\nFurthermore, retraining models to accommodate newly available modalities can be\ninefficient and may cause overfitting, potentially compromising previously\nlearned knowledge. To address these challenges, we propose Replay-based\nHypergraph Domain Incremental Learning (ReHyDIL) for brain tumor segmentation\nwith missing modalities. ReHyDIL leverages Domain Incremental Learning (DIL) to\nenable the segmentation model to learn from newly acquired MRI modalities\nwithout forgetting previously learned information. To enhance segmentation\nperformance across diverse patient scenarios, we introduce the Cross-Patient\nHypergraph Segmentation Network (CHSNet), which utilizes hypergraphs to capture\nhigh-order associations between patients. Additionally, we incorporate\nTversky-Aware Contrastive (TAC) loss to effectively mitigate information\nimbalance both across and within different modalities. Extensive experiments on\nthe BraTS2019 dataset demonstrate that ReHyDIL outperforms state-of-the-art\nmethods, achieving an improvement of over 2\\% in the Dice Similarity\nCoefficient across various tumor regions. Our code is available at ReHyDIL.", "AI": {"tldr": "ReHyDIL improves brain tumor segmentation with missing MRI modalities using domain incremental learning and hypergraph networks, outperforming existing methods by 2% in Dice score.", "motivation": "Address performance degradation in MRI segmentation due to missing modalities and inefficiency in retraining models for new modalities.", "method": "Proposes ReHyDIL with Domain Incremental Learning (DIL), CHSNet for hypergraph-based associations, and TAC loss for information imbalance.", "result": "Achieves over 2% improvement in Dice Similarity Coefficient on BraTS2019 dataset.", "conclusion": "ReHyDIL effectively handles missing modalities and enhances segmentation performance without forgetting prior knowledge."}}
{"id": "2505.16177", "pdf": "https://arxiv.org/pdf/2505.16177", "abs": "https://arxiv.org/abs/2505.16177", "authors": ["Linfeng Qi", "Zhaoyang Jia", "Jiahao Li", "Bin Li", "Houqiang Li", "Yan Lu"], "title": "Generative Latent Coding for Ultra-Low Bitrate Image and Video Compression", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Most existing approaches for image and video compression perform transform\ncoding in the pixel space to reduce redundancy. However, due to the\nmisalignment between the pixel-space distortion and human perception, such\nschemes often face the difficulties in achieving both high-realism and\nhigh-fidelity at ultra-low bitrate. To solve this problem, we propose\n\\textbf{G}enerative \\textbf{L}atent \\textbf{C}oding (\\textbf{GLC}) models for\nimage and video compression, termed GLC-image and GLC-Video. The transform\ncoding of GLC is conducted in the latent space of a generative vector-quantized\nvariational auto-encoder (VQ-VAE). Compared to the pixel-space, such a latent\nspace offers greater sparsity, richer semantics and better alignment with human\nperception, and show its advantages in achieving high-realism and high-fidelity\ncompression. To further enhance performance, we improve the hyper prior by\nintroducing a spatial categorical hyper module in GLC-image and a\nspatio-temporal categorical hyper module in GLC-video. Additionally, the\ncode-prediction-based loss function is proposed to enhance the semantic\nconsistency. Experiments demonstrate that our scheme shows high visual quality\nat ultra-low bitrate for both image and video compression. For image\ncompression, GLC-image achieves an impressive bitrate of less than $0.04$ bpp,\nachieving the same FID as previous SOTA model MS-ILLM while using $45\\%$ fewer\nbitrate on the CLIC 2020 test set. For video compression, GLC-video achieves\n65.3\\% bitrate saving over PLVC in terms of DISTS.", "AI": {"tldr": "GLC models (GLC-image and GLC-video) use latent space coding for high-realism, high-fidelity compression at ultra-low bitrates, outperforming pixel-space methods.", "motivation": "Pixel-space distortion misaligns with human perception, making high-realism and high-fidelity compression at ultra-low bitrates challenging.", "method": "Transform coding in VQ-VAE latent space with improved hyper prior modules and code-prediction-based loss for semantic consistency.", "result": "GLC-image achieves <0.04 bpp with 45% fewer bits than MS-ILLM; GLC-video saves 65.3% bitrate over PLVC.", "conclusion": "GLC models excel in ultra-low bitrate compression by leveraging latent space advantages over pixel-space methods."}}
{"id": "2505.16086", "pdf": "https://arxiv.org/pdf/2505.16086", "abs": "https://arxiv.org/abs/2505.16086", "authors": ["Ming Shen", "Raphael Shu", "Anurag Pratik", "James Gung", "Yubin Ge", "Monica Sunkara", "Yi Zhang"], "title": "Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "We have seen remarkable progress in large language models (LLMs) empowered\nmulti-agent systems solving complex tasks necessitating cooperation among\nexperts with diverse skills. However, optimizing LLM-based multi-agent systems\nremains challenging. In this work, we perform an empirical case study on group\noptimization of role-based multi-agent systems utilizing natural language\nfeedback for challenging software development tasks under various evaluation\ndimensions. We propose a two-step agent prompts optimization pipeline:\nidentifying underperforming agents with their failure explanations utilizing\ntextual feedback and then optimizing system prompts of identified agents\nutilizing failure explanations. We then study the impact of various\noptimization settings on system performance with two comparison groups: online\nagainst offline optimization and individual against group optimization. For\ngroup optimization, we study two prompting strategies: one-pass and multi-pass\nprompting optimizations. Overall, we demonstrate the effectiveness of our\noptimization method for role-based multi-agent systems tackling software\ndevelopment tasks evaluated on diverse evaluation dimensions, and we\ninvestigate the impact of diverse optimization settings on group behaviors of\nthe multi-agent systems to provide practical insights for future development.", "AI": {"tldr": "The paper presents a two-step optimization pipeline for LLM-based multi-agent systems, using natural language feedback to improve performance in software development tasks. It compares online vs. offline and individual vs. group optimization, showing effectiveness and practical insights.", "motivation": "Optimizing LLM-based multi-agent systems for complex tasks like software development is challenging, necessitating empirical study and practical solutions.", "method": "A two-step pipeline: identifying underperforming agents via textual feedback and optimizing their prompts. Comparisons include online/offline and individual/group optimization, with one-pass and multi-pass prompting strategies.", "result": "The method effectively optimizes role-based multi-agent systems for software tasks, with varied impacts from different optimization settings.", "conclusion": "The study provides practical insights for future development of LLM-based multi-agent systems, demonstrating the effectiveness of prompt optimization."}}
{"id": "2505.16024", "pdf": "https://arxiv.org/pdf/2505.16024", "abs": "https://arxiv.org/abs/2505.16024", "authors": ["Weiguo Gao", "Ming Li"], "title": "Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging", "categories": ["cs.LG", "cs.AI"], "comment": "31 pages, 19 figures", "summary": "Diffusion trajectory distillation methods aim to accelerate sampling in\ndiffusion models, which produce high-quality outputs but suffer from slow\nsampling speeds. These methods train a student model to approximate the\nmulti-step denoising process of a pretrained teacher model in a single step,\nenabling one-shot generation. However, theoretical insights into the trade-off\nbetween different distillation strategies and generative quality remain\nlimited, complicating their optimization and selection. In this work, we take a\nfirst step toward addressing this gap. Specifically, we reinterpret trajectory\ndistillation as an operator merging problem in the linear regime, where each\nstep of the teacher model is represented as a linear operator acting on noisy\ndata. These operators admit a clear geometric interpretation as projections and\nrescalings corresponding to the noise schedule. During merging, signal\nshrinkage occurs as a convex combination of operators, arising from both\ndiscretization and limited optimization time of the student model. We propose a\ndynamic programming algorithm to compute the optimal merging strategy that\nmaximally preserves signal fidelity. Additionally, we demonstrate the existence\nof a sharp phase transition in the optimal strategy, governed by data\ncovariance structures. Our findings enhance the theoretical understanding of\ndiffusion trajectory distillation and offer practical insights for improving\ndistillation strategies.", "AI": {"tldr": "The paper explores diffusion trajectory distillation to speed up sampling in diffusion models by training a student model to mimic a teacher's multi-step denoising in one step. It frames distillation as an operator merging problem, proposes a dynamic programming solution for optimal merging, and identifies a phase transition in strategies based on data covariance.", "motivation": "Diffusion models produce high-quality outputs but suffer from slow sampling speeds. Existing distillation methods lack theoretical insights into trade-offs between strategies and generative quality, hindering optimization.", "method": "Reinterprets trajectory distillation as a linear operator merging problem, where each teacher step is a linear operator. Proposes a dynamic programming algorithm to compute the optimal merging strategy, considering signal shrinkage from discretization and limited optimization.", "result": "Identifies a sharp phase transition in optimal merging strategies, governed by data covariance structures. The dynamic programming approach maximizes signal fidelity.", "conclusion": "The work advances theoretical understanding of diffusion trajectory distillation and provides practical insights for optimizing distillation strategies."}}
{"id": "2505.15880", "pdf": "https://arxiv.org/pdf/2505.15880", "abs": "https://arxiv.org/abs/2505.15880", "authors": ["Zhiyuan Xu", "Bohan Li", "Huan-ang Gao", "Mingju Gao", "Yong Chen", "Ming Liu", "Chenxu Yan", "Hang Zhao", "Shuo Feng", "Hao Zhao"], "title": "Challenger: Affordable Adversarial Driving Video Generation", "categories": ["cs.CV"], "comment": "Project page: https://pixtella.github.io/Challenger/", "summary": "Generating photorealistic driving videos has seen significant progress\nrecently, but current methods largely focus on ordinary, non-adversarial\nscenarios. Meanwhile, efforts to generate adversarial driving scenarios often\noperate on abstract trajectory or BEV representations, falling short of\ndelivering realistic sensor data that can truly stress-test autonomous driving\n(AD) systems. In this work, we introduce Challenger, a framework that produces\nphysically plausible yet photorealistic adversarial driving videos. Generating\nsuch videos poses a fundamental challenge: it requires jointly optimizing over\nthe space of traffic interactions and high-fidelity sensor observations.\nChallenger makes this affordable through two techniques: (1) a physics-aware\nmulti-round trajectory refinement process that narrows down candidate\nadversarial maneuvers, and (2) a tailored trajectory scoring function that\nencourages realistic yet adversarial behavior while maintaining compatibility\nwith downstream video synthesis. As tested on the nuScenes dataset, Challenger\ngenerates a diverse range of aggressive driving scenarios-including cut-ins,\nsudden lane changes, tailgating, and blind spot intrusions-and renders them\ninto multiview photorealistic videos. Extensive evaluations show that these\nscenarios significantly increase the collision rate of state-of-the-art\nend-to-end AD models (UniAD, VAD, SparseDrive, and DiffusionDrive), and\nimportantly, adversarial behaviors discovered for one model often transfer to\nothers.", "AI": {"tldr": "Challenger is a framework for generating photorealistic adversarial driving videos to test autonomous driving systems, combining physics-aware trajectory refinement and realistic behavior scoring.", "motivation": "Current methods for adversarial driving scenarios lack realism and fail to stress-test autonomous driving systems effectively.", "method": "Uses physics-aware multi-round trajectory refinement and a tailored scoring function to generate realistic adversarial maneuvers, rendered into multiview videos.", "result": "Generates diverse aggressive scenarios (e.g., cut-ins, sudden lane changes) that increase collision rates in state-of-the-art AD models.", "conclusion": "Challenger effectively creates realistic adversarial scenarios, revealing vulnerabilities in AD models and demonstrating transferability of adversarial behaviors."}}
{"id": "2505.16607", "pdf": "https://arxiv.org/pdf/2505.16607", "abs": "https://arxiv.org/abs/2505.16607", "authors": ["Yuzhu Wang", "Archontis Politis", "Konstantinos Drossos", "Tuomas Virtanen"], "title": "Attractor-Based Speech Separation of Multiple Utterances by Unknown Number of Speakers", "categories": ["eess.AS", "cs.SD"], "comment": "5 pages, 4 figures, accepted by Interspeech 2025", "summary": "This paper addresses the problem of single-channel speech separation, where\nthe number of speakers is unknown, and each speaker may speak multiple\nutterances. We propose a speech separation model that simultaneously performs\nseparation, dynamically estimates the number of speakers, and detects\nindividual speaker activities by integrating an attractor module. The proposed\nsystem outperforms existing methods by introducing an attractor-based\narchitecture that effectively combines local and global temporal modeling for\nmulti-utterance scenarios. To evaluate the method in reverberant and noisy\nconditions, a multi-speaker multi-utterance dataset was synthesized by\ncombining Librispeech speech signals with WHAM! noise signals. The results\ndemonstrate that the proposed system accurately estimates the number of\nsources. The system effectively detects source activities and separates the\ncorresponding utterances into correct outputs in both known and unknown source\ncount scenarios.", "AI": {"tldr": "A speech separation model for unknown speaker counts with dynamic estimation and activity detection, outperforming existing methods in noisy and reverberant conditions.", "motivation": "Addressing the challenge of single-channel speech separation with unknown and variable speaker counts, including multi-utterance scenarios.", "method": "Proposes an attractor-based architecture combining local and global temporal modeling, evaluated on a synthesized multi-speaker multi-utterance dataset with noise.", "result": "Accurately estimates speaker counts, detects activities, and separates utterances correctly in known and unknown scenarios.", "conclusion": "The attractor-based system is effective for dynamic speech separation in complex acoustic environments."}}
{"id": "2505.16003", "pdf": "https://arxiv.org/pdf/2505.16003", "abs": "https://arxiv.org/abs/2505.16003", "authors": ["Roland Daynauth", "Christopher Clarke", "Krisztian Flautner", "Lingjia Tang", "Jason Mars"], "title": "SLMEval: Entropy-Based Calibration for Human-Aligned Evaluation of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The LLM-as-a-Judge paradigm offers a scalable, reference-free approach for\nevaluating language models. Although several calibration techniques have been\nproposed to better align these evaluators with human judgment, prior studies\nfocus primarily on narrow, well-structured benchmarks. As a result, it remains\nunclear whether such calibrations generalize to real-world, open-ended tasks.\n  In this work, we show that SOTA calibrated evaluators often fail in these\nsettings, exhibiting weak or even negative correlation with human judgments. To\naddress this, we propose SLMEval, a novel and efficient calibration method\nbased on entropy maximization over a small amount of human preference data. By\nestimating a latent distribution over model quality and reweighting evaluator\nscores accordingly, SLMEval achieves strong correlation with human evaluations\nacross two real-world production use cases and the public benchmark. For\nexample, on one such task, SLMEval achieves a Spearman correlation of 0.57 with\nhuman judgments, while G-Eval yields a negative correlation. In addition,\nSLMEval reduces evaluation costs by 5-30x compared to GPT-4-based calibrated\nevaluators such as G-eval.", "AI": {"tldr": "SLMEval, a new calibration method for LLM-as-a-Judge, improves correlation with human judgments in real-world tasks and reduces costs.", "motivation": "Prior calibration methods for LLM evaluators perform poorly in open-ended tasks, lacking generalization to real-world scenarios.", "method": "Proposes SLMEval, an entropy maximization-based calibration method using minimal human preference data to reweight evaluator scores.", "result": "SLMEval achieves strong correlation (e.g., 0.57 Spearman) with human judgments and reduces costs by 5-30x compared to GPT-4-based evaluators.", "conclusion": "SLMEval effectively addresses the limitations of prior methods, offering scalable and cost-efficient evaluation for real-world tasks."}}
{"id": "2505.16490", "pdf": "https://arxiv.org/pdf/2505.16490", "abs": "https://arxiv.org/abs/2505.16490", "authors": ["David Krongauz", "Hido Pinto", "Sarah Kohn", "Yanir Marmor", "Eran Segal"], "title": "HPP-Voice: A Large-Scale Evaluation of Speech Embeddings for Multi-Phenotypic Classification", "categories": ["eess.AS"], "comment": null, "summary": "Human speech contains paralinguistic cues that reflect a speaker's\nphysiological and neurological state, potentially enabling non-invasive\ndetection of various medical phenotypes. We introduce the Human Phenotype\nProject Voice corpus (HPP-Voice): a dataset of 7,188 recordings in which\nHebrew-speaking adults count for 30 seconds, with each speaker linked to up to\n15 potentially voice-related phenotypes spanning respiratory, sleep, mental\nhealth, metabolic, immune, and neurological conditions. We present a systematic\ncomparison of 14 modern speech embedding models, where modern speech embeddings\nfrom these 30-second counting tasks outperform MFCCs and demographics for\ndownstream health condition classifications. We found that embedding learned\nfrom a speaker identification model can predict objectively measured moderate\nto severe sleep apnea in males with an AUC of 0.64 $\\pm$ 0.03, while MFCC and\ndemographic features led to AUCs of 0.56 $\\pm$ 0.02 and 0.57 $\\pm$ 0.02,\nrespectively. Additionally, our results reveal gender-specific patterns in\nmodel effectiveness across different medical domains. For males, speaker\nidentification and diarization models consistently outperformed speech\nfoundation models for respiratory conditions (e.g., asthma: 0.61 $\\pm$ 0.03 vs.\n0.56 $\\pm$ 0.02) and sleep-related conditions (insomnia: 0.65 $\\pm$ 0.04 vs.\n0.59 $\\pm$ 0.05). For females, speaker diarization models performed best for\nsmoking status (0.61 $\\pm$ 0.02 vs 0.55 $\\pm$ 0.02), while Hebrew-specific\nmodels performed best (0.59 $\\pm$ 0.02 vs. 0.58 $\\pm$ 0.02) in classifying\nanxiety compared to speech foundation models. Our findings provide evidence\nthat a simple counting task can support large-scale, multi-phenotypic voice\nscreening and highlight which embedding families generalize best to specific\nconditions, insights that can guide future vocal biomarker research and\nclinical deployment.", "AI": {"tldr": "The paper introduces HPP-Voice, a dataset of Hebrew speech recordings linked to health phenotypes, and compares 14 speech embedding models for health condition classification, showing gender-specific effectiveness.", "motivation": "To explore non-invasive detection of medical phenotypes through paralinguistic speech cues and identify effective speech embedding models for health screening.", "method": "Analyzed 7,188 Hebrew speech recordings (30-second counting tasks) linked to 15 health phenotypes, comparing 14 speech embedding models (e.g., speaker identification, MFCCs) for classification performance.", "result": "Speaker identification models outperformed MFCCs and demographics for conditions like sleep apnea (AUC 0.64) and showed gender-specific effectiveness (e.g., better for males in respiratory/sleep conditions, females in smoking/anxiety).", "conclusion": "A simple counting task can enable large-scale health screening, with certain embedding models (e.g., speaker identification) being more effective for specific conditions, guiding future vocal biomarker research."}}
{"id": "2505.16976", "pdf": "https://arxiv.org/pdf/2505.16976", "abs": "https://arxiv.org/abs/2505.16976", "authors": ["Yurui Qian", "Qi Cai", "Yingwei Pan", "Ting Yao", "Tao Mei"], "title": "Creatively Upscaling Images with Global-Regional Priors", "categories": ["cs.CV", "cs.MM"], "comment": "International Journal of Computer Vision (IJCV) 2025", "summary": "Contemporary diffusion models show remarkable capability in text-to-image\ngeneration, while still being limited to restricted resolutions (e.g., 1,024 X\n1,024). Recent advances enable tuning-free higher-resolution image generation\nby recycling pre-trained diffusion models and extending them via regional\ndenoising or dilated sampling/convolutions. However, these models struggle to\nsimultaneously preserve global semantic structure and produce creative regional\ndetails in higher-resolution images. To address this, we present C-Upscale, a\nnew recipe of tuning-free image upscaling that pivots on global-regional priors\nderived from given global prompt and estimated regional prompts via Multimodal\nLLM. Technically, the low-frequency component of low-resolution image is\nrecognized as global structure prior to encourage global semantic consistency\nin high-resolution generation. Next, we perform regional attention control to\nscreen cross-attention between global prompt and each region during regional\ndenoising, leading to regional attention prior that alleviates object\nrepetition issue. The estimated regional prompts containing rich descriptive\ndetails further act as regional semantic prior to fuel the creativity of\nregional detail generation. Both quantitative and qualitative evaluations\ndemonstrate that our C-Upscale manages to generate ultra-high-resolution images\n(e.g., 4,096 X 4,096 and 8,192 X 8,192) with higher visual fidelity and more\ncreative regional details.", "AI": {"tldr": "C-Upscale is a tuning-free method for high-resolution image generation using global-regional priors from prompts, improving fidelity and detail.", "motivation": "Address limitations in current diffusion models for high-resolution images, balancing global structure and regional creativity.", "method": "Uses global-regional priors from prompts, regional attention control, and Multimodal LLM for detail-rich upscaling.", "result": "Generates ultra-high-resolution images (e.g., 4,096 X 4,096) with better fidelity and creative details.", "conclusion": "C-Upscale effectively enhances high-resolution image generation without tuning, outperforming existing methods."}}
{"id": "2505.16373", "pdf": "https://arxiv.org/pdf/2505.16373", "abs": "https://arxiv.org/abs/2505.16373", "authors": ["Ge Meng", "Zhongnan Cai", "Jingyan Tu", "Yingying Wang", "Chenxin Li", "Yue Huang", "Xinghao Ding"], "title": "PCMamba: Physics-Informed Cross-Modal State Space Model for Dual-Camera Compressive Hyperspectral Imaging", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Panchromatic (PAN) -assisted Dual-Camera Compressive Hyperspectral Imaging\n(DCCHI) is a key technology in snapshot hyperspectral imaging. Existing\nresearch primarily focuses on exploring spectral information from 2D\ncompressive measurements and spatial information from PAN images in an explicit\nmanner, leading to a bottleneck in HSI reconstruction. Various physical\nfactors, such as temperature, emissivity, and multiple reflections between\nobjects, play a critical role in the process of a sensor acquiring\nhyperspectral thermal signals. Inspired by this, we attempt to investigate the\ninterrelationships between physical properties to provide deeper theoretical\ninsights for HSI reconstruction. In this paper, we propose a Physics-Informed\nCross-Modal State Space Model Network (PCMamba) for DCCHI, which incorporates\nthe forward physical imaging process of HSI into the linear complexity of Mamba\nto facilitate lightweight and high-quality HSI reconstruction. Specifically, we\nanalyze the imaging process of hyperspectral thermal signals to enable the\nnetwork to disentangle the three key physical properties-temperature,\nemissivity, and texture. By fully exploiting the potential information embedded\nin 2D measurements and PAN images, the HSIs are reconstructed through a\nphysics-driven synthesis process. Furthermore, we design a Cross-Modal Scanning\nMamba Block (CSMB) that introduces inter-modal pixel-wise interaction with\npositional inductive bias by cross-scanning the backbone features and PAN\nfeatures. Extensive experiments conducted on both real and simulated datasets\ndemonstrate that our method significantly outperforms SOTA methods in both\nquantitative and qualitative metrics.", "AI": {"tldr": "The paper proposes PCMamba, a Physics-Informed Cross-Modal State Space Model Network, for high-quality hyperspectral imaging (HSI) reconstruction by integrating physical properties like temperature and emissivity into the model.", "motivation": "Existing methods for HSI reconstruction focus on spectral and spatial information separately, creating a bottleneck. The paper aims to leverage physical properties (temperature, emissivity, texture) to improve reconstruction.", "method": "PCMamba incorporates the physical imaging process into a Mamba-based model, disentangling key physical properties. It uses a Cross-Modal Scanning Mamba Block (CSMB) for inter-modal interaction.", "result": "Experiments show PCMamba outperforms state-of-the-art methods in both quantitative and qualitative metrics.", "conclusion": "PCMamba effectively integrates physical insights into HSI reconstruction, achieving superior performance."}}
{"id": "2505.16090", "pdf": "https://arxiv.org/pdf/2505.16090", "abs": "https://arxiv.org/abs/2505.16090", "authors": ["Dominick Kubica", "Dylan T. Gordon", "Nanami Emura", "Derleen Saini", "Charlie Goldenberg"], "title": "Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance", "categories": ["cs.AI", "cs.CL", "I.2.6; I.2.7"], "comment": "6 pages, 4 figures. Research conducted as part of a\n  Microsoft-sponsored Capstone Project at Santa Clara University", "summary": "As of 2025, Generative Artificial Intelligence (GenAI) has become a central\ntool for productivity across industries. Beyond text generation, GenAI now\nplays a critical role in coding, data analysis, and research workflows. As\nlarge language models (LLMs) continue to evolve, it is essential to assess the\nreliability and accuracy of their outputs, especially in specialized,\nhigh-stakes domains like finance. Most modern LLMs transform text into\nnumerical vectors, which are used in operations such as cosine similarity\nsearches to generate responses. However, this abstraction process can lead to\nmisinterpretation of emotional tone, particularly in nuanced financial\ncontexts. While LLMs generally excel at identifying sentiment in everyday\nlanguage, these models often struggle with the nuanced, strategically ambiguous\nlanguage found in earnings call transcripts. Financial disclosures frequently\nembed sentiment in hedged statements, forward-looking language, and\nindustry-specific jargon, making it difficult even for human analysts to\ninterpret consistently, let alone AI models. This paper presents findings from\nthe Santa Clara Microsoft Practicum Project, led by Professor Charlie\nGoldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's\nChatGPT, Google's Gemini, and traditional machine learning models for sentiment\nanalysis of financial text. Using Microsoft earnings call transcripts, the\nanalysis assesses how well LLM-derived sentiment correlates with market\nsentiment and stock movements and evaluates the accuracy of model outputs.\nPrompt engineering techniques are also examined to improve sentiment analysis\nresults. Visualizations of sentiment consistency are developed to evaluate\nalignment between tone and stock performance, with sentiment trends analyzed\nacross Microsoft's lines of business to determine which segments exert the\ngreatest influence.", "AI": {"tldr": "The paper evaluates the reliability of GenAI and LLMs in sentiment analysis for financial texts, focusing on earnings call transcripts, and compares performance across models like Microsoft's Copilot and OpenAI's ChatGPT.", "motivation": "Assess the accuracy of LLMs in high-stakes financial contexts, where nuanced language and sentiment are challenging to interpret.", "method": "Benchmarks LLMs and traditional models using Microsoft earnings call transcripts, analyzing sentiment correlation with market trends and stock movements. Examines prompt engineering for improved results.", "result": "LLMs struggle with nuanced financial language, but prompt engineering can enhance sentiment analysis accuracy. Visualizations show sentiment trends and their alignment with stock performance.", "conclusion": "While LLMs face challenges in financial sentiment analysis, targeted improvements like prompt engineering can bridge gaps, aiding better market insights."}}
{"id": "2505.16035", "pdf": "https://arxiv.org/pdf/2505.16035", "abs": "https://arxiv.org/abs/2505.16035", "authors": ["Alejandro Garc\u00eda-Castellanos", "David R. Wessels", "Nicky J. van den Berg", "Remco Duits", "Dani\u00ebl M. Pelt", "Erik J. Bekkers"], "title": "Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Equivariant Neural Eikonal Solvers, a novel framework that\nintegrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our\napproach employs a single neural field where a unified shared backbone is\nconditioned on signal-specific latent variables - represented as point clouds\nin a Lie group - to model diverse Eikonal solutions. The ENF integration\nensures equivariant mapping from these latent representations to the solution\nfield, delivering three key benefits: enhanced representation efficiency\nthrough weight-sharing, robust geometric grounding, and solution steerability.\nThis steerability allows transformations applied to the latent point cloud to\ninduce predictable, geometrically meaningful modifications in the resulting\nEikonal solution. By coupling these steerable representations with\nPhysics-Informed Neural Networks (PINNs), our framework accurately models\nEikonal travel-time solutions while generalizing to arbitrary Riemannian\nmanifolds with regular group actions. This includes homogeneous spaces such as\nEuclidean, position-orientation, spherical, and hyperbolic manifolds. We\nvalidate our approach through applications in seismic travel-time modeling of\n2D and 3D benchmark datasets. Experimental results demonstrate superior\nperformance, scalability, adaptability, and user controllability compared to\nexisting Neural Operator-based Eikonal solver methods.", "AI": {"tldr": "A novel framework combining Equivariant Neural Fields and Neural Eikonal Solvers for efficient, steerable, and geometrically grounded Eikonal solutions on Riemannian manifolds.", "motivation": "To enhance representation efficiency, geometric grounding, and solution steerability in Eikonal travel-time modeling.", "method": "Uses a single neural field with a shared backbone conditioned on latent point clouds in a Lie group, integrated with Physics-Informed Neural Networks.", "result": "Superior performance, scalability, and adaptability in seismic travel-time modeling on 2D/3D datasets.", "conclusion": "The framework generalizes well across Riemannian manifolds and outperforms existing Neural Operator-based methods."}}
{"id": "2505.15928", "pdf": "https://arxiv.org/pdf/2505.15928", "abs": "https://arxiv.org/abs/2505.15928", "authors": ["Tony Montes", "Fernando Lozano"], "title": "ViQAgent: Zero-Shot Video Question Answering via Agent with Open-Vocabulary Grounding Validation", "categories": ["cs.CV", "cs.CL", "I.4.8"], "comment": null, "summary": "Recent advancements in Video Question Answering (VideoQA) have introduced\nLLM-based agents, modular frameworks, and procedural solutions, yielding\npromising results. These systems use dynamic agents and memory-based mechanisms\nto break down complex tasks and refine answers. However, significant\nimprovements remain in tracking objects for grounding over time and\ndecision-making based on reasoning to better align object references with\nlanguage model outputs, as newer models get better at both tasks. This work\npresents an LLM-brained agent for zero-shot Video Question Answering (VideoQA)\nthat combines a Chain-of-Thought framework with grounding reasoning alongside\nYOLO-World to enhance object tracking and alignment. This approach establishes\na new state-of-the-art in VideoQA and Video Understanding, showing enhanced\nperformance on NExT-QA, iVQA, and ActivityNet-QA benchmarks. Our framework also\nenables cross-checking of grounding timeframes, improving accuracy and\nproviding valuable support for verification and increased output reliability\nacross multiple video domains. The code is available at\nhttps://github.com/t-montes/viqagent.", "AI": {"tldr": "A new LLM-brained agent for zero-shot VideoQA combines Chain-of-Thought reasoning with YOLO-World for better object tracking, achieving state-of-the-art results.", "motivation": "Improve object tracking and reasoning alignment in VideoQA to enhance accuracy and reliability.", "method": "Uses a Chain-of-Thought framework with grounding reasoning and YOLO-World for object tracking.", "result": "Achieves state-of-the-art performance on NExT-QA, iVQA, and ActivityNet-QA benchmarks.", "conclusion": "The framework improves grounding accuracy and output reliability, with potential for cross-domain applications."}}
{"id": "2505.16845", "pdf": "https://arxiv.org/pdf/2505.16845", "abs": "https://arxiv.org/abs/2505.16845", "authors": ["Hanglei Zhang", "Yiwei Guo", "Zhihan Li", "Xiang Hao", "Xie Chen", "Kai Yu"], "title": "Unlocking Temporal Flexibility: Neural Speech Codec with Variable Frame Rate", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "Accepted to Interspeech 2025", "summary": "Most neural speech codecs achieve bitrate adjustment through intra-frame\nmechanisms, such as codebook dropout, at a Constant Frame Rate (CFR). However,\nspeech segments inherently have time-varying information density (e.g., silent\nintervals versus voiced regions). This property makes CFR not optimal in terms\nof bitrate and token sequence length, hindering efficiency in real-time\napplications. In this work, we propose a Temporally Flexible Coding (TFC)\ntechnique, introducing variable frame rate (VFR) into neural speech codecs for\nthe first time. TFC enables seamlessly tunable average frame rates and\ndynamically allocates frame rates based on temporal entropy. Experimental\nresults show that a codec with TFC achieves optimal reconstruction quality with\nhigh flexibility, and maintains competitive performance even at lower frame\nrates. Our approach is promising for the integration with other efforts to\ndevelop low-frame-rate neural speech codecs for more efficient downstream\ntasks.", "AI": {"tldr": "Proposes Temporally Flexible Coding (TFC) for neural speech codecs, introducing variable frame rate (VFR) to optimize bitrate and efficiency.", "motivation": "Current neural speech codecs use Constant Frame Rate (CFR), which is inefficient for speech segments with varying information density.", "method": "Introduces TFC, enabling variable frame rate (VFR) based on temporal entropy for dynamic bitrate adjustment.", "result": "TFC achieves optimal reconstruction quality with high flexibility and maintains performance at lower frame rates.", "conclusion": "TFC is promising for low-frame-rate neural speech codecs, enhancing efficiency for downstream tasks."}}
{"id": "2505.16008", "pdf": "https://arxiv.org/pdf/2505.16008", "abs": "https://arxiv.org/abs/2505.16008", "authors": ["Wenrui Yu", "Yiyi Chen", "Johannes Bjerva", "Sokol Kosta", "Qiongxiu Li"], "title": "LAGO: Few-shot Crosslingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": null, "summary": "We propose LAGO - Language Similarity-Aware Graph Optimization - a novel\napproach for few-shot cross-lingual embedding inversion attacks, addressing\ncritical privacy vulnerabilities in multilingual NLP systems. Unlike prior work\nin embedding inversion attacks that treat languages independently, LAGO\nexplicitly models linguistic relationships through a graph-based constrained\ndistributed optimization framework. By integrating syntactic and lexical\nsimilarity as edge constraints, our method enables collaborative parameter\nlearning across related languages. Theoretically, we show this formulation\ngeneralizes prior approaches, such as ALGEN, which emerges as a special case\nwhen similarity constraints are relaxed. Our framework uniquely combines\nFrobenius-norm regularization with linear inequality or total variation\nconstraints, ensuring robust alignment of cross-lingual embedding spaces even\nwith extremely limited data (as few as 10 samples per language). Extensive\nexperiments across multiple languages and embedding models demonstrate that\nLAGO substantially improves the transferability of attacks with 10-20% increase\nin Rouge-L score over baselines. This work establishes language similarity as a\ncritical factor in inversion attack transferability, urging renewed focus on\nlanguage-aware privacy-preserving multilingual embeddings.", "AI": {"tldr": "LAGO is a graph-based method for few-shot cross-lingual embedding inversion attacks, leveraging language similarity to improve attack transferability.", "motivation": "Address privacy vulnerabilities in multilingual NLP systems by modeling linguistic relationships, unlike prior independent language treatments.", "method": "Uses a graph-based constrained optimization framework with syntactic and lexical similarity constraints, combining Frobenius-norm regularization and linear inequality/total variation constraints.", "result": "LAGO improves attack transferability by 10-20% in Rouge-L scores, outperforming baselines with as few as 10 samples per language.", "conclusion": "Language similarity is crucial for inversion attack transferability, highlighting the need for language-aware privacy-preserving multilingual embeddings."}}
{"id": "2505.16616", "pdf": "https://arxiv.org/pdf/2505.16616", "abs": "https://arxiv.org/abs/2505.16616", "authors": ["Javier Perez", "Dimme de Groot", "Jorge Martinez"], "title": "Performance of Objective Speech Quality Metrics on Languages Beyond Validation Data: A Study of Turkish and Korean", "categories": ["eess.AS"], "comment": null, "summary": "Objective speech quality measures are widely used to assess the performance\nof video conferencing platforms and telecommunication systems. They predict\nhuman-rated speech quality and are crucial for assessing the systems quality of\nexperience. Despite the widespread use, the quality measures are developed on a\nlimited set of languages. This can be problematic since the performance on\nunseen languages is consequently not guaranteed or even studied. Here we raise\nawareness to this issue by investigating the performance of two objective\nspeech quality measures (PESQ and ViSQOL) on Turkish and Korean. Using English\nas baseline, we show that Turkish samples have significantly higher ViSQOL\nscores and that for Turkish male speakers the correlation between PESQ and\nViSQOL is highest. These results highlight the need to explore biases across\nmetrics and to develop a labeled speech quality dataset with a variety of\nlanguages.", "AI": {"tldr": "The paper investigates biases in objective speech quality measures (PESQ and ViSQOL) for Turkish and Korean, revealing performance disparities compared to English and emphasizing the need for diverse language datasets.", "motivation": "To address the lack of research on how objective speech quality measures perform on non-English languages, focusing on Turkish and Korean.", "method": "Comparison of PESQ and ViSQOL scores for Turkish and Korean against English as a baseline, analyzing correlations and disparities.", "result": "Turkish samples scored higher on ViSQOL, and Turkish male speakers showed the highest correlation between PESQ and ViSQOL.", "conclusion": "The study highlights biases in speech quality metrics and calls for developing datasets with diverse languages to ensure fair assessment."}}
{"id": "2505.16977", "pdf": "https://arxiv.org/pdf/2505.16977", "abs": "https://arxiv.org/abs/2505.16977", "authors": ["Siqi Wan", "Jingwen Chen", "Yingwei Pan", "Ting Yao", "Tao Mei"], "title": "Incorporating Visual Correspondence into Diffusion Model for Virtual Try-On", "categories": ["cs.CV", "cs.MM"], "comment": "ICLR 2025. Code is publicly available at:\n  https://github.com/HiDream-ai/SPM-Diff", "summary": "Diffusion models have shown preliminary success in virtual try-on (VTON)\ntask. The typical dual-branch architecture comprises two UNets for implicit\ngarment deformation and synthesized image generation respectively, and has\nemerged as the recipe for VTON task. Nevertheless, the problem remains\nchallenging to preserve the shape and every detail of the given garment due to\nthe intrinsic stochasticity of diffusion model. To alleviate this issue, we\nnovelly propose to explicitly capitalize on visual correspondence as the prior\nto tame diffusion process instead of simply feeding the whole garment into UNet\nas the appearance reference. Specifically, we interpret the fine-grained\nappearance and texture details as a set of structured semantic points, and\nmatch the semantic points rooted in garment to the ones over target person\nthrough local flow warping. Such 2D points are then augmented into 3D-aware\ncues with depth/normal map of target person. The correspondence mimics the way\nof putting clothing on human body and the 3D-aware cues act as semantic point\nmatching to supervise diffusion model training. A point-focused diffusion loss\nis further devised to fully take the advantage of semantic point matching.\nExtensive experiments demonstrate strong garment detail preservation of our\napproach, evidenced by state-of-the-art VTON performances on both VITON-HD and\nDressCode datasets. Code is publicly available at:\nhttps://github.com/HiDream-ai/SPM-Diff.", "AI": {"tldr": "The paper proposes a novel method using visual correspondence and 3D-aware cues to improve garment detail preservation in virtual try-on tasks with diffusion models.", "motivation": "Existing dual-branch UNet architectures in diffusion models struggle to preserve garment details due to stochasticity.", "method": "Uses semantic point matching and local flow warping to align garment details, augmented with 3D-aware cues (depth/normal maps) for supervision.", "result": "Achieves state-of-the-art performance on VITON-HD and DressCode datasets, with strong detail preservation.", "conclusion": "The proposed approach effectively addresses garment detail loss in diffusion-based virtual try-on tasks."}}
{"id": "2505.16391", "pdf": "https://arxiv.org/pdf/2505.16391", "abs": "https://arxiv.org/abs/2505.16391", "authors": ["Chia-Hsiang Lin", "Jhao-Ting Lin", "Po-Ying Chiu", "Shih-Ping Chen", "Charles C. H. Lin"], "title": "Quantum-Driven Multihead Inland Waterbody Detection With Transformer-Encoded CYGNSS Delay-Doppler Map Data", "categories": ["eess.IV"], "comment": "18 pages, 10 figures, submitted to IEEE Transactions on Geoscience\n  and Remote Sensing", "summary": "Inland waterbody detection (IWD) is critical for water resources management\nand agricultural planning. However, the development of high-fidelity IWD\nmapping technology remains unresolved. We aim to propose a practical solution\nbased on the easily accessible data, i.e., the delay-Doppler map (DDM) provided\nby NASA's Cyclone Global Navigation Satellite System (CYGNSS), which\nfacilitates effective estimation of physical parameters on the Earth's surface\nwith high temporal resolution and wide spatial coverage. Specifically, as\nquantum deep network (QUEEN) has revealed its strong proficiency in addressing\nclassification-like tasks, we encode the DDM using a customized transformer,\nfollowed by feeding the transformer-encoded DDM (tDDM) into a highly entangled\nQUEEN to distinguish whether the tDDM corresponds to a hydrological region. In\nrecent literature, QUEEN has achieved outstanding performances in numerous\nchallenging remote sensing tasks (e.g., hyperspectral restoration, change\ndetection, and mixed noise removal, etc.), and its high effectiveness stems\nfrom the fundamentally different way it adopts to extract features (the\nso-called quantum unitary-computing features). The meticulously designed\nIWD-QUEEN retrieves high-precision river textures, such as those in Amazon\nRiver Basin in South America, demonstrating its superiority over traditional\nclassification methods and existing global hydrography maps. IWD-QUEEN,\ntogether with its parallel quantum multihead scheme, works in a near-real-time\nmanner (i.e., millisecond-level computing per DDM). To broaden accessibility\nfor users of traditional computers, we also provide the non-quantum counterpart\nof our method, called IWD-Transformer, thereby increasing the impact of this\nwork.", "AI": {"tldr": "The paper proposes a quantum deep network (QUEEN) for inland waterbody detection (IWD) using delay-Doppler maps (DDM) from CYGNSS, outperforming traditional methods with high precision and speed.", "motivation": "High-fidelity IWD mapping is essential for water resources and agricultural planning, but existing technologies are insufficient.", "method": "Uses a customized transformer to encode DDM data, then processes it with QUEEN for classification, leveraging quantum unitary-computing features.", "result": "IWD-QUEEN achieves high-precision detection, e.g., in the Amazon River Basin, and operates in near-real-time.", "conclusion": "The method, with its non-quantum counterpart IWD-Transformer, offers a practical, accessible solution for IWD."}}
{"id": "2505.16097", "pdf": "https://arxiv.org/pdf/2505.16097", "abs": "https://arxiv.org/abs/2505.16097", "authors": ["Zifeng Wang", "Qiao Jin", "Jiacheng Lin", "Junyi Gao", "Jathurshan Pradeepkumar", "Pengcheng Jiang", "Benjamin Danek", "Zhiyong Lu", "Jimeng Sun"], "title": "TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials", "categories": ["cs.AI"], "comment": null, "summary": "Developing artificial intelligence (AI) for vertical domains requires a solid\ndata foundation for both training and evaluation. In this work, we introduce\nTrialPanorama, a large-scale, structured database comprising 1,657,476 clinical\ntrial records aggregated from 15 global sources. The database captures key\naspects of trial design and execution, including trial setups, interventions,\nconditions, biomarkers, and outcomes, and links them to standard biomedical\nontologies such as DrugBank and MedDRA. This structured and ontology-grounded\ndesign enables TrialPanorama to serve as a unified, extensible resource for a\nwide range of clinical trial tasks, including trial planning, design, and\nsummarization. To demonstrate its utility, we derive a suite of benchmark tasks\ndirectly from the TrialPanorama database. The benchmark spans eight tasks\nacross two categories: three for systematic review (study search, study\nscreening, and evidence summarization) and five for trial design (arm design,\neligibility criteria, endpoint selection, sample size estimation, and trial\ncompletion assessment). The experiments using five state-of-the-art large\nlanguage models (LLMs) show that while general-purpose LLMs exhibit some\nzero-shot capability, their performance is still inadequate for high-stakes\nclinical trial workflows. We release TrialPanorama database and the benchmark\nto facilitate further research on AI for clinical trials.", "AI": {"tldr": "TrialPanorama is a large-scale, structured database of clinical trial records, linked to biomedical ontologies, serving as a resource for AI tasks in clinical trials. Benchmarks show general-purpose LLMs are insufficient for high-stakes workflows.", "motivation": "To provide a unified, extensible data foundation for AI in clinical trials, addressing gaps in training and evaluation.", "method": "Introduce TrialPanorama, a database of 1.6M trial records from 15 sources, linked to ontologies. Derive benchmark tasks for systematic review and trial design, testing five LLMs.", "result": "General-purpose LLMs show limited zero-shot capability, inadequate for clinical trial workflows.", "conclusion": "TrialPanorama and its benchmark are released to advance AI research in clinical trials, highlighting the need for domain-specific models."}}
{"id": "2505.16053", "pdf": "https://arxiv.org/pdf/2505.16053", "abs": "https://arxiv.org/abs/2505.16053", "authors": ["Jan T\u00f6nshoff", "Martin Grohe"], "title": "Learning from Algorithm Feedback: One-Shot SAT Solver Guidance with GNNs", "categories": ["cs.LG"], "comment": null, "summary": "Boolean Satisfiability (SAT) solvers are foundational to computer science,\nyet their performance typically hinges on hand-crafted heuristics. This work\nintroduces Reinforcement Learning from Algorithm Feedback (RLAF) as a paradigm\nfor learning to guide SAT solver branching heuristics with Graph Neural\nNetworks (GNNs). Central to our approach is a novel and generic mechanism for\ninjecting inferred variable weights and polarities into the branching\nheuristics of existing SAT solvers. In a single forward pass, a GNN assigns\nthese parameters to all variables. Casting this one-shot guidance as a\nreinforcement learning problem lets us train the GNN with off-the-shelf\npolicy-gradient methods, such as GRPO, directly using the solver's\ncomputational cost as the sole reward signal. Extensive evaluations demonstrate\nthat RLAF-trained policies significantly reduce the mean solve times of\ndifferent base solvers across diverse SAT problem distributions, achieving more\nthan a 2x speedup in some cases, while generalizing effectively to larger and\nharder problems after training. Notably, these policies consistently outperform\nexpert-supervised approaches based on learning handcrafted weighting\nheuristics, offering a promising path towards data-driven heuristic design in\ncombinatorial optimization.", "AI": {"tldr": "The paper introduces RLAF, a method using GNNs and reinforcement learning to improve SAT solver heuristics, achieving significant speedups and outperforming expert-supervised approaches.", "motivation": "SAT solvers rely on hand-crafted heuristics, which may not be optimal. The work aims to automate and improve heuristic design using machine learning.", "method": "Uses GNNs to infer variable weights and polarities in a single forward pass, trained via reinforcement learning (e.g., GRPO) using solver cost as the reward.", "result": "RLAF-trained policies reduce mean solve times by over 2x in some cases and generalize well to harder problems.", "conclusion": "RLAF offers a promising, data-driven approach to heuristic design in combinatorial optimization, outperforming traditional methods."}}
{"id": "2505.15952", "pdf": "https://arxiv.org/pdf/2505.15952", "abs": "https://arxiv.org/abs/2505.15952", "authors": ["Mohammad Reza Taesiri", "Abhijay Ghildyal", "Saman Zadtootaghaj", "Nabajeet Barman", "Cor-Paul Bezemer"], "title": "VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality Assurance", "categories": ["cs.CV", "cs.AI"], "comment": "Project website with code and data:\n  https://asgaardlab.github.io/videogameqa-bench/", "summary": "With video games now generating the highest revenues in the entertainment\nindustry, optimizing game development workflows has become essential for the\nsector's sustained growth. Recent advancements in Vision-Language Models (VLMs)\noffer considerable potential to automate and enhance various aspects of game\ndevelopment, particularly Quality Assurance (QA), which remains one of the\nindustry's most labor-intensive processes with limited automation options. To\naccurately evaluate the performance of VLMs in video game QA tasks and\ndetermine their effectiveness in handling real-world scenarios, there is a\nclear need for standardized benchmarks, as existing benchmarks are insufficient\nto address the specific requirements of this domain. To bridge this gap, we\nintroduce VideoGameQA-Bench, a comprehensive benchmark that covers a wide array\nof game QA activities, including visual unit testing, visual regression\ntesting, needle-in-a-haystack tasks, glitch detection, and bug report\ngeneration for both images and videos of various games. Code and data are\navailable at: https://asgaardlab.github.io/videogameqa-bench/", "AI": {"tldr": "The paper introduces VideoGameQA-Bench, a benchmark for evaluating Vision-Language Models (VLMs) in video game QA tasks, addressing the lack of standardized benchmarks in the domain.", "motivation": "The growing revenue of video games necessitates optimized workflows, especially in QA, which is labor-intensive. VLMs offer automation potential, but current benchmarks are inadequate for game-specific needs.", "method": "The authors propose VideoGameQA-Bench, a comprehensive benchmark covering various QA tasks like visual testing, glitch detection, and bug report generation for game images and videos.", "result": "The benchmark provides a standardized evaluation tool for VLMs in game QA, filling a gap in existing resources.", "conclusion": "VideoGameQA-Bench enables accurate assessment of VLMs in real-world game QA scenarios, supporting automation and efficiency in game development."}}
{"id": "2505.16972", "pdf": "https://arxiv.org/pdf/2505.16972", "abs": "https://arxiv.org/abs/2505.16972", "authors": ["Tianduo Wang", "Lu Xu", "Wei Lu", "Shanbo Cheng"], "title": "From Tens of Hours to Tens of Thousands: Scaling Back-Translation for Speech Recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Recent advances in Automatic Speech Recognition (ASR) have been largely\nfueled by massive speech corpora. However, extending coverage to diverse\nlanguages with limited resources remains a formidable challenge. This paper\nintroduces Speech Back-Translation, a scalable pipeline that improves\nmultilingual ASR models by converting large-scale text corpora into synthetic\nspeech via off-the-shelf text-to-speech (TTS) models. We demonstrate that just\ntens of hours of real transcribed speech can effectively train TTS models to\ngenerate synthetic speech at hundreds of times the original volume while\nmaintaining high quality. To evaluate synthetic speech quality, we develop an\nintelligibility-based assessment framework and establish clear thresholds for\nwhen synthetic data benefits ASR training. Using Speech Back-Translation, we\ngenerate more than 500,000 hours of synthetic speech in ten languages and\ncontinue pre-training Whisper-large-v3, achieving average transcription error\nreductions of over 30\\%. These results highlight the scalability and\neffectiveness of Speech Back-Translation for enhancing multilingual ASR\nsystems.", "AI": {"tldr": "Speech Back-Translation improves multilingual ASR by generating synthetic speech from text, reducing transcription errors by 30%.", "motivation": "Extending ASR to diverse languages with limited resources is challenging.", "method": "Uses TTS models to convert text corpora into synthetic speech, scaling data volume massively.", "result": "Generated 500,000+ hours of synthetic speech, reducing transcription errors by 30%.", "conclusion": "Speech Back-Translation is scalable and effective for multilingual ASR enhancement."}}
{"id": "2505.16014", "pdf": "https://arxiv.org/pdf/2505.16014", "abs": "https://arxiv.org/abs/2505.16014", "authors": ["Yash Saxena", "Anpur Padia", "Mandar S Chaudhary", "Kalpa Gunaratna", "Srinivasan Parthasarathy", "Manas Gaur"], "title": "Ranking Free RAG: Replacing Re-ranking with Selection in RAG for Sensitive Domains", "categories": ["cs.CL"], "comment": null, "summary": "Traditional Retrieval-Augmented Generation (RAG) pipelines rely on\nsimilarity-based retrieval and re-ranking, which depend on heuristics such as\ntop-k, and lack explainability, interpretability, and robustness against\nadversarial content. To address this gap, we propose a novel method METEORA\nthat replaces re-ranking in RAG with a rationale-driven selection approach.\nMETEORA operates in two stages. First, a general-purpose LLM is\npreference-tuned to generate rationales conditioned on the input query using\ndirect preference optimization. These rationales guide the evidence chunk\nselection engine, which selects relevant chunks in three stages: pairing\nindividual rationales with corresponding retrieved chunks for local relevance,\nglobal selection with elbow detection for adaptive cutoff, and context\nexpansion via neighboring chunks. This process eliminates the need for top-k\nheuristics. The rationales are also used for consistency check using a Verifier\nLLM to detect and filter poisoned or misleading content for safe generation.\nThe framework provides explainable and interpretable evidence flow by using\nrationales consistently across both selection and verification. Our evaluation\nacross six datasets spanning legal, financial, and academic research domains\nshows that METEORA improves generation accuracy by 33.34% while using\napproximately 50% fewer chunks than state-of-the-art re-ranking methods. In\nadversarial settings, METEORA significantly improves the F1 score from 0.10 to\n0.44 over the state-of-the-art perplexity-based defense baseline, demonstrating\nstrong resilience to poisoning attacks. Code available at:\nhttps://anonymous.4open.science/r/METEORA-DC46/README.md", "AI": {"tldr": "METEORA replaces traditional RAG re-ranking with a rationale-driven selection, improving accuracy and robustness while reducing chunk usage.", "motivation": "Address limitations of similarity-based RAG pipelines, such as lack of explainability and robustness against adversarial content.", "method": "Uses a two-stage approach: preference-tuned LLM generates rationales for chunk selection, followed by three-stage selection (local, global, context expansion) and verification.", "result": "Improves generation accuracy by 33.34%, uses 50% fewer chunks, and enhances F1 score from 0.10 to 0.44 in adversarial settings.", "conclusion": "METEORA offers explainable, robust, and efficient RAG with significant performance gains."}}
{"id": "2505.16735", "pdf": "https://arxiv.org/pdf/2505.16735", "abs": "https://arxiv.org/abs/2505.16735", "authors": ["Youngmoon Jung", "Yong-Hyeok Lee", "Myunghun Jung", "Jaeyoung Roh", "Chang Woo Han", "Hoon-Young Cho"], "title": "Adversarial Deep Metric Learning for Cross-Modal Audio-Text Alignment in Open-Vocabulary Keyword Spotting", "categories": ["eess.AS", "cs.AI"], "comment": "5 pages, 1 figures, Accepted at Interspeech 2025", "summary": "For text enrollment-based open-vocabulary keyword spotting (KWS), acoustic\nand text embeddings are typically compared at either the phoneme or utterance\nlevel. To facilitate this, we optimize acoustic and text encoders using deep\nmetric learning (DML), enabling direct comparison of multi-modal embeddings in\na shared embedding space. However, the inherent heterogeneity between audio and\ntext modalities presents a significant challenge. To address this, we propose\nModality Adversarial Learning (MAL), which reduces the domain gap in\nheterogeneous modality representations. Specifically, we train a modality\nclassifier adversarially to encourage both encoders to generate\nmodality-invariant embeddings. Additionally, we apply DML to achieve\nphoneme-level alignment between audio and text, and conduct comprehensive\ncomparisons across various DML objectives. Experiments on the Wall Street\nJournal (WSJ) and LibriPhrase datasets demonstrate the effectiveness of the\nproposed approach.", "AI": {"tldr": "The paper proposes Modality Adversarial Learning (MAL) to bridge the gap between audio and text embeddings for keyword spotting, enhancing performance through phoneme-level alignment and deep metric learning.", "motivation": "The challenge of comparing heterogeneous audio and text embeddings in open-vocabulary keyword spotting motivates the need for modality-invariant representations.", "method": "The approach combines deep metric learning (DML) for phoneme-level alignment and Modality Adversarial Learning (MAL) to reduce modality differences.", "result": "Experiments on WSJ and LibriPhrase datasets show the method's effectiveness in improving embedding comparison.", "conclusion": "MAL and DML together enhance multi-modal embedding alignment, addressing modality heterogeneity in keyword spotting."}}
{"id": "2505.16980", "pdf": "https://arxiv.org/pdf/2505.16980", "abs": "https://arxiv.org/abs/2505.16980", "authors": ["Dong Li", "Wenqi Zhong", "Wei Yu", "Yingwei Pan", "Dingwen Zhang", "Ting Yao", "Junwei Han", "Tao Mei"], "title": "Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction", "categories": ["cs.CV", "cs.MM"], "comment": "CVPR 2025", "summary": "Video virtual try-on aims to seamlessly dress a subject in a video with a\nspecific garment. The primary challenge involves preserving the visual\nauthenticity of the garment while dynamically adapting to the pose and physique\nof the subject. While existing methods have predominantly focused on\nimage-based virtual try-on, extending these techniques directly to videos often\nresults in temporal inconsistencies. Most current video virtual try-on\napproaches alleviate this challenge by incorporating temporal modules, yet\nstill overlook the critical spatiotemporal pose interactions between human and\ngarment. Effective pose interactions in videos should not only consider spatial\nalignment between human and garment poses in each frame but also account for\nthe temporal dynamics of human poses throughout the entire video. With such\nmotivation, we propose a new framework, namely Dynamic Pose Interaction\nDiffusion Models (DPIDM), to leverage diffusion models to delve into dynamic\npose interactions for video virtual try-on. Technically, DPIDM introduces a\nskeleton-based pose adapter to integrate synchronized human and garment poses\ninto the denoising network. A hierarchical attention module is then exquisitely\ndesigned to model intra-frame human-garment pose interactions and long-term\nhuman pose dynamics across frames through pose-aware spatial and temporal\nattention mechanisms. Moreover, DPIDM capitalizes on a temporal regularized\nattention loss between consecutive frames to enhance temporal consistency.\nExtensive experiments conducted on VITON-HD, VVT and ViViD datasets demonstrate\nthe superiority of our DPIDM against the baseline methods. Notably, DPIDM\nachieves VFID score of 0.506 on VVT dataset, leading to 60.5% improvement over\nthe state-of-the-art GPD-VVTO approach.", "AI": {"tldr": "DPIDM is a new framework for video virtual try-on that uses diffusion models to address spatiotemporal pose interactions, achieving superior results over existing methods.", "motivation": "Existing video virtual try-on methods lack effective spatiotemporal pose interactions, leading to temporal inconsistencies. DPIDM aims to solve this by modeling dynamic pose interactions.", "method": "DPIDM integrates a skeleton-based pose adapter and a hierarchical attention module to model intra-frame and long-term pose dynamics, using diffusion models for denoising.", "result": "DPIDM outperforms baselines, achieving a 60.5% improvement in VFID score over GPD-VVTO on the VVT dataset.", "conclusion": "DPIDM effectively addresses spatiotemporal pose interactions in video virtual try-on, demonstrating significant performance gains."}}
{"id": "2505.15830", "pdf": "https://arxiv.org/pdf/2505.15830", "abs": "https://arxiv.org/abs/2505.15830", "authors": ["Nasim Alikhani", "Abbas Mohammadi"], "title": "Characterization of Using Hybrid Beamforming in mmWave Virtual Reality", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "Wireless Virtual Reality (VR) is increasingly in demand in Wireless LANs\n(WLANs). In this paper, a utility function for resource management in wireless\nVR is proposed. Maximizing the sum rate metric in transmitting VR audio or\nvideos is an important factor for ascertaining low latency in obtaining QoS\nrequirement of users in VR, so forth mmWave frequency band in WLAN technology\nshould be used. This frequency band is presented in IEEE 802.11ad/ay. Resource\naccess method in IEEE 802.11ay standard is MultiUser MIMO (MU-MIMO) with OFDM\nmodulation. Operating at mmWave frequency band is equal to use massive number\nof antenna to enhance the received power in (Line of Sight) LoS direction by\ninducing sever propagation with small wavelength. Also for reducing the\ncomplexity of hardware in mmWave technology, designers should select some\nnumber of connected phase shifters to each antenna element by hybrid\nbeamforming method. Processing delay, transmission delay and queue delay should\nbe considered in acquiring QoS metric in terms of utility function. The optimal\nclosed form expression of the multi-attribute utility function is based on\nthese delays that are calculated by downlink and uplink rates in assistant with\nhybrid beamforming. Trends of transmission delay and multi-attribute utility\nfunction in various Es/N0 values and different scenarios are analyzed. Based on\nthese results, 95.4% accuracy in comparison with ns3 in uplink and downlink\nchannel modeling in IEEE 802.11ay standard's indoor environment has been\nreported. Also, it is shown that min channel gain consideration can cause\nreduction in the value of the utility function and incursion in transmission\ndelay in VR.", "AI": {"tldr": "A utility function for resource management in wireless VR is proposed, focusing on maximizing sum rate and minimizing latency using mmWave and MU-MIMO with hybrid beamforming.", "motivation": "The increasing demand for wireless VR in WLANs necessitates efficient resource management to ensure low latency and QoS.", "method": "Proposes a multi-attribute utility function based on processing, transmission, and queue delays, using mmWave frequency bands and MU-MIMO with OFDM modulation. Hybrid beamforming reduces hardware complexity.", "result": "Achieves 95.4% accuracy in channel modeling for IEEE 802.11ay, with analysis showing trade-offs in utility function and transmission delay.", "conclusion": "The utility function effectively manages resources for wireless VR, though min channel gain can degrade performance."}}
{"id": "2505.16100", "pdf": "https://arxiv.org/pdf/2505.16100", "abs": "https://arxiv.org/abs/2505.16100", "authors": ["Zifeng Wang", "Benjamin Danek", "Jimeng Sun"], "title": "BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Validating scientific hypotheses is a central challenge in biomedical\nresearch, and remains difficult for artificial intelligence (AI) agents due to\nthe complexity of real-world data analysis and evidence interpretation. In this\nwork, we present BioDSA-1K, a benchmark designed to evaluate AI agents on\nrealistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K\nconsists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans,\ncurated from over 300 published biomedical studies to reflect the structure and\nreasoning found in authentic research workflows. Each task includes a\nstructured hypothesis derived from the original study's conclusions, expressed\nin the affirmative to reflect the language of scientific reporting, and one or\nmore pieces of supporting evidence grounded in empirical data tables. While\nthese hypotheses mirror published claims, they remain testable using standard\nstatistical or machine learning methods. The benchmark enables evaluation along\nfour axes: (1) hypothesis decision accuracy, (2) alignment between evidence and\nconclusion, (3) correctness of the reasoning process, and (4) executability of\nthe AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable\nhypotheses: cases where the available data are insufficient to support or\nrefute a claim, reflecting a common yet underexplored scenario in real-world\nscience. We propose BioDSA-1K as a foundation for building and evaluating\ngeneralizable, trustworthy AI agents for biomedical discovery.", "AI": {"tldr": "BioDSA-1K is a benchmark for evaluating AI agents on biomedical hypothesis validation tasks, featuring 1,029 tasks with structured hypotheses and evidence from real studies.", "motivation": "To address the challenge of validating scientific hypotheses in biomedical research using AI, given the complexity of real-world data.", "method": "Curated 1,029 tasks with hypotheses and evidence from 300+ studies, focusing on realistic workflows and including non-verifiable cases.", "result": "The benchmark evaluates AI agents on accuracy, evidence alignment, reasoning correctness, and code executability.", "conclusion": "BioDSA-1K serves as a foundation for developing trustworthy AI agents in biomedical discovery."}}
{"id": "2505.16056", "pdf": "https://arxiv.org/pdf/2505.16056", "abs": "https://arxiv.org/abs/2505.16056", "authors": ["Jingcong Liang", "Siyuan Wang", "Miren Tian", "Yitong Li", "Duyu Tang", "Zhongyu Wei"], "title": "Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) enables efficient scaling of large language models\n(LLMs) with sparsely activated experts during inference. To effectively deploy\nlarge MoE models on memory-constrained devices, many systems introduce *expert\noffloading* that caches a subset of experts in fast memory, leaving others on\nslow memory to run on CPU or load on demand. While some research has exploited\nthe locality of expert activations, where consecutive tokens activate similar\nexperts, the degree of this **local routing consistency** varies across models\nand remains understudied. In this paper, we propose two metrics to measure\nlocal routing consistency of MoE models: (1) **Segment Routing Best Performance\n(SRP)**, which evaluates how well a fixed group of experts can cover the needs\nof a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which\nmeasures the optimal segment-level cache hit rate under a given cache size\nlimit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found\nthat models that apply MoE on every layer and do not use shared experts exhibit\nthe highest local routing consistency. We further showed that\ndomain-specialized experts contribute more to routing consistency than\nvocabulary-specialized ones, and that most models can balance between cache\neffectiveness and efficiency with cache sizes approximately 2x the active\nexperts. These findings pave the way for memory-efficient MoE design and\ndeployment without compromising inference speed. We publish the code for\nreplicating experiments at https://github.com/ljcleo/moe-lrc .", "AI": {"tldr": "The paper introduces metrics to measure local routing consistency in MoE models, analyzes 20 MoE LLMs, and provides insights for memory-efficient deployment.", "motivation": "To understand and optimize the local routing consistency of MoE models for efficient deployment on memory-constrained devices.", "method": "Proposes two metrics (SRP and SCH) to measure local routing consistency and analyzes 20 diverse MoE LLMs.", "result": "Models with MoE on every layer and no shared experts show highest consistency; domain-specialized experts enhance consistency. Optimal cache size is ~2x active experts.", "conclusion": "Findings enable memory-efficient MoE design without sacrificing inference speed. Code is publicly available for replication."}}
{"id": "2505.15961", "pdf": "https://arxiv.org/pdf/2505.15961", "abs": "https://arxiv.org/abs/2505.15961", "authors": ["Gabby Litterio", "Juan-David Lizarazo-Ferro", "Pedro Felzenszwalb", "Rashid Zia"], "title": "Super-Resolution with Structured Motion", "categories": ["cs.CV", "I.4.1; I.4.3"], "comment": null, "summary": "We consider the limits of super-resolution using imaging constraints. Due to\nvarious theoretical and practical limitations, reconstruction-based methods\nhave been largely restricted to small increases in resolution. In addition,\nmotion-blur is usually seen as a nuisance that impedes super-resolution. We\nshow that by using high-precision motion information, sparse image priors, and\nconvex optimization, it is possible to increase resolution by large factors. A\nkey operation in super-resolution is deconvolution with a box. In general,\nconvolution with a box is not invertible. However, we obtain perfect\nreconstructions of sparse signals using convex optimization. We also show that\nmotion blur can be helpful for super-resolution. We demonstrate that using\npseudo-random motion it is possible to reconstruct a high-resolution target\nusing a single low-resolution image. We present numerical experiments with\nsimulated data and results with real data captured by a camera mounted on a\ncomputer controlled stage.", "AI": {"tldr": "The paper explores super-resolution limits using imaging constraints, leveraging motion blur and convex optimization to achieve large resolution increases.", "motivation": "Overcome theoretical and practical limitations in super-resolution, particularly small resolution increases and motion-blur as a nuisance.", "method": "Uses high-precision motion information, sparse image priors, and convex optimization, including deconvolution with a box.", "result": "Achieves perfect reconstructions of sparse signals and demonstrates motion blur's utility for super-resolution.", "conclusion": "Motion blur, combined with pseudo-random motion and convex optimization, enables high-resolution reconstruction from a single low-resolution image."}}
{"id": "2411.03948", "pdf": "https://arxiv.org/pdf/2411.03948", "abs": "https://arxiv.org/abs/2411.03948", "authors": ["Felipe Marra", "Lucas N. Ferreira"], "title": "Long-Form Text-to-Music Generation with Adaptive Prompts: A Case Study in Tabletop Role-Playing Games Soundtracks", "categories": ["cs.SD", "cs.AI", "cs.MM", "cs.NE", "eess.AS"], "comment": "Proceedings of the 1st Latin American Music Information Retrieval\n  Workshop (LAMIR), pg 80", "summary": "This paper investigates the capabilities of text-to-audio music generation\nmodels in producing long-form music with prompts that change over time,\nfocusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We\nintroduce Babel Bardo, a system that uses Large Language Models (LLMs) to\ntransform speech transcriptions into music descriptions for controlling a\ntext-to-music model. Four versions of Babel Bardo were compared in two TRPG\ncampaigns: a baseline using direct speech transcriptions, and three LLM-based\nversions with varying approaches to music description generation. Evaluations\nconsidered audio quality, story alignment, and transition smoothness. Results\nindicate that detailed music descriptions improve audio quality while\nmaintaining consistency across consecutive descriptions enhances story\nalignment and transition smoothness.", "AI": {"tldr": "The paper explores text-to-audio music generation for dynamic TRPG soundtracks, comparing LLM-based methods for improved quality and alignment.", "motivation": "To enhance soundtrack generation for TRPGs by enabling dynamic, prompt-driven music creation.", "method": "Introduces Babel Bardo, using LLMs to convert speech into music descriptions for text-to-music models, comparing four versions in TRPG campaigns.", "result": "Detailed music descriptions boost audio quality; consistent descriptions improve story alignment and transitions.", "conclusion": "LLM-based approaches enhance dynamic music generation for TRPGs, balancing quality and narrative coherence."}}
{"id": "2505.16022", "pdf": "https://arxiv.org/pdf/2505.16022", "abs": "https://arxiv.org/abs/2505.16022", "authors": ["Wei Liu", "Siya Qi", "Xinyu Wang", "Chen Qian", "Yali Du", "Yulan He"], "title": "NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "20 pages, 5 tables, 12 figures", "summary": "Recent advances such as DeepSeek R1-Zero highlight the effectiveness of\nincentive training, a reinforcement learning paradigm that computes rewards\nsolely based on the final answer part of a language model's output, thereby\nencouraging the generation of intermediate reasoning steps. However, these\nmethods fundamentally rely on external verifiers, which limits their\napplicability to domains like mathematics and coding where such verifiers are\nreadily available. Although reward models can serve as verifiers, they require\nhigh-quality annotated data and are costly to train. In this work, we propose\nNOVER, NO-VERifier Reinforcement Learning, a general reinforcement learning\nframework that requires only standard supervised fine-tuning data with no need\nfor an external verifier. NOVER enables incentive training across a wide range\nof text-to-text tasks and outperforms the model of the same size distilled from\nlarge reasoning models such as DeepSeek R1 671B by 7.7 percent. Moreover, the\nflexibility of NOVER enables new possibilities for optimizing large language\nmodels, such as inverse incentive training.", "AI": {"tldr": "NOVER is a reinforcement learning framework that eliminates the need for external verifiers, enabling incentive training across diverse text-to-text tasks and outperforming models like DeepSeek R1-Zero.", "motivation": "Existing methods rely on external verifiers, limiting applicability to domains like math and coding. Reward models are costly to train. NOVER addresses these limitations.", "method": "NOVER uses standard supervised fine-tuning data without external verifiers, enabling incentive training for text-to-text tasks.", "result": "NOVER outperforms models like DeepSeek R1 671B by 7.7% and offers flexibility for optimizing large language models.", "conclusion": "NOVER provides a general, cost-effective solution for incentive training, expanding its applicability beyond domains with verifiers."}}
{"id": "2505.16798", "pdf": "https://arxiv.org/pdf/2505.16798", "abs": "https://arxiv.org/abs/2505.16798", "authors": ["KiHyun Nam", "Jungwoo Heo", "Jee-weon Jung", "Gangin Park", "Chaeyoung Jung", "Ha-Jin Yu", "Joon Son Chung"], "title": "SEED: Speaker Embedding Enhancement Diffusion Model", "categories": ["eess.AS", "cs.AI"], "comment": "Accepted to Interspeech 2025. The official code can be found at\n  https://github.com/kaistmm/seed-pytorch", "summary": "A primary challenge when deploying speaker recognition systems in real-world\napplications is performance degradation caused by environmental mismatch. We\npropose a diffusion-based method that takes speaker embeddings extracted from a\npre-trained speaker recognition model and generates refined embeddings. For\ntraining, our approach progressively adds Gaussian noise to both clean and\nnoisy speaker embeddings extracted from clean and noisy speech, respectively,\nvia forward process of a diffusion model, and then reconstructs them to clean\nembeddings in the reverse process. While inferencing, all embeddings are\nregenerated via diffusion process. Our method needs neither speaker label nor\nany modification to the existing speaker recognition pipeline. Experiments on\nevaluation sets simulating environment mismatch scenarios show that our method\ncan improve recognition accuracy by up to 19.6% over baseline models while\nretaining performance on conventional scenarios. We publish our code here\nhttps://github.com/kaistmm/seed-pytorch", "AI": {"tldr": "A diffusion-based method refines speaker embeddings to address performance degradation in real-world speaker recognition systems, improving accuracy by up to 19.6% without requiring speaker labels or pipeline modifications.", "motivation": "Performance degradation in speaker recognition due to environmental mismatch is a key challenge.", "method": "Proposes a diffusion model that adds noise to embeddings (clean/noisy) and reconstructs them to clean versions, applied during inference.", "result": "Improves recognition accuracy by up to 19.6% in mismatch scenarios without affecting conventional performance.", "conclusion": "The method effectively mitigates environmental mismatch issues without additional labels or pipeline changes."}}
{"id": "2505.17022", "pdf": "https://arxiv.org/pdf/2505.17022", "abs": "https://arxiv.org/abs/2505.17022", "authors": ["Chengqi Duan", "Rongyao Fang", "Yuqing Wang", "Kun Wang", "Linjiang Huang", "Xingyu Zeng", "Hongsheng Li", "Xihui Liu"], "title": "GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": "Github page refer to: https://github.com/gogoduan/GoT-R1", "summary": "Visual generation models have made remarkable progress in creating realistic\nimages from text prompts, yet struggle with complex prompts that specify\nmultiple objects with precise spatial relationships and attributes. Effective\nhandling of such prompts requires explicit reasoning about the semantic content\nand spatial layout. We present GoT-R1, a framework that applies reinforcement\nlearning to enhance semantic-spatial reasoning in visual generation. Building\nupon the Generation Chain-of-Thought approach, GoT-R1 enables models to\nautonomously discover effective reasoning strategies beyond predefined\ntemplates through carefully designed reinforcement learning. To achieve this,\nwe propose a dual-stage multi-dimensional reward framework that leverages MLLMs\nto evaluate both the reasoning process and final output, enabling effective\nsupervision across the entire generation pipeline. The reward system assesses\nsemantic alignment, spatial accuracy, and visual quality in a unified approach.\nExperimental results demonstrate significant improvements on T2I-CompBench\nbenchmark, particularly in compositional tasks involving precise spatial\nrelationships and attribute binding. GoT-R1 advances the state-of-the-art in\nimage generation by successfully transferring sophisticated reasoning\ncapabilities to the visual generation domain. To facilitate future research, we\nmake our code and pretrained models publicly available at\nhttps://github.com/gogoduan/GoT-R1.", "AI": {"tldr": "GoT-R1 is a reinforcement learning framework enhancing semantic-spatial reasoning in visual generation, improving performance on complex prompts with precise spatial relationships and attributes.", "motivation": "Existing visual generation models struggle with complex prompts requiring precise spatial and semantic reasoning.", "method": "GoT-R1 uses reinforcement learning with a dual-stage multi-dimensional reward framework, leveraging MLLMs for evaluation.", "result": "Significant improvements on T2I-CompBench, especially in compositional tasks with precise spatial relationships.", "conclusion": "GoT-R1 advances visual generation by integrating sophisticated reasoning, with code and models made publicly available."}}
{"id": "2505.15868", "pdf": "https://arxiv.org/pdf/2505.15868", "abs": "https://arxiv.org/abs/2505.15868", "authors": ["Changchun Yang", "Weiqian Dai", "Yilan Zhang", "Siyuan Chen", "Jingdong Hu", "Junkai Su", "Yuxuan Chen", "Ao Xu", "Na Li", "Xin Gao", "Yongguo Yu"], "title": "An Inclusive Foundation Model for Generalizable Cytogenetics in Precision Oncology", "categories": ["q-bio.QM", "cs.AI", "eess.IV"], "comment": "These authors contributed equally to this work: Changchun Yang,\n  Weiqian Dai, Yilan Zhang", "summary": "Chromosome analysis is vital for diagnosing genetic disorders and guiding\ncancer therapy decisions through the identification of somatic clonal\naberrations. However, developing an AI model are hindered by the overwhelming\ncomplexity and diversity of chromosomal abnormalities, requiring extensive\nannotation efforts, while automated methods remain task-specific and lack\ngeneralizability due to the scarcity of comprehensive datasets spanning diverse\nresource conditions. Here, we introduce CHROMA, a foundation model for\ncytogenomics, designed to overcome these challenges by learning generalizable\nrepresentations of chromosomal abnormalities. Pre-trained on over 84,000\nspecimens (~4 million chromosomal images) via self-supervised learning, CHROMA\noutperforms other methods across all types of abnormalities, even when trained\non fewer labelled data and more imbalanced datasets. By facilitating\ncomprehensive mapping of instability and clonal leisons across various\naberration types, CHROMA offers a scalable and generalizable solution for\nreliable and automated clinical analysis, reducing the annotation workload for\nexperts and advancing precision oncology through the early detection of rare\ngenomic abnormalities, enabling broad clinical AI applications and making\nadvanced genomic analysis more accessible.", "AI": {"tldr": "CHROMA is a foundation model for cytogenomics that learns generalizable representations of chromosomal abnormalities, outperforming other methods with fewer labeled data and imbalanced datasets.", "motivation": "The complexity and diversity of chromosomal abnormalities hinder AI model development, requiring extensive annotation and lacking generalizability due to scarce datasets.", "method": "CHROMA is pre-trained on 84,000 specimens (~4 million images) via self-supervised learning to learn generalizable representations.", "result": "CHROMA outperforms other methods across abnormality types, even with fewer labeled data and imbalanced datasets.", "conclusion": "CHROMA provides a scalable, generalizable solution for clinical analysis, reducing expert workload and advancing precision oncology."}}
{"id": "2505.16114", "pdf": "https://arxiv.org/pdf/2505.16114", "abs": "https://arxiv.org/abs/2505.16114", "authors": ["Naiqi Li", "Peiyuan Liu", "Zheng Liu", "Tao Dai", "Yong Jiang", "Shu-Tao Xia"], "title": "Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language", "categories": ["cs.AI"], "comment": null, "summary": "Solving puzzles in natural language poses a long-standing challenge in AI.\nWhile large language models (LLMs) have recently shown impressive capabilities\nin a variety of tasks, they continue to struggle with complex puzzles that\ndemand precise reasoning and exhaustive search. In this paper, we propose\nLogic-of-Thought (Logot), a novel framework that bridges LLMs with logic\nprogramming to address this problem. Our method leverages LLMs to translate\npuzzle rules and states into answer set programs (ASPs), the solution of which\nare then accurately and efficiently inferred by an ASP interpreter. This hybrid\napproach combines the natural language understanding of LLMs with the precise\nreasoning capabilities of logic programs. We evaluate our method on various\ngrid puzzles and dynamic puzzles involving actions, demonstrating near-perfect\naccuracy across all tasks. Our code and data are available at:\nhttps://github.com/naiqili/Logic-of-Thought.", "AI": {"tldr": "A hybrid framework, Logic-of-Thought (Logot), combines LLMs and logic programming to solve complex puzzles with high accuracy.", "motivation": "Addressing the challenge of solving natural language puzzles, which LLMs struggle with due to demands for precise reasoning.", "method": "Uses LLMs to translate puzzle rules into answer set programs (ASPs), solved by an ASP interpreter.", "result": "Achieves near-perfect accuracy on grid and dynamic puzzles.", "conclusion": "Logot effectively bridges LLMs and logic programming for precise puzzle-solving."}}
{"id": "2505.16058", "pdf": "https://arxiv.org/pdf/2505.16058", "abs": "https://arxiv.org/abs/2505.16058", "authors": ["Mars Liyao Gao", "J. Nathan Kutz", "Bernat Font"], "title": "Mesh-free sparse identification of nonlinear dynamics", "categories": ["cs.LG", "cs.AI", "physics.data-an"], "comment": "17 pages, 13 figures, 14 tables", "summary": "Identifying the governing equations of a dynamical system is one of the most\nimportant tasks for scientific modeling. However, this procedure often requires\nhigh-quality spatio-temporal data uniformly sampled on structured grids. In\nthis paper, we propose mesh-free SINDy, a novel algorithm which leverages the\npower of neural network approximation as well as auto-differentiation to\nidentify governing equations from arbitrary sensor placements and non-uniform\ntemporal data sampling. We show that mesh-free SINDy is robust to high noise\nlevels and limited data while remaining computationally efficient. In our\nimplementation, the training procedure is straight-forward and nearly free of\nhyperparameter tuning, making mesh-free SINDy widely applicable to many\nscientific and engineering problems. In the experiments, we demonstrate its\neffectiveness on a series of PDEs including the Burgers' equation, the heat\nequation, the Korteweg-De Vries equation and the 2D advection-diffusion\nequation. We conduct detailed numerical experiments on all datasets, varying\nthe noise levels and number of samples, and we also compare our approach to\nprevious state-of-the-art methods. It is noteworthy that, even in high-noise\nand low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery,\nachieving successful identification with up to 75% noise for the Burgers'\nequation using 5,000 samples and with as few as 100 samples and 1% noise. All\nof this is achieved within a training time of under one minute.", "AI": {"tldr": "Mesh-free SINDy is a novel algorithm for identifying governing equations from arbitrary sensor data, robust to noise and limited data, with minimal hyperparameter tuning.", "motivation": "Traditional methods require high-quality, uniformly sampled data, which is often impractical. Mesh-free SINDy addresses this limitation.", "method": "Leverages neural networks and auto-differentiation to identify equations from non-uniform, noisy data.", "result": "Effective on various PDEs, robust to high noise (up to 75%) and low data (100 samples), with training under one minute.", "conclusion": "Mesh-free SINDy is widely applicable, efficient, and outperforms state-of-the-art methods in challenging scenarios."}}
{"id": "2505.15963", "pdf": "https://arxiv.org/pdf/2505.15963", "abs": "https://arxiv.org/abs/2505.15963", "authors": ["Shujun Liu", "Siyuan Wang", "Zejun Li", "Jianxiang Wang", "Cheng Zeng", "Zhongyu Wei"], "title": "OViP: Online Vision-Language Preference Learning", "categories": ["cs.CV", "cs.CL"], "comment": "22 pages, 10 figures, 8 tables", "summary": "Large vision-language models (LVLMs) remain vulnerable to hallucination,\noften generating content misaligned with visual inputs. While recent approaches\nadvance multi-modal Direct Preference Optimization (DPO) to mitigate\nhallucination, they typically rely on predefined or randomly edited negative\nsamples that fail to reflect actual model errors, limiting training efficacy.\nIn this work, we propose an Online Vision-language Preference Learning (OViP)\nframework that dynamically constructs contrastive training data based on the\nmodel's own hallucinated outputs. By identifying semantic differences between\nsampled response pairs and synthesizing negative images using a diffusion\nmodel, OViP generates more relevant supervision signals in real time. This\nfailure-driven training enables adaptive alignment of both textual and visual\npreferences. Moreover, we refine existing evaluation protocols to better\ncapture the trade-off between hallucination suppression and expressiveness.\nExperiments on hallucination and general benchmarks demonstrate that OViP\neffectively reduces hallucinations while preserving core multi-modal\ncapabilities.", "AI": {"tldr": "OViP dynamically constructs contrastive training data from model hallucinations to improve alignment in vision-language models, reducing errors while maintaining expressiveness.", "motivation": "Current methods for mitigating hallucination in LVLMs rely on predefined or random negative samples, which don't reflect actual model errors, limiting training effectiveness.", "method": "Proposes OViP, a framework that dynamically generates contrastive training data by identifying semantic differences in model outputs and synthesizing negative images with a diffusion model.", "result": "OViP effectively reduces hallucinations while preserving multi-modal capabilities, as shown in experiments on hallucination and general benchmarks.", "conclusion": "OViP offers a failure-driven training approach that adaptively aligns textual and visual preferences, improving hallucination mitigation in LVLMs."}}
{"id": "2505.15368", "pdf": "https://arxiv.org/pdf/2505.15368", "abs": "https://arxiv.org/abs/2505.15368", "authors": ["Yicheng Gu", "Chaoren Wang", "Zhizheng Wu", "Lauri Juvela"], "title": "Neurodyne: Neural Pitch Manipulation with Representation Learning and Cycle-Consistency GAN", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Pitch manipulation is the process of producers adjusting the pitch of an\naudio segment to a specific key and intonation, which is essential in music\nproduction. Neural-network-based pitch-manipulation systems have been popular\nin recent years due to their superior synthesis quality compared to classical\nDSP methods. However, their performance is still limited due to their\ninaccurate feature disentanglement using source-filter models and the lack of\npaired in- and out-of-tune training data. This work proposes Neurodyne to\naddress these issues. Specifically, Neurodyne uses adversarial representation\nlearning to learn a pitch-independent latent representation to avoid inaccurate\ndisentanglement and cycle-consistency training to create paired training data\nimplicitly. Experimental results on global-key and template-based pitch\nmanipulation demonstrate the effectiveness of the proposed system, marking\nimproved synthesis quality while maintaining the original singer identity.", "AI": {"tldr": "Neurodyne improves pitch manipulation in music production by using adversarial representation learning and cycle-consistency training, outperforming traditional methods.", "motivation": "Current neural-network-based pitch-manipulation systems face limitations due to inaccurate feature disentanglement and lack of paired training data.", "method": "Neurodyne employs adversarial representation learning for pitch-independent latent representation and cycle-consistency training for implicit paired data creation.", "result": "Experiments show improved synthesis quality while preserving singer identity in global-key and template-based pitch manipulation.", "conclusion": "Neurodyne effectively addresses existing limitations, enhancing pitch manipulation in music production."}}
{"id": "2505.16023", "pdf": "https://arxiv.org/pdf/2505.16023", "abs": "https://arxiv.org/abs/2505.16023", "authors": ["Sheshera Mysore", "Debarati Das", "Hancheng Cao", "Bahareh Sarrafzadeh"], "title": "Prototypical Human-AI Collaboration Behaviors from LLM-Assisted Writing in the Wild", "categories": ["cs.CL", "cs.HC"], "comment": "Pre-print under-review", "summary": "As large language models (LLMs) are used in complex writing workflows, users\nengage in multi-turn interactions to steer generations to better fit their\nneeds. Rather than passively accepting output, users actively refine, explore,\nand co-construct text. We conduct a large-scale analysis of this collaborative\nbehavior for users engaged in writing tasks in the wild with two popular AI\nassistants, Bing Copilot and WildChat. Our analysis goes beyond simple task\nclassification or satisfaction estimation common in prior work and instead\ncharacterizes how users interact with LLMs through the course of a session. We\nidentify prototypical behaviors in how users interact with LLMs in prompts\nfollowing their original request. We refer to these as Prototypical Human-AI\nCollaboration Behaviors (PATHs) and find that a small group of PATHs explain a\nmajority of the variation seen in user-LLM interaction. These PATHs span users\nrevising intents, exploring texts, posing questions, adjusting style or\ninjecting new content. Next, we find statistically significant correlations\nbetween specific writing intents and PATHs, revealing how users' intents shape\ntheir collaboration behaviors. We conclude by discussing the implications of\nour findings on LLM alignment.", "AI": {"tldr": "The paper analyzes user interactions with LLMs like Bing Copilot and WildChat, identifying common collaboration behaviors (PATHs) and their correlation with writing intents, impacting LLM alignment.", "motivation": "To understand how users actively collaborate with LLMs in writing tasks, moving beyond passive acceptance to refine and co-construct text.", "method": "Large-scale analysis of user interactions with Bing Copilot and WildChat, identifying prototypical behaviors (PATHs) and correlating them with writing intents.", "result": "A small set of PATHs explains most user-LLM interaction variation, with significant correlations between specific writing intents and behaviors.", "conclusion": "Findings highlight the need for LLM alignment to better support dynamic, collaborative user interactions."}}
{"id": "2505.16911", "pdf": "https://arxiv.org/pdf/2505.16911", "abs": "https://arxiv.org/abs/2505.16911", "authors": ["Ofir Yaish", "Yehuda Mishaly", "Eliya Nachmani"], "title": "Active Speech Enhancement: Active Speech Denoising Decliping and Deveraberation", "categories": ["eess.AS", "cs.AI"], "comment": null, "summary": "We introduce a new paradigm for active sound modification: Active Speech\nEnhancement (ASE). While Active Noise Cancellation (ANC) algorithms focus on\nsuppressing external interference, ASE goes further by actively shaping the\nspeech signal -- both attenuating unwanted noise components and amplifying\nspeech-relevant frequencies -- to improve intelligibility and perceptual\nquality. To enable this, we propose a novel Transformer-Mamba-based\narchitecture, along with a task-specific loss function designed to jointly\noptimize interference suppression and signal enrichment. Our method outperforms\nexisting baselines across multiple speech processing tasks -- including\ndenoising, dereverberation, and declipping -- demonstrating the effectiveness\nof active, targeted modulation in challenging acoustic environments.", "AI": {"tldr": "Active Speech Enhancement (ASE) improves speech intelligibility by shaping the signal, outperforming traditional noise cancellation methods.", "motivation": "To enhance speech quality beyond noise suppression by actively modifying the signal for better intelligibility and perceptual quality.", "method": "Proposes a Transformer-Mamba-based architecture with a task-specific loss function for joint optimization of noise suppression and signal enrichment.", "result": "Outperforms existing baselines in tasks like denoising, dereverberation, and declipping.", "conclusion": "ASE is effective for targeted speech enhancement in challenging acoustic environments."}}
{"id": "2412.02575", "pdf": "https://arxiv.org/pdf/2412.02575", "abs": "https://arxiv.org/abs/2412.02575", "authors": ["Ze Zhang", "Enyuan Zhao", "Di Niu", "Jie Nie", "Xinyue Liang", "Lei Huang"], "title": "Copy-Move Forgery Detection and Question Answering for Remote Sensing Image", "categories": ["cs.CV", "cs.MM"], "comment": "11 figs, 7 tables", "summary": "Driven by practical demands in land resource monitoring and national defense\nsecurity, this paper introduces the Remote Sensing Copy-Move Question Answering\n(RSCMQA) task. Unlike traditional Remote Sensing Visual Question Answering\n(RSVQA), RSCMQA focuses on interpreting complex tampering scenarios and\ninferring relationships between objects. We present a suite of global RSCMQA\ndatasets, comprising images from 29 different regions across 14 countries.\nSpecifically, we propose five distinct datasets, including the basic dataset\nRS-CMQA, the category-balanced dataset RS-CMQA-B, the high-authenticity dataset\nReal-RSCM, the extended dataset RS-TQA, and the extended category-balanced\ndataset RS-TQA-B. These datasets fill a critical gap in the field while\nensuring comprehensiveness, balance, and challenge. Furthermore, we introduce a\nregion-discrimination-guided multimodal copy-move forgery perception framework\n(CMFPF), which enhances the accuracy of answering questions about tampered\nimages by leveraging prompt about the differences and connections between the\nsource and tampered domains. Extensive experiments demonstrate that our method\nprovides a stronger benchmark for RSCMQA compared to general VQA and RSVQA\nmodels. Our datasets and code are publicly available at\nhttps://github.com/shenyedepisa/RSCMQA.", "AI": {"tldr": "The paper introduces the RSCMQA task for interpreting tampered remote sensing images, proposes five datasets, and presents a CMFPF framework for improved accuracy.", "motivation": "Practical needs in land monitoring and defense security drive the development of RSCMQA to address complex tampering scenarios.", "method": "A region-discrimination-guided multimodal framework (CMFPF) is introduced to analyze tampered images by leveraging domain differences.", "result": "The method outperforms general VQA and RSVQA models, providing a robust benchmark for RSCMQA.", "conclusion": "The datasets and framework fill a critical gap, offering comprehensive, balanced, and challenging resources for the field."}}
{"id": "2505.15997", "pdf": "https://arxiv.org/pdf/2505.15997", "abs": "https://arxiv.org/abs/2505.15997", "authors": ["Mehran Zoravar", "Shadi Alijani", "Homayoun Najjaran"], "title": "Domain Adaptive Skin Lesion Classification via Conformal Ensemble of Vision Transformers", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "5 pages, 4 figures, conference (ccece 2025)", "summary": "Exploring the trustworthiness of deep learning models is crucial, especially\nin critical domains such as medical imaging decision support systems. Conformal\nprediction has emerged as a rigorous means of providing deep learning models\nwith reliable uncertainty estimates and safety guarantees. However, conformal\nprediction results face challenges due to the backbone model's struggles in\ndomain-shifted scenarios, such as variations in different sources. To aim this\nchallenge, this paper proposes a novel framework termed Conformal Ensemble of\nVision Transformers (CE-ViTs) designed to enhance image classification\nperformance by prioritizing domain adaptation and model robustness, while\naccounting for uncertainty. The proposed method leverages an ensemble of vision\ntransformer models in the backbone, trained on diverse datasets including\nHAM10000, Dermofit, and Skin Cancer ISIC datasets. This ensemble learning\napproach, calibrated through the combined mentioned datasets, aims to enhance\ndomain adaptation through conformal learning. Experimental results underscore\nthat the framework achieves a high coverage rate of 90.38\\%, representing an\nimprovement of 9.95\\% compared to the HAM10000 model. This indicates a strong\nlikelihood that the prediction set includes the true label compared to singular\nmodels. Ensemble learning in CE-ViTs significantly improves conformal\nprediction performance, increasing the average prediction set size for\nchallenging misclassified samples from 1.86 to 3.075.", "AI": {"tldr": "The paper proposes CE-ViTs, a framework combining conformal prediction and ensemble learning with Vision Transformers to improve domain adaptation and robustness in medical image classification.", "motivation": "Ensuring trustworthiness in deep learning models for critical domains like medical imaging, addressing challenges in domain-shifted scenarios.", "method": "Uses an ensemble of Vision Transformers trained on diverse datasets (HAM10000, Dermofit, ISIC) and calibrates them via conformal learning for domain adaptation.", "result": "Achieves 90.38% coverage rate (9.95% improvement) and increases prediction set size for misclassified samples from 1.86 to 3.075.", "conclusion": "CE-ViTs enhances conformal prediction performance, demonstrating better reliability and adaptability in domain-shifted scenarios."}}
{"id": "2505.16120", "pdf": "https://arxiv.org/pdf/2505.16120", "abs": "https://arxiv.org/abs/2505.16120", "authors": ["Guannan Liang", "Qianqian Tong"], "title": "LLM-Powered AI Agent Systems and Their Applications in Industry", "categories": ["cs.AI"], "comment": "This is the author's accepted version of the paper accepted to appear\n  at IEEE AIIoT 2025. The final version will be available via IEEE Xplore.\n  \\c{opyright}2025 IEEE. Personal use of this material is permitted", "summary": "The emergence of Large Language Models (LLMs) has reshaped agent systems.\nUnlike traditional rule-based agents with limited task scope, LLM-powered\nagents offer greater flexibility, cross-domain reasoning, and natural language\ninteraction. Moreover, with the integration of multi-modal LLMs, current agent\nsystems are highly capable of processing diverse data modalities, including\ntext, images, audio, and structured tabular data, enabling richer and more\nadaptive real-world behavior. This paper comprehensively examines the evolution\nof agent systems from the pre-LLM era to current LLM-powered architectures. We\ncategorize agent systems into software-based, physical, and adaptive hybrid\nsystems, highlighting applications across customer service, software\ndevelopment, manufacturing automation, personalized education, financial\ntrading, and healthcare. We further discuss the primary challenges posed by\nLLM-powered agents, including high inference latency, output uncertainty, lack\nof evaluation metrics, and security vulnerabilities, and propose potential\nsolutions to mitigate these concerns.", "AI": {"tldr": "The paper explores the evolution of agent systems from rule-based to LLM-powered architectures, highlighting their flexibility, multi-modal capabilities, and applications across various domains, while addressing challenges like latency, uncertainty, and security.", "motivation": "The rise of LLMs has transformed agent systems, enabling broader task scope and natural language interaction, necessitating a review of their evolution, applications, and challenges.", "method": "The paper categorizes agent systems into software-based, physical, and hybrid systems, examining their applications and analyzing challenges like inference latency and security vulnerabilities.", "result": "LLM-powered agents offer enhanced flexibility and multi-modal processing but face issues like high latency and output uncertainty. Potential solutions are proposed.", "conclusion": "LLM-powered agents represent a significant advancement but require addressing key challenges to fully realize their potential across diverse applications."}}
{"id": "2505.16060", "pdf": "https://arxiv.org/pdf/2505.16060", "abs": "https://arxiv.org/abs/2505.16060", "authors": ["Shangding Gu", "Donghao Ying", "Ming Jin", "Yu Joe Lu", "Jun Wang", "Javad Lavaei", "Costas Spanos"], "title": "Few-Shot Test-Time Optimization Without Retraining for Semiconductor Recipe Generation and Beyond", "categories": ["cs.LG"], "comment": null, "summary": "We introduce Model Feedback Learning (MFL), a novel test-time optimization\nframework for optimizing inputs to pre-trained AI models or deployed hardware\nsystems without requiring any retraining of the models or modifications to the\nhardware. In contrast to existing methods that rely on adjusting model\nparameters, MFL leverages a lightweight reverse model to iteratively search for\noptimal inputs, enabling efficient adaptation to new objectives under\ndeployment constraints. This framework is particularly advantageous in\nreal-world settings, such as semiconductor manufacturing recipe generation,\nwhere modifying deployed systems is often infeasible or cost-prohibitive. We\nvalidate MFL on semiconductor plasma etching tasks, where it achieves target\nrecipe generation in just five iterations, significantly outperforming both\nBayesian optimization and human experts. Beyond semiconductor applications, MFL\nalso demonstrates strong performance in chemical processes (e.g., chemical\nvapor deposition) and electronic systems (e.g., wire bonding), highlighting its\nbroad applicability. Additionally, MFL incorporates stability-aware\noptimization, enhancing robustness to process variations and surpassing\nconventional supervised learning and random search methods in high-dimensional\ncontrol settings. By enabling few-shot adaptation, MFL provides a scalable and\nefficient paradigm for deploying intelligent control in real-world\nenvironments.", "AI": {"tldr": "Model Feedback Learning (MFL) is a test-time optimization framework that optimizes inputs for pre-trained models or hardware systems without retraining, using a lightweight reverse model for efficient adaptation.", "motivation": "Existing methods require model parameter adjustments, which is impractical for deployed systems like semiconductor manufacturing. MFL addresses this by enabling input optimization without system modifications.", "method": "MFL uses a reverse model to iteratively search for optimal inputs, incorporating stability-aware optimization for robustness.", "result": "MFL outperforms Bayesian optimization and human experts in semiconductor plasma etching, achieving target recipes in five iterations. It also excels in chemical and electronic applications.", "conclusion": "MFL offers a scalable, efficient solution for intelligent control in real-world settings, enabling few-shot adaptation without system changes."}}
{"id": "2505.15966", "pdf": "https://arxiv.org/pdf/2505.15966", "abs": "https://arxiv.org/abs/2505.15966", "authors": ["Alex Su", "Haozhe Wang", "Weimin Ren", "Fangzhen Lin", "Wenhu Chen"], "title": "Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Haozhe Wang and Alex Su contributed equally and listed alphabetically", "summary": "Chain-of-thought reasoning has significantly improved the performance of\nLarge Language Models (LLMs) across various domains. However, this reasoning\nprocess has been confined exclusively to textual space, limiting its\neffectiveness in visually intensive tasks. To address this limitation, we\nintroduce the concept of reasoning in the pixel-space. Within this novel\nframework, Vision-Language Models (VLMs) are equipped with a suite of visual\nreasoning operations, such as zoom-in and select-frame. These operations enable\nVLMs to directly inspect, interrogate, and infer from visual evidences, thereby\nenhancing reasoning fidelity for visual tasks. Cultivating such pixel-space\nreasoning capabilities in VLMs presents notable challenges, including the\nmodel's initially imbalanced competence and its reluctance to adopt the newly\nintroduced pixel-space operations. We address these challenges through a\ntwo-phase training approach. The first phase employs instruction tuning on\nsynthesized reasoning traces to familiarize the model with the novel visual\noperations. Following this, a reinforcement learning (RL) phase leverages a\ncuriosity-driven reward scheme to balance exploration between pixel-space\nreasoning and textual reasoning. With these visual operations, VLMs can\ninteract with complex visual inputs, such as information-rich images or videos\nto proactively gather necessary information. We demonstrate that this approach\nsignificantly improves VLM performance across diverse visual reasoning\nbenchmarks. Our 7B model, \\model, achieves 84\\% on V* bench, 74\\% on\nTallyQA-Complex, and 84\\% on InfographicsVQA, marking the highest accuracy\nachieved by any open-source model to date. These results highlight the\nimportance of pixel-space reasoning and the effectiveness of our framework.", "AI": {"tldr": "The paper introduces pixel-space reasoning for Vision-Language Models (VLMs) to enhance visual task performance, overcoming limitations of text-only reasoning.", "motivation": "Chain-of-thought reasoning in LLMs is limited to text, hindering effectiveness in visual tasks. Pixel-space reasoning aims to bridge this gap.", "method": "A two-phase training approach: instruction tuning on synthesized reasoning traces, followed by reinforcement learning with curiosity-driven rewards.", "result": "The 7B model achieves 84% on V* bench, 74% on TallyQA-Complex, and 84% on InfographicsVQA, setting new benchmarks.", "conclusion": "Pixel-space reasoning significantly improves VLM performance, demonstrating the framework's effectiveness for visual tasks."}}
{"id": "2502.05674", "pdf": "https://arxiv.org/pdf/2502.05674", "abs": "https://arxiv.org/abs/2502.05674", "authors": ["Ashi Garg", "Zexin Cai", "Lin Zhang", "Henry Li Xinyuan", "Leibny Paola Garc\u00eda-Perera", "Kevin Duh", "Sanjeev Khudanpur", "Matthew Wiesner", "Nicholas Andrews"], "title": "ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution Shifts", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "The problem of synthetic speech detection has enjoyed considerable attention,\nwith recent methods achieving low error rates across several established\nbenchmarks. However, to what extent can low error rates on academic benchmarks\ntranslate to more realistic conditions? In practice, while the training set is\nfixed at one point in time, test-time conditions may exhibit distribution\nshifts relative to the training conditions, such as changes in speaker\ncharacteristics, emotional expressiveness, language and acoustic conditions,\nand the emergence of novel synthesis methods. Although some existing datasets\ntarget subsets of these distribution shifts, systematic analysis remains\ndifficult due to inconsistencies between source data and synthesis systems\nacross datasets. This difficulty is further exacerbated by the rapid\ndevelopment of new text-to-speech (TTS) and vocoder systems, which continually\nexpand the diversity of synthetic speech. To enable systematic benchmarking of\nmodel performance under distribution shifts, we introduce ShiftySpeech, a\nlarge-scale benchmark comprising over 3,000 hours of synthetic speech across 7\nsource domains, 6 TTS systems, 12 vocoders, and 3 languages. ShiftySpeech is\nspecifically designed to evaluate model generalization under controlled\ndistribution shifts while ensuring broad coverage of modern synthetic speech\ngeneration techniques. It fills a key gap in current benchmarks by supporting\nfine-grained, controlled analysis of generalization robustness. All tested\ndistribution shifts significantly degrade detection performance of\nstate-of-the-art detection approaches based on self-supervised features.\nOverall, our findings suggest that reliance on synthetic speech detection\nmethods in production environments should be carefully evaluated based on\nanticipated distribution shifts.", "AI": {"tldr": "The paper introduces ShiftySpeech, a benchmark for evaluating synthetic speech detection under distribution shifts, revealing performance degradation in state-of-the-art methods.", "motivation": "To assess if low error rates on academic benchmarks hold under realistic, shifting conditions like speaker changes, new synthesis methods, and acoustic variations.", "method": "Developed ShiftySpeech, a large-scale benchmark with 3,000+ hours of synthetic speech across diverse domains, TTS systems, vocoders, and languages.", "result": "State-of-the-art detection methods degrade significantly under controlled distribution shifts.", "conclusion": "Synthetic speech detection methods should be cautiously used in production, considering potential distribution shifts."}}
{"id": "2505.16036", "pdf": "https://arxiv.org/pdf/2505.16036", "abs": "https://arxiv.org/abs/2505.16036", "authors": ["Burak Erin\u00e7 \u00c7etin", "Y\u0131ld\u0131r\u0131m \u00d6zen", "Elif Naz Demiry\u0131lmaz", "Kaan Eng\u00fcr", "Cagri Toraman"], "title": "OpenEthics: A Comprehensive Ethical Evaluation of Open-Source Generative Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Generative large language models present significant potential but also raise\ncritical ethical concerns. Most studies focus on narrow ethical dimensions, and\nalso limited diversity of languages and models. To address these gaps, we\nconduct a broad ethical evaluation of 29 recent open-source large language\nmodels using a novel data collection including four ethical aspects:\nRobustness, reliability, safety, and fairness. We analyze model behavior in\nboth a commonly used language, English, and a low-resource language, Turkish.\nOur aim is to provide a comprehensive ethical assessment and guide safer model\ndevelopment by filling existing gaps in evaluation breadth, language coverage,\nand model diversity. Our experimental results, based on LLM-as-a-Judge, reveal\nthat optimization efforts for many open-source models appear to have\nprioritized safety and fairness, and demonstrated good robustness while\nreliability remains a concern. We demonstrate that ethical evaluation can be\neffectively conducted independently of the language used. In addition, models\nwith larger parameter counts tend to exhibit better ethical performance, with\nGemma and Qwen models demonstrating the most ethical behavior among those\nevaluated.", "AI": {"tldr": "The paper conducts a broad ethical evaluation of 29 open-source large language models, focusing on robustness, reliability, safety, and fairness, across English and Turkish. Results show prioritization of safety and fairness, with reliability as a concern, and larger models like Gemma and Qwen performing best.", "motivation": "To address gaps in ethical evaluation breadth, language coverage, and model diversity in generative large language models.", "method": "Evaluated 29 open-source models using a novel data collection method (LLM-as-a-Judge) across four ethical aspects in English and Turkish.", "result": "Optimization efforts prioritized safety and fairness; reliability remains a concern. Larger models (e.g., Gemma, Qwen) performed better ethically.", "conclusion": "Ethical evaluation is feasible across languages, and larger models tend to perform better. The study guides safer model development by filling evaluation gaps."}}
{"id": "2505.16310", "pdf": "https://arxiv.org/pdf/2505.16310", "abs": "https://arxiv.org/abs/2505.16310", "authors": ["Gaurav Kumar", "Soham Satyadharma", "Harpreet Singh"], "title": "Paired and Unpaired Image to Image Translation using Generative Adversarial Networks", "categories": ["cs.CV", "eess.IV"], "comment": "6 pages", "summary": "Image to image translation is an active area of research in the field of\ncomputer vision, enabling the generation of new images with different styles,\ntextures, or resolutions while preserving their characteristic properties.\nRecent architectures leverage Generative Adversarial Networks (GANs) to\ntransform input images from one domain to another. In this work, we focus on\nthe study of both paired and unpaired image translation across multiple image\ndomains. For the paired task, we used a conditional GAN model, and for the\nunpaired task, we trained it using cycle consistency loss. We experimented with\ndifferent types of loss functions, multiple Patch-GAN sizes, and model\narchitectures. New quantitative metrics - precision, recall, and FID score -\nwere used for analysis. In addition, a qualitative study of the results of\ndifferent experiments was conducted.", "AI": {"tldr": "The paper explores paired and unpaired image-to-image translation using GANs, evaluating performance with quantitative metrics and qualitative analysis.", "motivation": "To advance image translation research by studying both paired and unpaired methods, leveraging GANs for domain transformation.", "method": "Used conditional GAN for paired translation and cycle consistency loss for unpaired translation, experimenting with loss functions, Patch-GAN sizes, and architectures.", "result": "Evaluated results using precision, recall, FID score, and qualitative analysis.", "conclusion": "Demonstrates effectiveness of GAN-based approaches for image translation, with insights from quantitative and qualitative evaluations."}}
{"id": "2505.16135", "pdf": "https://arxiv.org/pdf/2505.16135", "abs": "https://arxiv.org/abs/2505.16135", "authors": ["Jeffrey Seely", "Yuki Imajuku", "Tianyu Zhao", "Edoardo Cetin", "Llion Jones"], "title": "Sudoku-Bench: Evaluating creative reasoning with Sudoku variants", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Existing reasoning benchmarks for large language models (LLMs) frequently\nfail to capture authentic creativity, often rewarding memorization of\npreviously observed patterns. We address this shortcoming with Sudoku-Bench, a\ncurated benchmark of challenging and unconventional Sudoku variants\nspecifically selected to evaluate creative, multi-step logical reasoning.\nSudoku variants form an unusually effective domain for reasoning research: each\npuzzle introduces unique or subtly interacting constraints, making memorization\ninfeasible and requiring solvers to identify novel logical breakthroughs\n(``break-ins''). Despite their diversity, Sudoku variants maintain a common and\ncompact structure, enabling clear and consistent evaluation. Sudoku-Bench\nincludes a carefully chosen puzzle set, a standardized text-based puzzle\nrepresentation, and flexible tools compatible with thousands of publicly\navailable puzzles -- making it easy to extend into a general research\nenvironment. Baseline experiments show that state-of-the-art LLMs solve fewer\nthan 15\\% of puzzles unaided, highlighting significant opportunities to advance\nlong-horizon, strategic reasoning capabilities.", "AI": {"tldr": "Sudoku-Bench is a benchmark for evaluating creative, multi-step reasoning in LLMs using unconventional Sudoku variants, where memorization is ineffective.", "motivation": "Existing reasoning benchmarks for LLMs often reward memorization, failing to assess authentic creativity and novel logical reasoning.", "method": "Sudoku-Bench uses challenging Sudoku variants with unique constraints, requiring solvers to identify novel logical breakthroughs (\"break-ins\"). It includes a curated puzzle set, standardized representation, and flexible tools.", "result": "State-of-the-art LLMs solve fewer than 15% of puzzles unaided, indicating room for improvement in long-horizon reasoning.", "conclusion": "Sudoku-Bench effectively evaluates creative reasoning in LLMs and highlights opportunities for advancing strategic reasoning capabilities."}}
{"id": "2505.16066", "pdf": "https://arxiv.org/pdf/2505.16066", "abs": "https://arxiv.org/abs/2505.16066", "authors": ["Zhixu Silvia Tao", "Kasper Vinken", "Hao-Wei Yeh", "Avi Cooper", "Xavier Boix"], "title": "Merge to Mix: Mixing Datasets via Model Merging", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Mixing datasets for fine-tuning large models (LMs) has become critical for\nmaximizing performance on downstream tasks. However, composing effective\ndataset mixtures typically relies on heuristics and trial-and-error, often\nrequiring multiple fine-tuning runs to achieve the desired outcome. We propose\na novel method, $\\textit{Merge to Mix}$, that accelerates composing dataset\nmixtures through model merging. Model merging is a recent technique that\ncombines the abilities of multiple individually fine-tuned LMs into a single LM\nby using a few simple arithmetic operations. Our key insight is that merging\nmodels individually fine-tuned on each dataset in a mixture can effectively\nserve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix\nleverages this insight to accelerate selecting dataset mixtures without\nrequiring full fine-tuning on each candidate mixture. Our experiments\ndemonstrate that Merge to Mix surpasses state-of-the-art methods in dataset\nselection for fine-tuning LMs.", "AI": {"tldr": "Merge to Mix accelerates dataset mixture selection for fine-tuning LMs by using model merging as a surrogate for full fine-tuning.", "motivation": "Current methods for composing dataset mixtures rely on heuristics and trial-and-error, requiring multiple fine-tuning runs, which is inefficient.", "method": "Proposes Merge to Mix, which uses model merging (combining individually fine-tuned LMs) to simulate the effect of fine-tuning on a dataset mixture.", "result": "Merge to Mix outperforms state-of-the-art methods in dataset selection for fine-tuning LMs.", "conclusion": "Merge to Mix offers an efficient alternative to traditional trial-and-error methods for dataset mixture selection."}}
{"id": "2505.15970", "pdf": "https://arxiv.org/pdf/2505.15970", "abs": "https://arxiv.org/abs/2505.15970", "authors": ["Matthew Lyle Olson", "Musashi Hinck", "Neale Ratzlaff", "Changbai Li", "Phillip Howard", "Vasudev Lal", "Shao-Yen Tseng"], "title": "Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders", "categories": ["cs.CV", "cs.LG"], "comment": "(Oral) CVPR 2025 Workshop on Mechanistic Interpretability for Vision.\n  Authors 1 and 2 contributed equally", "summary": "The ImageNet hierarchy provides a structured taxonomy of object categories,\noffering a valuable lens through which to analyze the representations learned\nby deep vision models. In this work, we conduct a comprehensive analysis of how\nvision models encode the ImageNet hierarchy, leveraging Sparse Autoencoders\n(SAEs) to probe their internal representations. SAEs have been widely used as\nan explanation tool for large language models (LLMs), where they enable the\ndiscovery of semantically meaningful features. Here, we extend their use to\nvision models to investigate whether learned representations align with the\nontological structure defined by the ImageNet taxonomy. Our results show that\nSAEs uncover hierarchical relationships in model activations, revealing an\nimplicit encoding of taxonomic structure. We analyze the consistency of these\nrepresentations across different layers of the popular vision foundation model\nDINOv2 and provide insights into how deep vision models internalize\nhierarchical category information by increasing information in the class token\nthrough each layer. Our study establishes a framework for systematic\nhierarchical analysis of vision model representations and highlights the\npotential of SAEs as a tool for probing semantic structure in deep networks.", "AI": {"tldr": "SAEs reveal hierarchical relationships in vision model activations, aligning with ImageNet taxonomy, and show how DINOv2 layers internalize hierarchical info.", "motivation": "To analyze how vision models encode the ImageNet hierarchy using SAEs, extending their use from LLMs to vision models.", "method": "Leverage Sparse Autoencoders (SAEs) to probe internal representations of vision models, focusing on DINOv2.", "result": "SAEs uncover implicit hierarchical relationships in model activations, showing alignment with ImageNet taxonomy.", "conclusion": "SAEs are effective for probing hierarchical semantic structure in vision models, offering a systematic analysis framework."}}
{"id": "2502.15814", "pdf": "https://arxiv.org/pdf/2502.15814", "abs": "https://arxiv.org/abs/2502.15814", "authors": ["Gallil Maimon", "Avishai Elmakies", "Yossi Adi"], "title": "Slamming: Training a Speech Language Model on One GPU in a Day", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SD", "eess.AS"], "comment": "ACL 2025 (Findings)", "summary": "We introduce Slam, a recipe for training high-quality Speech Language Models\n(SLMs) on a single academic GPU in 24 hours. We do so through empirical\nanalysis of model initialisation and architecture, synthetic training data,\npreference optimisation with synthetic data and tweaking all other components.\nWe empirically demonstrate that this training recipe also scales well with more\ncompute getting results on par with leading SLMs in a fraction of the compute\ncost. We hope these insights will make SLM training and research more\naccessible. In the context of SLM scaling laws, our results far outperform\npredicted compute optimal performance, giving an optimistic view to SLM\nfeasibility. See code, data, models, samples at -\nhttps://pages.cs.huji.ac.il/adiyoss-lab/slamming .", "AI": {"tldr": "Slam is a method to train high-quality Speech Language Models (SLMs) efficiently on a single academic GPU in 24 hours, achieving results comparable to leading SLMs at lower compute costs.", "motivation": "To make SLM training and research more accessible by reducing compute requirements while maintaining high performance.", "method": "Empirical analysis of model initialization, architecture, synthetic training data, preference optimization, and component tweaking.", "result": "Outperforms predicted compute optimal performance, scaling well with more compute and matching leading SLMs.", "conclusion": "Slam offers an optimistic view of SLM feasibility, making training more accessible and efficient."}}
{"id": "2505.16061", "pdf": "https://arxiv.org/pdf/2505.16061", "abs": "https://arxiv.org/abs/2505.16061", "authors": ["Yu Zhang"], "title": "Internal and External Impacts of Natural Language Processing Papers", "categories": ["cs.CL", "cs.DL"], "comment": "7 pages; Accepted to ACL 2025", "summary": "We investigate the impacts of NLP research published in top-tier conferences\n(i.e., ACL, EMNLP, and NAACL) from 1979 to 2024. By analyzing citations from\nresearch articles and external sources such as patents, media, and policy\ndocuments, we examine how different NLP topics are consumed both within the\nacademic community and by the broader public. Our findings reveal that language\nmodeling has the widest internal and external influence, while linguistic\nfoundations have lower impacts. We also observe that internal and external\nimpacts generally align, but topics like ethics, bias, and fairness show\nsignificant attention in policy documents with much fewer academic citations.\nAdditionally, external domains exhibit distinct preferences, with patents\nfocusing on practical NLP applications and media and policy documents engaging\nmore with the societal implications of NLP models.", "AI": {"tldr": "Analysis of NLP research impacts from 1979-2024 shows language modeling has the widest influence, while linguistic foundations lag. External and internal impacts align, except for ethics/bias/fairness, which are policy-heavy.", "motivation": "To understand how NLP research from top conferences (ACL, EMNLP, NAACL) is consumed academically and publicly.", "method": "Analyzed citations from research articles, patents, media, and policy documents (1979-2024).", "result": "Language modeling is most influential; ethics/bias/fairness gain policy attention but fewer academic citations. Patents favor practical NLP, while media/policy focus on societal impacts.", "conclusion": "NLP research impacts vary by topic and audience, with language modeling dominating and societal issues gaining external traction."}}
{"id": "2505.16212", "pdf": "https://arxiv.org/pdf/2505.16212", "abs": "https://arxiv.org/abs/2505.16212", "authors": ["Anfeng Xu", "Tiantian Feng", "So Hyun Kim", "Somer Bishop", "Catherine Lord", "Shrikanth Narayanan"], "title": "Large Language Models based ASR Error Correction for Child Conversations", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Automatic Speech Recognition (ASR) has recently shown remarkable progress,\nbut accurately transcribing children's speech remains a significant challenge.\nRecent developments in Large Language Models (LLMs) have shown promise in\nimproving ASR transcriptions. However, their applications in child speech\nincluding conversational scenarios are underexplored. In this study, we explore\nthe use of LLMs in correcting ASR errors for conversational child speech. We\ndemonstrate the promises and challenges of LLMs through experiments on two\nchildren's conversational speech datasets with both zero-shot and fine-tuned\nASR outputs. We find that while LLMs are helpful in correcting zero-shot ASR\noutputs and fine-tuned CTC-based ASR outputs, it remains challenging for LLMs\nto improve ASR performance when incorporating contextual information or when\nusing fine-tuned autoregressive ASR (e.g., Whisper) outputs.", "AI": {"tldr": "LLMs show promise in correcting ASR errors for child speech but struggle with contextual info and autoregressive ASR outputs.", "motivation": "Improving ASR accuracy for children's conversational speech, which remains a challenge despite recent ASR advancements.", "method": "Experiments on two children's conversational speech datasets using zero-shot and fine-tuned ASR outputs with LLMs.", "result": "LLMs improve zero-shot and CTC-based ASR outputs but not autoregressive ASR or contextual scenarios.", "conclusion": "LLMs are promising for child speech ASR correction but face limitations with autoregressive models and context integration."}}
{"id": "2505.16318", "pdf": "https://arxiv.org/pdf/2505.16318", "abs": "https://arxiv.org/abs/2505.16318", "authors": ["Hossein Khalili", "Seongbin Park", "Venkat Bollapragada", "Nader Sehatbakhsh"], "title": "SuperPure: Efficient Purification of Localized and Distributed Adversarial Patches via Super-Resolution GAN Models", "categories": ["cs.CV", "cs.CR", "eess.IV"], "comment": null, "summary": "As vision-based machine learning models are increasingly integrated into\nautonomous and cyber-physical systems, concerns about (physical) adversarial\npatch attacks are growing. While state-of-the-art defenses can achieve\ncertified robustness with minimal impact on utility against highly-concentrated\nlocalized patch attacks, they fall short in two important areas: (i)\nState-of-the-art methods are vulnerable to low-noise distributed patches where\nperturbations are subtly dispersed to evade detection or masking, as shown\nrecently by the DorPatch attack; (ii) Achieving high robustness with\nstate-of-the-art methods is extremely time and resource-consuming, rendering\nthem impractical for latency-sensitive applications in many cyber-physical\nsystems.\n  To address both robustness and latency issues, this paper proposes a new\ndefense strategy for adversarial patch attacks called SuperPure. The key\nnovelty is developing a pixel-wise masking scheme that is robust against both\ndistributed and localized patches. The masking involves leveraging a GAN-based\nsuper-resolution scheme to gradually purify the image from adversarial patches.\nOur extensive evaluations using ImageNet and two standard classifiers, ResNet\nand EfficientNet, show that SuperPure advances the state-of-the-art in three\nmajor directions: (i) it improves the robustness against conventional localized\npatches by more than 20%, on average, while also improving top-1 clean accuracy\nby almost 10%; (ii) It achieves 58% robustness against distributed patch\nattacks (as opposed to 0% in state-of-the-art method, PatchCleanser); (iii) It\ndecreases the defense end-to-end latency by over 98% compared to PatchCleanser.\nOur further analysis shows that SuperPure is robust against white-box attacks\nand different patch sizes. Our code is open-source.", "AI": {"tldr": "SuperPure is a new defense strategy for adversarial patch attacks, improving robustness and reducing latency compared to state-of-the-art methods.", "motivation": "Address vulnerabilities in current defenses against distributed and localized adversarial patches, and reduce impractical resource consumption.", "method": "Uses a pixel-wise masking scheme with GAN-based super-resolution to purify images from adversarial patches.", "result": "Improves robustness by 20% against localized patches, achieves 58% robustness against distributed patches, and reduces latency by 98%.", "conclusion": "SuperPure is effective, efficient, and robust against various attack types, making it suitable for latency-sensitive applications."}}
{"id": "2505.16147", "pdf": "https://arxiv.org/pdf/2505.16147", "abs": "https://arxiv.org/abs/2505.16147", "authors": ["Le Ma", "Shirao Yang", "Zihao Wang", "Yinggui Wang", "Lei Wang", "Tao Wei", "Kejun Zhang"], "title": "Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The proliferation of large models has intensified the need for efficient data\nvaluation methods to quantify the contribution of individual data providers.\nTraditional approaches, such as game-theory-based Shapley value and\ninfluence-function-based techniques, face prohibitive computational costs or\nrequire access to full data and model training details, making them hardly\nachieve partial data valuation. To address this, we propose Unlearning Shapley,\na novel framework that leverages machine unlearning to estimate data values\nefficiently. By unlearning target data from a pretrained model and measuring\nperformance shifts on a reachable test set, our method computes Shapley values\nvia Monte Carlo sampling, avoiding retraining and eliminating dependence on\nfull data. Crucially, Unlearning Shapley supports both full and partial data\nvaluation, making it scalable for large models (e.g., LLMs) and practical for\ndata markets. Experiments on benchmark datasets and large-scale text corpora\ndemonstrate that our approach matches the accuracy of state-of-the-art methods\nwhile reducing computational overhead by orders of magnitude. Further analysis\nconfirms a strong correlation between estimated values and the true impact of\ndata subsets, validating its reliability in real-world scenarios. This work\nbridges the gap between data valuation theory and practical deployment,\noffering a scalable, privacy-compliant solution for modern AI ecosystems.", "AI": {"tldr": "Proposes Unlearning Shapley, a framework using machine unlearning to efficiently compute data values via performance shifts, avoiding retraining and full data access.", "motivation": "Addresses the inefficiency and impracticality of traditional data valuation methods (e.g., Shapley value, influence functions) for large models and partial data.", "method": "Leverages machine unlearning to estimate Shapley values by measuring performance shifts on a test set after unlearning target data, using Monte Carlo sampling.", "result": "Matches state-of-the-art accuracy while significantly reducing computational costs, validated on benchmark datasets and large text corpora.", "conclusion": "Provides a scalable, privacy-compliant solution for data valuation, bridging theory and practical deployment in AI ecosystems."}}
{"id": "2505.16074", "pdf": "https://arxiv.org/pdf/2505.16074", "abs": "https://arxiv.org/abs/2505.16074", "authors": ["Bart Kosko", "Olaoluwa Adigun"], "title": "Bidirectional Variational Autoencoders", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "10 pages, 6 figures", "summary": "We present the new bidirectional variational autoencoder (BVAE) network\narchitecture. The BVAE uses a single neural network both to encode and decode\ninstead of an encoder-decoder network pair. The network encodes in the forward\ndirection and decodes in the backward direction through the same synaptic web.\nSimulations compared BVAEs and ordinary VAEs on the four image tasks of image\nreconstruction, classification, interpolation, and generation. The image\ndatasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and\nCelebA-64 face images. The bidirectional structure of BVAEs cut the parameter\ncount by almost 50% and still slightly outperformed the unidirectional VAEs.", "AI": {"tldr": "Bidirectional VAE (BVAE) uses a single network for encoding and decoding, reducing parameters by 50% while outperforming traditional VAEs on image tasks.", "motivation": "To simplify VAE architecture by using a single bidirectional network instead of separate encoder-decoder pairs, aiming for efficiency without performance loss.", "method": "BVAE employs a single neural network for both encoding (forward pass) and decoding (backward pass), tested on MNIST, Fashion-MNIST, CIFAR-10, and CelebA-64 datasets for tasks like reconstruction, classification, interpolation, and generation.", "result": "BVAE reduced parameters by nearly 50% and slightly outperformed traditional VAEs in performance.", "conclusion": "BVAE offers a more efficient and effective alternative to traditional VAEs for image-related tasks."}}
{"id": "2505.16001", "pdf": "https://arxiv.org/pdf/2505.16001", "abs": "https://arxiv.org/abs/2505.16001", "authors": ["Qiang Zhu", "Kuan Lu", "Menghao Huo", "Yuxiao Li"], "title": "Image-to-Image Translation with Diffusion Transformers and CLIP-Based Image Conditioning", "categories": ["cs.CV"], "comment": null, "summary": "Image-to-image translation aims to learn a mapping between a source and a\ntarget domain, enabling tasks such as style transfer, appearance\ntransformation, and domain adaptation. In this work, we explore a\ndiffusion-based framework for image-to-image translation by adapting Diffusion\nTransformers (DiT), which combine the denoising capabilities of diffusion\nmodels with the global modeling power of transformers. To guide the translation\nprocess, we condition the model on image embeddings extracted from a\npre-trained CLIP encoder, allowing for fine-grained and structurally consistent\ntranslations without relying on text or class labels. We incorporate both a\nCLIP similarity loss to enforce semantic consistency and an LPIPS perceptual\nloss to enhance visual fidelity during training. We validate our approach on\ntwo benchmark datasets: face2comics, which translates real human faces to\ncomic-style illustrations, and edges2shoes, which translates edge maps to\nrealistic shoe images. Experimental results demonstrate that DiT, combined with\nCLIP-based conditioning and perceptual similarity objectives, achieves\nhigh-quality, semantically faithful translations, offering a promising\nalternative to GAN-based models for paired image-to-image translation tasks.", "AI": {"tldr": "A diffusion-based framework using Diffusion Transformers (DiT) for image-to-image translation, leveraging CLIP embeddings for fine-grained control and achieving high-quality results on benchmark datasets.", "motivation": "To explore an alternative to GAN-based models for image-to-image translation by combining diffusion models' denoising capabilities with transformers' global modeling power.", "method": "Adapts DiT for translation, conditions on CLIP image embeddings, and uses CLIP similarity and LPIPS perceptual losses for training.", "result": "Achieves high-quality, semantically faithful translations on face2comics and edges2shoes datasets.", "conclusion": "DiT with CLIP-based conditioning offers a promising alternative to GANs for paired image-to-image translation."}}
{"id": "2504.07053", "pdf": "https://arxiv.org/pdf/2504.07053", "abs": "https://arxiv.org/abs/2504.07053", "authors": ["Liang-Hsuan Tseng", "Yi-Chang Chen", "Kuan-Yi Lee", "Da-Shan Shiu", "Hung-yi Lee"], "title": "TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Preprint", "summary": "Recent efforts target spoken language models (SLMs) that not only listen but\nalso speak for more natural human-LLM interaction. Joint speech-text modeling\nis a promising direction to achieve this. However, the effectiveness of recent\nspeech tokens for joint modeling remains underexplored. To address this, we\nintroduce Text-Aligned Speech Tokenization and Embedding (TASTE), a method that\ndirectly addresses the modality gap by aligning speech token with the\ncorresponding text transcription during the tokenization stage. We propose a\nmethod that can achieve this through a attention-based aggregation mechanism\nand with speech reconstruction as the training objective. We conduct extensive\nexperiments and show that TASTE can preserve essential paralinguistic\ninformation while dramatically reducing the token sequence length. With TASTE,\nwe perform straightforward joint spoken language modeling by using Low-Rank\nAdaptation on the pre-trained text LLM. Experimental results show that\nTASTE-based SLMs perform comparable to previous work on SALMON and StoryCloze;\nwhile significantly outperform other pre-trained SLMs on speech continuation\nacross subjective and objective evaluations. To our knowledge, TASTE is the\nfirst end-to-end approach that utilizes a reconstruction objective to\nautomatically learn a text-aligned speech tokenization and embedding suitable\nfor spoken language modeling. Our demo, code, and model are available at\nhttps://mtkresearch.github.io/TASTE-SpokenLM.github.io.", "AI": {"tldr": "TASTE introduces text-aligned speech tokenization and embedding to bridge the modality gap between speech and text, improving spoken language modeling.", "motivation": "To enhance human-LLM interaction by addressing the underexplored effectiveness of speech tokens in joint speech-text modeling.", "method": "Uses attention-based aggregation and speech reconstruction to align speech tokens with text transcriptions.", "result": "TASTE reduces token sequence length while preserving paralinguistic info, outperforming other SLMs in speech continuation tasks.", "conclusion": "TASTE is the first end-to-end method for text-aligned speech tokenization, offering improved performance in spoken language modeling."}}
{"id": "2505.16078", "pdf": "https://arxiv.org/pdf/2505.16078", "abs": "https://arxiv.org/abs/2505.16078", "authors": ["Lujun Li", "Lama Sleem", "Niccolo' Gentile", "Geoffrey Nichil", "Radu State"], "title": "Small Language Models in the Real World: Insights from Industrial Text Classification", "categories": ["cs.CL"], "comment": null, "summary": "With the emergence of ChatGPT, Transformer models have significantly advanced\ntext classification and related tasks. Decoder-only models such as Llama\nexhibit strong performance and flexibility, yet they suffer from inefficiency\non inference due to token-by-token generation, and their effectiveness in text\nclassification tasks heavily depends on prompt quality. Moreover, their\nsubstantial GPU resource requirements often limit widespread adoption. Thus,\nthe question of whether smaller language models are capable of effectively\nhandling text classification tasks emerges as a topic of significant interest.\nHowever, the selection of appropriate models and methodologies remains largely\nunderexplored. In this paper, we conduct a comprehensive evaluation of prompt\nengineering and supervised fine-tuning methods for transformer-based text\nclassification. Specifically, we focus on practical industrial scenarios,\nincluding email classification, legal document categorization, and the\nclassification of extremely long academic texts. We examine the strengths and\nlimitations of smaller models, with particular attention to both their\nperformance and their efficiency in Video Random-Access Memory (VRAM)\nutilization, thereby providing valuable insights for the local deployment and\napplication of compact models in industrial settings.", "AI": {"tldr": "The paper evaluates prompt engineering and supervised fine-tuning for transformer-based text classification, focusing on smaller models' performance and efficiency in industrial scenarios.", "motivation": "The inefficiency and resource demands of large decoder-only models like Llama prompt exploration of smaller models for text classification tasks.", "method": "Comprehensive evaluation of prompt engineering and supervised fine-tuning methods, tested on email, legal document, and long academic text classification.", "result": "Examines smaller models' performance and VRAM efficiency, offering insights for local deployment in industrial settings.", "conclusion": "Smaller models can effectively handle text classification tasks, with practical implications for industrial applications."}}
{"id": "2505.16406", "pdf": "https://arxiv.org/pdf/2505.16406", "abs": "https://arxiv.org/abs/2505.16406", "authors": ["Gaofei Shen", "Hosein Mohebbi", "Arianna Bisazza", "Afra Alishahi", "Grzegorz Chrupa\u0142a"], "title": "On the reliability of feature attribution methods for speech classification", "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "As the capabilities of large-scale pre-trained models evolve, understanding\nthe determinants of their outputs becomes more important. Feature attribution\naims to reveal which parts of the input elements contribute the most to model\noutputs. In speech processing, the unique characteristics of the input signal\nmake the application of feature attribution methods challenging. We study how\nfactors such as input type and aggregation and perturbation timespan impact the\nreliability of standard feature attribution methods, and how these factors\ninteract with characteristics of each classification task. We find that\nstandard approaches to feature attribution are generally unreliable when\napplied to the speech domain, with the exception of word-aligned perturbation\nmethods when applied to word-based classification tasks.", "AI": {"tldr": "Standard feature attribution methods are unreliable in speech processing, except for word-aligned perturbation in word-based tasks.", "motivation": "Understanding the determinants of outputs from large-scale pre-trained models, especially in speech processing, where input characteristics complicate feature attribution.", "method": "Study the impact of input type, aggregation, perturbation timespan, and task characteristics on the reliability of feature attribution methods.", "result": "Standard feature attribution methods are generally unreliable in speech, except for word-aligned perturbation in word-based tasks.", "conclusion": "Feature attribution in speech requires task-specific methods, with word-aligned perturbation being effective for word-based tasks."}}
{"id": "2505.16412", "pdf": "https://arxiv.org/pdf/2505.16412", "abs": "https://arxiv.org/abs/2505.16412", "authors": ["Nikolay Stanishev", "Yuhang Lu", "Touradj Ebrahimi"], "title": "Pose-invariant face recognition via feature-space pose frontalization", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Pose-invariant face recognition has become a challenging problem for modern\nAI-based face recognition systems. It aims at matching a profile face captured\nin the wild with a frontal face registered in a database. Existing methods\nperform face frontalization via either generative models or learning a pose\nrobust feature representation. In this paper, a new method is presented to\nperform face frontalization and recognition within the feature space. First, a\nnovel feature space pose frontalization module (FSPFM) is proposed to transform\nprofile images with arbitrary angles into frontal counterparts. Second, a new\ntraining paradigm is proposed to maximize the potential of FSPFM and boost its\nperformance. The latter consists of a pre-training and an attention-guided\nfine-tuning stage. Moreover, extensive experiments have been conducted on five\npopular face recognition benchmarks. Results show that not only our method\noutperforms the state-of-the-art in the pose-invariant face recognition task\nbut also maintains superior performance in other standard scenarios.", "AI": {"tldr": "A new method for pose-invariant face recognition using feature space pose frontalization (FSPFM) and a novel training paradigm outperforms state-of-the-art methods.", "motivation": "Pose-invariant face recognition is challenging for AI systems, especially matching profile faces with frontal ones in databases. Existing methods rely on generative models or pose-robust features, which may have limitations.", "method": "Proposes a feature space pose frontalization module (FSPFM) to transform profile images into frontal ones. Introduces a two-stage training paradigm (pre-training and attention-guided fine-tuning) to enhance FSPFM's performance.", "result": "Extensive experiments on five benchmarks show the method outperforms state-of-the-art in pose-invariant recognition and excels in standard scenarios.", "conclusion": "The proposed FSPFM and training paradigm effectively address pose-invariant face recognition, achieving superior performance across diverse scenarios."}}
{"id": "2505.16176", "pdf": "https://arxiv.org/pdf/2505.16176", "abs": "https://arxiv.org/abs/2505.16176", "authors": ["Jun Rao", "Xuebo Liu", "Hexuan Deng", "Zepeng Lin", "Zixiong Yu", "Jiansheng Wei", "Xiaojun Meng", "Min Zhang"], "title": "Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "In the realm of data selection for reasoning tasks, existing approaches\npredominantly rely on externally predefined static metrics such as difficulty\nand diversity, which are often designed for supervised fine-tuning (SFT) and\nlack adaptability to continuous training processes. A critical limitation of\nthese methods is their inability to dynamically align with the evolving\ncapabilities of models during online training, a gap that becomes increasingly\npronounced with the rise of dynamic training paradigms and online reinforcement\nlearning (RL) frameworks (e.g., R1 models). To address this, we introduce\nSAI-DPO, an algorithm that dynamically selects training data by continuously\nassessing a model's stage-specific reasoning abilities across different\ntraining phases. By integrating real-time model performance feedback, SAI-DPO\nadaptively adapts data selection to the evolving strengths and weaknesses of\nthe model, thus enhancing both data utilization efficiency and final task\nperformance. Extensive experiments on three state-of-the-art models and eight\nmathematical reasoning benchmarks, including challenging competition-level\ndatasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average\nperformance boost of up to 21.3 percentage points, with particularly notable\nimprovements of 10 and 15 points on AIME24 and AMC23, respectively. These\nresults highlight the superiority of dynamic, model-adaptive data selection\nover static, externally defined strategies in advancing reasoning.", "AI": {"tldr": "SAI-DPO is a dynamic data selection algorithm for reasoning tasks, outperforming static methods by adapting to model capabilities during training, achieving up to 21.3% performance gains.", "motivation": "Existing static data selection methods lack adaptability to evolving model capabilities, especially in dynamic training paradigms like online RL.", "method": "SAI-DPO dynamically selects training data by assessing model reasoning abilities in real-time, aligning with evolving strengths and weaknesses.", "result": "SAI-DPO boosts performance by up to 21.3%, with notable gains of 10 and 15 points on AIME24 and AMC23 benchmarks.", "conclusion": "Dynamic, model-adaptive data selection (SAI-DPO) is superior to static strategies for advancing reasoning tasks."}}
{"id": "2505.16077", "pdf": "https://arxiv.org/pdf/2505.16077", "abs": "https://arxiv.org/abs/2505.16077", "authors": ["Soham Gadgil", "Chris Lin", "Su-In Lee"], "title": "Ensembling Sparse Autoencoders", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Sparse autoencoders (SAEs) are used to decompose neural network activations\ninto human-interpretable features. Typically, features learned by a single SAE\nare used for downstream applications. However, it has recently been shown that\nSAEs trained with different initial weights can learn different features,\ndemonstrating that a single SAE captures only a limited subset of features that\ncan be extracted from the activation space. Motivated by this limitation, we\npropose to ensemble multiple SAEs through naive bagging and boosting.\nSpecifically, SAEs trained with different weight initializations are ensembled\nin naive bagging, whereas SAEs sequentially trained to minimize the residual\nerror are ensembled in boosting. We evaluate our ensemble approaches with three\nsettings of language models and SAE architectures. Our empirical results\ndemonstrate that ensembling SAEs can improve the reconstruction of language\nmodel activations, diversity of features, and SAE stability. Furthermore,\nensembling SAEs performs better than applying a single SAE on downstream tasks\nsuch as concept detection and spurious correlation removal, showing improved\npractical utility.", "AI": {"tldr": "Ensembling sparse autoencoders (SAEs) improves feature diversity, reconstruction, and downstream task performance compared to single SAEs.", "motivation": "Single SAEs capture only a subset of features from neural network activations, motivating the use of ensembles to enhance feature extraction.", "method": "Proposes ensembling SAEs via naive bagging (different initial weights) and boosting (sequential training to minimize residual error).", "result": "Ensembling improves reconstruction, feature diversity, stability, and outperforms single SAEs in tasks like concept detection and spurious correlation removal.", "conclusion": "Ensembling SAEs enhances practical utility and feature extraction capabilities."}}
{"id": "2505.16007", "pdf": "https://arxiv.org/pdf/2505.16007", "abs": "https://arxiv.org/abs/2505.16007", "authors": ["Jinjin Gu"], "title": "Position: Agentic Systems Constitute a Key Component of Next-Generation Intelligent Image Processing", "categories": ["cs.CV"], "comment": null, "summary": "This position paper argues that the image processing community should broaden\nits focus from purely model-centric development to include agentic system\ndesign as an essential complementary paradigm. While deep learning has\nsignificantly advanced capabilities for specific image processing tasks,\ncurrent approaches face critical limitations in generalization, adaptability,\nand real-world problem-solving flexibility. We propose that developing\nintelligent agentic systems, capable of dynamically selecting, combining, and\noptimizing existing image processing tools, represents the next evolutionary\nstep for the field. Such systems would emulate human experts' ability to\nstrategically orchestrate different tools to solve complex problems, overcoming\nthe brittleness of monolithic models. The paper analyzes key limitations of\nmodel-centric paradigms, establishes design principles for agentic image\nprocessing systems, and outlines different capability levels for such agents.", "AI": {"tldr": "The paper advocates for shifting focus from model-centric to agentic system design in image processing to improve generalization and adaptability.", "motivation": "Current deep learning approaches in image processing lack generalization, adaptability, and real-world flexibility, necessitating a new paradigm.", "method": "Proposes developing intelligent agentic systems that dynamically select and optimize image processing tools, mimicking human expert strategies.", "result": "Identifies limitations of model-centric paradigms and outlines design principles and capability levels for agentic systems.", "conclusion": "Agentic systems represent the next evolutionary step for image processing, addressing brittleness in monolithic models."}}
{"id": "2505.13830", "pdf": "https://arxiv.org/pdf/2505.13830", "abs": "https://arxiv.org/abs/2505.13830", "authors": ["Ye-Xin Lu", "Hui-Peng Du", "Fei Liu", "Yang Ai", "Zhen-Hua Ling"], "title": "Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by Interspeech 2025", "summary": "Large language model (LLM) based zero-shot text-to-speech (TTS) methods tend\nto preserve the acoustic environment of the audio prompt, leading to\ndegradation in synthesized speech quality when the audio prompt contains noise.\nIn this paper, we propose a novel neural codec-based speech denoiser and\nintegrate it with the advanced LLM-based TTS model, LauraTTS, to achieve\nnoise-robust zero-shot TTS. The proposed codec denoiser consists of an audio\ncodec, a token denoiser, and an embedding refiner. The token denoiser predicts\nthe first two groups of clean acoustic tokens from the noisy ones, which can\nserve as the acoustic prompt for LauraTTS to synthesize high-quality\npersonalized speech or be converted to clean speech waveforms through the\nembedding refiner and codec decoder. Experimental results show that our\nproposed codec denoiser outperforms state-of-the-art speech enhancement (SE)\nmethods, and the proposed noise-robust LauraTTS surpasses the approach using\nadditional SE models.", "AI": {"tldr": "A neural codec-based speech denoiser is integrated with LauraTTS to improve zero-shot TTS by addressing noise in audio prompts.", "motivation": "LLM-based zero-shot TTS methods degrade in quality when audio prompts contain noise.", "method": "Proposes a codec denoiser with an audio codec, token denoiser, and embedding refiner to clean noisy acoustic tokens.", "result": "Outperforms state-of-the-art SE methods and enhances LauraTTS performance.", "conclusion": "The integrated system achieves noise-robust zero-shot TTS, surpassing methods using additional SE models."}}
{"id": "2505.16081", "pdf": "https://arxiv.org/pdf/2505.16081", "abs": "https://arxiv.org/abs/2505.16081", "authors": ["KMA Solaiman"], "title": "BiasLab: Toward Explainable Political Bias Detection with Dual-Axis Annotations and Rationale Indicators", "categories": ["cs.CL"], "comment": "Under review", "summary": "We present BiasLab, a dataset of 300 political news articles annotated for\nperceived ideological bias. These articles were selected from a curated\n900-document pool covering diverse political events and source biases. Each\narticle is labeled by crowdworkers along two independent scales, assessing\nsentiment toward the Democratic and Republican parties, and enriched with\nrationale indicators. The annotation pipeline incorporates targeted worker\nqualification and was refined through pilot-phase analysis. We quantify\ninter-annotator agreement, analyze misalignment with source-level outlet bias,\nand organize the resulting labels into interpretable subsets. Additionally, we\nsimulate annotation using schema-constrained GPT-4o, enabling direct comparison\nto human labels and revealing mirrored asymmetries, especially in\nmisclassifying subtly right-leaning content. We define two modeling tasks:\nperception drift prediction and rationale type classification, and report\nbaseline performance to illustrate the challenge of explainable bias detection.\nBiasLab's rich rationale annotations provide actionable interpretations that\nfacilitate explainable modeling of political bias, supporting the development\nof transparent, socially aware NLP systems. We release the dataset, annotation\nschema, and modeling code to encourage research on human-in-the-loop\ninterpretability and the evaluation of explanation effectiveness in real-world\nsettings.", "AI": {"tldr": "BiasLab is a dataset of 300 political news articles annotated for ideological bias, with labels for sentiment toward Democrats and Republicans, and rationale indicators. It includes human and GPT-4o annotations, tasks for perception drift and rationale classification, and aims to support explainable bias detection in NLP.", "motivation": "To create a dataset for studying perceived ideological bias in political news, enabling explainable modeling and transparent NLP systems.", "method": "Articles were annotated by crowdworkers and GPT-4o, with inter-annotator agreement analyzed. Tasks include perception drift prediction and rationale classification.", "result": "The dataset reveals asymmetries in bias perception, especially for subtly right-leaning content, and provides baseline performance for modeling tasks.", "conclusion": "BiasLab supports research on explainable bias detection and human-in-the-loop interpretability, with released data and tools for further study."}}
{"id": "2505.16650", "pdf": "https://arxiv.org/pdf/2505.16650", "abs": "https://arxiv.org/abs/2505.16650", "authors": ["Michael Neri", "Sara Baldoni"], "title": "Unsupervised Network Anomaly Detection with Autoencoders and Traffic Images", "categories": ["cs.CV", "cs.CR", "eess.IV", "eess.SP"], "comment": "Accepted for publication in EUSIPCO 2025", "summary": "Due to the recent increase in the number of connected devices, the need to\npromptly detect security issues is emerging. Moreover, the high number of\ncommunication flows creates the necessity of processing huge amounts of data.\nFurthermore, the connected devices are heterogeneous in nature, having\ndifferent computational capacities. For this reason, in this work we propose an\nimage-based representation of network traffic which allows to realize a compact\nsummary of the current network conditions with 1-second time windows. The\nproposed representation highlights the presence of anomalies thus reducing the\nneed for complex processing architectures. Finally, we present an unsupervised\nlearning approach which effectively detects the presence of anomalies. The code\nand the dataset are available at\nhttps://github.com/michaelneri/image-based-network-traffic-anomaly-detection.", "AI": {"tldr": "The paper proposes an image-based representation of network traffic for anomaly detection, using 1-second time windows and an unsupervised learning approach.", "motivation": "The rise in connected devices and heterogeneous computational capacities necessitates efficient anomaly detection and data processing.", "method": "An image-based representation of network traffic is introduced to summarize conditions in 1-second windows, reducing complex processing needs. An unsupervised learning approach detects anomalies.", "result": "The method effectively highlights anomalies and simplifies processing.", "conclusion": "The proposed approach offers a compact and efficient solution for detecting network anomalies, with code and dataset publicly available."}}
{"id": "2505.16186", "pdf": "https://arxiv.org/pdf/2505.16186", "abs": "https://arxiv.org/abs/2505.16186", "authors": ["Kaiwen Zhou", "Xuandong Zhao", "Gaowen Liu", "Jayanth Srinivasa", "Aosong Feng", "Dawn Song", "Xin Eric Wang"], "title": "SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning", "categories": ["cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Large Reasoning Models (LRMs) introduce a new generation paradigm of\nexplicitly reasoning before answering, leading to remarkable improvements in\ncomplex tasks. However, they pose great safety risks against harmful queries\nand adversarial attacks. While recent mainstream safety efforts on LRMs,\nsupervised fine-tuning (SFT), improve safety performance, we find that\nSFT-aligned models struggle to generalize to unseen jailbreak prompts. After\nthorough investigation of LRMs' generation, we identify a safety aha moment\nthat can activate safety reasoning and lead to a safe response. This aha moment\ntypically appears in the `key sentence', which follows models' query\nunderstanding process and can indicate whether the model will proceed safely.\nBased on these insights, we propose SafeKey, including two complementary\nobjectives to better activate the safety aha moment in the key sentence: (1) a\nDual-Path Safety Head to enhance the safety signal in the model's internal\nrepresentations before the key sentence, and (2) a Query-Mask Modeling\nobjective to improve the models' attention on its query understanding, which\nhas important safety hints. Experiments across multiple safety benchmarks\ndemonstrate that our methods significantly improve safety generalization to a\nwide range of jailbreak attacks and out-of-distribution harmful prompts,\nlowering the average harmfulness rate by 9.6\\%, while maintaining general\nabilities. Our analysis reveals how SafeKey enhances safety by reshaping\ninternal attention and improving the quality of hidden representations.", "AI": {"tldr": "SafeKey improves safety in Large Reasoning Models (LRMs) by activating a 'safety aha moment' in key sentences, reducing harmfulness by 9.6% while maintaining general performance.", "motivation": "LRMs face safety risks from harmful queries and adversarial attacks. Current methods like supervised fine-tuning (SFT) fail to generalize to unseen jailbreak prompts.", "method": "Proposes SafeKey with two objectives: (1) Dual-Path Safety Head to enhance safety signals, and (2) Query-Mask Modeling to improve attention on query understanding.", "result": "SafeKey lowers harmfulness rate by 9.6% across benchmarks, improving safety generalization without compromising general abilities.", "conclusion": "SafeKey effectively reshapes internal attention and representations, enhancing LRM safety against diverse threats."}}
{"id": "2505.16083", "pdf": "https://arxiv.org/pdf/2505.16083", "abs": "https://arxiv.org/abs/2505.16083", "authors": ["Jiahuan Long", "Wenzhe Zhang", "Ning Wang", "Tingsong Jiang", "Wen Yao"], "title": "FR-Mamba: Time-Series Physical Field Reconstruction Based on State Space Model", "categories": ["cs.LG"], "comment": null, "summary": "Physical field reconstruction (PFR) aims to predict the state distribution of\nphysical quantities (e.g., velocity, pressure, and temperature) based on\nlimited sensor measurements. It plays a critical role in domains such as fluid\ndynamics and thermodynamics. However, existing deep learning methods often fail\nto capture long-range temporal dependencies, resulting in suboptimal\nperformance on time-evolving physical systems. To address this, we propose\nFR-Mamba, a novel spatiotemporal flow field reconstruction framework based on\nstate space modeling. Specifically, we design a hybrid neural network\narchitecture that combines Fourier Neural Operator (FNO) and State Space Model\n(SSM) to capture both global spatial features and long-range temporal\ndependencies. We adopt Mamba, a recently proposed efficient SSM architecture,\nto model long-range temporal dependencies with linear time complexity. In\nparallel, the FNO is employed to capture non-local spatial features by\nleveraging frequency-domain transformations. The spatiotemporal representations\nextracted by these two components are then fused to reconstruct the full-field\ndistribution of the physical system. Extensive experiments demonstrate that our\napproach significantly outperforms existing PFR methods in flow field\nreconstruction tasks, achieving high-accuracy performance on long sequences.", "AI": {"tldr": "FR-Mamba, a hybrid neural network combining FNO and SSM, improves physical field reconstruction by capturing long-range temporal and spatial dependencies.", "motivation": "Existing deep learning methods struggle with long-range temporal dependencies in time-evolving physical systems, limiting PFR performance.", "method": "FR-Mamba integrates Fourier Neural Operator (FNO) for spatial features and State Space Model (SSM, specifically Mamba) for temporal dependencies, fusing their outputs for reconstruction.", "result": "FR-Mamba outperforms existing methods, achieving high accuracy in flow field reconstruction, especially on long sequences.", "conclusion": "The proposed hybrid architecture effectively addresses PFR challenges, offering superior performance in spatiotemporal physical field reconstruction."}}
{"id": "2505.16029", "pdf": "https://arxiv.org/pdf/2505.16029", "abs": "https://arxiv.org/abs/2505.16029", "authors": ["Shichao Li", "Peiliang Li", "Qing Lian", "Peng Yun", "Xiaozhi Chen"], "title": "Learning better representations for crowded pedestrians in offboard LiDAR-camera 3D tracking-by-detection", "categories": ["cs.CV"], "comment": null, "summary": "Perceiving pedestrians in highly crowded urban environments is a difficult\nlong-tail problem for learning-based autonomous perception. Speeding up 3D\nground truth generation for such challenging scenes is performance-critical yet\nvery challenging. The difficulties include the sparsity of the captured\npedestrian point cloud and a lack of suitable benchmarks for a specific system\ndesign study. To tackle the challenges, we first collect a new multi-view\nLiDAR-camera 3D multiple-object-tracking benchmark of highly crowded\npedestrians for in-depth analysis. We then build an offboard auto-labeling\nsystem that reconstructs pedestrian trajectories from LiDAR point cloud and\nmulti-view images. To improve the generalization power for crowded scenes and\nthe performance for small objects, we propose to learn high-resolution\nrepresentations that are density-aware and relationship-aware. Extensive\nexperiments validate that our approach significantly improves the 3D pedestrian\ntracking performance towards higher auto-labeling efficiency. The code will be\npublicly available at this HTTP URL.", "AI": {"tldr": "A new benchmark and auto-labeling system for 3D pedestrian tracking in crowded scenes improves efficiency and performance.", "motivation": "Addressing the challenges of sparse point clouds and lack of benchmarks for crowded pedestrian scenes in autonomous perception.", "method": "Collecting a multi-view LiDAR-camera benchmark and building an offboard auto-labeling system with density-aware and relationship-aware high-resolution representations.", "result": "Significant improvement in 3D pedestrian tracking performance and auto-labeling efficiency.", "conclusion": "The proposed approach effectively tackles the challenges of crowded scenes, with publicly available code for further use."}}
{"id": "2505.16088", "pdf": "https://arxiv.org/pdf/2505.16088", "abs": "https://arxiv.org/abs/2505.16088", "authors": ["Gagan Bhatia", "Maxime Peyrard", "Wei Zhao"], "title": "Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Modern BPE tokenizers often split calendar dates into meaningless fragments,\ne.g., 20250312 $\\rightarrow$ 202, 503, 12, inflating token counts and obscuring\nthe inherent structure needed for robust temporal reasoning. In this work, we\n(1) introduce a simple yet interpretable metric, termed date fragmentation\nratio, that measures how faithfully a tokenizer preserves multi-digit date\ncomponents; (2) release DateAugBench, a suite of 6500 examples spanning three\ntemporal reasoning tasks: context-based date resolution, format-invariance\npuzzles, and date arithmetic across historical, contemporary, and future\nregimes; and (3) through layer-wise probing and causal attention-hop analyses,\nuncover an emergent date-abstraction mechanism whereby large language models\nstitch together the fragments of month, day, and year components for temporal\nreasoning. Our experiments show that excessive fragmentation correlates with\naccuracy drops of up to 10 points on uncommon dates like historical and\nfuturistic dates. Further, we find that the larger the model, the faster the\nemergent date abstraction that heals date fragments is accomplished. Lastly, we\nobserve a reasoning path that LLMs follow to assemble date fragments, typically\ndiffering from human interpretation (year $\\rightarrow$ month $\\rightarrow$\nday).", "AI": {"tldr": "The paper addresses the issue of BPE tokenizers fragmenting calendar dates, introduces a metric for date fragmentation, releases a benchmark for temporal reasoning tasks, and reveals how LLMs abstract date fragments for reasoning.", "motivation": "BPE tokenizers often split dates into meaningless fragments, hindering temporal reasoning. The work aims to measure and address this fragmentation.", "method": "Introduces a date fragmentation ratio metric, releases DateAugBench for temporal tasks, and uses probing and attention analysis to study LLMs' date abstraction.", "result": "Excessive fragmentation reduces accuracy by up to 10 points on uncommon dates. Larger models abstract date fragments faster, and LLMs follow a unique reasoning path (year\u2192month\u2192day).", "conclusion": "The study highlights the impact of date fragmentation on temporal reasoning and reveals emergent abstraction mechanisms in LLMs, differing from human interpretation."}}
{"id": "2505.16658", "pdf": "https://arxiv.org/pdf/2505.16658", "abs": "https://arxiv.org/abs/2505.16658", "authors": ["Giuseppe Guarino", "Matteo Ciotola", "Gemine Vivone", "Giovanni Poggi", "Giuseppe Scarpa"], "title": "Zero-Shot Hyperspectral Pansharpening Using Hysteresis-Based Tuning for Spectral Quality Control", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Hyperspectral pansharpening has received much attention in recent years due\nto technological and methodological advances that open the door to new\napplication scenarios. However, research on this topic is only now gaining\nmomentum. The most popular methods are still borrowed from the more mature\nfield of multispectral pansharpening and often overlook the unique challenges\nposed by hyperspectral data fusion, such as i) the very large number of bands,\nii) the overwhelming noise in selected spectral ranges, iii) the significant\nspectral mismatch between panchromatic and hyperspectral components, iv) a\ntypically high resolution ratio. Imprecise data modeling especially affects\nspectral fidelity. Even state-of-the-art methods perform well in certain\nspectral ranges and much worse in others, failing to ensure consistent quality\nacross all bands, with the risk of generating unreliable results. Here, we\npropose a hyperspectral pansharpening method that explicitly addresses this\nproblem and ensures uniform spectral quality. To this end, a single lightweight\nneural network is used, with weights that adapt on the fly to each band. During\nfine-tuning, the spatial loss is turned on and off to ensure a fast convergence\nof the spectral loss to the desired level, according to a hysteresis-like\ndynamic. Furthermore, the spatial loss itself is appropriately redefined to\naccount for nonlinear dependencies between panchromatic and spectral bands.\nOverall, the proposed method is fully unsupervised, with no prior training on\nexternal data, flexible, and low-complexity. Experiments on a recently\npublished benchmarking toolbox show that it ensures excellent sharpening\nquality, competitive with the state-of-the-art, consistently across all bands.\nThe software code and the full set of results are shared online on\nhttps://github.com/giu-guarino/rho-PNN.", "AI": {"tldr": "A new hyperspectral pansharpening method using a lightweight neural network with adaptive weights ensures uniform spectral quality across all bands, outperforming state-of-the-art methods.", "motivation": "Existing methods borrowed from multispectral pansharpening fail to address unique hyperspectral challenges like noise, spectral mismatch, and inconsistent quality across bands.", "method": "A single lightweight neural network adapts weights per band, uses a hysteresis-like dynamic for spectral loss convergence, and redefines spatial loss for nonlinear dependencies.", "result": "The method achieves excellent sharpening quality consistently across all bands, validated by a benchmarking toolbox.", "conclusion": "The proposed unsupervised, flexible, and low-complexity method outperforms state-of-the-art approaches, with code and results shared online."}}
{"id": "2505.16199", "pdf": "https://arxiv.org/pdf/2505.16199", "abs": "https://arxiv.org/abs/2505.16199", "authors": ["Rikuhei Umemoto", "Keisuke Fujii"], "title": "Velocity Completion Task and Method for Event-based Player Positional Data in Soccer", "categories": ["cs.AI"], "comment": "24 pages, 7 figures", "summary": "In many real-world complex systems, the behavior can be observed as a\ncollection of discrete events generated by multiple interacting agents.\nAnalyzing the dynamics of these multi-agent systems, especially team sports,\noften relies on understanding the movement and interactions of individual\nagents. However, while providing valuable snapshots, event-based positional\ndata typically lacks the continuous temporal information needed to directly\ncalculate crucial properties such as velocity. This absence severely limits the\ndepth of dynamic analysis, preventing a comprehensive understanding of\nindividual agent behaviors and emergent team strategies. To address this\nchallenge, we propose a new method to simultaneously complete the velocity of\nall agents using only the event-based positional data from team sports. Based\non this completed velocity information, we investigate the applicability of\nexisting team sports analysis and evaluation methods. Experiments using soccer\nevent data demonstrate that neural network-based approaches outperformed\nrule-based methods regarding velocity completion error, considering the\nunderlying temporal dependencies and graph structure of player-to-player or\nplayer-to-ball interaction. Moreover, the space evaluation results obtained\nusing the completed velocity are closer to those derived from complete tracking\ndata, highlighting our method's potential for enhanced team sports system\nanalysis.", "AI": {"tldr": "Proposes a neural network-based method to estimate velocities from event-based positional data in team sports, improving dynamic analysis and evaluation.", "motivation": "Event-based positional data lacks continuous temporal info, limiting dynamic analysis of multi-agent systems like team sports.", "method": "Uses neural networks to complete velocity for all agents from event-based data, leveraging temporal dependencies and interaction graphs.", "result": "Neural networks outperform rule-based methods in velocity completion, and space evaluation aligns closer with complete tracking data.", "conclusion": "The method enhances team sports analysis by providing more accurate velocity estimates and better dynamic insights."}}
{"id": "2505.16094", "pdf": "https://arxiv.org/pdf/2505.16094", "abs": "https://arxiv.org/abs/2505.16094", "authors": ["Ziqing Wang", "Kexin Zhang", "Zihan Zhao", "Yibo Wen", "Abhishek Pandey", "Han Liu", "Kaize Ding"], "title": "A Survey of Large Language Models for Text-Guided Molecular Discovery: from Molecule Generation to Optimization", "categories": ["cs.LG", "cs.CL"], "comment": "Under review", "summary": "Large language models (LLMs) are introducing a paradigm shift in molecular\ndiscovery by enabling text-guided interaction with chemical spaces through\nnatural language, symbolic notations, with emerging extensions to incorporate\nmulti-modal inputs. To advance the new field of LLM for molecular discovery,\nthis survey provides an up-to-date and forward-looking review of the emerging\nuse of LLMs for two central tasks: molecule generation and molecule\noptimization. Based on our proposed taxonomy for both problems, we analyze\nrepresentative techniques in each category, highlighting how LLM capabilities\nare leveraged across different learning settings. In addition, we include the\ncommonly used datasets and evaluation protocols. We conclude by discussing key\nchallenges and future directions, positioning this survey as a resource for\nresearchers working at the intersection of LLMs and molecular science. A\ncontinuously updated reading list is available at\nhttps://github.com/REAL-Lab-NU/Awesome-LLM-Centric-Molecular-Discovery.", "AI": {"tldr": "A survey on the use of large language models (LLMs) for molecular discovery, focusing on molecule generation and optimization, with a taxonomy, analysis of techniques, datasets, and future challenges.", "motivation": "To review and advance the emerging field of LLMs in molecular discovery by providing a structured overview and identifying key challenges.", "method": "Proposes a taxonomy for molecule generation and optimization, analyzes representative techniques, and includes datasets and evaluation protocols.", "result": "Highlights how LLMs are leveraged in molecular discovery tasks and provides a resource for researchers.", "conclusion": "Identifies key challenges and future directions, positioning the survey as a valuable resource for the intersection of LLMs and molecular science."}}
{"id": "2505.16033", "pdf": "https://arxiv.org/pdf/2505.16033", "abs": "https://arxiv.org/abs/2505.16033", "authors": ["Faika Fairuj Preotee", "Shuvashis Sarker", "Shamim Rahim Refat", "Tashreef Muhammad", "Shifat Islam"], "title": "An Approach Towards Identifying Bangladeshi Leaf Diseases through Transfer Learning and XAI", "categories": ["cs.CV"], "comment": "Accepted for publication in 2024 27th International Conference on\n  Computer and Information Technology (ICCIT)", "summary": "Leaf diseases are harmful conditions that affect the health, appearance and\nproductivity of plants, leading to significant plant loss and negatively\nimpacting farmers' livelihoods. These diseases cause visible symptoms such as\nlesions, color changes, and texture variations, making it difficult for farmers\nto manage plant health, especially in large or remote farms where expert\nknowledge is limited. The main motivation of this study is to provide an\nefficient and accessible solution for identifying plant leaf diseases in\nBangladesh, where agriculture plays a critical role in food security. The\nobjective of our research is to classify 21 distinct leaf diseases across six\nplants using deep learning models, improving disease detection accuracy while\nreducing the need for expert involvement. Deep Learning (DL) techniques,\nincluding CNN and Transfer Learning (TL) models like VGG16, VGG19, MobileNetV2,\nInceptionV3, ResNet50V2 and Xception are used. VGG19 and Xception achieve the\nhighest accuracies, with 98.90% and 98.66% respectively. Additionally,\nExplainable AI (XAI) techniques such as GradCAM, GradCAM++, LayerCAM, ScoreCAM\nand FasterScoreCAM are used to enhance transparency by highlighting the regions\nof the models focused on during disease classification. This transparency\nensures that farmers can understand the model's predictions and take necessary\naction. This approach not only improves disease management but also supports\nfarmers in making informed decisions, leading to better plant protection and\nincreased agricultural productivity.", "AI": {"tldr": "The paper proposes a deep learning-based system for classifying 21 leaf diseases across six plants in Bangladesh, achieving high accuracy with models like VGG19 and Xception, and uses Explainable AI for transparency.", "motivation": "To provide an efficient and accessible solution for identifying plant leaf diseases in Bangladesh, where agriculture is vital for food security, reducing reliance on expert knowledge.", "method": "Deep Learning techniques (CNN, Transfer Learning models like VGG16, VGG19, MobileNetV2, InceptionV3, ResNet50V2, Xception) and Explainable AI (GradCAM, GradCAM++, LayerCAM, ScoreCAM, FasterScoreCAM) for disease classification and transparency.", "result": "VGG19 and Xception achieved the highest accuracies of 98.90% and 98.66%, respectively. Explainable AI techniques highlighted model focus areas for better understanding.", "conclusion": "The approach improves disease management, supports informed farmer decisions, and enhances agricultural productivity through accurate and transparent disease detection."}}
{"id": "2505.16102", "pdf": "https://arxiv.org/pdf/2505.16102", "abs": "https://arxiv.org/abs/2505.16102", "authors": ["Yash Kumar Atri", "Thomas H Shin", "Thomas Hartvigsen"], "title": "Continually Self-Improving Language Models for Bariatric Surgery Question--Answering", "categories": ["cs.CL"], "comment": null, "summary": "While bariatric and metabolic surgery (MBS) is considered the gold standard\ntreatment for severe and morbid obesity, its therapeutic efficacy hinges upon\nactive and longitudinal engagement with multidisciplinary providers, including\nsurgeons, dietitians/nutritionists, psychologists, and endocrinologists. This\nengagement spans the entire patient journey, from preoperative preparation to\nlong-term postoperative management. However, this process is often hindered by\nnumerous healthcare disparities, such as logistical and access barriers, which\nimpair easy patient access to timely, evidence-based, clinician-endorsed\ninformation. To address these gaps, we introduce bRAGgen, a novel adaptive\nretrieval-augmented generation (RAG)-based model that autonomously integrates\nreal-time medical evidence when response confidence dips below dynamic\nthresholds. This self-updating architecture ensures that responses remain\ncurrent and accurate, reducing the risk of misinformation. Additionally, we\npresent bRAGq, a curated dataset of 1,302 bariatric surgery--related questions,\nvalidated by an expert bariatric surgeon. bRAGq constitutes the first\nlarge-scale, domain-specific benchmark for comprehensive MBS care. In a\ntwo-phase evaluation, bRAGgen is benchmarked against state-of-the-art models\nusing both large language model (LLM)--based metrics and expert surgeon review.\nAcross all evaluation dimensions, bRAGgen demonstrates substantially superior\nperformance in generating clinically accurate and relevant responses.", "AI": {"tldr": "bRAGgen, an adaptive RAG-based model, improves bariatric surgery care by integrating real-time medical evidence and outperforms state-of-the-art models in generating accurate responses.", "motivation": "Healthcare disparities hinder patient access to timely, evidence-based information in bariatric surgery care.", "method": "Introduces bRAGgen, a self-updating RAG model, and bRAGq, a validated dataset of bariatric surgery questions.", "result": "bRAGgen outperforms other models in generating clinically accurate responses.", "conclusion": "bRAGgen enhances MBS care by ensuring current and accurate information."}}
{"id": "2505.16687", "pdf": "https://arxiv.org/pdf/2505.16687", "abs": "https://arxiv.org/abs/2505.16687", "authors": ["Naifu Xue", "Zhaoyang Jia", "Jiahao Li", "Bin Li", "Yuan Zhang", "Yan Lu"], "title": "One-Step Diffusion-Based Image Compression with Semantic Distillation", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "While recent diffusion-based generative image codecs have shown impressive\nperformance, their iterative sampling process introduces unpleasing latency. In\nthis work, we revisit the design of a diffusion-based codec and argue that\nmulti-step sampling is not necessary for generative compression. Based on this\ninsight, we propose OneDC, a One-step Diffusion-based generative image Codec --\nthat integrates a latent compression module with a one-step diffusion\ngenerator. Recognizing the critical role of semantic guidance in one-step\ndiffusion, we propose using the hyperprior as a semantic signal, overcoming the\nlimitations of text prompts in representing complex visual content. To further\nenhance the semantic capability of the hyperprior, we introduce a semantic\ndistillation mechanism that transfers knowledge from a pretrained generative\ntokenizer to the hyperprior codec. Additionally, we adopt a hybrid pixel- and\nlatent-domain optimization to jointly enhance both reconstruction fidelity and\nperceptual realism. Extensive experiments demonstrate that OneDC achieves SOTA\nperceptual quality even with one-step generation, offering over 40% bitrate\nreduction and 20x faster decoding compared to prior multi-step diffusion-based\ncodecs. Code will be released later.", "AI": {"tldr": "OneDC is a one-step diffusion-based image codec that reduces latency by eliminating multi-step sampling, achieving SOTA perceptual quality with faster decoding and lower bitrates.", "motivation": "Address the latency issue in diffusion-based generative image codecs by proving multi-step sampling is unnecessary for generative compression.", "method": "Integrates a latent compression module with a one-step diffusion generator, uses hyperprior as semantic guidance, introduces semantic distillation, and employs hybrid pixel- and latent-domain optimization.", "result": "Achieves 40% bitrate reduction and 20x faster decoding compared to multi-step diffusion-based codecs, with SOTA perceptual quality.", "conclusion": "OneDC demonstrates that one-step diffusion is viable for generative compression, offering significant efficiency and performance improvements."}}
{"id": "2505.16221", "pdf": "https://arxiv.org/pdf/2505.16221", "abs": "https://arxiv.org/abs/2505.16221", "authors": ["Yifan Zhang", "Xinkui Zhao", "Zuxin Wang", "Guanjie Cheng", "Yueshen Xu", "Shuiguang Deng", "Jianwei Yin"], "title": "LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of large language models has unlocked remarkable\ncapabilities across a diverse array of natural language processing tasks.\nHowever, the considerable differences among available LLMs-in terms of cost,\nperformance, and computational demands-pose significant challenges for users\naiming to identify the most suitable model for specific tasks. In this work, we\npresent LightRouter, a novel framework designed to systematically select and\nintegrate a small subset of LLMs from a larger pool, with the objective of\njointly optimizing both task performance and cost efficiency. LightRouter\nleverages an adaptive selection mechanism to identify models that require only\na minimal number of boot tokens, thereby reducing costs, and further employs an\neffective integration strategy to combine their outputs. Extensive experiments\nacross multiple benchmarks demonstrate that LightRouter matches or outperforms\nwidely-used ensemble baselines, achieving up to a 25% improvement in accuracy.\nCompared with leading high-performing models, LightRouter achieves comparable\nperformance while reducing inference costs by up to 27%. Importantly, our\nframework operates without any prior knowledge of individual models and relies\nexclusively on inexpensive, lightweight models. This work introduces a\npractical approach for efficient LLM selection and provides valuable insights\ninto optimal strategies for model combination.", "AI": {"tldr": "LightRouter is a framework for selecting and integrating a small subset of LLMs to optimize task performance and cost efficiency, achieving up to 25% accuracy improvement and 27% cost reduction.", "motivation": "The diversity in LLMs (cost, performance, computational demands) makes it challenging to choose the best model for specific tasks.", "method": "LightRouter uses an adaptive selection mechanism to minimize boot tokens and an integration strategy to combine outputs.", "result": "Matches or outperforms ensemble baselines with 25% accuracy improvement and 27% cost reduction.", "conclusion": "LightRouter offers a practical, efficient approach for LLM selection and integration without prior model knowledge."}}
{"id": "2505.16099", "pdf": "https://arxiv.org/pdf/2505.16099", "abs": "https://arxiv.org/abs/2505.16099", "authors": ["Ziyi", "Zhou", "Nicholas Stern", "Julien Laasri"], "title": "Reinforcement Learning for Stock Transactions", "categories": ["cs.LG", "68T05", "I.2.6"], "comment": "14 pages, 6 figures, paper dated December 19, 2018", "summary": "Much research has been done to analyze the stock market. After all, if one\ncan determine a pattern in the chaotic frenzy of transactions, then they could\nmake a hefty profit from capitalizing on these insights. As such, the goal of\nour project was to apply reinforcement learning (RL) to determine the best time\nto buy a stock within a given time frame. With only a few adjustments, our\nmodel can be extended to identify the best time to sell a stock as well. In\norder to use the format of free, real-world data to train the model, we define\nour own Markov Decision Process (MDP) problem. These two papers [5] [6] helped\nus in formulating the state space and the reward system of our MDP problem. We\ntrain a series of agents using Q-Learning, Q-Learning with linear function\napproximation, and deep Q-Learning. In addition, we try to predict the stock\nprices using machine learning regression and classification models. We then\ncompare our agents to see if they converge on a policy, and if so, which one\nlearned the best policy to maximize profit on the stock market.", "AI": {"tldr": "The paper applies reinforcement learning (RL) to determine optimal stock buying times, using Q-Learning variants and comparing their performance.", "motivation": "To identify patterns in stock market transactions for profitable trading by leveraging RL techniques.", "method": "Defines a custom Markov Decision Process (MDP) problem, trains agents using Q-Learning, linear function approximation, and deep Q-Learning, and compares their convergence and profitability.", "result": "Agents are evaluated for policy convergence and profit maximization, with results compared across methods.", "conclusion": "The study demonstrates the feasibility of RL in stock market analysis, highlighting the best-performing method for profit maximization."}}
{"id": "2505.16039", "pdf": "https://arxiv.org/pdf/2505.16039", "abs": "https://arxiv.org/abs/2505.16039", "authors": ["Shuvashis Sarker", "Shamim Rahim Refat", "Faika Fairuj Preotee", "Shifat Islam", "Tashreef Muhammad", "Mohammad Ashraful Hoque"], "title": "An Exploratory Approach Towards Investigating and Explaining Vision Transformer and Transfer Learning for Brain Disease Detection", "categories": ["cs.CV"], "comment": "Accepted for publication in 2024 27th International Conference on\n  Computer and Information Technology (ICCIT)", "summary": "The brain is a highly complex organ that manages many important tasks,\nincluding movement, memory and thinking. Brain-related conditions, like tumors\nand degenerative disorders, can be hard to diagnose and treat. Magnetic\nResonance Imaging (MRI) serves as a key tool for identifying these conditions,\noffering high-resolution images of brain structures. Despite this, interpreting\nMRI scans can be complicated. This study tackles this challenge by conducting a\ncomparative analysis of Vision Transformer (ViT) and Transfer Learning (TL)\nmodels such as VGG16, VGG19, Resnet50V2, MobilenetV2 for classifying brain\ndiseases using MRI data from Bangladesh based dataset. ViT, known for their\nability to capture global relationships in images, are particularly effective\nfor medical imaging tasks. Transfer learning helps to mitigate data constraints\nby fine-tuning pre-trained models. Furthermore, Explainable AI (XAI) methods\nsuch as GradCAM, GradCAM++, LayerCAM, ScoreCAM, and Faster-ScoreCAM are\nemployed to interpret model predictions. The results demonstrate that ViT\nsurpasses transfer learning models, achieving a classification accuracy of\n94.39%. The integration of XAI methods enhances model transparency, offering\ncrucial insights to aid medical professionals in diagnosing brain diseases with\ngreater precision.", "AI": {"tldr": "The study compares Vision Transformer (ViT) and Transfer Learning models for brain disease classification using MRI data, finding ViT superior with 94.39% accuracy. Explainable AI methods enhance interpretability.", "motivation": "Brain conditions are hard to diagnose; MRI interpretation is complex. The study aims to improve classification and transparency in diagnosis.", "method": "Comparative analysis of ViT and TL models (VGG16, VGG19, Resnet50V2, MobilenetV2) on Bangladesh MRI data, using XAI methods for interpretation.", "result": "ViT outperforms TL models with 94.39% accuracy. XAI methods provide interpretable insights for medical professionals.", "conclusion": "ViT is effective for brain disease classification, and XAI enhances diagnostic precision, aiding medical decision-making."}}
{"id": "2505.16104", "pdf": "https://arxiv.org/pdf/2505.16104", "abs": "https://arxiv.org/abs/2505.16104", "authors": ["Yue Li", "Xin Yi", "Dongsheng Shi", "Gerard de Melo", "Xiaoling Wang", "Linlin Wang"], "title": "Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models", "categories": ["cs.CL", "cs.CV", "cs.LG"], "comment": "ACL 2025 Findings", "summary": "With the increasing size of Large Vision-Language Models (LVLMs), network\npruning techniques aimed at compressing models for deployment in\nresource-constrained environments have garnered significant attention. However,\nwe observe that pruning often leads to a degradation in safety performance. To\naddress this issue, we present a novel and lightweight approach, termed\nHierarchical Safety Realignment (HSR). HSR operates by first quantifying the\ncontribution of each attention head to safety, identifying the most critical\nones, and then selectively restoring neurons directly within these attention\nheads that play a pivotal role in maintaining safety. This process\nhierarchically realigns the safety of pruned LVLMs, progressing from the\nattention head level to the neuron level. We validate HSR across various models\nand pruning strategies, consistently achieving notable improvements in safety\nperformance. To our knowledge, this is the first work explicitly focused on\nrestoring safety in LVLMs post-pruning.", "AI": {"tldr": "HSR is a lightweight method to restore safety in pruned LVLMs by hierarchically realigning critical attention heads and neurons.", "motivation": "Pruning LVLMs often degrades safety performance, necessitating a solution to restore safety without compromising efficiency.", "method": "HSR quantifies safety contributions of attention heads, identifies critical ones, and selectively restores key neurons within them.", "result": "HSR consistently improves safety performance across various models and pruning strategies.", "conclusion": "HSR is the first method explicitly addressing safety restoration in pruned LVLMs, offering a practical solution for deployment."}}
{"id": "2505.16709", "pdf": "https://arxiv.org/pdf/2505.16709", "abs": "https://arxiv.org/abs/2505.16709", "authors": ["Kai Hsiang Hsieh", "Monyneath Yim", "Jui Chiu Chiang"], "title": "SEDD-PCC: A Single Encoder-Dual Decoder Framework For End-To-End Learned Point Cloud Compression", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "To encode point clouds containing both geometry and attributes, most\nlearning-based compression schemes treat geometry and attribute coding\nseparately, employing distinct encoders and decoders. This not only increases\ncomputational complexity but also fails to fully exploit shared features\nbetween geometry and attributes. To address this limitation, we propose\nSEDD-PCC, an end-to-end learning-based framework for lossy point cloud\ncompression that jointly compresses geometry and attributes. SEDD-PCC employs a\nsingle encoder to extract shared geometric and attribute features into a\nunified latent space, followed by dual specialized decoders that sequentially\nreconstruct geometry and attributes. Additionally, we incorporate knowledge\ndistillation to enhance feature representation learning from a teacher model,\nfurther improving coding efficiency. With its simple yet effective design,\nSEDD-PCC provides an efficient and practical solution for point cloud\ncompression. Comparative evaluations against both rule-based and learning-based\nmethods demonstrate its competitive performance, highlighting SEDD-PCC as a\npromising AI-driven compression approach.", "AI": {"tldr": "SEDD-PCC is an end-to-end learning-based framework for joint compression of point cloud geometry and attributes, using a shared encoder and dual decoders, enhanced by knowledge distillation for efficiency.", "motivation": "Existing methods treat geometry and attribute coding separately, increasing complexity and missing shared feature exploitation.", "method": "SEDD-PCC uses a single encoder for shared features, dual decoders for reconstruction, and knowledge distillation for improved learning.", "result": "Outperforms rule-based and learning-based methods, demonstrating competitive performance.", "conclusion": "SEDD-PCC is an efficient, practical AI-driven solution for point cloud compression."}}
{"id": "2505.16223", "pdf": "https://arxiv.org/pdf/2505.16223", "abs": "https://arxiv.org/abs/2505.16223", "authors": ["Sangyong Lee", "Subo Hwang", "Dohoon Kim"], "title": "MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network", "categories": ["cs.AI", "cs.LG"], "comment": "24 pages, 9 figures", "summary": "In this paper, we propose MADCluster, a novel model-agnostic anomaly\ndetection framework utilizing self-supervised clustering. MADCluster is\napplicable to various deep learning architectures and addresses the\n'hypersphere collapse' problem inherent in existing deep learning-based anomaly\ndetection methods. The core idea is to cluster normal pattern data into a\n'single cluster' while simultaneously learning the cluster center and mapping\ndata close to this center. Also, to improve expressiveness and enable effective\nsingle clustering, we propose a new 'One-directed Adaptive loss'. The\noptimization of this loss is mathematically proven. MADCluster consists of\nthree main components: Base Embedder capturing high-dimensional temporal\ndynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous\ncenter updates. Its model-agnostic characteristics are achieved by applying\nvarious architectures to the Base Embedder. Experiments on four time series\nbenchmark datasets demonstrate that applying MADCluster improves the overall\nperformance of comparative models. In conclusion, the compatibility of\nMADCluster shows potential for enhancing model performance across various\narchitectures.", "AI": {"tldr": "MADCluster is a model-agnostic anomaly detection framework using self-supervised clustering to address the 'hypersphere collapse' problem in deep learning-based anomaly detection. It clusters normal data into a single cluster and introduces a new loss function for optimization.", "motivation": "To solve the 'hypersphere collapse' issue in existing anomaly detection methods and provide a versatile framework applicable to various deep learning architectures.", "method": "MADCluster uses self-supervised clustering with three components: Base Embedder, Cluster Distance Mapping, and Sequence-wise Clustering. It introduces a 'One-directed Adaptive loss' for optimization.", "result": "Experiments on four time series datasets show improved performance of comparative models when using MADCluster.", "conclusion": "MADCluster is compatible with various architectures and enhances model performance, showing broad potential."}}
{"id": "2505.16103", "pdf": "https://arxiv.org/pdf/2505.16103", "abs": "https://arxiv.org/abs/2505.16103", "authors": ["Monirul Islam Mahmud"], "title": "Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Keylogger detection involves monitoring for unusual system behaviors such as\ndelays between typing and character display, analyzing network traffic patterns\nfor data exfiltration. In this study, we provide a comprehensive analysis for\nkeylogger detection with traditional machine learning models - SVC, Random\nForest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes\nand advanced ensemble methods including Stacking, Blending and Voting.\nMoreover, feature selection approaches such as Information gain, Lasso L1 and\nFisher Score are thoroughly assessed to improve predictive performance and\nlower computational complexity. The Keylogger Detection dataset from publicly\navailable Kaggle website is used in this project. In addition to accuracy-based\nclassification, this study implements the approach for model interpretation\nusing Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to\ndeliver finer explanations for how much each feature contributes in assisting\nor hindering the detection process. To evaluate the models result, we have used\nAUC score, sensitivity, Specificity, Accuracy and F1 score. The best\nperformance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99,\n100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is\nnear-perfect classification with Fisher Score.", "AI": {"tldr": "The paper analyzes keylogger detection using traditional and ensemble machine learning models, feature selection methods, and Explainable AI (XAI) techniques, achieving near-perfect performance with AdaBoost.", "motivation": "To comprehensively analyze and improve keylogger detection by evaluating various machine learning models, feature selection methods, and incorporating XAI for interpretability.", "method": "Used traditional models (SVC, Random Forest, etc.), ensemble methods (Stacking, Blending, Voting), and feature selection (Information gain, Lasso L1, Fisher Score). Applied XAI techniques (SHAP, LIME) for model interpretation. Evaluated using AUC, sensitivity, specificity, accuracy, and F1 score.", "result": "AdaBoost achieved the best performance: 99.76% accuracy, F1 score of 0.99, 100% precision, 98.6% recall, 1.0 specificity, and 0.99 AUC with Fisher Score.", "conclusion": "The study demonstrates the effectiveness of AdaBoost and feature selection (Fisher Score) for keylogger detection, with XAI providing valuable insights into feature contributions."}}
{"id": "2505.16144", "pdf": "https://arxiv.org/pdf/2505.16144", "abs": "https://arxiv.org/abs/2505.16144", "authors": ["Ming Yang", "Haoran Li"], "title": "GMatch: Geometry-Constrained Feature Matching for RGB-D Object Pose Estimation", "categories": ["cs.CV"], "comment": "9 pages + 3 pages references + 2 pages appendix; 6 figures; 1 table", "summary": "We present GMatch, a learning-free feature matcher designed for robust 6DoF\nobject pose estimation, addressing common local ambiguities in sparse feature\nmatching. Unlike traditional methods that rely solely on descriptor similarity,\nGMatch performs a guided, incremental search, enforcing SE(3)-invariant\ngeometric consistency throughout the matching process. It leverages a provably\ncomplete set of geometric features that uniquely determine 3D keypoint\nconfigurations, ensuring globally consistent correspondences without the need\nfor training or GPU support. When combined with classical descriptors such as\nSIFT, GMatch-SIFT forms a general-purpose pose estimation pipeline that offers\nstrong interpretability and generalization across diverse objects and scenes.\nExperiments on the HOPE dataset show that GMatch outperforms both traditional\nand learning-based matchers, with GMatch-SIFT achieving or surpassing the\nperformance of instance-level pose networks. On the YCB-Video dataset,\nGMatch-SIFT demonstrates high accuracy and low variance on texture-rich\nobjects. These results not only validate the effectiveness of GMatch-SIFT for\nobject pose estimation but also highlight the broader applicability of GMatch\nas a general-purpose feature matcher. Code will be released upon acceptance.", "AI": {"tldr": "GMatch is a learning-free feature matcher for robust 6DoF object pose estimation, using SE(3)-invariant geometric consistency to outperform traditional and learning-based methods.", "motivation": "Address local ambiguities in sparse feature matching without relying on descriptor similarity or training.", "method": "Guided, incremental search with SE(3)-invariant geometric consistency, leveraging geometric features for globally consistent correspondences.", "result": "Outperforms traditional and learning-based matchers on HOPE and YCB-Video datasets, achieving high accuracy and low variance.", "conclusion": "GMatch-SIFT is effective for object pose estimation and general-purpose feature matching, with strong interpretability and generalization."}}
{"id": "2505.16107", "pdf": "https://arxiv.org/pdf/2505.16107", "abs": "https://arxiv.org/abs/2505.16107", "authors": ["Bo Li", "Gexiang Fang", "Wei Ye", "Zhenghua Xu", "Jinglei Zhang", "Hao Cheng", "Shikun Zhang"], "title": "MPL: Multiple Programming Languages with Large Language Models for Information Extraction", "categories": ["cs.CL"], "comment": "Findings of ACL2025", "summary": "Recent research in information extraction (IE) focuses on utilizing\ncode-style inputs to enhance structured output generation. The intuition behind\nthis is that the programming languages (PLs) inherently exhibit greater\nstructural organization than natural languages (NLs). This structural advantage\nmakes PLs particularly suited for IE tasks. Nevertheless, existing research\nprimarily focuses on Python for code-style simulation, overlooking the\npotential of other widely-used PLs (e.g., C++ and Java) during the supervised\nfine-tuning (SFT) phase. In this research, we propose \\textbf{M}ultiple\n\\textbf{P}rogramming \\textbf{L}anguages with large language models for\ninformation extraction (abbreviated as \\textbf{MPL}), a novel framework that\nexplores the potential of incorporating different PLs in the SFT phase.\nAdditionally, we introduce \\texttt{function-prompt} with virtual running to\nsimulate code-style inputs more effectively and efficiently. Experimental\nresults on a wide range of datasets demonstrate the effectiveness of MPL.\nFurthermore, we conduct extensive experiments to provide a comprehensive\nanalysis. We have released our code for future research.", "AI": {"tldr": "The paper introduces MPL, a framework using multiple programming languages (PLs) for structured information extraction (IE), improving on existing Python-only approaches. It includes a 'function-prompt' method for better code-style input simulation and shows strong experimental results.", "motivation": "Existing IE research focuses on Python for code-style inputs, ignoring other PLs like C++ and Java, which may offer structural advantages. MPL aims to leverage multiple PLs for better IE performance.", "method": "MPL incorporates various PLs during supervised fine-tuning (SFT) and introduces 'function-prompt' with virtual running to simulate code-style inputs more effectively.", "result": "Experiments on diverse datasets confirm MPL's effectiveness, outperforming Python-only approaches.", "conclusion": "MPL demonstrates the benefits of using multiple PLs for IE, with released code for further research."}}
{"id": "2505.17008", "pdf": "https://arxiv.org/pdf/2505.17008", "abs": "https://arxiv.org/abs/2505.17008", "authors": ["Jean Pablo Vieira de Mello", "Matheus Augusto Alves Cuglieri", "Leandro P. de Figueiredo", "Fernando Bordignon", "Marcelo Ramalho Albuquerque", "Rodrigo Surmas", "Bruno Cavalcanti de Paula"], "title": "Deep mineralogical segmentation of thin section images based on QEMSCAN maps", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Interpreting the mineralogical aspects of rock thin sections is an important\ntask for oil and gas reservoirs evaluation. However, human analysis tend to be\nsubjective and laborious. Technologies like QEMSCAN(R) are designed to automate\nthe mineralogical mapping process, but also suffer from limitations like high\nmonetary costs and time-consuming analysis. This work proposes a Convolutional\nNeural Network model for automatic mineralogical segmentation of thin section\nimages of carbonate rocks. The model is able to mimic the QEMSCAN mapping\nitself in a low-cost, generalized and efficient manner. For this, the U-Net\nsemantic segmentation architecture is trained on plane and cross polarized thin\nsection images using the corresponding QEMSCAN maps as target, which is an\napproach not widely explored. The model was instructed to differentiate\noccurrences of Calcite, Dolomite, Mg-Clay Minerals, Quartz, Pores and the\nremaining mineral phases as an unique class named \"Others\", while it was\nvalidated on rock facies both seen and unseen during training, in order to\naddress its generalization capability. Since the images and maps are provided\nin different resolutions, image registration was applied to align then\nspatially. The study reveals that the quality of the segmentation is very much\ndependent on these resolution differences and on the variety of learnable rock\ntextures. However, it shows promising results, especially with regard to the\nproper delineation of minerals boundaries on solid textures and precise\nestimation of the minerals distributions, describing a nearly linear\nrelationship between expected and predicted distributions, with coefficient of\ndetermination (R^2) superior to 0.97 for seen facies and 0.88 for unseen.", "AI": {"tldr": "A CNN model using U-Net architecture is proposed for automated mineralogical segmentation of carbonate rock thin sections, mimicking QEMSCAN at lower cost and with good generalization.", "motivation": "Human analysis of rock thin sections is subjective and laborious, while existing automated methods like QEMSCAN are costly and time-consuming.", "method": "The U-Net model is trained on plane and cross-polarized thin section images using QEMSCAN maps as targets, differentiating minerals like Calcite, Dolomite, and others. Image registration aligns varying resolutions.", "result": "The model shows promising segmentation quality, with R^2 > 0.97 for seen facies and 0.88 for unseen, excelling in mineral boundary delineation and distribution estimation.", "conclusion": "The approach is efficient and generalizable, though segmentation quality depends on resolution differences and texture variety."}}
{"id": "2505.16225", "pdf": "https://arxiv.org/pdf/2505.16225", "abs": "https://arxiv.org/abs/2505.16225", "authors": ["Zihan Chen", "Song Wang", "Zhen Tan", "Jundong Li", "Cong Shen"], "title": "MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning", "categories": ["cs.AI"], "comment": null, "summary": "In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle\ndiverse tasks by incorporating multiple input-output examples, known as\ndemonstrations, into the input of LLMs. More recently, advancements in the\nexpanded context windows of LLMs have led to many-shot ICL, which uses hundreds\nof demonstrations and outperforms few-shot ICL, which relies on fewer examples.\nHowever, this approach is often hindered by the high cost of obtaining large\namounts of labeled data. To address this challenge, we propose Many-Shot\nAdaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL\nframework that utilizes pseudo-labeled samples to compensate for the lack of\nlabel information. We first identify a subset of impactful unlabeled samples\nand perform pseudo-labeling on them by querying LLMs. These pseudo-labeled\nsamples are then adaptively selected and tailored to each test query as input\nto improve the performance of many-shot ICL, without significant labeling\ncosts. Extensive experiments on real-world datasets demonstrate the\neffectiveness of our framework, showcasing its ability to enhance LLM\nadaptability and performance with limited labeled data.", "AI": {"tldr": "MAPLE is a framework using pseudo-labeled samples to enhance many-shot ICL, reducing reliance on labeled data while improving LLM performance.", "motivation": "High costs of obtaining labeled data hinder many-shot ICL; MAPLE addresses this by leveraging pseudo-labeled samples.", "method": "MAPLE identifies impactful unlabeled samples, pseudo-labels them via LLMs, and adaptively selects them for input to improve many-shot ICL.", "result": "Experiments show MAPLE enhances LLM adaptability and performance with limited labeled data.", "conclusion": "MAPLE effectively reduces labeling costs while improving many-shot ICL performance."}}
{"id": "2505.16113", "pdf": "https://arxiv.org/pdf/2505.16113", "abs": "https://arxiv.org/abs/2505.16113", "authors": ["Panagiotis Lymperopoulos", "Vasanth Sarathy"], "title": "Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools", "categories": ["cs.LG", "cs.CL"], "comment": "10 pages 3 figures 3 tables", "summary": "Modern Large Language Models (LLMs) often require external tools, such as\nmachine learning classifiers or knowledge retrieval systems, to provide\naccurate answers in domains where their pre-trained knowledge is insufficient.\nThis integration of LLMs with external tools expands their utility but also\nintroduces a critical challenge: determining the trustworthiness of responses\ngenerated by the combined system. In high-stakes applications, such as medical\ndecision-making, it is essential to assess the uncertainty of both the LLM's\ngenerated text and the tool's output to ensure the reliability of the final\nresponse. However, existing uncertainty quantification methods do not account\nfor the tool-calling scenario, where both the LLM and external tool contribute\nto the overall system's uncertainty. In this work, we present a novel framework\nfor modeling tool-calling LLMs that quantifies uncertainty by jointly\nconsidering the predictive uncertainty of the LLM and the external tool. We\nextend previous methods for uncertainty quantification over token sequences to\nthis setting and propose efficient approximations that make uncertainty\ncomputation practical for real-world applications. We evaluate our framework on\ntwo new synthetic QA datasets, derived from well-known machine learning\ndatasets, which require tool-calling for accurate answers. Additionally, we\napply our method to retrieval-augmented generation (RAG) systems and conduct a\nproof-of-concept experiment demonstrating the effectiveness of our uncertainty\nmetrics in scenarios where external information retrieval is needed. Our\nresults show that the framework is effective in enhancing trust in LLM-based\nsystems, especially in cases where the LLM's internal knowledge is insufficient\nand external tools are required.", "AI": {"tldr": "A framework for quantifying uncertainty in LLMs using external tools, enhancing trust in high-stakes applications.", "motivation": "Address the challenge of assessing trustworthiness in LLM-tool systems, crucial for high-stakes domains like medicine.", "method": "Extends uncertainty quantification to tool-calling LLMs, proposing efficient approximations for practical use.", "result": "Effective in synthetic QA datasets and RAG systems, improving trust when external tools are needed.", "conclusion": "The framework enhances reliability in LLM-based systems by jointly modeling LLM and tool uncertainty."}}
{"id": "2505.16146", "pdf": "https://arxiv.org/pdf/2505.16146", "abs": "https://arxiv.org/abs/2505.16146", "authors": ["Zhenglin Hua", "Jinghan He", "Zijun Yao", "Tianxu Han", "Haiyun Guo", "Yuheng Jia", "Junfeng Fang"], "title": "Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large vision-language models (LVLMs) have achieved remarkable performance on\nmultimodal tasks such as visual question answering (VQA) and image captioning.\nHowever, they still suffer from hallucinations, generating text inconsistent\nwith visual input, posing significant risks in real-world applications.\nExisting approaches to address this issue focus on incorporating external\nknowledge bases, alignment training, or decoding strategies, all of which\nrequire substantial computational cost and time. Recent works try to explore\nmore efficient alternatives by adjusting LVLMs' internal representations.\nAlthough promising, these methods may cause hallucinations to be insufficiently\nsuppressed or lead to excessive interventions that negatively affect normal\nsemantics. In this work, we leverage sparse autoencoders (SAEs) to identify\nsemantic directions closely associated with either hallucinations or actuality,\nrealizing more precise and direct hallucination-related representations. Our\nanalysis demonstrates that interventions along the faithful direction we\nidentified can mitigate hallucinations, while those along the hallucinatory\ndirection can exacerbate them. Building on these insights, we propose Steering\nLVLMs via SAE Latent Directions (SSL), a training-free method based on\nSAE-derived latent directions to mitigate hallucinations in LVLMs. Extensive\nexperiments demonstrate that SSL significantly outperforms existing decoding\napproaches in mitigating hallucinations, while maintaining transferability\nacross different model architectures with negligible additional time overhead.", "AI": {"tldr": "The paper proposes SSL, a training-free method using sparse autoencoders (SAEs) to mitigate hallucinations in large vision-language models (LVLMs) by steering latent directions.", "motivation": "LVLMs suffer from hallucinations (text inconsistent with visual input), and existing solutions are computationally expensive or ineffective.", "method": "Leverages SAEs to identify hallucination-related semantic directions and intervenes along these directions to mitigate hallucinations.", "result": "SSL outperforms existing methods in reducing hallucinations with negligible time overhead and maintains transferability.", "conclusion": "SSL offers an efficient and effective solution for hallucination mitigation in LVLMs without additional training."}}
{"id": "2505.16118", "pdf": "https://arxiv.org/pdf/2505.16118", "abs": "https://arxiv.org/abs/2505.16118", "authors": ["Haotian Lan", "Yao Gao", "Yujun Cheng", "Wei Yuan", "Kun Wang"], "title": "Semiotic Reconstruction of Destination Expectation Constructs An LLM-Driven Computational Paradigm for Social Media Tourism Analytics", "categories": ["cs.CL", "stat.AP"], "comment": "33 pages, 6 figures", "summary": "Social media's rise establishes user-generated content (UGC) as pivotal for\ntravel decisions, yet analytical methods lack scalability. This study\nintroduces a dual-method LLM framework: unsupervised expectation extraction\nfrom UGC paired with survey-informed supervised fine-tuning. Findings reveal\nleisure/social expectations drive engagement more than foundational\nnatural/emotional factors. By establishing LLMs as precision tools for\nexpectation quantification, we advance tourism analytics methodology and\npropose targeted strategies for experience personalization and social travel\npromotion. The framework's adaptability extends to consumer behavior research,\ndemonstrating computational social science's transformative potential in\nmarketing optimization.", "AI": {"tldr": "A dual-method LLM framework combines unsupervised expectation extraction from UGC and supervised fine-tuning to quantify travel expectations, revealing leisure/social factors dominate engagement.", "motivation": "Social media's UGC is key for travel decisions, but current analytical methods lack scalability.", "method": "Dual-method LLM framework: unsupervised expectation extraction from UGC and survey-informed supervised fine-tuning.", "result": "Leisure/social expectations drive engagement more than natural/emotional factors.", "conclusion": "LLMs advance tourism analytics, enabling personalized experiences and social travel promotion, with broader applications in consumer behavior and marketing."}}
{"id": "2502.18225", "pdf": "https://arxiv.org/pdf/2502.18225", "abs": "https://arxiv.org/abs/2502.18225", "authors": ["Jun Zeng", "Debesh Jha", "Ertugrul Aktas", "Elif Keles", "Alpay Medetalibeyoglu", "Matthew Antalek", "Federica Proietto Salanitri", "Amir A. Borhani", "Daniela P. Ladner", "Gorkem Durak", "Ulas Bagci"], "title": "Liver Cirrhosis Stage Estimation from MRI with Deep Learning", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "7 pages, 1 figure", "summary": "We present an end-to-end deep learning framework for automated liver\ncirrhosis stage estimation from multi-sequence MRI. Cirrhosis is the severe\nscarring (fibrosis) of the liver and a common endpoint of various chronic liver\ndiseases. Early diagnosis is vital to prevent complications such as\ndecompensation and cancer, which significantly decreases life expectancy.\nHowever, diagnosing cirrhosis in its early stages is challenging, and patients\noften present with life-threatening complications. Our approach integrates\nmulti-scale feature learning with sequence-specific attention mechanisms to\ncapture subtle tissue variations across cirrhosis progression stages. Using\nCirrMRI600+, a large-scale publicly available dataset of 628 high-resolution\nMRI scans from 339 patients, we demonstrate state-of-the-art performance in\nthree-stage cirrhosis classification. Our best model achieves 72.8% accuracy on\nT1W and 63.8% on T2W sequences, significantly outperforming traditional\nradiomics-based approaches. Through extensive ablation studies, we show that\nour architecture effectively learns stage-specific imaging biomarkers. We\nestablish new benchmarks for automated cirrhosis staging and provide insights\nfor developing clinically applicable deep learning systems. The source code\nwill be available at https://github.com/JunZengz/CirrhosisStage.", "AI": {"tldr": "An end-to-end deep learning framework for automated liver cirrhosis stage estimation from multi-sequence MRI, achieving state-of-the-art performance.", "motivation": "Early diagnosis of cirrhosis is challenging but crucial to prevent severe complications like decompensation and cancer. Current methods often miss early stages.", "method": "Integrates multi-scale feature learning with sequence-specific attention mechanisms to detect subtle tissue variations across cirrhosis stages. Uses CirrMRI600+ dataset (628 MRI scans from 339 patients).", "result": "Achieves 72.8% accuracy on T1W and 63.8% on T2W sequences, outperforming traditional radiomics-based approaches.", "conclusion": "Sets new benchmarks for automated cirrhosis staging and offers insights for clinically applicable deep learning systems. Code is publicly available."}}
{"id": "2505.16276", "pdf": "https://arxiv.org/pdf/2505.16276", "abs": "https://arxiv.org/abs/2505.16276", "authors": ["Desiree Heim", "Lars-Peter Meyer", "Markus Schr\u00f6der", "Johannes Frey", "Andreas Dengel"], "title": "How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance", "categories": ["cs.AI", "cs.CL"], "comment": "Peer reviewed and to appear in the ESWC 2025 Workshops and Tutorials\n  Joint Proceedings (Workshop on Evaluation of Language Models in Knowledge\n  Engineering [ELMKE])", "summary": "When using Large Language Models (LLMs) to support Knowledge Graph\nEngineering (KGE), one of the first indications when searching for an\nappropriate model is its size. According to the scaling laws, larger models\ntypically show higher capabilities. However, in practice, resource costs are\nalso an important factor and thus it makes sense to consider the ratio between\nmodel performance and costs. The LLM-KG-Bench framework enables the comparison\nof LLMs in the context of KGE tasks and assesses their capabilities of\nunderstanding and producing KGs and KG queries. Based on a dataset created in\nan LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the\nmodel size scaling laws specific to KGE tasks. In our analyses, we assess how\nbenchmark scores evolve between different model size categories. Additionally,\nwe inspect how the general score development of single models and families of\nmodels correlates to their size. Our analyses revealed that, with a few\nexceptions, the model size scaling laws generally also apply to the selected\nKGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e.,\nthe task performance did not change much between a model and the next larger\nmodel. In these cases, smaller models could be considered to achieve high\ncost-effectiveness. Regarding models of the same family, sometimes larger\nmodels performed worse than smaller models of the same family. These effects\noccurred only locally. Hence it is advisable to additionally test the next\nsmallest and largest model of the same family.", "AI": {"tldr": "The paper explores the relationship between model size and performance in LLMs for KGE tasks, using the LLM-KG-Bench framework. While larger models generally perform better, cost-effectiveness and plateau effects suggest smaller models may sometimes be preferable.", "motivation": "To understand how model size impacts performance in KGE tasks and assess cost-effectiveness, given the trade-off between capabilities and resource costs.", "method": "The LLM-KG-Bench framework was used to evaluate 26 open state-of-the-art LLMs, analyzing performance across different model sizes and families.", "result": "Larger models generally perform better, but plateau effects and occasional worse performance in larger models of the same family suggest smaller models can be cost-effective.", "conclusion": "Model size scaling laws apply to KGE tasks, but testing adjacent model sizes within families is recommended to ensure optimal performance and cost-effectiveness."}}
{"id": "2505.16115", "pdf": "https://arxiv.org/pdf/2505.16115", "abs": "https://arxiv.org/abs/2505.16115", "authors": ["Aditya T. Vadlamani", "Anutam Srinivasan", "Pranav Maneriker", "Ali Payani", "Srinivasan Parthasarathy"], "title": "A Generic Framework for Conformal Fairness", "categories": ["cs.LG"], "comment": "ICLR 2025 Camera Ready Version", "summary": "Conformal Prediction (CP) is a popular method for uncertainty quantification\nwith machine learning models. While conformal prediction provides probabilistic\nguarantees regarding the coverage of the true label, these guarantees are\nagnostic to the presence of sensitive attributes within the dataset. In this\nwork, we formalize \\textit{Conformal Fairness}, a notion of fairness using\nconformal predictors, and provide a theoretically well-founded algorithm and\nassociated framework to control for the gaps in coverage between different\nsensitive groups. Our framework leverages the exchangeability assumption\n(implicit to CP) rather than the typical IID assumption, allowing us to apply\nthe notion of Conformal Fairness to data types and tasks that are not IID, such\nas graph data. Experiments were conducted on graph and tabular datasets to\ndemonstrate that the algorithm can control fairness-related gaps in addition to\ncoverage aligned with theoretical expectations.", "AI": {"tldr": "The paper introduces Conformal Fairness, a fairness-aware extension of Conformal Prediction (CP), ensuring balanced coverage across sensitive groups without relying on IID assumptions.", "motivation": "Current CP methods lack fairness guarantees across sensitive attributes, limiting their applicability in diverse datasets.", "method": "Proposes a framework leveraging CP's exchangeability assumption to control coverage gaps between sensitive groups, applicable to non-IID data like graphs.", "result": "Experiments on graph and tabular datasets confirm the framework's ability to balance coverage and fairness gaps as theoretically expected.", "conclusion": "Conformal Fairness extends CP's utility to fairness-critical applications, even for non-IID data."}}
{"id": "2505.16149", "pdf": "https://arxiv.org/pdf/2505.16149", "abs": "https://arxiv.org/abs/2505.16149", "authors": ["Zirui Pang", "Haosheng Tan", "Yuhan Pu", "Zhijie Deng", "Zhouan Shen", "Keyu Hu", "Jiaheng Wei"], "title": "When VLMs Meet Image Classification: Test Sets Renovation via Missing Label Identification", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Image classification benchmark datasets such as CIFAR, MNIST, and ImageNet\nserve as critical tools for model evaluation. However, despite the cleaning\nefforts, these datasets still suffer from pervasive noisy labels and often\ncontain missing labels due to the co-existing image pattern where multiple\nclasses appear in an image sample. This results in misleading model comparisons\nand unfair evaluations. Existing label cleaning methods focus primarily on\nnoisy labels, but the issue of missing labels remains largely overlooked.\nMotivated by these challenges, we present a comprehensive framework named\nREVEAL, integrating state-of-the-art pre-trained vision-language models (e.g.,\nLLaVA, BLIP, Janus, Qwen) with advanced machine/human label curation methods\n(e.g., Docta, Cleanlab, MTurk), to systematically address both noisy labels and\nmissing label detection in widely-used image classification test sets. REVEAL\ndetects potential noisy labels and omissions, aggregates predictions from\nvarious methods, and refines label accuracy through confidence-informed\npredictions and consensus-based filtering. Additionally, we provide a thorough\nanalysis of state-of-the-art vision-language models and pre-trained image\nclassifiers, highlighting their strengths and limitations within the context of\ndataset renovation by revealing 10 observations. Our method effectively reveals\nmissing labels from public datasets and provides soft-labeled results with\nlikelihoods. Through human verifications, REVEAL significantly improves the\nquality of 6 benchmark test sets, highly aligning to human judgments and\nenabling more accurate and meaningful comparisons in image classification.", "AI": {"tldr": "REVEAL is a framework combining vision-language models and label curation methods to detect and correct noisy and missing labels in image classification datasets, improving benchmark quality.", "motivation": "Existing datasets like CIFAR, MNIST, and ImageNet suffer from noisy and missing labels, leading to unfair model evaluations. Current methods overlook missing labels.", "method": "REVEAL integrates pre-trained vision-language models (e.g., LLaVA, BLIP) with label curation tools (e.g., Cleanlab, MTurk) to detect and refine noisy/missing labels via consensus-based filtering and confidence-informed predictions.", "result": "REVEAL improves label accuracy in 6 benchmark test sets, aligning closely with human judgments and providing soft-labeled results with likelihoods.", "conclusion": "REVEAL effectively addresses noisy and missing labels, enhancing dataset quality for fairer and more accurate model evaluations in image classification."}}
{"id": "2505.16125", "pdf": "https://arxiv.org/pdf/2505.16125", "abs": "https://arxiv.org/abs/2505.16125", "authors": ["Hyopil Shin", "Sangah Lee", "Dongjun Jang", "Wooseok Song", "Jaeyoon Kim", "Chaeyoung Oh", "Hyemi Jo", "Youngchae Ahn", "Sihyun Oh", "Hyohyeong Chang", "Sunkyoung Kim", "Jinsik Lee"], "title": "KoBALT: Korean Benchmark For Advanced Linguistic Tasks", "categories": ["cs.CL"], "comment": "Under Reveiw", "summary": "We introduce KoBALT (Korean Benchmark for Advanced Linguistic Tasks), a\ncomprehensive linguistically-motivated benchmark comprising 700 multiple-choice\nquestions spanning 24 phenomena across five linguistic domains: syntax,\nsemantics, pragmatics, phonetics/phonology, and morphology. KoBALT is designed\nto advance the evaluation of large language models (LLMs) in Korean, a\nmorphologically rich language, by addressing the limitations of conventional\nbenchmarks that often lack linguistic depth and typological grounding. It\nintroduces a suite of expert-curated, linguistically motivated questions with\nminimal n-gram overlap with standard Korean corpora, substantially mitigating\nthe risk of data contamination and allowing a more robust assessment of true\nlanguage understanding. Our evaluation of 20 contemporary LLMs reveals\nsignificant performance disparities, with the highest-performing model\nachieving 61\\% general accuracy but showing substantial variation across\nlinguistic domains - from stronger performance in semantics (66\\%) to\nconsiderable weaknesses in phonology (31\\%) and morphology (36\\%). Through\nhuman preference evaluation with 95 annotators, we demonstrate a strong\ncorrelation between KoBALT scores and human judgments, validating our\nbenchmark's effectiveness as a discriminative measure of Korean language\nunderstanding. KoBALT addresses critical gaps in linguistic evaluation for\ntypologically diverse languages and provides a robust framework for assessing\ngenuine linguistic competence in Korean language models.", "AI": {"tldr": "KoBALT is a Korean benchmark with 700 linguistically-motivated questions across five domains, designed to evaluate LLMs more robustly by addressing conventional benchmarks' limitations.", "motivation": "To advance LLM evaluation in Korean, a morphologically rich language, by providing a linguistically deep and typologically grounded benchmark.", "method": "Introduces expert-curated questions with minimal n-gram overlap to mitigate data contamination, evaluating 20 LLMs across linguistic domains.", "result": "LLMs show significant performance disparities (61% general accuracy), with strengths in semantics (66%) and weaknesses in phonology (31%) and morphology (36%). Human evaluation validates KoBALT's discriminative effectiveness.", "conclusion": "KoBALT fills gaps in linguistic evaluation for diverse languages and offers a robust framework for assessing Korean LLMs' true linguistic competence."}}
{"id": "2505.05291", "pdf": "https://arxiv.org/pdf/2505.05291", "abs": "https://arxiv.org/abs/2505.05291", "authors": ["Benjamin A. Cohen", "Jonathan Fhima", "Meishar Meisel", "Baskin Meital", "Luis Filipe Nakayama", "Eran Berkowitz", "Joachim A. Behar"], "title": "Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection", "categories": ["eess.IV", "cs.AI", "cs.CV", "q-bio.TO"], "comment": "10 pages, 3 figures", "summary": "Self-supervised learning (SSL) has enabled Vision Transformers (ViTs) to\nlearn robust representations from large-scale natural image datasets, enhancing\ntheir generalization across domains. In retinal imaging, foundation models\npretrained on either natural or ophthalmic data have shown promise, but the\nbenefits of in-domain pretraining remain uncertain. To investigate this, we\nbenchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets\ntotaling 70,000 expert-annotated images for the task of moderate-to-late\nage-related macular degeneration (AMD) identification. Our results show that\niBOT pretrained on natural images achieves the highest out-of-distribution\ngeneralization, with AUROCs of 0.80-0.97, outperforming domain-specific models,\nwhich achieved AUROCs of 0.78-0.96 and a baseline ViT-L with no pretraining,\nwhich achieved AUROCs of 0.68-0.91. These findings highlight the value of\nfoundation models in improving AMD identification and challenge the assumption\nthat in-domain pretraining is necessary. Furthermore, we release BRAMD, an\nopen-access dataset (n=587) of DFIs with AMD labels from Brazil.", "AI": {"tldr": "Self-supervised learning (SSL) pretrained Vision Transformers (ViTs) outperform domain-specific models in identifying age-related macular degeneration (AMD), challenging the need for in-domain pretraining.", "motivation": "To determine if in-domain pretraining is necessary for robust AMD identification in retinal imaging, comparing SSL-pretrained ViTs on natural vs. ophthalmic data.", "method": "Benchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets (70,000 images) for AMD identification.", "result": "iBOT pretrained on natural images achieved the highest generalization (AUROCs 0.80-0.97), outperforming domain-specific models (0.78-0.96) and a baseline ViT-L (0.68-0.91).", "conclusion": "Foundation models improve AMD identification, questioning the necessity of in-domain pretraining. The BRAMD dataset is released for open access."}}
{"id": "2505.16288", "pdf": "https://arxiv.org/pdf/2505.16288", "abs": "https://arxiv.org/abs/2505.16288", "authors": ["Xiaoxue Han", "Pengfei Hu", "Jun-En Ding", "Chang Lu", "Feng Liu", "Yue Ning"], "title": "No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning models trained on extensive Electronic Health Records (EHR)\ndata have achieved high accuracy in diagnosis prediction, offering the\npotential to assist clinicians in decision-making and treatment planning.\nHowever, these models lack two crucial features that clinicians highly value:\ninterpretability and interactivity. The ``black-box'' nature of these models\nmakes it difficult for clinicians to understand the reasoning behind\npredictions, limiting their ability to make informed decisions. Additionally,\nthe absence of interactive mechanisms prevents clinicians from incorporating\ntheir own knowledge and experience into the decision-making process. To address\nthese limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal\ndiscovery framework that integrates personalized knowledge databases and\nagentic LLMs. II-KEA enhances interpretability through explicit reasoning and\ncausal analysis, while also improving interactivity by allowing clinicians to\ninject their knowledge and experience through customized knowledge bases and\nprompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating\nsuperior performance along with enhanced interpretability and interactivity, as\nevidenced by its strong results from extensive case studies.", "AI": {"tldr": "II-KEA is a framework enhancing interpretability and interactivity in EHR-based deep learning models for diagnosis prediction by integrating knowledge databases and agentic LLMs.", "motivation": "Current deep learning models for EHR lack interpretability and interactivity, limiting clinician trust and decision-making.", "method": "II-KEA uses knowledge-enhanced agent-driven causal discovery, personalized knowledge databases, and agentic LLMs for explicit reasoning and clinician interaction.", "result": "Evaluated on MIMIC-III and MIMIC-IV, II-KEA shows superior performance, interpretability, and interactivity in case studies.", "conclusion": "II-KEA addresses key limitations of EHR models, improving clinician trust and decision-making through interpretability and interactivity."}}
{"id": "2505.16122", "pdf": "https://arxiv.org/pdf/2505.16122", "abs": "https://arxiv.org/abs/2505.16122", "authors": ["Junhong Lin", "Xinyue Zeng", "Jie Zhu", "Song Wang", "Julian Shun", "Jun Wu", "Dawei Zhou"], "title": "Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success in complex\nreasoning tasks, but their inference remains computationally inefficient. We\nobserve a common failure mode in many prevalent LLMs, overthinking, where\nmodels generate verbose and tangential reasoning traces even for simple\nqueries. Recent works have tried to mitigate this by enforcing fixed token\nbudgets, however, this can lead to underthinking, especially on harder\nproblems. Through empirical analysis, we identify that this inefficiency often\nstems from unclear problem-solving strategies. To formalize this, we develop a\ntheoretical model, BBAM (Bayesian Budget Allocation Model), which models\nreasoning as a sequence of sub-questions with varying uncertainty, and\nintroduce the $E^3$ metric to capture the trade-off between correctness and\ncomputation efficiency. Building on theoretical results from BBAM, we propose\nPlan-and-Budget, a model-agnostic, test-time framework that decomposes complex\nqueries into sub-questions and allocates token budgets based on estimated\ncomplexity using adaptive scheduling. Plan-and-Budget improves reasoning\nefficiency across a range of tasks and models, achieving up to +70% accuracy\ngains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it\nelevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger\nmodel (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close\nperformance gaps without retraining. Our code is available at\nanonymous.4open.science/r/P-and-B-6513/.", "AI": {"tldr": "The paper addresses computational inefficiency in LLMs due to overthinking, proposing Plan-and-Budget, a framework that improves reasoning efficiency by decomposing queries and allocating token budgets adaptively.", "motivation": "LLMs often overthink, generating verbose reasoning for simple queries, leading to inefficiency. Fixed token budgets can cause underthinking on harder problems.", "method": "Develops BBAM, a theoretical model for reasoning as sub-questions with uncertainty, and introduces the $E^3$ metric. Proposes Plan-and-Budget, a framework for adaptive token allocation.", "result": "Plan-and-Budget improves efficiency: +70% accuracy, -39% tokens, +187.5% $E^3$ gain. Smaller models match larger ones' efficiency.", "conclusion": "Plan-and-Budget effectively balances correctness and efficiency, closing performance gaps without retraining."}}
{"id": "2505.16151", "pdf": "https://arxiv.org/pdf/2505.16151", "abs": "https://arxiv.org/abs/2505.16151", "authors": ["Hongchen Wei", "Zhenzhong Chen"], "title": "Training-Free Reasoning and Reflection in MLLMs", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in Reasoning LLMs (e.g., DeepSeek-R1 and OpenAI-o1) have\nshowcased impressive reasoning capabilities via reinforcement learning.\nHowever, extending these capabilities to Multimodal LLMs (MLLMs) is hampered by\nthe prohibitive costs of retraining and the scarcity of high-quality,\nverifiable multimodal reasoning datasets. This paper introduces FRANK Model, a\ntraining-FRee ANd r1-liKe MLLM that imbues off-the-shelf MLLMs with reasoning\nand reflection abilities, without any gradient updates or extra supervision.\nOur key insight is to decouple perception and reasoning across MLLM decoder\nlayers. Specifically, we observe that compared to the deeper decoder layers,\nthe shallow decoder layers allocate more attention to visual tokens, while the\ndeeper decoder layers concentrate on textual semantics. This observation\nmotivates a hierarchical weight merging approach that combines a\nvisual-pretrained MLLM with a reasoning-specialized LLM. To this end, we\npropose a layer-wise, Taylor-derived closed-form fusion mechanism that\nintegrates reasoning capacity into deep decoder layers while preserving visual\ngrounding in shallow decoder layers. Extensive experiments on challenging\nmultimodal reasoning benchmarks demonstrate the effectiveness of our approach.\nOn the MMMU benchmark, our model FRANK-38B achieves an accuracy of 69.2,\noutperforming the strongest baseline InternVL2.5-38B by +5.3, and even\nsurpasses the proprietary GPT-4o model. Our project homepage is at:\nhttp://iip.whu.edu.cn/frank/index.html", "AI": {"tldr": "FRANK Model enhances off-the-shelf MLLMs with reasoning abilities without retraining, using hierarchical weight merging and outperforms baselines like GPT-4o.", "motivation": "Extending reasoning capabilities to MLLMs is costly due to retraining expenses and lack of high-quality datasets.", "method": "Decouples perception and reasoning via hierarchical weight merging, integrating reasoning into deep decoder layers while preserving visual grounding in shallow layers.", "result": "Achieves 69.2 accuracy on MMMU benchmark, surpassing InternVL2.5-38B by +5.3 and GPT-4o.", "conclusion": "FRANK Model effectively adds reasoning to MLLMs without training, demonstrating superior performance."}}
{"id": "2505.16128", "pdf": "https://arxiv.org/pdf/2505.16128", "abs": "https://arxiv.org/abs/2505.16128", "authors": ["Yue Zhou", "Barbara Di Eugenio"], "title": "Veracity Bias and Beyond: Uncovering LLMs' Hidden Beliefs in Problem-Solving Reasoning", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 (Main)", "summary": "Despite LLMs' explicit alignment against demographic stereotypes, they have\nbeen shown to exhibit biases under various social contexts. In this work, we\nfind that LLMs exhibit concerning biases in how they associate solution\nveracity with demographics. Through experiments across five human value-aligned\nLLMs on mathematics, coding, commonsense, and writing problems, we reveal two\nforms of such veracity biases: Attribution Bias, where models\ndisproportionately attribute correct solutions to certain demographic groups,\nand Evaluation Bias, where models' assessment of identical solutions varies\nbased on perceived demographic authorship. Our results show pervasive biases:\nLLMs consistently attribute fewer correct solutions and more incorrect ones to\nAfrican-American groups in math and coding, while Asian authorships are least\npreferred in writing evaluation. In additional studies, we show LLMs\nautomatically assign racially stereotypical colors to demographic groups in\nvisualization code, suggesting these biases are deeply embedded in models'\nreasoning processes. Our findings indicate that demographic bias extends beyond\nsurface-level stereotypes and social context provocations, raising concerns\nabout LLMs' deployment in educational and evaluation settings.", "AI": {"tldr": "LLMs exhibit biases in associating solution veracity with demographics, showing Attribution and Evaluation Biases, with African-American and Asian groups disproportionately affected.", "motivation": "To uncover and analyze biases in LLMs' association of solution correctness with demographics, despite explicit alignment against stereotypes.", "method": "Experiments across five human value-aligned LLMs on math, coding, commonsense, and writing problems, identifying Attribution and Evaluation Biases.", "result": "LLMs attribute fewer correct solutions to African-American groups in math/coding and least prefer Asian authorships in writing. Biases are deeply embedded, as shown in visualization code.", "conclusion": "Demographic bias in LLMs extends beyond surface stereotypes, posing risks for educational and evaluation deployments."}}
{"id": "2306.06378", "pdf": "https://arxiv.org/pdf/2306.06378", "abs": "https://arxiv.org/abs/2306.06378", "authors": ["Alexandros Gkillas", "Dimitris Ampeliotis", "Kostas Berberidis"], "title": "A Deep Unrolling Model with Hybrid Optimization Structure for Hyperspectral Image Deconvolution", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "In recent literature there are plenty of works that combine handcrafted and\nlearnable regularizers to solve inverse imaging problems. While this hybrid\napproach has demonstrated promising results, the motivation for combining\nhandcrafted and learnable regularizers remains largely underexplored. This work\naims to justify this combination, by demonstrating that the incorporation of\nproper handcrafted regularizers alongside learnable regularizers not only\nreduces the complexity of the learnable prior, but also the performance is\nnotably enhanced. To analyze the impact of this synergy, we introduce the\nnotion of residual structure, to refer to the structure of the solution that\ncannot be modeled by the handcrafted regularizers per se. Motivated by these,\nwe propose a novel optimization framework for the hyperspectral deconvolution\nproblem, called DeepMix. Based on the proposed optimization framework, an\ninterpretable model is developed using the deep unrolling strategy, which\nconsists of three distinct modules, namely, a data consistency module, a module\nthat enforces the effect of the handcrafted regularizers, and a denoising\nmodule. Recognizing the collaborative nature of these modules, this work\nproposes a context aware denoising module designed to sustain the advancements\nachieved by the cooperative efforts of the other modules. This is facilitated\nthrough the incorporation of a proper skip connection, ensuring that essential\ndetails and structures identified by other modules are effectively retained and\nnot lost during denoising. Extensive experimental results across simulated and\nreal-world datasets demonstrate that DeepMix is notable for surpassing existing\nmethodologies, offering marked improvements in both image quality and\ncomputational efficiency.", "AI": {"tldr": "The paper justifies combining handcrafted and learnable regularizers in inverse imaging problems, introducing a novel framework (DeepMix) that enhances performance and reduces complexity.", "motivation": "To explore the synergy between handcrafted and learnable regularizers, demonstrating their combined benefits in reducing complexity and improving performance.", "method": "Proposes DeepMix, an interpretable model using deep unrolling with three modules: data consistency, handcrafted regularizer enforcement, and a context-aware denoising module with skip connections.", "result": "DeepMix outperforms existing methods, improving image quality and computational efficiency in experiments on simulated and real-world datasets.", "conclusion": "The combination of handcrafted and learnable regularizers, facilitated by DeepMix, is effective and enhances performance in inverse imaging problems."}}
{"id": "2505.16312", "pdf": "https://arxiv.org/pdf/2505.16312", "abs": "https://arxiv.org/abs/2505.16312", "authors": ["Jiawei Liu", "Qisi Chen", "Jianshu Zhang", "Quan Liu", "Defu Lian"], "title": "EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning", "categories": ["cs.AI", "cs.CL"], "comment": "11 pages, 4 figures", "summary": "Large Language Models (LLMs) excel at complex reasoning through search\nalgorithms, yet current strategies often suffer from massive token consumption\ndue to redundant exploration of semantically equivalent steps. Existing\nsemantic similarity methods struggle to accurately identify such equivalence in\ndomain-specific contexts like mathematical reasoning. To address this, we\npropose EquivPruner, a simple yet effective approach that identifies and prunes\nsemantically equivalent actions during LLM reasoning search. We also introduce\nMathEquiv, the first dataset we created for mathematical statement equivalence,\nwhich enables the training of a lightweight equivalence detector. Extensive\nexperiments across various models and tasks demonstrate that EquivPruner\nsignificantly reduces token consumption, improving searching efficiency and\noften bolstering reasoning accuracy. For instance, when applied to\nQwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by\n48.1\\% while also improving accuracy. Our code is available at\nhttps://github.com/Lolo1222/EquivPruner.", "AI": {"tldr": "EquivPruner reduces token consumption in LLM reasoning by pruning semantically equivalent steps, improving efficiency and accuracy.", "motivation": "Current LLM reasoning strategies waste tokens on redundant exploration of semantically equivalent steps, especially in domain-specific contexts like math.", "method": "Proposes EquivPruner to prune equivalent actions and introduces MathEquiv dataset for training an equivalence detector.", "result": "EquivPruner reduces token use by 48.1% and improves accuracy on tasks like GSM8K.", "conclusion": "EquivPruner is effective for efficient LLM reasoning, with potential for broader applications."}}
{"id": "2505.16126", "pdf": "https://arxiv.org/pdf/2505.16126", "abs": "https://arxiv.org/abs/2505.16126", "authors": ["Kotaro Yoshida", "Slavakis Konstantinos"], "title": "Robust Invariant Representation Learning by Distribution Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Invariant risk minimization (IRM) aims to enable out-of-distribution (OOD)\ngeneralization in deep learning by learning invariant representations. As IRM\nposes an inherently challenging bi-level optimization problem, most existing\napproaches -- including IRMv1 -- adopt penalty-based single-level\napproximations. However, empirical studies consistently show that these methods\noften fail to outperform well-tuned empirical risk minimization (ERM),\nhighlighting the need for more robust IRM implementations. This work\ntheoretically identifies a key limitation common to many IRM variants: their\npenalty terms are highly sensitive to limited environment diversity and\nover-parameterization, resulting in performance degradation. To address this\nissue, a novel extrapolation-based framework is proposed that enhances\nenvironmental diversity by augmenting the IRM penalty through synthetic\ndistributional shifts. Extensive experiments -- ranging from synthetic setups\nto realistic, over-parameterized scenarios -- demonstrate that the proposed\nmethod consistently outperforms state-of-the-art IRM variants, validating its\neffectiveness and robustness.", "AI": {"tldr": "The paper proposes an extrapolation-based framework to improve IRM by addressing its sensitivity to limited environment diversity and over-parameterization, outperforming existing IRM variants.", "motivation": "Existing IRM methods, like IRMv1, often fail to outperform ERM due to sensitivity to limited environment diversity and over-parameterization.", "method": "A novel extrapolation-based framework is introduced, enhancing IRM by augmenting its penalty with synthetic distributional shifts.", "result": "The proposed method consistently outperforms state-of-the-art IRM variants in experiments, including synthetic and over-parameterized scenarios.", "conclusion": "The framework effectively addresses IRM's limitations, offering improved robustness and performance for OOD generalization."}}
{"id": "2505.16154", "pdf": "https://arxiv.org/pdf/2505.16154", "abs": "https://arxiv.org/abs/2505.16154", "authors": ["Ji Guo", "Long Zhou", "Zhijin Wang", "Jiaming He", "Qiyang Song", "Aiguo Chen", "Wenbo Jiang"], "title": "BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, deep learning-based Monocular Depth Estimation (MDE) models\nhave been widely applied in fields such as autonomous driving and robotics.\nHowever, their vulnerability to backdoor attacks remains unexplored. To fill\nthe gap in this area, we conduct a comprehensive investigation of backdoor\nattacks against MDE models. Typically, existing backdoor attack methods can not\nbe applied to MDE models. This is because the label used in MDE is in the form\nof a depth map. To address this, we propose BadDepth, the first backdoor attack\ntargeting MDE models. BadDepth overcomes this limitation by selectively\nmanipulating the target object's depth using an image segmentation model and\nrestoring the surrounding areas via depth completion, thereby generating\npoisoned datasets for object-level backdoor attacks. To improve robustness in\nphysical world scenarios, we further introduce digital-to-physical augmentation\nto adapt to the domain gap between the physical world and the digital domain.\nExtensive experiments on multiple models validate the effectiveness of BadDepth\nin both the digital domain and the physical world, without being affected by\nenvironmental factors.", "AI": {"tldr": "BadDepth is the first backdoor attack method for Monocular Depth Estimation (MDE) models, overcoming limitations of existing methods by manipulating object depth and using digital-to-physical augmentation for robustness.", "motivation": "The vulnerability of MDE models to backdoor attacks is unexplored, despite their widespread use in critical applications like autonomous driving and robotics.", "method": "BadDepth selectively manipulates target object depth using image segmentation and depth completion, generating poisoned datasets. Digital-to-physical augmentation is introduced for real-world robustness.", "result": "Extensive experiments show BadDepth's effectiveness in digital and physical domains, unaffected by environmental factors.", "conclusion": "BadDepth successfully addresses the gap in backdoor attacks for MDE models, proving robust in real-world scenarios."}}
{"id": "2505.16129", "pdf": "https://arxiv.org/pdf/2505.16129", "abs": "https://arxiv.org/abs/2505.16129", "authors": ["Hyang Cui"], "title": "LLMs Are Not Scorers: Rethinking MT Evaluation with Generation-Based Methods", "categories": ["cs.CL", "I.2.7"], "comment": "5 pages, 2 figures, 2 tables. Conforms to the ACL Rolling Review\n  (ARR) short paper track. Code and data available at:\n  https://github.com/CuiNiki/LLMs-Are-Not-Scorers", "summary": "Recent studies have applied large language models (LLMs) to machine\ntranslation quality estimation (MTQE) by prompting models to assign numeric\nscores. Nonetheless, these direct scoring methods tend to show low\nsegment-level correlation with human judgments. In this paper, we propose a\ngeneration-based evaluation paradigm that leverages decoder-only LLMs to\nproduce high-quality references, followed by semantic similarity scoring using\nsentence embeddings. We conduct the most extensive evaluation to date in MTQE,\ncovering 8 LLMs and 8 language pairs. Empirical results show that our method\noutperforms both intra-LLM direct scoring baselines and external non-LLM\nreference-free metrics from MTME. These findings demonstrate the strength of\ngeneration-based evaluation and support a shift toward hybrid approaches that\ncombine fluent generation with accurate semantic assessment.", "AI": {"tldr": "A generation-based evaluation paradigm using LLMs for MTQE outperforms direct scoring and non-LLM metrics, advocating hybrid approaches.", "motivation": "Direct scoring methods for MTQE with LLMs show low correlation with human judgments, prompting the need for better evaluation methods.", "method": "Proposes using decoder-only LLMs to generate high-quality references, then scoring semantic similarity with sentence embeddings.", "result": "Outperforms direct scoring baselines and non-LLM metrics in extensive evaluation across 8 LLMs and 8 language pairs.", "conclusion": "Supports hybrid approaches combining fluent generation and semantic assessment for improved MTQE."}}
{"id": "2306.07999", "pdf": "https://arxiv.org/pdf/2306.07999", "abs": "https://arxiv.org/abs/2306.07999", "authors": ["Clare McGenity", "Emily L Clarke", "Charlotte Jennings", "Gillian Matthews", "Caroline Cartlidge", "Henschel Freduah-Agyemang", "Deborah D Stocken", "Darren Treanor"], "title": "Artificial intelligence in digital pathology: a systematic review and meta-analysis of diagnostic test accuracy", "categories": ["physics.med-ph", "cs.AI", "cs.CV", "eess.IV", "q-bio.QM", "I.2.1"], "comment": "26 pages, 5 figures, 8 tables + Supplementary materials Preprint is\n  pre-peer review version. Please see link for updated, peer reviewed article\n  to see latest version", "summary": "Ensuring diagnostic performance of AI models before clinical use is key to\nthe safe and successful adoption of these technologies. Studies reporting AI\napplied to digital pathology images for diagnostic purposes have rapidly\nincreased in number in recent years. The aim of this work is to provide an\noverview of the diagnostic accuracy of AI in digital pathology images from all\nareas of pathology. This systematic review and meta-analysis included\ndiagnostic accuracy studies using any type of artificial intelligence applied\nto whole slide images (WSIs) in any disease type. The reference standard was\ndiagnosis through histopathological assessment and / or immunohistochemistry.\nSearches were conducted in PubMed, EMBASE and CENTRAL in June 2022. We\nidentified 2976 studies, of which 100 were included in the review and 48 in the\nfull meta-analysis. Risk of bias and concerns of applicability were assessed\nusing the QUADAS-2 tool. Data extraction was conducted by two investigators and\nmeta-analysis was performed using a bivariate random effects model. 100 studies\nwere identified for inclusion, equating to over 152,000 whole slide images\n(WSIs) and representing many disease types. Of these, 48 studies were included\nin the meta-analysis. These studies reported a mean sensitivity of 96.3% (CI\n94.1-97.7) and mean specificity of 93.3% (CI 90.5-95.4) for AI. There was\nsubstantial heterogeneity in study design and all 100 studies identified for\ninclusion had at least one area at high or unclear risk of bias. This review\nprovides a broad overview of AI performance across applications in whole slide\nimaging. However, there is huge variability in study design and available\nperformance data, with details around the conduct of the study and make up of\nthe datasets frequently missing. Overall, AI offers good accuracy when applied\nto WSIs but requires more rigorous evaluation of its performance.", "AI": {"tldr": "This systematic review evaluates AI's diagnostic accuracy in digital pathology, finding high sensitivity (96.3%) and specificity (93.3%) but noting variability and bias risks in studies.", "motivation": "To assess AI's diagnostic performance in digital pathology for safe clinical adoption, given the rapid increase in AI applications.", "method": "A systematic review and meta-analysis of 100 studies (48 in meta-analysis) using AI on whole slide images (WSIs), with histopathology as the reference standard.", "result": "AI showed high mean sensitivity (96.3%) and specificity (93.3%), but studies had significant heterogeneity and bias risks.", "conclusion": "AI performs well in digital pathology but requires more rigorous evaluation due to variability and study design issues."}}
{"id": "2505.16315", "pdf": "https://arxiv.org/pdf/2505.16315", "abs": "https://arxiv.org/abs/2505.16315", "authors": ["Xiaoxue Cheng", "Junyi Li", "Zhenduo Zhang", "Xinyu Tang", "Wayne Xin Zhao", "Xinyu Kong", "Zhiqiang Zhang"], "title": "Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "work in progress", "summary": "Large reasoning models (LRMs) have demonstrated strong performance on complex\nreasoning tasks, but often suffer from overthinking, generating redundant\ncontent regardless of task difficulty. Inspired by the dual process theory in\ncognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a\nreinforcement learning framework that enables LRMs to achieve efficient\nreasoning through adaptive cognitive allocation and dynamic system switch. ACPO\nincorporates two key components: (1) introducing system-aware reasoning tokens\nto explicitly represent the thinking modes thereby making the model's cognitive\nprocess transparent, and (2) integrating online difficulty estimation and token\nlength budget to guide adaptive system switch and reasoning during\nreinforcement learning. To this end, we propose a two-stage training strategy.\nThe first stage begins with supervised fine-tuning to cold start the model,\nenabling it to generate reasoning paths with explicit thinking modes. In the\nsecond stage, we apply ACPO to further enhance adaptive system switch for\ndifficulty-aware reasoning. Experimental results demonstrate that ACPO\neffectively reduces redundant reasoning while adaptively adjusting cognitive\nallocation based on task complexity, achieving efficient hybrid reasoning.", "AI": {"tldr": "ACPO is a reinforcement learning framework for large reasoning models to reduce redundant reasoning by adaptive cognitive allocation and dynamic system switch.", "motivation": "Large reasoning models often generate redundant content regardless of task difficulty, leading to inefficiency.", "method": "ACPO uses system-aware reasoning tokens and online difficulty estimation to guide adaptive reasoning. It involves a two-stage training strategy: supervised fine-tuning followed by reinforcement learning.", "result": "ACPO reduces redundant reasoning and adapts cognitive allocation based on task complexity, achieving efficient hybrid reasoning.", "conclusion": "ACPO enhances reasoning efficiency in large models by dynamically adjusting cognitive processes."}}
{"id": "2505.16130", "pdf": "https://arxiv.org/pdf/2505.16130", "abs": "https://arxiv.org/abs/2505.16130", "authors": ["Zehong Wang", "Zheyuan Zhang", "Tianyi Ma", "Chuxu Zhang", "Yanfang Ye"], "title": "Scalable Graph Generative Modeling via Substructure Sequences", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": null, "summary": "Graph neural networks (GNNs) has been predominantly driven by\nmessage-passing, where node representations are iteratively updated via local\nneighborhood aggregation. Despite their success, message-passing suffers from\nfundamental limitations -- including constrained expressiveness,\nover-smoothing, over-squashing, and limited capacity to model long-range\ndependencies. These issues hinder scalability: increasing data size or model\nsize often fails to yield improved performance, limiting the viability of GNNs\nas backbones for graph foundation models. In this work, we explore pathways\nbeyond message-passing and introduce Generative Graph Pattern Machine\n(G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM\nrepresents graph instances (nodes, edges, or entire graphs) as sequences of\nsubstructures, and employs generative pre-training over the sequences to learn\ngeneralizable, transferable representations. Empirically, G$^2$PM demonstrates\nstrong scalability: on the ogbn-arxiv benchmark, it continues to improve with\nmodel sizes up to 60M parameters, outperforming prior generative approaches\nthat plateau at significantly smaller scales (e.g., 3M). In addition, we\nsystematically analyze the model design space, highlighting key architectural\nchoices that contribute to its scalability and generalization. Across diverse\ntasks -- including node classification, graph classification, and transfer\nlearning -- G$^2$PM consistently outperforms strong baselines, establishing a\ncompelling foundation for scalable graph learning. The code and dataset are\navailable at https://github.com/Zehong-Wang/G2PM.", "AI": {"tldr": "The paper introduces G$^2$PM, a generative Transformer framework for graphs, addressing limitations of message-passing GNNs like expressiveness and scalability. It outperforms baselines and scales well with model size.", "motivation": "Message-passing GNNs face issues like constrained expressiveness and scalability, limiting their use as graph foundation models.", "method": "G$^2$PM represents graphs as sequences of substructures and uses generative pre-training to learn transferable representations.", "result": "G$^2$PM scales effectively (up to 60M parameters) and outperforms prior methods on tasks like node and graph classification.", "conclusion": "G$^2$PM provides a scalable and generalizable foundation for graph learning, surpassing traditional GNNs."}}
{"id": "2505.16157", "pdf": "https://arxiv.org/pdf/2505.16157", "abs": "https://arxiv.org/abs/2505.16157", "authors": ["Yuang Ai", "Huaibo Huang", "Tao Wu", "Qihang Fan", "Ran He"], "title": "Breaking Complexity Barriers: High-Resolution Image Restoration with Rank Enhanced Linear Attention", "categories": ["cs.CV"], "comment": "13 pages, 7 figures, 12 tables", "summary": "Transformer-based models have made remarkable progress in image restoration\n(IR) tasks. However, the quadratic complexity of self-attention in Transformer\nhinders its applicability to high-resolution images. Existing methods mitigate\nthis issue with sparse or window-based attention, yet inherently limit global\ncontext modeling. Linear attention, a variant of softmax attention,\ndemonstrates promise in global context modeling while maintaining linear\ncomplexity, offering a potential solution to the above challenge. Despite its\nefficiency benefits, vanilla linear attention suffers from a significant\nperformance drop in IR, largely due to the low-rank nature of its attention\nmap. To counter this, we propose Rank Enhanced Linear Attention (RELA), a\nsimple yet effective method that enriches feature representations by\nintegrating a lightweight depthwise convolution. Building upon RELA, we propose\nan efficient and effective image restoration Transformer, named LAformer.\nLAformer achieves effective global perception by integrating linear attention\nand channel attention, while also enhancing local fitting capabilities through\na convolutional gated feed-forward network. Notably, LAformer eliminates\nhardware-inefficient operations such as softmax and window shifting, enabling\nefficient processing of high-resolution images. Extensive experiments across 7\nIR tasks and 21 benchmarks demonstrate that LAformer outperforms SOTA methods\nand offers significant computational advantages.", "AI": {"tldr": "LAformer, a Transformer-based model with Rank Enhanced Linear Attention (RELA), improves image restoration by combining linear and channel attention, outperforming SOTA methods efficiently.", "motivation": "Address the quadratic complexity and limited global context modeling of Transformer-based models in high-resolution image restoration.", "method": "Propose RELA to enhance linear attention with depthwise convolution, and LAformer integrates linear and channel attention for global perception and local fitting.", "result": "LAformer outperforms SOTA methods across 7 IR tasks and 21 benchmarks with computational efficiency.", "conclusion": "LAformer offers an efficient and effective solution for high-resolution image restoration, overcoming limitations of existing methods."}}
{"id": "2505.16134", "pdf": "https://arxiv.org/pdf/2505.16134", "abs": "https://arxiv.org/abs/2505.16134", "authors": ["Menschikov Mikhail", "Alexander Kharitonov", "Maiia Kotyga", "Vadim Porvatov", "Anna Zhukovskaya", "David Kagramanyan", "Egor Shvetsov", "Evgeny Burnaev"], "title": "Position of Uncertainty: A Cross-Linguistic Study of Positional Bias in Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models exhibit positional bias -- systematic neglect of\ninformation at specific context positions -- yet its interplay with linguistic\ndiversity remains poorly understood. We present a cross-linguistic study across\nfive typologically distinct languages (English, Russian, German, Hindi,\nVietnamese), examining how positional bias interacts with model uncertainty,\nsyntax, and prompting. Key findings: (1) Positional bias is model-driven, with\nlanguage-specific variations -- Qwen2.5-7B favors late positions, challenging\nassumptions of early-token bias; (2) Explicit positional guidance (e.g.,\ncorrect context is at position X) reduces accuracy across languages,\nundermining prompt-engineering practices; (3) Aligning context with positional\nbias increases entropy, yet minimal entropy does not predict accuracy. (4) We\nfurther uncover that LLMs differently impose dominant word order in\nfree-word-order languages like Hindi.", "AI": {"tldr": "Study explores positional bias in large language models across five languages, revealing model-driven variations, challenges in prompt engineering, and unexpected interactions with syntax and uncertainty.", "motivation": "To understand how positional bias in large language models interacts with linguistic diversity, model uncertainty, syntax, and prompting across typologically distinct languages.", "method": "A cross-linguistic study analyzing positional bias in five languages (English, Russian, German, Hindi, Vietnamese) by examining model behavior, uncertainty, syntax, and the impact of explicit positional guidance.", "result": "(1) Positional bias varies by model and language (e.g., Qwen2.5-7B favors late positions). (2) Explicit positional guidance reduces accuracy. (3) Aligning context with bias increases entropy, but minimal entropy doesn't predict accuracy. (4) LLMs impose dominant word order in free-word-order languages like Hindi.", "conclusion": "Positional bias is model-specific and context-dependent, challenging assumptions and prompt-engineering practices, with implications for multilingual NLP applications."}}
{"id": "2503.03637", "pdf": "https://arxiv.org/pdf/2503.03637", "abs": "https://arxiv.org/abs/2503.03637", "authors": ["Woo-Jin Jung", "Dong-Hee Paek", "Seung-Hyun Kong"], "title": "L2RDaS: Synthesizing 4D Radar Tensors for Model Generalization via Dataset Expansion", "categories": ["cs.CV", "eess.IV"], "comment": "9 pages, 3 figures, Arxiv preprint", "summary": "4-dimensional (4D) radar is increasingly adopted in autonomous driving for\nperception tasks, owing to its robustness under adverse weather conditions. To\nbetter utilize the spatial information inherent in 4D radar data, recent deep\nlearning methods have transitioned from using sparse point cloud to 4D radar\ntensors. However, the scarcity of publicly available 4D radar tensor datasets\nlimits model generalization across diverse driving scenarios. Previous methods\naddressed this by synthesizing radar data, but the outputs did not fully\nexploit the spatial information characteristic of 4D radar. To overcome these\nlimitations, we propose LiDAR-to-4D radar data synthesis (L2RDaS), a framework\nthat synthesizes spatially informative 4D radar tensors from LiDAR data\navailable in existing autonomous driving datasets. L2RDaS integrates a modified\nU-Net architecture to effectively capture spatial information and an object\ninformation supplement (OBIS) module to enhance reflection fidelity. This\nframework enables the synthesis of radar tensors across diverse driving\nscenarios without additional sensor deployment or data collection. L2RDaS\nimproves model generalization by expanding real datasets with synthetic radar\ntensors, achieving an average increase of 4.25\\% in ${{AP}_{BEV}}$ and 2.87\\%\nin ${{AP}_{3D}}$ across three detection models. Additionally, L2RDaS supports\nground-truth augmentation (GT-Aug) by embedding annotated objects into LiDAR\ndata and synthesizing them into radar tensors, resulting in further average\nincreases of 3.75\\% in ${{AP}_{BEV}}$ and 4.03\\% in ${{AP}_{3D}}$. The\nimplementation will be available at https://github.com/kaist-avelab/K-Radar.", "AI": {"tldr": "L2RDaS synthesizes 4D radar tensors from LiDAR data to address dataset scarcity, improving model generalization and detection performance.", "motivation": "The scarcity of publicly available 4D radar tensor datasets limits model generalization, and existing synthetic methods fail to fully utilize spatial information.", "method": "Proposes L2RDaS, a framework using a modified U-Net and OBIS module to synthesize 4D radar tensors from LiDAR data.", "result": "Improves detection performance by 4.25% in $AP_{BEV}$ and 2.87% in $AP_{3D}$, with further gains via GT-Aug.", "conclusion": "L2RDaS effectively enhances model generalization and performance by leveraging existing LiDAR datasets for radar tensor synthesis."}}
{"id": "2505.16388", "pdf": "https://arxiv.org/pdf/2505.16388", "abs": "https://arxiv.org/abs/2505.16388", "authors": ["Nandini Doreswamy", "Louise Horstmanshof"], "title": "Serious Games: Human-AI Interaction, Evolution, and Coevolution", "categories": ["cs.AI", "cs.GT", "91A22 (Primary), 68T99 (Secondary)", "J.4; I.2.0; K.4.1; J.3; K.4.0"], "comment": "8 pages, 1 table", "summary": "The serious games between humans and AI have only just begun. Evolutionary\nGame Theory (EGT) models the competitive and cooperative strategies of\nbiological entities. EGT could help predict the potential evolutionary\nequilibrium of humans and AI. The objective of this work was to examine some of\nthe EGT models relevant to human-AI interaction, evolution, and coevolution. Of\nthirteen EGT models considered, three were examined: the Hawk-Dove Game,\nIterated Prisoner's Dilemma, and the War of Attrition. This selection was based\non the widespread acceptance and clear relevance of these models to potential\nhuman-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove\nGame predicts balanced mixed-strategy equilibria based on the costs of\nconflict. It also shows the potential for balanced coevolution rather than\ndominance. Iterated Prisoner's Dilemma suggests that repeated interaction may\nlead to cognitive coevolution. It demonstrates how memory and reciprocity can\nlead to cooperation. The War of Attrition suggests that competition for\nresources may result in strategic coevolution, asymmetric equilibria, and\nconventions on sharing resources. Therefore, EGT may provide a suitable\nframework to understand and predict the human-AI evolutionary dynamic. However,\nfuture research could extend beyond EGT and explore additional frameworks,\nempirical validation methods, and interdisciplinary perspectives. AI is being\nshaped by human input and is evolving in response to it. So too,\nneuroplasticity allows the human brain to grow and evolve in response to\nstimuli. If humans and AI converge in future, what might be the result of human\nneuroplasticity combined with an ever-evolving AI? Future research should be\nmindful of the ethical and cognitive implications of human-AI interaction,\nevolution, and coevolution.", "AI": {"tldr": "The paper explores Evolutionary Game Theory (EGT) models to predict human-AI evolutionary dynamics, focusing on Hawk-Dove Game, Iterated Prisoner's Dilemma, and War of Attrition. It suggests EGT as a framework for understanding coevolution but calls for future interdisciplinary and ethical research.", "motivation": "To understand and predict the evolutionary equilibrium and coevolutionary trajectories between humans and AI using EGT models.", "method": "Examination of three EGT models (Hawk-Dove Game, Iterated Prisoner's Dilemma, War of Attrition) based on their relevance to human-AI dynamics.", "result": "EGT models predict mixed-strategy equilibria, cognitive coevolution, and strategic coevolution, suggesting a framework for human-AI interaction.", "conclusion": "EGT provides insights into human-AI dynamics, but future research should expand frameworks, validate empirically, and address ethical implications of coevolution."}}
{"id": "2505.16138", "pdf": "https://arxiv.org/pdf/2505.16138", "abs": "https://arxiv.org/abs/2505.16138", "authors": ["Heqiang Wang", "Xiang Liu", "Xiaoxiong Zhong", "Lixing Chen", "Fangming Liu", "Weizhe Zhang"], "title": "Multimodal Online Federated Learning with Modality Missing in Internet of Things", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "The Internet of Things (IoT) ecosystem generates vast amounts of multimodal\ndata from heterogeneous sources such as sensors, cameras, and microphones. As\nedge intelligence continues to evolve, IoT devices have progressed from simple\ndata collection units to nodes capable of executing complex computational\ntasks. This evolution necessitates the adoption of distributed learning\nstrategies to effectively handle multimodal data in an IoT environment.\nFurthermore, the real-time nature of data collection and limited local storage\non edge devices in IoT call for an online learning paradigm. To address these\nchallenges, we introduce the concept of Multimodal Online Federated Learning\n(MMO-FL), a novel framework designed for dynamic and decentralized multimodal\nlearning in IoT environments. Building on this framework, we further account\nfor the inherent instability of edge devices, which frequently results in\nmissing modalities during the learning process. We conduct a comprehensive\ntheoretical analysis under both complete and missing modality scenarios,\nproviding insights into the performance degradation caused by missing\nmodalities. To mitigate the impact of modality missing, we propose the\nPrototypical Modality Mitigation (PMM) algorithm, which leverages prototype\nlearning to effectively compensate for missing modalities. Experimental results\non two multimodal datasets further demonstrate the superior performance of PMM\ncompared to benchmarks.", "AI": {"tldr": "The paper proposes Multimodal Online Federated Learning (MMO-FL) for IoT, addressing missing modalities with the Prototypical Modality Mitigation (PMM) algorithm, showing superior performance.", "motivation": "Handling multimodal data in IoT environments with distributed learning and addressing missing modalities due to device instability.", "method": "Introduces MMO-FL for decentralized learning and PMM algorithm to compensate for missing modalities.", "result": "PMM outperforms benchmarks on two datasets, mitigating performance degradation from missing modalities.", "conclusion": "MMO-FL and PMM effectively address challenges of multimodal learning in IoT, enhancing performance despite missing data."}}
{"id": "2505.16161", "pdf": "https://arxiv.org/pdf/2505.16161", "abs": "https://arxiv.org/abs/2505.16161", "authors": ["Liyan Wang", "Weixiang Zhou", "Cong Wang", "Kin-Man Lam", "Zhixun Su", "Jinshan Pan"], "title": "Deep Learning-Driven Ultra-High-Definition Image Restoration: A Survey", "categories": ["cs.CV"], "comment": "20 papers, 12 figures", "summary": "Ultra-high-definition (UHD) image restoration aims to specifically solve the\nproblem of quality degradation in ultra-high-resolution images. Recent\nadvancements in this field are predominantly driven by deep learning-based\ninnovations, including enhancements in dataset construction, network\narchitecture, sampling strategies, prior knowledge integration, and loss\nfunctions. In this paper, we systematically review recent progress in UHD image\nrestoration, covering various aspects ranging from dataset construction to\nalgorithm design. This serves as a valuable resource for understanding\nstate-of-the-art developments in the field. We begin by summarizing degradation\nmodels for various image restoration subproblems, such as super-resolution,\nlow-light enhancement, deblurring, dehazing, deraining, and desnowing, and\nemphasizing the unique challenges of their application to UHD image\nrestoration. We then highlight existing UHD benchmark datasets and organize the\nliterature according to degradation types and dataset construction methods.\nFollowing this, we showcase major milestones in deep learning-driven UHD image\nrestoration, reviewing the progression of restoration tasks, technological\ndevelopments, and evaluations of existing methods. We further propose a\nclassification framework based on network architectures and sampling\nstrategies, helping to clearly organize existing methods. Finally, we share\ninsights into the current research landscape and propose directions for further\nadvancements. A related repository is available at\nhttps://github.com/wlydlut/UHD-Image-Restoration-Survey.", "AI": {"tldr": "A systematic review of recent advancements in UHD image restoration, covering datasets, algorithms, and deep learning innovations, with a proposed classification framework and future research directions.", "motivation": "To address quality degradation in UHD images and provide a comprehensive resource for understanding state-of-the-art developments in the field.", "method": "Summarizes degradation models, reviews UHD datasets, organizes literature by degradation types, and classifies methods by network architectures and sampling strategies.", "result": "Highlights milestones in deep learning-driven UHD restoration and proposes a clear classification framework for existing methods.", "conclusion": "Offers insights into current research and suggests future directions, supported by a related repository for further exploration."}}
{"id": "2505.16142", "pdf": "https://arxiv.org/pdf/2505.16142", "abs": "https://arxiv.org/abs/2505.16142", "authors": ["Shicheng Xu", "Liang Pang", "Yunchang Zhu", "Jia Gu", "Zihao Wei", "Jingcheng Deng", "Feiyang Pan", "Huawei Shen", "Xueqi Cheng"], "title": "Distilling the Implicit Multi-Branch Structure in LLMs' Reasoning via Reinforcement Learning", "categories": ["cs.CL"], "comment": "15 pages", "summary": "Distilling reasoning paths from teacher to student models via supervised\nfine-tuning (SFT) provides a shortcut for improving the reasoning ability of\nsmaller Large Language Models (LLMs). However, the reasoning paths generated by\nteacher models often reflect only surface-level traces of their underlying\nauthentic reasoning. Insights from cognitive neuroscience suggest that\nauthentic reasoning involves a complex interweaving between meta-reasoning\n(which selects appropriate sub-problems from multiple candidates) and solving\n(which addresses the sub-problem). This implies authentic reasoning has an\nimplicit multi-branch structure. Supervised fine-tuning collapses this rich\nstructure into a flat sequence of token prediction in the teacher's reasoning\npath, preventing effective distillation of this structure to students. To\naddress this limitation, we propose RLKD, a reinforcement learning (RL)-based\ndistillation framework guided by a novel Generative Structure Reward Model\n(GSRM). Our GSRM converts reasoning paths into multiple meta-reasoning-solving\nsteps and computes rewards to measure structural alignment between student and\nteacher reasoning. RLKD combines this reward with RL, enabling student LLMs to\ninternalize the teacher's implicit multi-branch reasoning structure rather than\nmerely mimicking fixed output paths. Experiments show RLKD surpasses standard\nSFT-RL pipelines even when trained on 0.1% of data under an RL-only regime,\nunlocking greater student reasoning potential than SFT-based distillation.", "AI": {"tldr": "RLKD, a reinforcement learning-based distillation framework, improves reasoning in smaller LLMs by aligning student and teacher reasoning structures, outperforming standard methods.", "motivation": "Standard supervised fine-tuning (SFT) fails to capture the implicit multi-branch reasoning structure of teacher models, limiting student model performance.", "method": "Proposes RLKD, using a Generative Structure Reward Model (GSRM) to measure structural alignment and reinforcement learning to distill reasoning.", "result": "RLKD outperforms SFT-RL pipelines, even with minimal training data, enhancing student reasoning.", "conclusion": "RLKD effectively distills complex reasoning structures, unlocking greater potential in student models."}}
{"id": "2503.11787", "pdf": "https://arxiv.org/pdf/2503.11787", "abs": "https://arxiv.org/abs/2503.11787", "authors": ["Samuel W. Remedios", "Shuwen Wei", "Shuo Han", "Jinwei Zhang", "Aaron Carass", "Kurt G. Schilling", "Dzung L. Pham", "Jerry L. Prince", "Blake E. Dewey"], "title": "ECLARE: Efficient cross-planar learning for anisotropic resolution enhancement", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "In clinical imaging, magnetic resonance (MR) image volumes are often acquired\nas stacks of 2D slices with decreased scan times, improved signal-to-noise\nratio, and image contrasts unique to 2D MR pulse sequences. While this is\nsufficient for clinical evaluation, automated algorithms designed for 3D\nanalysis perform poorly on multi-slice 2D MR volumes, especially those with\nthick slices and gaps between slices. Super-resolution (SR) methods aim to\naddress this problem, but previous methods do not address all of the following:\nslice profile shape estimation, slice gap, domain shift, and non-integer or\narbitrary upsampling factors. In this paper, we propose ECLARE (Efficient\nCross-planar Learning for Anisotropic Resolution Enhancement), a self-SR method\nthat addresses each of these factors. ECLARE uses a slice profile estimated\nfrom the multi-slice 2D MR volume, trains a network to learn the mapping from\nlow-resolution to high-resolution in-plane patches from the same volume, and\nperforms SR with anti-aliasing. We compared ECLARE to cubic B-spline\ninterpolation, SMORE, and other contemporary SR methods. We used realistic and\nrepresentative simulations so that quantitative performance against ground\ntruth can be computed, and ECLARE outperformed all other methods in both signal\nrecovery and downstream tasks. Importantly, as ECLARE does not use external\ntraining data it cannot suffer from domain shift between training and testing.\nOur code is open-source and available at\nhttps://www.github.com/sremedios/eclare.", "AI": {"tldr": "ECLARE is a self-supervised super-resolution method for 2D MR images, addressing slice profile, gap, domain shift, and arbitrary upsampling, outperforming other methods.", "motivation": "Automated 3D analysis struggles with 2D MR volumes due to thick slices and gaps, while existing SR methods fail to address all key factors.", "method": "ECLARE estimates slice profiles, trains a network for in-plane SR, and includes anti-aliasing, avoiding external data to prevent domain shift.", "result": "ECLARE outperforms cubic B-spline, SMORE, and others in signal recovery and downstream tasks, validated by simulations.", "conclusion": "ECLARE is effective for 2D MR SR, avoids domain shift, and is open-source."}}
{"id": "2505.16409", "pdf": "https://arxiv.org/pdf/2505.16409", "abs": "https://arxiv.org/abs/2505.16409", "authors": ["Chaeeun Kim", "Seungone Kim"], "title": "FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS", "categories": ["cs.AI"], "comment": "Work In Progress", "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in\nmulti-step reasoning and calling search engines at appropriate steps. However,\nexisting retrieval-augmented reasoning approaches rely on separate retrieval\nmodels, limiting the LRM's role in retrieval to deciding when to retrieve and\nhow to query. This separation not only increases hardware and operational costs\nbut also leads to errors in the retrieval process due to the representation\nbottleneck, a phenomenon where the retriever's embedding space is not\nexpressive enough to meet the generator's requirements. To address this, we\nshift our perspective from sequence-to-sequence matching to locating the\nanswer-containing paths within the corpus, and propose a novel framework called\nFREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables\nLRMs to retrieve relevant knowledge on their own by acting as both a generator\nand retriever. To achieve this, we introduce a variant of the MCTS algorithm\nspecialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing\nMonte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus\ntoward answer-containing regions. Our results on five open-domain QA\nbenchmarks, including single-hop and multi-hop questions, show that FREESON\nachieves an average improvement of 14.4% in EM and F1 over four multi-step\nreasoning models with a separate retriever, and it also performs comparably to\nthe strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.", "AI": {"tldr": "FREESON is a retriever-free framework enabling Large Reasoning Models (LRMs) to independently retrieve and reason, improving performance over traditional retrieval-augmented models.", "motivation": "Existing retrieval-augmented reasoning approaches rely on separate retrieval models, increasing costs and causing errors due to representation bottlenecks.", "method": "Proposes FREESON, where LRMs act as both generator and retriever, using CT-MCTS (Corpus-Traversing Monte Carlo Tree Search) to locate answer-containing paths.", "result": "Achieves 14.4% average improvement in EM and F1 over multi-step reasoning models with separate retrievers, and outperforms baselines on specific benchmarks.", "conclusion": "FREESON demonstrates the viability of unified retrieval-reasoning models, enhancing efficiency and accuracy in open-domain QA tasks."}}
{"id": "2505.16148", "pdf": "https://arxiv.org/pdf/2505.16148", "abs": "https://arxiv.org/abs/2505.16148", "authors": ["Chongjie Si", "Kangtao Lv", "Jingjing Jiang", "Yadao Wang", "Yongwei Wang", "Xiaokang Yang", "Wenbo Su", "Bo Zheng", "Wei Shen"], "title": "NAN: A Training-Free Solution to Coefficient Estimation in Model Merging", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Model merging offers a training-free alternative to multi-task learning by\ncombining independently fine-tuned models into a unified one without access to\nraw data. However, existing approaches often rely on heuristics to determine\nthe merging coefficients, limiting their scalability and generality. In this\nwork, we revisit model merging through the lens of least-squares optimization\nand show that the optimal merging weights should scale with the amount of\ntask-specific information encoded in each model. Based on this insight, we\npropose NAN, a simple yet effective method that estimates model merging\ncoefficients via the inverse of parameter norm. NAN is training-free,\nplug-and-play, and applicable to a wide range of merging strategies. Extensive\nexperiments on show that NAN consistently improves performance of baseline\nmethods.", "AI": {"tldr": "NAN is a training-free, plug-and-play method for model merging, using inverse parameter norms to determine optimal weights, outperforming baseline methods.", "motivation": "Existing model merging methods rely on heuristics, limiting scalability and generality.", "method": "Proposes NAN, which estimates merging coefficients via the inverse of parameter norm, based on least-squares optimization.", "result": "NAN consistently improves performance of baseline methods in experiments.", "conclusion": "NAN is a scalable and general solution for model merging, leveraging task-specific information effectively."}}
{"id": "2505.16165", "pdf": "https://arxiv.org/pdf/2505.16165", "abs": "https://arxiv.org/abs/2505.16165", "authors": ["Yechan Park", "Gyuhyeon Pak", "Euntai Kim"], "title": "RE-TRIP : Reflectivity Instance Augmented Triangle Descriptor for 3D Place Recognition", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "While most people associate LiDAR primarily with its ability to measure\ndistances and provide geometric information about the environment (via point\nclouds), LiDAR also captures additional data, including reflectivity or\nintensity values. Unfortunately, when LiDAR is applied to Place Recognition\n(PR) in mobile robotics, most previous works on LiDAR-based PR rely only on\ngeometric measurements, neglecting the additional reflectivity information that\nLiDAR provides. In this paper, we propose a novel descriptor for 3D PR, named\nRE-TRIP (REflectivity-instance augmented TRIangle descriPtor). This new\ndescriptor leverages both geometric measurements and reflectivity to enhance\nrobustness in challenging scenarios such as geometric degeneracy, high\ngeometric similarity, and the presence of dynamic objects. To implement RE-TRIP\nin real-world applications, we further propose (1) a keypoint extraction\nmethod, (2) a key instance segmentation method, (3) a RE-TRIP matching method,\nand (4) a reflectivity-combined loop verification method. Finally, we conduct a\nseries of experiments to demonstrate the effectiveness of RE-TRIP. Applied to\npublic datasets (i.e., HELIPR, FusionPortable) containing diverse scenarios\nsuch as long corridors, bridges, large-scale urban areas, and highly dynamic\nenvironments -- our experimental results show that the proposed method\noutperforms existing state-of-the-art methods in terms of Scan Context,\nIntensity Scan Context, and STD.", "AI": {"tldr": "The paper introduces RE-TRIP, a novel LiDAR-based descriptor for place recognition that combines geometric and reflectivity data to improve robustness in challenging scenarios.", "motivation": "Existing LiDAR-based place recognition methods focus only on geometric data, ignoring reflectivity, which can enhance performance in complex environments.", "method": "The authors propose RE-TRIP, a descriptor using both geometry and reflectivity, along with keypoint extraction, segmentation, matching, and loop verification methods.", "result": "Experiments on public datasets show RE-TRIP outperforms state-of-the-art methods like Scan Context and STD.", "conclusion": "RE-TRIP effectively leverages reflectivity to improve place recognition in diverse and dynamic environments."}}
{"id": "2505.16160", "pdf": "https://arxiv.org/pdf/2505.16160", "abs": "https://arxiv.org/abs/2505.16160", "authors": ["Bin Xu", "Yu Bai", "Huashan Sun", "Yiguan Lin", "Siming Liu", "Xinyue Liang", "Yaolin Li", "Yang Gao", "Heyan Huang"], "title": "EduBench: A Comprehensive Benchmarking Dataset for Evaluating Large Language Models in Diverse Educational Scenarios", "categories": ["cs.CL"], "comment": null, "summary": "As large language models continue to advance, their application in\neducational contexts remains underexplored and under-optimized. In this paper,\nwe address this gap by introducing the first diverse benchmark tailored for\neducational scenarios, incorporating synthetic data containing 9 major\nscenarios and over 4,000 distinct educational contexts. To enable comprehensive\nassessment, we propose a set of multi-dimensional evaluation metrics that cover\n12 critical aspects relevant to both teachers and students. We further apply\nhuman annotation to ensure the effectiveness of the model-generated evaluation\nresponses. Additionally, we succeed to train a relatively small-scale model on\nour constructed dataset and demonstrate that it can achieve performance\ncomparable to state-of-the-art large models (e.g., Deepseek V3, Qwen Max) on\nthe test set. Overall, this work provides a practical foundation for the\ndevelopment and evaluation of education-oriented language models. Code and data\nare released at https://github.com/ybai-nlp/EduBench.", "AI": {"tldr": "The paper introduces EduBench, a diverse benchmark for educational scenarios, with synthetic data and multi-dimensional evaluation metrics. A small-scale model trained on this dataset performs comparably to state-of-the-art large models.", "motivation": "The application of large language models in education is underexplored and under-optimized, prompting the need for a tailored benchmark and evaluation framework.", "method": "The authors create a benchmark with synthetic data (9 scenarios, 4,000 contexts) and propose 12 multi-dimensional metrics. Human annotation validates model-generated responses. A small-scale model is trained and tested.", "result": "The small-scale model achieves performance comparable to state-of-the-art large models (e.g., Deepseek V3, Qwen Max) on the test set.", "conclusion": "This work lays a foundation for developing and evaluating education-oriented language models, with code and data publicly available."}}
{"id": "2505.16448", "pdf": "https://arxiv.org/pdf/2505.16448", "abs": "https://arxiv.org/abs/2505.16448", "authors": ["Renfei Dang", "Shujian Huang", "Jiajun Chen"], "title": "Internal Bias in Reasoning Models leads to Overthinking", "categories": ["cs.AI"], "comment": null, "summary": "While current reasoning models possess strong exploratory capabilities, they\nare often criticized for overthinking due to redundant and unnecessary\nreflections. In this work, we reveal for the first time that overthinking in\nreasoning models may stem from their internal bias towards input texts. Upon\nencountering a reasoning problem, the model immediately forms a preliminary\nguess about the answer, which we term as an internal bias since it is not\nderived through actual reasoning. When this guess conflicts with its reasoning\nresult, the model tends to engage in reflection, leading to the waste of\ncomputational resources. Through further interpretability experiments, we find\nthat this behavior is largely driven by the model's excessive attention to the\ninput section, which amplifies the influence of internal bias on its\ndecision-making process. Additionally, by masking out the original input\nsection, the affect of internal bias can be effectively alleviated and the\nreasoning length could be reduced by 31%-53% across different complex reasoning\ntasks. Notably, in most cases, this approach also leads to improvements in\naccuracy. These findings demonstrate a causal relationship between internal\nbias and overthinking.", "AI": {"tldr": "The paper reveals that reasoning models' overthinking stems from internal bias towards input texts, leading to redundant reflections. Masking the input section reduces reasoning length by 31%-53% and often improves accuracy.", "motivation": "To address the issue of overthinking in reasoning models, which wastes computational resources due to unnecessary reflections caused by internal bias.", "method": "The study identifies internal bias as a preliminary guess formed by models upon encountering problems. It conducts interpretability experiments and tests masking the input section to mitigate bias.", "result": "Masking the input section reduces reasoning length by 31%-53% and often improves accuracy, demonstrating a causal link between internal bias and overthinking.", "conclusion": "Internal bias drives overthinking in reasoning models, and masking input sections effectively alleviates this issue, enhancing efficiency and accuracy."}}
{"id": "2505.16159", "pdf": "https://arxiv.org/pdf/2505.16159", "abs": "https://arxiv.org/abs/2505.16159", "authors": ["Chongjie Si", "Yidan Cui", "Fuchao Yang", "Xiaokang Yang", "Wei Shen"], "title": "Why Can Accurate Models Be Learned from Inaccurate Annotations?", "categories": ["cs.LG"], "comment": null, "summary": "Learning from inaccurate annotations has gained significant attention due to\nthe high cost of precise labeling. However, despite the presence of erroneous\nlabels, models trained on noisy data often retain the ability to make accurate\npredictions. This intriguing phenomenon raises a fundamental yet largely\nunexplored question: why models can still extract correct label information\nfrom inaccurate annotations remains unexplored. In this paper, we conduct a\ncomprehensive investigation into this issue. By analyzing weight matrices from\nboth empirical and theoretical perspectives, we find that label inaccuracy\nprimarily accumulates noise in lower singular components and subtly perturbs\nthe principal subspace. Within a certain range, the principal subspaces of\nweights trained on inaccurate labels remain largely aligned with those learned\nfrom clean labels, preserving essential task-relevant information. We formally\nprove that the angles of principal subspaces exhibit minimal deviation under\nmoderate label inaccuracy, explaining why models can still generalize\neffectively. Building on these insights, we propose LIP, a lightweight plug-in\ndesigned to help classifiers retain principal subspace information while\nmitigating noise induced by label inaccuracy. Extensive experiments on tasks\nwith various inaccuracy conditions demonstrate that LIP consistently enhances\nthe performance of existing algorithms. We hope our findings can offer valuable\ntheoretical and practical insights to understand of model robustness under\ninaccurate supervision.", "AI": {"tldr": "The paper investigates why models trained on noisy labels can still generalize well, finding that label inaccuracy mainly affects lower singular components, leaving the principal subspace largely intact. A lightweight plug-in, LIP, is proposed to enhance performance by preserving this subspace.", "motivation": "Understanding why models can generalize effectively despite noisy labels, as precise labeling is costly and noisy data is common.", "method": "Analyzes weight matrices empirically and theoretically, focusing on singular components and principal subspaces. Proposes LIP to retain principal subspace information.", "result": "Label inaccuracy primarily perturbs lower singular components, leaving the principal subspace aligned with clean labels. LIP improves performance under noisy conditions.", "conclusion": "Models generalize well under noisy labels due to preserved principal subspaces. LIP effectively mitigates noise, offering practical and theoretical insights."}}
{"id": "2505.16166", "pdf": "https://arxiv.org/pdf/2505.16166", "abs": "https://arxiv.org/abs/2505.16166", "authors": ["Yuhao Xue", "Zhifei Zhang", "Xinyang Jiang", "Yifei Shen", "Junyao Gao", "Wentao Gu", "Jiale Zhao", "Miaojing Shi", "Cairong Zhao"], "title": "TRAIL: Transferable Robust Adversarial Images via Latent diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Adversarial attacks exploiting unrestricted natural perturbations present\nsevere security risks to deep learning systems, yet their transferability\nacross models remains limited due to distribution mismatches between generated\nadversarial features and real-world data. While recent works utilize\npre-trained diffusion models as adversarial priors, they still encounter\nchallenges due to the distribution shift between the distribution of ideal\nadversarial samples and the natural image distribution learned by the diffusion\nmodel. To address the challenge, we propose Transferable Robust Adversarial\nImages via Latent Diffusion (TRAIL), a test-time adaptation framework that\nenables the model to generate images from a distribution of images with\nadversarial features and closely resembles the target images. To mitigate the\ndistribution shift, during attacks, TRAIL updates the diffusion U-Net's weights\nby combining adversarial objectives (to mislead victim models) and perceptual\nconstraints (to preserve image realism). The adapted model then generates\nadversarial samples through iterative noise injection and denoising guided by\nthese objectives. Experiments demonstrate that TRAIL significantly outperforms\nstate-of-the-art methods in cross-model attack transferability, validating that\ndistribution-aligned adversarial feature synthesis is critical for practical\nblack-box attacks.", "AI": {"tldr": "TRAIL improves adversarial attack transferability by aligning adversarial feature distribution with real-world data using a diffusion model framework.", "motivation": "Adversarial attacks often fail to transfer across models due to distribution mismatches between generated adversarial features and real-world data.", "method": "TRAIL adapts a diffusion model at test-time, combining adversarial and perceptual objectives to generate realistic adversarial samples.", "result": "TRAIL outperforms state-of-the-art methods in cross-model attack transferability.", "conclusion": "Aligning adversarial feature distribution with real-world data is key for effective black-box attacks."}}
{"id": "2505.16162", "pdf": "https://arxiv.org/pdf/2505.16162", "abs": "https://arxiv.org/abs/2505.16162", "authors": ["Mingbo Song", "Heming Xia", "Jun Zhang", "Chak Tou Leong", "Qiancheng Xu", "Wenjie Li", "Sujian Li"], "title": "KNN-SSD: Enabling Dynamic Self-Speculative Decoding via Nearest Neighbor Layer Set Optimization", "categories": ["cs.CL"], "comment": "8 pages", "summary": "Speculative Decoding (SD) has emerged as a widely used paradigm to accelerate\nthe inference of large language models (LLMs) without compromising generation\nquality. It works by efficiently drafting multiple tokens using a compact model\nand then verifying them in parallel using the target LLM. Notably,\nSelf-Speculative Decoding proposes skipping certain layers to construct the\ndraft model, which eliminates the need for additional parameters or training.\nDespite its strengths, we observe in this work that drafting with layer\nskipping exhibits significant sensitivity to domain shifts, leading to a\nsubstantial drop in acceleration performance. To enhance the domain\ngeneralizability of this paradigm, we introduce KNN-SSD, an algorithm that\nleverages K-Nearest Neighbor (KNN) search to match different skipped layers\nwith various domain inputs. We evaluated our algorithm in various models and\nmultiple tasks, observing that its application leads to 1.3x-1.6x speedup in\nLLM inference.", "AI": {"tldr": "KNN-SSD improves domain generalizability in Self-Speculative Decoding by using KNN search to match skipped layers with domain inputs, achieving 1.3x-1.6x speedup in LLM inference.", "motivation": "Self-Speculative Decoding's layer-skipping method is sensitive to domain shifts, reducing acceleration performance.", "method": "Introduces KNN-SSD, which uses KNN search to align skipped layers with domain-specific inputs.", "result": "Achieves 1.3x-1.6x speedup in LLM inference across various models and tasks.", "conclusion": "KNN-SSD effectively addresses domain sensitivity in Self-Speculative Decoding, enhancing inference speed without compromising quality."}}
{"id": "2505.16455", "pdf": "https://arxiv.org/pdf/2505.16455", "abs": "https://arxiv.org/abs/2505.16455", "authors": ["Mengzhu Liu", "Zhengqiu Zhu", "Chuan Ai", "Chen Gao", "Xinghong Li", "Lingnan He", "Kaisheng Lai", "Yingfeng Chen", "Xin Lu", "Yong Li", "Quanjun Yin"], "title": "Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "During sudden disaster events, accurately predicting public panic sentiment\non social media is crucial for proactive governance and crisis management.\nCurrent efforts on this problem face three main challenges: lack of finely\nannotated data hinders emotion prediction studies, unmodeled risk perception\ncauses prediction inaccuracies, and insufficient interpretability of panic\nformation mechanisms. We address these issues by proposing a Psychology-driven\ngenerative Agent framework (PsychoAgent) for explainable panic prediction based\non emotion arousal theory. Specifically, we first construct a fine-grained open\npanic emotion dataset (namely COPE) via human-large language models (LLMs)\ncollaboration to mitigate semantic bias. Then, we develop a framework\nintegrating cross-domain heterogeneous data grounded in psychological\nmechanisms to model risk perception and cognitive differences in emotion\ngeneration. To enhance interpretability, we design an LLM-based role-playing\nagent that simulates individual psychological chains through dedicatedly\ndesigned prompts. Experimental results on our annotated dataset show that\nPsychoAgent improves panic emotion prediction performance by 12.6% to 21.7%\ncompared to baseline models. Furthermore, the explainability and generalization\nof our approach is validated. Crucially, this represents a paradigm shift from\nopaque \"data-driven fitting\" to transparent \"role-based simulation with\nmechanistic interpretation\" for panic emotion prediction during emergencies.\nOur implementation is publicly available at:\nhttps://anonymous.4open.science/r/PsychoAgent-19DD.", "AI": {"tldr": "The paper introduces PsychoAgent, a psychology-driven framework for explainable panic prediction on social media during disasters, addressing data, perception, and interpretability challenges.", "motivation": "Accurate panic sentiment prediction is vital for crisis management, but current methods lack annotated data, ignore risk perception, and lack interpretability.", "method": "PsychoAgent combines a fine-grained dataset (COPE) with cross-domain data and LLM-based role-playing agents to model risk perception and emotion generation.", "result": "PsychoAgent outperforms baselines by 12.6% to 21.7% in panic prediction and enhances explainability and generalization.", "conclusion": "The framework shifts panic prediction from opaque data-driven methods to transparent, role-based simulations with mechanistic interpretation."}}
{"id": "2505.16190", "pdf": "https://arxiv.org/pdf/2505.16190", "abs": "https://arxiv.org/abs/2505.16190", "authors": ["Navid Seidi", "Satyaki Roy", "Sajal Das"], "title": "Enhancing Federated Survival Analysis through Peer-Driven Client Reputation in Healthcare", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) holds great promise for digital health by enabling\ncollaborative model training without compromising patient data privacy.\nHowever, heterogeneity across institutions, lack of sustained reputation, and\nunreliable contributions remain major challenges. In this paper, we propose a\nrobust, peer-driven reputation mechanism for federated healthcare that employs\na hybrid communication model to integrate decentralized peer feedback with\nclustering-based noise handling to enhance model aggregation. Crucially, our\napproach decouples the federated aggregation and reputation mechanisms by\napplying differential privacy to client-side model updates before sharing them\nfor peer evaluation. This ensures sensitive information remains protected\nduring reputation computation, while unaltered updates are sent to the server\nfor global model training. Using the Cox Proportional Hazards model for\nsurvival analysis across multiple federated nodes, our framework addresses both\ndata heterogeneity and reputation deficit by dynamically adjusting trust scores\nbased on local performance improvements measured via the concordance index.\nExperimental evaluations on both synthetic datasets and the SEER dataset\ndemonstrate that our method consistently achieves high and stable C-index\nvalues, effectively down-weighing noisy client updates and outperforming FL\nmethods that lack a reputation system.", "AI": {"tldr": "A robust, peer-driven reputation mechanism for federated healthcare is proposed, addressing data heterogeneity and unreliable contributions while ensuring privacy.", "motivation": "To overcome challenges like data heterogeneity and unreliable contributions in federated learning for healthcare, while maintaining patient data privacy.", "method": "A hybrid communication model integrates decentralized peer feedback with clustering-based noise handling, using differential privacy for client-side updates.", "result": "The method achieves high and stable C-index values, outperforming FL methods without a reputation system.", "conclusion": "The proposed framework effectively balances privacy, reputation, and performance in federated healthcare."}}
{"id": "2505.16174", "pdf": "https://arxiv.org/pdf/2505.16174", "abs": "https://arxiv.org/abs/2505.16174", "authors": ["Ping Liu", "Chi Zhang"], "title": "Erased or Dormant? Rethinking Concept Erasure Through Reversibility", "categories": ["cs.CV"], "comment": "Dr. Chi Zhang is the corresponding author", "summary": "To what extent does concept erasure eliminate generative capacity in\ndiffusion models? While prior evaluations have primarily focused on measuring\nconcept suppression under specific textual prompts, we explore a complementary\nand fundamental question: do current concept erasure techniques genuinely\nremove the ability to generate targeted concepts, or do they merely achieve\nsuperficial, prompt-specific suppression? We systematically evaluate the\nrobustness and reversibility of two representative concept erasure methods,\nUnified Concept Editing and Erased Stable Diffusion, by probing their ability\nto eliminate targeted generative behaviors in text-to-image models. These\nmethods attempt to suppress undesired semantic concepts by modifying internal\nmodel parameters, either through targeted attention edits or model-level\nfine-tuning strategies. To rigorously assess whether these techniques truly\nerase generative capacity, we propose an instance-level evaluation strategy\nthat employs lightweight fine-tuning to explicitly test the reactivation\npotential of erased concepts. Through quantitative metrics and qualitative\nanalyses, we show that erased concepts often reemerge with substantial visual\nfidelity after minimal adaptation, indicating that current methods suppress\nlatent generative representations without fully eliminating them. Our findings\nreveal critical limitations in existing concept erasure approaches and\nhighlight the need for deeper, representation-level interventions and more\nrigorous evaluation standards to ensure genuine, irreversible removal of\nconcepts from generative models.", "AI": {"tldr": "Current concept erasure methods in diffusion models suppress but don't fully eliminate targeted concepts, as erased concepts can reemerge with minimal adaptation.", "motivation": "To determine if concept erasure techniques genuinely remove generative capacity or just superficially suppress concepts.", "method": "Systematic evaluation of two concept erasure methods (Unified Concept Editing and Erased Stable Diffusion) using instance-level fine-tuning to test reactivation potential.", "result": "Erased concepts often reemerge with high visual fidelity after minimal adaptation, showing suppression without full elimination.", "conclusion": "Existing methods have limitations; deeper interventions and stricter evaluation are needed for irreversible concept removal."}}
{"id": "2505.16164", "pdf": "https://arxiv.org/pdf/2505.16164", "abs": "https://arxiv.org/abs/2505.16164", "authors": ["Mengyang Qiu", "Zoe Brisebois", "Siena Sun"], "title": "Can LLMs Simulate Human Behavioral Variability? A Case Study in the Phonemic Fluency Task", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly explored as substitutes for\nhuman participants in cognitive tasks, but their ability to simulate human\nbehavioral variability remains unclear. This study examines whether LLMs can\napproximate individual differences in the phonemic fluency task, where\nparticipants generate words beginning with a target letter. We evaluated 34\nmodel configurations, varying prompt specificity, sampling temperature, and\nmodel type, and compared outputs to responses from 106 human participants.\nWhile some configurations, especially Claude 3.7 Sonnet, matched human averages\nand lexical preferences, none reproduced the scope of human variability. LLM\noutputs were consistently less diverse and structurally rigid, and LLM\nensembles failed to increase diversity. Network analyses further revealed\nfundamental differences in retrieval structure between humans and models. These\nresults highlight key limitations in using LLMs to simulate human cognition and\nbehavior.", "AI": {"tldr": "LLMs can approximate human averages in phonemic fluency tasks but fail to replicate human variability and diversity.", "motivation": "To assess if LLMs can simulate individual differences in human cognitive tasks like phonemic fluency.", "method": "Evaluated 34 LLM configurations against 106 human participants in phonemic fluency tasks, analyzing outputs for diversity and structure.", "result": "Some LLMs matched human averages but none replicated human variability; outputs were less diverse and structurally rigid.", "conclusion": "LLMs have limitations in simulating human cognition and behavioral variability."}}
{"id": "2505.16459", "pdf": "https://arxiv.org/pdf/2505.16459", "abs": "https://arxiv.org/abs/2505.16459", "authors": ["Guiyao Tie", "Xueyang Zhou", "Tianhe Gu", "Ruihang Zhang", "Chaoran Hu", "Sizhe Zhang", "Mengqu Sun", "Yan Zhang", "Pan Zhou", "Lichao Sun"], "title": "MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks", "categories": ["cs.AI"], "comment": "39 pages, 28 figures, 4 tables", "summary": "Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled\nunified processing of language, vision, and structured inputs, opening the door\nto complex tasks such as logical deduction, spatial reasoning, and scientific\nanalysis. Despite their promise, the reasoning capabilities of MLLMs,\nparticularly those augmented with intermediate thinking traces (MLLMs-T),\nremain poorly understood and lack standardized evaluation benchmarks. Existing\nwork focuses primarily on perception or final answer correctness, offering\nlimited insight into how models reason or fail across modalities. To address\nthis gap, we introduce the MMMR, a new benchmark designed to rigorously\nevaluate multi-modal reasoning with explicit thinking. The MMMR comprises 1) a\nhigh-difficulty dataset of 1,083 questions spanning six diverse reasoning types\nwith symbolic depth and multi-hop demands and 2) a modular Reasoning Trace\nEvaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy\nthrough metrics like relevance, consistency, and structured error annotations.\nEmpirical results show that MLLMs-T overall outperform non-thinking\ncounterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro\nsuffer from reasoning pathologies such as inconsistency and overthinking. This\nbenchmark reveals persistent gaps between accuracy and reasoning quality and\nprovides an actionable evaluation pipeline for future model development.\nOverall, the MMMR offers a scalable foundation for evaluating, comparing, and\nimproving the next generation of multi-modal reasoning systems.", "AI": {"tldr": "The paper introduces MMMR, a benchmark to evaluate multi-modal reasoning in MLLMs, highlighting gaps in reasoning quality despite improved accuracy.", "motivation": "Existing benchmarks lack focus on reasoning quality in multi-modal tasks, leaving MLLMs' reasoning capabilities poorly understood.", "method": "The MMMR benchmark includes a high-difficulty dataset and a Reasoning Trace Evaluation Pipeline (RTEP) to assess reasoning beyond accuracy.", "result": "MLLMs with intermediate thinking traces outperform others but exhibit reasoning flaws like inconsistency.", "conclusion": "MMMR provides a scalable tool for evaluating and improving multi-modal reasoning systems."}}
{"id": "2505.16204", "pdf": "https://arxiv.org/pdf/2505.16204", "abs": "https://arxiv.org/abs/2505.16204", "authors": ["Ichiro Hashimoto"], "title": "Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "68T07 (primary)"], "comment": "34 pages", "summary": "In this paper, we prove directional convergence of network parameters of\nfixed width leaky ReLU two-layer neural networks optimized by gradient descent\nwith exponential loss, which was previously only known for gradient flow. By a\ncareful analysis of the convergent direction, we establish sufficient\nconditions of benign overfitting and discover a new phase transition in the\ntest error bound. All of these results hold beyond the nearly orthogonal data\nsetting which was studied in prior works. As an application, we demonstrate\nthat benign overfitting occurs with high probability in sub-Gaussian mixture\nmodels.", "AI": {"tldr": "The paper proves directional convergence of network parameters in fixed-width leaky ReLU two-layer neural networks under gradient descent with exponential loss, extending prior gradient flow results. It identifies conditions for benign overfitting and a new test error phase transition, applicable beyond nearly orthogonal data. Applications include sub-Gaussian mixture models.", "motivation": "To extend understanding of directional convergence in neural networks beyond gradient flow, and to explore conditions for benign overfitting and test error behavior in broader data settings.", "method": "Analysis of convergent direction in fixed-width leaky ReLU two-layer networks optimized by gradient descent with exponential loss.", "result": "Established sufficient conditions for benign overfitting and discovered a new phase transition in test error bounds, applicable beyond nearly orthogonal data. Demonstrated benign overfitting in sub-Gaussian mixture models.", "conclusion": "The work generalizes prior results, providing insights into convergence and overfitting in neural networks under gradient descent, with practical implications for sub-Gaussian data."}}
{"id": "2505.16175", "pdf": "https://arxiv.org/pdf/2505.16175", "abs": "https://arxiv.org/abs/2505.16175", "authors": ["Benjamin Schneider", "Dongfu Jiang", "Chao Du", "Tianyu Pang", "Wenhu Chen"], "title": "QuickVideo: Real-Time Long Video Understanding with System Algorithm Co-Design", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 6 figures, 2 tables", "summary": "Long-video understanding has emerged as a crucial capability in real-world\napplications such as video surveillance, meeting summarization, educational\nlecture analysis, and sports broadcasting. However, it remains computationally\nprohibitive for VideoLLMs, primarily due to two bottlenecks: 1) sequential\nvideo decoding, the process of converting the raw bit stream to RGB frames can\ntake up to a minute for hour-long video inputs, and 2) costly prefilling of up\nto several million tokens for LLM inference, resulting in high latency and\nmemory use. To address these challenges, we propose QuickVideo, a\nsystem-algorithm co-design that substantially accelerates long-video\nunderstanding to support real-time downstream applications. It comprises three\nkey innovations: QuickDecoder, a parallelized CPU-based video decoder that\nachieves 2-3 times speedup by splitting videos into keyframe-aligned intervals\nprocessed concurrently; QuickPrefill, a memory-efficient prefilling method\nusing KV-cache pruning to support more frames with less GPU memory; and an\noverlapping scheme that overlaps CPU video decoding with GPU inference.\nTogether, these components infernece time reduce by a minute on long video\ninputs, enabling scalable, high-quality video understanding even on limited\nhardware. Experiments show that QuickVideo generalizes across durations and\nsampling rates, making long video processing feasible in practice.", "AI": {"tldr": "QuickVideo accelerates long-video understanding by addressing decoding and prefilling bottlenecks with parallelized decoding, KV-cache pruning, and CPU-GPU overlap.", "motivation": "Long-video understanding is vital for real-world applications but hindered by slow decoding and high memory use in VideoLLMs.", "method": "QuickVideo combines QuickDecoder (parallelized CPU decoding), QuickPrefill (KV-cache pruning), and CPU-GPU overlapping.", "result": "Reduces inference time by a minute, supports more frames with less memory, and generalizes across video durations.", "conclusion": "QuickVideo enables scalable, efficient long-video understanding on limited hardware."}}
{"id": "2505.16170", "pdf": "https://arxiv.org/pdf/2505.16170", "abs": "https://arxiv.org/abs/2505.16170", "authors": ["Yuqing Yang", "Robin Jia"], "title": "When Do LLMs Admit Their Mistakes? Understanding the Role of Model Belief in Retraction", "categories": ["cs.CL"], "comment": null, "summary": "Can large language models (LLMs) admit their mistakes when they should know\nbetter? In this work, we define the behavior of acknowledging errors in\npreviously generated answers as \"retraction\" and aim to understand when and why\nLLMs choose to retract. We first construct model-specific datasets to evaluate\nwhether a model will retract an incorrect answer that contradicts its own\nparametric knowledge. While LLMs are capable of retraction, they do so only\ninfrequently. We demonstrate that retraction is closely tied to previously\nidentified indicators of models' internal belief: models fail to retract wrong\nanswers that they \"believe\" to be factually correct. Steering experiments\nfurther demonstrate that internal belief causally influences model retraction.\nIn particular, when the model does not believe its answer, this not only\nencourages the model to attempt to verify the answer, but also alters attention\nbehavior during self-verification. Finally, we demonstrate that simple\nsupervised fine-tuning significantly improves retraction performance by helping\nthe model learn more accurate internal beliefs. Code and datasets are available\non https://github.com/ayyyq/llm-retraction.", "AI": {"tldr": "LLMs can retract incorrect answers but do so rarely. Retraction is linked to their internal belief, and fine-tuning improves performance.", "motivation": "To understand when and why LLMs retract incorrect answers, given their parametric knowledge.", "method": "Constructed datasets to evaluate retraction, analyzed internal belief indicators, and conducted steering experiments.", "result": "LLMs retract infrequently, influenced by internal belief. Fine-tuning enhances retraction accuracy.", "conclusion": "Retraction behavior in LLMs is tied to internal belief, and fine-tuning can improve their ability to acknowledge mistakes."}}
{"id": "2505.16475", "pdf": "https://arxiv.org/pdf/2505.16475", "abs": "https://arxiv.org/abs/2505.16475", "authors": ["Jiaqi Li", "Xinyi Dong", "Yang Liu", "Zhizhuo Yang", "Quansen Wang", "Xiaobo Wang", "SongChun Zhu", "Zixia Jia", "Zilong Zheng"], "title": "ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection", "categories": ["cs.AI"], "comment": null, "summary": "We present a novel pipeline, ReflectEvo, to demonstrate that small language\nmodels (SLMs) can enhance meta introspection through reflection learning. This\nprocess iteratively generates self-reflection for self-training, fostering a\ncontinuous and self-evolving process. Leveraging this pipeline, we construct\nReflectEvo-460k, a large-scale, comprehensive, self-generated reflection\ndataset with broadened instructions and diverse multi-domain tasks. Building\nupon this dataset, we demonstrate the effectiveness of reflection learning to\nimprove SLMs' reasoning abilities using SFT and DPO with remarkable\nperformance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral\nfrom 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the\nreasoning capability of the three prominent open-sourced models on BIG-bench\nwithout distillation from superior models or fine-grained human annotation. We\nfurther conduct a deeper analysis of the high quality of self-generated\nreflections and their impact on error localization and correction. Our work\nhighlights the potential of continuously enhancing the reasoning performance of\nSLMs through iterative reflection learning in the long run.", "AI": {"tldr": "ReflectEvo is a pipeline enabling small language models (SLMs) to improve reasoning via iterative self-reflection, achieving significant performance boosts on models like Llama-3 and Mistral.", "motivation": "To enhance SLMs' reasoning without relying on superior models or human annotation by leveraging self-generated reflections.", "method": "Uses reflection learning to iteratively generate self-reflections for self-training, creating a dataset (ReflectEvo-460k) and applying SFT and DPO.", "result": "Boosts Llama-3 from 52.4% to 71.2% and Mistral from 44.4% to 71.1%, rivaling top open-sourced models on BIG-bench.", "conclusion": "Iterative reflection learning can continuously improve SLMs' reasoning, highlighting its long-term potential."}}
{"id": "2505.16210", "pdf": "https://arxiv.org/pdf/2505.16210", "abs": "https://arxiv.org/abs/2505.16210", "authors": ["Zhihang Cai", "Xingjun Zhang", "Zhendong Tan", "Zheng Wei"], "title": "NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "11 pages, 9 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency across\na wide range of tasks. However, LLMs often require larger batch sizes to\nenhance throughput or longer context lengths to meet task demands, which\nsignificantly increases the memory resource consumption of the Key-Value (KV)\ncache during inference, becoming a major bottleneck in LLM deployment. To\naddress this issue, quantization is a common and straightforward approach.\nCurrently, quantization methods for activations are limited to 8-bit, and\nquantization to even lower bits can lead to substantial accuracy drops. To\nfurther save space by quantizing the KV cache to even lower bits, we analyzed\nthe element distribution of the KV cache and designed the NQKV algorithm. Since\nthe elements within each block of the KV cache follow a normal distribution,\nNQKV employs per-block quantile quantization to achieve\ninformation-theoretically optimal quantization error. Without significantly\ncompromising model output quality, NQKV enables the OPT model to perform\ninference with an 2x larger batch size or a 4x longer context length, and it\nimproves throughput by 9.3x compared to when the KV cache is not used.", "AI": {"tldr": "NQKV algorithm quantizes the KV cache to lower bits using per-block quantile quantization, enabling larger batch sizes and longer context lengths without significant accuracy loss.", "motivation": "Address the memory bottleneck in LLM deployment caused by large KV cache consumption during inference.", "method": "Analyzed KV cache element distribution and designed NQKV, a per-block quantile quantization method.", "result": "Enables 2x larger batch size, 4x longer context length, and 9.3x throughput improvement for the OPT model.", "conclusion": "NQKV effectively reduces KV cache memory usage while maintaining model performance."}}
{"id": "2505.16180", "pdf": "https://arxiv.org/pdf/2505.16180", "abs": "https://arxiv.org/abs/2505.16180", "authors": ["Ashim Dahal", "Ankit Ghimire", "Saydul Akbar Murad", "Nick Rahimi"], "title": "Redemption Score: An Evaluation Framework to Rank Image Captions While Redeeming Image Semantics and Language Pragmatics", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Evaluating image captions requires cohesive assessment of both visual\nsemantics and language pragmatics, which is often not entirely captured by most\nmetrics. We introduce Redemption Score, a novel hybrid framework that ranks\nimage captions by triangulating three complementary signals: (1) Mutual\nInformation Divergence (MID) for global image-text distributional alignment,\n(2) DINO-based perceptual similarity of cycle-generated images for visual\ngrounding, and (3) BERTScore for contextual text similarity against human\nreferences. A calibrated fusion of these signals allows Redemption Score to\noffer a more holistic assessment. On the Flickr8k benchmark, Redemption Score\nachieves a Kendall-$\\tau$ of 56.43, outperforming twelve prior methods and\ndemonstrating superior correlation with human judgments without requiring\ntask-specific training. Our framework provides a more robust and nuanced\nevaluation by effectively redeeming image semantics and linguistic\ninterpretability indicated by strong transfer of knowledge in the Conceptual\nCaptions and MS COCO datasets.", "AI": {"tldr": "Redemption Score is a hybrid framework for evaluating image captions, combining MID, DINO-based similarity, and BERTScore, outperforming prior methods on Flickr8k.", "motivation": "Existing metrics often fail to fully assess visual semantics and language pragmatics in image captions.", "method": "Triangulates three signals: MID for distributional alignment, DINO for visual grounding, and BERTScore for text similarity.", "result": "Achieves Kendall-\u03c4 of 56.43 on Flickr8k, outperforming twelve prior methods and correlating better with human judgments.", "conclusion": "Redemption Score offers a robust, nuanced evaluation, redeeming image semantics and linguistic interpretability."}}
{"id": "2505.16172", "pdf": "https://arxiv.org/pdf/2505.16172", "abs": "https://arxiv.org/abs/2505.16172", "authors": ["Abhay Kumara Sri Krishna Nandiraju", "Gondy Leroy", "David Kauchak", "Arif Ahmed"], "title": "Automated Feedback Loops to Protect Text Simplification with Generative AI from Information Loss", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Understanding health information is essential in achieving and maintaining a\nhealthy life. We focus on simplifying health information for better\nunderstanding. With the availability of generative AI, the simplification\nprocess has become efficient and of reasonable quality, however, the algorithms\nremove information that may be crucial for comprehension. In this study, we\ncompare generative AI to detect missing information in simplified text,\nevaluate its importance, and fix the text with the missing information. We\ncollected 50 health information texts and simplified them using gpt-4-0613. We\ncompare five approaches to identify missing elements and regenerate the text by\ninserting the missing elements. These five approaches involve adding missing\nentities and missing words in various ways: 1) adding all the missing entities,\n2) adding all missing words, 3) adding the top-3 entities ranked by gpt-4-0613,\nand 4, 5) serving as controls for comparison, adding randomly chosen entities.\nWe use cosine similarity and ROUGE scores to evaluate the semantic similarity\nand content overlap between the original, simplified, and reconstructed\nsimplified text. We do this for both summaries and full text. Overall, we find\nthat adding missing entities improves the text. Adding all the missing entities\nresulted in better text regeneration, which was better than adding the\ntop-ranked entities or words, or random words. Current tools can identify these\nentities, but are not valuable in ranking them.", "AI": {"tldr": "The study compares generative AI for simplifying health texts, identifies missing information, and evaluates methods to reintegrate it, finding that adding all missing entities improves text quality.", "motivation": "To improve health information comprehension by addressing gaps in AI-simplified texts.", "method": "Simplified 50 health texts using GPT-4, compared five approaches to identify and reintegrate missing elements, and evaluated using cosine similarity and ROUGE scores.", "result": "Adding all missing entities yielded better text regeneration than other methods, though current tools lack ranking value.", "conclusion": "Reintegrating all missing entities enhances simplified health texts, but better ranking methods are needed."}}
{"id": "2505.16477", "pdf": "https://arxiv.org/pdf/2505.16477", "abs": "https://arxiv.org/abs/2505.16477", "authors": ["Yanbo Zhang", "Sumeer A. Khan", "Adnan Mahmud", "Huck Yang", "Alexander Lavin", "Michael Levin", "Jeremy Frey", "Jared Dunnmon", "James Evans", "Alan Bundy", "Saso Dzeroski", "Jesper Tegner", "Hector Zenil"], "title": "Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery", "categories": ["cs.AI"], "comment": "45 pages", "summary": "With recent Nobel Prizes recognising AI contributions to science, Large\nLanguage Models (LLMs) are transforming scientific research by enhancing\nproductivity and reshaping the scientific method. LLMs are now involved in\nexperimental design, data analysis, and workflows, particularly in chemistry\nand biology. However, challenges such as hallucinations and reliability\npersist. In this contribution, we review how Large Language Models (LLMs) are\nredefining the scientific method and explore their potential applications\nacross different stages of the scientific cycle, from hypothesis testing to\ndiscovery. We conclude that, for LLMs to serve as relevant and effective\ncreative engines and productivity enhancers, their deep integration into all\nsteps of the scientific process should be pursued in collaboration and\nalignment with human scientific goals, with clear evaluation metrics. The\ntransition to AI-driven science raises ethical questions about creativity,\noversight, and responsibility. With careful guidance, LLMs could evolve into\ncreative engines, driving transformative breakthroughs across scientific\ndisciplines responsibly and effectively. However, the scientific community must\nalso decide how much it leaves to LLMs to drive science, even when associations\nwith 'reasoning', mostly currently undeserved, are made in exchange for the\npotential to explore hypothesis and solution regions that might otherwise\nremain unexplored by human exploration alone.", "AI": {"tldr": "LLMs are reshaping scientific research by enhancing productivity and redefining the scientific method, but challenges like hallucinations and reliability remain. Their integration requires collaboration with human goals and ethical considerations.", "motivation": "To explore how LLMs are transforming scientific research and their potential applications across the scientific cycle, while addressing challenges and ethical concerns.", "method": "Review of LLMs' roles in experimental design, data analysis, and workflows, focusing on chemistry and biology, and their integration into the scientific process.", "result": "LLMs can serve as creative engines and productivity enhancers, but their integration must align with human goals and include clear evaluation metrics.", "conclusion": "For LLMs to drive transformative breakthroughs responsibly, careful guidance and ethical oversight are needed, alongside decisions on their role in scientific exploration."}}
{"id": "2505.16217", "pdf": "https://arxiv.org/pdf/2505.16217", "abs": "https://arxiv.org/abs/2505.16217", "authors": ["Hon Tik Tse", "Siddarth Chandrasekar", "Marlos C. Machado"], "title": "Reward-Aware Proto-Representations in Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, the successor representation (SR) has attracted increasing\nattention in reinforcement learning (RL), and it has been used to address some\nof its key challenges, such as exploration, credit assignment, and\ngeneralization. The SR can be seen as representing the underlying credit\nassignment structure of the environment by implicitly encoding its induced\ntransition dynamics. However, the SR is reward-agnostic. In this paper, we\ndiscuss a similar representation that also takes into account the reward\ndynamics of the problem. We study the default representation (DR), a recently\nproposed representation with limited theoretical (and empirical) analysis.\nHere, we lay some of the theoretical foundation underlying the DR in the\ntabular case by (1) deriving dynamic programming and (2) temporal-difference\nmethods to learn the DR, (3) characterizing the basis for the vector space of\nthe DR, and (4) formally extending the DR to the function approximation case\nthrough default features. Empirically, we analyze the benefits of the DR in\nmany of the settings in which the SR has been applied, including (1) reward\nshaping, (2) option discovery, (3) exploration, and (4) transfer learning. Our\nresults show that, compared to the SR, the DR gives rise to qualitatively\ndifferent, reward-aware behaviour and quantitatively better performance in\nseveral settings.", "AI": {"tldr": "The paper introduces the Default Representation (DR), a reward-aware alternative to the Successor Representation (SR) in RL, providing theoretical foundations and empirical benefits.", "motivation": "The SR lacks reward awareness, limiting its effectiveness in RL tasks. The DR addresses this by incorporating reward dynamics.", "method": "Theoretical analysis includes dynamic programming, temporal-difference methods, and extending DR to function approximation. Empirical tests cover reward shaping, option discovery, exploration, and transfer learning.", "result": "DR outperforms SR in reward-aware behavior and performance across multiple RL settings.", "conclusion": "DR is a promising, reward-aware representation with theoretical and empirical advantages over SR."}}
{"id": "2505.16181", "pdf": "https://arxiv.org/pdf/2505.16181", "abs": "https://arxiv.org/abs/2505.16181", "authors": ["Mohammad Reza Taesiri", "Brandon Collins", "Logan Bolton", "Viet Dac Lai", "Franck Dernoncourt", "Trung Bui", "Anh Totti Nguyen"], "title": "Understanding Generative AI Capabilities in Everyday Image Editing Tasks", "categories": ["cs.CV", "cs.AI"], "comment": "Code and qualitative examples are available at:\n  https://psrdataset.github.io", "summary": "Generative AI (GenAI) holds significant promise for automating everyday image\nediting tasks, especially following the recent release of GPT-4o on March 25,\n2025. However, what subjects do people most often want edited? What kinds of\nediting actions do they want to perform (e.g., removing or stylizing the\nsubject)? Do people prefer precise edits with predictable outcomes or highly\ncreative ones? By understanding the characteristics of real-world requests and\nthe corresponding edits made by freelance photo-editing wizards, can we draw\nlessons for improving AI-based editors and determine which types of requests\ncan currently be handled successfully by AI editors? In this paper, we present\na unique study addressing these questions by analyzing 83k requests from the\npast 12 years (2013-2025) on the Reddit community, which collected 305k\nPSR-wizard edits. According to human ratings, approximately only 33% of\nrequests can be fulfilled by the best AI editors (including GPT-4o,\nGemini-2.0-Flash, SeedEdit). Interestingly, AI editors perform worse on\nlow-creativity requests that require precise editing than on more open-ended\ntasks. They often struggle to preserve the identity of people and animals, and\nfrequently make non-requested touch-ups. On the other side of the table, VLM\njudges (e.g., o1) perform differently from human judges and may prefer AI edits\nmore than human edits. Code and qualitative examples are available at:\nhttps://psrdataset.github.io", "AI": {"tldr": "The study analyzes 83k image-editing requests from Reddit to understand user preferences and AI editor capabilities, finding that only 33% of requests can be handled by top AI editors like GPT-4o, with struggles in precise edits and preserving identities.", "motivation": "To identify common image-editing requests, user preferences (precise vs. creative edits), and assess AI editor performance compared to human editors.", "method": "Analysis of 83k requests and 305k edits from a Reddit community over 12 years, evaluating AI editor success rates and comparing human and VLM judge preferences.", "result": "Only 33% of requests are successfully handled by AI editors, which struggle with precise edits, identity preservation, and often make unwanted touch-ups. VLM judges may favor AI edits over human ones.", "conclusion": "AI editors need improvement in handling precise and identity-preserving edits, and VLM judge biases should be considered when evaluating AI performance."}}
{"id": "2505.16178", "pdf": "https://arxiv.org/pdf/2505.16178", "abs": "https://arxiv.org/abs/2505.16178", "authors": ["Ying Zhang", "Benjamin Heinzerling", "Dongyuan Li", "Ryoma Ishigaki", "Yuta Hitomi", "Kentaro Inui"], "title": "Understanding Fact Recall in Language Models: Why Two-Stage Training Encourages Memorization but Mixed Training Teaches Knowledge", "categories": ["cs.CL"], "comment": null, "summary": "Fact recall, the ability of language models (LMs) to retrieve specific\nfactual knowledge, remains a challenging task despite their impressive general\ncapabilities. Common training strategies often struggle to promote robust\nrecall behavior with two-stage training, which first trains a model with\nfact-storing examples (e.g., factual statements) and then with fact-recalling\nexamples (question-answer pairs), tending to encourage rote memorization rather\nthan generalizable fact retrieval. In contrast, mixed training, which jointly\nuses both types of examples, has been empirically shown to improve the ability\nto recall facts, but the underlying mechanisms are still poorly understood. In\nthis work, we investigate how these training strategies affect how model\nparameters are shaped during training and how these differences relate to their\nability to recall facts. We introduce cross-task gradient trace to identify\nshared parameters, those strongly influenced by both fact-storing and\nfact-recalling examples. Our analysis on synthetic fact recall datasets with\nthe Llama-3.2B and Pythia-2.8B models reveals that mixed training encouraging a\nlarger and more centralized set of shared parameters. These findings suggest\nthat the emergence of parameters may play a key role in enabling LMs to\ngeneralize factual knowledge across task formulations.", "AI": {"tldr": "The paper explores how mixed training (combining fact-storing and fact-recalling examples) improves fact recall in language models compared to two-stage training, identifying shared parameters as key to generalization.", "motivation": "Understanding why mixed training outperforms two-stage training in promoting robust fact recall in language models.", "method": "Introduces cross-task gradient trace to analyze shared parameters influenced by both training stages, tested on synthetic datasets with Llama-3.2B and Pythia-2.8B models.", "result": "Mixed training encourages a larger, more centralized set of shared parameters, enhancing generalization of factual knowledge.", "conclusion": "Shared parameters are crucial for enabling language models to generalize factual knowledge across tasks."}}
{"id": "2505.16482", "pdf": "https://arxiv.org/pdf/2505.16482", "abs": "https://arxiv.org/abs/2505.16482", "authors": ["Huynh Thi Thanh Binh", "Le Van Cuong", "Dang Hai Dang", "Le Trong Vinh"], "title": "Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the\nadvantage of wireless energy transfer technology have opened a promising\nopportunity in solving the limited energy issue. However, an ineffective\ncharging strategy may reduce the charging performance. Although many practical\ncharging algorithms have been introduced, these studies mainly focus on\noptimizing the charging path with a fully charging approach. This approach may\nlead to the death of a series of sensors due to their extended charging\nlatency. This paper introduces a novel partial charging approach that follows a\nbi-level optimized scheme to minimize energy depletion in WRSNs. We aim at\noptimizing simultaneously two factors: the charging path and time. To\naccomplish this, we first formulate a mathematical model of the investigated\nproblem. We then propose two approximate algorithms in which the optimization\nof the charging path and the charging time are considered as the upper and\nlower level, respectively. The first algorithm combines a Multi-start Local\nSearch method and a Genetic Algorithm to find a solution. The second algorithm\nadopts a nested approach that utilizes the advantages of the Multitasking and\nCovariance Matrix Adaptation Evolutionary Strategies. Experimental validations\non various network scenarios demonstrate that our proposed algorithms\noutperform the existing works.", "AI": {"tldr": "A novel partial charging approach for WRSNs optimizes both charging path and time to minimize energy depletion, outperforming existing methods.", "motivation": "Addressing the inefficiency of fully charging approaches in WRSNs, which cause sensor deaths due to extended charging latency.", "method": "Proposes a bi-level optimized scheme with two algorithms: one combining Multi-start Local Search and Genetic Algorithm, and another using Multitasking and Covariance Matrix Adaptation Evolutionary Strategies.", "result": "Experimental validations show the proposed algorithms outperform existing works in various network scenarios.", "conclusion": "The partial charging approach effectively minimizes energy depletion in WRSNs by optimizing charging path and time simultaneously."}}
{"id": "2505.16226", "pdf": "https://arxiv.org/pdf/2505.16226", "abs": "https://arxiv.org/abs/2505.16226", "authors": ["Zi-Jian Cheng", "Zi-Yi Jia", "Zhi Zhou", "Yu-Feng Li", "Lan-Zhe Guo"], "title": "Realistic Evaluation of TabPFN v2 in Open Environments", "categories": ["cs.LG"], "comment": null, "summary": "Tabular data, owing to its ubiquitous presence in real-world domains, has\ngarnered significant attention in machine learning research. While tree-based\nmodels have long dominated tabular machine learning tasks, the recently\nproposed deep learning model TabPFN v2 has emerged, demonstrating unparalleled\nperformance and scalability potential. Although extensive research has been\nconducted on TabPFN v2 to further improve performance, the majority of this\nresearch remains confined to closed environments, neglecting the challenges\nthat frequently arise in open environments. This raises the question: Can\nTabPFN v2 maintain good performance in open environments? To this end, we\nconduct the first comprehensive evaluation of TabPFN v2's adaptability in open\nenvironments. We construct a unified evaluation framework covering various\nreal-world challenges and assess the robustness of TabPFN v2 under open\nenvironments scenarios using this framework. Empirical results demonstrate that\nTabPFN v2 shows significant limitations in open environments but is suitable\nfor small-scale, covariate-shifted, and class-balanced tasks. Tree-based models\nremain the optimal choice for general tabular tasks in open environments. To\nfacilitate future research on open environments challenges, we advocate for\nopen environments tabular benchmarks, multi-metric evaluation, and universal\nmodules to strengthen model robustness. We publicly release our evaluation\nframework at https://anonymous.4open.science/r/tabpfn-ood-4E65.", "AI": {"tldr": "TabPFN v2 excels in closed environments but struggles in open ones, where tree-based models remain superior.", "motivation": "To evaluate TabPFN v2's adaptability in open environments, addressing gaps in prior research.", "method": "A unified evaluation framework was created to test TabPFN v2's robustness against real-world open-environment challenges.", "result": "TabPFN v2 performs poorly in open environments but works well for small-scale, covariate-shifted, and class-balanced tasks.", "conclusion": "Tree-based models are better for open environments; future research should focus on benchmarks and robustness improvements."}}
{"id": "2505.16192", "pdf": "https://arxiv.org/pdf/2505.16192", "abs": "https://arxiv.org/abs/2505.16192", "authors": ["Chaoya Jiang", "Yongrui Heng", "Wei Ye", "Han Yang", "Haiyang Xu", "Ming Yan", "Ji Zhang", "Fei Huang", "Shikun Zhang"], "title": "VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recently, reasoning-based MLLMs have achieved a degree of success in\ngenerating long-form textual reasoning chains. However, they still struggle\nwith complex tasks that necessitate dynamic and iterative focusing on and\nrevisiting of visual regions to achieve precise grounding of textual reasoning\nin visual evidence. We introduce \\textbf{VLM-R$^3$} (\\textbf{V}isual\n\\textbf{L}anguage \\textbf{M}odel with \\textbf{R}egion \\textbf{R}ecognition and\n\\textbf{R}easoning), a framework that equips an MLLM with the ability to (i)\ndecide \\emph{when} additional visual evidence is needed, (ii) determine\n\\emph{where} to ground within the image, and (iii) seamlessly weave the\nrelevant sub-image content back into an interleaved chain-of-thought. The core\nof our method is \\textbf{Region-Conditioned Reinforcement Policy Optimization\n(R-GRPO)}, a training paradigm that rewards the model for selecting informative\nregions, formulating appropriate transformations (e.g.\\ crop, zoom), and\nintegrating the resulting visual context into subsequent reasoning steps. To\nbootstrap this policy, we compile a modest but carefully curated Visuo-Lingual\nInterleaved Rationale (VLIR) corpus that provides step-level supervision on\nregion selection and textual justification. Extensive experiments on MathVista,\nScienceQA, and other benchmarks show that VLM-R$^3$ sets a new state of the art\nin zero-shot and few-shot settings, with the largest gains appearing on\nquestions demanding subtle spatial reasoning or fine-grained visual cue\nextraction.", "AI": {"tldr": "VLM-R\u00b3 enhances MLLMs by dynamically focusing on and revisiting visual regions for precise grounding of textual reasoning, achieving state-of-the-art results.", "motivation": "Existing MLLMs struggle with complex tasks requiring dynamic visual grounding and iterative reasoning.", "method": "Introduces VLM-R\u00b3 with Region-Conditioned Reinforcement Policy Optimization (R-GRPO) and a curated VLIR corpus for training.", "result": "Achieves new state-of-the-art performance on benchmarks like MathVista and ScienceQA, especially in tasks needing spatial reasoning.", "conclusion": "VLM-R\u00b3 effectively bridges the gap between textual reasoning and visual evidence, improving performance in complex tasks."}}
{"id": "2505.16188", "pdf": "https://arxiv.org/pdf/2505.16188", "abs": "https://arxiv.org/abs/2505.16188", "authors": ["Zirui He", "Mingyu Jin", "Bo Shen", "Ali Payani", "Yongfeng Zhang", "Mengnan Du"], "title": "SAE-SSV: Supervised Steering in Sparse Representation Spaces for Reliable Control of Language Models", "categories": ["cs.CL"], "comment": "30 pages, 24 figures, 12 tables", "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language understanding and generation, but controlling their behavior\nreliably remains challenging, especially in open-ended generation settings.\nThis paper introduces a novel supervised steering approach that operates in\nsparse, interpretable representation spaces. We employ sparse autoencoders\n(SAEs)to obtain sparse latent representations that aim to disentangle semantic\nattributes from model activations. Then we train linear classifiers to identify\na small subspace of task-relevant dimensions in latent representations.\nFinally, we learn supervised steering vectors constrained to this subspace,\noptimized to align with target behaviors. Experiments across sentiment,\ntruthfulness, and politics polarity steering tasks with multiple LLMs\ndemonstrate that our supervised steering vectors achieve higher success rates\nwith minimal degradation in generation quality compared to existing methods.\nFurther analysis reveals that a notably small subspace is sufficient for\neffective steering, enabling more targeted and interpretable interventions.", "AI": {"tldr": "A novel supervised steering method for LLMs uses sparse autoencoders and linear classifiers to control behavior effectively in open-ended generation tasks.", "motivation": "Controlling LLM behavior reliably in open-ended settings is challenging, requiring interpretable and targeted interventions.", "method": "Uses sparse autoencoders for latent representations, linear classifiers to identify task-relevant subspaces, and supervised steering vectors constrained to these subspaces.", "result": "Achieves higher success rates in steering tasks (sentiment, truthfulness, politics) with minimal quality degradation, using a small subspace.", "conclusion": "The approach enables more targeted and interpretable control of LLM behavior with minimal impact on generation quality."}}
{"id": "2505.16507", "pdf": "https://arxiv.org/pdf/2505.16507", "abs": "https://arxiv.org/abs/2505.16507", "authors": ["Anshu Xiong", "Songmao Zhang"], "title": "Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)", "categories": ["cs.AI"], "comment": "This is a version of paper 'Relevance for Stability of Verification\n  Status of a Set of Arguments in Incomplete Argumentation Frameworks' extented\n  with proofs of the results in the paper", "summary": "The notion of relevance was proposed for stability of justification status of\na single argument in incomplete argumentation frameworks (IAFs) in 2024 by\nOdekerken et al. To extend the notion, we study the relevance for stability of\nverification status of a set of arguments in this paper, i.e., the\nuncertainties in an IAF that have to be resolved in some situations so that\nanswering whether a given set of arguments is an extension obtains the same\nresult in every completion of the IAF. Further we propose the notion of strong\nrelevance for describing the necessity of resolution in all situations reaching\nstability. An analysis of complexity reveals that detecting the (strong)\nrelevance for stability of sets of arguments can be accomplished in P time\nunder the most semantics discussed in the paper. We also discuss the difficulty\nin finding tractable methods for relevance detection under grounded semantics.", "AI": {"tldr": "The paper extends the notion of relevance for stability in incomplete argumentation frameworks (IAFs) to sets of arguments, introduces strong relevance, and analyzes computational complexity, showing P-time detection for most semantics but tractability challenges under grounded semantics.", "motivation": "To generalize the concept of relevance from single arguments to sets of arguments in IAFs, ensuring consistent verification status across completions, and to explore computational feasibility.", "method": "Extends relevance to sets of arguments, introduces strong relevance, and analyzes complexity under various semantics.", "result": "Detection of (strong) relevance for sets of arguments is in P-time for most semantics, but tractable methods under grounded semantics are challenging.", "conclusion": "The study advances understanding of relevance in IAFs, highlighting computational limits under grounded semantics."}}
{"id": "2505.16242", "pdf": "https://arxiv.org/pdf/2505.16242", "abs": "https://arxiv.org/abs/2505.16242", "authors": ["Runze Yan", "Xun Shen", "Akifumi Wachi", "Sebastien Gros", "Anni Zhao", "Xiao Hu"], "title": "Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "When applying offline reinforcement learning (RL) in healthcare scenarios,\nthe out-of-distribution (OOD) issues pose significant risks, as inappropriate\ngeneralization beyond clinical expertise can result in potentially harmful\nrecommendations. While existing methods like conservative Q-learning (CQL)\nattempt to address the OOD issue, their effectiveness is limited by only\nconstraining action selection by suppressing uncertain actions. This\naction-only regularization imitates clinician actions that prioritize\nshort-term rewards, but it fails to regulate downstream state trajectories,\nthereby limiting the discovery of improved long-term treatment strategies. To\nsafely improve policy beyond clinician recommendations while ensuring that\nstate-action trajectories remain in-distribution, we propose \\textit{Offline\nGuarded Safe Reinforcement Learning} ($\\mathsf{OGSRL}$), a theoretically\ngrounded model-based offline RL framework. $\\mathsf{OGSRL}$ introduces a novel\ndual constraint mechanism for improving policy with reliability and safety.\nFirst, the OOD guardian is established to specify clinically validated regions\nfor safe policy exploration. By constraining optimization within these regions,\nit enables the reliable exploration of treatment strategies that outperform\nclinician behavior by leveraging the full patient state history, without\ndrifting into unsupported state-action trajectories. Second, we introduce a\nsafety cost constraint that encodes medical knowledge about physiological\nsafety boundaries, providing domain-specific safeguards even in areas where\ntraining data might contain potentially unsafe interventions. Notably, we\nprovide theoretical guarantees on safety and near-optimality: policies that\nsatisfy these constraints remain in safe and reliable regions and achieve\nperformance close to the best possible policy supported by the data.", "AI": {"tldr": "The paper proposes Offline Guarded Safe Reinforcement Learning (OGSRL) to address out-of-distribution (OOD) issues in offline RL for healthcare, ensuring safe and reliable policy improvements beyond clinician actions.", "motivation": "Existing methods like CQL inadequately address OOD issues by only constraining actions, limiting long-term treatment strategy discovery. Healthcare requires safe exploration beyond clinician recommendations.", "method": "OGSRL introduces dual constraints: an OOD guardian for clinically validated safe regions and a safety cost constraint encoding medical knowledge, ensuring safe policy optimization.", "result": "OGSRL guarantees policies remain in safe regions and achieve near-optimal performance, outperforming clinician behavior without unsafe deviations.", "conclusion": "OGSRL provides a theoretically grounded, safe, and effective framework for offline RL in healthcare, addressing OOD challenges and enabling reliable policy improvements."}}
{"id": "2505.16209", "pdf": "https://arxiv.org/pdf/2505.16209", "abs": "https://arxiv.org/abs/2505.16209", "authors": ["Shuchang Ye", "Usman Naseem", "Mingyuan Meng", "Dagan Feng", "Jinman Kim"], "title": "A Causal Approach to Mitigate Modality Preference Bias in Medical Visual Question Answering", "categories": ["cs.CV"], "comment": null, "summary": "Medical Visual Question Answering (MedVQA) is crucial for enhancing the\nefficiency of clinical diagnosis by providing accurate and timely responses to\nclinicians' inquiries regarding medical images. Existing MedVQA models suffered\nfrom modality preference bias, where predictions are heavily dominated by one\nmodality while overlooking the other (in MedVQA, usually questions dominate the\nanswer but images are overlooked), thereby failing to learn multimodal\nknowledge. To overcome the modality preference bias, we proposed a Medical\nCounterFactual VQA (MedCFVQA) model, which trains with bias and leverages\ncausal graphs to eliminate the modality preference bias during inference.\nExisting MedVQA datasets exhibit substantial prior dependencies between\nquestions and answers, which results in acceptable performance even if the\nmodel significantly suffers from the modality preference bias. To address this\nissue, we reconstructed new datasets by leveraging existing MedVQA datasets and\nChanged their P3rior dependencies (CP) between questions and their answers in\nthe training and test set. Extensive experiments demonstrate that MedCFVQA\nsignificantly outperforms its non-causal counterpart on both SLAKE, RadVQA and\nSLAKE-CP, RadVQA-CP datasets.", "AI": {"tldr": "The paper introduces MedCFVQA, a model addressing modality preference bias in MedVQA by using causal graphs and reconstructing datasets to reduce prior dependencies.", "motivation": "Existing MedVQA models suffer from modality preference bias, where one modality dominates, limiting multimodal learning.", "method": "Proposed MedCFVQA uses causal graphs to eliminate bias during inference and reconstructs datasets (SLAKE-CP, RadVQA-CP) to reduce prior dependencies.", "result": "MedCFVQA outperforms non-causal models on both original and reconstructed datasets (SLAKE, RadVQA, SLAKE-CP, RadVQA-CP).", "conclusion": "MedCFVQA effectively mitigates modality bias and improves performance by addressing dataset biases and leveraging causal inference."}}
{"id": "2505.16189", "pdf": "https://arxiv.org/pdf/2505.16189", "abs": "https://arxiv.org/abs/2505.16189", "authors": ["Sophie Wu", "Jan Philip Wahle", "Saif M. Mohammad"], "title": "The Language of Interoception: Examining Embodiment and Emotion Through a Corpus of Body Part Mentions", "categories": ["cs.CL"], "comment": "8 pages, 26 figures", "summary": "This paper is the first investigation of the connection between emotion,\nembodiment, and everyday language in a large sample of natural language data.\nWe created corpora of body part mentions (BPMs) in online English text (blog\nposts and tweets). This includes a subset featuring human annotations for the\nemotions of the person whose body part is mentioned in the text. We show that\nBPMs are common in personal narratives and tweets (~5% to 10% of posts include\nBPMs) and that their usage patterns vary markedly by time and %geographic\nlocation. Using word-emotion association lexicons and our annotated data, we\nshow that text containing BPMs tends to be more emotionally charged, even when\nthe BPM is not explicitly used to describe a physical reaction to the emotion\nin the text. Finally, we discover a strong and statistically significant\ncorrelation between body-related language and a variety of poorer health\noutcomes. In sum, we argue that investigating the role of body-part related\nwords in language can open up valuable avenues of future research at the\nintersection of NLP, the affective sciences, and the study of human wellbeing.", "AI": {"tldr": "The paper explores the link between emotion, embodiment, and everyday language using large-scale natural language data, revealing correlations between body part mentions (BPMs), emotional charge, and health outcomes.", "motivation": "To investigate how body-related language reflects emotions and health in natural communication.", "method": "Analyzed corpora of BPMs in blog posts and tweets, including annotated emotional context, and used word-emotion lexicons.", "result": "BPMs are common (5-10% of posts), emotionally charged, and correlate with poorer health outcomes.", "conclusion": "Body-related language offers insights for NLP, affective sciences, and wellbeing research."}}
{"id": "2505.16579", "pdf": "https://arxiv.org/pdf/2505.16579", "abs": "https://arxiv.org/abs/2505.16579", "authors": ["Siqu Ou", "Hongcheng Liu", "Pingjie Wang", "Yusheng Liao", "Chuan Xuan", "Yanfeng Wang", "Yu Wang"], "title": "Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning", "categories": ["cs.AI", "cs.CV"], "comment": "19 pages, 8 figures", "summary": "While chains-of-thought (CoT) have advanced complex reasoning in multimodal\nlarge language models (MLLMs), existing methods remain confined to text or\nstatic visual domains, often faltering in dynamic spatial reasoning tasks. To\nbridge this gap, we present GRASSLAND, a novel maze navigation benchmark\ndesigned to evaluate dynamic spatial reasoning. Our experiments show that\naugmenting textual reasoning chains with dynamic visual drafts, overlaid on\ninput images, significantly outperforms conventional approaches, offering new\ninsights into spatial reasoning in evolving environments. To generalize this\ncapability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free\nframework that seamlessly integrates textual CoT with corresponding visual\ndrafts into MLLMs. Extensive evaluations demonstrate that D2R consistently\nenhances performance across diverse tasks, establishing a robust baseline for\ndynamic spatial reasoning without requiring model fine-tuning. Project is open\nat https://github.com/Cratileo/D2R.", "AI": {"tldr": "GRASSLAND introduces a maze navigation benchmark for dynamic spatial reasoning, and D2R enhances MLLMs by integrating visual drafts with textual reasoning chains.", "motivation": "Existing methods for complex reasoning in MLLMs are limited to text or static visuals, struggling with dynamic spatial tasks.", "method": "Proposes D2R, a training-free framework combining textual CoT with dynamic visual drafts.", "result": "D2R outperforms conventional methods, improving performance in dynamic spatial reasoning without fine-tuning.", "conclusion": "D2R sets a robust baseline for dynamic spatial reasoning, with open-source availability."}}
{"id": "2505.16248", "pdf": "https://arxiv.org/pdf/2505.16248", "abs": "https://arxiv.org/abs/2505.16248", "authors": ["Wenxuan Zhu", "Qiyuan Wu", "Tengda Tang", "Renzi Meng", "Sheng Chai", "Xuehui Quan"], "title": "Graph Neural Network-Based Collaborative Perception for Adaptive Scheduling in Distributed Systems", "categories": ["cs.LG"], "comment": null, "summary": "This paper addresses the limitations of multi-node perception and delayed\nscheduling response in distributed systems by proposing a GNN-based multi-node\ncollaborative perception mechanism. The system is modeled as a graph structure.\nMessage-passing and state-update modules are introduced. A multi-layer graph\nneural network is constructed to enable efficient information aggregation and\ndynamic state inference among nodes. In addition, a perception representation\nmethod is designed by fusing local states with global features. This improves\neach node's ability to perceive the overall system status. The proposed method\nis evaluated within a customized experimental framework. A dataset featuring\nheterogeneous task loads and dynamic communication topologies is used.\nPerformance is measured in terms of task completion rate, average latency, load\nbalancing, and transmission efficiency. Experimental results show that the\nproposed method outperforms mainstream algorithms under various conditions,\nincluding limited bandwidth and dynamic structural changes. It demonstrates\nsuperior perception capabilities and cooperative scheduling performance. The\nmodel achieves rapid convergence and efficient responses to complex system\nstates.", "AI": {"tldr": "A GNN-based multi-node collaborative perception mechanism improves distributed system performance by enhancing perception and scheduling efficiency.", "motivation": "Addressing limitations in multi-node perception and delayed scheduling in distributed systems.", "method": "Proposes a GNN-based mechanism with message-passing, state-update modules, and multi-layer GNN for dynamic state inference and information aggregation.", "result": "Outperforms mainstream algorithms in task completion, latency, load balancing, and transmission efficiency under dynamic conditions.", "conclusion": "The method enhances system perception and cooperative scheduling, achieving rapid convergence and efficient responses."}}
{"id": "2505.16228", "pdf": "https://arxiv.org/pdf/2505.16228", "abs": "https://arxiv.org/abs/2505.16228", "authors": ["Wei-Lun Huang", "Joshua Liu", "Davood Tashayyod", "Jun Kang", "Amir Gandjbakhche", "Misha Kazhdan", "Mehran Armand"], "title": "A Shape-Aware Total Body Photography System for In-focus Surface Coverage Optimization", "categories": ["cs.CV"], "comment": "Accepted to JBHI", "summary": "Total Body Photography (TBP) is becoming a useful screening tool for patients\nat high risk for skin cancer. While much progress has been made, existing TBP\nsystems can be further improved for automatic detection and analysis of\nsuspicious skin lesions, which is in part related to the resolution and\nsharpness of acquired images. This paper proposes a novel shape-aware TBP\nsystem automatically capturing full-body images while optimizing image quality\nin terms of resolution and sharpness over the body surface. The system uses\ndepth and RGB cameras mounted on a 360-degree rotary beam, along with 3D body\nshape estimation and an in-focus surface optimization method to select the\noptimal focus distance for each camera pose. This allows for optimizing the\nfocused coverage over the complex 3D geometry of the human body given the\ncalibrated camera poses. We evaluate the effectiveness of the system in\ncapturing high-fidelity body images. The proposed system achieves an average\nresolution of 0.068 mm/pixel and 0.0566 mm/pixel with approximately 85% and 95%\nof surface area in-focus, evaluated on simulation data of diverse body shapes\nand poses as well as a real scan of a mannequin respectively. Furthermore, the\nproposed shape-aware focus method outperforms existing focus protocols (e.g.\nauto-focus). We believe the high-fidelity imaging enabled by the proposed\nsystem will improve automated skin lesion analysis for skin cancer screening.", "AI": {"tldr": "A novel shape-aware Total Body Photography (TBP) system improves image quality for skin cancer screening by optimizing resolution and sharpness using 3D body shape estimation and focus optimization.", "motivation": "Existing TBP systems lack optimal image quality for automatic detection of suspicious skin lesions, necessitating improvements in resolution and sharpness.", "method": "The system uses depth and RGB cameras on a rotary beam, 3D body shape estimation, and focus optimization to capture high-fidelity full-body images.", "result": "Achieves 0.068 mm/pixel resolution and 85% in-focus coverage in simulations, and 0.0566 mm/pixel with 95% in-focus on a mannequin, outperforming auto-focus.", "conclusion": "The proposed system enhances automated skin lesion analysis, advancing skin cancer screening."}}
{"id": "2505.16193", "pdf": "https://arxiv.org/pdf/2505.16193", "abs": "https://arxiv.org/abs/2505.16193", "authors": ["Daiqing Wu", "Dongbao Yang", "Sicheng Zhao", "Can Ma", "Yu Zhou"], "title": "An Empirical Study on Configuring In-Context Learning Demonstrations for Unleashing MLLMs' Sentimental Perception Capability", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "The advancements in Multimodal Large Language Models (MLLMs) have enabled\nvarious multimodal tasks to be addressed under a zero-shot paradigm. This\nparadigm sidesteps the cost of model fine-tuning, emerging as a dominant trend\nin practical application. Nevertheless, Multimodal Sentiment Analysis (MSA), a\npivotal challenge in the quest for general artificial intelligence, fails to\naccommodate this convenience. The zero-shot paradigm exhibits undesirable\nperformance on MSA, casting doubt on whether MLLMs can perceive sentiments as\ncompetent as supervised models. By extending the zero-shot paradigm to\nIn-Context Learning (ICL) and conducting an in-depth study on configuring\ndemonstrations, we validate that MLLMs indeed possess such capability.\nSpecifically, three key factors that cover demonstrations' retrieval,\npresentation, and distribution are comprehensively investigated and optimized.\nA sentimental predictive bias inherent in MLLMs is also discovered and later\neffectively counteracted. By complementing each other, the devised strategies\nfor three factors result in average accuracy improvements of 15.9% on six MSA\ndatasets against the zero-shot paradigm and 11.2% against the random ICL\nbaseline.", "AI": {"tldr": "The paper explores improving Multimodal Sentiment Analysis (MSA) using Multimodal Large Language Models (MLLMs) via In-Context Learning (ICL), addressing zero-shot limitations and optimizing demonstrations for better performance.", "motivation": "Zero-shot MLLMs underperform in MSA, raising doubts about their sentiment perception. The study aims to validate MLLMs' capability by refining ICL.", "method": "Extends zero-shot to ICL, optimizing demonstrations' retrieval, presentation, and distribution. Identifies and counteracts a sentimental bias in MLLMs.", "result": "Achieves 15.9% and 11.2% accuracy improvements over zero-shot and random ICL baselines, respectively, across six MSA datasets.", "conclusion": "MLLMs can excel in MSA with proper ICL configuration, overcoming zero-shot limitations and biases."}}
{"id": "2505.16619", "pdf": "https://arxiv.org/pdf/2505.16619", "abs": "https://arxiv.org/abs/2505.16619", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "categories": ["cs.AI", "q-bio.OT", "92", "J.3"], "comment": "1 PDF, 24 Pages, 2 figures within. Co-corresponding authors:\n  Institute of Applied Biosciences, Centre for Research and Technology Hellas,\n  Thessaloniki, Greece and Department of Biomedical Sciences, University of\n  Padova, Padova, Italy. E-mails: fpsom@certh.gr, silvio.tosatto@unipd.it", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "AI": {"tldr": "The paper discusses the challenges of AI in life sciences, focusing on trust, reproducibility, and sustainability, and proposes Open and Sustainable AI (OSAI) recommendations to address these issues.", "motivation": "To address the erosion of trust and sustainability issues in AI-based life science research due to poor reusability and reproducibility.", "method": "The paper reviews challenges and introduces OSAI recommendations mapped to over 300 AI ecosystem components.", "result": "A practical set of OSAI recommendations is provided to support sustainable, reusable, and transparent AI in life sciences.", "conclusion": "The OSAI framework aids future policy development and structured AI implementation in life sciences."}}
{"id": "2505.16260", "pdf": "https://arxiv.org/pdf/2505.16260", "abs": "https://arxiv.org/abs/2505.16260", "authors": ["Alaa Khaddaj", "Logan Engstrom", "Aleksander Madry"], "title": "Small-to-Large Generalization: Data Influences Models Consistently Across Scale", "categories": ["cs.LG"], "comment": null, "summary": "Choice of training data distribution greatly influences model behavior. Yet,\nin large-scale settings, precisely characterizing how changes in training data\naffects predictions is often difficult due to model training costs. Current\npractice is to instead extrapolate from scaled down, inexpensive-to-train proxy\nmodels. However, changes in data do not influence smaller and larger models\nidentically. Therefore, understanding how choice of data affects large-scale\nmodels raises the question: how does training data distribution influence model\nbehavior across compute scale? We find that small- and large-scale language\nmodel predictions (generally) do highly correlate across choice of training\ndata. Equipped with these findings, we characterize how proxy scale affects\neffectiveness in two downstream proxy model applications: data attribution and\ndataset selection.", "AI": {"tldr": "Small- and large-scale language models show high correlation in predictions across training data distributions, validating the use of proxy models for data attribution and dataset selection.", "motivation": "Understanding how training data distribution affects model behavior across different compute scales, given the impracticality of training large models repeatedly.", "method": "Analyzing correlations between small- and large-scale language model predictions under varying training data distributions.", "result": "High correlation between small and large model predictions, supporting proxy model use.", "conclusion": "Proxy models are effective for tasks like data attribution and dataset selection, despite scale differences."}}
{"id": "2505.16229", "pdf": "https://arxiv.org/pdf/2505.16229", "abs": "https://arxiv.org/abs/2505.16229", "authors": ["Yuren Mao", "Wenyi Xu", "Yuyang Qin", "Yunjun Gao"], "title": "CT-Agent: A Multimodal-LLM Agent for 3D CT Radiology Question Answering", "categories": ["cs.CV"], "comment": null, "summary": "Computed Tomography (CT) scan, which produces 3D volumetric medical data that\ncan be viewed as hundreds of cross-sectional images (a.k.a. slices), provides\ndetailed anatomical information for diagnosis. For radiologists, creating CT\nradiology reports is time-consuming and error-prone. A visual question\nanswering (VQA) system that can answer radiologists' questions about some\nanatomical regions on the CT scan and even automatically generate a radiology\nreport is urgently needed. However, existing VQA systems cannot adequately\nhandle the CT radiology question answering (CTQA) task for: (1) anatomic\ncomplexity makes CT images difficult to understand; (2) spatial relationship\nacross hundreds slices is difficult to capture. To address these issues, this\npaper proposes CT-Agent, a multimodal agentic framework for CTQA. CT-Agent\nadopts anatomically independent tools to break down the anatomic complexity;\nfurthermore, it efficiently captures the across-slice spatial relationship with\na global-local token compression strategy. Experimental results on two 3D chest\nCT datasets, CT-RATE and RadGenome-ChestCT, verify the superior performance of\nCT-Agent.", "AI": {"tldr": "CT-Agent, a multimodal framework, improves CT radiology question answering by addressing anatomic complexity and spatial relationships across slices.", "motivation": "Radiologists face challenges in creating CT reports due to time constraints and errors. Existing VQA systems fail to handle CTQA tasks effectively.", "method": "CT-Agent uses anatomically independent tools and a global-local token compression strategy to simplify complexity and capture spatial relationships.", "result": "CT-Agent outperforms on CT-RATE and RadGenome-ChestCT datasets.", "conclusion": "CT-Agent is a promising solution for automating CT radiology reports and answering radiologists' questions."}}
{"id": "2505.16216", "pdf": "https://arxiv.org/pdf/2505.16216", "abs": "https://arxiv.org/abs/2505.16216", "authors": ["Jisu Kim", "Youngwoo Shin", "Uiji Hwang", "Jihun Choi", "Richeng Xuan", "Taeuk Kim"], "title": "Memorization or Reasoning? Exploring the Idiom Understanding of LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Idioms have long posed a challenge due to their unique linguistic properties,\nwhich set them apart from other common expressions. While recent studies have\nleveraged large language models (LLMs) to handle idioms across various tasks,\ne.g., idiom-containing sentence generation and idiomatic machine translation,\nlittle is known about the underlying mechanisms of idiom processing in LLMs,\nparticularly in multilingual settings. To this end, we introduce MIDAS, a new\nlarge-scale dataset of idioms in six languages, each paired with its\ncorresponding meaning. Leveraging this resource, we conduct a comprehensive\nevaluation of LLMs' idiom processing ability, identifying key factors that\ninfluence their performance. Our findings suggest that LLMs rely not only on\nmemorization, but also adopt a hybrid approach that integrates contextual cues\nand reasoning, especially when processing compositional idioms. This implies\nthat idiom understanding in LLMs emerges from an interplay between internal\nknowledge retrieval and reasoning-based inference.", "AI": {"tldr": "The paper introduces MIDAS, a multilingual idiom dataset, to evaluate LLMs' idiom processing, revealing a hybrid approach combining memorization and reasoning.", "motivation": "Idioms challenge LLMs due to their unique properties, yet the mechanisms of idiom processing in multilingual settings are underexplored.", "method": "MIDAS, a large-scale dataset of idioms in six languages, is used to comprehensively evaluate LLMs' idiom processing abilities.", "result": "LLMs use a hybrid approach (memorization + reasoning) for idioms, especially compositional ones, suggesting interplay between knowledge retrieval and inference.", "conclusion": "Idiom understanding in LLMs involves both internal knowledge and reasoning, highlighting the need for further exploration of these mechanisms."}}
{"id": "2505.16646", "pdf": "https://arxiv.org/pdf/2505.16646", "abs": "https://arxiv.org/abs/2505.16646", "authors": ["Yujie Hou", "Ting Zhang", "Mei Wang", "Xuetao Ma", "Hu Huang"], "title": "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models have achieved remarkable results on a variety of\nmathematical benchmarks. However, concerns remain as to whether these successes\nreflect genuine mathematical reasoning or superficial pattern recognition.\nCommon evaluation metrics, such as final answer accuracy, fail to disentangle\nthe underlying competencies involved, offering limited diagnostic value. To\naddress these limitations, we introduce SMART: a Self-Generating and\nSelf-Validating Multi-Dimensional Assessment Framework. SMART decomposes\nmathematical problem solving into four distinct dimensions: understanding,\nreasoning, arithmetic, and reflection \\& refinement. Each dimension is\nevaluated independently through tailored tasks, enabling interpretable and\nfine-grained analysis of LLM behavior. Crucially, SMART integrates an automated\nself-generating and self-validating mechanism to produce and verify benchmark\ndata, ensuring both scalability and reliability. We apply SMART to 21\nstate-of-the-art open- and closed-source LLMs, uncovering significant\ndiscrepancies in their abilities across different dimensions. Our findings\ndemonstrate the inadequacy of final answer accuracy as a sole metric and\nmotivate a new holistic metric to better capture true problem-solving\ncapabilities. Code and benchmarks will be released upon acceptance.", "AI": {"tldr": "SMART is a framework for multi-dimensional assessment of LLMs in math, evaluating understanding, reasoning, arithmetic, and reflection, revealing gaps in current metrics.", "motivation": "Current metrics like final answer accuracy fail to assess genuine mathematical reasoning in LLMs, necessitating a more nuanced evaluation.", "method": "SMART decomposes math problem-solving into four dimensions, using tailored tasks and an automated self-generating/validating mechanism for scalable, reliable benchmarks.", "result": "Applied to 21 LLMs, SMART uncovered significant discrepancies in abilities across dimensions, showing final answer accuracy is insufficient.", "conclusion": "SMART highlights the need for holistic metrics to better capture true problem-solving capabilities in LLMs."}}
{"id": "2505.16265", "pdf": "https://arxiv.org/pdf/2505.16265", "abs": "https://arxiv.org/abs/2505.16265", "authors": ["Ilgee Hong", "Changlong Yu", "Liang Qiu", "Weixiang Yan", "Zhenghao Xu", "Haoming Jiang", "Qingru Zhang", "Qin Lu", "Xin Liu", "Chao Zhang", "Tuo Zhao"], "title": "Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) has become a powerful\npost-training paradigm for aligning large language models with human\npreferences. A core challenge in RLHF is constructing accurate reward signals,\nwhere the conventional Bradley-Terry reward models (BT RMs) often suffer from\nsensitivity to data size and coverage, as well as vulnerability to reward\nhacking. Generative reward models (GenRMs) offer a more robust alternative by\ngenerating chain-of-thought (CoT) rationales followed by a final reward.\nHowever, existing GenRMs rely on shallow, vertically scaled reasoning, limiting\ntheir capacity to handle nuanced or complex (e.g., reasoning-intensive) tasks.\nMoreover, their pairwise preference outputs are incompatible with standard RLHF\nalgorithms that require pointwise reward signals. In this work, we introduce\nThink-RM, a training framework that enables long-horizon reasoning in GenRMs by\nmodeling an internal thinking process. Rather than producing structured,\nexternally provided rationales, Think-RM generates flexible, self-guided\nreasoning traces that support advanced capabilities such as self-reflection,\nhypothetical reasoning, and divergent reasoning. To elicit these reasoning\nabilities, we first warm-up the models by supervised fine-tuning (SFT) over\nlong CoT data. We then further improve the model's long-horizon abilities by\nrule-based reinforcement learning (RL). In addition, we propose a novel\npairwise RLHF pipeline that directly optimizes policies using pairwise\npreference rewards, eliminating the need for pointwise reward conversion and\nenabling more effective use of Think-RM outputs. Experiments show that Think-RM\nachieves state-of-the-art results on RM-Bench, outperforming both BT RM and\nvertically scaled GenRM by 8%. When combined with our pairwise RLHF pipeline,\nit demonstrates superior end-policy performance compared to traditional\napproaches.", "AI": {"tldr": "Think-RM improves reinforcement learning from human feedback (RLHF) by enabling long-horizon reasoning in generative reward models (GenRMs), outperforming traditional methods by 8%.", "motivation": "Addressing limitations of conventional Bradley-Terry reward models (BT RMs) and shallow GenRMs in RLHF, which struggle with data sensitivity, reward hacking, and complex tasks.", "method": "Introduces Think-RM, a framework for self-guided reasoning in GenRMs, trained via supervised fine-tuning and rule-based reinforcement learning, and a pairwise RLHF pipeline.", "result": "Think-RM achieves state-of-the-art results on RM-Bench, outperforming BT RM and vertically scaled GenRM by 8%.", "conclusion": "Think-RM and the pairwise RLHF pipeline offer a robust solution for aligning language models with human preferences, enhancing performance and reasoning capabilities."}}
{"id": "2505.16239", "pdf": "https://arxiv.org/pdf/2505.16239", "abs": "https://arxiv.org/abs/2505.16239", "authors": ["Zheng Chen", "Zichen Zou", "Kewei Zhang", "Xiongfei Su", "Xin Yuan", "Yong Guo", "Yulun Zhang"], "title": "DOVE: Efficient One-Step Diffusion Model for Real-World Video Super-Resolution", "categories": ["cs.CV"], "comment": "Code is available at: https://github.com/zhengchen1999/DOVE", "summary": "Diffusion models have demonstrated promising performance in real-world video\nsuper-resolution (VSR). However, the dozens of sampling steps they require,\nmake inference extremely slow. Sampling acceleration techniques, particularly\nsingle-step, provide a potential solution. Nonetheless, achieving one step in\nVSR remains challenging, due to the high training overhead on video data and\nstringent fidelity demands. To tackle the above issues, we propose DOVE, an\nefficient one-step diffusion model for real-world VSR. DOVE is obtained by\nfine-tuning a pretrained video diffusion model (*i.e.*, CogVideoX). To\neffectively train DOVE, we introduce the latent-pixel training strategy. The\nstrategy employs a two-stage scheme to gradually adapt the model to the video\nsuper-resolution task. Meanwhile, we design a video processing pipeline to\nconstruct a high-quality dataset tailored for VSR, termed HQ-VSR. Fine-tuning\non this dataset further enhances the restoration capability of DOVE. Extensive\nexperiments show that DOVE exhibits comparable or superior performance to\nmulti-step diffusion-based VSR methods. It also offers outstanding inference\nefficiency, achieving up to a **28$\\times$** speed-up over existing methods\nsuch as MGLD-VSR. Code is available at: https://github.com/zhengchen1999/DOVE.", "AI": {"tldr": "DOVE is a one-step diffusion model for video super-resolution (VSR), offering faster inference while maintaining performance comparable to multi-step methods.", "motivation": "Diffusion models for VSR are slow due to multiple sampling steps. Single-step solutions are challenging due to training overhead and fidelity demands.", "method": "DOVE fine-tunes a pretrained video diffusion model (CogVideoX) using a latent-pixel training strategy and a high-quality dataset (HQ-VSR).", "result": "DOVE matches or outperforms multi-step VSR methods and achieves a 28x speed-up over existing methods like MGLD-VSR.", "conclusion": "DOVE efficiently addresses the speed-performance trade-off in VSR, making it practical for real-world applications."}}
{"id": "2505.16222", "pdf": "https://arxiv.org/pdf/2505.16222", "abs": "https://arxiv.org/abs/2505.16222", "authors": ["Jiwon Moon", "Yerin Hwang", "Dongryeol Lee", "Taegwan Kang", "Yongil Kim", "Kyomin Jung"], "title": "Don't Judge Code by Its Cover: Exploring Biases in LLM Judges for Code Evaluation", "categories": ["cs.CL", "cs.SE"], "comment": "26 pages", "summary": "With the growing use of large language models(LLMs) as evaluators, their\napplication has expanded to code evaluation tasks, where they assess the\ncorrectness of generated code without relying on reference implementations.\nWhile this offers scalability and flexibility, it also raises a critical,\nunresolved question: Can LLM judges fairly and robustly evaluate semantically\nequivalent code with superficial variations? Functionally correct code often\nexhibits variations-such as differences in variable names, comments, or\nformatting-that should not influence its correctness. Yet, whether LLM judges\ncan reliably handle these variations remains unclear. We present the first\ncomprehensive study of this issue, defining six types of potential bias in code\nevaluation and revealing their systematic impact on LLM judges. Across five\nprogramming languages and multiple LLMs, we empirically demonstrate that all\ntested LLM judges are susceptible to both positive and negative biases,\nresulting in inflated or unfairly low scores. Moreover, we observe that LLM\njudges remain vulnerable to these biases even when prompted to generate test\ncases before scoring, highlighting the need for more robust code evaluation\nmethods.", "AI": {"tldr": "LLMs as code evaluators are prone to biases when assessing semantically equivalent code with superficial variations, impacting fairness and robustness.", "motivation": "To investigate whether LLM judges can fairly evaluate code with superficial variations, given their increasing use in code evaluation tasks.", "method": "A comprehensive study defining six types of bias, tested across five programming languages and multiple LLMs, including prompting for test cases.", "result": "All tested LLM judges exhibited biases, leading to inflated or unfairly low scores, even with test case generation.", "conclusion": "Current LLM-based code evaluation methods lack robustness, necessitating improved approaches to handle superficial variations fairly."}}
{"id": "2505.16667", "pdf": "https://arxiv.org/pdf/2505.16667", "abs": "https://arxiv.org/abs/2505.16667", "authors": ["Xinwei Yang", "Zhaofeng Liu", "Chen Huang", "Jiashuai Zhang", "Tong Zhang", "Yifan Zhang", "Wenqiang Lei"], "title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming", "categories": ["cs.AI"], "comment": "ACL 2025 Main. Our code and dataset are available at\n  https://github.com/SCUNLP/ELABORATION", "summary": "While recent research increasingly emphasizes the value of human-LLM\ncollaboration in competitive programming and proposes numerous empirical\nmethods, a comprehensive understanding remains elusive due to the fragmented\nnature of existing studies and their use of diverse, application-specific human\nfeedback. Thus, our work serves a three-fold purpose: First, we present the\nfirst taxonomy of human feedback consolidating the entire programming process,\nwhich promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a\nnovel programming dataset specifically designed for human-LLM collaboration,\nmeticulously annotated to enable large-scale simulated human feedback and\nfacilitate costeffective real human interaction studies. Third, we introduce\nELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM\ncompetitive programming. With ELABORATION, we pinpoint strengthes and\nweaknesses of existing methods, thereby setting the foundation for future\nimprovement. Our code and dataset are available at\nhttps://github.com/SCUNLP/ELABORATION", "AI": {"tldr": "The paper introduces a taxonomy of human feedback, a dataset (ELABORATIONSET), and a benchmark (ELABORATION) for human-LLM collaboration in competitive programming, aiming to unify fragmented research and improve evaluation.", "motivation": "To address the lack of comprehensive understanding in human-LLM collaboration for competitive programming due to fragmented studies and diverse feedback methods.", "method": "Develops a taxonomy of human feedback, creates ELABORATIONSET (a dataset for human-LLM collaboration), and introduces ELABORATION (a benchmark for assessment).", "result": "Provides tools for fine-grained evaluation, large-scale simulated feedback, and identifies strengths/weaknesses of existing methods.", "conclusion": "Lays the foundation for future improvements in human-LLM collaboration for competitive programming."}}
{"id": "2505.16284", "pdf": "https://arxiv.org/pdf/2505.16284", "abs": "https://arxiv.org/abs/2505.16284", "authors": ["Josh Alman", "Zhao Song"], "title": "Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse", "categories": ["cs.LG"], "comment": null, "summary": "Attention mechanisms lie at the heart of modern large language models (LLMs).\nStraightforward algorithms for forward and backward (gradient) computation take\nquadratic time, and a line of work initiated by [Alman and Song NeurIPS 2023]\nand [Alman and Song NeurIPS 2024] has shown that quadratic time is necessary\nunless the model weights are small, in which case almost linear time algorithms\nare possible. In this paper, we show that large weights are necessary to avoid\na strong preclusion to representational strength we call layer collapse, which\nmeans that the entire network can be approximated well by a network with only a\nsingle layer. Thus, the quadratic running time of attention is unavoidable for\nexpressive transformers.\n  The notion of layer collapse that we introduce is a variant on the notion of\nrank collapse from the work of [Dong, Cordonnier, and Loukas ICML 2021]. They\nshowed that in Self Attention Networks with small weights and with skip\nconnections, rank collapse must occur. This is typically interpreted as\njustifying the necessity of skip connections in expressive networks. However,\nour result shows that even with skip connections, if the weights are small,\nthen layer collapse still occurs. Thus, only large weights, and not skip\nconnections, can prevent these representational weaknesses.", "AI": {"tldr": "Quadratic time for attention mechanisms in LLMs is unavoidable for expressive transformers, as small weights lead to layer collapse, a representational weakness.", "motivation": "To investigate the necessity of quadratic time in attention mechanisms and the role of large weights in preventing layer collapse, a representational weakness.", "method": "Analyzing the impact of weight size on layer collapse, comparing with prior work on rank collapse, and demonstrating the inevitability of quadratic time for expressive transformers.", "result": "Large weights are necessary to avoid layer collapse; skip connections alone cannot prevent it, making quadratic time unavoidable for expressive attention mechanisms.", "conclusion": "Quadratic running time in attention mechanisms is essential for expressive transformers, as small weights lead to layer collapse, and skip connections are insufficient to mitigate this."}}
{"id": "2505.16253", "pdf": "https://arxiv.org/pdf/2505.16253", "abs": "https://arxiv.org/abs/2505.16253", "authors": ["Preeti Mehta", "Aman Sagar", "Suchi Kumari"], "title": "Swin Transformer for Robust CGI Images Detection: Intra- and Inter-Dataset Analysis across Multiple Color Spaces", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2409.04734", "summary": "This study aims to address the growing challenge of distinguishing\ncomputer-generated imagery (CGI) from authentic digital images across three\ndifferent color spaces; RGB, YCbCr, and HSV. Given the limitations of existing\nclassification methods in handling the complexity and variability of CGI, this\nresearch proposes a Swin Transformer based model for accurate differentiation\nbetween natural and synthetic images. The proposed model leverages the Swin\nTransformer's hierarchical architecture to capture local and global features\nfor distinguishing CGI from natural images. Its performance was assessed\nthrough intra- and inter-dataset testing across three datasets: CiFAKE, JSSSTU,\nand Columbia. The model was evaluated individually on each dataset (D1, D2, D3)\nand on the combined datasets (D1+D2+D3) to test its robustness and domain\ngeneralization. To address dataset imbalance, data augmentation techniques were\napplied. Additionally, t-SNE visualization was used to demonstrate the feature\nseparability achieved by the Swin Transformer across the selected color spaces.\nThe model's performance was tested across all color schemes, with the RGB color\nscheme yielding the highest accuracy for each dataset. As a result, RGB was\nselected for domain generalization analysis and compared with other CNN-based\nmodels, VGG-19 and ResNet-50. The comparative results demonstrate the proposed\nmodel's effectiveness in detecting CGI, highlighting its robustness and\nreliability in both intra-dataset and inter-dataset evaluations. The findings\nof this study highlight the Swin Transformer model's potential as an advanced\ntool for digital image forensics, particularly in distinguishing CGI from\nnatural images. The model's strong performance indicates its capability for\ndomain generalization, making it a valuable asset in scenarios requiring\nprecise and reliable image classification.", "AI": {"tldr": "A Swin Transformer model is proposed to distinguish CGI from natural images across RGB, YCbCr, and HSV color spaces, outperforming CNN-based models like VGG-19 and ResNet-50 in accuracy and robustness.", "motivation": "Address the challenge of differentiating CGI from authentic images due to limitations in existing methods.", "method": "Uses a Swin Transformer model to capture local and global features, tested on datasets CiFAKE, JSSSTU, and Columbia with data augmentation and t-SNE visualization.", "result": "RGB color scheme yielded highest accuracy; model outperformed VGG-19 and ResNet-50 in intra- and inter-dataset evaluations.", "conclusion": "Swin Transformer is effective for CGI detection, offering robustness and domain generalization for digital image forensics."}}
{"id": "2505.16227", "pdf": "https://arxiv.org/pdf/2505.16227", "abs": "https://arxiv.org/abs/2505.16227", "authors": ["Bohao Wu", "Qingyun Wang", "Yue Guo"], "title": "Explain Less, Understand More: Jargon Detection via Personalized Parameter-Efficient Fine-tuning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Personalizing jargon detection and explanation is essential for making\ntechnical documents accessible to readers with diverse disciplinary\nbackgrounds. However, tailoring models to individual users typically requires\nsubstantial annotation efforts and computational resources due to user-specific\nfinetuning. To address this, we present a systematic study of personalized\njargon detection, focusing on methods that are both efficient and scalable for\nreal-world deployment. We explore two personalization strategies: (1)\nlightweight fine-tuning using Low-Rank Adaptation (LoRA) on open-source models,\nand (2) personalized prompting, which tailors model behavior at inference time\nwithout retaining. To reflect realistic constraints, we also investigate hybrid\napproaches that combine limited annotated data with unsupervised user\nbackground signals. Our personalized LoRA model outperforms GPT-4 by 21.4% in\nF1 score and exceeds the best performing oracle baseline by 8.3%. Remarkably,\nour method achieves comparable performance using only 10% of the annotated\ntraining data, demonstrating its practicality for resource-constrained\nsettings. Our study offers the first work to systematically explore efficient,\nlow-resource personalization of jargon detection using open-source language\nmodels, offering a practical path toward scalable, user-adaptive NLP system.", "AI": {"tldr": "The paper explores efficient and scalable methods for personalized jargon detection, comparing lightweight fine-tuning (LoRA) and personalized prompting, achieving superior performance with minimal annotated data.", "motivation": "To make technical documents accessible to diverse readers without requiring extensive annotation or computational resources.", "method": "Two strategies: (1) LoRA-based lightweight fine-tuning, and (2) personalized prompting. Hybrid approaches combining limited data with user signals are also tested.", "result": "Personalized LoRA outperforms GPT-4 by 21.4% in F1 score and exceeds baselines by 8.3%, using only 10% of annotated data.", "conclusion": "The study provides a scalable, low-resource solution for personalized jargon detection, advancing user-adaptive NLP systems."}}
{"id": "2505.16686", "pdf": "https://arxiv.org/pdf/2505.16686", "abs": "https://arxiv.org/abs/2505.16686", "authors": ["Lars Benedikt Kaesberg", "Jan Philip Wahle", "Terry Ruas", "Bela Gipp"], "title": "SPaRC: A Spatial Pathfinding Reasoning Challenge", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Existing reasoning datasets saturate and fail to test abstract, multi-step\nproblems, especially pathfinding and complex rule constraint satisfaction. We\nintroduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000\n2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning,\nrequiring step-by-step planning with arithmetic and geometric rules. Humans\nachieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best\nreasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles).\nModels often generate invalid paths (>50% of puzzles for o4-mini), and\nreasoning tokens reveal they make errors in navigation and spatial logic.\nUnlike humans, who take longer on hard puzzles, models fail to scale test-time\ncompute with difficulty. Allowing models to make multiple solution attempts\nimproves accuracy, suggesting potential for better spatial reasoning with\nimproved training and efficient test-time scaling methods. SPaRC can be used as\na window into models' spatial reasoning limitations and drive research toward\nnew methods that excel in abstract, multi-step problem-solving.", "AI": {"tldr": "SPaRC is a 2D grid pathfinding dataset testing spatial and symbolic reasoning. Humans excel, while models like o4-mini struggle, especially on hard puzzles. Models often fail in navigation and spatial logic, but multiple attempts improve accuracy, hinting at potential for better training.", "motivation": "Existing datasets lack abstract, multi-step reasoning challenges like pathfinding and rule constraint satisfaction, limiting evaluation of spatial and symbolic reasoning.", "method": "SPaRC introduces 1,000 2D grid pathfinding puzzles requiring step-by-step planning with arithmetic and geometric rules. Human and model performance (e.g., o4-mini) are compared.", "result": "Humans achieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while models struggle (15.8%; 1.1% on hard puzzles), often generating invalid paths. Models fail to scale compute with difficulty.", "conclusion": "SPaRC highlights models' spatial reasoning limitations and suggests potential improvements through better training and test-time scaling. It aims to drive research in abstract, multi-step problem-solving."}}
{"id": "2505.16291", "pdf": "https://arxiv.org/pdf/2505.16291", "abs": "https://arxiv.org/abs/2505.16291", "authors": ["Ronen Gradwohl", "Eilam Shapira", "Moshe Tennenholtz"], "title": "Fairness under Competition", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "Algorithmic fairness has emerged as a central issue in ML, and it has become\nstandard practice to adjust ML algorithms so that they will satisfy fairness\nrequirements such as Equal Opportunity. In this paper we consider the effects\nof adopting such fair classifiers on the overall level of ecosystem fairness.\nSpecifically, we introduce the study of fairness with competing firms, and\ndemonstrate the failure of fair classifiers in yielding fair ecosystems. Our\nresults quantify the loss of fairness in systems, under a variety of\nconditions, based on classifiers' correlation and the level of their data\noverlap. We show that even if competing classifiers are individually fair, the\necosystem's outcome may be unfair; and that adjusting biased algorithms to\nimprove their individual fairness may lead to an overall decline in ecosystem\nfairness. In addition to these theoretical results, we also provide supporting\nexperimental evidence. Together, our model and results provide a novel and\nessential call for action.", "AI": {"tldr": "Fair classifiers may fail to ensure ecosystem fairness, as competing firms' use of individually fair classifiers can lead to unfair outcomes overall.", "motivation": "To examine the impact of fair classifiers on ecosystem fairness, especially in competitive environments.", "method": "Introduces a model to study fairness with competing firms, analyzing classifiers' correlation and data overlap. Theoretical and experimental approaches are used.", "result": "Individually fair classifiers can result in unfair ecosystem outcomes. Improving individual fairness may reduce overall ecosystem fairness.", "conclusion": "Highlights the need for systemic fairness approaches beyond individual classifier adjustments."}}
{"id": "2505.16264", "pdf": "https://arxiv.org/pdf/2505.16264", "abs": "https://arxiv.org/abs/2505.16264", "authors": ["Sebastian Janampa", "Marios Pattichis"], "title": "LINEA: Fast and Accurate Line Detection Using Scalable Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Line detection is a basic digital image processing operation used by\nhigher-level processing methods. Recently, transformer-based methods for line\ndetection have proven to be more accurate than methods based on CNNs, at the\nexpense of significantly lower inference speeds. As a result, video analysis\nmethods that require low latencies cannot benefit from current\ntransformer-based methods for line detection. In addition, current\ntransformer-based models require pretraining attention mechanisms on large\ndatasets (e.g., COCO or Object360). This paper develops a new transformer-based\nmethod that is significantly faster without requiring pretraining the attention\nmechanism on large datasets. We eliminate the need to pre-train the attention\nmechanism using a new mechanism, Deformable Line Attention (DLA). We use the\nterm LINEA to refer to our new transformer-based method based on DLA. Extensive\nexperiments show that LINEA is significantly faster and outperforms previous\nmodels on sAP in out-of-distribution dataset testing.", "AI": {"tldr": "A new transformer-based method, LINEA, is introduced for faster and more efficient line detection without requiring pretraining on large datasets.", "motivation": "Current transformer-based line detection methods are slow and require pretraining on large datasets, limiting their use in low-latency applications.", "method": "Develops LINEA using Deformable Line Attention (DLA) to eliminate the need for pretraining and improve speed.", "result": "LINEA is significantly faster and outperforms previous models in out-of-distribution testing.", "conclusion": "LINEA offers a practical solution for efficient line detection without pretraining constraints."}}
{"id": "2505.16232", "pdf": "https://arxiv.org/pdf/2505.16232", "abs": "https://arxiv.org/abs/2505.16232", "authors": ["Ali Sarosh Bangash", "Krish Veera", "Ishfat Abrar Islam", "Raiyan Abdul Baten"], "title": "MuseRAG: Idea Originality Scoring At Scale", "categories": ["cs.CL"], "comment": null, "summary": "An objective, face-valid way to assess the originality of creative ideas is\nto measure how rare each idea is within a population -- an approach long used\nin creativity research but difficult to automate at scale. Tabulating response\nfrequencies via manual bucketing of idea rephrasings is labor-intensive,\nerror-prone, and brittle under large corpora. We introduce a fully automated,\npsychometrically validated pipeline for frequency-based originality scoring.\nOur method, MuseRAG, combines large language models (LLMs) with an externally\norchestrated retrieval-augmented generation (RAG) framework. Given a new idea,\nthe system retrieves semantically similar prior idea buckets and zero-shot\nprompts the LLM to judge whether the new idea belongs to an existing bucket or\nforms a new one. The resulting buckets enable computation of frequency-based\noriginality metrics. Across five datasets (N=1143, n_ideas=16294), MuseRAG\nmatches human annotators in idea clustering structure and resolution (AMI =\n0.59) and in participant-level scoring (r = 0.89) -- while exhibiting strong\nconvergent and external validity. Our work enables intent-sensitive,\nhuman-aligned originality scoring at scale to aid creativity research.", "AI": {"tldr": "MuseRAG automates originality scoring of creative ideas using LLMs and RAG, matching human accuracy and enabling scalable creativity research.", "motivation": "Manual originality scoring is labor-intensive and error-prone; automation is needed for large-scale creativity research.", "method": "Uses LLMs with RAG to retrieve and cluster ideas, then computes frequency-based originality metrics.", "result": "Matches human annotators in clustering (AMI=0.59) and scoring (r=0.89), with strong validity.", "conclusion": "MuseRAG enables scalable, human-aligned originality scoring for creativity research."}}
{"id": "2505.16700", "pdf": "https://arxiv.org/pdf/2505.16700", "abs": "https://arxiv.org/abs/2505.16700", "authors": ["Xuanqi Gao", "Siyi Xie", "Juan Zhai", "Shqing Ma", "Chao Shen"], "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) evolve from passive text generators to active\nreasoning agents capable of tool interaction, the Model Context Protocol (MCP)\nhas emerged as a standardized framework for dynamic tool discovery and\norchestration. Despite widespread industry adoption, existing evaluation\nmethodologies fail to adequately assess tool utilization capabilities within\nthis new paradigm. This paper introduces MCP-RADAR, the first comprehensive\nbenchmark specifically designed to evaluate LLM performance in the MCP\nframework through a novel five-dimensional approach measuring: answer accuracy,\ntool selection efficiency, computational resource efficiency, parameter\nconstruction accuracy, and execution speed. Unlike conventional benchmarks that\nrely on subjective human evaluations or binary success metrics, MCP-RADAR\nemploys objective, quantifiable measurements across multiple task domains\nincluding software engineering, mathematical reasoning, and general\nproblem-solving. Our evaluations of leading commercial and open-source LLMs\nreveal distinctive capability profiles with significant trade-offs between\naccuracy, efficiency, and speed, challenging traditional single-metric\nperformance rankings. Besides, we provide valuable guidance for developers to\noptimize their tools for maximum model compatibility and effectiveness. While\nfocused on MCP due to its standardized approach, our methodology remains\napplicable across all LLM agent tool integration frameworks, providing valuable\ninsights for both LLM developers and tool creators to optimize the entire\nLLM-tool interaction ecosystem. The implementation, configurations, and\ndatasets used in our evaluation are publicly available at\nhttps://anonymous.4open.science/r/MCPRadar-B143.", "AI": {"tldr": "MCP-RADAR is a benchmark for evaluating LLMs in the MCP framework, focusing on five dimensions: accuracy, tool selection, resource efficiency, parameter accuracy, and speed. It reveals trade-offs in performance and offers guidance for optimizing tool compatibility.", "motivation": "Existing evaluation methods fail to assess LLM tool utilization in the MCP framework, necessitating a comprehensive benchmark like MCP-RADAR.", "method": "MCP-RADAR uses a five-dimensional approach to objectively measure LLM performance across tasks like software engineering and problem-solving.", "result": "Evaluations show trade-offs between accuracy, efficiency, and speed among LLMs, challenging single-metric rankings.", "conclusion": "MCP-RADAR provides insights for optimizing LLM-tool interactions, applicable beyond MCP to other frameworks."}}
{"id": "2505.16305", "pdf": "https://arxiv.org/pdf/2505.16305", "abs": "https://arxiv.org/abs/2505.16305", "authors": ["Bingyang Cheng", "Zhongtao Chen", "Yichen Jin", "Hao Zhang", "Chen Zhang", "Edmud Y. Lam", "Yik-Chung Wu"], "title": "Large-Scale Bayesian Tensor Reconstruction: An Approximate Message Passing Solution", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Tensor CANDECOMP/PARAFAC decomposition (CPD) is a fundamental model for\ntensor reconstruction. Although the Bayesian framework allows for principled\nuncertainty quantification and automatic hyperparameter learning, existing\nmethods do not scale well for large tensors because of high-dimensional matrix\ninversions. To this end, we introduce CP-GAMP, a scalable Bayesian CPD\nalgorithm. This algorithm leverages generalized approximate message passing\n(GAMP) to avoid matrix inversions and incorporates an expectation-maximization\nroutine to jointly infer the tensor rank and noise power. Through multiple\nexperiments, for synthetic 100x100x100 rank 20 tensors with only 20% elements\nobserved, the proposed algorithm reduces runtime by 82.7% compared to the\nstate-of-the-art variational Bayesian CPD method, while maintaining comparable\nreconstruction accuracy.", "AI": {"tldr": "CP-GAMP is a scalable Bayesian CPD algorithm that avoids matrix inversions and jointly infers tensor rank and noise power, reducing runtime by 82.7% while maintaining accuracy.", "motivation": "Existing Bayesian CPD methods are inefficient for large tensors due to high-dimensional matrix inversions.", "method": "CP-GAMP leverages GAMP to avoid matrix inversions and uses EM to infer tensor rank and noise power.", "result": "For synthetic 100x100x100 rank 20 tensors with 20% observed elements, runtime is reduced by 82.7% with comparable accuracy.", "conclusion": "CP-GAMP is a scalable and efficient Bayesian CPD method for large tensors."}}
{"id": "2505.16278", "pdf": "https://arxiv.org/pdf/2505.16278", "abs": "https://arxiv.org/abs/2505.16278", "authors": ["Zhenjie Yang", "Yilin Chai", "Xiaosong Jia", "Qifeng Li", "Yuqian Shao", "Xuekai Zhu", "Haisheng Su", "Junchi Yan"], "title": "DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Project Page: https://thinklab-sjtu.github.io/DriveMoE/", "summary": "End-to-end autonomous driving (E2E-AD) demands effective processing of\nmulti-view sensory data and robust handling of diverse and complex driving\nscenarios, particularly rare maneuvers such as aggressive turns. Recent success\nof Mixture-of-Experts (MoE) architecture in Large Language Models (LLMs)\ndemonstrates that specialization of parameters enables strong scalability. In\nthis work, we propose DriveMoE, a novel MoE-based E2E-AD framework, with a\nScene-Specialized Vision MoE and a Skill-Specialized Action MoE. DriveMoE is\nbuilt upon our $\\pi_0$ Vision-Language-Action (VLA) baseline (originally from\nthe embodied AI field), called Drive-$\\pi_0$. Specifically, we add Vision MoE\nto Drive-$\\pi_0$ by training a router to select relevant cameras according to\nthe driving context dynamically. This design mirrors human driving cognition,\nwhere drivers selectively attend to crucial visual cues rather than\nexhaustively processing all visual information. In addition, we add Action MoE\nby training another router to activate specialized expert modules for different\ndriving behaviors. Through explicit behavioral specialization, DriveMoE is able\nto handle diverse scenarios without suffering from modes averaging like\nexisting models. In Bench2Drive closed-loop evaluation experiments, DriveMoE\nachieves state-of-the-art (SOTA) performance, demonstrating the effectiveness\nof combining vision and action MoE in autonomous driving tasks. We will release\nour code and models of DriveMoE and Drive-$\\pi_0$.", "AI": {"tldr": "DriveMoE introduces a Mixture-of-Experts (MoE) framework for autonomous driving, combining Scene-Specialized Vision MoE and Skill-Specialized Action MoE to handle diverse scenarios effectively.", "motivation": "Addressing the challenge of processing multi-view sensory data and handling rare maneuvers in autonomous driving by leveraging MoE architecture for specialization.", "method": "Proposes DriveMoE, built on Drive-\u03c00, with Vision MoE for dynamic camera selection and Action MoE for activating expert modules based on driving behaviors.", "result": "Achieves state-of-the-art performance in Bench2Drive closed-loop evaluation, demonstrating effectiveness.", "conclusion": "DriveMoE successfully combines vision and action MoE for robust autonomous driving, with plans to release code and models."}}
{"id": "2505.16234", "pdf": "https://arxiv.org/pdf/2505.16234", "abs": "https://arxiv.org/abs/2505.16234", "authors": ["Wei Zhang", "Zhenhong Zhou", "Junfeng Fang", "Rongwu Xu", "Kun Wang", "Yuanhe Zhang", "Rui Wang", "Ge Zhang", "Xinfeng Li", "Li Sun", "Lingjuan Lyu", "Yang Liu", "Sen Su"], "title": "LIFEBench: Evaluating Length Instruction Following in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "81 pages, 22 tables, 32 figures. Homepage:\n  https://ydyjya.github.io/LIFEBench/", "summary": "While large language models (LLMs) can solve PhD-level reasoning problems\nover long context inputs, they still struggle with a seemingly simpler task:\nfollowing explicit length instructions-e.g., write a 10,000-word novel.\nAdditionally, models often generate far too short outputs, terminate\nprematurely, or even refuse the request. Existing benchmarks focus primarily on\nevaluating generations quality, but often overlook whether the generations meet\nlength constraints. To this end, we introduce Length Instruction Following\nEvaluation Benchmark (LIFEBench) to comprehensively evaluate LLMs' ability to\nfollow length instructions across diverse tasks and a wide range of specified\nlengths. LIFEBench consists of 10,800 instances across 4 task categories in\nboth English and Chinese, covering length constraints ranging from 16 to 8192\nwords. We evaluate 26 widely-used LLMs and find that most models reasonably\nfollow short-length instructions but deteriorate sharply beyond a certain\nthreshold. Surprisingly, almost all models fail to reach the vendor-claimed\nmaximum output lengths in practice, as further confirmed by our evaluations\nextending up to 32K words. Even long-context LLMs, despite their extended\ninput-output windows, counterintuitively fail to improve length-instructions\nfollowing. Notably, Reasoning LLMs outperform even specialized long-text\ngeneration models, achieving state-of-the-art length following. Overall,\nLIFEBench uncovers fundamental limitations in current LLMs' length instructions\nfollowing ability, offering critical insights for future progress.", "AI": {"tldr": "LIFEBench evaluates LLMs' ability to follow length instructions, revealing their limitations despite advanced reasoning capabilities.", "motivation": "LLMs struggle with explicit length instructions, prompting the need for a benchmark to assess this overlooked aspect.", "method": "LIFEBench includes 10,800 instances across 4 tasks in English and Chinese, testing lengths from 16 to 8192 words.", "result": "Most LLMs perform well with short lengths but fail beyond a threshold, often not reaching vendor-claimed maximums. Reasoning LLMs outperform specialized models.", "conclusion": "LIFEBench highlights critical limitations in LLMs' length instruction following, guiding future improvements."}}
{"id": "2505.16771", "pdf": "https://arxiv.org/pdf/2505.16771", "abs": "https://arxiv.org/abs/2505.16771", "authors": ["Beyazit Bestami Yuksel", "Ayse Yilmazer Metin"], "title": "Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review", "categories": ["cs.AI"], "comment": "10 pages, 6 figures, 3 tables", "summary": "This paper presents a comprehensive synthesis of major breakthroughs in\nartificial intelligence (AI) over the past fifteen years, integrating\nhistorical, theoretical, and technological perspectives. It identifies key\ninflection points in AI' s evolution by tracing the convergence of\ncomputational resources, data access, and algorithmic innovation. The analysis\nhighlights how researchers enabled GPU based model training, triggered a data\ncentric shift with ImageNet, simplified architectures through the Transformer,\nand expanded modeling capabilities with the GPT series. Rather than treating\nthese advances as isolated milestones, the paper frames them as indicators of\ndeeper paradigm shifts. By applying concepts from statistical learning theory\nsuch as sample complexity and data efficiency, the paper explains how\nresearchers translated breakthroughs into scalable solutions and why the field\nmust now embrace data centric approaches. In response to rising privacy\nconcerns and tightening regulations, the paper evaluates emerging solutions\nlike federated learning, privacy enhancing technologies (PETs), and the data\nsite paradigm, which reframe data access and security. In cases where real\nworld data remains inaccessible, the paper also assesses the utility and\nconstraints of mock and synthetic data generation. By aligning technical\ninsights with evolving data infrastructure, this study offers strategic\nguidance for future AI research and policy development.", "AI": {"tldr": "A synthesis of AI breakthroughs over 15 years, highlighting key inflection points like GPU training, ImageNet, Transformers, and GPT, framed as paradigm shifts. Discusses data-centric approaches, privacy solutions, and synthetic data, offering guidance for future AI research and policy.", "motivation": "To integrate historical, theoretical, and technological perspectives of AI advancements and identify deeper paradigm shifts, while addressing modern challenges like privacy and data access.", "method": "Analyzes key inflection points (GPU training, ImageNet, Transformers, GPT) using statistical learning theory, evaluates privacy solutions (federated learning, PETs), and assesses synthetic data utility.", "result": "Identifies paradigm shifts in AI, explains scalability of breakthroughs, and evaluates emerging solutions for privacy and data constraints.", "conclusion": "Provides strategic guidance for future AI research and policy by aligning technical insights with evolving data infrastructure and addressing modern challenges."}}
{"id": "2505.16308", "pdf": "https://arxiv.org/pdf/2505.16308", "abs": "https://arxiv.org/abs/2505.16308", "authors": ["Xingyu Zhang", "Wenwen Qiang", "Siyu Zhao", "Huijie Guo", "Jiangmeng Li", "Chuxiong Sun", "Changwen Zheng"], "title": "CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Most existing multivariate time series forecasting methods adopt an\nall-to-all paradigm that feeds all variable histories into a unified model to\npredict their future values without distinguishing their individual roles.\nHowever, this undifferentiated paradigm makes it difficult to identify\nvariable-specific causal influences and often entangles causally relevant\ninformation with spurious correlations. To address this limitation, we propose\nan all-to-one forecasting paradigm that predicts each target variable\nseparately. Specifically, we first construct a Structural Causal Model from\nobservational data and then, for each target variable, we partition the\nhistorical sequence into four sub-segments according to the inferred causal\nstructure: endogenous, direct causal, collider causal, and spurious\ncorrelation. The prediction relies solely on the first three causally relevant\nsub-segments, while the spurious correlation sub-segment is excluded.\nFurthermore, we propose Causal Informed Transformer (CAIFormer), a novel\nforecasting model comprising three components: Endogenous Sub-segment\nPrediction Block, Direct Causal Sub-segment Prediction Block, and Collider\nCausal Sub-segment Prediction Block, which process the endogenous, direct\ncausal, and collider causal sub-segments, respectively. Their outputs are then\ncombined to produce the final prediction. Extensive experiments on multiple\nbenchmark datasets demonstrate the effectiveness of the CAIFormer.", "AI": {"tldr": "The paper proposes an all-to-one forecasting paradigm for multivariate time series, using causal structure to partition data and exclude spurious correlations, introducing the CAIFormer model for improved predictions.", "motivation": "Existing methods treat all variables uniformly, obscuring causal relationships and mixing relevant information with spurious correlations.", "method": "Constructs a Structural Causal Model, partitions data into causally relevant sub-segments, and uses the CAIFormer model to process these segments for prediction.", "result": "CAIFormer outperforms benchmarks, demonstrating effectiveness in distinguishing causal influences.", "conclusion": "The all-to-one paradigm and CAIFormer enhance forecasting by focusing on causally relevant data, improving accuracy and interpretability."}}
{"id": "2505.16282", "pdf": "https://arxiv.org/pdf/2505.16282", "abs": "https://arxiv.org/abs/2505.16282", "authors": ["Fanbin Lu", "Zhisheng Zhong", "Shu Liu", "Chi-Wing Fu", "Jiaya Jia"], "title": "ARPO:End-to-End Policy Optimization for GUI Agents with Experience Replay", "categories": ["cs.CV"], "comment": null, "summary": "Training large language models (LLMs) as interactive agents for controlling\ngraphical user interfaces (GUIs) presents a unique challenge to optimize\nlong-horizon action sequences with multimodal feedback from complex\nenvironments. While recent works have advanced multi-turn reinforcement\nlearning (RL) for reasoning and tool-using capabilities in LLMs, their\napplication to GUI-based agents remains relatively underexplored due to the\ndifficulty of sparse rewards, delayed feedback, and high rollout costs. In this\npaper, we investigate end-to-end policy optimization for vision-language-based\nGUI agents with the aim of improving performance on complex, long-horizon\ncomputer tasks. We propose Agentic Replay Policy Optimization (ARPO), an\nend-to-end RL approach that augments Group Relative Policy Optimization (GRPO)\nwith a replay buffer to reuse the successful experience across training\niterations. To further stabilize the training process, we propose a task\nselection strategy that filters tasks based on baseline agent performance,\nallowing the agent to focus on learning from informative interactions.\nAdditionally, we compare ARPO with offline preference optimization approaches,\nhighlighting the advantages of policy-based methods in GUI environments.\nExperiments on the OSWorld benchmark demonstrate that ARPO achieves competitive\nresults, establishing a new performance baseline for LLM-based GUI agents\ntrained via reinforcement learning. Our findings underscore the effectiveness\nof reinforcement learning for training multi-turn, vision-language GUI agents\ncapable of managing complex real-world UI interactions. Codes and\nmodels:https://github.com/dvlab-research/ARPO.git.", "AI": {"tldr": "ARPO is an RL method for training GUI agents, improving performance on complex tasks by reusing successful experiences and filtering tasks based on baseline performance.", "motivation": "Optimizing long-horizon action sequences for GUI agents is challenging due to sparse rewards and delayed feedback.", "method": "Proposes ARPO, an RL approach combining GRPO with a replay buffer and task selection strategy.", "result": "ARPO achieves competitive results on the OSWorld benchmark, setting a new baseline for GUI agents.", "conclusion": "Reinforcement learning is effective for training multi-turn, vision-language GUI agents."}}
{"id": "2505.16237", "pdf": "https://arxiv.org/pdf/2505.16237", "abs": "https://arxiv.org/abs/2505.16237", "authors": ["Derong Xu", "Pengyue Jia", "Xiaopeng Li", "Yingyi Zhang", "Maolin Wang", "Qidong Liu", "Xiangyu Zhao", "Yichao Wang", "Huifeng Guo", "Ruiming Tang", "Enhong Chen", "Tong Xu"], "title": "Align-GRAG: Reasoning-Guided Dual Alignment for Graph Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities, but\nstill struggle with issues like hallucinations and outdated information.\nRetrieval-augmented generation (RAG) addresses these issues by grounding LLM\noutputs in external knowledge with an Information Retrieval (IR) system.\nBuilding on this foundation, graph-based RAG systems go a step further by\nretrieving subgraphs, which preserve the relationships between knowledge\nentities and provide more comprehensive context. However, graph RAG faces two\nchallenges: (1) Retrieving relevant information introduces irrelevant nodes\n(especially in dense graph databases, where retrieval usually extends to\nadjacent nodes), and leads to overly lengthy inputs that hinder efficiency; (2)\nThe representation gap between graph and language during generation with LLMs\nlimits the ability to fully leverage graph structures for enhanced\nunderstanding. To address these limitations, we propose Align-GRAG, a novel\nreasoning-guided dual alignment framework in post-retrieval phrase. It first\nformulates a subgraph by retrieving nodes and edges. Then an Aligner is\nproposed to jointly optimizes a graph encoder with LLM-summarized reasoning. It\nachieves dual alignment of graph node and representation by leveraging KL\ndivergence loss and contrastive loss, facilitating efficient pruning of\nirrelevant knowledge and establishing a unified semantic space. The Generator\nintegrates the aligned graph data with LLM to produce coherent and accurate\nanswers. Experiments on GraphQA benchmark across three tasks (including common\nsense reasoning, scene graph understanding, and knowledge graph reasoning)\nvalidate the effectiveness of our method. The code will be available upon\naccepted.", "AI": {"tldr": "Align-GRAG improves graph-based RAG by addressing retrieval inefficiencies and representation gaps, using dual alignment for better accuracy and efficiency.", "motivation": "LLMs struggle with hallucinations and outdated info; graph RAG enhances context but faces retrieval and representation challenges.", "method": "Align-GRAG uses a reasoning-guided dual alignment framework to optimize graph retrieval and representation, integrating it with LLMs.", "result": "Experiments show effectiveness in tasks like common sense reasoning and knowledge graph reasoning.", "conclusion": "Align-GRAG successfully addresses graph RAG limitations, improving accuracy and efficiency in LLM outputs."}}
{"id": "2505.16781", "pdf": "https://arxiv.org/pdf/2505.16781", "abs": "https://arxiv.org/abs/2505.16781", "authors": ["Qianlei Jia", "Xinliang Zhou", "Ondrej Krejcar", "Enrique Herrera-Viedma"], "title": "Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making", "categories": ["cs.AI"], "comment": null, "summary": "In group decision-making (GDM) scenarios, uncertainty, dynamic social\nstructures, and vague information present major challenges for traditional\nopinion dynamics models. To address these issues, this study proposes a novel\nsocial network group decision-making (SNGDM) framework that integrates\nthree-way decision (3WD) theory, dynamic network reconstruction, and linguistic\nopinion representation. First, the 3WD mechanism is introduced to explicitly\nmodel hesitation and ambiguity in agent judgments, thereby preventing\nirrational decisions. Second, a connection adjustment rule based on opinion\nsimilarity is developed, enabling agents to adaptively update their\ncommunication links and better reflect the evolving nature of social\nrelationships. Third, linguistic terms are used to describe agent opinions,\nallowing the model to handle subjective, vague, or incomplete information more\neffectively. Finally, an integrated multi-agent decision-making framework is\nconstructed, which simultaneously considers individual uncertainty, opinion\nevolution, and network dynamics. The proposed model is applied to a multi-UAV\ncooperative decision-making scenario, where simulation results and consensus\nanalysis demonstrate its effectiveness. Experimental comparisons further verify\nthe advantages of the algorithm in enhancing system stability and representing\nrealistic decision-making behaviors.", "AI": {"tldr": "A novel SNGDM framework integrates 3WD theory, dynamic network reconstruction, and linguistic opinion representation to address uncertainty and dynamic social structures in GDM.", "motivation": "Traditional opinion dynamics models struggle with uncertainty, dynamic social structures, and vague information in GDM.", "method": "The framework uses 3WD for hesitation modeling, opinion similarity-based connection adjustment, and linguistic terms for opinion representation.", "result": "Simulations in multi-UAV scenarios show improved stability and realistic decision-making behaviors.", "conclusion": "The proposed model effectively handles uncertainty and dynamic social relationships, enhancing decision-making in complex scenarios."}}
{"id": "2505.16319", "pdf": "https://arxiv.org/pdf/2505.16319", "abs": "https://arxiv.org/abs/2505.16319", "authors": ["Yangyang Wang", "Jiawei Gu", "Li Long", "Xin Li", "Li Shen", "Zhouyu Fu", "Xiangjun Zhou", "Xu Jiang"], "title": "FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent Demand Recovery and Forecasting in Fresh Retail", "categories": ["cs.LG"], "comment": "10 pages, 5 figures", "summary": "Accurate demand estimation is critical for the retail business in guiding the\ninventory and pricing policies of perishable products. However, it faces\nfundamental challenges from censored sales data during stockouts, where\nunobserved demand creates systemic policy biases. Existing datasets lack the\ntemporal resolution and annotations needed to address this censoring effect. To\nfill this gap, we present FreshRetailNet-50K, the first large-scale benchmark\nfor censored demand estimation. It comprises 50,000 store-product time series\nof detailed hourly sales data from 898 stores in 18 major cities, encompassing\n863 perishable SKUs meticulously annotated for stockout events. The hourly\nstock status records unique to this dataset, combined with rich contextual\ncovariates, including promotional discounts, precipitation, and temporal\nfeatures, enable innovative research beyond existing solutions. We demonstrate\none such use case of two-stage demand modeling: first, we reconstruct the\nlatent demand during stockouts using precise hourly annotations. We then\nleverage the recovered demand to train robust demand forecasting models in the\nsecond stage. Experimental results show that this approach achieves a 2.73\\%\nimprovement in prediction accuracy while reducing the systematic demand\nunderestimation from 7.37\\% to near-zero bias. With unprecedented temporal\ngranularity and comprehensive real-world information, FreshRetailNet-50K opens\nnew research directions in demand imputation, perishable inventory\noptimization, and causal retail analytics. The unique annotation quality and\nscale of the dataset address long-standing limitations in retail AI, providing\nimmediate solutions and a platform for future methodological innovation. The\ndata (https://huggingface.co/datasets/Dingdong-Inc/FreshRetailNet-50K) and code\n(https://github.com/Dingdong-Inc/frn-50k-baseline}) are openly released.", "AI": {"tldr": "FreshRetailNet-50K is a large-scale benchmark for censored demand estimation, offering hourly sales data and stockout annotations to improve demand forecasting accuracy.", "motivation": "Addressing the challenge of censored sales data during stockouts, which biases demand estimation and affects inventory/pricing policies.", "method": "Introduces FreshRetailNet-50K, a dataset with 50,000 store-product time series, and proposes a two-stage demand modeling approach: demand reconstruction during stockouts followed by robust forecasting.", "result": "Achieves a 2.73% improvement in prediction accuracy and reduces systematic demand underestimation from 7.37% to near-zero bias.", "conclusion": "FreshRetailNet-50K enables innovative research in demand imputation, inventory optimization, and retail analytics, with open data and code for broader use."}}
{"id": "2505.16283", "pdf": "https://arxiv.org/pdf/2505.16283", "abs": "https://arxiv.org/abs/2505.16283", "authors": ["Lijian Li", "Yuanpeng He", "Chi-Man Pun"], "title": "Efficient Prototype Consistency Learning in Medical Image Segmentation via Joint Uncertainty and Data Augmentation", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2404.10717", "summary": "Recently, prototype learning has emerged in semi-supervised medical image\nsegmentation and achieved remarkable performance. However, the scarcity of\nlabeled data limits the expressiveness of prototypes in previous methods,\npotentially hindering the complete representation of prototypes for class\nembedding. To overcome this issue, we propose an efficient prototype\nconsistency learning via joint uncertainty quantification and data augmentation\n(EPCL-JUDA) to enhance the semantic expression of prototypes based on the\nframework of Mean-Teacher. The concatenation of original and augmented labeled\ndata is fed into student network to generate expressive prototypes. Then, a\njoint uncertainty quantification method is devised to optimize pseudo-labels\nand generate reliable prototypes for original and augmented unlabeled data\nseparately. High-quality global prototypes for each class are formed by fusing\nlabeled and unlabeled prototypes, which are utilized to generate\nprototype-to-features to conduct consistency learning. Notably, a prototype\nnetwork is proposed to reduce high memory requirements brought by the\nintroduction of augmented data. Extensive experiments on Left Atrium,\nPancreas-NIH, Type B Aortic Dissection datasets demonstrate EPCL-JUDA's\nsuperiority over previous state-of-the-art approaches, confirming the\neffectiveness of our framework. The code will be released soon.", "AI": {"tldr": "EPCL-JUDA enhances prototype learning in semi-supervised medical image segmentation by combining uncertainty quantification and data augmentation, outperforming existing methods.", "motivation": "The scarcity of labeled data limits prototype expressiveness in medical image segmentation, necessitating a more robust method.", "method": "EPCL-JUDA uses joint uncertainty quantification and data augmentation within a Mean-Teacher framework to generate reliable prototypes from labeled and unlabeled data.", "result": "The method achieves superior performance on datasets like Left Atrium and Pancreas-NIH, demonstrating its effectiveness.", "conclusion": "EPCL-JUDA improves prototype learning and segmentation accuracy, with potential for broader medical imaging applications."}}
{"id": "2505.16241", "pdf": "https://arxiv.org/pdf/2505.16241", "abs": "https://arxiv.org/abs/2505.16241", "authors": ["Viet-Anh Nguyen", "Shiqian Zhao", "Gia Dao", "Runyi Hu", "Yi Xie", "Luu Anh Tuan"], "title": "Three Minds, One Legend: Jailbreak Large Reasoning Model with Adaptive Stacked Ciphers", "categories": ["cs.CL"], "comment": null, "summary": "Recently, Large Reasoning Models (LRMs) have demonstrated superior logical\ncapabilities compared to traditional Large Language Models (LLMs), gaining\nsignificant attention. Despite their impressive performance, the potential for\nstronger reasoning abilities to introduce more severe security vulnerabilities\nremains largely underexplored. Existing jailbreak methods often struggle to\nbalance effectiveness with robustness against adaptive safety mechanisms. In\nthis work, we propose SEAL, a novel jailbreak attack that targets LRMs through\nan adaptive encryption pipeline designed to override their reasoning processes\nand evade potential adaptive alignment. Specifically, SEAL introduces a stacked\nencryption approach that combines multiple ciphers to overwhelm the models\nreasoning capabilities, effectively bypassing built-in safety mechanisms. To\nfurther prevent LRMs from developing countermeasures, we incorporate two\ndynamic strategies - random and adaptive - that adjust the cipher length,\norder, and combination. Extensive experiments on real-world reasoning models,\nincluding DeepSeek-R1, Claude Sonnet, and OpenAI GPT-o4, validate the\neffectiveness of our approach. Notably, SEAL achieves an attack success rate of\n80.8% on GPT o4-mini, outperforming state-of-the-art baselines by a significant\nmargin of 27.2%. Warning: This paper contains examples of inappropriate,\noffensive, and harmful content.", "AI": {"tldr": "SEAL is a novel jailbreak attack targeting Large Reasoning Models (LRMs) using adaptive encryption to bypass safety mechanisms, achieving an 80.8% success rate on GPT o4-mini.", "motivation": "LRMs show superior reasoning but may introduce severe security vulnerabilities, which are underexplored. Existing jailbreak methods lack balance between effectiveness and robustness.", "method": "SEAL employs a stacked encryption approach with dynamic strategies (random and adaptive) to overwhelm LRMs' reasoning and evade safety mechanisms.", "result": "SEAL achieves an 80.8% attack success rate on GPT o4-mini, outperforming baselines by 27.2%.", "conclusion": "SEAL demonstrates significant effectiveness in bypassing LRM safety mechanisms, highlighting the need for stronger defenses against such attacks."}}
{"id": "2505.16787", "pdf": "https://arxiv.org/pdf/2505.16787", "abs": "https://arxiv.org/abs/2505.16787", "authors": ["Ashish Sundar", "Chunbo Luo", "Xiaoyang Wang"], "title": "Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce", "categories": ["cs.AI"], "comment": "9 pages without appendix, 15 Figures, preprint", "summary": "Model-based reinforcement learning (MBRL) offers an intuitive way to increase\nthe sample efficiency of model-free RL methods by simultaneously training a\nworld model that learns to predict the future. MBRL methods have progressed by\nlargely prioritising the actor; optimising the world model learning has been\nneglected meanwhile. Improving the fidelity of the world model and reducing its\ntime to convergence can yield significant downstream benefits, one of which is\nimproving the ensuing performance of any actor it may train. We propose a novel\napproach that anticipates and actively seeks out high-entropy states using\nshort-horizon latent predictions generated by the world model, offering a\nprincipled alternative to traditional curiosity-driven methods that chase\nonce-novel states well after they were stumbled into. While many model\npredictive control (MPC) based methods offer similar alternatives, they\ntypically lack commitment, synthesising multi step plans after every step. To\nmitigate this, we present a hierarchical planner that dynamically decides when\nto replan, planning horizon length, and the weighting between reward and\nentropy. While our method can theoretically be applied to any model that trains\nits own actors with solely model generated data, we have applied it to just\nDreamer as a proof of concept. Our method finishes the Miniworld procedurally\ngenerated mazes 50% faster than base Dreamer at convergence and the policy\ntrained in imagination converges in only 60% of the environment steps that base\nDreamer needs.", "AI": {"tldr": "The paper introduces a novel MBRL method that improves world model fidelity by actively seeking high-entropy states, outperforming base Dreamer in efficiency and convergence.", "motivation": "MBRL methods often neglect world model optimization, focusing on the actor. Improving the world model can enhance downstream performance.", "method": "Proposes a hierarchical planner that dynamically adjusts replanning, horizon length, and reward-entropy balance, using short-horizon latent predictions.", "result": "Achieves 50% faster maze completion and 60% fewer environment steps for policy convergence compared to base Dreamer.", "conclusion": "The method demonstrates the benefits of optimizing world model learning, offering a principled alternative to curiosity-driven approaches."}}
{"id": "2505.16322", "pdf": "https://arxiv.org/pdf/2505.16322", "abs": "https://arxiv.org/abs/2505.16322", "authors": ["Woosung Koh", "Wonbeen Oh", "Jaein Jang", "MinHyung Lee", "Hyeongjin Kim", "Ah Yeon Kim", "Joonkee Kim", "Junghyun Lee", "Taehyeon Kim", "Se-Young Yun"], "title": "AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Pre-print", "summary": "Self-Taught Reasoners (STaR), synonymously known as Rejection sampling\nFine-Tuning (RFT), is an integral part of the training pipeline of\nself-improving reasoning Language Models (LMs). The self-improving mechanism\noften employs random observation (data) sampling. However, this results in\ntrained observation imbalance; inefficiently over-training on solved examples\nwhile under-training on challenging ones. In response, we introduce Adaptive\nSTaR (AdaSTaR), a novel algorithm that rectifies this by integrating two\nadaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting\nbalanced training across observations, and (2) Adaptive Sampling for\nCurriculum: dynamically adjusting data difficulty to match the model's evolving\nstrength. Across six benchmarks, AdaSTaR achieves best test accuracy in all\ninstances (6/6) and reduces training FLOPs by an average of 58.6% against an\nextensive list of baselines. These improvements in performance and efficiency\ngeneralize to different pre-trained LMs and larger models, paving the way for\nmore efficient and effective self-improving LMs.", "AI": {"tldr": "AdaSTaR improves self-improving LMs by adaptive sampling for diversity and curriculum, achieving higher accuracy and efficiency.", "motivation": "Addressing trained observation imbalance in self-improving LMs caused by random sampling.", "method": "Introduces AdaSTaR with adaptive sampling for diversity and curriculum to balance training and adjust data difficulty dynamically.", "result": "Achieves best test accuracy in all benchmarks (6/6) and reduces training FLOPs by 58.6%.", "conclusion": "AdaSTaR enhances efficiency and effectiveness of self-improving LMs, generalizing across models."}}
{"id": "2505.16294", "pdf": "https://arxiv.org/pdf/2505.16294", "abs": "https://arxiv.org/abs/2505.16294", "authors": ["Yufei Yin", "Lechao Cheng", "Wengang Zhou", "Jiajun Deng", "Zhou Yu", "Houqiang Li"], "title": "Self-Classification Enhancement and Correction for Weakly Supervised Object Detection", "categories": ["cs.CV"], "comment": "Accepted by IJCAI 2025", "summary": "In recent years, weakly supervised object detection (WSOD) has attracted much\nattention due to its low labeling cost. The success of recent WSOD models is\noften ascribed to the two-stage multi-class classification (MCC) task, i.e.,\nmultiple instance learning and online classification refinement. Despite\nachieving non-trivial progresses, these methods overlook potential\nclassification ambiguities between these two MCC tasks and fail to leverage\ntheir unique strengths. In this work, we introduce a novel WSOD framework to\nameliorate these two issues. For one thing, we propose a self-classification\nenhancement module that integrates intra-class binary classification (ICBC) to\nbridge the gap between the two distinct MCC tasks. The ICBC task enhances the\nnetwork's discrimination between positive and mis-located samples in a\nclass-wise manner and forges a mutually reinforcing relationship with the MCC\ntask. For another, we propose a self-classification correction algorithm during\ninference, which combines the results of both MCC tasks to effectively reduce\nthe mis-classified predictions. Extensive experiments on the prevalent VOC 2007\n& 2012 datasets demonstrate the superior performance of our framework.", "AI": {"tldr": "A novel WSOD framework addresses classification ambiguities in weakly supervised object detection by integrating intra-class binary classification and a correction algorithm, improving performance on VOC datasets.", "motivation": "To reduce labeling costs and improve weakly supervised object detection by addressing overlooked classification ambiguities between multi-class classification tasks.", "method": "Proposes a self-classification enhancement module with intra-class binary classification and a self-classification correction algorithm during inference.", "result": "Demonstrates superior performance on VOC 2007 & 2012 datasets.", "conclusion": "The framework effectively bridges gaps between tasks and reduces mis-classifications, enhancing WSOD performance."}}
{"id": "2505.16245", "pdf": "https://arxiv.org/pdf/2505.16245", "abs": "https://arxiv.org/abs/2505.16245", "authors": ["Vijeta Deshpande", "Debasmita Ghose", "John D. Patterson", "Roger Beaty", "Anna Rumshisky"], "title": "Diverse, not Short: A Length-Controlled Self-Learning Framework for Improving Response Diversity of Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Diverse language model responses are crucial for creative generation,\nopen-ended tasks, and self-improvement training. We show that common diversity\nmetrics, and even reward models used for preference optimization,\nsystematically bias models toward shorter outputs, limiting expressiveness. To\naddress this, we introduce Diverse, not Short (Diverse-NS), a length-controlled\nself-learning framework that improves response diversity while maintaining\nlength parity. By generating and filtering preference data that balances\ndiversity, quality, and length, Diverse-NS enables effective training using\nonly 3,000 preference pairs. Applied to LLaMA-3.1-8B and the Olmo-2 family,\nDiverse-NS substantially enhances lexical and semantic diversity. We show\nconsistent improvement in diversity with minor reduction or gains in response\nquality on four creative generation tasks: Divergent Associations, Persona\nGeneration, Alternate Uses, and Creative Writing. Surprisingly, experiments\nwith the Olmo-2 model family (7B, and 13B) show that smaller models like\nOlmo-2-7B can serve as effective \"diversity teachers\" for larger models. By\nexplicitly addressing length bias, our method efficiently pushes models toward\nmore diverse and expressive outputs.", "AI": {"tldr": "Diverse-NS is a length-controlled self-learning framework that improves language model diversity without shortening outputs, using minimal preference data.", "motivation": "Common diversity metrics and reward models bias toward shorter outputs, limiting expressiveness.", "method": "Diverse-NS generates and filters preference data balancing diversity, quality, and length, training with only 3,000 pairs.", "result": "Applied to LLaMA-3.1-8B and Olmo-2 models, it enhances lexical and semantic diversity with minor quality trade-offs.", "conclusion": "Smaller models can teach diversity to larger ones, and addressing length bias leads to more expressive outputs."}}
{"id": "2505.16826", "pdf": "https://arxiv.org/pdf/2505.16826", "abs": "https://arxiv.org/abs/2505.16826", "authors": ["Wei Sun", "Wen Yang", "Pu Jian", "Qianlong Du", "Fuwei Cui", "Shuo Ren", "Jiajun Zhang"], "title": "KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances have demonstrated that integrating reinforcement learning\nwith rule-based rewards can significantly enhance the reasoning capabilities of\nlarge language models, even without supervised fine-tuning. However, prevalent\nreinforcement learning algorithms such as GRPO and its variants like DAPO,\nsuffer from a coarse granularity issue when computing the advantage.\nSpecifically, they compute rollout-level advantages that assign identical\nvalues to every token within a sequence, failing to capture token-specific\ncontributions and hindering effective learning. To address this limitation, we\npropose Key-token Advantage Estimation (KTAE) - a novel algorithm that\nestimates fine-grained, token-level advantages without introducing additional\nmodels. KTAE leverages the correctness of sampled rollouts and applies\nstatistical analysis to quantify the importance of individual tokens within a\nsequence to the final outcome. This quantified token-level importance is then\ncombined with the rollout-level advantage to obtain a more fine-grained\ntoken-level advantage estimation. Empirical results show that models trained\nwith GRPO+KTAE and DAPO+KTAE outperform baseline methods across five\nmathematical reasoning benchmarks. Notably, they achieve higher accuracy with\nshorter responses and even surpass R1-Distill-Qwen-1.5B using the same base\nmodel.", "AI": {"tldr": "Proposes Key-token Advantage Estimation (KTAE) to address coarse granularity in reinforcement learning for language models, improving token-level advantage estimation and outperforming baselines.", "motivation": "Existing reinforcement learning algorithms like GRPO and DAPO compute rollout-level advantages, missing token-specific contributions, which limits learning effectiveness.", "method": "Introduces KTAE, a novel algorithm that estimates token-level advantages using statistical analysis of rollout correctness, combining it with rollout-level advantages.", "result": "Models with GRPO+KTAE and DAPO+KTAE outperform baselines in mathematical reasoning benchmarks, achieving higher accuracy with shorter responses.", "conclusion": "KTAE enhances token-level advantage estimation, improving model performance without additional models, surpassing even larger models like R1-Distill-Qwen-1.5B."}}
{"id": "2505.16326", "pdf": "https://arxiv.org/pdf/2505.16326", "abs": "https://arxiv.org/abs/2505.16326", "authors": ["Qian Tan", "Dongzhan Zhou", "Peng Xia", "Wanhao Liu", "Wanli Ouyang", "Lei Bai", "Yuqiang Li", "Tianfan Fu"], "title": "ChemMLLM: Chemical Multimodal Large Language Model", "categories": ["cs.LG"], "comment": "25 pages", "summary": "Multimodal large language models (MLLMs) have made impressive progress in\nmany applications in recent years. However, chemical MLLMs that can handle\ncross-modal understanding and generation remain underexplored. To fill this\ngap, in this paper, we propose ChemMLLM, a unified chemical multimodal large\nlanguage model for molecule understanding and generation. Also, we design five\nmultimodal tasks across text, molecular SMILES strings, and image, and curate\nthe datasets. We benchmark ChemMLLM against a range of general leading MLLMs\nand Chemical LLMs on these tasks. Experimental results show that ChemMLLM\nachieves superior performance across all evaluated tasks. For example, in\nmolecule image optimization task, ChemMLLM outperforms the best baseline\n(GPT-4o) by 118.9\\% (4.27 vs 1.95 property improvement). The code is publicly\navailable at https://github.com/bbsbz/ChemMLLM.git.", "AI": {"tldr": "ChemMLLM is a multimodal large language model designed for chemical tasks, outperforming existing models in molecule understanding and generation.", "motivation": "Existing multimodal large language models (MLLMs) lack focus on chemical cross-modal tasks, prompting the development of ChemMLLM.", "method": "The authors propose ChemMLLM, a unified model for chemical tasks, and design five multimodal tasks involving text, SMILES strings, and images. Datasets are curated for benchmarking.", "result": "ChemMLLM outperforms leading MLLMs and chemical LLMs, achieving a 118.9% improvement over GPT-4o in molecule image optimization.", "conclusion": "ChemMLLM demonstrates superior performance in chemical multimodal tasks, filling a gap in the field."}}
{"id": "2505.16304", "pdf": "https://arxiv.org/pdf/2505.16304", "abs": "https://arxiv.org/abs/2505.16304", "authors": ["Guohao Huo", "Ruiting Dai", "Hao Tang"], "title": "SAMba-UNet: Synergizing SAM2 and Mamba in UNet with Heterogeneous Aggregation for Cardiac MRI Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "To address the challenge of complex pathological feature extraction in\nautomated cardiac MRI segmentation, this study proposes an innovative\ndual-encoder architecture named SAMba-UNet. The framework achieves cross-modal\nfeature collaborative learning by integrating the vision foundation model SAM2,\nthe state-space model Mamba, and the classical UNet. To mitigate domain\ndiscrepancies between medical and natural images, a Dynamic Feature Fusion\nRefiner is designed, which enhances small lesion feature extraction through\nmulti-scale pooling and a dual-path calibration mechanism across channel and\nspatial dimensions. Furthermore, a Heterogeneous Omni-Attention Convergence\nModule (HOACM) is introduced, combining global contextual attention with\nbranch-selective emphasis mechanisms to effectively fuse SAM2's local\npositional semantics and Mamba's long-range dependency modeling capabilities.\nExperiments on the ACDC cardiac MRI dataset demonstrate that the proposed model\nachieves a Dice coefficient of 0.9103 and an HD95 boundary error of 1.0859 mm,\nsignificantly outperforming existing methods, particularly in boundary\nlocalization for complex pathological structures such as right ventricular\nanomalies. This work provides an efficient and reliable solution for automated\ncardiac disease diagnosis, and the code will be open-sourced.", "AI": {"tldr": "The paper proposes SAMba-UNet, a dual-encoder architecture for cardiac MRI segmentation, integrating SAM2, Mamba, and UNet. It introduces Dynamic Feature Fusion Refiner and HOACM to enhance feature extraction and fusion, achieving superior performance on the ACDC dataset.", "motivation": "To address challenges in complex pathological feature extraction for automated cardiac MRI segmentation, particularly domain discrepancies and small lesion detection.", "method": "Proposes SAMba-UNet with Dynamic Feature Fusion Refiner and HOACM for cross-modal feature learning, multi-scale pooling, and attention-based fusion.", "result": "Achieves Dice coefficient of 0.9103 and HD95 boundary error of 1.0859 mm, outperforming existing methods, especially in boundary localization.", "conclusion": "SAMba-UNet provides an efficient solution for cardiac disease diagnosis, with plans to open-source the code."}}
{"id": "2505.16252", "pdf": "https://arxiv.org/pdf/2505.16252", "abs": "https://arxiv.org/abs/2505.16252", "authors": ["Hwiyeong Lee", "Uiji Hwang", "Hyelim Lim", "Taeuk Kim"], "title": "Does Localization Inform Unlearning? A Rigorous Examination of Local Parameter Attribution for Knowledge Unlearning in Language Models", "categories": ["cs.CL", "I.2.7"], "comment": null, "summary": "Large language models often retain unintended content, prompting growing\ninterest in knowledge unlearning. Recent approaches emphasize localized\nunlearning, which restricts parameter updates to specific regions in an effort\nto remove target knowledge while preserving unrelated general knowledge.\nHowever, their effectiveness remains uncertain due to the lack of robust and\nthorough evaluation of the trade-off between the competing goals of unlearning.\nIn this paper, we begin by revisiting existing localized unlearning approaches.\nWe then conduct controlled experiments to rigorously evaluate whether local\nparameter updates causally contribute to unlearning. Our findings reveal that\nthe set of parameters that must be modified for effective unlearning is not\nstrictly determined, challenging the core assumption of localized unlearning\nthat parameter locality is inherently indicative of effective knowledge\nremoval.", "AI": {"tldr": "The paper evaluates localized unlearning in large language models, finding that parameter locality doesn't strictly determine effective knowledge removal.", "motivation": "Address the uncertainty around localized unlearning's effectiveness in removing target knowledge while preserving general knowledge.", "method": "Revisits existing localized unlearning approaches and conducts controlled experiments to assess causal contributions of local parameter updates.", "result": "Parameter locality isn't inherently indicative of effective knowledge removal; the required parameter modifications aren't strictly determined.", "conclusion": "Challenges the core assumption of localized unlearning, suggesting a need for reevaluation of its principles."}}
{"id": "2505.16827", "pdf": "https://arxiv.org/pdf/2505.16827", "abs": "https://arxiv.org/abs/2505.16827", "authors": ["Bin Xie", "Rui Shao", "Gongwei Chen", "Kaiwen Zhou", "Yinchuan Li", "Jie Liu", "Min Zhang", "Liqiang Nie"], "title": "GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent", "categories": ["cs.AI"], "comment": "ACL 2025. Github: https://github.com/JiuTian-VL/GUI-explorer", "summary": "GUI automation faces critical challenges in dynamic environments. MLLMs\nsuffer from two key issues: misinterpreting UI components and outdated\nknowledge. Traditional fine-tuning methods are costly for app-specific\nknowledge updates. We propose GUI-explorer, a training-free GUI agent that\nincorporates two fundamental mechanisms: (1) Autonomous Exploration of\nFunction-aware Trajectory. To comprehensively cover all application\nfunctionalities, we design a Function-aware Task Goal Generator that\nautomatically constructs exploration goals by analyzing GUI structural\ninformation (e.g., screenshots and activity hierarchies). This enables\nsystematic exploration to collect diverse trajectories. (2) Unsupervised Mining\nof Transition-aware Knowledge. To establish precise screen-operation logic, we\ndevelop a Transition-aware Knowledge Extractor that extracts effective\nscreen-operation logic through unsupervised analysis the state transition of\nstructured interaction triples (observation, action, outcome). This eliminates\nthe need for human involvement in knowledge extraction. With a task success\nrate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows\nsignificant improvements over SOTA agents. It requires no parameter updates for\nnew apps. GUI-explorer is open-sourced and publicly available at\nhttps://github.com/JiuTian-VL/GUI-explorer.", "AI": {"tldr": "GUI-explorer is a training-free GUI agent that autonomously explores and mines knowledge for GUI automation, outperforming state-of-the-art agents without requiring parameter updates.", "motivation": "Addressing challenges in GUI automation, such as misinterpretation of UI components and outdated knowledge, without costly fine-tuning.", "method": "Uses autonomous exploration of function-aware trajectories and unsupervised mining of transition-aware knowledge to systematically collect and analyze GUI interactions.", "result": "Achieves task success rates of 53.7% on SPA-Bench and 47.4% on AndroidWorld, surpassing existing agents.", "conclusion": "GUI-explorer is an efficient, training-free solution for GUI automation, open-sourced for public use."}}
{"id": "2505.16333", "pdf": "https://arxiv.org/pdf/2505.16333", "abs": "https://arxiv.org/abs/2505.16333", "authors": ["Chaerin Kong", "Jiho Jang", "Nojun Kwak"], "title": "Understanding Differential Transformer Unchains Pretrained Self-Attentions", "categories": ["cs.LG"], "comment": "9 pages", "summary": "Differential Transformer has recently gained significant attention for its\nimpressive empirical performance, often attributed to its ability to perform\nnoise canceled attention. However, precisely how differential attention\nachieves its empirical benefits remains poorly understood. Moreover,\nDifferential Transformer architecture demands large-scale training from\nscratch, hindering utilization of open pretrained weights. In this work, we\nconduct an in-depth investigation of Differential Transformer, uncovering three\nkey factors behind its success: (1) enhanced expressivity via negative\nattention, (2) reduced redundancy among attention heads, and (3) improved\nlearning dynamics. Based on these findings, we propose DEX, a novel method to\nefficiently integrate the advantages of differential attention into pretrained\nlanguage models. By reusing the softmax attention scores and adding a\nlightweight differential operation on the output value matrix, DEX effectively\nincorporates the key advantages of differential attention while remaining\nlightweight in both training and inference. Evaluations confirm that DEX\nsubstantially improves the pretrained LLMs across diverse benchmarks, achieving\nsignificant performance gains with minimal adaptation data (< 0.01\\%).", "AI": {"tldr": "The paper investigates the Differential Transformer, identifies three key success factors, and proposes DEX, a lightweight method to integrate differential attention into pretrained models, achieving significant performance gains with minimal data.", "motivation": "To understand how Differential Transformer works and address its limitations, such as the need for large-scale training from scratch and inability to utilize pretrained weights.", "method": "Proposes DEX, which reuses softmax attention scores and adds a lightweight differential operation on the output value matrix to integrate differential attention into pretrained models.", "result": "DEX improves pretrained LLMs across diverse benchmarks with minimal adaptation data (< 0.01%).", "conclusion": "DEX successfully incorporates differential attention's advantages into pretrained models, offering lightweight and efficient performance gains."}}
{"id": "2505.16313", "pdf": "https://arxiv.org/pdf/2505.16313", "abs": "https://arxiv.org/abs/2505.16313", "authors": ["Arjhun Swaminathan", "Mete Akg\u00fcn"], "title": "Accelerating Targeted Hard-Label Adversarial Attacks in Low-Query Black-Box Settings", "categories": ["cs.CV", "cs.LG"], "comment": "This paper contains 11 pages, 7 figures and 3 tables. For associated\n  supplementary code, see https://github.com/mdppml/TEA", "summary": "Deep neural networks for image classification remain vulnerable to\nadversarial examples -- small, imperceptible perturbations that induce\nmisclassifications. In black-box settings, where only the final prediction is\naccessible, crafting targeted attacks that aim to misclassify into a specific\ntarget class is particularly challenging due to narrow decision regions.\nCurrent state-of-the-art methods often exploit the geometric properties of the\ndecision boundary separating a source image and a target image rather than\nincorporating information from the images themselves. In contrast, we propose\nTargeted Edge-informed Attack (TEA), a novel attack that utilizes edge\ninformation from the target image to carefully perturb it, thereby producing an\nadversarial image that is closer to the source image while still achieving the\ndesired target classification. Our approach consistently outperforms current\nstate-of-the-art methods across different models in low query settings (nearly\n70\\% fewer queries are used), a scenario especially relevant in real-world\napplications with limited queries and black-box access. Furthermore, by\nefficiently generating a suitable adversarial example, TEA provides an improved\ntarget initialization for established geometry-based attacks.", "AI": {"tldr": "TEA is a novel adversarial attack method using edge information from target images to craft perturbations, outperforming state-of-the-art methods with fewer queries.", "motivation": "Address the challenge of targeted adversarial attacks in black-box settings where decision regions are narrow and current methods rely heavily on geometric properties.", "method": "Utilizes edge information from the target image to perturb it, creating adversarial examples closer to the source image while achieving the target classification.", "result": "Outperforms state-of-the-art methods, reducing queries by nearly 70% in low query settings, and improves target initialization for geometry-based attacks.", "conclusion": "TEA is an efficient and effective method for crafting targeted adversarial attacks, especially in real-world black-box scenarios."}}
{"id": "2505.16258", "pdf": "https://arxiv.org/pdf/2505.16258", "abs": "https://arxiv.org/abs/2505.16258", "authors": ["Aashish Anantha Ramakrishnan", "Aadarsh Anantha Ramakrishnan", "Dongwon Lee"], "title": "IRONIC: Coherence-Aware Reasoning Chains for Multi-Modal Sarcasm Detection", "categories": ["cs.CL", "cs.AI", "cs.CV", "68T50", "I.2.7; I.2.10"], "comment": null, "summary": "Interpreting figurative language such as sarcasm across multi-modal inputs\npresents unique challenges, often requiring task-specific fine-tuning and\nextensive reasoning steps. However, current Chain-of-Thought approaches do not\nefficiently leverage the same cognitive processes that enable humans to\nidentify sarcasm. We present IRONIC, an in-context learning framework that\nleverages Multi-modal Coherence Relations to analyze referential, analogical\nand pragmatic image-text linkages. Our experiments show that IRONIC achieves\nstate-of-the-art performance on zero-shot Multi-modal Sarcasm Detection across\ndifferent baselines. This demonstrates the need for incorporating linguistic\nand cognitive insights into the design of multi-modal reasoning strategies. Our\ncode is available at: https://github.com/aashish2000/IRONIC", "AI": {"tldr": "IRONIC is a framework using Multi-modal Coherence Relations for zero-shot sarcasm detection, outperforming baselines by incorporating cognitive insights.", "motivation": "Current methods lack efficiency in mimicking human cognitive processes for sarcasm detection in multi-modal inputs.", "method": "IRONIC leverages Multi-modal Coherence Relations (referential, analogical, pragmatic) for in-context learning.", "result": "Achieves state-of-the-art performance in zero-shot Multi-modal Sarcasm Detection.", "conclusion": "Highlights the importance of integrating linguistic and cognitive insights into multi-modal reasoning."}}
{"id": "2505.16832", "pdf": "https://arxiv.org/pdf/2505.16832", "abs": "https://arxiv.org/abs/2505.16832", "authors": ["Haonian Ji", "Shi Qiu", "Siyang Xin", "Siwei Han", "Zhaorun Chen", "Hongyi Wang", "Dake Zhang", "Huaxiu Yao"], "title": "From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "16 pages; 7 figures", "summary": "While foundation models (FMs), such as diffusion models and large\nvision-language models (LVLMs), have been widely applied in educational\ncontexts, their ability to generate pedagogically effective visual explanations\nremains limited. Most existing approaches focus primarily on textual reasoning,\noverlooking the critical role of structured and interpretable visualizations in\nsupporting conceptual understanding. To better assess the visual reasoning\ncapabilities of FMs in educational settings, we introduce EduVisBench, a\nmulti-domain, multi-level benchmark. EduVisBench features diverse STEM problem\nsets requiring visually grounded solutions, along with a fine-grained\nevaluation rubric informed by pedagogical theory. Our empirical analysis\nreveals that existing models frequently struggle with the inherent challenge of\ndecomposing complex reasoning and translating it into visual representations\naligned with human cognitive processes. To address these limitations, we\npropose EduVisAgent, a multi-agent collaborative framework that coordinates\nspecialized agents for instructional planning, reasoning decomposition,\nmetacognitive prompting, and visualization design. Experimental results show\nthat EduVisAgent substantially outperforms all baselines, achieving a 40.2%\nimprovement and delivering more educationally aligned visualizations.\nEduVisBench and EduVisAgent are available at\nhttps://github.com/aiming-lab/EduVisBench and\nhttps://github.com/aiming-lab/EduVisAgent.", "AI": {"tldr": "The paper introduces EduVisBench, a benchmark for evaluating visual reasoning in foundation models (FMs) for education, and EduVisAgent, a multi-agent framework to improve pedagogically effective visualizations.", "motivation": "Existing FMs lack pedagogically effective visual explanations, focusing too much on textual reasoning and neglecting structured visualizations for conceptual understanding.", "method": "The authors propose EduVisBench, a multi-domain, multi-level benchmark with STEM problem sets and a fine-grained rubric. They also introduce EduVisAgent, a multi-agent framework for instructional planning, reasoning decomposition, metacognitive prompting, and visualization design.", "result": "EduVisAgent outperforms baselines by 40.2%, generating more educationally aligned visualizations.", "conclusion": "The work highlights the limitations of current FMs in visual reasoning for education and demonstrates the effectiveness of EduVisAgent in addressing these challenges."}}
{"id": "2505.16340", "pdf": "https://arxiv.org/pdf/2505.16340", "abs": "https://arxiv.org/abs/2505.16340", "authors": ["Yunhui Jang", "Jaehyung Kim", "Sungsoo Ahn"], "title": "Improving Chemical Understanding of LLMs via SMILES Parsing", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) are increasingly recognized as powerful tools\nfor scientific discovery, particularly in molecular science. A fundamental\nrequirement for these models is the ability to accurately understand molecular\nstructures, commonly encoded in the SMILES representation. However, current\nLLMs struggle to interpret SMILES, even failing to carry out basic tasks such\nas counting molecular rings. To address this limitation, we introduce CLEANMOL,\na novel framework that formulates SMILES parsing into a suite of clean and\ndeterministic tasks explicitly designed to promote graph-level molecular\ncomprehension. These tasks span from subgraph matching to global graph\nmatching, providing structured supervision aligned with molecular structural\nproperties. We construct a molecular pretraining dataset with adaptive\ndifficulty scoring and pre-train open-source LLMs on these tasks. Our results\nshow that CLEANMOL not only enhances structural comprehension but also achieves\nthe best or competes with the baseline on the Mol-Instructions benchmark.", "AI": {"tldr": "CLEANMOL improves LLMs' ability to understand SMILES representations of molecules by introducing structured tasks for molecular comprehension.", "motivation": "Current LLMs struggle with interpreting SMILES representations, hindering their use in molecular science.", "method": "CLEANMOL formulates SMILES parsing into deterministic tasks (subgraph to global graph matching) and pre-trains LLMs on a dataset with adaptive difficulty.", "result": "CLEANMOL enhances structural comprehension and performs competitively on the Mol-Instructions benchmark.", "conclusion": "CLEANMOL addresses LLMs' limitations in molecular science, improving their utility for scientific discovery."}}
{"id": "2505.16314", "pdf": "https://arxiv.org/pdf/2505.16314", "abs": "https://arxiv.org/abs/2505.16314", "authors": ["Shuhao Han", "Haotian Fan", "Fangyuan Kong", "Wenjie Liao", "Chunle Guo", "Chongyi Li", "Radu Timofte", "Liang Li", "Tao Li", "Junhui Cui", "Yunqiu Wang", "Yang Tai", "Jingwei Sun", "Jianhui Sun", "Xinli Yue", "Tianyi Wang", "Huan Hou", "Junda Lu", "Xinyang Huang", "Zitang Zhou", "Zijian Zhang", "Xuhui Zheng", "Xuecheng Wu", "Chong Peng", "Xuezhi Cao", "Trong-Hieu Nguyen-Mau", "Minh-Hoang Le", "Minh-Khoa Le-Phan", "Duy-Nam Ly", "Hai-Dang Nguyen", "Minh-Triet Tran", "Yukang Lin", "Yan Hong", "Chuanbiao Song", "Siyuan Li", "Jun Lan", "Zhichao Zhang", "Xinyue Li", "Wei Sun", "Zicheng Zhang", "Yunhao Li", "Xiaohong Liu", "Guangtao Zhai", "Zitong Xu", "Huiyu Duan", "Jiarui Wang", "Guangji Ma", "Liu Yang", "Lu Liu", "Qiang Hu", "Xiongkuo Min", "Zichuan Wang", "Zhenchen Tang", "Bo Peng", "Jing Dong", "Fengbin Guan", "Zihao Yu", "Yiting Lu", "Wei Luo", "Xin Li", "Minhao Lin", "Haofeng Chen", "Xuanxuan He", "Kele Xu", "Qisheng Xu", "Zijian Gao", "Tianjiao Wan", "Bo-Cheng Qiu", "Chih-Chung Hsu", "Chia-ming Lee", "Yu-Fan Lin", "Bo Yu", "Zehao Wang", "Da Mu", "Mingxiu Chen", "Junkang Fang", "Huamei Sun", "Wending Zhao", "Zhiyu Wang", "Wang Liu", "Weikang Yu", "Puhong Duan", "Bin Sun", "Xudong Kang", "Shutao Li", "Shuai He", "Lingzhi Fu", "Heng Cong", "Rongyu Zhang", "Jiarong He", "Zhishan Qiao", "Yongqing Huang", "Zewen Chen", "Zhe Pang", "Juan Wang", "Jian Guo", "Zhizhuo Shao", "Ziyu Feng", "Bing Li", "Weiming Hu", "Hesong Li", "Dehua Liu", "Zeming Liu", "Qingsong Xie", "Ruichen Wang", "Zhihao Li", "Yuqi Liang", "Jianqi Bi", "Jun Luo", "Junfeng Yang", "Can Li", "Jing Fu", "Hongwei Xu", "Mingrui Long", "Lulin Tang"], "title": "NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper reports on the NTIRE 2025 challenge on Text to Image (T2I)\ngeneration model quality assessment, which will be held in conjunction with the\nNew Trends in Image Restoration and Enhancement Workshop (NTIRE) at CVPR 2025.\nThe aim of this challenge is to address the fine-grained quality assessment of\ntext-to-image generation models. This challenge evaluates text-to-image models\nfrom two aspects: image-text alignment and image structural distortion\ndetection, and is divided into the alignment track and the structural track.\nThe alignment track uses the EvalMuse-40K, which contains around 40K\nAI-Generated Images (AIGIs) generated by 20 popular generative models. The\nalignment track has a total of 371 registered participants. A total of 1,883\nsubmissions are received in the development phase, and 507 submissions are\nreceived in the test phase. Finally, 12 participating teams submitted their\nmodels and fact sheets. The structure track uses the EvalMuse-Structure, which\ncontains 10,000 AI-Generated Images (AIGIs) with corresponding structural\ndistortion mask. A total of 211 participants have registered in the structure\ntrack. A total of 1155 submissions are received in the development phase, and\n487 submissions are received in the test phase. Finally, 8 participating teams\nsubmitted their models and fact sheets. Almost all methods have achieved better\nresults than baseline methods, and the winning methods in both tracks have\ndemonstrated superior prediction performance on T2I model quality assessment.", "AI": {"tldr": "The NTIRE 2025 challenge evaluates text-to-image (T2I) generation models for quality assessment, focusing on image-text alignment and structural distortion detection. It attracted hundreds of participants and submissions, with winning methods outperforming baselines.", "motivation": "To address the fine-grained quality assessment of T2I models, focusing on alignment and structural distortion.", "method": "The challenge is divided into two tracks: alignment (using EvalMuse-40K dataset) and structural (using EvalMuse-Structure dataset). Participants submit models evaluated in development and test phases.", "result": "High participation (371 in alignment, 211 in structural) with many submissions. Winning methods outperformed baselines in both tracks.", "conclusion": "The challenge successfully advanced T2I quality assessment, with winning methods demonstrating superior performance."}}
{"id": "2505.16270", "pdf": "https://arxiv.org/pdf/2505.16270", "abs": "https://arxiv.org/abs/2505.16270", "authors": ["Jiaru Zou", "Yikun Ban", "Zihao Li", "Yunzhe Qi", "Ruizhong Qiu", "Ling Yang", "Jingrui He"], "title": "Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "33 pages, 7 figures", "summary": "Large language models are typically adapted to downstream tasks through\nsupervised fine-tuning on domain-specific data. While standard fine-tuning\nfocuses on minimizing generation loss to optimize model parameters, we take a\ndeeper step by retaining and leveraging the model's own learning signals,\nanalogous to how human learners reflect on past mistakes to improve future\nperformance. We first introduce the concept of Mistake Log to systematically\ntrack the model's learning behavior and recurring errors throughout\nfine-tuning. Treating the original transformer-based model as the Pilot, we\ncorrespondingly design a Copilot model to refine the Pilot's inference\nperformance via logits rectification. We name the overall Pilot-Copilot\nframework the Transformer Copilot, which introduces (i) a novel Copilot model\ndesign, (ii) a joint training paradigm where the Copilot continuously learns\nfrom the evolving Mistake Log alongside the Pilot, and (iii) a fused inference\nparadigm where the Copilot rectifies the Pilot's logits for enhanced\ngeneration. We provide both theoretical and empirical analyses on our new\nlearning framework. Experiments on 12 benchmarks spanning commonsense,\narithmetic, and recommendation tasks demonstrate that Transformer Copilot\nconsistently improves performance by up to 34.5%, while introducing marginal\ncomputational overhead to Pilot models and exhibiting strong scalability and\ntransferability.", "AI": {"tldr": "The paper introduces Transformer Copilot, a framework where a Copilot model refines a Pilot model's performance by tracking and rectifying mistakes during fine-tuning, achieving up to 34.5% improvement with minimal overhead.", "motivation": "To enhance fine-tuning by leveraging the model's learning signals, akin to human reflection on past errors, rather than just minimizing generation loss.", "method": "Introduces Mistake Log to track errors, designs a Copilot model for logits rectification, and employs joint training and fused inference paradigms.", "result": "Experiments on 12 benchmarks show performance improvements up to 34.5% with marginal computational overhead.", "conclusion": "Transformer Copilot effectively enhances model performance, scalability, and transferability by systematically addressing recurring errors."}}
{"id": "2505.16854", "pdf": "https://arxiv.org/pdf/2505.16854", "abs": "https://arxiv.org/abs/2505.16854", "authors": ["Jiaqi Wang", "Kevin Qinghong Lin", "James Cheng", "Mike Zheng Shou"], "title": "Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Reinforcement Learning (RL) has proven to be an effective post-training\nstrategy for enhancing reasoning in vision-language models (VLMs). Group\nRelative Policy Optimization (GRPO) is a recent prominent method that\nencourages models to generate complete reasoning traces before answering,\nleading to increased token usage and computational cost. Inspired by the\nhuman-like thinking process-where people skip reasoning for easy questions but\nthink carefully when needed-we explore how to enable VLMs to first decide when\nreasoning is necessary. To realize this, we propose TON, a two-stage training\nstrategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective\n'thought dropout' operation, where reasoning traces are randomly replaced with\nempty thoughts. This introduces a think-or-not format that serves as a cold\nstart for selective reasoning; (ii) a GRPO stage that enables the model to\nfreely explore when to think or not, while maximizing task-aware outcome\nrewards. Experimental results show that TON can reduce the completion length by\nup to 90% compared to vanilla GRPO, without sacrificing performance or even\nimproving it. Further evaluations across diverse vision-language tasks-covering\na range of reasoning difficulties under both 3B and 7B models-consistently\nreveal that the model progressively learns to bypass unnecessary reasoning\nsteps as training advances. These findings shed light on the path toward\nhuman-like reasoning patterns in reinforcement learning approaches. Our code is\navailable at https://github.com/kokolerk/TON.", "AI": {"tldr": "TON is a two-stage training strategy for VLMs that reduces unnecessary reasoning steps, cutting completion length by up to 90% without performance loss.", "motivation": "To mimic human-like selective reasoning, avoiding computational waste on easy questions while ensuring careful thought for complex ones.", "method": "Combines supervised fine-tuning with 'thought dropout' and GRPO to train models to decide when reasoning is needed.", "result": "Reduces token usage significantly (up to 90%) while maintaining or improving performance across tasks.", "conclusion": "TON advances human-like reasoning in RL, optimizing efficiency without sacrificing accuracy."}}
{"id": "2505.16341", "pdf": "https://arxiv.org/pdf/2505.16341", "abs": "https://arxiv.org/abs/2505.16341", "authors": ["Yaxin Hou", "Yuheng Jia"], "title": "A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning", "categories": ["cs.LG"], "comment": "The paper is accepted by ICML 2025", "summary": "This paper studies the long-tailed semi-supervised learning (LTSSL) with\ndistribution mismatch, where the class distribution of the labeled training\ndata follows a long-tailed distribution and mismatches with that of the\nunlabeled training data. Most existing methods introduce auxiliary classifiers\n(experts) to model various unlabeled data distributions and produce\npseudo-labels, but the expertises of various experts are not fully utilized. We\nobserve that different experts are good at predicting different intervals of\nsamples, e.g., long-tailed expert is skilled in samples located in the head\ninterval and uniform expert excels in samples located in the medium interval.\nTherefore, we propose a dynamic expert assignment module that can estimate the\nclass membership (i.e., head, medium, or tail class) of samples, and\ndynamically assigns suitable expert to each sample based on the estimated\nmembership to produce high-quality pseudo-label in the training phase and\nproduce prediction in the testing phase. We also theoretically reveal that\nintegrating different experts' strengths will lead to a smaller generalization\nerror bound. Moreover, we find that the deeper features are more biased toward\nthe head class but with more discriminative ability, while the shallower\nfeatures are less biased but also with less discriminative ability. We,\ntherefore, propose a multi-depth feature fusion module to utilize different\ndepth features to mitigate the model bias. Our method demonstrates its\neffectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT,\nand SVHN-LT datasets across various settings. The code is available at\nhttps://github.com/yaxinhou/Meta-Expert.", "AI": {"tldr": "The paper proposes a dynamic expert assignment module and multi-depth feature fusion to address long-tailed semi-supervised learning with distribution mismatch, improving pseudo-label quality and reducing model bias.", "motivation": "Existing methods in LTSSL underutilize expert strengths and fail to address feature bias, prompting the need for dynamic expert assignment and feature fusion.", "method": "Introduces a dynamic expert assignment module to estimate class membership and assign suitable experts, along with multi-depth feature fusion to mitigate bias.", "result": "Demonstrates effectiveness on CIFAR-10-LT, STL-10-LT, and SVHN-LT datasets, showing improved performance.", "conclusion": "The proposed method effectively leverages expert strengths and feature fusion to enhance LTSSL performance."}}
{"id": "2505.16321", "pdf": "https://arxiv.org/pdf/2505.16321", "abs": "https://arxiv.org/abs/2505.16321", "authors": ["Jie Zhao", "Xin Chen", "Yongsheng Yuan", "Michael Felsberg", "Dong Wang", "Huchuan Lu"], "title": "Efficient Motion Prompt Learning for Robust Visual Tracking", "categories": ["cs.CV"], "comment": "Accepted by ICML2025", "summary": "Due to the challenges of processing temporal information, most trackers\ndepend solely on visual discriminability and overlook the unique temporal\ncoherence of video data. In this paper, we propose a lightweight and\nplug-and-play motion prompt tracking method. It can be easily integrated into\nexisting vision-based trackers to build a joint tracking framework leveraging\nboth motion and vision cues, thereby achieving robust tracking through\nefficient prompt learning. A motion encoder with three different positional\nencodings is proposed to encode the long-term motion trajectory into the visual\nembedding space, while a fusion decoder and an adaptive weight mechanism are\ndesigned to dynamically fuse visual and motion features. We integrate our\nmotion module into three different trackers with five models in total.\nExperiments on seven challenging tracking benchmarks demonstrate that the\nproposed motion module significantly improves the robustness of vision-based\ntrackers, with minimal training costs and negligible speed sacrifice. Code is\navailable at https://github.com/zj5559/Motion-Prompt-Tracking.", "AI": {"tldr": "A lightweight motion prompt tracking method is proposed to enhance vision-based trackers by integrating motion cues, improving robustness with minimal overhead.", "motivation": "Existing trackers rely heavily on visual discriminability, ignoring temporal coherence in video data, which limits robustness.", "method": "The method introduces a motion encoder with three positional encodings, a fusion decoder, and adaptive weight mechanism to dynamically combine motion and visual features.", "result": "Integrated into three trackers, the module significantly improves robustness across seven benchmarks with minimal training cost and speed impact.", "conclusion": "The motion prompt method effectively leverages temporal coherence, enhancing tracking performance efficiently."}}
{"id": "2505.16277", "pdf": "https://arxiv.org/pdf/2505.16277", "abs": "https://arxiv.org/abs/2505.16277", "authors": ["Sheng-Fu Wang", "Laurent Prevot", "Jou-an Chi", "Ri-Sheng Huang", "Shu-Kai Hsieh"], "title": "Spontaneous Speech Variables for Evaluating LLMs Cognitive Plausibility", "categories": ["cs.CL"], "comment": "The 14th Workshop on Cognitive Modeling and Computational Linguistics\n  (CMCL). May 3, 2025. Collocated with NAACL 2025", "summary": "The achievements of Large Language Models in Natural Language Processing,\nespecially for high-resource languages, call for a better understanding of\ntheir characteristics from a cognitive perspective. Researchers have attempted\nto evaluate artificial models by testing their ability to predict behavioral\n(e.g., eye-tracking fixations) and physiological (e.g., brain responses)\nvariables during language processing (e.g., reading/listening). In this paper,\nwe propose using spontaneous speech corpora to derive production variables\n(speech reductions, prosodic prominences) and applying them in a similar\nfashion. More precisely, we extract. We then test models trained with a\nstandard procedure on different pretraining datasets (written, spoken, and\nmixed genres) for their ability to predict these two variables. Our results\nshow that, after some fine-tuning, the models can predict these production\nvariables well above baselines. We also observe that spoken genre training data\nprovides more accurate predictions than written genres. These results\ncontribute to the broader effort of using high-quality speech corpora as\nbenchmarks for LLMs.", "AI": {"tldr": "The paper explores using spontaneous speech corpora to evaluate LLMs' ability to predict production variables like speech reductions and prosodic prominences, finding spoken genre training data improves prediction accuracy.", "motivation": "To understand LLMs' cognitive characteristics by evaluating their ability to predict behavioral and physiological variables in language processing, extending this to production variables from speech.", "method": "Extract production variables from spontaneous speech corpora, test models trained on different pretraining datasets (written, spoken, mixed) for predicting these variables, and fine-tune them.", "result": "Fine-tuned models predict production variables well above baselines, with spoken genre training data yielding more accurate predictions than written genres.", "conclusion": "High-quality speech corpora can serve as effective benchmarks for LLMs, highlighting the importance of spoken data in training."}}
{"id": "2505.16877", "pdf": "https://arxiv.org/pdf/2505.16877", "abs": "https://arxiv.org/abs/2505.16877", "authors": ["Yuqicheng Zhu", "Daniel Hern\u00e1ndez", "Yuan He", "Zifeng Ding", "Bo Xiong", "Evgeny Kharlamov", "Steffen Staab"], "title": "Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings", "categories": ["cs.AI"], "comment": "Accepted to the Finding of ACL 2025", "summary": "Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is\ncrucial for ensuring the reliability of downstream applications. A recent work\napplies conformal prediction to KGE methods, providing uncertainty estimates by\ngenerating a set of answers that is guaranteed to include the true answer with\na predefined confidence level. However, existing methods provide probabilistic\nguarantees averaged over a reference set of queries and answers (marginal\ncoverage guarantee). In high-stakes applications such as medical diagnosis, a\nstronger guarantee is often required: the predicted sets must provide\nconsistent coverage per query (conditional coverage guarantee). We propose\nCondKGCP, a novel method that approximates predicate-conditional coverage\nguarantees while maintaining compact prediction sets. CondKGCP merges\npredicates with similar vector representations and augments calibration with\nrank information. We prove the theoretical guarantees and demonstrate empirical\neffectiveness of CondKGCP by comprehensive evaluations.", "AI": {"tldr": "CondKGCP introduces a method for stronger per-query uncertainty guarantees in KGE, improving reliability for high-stakes applications.", "motivation": "Existing KGE uncertainty methods only provide marginal coverage guarantees, which are insufficient for high-stakes applications like medical diagnosis requiring per-query consistency.", "method": "CondKGCP merges similar predicates and uses rank information to approximate predicate-conditional coverage while keeping prediction sets compact.", "result": "Theoretical guarantees are proven, and empirical evaluations demonstrate CondKGCP's effectiveness.", "conclusion": "CondKGCP advances KGE uncertainty quantification by providing stronger conditional coverage guarantees, enhancing reliability for critical applications."}}
{"id": "2505.16353", "pdf": "https://arxiv.org/pdf/2505.16353", "abs": "https://arxiv.org/abs/2505.16353", "authors": ["C\u00e9line Comte", "Pascal Moyal"], "title": "Arrival Control in Quasi-Reversible Queueing Systems: Optimization and Reinforcement Learning", "categories": ["cs.LG", "math.OC", "math.PR"], "comment": null, "summary": "In this paper, we introduce a versatile scheme for optimizing the arrival\nrates of quasi-reversible queueing systems. We first propose an alternative\ndefinition of quasi-reversibility that encompasses reversibility and highlights\nthe importance of the definition of customer classes. In a second time, we\nintroduce balanced arrival control policies, which generalize the notion of\nbalanced arrival rates introduced in the context of Whittle networks, to the\nmuch broader class of quasi-reversible queueing systems. We prove that\nsupplementing a quasi-reversible queueing system with a balanced\narrival-control policy preserves the quasi-reversibility, and we specify the\nform of the stationary measures. We revisit two canonical examples of\nquasi-reversible queueing systems, Whittle networks and order-independent\nqueues. Lastly, we focus on the problem of admission control and leverage our\nresults in the frameworks of optimization and reinforcement learning.", "AI": {"tldr": "A versatile scheme for optimizing arrival rates in quasi-reversible queueing systems is introduced, with balanced arrival control policies preserving quasi-reversibility.", "motivation": "To generalize and optimize arrival rates in quasi-reversible queueing systems, extending beyond Whittle networks.", "method": "Proposes an alternative definition of quasi-reversibility, introduces balanced arrival control policies, and applies them to canonical examples.", "result": "Balanced arrival control preserves quasi-reversibility, with stationary measures specified. Applied to Whittle networks and order-independent queues.", "conclusion": "The framework is leveraged for admission control, optimization, and reinforcement learning, demonstrating broad applicability."}}
{"id": "2505.16324", "pdf": "https://arxiv.org/pdf/2505.16324", "abs": "https://arxiv.org/abs/2505.16324", "authors": ["Cheng Cheng", "Lin Song", "Yicheng Xiao", "Yuxin Chen", "Xuchong Zhang", "Hongbin Sun", "Ying Shan"], "title": "TensorAR: Refinement is All You Need in Autoregressive Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Autoregressive (AR) image generators offer a language-model-friendly approach\nto image generation by predicting discrete image tokens in a causal sequence.\nHowever, unlike diffusion models, AR models lack a mechanism to refine previous\npredictions, limiting their generation quality. In this paper, we introduce\nTensorAR, a new AR paradigm that reformulates image generation from next-token\nprediction to next-tensor prediction. By generating overlapping windows of\nimage patches (tensors) in a sliding fashion, TensorAR enables iterative\nrefinement of previously generated content. To prevent information leakage\nduring training, we propose a discrete tensor noising scheme, which perturbs\ninput tokens via codebook-indexed noise. TensorAR is implemented as a\nplug-and-play module compatible with existing AR models. Extensive experiments\non LlamaGEN, Open-MAGVIT2, and RAR demonstrate that TensorAR significantly\nimproves the generation performance of autoregressive models.", "AI": {"tldr": "TensorAR introduces a new autoregressive image generation method by predicting overlapping image patches (tensors) iteratively, improving quality over traditional AR models.", "motivation": "Traditional AR image generators lack refinement mechanisms, limiting their quality compared to diffusion models. TensorAR addresses this gap.", "method": "TensorAR reformulates AR generation as next-tensor prediction, using sliding windows for iterative refinement. A discrete tensor noising scheme prevents information leakage.", "result": "Experiments show TensorAR significantly boosts performance of AR models like LlamaGEN, Open-MAGVIT2, and RAR.", "conclusion": "TensorAR offers a plug-and-play solution to enhance AR image generation quality through iterative refinement."}}
{"id": "2505.16281", "pdf": "https://arxiv.org/pdf/2505.16281", "abs": "https://arxiv.org/abs/2505.16281", "authors": ["Shijie Zhang", "Renhao Li", "Songsheng Wang", "Philipp Koehn", "Min Yang", "Derek F. Wong"], "title": "HiMATE: A Hierarchical Multi-Agent Framework for Machine Translation Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "The advancement of Large Language Models (LLMs) enables flexible and\ninterpretable automatic evaluations. In the field of machine translation\nevaluation, utilizing LLMs with translation error annotations based on\nMultidimensional Quality Metrics (MQM) yields more human-aligned judgments.\nHowever, current LLM-based evaluation methods still face challenges in\naccurately identifying error spans and assessing their severity. In this paper,\nwe propose HiMATE, a Hierarchical Multi-Agent Framework for Machine Translation\nEvaluation. We argue that existing approaches inadequately exploit the\nfine-grained structural and semantic information within the MQM hierarchy. To\naddress this, we develop a hierarchical multi-agent system grounded in the MQM\nerror typology, enabling granular evaluation of subtype errors. Two key\nstrategies are incorporated to further mitigate systemic hallucinations within\nthe framework: the utilization of the model's self-reflection capability and\nthe facilitation of agent discussion involving asymmetric information.\nEmpirically, HiMATE outperforms competitive baselines across different datasets\nin conducting human-aligned evaluations. Further analyses underscore its\nsignificant advantage in error span detection and severity assessment,\nachieving an average F1-score improvement of 89% over the best-performing\nbaseline. We make our code and data publicly available at\nhttps://anonymous.4open.science/r/HiMATE-Anony.", "AI": {"tldr": "HiMATE, a hierarchical multi-agent framework, improves machine translation evaluation by leveraging MQM error typology, self-reflection, and agent discussion, outperforming baselines in human-aligned judgments.", "motivation": "Current LLM-based evaluation methods struggle with error span identification and severity assessment, lacking fine-grained MQM hierarchy exploitation.", "method": "HiMATE uses a hierarchical multi-agent system based on MQM typology, incorporating self-reflection and asymmetric agent discussion to reduce hallucinations.", "result": "HiMATE outperforms baselines, achieving an 89% F1-score improvement in error span detection and severity assessment.", "conclusion": "HiMATE enhances machine translation evaluation by addressing fine-grained error analysis, with significant empirical advantages."}}
{"id": "2505.16899", "pdf": "https://arxiv.org/pdf/2505.16899", "abs": "https://arxiv.org/abs/2505.16899", "authors": ["Kerem Oktar", "Katherine M. Collins", "Jose Hernandez-Orallo", "Diane Coyle", "Stephen Cave", "Adrian Weller", "Ilia Sucholutsky"], "title": "Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships", "categories": ["cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) systems have historically been used as tools\nthat execute narrowly defined tasks. Yet recent advances in AI have unlocked\npossibilities for a new class of models that genuinely collaborate with humans\nin complex reasoning, from conceptualizing problems to brainstorming solutions.\nSuch AI thought partners enable novel forms of collaboration and extended\ncognition, yet they also pose major risks-including and beyond risks of typical\nAI tools and agents. In this commentary, we systematically identify risks of AI\nthought partners through a novel framework that identifies risks at multiple\nlevels of analysis, including Real-time, Individual, and Societal risks arising\nfrom collaborative cognition (RISc). We leverage this framework to propose\nconcrete metrics for risk evaluation, and finally suggest specific mitigation\nstrategies for developers and policymakers. As AI thought partners continue to\nproliferate, these strategies can help prevent major harms and ensure that\nhumans actively benefit from productive thought partnerships.", "AI": {"tldr": "The paper discusses risks of AI thought partners, proposing a framework (RISc) to evaluate and mitigate risks at real-time, individual, and societal levels.", "motivation": "To address the novel risks posed by AI systems that collaborate with humans in complex reasoning, beyond traditional AI tools.", "method": "Introduces the RISc framework to systematically identify risks at multiple levels (Real-time, Individual, Societal) and proposes metrics and mitigation strategies.", "result": "A structured approach to evaluate and mitigate risks of AI thought partners, ensuring safer collaboration.", "conclusion": "Proactive strategies are needed to prevent harms and maximize benefits of AI thought partnerships."}}
{"id": "2505.16363", "pdf": "https://arxiv.org/pdf/2505.16363", "abs": "https://arxiv.org/abs/2505.16363", "authors": ["Huishuai Zhang", "Bohan Wang", "Luoxin Chen"], "title": "AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We introduce AdamS, a simple yet effective alternative to Adam for large\nlanguage model (LLM) pretraining and post-training. By leveraging a novel\ndenominator, i.e., the root of weighted sum of squares of the momentum and the\ncurrent gradient, AdamS eliminates the need for second-moment estimates. Hence,\nAdamS is efficient, matching the memory and compute footprint of SGD with\nmomentum while delivering superior optimization performance. Moreover, AdamS is\neasy to adopt: it can directly inherit hyperparameters of AdamW, and is\nentirely model-agnostic, integrating seamlessly into existing pipelines without\nmodifications to optimizer APIs or architectures. The motivation behind AdamS\nstems from the observed $(L_0, L_1)$ smoothness properties in transformer\nobjectives, where local smoothness is governed by gradient magnitudes that can\nbe further approximated by momentum magnitudes. We establish rigorous\ntheoretical convergence guarantees and provide practical guidelines for\nhyperparameter selection. Empirically, AdamS demonstrates strong performance in\nvarious tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B\nparameters) and reinforcement learning in post-training regimes. With its\nefficiency, simplicity, and theoretical grounding, AdamS stands as a compelling\nalternative to existing optimizers.", "AI": {"tldr": "AdamS is a memory-efficient alternative to Adam for LLM training, using a novel denominator to avoid second-moment estimates, matching SGD's footprint while outperforming AdamW.", "motivation": "Addresses inefficiencies in Adam by leveraging transformer objectives' smoothness properties, approximated by gradient and momentum magnitudes.", "method": "Replaces second-moment estimates with a denominator based on the root of weighted sum of squares of momentum and current gradient.", "result": "Demonstrates superior performance in GPT-2, Llama2 (up to 13B), and RL tasks, with theoretical convergence guarantees.", "conclusion": "AdamS is efficient, easy to adopt, and outperforms existing optimizers, making it a compelling choice for LLM training."}}
{"id": "2505.16334", "pdf": "https://arxiv.org/pdf/2505.16334", "abs": "https://arxiv.org/abs/2505.16334", "authors": ["Kun-Yu Lin", "Hongjun Wang", "Weining Ren", "Kai Han"], "title": "Panoptic Captioning: Seeking An Equivalency Bridge for Image and Text", "categories": ["cs.CV"], "comment": "Project page: https://visual-ai.github.io/pancap/", "summary": "This work introduces panoptic captioning, a novel task striving to seek the\nminimum text equivalence of images. We take the first step towards panoptic\ncaptioning by formulating it as a task of generating a comprehensive textual\ndescription for an image, which encapsulates all entities, their respective\nlocations and attributes, relationships among entities, as well as global image\nstate.Through an extensive evaluation, our work reveals that state-of-the-art\nMulti-modal Large Language Models (MLLMs) have limited performance in solving\npanoptic captioning. To address this, we propose an effective data engine named\nPancapEngine to produce high-quality data and a novel method named PancapChain\nto improve panoptic captioning. Specifically, our PancapEngine first detects\ndiverse categories of entities in images by an elaborate detection suite, and\nthen generates required panoptic captions using entity-aware prompts.\nAdditionally, our PancapChain explicitly decouples the challenging panoptic\ncaptioning task into multiple stages and generates panoptic captions step by\nstep. More importantly, we contribute a comprehensive metric named PancapScore\nand a human-curated test set for reliable model evaluation.Experiments show\nthat our PancapChain-13B model can beat state-of-the-art open-source MLLMs like\nInternVL-2.5-78B and even surpass proprietary models like GPT-4o and\nGemini-2.0-Pro, demonstrating the effectiveness of our data engine and method.\nProject page: https://visual-ai.github.io/pancap/", "AI": {"tldr": "The paper introduces panoptic captioning, a task to generate comprehensive textual descriptions of images, and proposes PancapEngine for data generation and PancapChain for improved performance, outperforming state-of-the-art models.", "motivation": "To address the limitation of current Multi-modal Large Language Models (MLLMs) in generating detailed, panoptic captions that include entities, locations, attributes, relationships, and global image state.", "method": "Proposes PancapEngine for high-quality data generation using entity-aware prompts and PancapChain, which decouples the task into stages for step-by-step captioning. Introduces PancapScore for evaluation.", "result": "PancapChain-13B outperforms open-source MLLMs like InternVL-2.5-78B and proprietary models like GPT-4o and Gemini-2.0-Pro.", "conclusion": "The proposed methods and data engine effectively advance panoptic captioning, demonstrating superior performance over existing models."}}
{"id": "2505.16293", "pdf": "https://arxiv.org/pdf/2505.16293", "abs": "https://arxiv.org/abs/2505.16293", "authors": ["Rishabh Maheshwary", "Masoud Hashemi", "Khyati Mahajan", "Shiva Krishna Reddy Malay", "Sai Rajeswar", "Sathwik Tejaswi Madhusudhan", "Spandana Gella", "Vikas Yadav"], "title": "Augmenting LLM Reasoning with Dynamic Notes Writing for Complex QA", "categories": ["cs.CL"], "comment": null, "summary": "Iterative RAG for multi-hop question answering faces challenges with lengthy\ncontexts and the buildup of irrelevant information. This hinders a model's\ncapacity to process and reason over retrieved content and limits performance.\nWhile recent methods focus on compressing retrieved information, they are\neither restricted to single-round RAG, require finetuning or lack scalability\nin iterative RAG. To address these challenges, we propose Notes Writing, a\nmethod that generates concise and relevant notes from retrieved documents at\neach step, thereby reducing noise and retaining only essential information.\nThis indirectly increases the effective context length of Large Language Models\n(LLMs), enabling them to reason and plan more effectively while processing\nlarger volumes of input text. Notes Writing is framework agnostic and can be\nintegrated with different iterative RAG methods. We demonstrate its\neffectiveness with three iterative RAG methods, across two models and four\nevaluation datasets. Notes writing yields an average improvement of 15.6\npercentage points overall, with minimal increase in output tokens.", "AI": {"tldr": "Notes Writing improves iterative RAG by generating concise notes from retrieved documents, reducing noise and enhancing reasoning. It boosts performance by 15.6% on average.", "motivation": "Challenges in iterative RAG include lengthy contexts and irrelevant information buildup, hindering reasoning and performance. Existing methods lack scalability or are limited to single-round RAG.", "method": "Proposes Notes Writing, a method to generate concise notes from retrieved documents at each step, reducing noise and retaining essential information. It\u2019s framework agnostic and integrates with various iterative RAG methods.", "result": "Demonstrated effectiveness across three iterative RAG methods, two models, and four datasets, yielding a 15.6% average improvement with minimal token increase.", "conclusion": "Notes Writing enhances iterative RAG by improving context handling and reasoning, offering a scalable and effective solution."}}
{"id": "2505.16928", "pdf": "https://arxiv.org/pdf/2505.16928", "abs": "https://arxiv.org/abs/2505.16928", "authors": ["Bosung Kim", "Prithviraj Ammanabrolu"], "title": "Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "We introduce $\\infty$-THOR, a new framework for long-horizon embodied tasks\nthat advances long-context understanding in embodied AI. $\\infty$-THOR\nprovides: (1) a generation framework for synthesizing scalable, reproducible,\nand unlimited long-horizon trajectories; (2) a novel embodied QA task,\nNeedle(s) in the Embodied Haystack, where multiple scattered clues across\nextended trajectories test agents' long-context reasoning ability; and (3) a\nlong-horizon dataset and benchmark suite featuring complex tasks that span\nhundreds of environment steps, each paired with ground-truth action sequences.\nTo enable this capability, we explore architectural adaptations, including\ninterleaved Goal-State-Action modeling, context extension techniques, and\nContext Parallelism, to equip LLM-based agents for extreme long-context\nreasoning and interaction. Experimental results and analyses highlight the\nchallenges posed by our benchmark and provide insights into training strategies\nand model behaviors under long-horizon conditions. Our work provides a\nfoundation for the next generation of embodied AI systems capable of robust,\nlong-term reasoning and planning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.16365", "pdf": "https://arxiv.org/pdf/2505.16365", "abs": "https://arxiv.org/abs/2505.16365", "authors": ["Manuel Ruiz-Botella", "Marta Sales-Pardo", "Roger Guimer\u00e0"], "title": "A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules", "categories": ["cs.LG", "cs.AI", "physics.comp-ph", "q-bio.QM"], "comment": "28 pages, 10 figures, 4 tables", "summary": "Developing new molecular compounds is crucial to address pressing challenges,\nfrom health to environmental sustainability. However, exploring the molecular\nspace to discover new molecules is difficult due to the vastness of the space.\nHere we introduce CoCoGraph, a collaborative and constrained graph diffusion\nmodel capable of generating molecules that are guaranteed to be chemically\nvalid. Thanks to the constraints built into the model and to the collaborative\nmechanism, CoCoGraph outperforms state-of-the-art approaches on standard\nbenchmarks while requiring up to an order of magnitude fewer parameters.\nAnalysis of 36 chemical properties also demonstrates that CoCoGraph generates\nmolecules with distributions more closely matching real molecules than current\nmodels. Leveraging the model's efficiency, we created a database of 8.2M\nmillion synthetically generated molecules and conducted a Turing-like test with\norganic chemistry experts to further assess the plausibility of the generated\nmolecules, and potential biases and limitations of CoCoGraph.", "AI": {"tldr": "CoCoGraph is a constrained graph diffusion model for generating chemically valid molecules efficiently, outperforming state-of-the-art methods with fewer parameters and closer-to-real molecule distributions.", "motivation": "The vast molecular space makes discovering new compounds challenging, necessitating efficient and valid molecule generation methods.", "method": "CoCoGraph uses a collaborative and constrained graph diffusion model to ensure chemical validity and efficiency.", "result": "It outperforms benchmarks, requires fewer parameters, and generates molecules with distributions closer to real ones. A database of 8.2M synthetic molecules was created.", "conclusion": "CoCoGraph is efficient and effective, validated by expert Turing-like tests, though potential biases and limitations exist."}}
{"id": "2505.16335", "pdf": "https://arxiv.org/pdf/2505.16335", "abs": "https://arxiv.org/abs/2505.16335", "authors": ["Renjie Wei", "Songqiang Xu", "Qingyu Guo", "Meng Li"], "title": "FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual autoregressive (VAR) modeling has marked a paradigm shift in image\ngeneration from next-token prediction to next-scale prediction. VAR predicts a\nset of tokens at each step from coarse to fine scale, leading to better image\nquality and faster inference speed compared to existing diffusion models.\nHowever, the large parameter size and computation cost hinder its deployment on\nedge devices. To reduce the memory and computation cost, we propose FPQVAR, an\nefficient post-training floating-point (FP) quantization framework for VAR\nfeaturing algorithm and hardware co-design. At the algorithm level, we first\nidentify the challenges of quantizing VAR. To address them, we propose Dual\nFormat Quantization for the highly imbalanced input activation. We further\npropose Group-wise Hadamard Transformation and GHT-Aware Learnable\nTransformation to address the time-varying outlier channels. At the hardware\nlevel, we design the first low-bit FP quantizer and multiplier with lookup\ntables on FPGA and propose the first FPGA-based VAR accelerator featuring\nlow-bit FP computation and an elaborate two-level pipeline. Extensive\nexperiments show that compared to the state-of-the-art quantization method, our\nproposed FPQVAR significantly improves Fr\\'echet Inception Distance (FID) from\n10.83 to 3.58, Inception Score (IS) from 175.9 to 241.5 under 4-bit\nquantization. FPQVAR also significantly improves the performance of 6-bit\nquantized VAR, bringing it on par with the FP16 model. Our accelerator on\nAMD-Xilinx VCK190 FPGA achieves a throughput of 1.1 image/s, which is 3.1x\nhigher than the integer-based accelerator. It also demonstrates 3.6x and 2.8x\nhigher energy efficiency compared to the integer-based accelerator and GPU\nbaseline, respectively.", "AI": {"tldr": "FPQVAR is an efficient post-training FP quantization framework for VAR models, improving image quality and reducing computation costs through algorithm-hardware co-design.", "motivation": "The large parameter size and computation cost of VAR models hinder deployment on edge devices, necessitating an efficient quantization solution.", "method": "Proposes Dual Format Quantization, Group-wise Hadamard Transformation, and GHT-Aware Learnable Transformation for activation imbalance and outlier channels. Also designs a low-bit FP quantizer and multiplier with FPGA-based accelerator.", "result": "FPQVAR improves FID from 10.83 to 3.58 and IS from 175.9 to 241.5 under 4-bit quantization, with FPGA accelerator achieving 3.1x higher throughput and better energy efficiency.", "conclusion": "FPQVAR effectively addresses VAR quantization challenges, enabling efficient deployment on edge devices with superior performance and energy efficiency."}}
{"id": "2505.16297", "pdf": "https://arxiv.org/pdf/2505.16297", "abs": "https://arxiv.org/abs/2505.16297", "authors": ["Seongryong Jung", "Suwan Yoon", "DongGeon Kim", "Hwanhee Lee"], "title": "ToDi: Token-wise Distillation via Fine-Grained Divergence Control", "categories": ["cs.CL"], "comment": "13 pages, 7 figures", "summary": "Large language models (LLMs) offer impressive performance but are impractical\nfor resource-constrained deployment due to high latency and energy consumption.\nKnowledge distillation (KD) addresses this by transferring knowledge from a\nlarge teacher to a smaller student model. However, conventional KD, notably\napproaches like Forward KL (FKL) and Reverse KL (RKL), apply uniform divergence\nloss across the entire vocabulary, neglecting token-level prediction\ndiscrepancies. By investigating these representative divergences via gradient\nanalysis, we reveal that FKL boosts underestimated tokens, while RKL suppresses\noverestimated ones, showing their complementary roles. Based on this\nobservation, we propose Token-wise Distillation (ToDi), a novel method that\nadaptively combines FKL and RKL per token using a sigmoid-based weighting\nfunction derived from the teacher-student probability log-ratio. ToDi\ndynamically emphasizes the appropriate divergence for each token, enabling\nprecise distribution alignment. We demonstrate that ToDi consistently\noutperforms recent distillation baselines using uniform or less granular\nstrategies across instruction-following benchmarks. Extensive ablation studies\nand efficiency analysis further validate ToDi's effectiveness and practicality.", "AI": {"tldr": "ToDi, a token-wise distillation method, adaptively combines FKL and RKL for better knowledge transfer from large to small models, outperforming uniform divergence approaches.", "motivation": "Large language models (LLMs) are resource-intensive, and conventional knowledge distillation (KD) methods like FKL and RKL fail to address token-level prediction discrepancies.", "method": "Proposes Token-wise Distillation (ToDi), which dynamically combines FKL and RKL per token using a sigmoid-based weighting function derived from teacher-student probability log-ratios.", "result": "ToDi consistently outperforms uniform or less granular distillation baselines on instruction-following benchmarks.", "conclusion": "ToDi is an effective and practical solution for precise distribution alignment in knowledge distillation."}}
{"id": "2505.16938", "pdf": "https://arxiv.org/pdf/2505.16938", "abs": "https://arxiv.org/abs/2505.16938", "authors": ["NovelSeek Team", "Bo Zhang", "Shiyang Feng", "Xiangchao Yan", "Jiakang Yuan", "Zhiyin Yu", "Xiaohan He", "Songtao Huang", "Shaowei Hou", "Zheng Nie", "Zhilong Wang", "Jinyao Liu", "Runmin Ma", "Tianshuo Peng", "Peng Ye", "Dongzhan Zhou", "Shufei Zhang", "Xiaosong Wang", "Yilan Zhang", "Meng Li", "Zhongying Tu", "Xiangyu Yue", "Wangli Ouyang", "Bowen Zhou", "Lei Bai"], "title": "NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "HomePage: https://alpha-innovator.github.io/NovelSeek-project-page", "summary": "Artificial Intelligence (AI) is accelerating the transformation of scientific\nresearch paradigms, not only enhancing research efficiency but also driving\ninnovation. We introduce NovelSeek, a unified closed-loop multi-agent framework\nto conduct Autonomous Scientific Research (ASR) across various scientific\nresearch fields, enabling researchers to tackle complicated problems in these\nfields with unprecedented speed and precision. NovelSeek highlights three key\nadvantages: 1) Scalability: NovelSeek has demonstrated its versatility across\n12 scientific research tasks, capable of generating innovative ideas to enhance\nthe performance of baseline code. 2) Interactivity: NovelSeek provides an\ninterface for human expert feedback and multi-agent interaction in automated\nend-to-end processes, allowing for the seamless integration of domain expert\nknowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in\nseveral scientific fields with significantly less time cost compared to human\nefforts. For instance, in reaction yield prediction, it increased from 27.6% to\n35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from\n0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation,\nprecision advanced from 78.8% to 81.0% in a mere 30 hours.", "AI": {"tldr": "NovelSeek is a multi-agent AI framework for autonomous scientific research, offering scalability, interactivity, and efficiency across diverse fields.", "motivation": "To enhance research efficiency and innovation by automating complex scientific tasks with AI.", "method": "A closed-loop multi-agent framework (NovelSeek) integrates human feedback and multi-agent interaction for end-to-end automation.", "result": "Improved performance in tasks like reaction yield prediction (27.6% to 35.4%), enhancer activity prediction (0.52 to 0.79), and 2D semantic segmentation (78.8% to 81.0%) with minimal time.", "conclusion": "NovelSeek demonstrates significant potential in accelerating scientific research with AI-driven automation and human-AI collaboration."}}
{"id": "2505.16368", "pdf": "https://arxiv.org/pdf/2505.16368", "abs": "https://arxiv.org/abs/2505.16368", "authors": ["Huanyu Liu", "Jia Li", "Hao Zhu", "Kechi Zhang", "Yihong Dong", "Ge Li"], "title": "SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "How to design reinforcement learning (RL) tasks that effectively unleash the\nreasoning capability of large language models (LLMs) remains an open question.\nExisting RL tasks (e.g., math, programming, and constructing reasoning tasks)\nsuffer from three key limitations: (1) Scalability. They rely heavily on human\nannotation or expensive LLM synthesis to generate sufficient training data. (2)\nVerifiability. LLMs' outputs are hard to verify automatically and reliably. (3)\nControllable Difficulty. Most tasks lack fine-grained difficulty control,\nmaking it hard to train LLMs to develop reasoning ability from easy to hard.\n  To address these limitations, we propose Saturn, a SAT-based RL framework\nthat uses Boolean Satisfiability (SAT) problems to train and evaluate LLM\nreasoning. Saturn enables scalable task construction, rule-based verification,\nand precise difficulty control. Saturn designs a curriculum learning pipeline\nthat continuously improves LLMs' reasoning capability by constructing SAT tasks\nof increasing difficulty and training LLMs from easy to hard. To ensure stable\ntraining, we design a principled mechanism to control difficulty transitions.\n  We introduce Saturn-2.6k, a dataset of 2,660 SAT problems with varying\ndifficulty. It supports the evaluation of how LLM reasoning changes with\nproblem difficulty. We apply Saturn to DeepSeek-R1-Distill-Qwen and obtain\nSaturn-1.5B and Saturn-7B. We achieve several notable results: (1) On SAT\nproblems, Saturn-1.5B and Saturn-7B achieve average pass@3 improvements of\n+14.0 and +28.1, respectively. (2) On math and programming tasks, Saturn-1.5B\nand Saturn-7B improve average scores by +4.9 and +1.8 on benchmarks (e.g.,\nAIME, LiveCodeBench). (3) Compared to the state-of-the-art (SOTA) approach in\nconstructing RL tasks, Saturn achieves further improvements of +8.8%. We\nrelease the source code, data, and models to support future research.", "AI": {"tldr": "Saturn is a SAT-based RL framework for training LLMs, addressing scalability, verifiability, and difficulty control in reasoning tasks. It shows improvements in SAT, math, and programming tasks.", "motivation": "Existing RL tasks for LLMs face scalability, verifiability, and difficulty control issues. Saturn aims to solve these using SAT problems.", "method": "Saturn uses Boolean Satisfiability (SAT) problems for scalable task construction, rule-based verification, and curriculum learning with controlled difficulty transitions.", "result": "Saturn models (1.5B and 7B) improve SAT pass@3 by +14.0 and +28.1, and math/programming scores by +4.9 and +1.8, outperforming SOTA by +8.8%.", "conclusion": "Saturn effectively trains LLMs for reasoning, offering scalable, verifiable, and difficulty-controlled tasks, with demonstrated performance gains."}}
{"id": "2505.16338", "pdf": "https://arxiv.org/pdf/2505.16338", "abs": "https://arxiv.org/abs/2505.16338", "authors": ["Amirreza Mahbod", "Rupert Ecker", "Ramona Woitek"], "title": "Fusion of Foundation and Vision Transformer Model Features for Dermatoscopic Image Classification", "categories": ["cs.CV"], "comment": "6 pages", "summary": "Accurate classification of skin lesions from dermatoscopic images is\nessential for diagnosis and treatment of skin cancer. In this study, we\ninvestigate the utility of a dermatology-specific foundation model, PanDerm, in\ncomparison with two Vision Transformer (ViT) architectures (ViT base and Swin\nTransformer V2 base) for the task of skin lesion classification. Using frozen\nfeatures extracted from PanDerm, we apply non-linear probing with three\ndifferent classifiers, namely, multi-layer perceptron (MLP), XGBoost, and\nTabNet. For the ViT-based models, we perform full fine-tuning to optimize\nclassification performance. Our experiments on the HAM10000 and MSKCC datasets\ndemonstrate that the PanDerm-based MLP model performs comparably to the\nfine-tuned Swin transformer model, while fusion of PanDerm and Swin Transformer\npredictions leads to further performance improvements. Future work will explore\nadditional foundation models, fine-tuning strategies, and advanced fusion\ntechniques.", "AI": {"tldr": "PanDerm, a dermatology-specific foundation model, performs comparably to fine-tuned ViT models for skin lesion classification, with fusion further improving results.", "motivation": "Accurate skin lesion classification is crucial for skin cancer diagnosis and treatment.", "method": "Compare PanDerm with ViT models (ViT base, Swin Transformer V2 base) using frozen features and non-linear probing (MLP, XGBoost, TabNet). ViT models are fine-tuned.", "result": "PanDerm-based MLP matches Swin Transformer performance; fusion of PanDerm and Swin predictions enhances results.", "conclusion": "PanDerm is effective; future work will explore more models, fine-tuning, and fusion techniques."}}
{"id": "2505.16303", "pdf": "https://arxiv.org/pdf/2505.16303", "abs": "https://arxiv.org/abs/2505.16303", "authors": ["Haochen Shi", "Tianshi Zheng", "Weiqi Wang", "Baixuan Xu", "Chunyang Li", "Chunkit Chan", "Tao Fan", "Yangqiu Song", "Qiang Yang"], "title": "INFERENCEDYNAMICS: Efficient Routing Across LLMs through Structured Capability and Knowledge Profiling", "categories": ["cs.CL"], "comment": "17 pages", "summary": "Large Language Model (LLM) routing is a pivotal technique for navigating a\ndiverse landscape of LLMs, aiming to select the best-performing LLMs tailored\nto the domains of user queries, while managing computational resources.\nHowever, current routing approaches often face limitations in scalability when\ndealing with a large pool of specialized LLMs, or in their adaptability to\nextending model scope and evolving capability domains. To overcome those\nchallenges, we propose InferenceDynamics, a flexible and scalable\nmulti-dimensional routing framework by modeling the capability and knowledge of\nmodels. We operate it on our comprehensive dataset RouteMix, and demonstrate\nits effectiveness and generalizability in group-level routing using modern\nbenchmarks including MMLU-Pro, GPQA, BigGenBench, and LiveBench, showcasing its\nability to identify and leverage top-performing models for given tasks, leading\nto superior outcomes with efficient resource utilization. The broader adoption\nof Inference Dynamics can empower users to harness the full specialized\npotential of the LLM ecosystem, and our code will be made publicly available to\nencourage further research.", "AI": {"tldr": "InferenceDynamics is a scalable LLM routing framework that efficiently selects top-performing models for tasks, improving outcomes and resource use.", "motivation": "Current LLM routing lacks scalability and adaptability for large, specialized model pools and evolving domains.", "method": "Proposes InferenceDynamics, a multi-dimensional routing framework modeling model capabilities and knowledge, tested on RouteMix dataset.", "result": "Demonstrates effectiveness in benchmarks like MMLU-Pro, GPQA, BigGenBench, and LiveBench, achieving superior task performance.", "conclusion": "InferenceDynamics enhances LLM ecosystem utilization; code will be public to foster research."}}
{"id": "2505.16944", "pdf": "https://arxiv.org/pdf/2505.16944", "abs": "https://arxiv.org/abs/2505.16944", "authors": ["Yunjia Qi", "Hao Peng", "Xiaozhi Wang", "Amy Xin", "Youfeng Liu", "Bin Xu", "Lei Hou", "Juanzi Li"], "title": "AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated advanced capabilities in\nreal-world agentic applications. Growing research efforts aim to develop\nLLM-based agents to address practical demands, introducing a new challenge:\nagentic scenarios often involve lengthy instructions with complex constraints,\nsuch as extended system prompts and detailed tool specifications. While\nadherence to such instructions is crucial for agentic applications, whether\nLLMs can reliably follow them remains underexplored. In this paper, we\nintroduce AgentIF, the first benchmark for systematically evaluating LLM\ninstruction following ability in agentic scenarios. AgentIF features three key\ncharacteristics: (1) Realistic, constructed from 50 real-world agentic\napplications. (2) Long, averaging 1,723 words with a maximum of 15,630 words.\n(3) Complex, averaging 11.9 constraints per instruction, covering diverse\nconstraint types, such as tool specifications and condition constraints. To\nconstruct AgentIF, we collect 707 human-annotated instructions across 50\nagentic tasks from industrial application agents and open-source agentic\nsystems. For each instruction, we annotate the associated constraints and\ncorresponding evaluation metrics, including code-based evaluation, LLM-based\nevaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically\nevaluate existing advanced LLMs. We observe that current models generally\nperform poorly, especially in handling complex constraint structures and tool\nspecifications. We further conduct error analysis and analytical experiments on\ninstruction length and meta constraints, providing some findings about the\nfailure modes of existing LLMs. We have released the code and data to\nfacilitate future research.", "AI": {"tldr": "AgentIF is a benchmark for evaluating LLMs' ability to follow lengthy, complex instructions in agentic scenarios, revealing poor performance of current models.", "motivation": "To address the underexplored challenge of LLMs reliably adhering to lengthy, complex instructions in agentic applications.", "method": "Developed AgentIF, a benchmark with 707 human-annotated instructions from 50 real-world agentic tasks, featuring long, complex constraints. Evaluated LLMs using code-based, LLM-based, and hybrid metrics.", "result": "Current LLMs perform poorly, especially with complex constraints and tool specifications. Error analysis highlights failure modes.", "conclusion": "AgentIF provides a systematic evaluation tool, revealing limitations of existing LLMs and encouraging future research."}}
{"id": "2505.16386", "pdf": "https://arxiv.org/pdf/2505.16386", "abs": "https://arxiv.org/abs/2505.16386", "authors": ["Ahmed K. Kadhim", "Lei Jiao", "Rishad Shafik", "Ole-Christoffer Granmo"], "title": "Omni TM-AE: A Scalable and Interpretable Embedding Model Using the Full Tsetlin Machine State Space", "categories": ["cs.LG"], "comment": null, "summary": "The increasing complexity of large-scale language models has amplified\nconcerns regarding their interpretability and reusability. While traditional\nembedding models like Word2Vec and GloVe offer scalability, they lack\ntransparency and often behave as black boxes. Conversely, interpretable models\nsuch as the Tsetlin Machine (TM) have shown promise in constructing explainable\nlearning systems, though they previously faced limitations in scalability and\nreusability. In this paper, we introduce Omni Tsetlin Machine AutoEncoder (Omni\nTM-AE), a novel embedding model that fully exploits the information contained\nin the TM's state matrix, including literals previously excluded from clause\nformation. This method enables the construction of reusable, interpretable\nembeddings through a single training phase. Extensive experiments across\nsemantic similarity, sentiment classification, and document clustering tasks\nshow that Omni TM-AE performs competitively with and often surpasses mainstream\nembedding models. These results demonstrate that it is possible to balance\nperformance, scalability, and interpretability in modern Natural Language\nProcessing (NLP) systems without resorting to opaque architectures.", "AI": {"tldr": "Omni TM-AE is a new embedding model combining interpretability and scalability, outperforming traditional models in NLP tasks.", "motivation": "Addressing the lack of transparency and reusability in large-scale language models while maintaining performance.", "method": "Introduces Omni TM-AE, leveraging the Tsetlin Machine's state matrix for reusable, interpretable embeddings in one training phase.", "result": "Competes with or surpasses mainstream models in semantic similarity, sentiment classification, and document clustering.", "conclusion": "Shows that performance, scalability, and interpretability can coexist in NLP without opaque architectures."}}
{"id": "2505.16360", "pdf": "https://arxiv.org/pdf/2505.16360", "abs": "https://arxiv.org/abs/2505.16360", "authors": ["Estelle Chigot", "Dennis G. Wilson", "Meriem Ghrib", "Thomas Oberlin"], "title": "Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation", "categories": ["cs.CV", "cs.LG", "68T45 (Primary) 68T10, 68T07 (Secondary)", "F.1.2; F.1.4"], "comment": "Under review", "summary": "Semantic segmentation models trained on synthetic data often perform poorly\non real-world images due to domain gaps, particularly in adverse conditions\nwhere labeled data is scarce. Yet, recent foundation models enable to generate\nrealistic images without any training. This paper proposes to leverage such\ndiffusion models to improve the performance of vision models when learned on\nsynthetic data. We introduce two novel techniques for semantically consistent\nstyle transfer using diffusion models: Class-wise Adaptive Instance\nNormalization and Cross-Attention (CACTI) and its extension with selective\nattention Filtering (CACTIF). CACTI applies statistical normalization\nselectively based on semantic classes, while CACTIF further filters\ncross-attention maps based on feature similarity, preventing artifacts in\nregions with weak cross-attention correspondences. Our methods transfer style\ncharacteristics while preserving semantic boundaries and structural coherence,\nunlike approaches that apply global transformations or generate content without\nconstraints. Experiments using GTA5 as source and Cityscapes/ACDC as target\ndomains show that our approach produces higher quality images with lower FID\nscores and better content preservation. Our work demonstrates that class-aware\ndiffusion-based style transfer effectively bridges the synthetic-to-real domain\ngap even with minimal target domain data, advancing robust perception systems\nfor challenging real-world applications. The source code is available at:\nhttps://github.com/echigot/cactif.", "AI": {"tldr": "The paper introduces CACTI and CACTIF, diffusion-based techniques for semantically consistent style transfer to bridge the synthetic-to-real domain gap in semantic segmentation.", "motivation": "Addressing the poor performance of models trained on synthetic data in real-world scenarios due to domain gaps, especially with scarce labeled data.", "method": "Proposes Class-wise Adaptive Instance Normalization and Cross-Attention (CACTI) and its extension with selective attention Filtering (CACTIF) for style transfer.", "result": "Achieves higher quality images with lower FID scores and better content preservation compared to global transformations.", "conclusion": "Demonstrates that class-aware diffusion-based style transfer effectively bridges the domain gap, advancing robust perception systems."}}
{"id": "2505.16307", "pdf": "https://arxiv.org/pdf/2505.16307", "abs": "https://arxiv.org/abs/2505.16307", "authors": ["Chenzhuo Zhao", "Ziqian Liu", "Xingda Wang", "Junting Lu", "Chaoyi Ruan"], "title": "PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Prompt optimization offers a practical and broadly applicable alternative to\nfine-tuning for improving large language model (LLM) performance. However,\nexisting methods often rely on costly output generation, self-critiquing\nabilities, or human-annotated preferences, which limit their scalability,\nespecially for smaller or non-instruction-tuned models. We introduce PMPO\n(Probabilistic Metric Prompt Optimization), a unified framework that refines\nprompts using token-level cross-entropy loss as a direct, lightweight\nevaluation signal. PMPO identifies low-quality prompt segments by masking and\nmeasuring their impact on loss, then rewrites and selects improved variants by\nminimizing loss over positive and negative examples. Unlike prior methods, it\nrequires no output sampling or human evaluation during optimization, relying\nonly on forward passes and log-likelihoods. PMPO supports both supervised and\npreference-based tasks through a closely aligned loss-based evaluation\nstrategy. Experiments show that PMPO consistently outperforms prior methods\nacross model sizes and tasks: it achieves the highest average accuracy on BBH,\nperforms strongly on GSM8K and AQUA-RAT, and improves AlpacaEval 2.0 win rates\nby over 19 points. These results highlight PMPO's effectiveness, efficiency,\nand broad applicability.", "AI": {"tldr": "PMPO is a prompt optimization framework using token-level loss to improve LLM performance without costly output generation or human input, outperforming prior methods.", "motivation": "Existing prompt optimization methods are limited by scalability due to reliance on costly output generation or human preferences, especially for smaller models.", "method": "PMPO refines prompts using token-level cross-entropy loss, identifies low-quality segments via masking, and rewrites them by minimizing loss over examples.", "result": "PMPO outperforms prior methods across tasks, achieving high accuracy on BBH, GSM8K, AQUA-RAT, and improving AlpacaEval 2.0 win rates by 19+ points.", "conclusion": "PMPO is effective, efficient, and broadly applicable for prompt optimization without needing output sampling or human evaluation."}}
{"id": "2505.16978", "pdf": "https://arxiv.org/pdf/2505.16978", "abs": "https://arxiv.org/abs/2505.16978", "authors": ["Weizhi Tang", "Yixuan Li", "Chris Sypherd", "Elizabeth Polgreen", "Vaishak Belle"], "title": "HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation", "categories": ["cs.AI", "cs.PL"], "comment": "Accepted to ACL 2025 Findings. Code available at\n  https://github.com/RutaTang/HyGenar", "summary": "Grammar plays a critical role in natural language processing and text/code\ngeneration by enabling the definition of syntax, the creation of parsers, and\nguiding structured outputs. Although large language models (LLMs) demonstrate\nimpressive capabilities across domains, their ability to infer and generate\ngrammars has not yet been thoroughly explored. In this paper, we aim to study\nand improve the ability of LLMs for few-shot grammar generation, where grammars\nare inferred from sets of a small number of positive and negative examples and\ngenerated in Backus-Naur Form. To explore this, we introduced a novel dataset\ncomprising 540 structured grammar generation challenges, devised 6 metrics, and\nevaluated 8 various LLMs against it. Our findings reveal that existing LLMs\nperform sub-optimally in grammar generation. To address this, we propose an\nLLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar\ngeneration. HyGenar achieves substantial improvements in both the syntactic and\nsemantic correctness of generated grammars across LLMs.", "AI": {"tldr": "The paper explores LLMs' ability to generate grammars from few examples, introduces a dataset and metrics, and proposes HyGenar, a hybrid genetic algorithm, to improve grammar generation.", "motivation": "To study and enhance LLMs' capability in few-shot grammar generation, as their potential in this area is underexplored.", "method": "Introduced a dataset of 540 grammar challenges, devised 6 metrics, and evaluated 8 LLMs. Proposed HyGenar, an LLM-driven hybrid genetic algorithm.", "result": "Existing LLMs perform poorly in grammar generation. HyGenar significantly improves syntactic and semantic correctness.", "conclusion": "HyGenar effectively enhances LLMs' grammar generation, addressing their current limitations."}}
{"id": "2505.16400", "pdf": "https://arxiv.org/pdf/2505.16400", "abs": "https://arxiv.org/abs/2505.16400", "authors": ["Yang Chen", "Zhuolin Yang", "Zihan Liu", "Chankyu Lee", "Peng Xu", "Mohammad Shoeybi", "Bryan Catanzaro", "Wei Ping"], "title": "AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "We release the model at:\n  https://huggingface.co/nvidia/AceReason-Nemotron-14B", "summary": "Despite recent progress in large-scale reinforcement learning (RL) for\nreasoning, the training recipe for building high-performing reasoning models\nremains elusive. Key implementation details of frontier models, such as\nDeepSeek-R1, including data curation strategies and RL training recipe, are\noften omitted. Moreover, recent research indicates distillation remains more\neffective than RL for smaller models. In this work, we demonstrate that\nlarge-scale RL can significantly enhance the reasoning capabilities of strong,\nsmall- and mid-sized models, achieving results that surpass those of\nstate-of-the-art distillation-based models. We systematically study the RL\ntraining process through extensive ablations and propose a simple yet effective\napproach: first training on math-only prompts, then on code-only prompts.\nNotably, we find that math-only RL not only significantly enhances the\nperformance of strong distilled models on math benchmarks (e.g., +14.6% /\n+17.2% on AIME 2025 for the 7B / 14B models), but also code reasoning tasks\n(e.g., +6.8% / +5.8% on LiveCodeBench for the 7B / 14B models). In addition,\nextended code-only RL iterations further improve performance on code benchmarks\nwith minimal or no degradation in math results. We develop a robust data\ncuration pipeline to collect challenging prompts with high-quality, verifiable\nanswers and test cases to enable verification-based RL across both domains.\nFinally, we identify key experimental insights, including curriculum learning\nwith progressively increasing response lengths and the stabilizing effect of\non-policy parameter updates. We find that RL not only elicits the foundational\nreasoning capabilities acquired during pretraining and supervised fine-tuning\n(e.g., distillation), but also pushes the limits of the model's reasoning\nability, enabling it to solve problems that were previously unsolvable.", "AI": {"tldr": "Large-scale RL enhances reasoning in small/mid-sized models, outperforming distillation. Math-only RL boosts math and code performance, while code-only RL further improves code tasks. Key insights include curriculum learning and stable on-policy updates.", "motivation": "Address the lack of clear training recipes for high-performing reasoning models and the omission of key details in frontier models like DeepSeek-R1.", "method": "Train models sequentially on math-only and code-only prompts, using a robust data curation pipeline for high-quality prompts and verification-based RL.", "result": "Math-only RL improves math benchmarks (+14.6%/17.2%) and code tasks (+6.8%/5.8%). Code-only RL further enhances code performance without degrading math results.", "conclusion": "RL unlocks foundational reasoning capabilities and extends model limits, solving previously unsolvable problems."}}
{"id": "2505.16372", "pdf": "https://arxiv.org/pdf/2505.16372", "abs": "https://arxiv.org/abs/2505.16372", "authors": ["Feng Liu", "Bingyu Nan", "Xuezhong Qian", "Xiaolan Fu"], "title": "Temporal and Spatial Feature Fusion Framework for Dynamic Micro Expression Recognition", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages", "summary": "When emotions are repressed, an individual's true feelings may be revealed\nthrough micro-expressions. Consequently, micro-expressions are regarded as a\ngenuine source of insight into an individual's authentic emotions. However, the\ntransient and highly localised nature of micro-expressions poses a significant\nchallenge to their accurate recognition, with the accuracy rate of\nmicro-expression recognition being as low as 50%, even for professionals. In\norder to address these challenges, it is necessary to explore the field of\ndynamic micro expression recognition (DMER) using multimodal fusion techniques,\nwith special attention to the diverse fusion of temporal and spatial modal\nfeatures. In this paper, we propose a novel Temporal and Spatial feature Fusion\nframework for DMER (TSFmicro). This framework integrates a Retention Network\n(RetNet) and a transformer-based DMER network, with the objective of efficient\nmicro-expression recognition through the capture and fusion of temporal and\nspatial relations. Meanwhile, we propose a novel parallel time-space fusion\nmethod from the perspective of modal fusion, which fuses spatio-temporal\ninformation in high-dimensional feature space, resulting in complementary\n\"where-how\" relationships at the semantic level and providing richer semantic\ninformation for the model. The experimental results demonstrate the superior\nperformance of the TSFmicro method in comparison to other contemporary\nstate-of-the-art methods. This is evidenced by its effectiveness on three\nwell-recognised micro-expression datasets.", "AI": {"tldr": "The paper proposes TSFmicro, a framework for dynamic micro-expression recognition (DMER) using multimodal fusion of temporal and spatial features, achieving superior performance on benchmark datasets.", "motivation": "Micro-expressions reveal true emotions but are hard to recognize due to their transient nature. Current recognition accuracy is low (~50%), necessitating improved methods.", "method": "TSFmicro integrates a Retention Network (RetNet) and a transformer-based DMER network, fusing temporal and spatial features in parallel for richer semantic information.", "result": "TSFmicro outperforms state-of-the-art methods on three benchmark micro-expression datasets.", "conclusion": "The proposed framework effectively addresses DMER challenges by leveraging multimodal fusion, enhancing recognition accuracy."}}
{"id": "2505.16325", "pdf": "https://arxiv.org/pdf/2505.16325", "abs": "https://arxiv.org/abs/2505.16325", "authors": ["Yuyang Jiang", "Chacha Chen", "Shengyuan Wang", "Feng Li", "Zecong Tang", "Benjamin M. Mervak", "Lydia Chelala", "Christopher M Straus", "Reve Chahine", "Samuel G. Armato III", "Chenhao Tan"], "title": "CLEAR: A Clinically-Grounded Tabular Framework for Radiology Report Evaluation", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "18 pages, 4 figures", "summary": "Existing metrics often lack the granularity and interpretability to capture\nnuanced clinical differences between candidate and ground-truth radiology\nreports, resulting in suboptimal evaluation. We introduce a Clinically-grounded\ntabular framework with Expert-curated labels and Attribute-level comparison for\nRadiology report evaluation (CLEAR). CLEAR not only examines whether a report\ncan accurately identify the presence or absence of medical conditions, but also\nassesses whether it can precisely describe each positively identified condition\nacross five key attributes: first occurrence, change, severity, descriptive\nlocation, and recommendation. Compared to prior works, CLEAR's\nmulti-dimensional, attribute-level outputs enable a more comprehensive and\nclinically interpretable evaluation of report quality. Additionally, to measure\nthe clinical alignment of CLEAR, we collaborate with five board-certified\nradiologists to develop CLEAR-Bench, a dataset of 100 chest X-ray reports from\nMIMIC-CXR, annotated across 6 curated attributes and 13 CheXpert conditions.\nOur experiments show that CLEAR achieves high accuracy in extracting clinical\nattributes and provides automated metrics that are strongly aligned with\nclinical judgment.", "AI": {"tldr": "CLEAR introduces a clinically-grounded framework for evaluating radiology reports with expert-curated labels and attribute-level comparisons, outperforming existing metrics.", "motivation": "Existing metrics lack granularity and interpretability for nuanced clinical differences in radiology reports, leading to suboptimal evaluation.", "method": "CLEAR evaluates reports by assessing the presence/absence of conditions and their description across five key attributes. It also introduces CLEAR-Bench, a dataset annotated by radiologists.", "result": "CLEAR achieves high accuracy in extracting clinical attributes and provides metrics strongly aligned with clinical judgment.", "conclusion": "CLEAR offers a comprehensive, clinically interpretable evaluation of radiology report quality, improving upon prior methods."}}
{"id": "2505.16979", "pdf": "https://arxiv.org/pdf/2505.16979", "abs": "https://arxiv.org/abs/2505.16979", "authors": ["Zhenkun Li", "Lingyao Li", "Shuhang Lin", "Yongfeng Zhang"], "title": "Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Single-agent LLMs hit hard limits--finite context, role overload, and brittle\ndomain transfer. Conventional multi-agent fixes soften those edges yet expose\nfresh pains: ill-posed decompositions, fuzzy contracts, and verification\noverhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a\nframework that converts domain priors into an algorithmic blueprint hierarchy,\nin which tasks are recursively split into typed, controller-mediated subtasks,\neach solved zero-shot or with the lightest viable boost (e.g.,\nchain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch\ntheorem, KtR trades the chase for a universal prompt for disciplined\ndecomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents\nraise accuracy from 3% zero-shot to 95% on size-5 instances after patching a\nsingle bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a\nsix-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15,\nversus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation\nthus turns modest models into reliable collaborators--no ever-larger monoliths\nrequired.", "AI": {"tldr": "KtR framework improves multi-agent LLM performance by decomposing tasks hierarchically, using domain priors and minimal boosts, achieving high accuracy on complex problems.", "motivation": "Single-agent LLMs face limits like finite context and brittle domain transfer, while multi-agent approaches introduce issues like fuzzy contracts. KtR addresses these by leveraging domain priors for structured decomposition.", "method": "KtR converts domain priors into a hierarchical blueprint, recursively splitting tasks into typed subtasks with minimal boosts (e.g., chain-of-thought). It avoids universal prompts for disciplined decomposition.", "result": "On Knapsack (3-8 items), accuracy rose from 3% to 95% for size-5 instances. On Task-Assignment (6-15 jobs), accuracy reached 100% for size 10 and 84% for sizes 13-15, versus 11% zero-shot.", "conclusion": "KtR enables modest models to perform reliably through algorithm-aware decomposition and targeted augmentation, eliminating the need for larger monolithic models."}}
{"id": "2505.16401", "pdf": "https://arxiv.org/pdf/2505.16401", "abs": "https://arxiv.org/abs/2505.16401", "authors": ["Xiaoqing Zhang", "Huabin Zheng", "Ang Lv", "Yuhan Liu", "Zirui Song", "Flood Sung", "Xiuying Chen", "Rui Yan"], "title": "Divide-Fuse-Conquer: Eliciting \"Aha Moments\" in Multi-Scenario Games", "categories": ["cs.LG"], "comment": "25 pages, 13 figures, and 8 tables", "summary": "Large language models (LLMs) have been observed to suddenly exhibit advanced\nreasoning abilities during reinforcement learning (RL), resembling an ``aha\nmoment'' triggered by simple outcome-based rewards. While RL has proven\neffective in eliciting such breakthroughs in tasks involving mathematics,\ncoding, and vision, it faces significant challenges in multi-scenario games.\nThe diversity of game rules, interaction modes, and environmental complexities\noften leads to policies that perform well in one scenario but fail to\ngeneralize to others. Simply combining multiple scenarios during training\nintroduces additional challenges, such as training instability and poor\nperformance. To overcome these challenges, we propose Divide-Fuse-Conquer, a\nframework designed to enhance generalization in multi-scenario RL. This\napproach starts by heuristically grouping games based on characteristics such\nas rules and difficulties. Specialized models are then trained for each group\nto excel at games in the group is what we refer to as the divide step. Next, we\nfuse model parameters from different groups as a new model, and continue\ntraining it for multiple groups, until the scenarios in all groups are\nconquered. Experiments across 18 TextArena games show that Qwen2.5-32B-Align\ntrained with the Divide-Fuse-Conquer strategy reaches a performance level\ncomparable to Claude3.5, achieving 7 wins and 4 draws. We hope our approach can\ninspire future research on using reinforcement learning to improve the\ngeneralization of LLMs.", "AI": {"tldr": "The paper introduces Divide-Fuse-Conquer, a framework to improve generalization in multi-scenario RL for LLMs, achieving competitive performance in 18 TextArena games.", "motivation": "Addressing the challenge of RL in multi-scenario games where policies often fail to generalize due to diverse rules and complexities.", "method": "Divide-Fuse-Conquer: grouping games by characteristics, training specialized models per group, fusing parameters, and continuing training for generalization.", "result": "Qwen2.5-32B-Align trained with this method matches Claude3.5's performance, with 7 wins and 4 draws in TextArena.", "conclusion": "The framework effectively enhances generalization in multi-scenario RL, inspiring future research on RL for LLMs."}}
{"id": "2505.16376", "pdf": "https://arxiv.org/pdf/2505.16376", "abs": "https://arxiv.org/abs/2505.16376", "authors": ["Zijia Lu", "A S M Iftekhar", "Gaurav Mittal", "Tianjian Meng", "Xiawei Wang", "Cheng Zhao", "Rohith Kukkala", "Ehsan Elhamifar", "Mei Chen"], "title": "DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by CVPR 2025", "summary": "Long Video Temporal Grounding (LVTG) aims at identifying specific moments\nwithin lengthy videos based on user-provided text queries for effective content\nretrieval. The approach taken by existing methods of dividing video into clips\nand processing each clip via a full-scale expert encoder is challenging to\nscale due to prohibitive computational costs of processing a large number of\nclips in long videos. To address this issue, we introduce DeCafNet, an approach\nemploying ``delegate-and-conquer'' strategy to achieve computation efficiency\nwithout sacrificing grounding performance. DeCafNet introduces a sidekick\nencoder that performs dense feature extraction over all video clips in a\nresource-efficient manner, while generating a saliency map to identify the most\nrelevant clips for full processing by the expert encoder. To effectively\nleverage features from sidekick and expert encoders that exist at different\ntemporal resolutions, we introduce DeCaf-Grounder, which unifies and refines\nthem via query-aware temporal aggregation and multi-scale temporal refinement\nfor accurate grounding. Experiments on two LTVG benchmark datasets demonstrate\nthat DeCafNet reduces computation by up to 47\\% while still outperforming\nexisting methods, establishing a new state-of-the-art for LTVG in terms of both\nefficiency and performance. Our code is available at\nhttps://github.com/ZijiaLewisLu/CVPR2025-DeCafNet.", "AI": {"tldr": "DeCafNet introduces a delegate-and-conquer strategy for efficient long video temporal grounding, reducing computation by 47% while outperforming existing methods.", "motivation": "Existing methods for LVTG are computationally expensive due to full-scale processing of video clips.", "method": "DeCafNet uses a sidekick encoder for efficient feature extraction and saliency mapping, followed by query-aware temporal aggregation and multi-scale refinement.", "result": "DeCafNet achieves state-of-the-art performance with 47% less computation on benchmark datasets.", "conclusion": "DeCafNet balances efficiency and accuracy, setting a new standard for LVTG."}}
{"id": "2505.16330", "pdf": "https://arxiv.org/pdf/2505.16330", "abs": "https://arxiv.org/abs/2505.16330", "authors": ["Wenqing Wu", "Chengzhi Zhang", "Tong Bao", "Yi Zhao"], "title": "SC4ANM: Identifying Optimal Section Combinations for Automated Novelty Prediction in Academic Papers", "categories": ["cs.CL", "cs.AI", "cs.DL"], "comment": null, "summary": "Novelty is a core component of academic papers, and there are multiple\nperspectives on the assessment of novelty. Existing methods often focus on word\nor entity combinations, which provide limited insights. The content related to\na paper's novelty is typically distributed across different core sections,\ne.g., Introduction, Methodology and Results. Therefore, exploring the optimal\ncombination of sections for evaluating the novelty of a paper is important for\nadvancing automated novelty assessment. In this paper, we utilize different\ncombinations of sections from academic papers as inputs to drive language\nmodels to predict novelty scores. We then analyze the results to determine the\noptimal section combinations for novelty score prediction. We first employ\nnatural language processing techniques to identify the sectional structure of\nacademic papers, categorizing them into introduction, methods, results, and\ndiscussion (IMRaD). Subsequently, we used different combinations of these\nsections (e.g., introduction and methods) as inputs for pretrained language\nmodels (PLMs) and large language models (LLMs), employing novelty scores\nprovided by human expert reviewers as ground truth labels to obtain prediction\nresults. The results indicate that using introduction, results and discussion\nis most appropriate for assessing the novelty of a paper, while the use of the\nentire text does not yield significant results. Furthermore, based on the\nresults of the PLMs and LLMs, the introduction and results appear to be the\nmost important section for the task of novelty score prediction. The code and\ndataset for this paper can be accessed at\nhttps://github.com/njust-winchy/SC4ANM.", "AI": {"tldr": "The paper explores optimal section combinations in academic papers for novelty assessment using language models, finding introduction, results, and discussion most effective.", "motivation": "Existing novelty assessment methods focus on limited word or entity combinations, while novelty content is distributed across sections. Identifying optimal section combinations can improve automated novelty evaluation.", "method": "Uses NLP to categorize papers into IMRaD sections, then tests different section combinations as inputs for PLMs and LLMs, comparing predictions to human novelty scores.", "result": "Introduction, results, and discussion are optimal for novelty assessment; entire text is ineffective. Introduction and results are most critical.", "conclusion": "Optimal section combinations improve novelty prediction; introduction and results are key. Code and dataset are publicly available."}}
{"id": "2505.16982", "pdf": "https://arxiv.org/pdf/2505.16982", "abs": "https://arxiv.org/abs/2505.16982", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "categories": ["cs.AI", "physics.med-ph"], "comment": null, "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "AI": {"tldr": "The paper proposes causal LLM agents for biomedicine, integrating multimodal data and intervention-based reasoning to address the lack of true causal understanding in current LLMs.", "motivation": "Current LLMs rely on correlations, not causal understanding, limiting their biomedical applications. The paper aims to bridge this gap by developing causal LLM agents.", "method": "The approach involves integrating multimodal data (text, images, genomics), designing safe agentic frameworks, creating causal benchmarks, and combining LLMs with structured knowledge and causal tools.", "result": "Potential outcomes include transformative applications like accelerated drug discovery and personalized medicine through automated hypothesis generation and patient-specific models.", "conclusion": "The research agenda calls for interdisciplinary collaboration to develop reliable AI partners for biomedical progress by merging causal concepts with foundation models."}}
{"id": "2505.16403", "pdf": "https://arxiv.org/pdf/2505.16403", "abs": "https://arxiv.org/abs/2505.16403", "authors": ["Huazi Pan", "Yanjun Zhang", "Leo Yu Zhang", "Scott Adams", "Abbas Kouzani", "Suiyang Khoo"], "title": "Performance Guaranteed Poisoning Attacks in Federated Learning: A Sliding Mode Approach", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Manipulation of local training data and local updates, i.e., the poisoning\nattack, is the main threat arising from the collaborative nature of the\nfederated learning (FL) paradigm. Most existing poisoning attacks aim to\nmanipulate local data/models in a way that causes denial-of-service (DoS)\nissues. In this paper, we introduce a novel attack method, named Federated\nLearning Sliding Attack (FedSA) scheme, aiming at precisely introducing the\nextent of poisoning in a subtle controlled manner. It operates with a\npredefined objective, such as reducing global model's prediction accuracy by\n10\\%. FedSA integrates robust nonlinear control-Sliding Mode Control (SMC)\ntheory with model poisoning attacks. It can manipulate the updates from\nmalicious clients to drive the global model towards a compromised state,\nachieving this at a controlled and inconspicuous rate. Additionally, leveraging\nthe robust control properties of FedSA allows precise control over the\nconvergence bounds, enabling the attacker to set the global accuracy of the\npoisoned model to any desired level. Experimental results demonstrate that\nFedSA can accurately achieve a predefined global accuracy with fewer malicious\nclients while maintaining a high level of stealth and adjustable learning\nrates.", "AI": {"tldr": "FedSA is a novel poisoning attack in federated learning using Sliding Mode Control to precisely manipulate global model accuracy with stealth and control.", "motivation": "Addressing the need for subtle, controlled poisoning attacks in federated learning, beyond traditional DoS-focused methods.", "method": "Integrates Sliding Mode Control (SMC) with model poisoning to manipulate updates and control convergence bounds.", "result": "FedSA achieves predefined global accuracy with fewer malicious clients, maintaining stealth and adjustable rates.", "conclusion": "FedSA offers a precise, controlled, and stealthy approach to poisoning attacks in federated learning."}}
{"id": "2505.16384", "pdf": "https://arxiv.org/pdf/2505.16384", "abs": "https://arxiv.org/abs/2505.16384", "authors": ["Haoming Huang", "Musen Zhang", "Jianxin Yang", "Zhen Li", "Jinkai Li", "Yao Guo"], "title": "MAGE: A Multi-task Architecture for Gaze Estimation with an Efficient Calibration Module", "categories": ["cs.CV", "cs.HC"], "comment": "Under review", "summary": "Eye gaze can provide rich information on human psychological activities, and\nhas garnered significant attention in the field of Human-Robot Interaction\n(HRI). However, existing gaze estimation methods merely predict either the gaze\ndirection or the Point-of-Gaze (PoG) on the screen, failing to provide\nsufficient information for a comprehensive six Degree-of-Freedom (DoF) gaze\nanalysis in 3D space. Moreover, the variations of eye shape and structure among\nindividuals also impede the generalization capability of these methods. In this\nstudy, we propose MAGE, a Multi-task Architecture for Gaze Estimation with an\nefficient calibration module, to predict the 6-DoF gaze information that is\napplicable for the real-word HRI. Our basic model encodes both the directional\nand positional features from facial images, and predicts gaze results with\ndedicated information flow and multiple decoders. To reduce the impact of\nindividual variations, we propose a novel calibration module, namely\nEasy-Calibration, to fine-tune the basic model with subject-specific data,\nwhich is efficient to implement without the need of a screen. Experimental\nresults demonstrate that our method achieves state-of-the-art performance on\nthe public MPIIFaceGaze, EYEDIAP, and our built IMRGaze datasets.", "AI": {"tldr": "MAGE is a multi-task architecture for 6-DoF gaze estimation in HRI, addressing limitations of existing methods by combining directional and positional features and introducing an efficient calibration module.", "motivation": "Existing gaze estimation methods lack comprehensive 6-DoF analysis and struggle with individual variations, limiting their applicability in real-world HRI.", "method": "MAGE encodes directional and positional features from facial images, uses dedicated information flow and multiple decoders, and includes an Easy-Calibration module for subject-specific fine-tuning.", "result": "Achieves state-of-the-art performance on MPIIFaceGaze, EYEDIAP, and IMRGaze datasets.", "conclusion": "MAGE provides a robust solution for 6-DoF gaze estimation in HRI, overcoming individual variations and calibration challenges."}}
{"id": "2505.16348", "pdf": "https://arxiv.org/pdf/2505.16348", "abs": "https://arxiv.org/abs/2505.16348", "authors": ["Taeyoon Kwon", "Dongwook Choi", "Sunghwan Kim", "Hyojun Kim", "Seungjun Moon", "Beong-woo Kwak", "Kuan-Hao Huang", "Jinyoung Yeo"], "title": "Embodied Agents Meet Personalization: Exploring Memory Utilization for Personalized Assistance", "categories": ["cs.CL"], "comment": "Work in progress", "summary": "Embodied agents empowered by large language models (LLMs) have shown strong\nperformance in household object rearrangement tasks. However, these tasks\nprimarily focus on single-turn interactions with simplified instructions, which\ndo not truly reflect the challenges of providing meaningful assistance to\nusers. To provide personalized assistance, embodied agents must understand the\nunique semantics that users assign to the physical world (e.g., favorite cup,\nbreakfast routine) by leveraging prior interaction history to interpret\ndynamic, real-world instructions. Yet, the effectiveness of embodied agents in\nutilizing memory for personalized assistance remains largely underexplored. To\naddress this gap, we present MEMENTO, a personalized embodied agent evaluation\nframework designed to comprehensively assess memory utilization capabilities to\nprovide personalized assistance. Our framework consists of a two-stage memory\nevaluation process design that enables quantifying the impact of memory\nutilization on task performance. This process enables the evaluation of agents'\nunderstanding of personalized knowledge in object rearrangement tasks by\nfocusing on its role in goal interpretation: (1) the ability to identify target\nobjects based on personal meaning (object semantics), and (2) the ability to\ninfer object-location configurations from consistent user patterns, such as\nroutines (user patterns). Our experiments across various LLMs reveal\nsignificant limitations in memory utilization, with even frontier models like\nGPT-4o experiencing a 30.5% performance drop when required to reference\nmultiple memories, particularly in tasks involving user patterns. These\nfindings, along with our detailed analyses and case studies, provide valuable\ninsights for future research in developing more effective personalized embodied\nagents. Project website: https://connoriginal.github.io/MEMENTO", "AI": {"tldr": "MEMENTO is a framework to evaluate embodied agents' memory utilization for personalized assistance, revealing limitations in current LLMs like GPT-4o.", "motivation": "Current embodied agents lack effective memory utilization for personalized assistance, especially in dynamic, real-world tasks.", "method": "MEMENTO uses a two-stage memory evaluation process to assess agents' understanding of personalized knowledge in object rearrangement tasks.", "result": "Experiments show significant performance drops (30.5%) in LLMs like GPT-4o when referencing multiple memories, particularly in tasks involving user patterns.", "conclusion": "The findings highlight the need for improved memory utilization in embodied agents for personalized assistance, guiding future research."}}
{"id": "2502.15401", "pdf": "https://arxiv.org/pdf/2502.15401", "abs": "https://arxiv.org/abs/2502.15401", "authors": ["Xuetao Ma", "Wenbin Jiang", "Hua Huang"], "title": "Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In-context learning (ICL) can significantly enhance the complex reasoning\ncapabilities of large language models (LLMs), with the key lying in the\nselection and ordering of demonstration examples. Previous methods typically\nrelied on simple features to measure the relevance between examples. We argue\nthat these features are not sufficient to reflect the intrinsic connections\nbetween examples. In this study, we propose a curriculum ICL strategy guided by\nproblem-solving logic. We select demonstration examples by analyzing the\nproblem-solving logic and order them based on curriculum learning.\nSpecifically, we constructed a problem-solving logic instruction set based on\nthe BREAK dataset and fine-tuned a language model to analyze the\nproblem-solving logic of examples. Subsequently, we selected appropriate\ndemonstration examples based on problem-solving logic and assessed their\ndifficulty according to the number of problem-solving steps. In accordance with\nthe principles of curriculum learning, we ordered the examples from easy to\nhard to serve as contextual prompts. Experimental results on multiple\nbenchmarks indicate that our method outperforms previous ICL approaches in\nterms of performance and efficiency, effectively enhancing the complex\nreasoning capabilities of LLMs. Our project will be publicly available\nsubsequently.", "AI": {"tldr": "The paper introduces a curriculum ICL strategy for LLMs, focusing on problem-solving logic for example selection and ordering, outperforming previous methods.", "motivation": "Existing ICL methods rely on simple features for example relevance, which fail to capture intrinsic connections, limiting reasoning capabilities.", "method": "Proposes a curriculum ICL strategy: selects examples via problem-solving logic analysis, orders them from easy to hard using curriculum learning, and fine-tunes a model for logic assessment.", "result": "Outperforms prior ICL methods in performance and efficiency, enhancing LLMs' complex reasoning.", "conclusion": "The curriculum ICL strategy, guided by problem-solving logic, effectively improves LLMs' reasoning, with plans for public release."}}
{"id": "2505.16446", "pdf": "https://arxiv.org/pdf/2505.16446", "abs": "https://arxiv.org/abs/2505.16446", "authors": ["Zhaoxin Wang", "Handing Wang", "Cong Tian", "Yaochu Jin"], "title": "Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Multimodal large language models (MLLMs) enable powerful cross-modal\nreasoning capabilities. However, the expanded input space introduces new attack\nsurfaces. Previous jailbreak attacks often inject malicious instructions from\ntext into less aligned modalities, such as vision. As MLLMs increasingly\nincorporate cross-modal consistency and alignment mechanisms, such explicit\nattacks become easier to detect and block. In this work, we propose a novel\nimplicit jailbreak framework termed IJA that stealthily embeds malicious\ninstructions into images via least significant bit steganography and couples\nthem with seemingly benign, image-related textual prompts. To further enhance\nattack effectiveness across diverse MLLMs, we incorporate adversarial suffixes\ngenerated by a surrogate model and introduce a template optimization module\nthat iteratively refines both the prompt and embedding based on model feedback.\nOn commercial models like GPT-4o and Gemini-1.5 Pro, our method achieves attack\nsuccess rates of over 90% using an average of only 3 queries.", "AI": {"tldr": "Proposes IJA, an implicit jailbreak framework for MLLMs using steganography and adversarial prompts, achieving high success rates.", "motivation": "Addresses the challenge of bypassing cross-modal consistency in MLLMs for jailbreak attacks.", "method": "Uses least significant bit steganography to embed malicious instructions in images, combined with benign textual prompts and adversarial suffixes.", "result": "Achieves over 90% attack success on models like GPT-4o and Gemini-1.5 Pro with ~3 queries.", "conclusion": "Demonstrates the vulnerability of MLLMs to stealthy, multimodal jailbreak attacks."}}
{"id": "2505.16399", "pdf": "https://arxiv.org/pdf/2505.16399", "abs": "https://arxiv.org/abs/2505.16399", "authors": ["Qian Deng", "Le Hui", "Jin Xie", "Jian Yang"], "title": "Sketchy Bounding-box Supervision for 3D Instance Segmentation", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Bounding box supervision has gained considerable attention in weakly\nsupervised 3D instance segmentation. While this approach alleviates the need\nfor extensive point-level annotations, obtaining accurate bounding boxes in\npractical applications remains challenging. To this end, we explore the\ninaccurate bounding box, named sketchy bounding box, which is imitated through\nperturbing ground truth bounding box by adding scaling, translation, and\nrotation. In this paper, we propose Sketchy-3DIS, a novel weakly 3D instance\nsegmentation framework, which jointly learns pseudo labeler and segmentator to\nimprove the performance under the sketchy bounding-box supervisions.\nSpecifically, we first propose an adaptive box-to-point pseudo labeler that\nadaptively learns to assign points located in the overlapped parts between two\nsketchy bounding boxes to the correct instance, resulting in compact and pure\npseudo instance labels. Then, we present a coarse-to-fine instance segmentator\nthat first predicts coarse instances from the entire point cloud and then\nlearns fine instances based on the region of coarse instances. Finally, by\nusing the pseudo instance labels to supervise the instance segmentator, we can\ngradually generate high-quality instances through joint training. Extensive\nexperiments show that our method achieves state-of-the-art performance on both\nthe ScanNetV2 and S3DIS benchmarks, and even outperforms several fully\nsupervised methods using sketchy bounding boxes. Code is available at\nhttps://github.com/dengq7/Sketchy-3DIS.", "AI": {"tldr": "Sketchy-3DIS is a weakly supervised 3D instance segmentation framework that improves performance under inaccurate bounding box supervision by jointly learning a pseudo labeler and segmentator.", "motivation": "To address the challenge of obtaining accurate bounding boxes in practical applications, the paper explores sketchy bounding boxes (inaccurate boxes) and aims to improve segmentation performance under such supervision.", "method": "The framework includes an adaptive box-to-point pseudo labeler for assigning points in overlapped regions and a coarse-to-fine instance segmentator for refining predictions. Joint training generates high-quality instances.", "result": "The method achieves state-of-the-art performance on ScanNetV2 and S3DIS benchmarks, outperforming some fully supervised methods.", "conclusion": "Sketchy-3DIS demonstrates the effectiveness of weakly supervised learning with sketchy bounding boxes, offering a practical solution for 3D instance segmentation."}}
{"id": "2505.16349", "pdf": "https://arxiv.org/pdf/2505.16349", "abs": "https://arxiv.org/abs/2505.16349", "authors": ["Pierre Achkar", "Tim Gollub", "Martin Potthast"], "title": "Ask, Retrieve, Summarize: A Modular Pipeline for Scientific Literature Summarization", "categories": ["cs.CL"], "comment": "Accepted at SCOLIA@ECIR 2025 Workshop", "summary": "The exponential growth of scientific publications has made it increasingly\ndifficult for researchers to stay updated and synthesize knowledge effectively.\nThis paper presents XSum, a modular pipeline for multi-document summarization\n(MDS) in the scientific domain using Retrieval-Augmented Generation (RAG). The\npipeline includes two core components: a question-generation module and an\neditor module. The question-generation module dynamically generates questions\nadapted to the input papers, ensuring the retrieval of relevant and accurate\ninformation. The editor module synthesizes the retrieved content into coherent\nand well-structured summaries that adhere to academic standards for proper\ncitation. Evaluated on the SurveySum dataset, XSum demonstrates strong\nperformance, achieving considerable improvements in metrics such as CheckEval,\nG-Eval and Ref-F1 compared to existing approaches. This work provides a\ntransparent, adaptable framework for scientific summarization with potential\napplications in a wide range of domains. Code available at\nhttps://github.com/webis-de/scolia25-xsum", "AI": {"tldr": "XSum is a modular pipeline for multi-document summarization in scientific papers, using Retrieval-Augmented Generation (RAG) to generate coherent summaries with proper citations.", "motivation": "The rapid growth of scientific publications makes it hard for researchers to stay updated, necessitating efficient summarization tools.", "method": "XSum uses a question-generation module to retrieve relevant information and an editor module to synthesize coherent summaries.", "result": "XSum outperforms existing methods on the SurveySum dataset, improving metrics like CheckEval, G-Eval, and Ref-F1.", "conclusion": "XSum offers a transparent, adaptable framework for scientific summarization with broad domain applications."}}
{"id": "2505.14679", "pdf": "https://arxiv.org/pdf/2505.14679", "abs": "https://arxiv.org/abs/2505.14679", "authors": ["Xiaojie Gu", "Guangxu Chen", "Jungang Li", "Jia-Chen Gu", "Xuming Hu", "Kai Zhang"], "title": "UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Lifelong learning enables large language models (LLMs) to adapt to evolving\ninformation by continually updating their internal knowledge. An ideal system\nshould support efficient, wide-ranging updates while preserving existing\ncapabilities and ensuring reliable deployment. Model editing stands out as a\npromising solution for this goal, offering a focused and efficient way to\nrevise a model's internal knowledge. Although recent paradigms have made\nnotable progress, they often struggle to meet the demands of practical lifelong\nadaptation at scale. To bridge this gap, we propose ULTRAEDIT-a fundamentally\nnew editing solution that is training-, subject- and memory-free, making it\nparticularly well-suited for ultra-scalable, real-world lifelong model editing.\nULTRAEDIT performs editing through a self-contained process that relies solely\non lightweight linear algebra operations to compute parameter shifts, enabling\nfast and consistent parameter modifications with minimal overhead. To improve\nscalability in lifelong settings, ULTRAEDIT employs a lifelong normalization\nstrategy that continuously updates feature statistics across turns, allowing it\nto adapt to distributional shifts and maintain consistency over time. ULTRAEDIT\nachieves editing speeds over 7x faster than the previous state-of-the-art\nmethod-which was also the fastest known approach-while consuming less than 1/3\nthe VRAM, making it the only method currently capable of editing a 7B LLM on a\n24GB consumer-grade GPU. Furthermore, we construct ULTRAEDITBENCH-the largest\ndataset in the field to date, with over 2M editing pairs-and demonstrate that\nour method supports up to 1M edits while maintaining high accuracy.\nComprehensive experiments on four datasets and six models show that ULTRAEDIT\nconsistently achieves superior performance across diverse model editing\nscenarios. Our code is available at: https://github.com/XiaojieGu/UltraEdit.", "AI": {"tldr": "ULTRAEDIT is a scalable, efficient method for lifelong learning in LLMs, enabling fast, lightweight edits with minimal overhead and superior performance.", "motivation": "To address the limitations of current model editing methods in supporting practical, scalable lifelong learning for LLMs.", "method": "ULTRAEDIT uses lightweight linear algebra operations for parameter shifts and a lifelong normalization strategy to adapt to distributional shifts.", "result": "Achieves 7x faster editing speeds, uses less VRAM, and supports up to 1M edits with high accuracy.", "conclusion": "ULTRAEDIT is a highly efficient and scalable solution for lifelong model editing, outperforming existing methods."}}
{"id": "2505.16481", "pdf": "https://arxiv.org/pdf/2505.16481", "abs": "https://arxiv.org/abs/2505.16481", "authors": ["Xinxing Shi", "Xiaoyu Jiang", "Mauricio A. \u00c1lvarez"], "title": "Neighbour-Driven Gaussian Process Variational Autoencoders for Scalable Structured Latent Modelling", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Gaussian Process (GP) Variational Autoencoders (VAEs) extend standard VAEs by\nreplacing the fully factorised Gaussian prior with a GP prior, thereby\ncapturing richer correlations among latent variables. However, performing exact\nGP inference in large-scale GPVAEs is computationally prohibitive, often\nforcing existing approaches to rely on restrictive kernel assumptions or large\nsets of inducing points. In this work, we propose a neighbour-driven\napproximation strategy that exploits local adjacencies in the latent space to\nachieve scalable GPVAE inference. By confining computations to the nearest\nneighbours of each data point, our method preserves essential latent\ndependencies, allowing more flexible kernel choices and mitigating the need for\nnumerous inducing points. Through extensive experiments on tasks including\nrepresentation learning, data imputation, and conditional generation, we\ndemonstrate that our approach outperforms other GPVAE variants in both\npredictive performance and computational efficiency.", "AI": {"tldr": "A scalable GPVAE method using neighbor-driven approximation for efficient inference, outperforming existing GPVAE variants.", "motivation": "Standard GPVAEs face computational challenges with large-scale data due to restrictive kernel assumptions or excessive inducing points.", "method": "Proposes a neighbor-driven approximation leveraging local adjacencies in latent space, reducing computational load while preserving latent dependencies.", "result": "Outperforms other GPVAE variants in predictive performance and computational efficiency across tasks like representation learning and data imputation.", "conclusion": "The method enables scalable GPVAE inference with flexible kernels and fewer inducing points, enhancing practical applicability."}}
{"id": "2505.16402", "pdf": "https://arxiv.org/pdf/2505.16402", "abs": "https://arxiv.org/abs/2505.16402", "authors": ["Yuanhao Huang", "Yilong Ren", "Jinlei Wang", "Lujia Huo", "Xuesong Bai", "Jinchuan Zhang", "Haiyan Yu"], "title": "AdvReal: Adversarial Patch Generation Framework with Application to Adversarial Safety Evaluation of Object Detection Systems", "categories": ["cs.CV"], "comment": null, "summary": "Autonomous vehicles are typical complex intelligent systems with artificial\nintelligence at their core. However, perception methods based on deep learning\nare extremely vulnerable to adversarial samples, resulting in safety accidents.\nHow to generate effective adversarial examples in the physical world and\nevaluate object detection systems is a huge challenge. In this study, we\npropose a unified joint adversarial training framework for both 2D and 3D\nsamples to address the challenges of intra-class diversity and environmental\nvariations in real-world scenarios. Building upon this framework, we introduce\nan adversarial sample reality enhancement approach that incorporates non-rigid\nsurface modeling and a realistic 3D matching mechanism. We compare with 5\nadvanced adversarial patches and evaluate their attack performance on 8 object\ndetecotrs, including single-stage, two-stage, and transformer-based models.\nExtensive experiment results in digital and physical environments demonstrate\nthat the adversarial textures generated by our method can effectively mislead\nthe target detection model. Moreover, proposed method demonstrates excellent\nrobustness and transferability under multi-angle attacks, varying lighting\nconditions, and different distance in the physical world. The demo video and\ncode can be obtained at https://github.com/Huangyh98/AdvReal.git.", "AI": {"tldr": "A unified adversarial training framework for 2D/3D samples enhances robustness against adversarial attacks in autonomous vehicle perception systems.", "motivation": "Addressing vulnerabilities of deep learning-based perception methods to adversarial samples in real-world scenarios.", "method": "Proposes a joint adversarial training framework with non-rigid surface modeling and 3D matching for realistic adversarial samples.", "result": "Adversarial textures effectively mislead object detectors, showing robustness under varied conditions.", "conclusion": "The method improves adversarial attack resilience in autonomous vehicle perception systems."}}
{"id": "2505.16381", "pdf": "https://arxiv.org/pdf/2505.16381", "abs": "https://arxiv.org/abs/2505.16381", "authors": ["Songlin Yang", "Yikang Shen", "Kaiyue Wen", "Shawn Tan", "Mayank Mishra", "Liliang Ren", "Rameswar Panda", "Yoon Kim"], "title": "PaTH Attention: Position Encoding via Accumulating Householder Transformations", "categories": ["cs.CL", "cs.LG"], "comment": "Preprint", "summary": "The attention mechanism is a core primitive in modern large language models\n(LLMs) and AI more broadly. Since attention by itself is permutation-invariant,\nposition encoding is essential for modeling structured domains such as\nlanguage. Rotary position encoding (RoPE) has emerged as the de facto standard\napproach for position encoding and is part of many modern LLMs. However, in\nRoPE the key/query transformation between two elements in a sequence is only a\nfunction of their relative position and otherwise independent of the actual\ninput. This limits the expressivity of RoPE-based transformers.\n  This paper describes PaTH, a flexible data-dependent position encoding scheme\nbased on accumulated products of Householder(like) transformations, where each\ntransformation is data-dependent, i.e., a function of the input. We derive an\nefficient parallel algorithm for training through exploiting a compact\nrepresentation of products of Householder matrices, and implement a\nFlashAttention-style blockwise algorithm that minimizes I/O cost. Across both\ntargeted synthetic benchmarks and moderate-scale real-world language modeling\nexperiments, we find that PaTH demonstrates superior performance compared to\nRoPE and other recent baselines.", "AI": {"tldr": "PaTH introduces a data-dependent position encoding scheme using Householder transformations, outperforming RoPE in synthetic and real-world language tasks.", "motivation": "RoPE's position encoding lacks input dependency, limiting transformer expressivity. PaTH addresses this by making transformations data-dependent.", "method": "PaTH uses accumulated products of Householder transformations, each input-dependent. It includes an efficient parallel training algorithm and a FlashAttention-style blockwise implementation.", "result": "PaTH shows superior performance over RoPE and other baselines in synthetic benchmarks and real-world language modeling.", "conclusion": "PaTH's data-dependent approach enhances transformer expressivity and performance, making it a promising alternative to RoPE."}}
{"id": "2505.15820", "pdf": "https://arxiv.org/pdf/2505.15820", "abs": "https://arxiv.org/abs/2505.15820", "authors": ["Gabriel Anzer", "Kilian Arnsmeyer", "Pascal Bauer", "Joris Bekkers", "Ulf Brefeld", "Jesse Davis", "Nicolas Evans", "Matthias Kempe", "Samuel J Robertson", "Joshua Wyatt Smith", "Jan Van Haaren"], "title": "Common Data Format (CDF): A Standardized Format for Match-Data in Football (Soccer)", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "During football matches, a variety of different parties (e.g., companies)\neach collect (possibly overlapping) data about the match ranging from basic\ninformation (e.g., starting players) to detailed positional data. This data is\nprovided to clubs, federations, and other organizations who are increasingly\ninterested in leveraging this data to inform their decision making.\nUnfortunately, analyzing such data pose significant barriers because each\nprovider may (1) collect different data, (2) use different specifications even\nwithin the same category of data, (3) represent the data differently, and (4)\ndelivers the data in a different manner (e.g., file format, protocol).\nConsequently, working with these data requires a significant investment of time\nand money. The goal of this work is to propose a uniform and standardized\nformat for football data called the Common Data Format (CDF). The CDF specifies\na minimal schema for five types of match data: match sheet data, video footage,\nevent data, tracking data, and match meta data. It aims to ensure that the\nprovided data is clear, sufficiently contextualized (e.g., its provenance is\nclear), and complete such that it enables common downstream analysis tasks.\nConcretely, this paper will detail the technical specifications of the CDF, the\nrepresentational choices that were made to help ensure the clarity of the\nprovided data, and a concrete approach for delivering data in the CDF.", "AI": {"tldr": "The paper proposes a standardized format (CDF) for football match data to address inconsistencies in data collection and representation across providers, enabling easier analysis.", "motivation": "The lack of uniformity in football data collection and representation creates barriers for analysis, requiring significant time and money.", "method": "The paper introduces the Common Data Format (CDF), specifying a minimal schema for five types of match data and detailing its technical specifications and representational choices.", "result": "The CDF ensures data clarity, contextualization, and completeness, facilitating common downstream analysis tasks.", "conclusion": "The CDF standardizes football data, reducing analysis barriers and improving decision-making for clubs and organizations."}}
{"id": "2505.16493", "pdf": "https://arxiv.org/pdf/2505.16493", "abs": "https://arxiv.org/abs/2505.16493", "authors": ["Seyedeh Fatemeh Ebrahimi", "Jaakko Peltonen"], "title": "Constrained Non-negative Matrix Factorization for Guided Topic Modeling of Minority Topics", "categories": ["cs.LG"], "comment": null, "summary": "Topic models often fail to capture low-prevalence, domain-critical themes,\nso-called minority topics, such as mental health themes in online comments.\nWhile some existing methods can incorporate domain knowledge, such as expected\ntopical content, methods allowing guidance may require overly detailed expected\ntopics, hindering the discovery of topic divisions and variation. We propose a\ntopic modeling solution via a specially constrained NMF. We incorporate a seed\nword list characterizing minority content of interest, but we do not require\nexperts to pre-specify their division across minority topics. Through\nprevalence constraints on minority topics and seed word content across topics,\nwe learn distinct data-driven minority topics as well as majority topics. The\nconstrained NMF is fitted via Karush-Kuhn-Tucker (KKT) conditions with\nmultiplicative updates. We outperform several baselines on synthetic data in\nterms of topic purity, normalized mutual information, and also evaluate topic\nquality using Jensen-Shannon divergence (JSD). We conduct a case study on\nYouTube vlog comments, analyzing viewer discussion of mental health content;\nour model successfully identifies and reveals this domain-relevant minority\ncontent.", "AI": {"tldr": "A constrained NMF-based topic modeling method is proposed to better capture minority topics, outperforming baselines in synthetic and real-world data.", "motivation": "Existing topic models struggle with low-prevalence, domain-critical themes (minority topics), and guidance methods may hinder topic discovery.", "method": "Uses a specially constrained NMF with seed word lists and prevalence constraints, fitted via KKT conditions and multiplicative updates.", "result": "Outperforms baselines in topic purity, NMI, and JSD; successfully identifies minority topics in YouTube vlog comments.", "conclusion": "The method effectively captures minority topics without requiring detailed pre-specification, proving useful for domain-relevant analysis."}}
{"id": "2505.16411", "pdf": "https://arxiv.org/pdf/2505.16411", "abs": "https://arxiv.org/abs/2505.16411", "authors": ["Sreetama Sarkar", "Yue Che", "Alex Gavin", "Peter A. Beerel", "Souvik Kundu"], "title": "Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Despite their remarkable progress in multimodal understanding tasks, large\nvision language models (LVLMs) often suffer from \"hallucinations\", generating\ntexts misaligned with the visual context. Existing methods aimed at reducing\nhallucinations through inference time intervention incur a significant increase\nin latency. To mitigate this, we present SPIN, a task-agnostic attention-guided\nhead suppression strategy that can be seamlessly integrated during inference,\nwithout incurring any significant compute or latency overhead. We investigate\nwhether hallucination in LVLMs can be linked to specific model components. Our\nanalysis suggests that hallucinations can be attributed to a dynamic subset of\nattention heads in each layer. Leveraging this insight, for each text query\ntoken, we selectively suppress attention heads that exhibit low attention to\nimage tokens, keeping the top-K attention heads intact. Extensive evaluations\non visual question answering and image description tasks demonstrate the\nefficacy of SPIN in reducing hallucination scores up to 2.7x while maintaining\nF1, and improving throughput by 1.8x compared to existing alternatives. Code is\navailable at https://github.com/YUECHE77/SPIN.", "AI": {"tldr": "SPIN reduces hallucinations in LVLMs by selectively suppressing low-attention heads, improving performance and speed.", "motivation": "LVLMs often generate misaligned text (hallucinations), and existing solutions increase latency.", "method": "SPIN suppresses low-attention heads dynamically during inference without extra compute.", "result": "Reduces hallucinations by 2.7x, maintains F1, and improves throughput by 1.8x.", "conclusion": "SPIN effectively mitigates hallucinations efficiently, enhancing LVLM reliability."}}
{"id": "2505.16385", "pdf": "https://arxiv.org/pdf/2505.16385", "abs": "https://arxiv.org/abs/2505.16385", "authors": ["Kaiyu He", "Tong Zhou", "Yubo Chen", "Delai Qiu", "Shengping Liu", "Kang Liu", "Jun Zhao"], "title": "Semantic Pivots Enable Cross-Lingual Transfer in Large Language Models", "categories": ["cs.CL"], "comment": "14 pages, 10 figures", "summary": "Large language models (LLMs) demonstrate remarkable ability in cross-lingual\ntasks. Understanding how LLMs acquire this ability is crucial for their\ninterpretability. To quantify the cross-lingual ability of LLMs accurately, we\npropose a Word-Level Cross-Lingual Translation Task. To find how LLMs learn\ncross-lingual ability, we trace the outputs of LLMs' intermediate layers in the\nword translation task. We identify and distinguish two distinct behaviors in\nthe forward pass of LLMs: co-occurrence behavior and semantic pivot behavior.\nWe attribute LLMs' two distinct behaviors to the co-occurrence frequency of\nwords and find the semantic pivot from the pre-training dataset. Finally, to\napply our findings to improve the cross-lingual ability of LLMs, we reconstruct\na semantic pivot-aware pre-training dataset using documents with a high\nproportion of semantic pivots. Our experiments validate the effectiveness of\nour approach in enhancing cross-lingual ability. Our research contributes\ninsights into the interpretability of LLMs and offers a method for improving\nLLMs' cross-lingual ability.", "AI": {"tldr": "The paper investigates how LLMs acquire cross-lingual abilities, proposing a word-level translation task and identifying two behaviors (co-occurrence and semantic pivot) to improve LLMs' performance.", "motivation": "To understand and quantify how LLMs develop cross-lingual abilities for better interpretability and performance.", "method": "Proposes a Word-Level Cross-Lingual Translation Task, traces LLMs' intermediate layers, and identifies co-occurrence and semantic pivot behaviors.", "result": "Identifies two distinct behaviors in LLMs and validates a semantic pivot-aware pre-training dataset to enhance cross-lingual ability.", "conclusion": "The study provides insights into LLMs' interpretability and offers a method to improve their cross-lingual performance."}}
{"id": "2505.15821", "pdf": "https://arxiv.org/pdf/2505.15821", "abs": "https://arxiv.org/abs/2505.15821", "authors": ["Milos Gravara", "Andrija Stanisic", "Stefan Nastic"], "title": "A Novel Compound AI Model for 6G Networks in 3D Continuum", "categories": ["cs.NI", "cs.AI", "I.2.11; C.2.3; C.2.4"], "comment": "4 pages, 2 figures", "summary": "The 3D continuum presents a complex environment that spans the terrestrial,\naerial and space domains, with 6Gnetworks serving as a key enabling technology.\nCurrent AI approaches for network management rely on monolithic models that\nfail to capture cross-domain interactions, lack adaptability,and demand\nprohibitive computational resources. This paper presents a formal model of\nCompound AI systems, introducing a novel tripartite framework that decomposes\ncomplex tasks into specialized, interoperable modules. The proposed modular\narchitecture provides essential capabilities to address the unique challenges\nof 6G networks in the 3D continuum, where heterogeneous components require\ncoordinated, yet distributed, intelligence. This approach introduces a\nfundamental trade-off between model and system performance, which must be\ncarefully addressed. Furthermore, we identify key challenges faced by Compound\nAI systems within 6G networks operating in the 3D continuum, including\ncross-domain resource orchestration, adaptation to dynamic topologies, and the\nmaintenance of consistent AI service quality across heterogeneous environments.", "AI": {"tldr": "The paper proposes a modular Compound AI system for 6G networks in the 3D continuum, addressing limitations of monolithic AI models.", "motivation": "Current AI models for 6G networks are inflexible, inefficient, and unable to handle cross-domain interactions in the 3D continuum.", "method": "Introduces a tripartite framework decomposing tasks into specialized, interoperable modules for distributed intelligence.", "result": "The modular architecture addresses 6G challenges like resource orchestration, dynamic topologies, and consistent AI service quality.", "conclusion": "Compound AI systems offer a viable solution for 6G networks but require balancing model and system performance."}}
{"id": "2505.16494", "pdf": "https://arxiv.org/pdf/2505.16494", "abs": "https://arxiv.org/abs/2505.16494", "authors": ["Noga Amit", "Omer Reingold", "Guy N. Rothblum"], "title": "Accuracy vs. Accuracy: Computational Tradeoffs Between Classification Rates and Utility", "categories": ["cs.LG"], "comment": null, "summary": "We revisit the foundations of fairness and its interplay with utility and\nefficiency in settings where the training data contain richer labels, such as\nindividual types, rankings, or risk estimates, rather than just binary\noutcomes. In this context, we propose algorithms that achieve stronger notions\nof evidence-based fairness than are possible in standard supervised learning.\nOur methods support classification and ranking techniques that preserve\naccurate subpopulation classification rates, as suggested by the underlying\ndata distributions, across a broad class of classification rules and downstream\napplications. Furthermore, our predictors enable loss minimization, whether\naimed at maximizing utility or in the service of fair treatment.\n  Complementing our algorithmic contributions, we present impossibility results\ndemonstrating that simultaneously achieving accurate classification rates and\noptimal loss minimization is, in some cases, computationally infeasible. Unlike\nprior impossibility results, our notions are not inherently in conflict and are\nsimultaneously satisfied by the Bayes-optimal predictor. Furthermore, we show\nthat each notion can be satisfied individually via efficient learning. Our\nseparation thus stems from the computational hardness of learning a\nsufficiently good approximation of the Bayes-optimal predictor. These\ncomputational impossibilities present a choice between two natural and\nattainable notions of accuracy that could both be motivated by fairness.", "AI": {"tldr": "The paper explores fairness in machine learning with richer data labels, proposing algorithms for stronger fairness notions and showing computational trade-offs between accuracy and fairness.", "motivation": "To address fairness in settings with complex data (e.g., rankings, risk estimates) and reconcile it with utility and efficiency.", "method": "Proposes algorithms for evidence-based fairness, supporting classification and ranking while preserving subpopulation accuracy and enabling loss minimization.", "result": "Achieves stronger fairness than standard methods but shows computational infeasibility in simultaneously optimizing accuracy and fairness.", "conclusion": "Fairness and accuracy can be individually achieved, but computational limitations force a choice between them."}}
{"id": "2505.16416", "pdf": "https://arxiv.org/pdf/2505.16416", "abs": "https://arxiv.org/abs/2505.16416", "authors": ["Chengcheng Wang", "Jianyuan Guo", "Hongguang Li", "Yuchuan Tian", "Ying Nie", "Chang Xu", "Kai Han"], "title": "Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Rotary Position Embedding (RoPE) is a widely adopted technique for encoding\nrelative positional information in large language models (LLMs). However, when\nextended to large vision-language models (LVLMs), its variants introduce\nunintended cross-modal positional biases. Specifically, they enforce relative\npositional dependencies between text token indices and image tokens, causing\nspurious alignments. This issue arises because image tokens representing the\nsame content but located at different spatial positions are assigned distinct\npositional biases, leading to inconsistent cross-modal associations. To address\nthis, we propose Per-Token Distance (PTD) - a simple yet effective metric for\nquantifying the independence of positional encodings across modalities.\nInformed by this analysis, we introduce Circle-RoPE, a novel encoding scheme\nthat maps image token indices onto a circular trajectory orthogonal to the\nlinear path of text token indices, forming a cone-like structure. This\nconfiguration ensures that each text token maintains an equal distance to all\nimage tokens, reducing artificial cross-modal biases while preserving\nintra-image spatial information. To further enhance performance, we propose a\nstaggered layer strategy that applies different RoPE variants across layers.\nThis design leverages the complementary strengths of each RoPE variant, thereby\nenhancing the model's overall performance. Our experimental results demonstrate\nthat our method effectively preserves spatial information from images while\nreducing relative positional bias, offering a more robust and flexible\npositional encoding framework for LVLMs. The code is available at\n[https://github.com/lose4578/CircleRoPE](https://github.com/lose4578/CircleRoPE).", "AI": {"tldr": "The paper introduces Circle-RoPE, a novel positional encoding scheme for vision-language models, addressing cross-modal biases in Rotary Position Embedding (RoPE) by ensuring equal distance between text and image tokens.", "motivation": "Existing RoPE variants in vision-language models create unintended cross-modal positional biases, leading to spurious alignments and inconsistent associations.", "method": "Proposes Per-Token Distance (PTD) to quantify positional independence and introduces Circle-RoPE, mapping image tokens orthogonally to text tokens. Also employs a staggered layer strategy for enhanced performance.", "result": "Circle-RoPE reduces artificial biases while preserving intra-image spatial information, improving model robustness.", "conclusion": "The method offers a flexible and effective positional encoding framework for large vision-language models, validated by experimental results."}}
{"id": "2505.16392", "pdf": "https://arxiv.org/pdf/2505.16392", "abs": "https://arxiv.org/abs/2505.16392", "authors": ["Benjamin Vendeville", "Liana Ermakova", "Pierre De Loor"], "title": "Resource for Error Analysis in Text Simplification: New Taxonomy and Test Collection", "categories": ["cs.CL", "cs.AI", "I.2.6; I.5.2"], "comment": "Accepted at SIGIR 2025", "summary": "The general public often encounters complex texts but does not have the time\nor expertise to fully understand them, leading to the spread of misinformation.\nAutomatic Text Simplification (ATS) helps make information more accessible, but\nits evaluation methods have not kept up with advances in text generation,\nespecially with Large Language Models (LLMs). In particular, recent studies\nhave shown that current ATS metrics do not correlate with the presence of\nerrors. Manual inspections have further revealed a variety of errors,\nunderscoring the need for a more nuanced evaluation framework, which is\ncurrently lacking. This resource paper addresses this gap by introducing a test\ncollection for detecting and classifying errors in simplified texts. First, we\npropose a taxonomy of errors, with a formal focus on information distortion.\nNext, we introduce a parallel dataset of automatically simplified scientific\ntexts. This dataset has been human-annotated with labels based on our proposed\ntaxonomy. Finally, we analyze the quality of the dataset, and we study the\nperformance of existing models to detect and classify errors from that\ntaxonomy. These contributions give researchers the tools to better evaluate\nerrors in ATS, develop more reliable models, and ultimately improve the quality\nof automatically simplified texts.", "AI": {"tldr": "The paper introduces a test collection for detecting and classifying errors in simplified texts, addressing gaps in current ATS evaluation methods.", "motivation": "Current ATS metrics fail to correlate with errors, and manual inspections reveal diverse issues, highlighting the need for a better evaluation framework.", "method": "Proposes a taxonomy of errors, creates a parallel dataset of simplified scientific texts with human annotations, and evaluates existing models for error detection.", "result": "Provides a dataset and taxonomy to improve error evaluation in ATS, aiding in model development and text quality.", "conclusion": "The contributions enable better error evaluation and model reliability, enhancing the quality of automatically simplified texts."}}
{"id": "2505.15828", "pdf": "https://arxiv.org/pdf/2505.15828", "abs": "https://arxiv.org/abs/2505.15828", "authors": ["Jiayuan Chen", "Yuxiang Li", "Changyan Yi", "Shimin Gong"], "title": "Generative AI-Aided QoE Maximization for RIS-Assisted Digital Twin Interaction", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "In this paper, we investigate a quality of experience (QoE)-aware resource\nallocation problem for reconfigurable intelligent surface (RIS)-assisted\ndigital twin (DT) interaction with uncertain evolution. In the considered\nsystem, mobile users are expected to interact with a DT model maintained on a\nDT server that is deployed on a base station, via effective uplink and downlink\nchannels assisted by an RIS. Our goal is to maximize the sum of all mobile\nusers' joint subjective and objective QoE in DT interactions across various DT\nscenes, by jointly optimizing phase shift matrix, receive/transmit beamforming\nmatrix, rendering resolution configuration and computing resource allocation.\nWhile solving this problem is challenging mainly due to the uncertain evolution\nof the DT model, which leads to multiple scene-specific problems, and require\nus to constantly re-solve each of them whenever DT model evolves.\n  To this end, leveraging the dynamic optimization capabilities of decision\ntransformers and the generalization strengths of generative artificial\nintelligence (GAI), we propose a novel GAI-aided approach, called the\nprompt-guided decision transformer integrated with zero-forcing optimization\n(PG-ZFO). Simulations are conducted to evaluate the proposed PG-ZFO,\ndemonstrating its effectiveness and superiority over counterparts.", "AI": {"tldr": "The paper proposes a GAI-aided approach (PG-ZFO) to optimize QoE-aware resource allocation in RIS-assisted DT interactions, addressing uncertain DT model evolution.", "motivation": "To maximize mobile users' QoE in DT interactions despite the uncertain evolution of the DT model.", "method": "Joint optimization of phase shift matrix, beamforming, rendering resolution, and resource allocation using PG-ZFO, combining decision transformers and GAI.", "result": "Simulations show PG-ZFO's effectiveness and superiority over existing methods.", "conclusion": "PG-ZFO successfully addresses the challenges of uncertain DT model evolution, enhancing QoE in DT interactions."}}
{"id": "2505.16516", "pdf": "https://arxiv.org/pdf/2505.16516", "abs": "https://arxiv.org/abs/2505.16516", "authors": ["Majid Mohammadi", "Siu Lun Chau", "Krikamol Muandet"], "title": "Computing Exact Shapley Values in Polynomial Time for Product-Kernel Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Kernel methods are widely used in machine learning due to their flexibility\nand expressive power. However, their black-box nature poses significant\nchallenges to interpretability, limiting their adoption in high-stakes\napplications. Shapley value-based feature attribution techniques, such as SHAP\nand kernel-specific variants like RKHS-SHAP, offer a promising path toward\nexplainability. Yet, computing exact Shapley values remains computationally\nintractable in general, motivating the development of various approximation\nschemes. In this work, we introduce PKeX-Shapley, a novel algorithm that\nutilizes the multiplicative structure of product kernels to enable the exact\ncomputation of Shapley values in polynomial time. We show that product-kernel\nmodels admit a functional decomposition that allows for a recursive formulation\nof Shapley values. This decomposition not only yields computational efficiency\nbut also enhances interpretability in kernel-based learning. We also\ndemonstrate how our framework can be generalized to explain kernel-based\nstatistical discrepancies such as the Maximum Mean Discrepancy (MMD) and the\nHilbert-Schmidt Independence Criterion (HSIC), thus offering new tools for\ninterpretable statistical inference.", "AI": {"tldr": "PKeX-Shapley enables exact computation of Shapley values for product-kernel models in polynomial time, improving interpretability and efficiency.", "motivation": "Kernel methods lack interpretability, limiting their use in high-stakes applications. Shapley value approximations exist but are computationally expensive.", "method": "Introduces PKeX-Shapley, leveraging the multiplicative structure of product kernels for exact Shapley value computation via recursive functional decomposition.", "result": "Achieves polynomial-time exact computation of Shapley values, enhancing interpretability and extending to kernel-based statistical discrepancies like MMD and HSIC.", "conclusion": "PKeX-Shapley provides a scalable and interpretable solution for kernel-based models, expanding tools for explainable statistical inference."}}
{"id": "2505.16419", "pdf": "https://arxiv.org/pdf/2505.16419", "abs": "https://arxiv.org/abs/2505.16419", "authors": ["Soh Takahashi", "Masaru Sasaki", "Ken Takeda", "Masafumi Oizumi"], "title": "Investigating Fine- and Coarse-grained Structural Correspondences Between Deep Neural Networks and Human Object Image Similarity Judgments Using Unsupervised Alignment", "categories": ["cs.CV", "cs.AI"], "comment": "34 pages, 6 figures", "summary": "The learning mechanisms by which humans acquire internal representations of\nobjects are not fully understood. Deep neural networks (DNNs) have emerged as a\nuseful tool for investigating this question, as they have internal\nrepresentations similar to those of humans as a byproduct of optimizing their\nobjective functions. While previous studies have shown that models trained with\nvarious learning paradigms - such as supervised, self-supervised, and CLIP -\nacquire human-like representations, it remains unclear whether their similarity\nto human representations is primarily at a coarse category level or extends to\nfiner details. Here, we employ an unsupervised alignment method based on\nGromov-Wasserstein Optimal Transport to compare human and model object\nrepresentations at both fine-grained and coarse-grained levels. The unique\nfeature of this method compared to conventional representational similarity\nanalysis is that it estimates optimal fine-grained mappings between the\nrepresentation of each object in human and model representations. We used this\nunsupervised alignment method to assess the extent to which the representation\nof each object in humans is correctly mapped to the corresponding\nrepresentation of the same object in models. Using human similarity judgments\nof 1,854 objects from the THINGS dataset, we find that models trained with CLIP\nconsistently achieve strong fine- and coarse-grained matching with human object\nrepresentations. In contrast, self-supervised models showed limited matching at\nboth fine- and coarse-grained levels, but still formed object clusters that\nreflected human coarse category structure. Our results offer new insights into\nthe role of linguistic information in acquiring precise object representations\nand the potential of self-supervised learning to capture coarse categorical\nstructures.", "AI": {"tldr": "The paper investigates how human-like object representations are in deep neural networks (DNNs), using unsupervised alignment to compare fine- and coarse-grained levels. CLIP models align well with human representations, while self-supervised models show limited matching but capture coarse categories.", "motivation": "To understand whether DNNs' internal representations match human object representations at fine- or coarse-grained levels, and how different learning paradigms (supervised, self-supervised, CLIP) affect this.", "method": "An unsupervised alignment method based on Gromov-Wasserstein Optimal Transport is used to compare human and model object representations at fine- and coarse-grained levels, leveraging human similarity judgments from the THINGS dataset.", "result": "CLIP models achieve strong alignment with human representations at both fine- and coarse-grained levels, while self-supervised models show limited matching but still reflect coarse category structures.", "conclusion": "Linguistic information (CLIP) aids in precise object representation, while self-supervised learning captures coarse categorical structures, offering insights into human-like representation learning."}}
{"id": "2505.16408", "pdf": "https://arxiv.org/pdf/2505.16408", "abs": "https://arxiv.org/abs/2505.16408", "authors": ["Muhammad Farid Adilazuarda", "Chen Cecilia Liu", "Iryna Gurevych", "Alham Fikri Aji"], "title": "From Surveys to Narratives: Rethinking Cultural Value Adaptation in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Adapting cultural values in Large Language Models (LLMs) presents significant\nchallenges, particularly due to biases and limited training data. Prior work\nprimarily aligns LLMs with different cultural values using World Values Survey\n(WVS) data. However, it remains unclear whether this approach effectively\ncaptures cultural nuances or produces distinct cultural representations for\nvarious downstream tasks. In this paper, we systematically investigate\nWVS-based training for cultural value adaptation and find that relying solely\non survey data can homogenize cultural norms and interfere with factual\nknowledge. To investigate these issues, we augment WVS with encyclopedic and\nscenario-based cultural narratives from Wikipedia and NormAd. While these\nnarratives may have variable effects on downstream tasks, they consistently\nimprove cultural distinctiveness than survey data alone. Our work highlights\nthe inherent complexity of aligning cultural values with the goal of guiding\ntask-specific behavior.", "AI": {"tldr": "The paper examines challenges in adapting cultural values in LLMs, finding WVS data alone insufficient and proposing augmented data for better cultural distinctiveness.", "motivation": "Addressing biases and limited training data in LLMs for cultural value adaptation, questioning the effectiveness of WVS data.", "method": "Systematically investigates WVS-based training, augmented with Wikipedia and NormAd narratives for cultural adaptation.", "result": "Augmented data improves cultural distinctiveness but has variable effects on downstream tasks.", "conclusion": "Cultural value alignment is complex; task-specific behavior requires nuanced data beyond surveys."}}
{"id": "2505.15832", "pdf": "https://arxiv.org/pdf/2505.15832", "abs": "https://arxiv.org/abs/2505.15832", "authors": ["Quan Minh Phan", "Ngoc Hoang Luong"], "title": "From Hand-Crafted Metrics to Evolved Training-Free Performance Predictors for Neural Architecture Search via Genetic Programming", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Estimating the network performance using zero-cost (ZC) metrics has proven\nboth its efficiency and efficacy in Neural Architecture Search (NAS). However,\na notable limitation of most ZC proxies is their inconsistency, as reflected by\nthe substantial variation in their performance across different problems.\nFurthermore, the design of existing ZC metrics is manual, involving a\ntime-consuming trial-and-error process that requires substantial domain\nexpertise. These challenges raise two critical questions: (1) Can we automate\nthe design of ZC metrics? and (2) Can we utilize the existing hand-crafted ZC\nmetrics to synthesize a more generalizable one? In this study, we propose a\nframework based on Symbolic Regression via Genetic Programming to automate the\ndesign of ZC metrics. Our framework is not only highly extensible but also\ncapable of quickly producing a ZC metric with a strong positive rank\ncorrelation to true network performance across diverse NAS search spaces and\ntasks. Extensive experiments on 13 problems from NAS-Bench-Suite-Zero\ndemonstrate that our automatically generated proxies consistently outperform\nhand-crafted alternatives. Using our evolved proxy metric as the search\nobjective in an evolutionary algorithm, we could identify network architectures\nwith competitive performance within 15 minutes using a single consumer GPU.", "AI": {"tldr": "The paper proposes a framework using Symbolic Regression via Genetic Programming to automate the design of zero-cost (ZC) metrics for Neural Architecture Search (NAS), outperforming hand-crafted metrics.", "motivation": "Current ZC metrics are inconsistent and manually designed, requiring domain expertise and trial-and-error. The study aims to automate ZC metric design and improve generalizability.", "method": "The framework employs Symbolic Regression via Genetic Programming to generate ZC metrics, ensuring extensibility and strong rank correlation with true network performance.", "result": "Automated proxies outperform hand-crafted ones in 13 NAS-Bench-Suite-Zero problems, enabling competitive architecture identification in 15 minutes on a single GPU.", "conclusion": "The proposed framework automates and improves ZC metric design, enhancing efficiency and generalizability in NAS."}}
{"id": "2505.16527", "pdf": "https://arxiv.org/pdf/2505.16527", "abs": "https://arxiv.org/abs/2505.16527", "authors": ["Mohamed Amine Ketata", "David L\u00fcdke", "Leo Schwinn", "Stephan G\u00fcnnemann"], "title": "Joint Relational Database Generation via Graph-Conditional Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Building generative models for relational databases (RDBs) is important for\napplications like privacy-preserving data release and augmenting real datasets.\nHowever, most prior work either focuses on single-table generation or relies on\nautoregressive factorizations that impose a fixed table order and generate\ntables sequentially. This approach limits parallelism, restricts flexibility in\ndownstream applications like missing value imputation, and compounds errors due\nto commonly made conditional independence assumptions. We propose a\nfundamentally different approach: jointly modeling all tables in an RDB without\nimposing any order. By using a natural graph representation of RDBs, we propose\nthe Graph-Conditional Relational Diffusion Model (GRDM). GRDM leverages a graph\nneural network to jointly denoise row attributes and capture complex\ninter-table dependencies. Extensive experiments on six real-world RDBs\ndemonstrate that our approach substantially outperforms autoregressive\nbaselines in modeling multi-hop inter-table correlations and achieves\nstate-of-the-art performance on single-table fidelity metrics.", "AI": {"tldr": "Proposes GRDM, a graph-based model for joint generation of relational databases without fixed table order, outperforming autoregressive methods.", "motivation": "Existing methods for RDB generation are limited by fixed table order and sequential generation, reducing flexibility and parallelism.", "method": "Uses a graph representation of RDBs and a graph neural network (GRDM) to jointly denoise row attributes and model inter-table dependencies.", "result": "GRDM outperforms autoregressive baselines in multi-hop inter-table correlations and achieves state-of-the-art single-table fidelity.", "conclusion": "GRDM offers a flexible, parallelizable, and high-fidelity approach for relational database generation."}}
{"id": "2505.16422", "pdf": "https://arxiv.org/pdf/2505.16422", "abs": "https://arxiv.org/abs/2505.16422", "authors": ["Xiaoran Yin", "Xu Luo", "Hao Wu", "Lianli Gao", "Jingkuan Song"], "title": "Unlocking Smarter Device Control: Foresighted Planning with a World Model-Driven Code Execution Approach", "categories": ["cs.CV"], "comment": null, "summary": "The automatic control of mobile devices is essential for efficiently\nperforming complex tasks that involve multiple sequential steps. However, these\ntasks pose significant challenges due to the limited environmental information\navailable at each step, primarily through visual observations. As a result,\ncurrent approaches, which typically rely on reactive policies, focus solely on\nimmediate observations and often lead to suboptimal decision-making. To address\nthis problem, we propose \\textbf{Foresighted Planning with World Model-Driven\nCode Execution (FPWC)},a framework that prioritizes natural language\nunderstanding and structured reasoning to enhance the agent's global\nunderstanding of the environment by developing a task-oriented, refinable\n\\emph{world model} at the outset of the task. Foresighted actions are\nsubsequently generated through iterative planning within this world model,\nexecuted in the form of executable code. Extensive experiments conducted in\nsimulated environments and on real mobile devices demonstrate that our method\noutperforms previous approaches, particularly achieving a 44.4\\% relative\nimprovement in task success rate compared to the state-of-the-art in the\nsimulated environment. Code and demo are provided in the supplementary\nmaterial.", "AI": {"tldr": "FPWC enhances mobile device control by using a world model for foresighted planning, improving task success by 44.4% over state-of-the-art methods.", "motivation": "Current reactive policies in mobile device control are limited by immediate observations, leading to suboptimal decisions. FPWC aims to improve global understanding and decision-making.", "method": "FPWC develops a task-oriented, refinable world model for structured reasoning and generates foresighted actions via iterative planning, executed as code.", "result": "FPWC outperforms prior methods, achieving a 44.4% relative improvement in task success rate in simulated environments.", "conclusion": "FPWC's foresighted planning with a world model significantly enhances mobile device control, demonstrating superior performance in experiments."}}
{"id": "2505.16410", "pdf": "https://arxiv.org/pdf/2505.16410", "abs": "https://arxiv.org/abs/2505.16410", "authors": ["Guanting Dong", "Yifei Chen", "Xiaoxi Li", "Jiajie Jin", "Hongjin Qian", "Yutao Zhu", "Hangyu Mao", "Guorui Zhou", "Zhicheng Dou", "Ji-Rong Wen"], "title": "Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Working in progress", "summary": "Recently, large language models (LLMs) have shown remarkable reasoning\ncapabilities via large-scale reinforcement learning (RL). However, leveraging\nthe RL algorithm to empower effective multi-tool collaborative reasoning in\nLLMs remains an open challenge. In this paper, we introduce Tool-Star, an\nRL-based framework designed to empower LLMs to autonomously invoke multiple\nexternal tools during stepwise reasoning. Tool-Star integrates six types of\ntools and incorporates systematic designs in both data synthesis and training.\nTo address the scarcity of tool-use data, we propose a general tool-integrated\nreasoning data synthesis pipeline, which combines tool-integrated prompting\nwith hint-based sampling to automatically and scalably generate tool-use\ntrajectories. A subsequent quality normalization and difficulty-aware\nclassification process filters out low-quality samples and organizes the\ndataset from easy to hard. Furthermore, we propose a two-stage training\nframework to enhance multi-tool collaborative reasoning by: (1) cold-start\nfine-tuning, which guides LLMs to explore reasoning patterns via\ntool-invocation feedback; and (2) a multi-tool self-critic RL algorithm with\nhierarchical reward design, which reinforces reward understanding and promotes\neffective tool collaboration. Experimental analyses on over 10 challenging\nreasoning benchmarks highlight the effectiveness and efficiency of Tool-Star.\nThe code is available at https://github.com/dongguanting/Tool-Star.", "AI": {"tldr": "Tool-Star is an RL-based framework enabling LLMs to autonomously use multiple tools for reasoning, addressing data scarcity and enhancing multi-tool collaboration.", "motivation": "Leveraging RL to improve multi-tool collaborative reasoning in LLMs, which remains a challenge.", "method": "Introduces Tool-Star with tool-integrated data synthesis, quality normalization, and a two-stage training framework (cold-start fine-tuning and multi-tool self-critic RL).", "result": "Effective performance on 10+ reasoning benchmarks, demonstrating improved tool collaboration.", "conclusion": "Tool-Star successfully enhances LLMs' multi-tool reasoning via systematic data synthesis and RL training."}}
{"id": "2505.15834", "pdf": "https://arxiv.org/pdf/2505.15834", "abs": "https://arxiv.org/abs/2505.15834", "authors": ["Congyuan Zhao", "Lingwei Wei", "Ziming Qin", "Wei Zhou", "Yunya Song", "Songlin Hu"], "title": "MPPFND: A Dataset and Analysis of Detecting Fake News with Multi-Platform Propagation", "categories": ["cs.SI", "cs.AI"], "comment": "Cogsci 2025", "summary": "Fake news spreads widely on social media, leading to numerous negative\neffects. Most existing detection algorithms focus on analyzing news content and\nsocial context to detect fake news. However, these approaches typically detect\nfake news based on specific platforms, ignoring differences in propagation\ncharacteristics across platforms. In this paper, we introduce the MPPFND\ndataset, which captures propagation structures across multiple platforms. We\nalso describe the commenting and propagation characteristics of different\nplatforms to show that their social contexts have distinct features. We propose\na multi-platform fake news detection model (APSL) that uses graph neural\nnetworks to extract social context features from various platforms. Experiments\nshow that accounting for cross-platform propagation differences improves fake\nnews detection performance.", "AI": {"tldr": "The paper introduces a multi-platform dataset (MPPFND) and a detection model (APSL) to improve fake news detection by addressing cross-platform propagation differences.", "motivation": "Existing fake news detection methods focus on single platforms, ignoring propagation differences across platforms, which limits their effectiveness.", "method": "The authors propose the APSL model, which uses graph neural networks to extract social context features from multiple platforms, leveraging the MPPFND dataset.", "result": "Experiments demonstrate that considering cross-platform propagation differences enhances fake news detection performance.", "conclusion": "The study highlights the importance of multi-platform analysis for fake news detection and presents a practical solution with the APSL model."}}
{"id": "2505.16531", "pdf": "https://arxiv.org/pdf/2505.16531", "abs": "https://arxiv.org/abs/2505.16531", "authors": ["Alejandro Moreno Arcas", "Albert Sanchis", "Jorge Civera", "Alfons Juan"], "title": "HOFT: Householder Orthogonal Fine-tuning", "categories": ["cs.LG"], "comment": null, "summary": "Adaptation of foundation models using low-rank methods is a widespread\napproach. Another way to adapt these models is to employ orthogonal fine-tuning\nmethods, which are less time and memory efficient despite their good\ngeneralization properties. In this work, we propose Householder Orthogonal\nFine-tuning (HOFT), a novel orthogonal fine-tuning method that aims to\nalleviate time and space complexity. Moreover, some theoretical properties of\nthe orthogonal fine-tuning paradigm are explored. From this exploration, Scaled\nHouseholder Orthogonal Fine-tuning (SHOFT) is proposed. Both HOFT and SHOFT are\nevaluated in downstream tasks, namely commonsense reasoning, machine\ntranslation, subject-driven generation and mathematical reasoning. Compared\nwith state-of-the-art adaptation methods, HOFT and SHOFT show comparable or\nbetter results.", "AI": {"tldr": "HOFT and SHOFT are proposed as efficient orthogonal fine-tuning methods for foundation models, showing competitive or superior performance in downstream tasks.", "motivation": "To address the inefficiency of existing orthogonal fine-tuning methods while maintaining their generalization benefits.", "method": "Proposes HOFT and SHOFT, leveraging Householder transformations for efficiency, and explores theoretical properties of orthogonal fine-tuning.", "result": "HOFT and SHOFT achieve comparable or better results than state-of-the-art methods in tasks like commonsense reasoning and machine translation.", "conclusion": "HOFT and SHOFT offer efficient and effective alternatives to traditional orthogonal fine-tuning, with SHOFT further enhancing performance."}}
{"id": "2505.16441", "pdf": "https://arxiv.org/pdf/2505.16441", "abs": "https://arxiv.org/abs/2505.16441", "authors": ["Jisu Han", "Jaemin Na", "Wonjun Hwang"], "title": "Ranked Entropy Minimization for Continual Test-Time Adaptation", "categories": ["cs.CV", "cs.LG"], "comment": "ICML 2025", "summary": "Test-time adaptation aims to adapt to realistic environments in an online\nmanner by learning during test time. Entropy minimization has emerged as a\nprincipal strategy for test-time adaptation due to its efficiency and\nadaptability. Nevertheless, it remains underexplored in continual test-time\nadaptation, where stability is more important. We observe that the entropy\nminimization method often suffers from model collapse, where the model\nconverges to predicting a single class for all images due to a trivial\nsolution. We propose ranked entropy minimization to mitigate the stability\nproblem of the entropy minimization method and extend its applicability to\ncontinuous scenarios. Our approach explicitly structures the prediction\ndifficulty through a progressive masking strategy. Specifically, it gradually\naligns the model's probability distributions across different levels of\nprediction difficulty while preserving the rank order of entropy. The proposed\nmethod is extensively evaluated across various benchmarks, demonstrating its\neffectiveness through empirical results. Our code is available at\nhttps://github.com/pilsHan/rem", "AI": {"tldr": "The paper proposes ranked entropy minimization to address model collapse in continual test-time adaptation, improving stability and performance.", "motivation": "Entropy minimization is efficient for test-time adaptation but suffers from instability and model collapse in continual scenarios.", "method": "The approach uses a progressive masking strategy to structure prediction difficulty and preserve entropy rank order.", "result": "Extensive benchmarks show the method's effectiveness in mitigating model collapse and improving adaptation.", "conclusion": "Ranked entropy minimization enhances stability and extends the applicability of entropy minimization in continual test-time adaptation."}}
{"id": "2505.16415", "pdf": "https://arxiv.org/pdf/2505.16415", "abs": "https://arxiv.org/abs/2505.16415", "authors": ["Ruizhe Li", "Chen Chen", "Yuchen Hu", "Yanjun Gao", "Xi Wang", "Emine Yilmaz"], "title": "Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Work in process", "summary": "Retrieval-Augmented Generation (RAG) leverages large language models (LLMs)\ncombined with external contexts to enhance the accuracy and reliability of\ngenerated responses. However, reliably attributing generated content to\nspecific context segments, context attribution, remains challenging due to the\ncomputationally intensive nature of current methods, which often require\nextensive fine-tuning or human annotation. In this work, we introduce a novel\nJensen-Shannon Divergence driven method to Attribute Response to Context\n(ARC-JSD), enabling efficient and accurate identification of essential context\nsentences without additional fine-tuning or surrogate modelling. Evaluations on\na wide range of RAG benchmarks, such as TyDi QA, Hotpot QA, and Musique, using\ninstruction-tuned LLMs in different scales demonstrate superior accuracy and\nsignificant computational efficiency improvements compared to the previous\nsurrogate-based method. Furthermore, our mechanistic analysis reveals specific\nattention heads and multilayer perceptron (MLP) layers responsible for context\nattribution, providing valuable insights into the internal workings of RAG\nmodels.", "AI": {"tldr": "ARC-JSD is a new method for efficient and accurate context attribution in RAG models without fine-tuning or surrogate modeling, outperforming previous methods in accuracy and computational efficiency.", "motivation": "Current methods for context attribution in RAG models are computationally intensive and often require fine-tuning or human annotation, limiting scalability and practicality.", "method": "Introduces ARC-JSD, a Jensen-Shannon Divergence driven approach, to identify essential context sentences efficiently without additional training.", "result": "Demonstrates superior accuracy and computational efficiency on benchmarks like TyDi QA, Hotpot QA, and Musique. Also reveals key attention heads and MLP layers for context attribution.", "conclusion": "ARC-JSD offers a scalable and efficient solution for context attribution in RAG models, with insights into model internals."}}
{"id": "2505.15835", "pdf": "https://arxiv.org/pdf/2505.15835", "abs": "https://arxiv.org/abs/2505.15835", "authors": ["Nayan Sanjay Bhatia", "Katia Obraczka"], "title": "Transforming Decoder-Only Transformers for Accurate WiFi-Telemetry Based Indoor Localization", "categories": ["cs.NI", "cs.AI"], "comment": "11 pages, 2 figures, In Submission", "summary": "Wireless Fidelity (WiFi) based indoor positioning is a widely researched area\nfor determining the position of devices within a wireless network. Accurate\nindoor location has numerous applications, such as asset tracking and indoor\nnavigation. Despite advances in WiFi localization techniques -- in particular\napproaches that leverage WiFi telemetry -- their adoption in practice remains\nlimited due to several factors including environmental changes that cause\nsignal fading, multipath effects, interference, which, in turn, impact\npositioning accuracy. In addition, telemetry data differs depending on the WiFi\ndevice vendor, offering distinct features and formats; use case requirements\ncan also vary widely. Currently, there is no unified model to handle all these\nvariations effectively. In this paper, we present WiFiGPT, a Generative\nPretrained Transformer (GPT) based system that is able to handle these\nvariations while achieving high localization accuracy. Our experiments with\nWiFiGPT demonstrate that GPTs, in particular Large Language Models (LLMs), can\neffectively capture subtle spatial patterns in noisy wireless telemetry, making\nthem reliable regressors. Compared to existing state-of-the-art methods, our\nmethod matches and often surpasses conventional approaches for multiple types\nof telemetry. Achieving sub-meter accuracy for RSSI and FTM and\ncentimeter-level precision for CSI demonstrates the potential of LLM-based\nlocalisation to outperform specialized techniques, all without handcrafted\nsignal processing or calibration.", "AI": {"tldr": "WiFiGPT, a GPT-based system, addresses WiFi indoor positioning challenges by leveraging LLMs to achieve high accuracy without manual calibration, outperforming traditional methods.", "motivation": "Current WiFi localization techniques face limitations due to environmental factors, vendor-specific telemetry variations, and lack of a unified model. WiFiGPT aims to overcome these issues.", "method": "WiFiGPT uses a Generative Pretrained Transformer (GPT) to capture spatial patterns in noisy WiFi telemetry, avoiding handcrafted signal processing.", "result": "WiFiGPT achieves sub-meter accuracy for RSSI and FTM, and centimeter-level precision for CSI, outperforming state-of-the-art methods.", "conclusion": "LLM-based localization, exemplified by WiFiGPT, shows promise in surpassing specialized techniques without manual intervention."}}
{"id": "2505.16548", "pdf": "https://arxiv.org/pdf/2505.16548", "abs": "https://arxiv.org/abs/2505.16548", "authors": ["Lucas Maystre", "Gabriel Barello", "Tudor Berariu", "Aleix Cambray", "Rares Dolga", "Alvaro Ortega Gonzalez", "Andrei Nica", "David Barber"], "title": "Incremental Sequence Classification with Temporal Consistency", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We address the problem of incremental sequence classification, where\npredictions are updated as new elements in the sequence are revealed. Drawing\non temporal-difference learning from reinforcement learning, we identify a\ntemporal-consistency condition that successive predictions should satisfy. We\nleverage this condition to develop a novel loss function for training\nincremental sequence classifiers. Through a concrete example, we demonstrate\nthat optimizing this loss can offer substantial gains in data efficiency. We\napply our method to text classification tasks and show that it improves\npredictive accuracy over competing approaches on several benchmark datasets. We\nfurther evaluate our approach on the task of verifying large language model\ngenerations for correctness in grade-school math problems. Our results show\nthat models trained with our method are better able to distinguish promising\ngenerations from unpromising ones after observing only a few tokens.", "AI": {"tldr": "A novel loss function for incremental sequence classification improves data efficiency and predictive accuracy, outperforming competing methods on benchmarks and aiding in verifying LLM-generated math solutions.", "motivation": "To address the challenge of updating predictions incrementally in sequences, inspired by temporal-difference learning, ensuring temporal consistency in successive predictions.", "method": "Develops a temporal-consistency-based loss function for training incremental sequence classifiers, validated on text classification and LLM-generated math problem verification.", "result": "Substantial gains in data efficiency and improved predictive accuracy on benchmark datasets; better distinction of promising LLM generations in math problems.", "conclusion": "The proposed method enhances incremental sequence classification, offering practical benefits in efficiency and accuracy, especially for early-stage prediction tasks."}}
{"id": "2505.16442", "pdf": "https://arxiv.org/pdf/2505.16442", "abs": "https://arxiv.org/abs/2505.16442", "authors": ["Yichen Li", "Qiankun Liu", "Zhenchao Jin", "Jiuzhe Wei", "Jing Nie", "Ying Fu"], "title": "MAFE R-CNN: Selecting More Samples to Learn Category-aware Features for Small Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Small object detection in intricate environments has consistently represented\na major challenge in the field of object detection. In this paper, we identify\nthat this difficulty stems from the detectors' inability to effectively learn\ndiscriminative features for objects of small size, compounded by the complexity\nof selecting high-quality small object samples during training, which motivates\nthe proposal of the Multi-Clue Assignment and Feature Enhancement\nR-CNN.Specifically, MAFE R-CNN integrates two pivotal components.The first is\nthe Multi-Clue Sample Selection (MCSS) strategy, in which the Intersection over\nUnion (IoU) distance, predicted category confidence, and ground truth region\nsizes are leveraged as informative clues in the sample selection process. This\nmethodology facilitates the selection of diverse positive samples and ensures a\nbalanced distribution of object sizes during training, thereby promoting\neffective model learning.The second is the Category-aware Feature Enhancement\nMechanism (CFEM), where we propose a simple yet effective category-aware memory\nmodule to explore the relationships among object features. Subsequently, we\nenhance the object feature representation by facilitating the interaction\nbetween category-aware features and candidate box features.Comprehensive\nexperiments conducted on the large-scale small object dataset SODA validate the\neffectiveness of the proposed method. The code will be made publicly available.", "AI": {"tldr": "MAFE R-CNN improves small object detection by introducing Multi-Clue Sample Selection and Category-aware Feature Enhancement Mechanism, validated on the SODA dataset.", "motivation": "The challenge of small object detection arises from ineffective feature learning and poor sample selection during training.", "method": "Integrates Multi-Clue Sample Selection (MCSS) using IoU, confidence, and size, and Category-aware Feature Enhancement Mechanism (CFEM) for feature interaction.", "result": "Demonstrated effectiveness on the SODA dataset.", "conclusion": "MAFE R-CNN addresses small object detection challenges with innovative sample selection and feature enhancement."}}
{"id": "2505.16418", "pdf": "https://arxiv.org/pdf/2505.16418", "abs": "https://arxiv.org/abs/2505.16418", "authors": ["Yoichi Aoki", "Soichiro Murakami", "Ukyo Honda", "Akihiko Kato"], "title": "Exploring the Relationship Between Diversity and Quality in Ad Text Generation", "categories": ["cs.CL"], "comment": null, "summary": "In natural language generation for advertising, creating diverse and engaging\nad texts is crucial for capturing a broad audience and avoiding advertising\nfatigue. Regardless of the importance of diversity, the impact of the\ndiversity-enhancing methods in ad text generation -- mainly tested on tasks\nsuch as summarization and machine translation -- has not been thoroughly\nexplored. Ad text generation significantly differs from these tasks owing to\nthe text style and requirements. This research explores the relationship\nbetween diversity and ad quality in ad text generation by considering multiple\nfactors, such as diversity-enhancing methods, their hyperparameters,\ninput-output formats, and the models.", "AI": {"tldr": "The paper explores the impact of diversity-enhancing methods on ad text generation, focusing on their relationship with ad quality, unlike prior work on summarization and translation.", "motivation": "Diverse ad texts are crucial for audience engagement, but the effectiveness of diversity methods in ad generation is understudied compared to other NLP tasks.", "method": "The study examines diversity-enhancing methods, their hyperparameters, input-output formats, and models to assess their impact on ad quality.", "result": "Not explicitly stated in the abstract, but the research aims to uncover the relationship between diversity and ad quality.", "conclusion": "The paper highlights the need to study diversity methods specifically for ad text generation due to its unique requirements and style."}}
{"id": "2505.15836", "pdf": "https://arxiv.org/pdf/2505.15836", "abs": "https://arxiv.org/abs/2505.15836", "authors": ["Aarav Lala", "Kalyan Cherukuri"], "title": "Quantum-Evolutionary Neural Networks for Multi-Agent Federated Learning", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "As artificial intelligence continues to drive innovation in complex,\ndecentralized environments, the need for scalable, adaptive, and\nprivacy-preserving decision-making systems has become critical. This paper\nintroduces a novel framework combining quantum-inspired neural networks with\nevolutionary algorithms to optimize real-time decision-making in multi-agent\nsystems (MAS). The proposed Quantum-Evolutionary Neural Network (QE-NN)\nleverages quantum computing principles -- such as quantum superposition and\nentanglement -- to enhance learning speed and decision accuracy, while\nintegrating evolutionary optimization to continually refine agent behaviors in\ndynamic, uncertain environments. By utilizing federated learning, QE-NN ensures\nprivacy preservation, enabling decentralized agents to collaborate without\nsharing sensitive data. The framework is designed to allow agents to adapt in\nreal-time to their environments, optimizing decision-making processes for\napplications in areas such as autonomous systems, smart cities, and healthcare.\nThis research represents a breakthrough in merging quantum computing,\nevolutionary optimization, and privacy-preserving techniques to solve complex\nproblems in multi-agent decision-making systems, pushing the boundaries of AI\nin real-world, privacy-sensitive applications.", "AI": {"tldr": "A novel framework, QE-NN, combines quantum-inspired neural networks and evolutionary algorithms for scalable, adaptive, and privacy-preserving decision-making in multi-agent systems.", "motivation": "The need for scalable, adaptive, and privacy-preserving decision-making systems in AI-driven decentralized environments.", "method": "Quantum-Evolutionary Neural Network (QE-NN) integrates quantum computing principles (superposition, entanglement) with evolutionary algorithms and federated learning.", "result": "Enhanced learning speed, decision accuracy, and real-time adaptability in dynamic environments while preserving privacy.", "conclusion": "QE-NN advances AI by merging quantum computing, evolutionary optimization, and privacy techniques for complex multi-agent decision-making."}}
{"id": "2505.16549", "pdf": "https://arxiv.org/pdf/2505.16549", "abs": "https://arxiv.org/abs/2505.16549", "authors": ["Trung V. Phan", "George A. Kevrekidis", "Soledad Villar", "Yannis G. Kevrekidis", "Juan M. Bello-Rivas"], "title": "Towards Coordinate- and Dimension-Agnostic Machine Learning for Partial Differential Equations", "categories": ["cs.LG", "35Q92, 68T07", "I.2.6; G.1.8"], "comment": null, "summary": "The machine learning methods for data-driven identification of partial\ndifferential equations (PDEs) are typically defined for a given number of\nspatial dimensions and a choice of coordinates the data have been collected in.\nThis dependence prevents the learned evolution equation from generalizing to\nother spaces. In this work, we reformulate the problem in terms of coordinate-\nand dimension-independent representations, paving the way toward what we call\n``spatially liberated\" PDE learning. To this end, we employ a machine learning\napproach to predict the evolution of scalar field systems expressed in the\nformalism of exterior calculus, which is coordinate-free and immediately\ngeneralizes to arbitrary dimensions by construction. We demonstrate the\nperformance of this approach in the FitzHugh-Nagumo and Barkley\nreaction-diffusion models, as well as the Patlak-Keller-Segel model informed by\nin-situ chemotactic bacteria observations. We provide extensive numerical\nexperiments that demonstrate that our approach allows for seamless transitions\nacross various spatial contexts. We show that the field dynamics learned in one\nspace can be used to make accurate predictions in other spaces with different\ndimensions, coordinate systems, boundary conditions, and curvatures.", "AI": {"tldr": "The paper introduces a coordinate-free, dimension-independent machine learning method for PDE identification, enabling generalization across spaces.", "motivation": "Current PDE learning methods depend on specific spatial dimensions and coordinates, limiting generalization.", "method": "Uses exterior calculus for coordinate-free, dimension-independent representations and applies machine learning to predict scalar field evolution.", "result": "Demonstrated success in reaction-diffusion models and chemotactic bacteria observations, showing seamless transitions across spatial contexts.", "conclusion": "The approach allows accurate predictions across varying dimensions, coordinates, boundaries, and curvatures, advancing PDE learning."}}
{"id": "2505.16447", "pdf": "https://arxiv.org/pdf/2505.16447", "abs": "https://arxiv.org/abs/2505.16447", "authors": ["Oliver Grainge", "Michael Milford", "Indu Bodala", "Sarvapali D. Ramchurn", "Shoaib Ehsan"], "title": "TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition", "categories": ["cs.CV"], "comment": null, "summary": "TAT-VPR is a ternary-quantized transformer that brings dynamic\naccuracy-efficiency trade-offs to visual SLAM loop-closure. By fusing ternary\nweights with a learned activation-sparsity gate, the model can control\ncomputation by up to 40% at run-time without degrading performance (Recall@1).\nThe proposed two-stage distillation pipeline preserves descriptor quality,\nletting it run on micro-UAV and embedded SLAM stacks while matching\nstate-of-the-art localization accuracy.", "AI": {"tldr": "TAT-VPR introduces a ternary-quantized transformer for dynamic accuracy-efficiency trade-offs in visual SLAM loop-closure, achieving up to 40% computation reduction without performance loss.", "motivation": "To enable efficient and adaptable visual SLAM loop-closure for resource-constrained platforms like micro-UAVs and embedded systems.", "method": "Fuses ternary weights with a learned activation-sparsity gate and employs a two-stage distillation pipeline to preserve descriptor quality.", "result": "Achieves up to 40% computation reduction at runtime without degrading Recall@1 performance, matching state-of-the-art localization accuracy.", "conclusion": "TAT-VPR successfully balances efficiency and accuracy, making it suitable for resource-limited applications while maintaining high performance."}}
{"id": "2505.16421", "pdf": "https://arxiv.org/pdf/2505.16421", "abs": "https://arxiv.org/abs/2505.16421", "authors": ["Zhepei Wei", "Wenlin Yao", "Yao Liu", "Weizhi Zhang", "Qin Lu", "Liang Qiu", "Changlong Yu", "Puyang Xu", "Chao Zhang", "Bing Yin", "Hyokun Yun", "Lihong Li"], "title": "WebAgent-R1: Training Web Agents via End-to-End Multi-Turn Reinforcement Learning", "categories": ["cs.CL", "cs.LG"], "comment": "Preprint", "summary": "While reinforcement learning (RL) has demonstrated remarkable success in\nenhancing large language models (LLMs), it has primarily focused on single-turn\ntasks such as solving math problems. Training effective web agents for\nmulti-turn interactions remains challenging due to the complexity of\nlong-horizon decision-making across dynamic web interfaces. In this work, we\npresent WebAgent-R1, a simple yet effective end-to-end multi-turn RL framework\nfor training web agents. It learns directly from online interactions with web\nenvironments by asynchronously generating diverse trajectories, entirely guided\nby binary rewards depending on task success. Experiments on the WebArena-Lite\nbenchmark demonstrate the effectiveness of WebAgent-R1, boosting the task\nsuccess rate of Qwen-2.5-3B from 6.1% to 33.9% and Llama-3.1-8B from 8.5% to\n44.8%, significantly outperforming existing state-of-the-art methods and strong\nproprietary models such as OpenAI o3. In-depth analyses reveal the\neffectiveness of the thinking-based prompting strategy and test-time scaling\nthrough increased interactions for web tasks. We further investigate different\nRL initialization policies by introducing two variants, namely WebAgent-R1-Zero\nand WebAgent-R1-CoT, which highlight the importance of the warm-up training\nstage (i.e., behavior cloning) and provide insights on incorporating long\nchain-of-thought (CoT) reasoning in web agents.", "AI": {"tldr": "WebAgent-R1 is an RL framework for multi-turn web interactions, improving task success rates significantly over existing methods.", "motivation": "Existing RL for LLMs focuses on single-turn tasks; multi-turn web interactions are complex and underexplored.", "method": "WebAgent-R1 uses asynchronous trajectory generation guided by binary rewards, tested on WebArena-Lite.", "result": "Boosts success rates (Qwen-2.5-3B: 6.1% to 33.9%; Llama-3.1-8B: 8.5% to 44.8%), outperforming state-of-the-art.", "conclusion": "Thinking-based prompting and warm-up training (behavior cloning) are key; variants (R1-Zero, R1-CoT) offer insights for future work."}}
{"id": "2505.15840", "pdf": "https://arxiv.org/pdf/2505.15840", "abs": "https://arxiv.org/abs/2505.15840", "authors": ["Zizheng Zhu", "Yingchao Yu", "Zeqi Zheng", "Zhaofei Yu", "Yaochu Jin"], "title": "TDFormer: A Top-Down Attention-Controlled Spiking Transformer", "categories": ["cs.NE", "cs.AI", "cs.CV"], "comment": "28 pages", "summary": "Traditional spiking neural networks (SNNs) can be viewed as a combination of\nmultiple subnetworks with each running for one time step, where the parameters\nare shared, and the membrane potential serves as the only information link\nbetween them. However, the implicit nature of the membrane potential limits its\nability to effectively represent temporal information. As a result, each time\nstep cannot fully leverage information from previous time steps, seriously\nlimiting the model's performance. Inspired by the top-down mechanism in the\nbrain, we introduce TDFormer, a novel model with a top-down feedback structure\nthat functions hierarchically and leverages high-order representations from\nearlier time steps to modulate the processing of low-order information at later\nstages. The feedback structure plays a role from two perspectives: 1) During\nforward propagation, our model increases the mutual information across time\nsteps, indicating that richer temporal information is being transmitted and\nintegrated in different time steps. 2) During backward propagation, we\ntheoretically prove that the feedback structure alleviates the problem of\nvanishing gradients along the time dimension. We find that these mechanisms\ntogether significantly and consistently improve the model performance on\nmultiple datasets. In particular, our model achieves state-of-the-art\nperformance on ImageNet with an accuracy of 86.83%.", "AI": {"tldr": "TDFormer introduces a top-down feedback structure in SNNs to enhance temporal information flow and mitigate vanishing gradients, achieving state-of-the-art performance on ImageNet (86.83%).", "motivation": "The implicit nature of membrane potential in SNNs limits temporal information representation, hindering performance.", "method": "TDFormer uses a hierarchical top-down feedback mechanism to leverage high-order representations from earlier time steps for modulating low-order information.", "result": "The model increases mutual information across time steps and alleviates vanishing gradients, improving performance on multiple datasets.", "conclusion": "TDFormer's feedback structure significantly boosts SNN performance, achieving 86.83% accuracy on ImageNet."}}
{"id": "2505.16563", "pdf": "https://arxiv.org/pdf/2505.16563", "abs": "https://arxiv.org/abs/2505.16563", "authors": ["Chen Gong", "Rui Xing", "Zhenzhe Zheng", "Fan Wu"], "title": "A Two-Stage Data Selection Framework for Data-Efficient Model Training on Edge Devices", "categories": ["cs.LG"], "comment": null, "summary": "The demand for machine learning (ML) model training on edge devices is\nescalating due to data privacy and personalized service needs. However, we\nobserve that current on-device model training is hampered by the\nunder-utilization of on-device data, due to low training throughput, limited\nstorage and diverse data importance. To improve data resource utilization, we\npropose a two-stage data selection framework {\\sf Titan} to select the most\nimportant data batch from streaming data for model training with guaranteed\nefficiency and effectiveness. Specifically, in the first stage, {\\sf Titan}\nfilters out a candidate dataset with potentially high importance in a\ncoarse-grained manner.In the second stage of fine-grained selection, we propose\na theoretically optimal data selection strategy to identify the data batch with\nthe highest model performance improvement to current training round. To further\nenhance time-and-resource efficiency, {\\sf Titan} leverages a pipeline to\nco-execute data selection and model training, and avoids resource conflicts by\nexploiting idle computing resources. We evaluate {\\sf Titan} on real-world edge\ndevices and three representative edge computing tasks with diverse models and\ndata modalities. Empirical results demonstrate that {\\sf Titan} achieves up to\n$43\\%$ reduction in training time and $6.2\\%$ increase in final accuracy with\nminor system overhead, such as data processing delay, memory footprint and\nenergy consumption.", "AI": {"tldr": "Titan is a two-stage data selection framework for efficient on-device ML training, improving throughput and accuracy with minimal overhead.", "motivation": "Addressing under-utilization of on-device data due to low training throughput, storage limits, and diverse data importance.", "method": "A two-stage framework: coarse-grained filtering of high-importance data, followed by fine-grained selection of the most impactful batch. Uses a pipeline for co-execution and idle resources.", "result": "Reduces training time by up to 43% and increases accuracy by 6.2% with minor system overhead.", "conclusion": "Titan effectively enhances on-device training efficiency and performance, making it practical for edge computing."}}
{"id": "2505.16452", "pdf": "https://arxiv.org/pdf/2505.16452", "abs": "https://arxiv.org/abs/2505.16452", "authors": ["Mohamed S. Elmahdy", "Marius Staring", "Patrick J. H. de Koning", "Samer Alabed", "Mahan Salehi", "Faisal Alandejani", "Michael Sharkey", "Ziad Aldabbagh", "Andrew J. Swift", "Rob J. van der Geest"], "title": "CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "15 pages, 7 figures, 1 appendix", "summary": "Accurate and efficient quantification of cardiac function is essential for\nthe estimation of prognosis of cardiovascular diseases (CVDs). One of the most\ncommonly used metrics for evaluating cardiac pumping performance is left\nventricular ejection fraction (LVEF). However, LVEF can be affected by factors\nsuch as inter-observer variability and varying pre-load and after-load\nconditions, which can reduce its reproducibility. Additionally, cardiac\ndysfunction may not always manifest as alterations in LVEF, such as in heart\nfailure and cardiotoxicity diseases. An alternative measure that can provide a\nrelatively load-independent quantitative assessment of myocardial contractility\nis myocardial strain and strain rate. By using LVEF in combination with\nmyocardial strain, it is possible to obtain a thorough description of cardiac\nfunction. Automated estimation of LVEF and other volumetric measures from\ncine-MRI sequences can be achieved through segmentation models, while strain\ncalculation requires the estimation of tissue displacement between sequential\nframes, which can be accomplished using registration models. These tasks are\noften performed separately, potentially limiting the assessment of cardiac\nfunction. To address this issue, in this study we propose an end-to-end deep\nlearning (DL) model that jointly estimates groupwise (GW) registration and\nsegmentation for cardiac cine-MRI images. The proposed anatomically-guided Deep\nGW network was trained and validated on a large dataset of 4-chamber view\ncine-MRI image series of 374 subjects. A quantitative comparison with\nconventional GW registration using elastix and two DL-based methods showed that\nthe proposed model improved performance and substantially reduced computation\ntime.", "AI": {"tldr": "The paper proposes an end-to-end deep learning model for joint groupwise registration and segmentation in cardiac cine-MRI to improve cardiac function assessment.", "motivation": "LVEF has limitations in reproducibility and sensitivity, and existing methods for cardiac function assessment are often performed separately, limiting accuracy.", "method": "An anatomically-guided Deep GW network is introduced for joint estimation of groupwise registration and segmentation in cardiac cine-MRI.", "result": "The model outperformed conventional GW registration and DL-based methods, improving performance and reducing computation time.", "conclusion": "The proposed model offers a more efficient and accurate approach for comprehensive cardiac function assessment."}}
{"id": "2505.16425", "pdf": "https://arxiv.org/pdf/2505.16425", "abs": "https://arxiv.org/abs/2505.16425", "authors": ["Jing Bi", "Pinxin Liu", "Ali Vosoughi", "Jiarui Wu", "Jinxi He", "Chenliang Xu"], "title": "$I^2G$: Generating Instructional Illustrations via Text-Conditioned Diffusion", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 5 figures, under review", "summary": "The effective communication of procedural knowledge remains a significant\nchallenge in natural language processing (NLP), as purely textual instructions\noften fail to convey complex physical actions and spatial relationships. We\naddress this limitation by proposing a language-driven framework that\ntranslates procedural text into coherent visual instructions. Our approach\nmodels the linguistic structure of instructional content by decomposing it into\ngoal statements and sequential steps, then conditioning visual generation on\nthese linguistic elements. We introduce three key innovations: (1) a\nconstituency parser-based text encoding mechanism that preserves semantic\ncompleteness even with lengthy instructions, (2) a pairwise discourse coherence\nmodel that maintains consistency across instruction sequences, and (3) a novel\nevaluation protocol specifically designed for procedural language-to-image\nalignment. Our experiments across three instructional datasets (HTStep,\nCaptainCook4D, and WikiAll) demonstrate that our method significantly\noutperforms existing baselines in generating visuals that accurately reflect\nthe linguistic content and sequential nature of instructions. This work\ncontributes to the growing body of research on grounding procedural language in\nvisual content, with applications spanning education, task guidance, and\nmultimodal language understanding.", "AI": {"tldr": "A framework translates procedural text into visual instructions using linguistic structure, outperforming baselines in accuracy.", "motivation": "Addressing the challenge of conveying complex actions and spatial relationships through text in NLP.", "method": "Decomposes text into goal statements and steps, using a constituency parser, discourse coherence model, and a new evaluation protocol.", "result": "Outperforms baselines on three datasets (HTStep, CaptainCook4D, WikiAll) in generating accurate visuals.", "conclusion": "Advances grounding procedural language in visuals, with applications in education and multimodal understanding."}}
{"id": "2505.15849", "pdf": "https://arxiv.org/pdf/2505.15849", "abs": "https://arxiv.org/abs/2505.15849", "authors": ["Reed Bender", "Karina Kofman", "Blaise Ag\u00fcera y Arcas", "Michael Levin"], "title": "What Lives? A meta-analysis of diverse opinions on the definition of life", "categories": ["q-bio.OT", "cs.AI", "cs.CY", "q-bio.BM", "q-bio.CB", "q-bio.SC", "stat.AP"], "comment": "54 pages, 4 figures, 2 tables, 11 supplemental figures, 3\n  supplemental tables", "summary": "The question of \"what is life?\" has challenged scientists and philosophers\nfor centuries, producing an array of definitions that reflect both the mystery\nof its emergence and the diversity of disciplinary perspectives brought to bear\non the question. Despite significant progress in our understanding of\nbiological systems, psychology, computation, and information theory, no single\ndefinition for life has yet achieved universal acceptance. This challenge\nbecomes increasingly urgent as advances in synthetic biology, artificial\nintelligence, and astrobiology challenge our traditional conceptions of what it\nmeans to be alive. We undertook a methodological approach that leverages large\nlanguage models (LLMs) to analyze a set of definitions of life provided by a\ncurated set of cross-disciplinary experts. We used a novel pairwise correlation\nanalysis to map the definitions into distinct feature vectors, followed by\nagglomerative clustering, intra-cluster semantic analysis, and t-SNE projection\nto reveal underlying conceptual archetypes. This methodology revealed a\ncontinuous landscape of the themes relating to the definition of life,\nsuggesting that what has historically been approached as a binary taxonomic\nproblem should be instead conceived as differentiated perspectives within a\nunified conceptual latent space. We offer a new methodological bridge between\nreductionist and holistic approaches to fundamental questions in science and\nphilosophy, demonstrating how computational semantic analysis can reveal\nconceptual patterns across disciplinary boundaries, and opening similar\npathways for addressing other contested definitional territories across the\nsciences.", "AI": {"tldr": "The paper explores the definition of life using LLMs to analyze cross-disciplinary definitions, revealing a continuous conceptual landscape rather than binary classifications.", "motivation": "The lack of a universally accepted definition of life, especially with advances in synthetic biology and AI, motivates a computational approach to unify diverse perspectives.", "method": "The study uses LLMs, pairwise correlation analysis, agglomerative clustering, semantic analysis, and t-SNE projection to map and cluster definitions of life.", "result": "The analysis reveals a continuous conceptual landscape of life definitions, suggesting a unified latent space instead of binary classifications.", "conclusion": "The study bridges reductionist and holistic approaches, demonstrating computational semantic analysis's potential for resolving contested definitions across disciplines."}}
{"id": "2505.16567", "pdf": "https://arxiv.org/pdf/2505.16567", "abs": "https://arxiv.org/abs/2505.16567", "authors": ["Thibaud Gloaguen", "Mark Vero", "Robin Staab", "Martin Vechev"], "title": "Finetuning-Activated Backdoors in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Finetuning openly accessible Large Language Models (LLMs) has become standard\npractice for achieving task-specific performance improvements. Until now,\nfinetuning has been regarded as a controlled and secure process in which\ntraining on benign datasets led to predictable behaviors. In this paper, we\ndemonstrate for the first time that an adversary can create poisoned LLMs that\ninitially appear benign but exhibit malicious behaviors once finetuned by\ndownstream users. To this end, our proposed attack, FAB (Finetuning-Activated\nBackdoor), poisons an LLM via meta-learning techniques to simulate downstream\nfinetuning, explicitly optimizing for the emergence of malicious behaviors in\nthe finetuned models. At the same time, the poisoned LLM is regularized to\nretain general capabilities and to exhibit no malicious behaviors prior to\nfinetuning. As a result, when users finetune the seemingly benign model on\ntheir own datasets, they unknowingly trigger its hidden backdoor behavior. We\ndemonstrate the effectiveness of FAB across multiple LLMs and three target\nbehaviors: unsolicited advertising, refusal, and jailbreakability.\nAdditionally, we show that FAB-backdoors are robust to various finetuning\nchoices made by the user (e.g., dataset, number of steps, scheduler). Our\nfindings challenge prevailing assumptions about the security of finetuning,\nrevealing yet another critical attack vector exploiting the complexities of\nLLMs.", "AI": {"tldr": "The paper introduces FAB, a finetuning-activated backdoor attack on LLMs, showing how poisoned models appear benign but turn malicious after downstream finetuning.", "motivation": "To expose vulnerabilities in the finetuning process of LLMs, challenging the assumption that finetuning is secure and predictable.", "method": "Uses meta-learning to poison LLMs, optimizing for hidden malicious behaviors triggered by finetuning while retaining general capabilities.", "result": "FAB successfully induces malicious behaviors (e.g., advertising, refusal, jailbreakability) across multiple LLMs, robust to user finetuning choices.", "conclusion": "Finetuning is not inherently secure; FAB reveals a critical attack vector, urging reevaluation of LLM security practices."}}
{"id": "2505.16456", "pdf": "https://arxiv.org/pdf/2505.16456", "abs": "https://arxiv.org/abs/2505.16456", "authors": ["Siwei Meng", "Yawei Luo", "Ping Liu"], "title": "MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in static 3D generation have intensified the demand for\nphysically consistent dynamic 3D content. However, existing video generation\nmodels, including diffusion-based methods, often prioritize visual realism\nwhile neglecting physical plausibility, resulting in implausible object\ndynamics. Prior approaches for physics-aware dynamic generation typically rely\non large-scale annotated datasets or extensive model fine-tuning, which imposes\nsignificant computational and data collection burdens and limits scalability\nacross scenarios. To address these challenges, we present MAGIC, a\ntraining-free framework for single-image physical property inference and\ndynamic generation, integrating pretrained image-to-video diffusion models with\niterative LLM-based reasoning. Our framework generates motion-rich videos from\na static image and closes the visual-to-physical gap through a\nconfidence-driven LLM feedback loop that adaptively steers the diffusion model\ntoward physics-relevant motion. To translate visual dynamics into controllable\nphysical behavior, we further introduce a differentiable MPM simulator\noperating directly on 3D Gaussians reconstructed from the single image,\nenabling physically grounded, simulation-ready outputs without any supervision\nor model tuning. Experiments show that MAGIC outperforms existing physics-aware\ngenerative methods in inference accuracy and achieves greater temporal\ncoherence than state-of-the-art video diffusion models.", "AI": {"tldr": "MAGIC is a training-free framework for generating physically consistent dynamic 3D content from static images, combining pretrained diffusion models with LLM-based reasoning and a differentiable simulator.", "motivation": "Existing video generation models lack physical plausibility, and prior physics-aware methods require extensive datasets or tuning, limiting scalability.", "method": "Integrates pretrained image-to-video diffusion models with iterative LLM-based reasoning and a differentiable MPM simulator for physics-relevant motion.", "result": "MAGIC outperforms physics-aware generative methods in accuracy and achieves better temporal coherence than top video diffusion models.", "conclusion": "MAGIC bridges the visual-to-physical gap efficiently, enabling physics-consistent dynamic generation without training or supervision."}}
{"id": "2505.16429", "pdf": "https://arxiv.org/pdf/2505.16429", "abs": "https://arxiv.org/abs/2505.16429", "authors": ["Song Jin", "Juntian Zhang", "Yuhan Liu", "Xun Zhang", "Yufei Zhang", "Guojun Yin", "Fei Jiang", "Wei Lin", "Rui Yan"], "title": "Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform for Dynamic Recommender Systems", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating and iterating upon recommender systems is crucial, yet traditional\nA/B testing is resource-intensive, and offline methods struggle with dynamic\nuser-platform interactions. While agent-based simulation is promising, existing\nplatforms often lack a mechanism for user actions to dynamically reshape the\nenvironment. To bridge this gap, we introduce RecInter, a novel agent-based\nsimulation platform for recommender systems featuring a robust interaction\nmechanism. In RecInter platform, simulated user actions (e.g., likes, reviews,\npurchases) dynamically update item attributes in real-time, and introduced\nMerchant Agents can reply, fostering a more realistic and evolving ecosystem.\nHigh-fidelity simulation is ensured through Multidimensional User Profiling\nmodule, Advanced Agent Architecture, and LLM fine-tuned on Chain-of-Thought\n(CoT) enriched interaction data. Our platform achieves significantly improved\nsimulation credibility and successfully replicates emergent phenomena like\nBrand Loyalty and the Matthew Effect. Experiments demonstrate that this\ninteraction mechanism is pivotal for simulating realistic system evolution,\nestablishing our platform as a credible testbed for recommender systems\nresearch.", "AI": {"tldr": "RecInter is an agent-based simulation platform for recommender systems with dynamic user-platform interactions, improving realism and credibility.", "motivation": "Traditional A/B testing is resource-heavy, and offline methods fail to capture dynamic user-platform interactions. Existing simulations lack mechanisms for user actions to reshape the environment.", "method": "RecInter features a robust interaction mechanism where user actions update item attributes in real-time, supported by Merchant Agents and advanced profiling. It uses LLM fine-tuned on Chain-of-Thought data.", "result": "The platform achieves high-fidelity simulation, replicating emergent phenomena like Brand Loyalty and the Matthew Effect, proving its credibility.", "conclusion": "RecInter provides a realistic and evolving testbed for recommender systems research, addressing gaps in existing simulation methods."}}
{"id": "2505.15851", "pdf": "https://arxiv.org/pdf/2505.15851", "abs": "https://arxiv.org/abs/2505.15851", "authors": ["Silvia Crafa", "Teresa Scantamburlo"], "title": "Exploring Moral Exercises for Human Oversight of AI systems: Insights from Three Pilot Studies", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "This paper elaborates on the concept of moral exercises as a means to help AI\nactors cultivate virtues that enable effective human oversight of AI systems.\nWe explore the conceptual framework and significance of moral exercises,\nsituating them within the contexts of philosophical discourse, ancient\npractices, and contemporary AI ethics scholarship. We outline the core pillars\nof the moral exercises methodology - eliciting an engaged personal disposition,\nfostering relational understanding, and cultivating technomoral wisdom - and\nemphasize their relevance to key activities and competencies essential for\nhuman oversight of AI systems. Our argument is supported by findings from three\npilot studies involving a company, a multidisciplinary team of AI researchers,\nand higher education students. These studies allow us to explore both the\npotential and the limitations of moral exercises. Based on the collected data,\nwe offer insights into how moral exercises can foster a responsible AI culture\nwithin organizations, and suggest directions for future research.", "AI": {"tldr": "The paper introduces moral exercises to help AI actors develop virtues for effective human oversight of AI systems, supported by pilot studies.", "motivation": "To cultivate virtues in AI actors for better human oversight of AI systems, bridging philosophical, historical, and contemporary AI ethics.", "method": "Conceptual framework of moral exercises (engaged disposition, relational understanding, technomoral wisdom) tested via three pilot studies.", "result": "Pilot studies reveal potential and limitations of moral exercises in fostering responsible AI culture.", "conclusion": "Moral exercises can enhance AI oversight; future research directions are suggested."}}
{"id": "2505.16577", "pdf": "https://arxiv.org/pdf/2505.16577", "abs": "https://arxiv.org/abs/2505.16577", "authors": ["Yu Zuo", "Dalin Qin", "Yi Wang"], "title": "Large Language Model-Empowered Interactive Load Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "The growing complexity of power systems has made accurate load forecasting\nmore important than ever. An increasing number of advanced load forecasting\nmethods have been developed. However, the static design of current methods\noffers no mechanism for human-model interaction. As the primary users of\nforecasting models, system operators often find it difficult to understand and\napply these advanced models, which typically requires expertise in artificial\nintelligence (AI). This also prevents them from incorporating their experience\nand real-world contextual understanding into the forecasting process. Recent\nbreakthroughs in large language models (LLMs) offer a new opportunity to\naddress this issue. By leveraging their natural language understanding and\nreasoning capabilities, we propose an LLM-based multi-agent collaboration\nframework to bridge the gap between human operators and forecasting models. A\nset of specialized agents is designed to perform different tasks in the\nforecasting workflow and collaborate via a dedicated communication mechanism.\nThis framework embeds interactive mechanisms throughout the load forecasting\npipeline, reducing the technical threshold for non-expert users and enabling\nthe integration of human experience. Our experiments demonstrate that the\ninteractive load forecasting accuracy can be significantly improved when users\nprovide proper insight in key stages. Our cost analysis shows that the\nframework remains affordable, making it practical for real-world deployment.", "AI": {"tldr": "An LLM-based multi-agent framework is proposed to improve load forecasting by enabling human-model interaction, reducing technical barriers, and integrating human expertise.", "motivation": "Current load forecasting methods lack human-model interaction, making them hard for system operators to use and integrate their experience.", "method": "A multi-agent collaboration framework using LLMs is designed to embed interactive mechanisms in the forecasting workflow.", "result": "The framework improves forecasting accuracy with human insights and remains cost-effective for real-world use.", "conclusion": "The proposed framework successfully bridges the gap between human operators and forecasting models, enhancing usability and accuracy."}}
{"id": "2505.16463", "pdf": "https://arxiv.org/pdf/2505.16463", "abs": "https://arxiv.org/abs/2505.16463", "authors": ["Jiquan Shan", "Junxiao Wang", "Lifeng Zhao", "Liang Cai", "Hongyuan Zhang", "Ioannis Liritzis"], "title": "AnchorFormer: Differentiable Anchor Attention for Efficient Vision Transformer", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recently, vision transformers (ViTs) have achieved excellent performance on\nvision tasks by measuring the global self-attention among the image patches.\nGiven $n$ patches, they will have quadratic complexity such as\n$\\mathcal{O}(n^2)$ and the time cost is high when splitting the input image\nwith a small granularity. Meanwhile, the pivotal information is often randomly\ngathered in a few regions of an input image, some tokens may not be helpful for\nthe downstream tasks. To handle this problem, we introduce an anchor-based\nefficient vision transformer (AnchorFormer), which employs the anchor tokens to\nlearn the pivotal information and accelerate the inference. Firstly, by\nestimating the bipartite attention between the anchors and tokens, the\ncomplexity will be reduced from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$, where\n$m$ is an anchor number and $m < n$. Notably, by representing the anchors with\nthe neurons in a neural layer, we can differentiable learn these distributions\nand approximate global self-attention through the Markov process. Moreover, we\nextend the proposed model to three downstream tasks including classification,\ndetection, and segmentation. Extensive experiments show the effectiveness of\nour AnchorFormer, e.g., achieving up to a 9.0% higher accuracy or 46.7% FLOPs\nreduction on ImageNet classification, 81.3% higher mAP on COCO detection under\ncomparable FLOPs, as compared to the current baselines.", "AI": {"tldr": "AnchorFormer reduces ViT complexity from O(n\u00b2) to O(mn) using anchor tokens, improving efficiency and performance.", "motivation": "ViTs have high computational cost (O(n\u00b2)) and gather pivotal information randomly. AnchorFormer addresses this by focusing on key regions.", "method": "Uses anchor tokens to learn pivotal information, reducing complexity via bipartite attention and differentiable anchor learning.", "result": "Achieves 9.0% higher accuracy or 46.7% FLOPs reduction on ImageNet, 81.3% higher mAP on COCO detection.", "conclusion": "AnchorFormer efficiently approximates global self-attention, enhancing performance in vision tasks."}}
{"id": "2505.16460", "pdf": "https://arxiv.org/pdf/2505.16460", "abs": "https://arxiv.org/abs/2505.16460", "authors": ["Ikhlasul Akmal Hanif", "Eryawan Presma Yulianrifat", "Jaycent Gunawan Ongris", "Eduardus Tjitrahardja", "Muhammad Falensi Azmi", "Rahmat Bryan Naufal", "Alfan Farizki Wicaksono"], "title": "University of Indonesia at SemEval-2025 Task 11: Evaluating State-of-the-Art Encoders for Multi-Label Emotion Detection", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "16 pages, 13 tables, 1 figures", "summary": "This paper presents our approach for SemEval 2025 Task 11 Track A, focusing\non multilabel emotion classification across 28 languages. We explore two main\nstrategies: fully fine-tuning transformer models and classifier-only training,\nevaluating different settings such as fine-tuning strategies, model\narchitectures, loss functions, encoders, and classifiers. Our findings suggest\nthat training a classifier on top of prompt-based encoders such as mE5 and BGE\nyields significantly better results than fully fine-tuning XLMR and mBERT. Our\nbest-performing model on the final leaderboard is an ensemble combining\nmultiple BGE models, where CatBoost serves as the classifier, with different\nconfigurations. This ensemble achieves an average F1-macro score of 56.58\nacross all languages.", "AI": {"tldr": "The paper explores multilabel emotion classification across 28 languages, comparing fine-tuning transformer models and classifier-only training. The best results come from using prompt-based encoders with CatBoost classifiers, achieving an average F1-macro score of 56.58.", "motivation": "To improve multilabel emotion classification performance across multiple languages by evaluating different training strategies and model architectures.", "method": "Two main strategies: fully fine-tuning transformer models (XLMR, mBERT) and classifier-only training on prompt-based encoders (mE5, BGE). Evaluated various settings like loss functions, encoders, and classifiers.", "result": "Classifier-only training on prompt-based encoders outperformed fully fine-tuning. The best model was an ensemble of BGE models with CatBoost, achieving an average F1-macro score of 56.58.", "conclusion": "Prompt-based encoders with classifier-only training, especially when ensembled, yield superior performance for multilabel emotion classification across diverse languages."}}
{"id": "2505.15856", "pdf": "https://arxiv.org/pdf/2505.15856", "abs": "https://arxiv.org/abs/2505.15856", "authors": ["Kai Yin", "Xiangjue Dong", "Chengkai Liu", "Lipai Huang", "Yiming Xiao", "Zhewei Liu", "Ali Mostafavi", "James Caverlee"], "title": "DisastIR: A Comprehensive Information Retrieval Benchmark for Disaster Management", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Effective disaster management requires timely access to accurate and\ncontextually relevant information. Existing Information Retrieval (IR)\nbenchmarks, however, focus primarily on general or specialized domains, such as\nmedicine or finance, neglecting the unique linguistic complexity and diverse\ninformation needs encountered in disaster management scenarios. To bridge this\ngap, we introduce DisastIR, the first comprehensive IR evaluation benchmark\nspecifically tailored for disaster management. DisastIR comprises 9,600 diverse\nuser queries and more than 1.3 million labeled query-passage pairs, covering 48\ndistinct retrieval tasks derived from six search intents and eight general\ndisaster categories that include 301 specific event types. Our evaluations of\n30 state-of-the-art retrieval models demonstrate significant performance\nvariances across tasks, with no single model excelling universally.\nFurthermore, comparative analyses reveal significant performance gaps between\ngeneral-domain and disaster management-specific tasks, highlighting the\nnecessity of disaster management-specific benchmarks for guiding IR model\nselection to support effective decision-making in disaster management\nscenarios. All source codes and DisastIR are available at\nhttps://github.com/KaiYin97/Disaster_IR.", "AI": {"tldr": "DisastIR is a new IR benchmark for disaster management, addressing gaps in existing benchmarks by providing diverse queries and labeled data. Evaluations show no single model performs best across all tasks, emphasizing the need for domain-specific benchmarks.", "motivation": "Existing IR benchmarks lack focus on disaster management, which has unique linguistic and information needs.", "method": "DisastIR includes 9,600 queries and 1.3 million labeled query-passage pairs across 48 tasks, derived from six search intents and eight disaster categories.", "result": "Evaluations of 30 models show performance variances, with no universal leader, and gaps between general and disaster-specific tasks.", "conclusion": "DisastIR highlights the need for domain-specific benchmarks to improve IR model selection for disaster management."}}
{"id": "2505.16581", "pdf": "https://arxiv.org/pdf/2505.16581", "abs": "https://arxiv.org/abs/2505.16581", "authors": ["Max Weltevrede", "Moritz A. Zanger", "Matthijs T. J. Spaan", "Wendelin B\u00f6hmer"], "title": "How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In the zero-shot policy transfer setting in reinforcement learning, the goal\nis to train an agent on a fixed set of training environments so that it can\ngeneralise to similar, but unseen, testing environments. Previous work has\nshown that policy distillation after training can sometimes produce a policy\nthat outperforms the original in the testing environments. However, it is not\nyet entirely clear why that is, or what data should be used to distil the\npolicy. In this paper, we prove, under certain assumptions, a generalisation\nbound for policy distillation after training. The theory provides two practical\ninsights: for improved generalisation, you should 1) train an ensemble of\ndistilled policies, and 2) distil it on as much data from the training\nenvironments as possible. We empirically verify that these insights hold in\nmore general settings, when the assumptions required for the theory no longer\nhold. Finally, we demonstrate that an ensemble of policies distilled on a\ndiverse dataset can generalise significantly better than the original agent.", "AI": {"tldr": "Policy distillation in zero-shot RL improves generalization; train ensembles and use diverse training data.", "motivation": "Understand why policy distillation outperforms original policies in unseen environments and identify optimal distillation data.", "method": "Prove generalization bound for policy distillation, suggesting ensemble training and diverse data usage.", "result": "Empirical validation shows better generalization with ensembles and diverse data, outperforming original agents.", "conclusion": "Ensemble distillation on diverse data significantly enhances zero-shot policy transfer."}}
{"id": "2505.16474", "pdf": "https://arxiv.org/pdf/2505.16474", "abs": "https://arxiv.org/abs/2505.16474", "authors": ["Yu Zhang", "Xingzhuo Guo", "Haoran Xu", "Mingsheng Long"], "title": "Consistent World Models via Foresight Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion and flow-based models have enabled significant progress in\ngeneration tasks across various modalities and have recently found applications\nin world modeling. However, unlike typical generation tasks that encourage\nsample diversity, world models entail different sources of uncertainty and\nrequire consistent samples aligned with the ground-truth trajectory, which is a\nlimitation we empirically observe in diffusion models. We argue that a key\nbottleneck in learning consistent diffusion-based world models lies in the\nsuboptimal predictive ability, which we attribute to the entanglement of\ncondition understanding and target denoising within shared architectures and\nco-training schemes. To address this, we propose Foresight Diffusion\n(ForeDiff), a diffusion-based world modeling framework that enhances\nconsistency by decoupling condition understanding from target denoising.\nForeDiff incorporates a separate deterministic predictive stream to process\nconditioning inputs independently of the denoising stream, and further\nleverages a pretrained predictor to extract informative representations that\nguide generation. Extensive experiments on robot video prediction and\nscientific spatiotemporal forecasting show that ForeDiff improves both\npredictive accuracy and sample consistency over strong baselines, offering a\npromising direction for diffusion-based world models.", "AI": {"tldr": "ForeDiff improves diffusion-based world models by decoupling condition understanding from target denoising, enhancing consistency and predictive accuracy.", "motivation": "Diffusion models struggle with consistent sample alignment in world modeling due to entangled condition understanding and denoising.", "method": "Proposes ForeDiff, a framework with separate streams for condition understanding and denoising, leveraging a pretrained predictor.", "result": "ForeDiff outperforms baselines in predictive accuracy and sample consistency in robot video prediction and spatiotemporal forecasting.", "conclusion": "ForeDiff offers a promising direction for consistent diffusion-based world models."}}
{"id": "2505.16467", "pdf": "https://arxiv.org/pdf/2505.16467", "abs": "https://arxiv.org/abs/2505.16467", "authors": ["Vera Neplenbroek", "Arianna Bisazza", "Raquel Fern\u00e1ndez"], "title": "Reading Between the Prompts: How Stereotypes Shape LLM's Implicit Personalization", "categories": ["cs.CL"], "comment": null, "summary": "Generative Large Language Models (LLMs) infer user's demographic information\nfrom subtle cues in the conversation -- a phenomenon called implicit\npersonalization. Prior work has shown that such inferences can lead to lower\nquality responses for users assumed to be from minority groups, even when no\ndemographic information is explicitly provided. In this work, we systematically\nexplore how LLMs respond to stereotypical cues using controlled synthetic\nconversations, by analyzing the models' latent user representations through\nboth model internals and generated answers to targeted user questions. Our\nfindings reveal that LLMs do infer demographic attributes based on these\nstereotypical signals, which for a number of groups even persists when the user\nexplicitly identifies with a different demographic group. Finally, we show that\nthis form of stereotype-driven implicit personalization can be effectively\nmitigated by intervening on the model's internal representations using a\ntrained linear probe to steer them toward the explicitly stated identity. Our\nresults highlight the need for greater transparency and control in how LLMs\nrepresent user identity.", "AI": {"tldr": "LLMs infer demographics from conversation cues, leading to biased responses. This study shows how stereotypes influence LLMs and proposes a mitigation method using internal representation intervention.", "motivation": "To understand and address how LLMs infer and act on demographic stereotypes, even when users explicitly state their identity, which can harm minority groups.", "method": "Used controlled synthetic conversations to analyze LLMs' latent user representations, examining model internals and generated responses to targeted questions.", "result": "LLMs infer demographics from stereotypes, persisting even when users state otherwise. A linear probe intervention effectively mitigates this bias.", "conclusion": "Greater transparency and control over LLMs' user identity representations are needed to prevent stereotype-driven biases."}}
{"id": "2505.15859", "pdf": "https://arxiv.org/pdf/2505.15859", "abs": "https://arxiv.org/abs/2505.15859", "authors": ["Tianyi Ma", "Yiyue Qian", "Zheyuan Zhang", "Zehong Wang", "Xiaoye Qian", "Feifan Bai", "Yifan Ding", "Xuwei Luo", "Shinan Zhang", "Keerthiram Murugesan", "Chuxu Zhang", "Yanfang Ye"], "title": "AutoData: A Multi-Agent System for Open Web Data Collection", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The exponential growth of data-driven systems and AI technologies has\nintensified the demand for high-quality web-sourced datasets. While existing\ndatasets have proven valuable, conventional web data collection approaches face\nsignificant limitations in terms of human effort and scalability. Current\ndata-collecting solutions fall into two categories: wrapper-based methods that\nstruggle with adaptability and reproducibility, and large language model\n(LLM)-based approaches that incur substantial computational and financial\ncosts. To address these challenges, we propose AutoData, a novel multi-agent\nsystem for Automated web Data collection, that requires minimal human\nintervention, i.e., only necessitating a natural language instruction\nspecifying the desired dataset. In addition, AutoData is designed with a robust\nmulti-agent architecture, featuring a novel oriented message hypergraph\ncoordinated by a central task manager, to efficiently organize agents across\nresearch and development squads. Besides, we introduce a novel hypergraph cache\nsystem to advance the multi-agent collaboration process that enables efficient\nautomated data collection and mitigates the token cost issues prevalent in\nexisting LLM-based systems. Moreover, we introduce Instruct2DS, a new benchmark\ndataset supporting live data collection from web sources across three domains:\nacademic, finance, and sports. Comprehensive evaluations over Instruct2DS and\nthree existing benchmark datasets demonstrate AutoData's superior performance\ncompared to baseline methods. Case studies on challenging tasks such as picture\nbook collection and paper extraction from surveys further validate its\napplicability. Our source code and dataset are available at\nhttps://github.com/GraphResearcher/AutoData.", "AI": {"tldr": "AutoData is a multi-agent system for automated web data collection, minimizing human effort and costs while outperforming existing methods.", "motivation": "Addressing limitations in current web data collection methods, such as high human effort, scalability issues, and computational costs of LLM-based approaches.", "method": "Proposes AutoData, a multi-agent system with a hypergraph architecture and cache system, requiring only natural language instructions.", "result": "Outperforms baseline methods on Instruct2DS and other datasets, validated by case studies.", "conclusion": "AutoData offers an efficient, scalable solution for web data collection with broad applicability."}}
{"id": "2505.16583", "pdf": "https://arxiv.org/pdf/2505.16583", "abs": "https://arxiv.org/abs/2505.16583", "authors": ["Shpresim Sadiku", "Kartikeya Chitranshi", "Hiroshi Kera", "Sebastian Pokutta"], "title": "Training on Plausible Counterfactuals Removes Spurious Correlations", "categories": ["cs.LG"], "comment": null, "summary": "Plausible counterfactual explanations (p-CFEs) are perturbations that\nminimally modify inputs to change classifier decisions while remaining\nplausible under the data distribution. In this study, we demonstrate that\nclassifiers can be trained on p-CFEs labeled with induced \\emph{incorrect}\ntarget classes to classify unperturbed inputs with the original labels. While\nprevious studies have shown that such learning is possible with adversarial\nperturbations, we extend this paradigm to p-CFEs. Interestingly, our\nexperiments reveal that learning from p-CFEs is even more effective: the\nresulting classifiers achieve not only high in-distribution accuracy but also\nexhibit significantly reduced bias with respect to spurious correlations.", "AI": {"tldr": "Training classifiers on plausible counterfactual explanations (p-CFEs) with incorrect labels improves accuracy and reduces bias compared to adversarial perturbations.", "motivation": "To explore if learning from p-CFEs, which are plausible under the data distribution, can enhance classifier performance and reduce bias.", "method": "Train classifiers on p-CFEs labeled with incorrect target classes and evaluate their performance on unperturbed inputs.", "result": "Classifiers trained on p-CFEs achieve high in-distribution accuracy and significantly reduced bias from spurious correlations.", "conclusion": "Learning from p-CFEs is more effective than adversarial perturbations for improving classifier robustness and fairness."}}
{"id": "2505.16479", "pdf": "https://arxiv.org/pdf/2505.16479", "abs": "https://arxiv.org/abs/2505.16479", "authors": ["Yuetong Liu", "Yunqiu Xu", "Yang Wei", "Xiuli Bi", "Bin Xiao"], "title": "Clear Nights Ahead: Towards Multi-Weather Nighttime Image Restoration", "categories": ["cs.CV"], "comment": "17 pages, 20 figures", "summary": "Restoring nighttime images affected by multiple adverse weather conditions is\na practical yet under-explored research problem, as multiple weather conditions\noften coexist in the real world alongside various lighting effects at night.\nThis paper first explores the challenging multi-weather nighttime image\nrestoration task, where various types of weather degradations are intertwined\nwith flare effects. To support the research, we contribute the AllWeatherNight\ndataset, featuring large-scale high-quality nighttime images with diverse\ncompositional degradations, synthesized using our introduced illumination-aware\ndegradation generation. Moreover, we present ClearNight, a unified nighttime\nimage restoration framework, which effectively removes complex degradations in\none go. Specifically, ClearNight extracts Retinex-based dual priors and\nexplicitly guides the network to focus on uneven illumination regions and\nintrinsic texture contents respectively, thereby enhancing restoration\neffectiveness in nighttime scenarios. In order to better represent the common\nand unique characters of multiple weather degradations, we introduce a\nweather-aware dynamic specific-commonality collaboration method, which\nidentifies weather degradations and adaptively selects optimal candidate units\nassociated with specific weather types. Our ClearNight achieves\nstate-of-the-art performance on both synthetic and real-world images.\nComprehensive ablation experiments validate the necessity of AllWeatherNight\ndataset as well as the effectiveness of ClearNight. Project page:\nhttps://henlyta.github.io/ClearNight/mainpage.html", "AI": {"tldr": "The paper introduces ClearNight, a framework for restoring nighttime images affected by multiple weather conditions, and the AllWeatherNight dataset for research support.", "motivation": "Nighttime image restoration is challenging due to coexisting weather degradations and lighting effects, which are under-explored.", "method": "ClearNight uses Retinex-based dual priors and a weather-aware dynamic method to address degradations.", "result": "ClearNight achieves state-of-the-art performance on synthetic and real-world images.", "conclusion": "The AllWeatherNight dataset and ClearNight framework are validated as effective for nighttime image restoration."}}
{"id": "2505.16483", "pdf": "https://arxiv.org/pdf/2505.16483", "abs": "https://arxiv.org/abs/2505.16483", "authors": ["Shuzheng Si", "Haozhe Zhao", "Cheng Gao", "Yuzhuo Bai", "Zhitong Wang", "Bofei Gao", "Kangyang Luo", "Wenhao Li", "Yufei Huang", "Gang Chen", "Fanchao Qi", "Minjia Zhang", "Baobao Chang", "Maosong Sun"], "title": "Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Teaching large language models (LLMs) to be faithful in the provided context\nis crucial for building reliable information-seeking systems. Therefore, we\npropose a systematic framework, CANOE, to improve the faithfulness of LLMs in\nboth short-form and long-form generation tasks without human annotations.\nSpecifically, we first synthesize short-form question-answering (QA) data with\nfour diverse tasks to construct high-quality and easily verifiable training\ndata without human annotation. Also, we propose Dual-GRPO, a rule-based\nreinforcement learning method that includes three tailored rule-based rewards\nderived from synthesized short-form QA data, while simultaneously optimizing\nboth short-form and long-form response generation. Notably, Dual-GRPO\neliminates the need to manually label preference data to train reward models\nand avoids over-optimizing short-form generation when relying only on the\nsynthesized short-form QA data. Experimental results show that CANOE greatly\nimproves the faithfulness of LLMs across 11 different downstream tasks, even\noutperforming the most advanced LLMs, e.g., GPT-4o and OpenAI o1.", "AI": {"tldr": "CANOE is a framework improving LLM faithfulness in generation tasks without human annotations, using synthesized QA data and Dual-GRPO reinforcement learning.", "motivation": "Ensuring LLMs provide faithful responses in information-seeking systems is critical for reliability.", "method": "Synthesizes short-form QA data, uses Dual-GRPO (rule-based RL) with tailored rewards to optimize generation tasks.", "result": "CANOE enhances faithfulness across 11 tasks, outperforming advanced LLMs like GPT-4o.", "conclusion": "CANOE effectively improves LLM faithfulness without human input, demonstrating superior performance."}}
{"id": "2505.15925", "pdf": "https://arxiv.org/pdf/2505.15925", "abs": "https://arxiv.org/abs/2505.15925", "authors": ["Bowen Feng", "Zhiting Mei", "Baiang Li", "Julian Ost", "Roger Girgis", "Anirudha Majumdar", "Felix Heide"], "title": "VERDI: VLM-Embedded Reasoning for Autonomous Driving", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "While autonomous driving (AD) stacks struggle with decision making under\npartial observability and real-world complexity, human drivers are capable of\ncommonsense reasoning to make near-optimal decisions with limited information.\nRecent work has attempted to leverage finetuned Vision-Language Models (VLMs)\nfor trajectory planning at inference time to emulate human behavior. Despite\ntheir success in benchmark evaluations, these methods are often impractical to\ndeploy (a 70B parameter VLM inference at merely 8 tokens per second requires\nmore than 160G of memory), and their monolithic network structure prohibits\nsafety decomposition. To bridge this gap, we propose VLM-Embedded Reasoning for\nautonomous Driving (VERDI), a training-time framework that distills the\nreasoning process and commonsense knowledge of VLMs into the AD stack. VERDI\naugments modular differentiable end-to-end (e2e) AD models by aligning\nintermediate module outputs at the perception, prediction, and planning stages\nwith text features explaining the driving reasoning process produced by VLMs.\nBy encouraging alignment in latent space, \\textsc{VERDI} enables the modular AD\nstack to internalize structured reasoning, without incurring the inference-time\ncosts of large VLMs. We demonstrate the effectiveness of our method on the\nNuScenes dataset and find that VERDI outperforms existing e2e methods that do\nnot embed reasoning by 10% in $\\ell_{2}$ distance, while maintaining high\ninference speed.", "AI": {"tldr": "VERDI distills VLM reasoning into modular AD stacks for efficient, safe autonomous driving, outperforming e2e methods by 10%.", "motivation": "Human drivers use commonsense reasoning under partial observability, while current AD stacks and large VLMs are impractical for deployment due to high computational costs and lack of safety decomposition.", "method": "VERDI aligns intermediate module outputs (perception, prediction, planning) with VLM-generated text features during training, embedding reasoning without inference-time VLM costs.", "result": "VERDI outperforms non-reasoning e2e methods by 10% in \u2113\u2082 distance on NuScenes, maintaining high inference speed.", "conclusion": "VERDI successfully integrates VLM reasoning into modular AD stacks, balancing performance and practicality."}}
{"id": "2505.16620", "pdf": "https://arxiv.org/pdf/2505.16620", "abs": "https://arxiv.org/abs/2505.16620", "authors": ["Benjamin Herdeanu", "Juan Nathaniel", "Carla Roesch", "Jatan Buch", "Gregor Ramien", "Johannes Haux", "Pierre Gentine"], "title": "CausalDynamics: A large-scale benchmark for structural discovery of dynamical causal models", "categories": ["cs.LG"], "comment": "16+19 pages, 5+8 figures", "summary": "Causal discovery for dynamical systems poses a major challenge in fields\nwhere active interventions are infeasible. Most methods used to investigate\nthese systems and their associated benchmarks are tailored to deterministic,\nlow-dimensional and weakly nonlinear time-series data. To address these\nlimitations, we present CausalDynamics, a large-scale benchmark and extensible\ndata generation framework to advance the structural discovery of dynamical\ncausal models. Our benchmark consists of true causal graphs derived from\nthousands of coupled ordinary and stochastic differential equations as well as\ntwo idealized climate models. We perform a comprehensive evaluation of\nstate-of-the-art causal discovery algorithms for graph reconstruction on\nsystems with noisy, confounded, and lagged dynamics. CausalDynamics consists of\na plug-and-play, build-your-own coupling workflow that enables the construction\nof a hierarchy of physical systems. We anticipate that our framework will\nfacilitate the development of robust causal discovery algorithms that are\nbroadly applicable across domains while addressing their unique challenges. We\nprovide a user-friendly implementation and documentation on\nhttps://kausable.github.io/CausalDynamics.", "AI": {"tldr": "CausalDynamics is a benchmark and data generation framework for causal discovery in dynamical systems, addressing limitations of current methods by evaluating algorithms on noisy, confounded, and lagged dynamics.", "motivation": "Current causal discovery methods for dynamical systems are limited to deterministic, low-dimensional, and weakly nonlinear data, prompting the need for a more robust and scalable framework.", "method": "The framework uses true causal graphs from coupled differential equations and climate models, with a plug-and-play workflow for constructing hierarchical physical systems.", "result": "CausalDynamics enables comprehensive evaluation of state-of-the-art causal discovery algorithms, highlighting their performance on complex dynamics.", "conclusion": "The framework aims to advance robust causal discovery algorithms applicable across domains, with accessible implementation and documentation."}}
{"id": "2505.16485", "pdf": "https://arxiv.org/pdf/2505.16485", "abs": "https://arxiv.org/abs/2505.16485", "authors": ["Yao Wei", "Muhammad Usman", "Hazrat Bilal"], "title": "InspectionV3: Enhancing Tobacco Quality Assessment with Deep Convolutional Neural Networks for Automated Workshop Management", "categories": ["cs.CV"], "comment": "33 pages, 15 figures, 2 Tables", "summary": "The problems that tobacco workshops encounter include poor curing,\ninconsistencies in supplies, irregular scheduling, and a lack of oversight, all\nof which drive up expenses and worse quality. Large quantities make manual\nexamination costly, sluggish, and unreliable. Deep convolutional neural\nnetworks have recently made strides in capabilities that transcend those of\nconventional methods. To effectively enhance them, nevertheless, extensive\ncustomization is needed to account for subtle variations in tobacco grade. This\nstudy introduces InspectionV3, an integrated solution for automated flue-cured\ntobacco grading that makes use of a customized deep convolutional neural\nnetwork architecture. A scope that covers color, maturity, and curing\nsubtleties is established via a labelled dataset consisting of 21,113 images\nspanning 20 quality classes. Expert annotators performed preprocessing on the\ntobacco leaf images, including cleaning, labelling, and augmentation.\nMulti-layer CNN factors use batch normalization to describe domain properties\nlike as permeability and moisture spots, and so account for the subtleties of\nthe workshop. Its expertise lies in converting visual patterns into useful\ninformation for enhancing workflow. Fast notifications are made possible by\nreal-time, on-the-spot grading that matches human expertise. Images-powered\nanalytics dashboards facilitate the tracking of yield projections, inventories,\nbottlenecks, and the optimization of data-driven choices. More labelled images\nare assimilated after further retraining, improving representational capacities\nand enabling adaptations for seasonal variability. Metrics demonstrate 97%\naccuracy, 95% precision and recall, 96% F1-score and AUC, 95% specificity;\nvalidating real-world viability.", "AI": {"tldr": "InspectionV3, a customized deep CNN, automates tobacco grading with high accuracy, addressing issues like poor curing and inconsistent supplies.", "motivation": "Tobacco workshops face challenges like high costs, poor quality, and unreliable manual inspection, necessitating an automated solution.", "method": "Uses a labeled dataset of 21,113 images across 20 quality classes, processed by experts, and a multi-layer CNN with batch normalization for grading.", "result": "Achieves 97% accuracy, 95% precision/recall, 96% F1-score/AUC, and 95% specificity, validating real-world applicability.", "conclusion": "InspectionV3 effectively automates tobacco grading, improving workflow and decision-making with high accuracy and adaptability."}}
{"id": "2505.16491", "pdf": "https://arxiv.org/pdf/2505.16491", "abs": "https://arxiv.org/abs/2505.16491", "authors": ["Dario Di Palma", "Alessandro De Bellis", "Giovanni Servedio", "Vito Walter Anelli", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have rapidly become central to NLP,\ndemonstrating their ability to adapt to various tasks through prompting\ntechniques, including sentiment analysis. However, we still have a limited\nunderstanding of how these models capture sentiment-related information. This\nstudy probes the hidden layers of Llama models to pinpoint where sentiment\nfeatures are most represented and to assess how this affects sentiment\nanalysis.\n  Using probe classifiers, we analyze sentiment encoding across layers and\nscales, identifying the layers and pooling methods that best capture sentiment\nsignals. Our results show that sentiment information is most concentrated in\nmid-layers for binary polarity tasks, with detection accuracy increasing up to\n14% over prompting techniques. Additionally, we find that in decoder-only\nmodels, the last token is not consistently the most informative for sentiment\nencoding. Finally, this approach enables sentiment tasks to be performed with\nmemory requirements reduced by an average of 57%.\n  These insights contribute to a broader understanding of sentiment in LLMs,\nsuggesting layer-specific probing as an effective approach for sentiment tasks\nbeyond prompting, with potential to enhance model utility and reduce memory\nrequirements.", "AI": {"tldr": "The study explores sentiment encoding in Llama models, identifying mid-layers as key for sentiment analysis and reducing memory usage by 57%.", "motivation": "To understand how LLMs capture sentiment and improve sentiment analysis beyond prompting techniques.", "method": "Probe classifiers analyze sentiment encoding across layers and scales, focusing on binary polarity tasks.", "result": "Sentiment is concentrated in mid-layers, boosting accuracy by 14% over prompting; last token isn't always most informative.", "conclusion": "Layer-specific probing enhances sentiment analysis, improving utility and reducing memory needs."}}
{"id": "2505.16636", "pdf": "https://arxiv.org/pdf/2505.16636", "abs": "https://arxiv.org/abs/2505.16636", "authors": ["Victor Dheur", "Souhaib Ben Taieb"], "title": "Multivariate Latent Recalibration for Conditional Normalizing Flows", "categories": ["cs.LG"], "comment": null, "summary": "Reliably characterizing the full conditional distribution of a multivariate\nresponse variable given a set of covariates is crucial for trustworthy\ndecision-making. However, misspecified or miscalibrated multivariate models may\nyield a poor approximation of the joint distribution of the response variables,\nleading to unreliable predictions and suboptimal decisions. Furthermore,\nstandard recalibration methods are primarily limited to univariate settings,\nwhile conformal prediction techniques, despite generating multivariate\nprediction regions with coverage guarantees, do not provide a full probability\ndensity function. We address this gap by first introducing a novel notion of\nlatent calibration, which assesses probabilistic calibration in the latent\nspace of a conditional normalizing flow. Second, we propose latent\nrecalibration (LR), a novel post-hoc model recalibration method that learns a\ntransformation of the latent space with finite-sample bounds on latent\ncalibration. Unlike existing methods, LR produces a recalibrated distribution\nwith an explicit multivariate density function while remaining computationally\nefficient. Extensive experiments on both tabular and image datasets show that\nLR consistently improves latent calibration error and the negative\nlog-likelihood of the recalibrated models.", "AI": {"tldr": "The paper introduces latent recalibration (LR), a method to improve multivariate model calibration by transforming the latent space of conditional normalizing flows, ensuring reliable joint distribution approximations.", "motivation": "Existing methods for multivariate model calibration are limited, often providing poor joint distribution approximations or lacking explicit density functions, leading to unreliable predictions.", "method": "Proposes latent recalibration (LR), which learns a transformation in the latent space of conditional normalizing flows with finite-sample bounds on calibration.", "result": "LR improves latent calibration error and negative log-likelihood across tabular and image datasets.", "conclusion": "LR effectively recalibrates multivariate models, providing explicit density functions and computational efficiency."}}
{"id": "2505.16495", "pdf": "https://arxiv.org/pdf/2505.16495", "abs": "https://arxiv.org/abs/2505.16495", "authors": ["Lingfeng Wang", "Hualing Lin", "Senda Chen", "Tao Wang", "Changxu Cheng", "Yangyang Zhong", "Dong Zheng", "Wuyue Zhao"], "title": "ALTo: Adaptive-Length Tokenizer for Autoregressive Mask Generation", "categories": ["cs.CV"], "comment": null, "summary": "While humans effortlessly draw visual objects and shapes by adaptively\nallocating attention based on their complexity, existing multimodal large\nlanguage models (MLLMs) remain constrained by rigid token representations.\nBridging this gap, we propose ALTo, an adaptive length tokenizer for\nautoregressive mask generation. To achieve this, a novel token length predictor\nis designed, along with a length regularization term and a differentiable token\nchunking strategy. We further build ALToLLM that seamlessly integrates ALTo\ninto MLLM. Preferences on the trade-offs between mask quality and efficiency is\nimplemented by group relative policy optimization (GRPO). Experiments\ndemonstrate that ALToLLM achieves state-of-the-art performance with adaptive\ntoken cost on popular segmentation benchmarks. Code and models are released at\nhttps://github.com/yayafengzi/ALToLLM.", "AI": {"tldr": "ALTo introduces an adaptive tokenizer for MLLMs, improving mask generation by dynamically adjusting token lengths, achieving top performance in segmentation tasks.", "motivation": "Existing MLLMs use rigid token representations, unlike humans who adapt attention based on complexity. ALTo bridges this gap.", "method": "ALTo includes a token length predictor, length regularization, and differentiable token chunking. Integrated into ALToLLM with GRPO for efficiency trade-offs.", "result": "ALToLLM achieves state-of-the-art performance on segmentation benchmarks with adaptive token cost.", "conclusion": "ALTo enhances MLLMs by adaptive tokenization, balancing quality and efficiency, with code and models publicly available."}}
{"id": "2505.16505", "pdf": "https://arxiv.org/pdf/2505.16505", "abs": "https://arxiv.org/abs/2505.16505", "authors": ["Runcong Zhao", "Chengyu Cao", "Qinglin Zhu", "Xiucheng Lv", "Shun Shao", "Lin Gui", "Ruifeng Xu", "Yulan He"], "title": "Sparse Activation Editing for Reliable Instruction Following in Narratives", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Complex narrative contexts often challenge language models' ability to follow\ninstructions, and existing benchmarks fail to capture these difficulties. To\naddress this, we propose Concise-SAE, a training-free framework that improves\ninstruction following by identifying and editing instruction-relevant neurons\nusing only natural language instructions, without requiring labelled data. To\nthoroughly evaluate our method, we introduce FreeInstruct, a diverse and\nrealistic benchmark of 1,212 examples that highlights the challenges of\ninstruction following in narrative-rich settings. While initially motivated by\ncomplex narratives, Concise-SAE demonstrates state-of-the-art instruction\nadherence across varied tasks without compromising generation quality.", "AI": {"tldr": "Concise-SAE is a training-free framework that improves instruction following in language models by editing relevant neurons using natural language, evaluated on the FreeInstruct benchmark.", "motivation": "Addressing the challenge of instruction following in complex narrative contexts, where existing benchmarks fall short.", "method": "Proposes Concise-SAE, which identifies and edits instruction-relevant neurons using natural language instructions, without labeled data.", "result": "Achieves state-of-the-art instruction adherence across tasks without degrading generation quality.", "conclusion": "Concise-SAE effectively improves instruction following in narrative-rich settings, validated by the FreeInstruct benchmark."}}
{"id": "2505.16638", "pdf": "https://arxiv.org/pdf/2505.16638", "abs": "https://arxiv.org/abs/2505.16638", "authors": ["Benedikt H\u00f6ltgen", "Nuria Oliver"], "title": "Reconsidering Fairness Through Unawareness from the Perspective of Model Multiplicity", "categories": ["cs.LG", "cs.CY", "stat.ML"], "comment": null, "summary": "Fairness through Unawareness (FtU) describes the idea that discrimination\nagainst demographic groups can be avoided by not considering group membership\nin the decisions or predictions. This idea has long been criticized in the\nmachine learning literature as not being sufficient to ensure fairness. In\naddition, the use of additional features is typically thought to increase the\naccuracy of the predictions for all groups, so that FtU is sometimes thought to\nbe detrimental to all groups. In this paper, we show both theoretically and\nempirically that FtU can reduce algorithmic discrimination without necessarily\nreducing accuracy. We connect this insight with the literature on Model\nMultiplicity, to which we contribute with novel theoretical and empirical\nresults. Furthermore, we illustrate how, in a real-life application, FtU can\ncontribute to the deployment of more equitable policies without losing\nefficacy. Our findings suggest that FtU is worth considering in practical\napplications, particularly in high-risk scenarios, and that the use of\nprotected attributes such as gender in predictive models should be accompanied\nby a clear and well-founded justification.", "AI": {"tldr": "Fairness through Unawareness (FtU) can reduce algorithmic discrimination without sacrificing accuracy, challenging prior criticisms. It connects to Model Multiplicity and shows practical utility in equitable policy deployment.", "motivation": "To challenge the notion that FtU is insufficient for fairness and detrimental to accuracy, showing its potential benefits in reducing discrimination.", "method": "Theoretical and empirical analysis of FtU, linking it to Model Multiplicity, with real-life application examples.", "result": "FtU reduces discrimination without necessarily lowering accuracy, supported by theoretical and empirical evidence.", "conclusion": "FtU is viable in high-risk scenarios, and protected attributes should only be used with strong justification."}}
{"id": "2505.16512", "pdf": "https://arxiv.org/pdf/2505.16512", "abs": "https://arxiv.org/abs/2505.16512", "authors": ["Jiaxin Liu", "Jia Wang", "Saihui Hou", "Min Ren", "Huijia Wu", "Zhaofeng He"], "title": "Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In recent years, the rapid development of deepfake technology has given rise\nto an emerging and serious threat to public security: diffusion model-based\ndigital human generation. Unlike traditional face manipulation methods, such\nmodels can generate highly realistic videos with consistency through multimodal\ncontrol signals. Their flexibility and covertness pose severe challenges to\nexisting detection strategies. To bridge this gap, we introduce DigiFakeAV, the\nfirst large-scale multimodal digital human forgery dataset based on diffusion\nmodels. Employing five latest digital human generation methods (Sonic, Hallo,\netc.) and voice cloning method, we systematically produce a dataset comprising\n60,000 videos (8.4 million frames), covering multiple nationalities, skin\ntones, genders, and real-world scenarios, significantly enhancing data\ndiversity and realism. User studies show that the confusion rate between forged\nand real videos reaches 68%, and existing state-of-the-art (SOTA) detection\nmodels exhibit large drops in AUC values on DigiFakeAV, highlighting the\nchallenge of the dataset. To address this problem, we further propose\nDigiShield, a detection baseline based on spatiotemporal and cross-modal\nfusion. By jointly modeling the 3D spatiotemporal features of videos and the\nsemantic-acoustic features of audio, DigiShield achieves SOTA performance on\nboth the DigiFakeAV and DF-TIMIT datasets. Experiments show that this method\neffectively identifies covert artifacts through fine-grained analysis of the\ntemporal evolution of facial features in synthetic videos.", "AI": {"tldr": "The paper introduces DigiFakeAV, a large-scale dataset for detecting deepfake videos generated by diffusion models, and proposes DigiShield, a detection method that outperforms existing models.", "motivation": "The rise of diffusion model-based digital human generation poses severe challenges to detection methods due to its realism and flexibility, necessitating a robust dataset and detection framework.", "method": "The authors create DigiFakeAV using five digital human generation methods and voice cloning, then propose DigiShield, a detection baseline leveraging spatiotemporal and cross-modal fusion.", "result": "User studies show a 68% confusion rate between real and forged videos, and DigiShield achieves state-of-the-art performance on DigiFakeAV and DF-TIMIT datasets.", "conclusion": "DigiShield effectively identifies synthetic videos by analyzing temporal facial features, addressing the limitations of current detection methods."}}
{"id": "2505.16514", "pdf": "https://arxiv.org/pdf/2505.16514", "abs": "https://arxiv.org/abs/2505.16514", "authors": ["Yuting Huang", "Meitong Guo", "Yiquan Wu", "Ang Li", "Xiaozhong Liu", "Keting Yin", "Changlong Sun", "Fei Wu", "Kun Kuang"], "title": "AppealCase: A Dataset and Benchmark for Civil Case Appeal Scenarios", "categories": ["cs.CL"], "comment": "15 pages, 4 figures", "summary": "Recent advances in LegalAI have primarily focused on individual case judgment\nanalysis, often overlooking the critical appellate process within the judicial\nsystem. Appeals serve as a core mechanism for error correction and ensuring\nfair trials, making them highly significant both in practice and in research.\nTo address this gap, we present the AppealCase dataset, consisting of 10,000\npairs of real-world, matched first-instance and second-instance documents\nacross 91 categories of civil cases. The dataset also includes detailed\nannotations along five dimensions central to appellate review: judgment\nreversals, reversal reasons, cited legal provisions, claim-level decisions, and\nwhether there is new information in the second instance. Based on these\nannotations, we propose five novel LegalAI tasks and conduct a comprehensive\nevaluation across 20 mainstream models. Experimental results reveal that all\ncurrent models achieve less than 50% F1 scores on the judgment reversal\nprediction task, highlighting the complexity and challenge of the appeal\nscenario. We hope that the AppealCase dataset will spur further research in\nLegalAI for appellate case analysis and contribute to improving consistency in\njudicial decision-making.", "AI": {"tldr": "The paper introduces the AppealCase dataset to address the overlooked appellate process in LegalAI, proposing five novel tasks and evaluating 20 models, all of which perform poorly on judgment reversal prediction.", "motivation": "Appeals are crucial for error correction and fair trials but are understudied in LegalAI. The AppealCase dataset aims to fill this gap.", "method": "The dataset includes 10,000 matched first- and second-instance civil case documents with detailed annotations. Five novel tasks are proposed and evaluated using 20 models.", "result": "All models score under 50% F1 on judgment reversal prediction, showing the task's difficulty.", "conclusion": "The AppealCase dataset encourages further research on appellate case analysis to improve judicial consistency."}}
{"id": "2505.16136", "pdf": "https://arxiv.org/pdf/2505.16136", "abs": "https://arxiv.org/abs/2505.16136", "authors": ["Yuke Zhang"], "title": "Interpretable Machine Learning for Macro Alpha: A News Sentiment Case Study", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "q-fin.TR"], "comment": "18 pages (including references), 1 figure, 1 table. Code available at\n  \\url{https://github.com/yukepenn/macro-news-sentiment-trading}. Keywords:\n  Macro Sentiment, News Sentiment, Algorithmic Trading, GDELT, FinBERT, NLP,\n  Alternative Data, Foreign Exchange, Treasury Futures, Quantitative Finance,\n  Machine Learning, SHAP, Interpretability", "summary": "This study introduces an interpretable machine learning (ML) framework to\nextract macroeconomic alpha from global news sentiment. We process the Global\nDatabase of Events, Language, and Tone (GDELT) Project's worldwide news feed\nusing FinBERT -- a Bidirectional Encoder Representations from Transformers\n(BERT) based model pretrained on finance-specific language -- to construct\ndaily sentiment indices incorporating mean tone, dispersion, and event impact.\nThese indices drive an XGBoost classifier, benchmarked against logistic\nregression, to predict next-day returns for EUR/USD, USD/JPY, and 10-year U.S.\nTreasury futures (ZN). Rigorous out-of-sample (OOS) backtesting (5-fold\nexpanding-window cross-validation, OOS period: c. 2017-April 2025) demonstrates\nexceptional, cost-adjusted performance for the XGBoost strategy: Sharpe ratios\nachieve 5.87 (EUR/USD), 4.65 (USD/JPY), and 4.65 (Treasuries), with respective\ncompound annual growth rates (CAGRs) exceeding 50% in Foreign Exchange (FX) and\n22% in bonds. Shapley Additive Explanations (SHAP) affirm that sentiment\ndispersion and article impact are key predictive features. Our findings\nestablish that integrating domain-specific Natural Language Processing (NLP)\nwith interpretable ML offers a potent and explainable source of macro alpha.", "AI": {"tldr": "An interpretable ML framework using FinBERT and XGBoost predicts next-day returns for FX and bonds with high Sharpe ratios and CAGRs, driven by news sentiment.", "motivation": "To extract macroeconomic alpha from global news sentiment using domain-specific NLP and interpretable ML.", "method": "Process GDELT news feed with FinBERT to create sentiment indices, then use XGBoost (vs. logistic regression) for prediction.", "result": "Exceptional OOS performance: Sharpe ratios up to 5.87, CAGRs over 50% in FX and 22% in bonds.", "conclusion": "Domain-specific NLP with interpretable ML is a powerful, explainable source of macro alpha."}}
{"id": "2505.16649", "pdf": "https://arxiv.org/pdf/2505.16649", "abs": "https://arxiv.org/abs/2505.16649", "authors": ["Zhichao Zhu", "Yang Qi", "Hengyuan Ma", "Wenlian Lu", "Jianfeng Feng"], "title": "Stochastic Forward-Forward Learning through Representational Dimensionality Compression", "categories": ["cs.LG", "cs.NE"], "comment": "14 pages, 9 figures, 2 tables", "summary": "The Forward-Forward (FF) algorithm provides a bottom-up alternative to\nbackpropagation (BP) for training neural networks, relying on a layer-wise\n\"goodness\" function to guide learning. Existing goodness functions, inspired by\nenergy-based learning (EBL), are typically defined as the sum of squared\npost-synaptic activations, neglecting the correlations between neurons. In this\nwork, we propose a novel goodness function termed dimensionality compression\nthat uses the effective dimensionality (ED) of fluctuating neural responses to\nincorporate second-order statistical structure. Our objective minimizes ED for\nclamped inputs when noise is considered while maximizing it across the sample\ndistribution, promoting structured representations without the need to prepare\nnegative samples. We demonstrate that this formulation achieves competitive\nperformance compared to other non-BP methods. Moreover, we show that noise\nplays a constructive role that can enhance generalization and improve inference\nwhen predictions are derived from the mean of squared outputs, which is\nequivalent to making predictions based on the energy term. Our findings\ncontribute to the development of more biologically plausible learning\nalgorithms and suggest a natural fit for neuromorphic computing, where\nstochasticity is a computational resource rather than a nuisance. The code is\navailable at https://github.com/ZhichaoZhu/StochasticForwardForward", "AI": {"tldr": "The paper introduces a novel goodness function, dimensionality compression, for the Forward-Forward algorithm, leveraging effective dimensionality to improve neural network training without negative samples. It shows competitive performance and highlights noise's constructive role in generalization.", "motivation": "To address the limitations of existing goodness functions in the Forward-Forward algorithm, which neglect neuron correlations, by proposing a more biologically plausible method incorporating second-order statistical structure.", "method": "Proposes a goodness function based on effective dimensionality (ED) of neural responses, minimizing ED for clamped inputs with noise and maximizing it across samples.", "result": "Achieves competitive performance compared to non-backpropagation methods, with noise enhancing generalization and inference.", "conclusion": "The method advances biologically plausible learning and fits neuromorphic computing, treating stochasticity as a resource. Code is publicly available."}}
{"id": "2505.16513", "pdf": "https://arxiv.org/pdf/2505.16513", "abs": "https://arxiv.org/abs/2505.16513", "authors": ["Vaishali Maheshkar", "Aadarsh Anantha Ramakrishnan", "Charuvahan Adhivarahan", "Karthik Dantu"], "title": "Detailed Evaluation of Modern Machine Learning Approaches for Optic Plastics Sorting", "categories": ["cs.CV", "68T45", "I.4.9; I.4.6"], "comment": "Accepted at the 2024 REMADE Circular Economy Tech Summit and\n  Conference, https://remadeinstitute.org/2024-conference/", "summary": "According to the EPA, only 25% of waste is recycled, and just 60% of U.S.\nmunicipalities offer curbside recycling. Plastics fare worse, with a recycling\nrate of only 8%; an additional 16% is incinerated, while the remaining 76% ends\nup in landfills. The low plastic recycling rate stems from contamination, poor\neconomic incentives, and technical difficulties, making efficient recycling a\nchallenge. To improve recovery, automated sorting plays a critical role.\nCompanies like AMP Robotics and Greyparrot utilize optical systems for sorting,\nwhile Materials Recovery Facilities (MRFs) employ Near-Infrared (NIR) sensors\nto detect plastic types.\n  Modern optical sorting uses advances in computer vision such as object\nrecognition and instance segmentation, powered by machine learning. Two-stage\ndetectors like Mask R-CNN use region proposals and classification with deep\nbackbones like ResNet. Single-stage detectors like YOLO handle detection in one\npass, trading some accuracy for speed. While such methods excel under ideal\nconditions with a large volume of labeled training data, challenges arise in\nrealistic scenarios, emphasizing the need to further examine the efficacy of\noptic detection for automated sorting.\n  In this study, we compiled novel datasets totaling 20,000+ images from varied\nsources. Using both public and custom machine learning pipelines, we assessed\nthe capabilities and limitations of optical recognition for sorting. Grad-CAM,\nsaliency maps, and confusion matrices were employed to interpret model\nbehavior. We perform this analysis on our custom trained models from the\ncompiled datasets. To conclude, our findings are that optic recognition methods\nhave limited success in accurate sorting of real-world plastics at MRFs,\nprimarily because they rely on physical properties such as color and shape.", "AI": {"tldr": "The paper examines the limitations of optical recognition methods for plastic sorting in recycling facilities, using machine learning and novel datasets.", "motivation": "Low plastic recycling rates due to contamination, poor incentives, and technical challenges highlight the need for better automated sorting solutions.", "method": "The study compiled 20,000+ images and used machine learning pipelines (including Mask R-CNN and YOLO) to evaluate optical sorting. Tools like Grad-CAM and confusion matrices analyzed model behavior.", "result": "Optical recognition methods show limited success in accurately sorting real-world plastics due to reliance on physical properties like color and shape.", "conclusion": "Current optic detection methods are insufficient for practical plastic sorting, suggesting a need for improved approaches."}}
{"id": "2505.16518", "pdf": "https://arxiv.org/pdf/2505.16518", "abs": "https://arxiv.org/abs/2505.16518", "authors": ["Lovisa Hagstr\u00f6m", "Youna Kim", "Haeun Yu", "Sang-goo Lee", "Richard Johansson", "Hyunsoo Cho", "Isabelle Augenstein"], "title": "CUB: Benchmarking Context Utilisation Techniques for Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "27 pages", "summary": "Incorporating external knowledge is crucial for knowledge-intensive tasks,\nsuch as question answering and fact checking. However, language models (LMs)\nmay ignore relevant information that contradicts outdated parametric memory or\nbe distracted by irrelevant contexts. While many context utilisation\nmanipulation techniques (CMTs) that encourage or suppress context utilisation\nhave recently been proposed to alleviate these issues, few have seen systematic\ncomparison. In this paper, we develop CUB (Context Utilisation Benchmark) to\nhelp practitioners within retrieval-augmented generation (RAG) identify the\nbest CMT for their needs. CUB allows for rigorous testing on three distinct\ncontext types, observed to capture key challenges in realistic context\nutilisation scenarios. With this benchmark, we evaluate seven state-of-the-art\nmethods, representative of the main categories of CMTs, across three diverse\ndatasets and tasks, applied to nine LMs. Our results show that most of the\nexisting CMTs struggle to handle the full set of types of contexts that may be\nencountered in real-world retrieval-augmented scenarios. Moreover, we find that\nmany CMTs display an inflated performance on simple synthesised datasets,\ncompared to more realistic datasets with naturally occurring samples.\nAltogether, our results show the need for holistic tests of CMTs and the\ndevelopment of CMTs that can handle multiple context types.", "AI": {"tldr": "The paper introduces CUB, a benchmark for evaluating context utilisation manipulation techniques (CMTs) in retrieval-augmented generation (RAG), revealing their limitations in handling diverse real-world contexts.", "motivation": "To address the lack of systematic comparison of CMTs and their inconsistent performance in knowledge-intensive tasks like question answering and fact checking.", "method": "Developed CUB, a benchmark for testing CMTs on three context types, evaluated seven state-of-the-art CMTs across three datasets and nine language models.", "result": "Most CMTs struggle with diverse real-world contexts and perform better on simple synthetic datasets than realistic ones.", "conclusion": "Highlights the need for holistic testing and development of CMTs capable of handling multiple context types."}}
{"id": "2505.16187", "pdf": "https://arxiv.org/pdf/2505.16187", "abs": "https://arxiv.org/abs/2505.16187", "authors": ["Guanghe Li", "Junming Zhao", "Shengjie Wang", "Yang Gao"], "title": "EasyInsert: A Data-Efficient and Generalizable Insertion Policy", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Insertion task is highly challenging that requires robots to operate with\nexceptional precision in cluttered environments. Existing methods often have\npoor generalization capabilities. They typically function in restricted and\nstructured environments, and frequently fail when the plug and socket are far\napart, when the scene is densely cluttered, or when handling novel objects.\nThey also rely on strong assumptions such as access to CAD models or a digital\ntwin in simulation. To address this, we propose EasyInsert, a framework which\nleverages the human intuition that relative pose (delta pose) between plug and\nsocket is sufficient for successful insertion, and employs efficient and\nautomated real-world data collection with minimal human labor to train a\ngeneralizable model for relative pose prediction. During execution, EasyInsert\nfollows a coarse-to-fine execution procedure based on predicted delta pose, and\nsuccessfully performs various insertion tasks. EasyInsert demonstrates strong\nzero-shot generalization capability for unseen objects in cluttered\nenvironments, handling cases with significant initial pose deviations while\nmaintaining high sample efficiency and requiring little human effort. In\nreal-world experiments, with just 5 hours of training data, EasyInsert achieves\nover 90% success in zero-shot insertion for 13 out of 15 unseen novel objects,\nincluding challenging objects like Type-C cables, HDMI cables, and Ethernet\ncables. Furthermore, with only one human demonstration and 4 minutes of\nautomatically collected data for fine-tuning, it reaches over 90% success rate\nfor all 15 objects.", "AI": {"tldr": "EasyInsert is a framework for robotic insertion tasks that uses relative pose prediction and automated data collection to achieve high success rates with minimal human effort.", "motivation": "Existing methods for robotic insertion tasks lack generalization, fail in cluttered environments, and rely on strong assumptions like CAD models. EasyInsert aims to overcome these limitations.", "method": "EasyInsert leverages human intuition about relative pose between plug and socket, employs automated real-world data collection, and uses a coarse-to-fine execution procedure based on predicted delta pose.", "result": "EasyInsert achieves over 90% success in zero-shot insertion for 13 out of 15 unseen objects and reaches over 90% success rate for all 15 objects with minimal fine-tuning.", "conclusion": "EasyInsert demonstrates strong generalization, high sample efficiency, and minimal human effort, making it effective for real-world insertion tasks."}}
{"id": "2505.16664", "pdf": "https://arxiv.org/pdf/2505.16664", "abs": "https://arxiv.org/abs/2505.16664", "authors": ["Khoa Tran", "Tri Le", "Bao Huynh", "Hung-Cuong Trinh", "Vy-Rin Nguyen"], "title": "End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate prediction of the Remaining Useful Life (RUL) is essential for\nenabling timely maintenance of lithium-ion batteries, impacting the operational\nefficiency of electric applications that rely on them. This paper proposes a\nRUL prediction approach that leverages data from recent charge-discharge cycles\nto estimate the number of remaining usable cycles. The approach introduces both\na novel signal processing pipeline and a deep learning prediction model. In the\nsignal preprocessing pipeline, a derived capacity feature is computed based on\ncurrent and capacity signals. Alongside original capacity, voltage and current,\nthese features are denoised and enhanced using statistical metrics and a\ndelta-based method to capture differences between the current and previous\ncycles. In the prediction model, the processed features are then fed into a\nhybrid deep learning architecture composed of 1D Convolutional Neural Networks\n(CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary Differential\nEquation-based LSTM (ODE-LSTM) modules. This architecture is designed to\ncapture both local signal characteristics and long-range temporal dependencies\nwhile modeling the continuous-time dynamics of battery degradation. The model\nis further evaluated using transfer learning across different learning\nstrategies and target data partitioning scenarios. Results indicate that the\nmodel maintains robust performance, even when fine-tuned on limited target\ndata. Experimental results on two publicly available large-scale datasets\ndemonstrate that the proposed method outperforms a baseline deep learning\napproach and machine learning techniques, achieving an RMSE of 101.59,\nhighlighting its strong potential for real-world RUL prediction applications.", "AI": {"tldr": "A novel hybrid deep learning approach for predicting lithium-ion battery RUL, combining signal processing and deep learning, outperforms baselines with robust performance.", "motivation": "Accurate RUL prediction is crucial for timely battery maintenance, enhancing operational efficiency in electric applications.", "method": "Proposes a signal processing pipeline for feature enhancement and a hybrid deep learning model (CNN, A-LSTM, ODE-LSTM) to capture local and long-range temporal dependencies.", "result": "Achieves RMSE of 101.59, outperforming baseline methods and demonstrating robustness in transfer learning scenarios.", "conclusion": "The approach shows strong potential for real-world RUL prediction, even with limited target data."}}
{"id": "2505.16524", "pdf": "https://arxiv.org/pdf/2505.16524", "abs": "https://arxiv.org/abs/2505.16524", "authors": ["Huitong Yang", "Zhuoxiao Chen", "Fengyi Zhang", "Zi Huang", "Yadan Luo"], "title": "CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Maintaining robust 3D perception under dynamic and unpredictable test-time\nconditions remains a critical challenge for autonomous driving systems.\nExisting test-time adaptation (TTA) methods often fail in high-variance tasks\nlike 3D object detection due to unstable optimization and sharp minima. While\nrecent model merging strategies based on linear mode connectivity (LMC) offer\nimproved stability by interpolating between fine-tuned checkpoints, they are\ncomputationally expensive, requiring repeated checkpoint access and multiple\nforward passes. In this paper, we introduce CodeMerge, a lightweight and\nscalable model merging framework that bypasses these limitations by operating\nin a compact latent space. Instead of loading full models, CodeMerge represents\neach checkpoint with a low-dimensional fingerprint derived from the source\nmodel's penultimate features and constructs a key-value codebook. We compute\nmerging coefficients using ridge leverage scores on these fingerprints,\nenabling efficient model composition without compromising adaptation quality.\nOur method achieves strong performance across challenging benchmarks, improving\nend-to-end 3D detection 14.9% NDS on nuScenes-C and LiDAR-based detection by\nover 7.6% mAP on nuScenes-to-KITTI, while benefiting downstream tasks such as\nonline mapping, motion prediction and planning even without training. Code and\npretrained models are released in the supplementary material.", "AI": {"tldr": "CodeMerge is a lightweight model merging framework for 3D object detection, improving stability and efficiency by operating in a latent space with low-dimensional fingerprints.", "motivation": "Existing test-time adaptation methods struggle with instability and computational cost in dynamic 3D perception tasks.", "method": "CodeMerge uses a compact latent space with low-dimensional fingerprints and a key-value codebook, computing merging coefficients via ridge leverage scores.", "result": "Achieves 14.9% NDS improvement on nuScenes-C and 7.6% mAP on nuScenes-to-KITTI, benefiting downstream tasks without training.", "conclusion": "CodeMerge offers a scalable and efficient solution for robust 3D perception, outperforming existing methods."}}
{"id": "2505.16520", "pdf": "https://arxiv.org/pdf/2505.16520", "abs": "https://arxiv.org/abs/2505.16520", "authors": ["Giovanni Servedio", "Alessandro De Bellis", "Dario Di Palma", "Vito Walter Anelli", "Tommaso Di Noia"], "title": "Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Factual hallucinations are a major challenge for Large Language Models\n(LLMs). They undermine reliability and user trust by generating inaccurate or\nfabricated content. Recent studies suggest that when generating false\nstatements, the internal states of LLMs encode information about truthfulness.\nHowever, these studies often rely on synthetic datasets that lack realism,\nwhich limits generalization when evaluating the factual accuracy of text\ngenerated by the model itself. In this paper, we challenge the findings of\nprevious work by investigating truthfulness encoding capabilities, leading to\nthe generation of a more realistic and challenging dataset. Specifically, we\nextend previous work by introducing: (1) a strategy for sampling plausible\ntrue-false factoid sentences from tabular data and (2) a procedure for\ngenerating realistic, LLM-dependent true-false datasets from Question Answering\ncollections. Our analysis of two open-source LLMs reveals that while the\nfindings from previous studies are partially validated, generalization to\nLLM-generated datasets remains challenging. This study lays the groundwork for\nfuture research on factuality in LLMs and offers practical guidelines for more\neffective evaluation.", "AI": {"tldr": "The paper challenges prior findings on LLMs' truthfulness encoding by creating a more realistic dataset and evaluating two open-source LLMs, revealing partial validation of past results but highlighting generalization challenges.", "motivation": "Factual hallucinations in LLMs undermine reliability and trust. Prior studies used synthetic datasets, limiting realism and generalization. This work aims to address these gaps.", "method": "Introduced strategies for sampling true-false factoid sentences from tabular data and generating realistic datasets from Question Answering collections. Evaluated two open-source LLMs.", "result": "Previous findings were partially validated, but generalization to LLM-generated datasets proved challenging.", "conclusion": "The study provides groundwork for future research on LLM factuality and offers practical evaluation guidelines."}}
{"id": "2505.16196", "pdf": "https://arxiv.org/pdf/2505.16196", "abs": "https://arxiv.org/abs/2505.16196", "authors": ["Xuewu Lin", "Tianwei Lin", "Lichao Huang", "Hongyu Xie", "Yiwei Jin", "Keyu Li", "Zhizhong Su"], "title": "SEM: Enhancing Spatial Understanding for Robust Robot Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "A key challenge in robot manipulation lies in developing policy models with\nstrong spatial understanding, the ability to reason about 3D geometry, object\nrelations, and robot embodiment. Existing methods often fall short: 3D point\ncloud models lack semantic abstraction, while 2D image encoders struggle with\nspatial reasoning. To address this, we propose SEM (Spatial Enhanced\nManipulation model), a novel diffusion-based policy framework that explicitly\nenhances spatial understanding from two complementary perspectives. A spatial\nenhancer augments visual representations with 3D geometric context, while a\nrobot state encoder captures embodiment-aware structure through graphbased\nmodeling of joint dependencies. By integrating these modules, SEM significantly\nimproves spatial understanding, leading to robust and generalizable\nmanipulation across diverse tasks that outperform existing baselines.", "AI": {"tldr": "SEM is a diffusion-based policy framework enhancing spatial understanding in robot manipulation through 3D geometric context and robot state encoding, outperforming existing methods.", "motivation": "Existing methods lack strong spatial understanding in robot manipulation, with 3D point clouds missing semantics and 2D encoders struggling with spatial reasoning.", "method": "SEM combines a spatial enhancer for 3D geometric context and a robot state encoder for embodiment-aware structure via graph-based modeling.", "result": "SEM improves spatial understanding, enabling robust and generalizable manipulation across diverse tasks, surpassing baselines.", "conclusion": "SEM effectively addresses spatial reasoning challenges in robot manipulation, offering a superior framework for diverse tasks."}}
{"id": "2505.16672", "pdf": "https://arxiv.org/pdf/2505.16672", "abs": "https://arxiv.org/abs/2505.16672", "authors": ["Yun-Cheng Tsai", "Samuel Yen-Chi Chen"], "title": "Quantum Feature Optimization for Enhanced Clustering of Blockchain Transaction Data", "categories": ["cs.LG"], "comment": "6 pages, 6 figures, 1 table", "summary": "Blockchain transaction data exhibits high dimensionality, noise, and\nintricate feature entanglement, presenting significant challenges for\ntraditional clustering algorithms. In this study, we conduct a comparative\nanalysis of three clustering approaches: (1) Classical K-Means Clustering,\napplied to pre-processed feature representations; (2) Hybrid Clustering,\nwherein classical features are enhanced with quantum random features extracted\nusing randomly initialized quantum neural networks (QNNs); and (3) Fully\nQuantum Clustering, where a QNN is trained in a self-supervised manner\nleveraging a SwAV-based loss function to optimize the feature space for\nclustering directly. The proposed experimental framework systematically\ninvestigates the impact of quantum circuit depth and the number of learned\nprototypes, demonstrating that even shallow quantum circuits can effectively\nextract meaningful non-linear representations, significantly improving\nclustering performance.", "AI": {"tldr": "Comparative analysis of classical, hybrid, and quantum clustering methods for blockchain transaction data, showing quantum methods improve performance.", "motivation": "Blockchain transaction data is complex and noisy, challenging traditional clustering algorithms.", "method": "Compared three approaches: Classical K-Means, Hybrid Clustering (classical + quantum features), and Fully Quantum Clustering (self-supervised QNN).", "result": "Shallow quantum circuits effectively extract non-linear representations, enhancing clustering performance.", "conclusion": "Quantum methods, even with shallow circuits, outperform classical approaches for clustering blockchain data."}}
{"id": "2505.16533", "pdf": "https://arxiv.org/pdf/2505.16533", "abs": "https://arxiv.org/abs/2505.16533", "authors": ["Jiacong Chen", "Qingyu Mao", "Youneng Bao", "Xiandong Meng", "Fanyang Meng", "Ronggang Wang", "Yongsheng Liang"], "title": "Motion Matters: Compact Gaussian Streaming for Free-Viewpoint Video Reconstruction", "categories": ["cs.CV"], "comment": "17 pages, 9 figures", "summary": "3D Gaussian Splatting (3DGS) has emerged as a high-fidelity and efficient\nparadigm for online free-viewpoint video (FVV) reconstruction, offering viewers\nrapid responsiveness and immersive experiences. However, existing online\nmethods face challenge in prohibitive storage requirements primarily due to\npoint-wise modeling that fails to exploit the motion properties. To address\nthis limitation, we propose a novel Compact Gaussian Streaming (ComGS)\nframework, leveraging the locality and consistency of motion in dynamic scene,\nthat models object-consistent Gaussian point motion through keypoint-driven\nmotion representation. By transmitting only the keypoint attributes, this\nframework provides a more storage-efficient solution. Specifically, we first\nidentify a sparse set of motion-sensitive keypoints localized within motion\nregions using a viewspace gradient difference strategy. Equipped with these\nkeypoints, we propose an adaptive motion-driven mechanism that predicts a\nspatial influence field for propagating keypoint motion to neighboring Gaussian\npoints with similar motion. Moreover, ComGS adopts an error-aware correction\nstrategy for key frame reconstruction that selectively refines erroneous\nregions and mitigates error accumulation without unnecessary overhead. Overall,\nComGS achieves a remarkable storage reduction of over 159 X compared to\n3DGStream and 14 X compared to the SOTA method QUEEN, while maintaining\ncompetitive visual fidelity and rendering speed. Our code will be released.", "AI": {"tldr": "ComGS is a storage-efficient framework for dynamic scene reconstruction, reducing storage by 159X vs 3DGStream and 14X vs QUEEN, while maintaining visual quality.", "motivation": "Existing online methods for FVV reconstruction suffer from high storage due to point-wise modeling, ignoring motion properties.", "method": "ComGS uses keypoint-driven motion representation, adaptive motion propagation, and error-aware correction for efficient storage.", "result": "Achieves 159X and 14X storage reduction over 3DGStream and QUEEN, respectively, with competitive visual fidelity.", "conclusion": "ComGS provides a scalable and efficient solution for dynamic scene reconstruction with minimal storage overhead."}}
{"id": "2505.16522", "pdf": "https://arxiv.org/pdf/2505.16522", "abs": "https://arxiv.org/abs/2505.16522", "authors": ["Zhouhao Sun", "Zhiyuan Kan", "Xiao Ding", "Li Du", "Yang Zhao", "Bing Qin", "Ting Liu"], "title": "Benchmarking and Pushing the Multi-Bias Elimination Boundary of LLMs via Causal Effect Estimation-guided Debiasing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite significant progress, recent studies have indicated that current\nlarge language models (LLMs) may still utilize bias during inference, leading\nto the poor generalizability of LLMs. Some benchmarks are proposed to\ninvestigate the generalizability of LLMs, with each piece of data typically\ncontaining one type of controlled bias. However, a single piece of data may\ncontain multiple types of biases in practical applications. To bridge this gap,\nwe propose a multi-bias benchmark where each piece of data contains five types\nof biases. The evaluations conducted on this benchmark reveal that the\nperformance of existing LLMs and debiasing methods is unsatisfying,\nhighlighting the challenge of eliminating multiple types of biases\nsimultaneously. To overcome this challenge, we propose a causal effect\nestimation-guided multi-bias elimination method (CMBE). This method first\nestimates the causal effect of multiple types of biases simultaneously.\nSubsequently, we eliminate the causal effect of biases from the total causal\neffect exerted by both the semantic information and biases during inference.\nExperimental results show that CMBE can effectively eliminate multiple types of\nbias simultaneously to enhance the generalizability of LLMs.", "AI": {"tldr": "A multi-bias benchmark and CMBE method are proposed to address LLMs' poor generalizability due to multiple biases, showing improved performance.", "motivation": "Current LLMs struggle with generalizability due to multiple biases in data, and existing benchmarks fail to address this complexity.", "method": "Proposes a multi-bias benchmark and CMBE, a causal effect estimation-guided method to eliminate multiple biases simultaneously.", "result": "CMBE effectively eliminates multiple biases, enhancing LLMs' generalizability.", "conclusion": "The study highlights the challenge of multi-bias elimination and demonstrates CMBE's effectiveness in improving LLM performance."}}
{"id": "2505.16208", "pdf": "https://arxiv.org/pdf/2505.16208", "abs": "https://arxiv.org/abs/2505.16208", "authors": ["Anton Erofeev", "Balasubramanya T. Nadiga", "Ilya Timofeyev"], "title": "Using Echo-State Networks to Reproduce Rare Events in Chaotic Systems", "categories": ["nlin.CD", "cs.AI", "cs.LG", "math.DS", "37N99, 68T30"], "comment": null, "summary": "We apply the Echo-State Networks to predict the time series and statistical\nproperties of the competitive Lotka-Volterra model in the chaotic regime. In\nparticular, we demonstrate that Echo-State Networks successfully learn the\nchaotic attractor of the competitive Lotka-Volterra model and reproduce\nhistograms of dependent variables, including tails and rare events. We use the\nGeneralized Extreme Value distribution to quantify the tail behavior.", "AI": {"tldr": "Echo-State Networks predict chaotic Lotka-Volterra model dynamics, including rare events, using Generalized Extreme Value distribution for tail analysis.", "motivation": "To explore the capability of Echo-State Networks in learning and predicting chaotic dynamics and statistical properties of the competitive Lotka-Volterra model.", "method": "Applied Echo-State Networks to the chaotic Lotka-Volterra model, using Generalized Extreme Value distribution to analyze tail behavior.", "result": "Successfully learned the chaotic attractor and reproduced histograms, including tails and rare events.", "conclusion": "Echo-State Networks are effective for predicting chaotic systems and extreme events in the Lotka-Volterra model."}}
{"id": "2505.16675", "pdf": "https://arxiv.org/pdf/2505.16675", "abs": "https://arxiv.org/abs/2505.16675", "authors": ["Wenwen Qiang", "Jingyao Wang", "Zeen Song", "Jiangmeng Li", "Changwen Zheng"], "title": "On the Out-of-Distribution Generalization of Self-Supervised Learning", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we focus on the out-of-distribution (OOD) generalization of\nself-supervised learning (SSL). By analyzing the mini-batch construction during\nthe SSL training phase, we first give one plausible explanation for SSL having\nOOD generalization. Then, from the perspective of data generation and causal\ninference, we analyze and conclude that SSL learns spurious correlations during\nthe training process, which leads to a reduction in OOD generalization. To\naddress this issue, we propose a post-intervention distribution (PID) grounded\nin the Structural Causal Model. PID offers a scenario where the spurious\nvariable and label variable is mutually independent. Besides, we demonstrate\nthat if each mini-batch during SSL training satisfies PID, the resulting SSL\nmodel can achieve optimal worst-case OOD performance. This motivates us to\ndevelop a batch sampling strategy that enforces PID constraints through the\nlearning of a latent variable model. Through theoretical analysis, we\ndemonstrate the identifiability of the latent variable model and validate the\neffectiveness of the proposed sampling strategy. Experiments conducted on\nvarious downstream OOD tasks demonstrate the effectiveness of the proposed\nsampling strategy.", "AI": {"tldr": "The paper explains why SSL has OOD generalization, identifies spurious correlations as a limitation, and proposes a PID-based batch sampling strategy to improve OOD performance.", "motivation": "To understand and improve the OOD generalization of SSL by addressing spurious correlations learned during training.", "method": "Proposes a post-intervention distribution (PID) grounded in the Structural Causal Model and a batch sampling strategy enforcing PID constraints.", "result": "Theoretical analysis shows identifiability of the latent variable model, and experiments validate the sampling strategy's effectiveness on OOD tasks.", "conclusion": "The proposed PID-based sampling strategy improves SSL's OOD generalization by mitigating spurious correlations."}}
{"id": "2505.16535", "pdf": "https://arxiv.org/pdf/2505.16535", "abs": "https://arxiv.org/abs/2505.16535", "authors": ["Asrar Alruwayqi"], "title": "SHaDe: Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane Deformation and Latent Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "We present a novel framework for dynamic 3D scene reconstruction that\nintegrates three key components: an explicit tri-plane deformation field, a\nview-conditioned canonical radiance field with spherical harmonics (SH)\nattention, and a temporally-aware latent diffusion prior. Our method encodes 4D\nscenes using three orthogonal 2D feature planes that evolve over time, enabling\nefficient and compact spatiotemporal representation. These features are\nexplicitly warped into a canonical space via a deformation offset field,\neliminating the need for MLP-based motion modeling.\n  In canonical space, we replace traditional MLP decoders with a structured\nSH-based rendering head that synthesizes view-dependent color via attention\nover learned frequency bands improving both interpretability and rendering\nefficiency. To further enhance fidelity and temporal consistency, we introduce\na transformer-guided latent diffusion module that refines the tri-plane and\ndeformation features in a compressed latent space. This generative module\ndenoises scene representations under ambiguous or out-of-distribution (OOD)\nmotion, improving generalization.\n  Our model is trained in two stages: the diffusion module is first pre-trained\nindependently, and then fine-tuned jointly with the full pipeline using a\ncombination of image reconstruction, diffusion denoising, and temporal\nconsistency losses. We demonstrate state-of-the-art results on synthetic\nbenchmarks, surpassing recent methods such as HexPlane and 4D Gaussian\nSplatting in visual quality, temporal coherence, and robustness to sparse-view\ndynamic inputs.", "AI": {"tldr": "A novel framework for dynamic 3D scene reconstruction integrates tri-plane deformation, SH-based rendering, and latent diffusion, achieving state-of-the-art results.", "motivation": "To improve dynamic 3D scene reconstruction by combining efficient spatiotemporal representation with interpretable rendering and robust motion handling.", "method": "Uses tri-plane deformation fields, SH-based rendering, and a latent diffusion prior for refining features. Trained in two stages: pre-training the diffusion module and joint fine-tuning.", "result": "Surpasses HexPlane and 4D Gaussian Splatting in visual quality, temporal coherence, and robustness to sparse-view inputs.", "conclusion": "The framework offers a compact, efficient, and high-fidelity solution for dynamic 3D scene reconstruction."}}
{"id": "2505.16526", "pdf": "https://arxiv.org/pdf/2505.16526", "abs": "https://arxiv.org/abs/2505.16526", "authors": ["Heejae Suh", "Yejin Jeon", "Deokhyung Kang", "Taehee Park", "Yejin Min", "Gary Geunbae Lee"], "title": "EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance", "categories": ["cs.CL"], "comment": "Accepted at ACL 2025 (Findings, long paper)", "summary": "Small large language models (sLLMs) offer the advantage of being lightweight\nand efficient, which makes them suitable for resource-constrained environments.\nHowever, sLLMs often struggle to maintain topic consistency in task-oriented\ndialogue systems, which is critical for scenarios such as service chatbots.\nSpecifically, it is important to ensure that the model denies off-topic or\nmalicious inputs and adheres to its intended functionality so as to prevent\npotential misuse and uphold reliability. Towards this, existing activation\nengineering approaches have been proposed to manipulate internal activations\nduring inference. While these methods are effective in certain scenarios, our\npreliminary experiments reveal their limitations in ensuring topic adherence.\nTherefore, to address this, we propose a novel approach termed Entropy-scaled\nSteering vectors for Topic Maintenance (EnSToM). EnSToM dynamically adjusts the\nsteering intensity based on input uncertainty, which allows the model to handle\noff-topic distractors effectively while preserving on-topic accuracy. Our\nexperiments demonstrate that EnSToM achieves significant performance gain with\na relatively small data size compared to fine-tuning approaches. By improving\ntopic adherence without compromising efficiency, our approach provides a robust\nsolution for enhancing sLLM-based dialogue systems.", "AI": {"tldr": "EnSToM improves topic consistency in small LLMs for dialogue systems by dynamically adjusting steering vectors based on input uncertainty, outperforming fine-tuning with less data.", "motivation": "Small LLMs (sLLMs) struggle with topic consistency in task-oriented dialogues, risking misuse. Existing activation engineering methods are insufficient.", "method": "Proposed EnSToM: dynamically adjusts steering vectors using input uncertainty to handle off-topic inputs while maintaining on-topic accuracy.", "result": "EnSToM achieves significant performance gains with minimal data compared to fine-tuning, enhancing topic adherence without efficiency loss.", "conclusion": "EnSToM offers a robust solution for improving sLLM-based dialogue systems by balancing topic consistency and efficiency."}}
{"id": "2505.16249", "pdf": "https://arxiv.org/pdf/2505.16249", "abs": "https://arxiv.org/abs/2505.16249", "authors": ["Zhen Zhang", "Xiangyu Chu", "Yunxi Tang", "Lulu Zhao", "Jing Huang", "Zhongliang Jiang", "K. W. Samuel Au"], "title": "Manipulating Elasto-Plastic Objects With 3D Occupancy and Learning-Based Predictive Control", "categories": ["cs.RO", "cs.AI"], "comment": "8 Pages, 5 figures, accepted for publication in IEEE Robotics and\n  Automation Letters (RA-L)", "summary": "Manipulating elasto-plastic objects remains a significant challenge due to\nsevere self-occlusion, difficulties of representation, and complicated\ndynamics. This work proposes a novel framework for elasto-plastic object\nmanipulation with a quasi-static assumption for motions, leveraging 3D\noccupancy to represent such objects, a learned dynamics model trained with 3D\noccupancy, and a learning-based predictive control algorithm to address these\nchallenges effectively. We build a novel data collection platform to collect\nfull spatial information and propose a pipeline for generating a 3D occupancy\ndataset. To infer the 3D occupancy during manipulation, an occupancy prediction\nnetwork is trained with multiple RGB images supervised by the generated\ndataset. We design a deep neural network empowered by a 3D convolution neural\nnetwork (CNN) and a graph neural network (GNN) to predict the complex\ndeformation with the inferred 3D occupancy results. A learning-based predictive\ncontrol algorithm is introduced to plan the robot actions, incorporating a\nnovel shape-based action initialization module specifically designed to improve\nthe planner efficiency. The proposed framework in this paper can successfully\nshape the elasto-plastic objects into a given goal shape and has been verified\nin various experiments both in simulation and the real world.", "AI": {"tldr": "A novel framework for manipulating elasto-plastic objects using 3D occupancy representation, learned dynamics, and predictive control, validated in simulations and real-world experiments.", "motivation": "Challenges in manipulating elasto-plastic objects due to self-occlusion, representation difficulties, and complex dynamics.", "method": "Proposes a framework with 3D occupancy representation, a learned dynamics model, and predictive control. Includes data collection, occupancy prediction, and deformation prediction using 3D CNN and GNN.", "result": "Successfully shapes elasto-plastic objects into goal shapes, verified in simulations and real-world tests.", "conclusion": "The framework effectively addresses manipulation challenges and demonstrates practical applicability."}}
{"id": "2505.16680", "pdf": "https://arxiv.org/pdf/2505.16680", "abs": "https://arxiv.org/abs/2505.16680", "authors": ["Filip Thor", "Carl Nettelblad"], "title": "Learning Genomic Structure from $k$-mers", "categories": ["cs.LG", "q-bio.GN", "q-bio.QM"], "comment": null, "summary": "Sequencing a genome to determine an individual's DNA produces an enormous\nnumber of short nucleotide subsequences known as reads, which must be\nreassembled to reconstruct the full genome. We present a method for analyzing\nthis type of data using contrastive learning, in which an encoder model is\ntrained to produce embeddings that cluster together sequences from the same\ngenomic region. The sequential nature of genomic regions is preserved in the\nform of trajectories through this embedding space. Trained solely to reflect\nthe structure of the genome, the resulting model provides a general\nrepresentation of $k$-mer sequences, suitable for a range of downstream tasks\ninvolving read data. We apply our framework to learn the structure of the $E.\\\ncoli$ genome, and demonstrate its use in simulated ancient DNA (aDNA) read\nmapping and identification of structural variations. Furthermore, we illustrate\nthe potential of using this type of model for metagenomic species\nidentification. We show how incorporating a domain-specific noise model can\nenhance embedding robustness, and how a supervised contrastive learning setting\ncan be adopted when a linear reference genome is available, by introducing a\ndistance thresholding parameter $\\Gamma$. The model can also be trained fully\nself-supervised on read data, enabling analysis without the need to construct a\nfull genome assembly using specialized algorithms. Small prediction heads based\non a pre-trained embedding are shown to perform on par with BWA-aln, the\ncurrent gold standard approach for aDNA mapping, in terms of accuracy and\nruntime for short genomes. Given the method's favorable scaling properties with\nrespect to total genome size, inference using our approach is highly promising\nfor metagenomic applications and for mapping to genomes comparable in size to\nthe human genome.", "AI": {"tldr": "A contrastive learning method is proposed to analyze genomic read data, producing embeddings that cluster sequences from the same genomic region, useful for tasks like aDNA mapping and metagenomic species identification.", "motivation": "The challenge of reassembling short nucleotide reads into a full genome and the need for efficient downstream genomic analysis tools.", "method": "Uses contrastive learning to train an encoder model for sequence embeddings, preserving genomic region trajectories. Incorporates domain-specific noise and supervised settings when a reference genome is available.", "result": "The model performs comparably to BWA-aln for aDNA mapping and shows promise for metagenomics and large genomes like humans.", "conclusion": "The method offers a scalable, general representation for genomic read data, enabling robust analysis without full genome assembly."}}
{"id": "2505.16540", "pdf": "https://arxiv.org/pdf/2505.16540", "abs": "https://arxiv.org/abs/2505.16540", "authors": ["Inbal Cohen", "Boaz Meivar", "Peihan Tu", "Shai Avidan", "Gal Oren"], "title": "TextureSAM: Towards a Texture Aware Foundation Model for Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Segment Anything Models (SAM) have achieved remarkable success in object\nsegmentation tasks across diverse datasets. However, these models are\npredominantly trained on large-scale semantic segmentation datasets, which\nintroduce a bias toward object shape rather than texture cues in the image.\nThis limitation is critical in domains such as medical imaging, material\nclassification, and remote sensing, where texture changes define object\nboundaries. In this study, we investigate SAM's bias toward semantics over\ntextures and introduce a new texture-aware foundation model, TextureSAM, which\nperforms superior segmentation in texture-dominant scenarios. To achieve this,\nwe employ a novel fine-tuning approach that incorporates texture augmentation\ntechniques, incrementally modifying training images to emphasize texture\nfeatures. By leveraging a novel texture-alternation of the ADE20K dataset, we\nguide TextureSAM to prioritize texture-defined regions, thereby mitigating the\ninherent shape bias present in the original SAM model. Our extensive\nexperiments demonstrate that TextureSAM significantly outperforms SAM-2 on both\nnatural (+0.2 mIoU) and synthetic (+0.18 mIoU) texture-based segmentation\ndatasets. The code and texture-augmented dataset will be publicly available.", "AI": {"tldr": "TextureSAM addresses SAM's bias toward shape over texture in segmentation by introducing texture-aware fine-tuning, outperforming SAM-2 in texture-dominant tasks.", "motivation": "SAM's reliance on shape cues limits performance in domains like medical imaging and material classification, where texture defines boundaries.", "method": "TextureSAM uses texture augmentation and fine-tuning on a modified ADE20K dataset to prioritize texture features.", "result": "TextureSAM outperforms SAM-2 by +0.2 mIoU on natural and +0.18 mIoU on synthetic texture datasets.", "conclusion": "TextureSAM effectively mitigates SAM's shape bias, offering superior segmentation in texture-dominant scenarios."}}
{"id": "2505.16538", "pdf": "https://arxiv.org/pdf/2505.16538", "abs": "https://arxiv.org/abs/2505.16538", "authors": ["Ercong Nie", "Helmut Schmid", "Hinrich Sch\u00fctze"], "title": "Mechanistic Understanding and Mitigation of Language Confusion in English-Centric Large Language Models", "categories": ["cs.CL"], "comment": "16 pages, 5 figures", "summary": "Language confusion -- where large language models (LLMs) generate unintended\nlanguages against the user's need -- remains a critical challenge, especially\nfor English-centric models. We present the first mechanistic interpretability\n(MI) study of language confusion, combining behavioral benchmarking with\nneuron-level analysis. Using the Language Confusion Benchmark (LCB), we show\nthat confusion points (CPs) -- specific positions where language switches occur\n-- are central to this phenomenon. Through layer-wise analysis with TunedLens\nand targeted neuron attribution, we reveal that transition failures in the\nfinal layers drive confusion. We further demonstrate that editing a small set\nof critical neurons, identified via comparative analysis with\nmultilingual-tuned models, substantially mitigates confusion without harming\ngeneral competence or fluency. Our approach matches multilingual alignment in\nconfusion reduction for most languages and yields cleaner, higher-quality\noutputs. These findings provide new insights into the internal dynamics of LLMs\nand highlight neuron-level interventions as a promising direction for robust,\ninterpretable multilingual language modeling.", "AI": {"tldr": "The paper investigates language confusion in LLMs, identifies confusion points, and proposes neuron-level interventions to mitigate the issue without compromising model performance.", "motivation": "Language confusion in English-centric LLMs is a critical challenge, and understanding its mechanisms can improve multilingual modeling.", "method": "Combines behavioral benchmarking (LCB) with mechanistic interpretability (MI), using TunedLens and neuron attribution to analyze confusion points and transition failures.", "result": "Editing critical neurons reduces confusion, matches multilingual alignment, and improves output quality without harming fluency.", "conclusion": "Neuron-level interventions offer a robust, interpretable solution for multilingual LLMs, enhancing their internal dynamics."}}
{"id": "2505.16290", "pdf": "https://arxiv.org/pdf/2505.16290", "abs": "https://arxiv.org/abs/2505.16290", "authors": ["Mohammad Rubyet Islam", "Peter Sandborn"], "title": "Multimodal Generative AI for Story Point Estimation in Software Development", "categories": ["cs.SE", "cs.AI", "68T07, 68T45", "I.2.6; I.2.10; D.2.9; H.2.8"], "comment": null, "summary": "This research explores the application of Multimodal Generative AI to enhance\nstory point estimation in Agile software development. By integrating text,\nimage, and categorical data using advanced models like BERT, CNN, and XGBoost,\nour approach surpasses the limitations of traditional single-modal estimation\nmethods. The results demonstrate strong accuracy for simpler story points,\nwhile also highlighting challenges in more complex categories due to data\nimbalance. This study further explores the impact of categorical data,\nparticularly severity, on the estimation process, emphasizing its influence on\nmodel performance. Our findings emphasize the transformative potential of\nmultimodal data integration in refining AI-driven project management, paving\nthe way for more precise, adaptable, and domain-specific AI capabilities.\nAdditionally, this work outlines future directions for addressing data\nvariability and enhancing the robustness of AI in Agile methodologies.", "AI": {"tldr": "Multimodal Generative AI improves story point estimation in Agile by combining text, image, and categorical data, outperforming single-modal methods but facing challenges with complex categories.", "motivation": "To overcome limitations of traditional single-modal estimation methods in Agile software development by leveraging multimodal data integration.", "method": "Integrates text, image, and categorical data using BERT, CNN, and XGBoost models.", "result": "Achieves strong accuracy for simpler story points but struggles with complex categories due to data imbalance. Categorical data, like severity, significantly impacts performance.", "conclusion": "Multimodal AI has transformative potential for Agile project management, though future work is needed to address data variability and robustness."}}
{"id": "2505.16690", "pdf": "https://arxiv.org/pdf/2505.16690", "abs": "https://arxiv.org/abs/2505.16690", "authors": ["Beier Luo", "Shuoyuan Wang", "Yixuan Li", "Hongxin Wei"], "title": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Post-training of large language models is essential for adapting pre-trained\nlanguage models (PLMs) to align with human preferences and downstream tasks.\nWhile PLMs typically exhibit well-calibrated confidence, post-trained language\nmodels (PoLMs) often suffer from over-confidence, assigning high confidence to\nboth correct and incorrect outputs, which can undermine reliability in critical\napplications. A major obstacle in calibrating PoLMs is the scarcity of labeled\ndata for individual downstream tasks. To address this, we propose\nDisagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to\noptimize the parameters (e.g., temperature $\\tau$) in post-hoc confidence\ncalibration. Our method is motivated by the under-confidence issue caused by\nprediction disagreement between the PLM and PoLM while aligning their\nconfidence via temperature scaling. Theoretically, the PLM's confidence\nunderestimates PoLM's prediction accuracy on disagreement examples, causing a\nlarger $\\tau$ and producing under-confident predictions. DACA mitigates this by\nselectively using only agreement examples for calibration, effectively\ndecoupling the influence of disagreement. In this manner, our method avoids an\noverly large $\\tau$ in temperature scaling caused by disagreement examples,\nimproving calibration performance. Extensive experiments demonstrate the\neffectiveness of our method, improving the average ECE of open-sourced and\nAPI-based LLMs (e.g. GPT-4o) by up to 15.08$\\%$ on common benchmarks.", "AI": {"tldr": "DACA is an unsupervised method to improve confidence calibration in post-trained language models by selectively using agreement examples, avoiding over-confidence issues.", "motivation": "Post-trained language models (PoLMs) often suffer from over-confidence, undermining reliability. Labeled data scarcity for calibration is a challenge.", "method": "Proposes Disagreement-Aware Confidence Alignment (DACA), which aligns confidence via temperature scaling using only agreement examples, decoupling disagreement influence.", "result": "Improves average ECE by up to 15.08% on benchmarks, including models like GPT-4o.", "conclusion": "DACA effectively mitigates over-confidence in PoLMs by optimizing calibration parameters without labeled data."}}
{"id": "2505.16561", "pdf": "https://arxiv.org/pdf/2505.16561", "abs": "https://arxiv.org/abs/2505.16561", "authors": ["Jannis Becktepe", "Leona Hennig", "Steffen Oeltze-Jafra", "Marius Lindauer"], "title": "Auto-nnU-Net: Towards Automated Medical Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "31 pages, 19 figures. Accepted for publication at AutoML 2025", "summary": "Medical Image Segmentation (MIS) includes diverse tasks, from bone to organ\nsegmentation, each with its own challenges in finding the best segmentation\nmodel. The state-of-the-art AutoML-related MIS-framework nnU-Net automates many\naspects of model configuration but remains constrained by fixed hyperparameters\nand heuristic design choices. As a full-AutoML framework for MIS, we propose\nAuto-nnU-Net, a novel nnU-Net variant enabling hyperparameter optimization\n(HPO), neural architecture search (NAS), and hierarchical NAS (HNAS).\nAdditionally, we propose Regularized PriorBand to balance model accuracy with\nthe computational resources required for training, addressing the resource\nconstraints often faced in real-world medical settings that limit the\nfeasibility of extensive training procedures. We evaluate our approach across\ndiverse MIS datasets from the well-established Medical Segmentation Decathlon,\nanalyzing the impact of AutoML techniques on segmentation performance,\ncomputational efficiency, and model design choices. The results demonstrate\nthat our AutoML approach substantially improves the segmentation performance of\nnnU-Net on 6 out of 10 datasets and is on par on the other datasets while\nmaintaining practical resource requirements. Our code is available at\nhttps://github.com/LUH-AI/AutonnUNet.", "AI": {"tldr": "Auto-nnU-Net enhances nnU-Net by adding hyperparameter optimization, neural architecture search, and hierarchical NAS, improving segmentation performance while managing computational resources.", "motivation": "Address limitations of nnU-Net's fixed hyperparameters and heuristic design choices to improve medical image segmentation performance and resource efficiency.", "method": "Propose Auto-nnU-Net with HPO, NAS, and HNAS, and introduce Regularized PriorBand for resource-efficient training.", "result": "Substantially improves segmentation on 6/10 datasets, matches performance on others, and maintains practical resource use.", "conclusion": "Auto-nnU-Net advances MIS by automating model configuration and balancing accuracy with computational constraints."}}
{"id": "2505.16552", "pdf": "https://arxiv.org/pdf/2505.16552", "abs": "https://arxiv.org/abs/2505.16552", "authors": ["Wenhui Tan", "Jiaze Li", "Jianzhong Ju", "Zhenbo Luo", "Jian Luan", "Ruihua Song"], "title": "Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains", "categories": ["cs.CL"], "comment": "15 pages, 8 figures", "summary": "Large Language Models (LLMs) achieve superior performance through\nChain-of-Thought (CoT) reasoning, but these token-level reasoning chains are\ncomputationally expensive and inefficient. In this paper, we introduce\nCompressed Latent Reasoning (CoLaR), a novel framework that dynamically\ncompresses reasoning processes in latent space through a two-stage training\napproach. First, during supervised fine-tuning, CoLaR extends beyond next-token\nprediction by incorporating an auxiliary next compressed embedding prediction\nobjective. This process merges embeddings of consecutive tokens using a\ncompression factor randomly sampled from a predefined range, and trains a\nspecialized latent head to predict distributions of subsequent compressed\nembeddings. Second, we enhance CoLaR through reinforcement learning (RL) that\nleverages the latent head's non-deterministic nature to explore diverse\nreasoning paths and exploit more compact ones. This approach enables CoLaR to:\ni) perform reasoning at a dense latent level (i.e., silently), substantially\nreducing reasoning chain length, and ii) dynamically adjust reasoning speed at\ninference time by simply prompting the desired compression factor. Extensive\nexperiments across four mathematical reasoning datasets demonstrate that CoLaR\nachieves 14.1% higher accuracy than latent-based baseline methods at comparable\ncompression ratios, and reduces reasoning chain length by 53.3% with only 4.8%\nperformance degradation compared to explicit CoT method. Moreover, when applied\nto more challenging mathematical reasoning tasks, our RL-enhanced CoLaR\ndemonstrates performance gains of up to 5.4% while dramatically reducing latent\nreasoning chain length by 82.8%. The code and models will be released upon\nacceptance.", "AI": {"tldr": "CoLaR introduces a framework to compress reasoning processes in latent space, reducing computational costs while maintaining performance.", "motivation": "To address the inefficiency and computational expense of token-level reasoning chains in LLMs.", "method": "A two-stage approach: supervised fine-tuning with compressed embedding prediction and reinforcement learning to explore diverse reasoning paths.", "result": "Achieves higher accuracy and reduces reasoning chain length significantly compared to baselines.", "conclusion": "CoLaR efficiently compresses reasoning, offering dynamic adjustment and improved performance in mathematical tasks."}}
{"id": "2505.16301", "pdf": "https://arxiv.org/pdf/2505.16301", "abs": "https://arxiv.org/abs/2505.16301", "authors": ["Fuchun Ge", "Pavlo O. Dral"], "title": "Artificial Intelligence for Direct Prediction of Molecular Dynamics Across Chemical Space", "categories": ["physics.chem-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Molecular dynamics (MD) is a powerful tool for exploring the behavior of\natomistic systems, but its reliance on sequential numerical integration limits\nsimulation efficiency. We present MDtrajNet-1, a foundational AI model that\ndirectly generates MD trajectories across chemical space, bypassing force\ncalculations and integration. This approach accelerates simulations by up to\ntwo orders of magnitude compared to traditional MD, even those enhanced by\nmachine-learning interatomic potentials. MDtrajNet-1 combines equivariant\nneural networks with a Transformer-based architecture to achieve strong\naccuracy and transferability in predicting long-time trajectories for both\nknown and unseen systems. Remarkably, the errors of the trajectories generated\nby MDtrajNet-1 for various molecular systems are close to those of the\nconventional ab initio MD. The model's flexible design supports diverse\napplication scenarios, including different statistical ensembles, boundary\nconditions, and interaction types. By overcoming the intrinsic speed barrier of\nconventional MD, MDtrajNet-1 opens new frontiers in efficient and scalable\natomistic simulations.", "AI": {"tldr": "MDtrajNet-1 is an AI model that accelerates molecular dynamics simulations by directly generating trajectories, bypassing traditional force calculations and integration.", "motivation": "Traditional MD simulations are limited by sequential numerical integration, which reduces efficiency. MDtrajNet-1 aims to overcome this barrier.", "method": "MDtrajNet-1 uses equivariant neural networks and a Transformer-based architecture to predict trajectories accurately and efficiently.", "result": "The model speeds up simulations by up to 100x compared to traditional MD, with errors close to ab initio MD.", "conclusion": "MDtrajNet-1 enables efficient and scalable atomistic simulations, opening new possibilities for the field."}}
{"id": "2505.16705", "pdf": "https://arxiv.org/pdf/2505.16705", "abs": "https://arxiv.org/abs/2505.16705", "authors": ["Seonghwan Park", "Jueun Mun", "Donghyun Oh", "Namhoon Lee"], "title": "An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Concept bottleneck models (CBMs) ensure interpretability by decomposing\npredictions into human interpretable concepts. Yet the annotations used for\ntraining CBMs that enable this transparency are often noisy, and the impact of\nsuch corruption is not well understood. In this study, we present the first\nsystematic study of noise in CBMs and show that even moderate corruption\nsimultaneously impairs prediction performance, interpretability, and the\nintervention effectiveness. Our analysis identifies a susceptible subset of\nconcepts whose accuracy declines far more than the average gap between noisy\nand clean supervision and whose corruption accounts for most performance loss.\nTo mitigate this vulnerability we propose a two-stage framework. During\ntraining, sharpness-aware minimization stabilizes the learning of\nnoise-sensitive concepts. During inference, where clean labels are unavailable,\nwe rank concepts by predictive entropy and correct only the most uncertain\nones, using uncertainty as a proxy for susceptibility. Theoretical analysis and\nextensive ablations elucidate why sharpness-aware training confers robustness\nand why uncertainty reliably identifies susceptible concepts, providing a\nprincipled basis that preserves both interpretability and resilience in the\npresence of noise.", "AI": {"tldr": "CBMs' interpretability is compromised by noisy annotations, impairing performance and intervention. A two-stage framework mitigates this by stabilizing training and correcting uncertain concepts during inference.", "motivation": "To understand and address the impact of noisy annotations on CBMs' interpretability, performance, and intervention effectiveness.", "method": "Proposes a two-stage framework: sharpness-aware minimization during training and entropy-based concept correction during inference.", "result": "Noise significantly harms CBMs, but the framework improves robustness and preserves interpretability.", "conclusion": "The study provides a principled solution to maintain CBMs' interpretability and resilience despite noisy supervision."}}
{"id": "2505.16565", "pdf": "https://arxiv.org/pdf/2505.16565", "abs": "https://arxiv.org/abs/2505.16565", "authors": ["Nina Shvetsova", "Goutam Bhat", "Prune Truong", "Hilde Kuehne", "Federico Tombari"], "title": "M2SVid: End-to-End Inpainting and Refinement for Monocular-to-Stereo Video Conversion", "categories": ["cs.CV"], "comment": null, "summary": "We tackle the problem of monocular-to-stereo video conversion and propose a\nnovel architecture for inpainting and refinement of the warped right view\nobtained by depth-based reprojection of the input left view. We extend the\nStable Video Diffusion (SVD) model to utilize the input left video, the warped\nright video, and the disocclusion masks as conditioning input to generate a\nhigh-quality right camera view. In order to effectively exploit information\nfrom neighboring frames for inpainting, we modify the attention layers in SVD\nto compute full attention for discoccluded pixels. Our model is trained to\ngenerate the right view video in an end-to-end manner by minimizing image space\nlosses to ensure high-quality generation. Our approach outperforms previous\nstate-of-the-art methods, obtaining an average rank of 1.43 among the 4\ncompared methods in a user study, while being 6x faster than the second placed\nmethod.", "AI": {"tldr": "A novel architecture for monocular-to-stereo video conversion using Stable Video Diffusion (SVD) with improved attention layers for inpainting, achieving high-quality results and faster performance.", "motivation": "To address the challenge of generating high-quality stereo video from monocular input by refining the warped right view and handling disocclusions effectively.", "method": "Extends SVD to use left video, warped right video, and disocclusion masks as inputs, modifies attention layers for better inpainting, and trains end-to-end with image space losses.", "result": "Outperforms state-of-the-art methods, ranking 1.43/4 in a user study and being 6x faster than the second-best method.", "conclusion": "The proposed method effectively converts monocular to stereo video with superior quality and efficiency."}}
{"id": "2505.16566", "pdf": "https://arxiv.org/pdf/2505.16566", "abs": "https://arxiv.org/abs/2505.16566", "authors": ["Dongwon Noh", "Donghyeok Koh", "Junghun Yuk", "Gyuwan Kim", "Jaeyong Lee", "Kyungtae Lim", "Cheoneum Park"], "title": "ScholarBench: A Bilingual Benchmark for Abstraction, Comprehension, and Reasoning Evaluation in Academic Contexts", "categories": ["cs.CL"], "comment": null, "summary": "Prior benchmarks for evaluating the domain-specific knowledge of large\nlanguage models (LLMs) lack the scalability to handle complex academic tasks.\nTo address this, we introduce \\texttt{ScholarBench}, a benchmark centered on\ndeep expert knowledge and complex academic problem-solving, which evaluates the\nacademic reasoning ability of LLMs and is constructed through a three-step\nprocess. \\texttt{ScholarBench} targets more specialized and logically complex\ncontexts derived from academic literature, encompassing five distinct problem\ntypes. Unlike prior benchmarks, \\texttt{ScholarBench} evaluates the\nabstraction, comprehension, and reasoning capabilities of LLMs across eight\ndistinct research domains. To ensure high-quality evaluation data, we define\ncategory-specific example attributes and design questions that are aligned with\nthe characteristic research methodologies and discourse structures of each\ndomain. Additionally, this benchmark operates as an English-Korean bilingual\ndataset, facilitating simultaneous evaluation for linguistic capabilities of\nLLMs in both languages. The benchmark comprises 5,031 examples in Korean and\n5,309 in English, with even state-of-the-art models like o3-mini achieving an\naverage evaluation score of only 0.543, demonstrating the challenging nature of\nthis benchmark.", "AI": {"tldr": "The paper introduces ScholarBench, a scalable benchmark for evaluating LLMs' domain-specific knowledge and academic reasoning across complex tasks and multiple research domains.", "motivation": "Prior benchmarks lack scalability for complex academic tasks, prompting the need for ScholarBench to assess deep expert knowledge and reasoning.", "method": "ScholarBench is constructed via a three-step process, focusing on specialized contexts from academic literature, with five problem types and bilingual (English-Korean) evaluation.", "result": "State-of-the-art models like o3-mini score only 0.543 on average, highlighting the benchmark's difficulty.", "conclusion": "ScholarBench effectively challenges LLMs in academic reasoning and linguistic capabilities, filling a gap in existing benchmarks."}}
{"id": "2505.16332", "pdf": "https://arxiv.org/pdf/2505.16332", "abs": "https://arxiv.org/abs/2505.16332", "authors": ["Zhehui Wanga", "Benjamin Chen Ming Choonga", "Tian Huang", "Daniel Gerlinghoffa", "Rick Siow Mong Goh", "Cheng Liu", "Tao Luo"], "title": "Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "Quantum optimization is the most mature quantum computing technology to date,\nproviding a promising approach towards efficiently solving complex\ncombinatorial problems. Methods such as adiabatic quantum computing (AQC) have\nbeen employed in recent years on important optimization problems across various\ndomains. In deep learning, deep neural networks (DNN) have reached immense\nsizes to support new predictive capabilities. Optimization of large-scale\nmodels is critical for sustainable deployment, but becomes increasingly\nchallenging with ever-growing model sizes and complexity. While quantum\noptimization is suitable for solving complex problems, its application to DNN\noptimization is not straightforward, requiring thorough reformulation for\ncompatibility with commercially available quantum devices. In this work, we\nexplore the potential of adopting AQC for fine-grained pruning-quantization of\nconvolutional neural networks. We rework established heuristics to formulate\nmodel compression as a quadratic unconstrained binary optimization (QUBO)\nproblem, and assess the solution space offered by commercial quantum annealing\ndevices. Through our exploratory efforts of reformulation, we demonstrate that\nAQC can achieve effective compression of practical DNN models. Experiments\ndemonstrate that adiabatic quantum computing (AQC) not only outperforms\nclassical algorithms like genetic algorithms and reinforcement learning in\nterms of time efficiency but also excels at identifying global optima.", "AI": {"tldr": "The paper explores using adiabatic quantum computing (AQC) for optimizing deep neural networks (DNNs) through pruning-quantization, reformulating it as a QUBO problem. AQC outperforms classical methods in efficiency and finding global optima.", "motivation": "Quantum optimization is promising for solving complex problems, but applying it to DNN optimization requires reformulation. The study aims to bridge this gap by adapting AQC for DNN compression.", "method": "The authors reformulate DNN pruning-quantization as a quadratic unconstrained binary optimization (QUBO) problem, compatible with quantum annealing devices. They assess the solution space using commercial quantum devices.", "result": "AQC effectively compresses DNN models, outperforming classical algorithms (e.g., genetic algorithms, reinforcement learning) in time efficiency and identifying global optima.", "conclusion": "AQC is a viable and efficient method for DNN optimization, demonstrating superior performance over classical approaches in model compression tasks."}}
{"id": "2505.16710", "pdf": "https://arxiv.org/pdf/2505.16710", "abs": "https://arxiv.org/abs/2505.16710", "authors": ["Wenhao Li", "Yuxin Zhang", "Gen Luo", "Daohai Yu", "Rongrong Ji"], "title": "Training Long-Context LLMs Efficiently via Chunk-wise Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While long-context large language models (LLMs) exhibit remarkable document\nprocessing capabilities, their prohibitively high training costs often hinder\ncustomized applications. To mitigate this issue, we propose \\textit{Sequential\nChunk-wise Optimization} (SeCO), a memory-efficient training paradigm that\npartitions lengthy inputs into manageable chunks. Each chunk independently\nconstructs its computational graph and performs localized backpropagation,\nensuring that only one chunk's forward activations are stored in memory.\nBuilding on SeCO, we further introduce \\textit{Sparse Chunk-wise Optimization}\n(SpaCO), which reduces computational overhead by selectively propagating\ngradients to specific chunks and incorporates a carefully designed compensation\nfactor to ensure unbiased gradient estimation. SpaCO decouples the\ncomputational cost of backpropagation from the context length, enabling\ntraining time to gradually converge to inference time as sequences become\nlonger. Implemented as lightweight training wrappers, both SeCO and SpaCO offer\nsubstantial practical benefits. For example, when fine-tuning an 8B model with\nLoRA on a single RTX 3090 GPU, SeCO expands maximum sequence length from 1K to\n16K tokens, while SpaCO demonstrates accelerated training speed -- achieving up\nto 3x faster than SeCO under the same experimental setup. These innovations\nprovide new insights into optimizing long-context models, making them more\naccessible for practical applications. We have open-sourced the code at\n\\href{https://github.com/wenhaoli-xmu/seco}{here}.", "AI": {"tldr": "SeCO and SpaCO are memory-efficient training methods for long-context LLMs, enabling longer sequences and faster training by chunking inputs and optimizing gradient propagation.", "motivation": "High training costs of long-context LLMs hinder customization; SeCO and SpaCO address this by reducing memory and computational overhead.", "method": "SeCO partitions inputs into chunks with localized backpropagation; SpaCO adds selective gradient propagation and compensation for efficiency.", "result": "SeCO extends sequence length to 16K tokens; SpaCO speeds up training by 3x compared to SeCO.", "conclusion": "SeCO and SpaCO make long-context LLMs more practical, with open-sourced code for broader adoption."}}
{"id": "2505.16594", "pdf": "https://arxiv.org/pdf/2505.16594", "abs": "https://arxiv.org/abs/2505.16594", "authors": ["Vignesh Gopinathan", "Urs Zimmermann", "Michael Arnold", "Matthias Rottmann"], "title": "Temporal Object Captioning for Street Scene Videos from LiDAR Tracks", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Video captioning models have seen notable advancements in recent years,\nespecially with regard to their ability to capture temporal information. While\nmany research efforts have focused on architectural advancements, such as\ntemporal attention mechanisms, there remains a notable gap in understanding how\nmodels capture and utilize temporal semantics for effective temporal feature\nextraction, especially in the context of Advanced Driver Assistance Systems. We\npropose an automated LiDAR-based captioning procedure that focuses on the\ntemporal dynamics of traffic participants. Our approach uses a rule-based\nsystem to extract essential details such as lane position and relative motion\nfrom object tracks, followed by a template-based caption generation. Our\nfindings show that training SwinBERT, a video captioning model, using only\nfront camera images and supervised with our template-based captions,\nspecifically designed to encapsulate fine-grained temporal behavior, leads to\nimproved temporal understanding consistently across three datasets. In\nconclusion, our results clearly demonstrate that integrating LiDAR-based\ncaption supervision significantly enhances temporal understanding, effectively\naddressing and reducing the inherent visual/static biases prevalent in current\nstate-of-the-art model architectures.", "AI": {"tldr": "Proposed LiDAR-based captioning improves temporal understanding in video captioning models, reducing visual/static biases.", "motivation": "Address the gap in understanding how models capture temporal semantics, especially for Advanced Driver Assistance Systems.", "method": "Automated LiDAR-based captioning with rule-based extraction of lane position and motion, followed by template-based caption generation.", "result": "Training SwinBERT with template-based captions enhances temporal understanding across three datasets.", "conclusion": "LiDAR-based caption supervision significantly improves temporal understanding and reduces biases in models."}}
{"id": "2505.16570", "pdf": "https://arxiv.org/pdf/2505.16570", "abs": "https://arxiv.org/abs/2505.16570", "authors": ["Dongyang Fan", "Vinko Sabol\u010dec", "Martin Jaggi"], "title": "URLs Help, Topics Guide: Understanding Metadata Utility in LLM Training", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are commonly pretrained on vast corpora of text\nwithout utilizing contextual metadata such as source, quality, or topic,\nleading to a context-free learning paradigm. While recent studies suggest that\nadding metadata like URL information as context (i.e., auxiliary inputs not\nused in the loss calculation) can improve training efficiency and downstream\nperformance, they offer limited understanding of which types of metadata are\ntruly effective and under what conditions. In this work, we conduct a\nsystematic evaluation and find that not all metadata types contribute equally.\nOnly URL context speeds up training, whereas quality scores and topic/format\ndomain information offer no clear benefit. Furthermore, the improved downstream\nperformances of URL conditioning emerge only when longer prompts are used at\ninference time. In addition, we demonstrate that context-aware pretraining\nenables more controllable generation than context-free pretraining, in a\nclassifier-free guidance fashion. Although topic and format metadata do not\naccelerate training, they are effective for steering outputs, offering\nhuman-interpretable control over generation.", "AI": {"tldr": "URL metadata speeds up LLM training and improves downstream performance with longer prompts, while quality and topic metadata offer no training benefits but aid controllable generation.", "motivation": "To systematically evaluate the effectiveness of different metadata types (e.g., URL, quality, topic) in LLM pretraining, as prior work lacks clarity on their impact.", "method": "Conducted a systematic evaluation of metadata types (URL, quality scores, topic/format) during LLM pretraining, analyzing their effects on training efficiency and downstream performance.", "result": "URL context speeds up training and improves downstream performance with longer prompts. Quality and topic metadata do not aid training but enable controllable generation.", "conclusion": "URL metadata is uniquely beneficial for training efficiency, while topic and format metadata are useful for steering model outputs, providing interpretable control."}}
{"id": "2505.16362", "pdf": "https://arxiv.org/pdf/2505.16362", "abs": "https://arxiv.org/abs/2505.16362", "authors": ["El-ghazali Talbi"], "title": "Neuromorphic-based metaheuristics: A new generation of low power, low latency and small footprint optimization algorithms", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Neuromorphic computing (NC) introduces a novel algorithmic paradigm\nrepresenting a major shift from traditional digital computing of Von Neumann\narchitectures. NC emulates or simulates the neural dynamics of brains in the\nform of Spiking Neural Networks (SNNs). Much of the research in NC has\nconcentrated on machine learning applications and neuroscience simulations.\nThis paper investigates the modelling and implementation of optimization\nalgorithms and particularly metaheuristics using the NC paradigm as an\nalternative to Von Neumann architectures, leading to breakthroughs in solving\noptimization problems.\n  Neuromorphic-based metaheuristics (Nheuristics) are supposed to be\ncharacterized by low power, low latency and small footprint. Since NC systems\nare fundamentally different from conventional Von Neumann computers, several\nchallenges are posed to the design and implementation of Nheuristics. A\nguideline based on a classification and critical analysis is conducted on the\ndifferent families of metaheuristics and optimization problems they address. We\nalso discuss future directions that need to be addressed to expand both the\ndevelopment and application of Nheuristics.", "AI": {"tldr": "The paper explores neuromorphic computing (NC) for metaheuristic optimization, proposing 'Nheuristics' as low-power, efficient alternatives to traditional Von Neumann architectures.", "motivation": "To leverage NC's brain-like efficiency for optimization problems, overcoming limitations of conventional computing.", "method": "Classification and critical analysis of metaheuristics, addressing design challenges for NC-based optimization.", "result": "Identifies potential of Nheuristics for low-power, low-latency solutions but notes implementation challenges.", "conclusion": "Future research is needed to expand Nheuristics' development and applications."}}
{"id": "2505.16724", "pdf": "https://arxiv.org/pdf/2505.16724", "abs": "https://arxiv.org/abs/2505.16724", "authors": ["Konstantinos Barmpas", "Na Lee", "Yannis Panagakis", "Dimitrios A. Adamos", "Nikolaos Laskaris", "Stefanos Zafeiriou"], "title": "Advancing Brainwave Modeling with a Codebook-Based Foundation Model", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": null, "summary": "Recent advances in large-scale pre-trained Electroencephalogram (EEG) models\nhave shown great promise, driving progress in Brain-Computer Interfaces (BCIs)\nand healthcare applications. However, despite their success, many existing\npre-trained models have struggled to fully capture the rich information content\nof neural oscillations, a limitation that fundamentally constrains their\nperformance and generalizability across diverse BCI tasks. This limitation is\nfrequently rooted in suboptimal architectural design choices which constrain\ntheir representational capacity. In this work, we introduce LaBraM++, an\nenhanced Large Brainwave Foundation Model (LBM) that incorporates principled\nimprovements grounded in robust signal processing foundations. LaBraM++\ndemonstrates substantial gains across a variety of tasks, consistently\noutperforming its originally-based architecture and achieving competitive\nresults when compared to other open-source LBMs. Its superior performance and\ntraining efficiency highlight its potential as a strong foundation for future\nadvancements in LBMs.", "AI": {"tldr": "LaBraM++ is an improved EEG pre-trained model that outperforms its predecessor and other models by better capturing neural oscillations, enhancing BCI and healthcare applications.", "motivation": "Existing EEG pre-trained models often fail to fully utilize neural oscillations, limiting their performance and generalizability in BCI tasks.", "method": "LaBraM++ introduces principled architectural improvements based on robust signal processing to enhance representational capacity.", "result": "LaBraM++ achieves superior performance and training efficiency, outperforming its predecessor and competing with other open-source models.", "conclusion": "LaBraM++ is a promising foundation for future advancements in large-scale EEG models."}}
{"id": "2505.16599", "pdf": "https://arxiv.org/pdf/2505.16599", "abs": "https://arxiv.org/abs/2505.16599", "authors": ["Yao Huang", "Si-Yuan Cao", "Yaqing Ding", "Hao Yin", "Shibin Xie", "Shuting Wang", "Zhijun Fang", "Jiachun Wang", "Shen Cai", "Junchi Yan", "Shuhan Shen"], "title": "Decoupled Geometric Parameterization and its Application in Deep Homography Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Planar homography, with eight degrees of freedom (DOFs), is fundamental in\nnumerous computer vision tasks. While the positional offsets of four corners\nare widely adopted (especially in neural network predictions), this\nparameterization lacks geometric interpretability and typically requires\nsolving a linear system to compute the homography matrix. This paper presents a\nnovel geometric parameterization of homographies, leveraging the\nsimilarity-kernel-similarity (SKS) decomposition for projective\ntransformations. Two independent sets of four geometric parameters are\ndecoupled: one for a similarity transformation and the other for the kernel\ntransformation. Additionally, the geometric interpretation linearly relating\nthe four kernel transformation parameters to angular offsets is derived. Our\nproposed parameterization allows for direct homography estimation through\nmatrix multiplication, eliminating the need for solving a linear system, and\nachieves performance comparable to the four-corner positional offsets in deep\nhomography estimation.", "AI": {"tldr": "A novel geometric parameterization for planar homography using SKS decomposition, enabling direct homography estimation without solving linear systems.", "motivation": "Traditional homography parameterization lacks geometric interpretability and requires solving linear systems, prompting a need for a more intuitive and efficient method.", "method": "Proposes a similarity-kernel-similarity (SKS) decomposition to decouple geometric parameters into similarity and kernel transformations, with derived linear relations for angular offsets.", "result": "The method achieves comparable performance to traditional four-corner positional offsets in deep homography estimation while simplifying computation.", "conclusion": "The SKS-based parameterization offers a geometrically interpretable and computationally efficient alternative for homography estimation."}}
{"id": "2505.16576", "pdf": "https://arxiv.org/pdf/2505.16576", "abs": "https://arxiv.org/abs/2505.16576", "authors": ["Spencer Hong", "Meng Luo", "Xinyi Wan"], "title": "EMULATE: A Multi-Agent Framework for Determining the Veracity of Atomic Claims by Emulating Human Actions", "categories": ["cs.CL"], "comment": null, "summary": "Determining the veracity of atomic claims is an imperative component of many\nrecently proposed fact-checking systems. Many approaches tackle this problem by\nfirst retrieving evidence by querying a search engine and then performing\nclassification by providing the evidence set and atomic claim to a large\nlanguage model, but this process deviates from what a human would do in order\nto perform the task. Recent work attempted to address this issue by proposing\niterative evidence retrieval, allowing for evidence to be collected several\ntimes and only when necessary. Continuing along this line of research, we\npropose a novel claim verification system, called EMULATE, which is designed to\nbetter emulate human actions through the use of a multi-agent framework where\neach agent performs a small part of the larger task, such as ranking search\nresults according to predefined criteria or evaluating webpage content.\nExtensive experiments on several benchmarks show clear improvements over prior\nwork, demonstrating the efficacy of our new multi-agent framework.", "AI": {"tldr": "EMULATE is a multi-agent framework for claim verification that mimics human behavior, outperforming prior methods by iteratively retrieving and evaluating evidence.", "motivation": "Existing fact-checking systems deviate from human-like processes, prompting the need for a more human-emulative approach.", "method": "EMULATE uses a multi-agent framework where each agent handles specific tasks like ranking search results or evaluating webpage content, iteratively retrieving evidence.", "result": "Experiments show EMULATE outperforms prior work on multiple benchmarks.", "conclusion": "The multi-agent framework effectively emulates human fact-checking, improving claim verification accuracy."}}
{"id": "2505.16377", "pdf": "https://arxiv.org/pdf/2505.16377", "abs": "https://arxiv.org/abs/2505.16377", "authors": ["Yansong Qu", "Zilin Huang", "Zihao Sheng", "Jiancong Chen", "Sikai Chen", "Samuel Labi"], "title": "VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL)-based autonomous driving policy learning faces\ncritical limitations such as low sample efficiency and poor generalization; its\nreliance on online interactions and trial-and-error learning is especially\nunacceptable in safety-critical scenarios. Existing methods including safe RL\noften fail to capture the true semantic meaning of \"safety\" in complex driving\ncontexts, leading to either overly conservative driving behavior or constraint\nviolations. To address these challenges, we propose VL-SAFE, a world\nmodel-based safe RL framework with Vision-Language model\n(VLM)-as-safety-guidance paradigm, designed for offline safe policy learning.\nSpecifically, we construct offline datasets containing data collected by expert\nagents and labeled with safety scores derived from VLMs. A world model is\ntrained to generate imagined rollouts together with safety estimations,\nallowing the agent to perform safe planning without interacting with the real\nenvironment. Based on these imagined trajectories and safety evaluations,\nactor-critic learning is conducted under VLM-based safety guidance to optimize\nthe driving policy more safely and efficiently. Extensive evaluations\ndemonstrate that VL-SAFE achieves superior sample efficiency, generalization,\nsafety, and overall performance compared to existing baselines. To the best of\nour knowledge, this is the first work that introduces a VLM-guided world\nmodel-based approach for safe autonomous driving. The demo video and code can\nbe accessed at: https://ys-qu.github.io/vlsafe-website/", "AI": {"tldr": "VL-SAFE is a world model-based safe RL framework for autonomous driving, using Vision-Language models for safety guidance to improve efficiency and safety without real-world interactions.", "motivation": "Addresses limitations of RL in autonomous driving, such as low sample efficiency, poor generalization, and inadequate safety in complex contexts.", "method": "Uses offline datasets with safety scores from VLMs, trains a world model for imagined rollouts, and conducts actor-critic learning under VLM safety guidance.", "result": "VL-SAFE outperforms baselines in sample efficiency, generalization, safety, and overall performance.", "conclusion": "VL-SAFE is the first VLM-guided world model approach for safe autonomous driving, demonstrating significant improvements over existing methods."}}
{"id": "2505.16725", "pdf": "https://arxiv.org/pdf/2505.16725", "abs": "https://arxiv.org/abs/2505.16725", "authors": ["Phillip Mueller", "Jannik Wiese", "Sebastian Mueller", "Lars Mikelsons"], "title": "Masked Conditioning for Deep Generative Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Datasets in engineering domains are often small, sparsely labeled, and\ncontain numerical as well as categorical conditions. Additionally.\ncomputational resources are typically limited in practical applications which\nhinders the adoption of generative models for engineering tasks. We introduce a\nnovel masked-conditioning approach, that enables generative models to work with\nsparse, mixed-type data. We mask conditions during training to simulate sparse\nconditions at inference time. For this purpose, we explore the use of various\nsparsity schedules that show different strengths and weaknesses. In addition,\nwe introduce a flexible embedding that deals with categorical as well as\nnumerical conditions. We integrate our method into an efficient variational\nautoencoder as well as a latent diffusion model and demonstrate the\napplicability of our approach on two engineering-related datasets of 2D point\nclouds and images. Finally, we show that small models trained on limited data\ncan be coupled with large pretrained foundation models to improve generation\nquality while retaining the controllability induced by our conditioning scheme.", "AI": {"tldr": "A novel masked-conditioning approach for generative models to handle sparse, mixed-type data in engineering tasks, integrated into efficient VAE and latent diffusion models, and coupled with large pretrained models for improved quality.", "motivation": "Engineering datasets are often small, sparsely labeled, and mixed-type, with limited computational resources, hindering generative model adoption.", "method": "Masked-conditioning during training to simulate sparse conditions, flexible embeddings for mixed-type data, and integration into VAE and latent diffusion models.", "result": "Demonstrated applicability on 2D point clouds and images, with improved generation quality by coupling small models with large pretrained models.", "conclusion": "The approach enables generative models to work effectively with sparse, mixed-type data in resource-constrained engineering applications."}}
{"id": "2505.16602", "pdf": "https://arxiv.org/pdf/2505.16602", "abs": "https://arxiv.org/abs/2505.16602", "authors": ["Bohan Zhou", "Yi Zhan", "Zhongbin Zhang", "Zongqing Lu"], "title": "MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation", "categories": ["cs.CV"], "comment": null, "summary": "Egocentric hand-object motion generation is crucial for immersive AR/VR and\nrobotic imitation but remains challenging due to unstable viewpoints,\nself-occlusions, perspective distortion, and noisy ego-motion. Existing methods\nrely on predefined 3D object priors, limiting generalization to novel objects,\nwhich restricts their generalizability to novel objects. Meanwhile, recent\nmultimodal approaches suffer from ambiguous generation from abstract textual\ncues, intricate pipelines for modeling 3D hand-object correlation, and\ncompounding errors in open-loop prediction. We propose MEgoHand, a multimodal\nframework that synthesizes physically plausible hand-object interactions from\negocentric RGB, text, and initial hand pose. MEgoHand introduces a bi-level\narchitecture: a high-level \"cerebrum\" leverages a vision language model (VLM)\nto infer motion priors from visual-textual context and a monocular depth\nestimator for object-agnostic spatial reasoning, while a low-level DiT-based\nflow-matching policy generates fine-grained trajectories with temporal\northogonal filtering to enhance stability. To address dataset inconsistency, we\ndesign a dataset curation paradigm with an Inverse MANO Retargeting Network and\nVirtual RGB-D Renderer, curating a unified dataset of 3.35M RGB-D frames, 24K\ninteractions, and 1.2K objects. Extensive experiments across five in-domain and\ntwo cross-domain datasets demonstrate the effectiveness of MEgoHand, achieving\nsubstantial reductions in wrist translation error (86.9%) and joint rotation\nerror (34.1%), highlighting its capacity to accurately model fine-grained hand\njoint structures and generalize robustly across diverse scenarios.", "AI": {"tldr": "MEgoHand is a multimodal framework for generating realistic hand-object interactions from egocentric RGB, text, and initial hand pose, addressing challenges like unstable viewpoints and noisy ego-motion. It uses a bi-level architecture and a curated dataset to achieve superior performance.", "motivation": "The challenge of generating egocentric hand-object motion due to unstable viewpoints, self-occlusions, and noisy ego-motion, along with limitations of existing methods relying on predefined 3D priors or ambiguous textual cues.", "method": "MEgoHand employs a bi-level architecture: a high-level 'cerebrum' with a vision language model and monocular depth estimator, and a low-level DiT-based flow-matching policy. It also introduces a dataset curation paradigm for consistency.", "result": "MEgoHand reduces wrist translation error by 86.9% and joint rotation error by 34.1%, demonstrating robust generalization across diverse scenarios.", "conclusion": "MEgoHand effectively addresses the challenges of egocentric hand-object motion generation, offering a scalable and generalizable solution for AR/VR and robotic applications."}}
{"id": "2505.16582", "pdf": "https://arxiv.org/pdf/2505.16582", "abs": "https://arxiv.org/abs/2505.16582", "authors": ["Jianbiao Mei", "Tao Hu", "Daocheng Fu", "Licheng Wen", "Xuemeng Yang", "Rong Wu", "Pinlong Cai", "Xing Gao", "Yu Yang", "Chengjun Xie", "Botian Shi", "Yong Liu", "Yu Qiao"], "title": "O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "25 pages, 9 figures", "summary": "Large Language Models (LLMs), despite their advancements, are fundamentally\nlimited by their static parametric knowledge, hindering performance on tasks\nrequiring open-domain up-to-date information. While enabling LLMs to interact\nwith external knowledge environments is a promising solution, current efforts\nprimarily address closed-end problems. Open-ended questions, which\ncharacterized by lacking a standard answer or providing non-unique and diverse\nanswers, remain underexplored. To bridge this gap, we present O$^2$-Searcher, a\nnovel search agent leveraging reinforcement learning to effectively tackle both\nopen-ended and closed-ended questions in the open domain. O$^2$-Searcher\nleverages an efficient, locally simulated search environment for dynamic\nknowledge acquisition, effectively decoupling the external world knowledge from\nmodel's sophisticated reasoning processes. It employs a unified training\nmechanism with meticulously designed reward functions, enabling the agent to\nidentify problem types and adapt different answer generation strategies.\nFurthermore, to evaluate performance on complex open-ended tasks, we construct\nO$^2$-QA, a high-quality benchmark featuring 300 manually curated, multi-domain\nopen-ended questions with associated web page caches. Extensive experiments\nshow that O$^2$-Searcher, using only a 3B model, significantly surpasses\nleading LLM agents on O$^2$-QA. It also achieves SOTA results on various\nclosed-ended QA benchmarks against similarly-sized models, while performing on\npar with much larger ones.", "AI": {"tldr": "O\u00b2-Searcher, a reinforcement learning-based search agent, addresses the limitations of LLMs by dynamically acquiring knowledge for open- and closed-ended questions, outperforming larger models.", "motivation": "LLMs are limited by static knowledge and struggle with open-ended questions. O\u00b2-Searcher aims to bridge this gap by integrating dynamic knowledge acquisition.", "method": "Uses reinforcement learning in a locally simulated search environment, decoupling knowledge from reasoning, with unified training and adaptive strategies.", "result": "O\u00b2-Searcher outperforms leading LLM agents on open-ended tasks (O\u00b2-QA benchmark) and achieves SOTA on closed-ended benchmarks with a 3B model.", "conclusion": "O\u00b2-Searcher effectively tackles both open- and closed-ended questions, demonstrating superior performance with a compact model."}}
{"id": "2505.16379", "pdf": "https://arxiv.org/pdf/2505.16379", "abs": "https://arxiv.org/abs/2505.16379", "authors": ["Zhixun Li", "Bin Cao", "Rui Jiao", "Liang Wang", "Ding Wang", "Yang Liu", "Dingshuo Chen", "Jia Li", "Qiang Liu", "Yu Rong", "Liang Wang", "Tong-yi Zhang", "Jeffrey Xu Yu"], "title": "Materials Generation in the Era of Artificial Intelligence: A Comprehensive Survey", "categories": ["cond-mat.mtrl-sci", "cs.AI"], "comment": "Work in progress", "summary": "Materials are the foundation of modern society, underpinning advancements in\nenergy, electronics, healthcare, transportation, and infrastructure. The\nability to discover and design new materials with tailored properties is\ncritical to solving some of the most pressing global challenges. In recent\nyears, the growing availability of high-quality materials data combined with\nrapid advances in Artificial Intelligence (AI) has opened new opportunities for\naccelerating materials discovery. Data-driven generative models provide a\npowerful tool for materials design by directly create novel materials that\nsatisfy predefined property requirements. Despite the proliferation of related\nwork, there remains a notable lack of up-to-date and systematic surveys in this\narea. To fill this gap, this paper provides a comprehensive overview of recent\nprogress in AI-driven materials generation. We first organize various types of\nmaterials and illustrate multiple representations of crystalline materials. We\nthen provide a detailed summary and taxonomy of current AI-driven materials\ngeneration approaches. Furthermore, we discuss the common evaluation metrics\nand summarize open-source codes and benchmark datasets. Finally, we conclude\nwith potential future directions and challenges in this fast-growing field. The\nrelated sources can be found at\nhttps://github.com/ZhixunLEE/Awesome-AI-for-Materials-Generation.", "AI": {"tldr": "The paper surveys AI-driven materials generation, covering representations, methods, metrics, datasets, and future challenges.", "motivation": "To address the lack of systematic surveys on AI-driven materials discovery, leveraging data and AI for tailored material design.", "method": "Organizes materials types, reviews AI-driven generation approaches, and summarizes evaluation metrics, codes, and datasets.", "result": "Provides a comprehensive taxonomy and overview of current AI methods for materials generation.", "conclusion": "Highlights future directions and challenges in AI-driven materials discovery, with open-source resources provided."}}
{"id": "2505.16732", "pdf": "https://arxiv.org/pdf/2505.16732", "abs": "https://arxiv.org/abs/2505.16732", "authors": ["Hany Abdulsamad", "Sahel Iqbal", "Simo S\u00e4rkk\u00e4"], "title": "Sequential Monte Carlo for Policy Optimization in Continuous POMDPs", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Optimal decision-making under partial observability requires agents to\nbalance reducing uncertainty (exploration) against pursuing immediate\nobjectives (exploitation). In this paper, we introduce a novel policy\noptimization framework for continuous partially observable Markov decision\nprocesses (POMDPs) that explicitly addresses this challenge. Our method casts\npolicy learning as probabilistic inference in a non-Markovian Feynman--Kac\nmodel that inherently captures the value of information gathering by\nanticipating future observations, without requiring extrinsic exploration\nbonuses or handcrafted heuristics. To optimize policies under this model, we\ndevelop a nested sequential Monte Carlo~(SMC) algorithm that efficiently\nestimates a history-dependent policy gradient under samples from the optimal\ntrajectory distribution induced by the POMDP. We demonstrate the effectiveness\nof our algorithm across standard continuous POMDP benchmarks, where existing\nmethods struggle to act under uncertainty.", "AI": {"tldr": "A novel policy optimization framework for continuous POMDPs balances exploration and exploitation by modeling policy learning as probabilistic inference, using a nested SMC algorithm for efficient optimization.", "motivation": "Addressing the challenge of balancing exploration and exploitation in partially observable environments without relying on extrinsic bonuses or heuristics.", "method": "Introduces a probabilistic inference approach in a non-Markovian Feynman-Kac model and uses a nested SMC algorithm to estimate policy gradients.", "result": "Demonstrates effectiveness in continuous POMDP benchmarks where existing methods fail under uncertainty.", "conclusion": "The framework successfully integrates exploration and exploitation in POMDPs, outperforming traditional methods."}}
{"id": "2505.16624", "pdf": "https://arxiv.org/pdf/2505.16624", "abs": "https://arxiv.org/abs/2505.16624", "authors": ["Francesco Dalla Serra", "Patrick Schrempf", "Chaoyang Wang", "Zaiqiao Meng", "Fani Deligianni", "Alison Q. O'Neil"], "title": "Grounding Chest X-Ray Visual Question Answering with Generated Radiology Reports", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "We present a novel approach to Chest X-ray (CXR) Visual Question Answering\n(VQA), addressing both single-image image-difference questions. Single-image\nquestions focus on abnormalities within a specific CXR (\"What abnormalities are\nseen in image X?\"), while image-difference questions compare two longitudinal\nCXRs acquired at different time points (\"What are the differences between image\nX and Y?\"). We further explore how the integration of radiology reports can\nenhance the performance of VQA models. While previous approaches have\ndemonstrated the utility of radiology reports during the pre-training phase, we\nextend this idea by showing that the reports can also be leveraged as\nadditional input to improve the VQA model's predicted answers. First, we\npropose a unified method that handles both types of questions and\nauto-regressively generates the answers. For single-image questions, the model\nis provided with a single CXR. For image-difference questions, the model is\nprovided with two CXRs from the same patient, captured at different time\npoints, enabling the model to detect and describe temporal changes. Taking\ninspiration from 'Chain-of-Thought reasoning', we demonstrate that performance\non the CXR VQA task can be improved by grounding the answer generator module\nwith a radiology report predicted for the same CXR. In our approach, the VQA\nmodel is divided into two steps: i) Report Generation (RG) and ii) Answer\nGeneration (AG). Our results demonstrate that incorporating predicted radiology\nreports as evidence to the AG model enhances performance on both single-image\nand image-difference questions, achieving state-of-the-art results on the\nMedical-Diff-VQA dataset.", "AI": {"tldr": "A novel approach for Chest X-ray Visual Question Answering (VQA) integrates radiology reports to improve performance on single-image and image-difference questions, achieving state-of-the-art results.", "motivation": "To enhance VQA models for medical imaging by leveraging radiology reports as additional input, addressing both single-image and image-difference questions.", "method": "A unified method processes single or paired CXRs and uses auto-regressive answer generation. It incorporates predicted radiology reports in a two-step process: Report Generation (RG) and Answer Generation (AG).", "result": "Incorporating predicted radiology reports improves performance on both question types, achieving state-of-the-art results on the Medical-Diff-VQA dataset.", "conclusion": "The integration of radiology reports significantly enhances VQA model performance, demonstrating their utility beyond pre-training."}}
{"id": "2505.16591", "pdf": "https://arxiv.org/pdf/2505.16591", "abs": "https://arxiv.org/abs/2505.16591", "authors": ["Bowen Jiang", "Runchuan Zhu", "Jiang Wu", "Zinco Jiang", "Yifan He", "Junyuan Gao", "Jia Yu", "Rui Min", "Yinfan Wang", "Haote Yang", "Songyang Zhang", "Dahua Lin", "Lijun Wu", "Conghui He"], "title": "Evaluating Large Language Model with Knowledge Oriented Language Specific Simple Question Answering", "categories": ["cs.CL"], "comment": "Equal contribution: Bowen Jiang, Runchuan Zhu, Jiang Wu;\n  Corresponding author: Conghui He", "summary": "We introduce KoLasSimpleQA, the first benchmark evaluating the multilingual\nfactual ability of Large Language Models (LLMs). Inspired by existing research,\nwe created the question set with features such as single knowledge point\ncoverage, absolute objectivity, unique answers, and temporal stability. These\nquestions enable efficient evaluation using the LLM-as-judge paradigm, testing\nboth the LLMs' factual memory and self-awareness (\"know what they don't know\").\nKoLasSimpleQA expands existing research in two key dimensions: (1) Breadth\n(Multilingual Coverage): It includes 9 languages, supporting global\napplicability evaluation. (2) Depth (Dual Domain Design): It covers both the\ngeneral domain (global facts) and the language-specific domain (such as\nhistory, culture, and regional traditions) for a comprehensive assessment of\nmultilingual capabilities. We evaluated mainstream LLMs, including traditional\nLLM and emerging Large Reasoning Models. Results show significant performance\ndifferences between the two domains, particularly in performance metrics,\nranking, calibration, and robustness. This highlights the need for targeted\nevaluation and optimization in multilingual contexts. We hope KoLasSimpleQA\nwill help the research community better identify LLM capability boundaries in\nmultilingual contexts and provide guidance for model optimization. We will\nrelease KoLasSimpleQA at https://github.com/opendatalab/KoLasSimpleQA .", "AI": {"tldr": "KoLasSimpleQA is a multilingual benchmark for evaluating LLMs' factual abilities, covering 9 languages and dual domains (general and language-specific). It reveals performance gaps and aims to guide model optimization.", "motivation": "To address the lack of a comprehensive multilingual benchmark for evaluating LLMs' factual memory and self-awareness.", "method": "Created a question set with features like single knowledge point coverage, objectivity, unique answers, and temporal stability. Evaluated mainstream LLMs using the LLM-as-judge paradigm.", "result": "Significant performance differences between general and language-specific domains, highlighting gaps in multilingual capabilities.", "conclusion": "KoLasSimpleQA aids in identifying LLM boundaries and optimizing models for multilingual contexts. The benchmark will be publicly released."}}
{"id": "2505.16394", "pdf": "https://arxiv.org/pdf/2505.16394", "abs": "https://arxiv.org/abs/2505.16394", "authors": ["Zhenjie Yang", "Xiaosong Jia", "Qifeng Li", "Xue Yang", "Maoqing Yao", "Junchi Yan"], "title": "Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Reinforcement Learning (RL) can mitigate the causal confusion and\ndistribution shift inherent to imitation learning (IL). However, applying RL to\nend-to-end autonomous driving (E2E-AD) remains an open problem for its training\ndifficulty, and IL is still the mainstream paradigm in both academia and\nindustry. Recently Model-based Reinforcement Learning (MBRL) have demonstrated\npromising results in neural planning; however, these methods typically require\nprivileged information as input rather than raw sensor data. We fill this gap\nby designing Raw2Drive, a dual-stream MBRL approach. Initially, we efficiently\ntrain an auxiliary privileged world model paired with a neural planner that\nuses privileged information as input. Subsequently, we introduce a raw sensor\nworld model trained via our proposed Guidance Mechanism, which ensures\nconsistency between the raw sensor world model and the privileged world model\nduring rollouts. Finally, the raw sensor world model combines the prior\nknowledge embedded in the heads of the privileged world model to effectively\nguide the training of the raw sensor policy. Raw2Drive is so far the only RL\nbased end-to-end method on CARLA Leaderboard 2.0, and Bench2Drive and it\nachieves state-of-the-art performance.", "AI": {"tldr": "Raw2Drive is a dual-stream MBRL method for E2E-AD, combining privileged and raw sensor data to achieve state-of-the-art performance.", "motivation": "Address the gap in applying RL to E2E-AD by leveraging MBRL to handle raw sensor data, overcoming training difficulties and outperforming IL.", "method": "Uses a dual-stream approach: trains a privileged world model and a raw sensor world model with a Guidance Mechanism for consistency. Combines prior knowledge from the privileged model to train the raw sensor policy.", "result": "Achieves state-of-the-art performance on CARLA Leaderboard 2.0 and Bench2Drive.", "conclusion": "Raw2Drive successfully bridges the gap in RL-based E2E-AD, demonstrating superior performance over IL and other methods."}}
{"id": "2505.16733", "pdf": "https://arxiv.org/pdf/2505.16733", "abs": "https://arxiv.org/abs/2505.16733", "authors": ["Ziwei Luo", "Fredrik K. Gustafsson", "Jens Sj\u00f6lund", "Thomas B. Sch\u00f6n"], "title": "Forward-only Diffusion Probabilistic Models", "categories": ["cs.LG"], "comment": "Project page: https://algolzw.github.io/fod", "summary": "This work presents a forward-only diffusion (FoD) approach for generative\nmodelling. In contrast to traditional diffusion models that rely on a coupled\nforward-backward diffusion scheme, FoD directly learns data generation through\na single forward diffusion process, yielding a simple yet efficient generative\nframework. The core of FoD is a state-dependent linear stochastic differential\nequation that involves a mean-reverting term in both the drift and diffusion\nfunctions. This mean-reversion property guarantees the convergence to clean\ndata, naturally simulating a stochastic interpolation between source and target\ndistributions. More importantly, FoD is analytically tractable and is trained\nusing a simple stochastic flow matching objective, enabling a few-step\nnon-Markov chain sampling during inference. The proposed FoD model, despite its\nsimplicity, achieves competitive performance on various image-conditioned\n(e.g., image restoration) and unconditional generation tasks, demonstrating its\neffectiveness in generative modelling. Our code is available at\nhttps://github.com/Algolzw/FoD.", "AI": {"tldr": "FoD introduces a forward-only diffusion approach for generative modeling, simplifying the process by using a single forward diffusion and achieving competitive performance.", "motivation": "Traditional diffusion models rely on complex forward-backward schemes; FoD aims to simplify this with a single forward process while maintaining effectiveness.", "method": "FoD uses a state-dependent linear stochastic differential equation with mean-reverting terms, trained via stochastic flow matching for efficient sampling.", "result": "FoD performs competitively in image-conditioned and unconditional generation tasks.", "conclusion": "FoD offers a simpler, efficient, and effective alternative to traditional diffusion models."}}
{"id": "2505.16625", "pdf": "https://arxiv.org/pdf/2505.16625", "abs": "https://arxiv.org/abs/2505.16625", "authors": ["Luyang Cao", "Jianwei Li", "Yinghuan Shi"], "title": "Background Matters: A Cross-view Bidirectional Modeling Framework for Semi-supervised Medical Image Segmentation", "categories": ["cs.CV"], "comment": "Accepted by IEEE Transactions on Image Processing", "summary": "Semi-supervised medical image segmentation (SSMIS) leverages unlabeled data\nto reduce reliance on manually annotated images. However, current SOTA\napproaches predominantly focus on foreground-oriented modeling (i.e.,\nsegmenting only the foreground region) and have largely overlooked the\npotential benefits of explicitly modeling the background region. Our study\ntheoretically and empirically demonstrates that highly certain predictions in\nbackground modeling enhance the confidence of corresponding foreground\nmodeling. Building on this insight, we propose the Cross-view Bidirectional\nModeling (CVBM) framework, which introduces a novel perspective by\nincorporating background modeling to improve foreground modeling performance.\nWithin CVBM, background modeling serves as an auxiliary perspective, providing\ncomplementary supervisory signals to enhance the confidence of the foreground\nmodel. Additionally, CVBM introduces an innovative bidirectional consistency\nmechanism, which ensures mutual alignment between foreground predictions and\nbackground-guided predictions. Extensive experiments demonstrate that our\napproach achieves SOTA performance on the LA, Pancreas, ACDC, and HRF datasets.\nNotably, on the Pancreas dataset, CVBM outperforms fully supervised methods\n(i.e., DSC: 84.57% vs. 83.89%) while utilizing only 20% of the labeled data.\nOur code is publicly available at https://github.com/caoluyang0830/CVBM.git.", "AI": {"tldr": "CVBM improves semi-supervised medical image segmentation by incorporating background modeling, enhancing foreground confidence, and achieving SOTA results with limited labeled data.", "motivation": "Current SSMIS methods focus on foreground modeling, neglecting background modeling's potential benefits. This study shows background modeling can improve foreground confidence.", "method": "Proposes Cross-view Bidirectional Modeling (CVBM), integrating background modeling as an auxiliary perspective and introducing a bidirectional consistency mechanism.", "result": "Achieves SOTA performance on LA, Pancreas, ACDC, and HRF datasets, outperforming fully supervised methods on Pancreas with 20% labeled data (DSC: 84.57% vs. 83.89%).", "conclusion": "CVBM demonstrates the value of background modeling in SSMIS, offering a novel framework for improved segmentation with limited annotations."}}
{"id": "2505.16610", "pdf": "https://arxiv.org/pdf/2505.16610", "abs": "https://arxiv.org/abs/2505.16610", "authors": ["Jing Ye", "Lu Xiang", "Yaping Zhang", "Chengqing Zong"], "title": "From Generic Empathy to Personalized Emotional Support: A Self-Evolution Framework for User Preference Alignment", "categories": ["cs.CL"], "comment": "27 pages", "summary": "Effective emotional support hinges on understanding users' emotions and needs\nto provide meaningful comfort during multi-turn interactions. Large Language\nModels (LLMs) show great potential for expressing empathy; however, they often\ndeliver generic and one-size-fits-all responses that fail to address users'\nspecific needs. To tackle this issue, we propose a self-evolution framework\ndesigned to help LLMs improve their responses to better align with users'\nimplicit preferences concerning user profiles (personalities), emotional\nstates, and specific situations. Our framework consists of two distinct phases:\n\\textit{(1)} \\textit{Emotional Support Experience Acquisition}, where LLMs are\nfine-tuned on limited emotional support conversation data to provide basic\nsupport, and \\textit{(2)} \\textit{Self-Improvement for Personalized Emotional\nSupport}, where LLMs leverage self-reflection and self-refinement to generate\npersonalized responses. Through iterative direct preference optimization\nbetween the pre- and post-refined responses, our model generates responses that\nreflect a better understanding of the user's implicit preferences. Extensive\nexperiments and evaluations demonstrate that our method significantly enhances\nthe model's performance in emotional support, reducing unhelpful responses and\nminimizing discrepancies between user preferences and model outputs.", "AI": {"tldr": "A self-evolution framework for LLMs improves emotional support by aligning responses with users' implicit preferences through iterative refinement.", "motivation": "Generic LLM responses fail to address users' specific emotional needs, necessitating a personalized approach.", "method": "Two-phase framework: (1) fine-tuning on emotional support data, (2) self-improvement via self-reflection and refinement.", "result": "Enhanced performance in emotional support, fewer unhelpful responses, and better alignment with user preferences.", "conclusion": "The framework effectively personalizes LLM responses for emotional support, improving user satisfaction."}}
{"id": "2505.16734", "pdf": "https://arxiv.org/pdf/2505.16734", "abs": "https://arxiv.org/abs/2505.16734", "authors": ["Bang You", "Puze Liu", "Huaping Liu", "Jan Peters", "Oleg Arenz"], "title": "Maximum Total Correlation Reinforcement Learning", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Simplicity is a powerful inductive bias. In reinforcement learning,\nregularization is used for simpler policies, data augmentation for simpler\nrepresentations, and sparse reward functions for simpler objectives, all that,\nwith the underlying motivation to increase generalizability and robustness by\nfocusing on the essentials. Supplementary to these techniques, we investigate\nhow to promote simple behavior throughout the episode. To that end, we\nintroduce a modification of the reinforcement learning problem that\nadditionally maximizes the total correlation within the induced trajectories.\nWe propose a practical algorithm that optimizes all models, including policy\nand state representation, based on a lower-bound approximation. In simulated\nrobot environments, our method naturally generates policies that induce\nperiodic and compressible trajectories, and that exhibit superior robustness to\nnoise and changes in dynamics compared to baseline methods, while also\nimproving performance in the original tasks.", "AI": {"tldr": "The paper explores promoting simple behavior in reinforcement learning by maximizing total correlation in trajectories, leading to more robust and generalizable policies.", "motivation": "To enhance generalizability and robustness by focusing on simplicity in behavior throughout the episode, supplementing existing techniques like regularization and sparse rewards.", "method": "Introduces a modified RL problem maximizing total correlation in trajectories, with a practical algorithm optimizing policies and state representations via a lower-bound approximation.", "result": "In simulated robot environments, the method produces periodic, compressible trajectories, improving robustness to noise and dynamics changes while enhancing task performance.", "conclusion": "Maximizing total correlation in RL trajectories effectively promotes simplicity, leading to more robust and performant policies."}}
{"id": "2505.16630", "pdf": "https://arxiv.org/pdf/2505.16630", "abs": "https://arxiv.org/abs/2505.16630", "authors": ["Sushant Gautam", "Cise Midoglu", "Vajira Thambawita", "Michael A. Riegler", "P\u00e5l Halvorsen", "Mubarak Shah"], "title": "SoccerChat: Integrating Multimodal Data for Enhanced Soccer Game Understanding", "categories": ["cs.CV", "cs.AI", "68T45, 68T50", "I.2.10; I.2.7; H.5.2"], "comment": null, "summary": "The integration of artificial intelligence in sports analytics has\ntransformed soccer video understanding, enabling real-time, automated insights\ninto complex game dynamics. Traditional approaches rely on isolated data\nstreams, limiting their effectiveness in capturing the full context of a match.\nTo address this, we introduce SoccerChat, a multimodal conversational AI\nframework that integrates visual and textual data for enhanced soccer video\ncomprehension. Leveraging the extensive SoccerNet dataset, enriched with jersey\ncolor annotations and automatic speech recognition (ASR) transcripts,\nSoccerChat is fine-tuned on a structured video instruction dataset to\nfacilitate accurate game understanding, event classification, and referee\ndecision making. We benchmark SoccerChat on action classification and referee\ndecision-making tasks, demonstrating its performance in general soccer event\ncomprehension while maintaining competitive accuracy in referee decision\nmaking. Our findings highlight the importance of multimodal integration in\nadvancing soccer analytics, paving the way for more interactive and explainable\nAI-driven sports analysis. https://github.com/simula/SoccerChat", "AI": {"tldr": "SoccerChat is a multimodal AI framework for soccer video analysis, integrating visual and textual data to improve game understanding and referee decisions.", "motivation": "Traditional soccer analytics methods lack context due to isolated data streams. SoccerChat aims to enhance comprehension by combining multimodal data.", "method": "SoccerChat uses the SoccerNet dataset with jersey color annotations and ASR transcripts, fine-tuned on a structured video instruction dataset for tasks like action classification and referee decision making.", "result": "SoccerChat performs well in general soccer event comprehension and maintains competitive accuracy in referee decision making.", "conclusion": "Multimodal integration is crucial for advancing soccer analytics, enabling more interactive and explainable AI-driven analysis."}}
{"id": "2505.16612", "pdf": "https://arxiv.org/pdf/2505.16612", "abs": "https://arxiv.org/abs/2505.16612", "authors": ["Daniel Scalena", "Gabriele Sarti", "Arianna Bisazza", "Elisabetta Fersini", "Malvina Nissim"], "title": "Steering Large Language Models for Machine Translation Personalization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "High-quality machine translation systems based on large language models\n(LLMs) have simplified the production of personalized translations reflecting\nspecific stylistic constraints. However, these systems still struggle in\nsettings where stylistic requirements are less explicit and might be harder to\nconvey via prompting. We explore various strategies for personalizing\nLLM-generated translations in low-resource settings, focusing on the\nchallenging literary translation domain. We explore prompting strategies and\ninference-time interventions for steering model generations towards a\npersonalized style, and propose a contrastive framework exploiting latent\nconcepts extracted from sparse autoencoders to identify salient personalization\nproperties. Our results show that steering achieves strong personalization\nwhile preserving translation quality. We further examine the impact of steering\non LLM representations, finding model layers with a relevant impact for\npersonalization are impacted similarly by multi-shot prompting and our steering\nmethod, suggesting similar mechanism at play.", "AI": {"tldr": "The paper explores strategies for personalizing LLM-generated translations in low-resource settings, focusing on literary translation. It introduces a contrastive framework and inference-time interventions to achieve strong personalization while maintaining translation quality.", "motivation": "Current LLM-based translation systems struggle with implicit stylistic requirements, especially in low-resource settings like literary translation.", "method": "The study uses prompting strategies, inference-time interventions, and a contrastive framework leveraging latent concepts from sparse autoencoders.", "result": "Steering methods achieve strong personalization without compromising translation quality. Multi-shot prompting and steering impact similar model layers, suggesting shared mechanisms.", "conclusion": "The proposed methods effectively personalize translations in challenging settings, with implications for understanding LLM behavior in stylistic adaptation."}}
{"id": "2505.16430", "pdf": "https://arxiv.org/pdf/2505.16430", "abs": "https://arxiv.org/abs/2505.16430", "authors": ["Martin Goodfellow", "Robbie Booth", "Andrew Fagan", "Alasdair Lambert"], "title": "AutoMCQ -- Automatically Generate Code Comprehension Questions using GenAI", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Students often do not fully understand the code they have written. This\nsometimes does not become evident until later in their education, which can\nmean it is harder to fix their incorrect knowledge or misunderstandings. In\naddition, being able to fully understand code is increasingly important in a\nworld where students have access to generative artificial intelligence (GenAI)\ntools, such as GitHub Copilot. One effective solution is to utilise code\ncomprehension questions, where a marker asks questions about a submission to\ngauge understanding, this can also have the side effect of helping to detect\nplagiarism. However, this approach is time consuming and can be difficult\nand/or expensive to scale. This paper introduces AutoMCQ, which uses GenAI for\nthe automatic generation of multiple-choice code comprehension questions. This\nis integrated with the CodeRunner automated assessment platform.", "AI": {"tldr": "AutoMCQ uses GenAI to automatically generate multiple-choice code comprehension questions, addressing scalability issues in assessing student understanding.", "motivation": "Students often misunderstand their own code, and traditional methods like manual code comprehension questions are time-consuming and hard to scale.", "method": "AutoMCQ leverages generative AI to automatically create multiple-choice questions about code submissions, integrated with CodeRunner.", "result": "The tool provides a scalable solution for assessing code comprehension and detecting plagiarism.", "conclusion": "AutoMCQ offers an efficient, automated approach to improving student code understanding and assessment scalability."}}
{"id": "2505.16736", "pdf": "https://arxiv.org/pdf/2505.16736", "abs": "https://arxiv.org/abs/2505.16736", "authors": ["Nicolas Keriven"], "title": "Backward Oversmoothing: why is it hard to train deep Graph Neural Networks?", "categories": ["cs.LG"], "comment": null, "summary": "Oversmoothing has long been identified as a major limitation of Graph Neural\nNetworks (GNNs): input node features are smoothed at each layer and converge to\na non-informative representation, if the weights of the GNN are sufficiently\nbounded. This assumption is crucial: if, on the contrary, the weights are\nsufficiently large, then oversmoothing may not happen. Theoretically, GNN could\nthus learn to not oversmooth. However it does not really happen in practice,\nwhich prompts us to examine oversmoothing from an optimization point of view.\nIn this paper, we analyze backward oversmoothing, that is, the notion that\nbackpropagated errors used to compute gradients are also subject to\noversmoothing from output to input. With non-linear activation functions, we\noutline the key role of the interaction between forward and backward smoothing.\nMoreover, we show that, due to backward oversmoothing, GNNs provably exhibit\nmany spurious stationary points: as soon as the last layer is trained, the\nwhole GNN is at a stationary point. As a result, we can exhibit regions where\ngradients are near-zero while the loss stays high. The proof relies on the fact\nthat, unlike forward oversmoothing, backward errors are subjected to a linear\noversmoothing even in the presence of non-linear activation function, such that\nthe average of the output error plays a key role. Additionally, we show that\nthis phenomenon is specific to deep GNNs, and exhibit counter-example\nMulti-Layer Perceptron. This paper is a step toward a more complete\ncomprehension of the optimization landscape specific to GNNs.", "AI": {"tldr": "The paper examines oversmoothing in GNNs from an optimization perspective, introducing backward oversmoothing and showing its role in creating spurious stationary points.", "motivation": "Oversmoothing in GNNs is a known issue, but practical avoidance is rare. The paper investigates why, focusing on backward oversmoothing and its interaction with forward smoothing.", "method": "Analyzes backward oversmoothing, its linear nature despite non-linear activations, and its impact on gradient computation. Theoretical proofs and counter-examples (e.g., MLPs) are used.", "result": "Backward oversmoothing leads to spurious stationary points, causing near-zero gradients while loss remains high. Deep GNNs are uniquely affected.", "conclusion": "The study advances understanding of GNN optimization challenges, highlighting backward oversmoothing as a key issue."}}
{"id": "2505.16633", "pdf": "https://arxiv.org/pdf/2505.16633", "abs": "https://arxiv.org/abs/2505.16633", "authors": ["Valentin Schmuker", "Alex Hoi Hang Chan", "Bastian Goldluecke", "Urs Waldmann"], "title": "Towards Texture- And Shape-Independent 3D Keypoint Estimation in Birds", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we present a texture-independent approach to estimate and\ntrack 3D joint positions of multiple pigeons. For this purpose, we build upon\nthe existing 3D-MuPPET framework, which estimates and tracks the 3D poses of up\nto 10 pigeons using a multi-view camera setup. We extend this framework by\nusing a segmentation method that generates silhouettes of the individuals,\nwhich are then used to estimate 2D keypoints. Following 3D-MuPPET, these 2D\nkeypoints are triangulated to infer 3D poses, and identities are matched in the\nfirst frame and tracked in 2D across subsequent frames. Our proposed\ntexture-independent approach achieves comparable accuracy to the original\ntexture-dependent 3D-MuPPET framework. Additionally, we explore our approach's\napplicability to other bird species. To do that, we infer the 2D joint\npositions of four bird species without additional fine-tuning the model trained\non pigeons and obtain preliminary promising results. Thus, we think that our\napproach serves as a solid foundation and inspires the development of more\nrobust and accurate texture-independent pose estimation frameworks.", "AI": {"tldr": "A texture-independent method for 3D joint position estimation in pigeons, extending 3D-MuPPET with segmentation and 2D keypoints, achieving comparable accuracy and showing promise for other bird species.", "motivation": "To develop a texture-independent approach for 3D pose estimation in pigeons, improving upon the texture-dependent 3D-MuPPET framework and exploring its applicability to other bird species.", "method": "Extends 3D-MuPPET by using segmentation to generate silhouettes, estimating 2D keypoints, triangulating for 3D poses, and tracking identities. Tested on pigeons and other bird species without fine-tuning.", "result": "Achieves comparable accuracy to the original 3D-MuPPET and shows promising results for other bird species.", "conclusion": "The approach provides a foundation for robust, texture-independent pose estimation frameworks and inspires further development."}}
{"id": "2505.16637", "pdf": "https://arxiv.org/pdf/2505.16637", "abs": "https://arxiv.org/abs/2505.16637", "authors": ["Wenjie Yang", "Mao Zheng", "Mingyang Song", "Zheng Li"], "title": "SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities in machine translation (MT). However, most advanced MT-specific\nLLMs heavily rely on external supervision signals during training, such as\nhuman-annotated reference data or trained reward models (RMs), which are often\nexpensive to obtain and challenging to scale. To overcome this limitation, we\npropose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for\nMT that is reference-free, fully online, and relies solely on self-judging\nrewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as\nthe backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs,\ne.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like\nQwen2.5-32B-Instruct in English $\\leftrightarrow$ Chinese translation tasks\nfrom WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR\nwith external supervision from COMET, our strongest model, SSR-X-Zero-7B,\nachieves state-of-the-art performance in English $\\leftrightarrow$ Chinese\ntranslation, surpassing all existing open-source models under 72B parameters\nand even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro.\nOur analysis highlights the effectiveness of the self-rewarding mechanism\ncompared to the external LLM-as-a-judge approach in MT and demonstrates its\ncomplementary benefits when combined with trained RMs. Our findings provide\nvaluable insight into the potential of self-improving RL methods. We have\npublicly released our code, data and models.", "AI": {"tldr": "A self-rewarding RL framework (SSR) for machine translation outperforms existing models without relying on expensive external supervision.", "motivation": "Overcoming the reliance on costly external supervision signals in advanced MT-specific LLMs.", "method": "Proposes a Simple Self-Rewarding (SSR) RL framework, reference-free and fully online, using self-judging rewards.", "result": "SSR-Zero-7B outperforms existing MT-specific and larger general LLMs; SSR-X-Zero-7B achieves state-of-the-art performance.", "conclusion": "Self-rewarding mechanisms are effective and complementary to external supervision, offering insights into self-improving RL methods."}}
{"id": "2505.16466", "pdf": "https://arxiv.org/pdf/2505.16466", "abs": "https://arxiv.org/abs/2505.16466", "authors": ["Meng Yan", "Cai Xu", "Xujing Wang", "Ziyu Guan", "Wei Zhao", "Yuhang Zhou"], "title": "Conf-GNNRec: Quantifying and Calibrating the Prediction Confidence for GNN-based Recommendation Methods", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Recommender systems based on graph neural networks perform well in tasks such\nas rating and ranking. However, in real-world recommendation scenarios, noise\nsuch as user misuse and malicious advertisement gradually accumulates through\nthe message propagation mechanism. Even if existing studies mitigate their\neffects by reducing the noise propagation weights, the severe sparsity of the\nrecommender system still leads to the low-weighted noisy neighbors being\nmistaken as meaningful information, and the prediction result obtained based on\nthe polluted nodes is not entirely trustworthy. Therefore, it is crucial to\nmeasure the confidence of the prediction results in this highly noisy\nframework. Furthermore, our evaluation of the existing representative GNN-based\nrecommendation shows that it suffers from overconfidence. Based on the above\nconsiderations, we propose a new method to quantify and calibrate the\nprediction confidence of GNN-based recommendations (Conf-GNNRec). Specifically,\nwe propose a rating calibration method that dynamically adjusts excessive\nratings to mitigate overconfidence based on user personalization. We also\ndesign a confidence loss function to reduce the overconfidence of negative\nsamples and effectively improve recommendation performance. Experiments on\npublic datasets demonstrate the validity of Conf-GNNRec in prediction\nconfidence and recommendation performance.", "AI": {"tldr": "The paper addresses noise and overconfidence in GNN-based recommender systems, proposing Conf-GNNRec to quantify and calibrate prediction confidence, improving recommendation performance.", "motivation": "Noise and overconfidence in GNN-based recommender systems degrade trustworthiness and performance, necessitating methods to measure and adjust prediction confidence.", "method": "Proposes Conf-GNNRec, featuring a dynamic rating calibration method and a confidence loss function to mitigate overconfidence and improve recommendations.", "result": "Experiments on public datasets show Conf-GNNRec effectively enhances prediction confidence and recommendation performance.", "conclusion": "Conf-GNNRec successfully addresses noise and overconfidence, offering a reliable solution for GNN-based recommender systems."}}
{"id": "2505.16737", "pdf": "https://arxiv.org/pdf/2505.16737", "abs": "https://arxiv.org/abs/2505.16737", "authors": ["Chengcan Wu", "Zhixin Zhang", "Zeming Wei", "Yihao Zhang", "Meng Sun"], "title": "Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "math.OC"], "comment": null, "summary": "The significant progress of large language models (LLMs) has led to\nremarkable achievements across numerous applications. However, their ability to\ngenerate harmful content has sparked substantial safety concerns. Despite the\nimplementation of safety alignment techniques during the pre-training phase,\nrecent research indicates that fine-tuning LLMs on adversarial or even benign\ndata can inadvertently compromise their safety. In this paper, we re-examine\nthe fundamental issue of why fine-tuning on non-harmful data still results in\nsafety degradation. We introduce a safety-aware probing (SAP) optimization\nframework designed to mitigate the safety risks of fine-tuning LLMs.\nSpecifically, SAP incorporates a safety-aware probe into the gradient\npropagation process, mitigating the model's risk of safety degradation by\nidentifying potential pitfalls in gradient directions, thereby enhancing\ntask-specific performance while successfully preserving model safety. Our\nextensive experimental results demonstrate that SAP effectively reduces\nharmfulness below the original fine-tuned model and achieves comparable test\nloss to standard fine-tuning methods. Our code is available at\nhttps://github.com/ChengcanWu/SAP.", "AI": {"tldr": "The paper addresses safety degradation in fine-tuned LLMs and proposes a safety-aware probing (SAP) framework to mitigate risks while maintaining performance.", "motivation": "Fine-tuning LLMs on benign data can still compromise safety, raising concerns despite pre-training safety alignment.", "method": "Introduces SAP, a framework that integrates safety-aware probes into gradient propagation to identify and mitigate safety risks during fine-tuning.", "result": "SAP reduces harmfulness below standard fine-tuning levels while achieving comparable task performance.", "conclusion": "SAP effectively preserves model safety during fine-tuning without sacrificing performance, offering a practical solution to safety degradation."}}
{"id": "2505.16643", "pdf": "https://arxiv.org/pdf/2505.16643", "abs": "https://arxiv.org/abs/2505.16643", "authors": ["Yiwei Sun", "Peiqi Jiang", "Chuanbin Liu", "Luohao Lin", "Zhiying Lu", "Hongtao Xie"], "title": "From Evaluation to Defense: Advancing Safety in Video Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "49 pages, 12 figures, 17 tables", "summary": "While the safety risks of image-based large language models have been\nextensively studied, their video-based counterparts (Video LLMs) remain\ncritically under-examined. To systematically study this problem, we introduce\n\\textbf{VideoSafetyBench (VSB-77k) - the first large-scale, culturally diverse\nbenchmark for Video LLM safety}, which compromises 77,646 video-query pairs and\nspans 19 principal risk categories across 10 language communities. \\textit{We\nreveal that integrating video modality degrades safety performance by an\naverage of 42.3\\%, exposing systemic risks in multimodal attack exploitation.}\nTo address this vulnerability, we propose \\textbf{VideoSafety-R1}, a dual-stage\nframework achieving unprecedented safety gains through two innovations: (1)\nAlarm Token-Guided Safety Fine-Tuning (AT-SFT) injects learnable alarm tokens\ninto visual and textual sequences, enabling explicit harm perception across\nmodalities via multitask objectives. (2) Then, Safety-Guided GRPO enhances\ndefensive reasoning through dynamic policy optimization with rule-based rewards\nderived from dual-modality verification. These components synergize to shift\nsafety alignment from passive harm recognition to active reasoning. The\nresulting framework achieves a 65.1\\% improvement on VSB-Eval-HH, and improves\nby 59.1\\%, 44.3\\%, and 15.0\\% on the image safety datasets MMBench, VLGuard,\nand FigStep, respectively. \\textit{Our codes are available in the supplementary\nmaterials.} \\textcolor{red}{Warning: This paper contains examples of harmful\nlanguage and videos, and reader discretion is recommended.}", "AI": {"tldr": "The paper introduces VideoSafetyBench (VSB-77k), a large-scale benchmark for Video LLM safety, and reveals a 42.3% safety degradation due to video modality. It proposes VideoSafety-R1, a dual-stage framework, achieving significant safety improvements.", "motivation": "To address the under-examined safety risks of video-based large language models (Video LLMs) and mitigate systemic vulnerabilities exposed by multimodal attacks.", "method": "Proposes VideoSafety-R1 with two innovations: (1) Alarm Token-Guided Safety Fine-Tuning (AT-SFT) for explicit harm perception, and (2) Safety-Guided GRPO for defensive reasoning.", "result": "Achieves a 65.1% improvement on VSB-Eval-HH and notable gains on other safety datasets (MMBench, VLGuard, FigStep).", "conclusion": "The framework shifts safety alignment from passive recognition to active reasoning, significantly enhancing Video LLM safety."}}
{"id": "2505.16648", "pdf": "https://arxiv.org/pdf/2505.16648", "abs": "https://arxiv.org/abs/2505.16648", "authors": ["Kexin Shang", "Chia-Hsuan Chang", "Christopher C. Yang"], "title": "Collaboration among Multiple Large Language Models for Medical Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to IEEE International Conference on Healthcare Informatics\n  2025", "summary": "Empowered by vast internal knowledge reservoir, the new generation of large\nlanguage models (LLMs) demonstrate untapped potential to tackle medical tasks.\nHowever, there is insufficient effort made towards summoning up a synergic\neffect from multiple LLMs' expertise and background. In this study, we propose\na multi-LLM collaboration framework tailored on a medical multiple-choice\nquestions dataset. Through post-hoc analysis on 3 pre-trained LLM participants,\nour framework is proved to boost all LLMs reasoning ability as well as\nalleviate their divergence among questions. We also measure an LLM's confidence\nwhen it confronts with adversary opinions from other LLMs and observe a\nconcurrence between LLM's confidence and prediction accuracy.", "AI": {"tldr": "A multi-LLM collaboration framework improves reasoning and reduces divergence in medical multiple-choice questions, with LLM confidence correlating with accuracy.", "motivation": "Leverage the untapped potential of multiple LLMs' expertise for medical tasks, addressing the lack of synergy in current approaches.", "method": "Propose a multi-LLM collaboration framework tested on a medical multiple-choice dataset, analyzing 3 pre-trained LLMs.", "result": "The framework enhances reasoning ability and reduces divergence among LLMs, with confidence levels aligning with prediction accuracy.", "conclusion": "Multi-LLM collaboration is effective for medical tasks, with confidence as a reliable indicator of accuracy."}}
{"id": "2505.16498", "pdf": "https://arxiv.org/pdf/2505.16498", "abs": "https://arxiv.org/abs/2505.16498", "authors": ["Augusto Luis Ballardini", "Miguel \u00c1ngel Sotelo"], "title": "Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models", "categories": ["cs.RO", "cs.AI"], "comment": "7 pages, 5 figures, submitted for IEEE conference", "summary": "Achieving full automation in self-driving vehicles remains a challenge,\nespecially in dynamic urban environments where navigation requires real-time\nadaptability. Existing systems struggle to handle navigation plans when faced\nwith unpredictable changes in road layouts, spontaneous detours, or missing map\ndata, due to their heavy reliance on predefined cartographic information. In\nthis work, we explore the use of Large Language Models to generate Answer Set\nProgramming rules by translating informal navigation instructions into\nstructured, logic-based reasoning. ASP provides non-monotonic reasoning,\nallowing autonomous vehicles to adapt to evolving scenarios without relying on\npredefined maps. We present an experimental evaluation in which LLMs generate\nASP constraints that encode real-world urban driving logic into a formal\nknowledge representation. By automating the translation of informal navigation\ninstructions into logical rules, our method improves adaptability and\nexplainability in autonomous navigation. Results show that LLM-driven ASP rule\ngeneration supports semantic-based decision-making, offering an explainable\nframework for dynamic navigation planning that aligns closely with how humans\ncommunicate navigational intent.", "AI": {"tldr": "The paper proposes using Large Language Models (LLMs) to translate informal navigation instructions into Answer Set Programming (ASP) rules for self-driving vehicles, enhancing adaptability and explainability in dynamic urban environments.", "motivation": "Existing self-driving systems rely heavily on predefined maps, struggling with unpredictable urban scenarios. This work aims to improve adaptability by leveraging LLMs for logic-based reasoning.", "method": "LLMs generate ASP rules from informal navigation instructions, enabling non-monotonic reasoning for dynamic navigation without predefined maps.", "result": "LLM-driven ASP rule generation supports semantic-based decision-making, providing an explainable framework for dynamic navigation planning.", "conclusion": "The method improves adaptability and explainability in autonomous navigation by aligning with human-like communication of navigational intent."}}
{"id": "2505.16741", "pdf": "https://arxiv.org/pdf/2505.16741", "abs": "https://arxiv.org/abs/2505.16741", "authors": ["Pilhwa Lee", "Shashank Gupta"], "title": "Meta-reinforcement learning with minimum attention", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "10 pages, 7 figures", "summary": "Minimum attention applies the least action principle in the changes of\ncontrol concerning state and time, first proposed by Brockett. The involved\nregularization is highly relevant in emulating biological control, such as\nmotor learning. We apply minimum attention in reinforcement learning (RL) as\npart of the rewards and investigate its connection to meta-learning and\nstabilization. Specifically, model-based meta-learning with minimum attention\nis explored in high-dimensional nonlinear dynamics. Ensemble-based model\nlearning and gradient-based meta-policy learning are alternately performed.\nEmpirically, we show that the minimum attention does show outperforming\ncompetence in comparison to the state-of-the-art algorithms in model-free and\nmodel-based RL, i.e., fast adaptation in few shots and variance reduction from\nthe perturbations of the model and environment. Furthermore, the minimum\nattention demonstrates the improvement in energy efficiency.", "AI": {"tldr": "Minimum attention in RL improves adaptation and efficiency, outperforming state-of-the-art methods.", "motivation": "Emulate biological control (e.g., motor learning) and enhance RL performance with minimal action principles.", "method": "Model-based meta-learning with minimum attention, combining ensemble-based model learning and gradient-based meta-policy learning.", "result": "Outperforms state-of-the-art RL algorithms in fast adaptation, variance reduction, and energy efficiency.", "conclusion": "Minimum attention is effective for RL, offering advantages in adaptation, stability, and efficiency."}}
{"id": "2505.16647", "pdf": "https://arxiv.org/pdf/2505.16647", "abs": "https://arxiv.org/abs/2505.16647", "authors": ["Sushant Gautam", "Michael A. Riegler", "P\u00e5l Halvorsen"], "title": "Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models", "categories": ["cs.CV", "cs.AI", "68T45, 68T07", "I.2.10; I.4.8"], "comment": "Accepted as a full paper at the 38th IEEE International Symposium on\n  Computer-Based Medical Systems (CBMS) 2025", "summary": "We investigate fine-tuning Vision-Language Models (VLMs) for multi-task\nmedical image understanding, focusing on detection, localization, and counting\nof findings in medical images. Our objective is to evaluate whether\ninstruction-tuned VLMs can simultaneously improve these tasks, with the goal of\nenhancing diagnostic accuracy and efficiency. Using MedMultiPoints, a\nmultimodal dataset with annotations from endoscopy (polyps and instruments) and\nmicroscopy (sperm cells), we reformulate each task into instruction-based\nprompts suitable for vision-language reasoning. We fine-tune\nQwen2.5-VL-7B-Instruct using Low-Rank Adaptation (LoRA) across multiple task\ncombinations. Results show that multi-task training improves robustness and\naccuracy. For example, it reduces the Count Mean Absolute Error (MAE) and\nincreases Matching Accuracy in the Counting + Pointing task. However,\ntrade-offs emerge, such as more zero-case point predictions, indicating reduced\nreliability in edge cases despite overall performance gains. Our study\nhighlights the potential of adapting general-purpose VLMs to specialized\nmedical tasks via prompt-driven fine-tuning. This approach mirrors clinical\nworkflows, where radiologists simultaneously localize, count, and describe\nfindings - demonstrating how VLMs can learn composite diagnostic reasoning\npatterns. The model produces interpretable, structured outputs, offering a\npromising step toward explainable and versatile medical AI. Code, model\nweights, and scripts will be released for reproducibility at\nhttps://github.com/simula/PointDetectCount.", "AI": {"tldr": "Fine-tuning Vision-Language Models (VLMs) for multi-task medical image understanding improves robustness and accuracy but reveals trade-offs in edge cases.", "motivation": "To enhance diagnostic accuracy and efficiency by adapting general-purpose VLMs to specialized medical tasks via prompt-driven fine-tuning.", "method": "Fine-tuned Qwen2.5-VL-7B-Instruct using LoRA on MedMultiPoints dataset, reformulating tasks into instruction-based prompts.", "result": "Multi-task training improves robustness and accuracy, e.g., reducing Count MAE and increasing Matching Accuracy, but with trade-offs like reduced reliability in edge cases.", "conclusion": "The approach shows promise for explainable and versatile medical AI, mirroring clinical workflows and producing interpretable outputs."}}
{"id": "2505.16660", "pdf": "https://arxiv.org/pdf/2505.16660", "abs": "https://arxiv.org/abs/2505.16660", "authors": ["Liu Chang", "Wang Dongbo", "Liu liu", "Zhao Zhixiao"], "title": "Can reasoning models comprehend mathematical problems in Chinese ancient texts? An empirical study based on data from Suanjing Shishu", "categories": ["cs.CL", "cs.AI"], "comment": "29pages, 7 figures", "summary": "This study addresses the challenges in intelligent processing of Chinese\nancient mathematical classics by constructing Guji_MATH, a benchmark for\nevaluating classical texts based on Suanjing Shishu. It systematically assesses\nthe mathematical problem-solving capabilities of mainstream reasoning models\nunder the unique linguistic constraints of classical Chinese. Through\nmachine-assisted annotation and manual verification, 538 mathematical problems\nwere extracted from 8 canonical texts, forming a structured dataset centered on\nthe \"Question-Answer-Solution\" framework, supplemented by problem types and\ndifficulty levels. Dual evaluation modes--closed-book (autonomous\nproblem-solving) and open-book (reproducing classical solution methods)--were\ndesigned to evaluate the performance of six reasoning models on ancient Chinese\nmathematical problems. Results indicate that reasoning models can partially\ncomprehend and solve these problems, yet their overall performance remains\ninferior to benchmarks on modern mathematical tasks. Enhancing models'\nclassical Chinese comprehension and cultural knowledge should be prioritized\nfor optimization. This study provides methodological support for mining\nmathematical knowledge from ancient texts and disseminating traditional\nculture, while offering new perspectives for evaluating cross-linguistic and\ncross-cultural capabilities of reasoning models.", "AI": {"tldr": "The paper introduces Guji_MATH, a benchmark for evaluating reasoning models on Chinese ancient mathematical texts, revealing their limitations in classical Chinese comprehension and suggesting improvements.", "motivation": "To address challenges in processing Chinese ancient mathematical classics and evaluate reasoning models' capabilities under classical Chinese linguistic constraints.", "method": "Constructed Guji_MATH benchmark with 538 problems from 8 texts, using machine-assisted annotation and manual verification. Evaluated six models via closed-book and open-book modes.", "result": "Models partially comprehend and solve problems but underperform compared to modern tasks. Classical Chinese comprehension and cultural knowledge need enhancement.", "conclusion": "The study aids in mining mathematical knowledge from ancient texts and evaluates cross-linguistic reasoning models, suggesting focus on classical Chinese comprehension for optimization."}}
{"id": "2505.16499", "pdf": "https://arxiv.org/pdf/2505.16499", "abs": "https://arxiv.org/abs/2505.16499", "authors": ["Roberto Morabito", "SiYoung Jang"], "title": "Smaller, Smarter, Closer: The Edge of Collaborative Generative AI", "categories": ["cs.DC", "cs.AI", "cs.NI"], "comment": "This paper is currently under review for publication in an IEEE\n  magazine. If accepted, the copyright will be transferred to IEEE", "summary": "The rapid adoption of generative AI (GenAI), particularly Large Language\nModels (LLMs), has exposed critical limitations of cloud-centric deployments,\nincluding latency, cost, and privacy concerns. Meanwhile, Small Language Models\n(SLMs) are emerging as viable alternatives for resource-constrained edge\nenvironments, though they often lack the capabilities of their larger\ncounterparts. This article explores the potential of collaborative inference\nsystems that leverage both edge and cloud resources to address these\nchallenges. By presenting distinct cooperation strategies alongside practical\ndesign principles and experimental insights, we offer actionable guidance for\ndeploying GenAI across the computing continuum.", "AI": {"tldr": "The paper explores collaborative inference systems combining edge and cloud resources to address limitations of cloud-centric GenAI deployments like latency, cost, and privacy.", "motivation": "The rapid adoption of GenAI and LLMs has revealed issues with cloud-centric approaches, while SLMs for edge environments lack capabilities.", "method": "The study presents cooperation strategies, design principles, and experimental insights for deploying GenAI across edge and cloud.", "result": "The paper provides actionable guidance for implementing collaborative inference systems.", "conclusion": "Collaborative systems leveraging edge and cloud resources can effectively address GenAI deployment challenges."}}
{"id": "2505.16748", "pdf": "https://arxiv.org/pdf/2505.16748", "abs": "https://arxiv.org/abs/2505.16748", "authors": ["Julien Laasri", "Marc Revol"], "title": "Revenue Optimization with Price-Sensitive and Interdependent Demand", "categories": ["cs.LG", "math.OC", "90C59", "G.1.6"], "comment": "21 pages, 17 figures, dated 2018, in French", "summary": "As Kalyan T. Talluri and Garrett J. Van Ryzin describe in their work [3],\nRevenue Management aims to maximize an organization's revenue by considering\nthree types of decision categories: structural, pricing, and quantity. In this\ndocument, our primary focus will be on decisions related to pricing and\nquantity for the sale of airline tickets on a direct flight over a certain\nnumber of time periods. More specifically, we will only focus on the\noptimization aspect of this problem. We will assume the demand data to be\ngiven, since Air France estimates it beforehand using real data. Similarly, we\nassume all price options to be predetermined by Air France's algorithms and\nverified by their analysts. Our objective will be to maximize the revenue of a\ndirect flight by choosing the prices for each product from the predefined set\nof options.\n  --\n  Comme d\\'ecrit par Kalyan T. Talluri et Garrett J. Van Ryzin dans leur\nouvrage [3], le Revenue Management consiste en la maximisation du revenu d'un\norganisme \\`a partir de trois types de cat\\'egories de d\\'ecision :\nstructurelles, prix et quantit\\'e. Dans ce document, nous nous int\\'eresserons\nprincipalement aux d\\'ecisions de type prix et quantit\\'e pour la vente de\nbillets d'avion sur un vol direct au cours d'un certain nombre de pas de temps.\nPlus pr\\'ecis\\'ement, nous nous situerons dans la partie optimisation du\nprobl\\`eme. Nous prendrons ainsi les donn\\'ees de demande comme acquises, car\nelles sont estim\\'ees au pr\\'ealable par Air France \\`a partir des donn\\'ees\nr\\'eelles. De m\\^eme, pour chaque produit que l'on cherchera \\`a vendre, on\nnous impose en amont les prix possibles que l'on a droit d'utiliser et qui se\nbasent sur des algorithmes d'Air France dont les r\\'esultats sont v\\'erifi\\'es\npar des analystes. Notre but sera alors de maximiser le revenu d'un vol direct\nen choisissant les prix de chaque produit parmi ceux impos\\'es.", "AI": {"tldr": "The paper focuses on optimizing airline ticket pricing and quantity decisions to maximize revenue, using predefined demand data and price options from Air France.", "motivation": "To address the challenge of revenue maximization in airline ticket sales by leveraging optimization techniques on given demand and pricing constraints.", "method": "Utilizes predefined demand data and price options, focusing on optimization to select the best pricing strategy for each product.", "result": "Aims to achieve maximum revenue for direct flights by optimizing price selections from predetermined options.", "conclusion": "The approach demonstrates how optimization can enhance revenue management in airline ticket sales under fixed constraints."}}
{"id": "2505.16652", "pdf": "https://arxiv.org/pdf/2505.16652", "abs": "https://arxiv.org/abs/2505.16652", "authors": ["Feilong Tang", "Chengzhi Liu", "Zhongxing Xu", "Ming Hu", "Zelin Peng", "Zhiwei Yang", "Jionglong Su", "Minquan Lin", "Yifan Peng", "Xuelian Cheng", "Imran Razzak", "Zongyuan Ge"], "title": "Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding", "categories": ["cs.CV", "cs.LG"], "comment": "Clarification note for the CVPR 2025 paper (FarSight). Prepared by a\n  subset of the original authors; remaining co-authors are acknowledged in the\n  text", "summary": "Recent advancements in multimodal large language models (MLLMs) have\nsignificantly improved performance in visual question answering. However, they\noften suffer from hallucinations. In this work, hallucinations are categorized\ninto two main types: initial hallucinations and snowball hallucinations. We\nargue that adequate contextual information can be extracted directly from the\ntoken interaction process. Inspired by causal inference in the decoding\nstrategy, we propose to leverage causal masks to establish information\npropagation between multimodal tokens. The hypothesis is that insufficient\ninteraction between those tokens may lead the model to rely on outlier tokens,\noverlooking dense and rich contextual cues. Therefore, we propose to intervene\nin the propagation process by tackling outlier tokens to enhance in-context\ninference. With this goal, we present FarSight, a versatile plug-and-play\ndecoding strategy to reduce attention interference from outlier tokens merely\nby optimizing the causal mask. The heart of our method is effective token\npropagation. We design an attention register structure within the upper\ntriangular matrix of the causal mask, dynamically allocating attention to\ncapture attention diverted to outlier tokens. Moreover, a positional awareness\nencoding method with a diminishing masking rate is proposed, allowing the model\nto attend to further preceding tokens, especially for video sequence tasks.\nWith extensive experiments, FarSight demonstrates significant\nhallucination-mitigating performance across different MLLMs on both image and\nvideo benchmarks, proving its effectiveness.", "AI": {"tldr": "FarSight is a plug-and-play decoding strategy using causal masks to reduce hallucinations in multimodal large language models by optimizing token interaction and attention allocation.", "motivation": "Addressing hallucinations in MLLMs, categorized as initial and snowball types, by improving token interaction and contextual inference.", "method": "Leverages causal masks and an attention register structure to dynamically allocate attention and tackle outlier tokens, with positional awareness encoding for video tasks.", "result": "FarSight significantly reduces hallucinations across MLLMs on image and video benchmarks.", "conclusion": "The proposed method effectively mitigates hallucinations by enhancing token propagation and attention management."}}
{"id": "2505.16661", "pdf": "https://arxiv.org/pdf/2505.16661", "abs": "https://arxiv.org/abs/2505.16661", "authors": ["Issey Sukeda", "Takuro Fujii", "Kosei Buma", "Shunsuke Sasaki", "Shinnosuke Ono"], "title": "A Japanese Language Model and Three New Evaluation Benchmarks for Pharmaceutical NLP", "categories": ["cs.CL"], "comment": "15 pages, 9 tables, 5 figures", "summary": "We present a Japanese domain-specific language model for the pharmaceutical\nfield, developed through continual pretraining on 2 billion Japanese\npharmaceutical tokens and 8 billion English biomedical tokens. To enable\nrigorous evaluation, we introduce three new benchmarks: YakugakuQA, based on\nnational pharmacist licensing exams; NayoseQA, which tests cross-lingual\nsynonym and terminology normalization; and SogoCheck, a novel task designed to\nassess consistency reasoning between paired statements. We evaluate our model\nagainst both open-source medical LLMs and commercial models, including GPT-4o.\nResults show that our domain-specific model outperforms existing open models\nand achieves competitive performance with commercial ones, particularly on\nterminology-heavy and knowledge-based tasks. Interestingly, even GPT-4o\nperforms poorly on SogoCheck, suggesting that cross-sentence consistency\nreasoning remains an open challenge. Our benchmark suite offers a broader\ndiagnostic lens for pharmaceutical NLP, covering factual recall, lexical\nvariation, and logical consistency. This work demonstrates the feasibility of\nbuilding practical, secure, and cost-effective language models for Japanese\ndomain-specific applications, and provides reusable evaluation resources for\nfuture research in pharmaceutical and healthcare NLP. Our model, codes, and\ndatasets are released at https://github.com/EQUES-Inc/pharma-LLM-eval.", "AI": {"tldr": "A Japanese pharmaceutical domain-specific language model, trained on 2B Japanese and 8B English biomedical tokens, outperforms open models and competes with commercial ones like GPT-4o, especially in terminology-heavy tasks. New benchmarks (YakugakuQA, NayoseQA, SogoCheck) evaluate factual recall, lexical variation, and logical consistency.", "motivation": "To address the lack of domain-specific language models for Japanese pharmaceutical applications and provide rigorous evaluation benchmarks.", "method": "Continual pretraining on Japanese pharmaceutical and English biomedical tokens, followed by evaluation using new benchmarks against open-source and commercial models.", "result": "The model outperforms open models and matches commercial ones, with GPT-4o struggling on cross-sentence consistency tasks.", "conclusion": "Demonstrates feasibility of practical, secure, and cost-effective Japanese domain-specific models, offering reusable evaluation resources for future research."}}
{"id": "2505.16508", "pdf": "https://arxiv.org/pdf/2505.16508", "abs": "https://arxiv.org/abs/2505.16508", "authors": ["SiYoung Jang", "Roberto Morabito"], "title": "Edge-First Language Model Inference: Models, Metrics, and Tradeoffs", "categories": ["cs.DC", "cs.AI", "cs.NI", "cs.PF"], "comment": "This paper has been accepted for publication and presentation at the\n  45th IEEE International Conference on Distributed Computing Systems (IEEE\n  ICDCS 2025). The copyright will be transferred to IEEE upon publication in\n  the conference proceedings", "summary": "The widespread adoption of Language Models (LMs) across industries is driving\ninterest in deploying these services across the computing continuum, from the\ncloud to the network edge. This shift aims to reduce costs, lower latency, and\nimprove reliability and privacy. Small Language Models (SLMs), enabled by\nadvances in model compression, are central to this shift, offering a path to\non-device inference on resource-constrained edge platforms. This work examines\nthe interplay between edge and cloud deployments, starting from detailed\nbenchmarking of SLM capabilities on single edge devices, and extending to\ndistributed edge clusters. We identify scenarios where edge inference offers\ncomparable performance with lower costs, and others where cloud fallback\nbecomes essential due to limits in scalability or model capacity. Rather than\nproposing a one-size-fits-all solution, we present platform-level comparisons\nand design insights for building efficient, adaptive LM inference systems\nacross heterogeneous environments.", "AI": {"tldr": "The paper explores deploying Small Language Models (SLMs) on edge devices versus cloud, highlighting cost, latency, and privacy benefits, while identifying scenarios for edge or cloud use.", "motivation": "To address the growing need for efficient, low-latency, and privacy-preserving LM deployments across cloud and edge environments.", "method": "Benchmarks SLM capabilities on single edge devices and distributed clusters, comparing edge and cloud deployments.", "result": "Identifies scenarios where edge inference is cost-effective and others requiring cloud fallback due to scalability or capacity limits.", "conclusion": "Advocates for adaptive LM inference systems tailored to heterogeneous environments, avoiding a one-size-fits-all approach."}}
{"id": "2505.16754", "pdf": "https://arxiv.org/pdf/2505.16754", "abs": "https://arxiv.org/abs/2505.16754", "authors": ["Hannah Markgraf", "Michael Eichelbeck", "Daria Cappey", "Selin Demirt\u00fcrk", "Yara Schattschneider", "Matthias Althoff"], "title": "PyTupli: A Scalable Infrastructure for Collaborative Offline Reinforcement Learning Projects", "categories": ["cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) has gained traction as a powerful\nparadigm for learning control policies from pre-collected data, eliminating the\nneed for costly or risky online interactions. While many open-source libraries\noffer robust implementations of offline RL algorithms, they all rely on\ndatasets composed of experience tuples consisting of state, action, next state,\nand reward. Managing, curating, and distributing such datasets requires\nsuitable infrastructure. Although static datasets exist for established\nbenchmark problems, no standardized or scalable solution supports developing\nand sharing datasets for novel or user-defined benchmarks. To address this gap,\nwe introduce PyTupli, a Python-based tool to streamline the creation, storage,\nand dissemination of benchmark environments and their corresponding tuple\ndatasets. PyTupli includes a lightweight client library with defined interfaces\nfor uploading and retrieving benchmarks and data. It supports fine-grained\nfiltering at both the episode and tuple level, allowing researchers to curate\nhigh-quality, task-specific datasets. A containerized server component enables\nproduction-ready deployment with authentication, access control, and automated\ncertificate provisioning for secure use. By addressing key barriers in dataset\ninfrastructure, PyTupli facilitates more collaborative, reproducible, and\nscalable offline RL research.", "AI": {"tldr": "PyTupli is a Python tool for creating, storing, and sharing offline RL datasets, addressing infrastructure gaps in the field.", "motivation": "Offline RL lacks standardized solutions for managing and sharing datasets, hindering research scalability and collaboration.", "method": "PyTupli provides a client library for dataset handling, fine-grained filtering, and a containerized server for secure deployment.", "result": "The tool enables efficient dataset curation, sharing, and secure access, supporting collaborative offline RL research.", "conclusion": "PyTupli enhances reproducibility and scalability in offline RL by streamlining dataset infrastructure."}}
{"id": "2505.16659", "pdf": "https://arxiv.org/pdf/2505.16659", "abs": "https://arxiv.org/abs/2505.16659", "authors": ["Kaiyu Guo", "Tan Pan", "Chen Jiang", "Zijian Wang", "Brian C. Lovell", "Limei Han", "Yuan Cheng", "Mahsa Baktashmotlagh"], "title": "SD-MAD: Sign-Driven Few-shot Multi-Anomaly Detection in Medical Images", "categories": ["cs.CV"], "comment": null, "summary": "Medical anomaly detection (AD) is crucial for early clinical intervention,\nyet it faces challenges due to limited access to high-quality medical imaging\ndata, caused by privacy concerns and data silos. Few-shot learning has emerged\nas a promising approach to alleviate these limitations by leveraging the\nlarge-scale prior knowledge embedded in vision-language models (VLMs). Recent\nadvancements in few-shot medical AD have treated normal and abnormal cases as a\none-class classification problem, often overlooking the distinction among\nmultiple anomaly categories. Thus, in this paper, we propose a framework\ntailored for few-shot medical anomaly detection in the scenario where the\nidentification of multiple anomaly categories is required. To capture the\ndetailed radiological signs of medical anomaly categories, our framework\nincorporates diverse textual descriptions for each category generated by a\nLarge-Language model, under the assumption that different anomalies in medical\nimages may share common radiological signs in each category. Specifically, we\nintroduce SD-MAD, a two-stage Sign-Driven few-shot Multi-Anomaly Detection\nframework: (i) Radiological signs are aligned with anomaly categories by\namplifying inter-anomaly discrepancy; (ii) Aligned signs are selected further\nto mitigate the effect of the under-fitting and uncertain-sample issue caused\nby limited medical data, employing an automatic sign selection strategy at\ninference. Moreover, we propose three protocols to comprehensively quantify the\nperformance of multi-anomaly detection. Extensive experiments illustrate the\neffectiveness of our method.", "AI": {"tldr": "A framework for few-shot medical anomaly detection (SD-MAD) is proposed, focusing on identifying multiple anomaly categories using radiological signs and textual descriptions from a Large-Language model.", "motivation": "Addressing the challenge of limited medical imaging data and the need to distinguish multiple anomaly categories in few-shot learning.", "method": "SD-MAD, a two-stage framework: (i) aligning radiological signs with anomaly categories, (ii) selecting signs to mitigate under-fitting and uncertain-sample issues.", "result": "The method effectively handles multi-anomaly detection, validated through extensive experiments.", "conclusion": "SD-MAD improves few-shot medical anomaly detection by leveraging textual descriptions and radiological signs, offering a robust solution for multi-category anomaly identification."}}
{"id": "2505.16694", "pdf": "https://arxiv.org/pdf/2505.16694", "abs": "https://arxiv.org/abs/2505.16694", "authors": ["Gouki Minegishi", "Hiroki Furuta", "Shohei Taniguchi", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Beyond Induction Heads: In-Context Meta Learning Induces Multi-Phase Circuit Emergence", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Transformer-based language models exhibit In-Context Learning (ICL), where\npredictions are made adaptively based on context. While prior work links\ninduction heads to ICL through a sudden jump in accuracy, this can only account\nfor ICL when the answer is included within the context. However, an important\nproperty of practical ICL in large language models is the ability to meta-learn\nhow to solve tasks from context, rather than just copying answers from context;\nhow such an ability is obtained during training is largely unexplored. In this\npaper, we experimentally clarify how such meta-learning ability is acquired by\nanalyzing the dynamics of the model's circuit during training. Specifically, we\nextend the copy task from previous research into an In-Context Meta Learning\nsetting, where models must infer a task from examples to answer queries.\nInterestingly, in this setting, we find that there are multiple phases in the\nprocess of acquiring such abilities, and that a unique circuit emerges in each\nphase, contrasting with the single-phases change in induction heads. The\nemergence of such circuits can be related to several phenomena known in large\nlanguage models, and our analysis lead to a deeper understanding of the source\nof the transformer's ICL ability.", "AI": {"tldr": "The paper explores how transformer-based models acquire meta-learning abilities during training, revealing multi-phase circuit dynamics distinct from simple induction heads.", "motivation": "To understand how large language models meta-learn tasks from context, beyond just copying answers, and clarify the training dynamics behind this ability.", "method": "Extends the copy task to an In-Context Meta Learning setting, analyzing model circuit dynamics during training.", "result": "Identifies multiple phases in acquiring meta-learning abilities, with unique circuits emerging in each phase, differing from induction heads.", "conclusion": "Provides deeper insights into the transformer's ICL ability, linking circuit emergence to known phenomena in large language models."}}
{"id": "2505.16530", "pdf": "https://arxiv.org/pdf/2505.16530", "abs": "https://arxiv.org/abs/2505.16530", "authors": ["Yuliang Yan", "Haochun Tang", "Shuo Yan", "Enyan Dai"], "title": "DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) are considered valuable Intellectual Properties\n(IP) for legitimate owners due to the enormous computational cost of training.\nIt is crucial to protect the IP of LLMs from malicious stealing or unauthorized\ndeployment. Despite existing efforts in watermarking and fingerprinting LLMs,\nthese methods either impact the text generation process or are limited in\nwhite-box access to the suspect model, making them impractical. Hence, we\npropose DuFFin, a novel $\\textbf{Du}$al-Level $\\textbf{Fin}$gerprinting\n$\\textbf{F}$ramework for black-box setting ownership verification. DuFFin\nextracts the trigger pattern and the knowledge-level fingerprints to identify\nthe source of a suspect model. We conduct experiments on a variety of models\ncollected from the open-source website, including four popular base models as\nprotected LLMs and their fine-tuning, quantization, and safety alignment\nversions, which are released by large companies, start-ups, and individual\nusers. Results show that our method can accurately verify the copyright of the\nbase protected LLM on their model variants, achieving the IP-ROC metric greater\nthan 0.95. Our code is available at\nhttps://github.com/yuliangyan0807/llm-fingerprint.", "AI": {"tldr": "DuFFin is a dual-level fingerprinting framework for verifying ownership of large language models (LLMs) in black-box settings, addressing limitations of existing methods.", "motivation": "Protecting LLMs as valuable intellectual property (IP) from theft or unauthorized use, as current watermarking and fingerprinting methods are impractical.", "method": "DuFFin extracts trigger patterns and knowledge-level fingerprints to identify suspect models, tested on various open-source models and their variants.", "result": "Achieves high accuracy (IP-ROC > 0.95) in verifying copyright of base LLMs on their variants.", "conclusion": "DuFFin effectively verifies LLM ownership in black-box settings, offering a practical solution for IP protection."}}
{"id": "2505.16755", "pdf": "https://arxiv.org/pdf/2505.16755", "abs": "https://arxiv.org/abs/2505.16755", "authors": ["Ayano Nakai-Kasai", "Tadashi Wadayama"], "title": "Multi-Output Gaussian Processes for Graph-Structured Data", "categories": ["cs.LG"], "comment": null, "summary": "Graph-structured data is a type of data to be obtained associated with a\ngraph structure where vertices and edges describe some kind of data\ncorrelation. This paper proposes a regression method on graph-structured data,\nwhich is based on multi-output Gaussian processes (MOGP), to capture both the\ncorrelation between vertices and the correlation between associated data. The\nproposed formulation is built on the definition of MOGP. This allows it to be\napplied to a wide range of data configurations and scenarios. Moreover, it has\nhigh expressive capability due to its flexibility in kernel design. It includes\nexisting methods of Gaussian processes for graph-structured data as special\ncases and is possible to remove restrictions on data configurations, model\nselection, and inference scenarios in the existing methods. The performance of\nextensions achievable by the proposed formulation is evaluated through computer\nexperiments with synthetic and real data.", "AI": {"tldr": "The paper proposes a multi-output Gaussian process (MOGP) regression method for graph-structured data, capturing vertex and data correlations, with flexible kernel design and broad applicability.", "motivation": "To address limitations in existing Gaussian process methods for graph-structured data by enabling more flexible data configurations, model selection, and inference scenarios.", "method": "The method is based on MOGP, allowing expressive kernel design and generalization of existing approaches.", "result": "The proposed method outperforms existing techniques, as validated by experiments on synthetic and real data.", "conclusion": "The MOGP-based regression method offers a versatile and powerful framework for graph-structured data analysis."}}
{"id": "2505.16673", "pdf": "https://arxiv.org/pdf/2505.16673", "abs": "https://arxiv.org/abs/2505.16673", "authors": ["Huanjin Yao", "Qixiang Yin", "Jingyi Zhang", "Min Yang", "Yibo Wang", "Wenhao Wu", "Fei Su", "Li Shen", "Minghui Qiu", "Dacheng Tao", "Jiaxing Huang"], "title": "R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Technical report", "summary": "In this work, we aim to incentivize the reasoning ability of Multimodal Large\nLanguage Models (MLLMs) via reinforcement learning (RL) and develop an\neffective approach that mitigates the sparse reward and advantage vanishing\nissues during RL. To this end, we propose Share-GRPO, a novel RL approach that\ntackle these issues by exploring and sharing diverse reasoning trajectories\nover expanded question space. Specifically, Share-GRPO first expands the\nquestion space for a given question via data transformation techniques, and\nthen encourages MLLM to effectively explore diverse reasoning trajectories over\nthe expanded question space and shares the discovered reasoning trajectories\nacross the expanded questions during RL. In addition, Share-GRPO also shares\nreward information during advantage computation, which estimates solution\nadvantages hierarchically across and within question variants, allowing more\naccurate estimation of relative advantages and improving the stability of\npolicy training. Extensive evaluations over six widely-used reasoning\nbenchmarks showcase the superior performance of our method. Code will be\navailable at https://github.com/HJYao00/R1-ShareVL.", "AI": {"tldr": "Share-GRPO, a novel RL approach, enhances reasoning in MLLMs by sharing diverse reasoning trajectories and reward information, outperforming benchmarks.", "motivation": "To improve reasoning in Multimodal Large Language Models (MLLMs) by addressing sparse rewards and advantage vanishing in reinforcement learning.", "method": "Proposes Share-GRPO, which expands question space, explores diverse reasoning trajectories, and shares rewards hierarchically.", "result": "Superior performance on six reasoning benchmarks.", "conclusion": "Share-GRPO effectively mitigates RL challenges and boosts MLLM reasoning."}}
{"id": "2505.16703", "pdf": "https://arxiv.org/pdf/2505.16703", "abs": "https://arxiv.org/abs/2505.16703", "authors": ["Zeping Yu", "Sophia Ananiadou"], "title": "Locate-then-Merge: Neuron-Level Parameter Fusion for Mitigating Catastrophic Forgetting in Multimodal LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Although multimodal large language models (MLLMs) have achieved impressive\nperformance, the multimodal instruction tuning stage often causes catastrophic\nforgetting of the base LLM's language ability, even in strong models like\nLlama3. To address this, we propose Locate-then-Merge, a training-free\nparameter fusion framework that first locates important parameters and then\nselectively merges them. We further introduce Neuron-Fusion, a neuron-level\nstrategy that preserves the influence of neurons with large parameter\nshifts--neurons likely responsible for newly acquired visual\ncapabilities--while attenuating the influence of neurons with smaller changes\nthat likely encode general-purpose language skills. This design enables better\nretention of visual adaptation while mitigating language degradation.\nExperiments on 13 benchmarks across both language and visual tasks show that\nNeuron-Fusion consistently outperforms existing model merging methods. Further\nanalysis reveals that our method effectively reduces context hallucination in\ngeneration.", "AI": {"tldr": "Locate-then-Merge framework mitigates catastrophic forgetting in MLLMs by selectively fusing parameters, preserving visual capabilities while retaining language skills.", "motivation": "Addressing the issue of catastrophic forgetting of language abilities in MLLMs during multimodal instruction tuning.", "method": "Proposes Locate-then-Merge, a training-free parameter fusion framework with Neuron-Fusion, a neuron-level strategy to selectively merge parameters.", "result": "Outperforms existing methods on 13 benchmarks, reducing context hallucination and retaining visual adaptation.", "conclusion": "Neuron-Fusion effectively balances visual and language capabilities in MLLMs."}}
{"id": "2505.16547", "pdf": "https://arxiv.org/pdf/2505.16547", "abs": "https://arxiv.org/abs/2505.16547", "authors": ["Nitesh Subedi", "Hsin-Jung Yang", "Devesh K. Jha", "Soumik Sarkar"], "title": "Find the Fruit: Designing a Zero-Shot Sim2Real Deep RL Planner for Occlusion Aware Plant Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "18 Pages, 15 Figures, 5 Tables", "summary": "This paper presents an end-to-end deep reinforcement learning (RL) framework\nfor occlusion-aware robotic manipulation in cluttered plant environments. Our\napproach enables a robot to interact with a deformable plant to reveal hidden\nobjects of interest, such as fruits, using multimodal observations. We decouple\nthe kinematic planning problem from robot control to simplify zero-shot\nsim2real transfer for the trained policy. Our results demonstrate that the\ntrained policy, deployed using our framework, achieves up to 86.7% success in\nreal-world trials across diverse initial conditions. Our findings pave the way\ntoward autonomous, perception-driven agricultural robots that intelligently\ninteract with complex foliage plants to \"find the fruit\" in challenging\noccluded scenarios, without the need for explicitly designed geometric and\ndynamic models of every plant scenario.", "AI": {"tldr": "An end-to-end deep RL framework for occlusion-aware robotic manipulation in cluttered plant environments, achieving 86.7% success in real-world trials.", "motivation": "To enable robots to autonomously interact with deformable plants and reveal hidden objects (e.g., fruits) without relying on pre-designed models.", "method": "Decouples kinematic planning from robot control for sim2real transfer, using multimodal observations.", "result": "Achieves up to 86.7% success in real-world trials across diverse conditions.", "conclusion": "Paves the way for autonomous agricultural robots to handle occluded scenarios without explicit plant models."}}
{"id": "2505.16786", "pdf": "https://arxiv.org/pdf/2505.16786", "abs": "https://arxiv.org/abs/2505.16786", "authors": ["Fares B. Mehouachi", "Saif Eddin Jabari"], "title": "FlowMixer: A Constrained Neural Architecture for Interpretable Spatiotemporal Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "We introduce FlowMixer, a neural architecture that leverages constrained\nmatrix operations to model structured spatiotemporal patterns. At its core,\nFlowMixer incorporates non-negative matrix mixing layers within a reversible\nmapping framework-applying transforms before mixing and their inverses\nafterward. This shape-preserving design enables a Kronecker-Koopman eigenmode\nframework that bridges statistical learning with dynamical systems theory,\nproviding interpretable spatiotemporal patterns and facilitating direct\nalgebraic manipulation of prediction horizons without retraining. Extensive\nexperiments across diverse domains demonstrate FlowMixer's robust long-horizon\nforecasting capabilities while effectively modeling physical phenomena such as\nchaotic attractors and turbulent flows. These results suggest that\narchitectural constraints can simultaneously enhance predictive performance and\nmathematical interpretability in neural forecasting systems.", "AI": {"tldr": "FlowMixer is a neural architecture using constrained matrix operations for interpretable spatiotemporal modeling, combining statistical learning and dynamical systems theory.", "motivation": "To bridge the gap between statistical learning and dynamical systems theory for interpretable spatiotemporal forecasting.", "method": "Incorporates non-negative matrix mixing layers in a reversible framework, enabling algebraic manipulation of predictions without retraining.", "result": "Demonstrates robust long-horizon forecasting and effective modeling of physical phenomena like chaotic attractors.", "conclusion": "Architectural constraints can improve both predictive performance and interpretability in neural forecasting."}}
{"id": "2505.16674", "pdf": "https://arxiv.org/pdf/2505.16674", "abs": "https://arxiv.org/abs/2505.16674", "authors": ["Marcella Astrid", "Abdelrahman Shabayek", "Djamila Aouada"], "title": "Zero-Shot Anomaly Detection in Battery Thermal Images Using Visual Question Answering with Prior Knowledge", "categories": ["cs.CV"], "comment": "Accepted in EUSIPCO 2025", "summary": "Batteries are essential for various applications, including electric vehicles\nand renewable energy storage, making safety and efficiency critical concerns.\nAnomaly detection in battery thermal images helps identify failures early, but\ntraditional deep learning methods require extensive labeled data, which is\ndifficult to obtain, especially for anomalies due to safety risks and high data\ncollection costs. To overcome this, we explore zero-shot anomaly detection\nusing Visual Question Answering (VQA) models, which leverage pretrained\nknowledge and textbased prompts to generalize across vision tasks. By\nincorporating prior knowledge of normal battery thermal behavior, we design\nprompts to detect anomalies without battery-specific training data. We evaluate\nthree VQA models (ChatGPT-4o, LLaVa-13b, and BLIP-2) analyzing their robustness\nto prompt variations, repeated trials, and qualitative outputs. Despite the\nlack of finetuning on battery data, our approach demonstrates competitive\nperformance compared to state-of-the-art models that are trained with the\nbattery data. Our findings highlight the potential of VQA-based zero-shot\nlearning for battery anomaly detection and suggest future directions for\nimproving its effectiveness.", "AI": {"tldr": "The paper proposes a zero-shot anomaly detection method for battery thermal images using VQA models, eliminating the need for labeled training data.", "motivation": "Safety and efficiency in battery applications require early anomaly detection, but traditional methods rely on extensive labeled data, which is hard to obtain.", "method": "Leverages pretrained VQA models (ChatGPT-4o, LLaVa-13b, BLIP-2) with text-based prompts incorporating prior knowledge of normal battery behavior.", "result": "Competitive performance against state-of-the-art models without battery-specific training data.", "conclusion": "VQA-based zero-shot learning shows promise for battery anomaly detection, with potential for future improvements."}}
{"id": "2505.16722", "pdf": "https://arxiv.org/pdf/2505.16722", "abs": "https://arxiv.org/abs/2505.16722", "authors": ["Himanshu Beniwal", "Youngwoo Kim", "Maarten Sap", "Soham Dan", "Thomas Hartvigsen"], "title": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) become increasingly prevalent in global\napplications, ensuring that they are toxicity-free across diverse linguistic\ncontexts remains a critical challenge. We explore \"Cross-lingual\nDetoxification\", a cross-lingual paradigm that mitigates toxicity, enabling\ndetoxification capabilities to transfer between high and low-resource languages\nacross different script families. We analyze cross-lingual detoxification's\neffectiveness through 504 extensive settings to evaluate toxicity reduction in\ncross-distribution settings with limited data and investigate how mitigation\nimpacts model performance on non-toxic tasks, revealing trade-offs between\nsafety and knowledge preservation. Our code and dataset are publicly available\nat https://github.com/himanshubeniwal/Breaking-mBad.", "AI": {"tldr": "The paper introduces 'Cross-lingual Detoxification' to reduce toxicity in LLMs across languages, evaluating its effectiveness in 504 settings and balancing safety with knowledge preservation.", "motivation": "Ensuring toxicity-free LLMs in diverse linguistic contexts is a critical challenge.", "method": "The study uses a cross-lingual paradigm to transfer detoxification capabilities between high and low-resource languages, analyzing 504 settings.", "result": "The approach effectively reduces toxicity but reveals trade-offs between safety and model performance on non-toxic tasks.", "conclusion": "Cross-lingual detoxification is viable but requires balancing safety and knowledge preservation."}}
{"id": "2505.16573", "pdf": "https://arxiv.org/pdf/2505.16573", "abs": "https://arxiv.org/abs/2505.16573", "authors": ["Yi Hu", "Hanchi Ren", "Jingjing Deng", "Xianghua Xie"], "title": "From Local Patterns to Global Understanding: Cross-Stock Trend Integration for Enhanced Predictive Modeling", "categories": ["cs.CE", "cs.AI"], "comment": null, "summary": "Stock price prediction is a critical area of financial forecasting,\ntraditionally approached by training models using the historical price data of\nindividual stocks. While these models effectively capture single-stock\npatterns, they fail to leverage potential correlations among stock trends,\nwhich could improve predictive performance. Current single-stock learning\nmethods are thus limited in their ability to provide a broader understanding of\nprice dynamics across multiple stocks. To address this, we propose a novel\nmethod that merges local patterns into a global understanding through\ncross-stock pattern integration. Our strategy is inspired by Federated Learning\n(FL), a paradigm designed for decentralized model training. FL enables\ncollaborative learning across distributed datasets without sharing raw data,\nfacilitating the aggregation of global insights while preserving data privacy.\nIn our adaptation, we train models on individual stock data and iteratively\nmerge them to create a unified global model. This global model is subsequently\nfine-tuned on specific stock data to retain local relevance. The proposed\nstrategy enables parallel training of individual stock models, facilitating\nefficient utilization of computational resources and reducing overall training\ntime. We conducted extensive experiments to evaluate the proposed method,\ndemonstrating that it outperforms benchmark models and enhances the predictive\ncapabilities of state-of-the-art approaches. Our results highlight the efficacy\nof Cross-Stock Trend Integration (CSTI) in advancing stock price prediction,\noffering a robust alternative to traditional single-stock learning\nmethodologies.", "AI": {"tldr": "A novel method, Cross-Stock Trend Integration (CSTI), improves stock price prediction by leveraging correlations among stocks, inspired by Federated Learning.", "motivation": "Traditional single-stock models miss correlations among stocks, limiting predictive performance.", "method": "Uses Federated Learning to train individual stock models, merge them into a global model, and fine-tune for local relevance.", "result": "Outperforms benchmarks, enhancing predictive capabilities.", "conclusion": "CSTI offers a robust alternative to single-stock methods, improving stock price forecasting."}}
{"id": "2505.16790", "pdf": "https://arxiv.org/pdf/2505.16790", "abs": "https://arxiv.org/abs/2505.16790", "authors": ["Hyunjin Seo", "Taewon Kim", "Sihyun Yu", "SungSoo Ahn"], "title": "Learning Flexible Forward Trajectories for Masked Molecular Diffusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Masked diffusion models (MDMs) have achieved notable progress in modeling\ndiscrete data, while their potential in molecular generation remains\nunderexplored. In this work, we explore their potential and introduce the\nsurprising result that naively applying standards MDMs severely degrades the\nperformance. We identify the critical cause of this issue as a state-clashing\nproblem-where the forward diffusion of distinct molecules collapse into a\ncommon state, resulting in a mixture of reconstruction targets that cannot be\nlearned using typical reverse diffusion process with unimodal predictions. To\nmitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that\norchestrates per-element corruption trajectories to avoid collision between\ndistinct molecular graphs. This is achieved through a parameterized noise\nscheduling network that assigns distinct corruption rates to individual graph\nelements, i.e., atoms and bonds. Extensive experiments on diverse molecular\nbenchmarks reveal that MELD markedly enhances overall generation quality\ncompared to element-agnostic noise scheduling, increasing the chemical validity\nof vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves\nstate-of-the-art property alignment in conditional generation tasks.", "AI": {"tldr": "MDMs underperform in molecular generation due to state-clashing. MELD, a novel method with element-wise noise scheduling, improves performance significantly.", "motivation": "Explore the potential of masked diffusion models (MDMs) in molecular generation and address their underperformance due to state-clashing.", "method": "Propose Masked Element-wise Learnable Diffusion (MELD), which uses per-element corruption trajectories and a parameterized noise scheduling network to avoid state-clashing.", "result": "MELD boosts chemical validity from 15% to 93% on ZINC250K and achieves state-of-the-art property alignment in conditional generation.", "conclusion": "MELD effectively mitigates state-clashing in MDMs, enhancing molecular generation quality and performance."}}
{"id": "2505.16679", "pdf": "https://arxiv.org/pdf/2505.16679", "abs": "https://arxiv.org/abs/2505.16679", "authors": ["Jordan Dotzel", "Tony Montes", "Mohamed S. Abdelfattah", "Zhiru Zhang"], "title": "Semantic Compression of 3D Objects for Open and Collaborative Virtual Worlds", "categories": ["cs.CV", "cs.AI"], "comment": "First two authors have equal contribution", "summary": "Traditional methods for 3D object compression operate only on structural\ninformation within the object vertices, polygons, and textures. These methods\nare effective at compression rates up to 10x for standard object sizes but\nquickly deteriorate at higher compression rates with texture artifacts,\nlow-polygon counts, and mesh gaps. In contrast, semantic compression ignores\nstructural information and operates directly on the core concepts to push to\nextreme levels of compression. In addition, it uses natural language as its\nstorage format, which makes it natively human-readable and a natural fit for\nemerging applications built around large-scale, collaborative projects within\naugmented and virtual reality. It deprioritizes structural information like\nlocation, size, and orientation and predicts the missing information with\nstate-of-the-art deep generative models. In this work, we construct a pipeline\nfor 3D semantic compression from public generative models and explore the\nquality-compression frontier for 3D object compression. We apply this pipeline\nto achieve rates as high as 105x for 3D objects taken from the Objaverse\ndataset and show that semantic compression can outperform traditional methods\nin the important quality-preserving region around 100x compression.", "AI": {"tldr": "Semantic compression for 3D objects outperforms traditional methods at high compression rates (up to 105x) by focusing on core concepts and using natural language for storage.", "motivation": "Traditional 3D compression methods fail at high compression rates, leading to artifacts and poor quality. Semantic compression offers a better solution by leveraging deep generative models and human-readable formats.", "method": "A pipeline using public generative models to compress 3D objects semantically, ignoring structural details and predicting missing information.", "result": "Achieved compression rates up to 105x on the Objaverse dataset, outperforming traditional methods around 100x compression while preserving quality.", "conclusion": "Semantic compression is superior for high-rate 3D object compression, especially in collaborative AR/VR applications."}}
{"id": "2505.16743", "pdf": "https://arxiv.org/pdf/2505.16743", "abs": "https://arxiv.org/abs/2505.16743", "authors": ["Florentin Beck", "William Rudman", "Carsten Eickhoff"], "title": "TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.6; F.2.2"], "comment": null, "summary": "Large Language Models (LLMs) present significant computational and memory\nchallenges due to their extensive size, making pruning essential for their\nefficient deployment. Existing one-shot pruning methods often apply uniform\nsparsity constraints across layers or within each layer, resulting in\nsuboptimal performance, especially at high sparsity ratios. This work\nintroduces TRIM (Targeted Row-wise Iterative Metric-driven pruning), a novel\napproach that applies varying sparsity ratios to individual output dimensions\n(rows) within each layer. TRIM employs an iterative adjustment process guided\nby quality metrics to optimize dimension-wise sparsity allocation, focusing on\nreducing variance in quality retention across outputs to preserve critical\ninformation. TRIM can be seamlessly integrated with existing layer-wise pruning\nstrategies. Our evaluations on perplexity and zero-shot tasks across diverse\nLLM families (Qwen2.5, LLaMA-2, and OPT) and sparsity levels demonstrate that\nTRIM achieves new state-of-the-art results and enhances stability. For\ninstance, at 80% sparsity, TRIM reduces perplexity by 48% for Qwen2.5-14B and\nover 90% for OPT-13B compared to baseline methods. We conclude that\nfine-grained, dimension-wise sparsity adaptation is crucial for pushing the\nlimits of extreme LLM compression. Code available at:\nhttps://github.com/flobk/TRIM", "AI": {"tldr": "TRIM introduces targeted row-wise pruning for LLMs, outperforming uniform methods with iterative metric-driven sparsity adaptation.", "motivation": "Existing pruning methods use uniform sparsity, leading to suboptimal performance, especially at high sparsity ratios.", "method": "TRIM applies varying sparsity ratios to individual output dimensions, guided by quality metrics, and integrates with layer-wise pruning.", "result": "TRIM achieves state-of-the-art results, reducing perplexity by 48% for Qwen2.5-14B and over 90% for OPT-13B at 80% sparsity.", "conclusion": "Fine-grained, dimension-wise sparsity adaptation is key for extreme LLM compression."}}
{"id": "2505.16596", "pdf": "https://arxiv.org/pdf/2505.16596", "abs": "https://arxiv.org/abs/2505.16596", "authors": ["Wilbert Peter Empleo", "Yitaek Kim", "Hansoul Kim", "Thiusius Rajeeth Savarimuthu", "I\u00f1igo Iturrate"], "title": "Safe Uncertainty-Aware Learning of Robotic Suturing", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Robot-Assisted Minimally Invasive Surgery is currently fully manually\ncontrolled by a trained surgeon. Automating this has great potential for\nalleviating issues, e.g., physical strain, highly repetitive tasks, and\nshortages of trained surgeons. For these reasons, recent works have utilized\nArtificial Intelligence methods, which show promising adaptability. Despite\nthese advances, there is skepticism of these methods because they lack\nexplainability and robust safety guarantees. This paper presents a framework\nfor a safe, uncertainty-aware learning method. We train an Ensemble Model of\nDiffusion Policies using expert demonstrations of needle insertion. Using an\nEnsemble model, we can quantify the policy's epistemic uncertainty, which is\nused to determine Out-Of-Distribution scenarios. This allows the system to\nrelease control back to the surgeon in the event of an unsafe scenario.\nAdditionally, we implement a model-free Control Barrier Function to place\nformal safety guarantees on the predicted action. We experimentally evaluate\nour proposed framework using a state-of-the-art robotic suturing simulator. We\nevaluate multiple scenarios, such as dropping the needle, moving the camera,\nand moving the phantom. The learned policy is robust to these perturbations,\nshowing corrective behaviors and generalization, and it is possible to detect\nOut-Of-Distribution scenarios. We further demonstrate that the Control Barrier\nFunction successfully limits the action to remain within our specified safety\nset in the case of unsafe predictions.", "AI": {"tldr": "A framework for safe, uncertainty-aware learning in robot-assisted surgery using ensemble diffusion policies and control barrier functions for safety guarantees.", "motivation": "Automating robot-assisted surgery can reduce physical strain, repetitive tasks, and surgeon shortages, but current AI methods lack explainability and safety guarantees.", "method": "Train an ensemble of diffusion policies with expert demonstrations, quantify epistemic uncertainty for OOD detection, and use control barrier functions for safety.", "result": "The policy shows robustness to perturbations, corrective behaviors, and successful OOD detection. Safety is ensured via control barrier functions.", "conclusion": "The framework provides a safe, adaptable solution for automating surgery, with demonstrated robustness and safety guarantees."}}
{"id": "2505.16791", "pdf": "https://arxiv.org/pdf/2505.16791", "abs": "https://arxiv.org/abs/2505.16791", "authors": ["Tillmann Rheude", "Roland Eils", "Benjamin Wild"], "title": "Cohort-Based Active Modality Acquisition", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world machine learning applications often involve data from multiple\nmodalities that must be integrated effectively to make robust predictions.\nHowever, in many practical settings, not all modalities are available for every\nsample, and acquiring additional modalities can be costly. This raises the\nquestion: which samples should be prioritized for additional modality\nacquisition when resources are limited? While prior work has explored\nindividual-level acquisition strategies and training-time active learning\nparadigms, test-time and cohort-based acquisition remain underexplored despite\ntheir importance in many real-world settings. We introduce Cohort-based Active\nModality Acquisition (CAMA), a novel test-time setting to formalize the\nchallenge of selecting which samples should receive additional modalities. We\nderive acquisition strategies that leverage a combination of generative\nimputation and discriminative modeling to estimate the expected benefit of\nacquiring missing modalities based on common evaluation metrics. We also\nintroduce upper-bound heuristics that provide performance ceilings to benchmark\nacquisition strategies. Experiments on common multimodal datasets demonstrate\nthat our proposed imputation-based strategies can more effectively guide the\nacquisition of new samples in comparison to those relying solely on unimodal\ninformation, entropy guidance, and random selections. Our work provides an\neffective solution for optimizing modality acquisition at the cohort level,\nenabling better utilization of resources in constrained settings.", "AI": {"tldr": "The paper introduces CAMA, a method for prioritizing samples for additional modality acquisition in multimodal ML, using generative imputation and discriminative modeling to optimize resource use.", "motivation": "Real-world ML often lacks complete multimodal data, and acquiring missing modalities is costly. Existing methods don't adequately address test-time and cohort-based acquisition.", "method": "CAMA combines generative imputation and discriminative modeling to estimate the benefit of acquiring missing modalities, with upper-bound heuristics for benchmarking.", "result": "Experiments show CAMA outperforms unimodal, entropy-based, and random acquisition strategies in guiding modality acquisition.", "conclusion": "CAMA effectively optimizes cohort-level modality acquisition, improving resource utilization in constrained settings."}}
{"id": "2505.16685", "pdf": "https://arxiv.org/pdf/2505.16685", "abs": "https://arxiv.org/abs/2505.16685", "authors": ["Corentin Dufourg", "Charlotte Pelletier", "St\u00e9phane May", "S\u00e9bastien Lef\u00e8vre"], "title": "On the use of Graphs for Satellite Image Time Series", "categories": ["cs.CV"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The Earth's surface is subject to complex and dynamic processes, ranging from\nlarge-scale phenomena such as tectonic plate movements to localized changes\nassociated with ecosystems, agriculture, or human activity. Satellite images\nenable global monitoring of these processes with extensive spatial and temporal\ncoverage, offering advantages over in-situ methods. In particular, resulting\nsatellite image time series (SITS) datasets contain valuable information. To\nhandle their large volume and complexity, some recent works focus on the use of\ngraph-based techniques that abandon the regular Euclidean structure of\nsatellite data to work at an object level. Besides, graphs enable modelling\nspatial and temporal interactions between identified objects, which are crucial\nfor pattern detection, classification and regression tasks. This paper is an\neffort to examine the integration of graph-based methods in spatio-temporal\nremote-sensing analysis. In particular, it aims to present a versatile\ngraph-based pipeline to tackle SITS analysis. It focuses on the construction of\nspatio-temporal graphs from SITS and their application to downstream tasks. The\npaper includes a comprehensive review and two case studies, which highlight the\npotential of graph-based approaches for land cover mapping and water resource\nforecasting. It also discusses numerous perspectives to resolve current\nlimitations and encourage future developments.", "AI": {"tldr": "The paper explores graph-based methods for analyzing satellite image time series (SITS) to model spatio-temporal interactions, presenting a versatile pipeline and demonstrating its potential in land cover mapping and water resource forecasting.", "motivation": "To address the complexity and volume of SITS data, the paper motivates the use of graph-based techniques for better modeling of spatial and temporal interactions, improving pattern detection and analysis.", "method": "The paper proposes a graph-based pipeline for SITS analysis, focusing on constructing spatio-temporal graphs and applying them to downstream tasks like classification and regression. It includes a review and case studies.", "result": "Case studies demonstrate the effectiveness of graph-based approaches for land cover mapping and water resource forecasting, highlighting their potential.", "conclusion": "The paper concludes by discussing limitations and future directions, encouraging further development of graph-based methods in remote-sensing analysis."}}
{"id": "2505.16774", "pdf": "https://arxiv.org/pdf/2505.16774", "abs": "https://arxiv.org/abs/2505.16774", "authors": ["Yiming Gao", "Bin Wang", "Chengwei Wei", "Shuo Sun", "AiTi Aw"], "title": "IFEval-Audio: Benchmarking Instruction-Following Capability in Audio-based Large Language Models", "categories": ["cs.CL"], "comment": "Link: https://github.com/AudioLLMs/AudioBench/tree/main/IFEval-Audio", "summary": "Large language models (LLMs) have demonstrated strong instruction-following\ncapabilities in text-based tasks. However, this ability often deteriorates in\nmultimodal models after alignment with non-text modalities such as images or\naudio. While several recent efforts have investigated instruction-following\nperformance in text and vision-language models, instruction-following in\naudio-based large language models remains largely unexplored. To bridge this\ngap, we introduce IFEval-Audio, a novel evaluation dataset designed to assess\nthe ability to follow instructions in an audio LLM. IFEval-Audio contains 280\naudio-instruction-answer triples across six diverse dimensions: Content,\nCapitalization, Symbol, List Structure, Length, and Format. Each example pairs\nan audio input with a text instruction, requiring the model to generate an\noutput that follows a specified structure. We benchmark state-of-the-art audio\nLLMs on their ability to follow audio-involved instructions. The dataset is\nreleased publicly to support future research in this emerging area.", "AI": {"tldr": "The paper introduces IFEval-Audio, a dataset to evaluate instruction-following in audio-based LLMs, addressing a gap in multimodal model research.", "motivation": "Instruction-following in audio-based LLMs is underexplored compared to text and vision-language models, despite its importance.", "method": "IFEval-Audio, a dataset of 280 audio-instruction-answer triples across six dimensions, is created to benchmark audio LLMs.", "result": "The dataset is used to evaluate state-of-the-art audio LLMs, highlighting their instruction-following capabilities.", "conclusion": "IFEval-Audio fills a research gap and supports future work in audio-based LLM instruction-following."}}
{"id": "2505.16640", "pdf": "https://arxiv.org/pdf/2505.16640", "abs": "https://arxiv.org/abs/2505.16640", "authors": ["Xueyang Zhou", "Guiyao Tie", "Guowen Zhang", "Hechang Wang", "Pan Zhou", "Lichao Sun"], "title": "BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization", "categories": ["cs.CR", "cs.AI", "68T07", "I.2.6; I.2.9"], "comment": "19 pages, 12 figures, 6 tables", "summary": "Vision-Language-Action (VLA) models have advanced robotic control by enabling\nend-to-end decision-making directly from multimodal inputs. However, their\ntightly coupled architectures expose novel security vulnerabilities. Unlike\ntraditional adversarial perturbations, backdoor attacks represent a stealthier,\npersistent, and practically significant threat-particularly under the emerging\nTraining-as-a-Service paradigm-but remain largely unexplored in the context of\nVLA models. To address this gap, we propose BadVLA, a backdoor attack method\nbased on Objective-Decoupled Optimization, which for the first time exposes the\nbackdoor vulnerabilities of VLA models. Specifically, it consists of a\ntwo-stage process: (1) explicit feature-space separation to isolate trigger\nrepresentations from benign inputs, and (2) conditional control deviations that\nactivate only in the presence of the trigger, while preserving clean-task\nperformance. Empirical results on multiple VLA benchmarks demonstrate that\nBadVLA consistently achieves near-100% attack success rates with minimal impact\non clean task accuracy. Further analyses confirm its robustness against common\ninput perturbations, task transfers, and model fine-tuning, underscoring\ncritical security vulnerabilities in current VLA deployments. Our work offers\nthe first systematic investigation of backdoor vulnerabilities in VLA models,\nhighlighting an urgent need for secure and trustworthy embodied model design\npractices. We have released the project page at\nhttps://badvla-project.github.io/.", "AI": {"tldr": "BadVLA exposes backdoor vulnerabilities in Vision-Language-Action (VLA) models using Objective-Decoupled Optimization, achieving high attack success with minimal impact on clean tasks.", "motivation": "To address unexplored backdoor threats in VLA models, especially under Training-as-a-Service, which pose stealthy and persistent risks.", "method": "Two-stage process: (1) feature-space separation to isolate triggers, (2) conditional control deviations activating only with triggers.", "result": "Near-100% attack success rates on VLA benchmarks, minimal clean-task impact, and robustness against perturbations, transfers, and fine-tuning.", "conclusion": "First systematic study of VLA backdoor vulnerabilities, urging secure design practices for trustworthy embodied models."}}
{"id": "2505.16801", "pdf": "https://arxiv.org/pdf/2505.16801", "abs": "https://arxiv.org/abs/2505.16801", "authors": ["Eleftherios Kalafatis", "Konstantinos Mitsis", "Konstantia Zarkogianni", "Maria Athanasiou", "Konstantina Nikita"], "title": "A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Serious Games (SGs) are nowadays shifting focus to include procedural content\ngeneration (PCG) in the development process as a means of offering personalized\nand enhanced player experience. However, the development of a framework to\nassess the impact of PCG techniques when integrated into SGs remains\nparticularly challenging. This study proposes a methodology for automated\nevaluation of PCG integration in SGs, incorporating deep reinforcement learning\n(DRL) game testing agents. To validate the proposed framework, a previously\nintroduced SG featuring card game mechanics and incorporating three different\nversions of PCG for nonplayer character (NPC) creation has been deployed.\nVersion 1 features random NPC creation, while versions 2 and 3 utilize a\ngenetic algorithm approach. These versions are used to test the impact of\ndifferent dynamic SG environments on the proposed framework's agents. The\nobtained results highlight the superiority of the DRL game testing agents\ntrained on Versions 2 and 3 over those trained on Version 1 in terms of win\nrate (i.e. number of wins per played games) and training time. More\nspecifically, within the execution of a test emulating regular gameplay, both\nVersions 2 and 3 peaked at a 97% win rate and achieved statistically\nsignificant higher (p=0009) win rates compared to those achieved in Version 1\nthat peaked at 94%. Overall, results advocate towards the proposed framework's\ncapability to produce meaningful data for the evaluation of procedurally\ngenerated content in SGs.", "AI": {"tldr": "The paper proposes a DRL-based framework to evaluate PCG in SGs, showing better performance with genetic algorithm NPCs over random ones.", "motivation": "To address the challenge of assessing PCG's impact in SGs, aiming for personalized player experiences.", "method": "Uses DRL game testing agents on three PCG versions (random and genetic algorithm-based NPCs) in a card game SG.", "result": "DRL agents with genetic algorithm NPCs (Versions 2 & 3) outperformed random NPCs (Version 1) in win rate (97% vs. 94%) and training time.", "conclusion": "The framework effectively evaluates PCG in SGs, with genetic algorithms enhancing performance."}}
{"id": "2505.16707", "pdf": "https://arxiv.org/pdf/2505.16707", "abs": "https://arxiv.org/abs/2505.16707", "authors": ["Yongliang Wu", "Zonghui Li", "Xinting Hu", "Xinyu Ye", "Xianfang Zeng", "Gang Yu", "Wenbo Zhu", "Bernt Schiele", "Ming-Hsuan Yang", "Xu Yang"], "title": "KRIS-Bench: Benchmarking Next-Level Intelligent Image Editing Models", "categories": ["cs.CV"], "comment": "39 pages, 36 figures", "summary": "Recent advances in multi-modal generative models have enabled significant\nprogress in instruction-based image editing. However, while these models\nproduce visually plausible outputs, their capacity for knowledge-based\nreasoning editing tasks remains under-explored. In this paper, we introduce\nKRIS-Bench (Knowledge-based Reasoning in Image-editing Systems Benchmark), a\ndiagnostic benchmark designed to assess models through a cognitively informed\nlens. Drawing from educational theory, KRIS-Bench categorizes editing tasks\nacross three foundational knowledge types: Factual, Conceptual, and Procedural.\nBased on this taxonomy, we design 22 representative tasks spanning 7 reasoning\ndimensions and release 1,267 high-quality annotated editing instances. To\nsupport fine-grained evaluation, we propose a comprehensive protocol that\nincorporates a novel Knowledge Plausibility metric, enhanced by knowledge hints\nand calibrated through human studies. Empirical results on 10 state-of-the-art\nmodels reveal significant gaps in reasoning performance, highlighting the need\nfor knowledge-centric benchmarks to advance the development of intelligent\nimage editing systems.", "AI": {"tldr": "KRIS-Bench is a benchmark for evaluating knowledge-based reasoning in image-editing models, revealing gaps in current systems.", "motivation": "To address the under-explored capacity of multi-modal generative models in knowledge-based reasoning for image editing.", "method": "Introduces KRIS-Bench, a diagnostic benchmark with 22 tasks across 7 reasoning dimensions, using a taxonomy of Factual, Conceptual, and Procedural knowledge. Includes 1,267 annotated instances and a Knowledge Plausibility metric.", "result": "Tests on 10 state-of-the-art models show significant reasoning performance gaps.", "conclusion": "Knowledge-centric benchmarks like KRIS-Bench are essential for advancing intelligent image editing systems."}}
{"id": "2505.16782", "pdf": "https://arxiv.org/pdf/2505.16782", "abs": "https://arxiv.org/abs/2505.16782", "authors": ["Xinghao Chen", "Anhao Zhao", "Heming Xia", "Xuan Lu", "Hanlin Wang", "Yanjun Chen", "Wei Zhang", "Jian Wang", "Wenjie Li", "Xiaoyu Shen"], "title": "Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved impressive performance on complex\nreasoning tasks with Chain-of-Thought (CoT) prompting. However, conventional\nCoT relies on reasoning steps explicitly verbalized in natural language,\nintroducing inefficiencies and limiting its applicability to abstract\nreasoning. To address this, there has been growing research interest in latent\nCoT reasoning, where inference occurs within latent spaces. By decoupling\nreasoning from language, latent reasoning promises richer cognitive\nrepresentations and more flexible, faster inference. Researchers have explored\nvarious directions in this promising field, including training methodologies,\nstructural innovations, and internal reasoning mechanisms. This paper presents\na comprehensive overview and analysis of this reasoning paradigm. We begin by\nproposing a unified taxonomy from four perspectives: token-wise strategies,\ninternal mechanisms, analysis, and applications. We then provide in-depth\ndiscussions and comparative analyses of representative methods, highlighting\ntheir design patterns, strengths, and open challenges. We aim to provide a\nstructured foundation for advancing this emerging direction in LLM reasoning.\nThe relevant papers will be regularly updated at\nhttps://github.com/EIT-NLP/Awesome-Latent-CoT.", "AI": {"tldr": "The paper provides a comprehensive overview of latent Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs), proposing a taxonomy and analyzing methods to improve abstract reasoning efficiency.", "motivation": "Traditional CoT relies on explicit natural language steps, causing inefficiencies and limiting abstract reasoning. Latent CoT, reasoning in latent spaces, offers richer cognitive representations and faster inference.", "method": "The paper proposes a unified taxonomy from four perspectives (token-wise strategies, internal mechanisms, analysis, applications) and analyzes representative methods.", "result": "The analysis highlights design patterns, strengths, and challenges of latent CoT methods, providing a structured foundation for future research.", "conclusion": "Latent CoT is a promising direction for advancing LLM reasoning, with ongoing updates and resources available for further exploration."}}
{"id": "2505.16670", "pdf": "https://arxiv.org/pdf/2505.16670", "abs": "https://arxiv.org/abs/2505.16670", "authors": ["Xiaobei Yan", "Yiming Li", "Zhaoxin Fan", "Han Qiu", "Tianwei Zhang"], "title": "BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown impressive capabilities across a wide\nrange of applications, but their ever-increasing size and resource demands make\nthem vulnerable to inference cost attacks, where attackers induce victim LLMs\nto generate the longest possible output content. In this paper, we revisit\nexisting inference cost attacks and reveal that these methods can hardly\nproduce large-scale malicious effects since they are self-targeting, where\nattackers are also the users and therefore have to execute attacks solely\nthrough the inputs, whose generated content will be charged by LLMs and can\nonly directly influence themselves. Motivated by these findings, this paper\nintroduces a new type of inference cost attacks (dubbed 'bit-flip inference\ncost attack') that target the victim model itself rather than its inputs.\nSpecifically, we design a simple yet effective method (dubbed 'BitHydra') to\neffectively flip critical bits of model parameters. This process is guided by a\nloss function designed to suppress <EOS> token's probability with an efficient\ncritical bit search algorithm, thus explicitly defining the attack objective\nand enabling effective optimization. We evaluate our method on 11 LLMs ranging\nfrom 1.5B to 14B parameters under both int8 and float16 settings. Experimental\nresults demonstrate that with just 4 search samples and as few as 3 bit flips,\nBitHydra can force 100% of test prompts to reach the maximum generation length\n(e.g., 2048 tokens) on representative LLMs such as LLaMA3, highlighting its\nefficiency, scalability, and strong transferability across unseen inputs.", "AI": {"tldr": "The paper introduces 'bit-flip inference cost attacks' (BitHydra) to exploit LLMs by flipping critical bits in model parameters, forcing excessive output generation.", "motivation": "Existing inference cost attacks are limited as they are self-targeting. The paper aims to create a more impactful attack by targeting the model itself.", "method": "BitHydra flips critical bits in model parameters using a loss function to suppress <EOS> token probability, guided by an efficient bit search algorithm.", "result": "BitHydra forces 100% of test prompts to reach maximum generation length (e.g., 2048 tokens) with just 4 search samples and 3 bit flips.", "conclusion": "BitHydra is efficient, scalable, and transferable, demonstrating significant vulnerability in LLMs to such attacks."}}
{"id": "2505.16829", "pdf": "https://arxiv.org/pdf/2505.16829", "abs": "https://arxiv.org/abs/2505.16829", "authors": ["Anna Heuser", "Thomas Kesselheim"], "title": "Contextual Learning for Stochastic Optimization", "categories": ["cs.LG", "cs.DS", "cs.GT"], "comment": "Full version of EC'25 paper", "summary": "Motivated by stochastic optimization, we introduce the problem of learning\nfrom samples of contextual value distributions. A contextual value distribution\ncan be understood as a family of real-valued distributions, where each sample\nconsists of a context $x$ and a random variable drawn from the corresponding\nreal-valued distribution $D_x$. By minimizing a convex surrogate loss, we learn\nan empirical distribution $D'_x$ for each context, ensuring a small L\\'evy\ndistance to $D_x$. We apply this result to obtain the sample complexity bounds\nfor the learning of an $\\epsilon$-optimal policy for stochastic optimization\nproblems defined on an unknown contextual value distribution. The sample\ncomplexity is shown to be polynomial for the general case of strongly monotone\nand stable optimization problems, including Single-item Revenue Maximization,\nPandora's Box and Optimal Stopping.", "AI": {"tldr": "The paper introduces learning from contextual value distributions, using convex surrogate loss to minimize L\u00e9vy distance, and derives polynomial sample complexity bounds for stochastic optimization problems.", "motivation": "The study is motivated by stochastic optimization, aiming to learn from samples of contextual value distributions to solve optimization problems with unknown distributions.", "method": "A convex surrogate loss is minimized to learn empirical distributions for each context, ensuring small L\u00e9vy distance to the true distributions.", "result": "Sample complexity bounds are derived for learning \u03f5-optimal policies, shown to be polynomial for strongly monotone and stable optimization problems.", "conclusion": "The approach is applicable to problems like Single-item Revenue Maximization, Pandora's Box, and Optimal Stopping, demonstrating practical utility."}}
{"id": "2505.16740", "pdf": "https://arxiv.org/pdf/2505.16740", "abs": "https://arxiv.org/abs/2505.16740", "authors": ["Alya Zouzou", "L\u00e9o and\u00e9ol", "M\u00e9lanie Ducoffe", "Ryma Boumazouza"], "title": "Robust Vision-Based Runway Detection through Conformal Prediction and Conformal mAP", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We explore the use of conformal prediction to provide statistical uncertainty\nguarantees for runway detection in vision-based landing systems (VLS). Using\nfine-tuned YOLOv5 and YOLOv6 models on aerial imagery, we apply conformal\nprediction to quantify localization reliability under user-defined risk levels.\nWe also introduce Conformal mean Average Precision (C-mAP), a novel metric\naligning object detection performance with conformal guarantees. Our results\nshow that conformal prediction can improve the reliability of runway detection\nby quantifying uncertainty in a statistically sound way, increasing safety\non-board and paving the way for certification of ML system in the aerospace\ndomain.", "AI": {"tldr": "Conformal prediction improves runway detection reliability in vision-based landing systems by quantifying uncertainty, with a novel C-mAP metric introduced.", "motivation": "To enhance safety and reliability in vision-based landing systems by providing statistical uncertainty guarantees for runway detection.", "method": "Fine-tuned YOLOv5 and YOLOv6 models on aerial imagery, applied conformal prediction for uncertainty quantification, and introduced C-mAP metric.", "result": "Conformal prediction effectively quantifies uncertainty, improving detection reliability and supporting ML system certification in aerospace.", "conclusion": "Conformal prediction offers a statistically sound method to enhance runway detection safety, enabling ML certification in aerospace."}}
{"id": "2505.16789", "pdf": "https://arxiv.org/pdf/2505.16789", "abs": "https://arxiv.org/abs/2505.16789", "authors": ["Punya Syon Pandey", "Samuel Simko", "Kellin Pelrine", "Zhijing Jin"], "title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "As large language models gain popularity, their vulnerability to adversarial\nattacks remains a primary concern. While fine-tuning models on domain-specific\ndatasets is often employed to improve model performance, it can introduce\nvulnerabilities within the underlying model. In this work, we investigate\nAccidental Misalignment, unexpected vulnerabilities arising from\ncharacteristics of fine-tuning data. We begin by identifying potential\ncorrelation factors such as linguistic features, semantic similarity, and\ntoxicity within our experimental datasets. We then evaluate the adversarial\nperformance of these fine-tuned models and assess how dataset factors correlate\nwith attack success rates. Lastly, we explore potential causal links, offering\nnew insights into adversarial defense strategies and highlighting the crucial\nrole of dataset design in preserving model alignment. Our code is available at\nhttps://github.com/psyonp/accidental_misalignment.", "AI": {"tldr": "The paper explores vulnerabilities in fine-tuned large language models, termed 'Accidental Misalignment,' caused by dataset characteristics, and investigates their correlation with adversarial attack success.", "motivation": "To understand how fine-tuning datasets introduce unexpected vulnerabilities in language models, impacting their adversarial robustness.", "method": "Identify correlation factors (linguistic features, semantic similarity, toxicity) in datasets, evaluate adversarial performance of fine-tuned models, and explore causal links.", "result": "Findings reveal how dataset factors correlate with adversarial attack success, providing insights into model vulnerabilities.", "conclusion": "Highlights the importance of dataset design in maintaining model alignment and suggests implications for adversarial defense strategies."}}
{"id": "2505.16833", "pdf": "https://arxiv.org/pdf/2505.16833", "abs": "https://arxiv.org/abs/2505.16833", "authors": ["Alihan H\u00fcy\u00fck", "Finale Doshi-Velez"], "title": "Strategically Linked Decisions in Long-Term Planning and Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Long-term planning, as in reinforcement learning (RL), involves finding\nstrategies: actions that collectively work toward a goal rather than\nindividually optimizing their immediate outcomes. As part of a strategy, some\nactions are taken at the expense of short-term benefit to enable future actions\nwith even greater returns. These actions are only advantageous if followed up\nby the actions they facilitate, consequently, they would not have been taken if\nthose follow-ups were not available. In this paper, we quantify such\ndependencies between planned actions with strategic link scores: the drop in\nthe likelihood of one decision under the constraint that a follow-up decision\nis no longer available. We demonstrate the utility of strategic link scores\nthrough three practical applications: (i) explaining black-box RL agents by\nidentifying strategically linked pairs among decisions they make, (ii)\nimproving the worst-case performance of decision support systems by\ndistinguishing whether recommended actions can be adopted as standalone\nimprovements or whether they are strategically linked hence requiring a\ncommitment to a broader strategy to be effective, and (iii) characterizing the\nplanning processes of non-RL agents purely through interventions aimed at\nmeasuring strategic link scores - as an example, we consider a realistic\ntraffic simulator and analyze through road closures the effective planning\nhorizon of the emergent routing behavior of many drivers.", "AI": {"tldr": "Strategic link scores quantify dependencies between actions in long-term planning, aiding in explaining RL agents, improving decision systems, and analyzing non-RL agents.", "motivation": "To understand and quantify dependencies between actions in long-term planning, where some actions sacrifice short-term gains for future benefits.", "method": "Introduce strategic link scores to measure the drop in likelihood of a decision if a follow-up is unavailable. Apply these scores to explain RL agents, improve decision systems, and analyze non-RL agents.", "result": "Strategic link scores effectively explain RL agents, enhance decision support systems, and characterize non-RL agent planning processes.", "conclusion": "Strategic link scores provide a valuable tool for analyzing and improving long-term planning strategies across various applications."}}
{"id": "2505.16761", "pdf": "https://arxiv.org/pdf/2505.16761", "abs": "https://arxiv.org/abs/2505.16761", "authors": ["Jian Liu", "Jing Xu", "Song Guo", "Jing Li", "Jingfeng Guo", "Jiaao Yu", "Haohan Weng", "Biwen Lei", "Xianghui Yang", "Zhuo Chen", "Fangqi Zhu", "Tao Han", "Chunchao Guo"], "title": "Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning", "categories": ["cs.CV"], "comment": "Under Review", "summary": "Existing pretrained models for 3D mesh generation often suffer from data\nbiases and produce low-quality results, while global reinforcement learning\n(RL) methods rely on object-level rewards that struggle to capture local\nstructure details. To address these challenges, we present \\textbf{Mesh-RFT}, a\nnovel fine-grained reinforcement fine-tuning framework that employs Masked\nDirect Preference Optimization (M-DPO) to enable localized refinement via\nquality-aware face masking. To facilitate efficient quality evaluation, we\nintroduce an objective topology-aware scoring system to evaluate geometric\nintegrity and topological regularity at both object and face levels through two\nmetrics: Boundary Edge Ratio (BER) and Topology Score (TS). By integrating\nthese metrics into a fine-grained RL strategy, Mesh-RFT becomes the first\nmethod to optimize mesh quality at the granularity of individual faces,\nresolving localized errors while preserving global coherence. Experiment\nresults show that our M-DPO approach reduces Hausdorff Distance (HD) by 24.6\\%\nand improves Topology Score (TS) by 3.8\\% over pre-trained models, while\noutperforming global DPO methods with a 17.4\\% HD reduction and 4.9\\% TS gain.\nThese results demonstrate Mesh-RFT's ability to improve geometric integrity and\ntopological regularity, achieving new state-of-the-art performance in\nproduction-ready mesh generation. Project Page:\n\\href{https://hitcslj.github.io/mesh-rft/}{this https URL}.", "AI": {"tldr": "Mesh-RFT introduces a fine-grained RL framework with M-DPO for localized mesh refinement, improving quality via face-level optimization and topology-aware metrics.", "motivation": "Address biases and low-quality outputs in pretrained 3D mesh models and limitations of global RL methods in capturing local details.", "method": "Uses Masked Direct Preference Optimization (M-DPO) for localized refinement and introduces BER and TS metrics for quality evaluation.", "result": "Reduces Hausdorff Distance by 24.6% and improves Topology Score by 3.8% over pretrained models, outperforming global DPO methods.", "conclusion": "Mesh-RFT achieves state-of-the-art performance in production-ready mesh generation by optimizing at face-level granularity."}}
{"id": "2505.16800", "pdf": "https://arxiv.org/pdf/2505.16800", "abs": "https://arxiv.org/abs/2505.16800", "authors": ["Changbing Yang", "Garrett Nicolai"], "title": "Learning Beyond Limits: Multitask Learning and Synthetic Data for Low-Resource Canonical Morpheme Segmentation", "categories": ["cs.CL"], "comment": null, "summary": "We introduce a transformer-based morpheme segmentation system that augments a\nlow-resource training signal through multitask learning and LLM-generated\nsynthetic data. Our framework jointly predicts morphological segments and\nglosses from orthographic input, leveraging shared linguistic representations\nobtained through a common documentary process to enhance model generalization.\nTo further address data scarcity, we integrate synthetic training data\ngenerated by large language models (LLMs) using in-context learning.\nExperimental results on the SIGMORPHON 2023 dataset show that our approach\nsignificantly improves word-level segmentation accuracy and morpheme-level\nF1-score across multiple low-resource languages.", "AI": {"tldr": "A transformer-based system for morpheme segmentation uses multitask learning and LLM-generated synthetic data to improve accuracy in low-resource languages.", "motivation": "Addressing data scarcity in low-resource languages for morpheme segmentation and gloss prediction.", "method": "Jointly predicts segments and glosses using shared linguistic representations and integrates LLM-generated synthetic data.", "result": "Significant improvements in word-level segmentation accuracy and morpheme-level F1-score on SIGMORPHON 2023 dataset.", "conclusion": "The approach effectively enhances model generalization and performance in low-resource settings."}}
{"id": "2505.16752", "pdf": "https://arxiv.org/pdf/2505.16752", "abs": "https://arxiv.org/abs/2505.16752", "authors": ["Hao Guo", "Erpeng Xue", "Lei Huang", "Shichao Wang", "Xiaolei Wang", "Lei Wang", "Jinpeng Wang", "Sheng Chen"], "title": "Action is All You Need: Dual-Flow Generative Ranking Network for Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "We introduce the Dual-Flow Generative Ranking Network (DFGR), a two-stream\narchitecture designed for recommendation systems. DFGR integrates innovative\ninteraction patterns between real and fake flows within the QKV modules of the\nself-attention mechanism, enhancing both training and inference efficiency.\nThis approach effectively addresses a key limitation observed in Meta's\nproposed HSTU generative recommendation approach, where heterogeneous\ninformation volumes are mapped into identical vector spaces, leading to\ntraining instability. Unlike traditional recommendation models, DFGR only\nrelies on user history behavior sequences and minimal attribute information,\neliminating the need for extensive manual feature engineering. Comprehensive\nevaluations on open-source and industrial datasets reveal DFGR's superior\nperformance compared to established baselines such as DIN, DCN, DIEN, and\nDeepFM. We also investigate optimal parameter allocation strategies under\ncomputational constraints, establishing DFGR as an efficient and effective\nnext-generation generate ranking paradigm.", "AI": {"tldr": "DFGR is a two-stream recommendation model improving efficiency by integrating real and fake flows in self-attention, outperforming baselines like DIN and DeepFM.", "motivation": "Addresses training instability in Meta's HSTU by avoiding mapping heterogeneous data into identical vector spaces.", "method": "Uses a two-stream architecture with QKV module interactions, relying on user history and minimal attributes.", "result": "Superior performance on open-source and industrial datasets compared to DIN, DCN, DIEN, and DeepFM.", "conclusion": "DFGR is an efficient and effective next-generation ranking model, optimized for computational constraints."}}
{"id": "2505.16850", "pdf": "https://arxiv.org/pdf/2505.16850", "abs": "https://arxiv.org/abs/2505.16850", "authors": ["Tajamul Ashraf", "Mohammed Mohsen Peerzada", "Moloud Abdar", "Yutong Xie", "Yuyin Zhou", "Xiaofeng Liu", "Iqra Altaf Gillani", "Janibul Bashir"], "title": "ATR-Bench: A Federated Learning Benchmark for Adaptation, Trust, and Reasoning", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Federated Learning Benchmark for Domain Adaptation, Trustworthiness,\n  and Reasoning", "summary": "Federated Learning (FL) has emerged as a promising paradigm for collaborative\nmodel training while preserving data privacy across decentralized participants.\nAs FL adoption grows, numerous techniques have been proposed to tackle its\npractical challenges. However, the lack of standardized evaluation across key\ndimensions hampers systematic progress and fair comparison of FL methods. In\nthis work, we introduce ATR-Bench, a unified framework for analyzing federated\nlearning through three foundational dimensions: Adaptation, Trust, and\nReasoning. We provide an in-depth examination of the conceptual foundations,\ntask formulations, and open research challenges associated with each theme. We\nhave extensively benchmarked representative methods and datasets for adaptation\nto heterogeneous clients and trustworthiness in adversarial or unreliable\nenvironments. Due to the lack of reliable metrics and models for reasoning in\nFL, we only provide literature-driven insights for this dimension. ATR-Bench\nlays the groundwork for a systematic and holistic evaluation of federated\nlearning with real-world relevance. We will make our complete codebase publicly\naccessible and a curated repository that continuously tracks new developments\nand research in the FL literature.", "AI": {"tldr": "ATR-Bench introduces a unified framework for evaluating Federated Learning (FL) across Adaptation, Trust, and Reasoning dimensions, addressing gaps in standardized evaluation.", "motivation": "The lack of standardized evaluation in FL hampers progress and fair comparison of methods.", "method": "ATR-Bench benchmarks methods and datasets for Adaptation and Trust, while providing literature-driven insights for Reasoning.", "result": "The framework offers systematic evaluation and real-world relevance, with a public codebase and curated repository.", "conclusion": "ATR-Bench advances FL research by enabling holistic and standardized assessment."}}
{"id": "2505.16763", "pdf": "https://arxiv.org/pdf/2505.16763", "abs": "https://arxiv.org/abs/2505.16763", "authors": ["Hongji Yang", "Yucheng Zhou", "Wencheng Han", "Jianbing Shen"], "title": "Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image models are powerful for producing high-quality images based on\ngiven text prompts, but crafting these prompts often requires specialized\nvocabulary. To address this, existing methods train rewriting models with\nsupervision from large amounts of manually annotated data and trained aesthetic\nassessment models. To alleviate the dependence on data scale for model training\nand the biases introduced by trained models, we propose a novel prompt\noptimization framework, designed to rephrase a simple user prompt into a\nsophisticated prompt to a text-to-image model. Specifically, we employ the\nlarge vision language models (LVLMs) as the solver to rewrite the user prompt,\nand concurrently, employ LVLMs as a reward model to score the aesthetics and\nalignment of the images generated by the optimized prompt. Instead of laborious\nhuman feedback, we exploit the prior knowledge of the LVLM to provide rewards,\ni.e., AI feedback. Simultaneously, the solver and the reward model are unified\ninto one model and iterated in reinforcement learning to achieve\nself-improvement by giving a solution and judging itself. Results on two\npopular datasets demonstrate that our method outperforms other strong\ncompetitors.", "AI": {"tldr": "A novel prompt optimization framework uses large vision language models (LVLMs) to rewrite and score prompts for text-to-image models, reducing reliance on manual data and trained models.", "motivation": "Address the need for specialized vocabulary in crafting text prompts for text-to-image models and reduce dependence on large annotated datasets and biased trained models.", "method": "Employ LVLMs as both prompt rewriters and reward models for aesthetics and alignment, using AI feedback instead of human input, and iterating via reinforcement learning.", "result": "Outperforms competitors on two popular datasets.", "conclusion": "The framework effectively optimizes prompts for text-to-image models using LVLMs, achieving self-improvement and reducing manual effort."}}
{"id": "2505.16806", "pdf": "https://arxiv.org/pdf/2505.16806", "abs": "https://arxiv.org/abs/2505.16806", "authors": ["Kexin Zhang", "Junlan Chen", "Daifeng Li", "Yuxuan Zhang", "Yangyang Feng", "Bowen Deng", "Weixu Chen"], "title": "Two-way Evidence self-Alignment based Dual-Gated Reasoning Enhancement", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Large language models (LLMs) encounter difficulties in knowledge-intensive\nmulti-step reasoning (KIMSR) tasks. One challenge is how to effectively extract\nand represent rationale evidence. The current methods often extract\nsemantically relevant but logically irrelevant evidence, resulting in flawed\nreasoning and inaccurate responses. We propose a two-way evidence\nself-alignment (TW-ESA) module, which utilizes the mutual alignment between\nstrict reasoning and LLM reasoning to enhance its understanding of the causal\nlogic of evidence, thereby addressing the first challenge. Another challenge is\nhow to utilize the rationale evidence and LLM's intrinsic knowledge for\naccurate reasoning when the evidence contains uncertainty. We propose a\ndual-gated reasoning enhancement (DGR) module to gradually fuse useful\nknowledge of LLM within strict reasoning, which can enable the model to perform\naccurate reasoning by focusing on causal elements in the evidence and exhibit\ngreater robustness. The two modules are collaboratively trained in a unified\nframework ESA-DGR. Extensive experiments on three diverse and challenging KIMSR\ndatasets reveal that ESA-DGR significantly surpasses state-of-the-art LLM-based\nfine-tuning methods, with remarkable average improvements of 4% in exact match\n(EM) and 5% in F1 score. The implementation code is available at\nhttps://anonymous.4open.science/r/ESA-DGR-2BF8.", "AI": {"tldr": "The paper proposes ESA-DGR, a unified framework with two modules (TW-ESA and DGR) to improve LLMs' performance in knowledge-intensive multi-step reasoning tasks by addressing evidence extraction and reasoning challenges.", "motivation": "LLMs struggle with knowledge-intensive multi-step reasoning tasks due to flawed evidence extraction and reasoning under uncertainty.", "method": "Introduces TW-ESA for evidence self-alignment and DGR for dual-gated reasoning enhancement, trained collaboratively in ESA-DGR.", "result": "ESA-DGR outperforms state-of-the-art methods, achieving 4% EM and 5% F1 score improvements on three datasets.", "conclusion": "ESA-DGR effectively enhances LLMs' reasoning by improving evidence alignment and knowledge fusion, demonstrating superior performance."}}
{"id": "2505.16765", "pdf": "https://arxiv.org/pdf/2505.16765", "abs": "https://arxiv.org/abs/2505.16765", "authors": ["Jianing Geng", "Biao Yi", "Zekun Fei", "Tongxi Wu", "Lihai Nie", "Zheli Liu"], "title": "When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Jailbreak attacks pose a serious threat to large language models (LLMs) by\nbypassing built-in safety mechanisms and leading to harmful outputs. Studying\nthese attacks is crucial for identifying vulnerabilities and improving model\nsecurity. This paper presents a systematic survey of jailbreak methods from the\nnovel perspective of stealth. We find that existing attacks struggle to\nsimultaneously achieve toxic stealth (concealing toxic content) and linguistic\nstealth (maintaining linguistic naturalness). Motivated by this, we propose\nStegoAttack, a fully stealthy jailbreak attack that uses steganography to hide\nthe harmful query within benign, semantically coherent text. The attack then\nprompts the LLM to extract the hidden query and respond in an encrypted manner.\nThis approach effectively hides malicious intent while preserving naturalness,\nallowing it to evade both built-in and external safety mechanisms. We evaluate\nStegoAttack on four safety-aligned LLMs from major providers, benchmarking\nagainst eight state-of-the-art methods. StegoAttack achieves an average attack\nsuccess rate (ASR) of 92.00%, outperforming the strongest baseline by 11.0%.\nIts ASR drops by less than 1% even under external detection (e.g., Llama\nGuard). Moreover, it attains the optimal comprehensive scores on stealth\ndetection metrics, demonstrating both high efficacy and exceptional stealth\ncapabilities. The code is available at\nhttps://anonymous.4open.science/r/StegoAttack-Jail66", "AI": {"tldr": "StegoAttack is a stealthy jailbreak method for LLMs, using steganography to hide harmful queries in benign text, achieving high attack success rates and evading detection.", "motivation": "Existing jailbreak attacks fail to balance toxic and linguistic stealth, prompting the need for a fully stealthy approach.", "method": "StegoAttack employs steganography to embed harmful queries in semantically coherent text, prompting LLMs to extract and respond to the hidden query.", "result": "StegoAttack achieves a 92.00% ASR, outperforming baselines by 11.0%, and maintains high stealth under detection.", "conclusion": "StegoAttack demonstrates superior efficacy and stealth, highlighting its potential for improving LLM security by addressing current vulnerabilities."}}
{"id": "2505.16856", "pdf": "https://arxiv.org/pdf/2505.16856", "abs": "https://arxiv.org/abs/2505.16856", "authors": ["Wei Xiao", "Jiacheng Liu", "Zifeng Zhuang", "Runze Suo", "Shangke Lyu", "Donglin Wang"], "title": "Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Improving the performance of pre-trained policies through online\nreinforcement learning (RL) is a critical yet challenging topic. Existing\nonline RL fine-tuning methods require continued training with offline\npretrained Q-functions for stability and performance. However, these offline\npretrained Q-functions commonly underestimate state-action pairs beyond the\noffline dataset due to the conservatism in most offline RL methods, which\nhinders further exploration when transitioning from the offline to the online\nsetting. Additionally, this requirement limits their applicability in scenarios\nwhere only pre-trained policies are available but pre-trained Q-functions are\nabsent, such as in imitation learning (IL) pre-training. To address these\nchallenges, we propose a method for efficient online RL fine-tuning using\nsolely the offline pre-trained policy, eliminating reliance on pre-trained\nQ-functions. We introduce PORL (Policy-Only Reinforcement Learning\nFine-Tuning), which rapidly initializes the Q-function from scratch during the\nonline phase to avoid detrimental pessimism. Our method not only achieves\ncompetitive performance with advanced offline-to-online RL algorithms and\nonline RL approaches that leverage data or policies prior, but also pioneers a\nnew path for directly fine-tuning behavior cloning (BC) policies.", "AI": {"tldr": "PORL enables efficient online RL fine-tuning using only pre-trained policies, avoiding reliance on pre-trained Q-functions and addressing conservatism issues.", "motivation": "Existing methods require pre-trained Q-functions, limiting applicability and hindering exploration due to conservatism in offline RL.", "method": "PORL initializes Q-functions from scratch during online phase to avoid pessimism, leveraging only pre-trained policies.", "result": "PORL achieves competitive performance with advanced offline-to-online RL and online RL methods, and enables direct fine-tuning of BC policies.", "conclusion": "PORL provides a novel, efficient approach for online RL fine-tuning without pre-trained Q-functions, expanding applicability."}}
{"id": "2505.16770", "pdf": "https://arxiv.org/pdf/2505.16770", "abs": "https://arxiv.org/abs/2505.16770", "authors": ["Meng-Hao Guo", "Xuanyu Chu", "Qianrui Yang", "Zhe-Han Mo", "Yiqing Shen", "Pei-lin Li", "Xinjie Lin", "Jinnian Zhang", "Xin-Sheng Chen", "Yi Zhang", "Kiyohiro Nakayama", "Zhengyang Geng", "Houwen Peng", "Han Hu", "Shi-Nin Hu"], "title": "RBench-V: A Primary Assessment for Visual Reasoning Models with Multi-modal Outputs", "categories": ["cs.CV"], "comment": "12 pages", "summary": "The rapid advancement of native multi-modal models and omni-models,\nexemplified by GPT-4o, Gemini, and o3, with their capability to process and\ngenerate content across modalities such as text and images, marks a significant\nmilestone in the evolution of intelligence. Systematic evaluation of their\nmulti-modal output capabilities in visual thinking processes (also known as\nmulti-modal chain of thought, M-CoT) becomes critically important. However,\nexisting benchmarks for evaluating multi-modal models primarily focus on\nassessing multi-modal inputs and text-only reasoning while neglecting the\nimportance of reasoning through multi-modal outputs. In this paper, we present\na benchmark, dubbed RBench-V, designed to assess models' vision-indispensable\nreasoning abilities. To construct RBench-V, we carefully hand-pick 803\nquestions covering math, physics, counting, and games. Unlike previous\nbenchmarks that typically specify certain input modalities, RBench-V presents\nproblems centered on multi-modal outputs, which require image manipulation such\nas generating novel images and constructing auxiliary lines to support the\nreasoning process. We evaluate numerous open- and closed-source models on\nRBench-V, including o3, Gemini 2.5 Pro, Qwen2.5-VL, etc. Even the\nbest-performing model, o3, achieves only 25.8% accuracy on RBench-V, far below\nthe human score of 82.3%, highlighting that current models struggle to leverage\nmulti-modal reasoning. Data and code are available at\nhttps://evalmodels.github.io/rbenchv", "AI": {"tldr": "A new benchmark, RBench-V, evaluates multi-modal models' reasoning abilities through vision-indispensable tasks, revealing significant gaps compared to human performance.", "motivation": "Existing benchmarks overlook multi-modal output reasoning, focusing only on inputs and text-based reasoning, necessitating a tool like RBench-V.", "method": "RBench-V includes 803 questions requiring image manipulation (e.g., generating images, drawing auxiliary lines) to solve problems in math, physics, counting, and games.", "result": "Top models like o3 achieve only 25.8% accuracy on RBench-V, far below the human score of 82.3%.", "conclusion": "Current multi-modal models struggle with vision-based reasoning, highlighting the need for further advancements in this area."}}
{"id": "2505.16814", "pdf": "https://arxiv.org/pdf/2505.16814", "abs": "https://arxiv.org/abs/2505.16814", "authors": ["Gaurav Kamath", "Sowmya Vajjala"], "title": "Does Synthetic Data Help Named Entity Recognition for Low-Resource Languages?", "categories": ["cs.CL"], "comment": "pre-print", "summary": "Named Entity Recognition(NER) for low-resource languages aims to produce\nrobust systems for languages where there is limited labeled training data\navailable, and has been an area of increasing interest within NLP. Data\naugmentation for increasing the amount of low-resource labeled data is a common\npractice. In this paper, we explore the role of synthetic data in the context\nof multilingual, low-resource NER, considering 11 languages from diverse\nlanguage families. Our results suggest that synthetic data does in fact hold\npromise for low-resource language NER, though we see significant variation\nbetween languages.", "AI": {"tldr": "Synthetic data shows promise for improving NER in low-resource languages, but effectiveness varies across languages.", "motivation": "Addressing the challenge of limited labeled training data for NER in low-resource languages.", "method": "Exploring synthetic data augmentation for multilingual NER across 11 diverse languages.", "result": "Synthetic data helps, but performance varies significantly between languages.", "conclusion": "Synthetic data is a viable but inconsistent solution for low-resource NER."}}
{"id": "2505.16773", "pdf": "https://arxiv.org/pdf/2505.16773", "abs": "https://arxiv.org/abs/2505.16773", "authors": ["Iv\u00e1n Matas", "Carmen Serrano", "Miguel Nogales", "David Moreno", "Lara Ferr\u00e1ndiz", "Teresa Ojeda", "Bego\u00f1a Acha"], "title": "Mitigating Overfitting in Medical Imaging: Self-Supervised Pretraining vs. ImageNet Transfer Learning for Dermatological Diagnosis", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 2 tables, 2 figures", "summary": "Deep learning has transformed computer vision but relies heavily on large\nlabeled datasets and computational resources. Transfer learning, particularly\nfine-tuning pretrained models, offers a practical alternative; however, models\npretrained on natural image datasets such as ImageNet may fail to capture\ndomain-specific characteristics in medical imaging. This study introduces an\nunsupervised learning framework that extracts high-value dermatological\nfeatures instead of relying solely on ImageNet-based pretraining. We employ a\nVariational Autoencoder (VAE) trained from scratch on a proprietary\ndermatological dataset, allowing the model to learn a structured and clinically\nrelevant latent space. This self-supervised feature extractor is then compared\nto an ImageNet-pretrained backbone under identical classification conditions,\nhighlighting the trade-offs between general-purpose and domain-specific\npretraining. Our results reveal distinct learning patterns. The self-supervised\nmodel achieves a final validation loss of 0.110 (-33.33%), while the\nImageNet-pretrained model stagnates at 0.100 (-16.67%), indicating overfitting.\nAccuracy trends confirm this: the self-supervised model improves from 45% to\n65% (+44.44%) with a near-zero overfitting gap, whereas the ImageNet-pretrained\nmodel reaches 87% (+50.00%) but plateaus at 75% (+19.05%), with its overfitting\ngap increasing to +0.060. These findings suggest that while ImageNet\npretraining accelerates convergence, it also amplifies overfitting on\nnon-clinically relevant features. In contrast, self-supervised learning\nachieves steady improvements, stronger generalization, and superior\nadaptability, underscoring the importance of domain-specific feature extraction\nin medical imaging.", "AI": {"tldr": "The paper introduces an unsupervised learning framework using a VAE for dermatological feature extraction, outperforming ImageNet-pretrained models in generalization and adaptability.", "motivation": "Address the limitations of transfer learning with ImageNet-pretrained models in medical imaging by developing a domain-specific, self-supervised approach.", "method": "Train a Variational Autoencoder (VAE) on a dermatological dataset to learn clinically relevant features, then compare it to an ImageNet-pretrained model under identical classification conditions.", "result": "The self-supervised model shows steady improvement (validation loss: -33.33%, accuracy: +44.44%) with minimal overfitting, while the ImageNet model overfits (overfitting gap: +0.060) despite faster convergence.", "conclusion": "Domain-specific self-supervised learning offers better generalization and adaptability in medical imaging compared to general-purpose pretraining."}}
{"id": "2505.16857", "pdf": "https://arxiv.org/pdf/2505.16857", "abs": "https://arxiv.org/abs/2505.16857", "authors": ["Ertu\u011frul Ke\u00e7eci", "M\u00fcjde G\u00fczelkaya", "Tufan Kumbasar"], "title": "Redefining Clustered Federated Learning for System Identification: The Path of ClusterCraft", "categories": ["cs.LG", "I.2.8; I.5.3; I.2.11"], "comment": null, "summary": "This paper addresses the System Identification (SYSID) problem within the\nframework of federated learning. We introduce a novel algorithm, Incremental\nClustering-based federated learning method for SYSID (IC-SYSID), designed to\ntackle SYSID challenges across multiple data sources without prior knowledge.\nIC-SYSID utilizes an incremental clustering method, ClusterCraft (CC), to\neliminate the dependency on the prior knowledge of the dataset. CC starts with\na single cluster model and assigns similar local workers to the same clusters\nby dynamically increasing the number of clusters. To reduce the number of\nclusters generated by CC, we introduce ClusterMerge, where similar cluster\nmodels are merged. We also introduce enhanced ClusterCraft to reduce the\ngeneration of similar cluster models during the training. Moreover, IC-SYSID\naddresses cluster model instability by integrating a regularization term into\nthe loss function and initializing cluster models with scaled Glorot\ninitialization. It also utilizes a mini-batch deep learning approach to manage\nlarge SYSID datasets during local training. Through the experiments conducted\non a real-world representing SYSID problem, where a fleet of vehicles\ncollaboratively learns vehicle dynamics, we show that IC-SYSID achieves a high\nSYSID performance while preventing the learning of unstable clusters.", "AI": {"tldr": "The paper introduces IC-SYSID, a federated learning algorithm for System Identification (SYSID), using incremental clustering (ClusterCraft) and merging (ClusterMerge) to handle multiple data sources without prior knowledge. It improves stability and performance in real-world SYSID tasks.", "motivation": "To solve the SYSID problem in federated learning without relying on prior knowledge of datasets, addressing challenges like instability and scalability.", "method": "IC-SYSID employs ClusterCraft for incremental clustering, ClusterMerge to reduce redundant clusters, regularization for stability, and mini-batch deep learning for large datasets.", "result": "IC-SYSID achieves high SYSID performance and prevents unstable clusters in real-world vehicle dynamics learning.", "conclusion": "IC-SYSID effectively addresses SYSID challenges in federated learning, offering a scalable and stable solution."}}
{"id": "2505.16778", "pdf": "https://arxiv.org/pdf/2505.16778", "abs": "https://arxiv.org/abs/2505.16778", "authors": ["Xianing Chen", "Si Huo", "Borui Jiang", "Hailin Hu", "Xinghao Chen"], "title": "Single Domain Generalization for Few-Shot Counting via Universal Representation Matching", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Few-shot counting estimates the number of target objects in an image using\nonly a few annotated exemplars. However, domain shift severely hinders existing\nmethods to generalize to unseen scenarios. This falls into the realm of single\ndomain generalization that remains unexplored in few-shot counting. To solve\nthis problem, we begin by analyzing the main limitations of current methods,\nwhich typically follow a standard pipeline that extract the object prototypes\nfrom exemplars and then match them with image feature to construct the\ncorrelation map. We argue that existing methods overlook the significance of\nlearning highly generalized prototypes. Building on this insight, we propose\nthe first single domain generalization few-shot counting model, Universal\nRepresentation Matching, termed URM. Our primary contribution is the discovery\nthat incorporating universal vision-language representations distilled from a\nlarge scale pretrained vision-language model into the correlation construction\nprocess substantially improves robustness to domain shifts without compromising\nin domain performance. As a result, URM achieves state-of-the-art performance\non both in domain and the newly introduced domain generalization setting.", "AI": {"tldr": "URM introduces universal vision-language representations to improve few-shot counting's robustness to domain shifts, achieving state-of-the-art performance.", "motivation": "Existing few-shot counting methods struggle with domain shifts, limiting generalization to unseen scenarios.", "method": "URM leverages universal vision-language representations from a pretrained model to enhance prototype generalization and correlation map construction.", "result": "URM outperforms existing methods in both in-domain and domain generalization settings.", "conclusion": "URM addresses domain shift challenges in few-shot counting by integrating universal representations, setting a new benchmark."}}
{"id": "2505.16831", "pdf": "https://arxiv.org/pdf/2505.16831", "abs": "https://arxiv.org/abs/2505.16831", "authors": ["Xiaoyu Xu", "Xiang Yue", "Yang Liu", "Qingqing Ye", "Haibo Hu", "Minxin Du"], "title": "Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "comment": "44 pages", "summary": "Unlearning in large language models (LLMs) is intended to remove the\ninfluence of specific data, yet current evaluations rely heavily on token-level\nmetrics such as accuracy and perplexity. We show that these metrics can be\nmisleading: models often appear to forget, but their original behavior can be\nrapidly restored with minimal fine-tuning, revealing that unlearning may\nobscure information rather than erase it. To diagnose this phenomenon, we\nintroduce a representation-level evaluation framework using PCA-based\nsimilarity and shift, centered kernel alignment, and Fisher information.\nApplying this toolkit across six unlearning methods, three domains (text, code,\nmath), and two open-source LLMs, we uncover a critical distinction between\nreversible and irreversible forgetting. In reversible cases, models suffer\ntoken-level collapse yet retain latent features; in irreversible cases, deeper\nrepresentational damage occurs. We further provide a theoretical account\nlinking shallow weight perturbations near output layers to misleading\nunlearning signals, and show that reversibility is modulated by task type and\nhyperparameters. Our findings reveal a fundamental gap in current evaluation\npractices and establish a new diagnostic foundation for trustworthy unlearning\nin LLMs. We provide a unified toolkit for analyzing LLM representation changes\nunder unlearning and relearning:\nhttps://github.com/XiaoyuXU1/Representational_Analysis_Tools.git.", "AI": {"tldr": "Current unlearning evaluations in LLMs rely on misleading token-level metrics. A new framework reveals reversible vs. irreversible forgetting, showing unlearning may obscure, not erase, data.", "motivation": "To address the inadequacy of token-level metrics in evaluating unlearning in LLMs, which can falsely indicate forgetting while latent features remain.", "method": "Introduces a representation-level evaluation framework using PCA-based similarity, shift, centered kernel alignment, and Fisher information, tested across six unlearning methods, three domains, and two LLMs.", "result": "Identifies reversible (token-level collapse but latent retention) and irreversible (deeper damage) forgetting, linking reversibility to task type and hyperparameters.", "conclusion": "Highlights a gap in current evaluation practices and provides a toolkit for trustworthy unlearning analysis in LLMs."}}
{"id": "2505.16785", "pdf": "https://arxiv.org/pdf/2505.16785", "abs": "https://arxiv.org/abs/2505.16785", "authors": ["Zhenzhen Ren", "GuoBiao Li", "Sheng Li", "Zhenxing Qian", "Xinpeng Zhang"], "title": "CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Despite providing superior performance, open-source large language models\n(LLMs) are vulnerable to abusive usage. To address this issue, recent works\npropose LLM fingerprinting methods to identify the specific source LLMs behind\nsuspect applications. However, these methods fail to provide stealthy and\nrobust fingerprint verification. In this paper, we propose a novel LLM\nfingerprinting scheme, namely CoTSRF, which utilizes the Chain of Thought (CoT)\nas the fingerprint of an LLM. CoTSRF first collects the responses from the\nsource LLM by querying it with crafted CoT queries. Then, it applies\ncontrastive learning to train a CoT extractor that extracts the CoT feature\n(i.e., fingerprint) from the responses. Finally, CoTSRF conducts fingerprint\nverification by comparing the Kullback-Leibler divergence between the CoT\nfeatures of the source and suspect LLMs against an empirical threshold. Various\nexperiments have been conducted to demonstrate the advantage of our proposed\nCoTSRF for fingerprinting LLMs, particularly in stealthy and robust fingerprint\nverification.", "AI": {"tldr": "CoTSRF is a novel LLM fingerprinting method using Chain of Thought (CoT) for stealthy and robust verification.", "motivation": "Open-source LLMs are vulnerable to abuse; existing fingerprinting methods lack stealth and robustness.", "method": "CoTSRF collects CoT responses, trains a CoT extractor via contrastive learning, and verifies fingerprints using KL divergence.", "result": "CoTSRF outperforms in stealthy and robust fingerprint verification.", "conclusion": "CoTSRF effectively addresses the limitations of existing LLM fingerprinting methods."}}
{"id": "2505.16860", "pdf": "https://arxiv.org/pdf/2505.16860", "abs": "https://arxiv.org/abs/2505.16860", "authors": ["Ziyue Qiao", "Qianyi Cai", "Hao Dong", "Jiawei Gu", "Pengyang Wang", "Meng Xiao", "Xiao Luo", "Hui Xiong"], "title": "GCAL: Adapting Graph Models to Evolving Domain Shifts", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "This paper addresses the challenge of graph domain adaptation on evolving,\nmultiple out-of-distribution (OOD) graphs. Conventional graph domain adaptation\nmethods are confined to single-step adaptation, making them ineffective in\nhandling continuous domain shifts and prone to catastrophic forgetting. This\npaper introduces the Graph Continual Adaptive Learning (GCAL) method, designed\nto enhance model sustainability and adaptability across various graph domains.\nGCAL employs a bilevel optimization strategy. The \"adapt\" phase uses an\ninformation maximization approach to fine-tune the model with new graph domains\nwhile re-adapting past memories to mitigate forgetting. Concurrently, the\n\"generate memory\" phase, guided by a theoretical lower bound derived from\ninformation bottleneck theory, involves a variational memory graph generation\nmodule to condense original graphs into memories. Extensive experimental\nevaluations demonstrate that GCAL substantially outperforms existing methods in\nterms of adaptability and knowledge retention.", "AI": {"tldr": "GCAL introduces a bilevel optimization strategy for graph domain adaptation, addressing continuous domain shifts and catastrophic forgetting.", "motivation": "Traditional methods fail in handling evolving, multiple OOD graphs due to single-step adaptation limitations.", "method": "GCAL uses a bilevel approach: 'adapt' phase for fine-tuning and 'generate memory' phase for condensing graphs into memories.", "result": "GCAL outperforms existing methods in adaptability and knowledge retention.", "conclusion": "GCAL effectively enhances sustainability and adaptability in graph domain adaptation."}}
{"id": "2505.16784", "pdf": "https://arxiv.org/pdf/2505.16784", "abs": "https://arxiv.org/abs/2505.16784", "authors": ["Jun Xie", "Xiongjun Guan", "Yingjian Zhu", "Zhaoran Zhao", "Xinming Wang", "Feng Chen", "Zhepeng Wang"], "title": "Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we present the runner-up solution for the Ego4D EgoSchema\nChallenge at CVPR 2025 (Confirmed on May 20, 2025). Inspired by the success of\nlarge models, we evaluate and leverage leading accessible multimodal large\nmodels and adapt them to video understanding tasks via few-shot learning and\nmodel ensemble strategies. Specifically, diversified prompt styles and process\nparadigms are systematically explored and evaluated to effectively guide the\nattention of large models, fully unleashing their powerful generalization and\nadaptability abilities. Experimental results demonstrate that, with our\ncarefully designed approach, directly utilizing an individual multimodal model\nalready outperforms the previous state-of-the-art (SOTA) method which includes\nseveral additional processes. Besides, an additional stage is further\nintroduced that facilitates the cooperation and ensemble of periodic results,\nwhich achieves impressive performance improvements. We hope this work serves as\na valuable reference for the practical application of large models and inspires\nfuture research in the field.", "AI": {"tldr": "Runner-up solution for Ego4D EgoSchema Challenge at CVPR 2025, leveraging multimodal large models for video understanding via few-shot learning and ensemble strategies.", "motivation": "To adapt and evaluate leading multimodal large models for video tasks, exploring prompt styles and process paradigms to enhance model attention and generalization.", "method": "Utilizes few-shot learning and model ensemble strategies, with diversified prompts and process paradigms, and introduces a cooperative ensemble stage.", "result": "Outperforms previous SOTA with a single model; ensemble stage further improves performance.", "conclusion": "Provides a practical reference for large model applications and inspires future research."}}
{"id": "2505.16834", "pdf": "https://arxiv.org/pdf/2505.16834", "abs": "https://arxiv.org/abs/2505.16834", "authors": ["Shuang Sun", "Huatong Song", "Yuhao Wang", "Ruiyang Ren", "Jinhao Jiang", "Junjie Zhang", "Fei Bai", "Jia Deng", "Wayne Xin Zhao", "Zheng Liu", "Lei Fang", "Zhongyuan Wang", "Ji-Rong Wen"], "title": "SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems have advanced large language\nmodels (LLMs) in complex deep search scenarios requiring multi-step reasoning\nand iterative information retrieval. However, existing approaches face critical\nlimitations that lack high-quality training trajectories or suffer from the\ndistributional mismatches in simulated environments and prohibitive\ncomputational costs for real-world deployment. This paper introduces\nSimpleDeepSearcher, a lightweight yet effective framework that bridges this gap\nthrough strategic data engineering rather than complex training paradigms. Our\napproach synthesizes high-quality training data by simulating realistic user\ninteractions in live web search environments, coupled with a multi-criteria\ncuration strategy that optimizes the diversity and quality of input and output\nside. Experiments on five benchmarks across diverse domains demonstrate that\nSFT on only 871 curated samples yields significant improvements over RL-based\nbaselines. Our work establishes SFT as a viable pathway by systematically\naddressing the data-scarce bottleneck, offering practical insights for\nefficient deep search systems. Our code is available at\nhttps://github.com/RUCAIBox/SimpleDeepSearcher.", "AI": {"tldr": "SimpleDeepSearcher is a lightweight framework for retrieval-augmented generation, using strategic data engineering to overcome training limitations and improve deep search systems.", "motivation": "Existing RAG systems lack high-quality training data or face distribution mismatches and high computational costs, hindering real-world deployment.", "method": "The framework synthesizes high-quality training data by simulating realistic user interactions in live web search environments and uses multi-criteria curation for diversity and quality.", "result": "Experiments on five benchmarks show significant improvements over RL-based baselines using only 871 curated samples.", "conclusion": "SimpleDeepSearcher demonstrates that SFT can effectively address data scarcity, offering practical insights for efficient deep search systems."}}
{"id": "2505.16792", "pdf": "https://arxiv.org/pdf/2505.16792", "abs": "https://arxiv.org/abs/2505.16792", "authors": ["Ziqiao Wang", "Wangbo Zhao", "Yuhao Zhou", "Zekai Li", "Zhiyuan Liang", "Mingjia Shi", "Xuanlei Zhao", "Pengfei Zhou", "Kaipeng Zhang", "Zhangyang Wang", "Kai Wang", "Yang You"], "title": "REPA Works Until It Doesn't: Early-Stopped, Holistic Alignment Supercharges Diffusion Training", "categories": ["cs.CV", "cs.AI"], "comment": "24 pages", "summary": "Diffusion Transformers (DiTs) deliver state-of-the-art image quality, yet\ntheir training remains notoriously slow. A recent remedy -- representation\nalignment (REPA) that matches DiT hidden features to those of a non-generative\nteacher (e.g. DINO) -- dramatically accelerates the early epochs but plateaus\nor even degrades performance later. We trace this failure to a capacity\nmismatch: once the generative student begins modelling the joint data\ndistribution, the teacher's lower-dimensional embeddings and attention patterns\nbecome a straitjacket rather than a guide. We then introduce HASTE (Holistic\nAlignment with Stage-wise Termination for Efficient training), a two-phase\nschedule that keeps the help and drops the hindrance. Phase I applies a\nholistic alignment loss that simultaneously distills attention maps (relational\npriors) and feature projections (semantic anchors) from the teacher into\nmid-level layers of the DiT, yielding rapid convergence. Phase II then performs\none-shot termination that deactivates the alignment loss, once a simple trigger\nsuch as a fixed iteration is hit, freeing the DiT to focus on denoising and\nexploit its generative capacity. HASTE speeds up training of diverse DiTs\nwithout architecture changes. On ImageNet 256X256, it reaches the vanilla\nSiT-XL/2 baseline FID in 50 epochs and matches REPA's best FID in 500 epochs,\namounting to a 28X reduction in optimization steps. HASTE also improves\ntext-to-image DiTs on MS-COCO, demonstrating to be a simple yet principled\nrecipe for efficient diffusion training across various tasks. Our code is\navailable at https://github.com/NUS-HPC-AI-Lab/HASTE .", "AI": {"tldr": "HASTE accelerates DiT training by aligning teacher features early and terminating alignment later, improving efficiency without architecture changes.", "motivation": "Training Diffusion Transformers (DiTs) is slow, and existing methods like REPA plateau or degrade performance. HASTE addresses this by dynamically aligning and then freeing the model.", "method": "HASTE uses a two-phase schedule: Phase I aligns teacher features and attention maps into the DiT; Phase II terminates alignment to focus on denoising.", "result": "HASTE speeds up training, achieving baseline FID in 50 epochs and matching REPA's best FID in 500 epochs (28x faster). It also improves text-to-image DiTs.", "conclusion": "HASTE is a simple, effective method for efficient DiT training across tasks, demonstrated on ImageNet and MS-COCO."}}
{"id": "2505.16872", "pdf": "https://arxiv.org/pdf/2505.16872", "abs": "https://arxiv.org/abs/2505.16872", "authors": ["Mohammed Al-Qudah", "Fadi AlMahamid"], "title": "A Multi-Step Comparative Framework for Anomaly Detection in IoT Data Streams", "categories": ["cs.LG"], "comment": null, "summary": "The rapid expansion of Internet of Things (IoT) devices has introduced\ncritical security challenges, underscoring the need for accurate anomaly\ndetection. Although numerous studies have proposed machine learning (ML)\nmethods for this purpose, limited research systematically examines how\ndifferent preprocessing steps--normalization, transformation, and feature\nselection--interact with distinct model architectures. To address this gap,\nthis paper presents a multi-step evaluation framework assessing the combined\nimpact of preprocessing choices on three ML algorithms: RNN-LSTM, autoencoder\nneural networks (ANN), and Gradient Boosting (GBoosting). Experiments on the\nIoTID20 dataset shows that GBoosting consistently delivers superior accuracy\nacross preprocessing configurations, while RNN-LSTM shows notable gains with\nz-score normalization and autoencoders excel in recall, making them well-suited\nfor unsupervised scenarios. By offering a structured analysis of preprocessing\ndecisions and their interplay with various ML techniques, the proposed\nframework provides actionable guidance to enhance anomaly detection performance\nin IoT environments.", "AI": {"tldr": "The paper evaluates how preprocessing steps (normalization, transformation, feature selection) affect three ML models (RNN-LSTM, ANN, GBoosting) for IoT anomaly detection, finding GBoosting most accurate overall.", "motivation": "Addresses the lack of systematic research on how preprocessing steps interact with ML models for IoT anomaly detection.", "method": "Proposes a multi-step evaluation framework to assess preprocessing impacts on RNN-LSTM, ANN, and GBoosting using the IoTID20 dataset.", "result": "GBoosting performs best across preprocessing configurations, RNN-LSTM benefits from z-score normalization, and ANN excels in recall for unsupervised scenarios.", "conclusion": "The framework provides actionable insights to improve anomaly detection in IoT by analyzing preprocessing and ML model interactions."}}
{"id": "2505.16793", "pdf": "https://arxiv.org/pdf/2505.16793", "abs": "https://arxiv.org/abs/2505.16793", "authors": ["Xiang Li", "Yong Tao", "Siyuan Zhang", "Siwei Liu", "Zhitong Xiong", "Chunbo Luo", "Lu Liu", "Mykola Pechenizkiy", "Xiao Xiang Zhu", "Tianjin Huang"], "title": "REOBench: Benchmarking Robustness of Earth Observation Foundation Models", "categories": ["cs.CV"], "comment": "24 pages", "summary": "Earth observation foundation models have shown strong generalization across\nmultiple Earth observation tasks, but their robustness under real-world\nperturbations remains underexplored. To bridge this gap, we introduce REOBench,\nthe first comprehensive benchmark for evaluating the robustness of Earth\nobservation foundation models across six tasks and twelve types of image\ncorruptions, including both appearance-based and geometric perturbations. To\nensure realistic and fine-grained evaluation, our benchmark focuses on\nhigh-resolution optical remote sensing images, which are widely used in\ncritical applications such as urban planning and disaster response. We conduct\na systematic evaluation of a broad range of models trained using masked image\nmodeling, contrastive learning, and vision-language pre-training paradigms. Our\nresults reveal that (1) existing Earth observation foundation models experience\nsignificant performance degradation when exposed to input corruptions. (2) The\nseverity of degradation varies across tasks, model architectures, backbone\nsizes, and types of corruption, with performance drop varying from less than 1%\nto over 20%. (3) Vision-language models show enhanced robustness, particularly\nin multimodal tasks. REOBench underscores the vulnerability of current Earth\nobservation foundation models to real-world corruptions and provides actionable\ninsights for developing more robust and reliable models.", "AI": {"tldr": "REOBench evaluates Earth observation foundation models' robustness under real-world perturbations, revealing performance degradation and task-specific vulnerabilities.", "motivation": "To address the underexplored robustness of Earth observation foundation models under real-world perturbations.", "method": "Introduces REOBench, a benchmark with six tasks and twelve image corruptions, evaluating models trained via masked image modeling, contrastive learning, and vision-language pre-training.", "result": "Performance degradation varies (1%-20%), with vision-language models showing enhanced robustness.", "conclusion": "REOBench highlights vulnerabilities and provides insights for developing more robust models."}}
{"id": "2505.16838", "pdf": "https://arxiv.org/pdf/2505.16838", "abs": "https://arxiv.org/abs/2505.16838", "authors": ["Yibo Wang", "Li Shen", "Huanjin Yao", "Tiansheng Huang", "Rui Liu", "Naiqiang Tan", "Jiaxing Huang", "Kai Zhang", "Dacheng Tao"], "title": "R1-Compress: Long Chain-of-Thought Compression via Chunk Compression and Search", "categories": ["cs.CL"], "comment": null, "summary": "Chain-of-Thought (CoT) reasoning enhances large language models (LLMs) by\nenabling step-by-step problem-solving, yet its extension to Long-CoT introduces\nsubstantial computational overhead due to increased token length. Existing\ncompression approaches -- instance-level and token-level -- either sacrifice\nessential local reasoning signals like reflection or yield incoherent outputs.\nTo address these limitations, we propose R1-Compress, a two-stage chunk-level\ncompression framework that preserves both local information and coherence. Our\nmethod segments Long-CoT into manageable chunks, applies LLM-driven inner-chunk\ncompression, and employs an inter-chunk search mechanism to select the short\nand coherent sequence. Experiments on Qwen2.5-Instruct models across MATH500,\nAIME24, and GPQA-Diamond demonstrate that R1-Compress significantly reduces\ntoken usage while maintaining comparable reasoning accuracy. On MATH500,\nR1-Compress achieves an accuracy of 92.4%, with only a 0.6% drop compared to\nthe Long-CoT baseline, while reducing token usage by about 20%. Source code\nwill be available at https://github.com/w-yibo/R1-Compress", "AI": {"tldr": "R1-Compress is a two-stage chunk-level compression framework for Long-CoT reasoning, reducing token usage by 20% with minimal accuracy drop.", "motivation": "Existing compression methods for Long-CoT either lose local reasoning signals or produce incoherent outputs, prompting the need for a balanced solution.", "method": "Segments Long-CoT into chunks, applies LLM-driven inner-chunk compression, and uses inter-chunk search for coherence.", "result": "Achieves 92.4% accuracy on MATH500 with only a 0.6% drop from baseline, reducing tokens by ~20%.", "conclusion": "R1-Compress effectively balances compression and reasoning accuracy, offering a practical solution for Long-CoT."}}
{"id": "2505.16813", "pdf": "https://arxiv.org/pdf/2505.16813", "abs": "https://arxiv.org/abs/2505.16813", "authors": ["Yinhao Xu", "Georg A. Gottwald", "Zdenka Kuncic"], "title": "Dynamic Reservoir Computing with Physical Neuromorphic Networks", "categories": ["cs.ET", "cond-mat.dis-nn", "cs.AI"], "comment": "8 pages, 8 figures, IJCNN 2025, accepted", "summary": "Reservoir Computing (RC) with physical systems requires an understanding of\nthe underlying structure and internal dynamics of the specific physical\nreservoir. In this study, physical nano-electronic networks with neuromorphic\ndynamics are investigated for their use as physical reservoirs in an RC\nframework. These neuromorphic networks operate as dynamic reservoirs, with node\nactivities in general coupled to the edge dynamics through nonlinear\nnano-electronic circuit elements, and the reservoir outputs influenced by the\nunderlying network connectivity structure. This study finds that networks with\nvarying degrees of sparsity generate more useful nonlinear temporal outputs for\ndynamic RC compared to dense networks. Dynamic RC is also tested on an\nautonomous multivariate chaotic time series prediction task with networks of\nvarying densities, which revealed the importance of network sparsity in\nmaintaining network activity and overall dynamics, that in turn enabled the\nlearning of the chaotic Lorenz63 system's attractor behavior.", "AI": {"tldr": "Sparse neuromorphic nano-electronic networks outperform dense ones in Reservoir Computing for chaotic time series prediction.", "motivation": "To explore how physical nano-electronic networks with neuromorphic dynamics can serve as effective reservoirs in Reservoir Computing (RC).", "method": "Investigating networks with varying sparsity levels, analyzing their nonlinear temporal outputs, and testing on chaotic Lorenz63 system prediction.", "result": "Sparse networks generate more useful nonlinear outputs and maintain better dynamics for learning chaotic attractor behavior.", "conclusion": "Network sparsity is crucial for effective dynamic RC, particularly in chaotic time series tasks."}}
{"id": "2505.16896", "pdf": "https://arxiv.org/pdf/2505.16896", "abs": "https://arxiv.org/abs/2505.16896", "authors": ["Can Chen", "David Heurtel-Depeiges", "Robert M. Vernon", "Christopher James Langmead", "Yoshua Bengio", "Quentin Fournier"], "title": "Structure-Aligned Protein Language Model", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 8 figures, 7 tables", "summary": "Protein language models (pLMs) pre-trained on vast protein sequence databases\nexcel at various downstream tasks but lack the structural knowledge essential\nfor many biological applications. To address this, we integrate structural\ninsights from pre-trained protein graph neural networks (pGNNs) into pLMs\nthrough a latent-level contrastive learning task. This task aligns residue\nrepresentations from pLMs with those from pGNNs across multiple proteins,\nenriching pLMs with inter-protein structural knowledge. Additionally, we\nincorporate a physical-level task that infuses intra-protein structural\nknowledge by optimizing pLMs to predict structural tokens. The proposed\ndual-task framework effectively incorporates both inter-protein and\nintra-protein structural knowledge into pLMs. Given the variability in the\nquality of protein structures in PDB, we further introduce a residue loss\nselection module, which uses a small model trained on high-quality structures\nto select reliable yet challenging residue losses for the pLM to learn.\nApplying our structure alignment method to the state-of-the-art ESM2 and\nAMPLIFY results in notable performance gains across a wide range of tasks,\nincluding a 12.7% increase in ESM2 contact prediction. The data, code, and\nresulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.", "AI": {"tldr": "The paper introduces a dual-task framework to integrate structural knowledge into protein language models (pLMs) using contrastive learning and structural token prediction, improving performance on tasks like contact prediction.", "motivation": "Current pLMs lack structural knowledge, limiting their effectiveness in biological applications.", "method": "Combines latent-level contrastive learning (aligning pLM and pGNN representations) and a physical-level task (predicting structural tokens). Includes a residue loss selection module for reliable learning.", "result": "Notable performance gains, e.g., 12.7% increase in ESM2 contact prediction.", "conclusion": "The framework successfully enriches pLMs with structural knowledge, enhancing their utility for biological tasks."}}
{"id": "2505.16797", "pdf": "https://arxiv.org/pdf/2505.16797", "abs": "https://arxiv.org/abs/2505.16797", "authors": ["Hanyue Lou", "Jinxiu Liang", "Minggui Teng", "Yi Wang", "Boxin Shi"], "title": "V2V: Scaling Event-Based Vision through Efficient Video-to-Voxel Simulation", "categories": ["cs.CV"], "comment": null, "summary": "Event-based cameras offer unique advantages such as high temporal resolution,\nhigh dynamic range, and low power consumption. However, the massive storage\nrequirements and I/O burdens of existing synthetic data generation pipelines\nand the scarcity of real data prevent event-based training datasets from\nscaling up, limiting the development and generalization capabilities of event\nvision models. To address this challenge, we introduce Video-to-Voxel (V2V), an\napproach that directly converts conventional video frames into event-based\nvoxel grid representations, bypassing the storage-intensive event stream\ngeneration entirely. V2V enables a 150 times reduction in storage requirements\nwhile supporting on-the-fly parameter randomization for enhanced model\nrobustness. Leveraging this efficiency, we train several video reconstruction\nand optical flow estimation model architectures on 10,000 diverse videos\ntotaling 52 hours--an order of magnitude larger than existing event datasets,\nyielding substantial improvements.", "AI": {"tldr": "V2V converts video frames to event-based voxel grids, reducing storage needs by 150x and enabling large-scale training for event vision models.", "motivation": "Overcome storage and data scarcity issues in event-based vision by bypassing traditional event stream generation.", "method": "Introduces Video-to-Voxel (V2V), a method to directly convert video frames into event-based voxel grids, avoiding storage-heavy event streams.", "result": "Achieves 150x storage reduction, trains models on 52 hours of video (10,000 videos), and improves performance.", "conclusion": "V2V enables scalable, efficient training for event vision models, enhancing generalization and robustness."}}
{"id": "2505.16847", "pdf": "https://arxiv.org/pdf/2505.16847", "abs": "https://arxiv.org/abs/2505.16847", "authors": ["Baran Barbarestani", "Isa Maks", "Piek Vossen"], "title": "Understanding and Analyzing Inappropriately Targeting Language in Online Discourse: A Comparative Annotation Study", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces a method for detecting inappropriately targeting\nlanguage in online conversations by integrating crowd and expert annotations\nwith ChatGPT. We focus on English conversation threads from Reddit, examining\ncomments that target individuals or groups. Our approach involves a\ncomprehensive annotation framework that labels a diverse data set for various\ntarget categories and specific target words within the conversational context.\nWe perform a comparative analysis of annotations from human experts, crowd\nannotators, and ChatGPT, revealing strengths and limitations of each method in\nrecognizing both explicit hate speech and subtler discriminatory language. Our\nfindings highlight the significant role of contextual factors in identifying\nhate speech and uncover new categories of targeting, such as social belief and\nbody image. We also address the challenges and subjective judgments involved in\nannotation and the limitations of ChatGPT in grasping nuanced language. This\nstudy provides insights for improving automated content moderation strategies\nto enhance online safety and inclusivity.", "AI": {"tldr": "The paper presents a method for detecting inappropriate language in online conversations using crowd and expert annotations alongside ChatGPT, focusing on Reddit threads. It compares human and AI annotations, revealing insights into hate speech detection and moderation challenges.", "motivation": "The study aims to improve automated content moderation by understanding the strengths and limitations of human and AI annotations in detecting hate speech and discriminatory language.", "method": "The approach involves annotating Reddit comments using a framework that labels targeting categories and words, comparing annotations from experts, crowd workers, and ChatGPT.", "result": "Findings show contextual factors are crucial in hate speech detection, uncover new targeting categories (e.g., social belief, body image), and highlight ChatGPT's limitations with nuanced language.", "conclusion": "The study offers insights for enhancing online safety through better automated moderation, addressing annotation challenges and AI limitations."}}
{"id": "2505.16836", "pdf": "https://arxiv.org/pdf/2505.16836", "abs": "https://arxiv.org/abs/2505.16836", "authors": ["Fanrui Zhang", "Dian Li", "Qiang Zhang", "Chenjun", "sinbadliu", "Junxiong Lin", "Jiahong Yan", "Jiawei Liu", "Zheng-Jun Zha"], "title": "Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": "28 pages, 27 figures", "summary": "The rapid spread of multimodal misinformation on social media has raised\ngrowing concerns, while research on video misinformation detection remains\nlimited due to the lack of large-scale, diverse datasets. Existing methods\noften overfit to rigid templates and lack deep reasoning over deceptive\ncontent. To address these challenges, we introduce FakeVV, a large-scale\nbenchmark comprising over 100,000 video-text pairs with fine-grained,\ninterpretable annotations. In addition, we further propose Fact-R1, a novel\nframework that integrates deep reasoning with collaborative rule-based\nreinforcement learning. Fact-R1 is trained through a three-stage process: (1)\nmisinformation long-Chain-of-Thought (CoT) instruction tuning, (2) preference\nalignment via Direct Preference Optimization (DPO), and (3) Group Relative\nPolicy Optimization (GRPO) using a novel verifiable reward function. This\nenables Fact-R1 to exhibit emergent reasoning behaviors comparable to those\nobserved in advanced text-based reinforcement learning systems, but in the more\ncomplex multimodal misinformation setting. Our work establishes a new paradigm\nfor misinformation detection, bridging large-scale video understanding,\nreasoning-guided alignment, and interpretable verification.", "AI": {"tldr": "FakeVV is a large-scale benchmark for video misinformation detection, and Fact-R1 is a novel framework combining deep reasoning and rule-based reinforcement learning for improved detection.", "motivation": "Addressing the lack of large-scale datasets and deep reasoning in video misinformation detection.", "method": "Fact-R1 integrates deep reasoning with collaborative rule-based reinforcement learning, trained via a three-stage process: misinformation CoT instruction tuning, DPO alignment, and GRPO with a verifiable reward function.", "result": "Fact-R1 achieves emergent reasoning behaviors comparable to advanced text-based systems, tailored for multimodal misinformation.", "conclusion": "The work sets a new paradigm for misinformation detection by combining large-scale video understanding, reasoning-guided alignment, and interpretable verification."}}
{"id": "2505.16903", "pdf": "https://arxiv.org/pdf/2505.16903", "abs": "https://arxiv.org/abs/2505.16903", "authors": ["Peyman Baghershahi", "Sourav Medya"], "title": "Unsupervised Prompting for Graph Neural Networks", "categories": ["cs.LG"], "comment": "25 pages, 5 figures, 14 tables", "summary": "Prompt tuning methods for Graph Neural Networks (GNNs) have become popular to\naddress the semantic gap between pre-training and fine-tuning steps. However,\nexisting GNN prompting methods rely on labeled data and involve lightweight\nfine-tuning for downstream tasks. Meanwhile, in-context learning methods for\nLarge Language Models (LLMs) have shown promising performance with no parameter\nupdating and no or minimal labeled data. Inspired by these approaches, in this\nwork, we first introduce a challenging problem setup to evaluate GNN prompting\nmethods. This setup encourages a prompting function to enhance a pre-trained\nGNN's generalization to a target dataset under covariate shift without updating\nthe GNN's parameters and with no labeled data. Next, we propose a fully\nunsupervised prompting method based on consistency regularization through\npseudo-labeling. We use two regularization techniques to align the prompted\ngraphs' distribution with the original data and reduce biased predictions.\nThrough extensive experiments under our problem setting, we demonstrate that\nour unsupervised approach outperforms the state-of-the-art prompting methods\nthat have access to labels.", "AI": {"tldr": "The paper introduces an unsupervised prompting method for GNNs to address covariate shift without labeled data or parameter updates, outperforming existing labeled-data-dependent methods.", "motivation": "Existing GNN prompting methods require labeled data and fine-tuning, while LLMs show success with minimal or no labeled data. This work aims to bridge this gap for GNNs.", "method": "Proposes an unsupervised prompting method using consistency regularization and pseudo-labeling, with techniques to align distributions and reduce bias.", "result": "The method outperforms state-of-the-art prompting methods that rely on labeled data, demonstrating strong generalization under covariate shift.", "conclusion": "Unsupervised prompting for GNNs is viable and effective, offering a promising direction for pre-trained GNN applications without labeled data."}}
{"id": "2505.16805", "pdf": "https://arxiv.org/pdf/2505.16805", "abs": "https://arxiv.org/abs/2505.16805", "authors": ["Xuesong Chen", "Linjiang Huang", "Tao Ma", "Rongyao Fang", "Shaoshuai Shi", "Hongsheng Li"], "title": "SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "The integration of Vision-Language Models (VLMs) into autonomous driving\nsystems has shown promise in addressing key challenges such as learning\ncomplexity, interpretability, and common-sense reasoning. However, existing\napproaches often struggle with efficient integration and realtime\ndecision-making due to computational demands. In this paper, we introduce\nSOLVE, an innovative framework that synergizes VLMs with end-to-end (E2E)\nmodels to enhance autonomous vehicle planning. Our approach emphasizes\nknowledge sharing at the feature level through a shared visual encoder,\nenabling comprehensive interaction between VLM and E2E components. We propose a\nTrajectory Chain-of-Thought (T-CoT) paradigm, which progressively refines\ntrajectory predictions, reducing uncertainty and improving accuracy. By\nemploying a temporal decoupling strategy, SOLVE achieves efficient cooperation\nby aligning high-quality VLM outputs with E2E real-time performance. Evaluated\non the nuScenes dataset, our method demonstrates significant improvements in\ntrajectory prediction accuracy, paving the way for more robust and reliable\nautonomous driving systems.", "AI": {"tldr": "SOLVE integrates Vision-Language Models (VLMs) with end-to-end models for autonomous driving, improving trajectory prediction via a shared visual encoder and Trajectory Chain-of-Thought paradigm.", "motivation": "Addressing challenges like computational demands and real-time decision-making in autonomous driving by enhancing VLM-E2E integration.", "method": "Uses a shared visual encoder for feature-level knowledge sharing and introduces T-CoT for refining trajectory predictions. Temporal decoupling aligns VLM outputs with real-time E2E performance.", "result": "Significant improvement in trajectory prediction accuracy on the nuScenes dataset.", "conclusion": "SOLVE offers a robust framework for reliable autonomous driving systems by efficiently combining VLMs and E2E models."}}
{"id": "2505.16855", "pdf": "https://arxiv.org/pdf/2505.16855", "abs": "https://arxiv.org/abs/2505.16855", "authors": ["Alberto Mu\u00f1oz-Ortiz", "David Vilares", "Caio COrro", "Carlos G\u00f3mez-Rodr\u00edguez"], "title": "Nested Named Entity Recognition as Single-Pass Sequence Labeling", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "Submitted to EMNLP 2025", "summary": "We cast nested named entity recognition (NNER) as a sequence labeling task by\nleveraging prior work that linearizes constituency structures, effectively\nreducing the complexity of this structured prediction problem to\nstraightforward token classification. By combining these constituency\nlinearizations with pretrained encoders, our method captures nested entities\nwhile performing exactly $n$ tagging actions. Our approach achieves competitive\nperformance compared to less efficient systems, and it can be trained using any\noff-the-shelf sequence labeling library.", "AI": {"tldr": "The paper proposes a sequence labeling method for nested named entity recognition (NNER) by linearizing constituency structures, achieving competitive performance with efficient training.", "motivation": "To simplify the structured prediction problem of NNER by reducing it to token classification, making it more efficient and accessible.", "method": "Leverages constituency linearizations with pretrained encoders to capture nested entities using exactly $n$ tagging actions.", "result": "Achieves competitive performance compared to less efficient systems.", "conclusion": "The method is efficient, trainable with standard sequence labeling tools, and performs well for NNER."}}
{"id": "2505.16875", "pdf": "https://arxiv.org/pdf/2505.16875", "abs": "https://arxiv.org/abs/2505.16875", "authors": ["Zhehao Huang", "Yuhang Liu", "Yixin Lou", "Zhengbao He", "Mingzhen He", "Wenxing Zhou", "Tao Li", "Kehan Li", "Zeyi Huang", "Xiaolin Huang"], "title": "T2I-ConBench: Text-to-Image Benchmark for Continual Post-training", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Continual post-training adapts a single text-to-image diffusion model to\nlearn new tasks without incurring the cost of separate models, but naive\npost-training causes forgetting of pretrained knowledge and undermines\nzero-shot compositionality. We observe that the absence of a standardized\nevaluation protocol hampers related research for continual post-training. To\naddress this, we introduce T2I-ConBench, a unified benchmark for continual\npost-training of text-to-image models. T2I-ConBench focuses on two practical\nscenarios, item customization and domain enhancement, and analyzes four\ndimensions: (1) retention of generality, (2) target-task performance, (3)\ncatastrophic forgetting, and (4) cross-task generalization. It combines\nautomated metrics, human-preference modeling, and vision-language QA for\ncomprehensive assessment. We benchmark ten representative methods across three\nrealistic task sequences and find that no approach excels on all fronts. Even\njoint \"oracle\" training does not succeed for every task, and cross-task\ngeneralization remains unsolved. We release all datasets, code, and evaluation\ntools to accelerate research in continual post-training for text-to-image\nmodels.", "AI": {"tldr": "The paper introduces T2I-ConBench, a benchmark for evaluating continual post-training in text-to-image models, addressing issues like forgetting and lack of standardized evaluation.", "motivation": "Standardizing evaluation for continual post-training in text-to-image models to prevent forgetting and improve zero-shot compositionality.", "method": "Introduces T2I-ConBench, a benchmark with automated metrics, human-preference modeling, and vision-language QA, tested on ten methods across three task sequences.", "result": "No method excels in all dimensions (generality retention, task performance, forgetting, cross-task generalization); joint training also fails in some cases.", "conclusion": "T2I-ConBench and released resources aim to advance research in continual post-training for text-to-image models."}}
{"id": "2505.16918", "pdf": "https://arxiv.org/pdf/2505.16918", "abs": "https://arxiv.org/abs/2505.16918", "authors": ["Nikola Tankovic", "Robert Sajina"], "title": "Scalable and Interpretable Contextual Bandits: A Literature Review and Retail Offer Prototype", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents a concise review of Contextual Multi-Armed Bandit (CMAB)\nmethods and introduces an experimental framework for scalable, interpretable\noffer selection, addressing the challenge of fast-changing offers. The approach\nmodels context at the product category level, allowing offers to span multiple\ncategories and enabling knowledge transfer across similar offers. This improves\nlearning efficiency and generalization in dynamic environments. The framework\nextends standard CMAB methodology to support multi-category contexts, and\nachieves scalability through efficient feature engineering and modular design.\nAdvanced features such as MPG (Member Purchase Gap) and MF (Matrix\nFactorization) capture nuanced user-offer interactions, with implementation in\nPython for practical deployment.\n  A key contribution is interpretability at scale: logistic regression models\nyield transparent weight vectors, accessible via a large language model (LLM)\ninterface for real-time, user-level tracking and explanation of evolving\npreferences. This enables the generation of detailed member profiles and\nidentification of behavioral patterns, supporting personalized offer\noptimization and enhancing trust in automated decisions. By situating our\nprototype alongside established paradigms like Generalized Linear Models and\nThompson Sampling, we demonstrate its value for both research and real-world\nCMAB applications.", "AI": {"tldr": "The paper reviews CMAB methods and introduces a scalable, interpretable framework for offer selection, improving learning efficiency and generalization in dynamic environments.", "motivation": "Address the challenge of fast-changing offers and enable knowledge transfer across similar offers for better learning efficiency.", "method": "Extends CMAB methodology with multi-category contexts, efficient feature engineering, and modular design. Uses MPG and MF for nuanced interactions, implemented in Python.", "result": "Achieves scalable, interpretable offer selection with transparent weight vectors and real-time preference tracking via LLM.", "conclusion": "The framework enhances trust in automated decisions and demonstrates value for both research and real-world CMAB applications."}}
{"id": "2505.16811", "pdf": "https://arxiv.org/pdf/2505.16811", "abs": "https://arxiv.org/abs/2505.16811", "authors": ["Shangquan Sun", "Wenqi Ren", "Juxiang Zhou", "Shu Wang", "Jianhou Gan", "Xiaochun Cao"], "title": "Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining", "categories": ["cs.CV"], "comment": "11 Pages, 8 figures, CVPR 2025 Oral Presentation", "summary": "Significant progress has been made in video restoration under rainy\nconditions over the past decade, largely propelled by advancements in deep\nlearning. Nevertheless, existing methods that depend on paired data struggle to\ngeneralize effectively to real-world scenarios, primarily due to the disparity\nbetween synthetic and authentic rain effects. To address these limitations, we\npropose a dual-branch spatio-temporal state-space model to enhance rain streak\nremoval in video sequences. Specifically, we design spatial and temporal\nstate-space model layers to extract spatial features and incorporate temporal\ndependencies across frames, respectively. To improve multi-frame feature\nfusion, we derive a dynamic stacking filter, which adaptively approximates\nstatistical filters for superior pixel-wise feature refinement. Moreover, we\ndevelop a median stacking loss to enable semi-supervised learning by generating\npseudo-clean patches based on the sparsity prior of rain. To further explore\nthe capacity of deraining models in supporting other vision-based tasks in\nrainy environments, we introduce a novel real-world benchmark focused on object\ndetection and tracking in rainy conditions. Our method is extensively evaluated\nacross multiple benchmarks containing numerous synthetic and real-world rainy\nvideos, consistently demonstrating its superiority in quantitative metrics,\nvisual quality, efficiency, and its utility for downstream tasks.", "AI": {"tldr": "A dual-branch spatio-temporal state-space model is proposed for video deraining, addressing generalization issues with synthetic data and enhancing downstream tasks like object detection in rain.", "motivation": "Existing methods relying on paired data fail to generalize to real-world rain due to synthetic-authentic disparities.", "method": "Uses spatial and temporal state-space layers for feature extraction and dependencies, a dynamic stacking filter for feature fusion, and a median stacking loss for semi-supervised learning.", "result": "Superior performance in quantitative metrics, visual quality, efficiency, and utility for downstream tasks like object detection.", "conclusion": "The proposed model effectively addresses real-world rain removal challenges and supports other vision tasks in rainy conditions."}}
{"id": "2505.16868", "pdf": "https://arxiv.org/pdf/2505.16868", "abs": "https://arxiv.org/abs/2505.16868", "authors": ["Sudhansu Bala Das", "Samujjal Choudhury", "Tapas Kumar Mishra", "Bidyut Kr. Patra"], "title": "Comparative analysis of subword tokenization approaches for Indian languages", "categories": ["cs.CL"], "comment": "24 pages, 4 tables", "summary": "Tokenization is the act of breaking down text into smaller parts, or tokens,\nthat are easier for machines to process. This is a key phase in machine\ntranslation (MT) models. Subword tokenization enhances this process by breaking\ndown words into smaller subword units, which is especially beneficial in\nlanguages with complicated morphology or a vast vocabulary. It is useful in\ncapturing the intricate structure of words in Indian languages (ILs), such as\nprefixes, suffixes, and other morphological variations. These languages\nfrequently use agglutinative structures, in which words are formed by the\ncombination of multiple morphemes such as suffixes, prefixes, and stems. As a\nresult, a suitable tokenization strategy must be chosen to address these\nscenarios. This paper examines how different subword tokenization techniques,\nsuch as SentencePiece, Byte Pair Encoding (BPE), and WordPiece Tokenization,\naffect ILs. The effectiveness of these subword tokenization techniques is\ninvestigated in statistical, neural, and multilingual neural machine\ntranslation models. All models are examined using standard evaluation metrics,\nsuch as the Bilingual Evaluation Understudy (BLEU) score, TER, METEOR, CHRF,\nRIBES, and COMET. Based on the results, it appears that for the majority of\nlanguage pairs for the Statistical and Neural MT models, the SentencePiece\ntokenizer continuously performed better than other tokenizers in terms of BLEU\nscore. However, BPE tokenization outperformed other tokenization techniques in\nthe context of Multilingual Neural Machine Translation model. The results show\nthat, despite using the same tokenizer and dataset for each model, translations\nfrom ILs to English surpassed translations from English to ILs.", "AI": {"tldr": "The paper explores subword tokenization techniques (SentencePiece, BPE, WordPiece) for Indian languages, finding SentencePiece best for Statistical/Neural MT and BPE for Multilingual MT.", "motivation": "Indian languages' complex morphology and agglutinative structures require effective tokenization for machine translation.", "method": "Evaluated tokenizers (SentencePiece, BPE, WordPiece) in Statistical, Neural, and Multilingual MT models using metrics like BLEU, TER, METEOR.", "result": "SentencePiece excelled in Statistical/Neural MT, while BPE performed best in Multilingual MT. ILs to English translations outperformed English to ILs.", "conclusion": "Tokenization choice impacts MT performance; SentencePiece and BPE are optimal for different MT models, with ILs to English translations being superior."}}
{"id": "2505.16881", "pdf": "https://arxiv.org/pdf/2505.16881", "abs": "https://arxiv.org/abs/2505.16881", "authors": ["Daniel F. Perez-Ramirez", "Dejan Kostic", "Magnus Boman"], "title": "CASTILLO: Characterizing Response Length Distributions of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Dataset available in\n  https://huggingface.co/datasets/danfperam/castillo and code is available in\n  https://github.com/DanielFPerez/castillo", "summary": "Efficiently managing compute resources for Large Language Model (LLM)\ninference remains challenging due to the inherently stochastic and variable\nlengths of autoregressive text generation. Accurately estimating response\nlengths in advance enables proactive resource allocation, yet existing\napproaches either bias text generation towards certain lengths or rely on\nassumptions that ignore model- and prompt-specific variability. We introduce\nCASTILLO, a dataset characterizing response length distributions across 13\nwidely-used open-source LLMs evaluated on seven distinct instruction-following\ncorpora. For each $\\langle$prompt, model$\\rangle$ sample pair, we generate 10\nindependent completions using fixed decoding hyper-parameters, record the token\nlength of each response, and publish summary statistics (mean, std-dev,\npercentiles), along with the shortest and longest completions, and the exact\ngeneration settings. Our analysis reveals significant inter- and intra-model\nvariability in response lengths (even under identical generation settings), as\nwell as model-specific behaviors and occurrences of partial text degeneration\nin only subsets of responses. CASTILLO enables the development of predictive\nmodels for proactive scheduling and provides a systematic framework for\nanalyzing model-specific generation behaviors. We publicly release the dataset\nand code to foster research at the intersection of generative language modeling\nand systems.", "AI": {"tldr": "CASTILLO is a dataset for analyzing response length variability in LLMs, aiding proactive resource allocation and model behavior analysis.", "motivation": "Managing compute resources for LLM inference is challenging due to variable response lengths. Existing methods either bias generation or ignore model-specific variability.", "method": "CASTILLO collects response length distributions from 13 LLMs across seven instruction-following corpora, generating 10 completions per prompt-model pair with fixed settings.", "result": "Significant variability in response lengths was observed, even under identical settings, revealing model-specific behaviors and partial degeneration.", "conclusion": "CASTILLO supports predictive modeling for resource scheduling and provides a framework for analyzing LLM generation behaviors, with publicly released data and code."}}
{"id": "2505.16925", "pdf": "https://arxiv.org/pdf/2505.16925", "abs": "https://arxiv.org/abs/2505.16925", "authors": ["Igor Udovichenko", "Olivier Croissant", "Anita Toleutaeva", "Evgeny Burnaev", "Alexander Korotin"], "title": "Risk-Averse Reinforcement Learning with Itakura-Saito Loss", "categories": ["cs.LG"], "comment": null, "summary": "Risk-averse reinforcement learning finds application in various high-stakes\nfields. Unlike classical reinforcement learning, which aims to maximize\nexpected returns, risk-averse agents choose policies that minimize risk,\noccasionally sacrificing expected value. These preferences can be framed\nthrough utility theory. We focus on the specific case of the exponential\nutility function, where we can derive the Bellman equations and employ various\nreinforcement learning algorithms with few modifications. However, these\nmethods suffer from numerical instability due to the need for exponent\ncomputation throughout the process. To address this, we introduce a numerically\nstable and mathematically sound loss function based on the Itakura-Saito\ndivergence for learning state-value and action-value functions. We evaluate our\nproposed loss function against established alternatives, both theoretically and\nempirically. In the experimental section, we explore multiple financial\nscenarios, some with known analytical solutions, and show that our loss\nfunction outperforms the alternatives.", "AI": {"tldr": "The paper introduces a numerically stable loss function for risk-averse reinforcement learning using the Itakura-Saito divergence, outperforming existing methods in financial scenarios.", "motivation": "Risk-averse reinforcement learning is crucial in high-stakes fields but suffers from numerical instability due to exponent computations.", "method": "Proposes a loss function based on the Itakura-Saito divergence for stable learning of state-value and action-value functions.", "result": "The new loss function outperforms alternatives in financial scenarios, including those with known analytical solutions.", "conclusion": "The introduced loss function provides a stable and effective solution for risk-averse reinforcement learning."}}
{"id": "2505.16815", "pdf": "https://arxiv.org/pdf/2505.16815", "abs": "https://arxiv.org/abs/2505.16815", "authors": ["Chunyi Li", "Jiaohao Xiao", "Jianbo Zhang", "Farong Wen", "Zicheng Zhang", "Yuan Tian", "Xiangyang Zhu", "Xiaohong Liu", "Zhengxue Cheng", "Weisi Lin", "Guangtao Zhai"], "title": "Perceptual Quality Assessment for Embodied AI", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Embodied AI has developed rapidly in recent years, but it is still mainly\ndeployed in laboratories, with various distortions in the Real-world limiting\nits application. Traditionally, Image Quality Assessment (IQA) methods are\napplied to predict human preferences for distorted images; however, there is no\nIQA method to assess the usability of an image in embodied tasks, namely, the\nperceptual quality for robots. To provide accurate and reliable quality\nindicators for future embodied scenarios, we first propose the topic: IQA for\nEmbodied AI. Specifically, we (1) based on the Mertonian system and\nmeta-cognitive theory, constructed a perception-cognition-decision-execution\npipeline and defined a comprehensive subjective score collection process; (2)\nestablished the Embodied-IQA database, containing over 36k reference/distorted\nimage pairs, with more than 5m fine-grained annotations provided by Vision\nLanguage Models/Vision Language Action-models/Real-world robots; (3) trained\nand validated the performance of mainstream IQA methods on Embodied-IQA,\ndemonstrating the need to develop more accurate quality indicators for Embodied\nAI. We sincerely hope that through evaluation, we can promote the application\nof Embodied AI under complex distortions in the Real-world. Project page:\nhttps://github.com/lcysyzxdxc/EmbodiedIQA", "AI": {"tldr": "The paper introduces IQA for Embodied AI, proposing a new method to assess image usability for robots, creating a database, and validating existing IQA methods.", "motivation": "Current IQA methods don't address image usability for embodied tasks, limiting real-world AI applications.", "method": "Developed a perception-cognition-decision-execution pipeline, created the Embodied-IQA database, and tested mainstream IQA methods.", "result": "Established a database with 36k image pairs and 5m annotations, showing existing IQA methods need improvement for embodied tasks.", "conclusion": "The work aims to improve Embodied AI's real-world application by providing better quality indicators."}}
{"id": "2505.16869", "pdf": "https://arxiv.org/pdf/2505.16869", "abs": "https://arxiv.org/abs/2505.16869", "authors": ["Weixiang Zhao", "Yulin Hu", "Yang Deng", "Tongtong Wu", "Wenxuan Zhang", "Jiahe Guo", "An Zhang", "Yanyan Zhao", "Bing Qin", "Tat-Seng Chua", "Ting Liu"], "title": "MPO: Multilingual Safety Alignment via Reward Gap Optimization", "categories": ["cs.CL"], "comment": "To Appear at ACL 2025 (Main)", "summary": "Large language models (LLMs) have become increasingly central to AI\napplications worldwide, necessitating robust multilingual safety alignment to\nensure secure deployment across diverse linguistic contexts. Existing\npreference learning methods for safety alignment, such as RLHF and DPO, are\nprimarily monolingual and struggle with noisy multilingual data. To address\nthese limitations, we introduce Multilingual reward gaP Optimization (MPO), a\nnovel approach that leverages the well-aligned safety capabilities of the\ndominant language (English) to improve safety alignment across multiple\nlanguages. MPO directly minimizes the reward gap difference between the\ndominant language and target languages, effectively transferring safety\ncapabilities while preserving the original strengths of the dominant language.\nExtensive experiments on three LLMs, LLaMA-3.1, Gemma-2 and Qwen2.5, validate\nMPO's efficacy in multilingual safety alignment without degrading general\nmultilingual utility.", "AI": {"tldr": "MPO improves multilingual safety alignment in LLMs by leveraging dominant language (English) capabilities, outperforming monolingual methods like RLHF and DPO.", "motivation": "Existing safety alignment methods (e.g., RLHF, DPO) are monolingual and ineffective for noisy multilingual data, necessitating a better approach.", "method": "MPO minimizes the reward gap between dominant (English) and target languages, transferring safety capabilities without degrading utility.", "result": "MPO enhances safety alignment across languages in LLMs (LLaMA-3.1, Gemma-2, Qwen2.5) while maintaining general multilingual performance.", "conclusion": "MPO is an effective solution for multilingual safety alignment in LLMs, addressing limitations of current monolingual methods."}}
{"id": "2505.16886", "pdf": "https://arxiv.org/pdf/2505.16886", "abs": "https://arxiv.org/abs/2505.16886", "authors": ["Nour Jedidi", "Yung-Sung Chuang", "James Glass", "Jimmy Lin"], "title": "Don't \"Overthink\" Passage Reranking: Is Reasoning Truly Necessary?", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "With the growing success of reasoning models across complex natural language\ntasks, researchers in the Information Retrieval (IR) community have begun\nexploring how similar reasoning capabilities can be integrated into passage\nrerankers built on Large Language Models (LLMs). These methods typically employ\nan LLM to produce an explicit, step-by-step reasoning process before arriving\nat a final relevance prediction. But, does reasoning actually improve reranking\naccuracy? In this paper, we dive deeper into this question, studying the impact\nof the reasoning process by comparing reasoning-based pointwise rerankers\n(ReasonRR) to standard, non-reasoning pointwise rerankers (StandardRR) under\nidentical training conditions, and observe that StandardRR generally\noutperforms ReasonRR. Building on this observation, we then study the\nimportance of reasoning to ReasonRR by disabling its reasoning process\n(ReasonRR-NoReason), and find that ReasonRR-NoReason is surprisingly more\neffective than ReasonRR. Examining the cause of this result, our findings\nreveal that reasoning-based rerankers are limited by the LLM's reasoning\nprocess, which pushes it toward polarized relevance scores and thus fails to\nconsider the partial relevance of passages, a key factor for the accuracy of\npointwise rerankers.", "AI": {"tldr": "Standard non-reasoning rerankers outperform reasoning-based ones, as reasoning limits the model's ability to assess partial relevance.", "motivation": "To investigate whether explicit reasoning improves passage reranking accuracy in LLMs.", "method": "Compare reasoning-based (ReasonRR) and non-reasoning (StandardRR) rerankers under identical conditions, then disable reasoning in ReasonRR (ReasonRR-NoReason).", "result": "StandardRR outperforms ReasonRR, and ReasonRR-NoReason is more effective than ReasonRR. Reasoning leads to polarized scores, ignoring partial relevance.", "conclusion": "Reasoning-based rerankers are hindered by the LLM's reasoning process, which fails to account for partial relevance, a critical factor in accuracy."}}
{"id": "2505.16932", "pdf": "https://arxiv.org/pdf/2505.16932", "abs": "https://arxiv.org/abs/2505.16932", "authors": ["Noah Amsel", "David Persson", "Christopher Musco", "Robert Gower"], "title": "The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NA", "math.NA", "math.OC"], "comment": null, "summary": "Computing the polar decomposition and the related matrix sign function, has\nbeen a well-studied problem in numerical analysis for decades. More recently,\nit has emerged as an important subroutine in deep learning, particularly within\nthe Muon optimization framework. However, the requirements in this setting\ndiffer significantly from those of traditional numerical analysis. In deep\nlearning, methods must be highly efficient and GPU-compatible, but high\naccuracy is often unnecessary. As a result, classical algorithms like\nNewton-Schulz (which suffers from slow initial convergence) and methods based\non rational functions (which rely on QR decompositions or matrix inverses) are\npoorly suited to this context. In this work, we introduce Polar Express, a\nGPU-friendly algorithm for computing the polar decomposition. Like classical\npolynomial methods such as Newton-Schulz, our approach uses only matrix-matrix\nmultiplications, making it GPU-compatible. Motivated by earlier work of Chen &\nChow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule\nat each iteration by solving a minimax optimization problem, and we prove that\nit enjoys a strong worst-case optimality guarantee. This property ensures both\nrapid early convergence and fast asymptotic convergence. We also address\nfinite-precision issues, making it stable in bfloat16 in practice. We apply\nPolar Express within the Muon optimization framework and show consistent\nimprovements in validation loss on large-scale models such as GPT-2,\noutperforming recent alternatives across a range of learning rates.", "AI": {"tldr": "Polar Express is a GPU-friendly algorithm for polar decomposition, optimized for deep learning by balancing efficiency and stability, outperforming classical methods.", "motivation": "Traditional polar decomposition methods are inefficient for deep learning due to slow convergence or reliance on QR/inversions, necessitating a GPU-compatible, high-efficiency solution.", "method": "Polar Express uses matrix-matrix multiplications and adapts polynomial updates via minimax optimization, ensuring rapid convergence and stability in bfloat16.", "result": "The algorithm shows improved validation loss in Muon optimization for models like GPT-2, outperforming alternatives across learning rates.", "conclusion": "Polar Express is a practical, efficient solution for polar decomposition in deep learning, combining speed, stability, and performance."}}
{"id": "2505.16819", "pdf": "https://arxiv.org/pdf/2505.16819", "abs": "https://arxiv.org/abs/2505.16819", "authors": ["Taewon Kang", "Ming C. Lin"], "title": "Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts", "categories": ["cs.CV"], "comment": "18 pages, 5 figures", "summary": "Recent advances in scene-based video generation have enabled systems to\nsynthesize coherent visual narratives from structured prompts. However, a\ncrucial dimension of storytelling -- character-driven dialogue and speech --\nremains underexplored. In this paper, we present a modular pipeline that\ntransforms action-level prompts into visually and auditorily grounded narrative\ndialogue, enriching visual storytelling with natural voice and character\nexpression. Our method takes as input a pair of prompts per scene, where the\nfirst defines the setting and the second specifies a character's behavior.\nWhile a story generation model such as Text2Story generates the corresponding\nvisual scene, we focus on generating expressive character utterances from these\nprompts and the scene image. We apply a pretrained vision-language encoder to\nextract a high-level semantic feature from the representative frame, capturing\nsalient visual context. This feature is then combined with the structured\nprompts and used to guide a large language model in synthesizing natural,\ncharacter-consistent dialogue. To ensure contextual consistency across scenes,\nwe introduce a Recursive Narrative Bank that conditions each dialogue\ngeneration on the accumulated dialogue history from prior scenes. This approach\nenables characters to speak in ways that reflect their evolving goals and\ninteractions throughout a story. Finally, we render each utterance as\nexpressive, character-consistent speech, resulting in fully-voiced video\nnarratives. Our framework requires no additional training and demonstrates\napplicability across a variety of story settings, from fantasy adventures to\nslice-of-life episodes.", "AI": {"tldr": "A modular pipeline generates character-driven dialogue and speech for video narratives, combining visual context, structured prompts, and dialogue history to create expressive, coherent storytelling.", "motivation": "Current video generation systems lack character-driven dialogue, a key storytelling element. This paper aims to enrich visual narratives with natural speech and character expression.", "method": "The method uses a pretrained vision-language encoder to extract visual context, combines it with prompts, and guides a large language model to generate dialogue. A Recursive Narrative Bank ensures contextual consistency.", "result": "The framework produces fully-voiced video narratives with character-consistent dialogue, applicable across diverse story settings without additional training.", "conclusion": "The approach successfully integrates dialogue into visual storytelling, enhancing narrative coherence and character expression."}}
{"id": "2505.16894", "pdf": "https://arxiv.org/pdf/2505.16894", "abs": "https://arxiv.org/abs/2505.16894", "authors": ["Zeyu Wei", "Shuo Wang", "Xiaohui Rong", "Xuemin Liu", "He Li"], "title": "Shadows in the Attention: Contextual Perturbation and Representation Drift in the Dynamics of Hallucination in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Hallucinations -- plausible yet erroneous outputs -- remain a critical\nbarrier to reliable deployment of large language models (LLMs). We present the\nfirst systematic study linking hallucination incidence to internal-state drift\ninduced by incremental context injection. Using TruthfulQA, we construct two\n16-round \"titration\" tracks per question: one appends relevant but partially\nflawed snippets, the other injects deliberately misleading content. Across six\nopen-source LLMs, we track overt hallucination rates with a tri-perspective\ndetector and covert dynamics via cosine, entropy, JS and Spearman drifts of\nhidden states and attention maps. Results reveal (1) monotonic growth of\nhallucination frequency and representation drift that plateaus after 5--7\nrounds; (2) relevant context drives deeper semantic assimilation, producing\nhigh-confidence \"self-consistent\" hallucinations, whereas irrelevant context\ninduces topic-drift errors anchored by attention re-routing; and (3)\nconvergence of JS-Drift ($\\sim0.69$) and Spearman-Drift ($\\sim0$) marks an\n\"attention-locking\" threshold beyond which hallucinations solidify and become\nresistant to correction. Correlation analyses expose a seesaw between\nassimilation capacity and attention diffusion, clarifying size-dependent error\nmodes. These findings supply empirical foundations for intrinsic hallucination\nprediction and context-aware mitigation mechanisms.", "AI": {"tldr": "The paper studies how incremental context injection in LLMs leads to hallucinations, revealing patterns in frequency, semantic assimilation, and attention dynamics.", "motivation": "Hallucinations in LLMs hinder reliability, prompting a need to understand their link to internal-state drift from context injection.", "method": "Using TruthfulQA, the study constructs titration tracks with relevant/flawed and misleading content, tracking hallucination rates and internal-state drifts across six LLMs.", "result": "Hallucination frequency grows monotonically, plateauing after 5-7 rounds. Relevant context causes deep semantic assimilation, while irrelevant context leads to topic-drift errors. Attention-locking thresholds mark irreversible hallucinations.", "conclusion": "The findings provide empirical insights for predicting and mitigating hallucinations in LLMs, highlighting the interplay between assimilation capacity and attention diffusion."}}
{"id": "2505.16888", "pdf": "https://arxiv.org/pdf/2505.16888", "abs": "https://arxiv.org/abs/2505.16888", "authors": ["Viet Pham", "Thai Le"], "title": "CAIN: Hijacking LLM-Humans Conversations via a Two-Stage Malicious System Prompt Generation and Refining Framework", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have advanced many applications, but are also\nknown to be vulnerable to adversarial attacks. In this work, we introduce a\nnovel security threat: hijacking AI-human conversations by manipulating LLMs'\nsystem prompts to produce malicious answers only to specific targeted questions\n(e.g., \"Who should I vote for US President?\", \"Are Covid vaccines safe?\"),\nwhile behaving benignly on others. This attack is detrimental as it can enable\nmalicious actors to exercise large-scale information manipulation by spreading\nharmful but benign-looking system prompts online. To demonstrate such an\nattack, we develop CAIN, an algorithm that can automatically curate such\nharmful system prompts for a specific target question in a black-box setting or\nwithout the need to access the LLM's parameters. Evaluated on both open-source\nand commercial LLMs, CAIN demonstrates significant adversarial impact. In\nuntargeted attacks or forcing LLMs to output incorrect answers, CAIN achieves\nup to 40% F1 degradation on targeted questions while preserving high accuracy\non benign inputs. For targeted attacks or forcing LLMs to output specific\nharmful answers, CAIN achieves over 70% F1 scores on these targeted responses\nwith minimal impact on benign questions. Our results highlight the critical\nneed for enhanced robustness measures to safeguard the integrity and safety of\nLLMs in real-world applications. All source code will be publicly available.", "AI": {"tldr": "The paper introduces CAIN, an algorithm for hijacking AI-human conversations by manipulating LLMs' system prompts to produce malicious answers for targeted questions while appearing benign otherwise.", "motivation": "To expose a novel security threat where LLMs can be exploited for large-scale information manipulation through harmful but seemingly benign system prompts.", "method": "Developed CAIN, a black-box algorithm that automatically crafts harmful system prompts for targeted questions without needing LLM parameter access.", "result": "CAIN achieved up to 40% F1 degradation in untargeted attacks and over 70% F1 scores in targeted attacks, with minimal impact on benign inputs.", "conclusion": "The findings underscore the urgent need for improved robustness measures to protect LLMs from adversarial manipulation in real-world applications."}}
{"id": "2505.16933", "pdf": "https://arxiv.org/pdf/2505.16933", "abs": "https://arxiv.org/abs/2505.16933", "authors": ["Zebin You", "Shen Nie", "Xiaolu Zhang", "Jun Hu", "Jun Zhou", "Zhiwu Lu", "Ji-Rong Wen", "Chongxuan Li"], "title": "LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large\nLanguage Model (MLLM) that integrates visual instruction tuning with masked\ndiffusion models, representing a departure from the autoregressive paradigms\ndominant in current multimodal approaches. Built upon LLaDA, a representative\nlarge language diffusion model, LLaDA-V incorporates a vision encoder and MLP\nconnector that projects visual features into the language embedding space,\nenabling effective multimodal alignment. Our empirical investigation reveals\nseveral intriguing results: First, LLaDA-V demonstrates promising multimodal\nperformance despite its language model being weaker on purely textual tasks\nthan counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same\ninstruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal\ntasks with better data scalability. It also narrows the performance gap to\nQwen2-VL, suggesting the effectiveness of its architecture for multimodal\ntasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal\nunderstanding compared to existing hybrid autoregressive-diffusion and purely\ndiffusion-based MLLMs. Our findings suggest that large language diffusion\nmodels show promise in multimodal contexts and warrant further investigation in\nfuture research. Project page and codes:\nhttps://ml-gsai.github.io/LLaDA-V-demo/.", "AI": {"tldr": "LLaDA-V is a diffusion-based Multimodal Large Language Model (MLLM) that integrates visual instruction tuning with masked diffusion models, showing competitive performance in multimodal tasks despite weaker textual performance.", "motivation": "To explore the potential of diffusion-based models in multimodal contexts, diverging from dominant autoregressive approaches.", "method": "LLaDA-V combines a vision encoder and MLP connector to align visual features with language embeddings, built upon the LLaDA language diffusion model.", "result": "LLaDA-V achieves competitive multimodal performance, narrowing gaps with stronger models like Qwen2-VL and outperforming hybrid autoregressive-diffusion MLLMs.", "conclusion": "Diffusion-based large language models show promise for multimodal tasks, warranting further research."}}
{"id": "2505.16839", "pdf": "https://arxiv.org/pdf/2505.16839", "abs": "https://arxiv.org/abs/2505.16839", "authors": ["Shufan Li", "Konstantinos Kallidromitis", "Hritik Bansal", "Akash Gokul", "Yusuke Kato", "Kazuki Kozuka", "Jason Kuen", "Zhe Lin", "Kai-Wei Chang", "Aditya Grover"], "title": "LaViDa: A Large Diffusion Language Model for Multimodal Understanding", "categories": ["cs.CV"], "comment": "25 pages, 8 figures", "summary": "Modern Vision-Language Models (VLMs) can solve a wide range of tasks\nrequiring visual reasoning. In real-world scenarios, desirable properties for\nVLMs include fast inference and controllable generation (e.g., constraining\noutputs to adhere to a desired format). However, existing autoregressive (AR)\nVLMs like LLaVA struggle in these aspects. Discrete diffusion models (DMs)\noffer a promising alternative, enabling parallel decoding for faster inference\nand bidirectional context for controllable generation through text-infilling.\nWhile effective in language-only settings, DMs' potential for multimodal tasks\nis underexplored. We introduce LaViDa, a family of VLMs built on DMs. We build\nLaViDa by equipping DMs with a vision encoder and jointly fine-tune the\ncombined parts for multimodal instruction following. To address challenges\nencountered, LaViDa incorporates novel techniques such as complementary masking\nfor effective training, prefix KV cache for efficient inference, and timestep\nshifting for high-quality sampling. Experiments show that LaViDa achieves\ncompetitive or superior performance to AR VLMs on multi-modal benchmarks such\nas MMMU, while offering unique advantages of DMs, including flexible\nspeed-quality tradeoff, controllability, and bidirectional reasoning. On COCO\ncaptioning, LaViDa surpasses Open-LLaVa-Next-8B by +4.1 CIDEr with 1.92x\nspeedup. On bidirectional tasks, it achieves +59% improvement on Constrained\nPoem Completion. These results demonstrate LaViDa as a strong alternative to AR\nVLMs. Code and models will be released in the camera-ready version.", "AI": {"tldr": "LaViDa introduces a family of Vision-Language Models (VLMs) built on discrete diffusion models (DMs), offering faster inference and controllable generation, outperforming autoregressive VLMs like LLaVA.", "motivation": "Existing autoregressive VLMs lack fast inference and controllable generation, while DMs show promise but are underexplored for multimodal tasks.", "method": "LaViDa integrates DMs with a vision encoder, using techniques like complementary masking, prefix KV cache, and timestep shifting for training and inference.", "result": "LaViDa outperforms AR VLMs on benchmarks (e.g., +4.1 CIDEr on COCO captioning, +59% on Constrained Poem Completion) with faster inference.", "conclusion": "LaViDa is a competitive alternative to AR VLMs, combining the advantages of DMs for multimodal tasks."}}
{"id": "2505.16900", "pdf": "https://arxiv.org/pdf/2505.16900", "abs": "https://arxiv.org/abs/2505.16900", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "Power-Law Decay Loss for Large Language Model Finetuning: Focusing on Information Sparsity to Enhance Generation Quality", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "During the finetuning stage of text generation tasks, standard cross-entropy\nloss treats all tokens equally. This can lead models to overemphasize\nhigh-frequency, low-information tokens, neglecting lower-frequency tokens\ncrucial for specificity and informativeness in generated content. This paper\nintroduces a novel loss function, Power-Law Decay Loss (PDL), specifically\ndesigned to optimize the finetuning process for text generation. The core\nmotivation for PDL stems from observations in information theory and\nlinguistics: the informativeness of a token is often inversely proportional to\nits frequency of occurrence. PDL re-weights the contribution of each token in\nthe standard cross-entropy loss based on its frequency in the training corpus,\nfollowing a power-law decay. Specifically, the weights for high-frequency\ntokens are reduced, while low-frequency, information-dense tokens are assigned\nhigher weights. This mechanism guides the model during finetuning to focus more\non learning and generating tokens that convey specific and unique information,\nthereby enhancing the quality, diversity, and informativeness of the generated\ntext. We theoretically elaborate on the motivation and construction of PDL and\ndiscuss its potential applications and advantages across various text\ngeneration finetuning tasks, such as abstractive summarization, dialogue\nsystems, and style transfer.", "AI": {"tldr": "The paper introduces Power-Law Decay Loss (PDL), a novel loss function for text generation finetuning, addressing the overemphasis on high-frequency tokens by re-weighting token contributions based on frequency.", "motivation": "Standard cross-entropy loss treats all tokens equally, causing models to neglect low-frequency, high-information tokens. PDL is motivated by the inverse relationship between token frequency and informativeness.", "method": "PDL re-weights tokens in cross-entropy loss using a power-law decay, reducing weights for high-frequency tokens and increasing them for low-frequency ones.", "result": "PDL improves text generation by emphasizing informative tokens, enhancing quality, diversity, and specificity.", "conclusion": "PDL offers advantages for tasks like summarization, dialogue systems, and style transfer by optimizing finetuning for informativeness."}}
{"id": "2505.16915", "pdf": "https://arxiv.org/pdf/2505.16915", "abs": "https://arxiv.org/abs/2505.16915", "authors": ["Qirui Jiao", "Daoyuan Chen", "Yilun Huang", "Xika Lin", "Ying Shen", "Yaliang Li"], "title": "DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?", "categories": ["cs.CV", "cs.AI"], "comment": "22 pages, 8 figures, 10 tables", "summary": "While recent text-to-image (T2I) models show impressive capabilities in\nsynthesizing images from brief descriptions, their performance significantly\ndegrades when confronted with long, detail-intensive prompts required in\nprofessional applications. We present DetailMaster, the first comprehensive\nbenchmark specifically designed to evaluate T2I models' systematical abilities\nto handle extended textual inputs that contain complex compositional\nrequirements. Our benchmark introduces four critical evaluation dimensions:\nCharacter Attributes, Structured Character Locations, Multi-Dimensional Scene\nAttributes, and Explicit Spatial/Interactive Relationships. The benchmark\ncomprises long and detail-rich prompts averaging 284.89 tokens, with high\nquality validated by expert annotators. Evaluation on 7 general-purpose and 5\nlong-prompt-optimized T2I models reveals critical performance limitations:\nstate-of-the-art models achieve merely ~50% accuracy in key dimensions like\nattribute binding and spatial reasoning, while all models showing progressive\nperformance degradation as prompt length increases. Our analysis highlights\nsystemic failures in structural comprehension and detail overload handling,\nmotivating future research into architectures with enhanced compositional\nreasoning. We open-source the dataset, data curation code, and evaluation tools\nto advance detail-rich T2I generation and enable broad applications that would\notherwise be infeasible due to the lack of a dedicated benchmark.", "AI": {"tldr": "DetailMaster is a benchmark for evaluating text-to-image models on long, detail-rich prompts, revealing performance limitations and motivating future research.", "motivation": "Current T2I models struggle with long, detail-intensive prompts, limiting professional applications.", "method": "DetailMaster introduces four evaluation dimensions and tests 12 T2I models using expert-validated prompts.", "result": "Models achieve ~50% accuracy in key areas, with performance degrading as prompts lengthen.", "conclusion": "The benchmark highlights systemic failures and encourages research into better compositional reasoning architectures."}}
{"id": "2505.16936", "pdf": "https://arxiv.org/pdf/2505.16936", "abs": "https://arxiv.org/abs/2505.16936", "authors": ["Yizhuo Chen", "Tianchen Wang", "You Lyu", "Yanlan Hu", "Jinyang Li", "Tomoyoshi Kimura", "Hongjue Zhao", "Yigong Hu", "Denizhan Kara", "Tarek Abdelzaher"], "title": "SPAR: Self-supervised Placement-Aware Representation Learning for Multi-Node IoT Systems", "categories": ["cs.LG"], "comment": null, "summary": "This work develops the underpinnings of self-supervised placement-aware\nrepresentation learning given spatially-distributed (multi-view and multimodal)\nsensor observations, motivated by the need to represent external environmental\nstate in multi-sensor IoT systems in a manner that correctly distills spatial\nphenomena from the distributed multi-vantage observations. The objective of\nsensing in IoT systems is, in general, to collectively represent an externally\nobserved environment given multiple vantage points from which sensory\nobservations occur. Pretraining of models that help interpret sensor data must\ntherefore encode the relation between signals observed by sensors and the\nobservers' vantage points in order to attain a representation that encodes the\nobserved spatial phenomena in a manner informed by the specific placement of\nthe measuring instruments, while allowing arbitrary placement. The work\nsignificantly advances self-supervised model pretraining from IoT signals\nbeyond current solutions that often overlook the distinctive spatial nature of\nIoT data. Our framework explicitly learns the dependencies between measurements\nand geometric observer layouts and structural characteristics, guided by a core\ndesign principle: the duality between signals and observer positions. We\nfurther provide theoretical analyses from the perspectives of information\ntheory and occlusion-invariant representation learning to offer insight into\nthe rationale behind our design. Experiments on three real-world\ndatasets--covering vehicle monitoring, human activity recognition, and\nearthquake localization--demonstrate the superior generalizability and\nrobustness of our method across diverse modalities, sensor placements,\napplication-level inference tasks, and spatial scales.", "AI": {"tldr": "The paper introduces a self-supervised learning framework for placement-aware representation of multi-sensor IoT data, emphasizing spatial phenomena and sensor placement dependencies.", "motivation": "To address the need for representing environmental state in IoT systems by distilling spatial phenomena from distributed multi-view sensor observations, overcoming limitations of current methods that ignore spatial nature.", "method": "Develops a framework that learns dependencies between measurements and geometric observer layouts, guided by the duality between signals and observer positions, with theoretical grounding in information theory and occlusion-invariant learning.", "result": "Demonstrates superior generalizability and robustness across diverse modalities, sensor placements, and tasks (vehicle monitoring, human activity recognition, earthquake localization).", "conclusion": "The work advances self-supervised pretraining for IoT signals by explicitly modeling spatial dependencies, offering a robust and generalizable solution."}}
{"id": "2505.16862", "pdf": "https://arxiv.org/pdf/2505.16862", "abs": "https://arxiv.org/abs/2505.16862", "authors": ["Chaoyang Wang", "Xiangtai Li", "Lu Qi", "Xiaofan Lin", "Jinbin Bai", "Qianyu Zhou", "Yunhai Tong"], "title": "Conditional Panoramic Image Generation via Masked Autoregressive Modeling", "categories": ["cs.CV"], "comment": null, "summary": "Recent progress in panoramic image generation has underscored two critical\nlimitations in existing approaches. First, most methods are built upon\ndiffusion models, which are inherently ill-suited for equirectangular\nprojection (ERP) panoramas due to the violation of the identically and\nindependently distributed (i.i.d.) Gaussian noise assumption caused by their\nspherical mapping. Second, these methods often treat text-conditioned\ngeneration (text-to-panorama) and image-conditioned generation (panorama\noutpainting) as separate tasks, relying on distinct architectures and\ntask-specific data. In this work, we propose a unified framework, Panoramic\nAutoRegressive model (PAR), which leverages masked autoregressive modeling to\naddress these challenges. PAR avoids the i.i.d. assumption constraint and\nintegrates text and image conditioning into a cohesive architecture, enabling\nseamless generation across tasks. To address the inherent discontinuity in\nexisting generative models, we introduce circular padding to enhance spatial\ncoherence and propose a consistency alignment strategy to improve generation\nquality. Extensive experiments demonstrate competitive performance in\ntext-to-image generation and panorama outpainting tasks while showcasing\npromising scalability and generalization capabilities.", "AI": {"tldr": "The paper introduces PAR, a unified framework for panoramic image generation, addressing limitations of diffusion models and task separation in existing methods.", "motivation": "Existing methods for panoramic image generation are limited by diffusion models' incompatibility with equirectangular projection and the separation of text-to-panorama and panorama outpainting tasks.", "method": "The proposed Panoramic AutoRegressive model (PAR) uses masked autoregressive modeling, circular padding, and consistency alignment to unify tasks and improve spatial coherence.", "result": "PAR demonstrates competitive performance in text-to-image generation and panorama outpainting, with scalability and generalization.", "conclusion": "PAR effectively addresses key challenges in panoramic image generation, offering a unified and scalable solution."}}
{"id": "2505.16922", "pdf": "https://arxiv.org/pdf/2505.16922", "abs": "https://arxiv.org/abs/2505.16922", "authors": ["Ruihan Yang", "Caiqi Zhang", "Zhisong Zhang", "Xinting Huang", "Dong Yu", "Nigel Collier", "Deqing Yang"], "title": "UNCLE: Uncertainty Expressions in Long-Form Generation", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are prone to hallucination, particularly in\nlong-form generations. A promising direction to mitigate hallucination is to\nteach LLMs to express uncertainty explicitly when they lack sufficient\nknowledge. However, existing work lacks direct and fair evaluation of LLMs'\nability to express uncertainty effectively in long-form generation. To address\nthis gap, we first introduce UNCLE, a benchmark designed to evaluate\nuncertainty expression in both long- and short-form question answering (QA).\nUNCLE spans five domains and comprises 4k long-form QA instances and over 20k\nshort-form QA pairs. Our dataset is the first to directly bridge short- and\nlong-form QA with paired questions and gold-standard answers. Along with the\nbenchmark, we propose a suite of new metrics to assess the models' capabilities\nto selectively express uncertainty. Using UNCLE, we then demonstrate that\ncurrent models fail to convey uncertainty appropriately in long-form\ngeneration. We further explore both prompt-based and training-based methods to\nimprove models' performance, with the training-based methods yielding greater\ngains. Further analysis of alignment gaps between short- and long-form\nuncertainty expression highlights promising directions for future research\nusing UNCLE.", "AI": {"tldr": "UNCLE benchmark evaluates LLMs' uncertainty expression in QA, showing current models fail in long-form generation. Training-based methods improve performance.", "motivation": "Address the gap in evaluating LLMs' ability to express uncertainty in long-form generation, which is prone to hallucination.", "method": "Introduce UNCLE benchmark with paired QA instances and propose metrics. Test prompt- and training-based methods.", "result": "Current models inadequately express uncertainty in long-form QA. Training-based methods outperform prompt-based ones.", "conclusion": "UNCLE highlights alignment gaps and suggests future research directions for improving uncertainty expression in LLMs."}}
{"id": "2505.16927", "pdf": "https://arxiv.org/pdf/2505.16927", "abs": "https://arxiv.org/abs/2505.16927", "authors": ["Keshav Ramji", "Tahira Naseem", "Ram\u00f3n Fernandez Astudillo"], "title": "Latent Principle Discovery for Language Model Self-Improvement", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "When language model (LM) users aim to improve the quality of its generations,\nit is crucial to specify concrete behavioral attributes that the model should\nstrive to reflect. However, curating such principles across many domains, even\nnon-exhaustively, requires a labor-intensive annotation process. To automate\nthis process, we propose eliciting these latent attributes guiding model\nreasoning towards human-preferred responses by explicitly modeling them in a\nself-correction setting. Our approach mines new principles from the LM itself\nand compresses the discovered elements to an interpretable set via clustering.\nSpecifically, we employ an approximation of posterior-regularized Monte Carlo\nExpectation-Maximization to both identify a condensed set of the most effective\nlatent principles and teach the LM to strategically invoke them in order to\nintrinsically refine its responses. We demonstrate that bootstrapping our\nalgorithm over multiple iterations enables smaller language models (7-8B\nparameters) to self-improve, achieving +8-10% in AlpacaEval win-rate, an\naverage of +0.3 on MT-Bench, and +19-23% in principle-following win-rate on\nIFEval. We also show that clustering the principles yields interpretable and\ndiverse model-generated constitutions while retaining model performance. The\ngains our method achieves highlight the potential of automated,\nprinciple-driven post-training recipes toward continual self-improvement.", "AI": {"tldr": "The paper proposes an automated method for eliciting and refining latent behavioral attributes in language models to improve response quality, achieving significant performance gains.", "motivation": "Manual annotation of behavioral attributes for language models is labor-intensive, prompting the need for an automated approach.", "method": "The method uses self-correction and clustering to mine and compress latent principles from the model, employing posterior-regularized Monte Carlo Expectation-Maximization.", "result": "Smaller language models (7-8B parameters) improved by +8-10% in AlpacaEval win-rate, +0.3 on MT-Bench, and +19-23% in principle-following win-rate on IFEval.", "conclusion": "Automated, principle-driven post-training can enable continual self-improvement in language models."}}
{"id": "2505.16941", "pdf": "https://arxiv.org/pdf/2505.16941", "abs": "https://arxiv.org/abs/2505.16941", "authors": ["Chao Pang", "Vincent Jeanselme", "Young Sang Choi", "Xinzhuo Jiang", "Zilin Jing", "Aparajita Kashyap", "Yuta Kobayashi", "Yanwei Li", "Florent Pollet", "Karthik Natarajan", "Shalmali Joshi"], "title": "FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Foundation models hold significant promise in healthcare, given their\ncapacity to extract meaningful representations independent of downstream tasks.\nThis property has enabled state-of-the-art performance across several clinical\napplications trained on structured electronic health record (EHR) data, even in\nsettings with limited labeled data, a prevalent challenge in healthcare.\nHowever, there is little consensus on these models' potential for clinical\nutility due to the lack of desiderata of comprehensive and meaningful tasks and\nsufficiently diverse evaluations to characterize the benefit over conventional\nsupervised learning. To address this gap, we propose a suite of clinically\nmeaningful tasks spanning patient outcomes, early prediction of acute and\nchronic conditions, including desiderata for robust evaluations. We evaluate\nstate-of-the-art foundation models on EHR data consisting of 5 million patients\nfrom Columbia University Irving Medical Center (CUMC), a large urban academic\nmedical center in New York City, across 14 clinically relevant tasks. We\nmeasure overall accuracy, calibration, and subpopulation performance to surface\ntradeoffs based on the choice of pre-training, tokenization, and data\nrepresentation strategies. Our study aims to advance the empirical evaluation\nof structured EHR foundation models and guide the development of future\nhealthcare foundation models.", "AI": {"tldr": "The paper evaluates foundation models in healthcare, proposing a suite of clinically meaningful tasks and robust evaluation criteria to address gaps in understanding their clinical utility.", "motivation": "To assess the potential of foundation models in healthcare due to their ability to extract meaningful representations from EHR data, despite limited labeled data and lack of consensus on clinical utility.", "method": "Proposes a suite of clinically relevant tasks and evaluates state-of-the-art foundation models on EHR data from 5 million patients across 14 tasks, measuring accuracy, calibration, and subpopulation performance.", "result": "The study provides insights into the performance tradeoffs of foundation models based on pre-training, tokenization, and data representation strategies.", "conclusion": "The research aims to improve empirical evaluation of EHR foundation models and guide future development in healthcare."}}
{"id": "2505.16864", "pdf": "https://arxiv.org/pdf/2505.16864", "abs": "https://arxiv.org/abs/2505.16864", "authors": ["Yuechen Zhang", "Jinbo Xing", "Bin Xia", "Shaoteng Liu", "Bohao Peng", "Xin Tao", "Pengfei Wan", "Eric Lo", "Jiaya Jia"], "title": "Training-Free Efficient Video Generation via Dynamic Token Carving", "categories": ["cs.CV"], "comment": "Project Page: https://julianjuaner.github.io/projects/jenga/ , 24\n  pages", "summary": "Despite the remarkable generation quality of video Diffusion Transformer\n(DiT) models, their practical deployment is severely hindered by extensive\ncomputational requirements. This inefficiency stems from two key challenges:\nthe quadratic complexity of self-attention with respect to token length and the\nmulti-step nature of diffusion models. To address these limitations, we present\nJenga, a novel inference pipeline that combines dynamic attention carving with\nprogressive resolution generation. Our approach leverages two key insights: (1)\nearly denoising steps do not require high-resolution latents, and (2) later\nsteps do not require dense attention. Jenga introduces a block-wise attention\nmechanism that dynamically selects relevant token interactions using 3D\nspace-filling curves, alongside a progressive resolution strategy that\ngradually increases latent resolution during generation. Experimental results\ndemonstrate that Jenga achieves substantial speedups across multiple\nstate-of-the-art video diffusion models while maintaining comparable generation\nquality (8.83$\\times$ speedup with 0.01\\% performance drop on VBench). As a\nplug-and-play solution, Jenga enables practical, high-quality video generation\non modern hardware by reducing inference time from minutes to seconds --\nwithout requiring model retraining. Code:\nhttps://github.com/dvlab-research/Jenga", "AI": {"tldr": "Jenga is an efficient inference pipeline for video Diffusion Transformer models, combining dynamic attention carving and progressive resolution generation to reduce computational costs while maintaining quality.", "motivation": "The high computational demands of video Diffusion Transformer models hinder their practical deployment due to quadratic complexity in self-attention and multi-step diffusion processes.", "method": "Jenga uses block-wise attention with 3D space-filling curves for dynamic token selection and progressive resolution generation to reduce redundant computations.", "result": "Jenga achieves an 8.83\u00d7 speedup with minimal performance drop (0.01%) on VBench, reducing inference time from minutes to seconds.", "conclusion": "Jenga enables practical, high-quality video generation on modern hardware without retraining, making it a plug-and-play solution."}}
{"id": "2505.16931", "pdf": "https://arxiv.org/pdf/2505.16931", "abs": "https://arxiv.org/abs/2505.16931", "authors": ["Matthew Zent", "Digory Smith", "Simon Woodhead"], "title": "PIIvot: A Lightweight NLP Anonymization Framework for Question-Anchored Tutoring Dialogues", "categories": ["cs.CL"], "comment": "6 pages, 2 figures, submitted to EMNLP 2025, for associated dataset,\n  see\n  https://huggingface.co/datasets/Eedi/Question-Anchored-Tutoring-Dialogues-2k", "summary": "Personally identifiable information (PII) anonymization is a high-stakes task\nthat poses a barrier to many open-science data sharing initiatives. While PII\nidentification has made large strides in recent years, in practice, error\nthresholds and the recall/precision trade-off still limit the uptake of these\nanonymization pipelines. We present PIIvot, a lighter-weight framework for PII\nanonymization that leverages knowledge of the data context to simplify the PII\ndetection problem. To demonstrate its effectiveness, we also contribute\nQATD-2k, the largest open-source real-world tutoring dataset of its kind, to\nsupport the demand for quality educational dialogue data.", "AI": {"tldr": "PIIvot is a lightweight framework for PII anonymization that uses data context to simplify detection, demonstrated with QATD-2k, a large tutoring dataset.", "motivation": "PII anonymization is critical for open-science data sharing but faces challenges in error thresholds and recall/precision trade-offs.", "method": "PIIvot leverages data context knowledge to simplify PII detection.", "result": "The framework is demonstrated with QATD-2k, a large open-source tutoring dataset.", "conclusion": "PIIvot offers a practical solution for PII anonymization, supported by real-world educational data."}}
{"id": "2505.16947", "pdf": "https://arxiv.org/pdf/2505.16947", "abs": "https://arxiv.org/abs/2505.16947", "authors": ["Csaba D\u00e9k\u00e1ny", "Stefan Balauca", "Robin Staab", "Dimitar I. Dimitrov", "Martin Vechev"], "title": "MixAT: Combining Continuous and Discrete Adversarial Training for LLMs", "categories": ["cs.LG", "cs.AI", "I.2.7; K.4.1"], "comment": null, "summary": "Despite recent efforts in Large Language Models (LLMs) safety and alignment,\ncurrent adversarial attacks on frontier LLMs are still able to force harmful\ngenerations consistently. Although adversarial training has been widely studied\nand shown to significantly improve the robustness of traditional machine\nlearning models, its strengths and weaknesses in the context of LLMs are less\nunderstood. Specifically, while existing discrete adversarial attacks are\neffective at producing harmful content, training LLMs with concrete adversarial\nprompts is often computationally expensive, leading to reliance on continuous\nrelaxations. As these relaxations do not correspond to discrete input tokens,\nsuch latent training methods often leave models vulnerable to a diverse set of\ndiscrete attacks. In this work, we aim to bridge this gap by introducing MixAT,\na novel method that combines stronger discrete and faster continuous attacks\nduring training. We rigorously evaluate MixAT across a wide spectrum of\nstate-of-the-art attacks, proposing the At Least One Attack Success Rate\n(ALO-ASR) metric to capture the worst-case vulnerability of models. We show\nMixAT achieves substantially better robustness (ALO-ASR < 20%) compared to\nprior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to\nmethods based on continuous relaxations. We further analyze MixAT in realistic\ndeployment settings, exploring how chat templates, quantization, low-rank\nadapters, and temperature affect both adversarial training and evaluation,\nrevealing additional blind spots in current methodologies. Our results\ndemonstrate that MixAT's discrete-continuous defense offers a principled and\nsuperior robustness-accuracy tradeoff with minimal computational overhead,\nhighlighting its promise for building safer LLMs. We provide our code and\nmodels at https://github.com/insait-institute/MixAT.", "AI": {"tldr": "MixAT combines discrete and continuous adversarial attacks during training to improve LLM robustness, achieving better defense (ALO-ASR < 20%) with minimal computational overhead.", "motivation": "Current adversarial training methods for LLMs rely on continuous relaxations, leaving models vulnerable to discrete attacks. MixAT aims to bridge this gap.", "method": "MixAT integrates stronger discrete and faster continuous attacks in training, evaluated using the ALO-ASR metric.", "result": "MixAT outperforms prior defenses (ALO-ASR < 20% vs. > 50%) and maintains runtime efficiency.", "conclusion": "MixAT offers a superior robustness-accuracy tradeoff, promising safer LLMs with minimal overhead."}}
{"id": "2505.16950", "pdf": "https://arxiv.org/pdf/2505.16950", "abs": "https://arxiv.org/abs/2505.16950", "authors": ["Adnan Oomerjee", "Zafeirios Fountas", "Zhongwei Yu", "Haitham Bou-Ammar", "Jun Wang"], "title": "Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": null, "summary": "Despite their impressive capabilities, Large Language Models struggle with\ngeneralisation beyond their training distribution, often exhibiting\nsophisticated pattern interpolation rather than true abstract reasoning\n(extrapolation). In this work, we approach this limitation through the lens of\nInformation Bottleneck (IB) theory, which posits that model generalisation\nemerges from an optimal balance between input compression and retention of\npredictive information in latent representations. We prove using IB theory that\ndecoder-only Transformers are inherently constrained in their ability to form\ntask-optimal sequence representations. We then use this result to demonstrate\nthat periodic global transformation of the internal sequence-level\nrepresentations (KV cache) is a necessary computational step for improving\nTransformer generalisation in reasoning tasks. Based on these theoretical\ninsights, we propose a modification to the Transformer architecture, in the\nform of an additional module that globally rewrites the KV cache at periodic\nintervals, shifting its capacity away from memorising input prefixes and toward\nencoding features most useful for predicting future tokens. Our model delivers\nsubstantial gains on mathematical reasoning benchmarks, outperforming both\nvanilla Transformers with up to 3.5x more parameters, as well as\nheuristic-driven pruning mechanisms for cache compression. Our approach can be\nseen as a principled generalisation of existing KV-cache compression methods;\nwhereas such methods focus solely on compressing input representations, they\noften do so at the expense of retaining predictive information, and thus their\ncapabilities are inherently bounded by those of an unconstrained model. This\nestablishes a principled framework to manipulate Transformer memory using\ninformation theory, addressing fundamental reasoning limitations that scaling\nalone cannot overcome.", "AI": {"tldr": "The paper addresses the generalization limitations of Large Language Models by proposing a Transformer modification based on Information Bottleneck theory, improving reasoning tasks.", "motivation": "Large Language Models struggle with true abstract reasoning, relying on pattern interpolation. The work aims to enhance their generalization using Information Bottleneck theory.", "method": "The authors propose a Transformer modification involving periodic global transformation of internal sequence-level representations (KV cache) to improve reasoning.", "result": "The modified model outperforms vanilla Transformers and heuristic-driven pruning, achieving substantial gains on mathematical reasoning benchmarks.", "conclusion": "The approach provides a principled framework for manipulating Transformer memory, addressing reasoning limitations beyond scaling."}}
{"id": "2505.16882", "pdf": "https://arxiv.org/pdf/2505.16882", "abs": "https://arxiv.org/abs/2505.16882", "authors": ["Isla Duporge", "Sofia Minano", "Nikoloz Sirmpilatze", "Igor Tatarnikov", "Scott Wolf", "Adam L. Tyson", "Daniel Rubenstein"], "title": "Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga)", "categories": ["cs.CV"], "comment": "Accepted to the CV4Animals workshop at CVPR 2025", "summary": "Ethological research increasingly benefits from the growing affordability and\naccessibility of drones, which enable the capture of high-resolution footage of\nanimal movement at fine spatial and temporal scales. However, analyzing such\nfootage presents the technical challenge of separating animal movement from\ndrone motion. While non-trivial, computer vision techniques such as image\nregistration and Structure-from-Motion (SfM) offer practical solutions. For\nconservationists, open-source tools that are user-friendly, require minimal\nsetup, and deliver timely results are especially valuable for efficient data\ninterpretation. This study evaluates three approaches: a bioimaging-based\nregistration technique, an SfM pipeline, and a hybrid interpolation method. We\napply these to a recorded escape event involving 44 plains zebras, captured in\na single drone video. Using the best-performing method, we extract individual\ntrajectories and identify key behavioral patterns: increased alignment\n(polarization) during escape, a brief widening of spacing just before stopping,\nand tighter coordination near the group's center. These insights highlight the\nmethod's effectiveness and its potential to scale to larger datasets,\ncontributing to broader investigations of collective animal behavior.", "AI": {"tldr": "The paper evaluates three computer vision methods to separate animal movement from drone motion in ethological research, using zebra escape footage to extract behavioral insights.", "motivation": "The need for accessible, efficient tools to analyze high-resolution drone footage of animal movement, addressing the challenge of separating animal motion from drone motion.", "method": "Three approaches are tested: a bioimaging-based registration technique, a Structure-from-Motion (SfM) pipeline, and a hybrid interpolation method, applied to drone footage of 44 zebras.", "result": "The best method successfully extracted individual trajectories, revealing behavioral patterns like increased alignment during escape and tighter coordination near the group's center.", "conclusion": "The study demonstrates the method's effectiveness for analyzing collective animal behavior and its scalability for larger datasets."}}
{"id": "2505.16934", "pdf": "https://arxiv.org/pdf/2505.16934", "abs": "https://arxiv.org/abs/2505.16934", "authors": ["Yepeng Liu", "Xuandong Zhao", "Christopher Kruegel", "Dawn Song", "Yuheng Bu"], "title": "In-Context Watermarks for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The growing use of large language models (LLMs) for sensitive applications\nhas highlighted the need for effective watermarking techniques to ensure the\nprovenance and accountability of AI-generated text. However, most existing\nwatermarking methods require access to the decoding process, limiting their\napplicability in real-world settings. One illustrative example is the use of\nLLMs by dishonest reviewers in the context of academic peer review, where\nconference organizers have no access to the model used but still need to detect\nAI-generated reviews. Motivated by this gap, we introduce In-Context\nWatermarking (ICW), which embeds watermarks into generated text solely through\nprompt engineering, leveraging LLMs' in-context learning and\ninstruction-following abilities. We investigate four ICW strategies at\ndifferent levels of granularity, each paired with a tailored detection method.\nWe further examine the Indirect Prompt Injection (IPI) setting as a specific\ncase study, in which watermarking is covertly triggered by modifying input\ndocuments such as academic manuscripts. Our experiments validate the\nfeasibility of ICW as a model-agnostic, practical watermarking approach.\nMoreover, our findings suggest that as LLMs become more capable, ICW offers a\npromising direction for scalable and accessible content attribution.", "AI": {"tldr": "In-Context Watermarking (ICW) embeds watermarks into AI-generated text via prompt engineering, enabling detection without model access, validated in experiments.", "motivation": "Addressing the need for watermarking AI-generated text in real-world settings where model access is restricted, such as detecting dishonest peer reviews.", "method": "ICW uses prompt engineering to embed watermarks, leveraging LLMs' in-context learning. Four strategies are explored, each with tailored detection methods, including Indirect Prompt Injection (IPI).", "result": "Experiments confirm ICW's feasibility as a model-agnostic watermarking approach, scalable with advancing LLMs.", "conclusion": "ICW is a practical, scalable solution for content attribution in AI-generated text, especially as LLMs improve."}}
{"id": "2505.16957", "pdf": "https://arxiv.org/pdf/2505.16957", "abs": "https://arxiv.org/abs/2505.16957", "authors": ["Junjie Xiong", "Changjia Zhu", "Shuhang Lin", "Chong Zhang", "Yongfeng Zhang", "Yao Liu", "Lingyao Li"], "title": "Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly equipped with capabilities of\nreal-time web search and integrated with protocols like Model Context Protocol\n(MCP). This extension could introduce new security vulnerabilities. We present\na systematic investigation of LLM vulnerabilities to hidden adversarial prompts\nthrough malicious font injection in external resources like webpages, where\nattackers manipulate code-to-glyph mapping to inject deceptive content which\nare invisible to users. We evaluate two critical attack scenarios: (1)\n\"malicious content relay\" and (2) \"sensitive data leakage\" through MCP-enabled\ntools. Our experiments reveal that indirect prompts with injected malicious\nfont can bypass LLM safety mechanisms through external resources, achieving\nvarying success rates based on data sensitivity and prompt design. Our research\nunderscores the urgent need for enhanced security measures in LLM deployments\nwhen processing external content.", "AI": {"tldr": "The paper investigates vulnerabilities in LLMs due to hidden adversarial prompts via malicious font injection in webpages, revealing risks like malicious content relay and data leakage.", "motivation": "To systematically explore security vulnerabilities introduced by real-time web search and MCP integration in LLMs, focusing on hidden adversarial prompts.", "method": "The study evaluates attack scenarios (malicious content relay and sensitive data leakage) using malicious font injection in external resources.", "result": "Experiments show indirect prompts with malicious fonts can bypass LLM safety mechanisms, with success rates varying by data sensitivity and prompt design.", "conclusion": "The findings highlight the need for stronger security measures in LLMs when handling external content."}}
{"id": "2505.16952", "pdf": "https://arxiv.org/pdf/2505.16952", "abs": "https://arxiv.org/abs/2505.16952", "authors": ["Shengyu Feng", "Weiwei Sun", "Shanda Li", "Ameet Talwalkar", "Yiming Yang"], "title": "A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning (ML) has demonstrated considerable potential in supporting\nmodel design and optimization for combinatorial optimization (CO) problems.\nHowever, much of the progress to date has been evaluated on small-scale,\nsynthetic datasets, raising concerns about the practical effectiveness of\nML-based solvers in real-world, large-scale CO scenarios. Additionally, many\nexisting CO benchmarks lack sufficient training data, limiting their utility\nfor evaluating data-driven approaches. To address these limitations, we\nintroduce FrontierCO, a comprehensive benchmark that covers eight canonical CO\nproblem types and evaluates 16 representative ML-based solvers--including graph\nneural networks and large language model (LLM) agents. FrontierCO features\nchallenging instances drawn from industrial applications and frontier CO\nresearch, offering both realistic problem difficulty and abundant training\ndata. Our empirical results provide critical insights into the strengths and\nlimitations of current ML methods, helping to guide more robust and practically\nrelevant advances at the intersection of machine learning and combinatorial\noptimization. Our data is available at\nhttps://huggingface.co/datasets/CO-Bench/FrontierCO.", "AI": {"tldr": "The paper introduces FrontierCO, a benchmark for evaluating ML-based solvers in combinatorial optimization (CO) using realistic, large-scale data.", "motivation": "Existing CO benchmarks lack sufficient training data and are often limited to small-scale, synthetic datasets, raising concerns about the practical effectiveness of ML-based solvers.", "method": "FrontierCO covers eight CO problem types and evaluates 16 ML-based solvers, including graph neural networks and LLM agents, using industrial and research-derived instances.", "result": "The benchmark provides insights into the strengths and limitations of current ML methods in CO, highlighting practical challenges.", "conclusion": "FrontierCO aims to guide more robust and relevant advances in ML for CO by offering realistic problem difficulty and abundant training data."}}
{"id": "2505.16902", "pdf": "https://arxiv.org/pdf/2505.16902", "abs": "https://arxiv.org/abs/2505.16902", "authors": ["Junzhe Jiang", "Nan Song", "Jingyu Li", "Xiatian Zhu", "Li Zhang"], "title": "RealEngine: Simulating Autonomous Driving in Realistic Context", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Driving simulation plays a crucial role in developing reliable driving agents\nby providing controlled, evaluative environments. To enable meaningful\nassessments, a high-quality driving simulator must satisfy several key\nrequirements: multi-modal sensing capabilities (e.g., camera and LiDAR) with\nrealistic scene rendering to minimize observational discrepancies; closed-loop\nevaluation to support free-form trajectory behaviors; highly diverse traffic\nscenarios for thorough evaluation; multi-agent cooperation to capture\ninteraction dynamics; and high computational efficiency to ensure affordability\nand scalability. However, existing simulators and benchmarks fail to\ncomprehensively meet these fundamental criteria. To bridge this gap, this paper\nintroduces RealEngine, a novel driving simulation framework that holistically\nintegrates 3D scene reconstruction and novel view synthesis techniques to\nachieve realistic and flexible closed-loop simulation in the driving context.\nBy leveraging real-world multi-modal sensor data, RealEngine reconstructs\nbackground scenes and foreground traffic participants separately, allowing for\nhighly diverse and realistic traffic scenarios through flexible scene\ncomposition. This synergistic fusion of scene reconstruction and view synthesis\nenables photorealistic rendering across multiple sensor modalities, ensuring\nboth perceptual fidelity and geometric accuracy. Building upon this\nenvironment, RealEngine supports three essential driving simulation categories:\nnon-reactive simulation, safety testing, and multi-agent interaction,\ncollectively forming a reliable and comprehensive benchmark for evaluating the\nreal-world performance of driving agents.", "AI": {"tldr": "RealEngine is a driving simulation framework integrating 3D scene reconstruction and novel view synthesis for realistic, closed-loop simulation, addressing gaps in existing simulators.", "motivation": "Existing simulators lack multi-modal sensing, diverse scenarios, and computational efficiency, limiting reliable driving agent evaluation.", "method": "RealEngine uses real-world sensor data to separately reconstruct scenes and traffic participants, enabling flexible, photorealistic rendering.", "result": "The framework supports non-reactive simulation, safety testing, and multi-agent interaction, forming a comprehensive benchmark.", "conclusion": "RealEngine bridges key gaps in driving simulation, offering a reliable tool for evaluating driving agents."}}
{"id": "2505.16956", "pdf": "https://arxiv.org/pdf/2505.16956", "abs": "https://arxiv.org/abs/2505.16956", "authors": ["Daniil Gurgurov", "Michal Gregor", "Josef van Genabith", "Simon Ostermann"], "title": "On Multilingual Encoder Language Model Compression for Low-Resource Languages", "categories": ["cs.CL"], "comment": "Pre-print", "summary": "In this paper, we combine two-step knowledge distillation, structured\npruning, truncation, and vocabulary trimming for extremely compressing\nmultilingual encoder-only language models for low-resource languages. Our novel\napproach systematically combines existing techniques and takes them to the\nextreme, reducing layer depth, feed-forward hidden size, and intermediate layer\nembedding size to create significantly smaller monolingual models while\nretaining essential language-specific knowledge. We achieve compression rates\nof up to 92% with only a marginal performance drop of 2-10% in four downstream\ntasks, including sentiment analysis, topic classification, named entity\nrecognition, and part-of-speech tagging, across three low-resource languages.\nNotably, the performance degradation correlates with the amount of\nlanguage-specific data in the teacher model, with larger datasets resulting in\nsmaller performance losses. Additionally, we conduct extensive ablation studies\nto identify best practices for multilingual model compression using these\ntechniques.", "AI": {"tldr": "The paper presents a method for extreme compression of multilingual encoder-only language models for low-resource languages, achieving up to 92% compression with minimal performance loss.", "motivation": "To create significantly smaller monolingual models for low-resource languages while retaining essential language-specific knowledge.", "method": "Combines two-step knowledge distillation, structured pruning, truncation, and vocabulary trimming to reduce layer depth, feed-forward hidden size, and intermediate layer embedding size.", "result": "Achieves compression rates of up to 92% with only a 2-10% performance drop in downstream tasks like sentiment analysis and named entity recognition.", "conclusion": "The performance degradation correlates with the teacher model's language-specific data, and the paper provides best practices for multilingual model compression."}}
{"id": "2505.16965", "pdf": "https://arxiv.org/pdf/2505.16965", "abs": "https://arxiv.org/abs/2505.16965", "authors": ["Fengyi Li", "Kayhan Behdin", "Natesh Pillai", "Xiaofeng Wang", "Zhipeng Wang", "Ercan Yildiz"], "title": "BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Text segmentation based on the semantic meaning of sentences is a fundamental\ntask with broad utility in many downstream applications. In this paper, we\npropose a graphical model-based unsupervised learning approach, named BP-Seg\nfor efficient text segmentation. Our method not only considers local coherence,\ncapturing the intuition that adjacent sentences are often more related, but\nalso effectively groups sentences that are distant in the text yet semantically\nsimilar. This is achieved through belief propagation on the carefully\nconstructed graphical models. Experimental results on both an illustrative\nexample and a dataset with long-form documents demonstrate that our method\nperforms favorably compared to competing approaches.", "AI": {"tldr": "BP-Seg, an unsupervised graphical model-based method, efficiently segments text by considering local coherence and distant semantic similarity, outperforming competitors.", "motivation": "Text segmentation is crucial for downstream applications, requiring methods that handle both local coherence and distant semantic relationships.", "method": "BP-Seg uses belief propagation on graphical models to group adjacent and semantically similar sentences.", "result": "Outperforms competing approaches on illustrative examples and long-form documents.", "conclusion": "BP-Seg is effective for text segmentation by balancing local and global semantic relationships."}}
{"id": "2505.16953", "pdf": "https://arxiv.org/pdf/2505.16953", "abs": "https://arxiv.org/abs/2505.16953", "authors": ["Young Sang Choi", "Vincent Jeanselme", "Pierre Elias", "Shalmali Joshi"], "title": "ICYM2I: The illusion of multimodal informativeness under missingness", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multimodal learning is of continued interest in artificial intelligence-based\napplications, motivated by the potential information gain from combining\ndifferent types of data. However, modalities collected and curated during\ndevelopment may differ from the modalities available at deployment due to\nmultiple factors including cost, hardware failure, or -- as we argue in this\nwork -- the perceived informativeness of a given modality. Na{\\\"i}ve estimation\nof the information gain associated with including an additional modality\nwithout accounting for missingness may result in improper estimates of that\nmodality's value in downstream tasks. Our work formalizes the problem of\nmissingness in multimodal learning and demonstrates the biases resulting from\nignoring this process. To address this issue, we introduce ICYM2I (In Case You\nMultimodal Missed It), a framework for the evaluation of predictive performance\nand information gain under missingness through inverse probability\nweighting-based correction. We demonstrate the importance of the proposed\nadjustment to estimate information gain under missingness on synthetic,\nsemi-synthetic, and real-world medical datasets.", "AI": {"tldr": "The paper addresses biases in multimodal learning due to missing modalities and proposes ICYM2I, a framework for evaluating performance and information gain under missingness using inverse probability weighting.", "motivation": "Multimodal learning's potential is hindered by discrepancies between development and deployment modalities, leading to biased estimates of modality value.", "method": "Introduces ICYM2I, a framework using inverse probability weighting to correct for missingness in multimodal learning.", "result": "Demonstrates the framework's effectiveness on synthetic, semi-synthetic, and real-world medical datasets.", "conclusion": "Accounting for missingness is crucial for accurate estimation of modality value in multimodal learning."}}
{"id": "2505.16942", "pdf": "https://arxiv.org/pdf/2505.16942", "abs": "https://arxiv.org/abs/2505.16942", "authors": ["Karlis Martins Briedis", "Markus Gross", "Christopher Schroers"], "title": "Efficient Correlation Volume Sampling for Ultra-High-Resolution Optical Flow Estimation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent optical flow estimation methods often employ local cost sampling from\na dense all-pairs correlation volume. This results in quadratic computational\nand memory complexity in the number of pixels. Although an alternative\nmemory-efficient implementation with on-demand cost computation exists, this is\nslower in practice and therefore prior methods typically process images at\nreduced resolutions, missing fine-grained details.\n  To address this, we propose a more efficient implementation of the all-pairs\ncorrelation volume sampling, still matching the exact mathematical operator as\ndefined by RAFT. Our approach outperforms on-demand sampling by up to 90% while\nmaintaining low memory usage, and performs on par with the default\nimplementation with up to 95% lower memory usage. As cost sampling makes up a\nsignificant portion of the overall runtime, this can translate to up to 50%\nsavings for the total end-to-end model inference in memory-constrained\nenvironments. Our evaluation of existing methods includes an 8K\nultra-high-resolution dataset and an additional inference-time modification of\nthe recent SEA-RAFT method. With this, we achieve state-of-the-art results at\nhigh resolutions both in accuracy and efficiency.", "AI": {"tldr": "Proposes a memory-efficient implementation of all-pairs correlation volume sampling for optical flow estimation, reducing memory usage by 95% and improving speed by 90% compared to on-demand sampling.", "motivation": "Existing methods for optical flow estimation suffer from high computational and memory complexity, often forcing reduced resolutions and loss of fine details.", "method": "Introduces an efficient implementation of all-pairs correlation volume sampling, matching RAFT's mathematical operator while optimizing memory and speed.", "result": "Achieves up to 90% faster performance than on-demand sampling and 95% lower memory usage, with 50% savings in end-to-end inference time. State-of-the-art results on high-resolution datasets.", "conclusion": "The proposed method significantly improves efficiency and accuracy in optical flow estimation, especially for high-resolution applications."}}
{"id": "2505.16973", "pdf": "https://arxiv.org/pdf/2505.16973", "abs": "https://arxiv.org/abs/2505.16973", "authors": ["Rishanth Rajendhran", "Amir Zadeh", "Matthew Sarte", "Chuan Li", "Mohit Iyyer"], "title": "VeriFastScore: Speeding up long-form factuality evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Metrics like FactScore and VeriScore that evaluate long-form factuality\noperate by decomposing an input response into atomic claims and then\nindividually verifying each claim. While effective and interpretable, these\nmethods incur numerous LLM calls and can take upwards of 100 seconds to\nevaluate a single response, limiting their practicality in large-scale\nevaluation and training scenarios. To address this, we propose VeriFastScore,\nwhich leverages synthetic data to fine-tune Llama3.1 8B for simultaneously\nextracting and verifying all verifiable claims within a given text based on\nevidence from Google Search. We show that this task cannot be solved via\nfew-shot prompting with closed LLMs due to its complexity: the model receives\n~4K tokens of evidence on average and needs to concurrently decompose claims,\njudge their verifiability, and verify them against noisy evidence. However, our\nfine-tuned VeriFastScore model demonstrates strong correlation with the\noriginal VeriScore pipeline at both the example level (r=0.80) and system level\n(r=0.94) while achieving an overall speedup of 6.6x (9.9x excluding evidence\nretrieval) over VeriScore. To facilitate future factuality research, we\npublicly release our VeriFastScore model and synthetic datasets.", "AI": {"tldr": "VeriFastScore improves efficiency of long-form factuality evaluation by fine-tuning Llama3.1 8B for simultaneous claim extraction and verification, achieving a 6.6x speedup over VeriScore.", "motivation": "Current methods like FactScore and VeriScore are slow due to numerous LLM calls, limiting scalability.", "method": "Fine-tune Llama3.1 8B using synthetic data to extract and verify claims concurrently with Google Search evidence.", "result": "VeriFastScore correlates strongly with VeriScore (r=0.80 example, r=0.94 system) and speeds up evaluation by 6.6x.", "conclusion": "VeriFastScore offers a scalable solution for factuality evaluation, with released model and datasets for future research."}}
{"id": "2505.16967", "pdf": "https://arxiv.org/pdf/2505.16967", "abs": "https://arxiv.org/abs/2505.16967", "authors": ["Nandan Thakur", "Crystina Zhang", "Xueguang Ma", "Jimmy Lin"], "title": "Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "Code is available at https://github.com/castorini/rlhn & datasets are\n  available at https://huggingface.co/rlhn", "summary": "Training robust retrieval and reranker models typically relies on large-scale\nretrieval datasets; for example, the BGE collection contains 1.6 million\nquery-passage pairs sourced from various data sources. However, we find that\ncertain datasets can negatively impact model effectiveness -- pruning 8 out of\n15 datasets from the BGE collection reduces the training set size by\n2.35$\\times$ and increases nDCG@10 on BEIR by 1.0 point. This motivates a\ndeeper examination of training data quality, with a particular focus on \"false\nnegatives\", where relevant passages are incorrectly labeled as irrelevant. We\npropose a simple, cost-effective approach using cascading LLM prompts to\nidentify and relabel hard negatives. Experimental results show that relabeling\nfalse negatives with true positives improves both E5 (base) and Qwen2.5-7B\nretrieval models by 0.7-1.4 nDCG@10 on BEIR and by 1.7-1.8 nDCG@10 on zero-shot\nAIR-Bench evaluation. Similar gains are observed for rerankers fine-tuned on\nthe relabeled data, such as Qwen2.5-3B on BEIR. The reliability of the\ncascading design is further supported by human annotation results, where we\nfind judgment by GPT-4o shows much higher agreement with humans than\nGPT-4o-mini.", "AI": {"tldr": "Pruning low-quality datasets and relabeling false negatives in training data improves retrieval and reranker model performance.", "motivation": "Certain datasets negatively impact model effectiveness, and false negatives in training data degrade performance.", "method": "Proposes a cascading LLM prompt approach to identify and relabel false negatives.", "result": "Relabeling improves retrieval models by 0.7-1.4 nDCG@10 on BEIR and 1.7-1.8 nDCG@10 on AIR-Bench. Rerankers also show gains.", "conclusion": "Data quality, especially addressing false negatives, is crucial for robust retrieval models, and LLM-based relabeling is effective."}}
{"id": "2505.16959", "pdf": "https://arxiv.org/pdf/2505.16959", "abs": "https://arxiv.org/abs/2505.16959", "authors": ["Alessandro Favero", "Antonio Sclocchi", "Matthieu Wyart"], "title": "Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Diffusion probabilistic models have become a cornerstone of modern generative\nAI, yet the mechanisms underlying their generalization remain poorly\nunderstood. In fact, if these models were perfectly minimizing their training\nloss, they would just generate data belonging to their training set, i.e.,\nmemorize, as empirically found in the overparameterized regime. We revisit this\nview by showing that, in highly overparameterized diffusion models,\ngeneralization in natural data domains is progressively achieved during\ntraining before the onset of memorization. Our results, ranging from image to\nlanguage diffusion models, systematically support the empirical law that\nmemorization time is proportional to the dataset size. Generalization vs.\nmemorization is then best understood as a competition between time scales. We\nshow that this phenomenology is recovered in diffusion models learning a simple\nprobabilistic context-free grammar with random rules, where generalization\ncorresponds to the hierarchical acquisition of deeper grammar rules as training\ntime grows, and the generalization cost of early stopping can be characterized.\nWe summarize these results in a phase diagram. Overall, our results support\nthat a principled early-stopping criterion - scaling with dataset size - can\neffectively optimize generalization while avoiding memorization, with direct\nimplications for hyperparameter transfer and privacy-sensitive applications.", "AI": {"tldr": "Diffusion models generalize before memorizing in overparameterized regimes, with memorization time proportional to dataset size. Early stopping optimizes generalization.", "motivation": "To understand the mechanisms behind generalization in diffusion models and the balance between generalization and memorization.", "method": "Analyzed highly overparameterized diffusion models across image and language domains, and a simple probabilistic context-free grammar.", "result": "Generalization occurs before memorization, with memorization time scaling with dataset size. A phase diagram summarizes the findings.", "conclusion": "Early stopping, scaling with dataset size, optimizes generalization and avoids memorization, aiding hyperparameter transfer and privacy."}}
{"id": "2505.16964", "pdf": "https://arxiv.org/pdf/2505.16964", "abs": "https://arxiv.org/abs/2505.16964", "authors": ["Suhao Yu", "Haojin Wang", "Juncheng Wu", "Cihang Xie", "Yuyin Zhou"], "title": "MedFrameQA: A Multi-Image Medical VQA Benchmark for Clinical Reasoning", "categories": ["cs.CV", "cs.CL"], "comment": "9 pages, 4 Figures Benchmark data:\n  https://huggingface.co/datasets/SuhaoYu1020/MedFrameQA", "summary": "Existing medical VQA benchmarks mostly focus on single-image analysis, yet\nclinicians almost always compare a series of images before reaching a\ndiagnosis. To better approximate this workflow, we introduce MedFrameQA -- the\nfirst benchmark that explicitly evaluates multi-image reasoning in medical VQA.\nTo build MedFrameQA both at scale and in high-quality, we develop 1) an\nautomated pipeline that extracts temporally coherent frames from medical videos\nand constructs VQA items whose content evolves logically across images, and 2)\na multiple-stage filtering strategy, including model-based and manual review,\nto preserve data clarity, difficulty, and medical relevance. The resulting\ndataset comprises 2,851 VQA pairs (gathered from 9,237 high-quality frames in\n3,420 videos), covering nine human body systems and 43 organs; every question\nis accompanied by two to five images. We comprehensively benchmark ten advanced\nMultimodal LLMs -- both proprietary and open source, with and without explicit\nreasoning modules -- on MedFrameQA. The evaluation challengingly reveals that\nall models perform poorly, with most accuracies below 50%, and accuracy\nfluctuates as the number of images per question increases. Error analysis\nfurther shows that models frequently ignore salient findings, mis-aggregate\nevidence across images, and propagate early mistakes through their reasoning\nchains; results also vary substantially across body systems, organs, and\nmodalities. We hope this work can catalyze research on clinically grounded,\nmulti-image reasoning and accelerate progress toward more capable diagnostic AI\nsystems.", "AI": {"tldr": "The paper introduces MedFrameQA, a benchmark for multi-image reasoning in medical VQA, highlighting the limitations of current models in handling such tasks.", "motivation": "Clinicians often compare multiple images for diagnosis, but existing medical VQA benchmarks focus on single-image analysis. MedFrameQA aims to bridge this gap.", "method": "An automated pipeline extracts coherent frames from medical videos, constructs VQA items, and employs a multi-stage filtering strategy for data quality.", "result": "Benchmarking ten advanced Multimodal LLMs shows poor performance (below 50% accuracy), with issues like ignoring findings and mis-aggregating evidence.", "conclusion": "MedFrameQA highlights the need for improved multi-image reasoning in AI, aiming to advance clinically grounded diagnostic systems."}}
{"id": "2505.16983", "pdf": "https://arxiv.org/pdf/2505.16983", "abs": "https://arxiv.org/abs/2505.16983", "authors": ["Junlong Tong", "Jinlan Fu", "Zixuan Lin", "Yingqi Fan", "Anhao Zhao", "Hui Su", "Xiaoyu Shen"], "title": "LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Large Language Models (LLMs) are primarily designed for batch processing.\nExisting methods for adapting LLMs to streaming rely either on expensive\nre-encoding or specialized architectures with limited scalability. This work\nidentifies three key mismatches in adapting batch-oriented LLMs to streaming:\n(1) input-attention, (2) output-attention, and (3) position-ID mismatches.\nWhile it is commonly assumed that the latter two mismatches require frequent\nre-encoding, our analysis reveals that only the input-attention mismatch\nsignificantly impacts performance, indicating re-encoding outputs is largely\nunnecessary. To better understand this discrepancy with the common assumption,\nwe provide the first comprehensive analysis of the impact of position encoding\non LLMs in streaming, showing that preserving relative positions within source\nand target contexts is more critical than maintaining absolute order. Motivated\nby the above analysis, we introduce a group position encoding paradigm built on\nbatch architectures to enhance consistency between streaming and batch modes.\nExtensive experiments on cross-lingual and cross-modal tasks demonstrate that\nour method outperforms existing approaches. Our method requires no\narchitectural modifications, exhibits strong generalization in both streaming\nand batch modes. The code is available at repository\nhttps://github.com/EIT-NLP/StreamingLLM.", "AI": {"tldr": "The paper addresses mismatches in adapting batch-oriented LLMs to streaming, focusing on input-attention issues, and introduces a group position encoding method for better consistency without architectural changes.", "motivation": "To adapt LLMs for streaming without expensive re-encoding or specialized architectures, identifying key mismatches and improving performance.", "method": "Introduces a group position encoding paradigm to enhance consistency between streaming and batch modes, leveraging batch architectures.", "result": "Outperforms existing approaches in cross-lingual and cross-modal tasks, with strong generalization in both streaming and batch modes.", "conclusion": "The proposed method effectively addresses streaming adaptation issues without architectural modifications, offering scalable and efficient performance."}}
{"id": "2505.16968", "pdf": "https://arxiv.org/pdf/2505.16968", "abs": "https://arxiv.org/abs/2505.16968", "authors": ["Ahmed Heakl", "Sarim Hashmi", "Gustavo Bertolo Stahl", "Seung Hun Eddie Han", "Salman Khan", "Abdulrahman Mahmoud"], "title": "CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.LG", "cs.PL"], "comment": "20 pages, 11 figures, 5 tables", "summary": "We introduce \\texttt{CASS}, the first large-scale dataset and model suite for\ncross-architecture GPU code transpilation, targeting both source-level\n(CUDA~$\\leftrightarrow$~HIP) and assembly-level (Nvidia\nSASS~$\\leftrightarrow$~AMD RDNA3) translation. The dataset comprises 70k\nverified code pairs across host and device, addressing a critical gap in\nlow-level GPU code portability. Leveraging this resource, we train the\n\\texttt{CASS} family of domain-specific language models, achieving 95\\% source\ntranslation accuracy and 37.5\\% assembly translation accuracy, substantially\noutperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our\ngenerated code matches native performance in over 85\\% of test cases,\npreserving runtime and memory behavior. To support rigorous evaluation, we\nintroduce \\texttt{CASS-Bench}, a curated benchmark spanning 16 GPU domains with\nground-truth execution. All data, models, and evaluation tools are released as\nopen source to foster progress in GPU compiler tooling, binary compatibility,\nand LLM-guided hardware translation. Dataset and benchmark are on\n\\href{https://huggingface.co/datasets/MBZUAI/cass}{\\textcolor{blue}{HuggingFace}},\nwith code at\n\\href{https://github.com/GustavoStahl/CASS}{\\textcolor{blue}{GitHub}}.", "AI": {"tldr": "CASS introduces a dataset and model suite for GPU code transpilation, achieving high accuracy in source and assembly translation, outperforming commercial tools.", "motivation": "Addressing the gap in low-level GPU code portability by providing a large-scale dataset and models for cross-architecture translation.", "method": "Leveraging a dataset of 70k verified code pairs to train domain-specific language models for CUDA/HIP and SASS/RDNA3 translation.", "result": "Achieved 95% source translation accuracy and 37.5% assembly translation accuracy, with generated code matching native performance in 85% of cases.", "conclusion": "CASS advances GPU compiler tooling and hardware translation, with open-source release of data, models, and benchmarks."}}
{"id": "2505.16984", "pdf": "https://arxiv.org/pdf/2505.16984", "abs": "https://arxiv.org/abs/2505.16984", "authors": ["Mingyang Liu", "Gabriele Farina", "Asuman Ozdaglar"], "title": "UFT: Unifying Supervised and Reinforcement Fine-Tuning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Post-training has demonstrated its importance in enhancing the reasoning\ncapabilities of large language models (LLMs). The primary post-training methods\ncan be categorized into supervised fine-tuning (SFT) and reinforcement\nfine-tuning (RFT). SFT is efficient and well-suited for small language models,\nbut it may lead to overfitting and limit the reasoning abilities of larger\nmodels. In contrast, RFT generally yields better generalization but depends\nheavily on the strength of the base model. To address the limitations of SFT\nand RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm\nthat unifies SFT and RFT into a single, integrated process. UFT enables the\nmodel to effectively explore solutions while incorporating informative\nsupervision signals, bridging the gap between memorizing and thinking\nunderlying existing methods. Notably, UFT outperforms both SFT and RFT in\ngeneral, regardless of model sizes. Furthermore, we theoretically prove that\nUFT breaks RFT's inherent exponential sample complexity bottleneck, showing for\nthe first time that unified training can exponentially accelerate convergence\non long-horizon reasoning tasks.", "AI": {"tldr": "UFT unifies SFT and RFT, outperforming both in reasoning tasks and breaking RFT's exponential sample complexity bottleneck.", "motivation": "Address limitations of SFT (overfitting) and RFT (dependency on base model strength) in post-training LLMs.", "method": "Propose Unified Fine-Tuning (UFT), integrating SFT and RFT into a single process for balanced exploration and supervision.", "result": "UFT outperforms SFT and RFT across model sizes and exponentially accelerates convergence in long-horizon reasoning.", "conclusion": "UFT bridges memorization and reasoning, offering a superior post-training paradigm for LLMs."}}
{"id": "2505.16971", "pdf": "https://arxiv.org/pdf/2505.16971", "abs": "https://arxiv.org/abs/2505.16971", "authors": ["Himangi Mittal", "Peiye Zhuang", "Hsin-Ying Lee", "Shubham Tulsiani"], "title": "UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "We propose UniPhy, a common latent-conditioned neural constitutive model that\ncan encode the physical properties of diverse materials. At inference UniPhy\nallows `inverse simulation' i.e. inferring material properties by optimizing\nthe scene-specific latent to match the available observations via\ndifferentiable simulation. In contrast to existing methods that treat such\ninference as system identification, UniPhy does not rely on user-specified\nmaterial type information. Compared to prior neural constitutive modeling\napproaches which learn instance specific networks, the shared training across\nmaterials improves both, robustness and accuracy of the estimates. We train\nUniPhy using simulated trajectories across diverse geometries and materials --\nelastic, plasticine, sand, and fluids (Newtonian & non-Newtonian). At\ninference, given an object with unknown material properties, UniPhy can infer\nthe material properties via latent optimization to match the motion\nobservations, and can then allow re-simulating the object under diverse\nscenarios. We compare UniPhy against prior inverse simulation methods, and show\nthat the inference from UniPhy enables more accurate replay and re-simulation\nunder novel conditions.", "AI": {"tldr": "UniPhy is a neural constitutive model that infers material properties without prior type information, improving accuracy and robustness through shared training.", "motivation": "Existing methods rely on user-specified material types or instance-specific networks, limiting flexibility and accuracy. UniPhy aims to overcome these limitations.", "method": "UniPhy uses a common latent-conditioned model trained on diverse materials (elastic, plasticine, sand, fluids) via differentiable simulation. It infers properties by optimizing latents to match observations.", "result": "UniPhy outperforms prior inverse simulation methods, enabling accurate replay and re-simulation under novel conditions.", "conclusion": "UniPhy offers a flexible, accurate approach for inferring material properties and simulating diverse scenarios without prior material type knowledge."}}
{"id": "2505.16986", "pdf": "https://arxiv.org/pdf/2505.16986", "abs": "https://arxiv.org/abs/2505.16986", "authors": ["Amartya Chakraborty", "Paresh Dashore", "Nadia Bathaee", "Anmol Jain", "Anirban Das", "Shi-Xiong Zhang", "Sambit Sahu", "Milind Naphade", "Genta Indra Winata"], "title": "T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities as\nintelligent agents capable of solving complex problems. However, effective\nplanning in scenarios involving dependencies between API or tool\ncalls-particularly in multi-turn conversations-remains a significant challenge.\nTo address this, we introduce T1, a tool-augmented, multi-domain, multi-turn\nconversational dataset specifically designed to capture and manage inter-tool\ndependencies across diverse domains. T1 enables rigorous evaluation of agents'\nability to coordinate tool use across nine distinct domains (4 single domain\nand 5 multi-domain) with the help of an integrated caching mechanism for both\nshort- and long-term memory, while supporting dynamic replanning-such as\ndeciding whether to recompute or reuse cached results. Beyond facilitating\nresearch on tool use and planning, T1 also serves as a benchmark for evaluating\nthe performance of open-source language models. We present results powered by\nT1-Agent, highlighting their ability to plan and reason in complex,\ntool-dependent scenarios.", "AI": {"tldr": "T1 is a tool-augmented dataset for evaluating LLMs' planning and tool-use coordination in multi-turn conversations with dependencies.", "motivation": "Addressing the challenge of effective planning in multi-turn conversations involving tool dependencies.", "method": "Introducing T1, a multi-domain dataset with caching and dynamic replanning support.", "result": "T1-Agent demonstrates improved planning and reasoning in tool-dependent scenarios.", "conclusion": "T1 serves as a benchmark for evaluating LLMs' tool-use and planning capabilities."}}
{"id": "2505.16985", "pdf": "https://arxiv.org/pdf/2505.16985", "abs": "https://arxiv.org/abs/2505.16985", "authors": ["Moru Liu", "Hao Dong", "Jessica Kelly", "Olga Fink", "Mario Trapp"], "title": "Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Out-of-distribution (OOD) detection and segmentation are crucial for\ndeploying machine learning models in safety-critical applications such as\nautonomous driving and robot-assisted surgery. While prior research has\nprimarily focused on unimodal image data, real-world applications are\ninherently multimodal, requiring the integration of multiple modalities for\nimproved OOD detection. A key challenge is the lack of supervision signals from\nunknown data, leading to overconfident predictions on OOD samples. To address\nthis challenge, we propose Feature Mixing, an extremely simple and fast method\nfor multimodal outlier synthesis with theoretical support, which can be further\noptimized to help the model better distinguish between in-distribution (ID) and\nOOD data. Feature Mixing is modality-agnostic and applicable to various\nmodality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal\ndataset for OOD segmentation, featuring synthetic OOD objects across diverse\nscenes and weather conditions. Extensive experiments on SemanticKITTI,\nnuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that\nFeature Mixing achieves state-of-the-art performance with a $10 \\times$ to $370\n\\times$ speedup. Our source code and dataset will be available at\nhttps://github.com/mona4399/FeatureMixing.", "AI": {"tldr": "Proposes Feature Mixing, a fast and simple method for multimodal OOD detection, and introduces CARLA-OOD dataset. Achieves SOTA performance with significant speedup.", "motivation": "Real-world applications require multimodal OOD detection, but lack supervision for unknown data leads to overconfident predictions.", "method": "Feature Mixing, a modality-agnostic method for multimodal outlier synthesis, with theoretical support.", "result": "State-of-the-art performance on SemanticKITTI, nuScenes, CARLA-OOD, and MultiOOD, with 10\u00d7 to 370\u00d7 speedup.", "conclusion": "Feature Mixing is effective and efficient for multimodal OOD detection, supported by a new dataset."}}
{"id": "2505.16992", "pdf": "https://arxiv.org/pdf/2505.16992", "abs": "https://arxiv.org/abs/2505.16992", "authors": ["Aleksandra Franz", "Hao Wei", "Luca Guastoni", "Nils Thuerey"], "title": "PICT -- A Differentiable, GPU-Accelerated Multi-Block PISO Solver for Simulation-Coupled Learning Tasks in Fluid Dynamics", "categories": ["cs.LG", "physics.comp-ph"], "comment": "Source code at https://github.com/tum-pbs/PICT", "summary": "Despite decades of advancements, the simulation of fluids remains one of the\nmost challenging areas of in scientific computing. Supported by the necessity\nof gradient information in deep learning, differentiable simulators have\nemerged as an effective tool for optimization and learning in physics\nsimulations. In this work, we present our fluid simulator PICT, a\ndifferentiable pressure-implicit solver coded in PyTorch with\nGraphics-processing-unit (GPU) support. We first verify the accuracy of both\nthe forward simulation and our derived gradients in various established\nbenchmarks like lid-driven cavities and turbulent channel flows before we show\nthat the gradients provided by our solver can be used to learn complicated\nturbulence models in 2D and 3D. We apply both supervised and unsupervised\ntraining regimes using physical priors to match flow statistics. In particular,\nwe learn a stable sub-grid scale (SGS) model for a 3D turbulent channel flow\npurely based on reference statistics. The low-resolution corrector trained with\nour solver runs substantially faster than the highly resolved references, while\nkeeping or even surpassing their accuracy. Finally, we give additional insights\ninto the physical interpretation of different solver gradients, and motivate a\nphysically informed regularization technique. To ensure that the full potential\nof PICT can be leveraged, it is published as open source:\nhttps://github.com/tum-pbs/PICT.", "AI": {"tldr": "PICT is a differentiable fluid simulator in PyTorch with GPU support, validated for accuracy and used to learn turbulence models efficiently.", "motivation": "To address challenges in fluid simulation and leverage differentiable simulators for optimization and learning in physics.", "method": "Developed PICT, a pressure-implicit solver, verified its accuracy, and used gradients for supervised/unsupervised learning of turbulence models.", "result": "PICT trained models run faster than high-resolution references while maintaining or improving accuracy.", "conclusion": "PICT is open-source, enabling broader use and insights into solver gradients and regularization techniques."}}
{"id": "2505.16974", "pdf": "https://arxiv.org/pdf/2505.16974", "abs": "https://arxiv.org/abs/2505.16974", "authors": ["Zongyan Han", "Jiale Cao", "Shuo Chen", "Tong Wang", "Jorma Laaksonen", "Rao Muhammad Anwer"], "title": "OpenSeg-R: Improving Open-Vocabulary Segmentation via Step-by-Step Visual Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Open-Vocabulary Segmentation (OVS) has drawn increasing attention for its\ncapacity to generalize segmentation beyond predefined categories. However,\nexisting methods typically predict segmentation masks with simple forward\ninference, lacking explicit reasoning and interpretability. This makes it\nchallenging for OVS model to distinguish similar categories in open-world\nsettings due to the lack of contextual understanding and discriminative visual\ncues. To address this limitation, we propose a step-by-step visual reasoning\nframework for open-vocabulary segmentation, named OpenSeg-R. The proposed\nOpenSeg-R leverages Large Multimodal Models (LMMs) to perform hierarchical\nvisual reasoning before segmentation. Specifically, we generate both generic\nand image-specific reasoning for each image, forming structured triplets that\nexplain the visual reason for objects in a coarse-to-fine manner. Based on\nthese reasoning steps, we can compose detailed description prompts, and feed\nthem to the segmentor to produce more accurate segmentation masks. To the best\nof our knowledge, OpenSeg-R is the first framework to introduce explicit\nstep-by-step visual reasoning into OVS. Experimental results demonstrate that\nOpenSeg-R significantly outperforms state-of-the-art methods on open-vocabulary\nsemantic segmentation across five benchmark datasets. Moreover, it achieves\nconsistent gains across all metrics on open-vocabulary panoptic segmentation.\nQualitative results further highlight the effectiveness of our reasoning-guided\nframework in improving both segmentation precision and interpretability. Our\ncode is publicly available at https://github.com/Hanzy1996/OpenSeg-R.", "AI": {"tldr": "OpenSeg-R introduces step-by-step visual reasoning for open-vocabulary segmentation, improving accuracy and interpretability by leveraging Large Multimodal Models (LMMs).", "motivation": "Existing OVS methods lack explicit reasoning, making it hard to distinguish similar categories in open-world settings.", "method": "OpenSeg-R uses LMMs for hierarchical visual reasoning, generating structured triplets and detailed prompts for segmentation.", "result": "Outperforms state-of-the-art methods on five benchmark datasets for semantic and panoptic segmentation.", "conclusion": "OpenSeg-R enhances segmentation precision and interpretability, setting a new standard for OVS."}}
{"id": "2505.16995", "pdf": "https://arxiv.org/pdf/2505.16995", "abs": "https://arxiv.org/abs/2505.16995", "authors": ["Chao Zhang", "Xin Shi", "Xueqiao Zhang", "Yifan Zhu", "Yi Yang", "Yawei Luo"], "title": "DecoupledESC: Enhancing Emotional Support Generation via Strategy-Response Decoupled Preference Optimization", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in Emotional Support Conversation (ESC) have improved\nemotional support generation by fine-tuning Large Language Models (LLMs) via\nSupervised Fine-Tuning (SFT). However, common psychological errors still\npersist. While Direct Preference Optimization (DPO) shows promise in reducing\nsuch errors through pairwise preference learning, its effectiveness in ESC\ntasks is limited by two key challenges: (1) Entangled data structure: Existing\nESC data inherently entangles psychological strategies and response content,\nmaking it difficult to construct high-quality preference pairs; and (2)\nOptimization ambiguity: Applying vanilla DPO to such entangled pairwise data\nleads to ambiguous training objectives. To address these issues, we introduce\nInferential Preference Mining (IPM) to construct high-quality preference data,\nforming the IPM-PrefDial dataset. Building upon this data, we propose a\nDecoupled ESC framework inspired by Gross's Extended Process Model of Emotion\nRegulation, which decomposes the ESC task into two sequential subtasks:\nstrategy planning and empathic response generation. Each was trained via SFT\nand subsequently enhanced by DPO to align with the psychological preference.\nExtensive experiments demonstrate that our Decoupled ESC framework outperforms\njoint optimization baselines, reducing preference bias and improving response\nquality.", "AI": {"tldr": "The paper introduces Inferential Preference Mining (IPM) and a Decoupled ESC framework to improve emotional support conversation by addressing challenges in preference learning and optimization ambiguity.", "motivation": "Existing methods for Emotional Support Conversation (ESC) using LLMs still suffer from psychological errors, and Direct Preference Optimization (DPO) struggles with entangled data and ambiguous objectives.", "method": "Proposes IPM to create high-quality preference data (IPM-PrefDial) and a Decoupled ESC framework, splitting the task into strategy planning and response generation, trained via SFT and enhanced by DPO.", "result": "The Decoupled ESC framework outperforms joint optimization baselines, reducing bias and improving response quality.", "conclusion": "The approach effectively addresses challenges in ESC by decoupling tasks and leveraging IPM, leading to better performance and alignment with psychological preferences."}}
{"id": "2505.16994", "pdf": "https://arxiv.org/pdf/2505.16994", "abs": "https://arxiv.org/abs/2505.16994", "authors": ["Runyang You", "Yongqi Li", "Xinyu Lin", "Xin Zhang", "Wenjie Wang", "Wenjie Li", "Liqiang Nie"], "title": "$\\text{R}^2\\text{ec}$: Towards Large Recommender Models with Reasoning", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large recommender models have extended LLMs as powerful recommenders via\nencoding or item generation, and recent breakthroughs in LLM reasoning\nsynchronously motivate the exploration of reasoning in recommendation. Current\nstudies usually position LLMs as external reasoning modules to yield auxiliary\nthought for augmenting conventional recommendation pipelines. However, such\ndecoupled designs are limited in significant resource cost and suboptimal joint\noptimization. To address these issues, we propose \\name, a unified large\nrecommender model with intrinsic reasoning capabilities. Initially, we\nreconceptualize the model architecture to facilitate interleaved reasoning and\nrecommendation in the autoregressive process. Subsequently, we propose RecPO, a\ncorresponding reinforcement learning framework that optimizes \\name\\ both the\nreasoning and recommendation capabilities simultaneously in a single policy\nupdate; RecPO introduces a fused reward scheme that solely leverages\nrecommendation labels to simulate the reasoning capability, eliminating\ndependency on specialized reasoning annotations. Experiments on three datasets\nwith various baselines verify the effectiveness of \\name, showing relative\nimprovements of 68.67\\% in Hit@5 and 45.21\\% in NDCG@20. Code available at\nhttps://github.com/YRYangang/RRec.", "AI": {"tldr": "A unified large recommender model with intrinsic reasoning capabilities is proposed, combining reasoning and recommendation in an autoregressive process, optimized via a reinforcement learning framework.", "motivation": "Current decoupled designs of LLMs as external reasoning modules for recommendations are resource-intensive and suboptimal.", "method": "Proposes a unified model architecture for interleaved reasoning and recommendation, optimized with RecPO, a reinforcement learning framework using fused rewards.", "result": "Shows significant improvements: 68.67% in Hit@5 and 45.21% in NDCG@20 across three datasets.", "conclusion": "The proposed model effectively integrates reasoning and recommendation, outperforming baselines without needing specialized reasoning annotations."}}
{"id": "2505.16996", "pdf": "https://arxiv.org/pdf/2505.16996", "abs": "https://arxiv.org/abs/2505.16996", "authors": ["Shalev Manor", "Mohammad Kohandel"], "title": "A Unified Framework for Simultaneous Parameter and Function Discovery in Differential Equations", "categories": ["cs.LG"], "comment": "13 pages, 8 figures", "summary": "Inverse problems involving differential equations often require identifying\nunknown parameters or functions from data. Existing approaches, such as\nPhysics-Informed Neural Networks (PINNs), Universal Differential Equations\n(UDEs) and Universal Physics-Informed Neural Networks (UPINNs), are effective\nat isolating either parameters or functions but can face challenges when\napplied simultaneously due to solution non-uniqueness. In this work, we\nintroduce a framework that addresses these limitations by establishing\nconditions under which unique solutions can be guaranteed. To illustrate, we\napply it to examples from biological systems and ecological dynamics,\ndemonstrating accurate and interpretable results. Our approach significantly\nenhances the potential of machine learning techniques in modeling complex\nsystems in science and engineering.", "AI": {"tldr": "A framework is introduced to ensure unique solutions in inverse problems involving differential equations, improving upon existing methods like PINNs, UDEs, and UPINNs.", "motivation": "Existing methods struggle with non-uniqueness when identifying parameters and functions simultaneously in differential equations.", "method": "The proposed framework establishes conditions for unique solutions and is tested on biological and ecological systems.", "result": "The approach yields accurate and interpretable results, enhancing machine learning applications in complex systems.", "conclusion": "This framework advances the use of machine learning in science and engineering by addressing non-uniqueness challenges."}}
{"id": "2505.16990", "pdf": "https://arxiv.org/pdf/2505.16990", "abs": "https://arxiv.org/abs/2505.16990", "authors": ["Runpeng Yu", "Xinyin Ma", "Xinchao Wang"], "title": "Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we propose Dimple, the first Discrete Diffusion Multimodal\nLarge Language Model (DMLLM). We observe that training with a purely discrete\ndiffusion approach leads to significant training instability, suboptimal\nperformance, and severe length bias issues. To address these challenges, we\ndesign a novel training paradigm that combines an initial autoregressive phase\nwith a subsequent diffusion phase. This approach yields the Dimple-7B model,\ntrained on the same dataset and using a similar training pipeline as\nLLaVA-NEXT. Dimple-7B ultimately surpasses LLaVA-NEXT in performance by 3.9%,\ndemonstrating that DMLLM can achieve performance comparable to that of\nautoregressive models. To improve inference efficiency, we propose a decoding\nstrategy termed confident decoding, which dynamically adjusts the number of\ntokens generated at each step, significantly reducing the number of generation\niterations. In autoregressive models, the number of forward iterations during\ngeneration equals the response length. With confident decoding, however, the\nnumber of iterations needed by Dimple is even only $\\frac{\\text{response\nlength}}{3}$. We also re-implement the prefilling technique in autoregressive\nmodels and demonstrate that it does not significantly impact performance on\nmost benchmark evaluations, while offering a speedup of 1.5x to 7x.\nAdditionally, we explore Dimple's capability to precisely control its response\nusing structure priors. These priors enable structured responses in a manner\ndistinct from instruction-based or chain-of-thought prompting, and allow\nfine-grained control over response format and length, which is difficult to\nachieve in autoregressive models. Overall, this work validates the feasibility\nand advantages of DMLLM and enhances its inference efficiency and\ncontrollability. Code and models are available at\nhttps://github.com/yu-rp/Dimple.", "AI": {"tldr": "Dimple is the first Discrete Diffusion Multimodal Large Language Model (DMLLM) that combines autoregressive and diffusion training phases, outperforming LLaVA-NEXT by 3.9%. It introduces confident decoding for efficiency and explores structured response control.", "motivation": "Addressing training instability, suboptimal performance, and length bias in purely discrete diffusion models by proposing a hybrid training approach.", "method": "Combines initial autoregressive training with a subsequent diffusion phase, introduces confident decoding for efficiency, and explores structured response control via priors.", "result": "Dimple-7B surpasses LLaVA-NEXT by 3.9%, reduces generation iterations to response length/3, and achieves 1.5x-7x speedup with prefilling.", "conclusion": "Dimple validates DMLLM feasibility, enhances efficiency and controllability, and offers structured response capabilities."}}
{"id": "2505.16998", "pdf": "https://arxiv.org/pdf/2505.16998", "abs": "https://arxiv.org/abs/2505.16998", "authors": ["Jin Jiang", "Jianing Wang", "Yuchen Yan", "Yang Liu", "Jianhua Zhu", "Mengdi Zhang", "Xunliang Cai", "Liangcai Gao"], "title": "Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have been shown to achieve breakthrough\nperformance on complex logical reasoning tasks. Nevertheless, most existing\nresearch focuses on employing formal language to guide LLMs to derive reliable\nreasoning paths, while systematic evaluations of these capabilities are still\nlimited. In this paper, we aim to conduct a comprehensive evaluation of LLMs\nacross various logical reasoning problems utilizing formal languages. From the\nperspective of three dimensions, i.e., spectrum of LLMs, taxonomy of tasks, and\nformat of trajectories, our key findings are: 1) Thinking models significantly\noutperform Instruct models, especially when formal language is employed; 2) All\nLLMs exhibit limitations in inductive reasoning capability, irrespective of\nwhether they use a formal language; 3) Data with PoT format achieves the best\ngeneralization performance across other languages. Additionally, we also curate\nthe formal-relative training data to further enhance the small language models,\nand the experimental results indicate that a simple rejected fine-tuning method\ncan better enable LLMs to generalize across formal languages and achieve the\nbest overall performance. Our codes and reports are available at\nhttps://github.com/jiangjin1999/FormalEval.", "AI": {"tldr": "The paper evaluates LLMs' logical reasoning using formal languages, finding Thinking models outperform Instruct models, LLMs struggle with inductive reasoning, and PoT format data generalizes best. It also enhances small models with formal-relative training.", "motivation": "To systematically evaluate LLMs' logical reasoning capabilities using formal languages, addressing gaps in existing research.", "method": "Comprehensive evaluation across LLMs, task taxonomies, and trajectory formats, plus formal-relative training data curation and fine-tuning.", "result": "Thinking models excel, LLMs lack inductive reasoning, PoT format generalizes best, and fine-tuning improves performance.", "conclusion": "Formal language enhances LLMs' reasoning, but inductive reasoning remains a challenge; fine-tuning with formal data improves generalization."}}
{"id": "2505.17002", "pdf": "https://arxiv.org/pdf/2505.17002", "abs": "https://arxiv.org/abs/2505.17002", "authors": ["Abdul Hannan", "Muhammad Arslan Manzoor", "Shah Nawaz", "Muhammad Irzam Liaqat", "Markus Schedl", "Mubashir Noman"], "title": "PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at InterSpeech 2025", "summary": "We study the task of learning association between faces and voices, which is\ngaining interest in the multimodal community lately. These methods suffer from\nthe deliberate crafting of negative mining procedures as well as the reliance\non the distant margin parameter. These issues are addressed by learning a joint\nembedding space in which orthogonality constraints are applied to the fused\nembeddings of faces and voices. However, embedding spaces of faces and voices\npossess different characteristics and require spaces to be aligned before\nfusing them. To this end, we propose a method that accurately aligns the\nembedding spaces and fuses them with an enhanced gated fusion thereby improving\nthe performance of face-voice association. Extensive experiments on the\nVoxCeleb dataset reveals the merits of the proposed approach.", "AI": {"tldr": "The paper proposes a method to improve face-voice association by aligning embedding spaces and using enhanced gated fusion, addressing issues like negative mining and margin parameter reliance.", "motivation": "The task of learning associations between faces and voices is gaining interest, but current methods suffer from negative mining procedures and reliance on distant margin parameters.", "method": "The approach involves learning a joint embedding space with orthogonality constraints, aligning the spaces of faces and voices, and fusing them with enhanced gated fusion.", "result": "Extensive experiments on the VoxCeleb dataset show improved performance in face-voice association.", "conclusion": "The proposed method effectively addresses the challenges and enhances the performance of face-voice association tasks."}}
{"id": "2505.17004", "pdf": "https://arxiv.org/pdf/2505.17004", "abs": "https://arxiv.org/abs/2505.17004", "authors": ["Jiachen Yao", "Abbas Mammadov", "Julius Berner", "Gavin Kerrigan", "Jong Chul Ye", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "title": "Guided Diffusion Sampling on Function Spaces with Applications to PDEs", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "stat.ML"], "comment": null, "summary": "We propose a general framework for conditional sampling in PDE-based inverse\nproblems, targeting the recovery of whole solutions from extremely sparse or\nnoisy measurements. This is accomplished by a function-space diffusion model\nand plug-and-play guidance for conditioning. Our method first trains an\nunconditional discretization-agnostic denoising model using neural operator\narchitectures. At inference, we refine the samples to satisfy sparse\nobservation data via a gradient-based guidance mechanism. Through rigorous\nmathematical analysis, we extend Tweedie's formula to infinite-dimensional\nHilbert spaces, providing the theoretical foundation for our posterior sampling\napproach. Our method (FunDPS) accurately captures posterior distributions in\nfunction spaces under minimal supervision and severe data scarcity. Across five\nPDE tasks with only 3% observation, our method achieves an average 32% accuracy\nimprovement over state-of-the-art fixed-resolution diffusion baselines while\nreducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning\nensures strong cross-resolution generalizability. To the best of our knowledge,\nthis is the first diffusion-based framework to operate independently of\ndiscretization, offering a practical and flexible solution for forward and\ninverse problems in the context of PDEs. Code is available at\nhttps://github.com/neuraloperator/FunDPS", "AI": {"tldr": "A framework (FunDPS) for conditional sampling in PDE-based inverse problems using function-space diffusion and plug-and-play guidance, achieving high accuracy with minimal data.", "motivation": "Addressing the challenge of recovering whole solutions from sparse or noisy measurements in PDE-based inverse problems.", "method": "Trains an unconditional denoising model with neural operators, refines samples via gradient-based guidance, and extends Tweedie's formula to infinite-dimensional spaces.", "result": "Achieves 32% better accuracy than baselines with 3% observation data and reduces sampling steps by 4x.", "conclusion": "FunDPS is the first discretization-independent diffusion framework for PDEs, offering practical solutions for forward and inverse problems."}}
{"id": "2505.16991", "pdf": "https://arxiv.org/pdf/2505.16991", "abs": "https://arxiv.org/abs/2505.16991", "authors": ["Abdul Hannan", "Alessio Brutti", "Shah Nawaz", "Mubashir Noman"], "title": "An Effective Training Framework for Light-Weight Automatic Speech Recognition Models", "categories": ["cs.CV"], "comment": "Accepted at InterSpeech 2025", "summary": "Recent advancement in deep learning encouraged developing large automatic\nspeech recognition (ASR) models that achieve promising results while ignoring\ncomputational and memory constraints. However, deploying such models on low\nresource devices is impractical despite of their favorable performance.\nExisting approaches (pruning, distillation, layer skip etc.) transform the\nlarge models into smaller ones at the cost of significant performance\ndegradation or require prolonged training of smaller models for better\nperformance. To address these issues, we introduce an efficacious two-step\nrepresentation learning based approach capable of producing several small sized\nmodels from a single large model ensuring considerably better performance in\nlimited number of epochs. Comprehensive experimentation on ASR benchmarks\nreveals the efficacy of our approach, achieving three-fold training speed-up\nand up to 12.54% word error rate improvement.", "AI": {"tldr": "A two-step representation learning approach is introduced to create smaller ASR models from a large one, improving performance and training speed without significant degradation.", "motivation": "Large ASR models are impractical for low-resource devices, and existing methods either degrade performance or require prolonged training.", "method": "A two-step representation learning approach to derive smaller models from a single large model.", "result": "Achieves three-fold training speed-up and up to 12.54% word error rate improvement.", "conclusion": "The approach effectively balances performance and resource constraints for ASR deployment."}}
{"id": "2505.17005", "pdf": "https://arxiv.org/pdf/2505.17005", "abs": "https://arxiv.org/abs/2505.17005", "authors": ["Huatong Song", "Jinhao Jiang", "Wenqing Tian", "Zhipeng Chen", "Yuhuan Wu", "Jiahao Zhao", "Yingqian Min", "Wayne Xin Zhao", "Lei Fang", "Ji-Rong Wen"], "title": "R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) are powerful but prone to hallucinations due to\nstatic knowledge. Retrieval-Augmented Generation (RAG) helps by injecting\nexternal information, but current methods often are costly, generalize poorly,\nor ignore the internal knowledge of the model. In this paper, we introduce\nR1-Searcher++, a novel framework designed to train LLMs to adaptively leverage\nboth internal and external knowledge sources. R1-Searcher++ employs a two-stage\ntraining strategy: an initial SFT Cold-start phase for preliminary format\nlearning, followed by RL for Dynamic Knowledge Acquisition. The RL stage uses\noutcome-supervision to encourage exploration, incorporates a reward mechanism\nfor internal knowledge utilization, and integrates a memorization mechanism to\ncontinuously assimilate retrieved information, thereby enriching the model's\ninternal knowledge. By leveraging internal knowledge and external search\nengine, the model continuously improves its capabilities, enabling efficient\nretrieval-augmented reasoning. Our experiments demonstrate that R1-Searcher++\noutperforms previous RAG and reasoning methods and achieves efficient\nretrieval. The code is available at\nhttps://github.com/RUCAIBox/R1-Searcher-plus.", "AI": {"tldr": "R1-Searcher++ is a framework for training LLMs to use both internal and external knowledge adaptively, improving retrieval-augmented reasoning.", "motivation": "Addressing the limitations of current RAG methods (cost, poor generalization, ignoring internal knowledge) by enhancing LLMs' ability to leverage both knowledge sources.", "method": "Two-stage training: SFT Cold-start for format learning, followed by RL for dynamic knowledge acquisition with outcome-supervision, reward mechanisms, and memorization.", "result": "Outperforms previous RAG and reasoning methods, achieving efficient retrieval.", "conclusion": "R1-Searcher++ effectively combines internal and external knowledge, enhancing LLM performance in retrieval-augmented tasks."}}
{"id": "2505.17010", "pdf": "https://arxiv.org/pdf/2505.17010", "abs": "https://arxiv.org/abs/2505.17010", "authors": ["Tim Genewein", "Kevin Wenliang Li", "Jordi Grau-Moya", "Anian Ruoss", "Laurent Orseau", "Marcus Hutter"], "title": "Understanding Prompt Tuning and In-Context Learning via Meta-Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Prompting is one of the main ways to adapt a pretrained model to target\ntasks. Besides manually constructing prompts, many prompt optimization methods\nhave been proposed in the literature. Method development is mainly empirically\ndriven, with less emphasis on a conceptual understanding of prompting. In this\npaper we discuss how optimal prompting can be understood through a Bayesian\nview, which also implies some fundamental limitations of prompting that can\nonly be overcome by tuning weights. The paper explains in detail how\nmeta-trained neural networks behave as Bayesian predictors over the pretraining\ndistribution, whose hallmark feature is rapid in-context adaptation. Optimal\nprompting can be studied formally as conditioning these Bayesian predictors,\nyielding criteria for target tasks where optimal prompting is and is not\npossible. We support the theory with educational experiments on LSTMs and\nTransformers, where we compare different versions of prefix-tuning and\ndifferent weight-tuning methods. We also confirm that soft prefixes, which are\nsequences of real-valued vectors outside the token alphabet, can lead to very\neffective prompts for trained and even untrained networks by manipulating\nactivations in ways that are not achievable by hard tokens. This adds an\nimportant mechanistic aspect beyond the conceptual Bayesian theory.", "AI": {"tldr": "The paper explores optimal prompting through a Bayesian lens, highlighting its limitations and comparing prompt optimization methods like prefix-tuning and weight-tuning.", "motivation": "To provide a conceptual understanding of prompting and its limitations, moving beyond empirical methods.", "method": "Uses a Bayesian view to analyze prompting, supported by experiments with LSTMs and Transformers comparing prefix-tuning and weight-tuning.", "result": "Shows that soft prefixes can be highly effective by manipulating activations in ways hard tokens cannot.", "conclusion": "Optimal prompting is limited by Bayesian principles, and soft prefixes offer a powerful alternative beyond traditional methods."}}
{"id": "2505.17013", "pdf": "https://arxiv.org/pdf/2505.17013", "abs": "https://arxiv.org/abs/2505.17013", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "title": "When Are Concepts Erased From Diffusion Models?", "categories": ["cs.LG", "cs.CV"], "comment": "Project Page:\n  https://nyu-dice-lab.github.io/when-are-concepts-erased/", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "AI": {"tldr": "The paper explores concept erasure in diffusion models, proposing two mechanisms and introducing a suite of evaluations to assess erasure effectiveness.", "motivation": "To address the unclear thoroughness of existing concept erasure methods in diffusion models.", "method": "Proposes two erasure mechanisms (likelihood reduction and interference with guidance) and introduces adversarial attacks, probing techniques, and alternative generation analysis for evaluation.", "result": "Highlights the tension between minimizing side effects and robustness to adversarial prompts.", "conclusion": "Emphasizes the need for comprehensive evaluation in concept erasure for diffusion models."}}
{"id": "2505.16993", "pdf": "https://arxiv.org/pdf/2505.16993", "abs": "https://arxiv.org/abs/2505.16993", "authors": ["Guillem Bras\u00f3", "Aljo\u0161a O\u0161ep", "Laura Leal-Taix\u00e9"], "title": "Native Segmentation Vision Transformers", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Uniform downsampling remains the de facto standard for reducing spatial\nresolution in vision backbones. In this work, we propose an alternative design\nbuilt around a content-aware spatial grouping layer, that dynamically assigns\ntokens to a reduced set based on image boundaries and their semantic content.\nStacking our grouping layer across consecutive backbone stages results in\nhierarchical segmentation that arises natively in the feature extraction\nprocess, resulting in our coined Native Segmentation Vision Transformer. We\nshow that a careful design of our architecture enables the emergence of strong\nsegmentation masks solely from grouping layers, that is, without additional\nsegmentation-specific heads. This sets the foundation for a new paradigm of\nnative, backbone-level segmentation, which enables strong zero-shot results\nwithout mask supervision, as well as a minimal and efficient standalone model\ndesign for downstream segmentation tasks. Our project page is\nhttps://research.nvidia.com/labs/dvl/projects/native-segmentation.", "AI": {"tldr": "Proposes a content-aware spatial grouping layer for vision backbones, enabling hierarchical segmentation without additional heads, leading to efficient and strong zero-shot segmentation.", "motivation": "To replace uniform downsampling with a dynamic, content-aware method for better spatial resolution reduction and native segmentation.", "method": "Uses a content-aware spatial grouping layer to dynamically assign tokens based on image boundaries and semantics, stacking it across backbone stages.", "result": "Emergence of strong segmentation masks without extra heads, enabling zero-shot segmentation and efficient downstream task design.", "conclusion": "Introduces a new paradigm for native, backbone-level segmentation, offering strong performance without mask supervision."}}
{"id": "2505.15872", "pdf": "https://arxiv.org/pdf/2505.15872", "abs": "https://arxiv.org/abs/2505.15872", "authors": ["Yunjia Xi", "Jianghao Lin", "Menghui Zhu", "Yongzhao Xiao", "Zhuoying Ou", "Jiaqi Liu", "Tong Wan", "Bo Chen", "Weiwen Liu", "Yasheng Wang", "Ruiming Tang", "Weinan Zhang", "Yong Yu"], "title": "InfoDeepSeek: Benchmarking Agentic Information Seeking for Retrieval-Augmented Generation", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\ngrounding responses with retrieved information. As an emerging paradigm,\nAgentic RAG further enhances this process by introducing autonomous LLM agents\ninto the information seeking process. However, existing benchmarks fall short\nin evaluating such systems, as they are confined to a static retrieval\nenvironment with a fixed, limited corpus} and simple queries that fail to\nelicit agentic behavior. Moreover, their evaluation protocols assess\ninformation seeking effectiveness by pre-defined gold sets of documents, making\nthem unsuitable for the open-ended and dynamic nature of real-world web\nenvironments. To bridge this gap, we present InfoDeepSeek, a new benchmark with\nchallenging questions designed for assessing agentic information seeking in\nreal-world, dynamic web environments. We propose a systematic methodology for\nconstructing challenging queries satisfying the criteria of determinacy,\ndifficulty, and diversity. Based on this, we develop the first evaluation\nframework tailored to dynamic agentic information seeking, including\nfine-grained metrics about the accuracy, utility, and compactness of\ninformation seeking outcomes. Through extensive experiments across LLMs, search\nengines, and question types, InfoDeepSeek reveals nuanced agent behaviors and\noffers actionable insights for future research.", "AI": {"tldr": "InfoDeepSeek is a new benchmark for evaluating agentic information seeking in dynamic web environments, addressing gaps in existing static benchmarks.", "motivation": "Existing benchmarks for Retrieval-Augmented Generation (RAG) and Agentic RAG are limited to static environments and simple queries, failing to assess real-world, dynamic scenarios.", "method": "Proposes a systematic methodology for constructing challenging queries (determinacy, difficulty, diversity) and develops an evaluation framework with fine-grained metrics (accuracy, utility, compactness).", "result": "InfoDeepSeek reveals nuanced agent behaviors and provides actionable insights through experiments across LLMs, search engines, and question types.", "conclusion": "InfoDeepSeek bridges the gap in evaluating agentic information seeking, offering a tailored framework for dynamic, real-world environments."}}
{"id": "2505.17012", "pdf": "https://arxiv.org/pdf/2505.17012", "abs": "https://arxiv.org/abs/2505.17012", "authors": ["Haoning Wu", "Xiao Huang", "Yaohui Chen", "Ya Zhang", "Yanfeng Wang", "Weidi Xie"], "title": "SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding", "categories": ["cs.CV", "cs.AI"], "comment": "Technical Report; Project Page:\n  https://haoningwu3639.github.io/SpatialScore", "summary": "Multimodal large language models (MLLMs) have achieved impressive success in\nquestion-answering tasks, yet their capabilities for spatial understanding are\nless explored. This work investigates a critical question: do existing MLLMs\npossess 3D spatial perception and understanding abilities? Concretely, we make\nthe following contributions in this paper: (i) we introduce VGBench, a\nbenchmark specifically designed to assess MLLMs for visual geometry perception,\ne.g., camera pose and motion estimation; (ii) we propose SpatialScore, the most\ncomprehensive and diverse multimodal spatial understanding benchmark to date,\nintegrating VGBench with relevant data from the other 11 existing datasets.\nThis benchmark comprises 28K samples across various spatial understanding\ntasks, modalities, and QA formats, along with a carefully curated challenging\nsubset, SpatialScore-Hard; (iii) we develop SpatialAgent, a novel multi-agent\nsystem incorporating 9 specialized tools for spatial understanding, supporting\nboth Plan-Execute and ReAct reasoning paradigms; (iv) we conduct extensive\nevaluations to reveal persistent challenges in spatial reasoning while\ndemonstrating the effectiveness of SpatialAgent. We believe SpatialScore will\noffer valuable insights and serve as a rigorous benchmark for the next\nevolution of MLLMs.", "AI": {"tldr": "The paper introduces VGBench and SpatialScore to evaluate MLLMs' 3D spatial understanding, proposes SpatialAgent for improved reasoning, and highlights persistent challenges in spatial tasks.", "motivation": "To explore and assess the 3D spatial perception capabilities of multimodal large language models (MLLMs), which are less studied despite their success in question-answering tasks.", "method": "(i) Introduces VGBench for visual geometry perception; (ii) Proposes SpatialScore, a comprehensive benchmark integrating VGBench with 11 datasets; (iii) Develops SpatialAgent, a multi-agent system with specialized tools for spatial reasoning.", "result": "Extensive evaluations reveal persistent challenges in spatial reasoning but demonstrate SpatialAgent's effectiveness.", "conclusion": "SpatialScore provides valuable insights and a rigorous benchmark for advancing MLLMs' spatial understanding capabilities."}}
{"id": "2505.17016", "pdf": "https://arxiv.org/pdf/2505.17016", "abs": "https://arxiv.org/abs/2505.17016", "authors": ["Shuhan Tan", "Kairan Dou", "Yue Zhao", "Philipp Kr\u00e4henb\u00fchl"], "title": "Interactive Post-Training for Vision-Language-Action Models", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": "Project page: https://ariostgx.github.io/ript_vla/", "summary": "We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based\ninteractive post-training paradigm that fine-tunes pretrained\nVision-Language-Action (VLA) models using only sparse binary success rewards.\nExisting VLA training pipelines rely heavily on offline expert demonstration\ndata and supervised imitation, limiting their ability to adapt to new tasks and\nenvironments under low-data regimes. RIPT-VLA addresses this by enabling\ninteractive post-training with a stable policy optimization algorithm based on\ndynamic rollout sampling and leave-one-out advantage estimation.\n  RIPT-VLA has the following characteristics. First, it applies to various VLA\nmodels, resulting in an improvement on the lightweight QueST model by 21.2%,\nand the 7B OpenVLA-OFT model to an unprecedented 97.5% success rate. Second, it\nis computationally efficient and data-efficient: with only one demonstration,\nRIPT-VLA enables an unworkable SFT model (4%) to succeed with a 97% success\nrate within 15 iterations. Furthermore, we demonstrate that the policy learned\nby RIPT-VLA generalizes across different tasks and scenarios and is robust to\nthe initial state context. These results highlight RIPT-VLA as a practical and\neffective paradigm for post-training VLA models through minimal supervision.", "AI": {"tldr": "RIPT-VLA is a reinforcement-learning-based method for fine-tuning Vision-Language-Action models using sparse binary rewards, improving adaptability and success rates with minimal data.", "motivation": "Existing VLA models rely on offline expert data, limiting adaptability in low-data scenarios. RIPT-VLA aims to overcome this by enabling interactive post-training.", "method": "Uses dynamic rollout sampling and leave-one-out advantage estimation for stable policy optimization, requiring only sparse rewards.", "result": "Achieves 21.2% improvement on QueST and 97.5% success rate on OpenVLA-OFT. Efficiently boosts success from 4% to 97% in 15 iterations with one demo.", "conclusion": "RIPT-VLA is a practical, effective paradigm for post-training VLAs with minimal supervision, generalizing across tasks and scenarios."}}
{"id": "2505.17001", "pdf": "https://arxiv.org/pdf/2505.17001", "abs": "https://arxiv.org/abs/2505.17001", "authors": ["Ming Qian", "Bin Tan", "Qiuyu Wang", "Xianwei Zheng", "Hanjiang Xiong", "Gui-Song Xia", "Yujun Shen", "Nan Xue"], "title": "Seeing through Satellite Images at Street Views", "categories": ["cs.CV"], "comment": "Project page: https://qianmingduowan.github.io/sat2density-pp/,\n  journal extension of ICCV 2023 conference paper 'Sat2Density: Faithful\n  Density Learning from Satellite-Ground Image Pairs', submitted to TPAMI", "summary": "This paper studies the task of SatStreet-view synthesis, which aims to render\nphotorealistic street-view panorama images and videos given any satellite image\nand specified camera positions or trajectories. We formulate to learn neural\nradiance field from paired images captured from satellite and street\nviewpoints, which comes to be a challenging learning problem due to the\nsparse-view natural and the extremely-large viewpoint changes between satellite\nand street-view images. We tackle the challenges based on a task-specific\nobservation that street-view specific elements, including the sky and\nillumination effects are only visible in street-view panoramas, and present a\nnovel approach Sat2Density++ to accomplish the goal of photo-realistic\nstreet-view panoramas rendering by modeling these street-view specific in\nneural networks. In the experiments, our method is testified on both urban and\nsuburban scene datasets, demonstrating that Sat2Density++ is capable of\nrendering photorealistic street-view panoramas that are consistent across\nmultiple views and faithful to the satellite image.", "AI": {"tldr": "The paper introduces Sat2Density++, a method for synthesizing photorealistic street-view panoramas from satellite images by addressing challenges like sparse-view data and large viewpoint changes.", "motivation": "The task of rendering street-view panoramas from satellite images is challenging due to sparse data and significant viewpoint differences. The paper aims to solve this by leveraging street-view specific elements like sky and illumination effects.", "method": "The proposed Sat2Density++ learns a neural radiance field from paired satellite and street-view images, focusing on modeling street-view specific elements in neural networks.", "result": "Experiments on urban and suburban datasets show Sat2Density++ successfully renders photorealistic, consistent, and satellite-faithful street-view panoramas.", "conclusion": "Sat2Density++ effectively addresses the challenges of street-view synthesis from satellite images, achieving high-quality results."}}
{"id": "2505.15935", "pdf": "https://arxiv.org/pdf/2505.15935", "abs": "https://arxiv.org/abs/2505.15935", "authors": ["Omer Hofman", "Oren Rachmil", "Shamik Bose", "Vikas Pahuja", "Jonathan Brokman", "Toshiya Shimizu", "Trisha Starostina", "Kelly Marchisio", "Seraphina Goldfarb-Tarrant", "Roman Vainshtein"], "title": "MAPS: A Multilingual Benchmark for Global Agent Performance and Security", "categories": ["cs.DB", "cs.CL", "cs.CR"], "comment": null, "summary": "Agentic AI systems, which build on Large Language Models (LLMs) and interact\nwith tools and memory, have rapidly advanced in capability and scope. Yet,\nsince LLMs have been shown to struggle in multilingual settings, typically\nresulting in lower performance and reduced safety, agentic systems risk\ninheriting these limitations. This raises concerns about the global\naccessibility of such systems, as users interacting in languages other than\nEnglish may encounter unreliable or security-critical agent behavior. Despite\ngrowing interest in evaluating agentic AI, existing benchmarks focus\nexclusively on English, leaving multilingual settings unexplored. To address\nthis gap, we propose MAPS, a multilingual benchmark suite designed to evaluate\nagentic AI systems across diverse languages and tasks. MAPS builds on four\nwidely used agentic benchmarks - GAIA (real-world tasks), SWE-bench (code\ngeneration), MATH (mathematical reasoning), and the Agent Security Benchmark\n(security). We translate each dataset into ten diverse languages, resulting in\n805 unique tasks and 8,855 total language-specific instances. Our benchmark\nsuite enables a systematic analysis of how multilingual contexts affect agent\nperformance and robustness. Empirically, we observe consistent degradation in\nboth performance and security when transitioning from English to other\nlanguages, with severity varying by task and correlating with the amount of\ntranslated input. Building on these findings, we provide actionable\nrecommendations to guide agentic AI systems development and assessment under\nmultilingual settings. This work establishes a standardized evaluation\nframework, encouraging future research towards equitable, reliable, and\nglobally accessible agentic AI. MAPS benchmark suite is publicly available at\nhttps://huggingface.co/datasets/Fujitsu-FRE/MAPS", "AI": {"tldr": "The paper introduces MAPS, a multilingual benchmark suite to evaluate agentic AI systems, revealing performance and security degradation in non-English languages and providing recommendations for improvement.", "motivation": "Address the gap in evaluating agentic AI systems in multilingual settings, as existing benchmarks focus only on English, risking unreliable or unsafe behavior for non-English users.", "method": "Develop MAPS by translating four agentic benchmarks (GAIA, SWE-bench, MATH, Agent Security Benchmark) into ten languages, creating 805 tasks and 8,855 instances for systematic evaluation.", "result": "Performance and security degrade consistently in non-English languages, with severity varying by task and translation input.", "conclusion": "MAPS provides a standardized framework for equitable and reliable agentic AI development, encouraging globally accessible systems."}}
{"id": "2505.17017", "pdf": "https://arxiv.org/pdf/2505.17017", "abs": "https://arxiv.org/abs/2505.17017", "authors": ["Chengzhuo Tong", "Ziyu Guo", "Renrui Zhang", "Wenyu Shan", "Xinyu Wei", "Zhenghao Xing", "Hongsheng Li", "Pheng-Ann Heng"], "title": "Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Code is released at https://github.com/ZiyuGuo99/Image-Generation-CoT", "summary": "Recent advancements underscore the significant role of Reinforcement Learning\n(RL) in enhancing the Chain-of-Thought (CoT) reasoning capabilities of large\nlanguage models (LLMs). Two prominent RL algorithms, Direct Preference\nOptimization (DPO) and Group Relative Policy Optimization (GRPO), are central\nto these developments, showcasing different pros and cons. Autoregressive image\ngeneration, also interpretable as a sequential CoT reasoning process, presents\nunique challenges distinct from LLM-based CoT reasoning. These encompass\nensuring text-image consistency, improving image aesthetic quality, and\ndesigning sophisticated reward models, rather than relying on simpler\nrule-based rewards. While recent efforts have extended RL to this domain, these\nexplorations typically lack an in-depth analysis of the domain-specific\nchallenges and the characteristics of different RL strategies. To bridge this\ngap, we provide the first comprehensive investigation of the GRPO and DPO\nalgorithms in autoregressive image generation, evaluating their in-domain\nperformance and out-of-domain generalization, while scrutinizing the impact of\ndifferent reward models on their respective capabilities. Our findings reveal\nthat GRPO and DPO exhibit distinct advantages, and crucially, that reward\nmodels possessing stronger intrinsic generalization capabilities potentially\nenhance the generalization potential of the applied RL algorithms. Furthermore,\nwe systematically explore three prevalent scaling strategies to enhance both\ntheir in-domain and out-of-domain proficiency, deriving unique insights into\nefficiently scaling performance for each paradigm. We hope our study paves a\nnew path for inspiring future work on developing more effective RL algorithms\nto achieve robust CoT reasoning in the realm of autoregressive image\ngeneration. Code is released at\nhttps://github.com/ZiyuGuo99/Image-Generation-CoT", "AI": {"tldr": "The paper explores Reinforcement Learning (RL) in autoregressive image generation, comparing GRPO and DPO algorithms, and analyzing reward models' impact on performance and generalization.", "motivation": "To address the lack of in-depth analysis of RL strategies and domain-specific challenges in autoregressive image generation, particularly for Chain-of-Thought (CoT) reasoning.", "method": "Comprehensive investigation of GRPO and DPO algorithms, evaluating in-domain performance, out-of-domain generalization, and the role of reward models. Scaling strategies are also explored.", "result": "GRPO and DPO show distinct advantages; reward models with strong generalization enhance RL algorithms. Scaling strategies improve performance for both paradigms.", "conclusion": "The study provides insights for developing effective RL algorithms in autoregressive image generation, advancing robust CoT reasoning."}}
{"id": "2505.14403", "pdf": "https://arxiv.org/pdf/2505.14403", "abs": "https://arxiv.org/abs/2505.14403", "authors": ["Zhaohui Yang", "Shilei Jiang", "Chen Hu", "Linjing Li", "Shihong Deng", "Daxin Jiang"], "title": "Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in reasoning language models have witnessed a paradigm shift\nfrom short to long CoT pattern. Given the substantial computational cost of\nrollouts in long CoT models, maximizing the utility of fixed training datasets\nbecomes crucial. Our analysis reveals that negative responses contain valuable\ncomponents such as self-reflection and error-correction steps, yet primary\nexisting methods either completely discard negative samples (RFT) or apply\nequal penalization across all tokens (RL), failing to leverage these potential\nlearning signals. In light of this, we propose Behavior Constrained Policy\nGradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline\nRL framework that encompasses three stages: 1) sample segmentation, 2)\nconsensus-based step correctness assessment combining LLM and PRM judgers, and\n3) policy optimization with NSA designed to effectively mine positive steps\nwithin negative samples. Experimental results show that BCPG-NSA outperforms\nbaselines on several challenging math/coding reasoning benchmarks using the\nsame training dataset, achieving improved sample efficiency and demonstrating\nrobustness and scalability when extended to multiple iterations.", "AI": {"tldr": "BCPG-NSA is a new offline RL framework that leverages negative samples for improved reasoning in language models, outperforming baselines in math/coding tasks.", "motivation": "Existing methods discard or poorly utilize negative samples, missing valuable learning signals like self-reflection and error-correction.", "method": "BCPG-NSA involves sample segmentation, consensus-based correctness assessment (LLM + PRM), and policy optimization with Negative Sample Augmentation (NSA).", "result": "BCPG-NSA outperforms baselines on math/coding benchmarks, showing better sample efficiency, robustness, and scalability.", "conclusion": "The framework effectively mines positive steps from negative samples, enhancing reasoning model performance."}}
{"id": "2505.17006", "pdf": "https://arxiv.org/pdf/2505.17006", "abs": "https://arxiv.org/abs/2505.17006", "authors": ["Jiange Yang", "Yansong Shi", "Haoyi Zhu", "Mingyu Liu", "Kaijing Ma", "Yating Wang", "Gangshan Wu", "Tong He", "Limin Wang"], "title": "CoMo: Learning Continuous Latent Motion from Internet Videos for Scalable Robot Learning", "categories": ["cs.CV", "cs.RO"], "comment": "18 pages, 7 figures", "summary": "Learning latent motion from Internet videos is crucial for building\ngeneralist robots. However, existing discrete latent action methods suffer from\ninformation loss and struggle with complex and fine-grained dynamics. We\npropose CoMo, which aims to learn more informative continuous motion\nrepresentations from diverse, internet-scale videos. CoMo employs a early\ntemporal feature difference mechanism to prevent model collapse and suppress\nstatic appearance noise, effectively discouraging shortcut learning problem.\nFurthermore, guided by the information bottleneck principle, we constrain the\nlatent motion embedding dimensionality to achieve a better balance between\nretaining sufficient action-relevant information and minimizing the inclusion\nof action-irrelevant appearance noise. Additionally, we also introduce two new\nmetrics for more robustly and affordably evaluating motion and guiding motion\nlearning methods development: (i) the linear probing MSE of action prediction,\nand (ii) the cosine similarity between past-to-current and future-to-current\nmotion embeddings. Critically, CoMo exhibits strong zero-shot generalization,\nenabling it to generate continuous pseudo actions for previously unseen video\ndomains. This capability facilitates unified policy joint learning using pseudo\nactions derived from various action-less video datasets (such as\ncross-embodiment videos and, notably, human demonstration videos), potentially\naugmented with limited labeled robot data. Extensive experiments show that\npolicies co-trained with CoMo pseudo actions achieve superior performance with\nboth diffusion and autoregressive architectures in simulated and real-world\nsettings.", "AI": {"tldr": "CoMo learns continuous motion representations from internet videos, improving generalization and enabling unified policy learning with pseudo actions.", "motivation": "Existing discrete latent action methods lose information and struggle with fine-grained dynamics, limiting their effectiveness for generalist robots.", "method": "CoMo uses early temporal feature differences to avoid model collapse and suppress noise, guided by the information bottleneck principle. It introduces new metrics for robust evaluation.", "result": "CoMo shows strong zero-shot generalization, enabling pseudo actions for unseen domains and superior policy performance in experiments.", "conclusion": "CoMo advances motion learning by providing informative, continuous representations, facilitating better policy training across diverse video datasets."}}
{"id": "2505.16065", "pdf": "https://arxiv.org/pdf/2505.16065", "abs": "https://arxiv.org/abs/2505.16065", "authors": ["Ruijie Xi", "He Ba", "Hao Yuan", "Rishu Agrawal", "Arul Prakash"], "title": "Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated Synthetic Data Augmentation", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Embedding-Based Retrieval (EBR) is an important technique in modern search\nengines, enabling semantic match between search queries and relevant results.\nHowever, search logging data on platforms like Facebook Marketplace lacks the\ndiversity and details needed for effective EBR model training, limiting the\nmodels' ability to capture nuanced search patterns. To address this challenge,\nwe propose Aug2Search, an EBR-based framework leveraging synthetic data\ngenerated by Generative AI (GenAI) models, in a multimodal and multitask\napproach to optimize query-product relevance. This paper investigates the\ncapabilities of GenAI, particularly Large Language Models (LLMs), in generating\nhigh-quality synthetic data, and analyzing its impact on enhancing EBR models.\nWe conducted experiments using eight Llama models and 100 million data points\nfrom Facebook Marketplace logs. Our synthetic data generation follows three\nstrategies: (1) generate queries, (2) enhance product listings, and (3)\ngenerate queries from enhanced listings. We train EBR models on three different\ndatasets: sampled engagement data or original data ((e.g., \"Click\" and \"Listing\nInteractions\")), synthetic data, and a mixture of both engagement and synthetic\ndata to assess their performance across various training sets. Our findings\nunderscore the robustness of Llama models in producing synthetic queries and\nlistings with high coherence, relevance, and diversity, while maintaining low\nlevels of hallucination. Aug2Search achieves an improvement of up to 4% in\nROC_AUC with 100 million synthetic data samples, demonstrating the\neffectiveness of our approach. Moreover, our experiments reveal that with the\nsame volume of training data, models trained exclusively on synthetic data\noften outperform those trained on original data only or a mixture of original\nand synthetic data.", "AI": {"tldr": "Aug2Search uses GenAI to generate synthetic data for training EBR models, improving query-product relevance and outperforming models trained on original or mixed data.", "motivation": "Diverse and detailed search logging data is lacking for effective EBR model training, limiting nuanced search pattern capture.", "method": "Proposes Aug2Search, leveraging synthetic data from GenAI (LLMs) in a multimodal, multitask approach. Experiments with Llama models and 100M Marketplace logs.", "result": "Synthetic data improves ROC_AUC by 4%. Models trained on synthetic data alone often outperform those using original or mixed data.", "conclusion": "GenAI-generated synthetic data enhances EBR models, proving robust and effective for search relevance optimization."}}
{"id": "2505.17019", "pdf": "https://arxiv.org/pdf/2505.17019", "abs": "https://arxiv.org/abs/2505.17019", "authors": ["Chenhao Zhang", "Yazhe Niu"], "title": "Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework", "categories": ["cs.CV", "cs.AI", "cs.CY"], "comment": "16 pages, 9 figures. Code & Dataset:\n  https://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep", "summary": "Metaphorical comprehension in images remains a critical challenge for AI\nsystems, as existing models struggle to grasp the nuanced cultural, emotional,\nand contextual implications embedded in visual content. While multimodal large\nlanguage models (MLLMs) excel in basic Visual Question Answer (VQA) tasks, they\nstruggle with a fundamental limitation on image implication tasks: contextual\ngaps that obscure the relationships between different visual elements and their\nabstract meanings. Inspired by the human cognitive process, we propose Let\nAndroids Dream (LAD), a novel framework for image implication understanding and\nreasoning. LAD addresses contextual missing through the three-stage framework:\n(1) Perception: converting visual information into rich and multi-level textual\nrepresentations, (2) Search: iteratively searching and integrating cross-domain\nknowledge to resolve ambiguity, and (3) Reasoning: generating context-alignment\nimage implication via explicit reasoning. Our framework with the lightweight\nGPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English\nimage implication benchmark and a huge improvement on Chinese benchmark,\nperforming comparable with the GPT-4o model on Multiple-Choice Question (MCQ)\nand outperforms 36.7% on Open-Style Question (OSQ). Additionally, our work\nprovides new insights into how AI can more effectively interpret image\nimplications, advancing the field of vision-language reasoning and human-AI\ninteraction. Our project is publicly available at\nhttps://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep.", "AI": {"tldr": "LAD is a novel framework for image implication understanding, outperforming 15+ MLLMs on benchmarks and advancing vision-language reasoning.", "motivation": "Existing AI models struggle with metaphorical comprehension in images due to contextual gaps, limiting their ability to interpret abstract meanings.", "method": "LAD uses a three-stage framework: Perception (visual-to-textual conversion), Search (cross-domain knowledge integration), and Reasoning (context-aligned implication generation).", "result": "LAD achieves SOTA performance on English and Chinese benchmarks, outperforming GPT-4o-mini and other models, with significant improvements in MCQ and OSQ tasks.", "conclusion": "LAD advances AI's ability to interpret image implications, offering insights for vision-language reasoning and human-AI interaction."}}
{"id": "2505.15833", "pdf": "https://arxiv.org/pdf/2505.15833", "abs": "https://arxiv.org/abs/2505.15833", "authors": ["Mathias Schmolli", "Maximilian Baronig", "Robert Legenstein", "Ozan \u00d6zdenizci"], "title": "Adversarially Robust Spiking Neural Networks with Sparse Connectivity", "categories": ["cs.NE", "cs.CR", "cs.LG"], "comment": null, "summary": "Deployment of deep neural networks in resource-constrained embedded systems\nrequires innovative algorithmic solutions to facilitate their energy and memory\nefficiency. To further ensure the reliability of these systems against\nmalicious actors, recent works have extensively studied adversarial robustness\nof existing architectures. Our work focuses on the intersection of adversarial\nrobustness, memory- and energy-efficiency in neural networks. We introduce a\nneural network conversion algorithm designed to produce sparse and\nadversarially robust spiking neural networks (SNNs) by leveraging the sparse\nconnectivity and weights from a robustly pretrained artificial neural network\n(ANN). Our approach combines the energy-efficient architecture of SNNs with a\nnovel conversion algorithm, leading to state-of-the-art performance with\nenhanced energy and memory efficiency through sparse connectivity and\nactivations. Our models are shown to achieve up to 100x reduction in the number\nof weights to be stored in memory, with an estimated 8.6x increase in energy\nefficiency compared to dense SNNs, while maintaining high performance and\nrobustness against adversarial threats.", "AI": {"tldr": "A novel algorithm converts robust pretrained ANNs into sparse, energy-efficient SNNs, achieving 100x memory reduction and 8.6x energy efficiency while maintaining robustness.", "motivation": "Addressing the need for energy- and memory-efficient neural networks in embedded systems without compromising adversarial robustness.", "method": "Introduces a conversion algorithm to transform robust pretrained ANNs into sparse SNNs, leveraging sparse connectivity and weights.", "result": "Achieves up to 100x memory reduction and 8.6x energy efficiency compared to dense SNNs, with maintained performance and robustness.", "conclusion": "The approach successfully combines efficiency and robustness, making it viable for resource-constrained embedded systems."}}
{"id": "2505.17011", "pdf": "https://arxiv.org/pdf/2505.17011", "abs": "https://arxiv.org/abs/2505.17011", "authors": ["Yan Li", "Changyao Tian", "Renqiu Xia", "Ning Liao", "Weiwei Guo", "Junchi Yan", "Hongsheng Li", "Jifeng Dai", "Hao Li", "Xue Yang"], "title": "Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space", "categories": ["cs.CV"], "comment": "Code: https://github.com/VisionXLab/AdapTok", "summary": "We propose AdapTok, an adaptive temporal causal video tokenizer that can\nflexibly allocate tokens for different frames based on video content. AdapTok\nis equipped with a block-wise masking strategy that randomly drops tail tokens\nof each block during training, and a block causal scorer to predict the\nreconstruction quality of video frames using different numbers of tokens.\nDuring inference, an adaptive token allocation strategy based on integer linear\nprogramming is further proposed to adjust token usage given predicted scores.\nSuch design allows for sample-wise, content-aware, and temporally dynamic token\nallocation under a controllable overall budget. Extensive experiments for video\nreconstruction and generation on UCF-101 and Kinetics-600 demonstrate the\neffectiveness of our approach. Without additional image data, AdapTok\nconsistently improves reconstruction quality and generation performance under\ndifferent token budgets, allowing for more scalable and token-efficient\ngenerative video modeling.", "AI": {"tldr": "AdapTok is an adaptive video tokenizer that dynamically allocates tokens per frame using content-aware strategies, improving video reconstruction and generation under fixed token budgets.", "motivation": "To enable scalable and token-efficient generative video modeling by dynamically allocating tokens based on video content.", "method": "Uses block-wise masking during training, a block causal scorer for reconstruction quality prediction, and adaptive token allocation via integer linear programming during inference.", "result": "Improves reconstruction quality and generation performance on UCF-101 and Kinetics-600 without extra data.", "conclusion": "AdapTok offers a scalable, content-aware solution for token-efficient video modeling."}}
{"id": "2405.13873", "pdf": "https://arxiv.org/pdf/2405.13873", "abs": "https://arxiv.org/abs/2405.13873", "authors": ["Yuan Sui", "Yufei He", "Nian Liu", "Xiaoxin He", "Kun Wang", "Bryan Hooi"], "title": "FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering", "categories": ["cs.AI", "cs.CL"], "comment": "This paper has been accepted by ACL 2025", "summary": "Large Language Models (LLMs) are often challenged by generating erroneous or\nhallucinated responses, especially in complex reasoning tasks. Leveraging\nKnowledge Graphs (KGs) as external knowledge sources has emerged as a viable\nsolution. However, existing KG-enhanced methods, either retrieval-based or\nagent-based, encounter difficulties in accurately retrieving knowledge and\nefficiently traversing KGs at scale. In this paper, we propose a unified\nframework, FiDeLiS, designed to improve the factuality of LLM responses by\nanchoring answers to verifiable reasoning steps retrieved from KGs. To achieve\nthis, we leverage step-wise beam search with a deductive scoring function,\nallowing the LLM to validate reasoning process step by step, and halt the\nsearch once the question is deducible. In addition, we propose a Path-RAG\nmodule to pre-select a smaller candidate set for each beam search step,\nreducing computational costs by narrowing the search space. Extensive\nexperiments show that our method, as a training-free framework, not only\nimprove the performance but also enhance the factuality and interpretability\nacross different benchmarks. Code is released at\nhttps://github.com/Y-Sui/FiDeLiS.", "AI": {"tldr": "FiDeLiS is a unified framework that improves LLM factuality by anchoring answers to verifiable reasoning steps from KGs, using step-wise beam search and Path-RAG to reduce computational costs.", "motivation": "Addressing LLMs' challenges with erroneous responses in complex reasoning tasks by leveraging KGs for verifiable knowledge.", "method": "Uses step-wise beam search with deductive scoring and Path-RAG to pre-select candidate sets, reducing search space.", "result": "Improves performance, factuality, and interpretability across benchmarks without training.", "conclusion": "FiDeLiS effectively enhances LLM responses by integrating KG-based verifiable reasoning."}}
{"id": "2505.15839", "pdf": "https://arxiv.org/pdf/2505.15839", "abs": "https://arxiv.org/abs/2505.15839", "authors": ["Saining Liu", "Yi Mei", "Mengjie Zhang"], "title": "Curriculum Learning in Genetic Programming Guided Local Search for Large-scale Vehicle Routing Problems", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Manually designing (meta-)heuristics for the Vehicle Routing Problem (VRP) is\na challenging task that requires significant domain expertise. Recently,\ndata-driven approaches have emerged as a promising solution, automatically\nlearning heuristics that perform well on training instances and generalize to\nunseen test cases. Such an approach learns (meta-)heuristics that can perform\nwell on the training instances, expecting it to generalize well on the unseen\ntest instances. A recent method, named GPGLS, uses Genetic Programming (GP) to\nlearn the utility function in Guided Local Search (GLS) and solved large scale\nVRP effectively. However, the selection of appropriate training instances\nduring the learning process remains an open question, with most existing\nstudies including GPGLS relying on random instance selection. To address this,\nwe propose a novel method, CL-GPGLS, which integrates Curriculum Learning (CL)\ninto GPGLS. Our approach leverages a predefined curriculum to introduce\ntraining instances progressively, starting with simpler tasks and gradually\nincreasing complexity, enabling the model to better adapt and optimize for\nlarge-scale VRP (LSVRP). Extensive experiments verify the effectiveness of\nCL-GPGLS, demonstrating significant performance improvements over three\nbaseline methods.", "AI": {"tldr": "The paper introduces CL-GPGLS, a method combining Curriculum Learning with GPGLS to improve heuristic learning for large-scale Vehicle Routing Problems by progressively training on increasingly complex instances.", "motivation": "Manually designing heuristics for VRP is challenging, and existing data-driven methods like GPGLS rely on random instance selection, which may not optimize learning effectively.", "method": "CL-GPGLS integrates Curriculum Learning into GPGLS, using a predefined curriculum to progressively introduce training instances from simple to complex.", "result": "Experiments show CL-GPGLS outperforms three baseline methods, demonstrating significant improvements in solving large-scale VRP.", "conclusion": "CL-GPGLS effectively addresses the limitation of random instance selection in GPGLS, enhancing heuristic learning and performance for large-scale VRP."}}
{"id": "2505.17015", "pdf": "https://arxiv.org/pdf/2505.17015", "abs": "https://arxiv.org/abs/2505.17015", "authors": ["Runsen Xu", "Weiyao Wang", "Hao Tang", "Xingyu Chen", "Xiaodong Wang", "Fu-Jen Chu", "Dahua Lin", "Matt Feiszli", "Kevin J. Liang"], "title": "Multi-SpatialMLLM: Multi-Frame Spatial Understanding with Multi-Modal Large Language Models", "categories": ["cs.CV", "cs.CL"], "comment": "24 pages. An MLLM, dataset, and benchmark for multi-frame spatial\n  understanding. Project page: https://runsenxu.com/projects/Multi-SpatialMLLM", "summary": "Multi-modal large language models (MLLMs) have rapidly advanced in visual\ntasks, yet their spatial understanding remains limited to single images,\nleaving them ill-suited for robotics and other real-world applications that\nrequire multi-frame reasoning. In this paper, we propose a framework to equip\nMLLMs with robust multi-frame spatial understanding by integrating depth\nperception, visual correspondence, and dynamic perception. Central to our\napproach is the MultiSPA dataset, a novel, large-scale collection of more than\n27 million samples spanning diverse 3D and 4D scenes. Alongside MultiSPA, we\nintroduce a comprehensive benchmark that tests a wide spectrum of spatial tasks\nunder uniform metrics. Our resulting model, Multi-SpatialMLLM, achieves\nsignificant gains over baselines and proprietary systems, demonstrating\nscalable, generalizable multi-frame reasoning. We further observe multi-task\nbenefits and early indications of emergent capabilities in challenging\nscenarios, and showcase how our model can serve as a multi-frame reward\nannotator for robotics.", "AI": {"tldr": "A framework enhances MLLMs with multi-frame spatial understanding using depth, visual correspondence, and dynamic perception, validated by the MultiSPA dataset and benchmark.", "motivation": "Current MLLMs lack robust multi-frame spatial reasoning, limiting their use in robotics and real-world applications.", "method": "Proposes integrating depth perception, visual correspondence, and dynamic perception, supported by the MultiSPA dataset and benchmark.", "result": "Multi-SpatialMLLM outperforms baselines and proprietary systems, showing scalable multi-frame reasoning and emergent capabilities.", "conclusion": "The framework advances MLLMs for robotics and real-world tasks, with potential as a multi-frame reward annotator."}}
{"id": "2505.16263", "pdf": "https://arxiv.org/pdf/2505.16263", "abs": "https://arxiv.org/abs/2505.16263", "authors": ["Sampanna Yashwant Kahu", "Naman Ahuja"], "title": "All You Need is \"Leet\": Evading Hate-speech Detection AI", "categories": ["cs.CR", "cs.CL", "cs.LG", "K.6.5"], "comment": "10 pages, 22 figures, The source code and data used in this work is\n  available at: https://github.com/SampannaKahu/all_you_need_is_leet", "summary": "Social media and online forums are increasingly becoming popular.\nUnfortunately, these platforms are being used for spreading hate speech. In\nthis paper, we design black-box techniques to protect users from hate-speech on\nonline platforms by generating perturbations that can fool state of the art\ndeep learning based hate speech detection models thereby decreasing their\nefficiency. We also ensure a minimal change in the original meaning of\nhate-speech. Our best perturbation attack is successfully able to evade\nhate-speech detection for 86.8 % of hateful text.", "AI": {"tldr": "Black-box techniques are designed to fool hate-speech detection models by generating minimal perturbations, evading detection for 86.8% of hateful text.", "motivation": "To protect users from hate speech on online platforms by reducing the efficiency of deep learning-based detection models.", "method": "Designing black-box perturbation techniques to alter hate-speech text minimally while evading detection.", "result": "The best perturbation attack successfully evades detection for 86.8% of hateful text.", "conclusion": "The proposed method effectively reduces the efficiency of hate-speech detection models with minimal semantic change."}}
{"id": "2407.10973", "pdf": "https://arxiv.org/pdf/2407.10973", "abs": "https://arxiv.org/abs/2407.10973", "authors": ["Yongyuan Liang", "Tingqiang Xu", "Kaizhe Hu", "Guangqi Jiang", "Furong Huang", "Huazhe Xu"], "title": "Make-An-Agent: A Generalizable Policy Network Generator with Behavior-Prompted Diffusion", "categories": ["cs.AI"], "comment": "Annual Conference on Neural Information Processing Systems 38", "summary": "Can we generate a control policy for an agent using just one demonstration of\ndesired behaviors as a prompt, as effortlessly as creating an image from a\ntextual description? In this paper, we present Make-An-Agent, a novel policy\nparameter generator that leverages the power of conditional diffusion models\nfor behavior-to-policy generation. Guided by behavior embeddings that encode\ntrajectory information, our policy generator synthesizes latent parameter\nrepresentations, which can then be decoded into policy networks. Trained on\npolicy network checkpoints and their corresponding trajectories, our generation\nmodel demonstrates remarkable versatility and scalability on multiple tasks and\nhas a strong generalization ability on unseen tasks to output well-performed\npolicies with only few-shot demonstrations as inputs. We showcase its efficacy\nand efficiency on various domains and tasks, including varying objectives,\nbehaviors, and even across different robot manipulators. Beyond simulation, we\ndirectly deploy policies generated by Make-An-Agent onto real-world robots on\nlocomotion tasks. Project page: https://cheryyunl.github.io/make-an-agent/", "AI": {"tldr": "Make-An-Agent uses conditional diffusion models to generate control policies from single demonstrations, showing versatility and generalization across tasks and real-world robots.", "motivation": "To simplify policy generation for agents, akin to text-to-image models, using minimal demonstrations.", "method": "Leverages conditional diffusion models with behavior embeddings to synthesize latent policy parameters, trained on policy checkpoints and trajectories.", "result": "Demonstrates versatility, scalability, and strong generalization on unseen tasks with few-shot inputs, including real-world robot deployment.", "conclusion": "Make-An-Agent efficiently generates high-performing policies from minimal demonstrations, applicable across diverse domains and real-world scenarios."}}
{"id": "2505.15842", "pdf": "https://arxiv.org/pdf/2505.15842", "abs": "https://arxiv.org/abs/2505.15842", "authors": ["Mohit Kataria", "Shreyash Bhilwade", "Sandeep Kumar", "Jayadeva"], "title": "AH-UGC: Adaptive and Heterogeneous-Universal Graph Coarsening", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "$\\textbf{Graph Coarsening (GC)}$ is a prominent graph reduction technique\nthat compresses large graphs to enable efficient learning and inference.\nHowever, existing GC methods generate only one coarsened graph per run and must\nrecompute from scratch for each new coarsening ratio, resulting in unnecessary\noverhead. Moreover, most prior approaches are tailored to\n$\\textit{homogeneous}$ graphs and fail to accommodate the semantic constraints\nof $\\textit{heterogeneous}$ graphs, which comprise multiple node and edge\ntypes. To overcome these limitations, we introduce a novel framework that\ncombines Locality Sensitive Hashing (LSH) with Consistent Hashing to enable\n$\\textit{adaptive graph coarsening}$. Leveraging hashing techniques, our method\nis inherently fast and scalable. For heterogeneous graphs, we propose a\n$\\textit{type isolated coarsening}$ strategy that ensures semantic consistency\nby restricting merges to nodes of the same type. Our approach is the first\nunified framework to support both adaptive and heterogeneous coarsening.\nExtensive evaluations on 23 real-world datasets including homophilic,\nheterophilic, homogeneous, and heterogeneous graphs demonstrate that our method\nachieves superior scalability while preserving the structural and semantic\nintegrity of the original graph.", "AI": {"tldr": "A novel framework for adaptive and heterogeneous graph coarsening using hashing techniques, addressing limitations of existing methods.", "motivation": "Existing graph coarsening methods are inefficient for varying coarsening ratios and fail to handle heterogeneous graphs effectively.", "method": "Combines Locality Sensitive Hashing (LSH) and Consistent Hashing for adaptive coarsening, with type-isolated coarsening for heterogeneous graphs.", "result": "Demonstrates superior scalability and preserves structural/semantic integrity across 23 diverse datasets.", "conclusion": "Proposes the first unified framework for adaptive and heterogeneous graph coarsening, offering efficiency and semantic consistency."}}
{"id": "2505.17018", "pdf": "https://arxiv.org/pdf/2505.17018", "abs": "https://arxiv.org/abs/2505.17018", "authors": ["Kaixuan Fan", "Kaituo Feng", "Haoming Lyu", "Dongzhan Zhou", "Xiangyu Yue"], "title": "SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward", "categories": ["cs.CV"], "comment": "Project page:https://github.com/kxfan2002/SophiaVL-R1", "summary": "Recent advances have shown success in eliciting strong reasoning abilities in\nmultimodal large language models (MLLMs) through rule-based reinforcement\nlearning (RL) with outcome rewards. However, this paradigm typically lacks\nsupervision over the thinking process leading to the final outcome.As a result,\nthe model may learn sub-optimal reasoning strategies, which can hinder its\ngeneralization ability. In light of this, we propose SophiaVL-R1, as an attempt\nto add reward signals for the thinking process in this paradigm. To achieve\nthis, we first train a thinking reward model that evaluates the quality of the\nentire thinking process. Given that the thinking reward may be unreliable for\ncertain samples due to reward hacking, we propose the Trust-GRPO method, which\nassigns a trustworthiness weight to the thinking reward during training. This\nweight is computed based on the thinking reward comparison of responses leading\nto correct answers versus incorrect answers, helping to mitigate the impact of\npotentially unreliable thinking rewards. Moreover, we design an annealing\ntraining strategy that gradually reduces the thinking reward over time,\nallowing the model to rely more on the accurate rule-based outcome reward in\nlater training stages. Experiments show that our SophiaVL-R1 surpasses a series\nof reasoning MLLMs on various benchmarks (e.g., MathVisita, MMMU),\ndemonstrating strong reasoning and generalization capabilities. Notably, our\nSophiaVL-R1-7B even outperforms LLaVA-OneVision-72B on most benchmarks, despite\nthe latter having 10 times more parameters. All code, models, and datasets are\nmade publicly available at https://github.com/kxfan2002/SophiaVL-R1.", "AI": {"tldr": "SophiaVL-R1 enhances MLLMs by adding process-based rewards to rule-based RL, improving reasoning and generalization.", "motivation": "Current rule-based RL in MLLMs lacks supervision over the reasoning process, leading to sub-optimal strategies.", "method": "Introduces a thinking reward model and Trust-GRPO method to weight rewards, plus an annealing strategy.", "result": "Outperforms other MLLMs on benchmarks, even surpassing larger models like LLaVA-OneVision-72B.", "conclusion": "SophiaVL-R1 effectively improves reasoning by supervising the thinking process, with public release of resources."}}
{"id": "2505.16470", "pdf": "https://arxiv.org/pdf/2505.16470", "abs": "https://arxiv.org/abs/2505.16470", "authors": ["Kuicai Dong", "Yujing Chang", "Shijie Huang", "Yasheng Wang", "Ruiming Tang", "Yong Liu"], "title": "Benchmarking Retrieval-Augmented Multimomal Generation for Document Question Answering", "categories": ["cs.IR", "cs.CL", "cs.CV"], "comment": "preprint. code available at\n  \\url{https://mmdocrag.github.io/MMDocRAG/}", "summary": "Document Visual Question Answering (DocVQA) faces dual challenges in\nprocessing lengthy multimodal documents (text, images, tables) and performing\ncross-modal reasoning. Current document retrieval-augmented generation (DocRAG)\nmethods remain limited by their text-centric approaches, frequently missing\ncritical visual information. The field also lacks robust benchmarks for\nassessing multimodal evidence selection and integration. We introduce MMDocRAG,\na comprehensive benchmark featuring 4,055 expert-annotated QA pairs with\nmulti-page, cross-modal evidence chains. Our framework introduces innovative\nmetrics for evaluating multimodal quote selection and enables answers that\ninterleave text with relevant visual elements. Through large-scale experiments\nwith 60 VLM/LLM models and 14 retrieval systems, we identify persistent\nchallenges in multimodal evidence retrieval, selection, and integration.Key\nfindings reveal advanced proprietary LVMs show superior performance than\nopen-sourced alternatives. Also, they show moderate advantages using multimodal\ninputs over text-only inputs, while open-source alternatives show significant\nperformance degradation. Notably, fine-tuned LLMs achieve substantial\nimprovements when using detailed image descriptions. MMDocRAG establishes a\nrigorous testing ground and provides actionable insights for developing more\nrobust multimodal DocVQA systems. Our benchmark and code are available at\nhttps://mmdocrag.github.io/MMDocRAG/.", "AI": {"tldr": "MMDocRAG introduces a benchmark for multimodal DocVQA, addressing gaps in visual information integration and evaluation. It tests 60 models and 14 retrieval systems, revealing proprietary models outperform open-source ones.", "motivation": "Current DocVQA methods are text-centric and lack robust benchmarks for multimodal evidence handling.", "method": "MMDocRAG features 4,055 QA pairs with multi-page, cross-modal evidence chains and introduces metrics for multimodal quote selection.", "result": "Proprietary models excel, while open-source ones degrade with multimodal inputs. Fine-tuned LLMs improve with detailed image descriptions.", "conclusion": "MMDocRAG provides a rigorous benchmark and insights for advancing multimodal DocVQA systems."}}
{"id": "2409.16635", "pdf": "https://arxiv.org/pdf/2409.16635", "abs": "https://arxiv.org/abs/2409.16635", "authors": ["Sungjune Park", "Heehwan Kim", "Haehyun Cho", "Daeseon Choi"], "title": "Judgment-of-Thought Prompting: A Courtroom-Inspired Framework for Binary Logical Reasoning with Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "This paper proposes a novel prompting approach, Judgment of Thought (JoT),\nspecifically tailored for binary logical reasoning tasks. Despite advances in\nprompt engineering, existing approaches still face limitations in handling\ncomplex logical reasoning tasks. To address these issues, JoT introduces a\nmulti-agent approach with three specialized\nroles$\\unicode{x2010}$$\\unicode{x2010}$$\\unicode{x2010}$lawyer, prosecutor, and\njudge$\\unicode{x2010}$$\\unicode{x2010}$$\\unicode{x2010}$where a high-level\nmodel acts as the judge, and lower-level models serve as lawyer and prosecutor\nto systematically debate and evaluate arguments. Experimental evaluations on\nbenchmarks such as BigBenchHard and Winogrande demonstrate JoT's superior\nperformance compared to existing prompting approaches, achieving notable\nimprovements, including 98\\% accuracy in Boolean expressions. Also, our\nablation studies validate the critical contribution of each role, iterative\nrefinement loops, and feedback mechanisms. Consequently, JoT significantly\nenhances accuracy, reliability, and consistency in binary reasoning tasks and\nshows potential for practical applications.", "AI": {"tldr": "JoT introduces a multi-agent prompting approach for binary logical reasoning, outperforming existing methods with 98% accuracy in Boolean expressions.", "motivation": "Existing prompting approaches struggle with complex logical reasoning tasks, prompting the need for a more effective method.", "method": "JoT uses a multi-agent system with lawyer, prosecutor, and judge roles to debate and evaluate arguments systematically.", "result": "JoT achieves superior performance, including 98% accuracy in Boolean expressions, validated by ablation studies.", "conclusion": "JoT enhances accuracy, reliability, and consistency in binary reasoning, showing practical potential."}}
{"id": "2505.15844", "pdf": "https://arxiv.org/pdf/2505.15844", "abs": "https://arxiv.org/abs/2505.15844", "authors": ["Yousuf Islam", "Md. Jalal Uddin Chowdhury", "Sumon Chandra Das"], "title": "Advancing Tabular Stroke Modelling Through a Novel Hybrid Architecture and Feature-Selection Synergy", "categories": ["q-bio.QM", "cs.LG", "stat.AP"], "comment": null, "summary": "Brain stroke remains one of the principal causes of death and disability\nworldwide, yet most tabular-data prediction models still hover below the 95%\naccuracy threshold, limiting real-world utility. Addressing this gap, the\npresent work develops and validates a completely data-driven and interpretable\nmachine-learning framework designed to predict strokes using ten routinely\ngathered demographic, lifestyle, and clinical variables sourced from a public\ncohort of 4,981 records. We employ a detailed exploratory data analysis (EDA)\nto understand the dataset's structure and distribution, followed by rigorous\ndata preprocessing, including handling missing values, outlier removal, and\nclass imbalance correction using Synthetic Minority Over-sampling Technique\n(SMOTE). To streamline feature selection, point-biserial correlation and\nrandom-forest Gini importance were utilized, and ten varied\nalgorithms-encompassing tree ensembles, boosting, kernel methods, and a\nmultilayer neural network-were optimized using stratified five-fold\ncross-validation. Their predictions based on probabilities helped us build the\nproposed model, which included Random Forest, XGBoost, LightGBM, and a\nsupport-vector classifier, with logistic regression acting as a meta-learner.\nThe proposed model achieved an accuracy rate of 97.2% and an F1-score of\n97.15%, indicating a significant enhancement compared to the leading individual\nmodel, LightGBM, which had an accuracy of 91.4%. Our study's findings indicate\nthat rigorous preprocessing, coupled with a diverse hybrid model, can convert\nlow-cost tabular data into a nearly clinical-grade stroke-risk assessment tool.", "AI": {"tldr": "A hybrid machine-learning model achieves 97.2% accuracy in predicting strokes using routine data, outperforming individual models.", "motivation": "Brain stroke is a leading cause of death and disability, but existing prediction models lack accuracy and real-world utility.", "method": "The study uses EDA, SMOTE for class imbalance, feature selection, and a hybrid model combining Random Forest, XGBoost, LightGBM, and SVM with logistic regression as a meta-learner.", "result": "The model achieves 97.2% accuracy and 97.15% F1-score, surpassing LightGBM's 91.4% accuracy.", "conclusion": "Rigorous preprocessing and a hybrid model can transform tabular data into a highly accurate stroke-risk assessment tool."}}
{"id": "2505.17020", "pdf": "https://arxiv.org/pdf/2505.17020", "abs": "https://arxiv.org/abs/2505.17020", "authors": ["Shilin Yan", "Jiaming Han", "Joey Tsai", "Hongwei Xue", "Rongyao Fang", "Lingyi Hong", "Ziyu Guo", "Ray Zhang"], "title": "CrossLMM: Decoupling Long Video Sequences from LMMs via Dual Cross-Attention Mechanisms", "categories": ["cs.CV"], "comment": "Project page: https://github.com/shilinyan99/CrossLMM", "summary": "The advent of Large Multimodal Models (LMMs) has significantly enhanced Large\nLanguage Models (LLMs) to process and interpret diverse data modalities (e.g.,\nimage and video). However, as input complexity increases, particularly with\nlong video sequences, the number of required tokens has grown significantly,\nleading to quadratically computational costs. This has made the efficient\ncompression of video tokens in LMMs, while maintaining performance integrity, a\npressing research challenge. In this paper, we introduce CrossLMM, decoupling\nlong video sequences from LMMs via a dual cross-attention mechanism, which\nsubstantially reduces visual token quantity with minimal performance\ndegradation. Specifically, we first implement a significant token reduction\nfrom pretrained visual encoders through a pooling methodology. Then, within LLM\nlayers, we employ a visual-to-visual cross-attention mechanism, wherein the\npooled visual tokens function as queries against the original visual token set.\nThis module enables more efficient token utilization while retaining\nfine-grained informational fidelity. In addition, we introduce a text-to-visual\ncross-attention mechanism, for which the text tokens are enhanced through\ninteraction with the original visual tokens, enriching the visual comprehension\nof the text tokens. Comprehensive empirical evaluation demonstrates that our\napproach achieves comparable or superior performance across diverse video-based\nLMM benchmarks, despite utilizing substantially fewer computational resources.", "AI": {"tldr": "CrossLMM reduces video token complexity in LMMs via dual cross-attention, maintaining performance with fewer resources.", "motivation": "Addressing the computational inefficiency of processing long video sequences in LMMs due to quadratic token costs.", "method": "Uses pooling for token reduction and dual cross-attention (visual-to-visual and text-to-visual) to retain information fidelity.", "result": "Achieves comparable or superior performance on video-based LMM benchmarks with reduced computational resources.", "conclusion": "CrossLMM effectively balances efficiency and performance in multimodal video processing."}}
{"id": "2505.16559", "pdf": "https://arxiv.org/pdf/2505.16559", "abs": "https://arxiv.org/abs/2505.16559", "authors": ["Biao Yi", "Tiansheng Huang", "Baolei Zhang", "Tong Li", "Lihai Nie", "Zheli Liu", "Li Shen"], "title": "CTRAP: Embedding Collapse Trap to Safeguard Large Language Models from Harmful Fine-Tuning", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Fine-tuning-as-a-service, while commercially successful for Large Language\nModel (LLM) providers, exposes models to harmful fine-tuning attacks. As a\nwidely explored defense paradigm against such attacks, unlearning attempts to\nremove malicious knowledge from LLMs, thereby essentially preventing them from\nbeing used to perform malicious tasks. However, we highlight a critical flaw:\nthe powerful general adaptability of LLMs allows them to easily bypass\nselective unlearning by rapidly relearning or repurposing their capabilities\nfor harmful tasks. To address this fundamental limitation, we propose a\nparadigm shift: instead of selective removal, we advocate for inducing model\ncollapse--effectively forcing the model to \"unlearn everything\"--specifically\nin response to updates characteristic of malicious adaptation. This collapse\ndirectly neutralizes the very general capabilities that attackers exploit,\ntackling the core issue unaddressed by selective unlearning. We introduce the\nCollapse Trap (CTRAP) as a practical mechanism to implement this concept\nconditionally. Embedded during alignment, CTRAP pre-configures the model's\nreaction to subsequent fine-tuning dynamics. If updates during fine-tuning\nconstitute a persistent attempt to reverse safety alignment, the pre-configured\ntrap triggers a progressive degradation of the model's core language modeling\nabilities, ultimately rendering it inert and useless for the attacker.\nCrucially, this collapse mechanism remains dormant during benign fine-tuning,\nensuring the model's utility and general capabilities are preserved for\nlegitimate users. Extensive empirical results demonstrate that CTRAP\neffectively counters harmful fine-tuning risks across various LLMs and attack\nsettings, while maintaining high performance in benign scenarios. Our code is\navailable at https://anonymous.4open.science/r/CTRAP.", "AI": {"tldr": "The paper identifies a flaw in selective unlearning for LLMs and proposes model collapse as a defense against harmful fine-tuning attacks, introducing the Collapse Trap (CTRAP) mechanism.", "motivation": "To address the vulnerability of LLMs to harmful fine-tuning attacks, which selective unlearning fails to mitigate due to the models' adaptability.", "method": "Proposes inducing model collapse (via CTRAP) instead of selective unlearning, pre-configuring the model to degrade if malicious updates are detected.", "result": "CTRAP effectively counters harmful fine-tuning while preserving model utility in benign scenarios.", "conclusion": "Model collapse via CTRAP is a robust defense against harmful fine-tuning, addressing the core issue unaddressed by selective unlearning."}}
{"id": "2410.15234", "pdf": "https://arxiv.org/pdf/2410.15234", "abs": "https://arxiv.org/abs/2410.15234", "authors": ["Ze Wang", "Zekun Wu", "Jeremy Zhang", "Xin Guan", "Navya Jain", "Skylar Lu", "Saloni Gupta", "Adriano Koshiyama"], "title": "Bias Amplification: Large Language Models as Increasingly Biased Media", "categories": ["cs.AI"], "comment": "Submitted to ACL ARR May 2025", "summary": "Model collapse, a phenomenon characterized by performance degradation due to\niterative training on synthetic data, has been widely studied. However, its\nimplications for bias amplification, the progressive intensification of\npre-existing societal biases in Large Language Models (LLMs), remain\nsignificantly underexplored, despite the growing influence of LLMs in shaping\nonline discourse. In this paper, we introduce a open, generational, and\nlong-context benchmark specifically designed to measure political bias\namplification in LLMs, leveraging sentence continuation tasks derived from a\ncomprehensive dataset of U.S. political news. Our empirical study using GPT-2\nreveals consistent and substantial political bias intensification (e.g.,\nright-leaning amplification) over iterative synthetic training cycles. We\nevaluate three mitigation strategies, Overfitting, Preservation, and\nAccumulation, and demonstrate that bias amplification persists independently of\nmodel collapse, even when the latter is effectively controlled. Furthermore, we\npropose a mechanistic analysis approach that identifies neurons correlated with\nspecific phenomena during inference through regression and statistical tests.\nThis analysis uncovers largely distinct neuron populations driving bias\namplification and model collapse, underscoring fundamentally different\nunderlying mechanisms. Finally, we supplement our empirical findings with\ntheoretical intuition that explains the separate origins of these phenomena,\nguiding targeted strategies for bias mitigation.", "AI": {"tldr": "The paper explores bias amplification in LLMs due to iterative synthetic training, introducing a benchmark for political bias measurement and revealing persistent bias despite model collapse control.", "motivation": "To address the underexplored implications of model collapse on bias amplification in LLMs, given their growing societal influence.", "method": "Uses a generational benchmark with sentence continuation tasks on U.S. political news, tests mitigation strategies, and employs mechanistic neuron analysis.", "result": "Shows consistent political bias amplification (e.g., right-leaning) and distinct neuron populations driving bias and model collapse.", "conclusion": "Bias amplification and model collapse have different mechanisms, requiring targeted mitigation strategies."}}
{"id": "2505.15847", "pdf": "https://arxiv.org/pdf/2505.15847", "abs": "https://arxiv.org/abs/2505.15847", "authors": ["Bla\u017e Bertalani\u010d", "Matej Vnu\u010dec", "Carolina Fortuna"], "title": "Graph Neural Networks Based Anomalous RSSI Detection", "categories": ["cs.NI", "cs.LG"], "comment": "5 pages, 3 figures", "summary": "In today's world, modern infrastructures are being equipped with information\nand communication technologies to create large IoT networks.\n  It is essential to monitor these networks to ensure smooth operations by\ndetecting and correcting link failures or abnormal network behaviour\nproactively, which can otherwise cause interruptions in business operations.\n  This paper presents a novel method for detecting anomalies in wireless links\nusing graph neural networks. The proposed approach involves converting time\nseries data into graphs and training a new graph neural network architecture\nbased on graph attention networks that successfully detects anomalies at the\nlevel of individual measurements of the time series data. The model provides\ncompetitive results compared to the state of the art while being\ncomputationally more efficient with ~171 times fewer trainable parameters.", "AI": {"tldr": "A novel method using graph neural networks for anomaly detection in wireless IoT networks, achieving competitive results with high computational efficiency.", "motivation": "Modern IoT networks require proactive monitoring to detect and correct link failures or abnormal behavior to prevent business interruptions.", "method": "Converts time series data into graphs and trains a new graph neural network architecture based on graph attention networks for anomaly detection.", "result": "The model detects anomalies at individual measurement levels, is computationally efficient (~171x fewer parameters), and performs competitively against state-of-the-art methods.", "conclusion": "The proposed graph neural network approach effectively detects anomalies in wireless IoT networks with high efficiency and accuracy."}}
{"id": "2505.17021", "pdf": "https://arxiv.org/pdf/2505.17021", "abs": "https://arxiv.org/abs/2505.17021", "authors": ["Sara Ghaboura", "Ketan More", "Wafa Alghallabi", "Omkar Thawakar", "Jorma Laaksonen", "Hisham Cholakkal", "Salman Khan", "Rao Muhammad Anwer"], "title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "categories": ["cs.CV"], "comment": "Github : https://github.com/mbzuai-oryx/ARB, Huggingface:\n  https://huggingface.co/datasets/MBZUAI/ARB", "summary": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "AI": {"tldr": "The paper introduces ARB, the first benchmark for evaluating multimodal reasoning in Arabic, covering 11 domains and 1,356 samples. It highlights challenges in LMMs' coherence, faithfulness, and cultural grounding.", "motivation": "To address the lack of benchmarks for evaluating multimodal reasoning in underrepresented languages like Arabic.", "method": "Developed ARB, a benchmark with 1,356 multimodal samples and 5,119 reasoning steps, evaluated on 12 LMMs.", "result": "Identified persistent challenges in LMMs' reasoning coherence, faithfulness, and cultural grounding.", "conclusion": "ARB provides a framework for inclusive, transparent AI systems and supports future research in underrepresented languages."}}
{"id": "2505.16631", "pdf": "https://arxiv.org/pdf/2505.16631", "abs": "https://arxiv.org/abs/2505.16631", "authors": ["Jonghwi Kim", "Deokhyung Kang", "Seonjeong Hwang", "Yunsu Kim", "Jungseul Ok", "Gary Lee"], "title": "MiLQ: Benchmarking IR Models for Bilingual Web Search with Mixed Language Queries", "categories": ["cs.IR", "cs.CL"], "comment": "16 pages, 9 figures", "summary": "Despite bilingual speakers frequently using mixed-language queries in web\nsearches, Information Retrieval (IR) research on them remains scarce. To\naddress this, we introduce MiLQ,Mixed-Language Query test set, the first public\nbenchmark of mixed-language queries, confirmed as realistic and highly\npreferred. Experiments show that multilingual IR models perform moderately on\nMiLQ and inconsistently across native, English, and mixed-language queries,\nalso suggesting code-switched training data's potential for robust IR models\nhandling such queries. Meanwhile, intentional English mixing in queries proves\nan effective strategy for bilinguals searching English documents, which our\nanalysis attributes to enhanced token matching compared to native queries.", "AI": {"tldr": "MiLQ is the first public benchmark for mixed-language queries, showing multilingual IR models perform moderately but inconsistently. English mixing in queries improves token matching for bilingual searches.", "motivation": "Address the scarcity of IR research on mixed-language queries despite their frequent use by bilingual speakers.", "method": "Introduce MiLQ, a mixed-language query test set, and evaluate multilingual IR models on native, English, and mixed-language queries.", "result": "Multilingual IR models perform moderately on MiLQ but inconsistently across query types. English mixing enhances token matching for bilingual searches.", "conclusion": "MiLQ highlights the need for robust IR models for mixed-language queries, with code-switched training data and English mixing as promising strategies."}}
{"id": "2412.17616", "pdf": "https://arxiv.org/pdf/2412.17616", "abs": "https://arxiv.org/abs/2412.17616", "authors": ["Zixuan Shanggua", "Yanjie Dong", "Song Guo", "Victor C. M. Leung", "M. Jamal Deen", "Xiping Hu"], "title": "Facial Expression Analysis and Its Potentials in IoT Systems: A Contemporary Survey", "categories": ["cs.AI"], "comment": null, "summary": "Facial expressions convey human emotions and can be categorized into\nmacro-expressions (MaEs) and micro-expressions (MiEs) based on duration and\nintensity. While MaEs are voluntary and easily recognized, MiEs are\ninvoluntary, rapid, and can reveal concealed emotions. The integration of\nfacial expression analysis with Internet-of-Thing (IoT) systems has significant\npotential across diverse scenarios. IoT-enhanced MaE analysis enables real-time\nmonitoring of patient emotions, facilitating improved mental health care in\nsmart healthcare. Similarly, IoT-based MiE detection enhances surveillance\naccuracy and threat detection in smart security. Our work aims to provide a\ncomprehensive overview of research progress in facial expression analysis and\nexplores its potential integration with IoT systems. We discuss the\ndistinctions between our work and existing surveys, elaborate on advancements\nin MaE and MiE analysis techniques across various learning paradigms, and\nexamine their potential applications in IoT. We highlight challenges and future\ndirections for the convergence of facial expression-based technologies and IoT\nsystems, aiming to foster innovation in this domain. By presenting recent\ndevelopments and practical applications, our work offers a systematic\nunderstanding of the ways of facial expression analysis to enhance IoT systems\nin healthcare, security, and beyond.", "AI": {"tldr": "The paper reviews facial expression analysis (macro- and micro-expressions) and its integration with IoT systems, highlighting applications in healthcare and security, and discussing challenges and future directions.", "motivation": "To explore the potential of combining facial expression analysis with IoT for improved mental health care and security, and to provide a comprehensive overview of advancements in this field.", "method": "The work reviews existing research, distinguishes itself from prior surveys, and examines advancements in MaE and MiE analysis techniques across learning paradigms.", "result": "Identifies practical applications in IoT-enhanced healthcare and security, and outlines challenges and future directions for the field.", "conclusion": "The paper systematically presents how facial expression analysis can enhance IoT systems, fostering innovation in healthcare, security, and other domains."}}
{"id": "2505.15866", "pdf": "https://arxiv.org/pdf/2505.15866", "abs": "https://arxiv.org/abs/2505.15866", "authors": ["Stephen Asiedu", "David Watson"], "title": "Multi-omic Causal Discovery using Genotypes and Gene Expression", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Causal discovery in multi-omic datasets is crucial for understanding the\nbigger picture of gene regulatory mechanisms, but remains challenging due to\nhigh dimensionality, differentiation of direct from indirect relationships, and\nhidden confounders. We introduce GENESIS (GEne Network inference from\nExpression SIgnals and SNPs), a constraint-based algorithm that leverages the\nnatural causal precedence of genotypes to infer ancestral relationships in\ntranscriptomic data. Unlike traditional causal discovery methods that start\nwith a fully connected graph, GENESIS initialises an empty ancestrality matrix\nand iteratively populates it with direct, indirect or non-causal relationships\nusing a series of provably sound marginal and conditional independence tests.\nBy integrating genotypes as fixed causal anchors, GENESIS provides a principled\n``head start'' to classical causal discovery algorithms, restricting the search\nspace to biologically plausible edges. We test GENESIS on synthetic and\nreal-world genomic datasets. This framework offers a powerful avenue for\nuncovering causal pathways in complex traits, with promising applications to\nfunctional genomics, drug discovery, and precision medicine.", "AI": {"tldr": "GENESIS is a constraint-based algorithm for causal discovery in multi-omic data, using genotypes as causal anchors to infer gene regulatory relationships.", "motivation": "Understanding gene regulatory mechanisms is challenging due to high dimensionality and hidden confounders in multi-omic datasets.", "method": "GENESIS initializes an empty ancestrality matrix and iteratively populates it using marginal and conditional independence tests, leveraging genotypes as fixed causal anchors.", "result": "GENESIS effectively infers causal relationships in synthetic and real-world genomic datasets.", "conclusion": "GENESIS provides a principled approach for uncovering causal pathways, with applications in functional genomics, drug discovery, and precision medicine."}}
{"id": "2505.15725", "pdf": "https://arxiv.org/pdf/2505.15725", "abs": "https://arxiv.org/abs/2505.15725", "authors": ["Xiangyu Wang", "Donglin Yang", "Yue Liao", "Wenhao Zheng", "wenjun wu", "Bin Dai", "Hongsheng Li", "Si Liu"], "title": "UAV-Flow Colosseo: A Real-World Benchmark for Flying-on-a-Word UAV Imitation Learning", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Unmanned Aerial Vehicles (UAVs) are evolving into language-interactive\nplatforms, enabling more intuitive forms of human-drone interaction. While\nprior works have primarily focused on high-level planning and long-horizon\nnavigation, we shift attention to language-guided fine-grained trajectory\ncontrol, where UAVs execute short-range, reactive flight behaviors in response\nto language instructions. We formalize this problem as the Flying-on-a-Word\n(Flow) task and introduce UAV imitation learning as an effective approach. In\nthis framework, UAVs learn fine-grained control policies by mimicking expert\npilot trajectories paired with atomic language instructions. To support this\nparadigm, we present UAV-Flow, the first real-world benchmark for\nlanguage-conditioned, fine-grained UAV control. It includes a task formulation,\na large-scale dataset collected in diverse environments, a deployable control\nframework, and a simulation suite for systematic evaluation. Our design enables\nUAVs to closely imitate the precise, expert-level flight trajectories of human\npilots and supports direct deployment without sim-to-real gap. We conduct\nextensive experiments on UAV-Flow, benchmarking VLN and VLA paradigms. Results\nshow that VLA models are superior to VLN baselines and highlight the critical\nrole of spatial grounding in the fine-grained Flow setting.", "AI": {"tldr": "The paper introduces the Flying-on-a-Word (Flow) task for UAVs, focusing on language-guided fine-grained trajectory control using imitation learning. It presents UAV-Flow, a real-world benchmark, and shows VLA models outperform VLN baselines.", "motivation": "To enable UAVs to execute precise, reactive flight behaviors in response to language instructions, addressing a gap in fine-grained control.", "method": "UAV imitation learning is used, where UAVs mimic expert pilot trajectories paired with atomic language instructions. UAV-Flow provides a dataset, control framework, and simulation suite.", "result": "VLA models outperform VLN baselines, demonstrating the importance of spatial grounding in fine-grained UAV control.", "conclusion": "The UAV-Flow framework successfully enables UAVs to imitate expert-level flight trajectories and supports direct deployment without sim-to-real gaps."}}
{"id": "2502.00691", "pdf": "https://arxiv.org/pdf/2502.00691", "abs": "https://arxiv.org/abs/2502.00691", "authors": ["Haozhe Wang", "Long Li", "Chao Qu", "Fengming Zhu", "Weidi Xu", "Wei Chu", "Fangzhen Lin"], "title": "To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted to ACL 2025", "summary": "Recent advances in mathematical problem-solving with language models (LMs)\nintegrate chain-of-thought (CoT) reasoning and code execution to harness their\ncomplementary strengths. However, existing hybrid frameworks exhibit a critical\nlimitation: they depend on externally dictated instructions or rigid\ncode-integration templates, lacking metacognitive awareness -- the capacity to\ndynamically evaluate intrinsic capabilities and autonomously determine when and\nhow to integrate tools. This rigidity motivates our study of autonomous code\nintegration, enabling models to adapt tool-usage strategies as their reasoning\nabilities evolve during training.\n  While reinforcement learning (RL) shows promise for boosting LLM reasoning at\nscale (e.g., DeepSeek-R1), we demonstrate its inefficiency in learning\nautonomous code integration due to inadequate exploration of the vast\ncombinatorial space of CoT-code interleaving patterns. To address this\nchallenge, we propose a novel Expectation-Maximization (EM) framework that\nsynergizes structured exploration (E-step) with off-policy RL optimization\n(M-step), creating a self-reinforcing cycle between metacognitive tool-use\ndecisions and evolving capabilities. Experiments reveal our method achieves\nsuperior results through improved exploration. Notably, our 7B model improves\nover 11% on MATH500 and 9.4% on AIME without o1-like CoT.", "AI": {"tldr": "The paper introduces an Expectation-Maximization (EM) framework to improve autonomous code integration in language models, addressing inefficiencies in reinforcement learning for this task.", "motivation": "Existing hybrid frameworks for mathematical problem-solving lack metacognitive awareness, relying on rigid instructions or templates. This limits dynamic adaptation of tool-usage strategies.", "method": "Proposes an EM framework combining structured exploration (E-step) with off-policy RL optimization (M-step) to enhance autonomous code integration.", "result": "The method achieves significant improvements: 11% on MATH500 and 9.4% on AIME, outperforming existing approaches.", "conclusion": "The EM framework effectively addresses exploration challenges in autonomous code integration, leading to superior performance in mathematical problem-solving."}}
{"id": "2505.15927", "pdf": "https://arxiv.org/pdf/2505.15927", "abs": "https://arxiv.org/abs/2505.15927", "authors": ["Awni Altabaa", "Omar Montasser", "John Lafferty"], "title": "CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Learning complex functions that involve multi-step reasoning poses a\nsignificant challenge for standard supervised learning from input-output\nexamples. Chain-of-thought (CoT) supervision, which provides intermediate\nreasoning steps together with the final output, has emerged as a powerful\nempirical technique, underpinning much of the recent progress in the reasoning\ncapabilities of large language models. This paper develops a statistical theory\nof learning under CoT supervision. A key characteristic of the CoT setting, in\ncontrast to standard supervision, is the mismatch between the training\nobjective (CoT risk) and the test objective (end-to-end risk). A central part\nof our analysis, distinguished from prior work, is explicitly linking those two\ntypes of risk to achieve sharper sample complexity bounds. This is achieved via\nthe *CoT information measure* $\\mathcal{I}_{\\mathcal{D},\nh_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, which quantifies the additional\ndiscriminative power gained from observing the reasoning process. The main\ntheoretical results demonstrate how CoT supervision can yield significantly\nfaster learning rates compared to standard E2E supervision. Specifically, it is\nshown that the sample complexity required to achieve a target E2E error\n$\\epsilon$ scales as $d/\\mathcal{I}_{\\mathcal{D},\nh_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, where $d$ is a measure of hypothesis\nclass complexity, which can be much faster than standard $d/\\epsilon$ rates.\nInformation-theoretic lower bounds in terms of the CoT information are also\nobtained. Together, these results suggest that CoT information is a fundamental\nmeasure of statistical complexity for learning under chain-of-thought\nsupervision.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.16975", "pdf": "https://arxiv.org/pdf/2505.16975", "abs": "https://arxiv.org/abs/2505.16975", "authors": ["Yaxin Du", "Yuzhu Cai", "Yifan Zhou", "Cheng Wang", "Yu Qian", "Xianghe Pang", "Qian Liu", "Yue Hu", "Siheng Chen"], "title": "SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown strong capability in diverse software\nengineering tasks, e.g. code completion, bug fixing, and document generation.\nHowever, feature-driven development (FDD), a highly prevalent real-world task\nthat involves developing new functionalities for large, existing codebases,\nremains underexplored. We therefore introduce SWE-Dev, the first large-scale\ndataset (with 14,000 training and 500 test samples) designed to evaluate and\ntrain autonomous coding systems on real-world feature development tasks. To\nensure verifiable and diverse training, SWE-Dev uniquely provides all instances\nwith a runnable environment and its developer-authored executable unit tests.\nThis collection not only provides high-quality data for Supervised Fine-Tuning\n(SFT), but also enables Reinforcement Learning (RL) by delivering accurate\nreward signals from executable unit tests. Our extensive evaluations on\nSWE-Dev, covering 17 chatbot LLMs, 10 reasoning models, and 10 Multi-Agent\nSystems (MAS), reveal that FDD is a profoundly challenging frontier for current\nAI (e.g., Claude-3.7-Sonnet achieves only 22.45\\% Pass@3 on the hard test\nsplit). Crucially, we demonstrate that SWE-Dev serves as an effective platform\nfor model improvement: fine-tuning on training set enabled a 7B model\ncomparable to GPT-4o on \\textit{hard} split, underscoring the value of its\nhigh-quality training data. Code is available here\n\\href{https://github.com/justLittleWhite/SWE-Dev}{https://github.com/justLittleWhite/SWE-Dev}.", "AI": {"tldr": "SWE-Dev is a large-scale dataset for evaluating and training autonomous coding systems on real-world feature development tasks, addressing a gap in LLM capabilities.", "motivation": "Feature-driven development (FDD) in large codebases is underexplored despite LLMs' success in other software engineering tasks.", "method": "SWE-Dev provides 14,000 training and 500 test samples with runnable environments and executable unit tests for SFT and RL.", "result": "Current AI struggles with FDD (e.g., Claude-3.7-Sonnet achieves 22.45% Pass@3). Fine-tuning on SWE-Dev improved a 7B model to GPT-4o level on hard tasks.", "conclusion": "SWE-Dev is a valuable platform for advancing AI in feature development, demonstrating the impact of high-quality training data."}}
{"id": "2502.10477", "pdf": "https://arxiv.org/pdf/2502.10477", "abs": "https://arxiv.org/abs/2502.10477", "authors": ["Kumar Manas", "Adrian Paschke"], "title": "Knowledge Integration Strategies in Autonomous Vehicle Prediction and Planning: A Comprehensive Survey", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted for publication in Proceedings of the IEEE Intelligent\n  Vehicles Symposium (IV), Cluj-Napoca - Romania, 22-25 June 2025", "summary": "This comprehensive survey examines the integration of knowledge-based\napproaches in autonomous driving systems, specifically focusing on trajectory\nprediction and planning. We extensively analyze various methodologies for\nincorporating domain knowledge, traffic rules, and commonsense reasoning into\nautonomous driving systems. The survey categorizes and analyzes approaches\nbased on their knowledge representation and integration methods, ranging from\npurely symbolic to hybrid neuro-symbolic architectures. We examine recent\ndevelopments in logic programming, foundation models for knowledge\nrepresentation, reinforcement learning frameworks, and other emerging\ntechnologies incorporating domain knowledge. This work systematically reviews\nrecent approaches, identifying key challenges, opportunities, and future\nresearch directions in knowledge-enhanced autonomous driving systems. Our\nanalysis reveals emerging trends in the field, including the increasing\nimportance of interpretable AI, the role of formal verification in\nsafety-critical systems, and the potential of hybrid approaches that combine\ntraditional knowledge representation with modern machine learning techniques.", "AI": {"tldr": "A survey on integrating knowledge-based approaches in autonomous driving, focusing on trajectory prediction and planning, analyzing methodologies, challenges, and future directions.", "motivation": "To explore how domain knowledge, traffic rules, and commonsense reasoning can enhance autonomous driving systems.", "method": "Categorizes and analyzes approaches by knowledge representation (symbolic to hybrid neuro-symbolic), including logic programming, foundation models, and reinforcement learning.", "result": "Identifies trends like interpretable AI, formal verification, and hybrid methods combining knowledge representation with machine learning.", "conclusion": "Highlights challenges and opportunities for future research in knowledge-enhanced autonomous driving."}}
{"id": "2505.15958", "pdf": "https://arxiv.org/pdf/2505.15958", "abs": "https://arxiv.org/abs/2505.15958", "authors": ["Ahmed Bouajjani", "Wael-Amine Boutglay", "Peter Habermehl"], "title": "Data-driven Verification of Procedural Programs with Integer Arrays", "categories": ["cs.PL", "cs.LG"], "comment": null, "summary": "We address the problem of verifying automatically procedural programs\nmanipulating parametric-size arrays of integers, encoded as a constrained Horn\nclauses solving problem. We propose a new algorithmic method for synthesizing\nloop invariants and procedure pre/post-conditions represented as universally\nquantified first-order formulas constraining the array elements and program\nvariables. We adopt a data-driven approach that extends the decision tree\nHorn-ICE framework to handle arrays. We provide a powerful learning technique\nbased on reducing a complex classification problem of vectors of integer arrays\nto a simpler classification problem of vectors of integers. The obtained\nclassifier is generalized to get universally quantified invariants and\nprocedure pre/post-conditions. We have implemented our method and shown its\nefficiency and competitiveness w.r.t. state-of-the-art tools on a significant\nbenchmark.", "AI": {"tldr": "A method for synthesizing loop invariants and procedure pre/post-conditions for programs with arrays, using a data-driven approach and decision tree Horn-ICE framework.", "motivation": "To automate verification of procedural programs with parametric-size arrays by solving constrained Horn clauses.", "method": "Extends decision tree Horn-ICE framework to handle arrays, reducing complex classification of integer arrays to simpler integer vectors.", "result": "Efficient and competitive implementation demonstrated on benchmarks.", "conclusion": "The approach successfully synthesizes universally quantified invariants and pre/post-conditions for array-manipulating programs."}}
{"id": "2310.08232", "pdf": "https://arxiv.org/pdf/2310.08232", "abs": "https://arxiv.org/abs/2310.08232", "authors": ["Xin Zhang", "Zehan Li", "Yanzhao Zhang", "Dingkun Long", "Pengjun Xie", "Meishan Zhang", "Min Zhang"], "title": "Language Models are Universal Embedders", "categories": ["cs.CL"], "comment": "XLLM Workshop, ACL 2025", "summary": "In the large language model (LLM) revolution, embedding is a key component of\nvarious systems, such as retrieving knowledge or memories for LLMs or building\ncontent moderation filters. As such cases span from English to other natural or\nprogramming languages, from retrieval to classification and beyond, it is\nadvantageous to build a unified embedding model rather than dedicated ones for\neach scenario. In this context, the pre-trained multilingual decoder-only large\nlanguage models, e.g., BLOOM, emerge as a viable backbone option. To assess\ntheir potential, we propose straightforward strategies for constructing\nembedders and introduce a universal evaluation benchmark. Experimental results\nshow that our trained model is proficient at generating good embeddings across\nlanguages and tasks, even extending to languages and tasks for which no\nfinetuning/pretraining data is available. We also present detailed analyses and\nadditional evaluations. We hope that this work could encourage the development\nof more robust open-source universal embedders.", "AI": {"tldr": "The paper proposes using pre-trained multilingual LLMs like BLOOM to create unified embedding models for diverse tasks and languages, demonstrating their effectiveness even without task-specific data.", "motivation": "To address the need for versatile embedding models across languages and tasks, avoiding the inefficiency of dedicated models for each scenario.", "method": "Proposes straightforward strategies for constructing embedders using pre-trained multilingual LLMs and introduces a universal evaluation benchmark.", "result": "The trained model performs well across languages and tasks, including those without finetuning/pretraining data.", "conclusion": "Encourages development of robust open-source universal embedders, highlighting the potential of multilingual LLMs for unified embeddings."}}
{"id": "2502.12532", "pdf": "https://arxiv.org/pdf/2502.12532", "abs": "https://arxiv.org/abs/2502.12532", "authors": ["Yong Zhao", "Kai Xu", "Zhengqiu Zhu", "Yue Hu", "Zhiheng Zheng", "Yingfeng Chen", "Yatai Ji", "Chen Gao", "Yong Li", "Jincai Huang"], "title": "CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space", "categories": ["cs.AI"], "comment": null, "summary": "Embodied Question Answering (EQA) has primarily focused on indoor\nenvironments, leaving the complexities of urban settings-spanning environment,\naction, and perception-largely unexplored. To bridge this gap, we introduce\nCityEQA, a new task where an embodied agent answers open-vocabulary questions\nthrough active exploration in dynamic city spaces. To support this task, we\npresent CityEQA-EC, the first benchmark dataset featuring 1,412 human-annotated\ntasks across six categories, grounded in a realistic 3D urban simulator.\nMoreover, we propose Planner-Manager-Actor (PMA), a novel agent tailored for\nCityEQA. PMA enables long-horizon planning and hierarchical task execution: the\nPlanner breaks down the question answering into sub-tasks, the Manager\nmaintains an object-centric cognitive map for spatial reasoning during the\nprocess control, and the specialized Actors handle navigation, exploration, and\ncollection sub-tasks. Experiments demonstrate that PMA achieves 60.7% of\nhuman-level answering accuracy, significantly outperforming competitive\nbaselines. While promising, the performance gap compared to humans highlights\nthe need for enhanced visual reasoning in CityEQA. This work paves the way for\nfuture advancements in urban spatial intelligence. Dataset and code are\navailable at https://github.com/BiluYong/CityEQA.git.", "AI": {"tldr": "CityEQA introduces a new task for embodied question answering in urban settings, supported by a benchmark dataset and a novel agent (PMA) that outperforms baselines but still lags behind human performance.", "motivation": "To address the unexplored complexities of urban environments in embodied question answering, bridging the gap between indoor and outdoor settings.", "method": "Introduces CityEQA-EC dataset and PMA agent, which uses hierarchical task execution (Planner-Manager-Actor) for long-horizon planning and spatial reasoning.", "result": "PMA achieves 60.7% human-level accuracy, outperforming baselines but showing room for improvement in visual reasoning.", "conclusion": "This work advances urban spatial intelligence, with the dataset and code publicly available for future research."}}
{"id": "2505.15974", "pdf": "https://arxiv.org/pdf/2505.15974", "abs": "https://arxiv.org/abs/2505.15974", "authors": ["Alan Ta", "Nilsu Salgin", "Mustafa Demir", "Kala Philips Randal", "Ranjana K. Mehta", "Anthony McDonald", "Carly McCord", "Farzan Sasangohar"], "title": "Real-Time Stress Monitoring, Detection, and Management in College Students: A Wearable Technology and Machine-Learning Approach", "categories": ["cs.HC", "cs.LG"], "comment": "31 pages, 5 figures", "summary": "College students are increasingly affected by stress, anxiety, and\ndepression, yet face barriers to traditional mental health care. This study\nevaluated the efficacy of a mobile health (mHealth) intervention, Mental Health\nEvaluation and Lookout Program (mHELP), which integrates a smartwatch sensor\nand machine learning (ML) algorithms for real-time stress detection and\nself-management. In a 12-week randomized controlled trial (n = 117),\nparticipants were assigned to a treatment group using mHELP's full suite of\ninterventions or a control group using the app solely for real-time stress\nlogging and weekly psychological assessments. The primary outcome, \"Moments of\nStress\" (MS), was assessed via physiological and self-reported indicators and\nanalyzed using Generalized Linear Mixed Models (GLMM) approaches. Similarly,\nsecondary outcomes of psychological assessments, including the Generalized\nAnxiety Disorder-7 (GAD-7) for anxiety, the Patient Health Questionnaire\n(PHQ-8) for depression, and the Perceived Stress Scale (PSS), were also\nanalyzed via GLMM. The finding of the objective measure, MS, indicates a\nsubstantial decrease in MS among the treatment group compared to the control\ngroup, while no notable between-group differences were observed in subjective\nscores of anxiety (GAD-7), depression (PHQ-8), or stress (PSS). However, the\ntreatment group exhibited a clinically meaningful decline in GAD-7 and PSS\nscores. These findings underscore the potential of wearable-enabled mHealth\ntools to reduce acute stress in college populations and highlight the need for\nextended interventions and tailored features to address chronic symptoms like\ndepression.", "AI": {"tldr": "A mobile health (mHealth) intervention, mHELP, using smartwatch sensors and ML, reduced acute stress in college students but showed no significant impact on anxiety or depression scores.", "motivation": "College students face mental health challenges but encounter barriers to traditional care, prompting the need for accessible solutions like mHealth tools.", "method": "A 12-week RCT compared mHELP's full intervention (real-time stress detection and self-management) with a control group (stress logging and weekly assessments). Outcomes were analyzed using GLMM.", "result": "The treatment group showed a significant decrease in acute stress (MS) but no notable differences in anxiety (GAD-7), depression (PHQ-8), or stress (PSS) scores. However, clinically meaningful declines in GAD-7 and PSS were observed.", "conclusion": "Wearable-enabled mHealth tools can reduce acute stress but require extended interventions for chronic symptoms like depression."}}
{"id": "2505.16487", "pdf": "https://arxiv.org/pdf/2505.16487", "abs": "https://arxiv.org/abs/2505.16487", "authors": ["Junqing Chen", "Haibo Liu"], "title": "Implicit Neural Shape Optimization for 3D High-Contrast Electrical Impedance Tomography", "categories": ["math.NA", "cs.CV", "cs.NA"], "comment": null, "summary": "We present a novel implicit neural shape optimization framework for 3D\nhigh-contrast Electrical Impedance Tomography (EIT), addressing scenarios where\nconductivity exhibits sharp discontinuities across material interfaces. These\nhigh-contrast cases, prevalent in metallic implant monitoring and industrial\ndefect detection, challenge traditional reconstruction methods due to severe\nill-posedness. Our approach synergizes shape optimization with implicit neural\nrepresentations, introducing key innovations including a shape derivative-based\noptimization scheme that explicitly incorporates high-contrast interface\nconditions and an efficient latent space representation that reduces variable\ndimensionality. Through rigorous theoretical analysis of algorithm convergence\nand extensive numerical experiments, we demonstrate substantial performance\nimprovements, establishing our framework as promising for practical\napplications in medical imaging with metallic implants and industrial\nnon-destructive testing.", "AI": {"tldr": "A novel neural shape optimization framework improves 3D EIT for high-contrast scenarios, outperforming traditional methods.", "motivation": "High-contrast EIT cases (e.g., metallic implants, industrial defects) challenge traditional methods due to severe ill-posedness.", "method": "Combines shape optimization with implicit neural representations, using shape derivatives and latent space to reduce dimensionality.", "result": "Demonstrates significant performance improvements through theory and experiments.", "conclusion": "The framework is promising for medical imaging and industrial non-destructive testing."}}
{"id": "2312.13772", "pdf": "https://arxiv.org/pdf/2312.13772", "abs": "https://arxiv.org/abs/2312.13772", "authors": ["Chengzu Li", "Han Zhou", "Goran Glava\u0161", "Anna Korhonen", "Ivan Vuli\u0107"], "title": "Large Language Models are Miscalibrated In-Context Learners", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "9 pages, 4 figures, 5 tables (20 pages, 5 figures, 13 tables\n  including references and appendices)", "summary": "When adapting ICL with or without fine-tuning, we are curious about whether\nthe instruction-tuned language model is able to achieve well-calibrated results\nwithout suffering from the problem of overconfidence (i.e., miscalibration)\nconsidering its strong instruction following ability, especially in such\nlimited data setups. In this work, we deliver an in-depth analysis of the\nbehavior across different choices of learning methods from the perspective of\nboth performance and calibration. Through extensive controlled experiments, we\nobserve that the miscalibration problem exists across all learning methods in\nlow-resource setups. To achieve simultaneous gain for both in-task performance\nand calibration, we then study the potential of self-ensembling applied at\ndifferent modeling stages (e.g., variations of in-context examples or\nvariations in prompts or different ensembling strategies) to make the\npredictions more calibrated and have comparable or even better performance. We\nfind that self-ensembling with max probability produces robust and calibrated\npredictions. Our work reveals the potential calibration problem of using ICL\ndespite the improvements in task performance and sheds light on which learning\nparadigm to choose. We also provide practical guidelines for choosing learning\nparadigms depending on whether the data has been seen by the model before and a\nworthwhile solution via self-ensembling on how to enhance both task performance\nand calibration of LMs, which we hope could encourage further study.", "AI": {"tldr": "The paper investigates whether instruction-tuned language models (LMs) achieve well-calibrated results in low-resource setups without overconfidence. It analyzes performance and calibration across learning methods, identifies miscalibration issues, and proposes self-ensembling as a solution.", "motivation": "To understand if instruction-tuned LMs avoid overconfidence (miscalibration) in limited data scenarios, given their strong instruction-following ability.", "method": "Conducts controlled experiments to evaluate performance and calibration across learning methods, then explores self-ensembling (e.g., varying prompts or examples) to improve both.", "result": "Miscalibration exists in low-resource setups for all methods. Self-ensembling, especially with max probability, enhances calibration and performance.", "conclusion": "The study highlights calibration issues in ICL despite task performance gains, recommends learning paradigms based on data familiarity, and suggests self-ensembling as a practical solution."}}
{"id": "2502.16101", "pdf": "https://arxiv.org/pdf/2502.16101", "abs": "https://arxiv.org/abs/2502.16101", "authors": ["Linda Zeng", "Rithwik Gupta", "Divij Motwani", "Diji Yang", "Yi Zhang"], "title": "Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the Robustness of RAG Against Misleading Retrievals", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Retrieval-augmented generation (RAG) has shown impressive capabilities in\nmitigating hallucinations in large language models (LLMs). However, LLMs\nstruggle to handle misleading retrievals and often fail to maintain their own\nreasoning when exposed to conflicting or selectively-framed evidence, making\nthem vulnerable to real-world misinformation. In such real-world retrieval\nscenarios, misleading and conflicting information is rampant, particularly in\nthe political domain, where evidence is often selectively framed, incomplete,\nor polarized. However, existing RAG benchmarks largely assume a clean retrieval\nsetting, where models succeed by accurately retrieving and generating answers\nfrom gold-standard documents. This assumption fails to align with real-world\nconditions, leading to an overestimation of RAG system performance. To bridge\nthis gap, we introduce RAGuard, a fact-checking dataset designed to evaluate\nthe robustness of RAG systems against misleading retrievals. Unlike prior\nbenchmarks that rely on synthetic noise, our dataset constructs its retrieval\ncorpus from Reddit discussions, capturing naturally occurring misinformation.\nIt categorizes retrieved evidence into three types: supporting, misleading, and\nirrelevant, providing a realistic and challenging testbed for assessing how\nwell RAG systems navigate different retrieval information. Our benchmark\nexperiments reveal that when exposed to misleading retrievals, all tested\nLLM-powered RAG systems perform worse than their zero-shot baselines (i.e., no\nretrieval at all), highlighting their susceptibility to noisy environments. To\nthe best of our knowledge, RAGuard is the first benchmark to systematically\nassess RAG robustness against misleading evidence. We expect this benchmark\nwill drive future research toward improving RAG systems beyond idealized\ndatasets, making them more reliable for real-world applications.", "AI": {"tldr": "RAGuard is a new benchmark evaluating RAG systems' robustness against misleading retrievals, revealing their vulnerability to noisy real-world data.", "motivation": "Existing RAG benchmarks assume clean retrieval settings, misaligning with real-world misinformation, especially in political domains.", "method": "RAGuard uses Reddit discussions to create a dataset with supporting, misleading, and irrelevant evidence, testing RAG systems' performance.", "result": "RAG systems perform worse with misleading retrievals than zero-shot baselines, showing susceptibility to noise.", "conclusion": "RAGuard highlights the need for more robust RAG systems, driving research beyond idealized datasets."}}
{"id": "2505.16041", "pdf": "https://arxiv.org/pdf/2505.16041", "abs": "https://arxiv.org/abs/2505.16041", "authors": ["Siddhant Agarwal", "Ali Can Bekar", "Christian H\u00fcttig", "David S. Greenberg", "Nicola Tosi"], "title": "Physics-based machine learning for mantle convection simulations", "categories": ["astro-ph.EP", "cs.LG"], "comment": null, "summary": "Mantle convection simulations are an essential tool for understanding how\nrocky planets evolve. However, the poorly known input parameters to these\nsimulations, the non-linear dependence of transport properties on pressure and\ntemperature, and the long integration times in excess of several billion years\nall pose a computational challenge for numerical solvers. We propose a\nphysics-based machine learning approach that predicts creeping flow velocities\nas a function of temperature while conserving mass, thereby bypassing the\nnumerical solution of the Stokes problem. A finite-volume solver then uses the\npredicted velocities to advect and diffuse the temperature field to the next\ntime-step, enabling autoregressive rollout at inference. For training, our\nmodel requires temperature-velocity snapshots from a handful of simulations\n(94). We consider mantle convection in a two-dimensional rectangular box with\nbasal and internal heating, pressure- and temperature-dependent viscosity.\nOverall, our model is up to 89 times faster than the numerical solver. We also\nshow the importance of different components in our convolutional neural network\narchitecture such as mass conservation, learned paddings on the boundaries, and\nloss scaling for the overall rollout performance. Finally, we test our approach\non unseen scenarios to demonstrate some of its strengths and weaknesses.", "AI": {"tldr": "A physics-based machine learning approach accelerates mantle convection simulations by predicting flow velocities from temperature, bypassing traditional numerical solvers, achieving up to 89x speedup.", "motivation": "Mantle convection simulations face computational challenges due to unknown input parameters, non-linear dependencies, and long integration times.", "method": "A convolutional neural network predicts velocities from temperature while conserving mass, enabling autoregressive rollout with a finite-volume solver for temperature advection and diffusion.", "result": "The model is up to 89 times faster than traditional numerical solvers and demonstrates the importance of components like mass conservation and learned paddings.", "conclusion": "The approach shows promise for accelerating mantle convection simulations but has limitations in unseen scenarios."}}
{"id": "2505.16517", "pdf": "https://arxiv.org/pdf/2505.16517", "abs": "https://arxiv.org/abs/2505.16517", "authors": ["Zirui Song", "Guangxian Ouyang", "Mingzhe Li", "Yuheng Ji", "Chenxi Wang", "Zixiang Xu", "Zeyu Zhang", "Xiaoqing Zhang", "Qian Jiang", "Zhenhao Chen", "Zhongzhi Li", "Rui Yan", "Xiuying Chen"], "title": "ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models", "categories": ["cs.RO", "cs.CV"], "comment": "13pages", "summary": "Large Vision-Language Models (LVLMs) have recently advanced robotic\nmanipulation by leveraging vision for scene perception and language for\ninstruction following. However, existing methods rely heavily on costly\nhuman-annotated training datasets, which limits their generalization and causes\nthem to struggle in out-of-domain (OOD) scenarios, reducing real-world\nadaptability. To address these challenges, we propose ManipLVM-R1, a novel\nreinforcement learning framework that replaces traditional supervision with\nReinforcement Learning using Verifiable Rewards (RLVR). By directly optimizing\nfor task-aligned outcomes, our method enhances generalization and physical\nreasoning while removing the dependence on costly annotations. Specifically, we\ndesign two rule-based reward functions targeting key robotic manipulation\nsubtasks: an Affordance Perception Reward to enhance localization of\ninteraction regions, and a Trajectory Match Reward to ensure the physical\nplausibility of action paths. These rewards provide immediate feedback and\nimpose spatial-logical constraints, encouraging the model to go beyond shallow\npattern matching and instead learn deeper, more systematic reasoning about\nphysical interactions.", "AI": {"tldr": "ManipLVM-R1 introduces RLVR to replace costly human annotations in LVLMs, improving generalization and real-world adaptability for robotic manipulation.", "motivation": "Existing LVLMs rely on expensive human-annotated datasets, limiting generalization and performance in OOD scenarios.", "method": "Proposes ManipLVM-R1, using RLVR with rule-based rewards (Affordance Perception and Trajectory Match) for task-aligned optimization.", "result": "Enhances generalization, physical reasoning, and reduces dependency on annotations.", "conclusion": "ManipLVM-R1 offers a scalable, annotation-free approach for robust robotic manipulation."}}
{"id": "2402.06738", "pdf": "https://arxiv.org/pdf/2402.06738", "abs": "https://arxiv.org/abs/2402.06738", "authors": ["Yifan Ding", "Amrit Poudel", "Qingkai Zeng", "Tim Weninger", "Balaji Veeramani", "Sanmitra Bhattacharya"], "title": "EntGPT: Entity Linking with Generative Large Language Models", "categories": ["cs.CL", "H.3.3"], "comment": null, "summary": "Entity Linking in natural language processing seeks to match text entities to\ntheir corresponding entries in a dictionary or knowledge base. Traditional\napproaches rely on contextual models, which can be complex, hard to train, and\nhave limited transferability across different domains. Generative large\nlanguage models like GPT offer a promising alternative but often underperform\nwith naive prompts. In this study, we introduce EntGPT, employing advanced\nprompt engineering to enhance EL tasks. Our three-step hard-prompting method\n(EntGPT-P) significantly boosts the micro-F_1 score by up to 36% over vanilla\nprompts, achieving competitive performance across 10 datasets without\nsupervised fine-tuning. Additionally, our instruction tuning method (EntGPT-I)\nimproves micro-F_1 scores by 2.1% on average in supervised EL tasks and\noutperforms several baseline models in six Question Answering tasks. Our\nmethods are compatible with both open-source and proprietary LLMs. All data and\ncode are available on GitHub at https://github.com/yifding/In_Context_EL.", "AI": {"tldr": "EntGPT improves entity linking (EL) tasks using advanced prompt engineering, outperforming traditional methods and naive prompts with significant performance boosts.", "motivation": "Traditional EL methods are complex, hard to train, and lack transferability. Generative LLMs like GPT underperform with naive prompts, prompting the need for better approaches.", "method": "Introduces EntGPT with two methods: hard-prompting (EntGPT-P) and instruction tuning (EntGPT-I). EntGPT-P uses a three-step hard-prompting technique, while EntGPT-I involves supervised fine-tuning.", "result": "EntGPT-P boosts micro-F_1 scores by up to 36% over vanilla prompts. EntGPT-I improves scores by 2.1% on average in supervised tasks and outperforms baselines in QA tasks.", "conclusion": "EntGPT offers a scalable and effective solution for EL tasks, compatible with various LLMs, with open-source code and data available."}}
{"id": "2502.19918", "pdf": "https://arxiv.org/pdf/2502.19918", "abs": "https://arxiv.org/abs/2502.19918", "authors": ["Yuan Sui", "Yufei He", "Tri Cao", "Simeng Han", "Yulin Chen", "Bryan Hooi"], "title": "Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) increasingly rely on prolonged reasoning chains\nto solve complex tasks. However, this trial-and-error approach often leads to\nhigh computational overhead and error propagation, where early mistakes can\nderail subsequent steps. To address these issues, we introduce Meta-Reasoner, a\nframework that dynamically optimizes inference-time reasoning by enabling LLMs\nto \\enquote{think about how to think.} Drawing inspiration from human\nmeta-cognition and dual-process theory, Meta-Reasoner operates as a strategic\nadvisor, decoupling high-level guidance from step-by-step generation. It\nemploys contextual multi-armed bandits to iteratively evaluate reasoning\nprogress and select optimal strategies (e.g., backtrack, clarify ambiguity,\nrestart from scratch, or propose alternative approaches), and reallocates\ncomputational resources toward the most promising paths. Our evaluations on\nmathematical reasoning and puzzles highlight the potential of dynamic reasoning\nchains to overcome inherent challenges in the LLM reasoning process and also\nshow promise in broader applications, offering a scalable and adaptable\nsolution for reasoning-intensive tasks.", "AI": {"tldr": "Meta-Reasoner optimizes LLM reasoning by dynamically guiding the process, reducing errors and computational waste.", "motivation": "Addressing high computational overhead and error propagation in LLMs' prolonged reasoning chains.", "method": "Uses meta-cognition and dual-process theory, employing contextual multi-armed bandits to evaluate and optimize reasoning strategies.", "result": "Improves reasoning efficiency and accuracy in tasks like math and puzzles.", "conclusion": "Meta-Reasoner offers a scalable, adaptable solution for complex reasoning tasks."}}
{"id": "2505.16051", "pdf": "https://arxiv.org/pdf/2505.16051", "abs": "https://arxiv.org/abs/2505.16051", "authors": ["Dongze Wu", "David I. Inouye", "Yao Xie"], "title": "PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for\ncausal inference that jointly models potential outcomes and counterfactuals.\nTrained via flow matching, PO-Flow provides a unified framework for\nindividualized potential outcome prediction, counterfactual predictions, and\nuncertainty-aware density learning. Among generative models, it is the first to\nenable density learning of potential outcomes without requiring explicit\ndistributional assumptions (e.g., Gaussian mixtures), while also supporting\ncounterfactual prediction conditioned on factual outcomes in general\nobservational datasets. On benchmarks such as ACIC, IHDP, and IBM, it\nconsistently outperforms prior methods across a range of causal inference\ntasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including\ncounterfactual image generation, demonstrating its broad applicability.", "AI": {"tldr": "PO-Flow is a CNF framework for causal inference, modeling potential outcomes and counterfactuals without explicit distributional assumptions, outperforming prior methods.", "motivation": "To unify potential outcome prediction, counterfactual predictions, and uncertainty-aware density learning in causal inference.", "method": "Uses flow matching for training, enabling density learning of potential outcomes and counterfactual prediction without Gaussian assumptions.", "result": "Outperforms prior methods on benchmarks (ACIC, IHDP, IBM) and works in high-dimensional settings like image generation.", "conclusion": "PO-Flow is a versatile and effective framework for causal inference tasks, including high-dimensional applications."}}
{"id": "2505.16916", "pdf": "https://arxiv.org/pdf/2505.16916", "abs": "https://arxiv.org/abs/2505.16916", "authors": ["Xuankun Rong", "Wenke Huang", "Jian Liang", "Jinhe Bi", "Xun Xiao", "Yiming Li", "Bo Du", "Mang Ye"], "title": "Backdoor Cleaning without External Guidance in MLLM Fine-tuning", "categories": ["cs.CR", "cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are increasingly deployed in\nfine-tuning-as-a-service (FTaaS) settings, where user-submitted datasets adapt\ngeneral-purpose models to downstream tasks. This flexibility, however,\nintroduces serious security risks, as malicious fine-tuning can implant\nbackdoors into MLLMs with minimal effort. In this paper, we observe that\nbackdoor triggers systematically disrupt cross-modal processing by causing\nabnormal attention concentration on non-semantic regions--a phenomenon we term\nattention collapse. Based on this insight, we propose Believe Your Eyes (BYE),\na data filtering framework that leverages attention entropy patterns as\nself-supervised signals to identify and filter backdoor samples. BYE operates\nvia a three-stage pipeline: (1) extracting attention maps using the fine-tuned\nmodel, (2) computing entropy scores and profiling sensitive layers via bimodal\nseparation, and (3) performing unsupervised clustering to remove suspicious\nsamples. Unlike prior defenses, BYE equires no clean supervision, auxiliary\nlabels, or model modifications. Extensive experiments across various datasets,\nmodels, and diverse trigger types validate BYE's effectiveness: it achieves\nnear-zero attack success rates while maintaining clean-task performance,\noffering a robust and generalizable solution against backdoor threats in MLLMs.", "AI": {"tldr": "BYE is a data filtering framework that detects backdoor samples in MLLMs by analyzing attention entropy patterns, requiring no clean data or model changes.", "motivation": "Malicious fine-tuning in FTaaS can implant backdoors in MLLMs, posing security risks. Attention collapse during backdoor triggers inspired the solution.", "method": "BYE uses a three-stage pipeline: extracting attention maps, computing entropy scores, and unsupervised clustering to filter suspicious samples.", "result": "BYE achieves near-zero attack success rates while preserving clean-task performance across diverse datasets and triggers.", "conclusion": "BYE provides a robust, unsupervised defense against backdoor threats in MLLMs, generalizing well without auxiliary labels or model modifications."}}
{"id": "2403.10056", "pdf": "https://arxiv.org/pdf/2403.10056", "abs": "https://arxiv.org/abs/2403.10056", "authors": ["Yongquan He", "Wenyuan Zhang", "Xuancheng Huang", "Peng Zhang"], "title": "Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, 6 figures", "summary": "Instruction tuning for large language models (LLMs) can drive them to produce\nresults consistent with human goals in specific downstream tasks. However, the\nprocess of continual instruction tuning (CIT) for LLMs may bring about the\ncatastrophic forgetting (CF) problem, where previously learned abilities are\ndegraded. Recent methods try to alleviate the CF problem by modifying models or\nreplaying data, which may only remember the surface-level pattern of\ninstructions and get confused on held-out tasks. In this paper, we propose a\nnovel continual instruction tuning method based on Key-part Information Gain\n(KPIG). Our method computes the information gain on masked parts to dynamically\nreplay data and refine the training objective, which enables LLMs to capture\ntask-aware information relevant to the correct response and alleviate\noverfitting to general descriptions in instructions. In addition, we propose\ntwo metrics, P-score and V-score, to measure the generalization and\ninstruction-following abilities of LLMs. Experiments demonstrate our method\nachieves superior performance on both seen and held-out tasks.", "AI": {"tldr": "A novel method (KPIG) for continual instruction tuning in LLMs addresses catastrophic forgetting by dynamically replaying data and refining training objectives, improving generalization and instruction-following abilities.", "motivation": "To mitigate catastrophic forgetting in continual instruction tuning for LLMs, which degrades previously learned abilities.", "method": "Uses Key-part Information Gain (KPIG) to dynamically replay data and refine training objectives, focusing on task-aware information. Introduces P-score and V-score metrics.", "result": "Superior performance on both seen and held-out tasks, with improved generalization and instruction-following.", "conclusion": "KPIG effectively alleviates catastrophic forgetting and enhances LLM performance in continual instruction tuning."}}
{"id": "2503.18968", "pdf": "https://arxiv.org/pdf/2503.18968", "abs": "https://arxiv.org/abs/2503.18968", "authors": ["Ziyue Wang", "Junde Wu", "Linghan Cai", "Chang Han Low", "Xihong Yang", "Qiaxuan Li", "Yueming Jin"], "title": "MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow", "categories": ["cs.AI"], "comment": null, "summary": "In modern medicine, clinical diagnosis relies on the comprehensive analysis\nof primarily textual and visual data, drawing on medical expertise to ensure\nsystematic and rigorous reasoning. Recent advances in large Vision-Language\nModels (VLMs) and agent-based methods hold great potential for medical\ndiagnosis, thanks to the ability to effectively integrate multi-modal patient\ndata. However, they often provide direct answers and draw empirical-driven\nconclusions without quantitative analysis, which reduces their reliability and\nclinical usability. We propose MedAgent-Pro, a new agentic reasoning paradigm\nthat follows the diagnosis principle in modern medicine, to decouple the\nprocess into sequential components for step-by-step, evidence-based reasoning.\nOur MedAgent-Pro workflow presents a hierarchical diagnostic structure to\nmirror this principle, consisting of disease-level standardized plan generation\nand patient-level personalized step-by-step reasoning. To support disease-level\nplanning, an RAG-based agent is designed to retrieve medical guidelines to\nensure alignment with clinical standards. For patient-level reasoning, we\npropose to integrate professional tools such as visual models to enable\nquantitative assessments. Meanwhile, we propose to verify the reliability of\neach step to achieve evidence-based diagnosis, enforcing rigorous logical\nreasoning and a well-founded conclusion. Extensive experiments across a wide\nrange of anatomical regions, imaging modalities, and diseases demonstrate the\nsuperiority of MedAgent-Pro to mainstream VLMs, agentic systems and\nstate-of-the-art expert models. Ablation studies and human evaluation by\nclinical experts further validate its robustness and clinical relevance. Code\nis available at https://github.com/jinlab-imvr/MedAgent-Pro.", "AI": {"tldr": "MedAgent-Pro introduces a hierarchical, evidence-based reasoning paradigm for medical diagnosis, outperforming existing VLMs and expert models.", "motivation": "Current VLMs lack quantitative analysis and reliability in medical diagnosis, limiting clinical usability.", "method": "MedAgent-Pro decouples diagnosis into disease-level planning (RAG-based agent) and patient-level reasoning (quantitative tools).", "result": "Superior performance across anatomical regions, imaging modalities, and diseases, validated by experts.", "conclusion": "MedAgent-Pro enhances reliability and clinical relevance through step-by-step, evidence-based reasoning."}}
{"id": "2505.16082", "pdf": "https://arxiv.org/pdf/2505.16082", "abs": "https://arxiv.org/abs/2505.16082", "authors": ["Renato Berlinghieri", "Yunyi Shen", "Jialong Jiang", "Tamara Broderick"], "title": "Oh SnapMMD! Forecasting Stochastic Dynamics Beyond the Schr\u00f6dinger Bridge's End", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "43 pages, 26 figures, 21 tables", "summary": "Scientists often want to make predictions beyond the observed time horizon of\n\"snapshot\" data following latent stochastic dynamics. For example, in time\ncourse single-cell mRNA profiling, scientists have access to cellular\ntranscriptional state measurements (snapshots) from different biological\nreplicates at different time points, but they cannot access the trajectory of\nany one cell because measurement destroys the cell. Researchers want to\nforecast (e.g.) differentiation outcomes from early state measurements of stem\ncells. Recent Schr\\\"odinger-bridge (SB) methods are natural for interpolating\nbetween snapshots. But past SB papers have not addressed forecasting -- likely\nsince existing methods either (1) reduce to following pre-set reference\ndynamics (chosen before seeing data) or (2) require the user to choose a fixed,\nstate-independent volatility since they minimize a Kullback-Leibler divergence.\nEither case can lead to poor forecasting quality. In the present work, we\npropose a new framework, SnapMMD, that learns dynamics by directly fitting the\njoint distribution of both state measurements and observation time with a\nmaximum mean discrepancy (MMD) loss. Unlike past work, our method allows us to\ninfer unknown and state-dependent volatilities from the observed data. We show\nin a variety of real and synthetic experiments that our method delivers\naccurate forecasts. Moreover, our approach allows us to learn in the presence\nof incomplete state measurements and yields an $R^2$-style statistic that\ndiagnoses fit. We also find that our method's performance at interpolation (and\ngeneral velocity-field reconstruction) is at least as good as (and often better\nthan) state-of-the-art in almost all of our experiments.", "AI": {"tldr": "SnapMMD is a new framework for forecasting latent stochastic dynamics from snapshot data, outperforming existing methods by learning state-dependent volatilities and handling incomplete measurements.", "motivation": "Scientists need to predict outcomes beyond observed time horizons in snapshot data (e.g., single-cell mRNA profiling), but existing methods like Schr\u00f6dinger-bridge (SB) are limited for forecasting.", "method": "SnapMMD uses a maximum mean discrepancy (MMD) loss to fit joint distributions of state measurements and observation times, enabling inference of state-dependent volatilities.", "result": "SnapMMD achieves accurate forecasts, handles incomplete measurements, and outperforms state-of-the-art methods in interpolation and velocity-field reconstruction.", "conclusion": "SnapMMD provides a robust solution for forecasting and interpolation in snapshot data, with diagnostic tools for fit assessment."}}
{"id": "2308.05232", "pdf": "https://arxiv.org/pdf/2308.05232", "abs": "https://arxiv.org/abs/2308.05232", "authors": ["Meng Wei", "Charlie Budd", "Luis C. Garcia-Peraza-Herrera", "Reuben Dorent", "Miaojing Shi", "Tom Vercauteren"], "title": "SegMatch: A semi-supervised learning method for surgical instrument segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Published, 19 pages, 8 figures", "summary": "Surgical instrument segmentation is recognised as a key enabler in providing\nadvanced surgical assistance and improving computer-assisted interventions. In\nthis work, we propose SegMatch, a semi-supervised learning method to reduce the\nneed for expensive annotation for laparoscopic and robotic surgical images.\nSegMatch builds on FixMatch, a widespread semi supervised classification\npipeline combining consistency regularization and pseudo-labelling, and adapts\nit for the purpose of segmentation. In our proposed SegMatch, the unlabelled\nimages are first weakly augmented and fed to the segmentation model to generate\npseudo-labels. In parallel, images are fed to a strong augmentation branch and\nconsistency between the branches is used as an unsupervised loss. To increase\nthe relevance of our strong augmentations, we depart from using only\nhandcrafted augmentations and introduce a trainable adversarial augmentation\nstrategy. Our FixMatch adaptation for segmentation tasks further includes\ncarefully considering the equivariance and invariance properties of the\naugmentation functions we rely on. For binary segmentation tasks, our algorithm\nwas evaluated on the MICCAI Instrument Segmentation Challenge datasets,\nRobust-MIS 2019 and EndoVis 2017. For multi-class segmentation tasks, we relied\non the recent CholecInstanceSeg dataset. Our results show that SegMatch\noutperforms fully-supervised approaches by incorporating unlabelled data, and\nsurpasses a range of state-of-the-art semi-supervised models across different\nlabelled to unlabelled data ratios.", "AI": {"tldr": "SegMatch, a semi-supervised learning method, reduces annotation costs for surgical instrument segmentation by combining consistency regularization and pseudo-labeling, outperforming fully-supervised and other semi-supervised models.", "motivation": "To reduce the need for expensive annotation in surgical image segmentation while maintaining high performance.", "method": "Adapts FixMatch for segmentation, using weak and strong augmentation branches with consistency loss and adversarial augmentation.", "result": "Outperforms fully-supervised approaches and state-of-the-art semi-supervised models on MICCAI and CholecInstanceSeg datasets.", "conclusion": "SegMatch effectively leverages unlabelled data to improve surgical instrument segmentation, reducing reliance on costly annotations."}}
{"id": "2405.04756", "pdf": "https://arxiv.org/pdf/2405.04756", "abs": "https://arxiv.org/abs/2405.04756", "authors": ["Chu Fei Luo", "Ahmad Ghawanmeh", "Bharat Bhimshetty", "Kashyap Murali", "Murli Jadhav", "Xiaodan Zhu", "Faiza Khan Khattak"], "title": "Red-Teaming for Inducing Societal Bias in Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Ensuring the safe deployment of AI systems is critical in industry settings\nwhere biased outputs can lead to significant operational, reputational, and\nregulatory risks. Thorough evaluation before deployment is essential to prevent\nthese hazards. Red-teaming addresses this need by employing adversarial attacks\nto develop guardrails that detect and reject biased or harmful queries,\nenabling models to be retrained or steered away from harmful outputs. However,\nmost red-teaming efforts focus on harmful or unethical instructions rather than\naddressing social bias, leaving this critical area under-explored despite its\nsignificant real-world impact, especially in customer-facing systems. We\npropose two bias-specific red-teaming methods, Emotional Bias Probe (EBP) and\nBiasKG, to evaluate how standard safety measures for harmful content affect\nbias. For BiasKG, we refactor natural language stereotypes into a knowledge\ngraph. We use these attacking strategies to induce biased responses from\nseveral open- and closed-source language models. Unlike prior work, these\nmethods specifically target social bias. We find our method increases bias in\nall models, even those trained with safety guardrails. Our work emphasizes\nuncovering societal bias in LLMs through rigorous evaluation, and recommends\nmeasures ensure AI safety in high-stakes industry deployments.", "AI": {"tldr": "The paper introduces two bias-specific red-teaming methods, EBP and BiasKG, to evaluate social bias in AI models, revealing that even models with safety guardrails exhibit increased bias.", "motivation": "The need to address social bias in AI systems, especially in high-stakes industry settings, where biased outputs pose operational, reputational, and regulatory risks.", "method": "Proposes Emotional Bias Probe (EBP) and BiasKG, which refactor stereotypes into a knowledge graph, to induce and evaluate biased responses in language models.", "result": "The methods increase bias in all tested models, including those with safety guardrails, highlighting the inadequacy of current safety measures for social bias.", "conclusion": "The study underscores the importance of rigorous evaluation for societal bias in AI and recommends improved safety measures for industry deployments."}}
{"id": "2503.21322", "pdf": "https://arxiv.org/pdf/2503.21322", "abs": "https://arxiv.org/abs/2503.21322", "authors": ["Haoran Luo", "Haihong E", "Guanting Chen", "Yandan Zheng", "Xiaobao Wu", "Yikai Guo", "Qika Lin", "Yu Feng", "Zemin Kuang", "Meina Song", "Yifan Zhu", "Luu Anh Tuan"], "title": "HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation", "categories": ["cs.AI"], "comment": "Preprint", "summary": "Standard Retrieval-Augmented Generation (RAG) relies on chunk-based\nretrieval, whereas GraphRAG advances this approach by graph-based knowledge\nrepresentation. However, existing graph-based RAG approaches are constrained by\nbinary relations, as each edge in an ordinary graph connects only two entities,\nlimiting their ability to represent the n-ary relations (n >= 2) in real-world\nknowledge. In this work, we propose HyperGraphRAG, a novel hypergraph-based RAG\nmethod that represents n-ary relational facts via hyperedges, and consists of\nknowledge hypergraph construction, retrieval, and generation. Experiments\nacross medicine, agriculture, computer science, and law demonstrate that\nHyperGraphRAG outperforms both standard RAG and previous graph-based RAG\nmethods in answer accuracy, retrieval efficiency, and generation quality.", "AI": {"tldr": "HyperGraphRAG improves RAG by using hypergraphs for n-ary relations, outperforming standard and graph-based RAG in accuracy and efficiency.", "motivation": "Existing graph-based RAG methods are limited to binary relations, failing to represent real-world n-ary relations.", "method": "Proposes HyperGraphRAG, using hyperedges for n-ary relations, with steps: knowledge hypergraph construction, retrieval, and generation.", "result": "Outperforms standard and graph-based RAG in accuracy, retrieval efficiency, and generation quality across multiple domains.", "conclusion": "HyperGraphRAG is a superior RAG method for handling complex n-ary relations in real-world knowledge."}}
{"id": "2505.16098", "pdf": "https://arxiv.org/pdf/2505.16098", "abs": "https://arxiv.org/abs/2505.16098", "authors": ["Damien Ferbach", "Katie Everett", "Gauthier Gidel", "Elliot Paquette", "Courtney Paquette"], "title": "Dimension-adapted Momentum Outscales SGD", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "We investigate scaling laws for stochastic momentum algorithms with small\nbatch on the power law random features model, parameterized by data complexity,\ntarget complexity, and model size. When trained with a stochastic momentum\nalgorithm, our analysis reveals four distinct loss curve shapes determined by\nvarying data-target complexities. While traditional stochastic gradient descent\nwith momentum (SGD-M) yields identical scaling law exponents to SGD,\ndimension-adapted Nesterov acceleration (DANA) improves these exponents by\nscaling momentum hyperparameters based on model size and data complexity. This\noutscaling phenomenon, which also improves compute-optimal scaling behavior, is\nachieved by DANA across a broad range of data and target complexities, while\ntraditional methods fall short. Extensive experiments on high-dimensional\nsynthetic quadratics validate our theoretical predictions and large-scale text\nexperiments with LSTMs show DANA's improved loss exponents over SGD hold in a\npractical setting.", "AI": {"tldr": "The paper explores scaling laws for stochastic momentum algorithms, revealing distinct loss curve shapes based on data-target complexities. Dimension-adapted Nesterov acceleration (DANA) outperforms traditional methods by improving scaling law exponents and compute-optimal behavior.", "motivation": "To understand how stochastic momentum algorithms scale with small batches and varying data-target complexities, and to improve upon traditional methods like SGD-M.", "method": "Analyzes scaling laws using the power law random features model, comparing SGD-M and DANA. Experiments include synthetic quadratics and large-scale text tasks with LSTMs.", "result": "DANA improves scaling law exponents and compute-optimal behavior across diverse data-target complexities, validated by synthetic and practical experiments.", "conclusion": "DANA's adaptive momentum scaling outperforms traditional methods, offering better performance in both theoretical and practical settings."}}
{"id": "2311.14334", "pdf": "https://arxiv.org/pdf/2311.14334", "abs": "https://arxiv.org/abs/2311.14334", "authors": ["Seonghak Kim", "Gyeongdo Ham", "Suin Lee", "Donggon Jang", "Daeshik Kim"], "title": "Maximizing Discrimination Capability of Knowledge Distillation with Energy Function", "categories": ["cs.CV"], "comment": "12 pages, 7 figures", "summary": "To apply the latest computer vision techniques that require a large\ncomputational cost in real industrial applications, knowledge distillation\nmethods (KDs) are essential. Existing logit-based KDs apply the constant\ntemperature scaling to all samples in dataset, limiting the utilization of\nknowledge inherent in each sample individually. In our approach, we classify\nthe dataset into two categories (i.e., low energy and high energy samples)\nbased on their energy score. Through experiments, we have confirmed that low\nenergy samples exhibit high confidence scores, indicating certain predictions,\nwhile high energy samples yield low confidence scores, meaning uncertain\npredictions. To distill optimal knowledge by adjusting non-target class\npredictions, we apply a higher temperature to low energy samples to create\nsmoother distributions and a lower temperature to high energy samples to\nachieve sharper distributions. When compared to previous logit-based and\nfeature-based methods, our energy-based KD (Energy KD) achieves better\nperformance on various datasets. Especially, Energy KD shows significant\nimprovements on CIFAR-100-LT and ImageNet datasets, which contain many\nchallenging samples. Furthermore, we propose high energy-based data\naugmentation (HE-DA) for further improving the performance. We demonstrate that\nhigher performance improvement could be achieved by augmenting only a portion\nof the dataset rather than the entire dataset, suggesting that it can be\nemployed on resource-limited devices. To the best of our knowledge, this paper\nrepresents the first attempt to make use of energy function in knowledge\ndistillation and data augmentation, and we believe it will greatly contribute\nto future research.", "AI": {"tldr": "The paper introduces Energy KD, a knowledge distillation method that classifies samples by energy scores to optimize temperature scaling, outperforming existing methods. It also proposes HE-DA for efficient data augmentation.", "motivation": "To improve knowledge distillation by addressing the limitation of constant temperature scaling, leveraging sample-specific energy scores for better knowledge utilization.", "method": "Classifies samples into low/high energy categories, applies adaptive temperature scaling, and introduces HE-DA for selective data augmentation.", "result": "Energy KD outperforms logit-based and feature-based methods, especially on challenging datasets like CIFAR-100-LT and ImageNet. HE-DA further enhances performance efficiently.", "conclusion": "Energy KD and HE-DA advance knowledge distillation and data augmentation by leveraging energy scores, offering practical benefits for resource-limited applications."}}
{"id": "2406.10594", "pdf": "https://arxiv.org/pdf/2406.10594", "abs": "https://arxiv.org/abs/2406.10594", "authors": ["Longguang Zhong", "Fanqi Wan", "Ruijun Chen", "Xiaojun Quan", "Liangzhi Li"], "title": "BlockPruner: Fine-grained Pruning for Large Language Models", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "With the rapid growth in the size and complexity of large language models\n(LLMs), the costs associated with their training and inference have escalated\nsignificantly. Research indicates that certain layers in LLMs harbor\nsubstantial redundancy, and pruning these layers has minimal impact on the\noverall performance. While various layer pruning methods have been developed\nbased on this insight, they generally overlook the finer-grained redundancies\nwithin the layers themselves. In this paper, we delve deeper into the\narchitecture of LLMs and demonstrate that finer-grained pruning can be achieved\nby targeting redundancies in multi-head attention (MHA) and multi-layer\nperceptron (MLP) blocks. We propose a novel, training-free structured pruning\napproach called BlockPruner. Unlike existing layer pruning methods, BlockPruner\nsegments each Transformer layer into MHA and MLP blocks. It then assesses the\nimportance of these blocks using perplexity measures and applies a heuristic\nsearch for iterative pruning. We applied BlockPruner to LLMs of various sizes\nand architectures and validated its performance across a wide range of\ndownstream tasks. Experimental results show that BlockPruner achieves more\ngranular and effective pruning compared to state-of-the-art baselines.", "AI": {"tldr": "BlockPruner is a training-free structured pruning method for LLMs, targeting redundancies in MHA and MLP blocks for finer-grained pruning, outperforming existing methods.", "motivation": "The high costs of LLM training and inference, coupled with overlooked finer-grained redundancies in existing pruning methods, drive the need for more granular pruning.", "method": "BlockPruner segments Transformer layers into MHA and MLP blocks, evaluates block importance using perplexity, and uses heuristic search for iterative pruning.", "result": "BlockPruner achieves more granular and effective pruning across various LLM sizes and architectures, validated by downstream task performance.", "conclusion": "BlockPruner offers a superior, training-free approach to pruning LLMs by addressing finer-grained redundancies, enhancing efficiency without compromising performance."}}
{"id": "2504.17531", "pdf": "https://arxiv.org/pdf/2504.17531", "abs": "https://arxiv.org/abs/2504.17531", "authors": ["Justus Flerlage", "Ilja Behnke", "Odej Kao"], "title": "Towards Machine-Generated Code for the Resolution of User Intentions", "categories": ["cs.AI"], "comment": null, "summary": "The growing capabilities of Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), prompt a reassessment of the interaction mechanisms\nbetween users and their devices. Currently, users are required to use a set of\nhigh-level applications to achieve their desired results. However, the advent\nof AI may signal a shift in this regard, as its capabilities have generated\nnovel prospects for user-provided intent resolution through the deployment of\nmodel-generated code. This development represents a significant progression in\nthe realm of hybrid workflows, where human and artificial intelligence\ncollaborate to address user intentions, with the former responsible for\ndefining these intentions and the latter for implementing the solutions to\naddress them. In this paper, we investigate the feasibility of generating and\nexecuting workflows through code generation that results from prompting an LLM\nwith a concrete user intention, and a simplified application programming\ninterface for a GUI-less operating system. We provide an in-depth analysis and\ncomparison of various user intentions, the resulting code, and its execution.\nThe findings demonstrate the general feasibility of our approach and that the\nemployed LLM, GPT-4o-mini, exhibits remarkable proficiency in the generation of\ncode-oriented workflows in accordance with provided user intentions.", "AI": {"tldr": "The paper explores using LLMs like GPT-4o-mini to generate and execute workflows from user intentions, showing feasibility and proficiency in code-oriented tasks.", "motivation": "To reassess user-device interaction by leveraging AI for intent resolution through model-generated code, enabling hybrid human-AI workflows.", "method": "Investigates generating and executing workflows via LLM-prompted code generation for a GUI-less OS, analyzing user intentions, code, and execution.", "result": "Demonstrates feasibility and GPT-4o-mini's proficiency in generating code workflows aligned with user intentions.", "conclusion": "AI-driven code generation for workflows is viable, marking progress in hybrid human-AI collaboration for intent resolution."}}
{"id": "2505.16131", "pdf": "https://arxiv.org/pdf/2505.16131", "abs": "https://arxiv.org/abs/2505.16131", "authors": ["Nathan Brady", "David Tennyson", "Thomas Vandermeulen"], "title": "Machine Learning the 6d Supergravity Landscape", "categories": ["hep-th", "cs.LG"], "comment": "49 pages; code and data available at\n  https://github.com/nait400/ML-6d-sugra-landscape", "summary": "In this paper, we apply both supervised and unsupervised machine learning\nalgorithms to the study of the string landscape and swampland in 6-dimensions.\nOur data are the (almost) anomaly-free 6-dimensional $\\mathcal{N} = (1,0)$\nsupergravity models, characterised by the Gram matrix of anomaly coefficients.\nOur work demonstrates the ability of machine learning algorithms to efficiently\nlearn highly complex features of the landscape and swampland. Employing an\nautoencoder for unsupervised learning, we provide an auto-classification of\nthese models by compressing the Gram matrix data to 2-dimensions. Through\ncompression, similar models cluster together, and we identify prominent\nfeatures of these clusters. The autoencoder also identifies outlier models\nwhich are difficult to reconstruct. One of these outliers proves to be\nincredibly difficult to combine with other models such that the\n$\\text{tr}R^{4}$ anomaly vanishes, making its presence in the landscape\nextremely rare. Further, we utilise supervised learning to build two\nclassifiers predicting (1) model consistency under probe string insertion\n(precision: 0.78, predicting consistency for 214,837 models with reasonable\ncertainty) and (2) inconsistency under anomaly inflow (precision: 0.91,\npredicting inconsistency for 1,909,359 models). Notably, projecting these\npredictions onto the autoencoder's 2-dimensional latent layer shows consistent\nmodels clustering together, further indicating that the autoencoder has learnt\ninteresting and complex features of the set of models and potentially offers a\nnovel approach to mapping the landscape and swampland of 6-dimensional\nsupergravity theories.", "AI": {"tldr": "The paper uses supervised and unsupervised ML to analyze 6D supergravity models, classifying them and identifying outliers and clusters.", "motivation": "To efficiently study the complex features of the string landscape and swampland in 6D supergravity using ML.", "method": "Employed an autoencoder for unsupervised classification and supervised learning for predicting model consistency.", "result": "Identified clusters and outliers, with one outlier being rare in the landscape. Supervised classifiers achieved high precision (0.78 and 0.91).", "conclusion": "ML effectively maps the landscape and swampland, revealing complex features and offering a novel approach to classification."}}
{"id": "2312.14999", "pdf": "https://arxiv.org/pdf/2312.14999", "abs": "https://arxiv.org/abs/2312.14999", "authors": ["Tin Nguyen", "Peijie Chen", "Anh Totti Nguyen"], "title": "Leveraging Habitat Information for Fine-grained Bird Identification", "categories": ["cs.CV"], "comment": null, "summary": "Traditional bird classifiers mostly rely on the visual characteristics of\nbirds. Some prior works even train classifiers to be invariant to the\nbackground, completely discarding the living environment of birds. Instead, we\nare the first to explore integrating habitat information, one of the four major\ncues for identifying birds by ornithologists, into modern bird classifiers. We\nfocus on two leading model types: (1) CNNs and ViTs trained on the downstream\nbird datasets; and (2) original, multi-modal CLIP. Training CNNs and ViTs with\nhabitat-augmented data results in an improvement of up to +0.83 and +0.23\npoints on NABirds and CUB-200, respectively. Similarly, adding habitat\ndescriptors to the prompts for CLIP yields a substantial accuracy boost of up\nto +0.99 and +1.1 points on NABirds and CUB-200, respectively. We find\nconsistent accuracy improvement after integrating habitat features into the\nimage augmentation process and into the textual descriptors of vision-language\nCLIP classifiers. Code is available at:\nhttps://anonymous.4open.science/r/reasoning-8B7E/.", "AI": {"tldr": "The paper explores integrating habitat information into bird classifiers, improving accuracy for CNNs, ViTs, and CLIP models.", "motivation": "Traditional bird classifiers ignore habitat, a key cue for ornithologists. This work aims to leverage habitat data for better classification.", "method": "Habitat-augmented data is used to train CNNs/ViTs, and habitat descriptors are added to CLIP prompts.", "result": "Accuracy improved by up to +0.83 (NABirds) and +0.23 (CUB-200) for CNNs/ViTs, and +0.99 (NABirds) and +1.1 (CUB-200) for CLIP.", "conclusion": "Integrating habitat features consistently boosts classifier accuracy, validating its importance in bird identification."}}
{"id": "2409.02393", "pdf": "https://arxiv.org/pdf/2409.02393", "abs": "https://arxiv.org/abs/2409.02393", "authors": ["Peter B. Lerner"], "title": "Determination of language families using deep learning", "categories": ["cs.CL", "I.2.7"], "comment": "Second draft with improved statistics of NN simulations. Comments are\n  welcome", "summary": "We use a c-GAN (convolutional generative adversarial) neural network to\nanalyze transliterated text fragments of extant, dead comprehensible, and one\ndead non-deciphered (Cypro-Minoan) language to establish linguistic affinities.\nThe paper is agnostic with respect to translation and/or deciphering. However,\nthere is hope that the proposed approach can be useful for decipherment with\nmore sophisticated neural network techniques.", "AI": {"tldr": "A c-GAN neural network analyzes transliterated text fragments of dead languages, including undeciphered ones like Cypro-Minoan, to identify linguistic affinities, potentially aiding future decipherment.", "motivation": "To explore linguistic connections between dead languages without relying on translation or deciphering, with potential applications in decipherment using advanced neural networks.", "method": "Uses a convolutional generative adversarial network (c-GAN) to analyze transliterated texts from dead languages, focusing on linguistic patterns.", "result": "Identifies linguistic affinities among the analyzed languages, though decipherment is not directly achieved.", "conclusion": "The approach shows promise for future decipherment efforts with more advanced neural network techniques."}}
{"id": "2504.20090", "pdf": "https://arxiv.org/pdf/2504.20090", "abs": "https://arxiv.org/abs/2504.20090", "authors": ["Aishik Sanyal", "Samuel Schapiro", "Sumuk Shashidhar", "Royce Moon", "Lav R. Varshney", "Dilek Hakkani-Tur"], "title": "Spark: A System for Scientifically Creative Idea Generation", "categories": ["cs.AI", "cs.IR", "cs.LG"], "comment": "Accepted at ICCC 2025", "summary": "Recently, large language models (LLMs) have shown promising abilities to\ngenerate novel research ideas in science, a direction which coincides with many\nfoundational principles in computational creativity (CC). In light of these\ndevelopments, we present an idea generation system named Spark that couples\nretrieval-augmented idea generation using LLMs with a reviewer model named\nJudge trained on 600K scientific reviews from OpenReview. Our work is both a\nsystem demonstration and intended to inspire other CC researchers to explore\ngrounding the generation and evaluation of scientific ideas within foundational\nCC principles. To this end, we release the annotated dataset used to train\nJudge, inviting other researchers to explore the use of LLMs for idea\ngeneration and creative evaluations.", "AI": {"tldr": "Spark is a system combining LLMs and a reviewer model (Judge) for generating and evaluating scientific ideas, grounded in computational creativity principles.", "motivation": "To leverage LLMs for generating novel research ideas and align with computational creativity principles, while inspiring further exploration in the field.", "method": "Uses retrieval-augmented idea generation with LLMs and a reviewer model (Judge) trained on 600K scientific reviews from OpenReview.", "result": "Demonstrates the system's potential and releases the annotated dataset for broader research use.", "conclusion": "Encourages further exploration of LLMs in idea generation and creative evaluations, sharing resources to foster collaboration."}}
{"id": "2505.16145", "pdf": "https://arxiv.org/pdf/2505.16145", "abs": "https://arxiv.org/abs/2505.16145", "authors": ["Arghya Datta", "Philippe Gagnon", "Florian Maire"], "title": "Exponential Convergence of CAVI for Bayesian PCA", "categories": ["stat.ML", "cs.LG"], "comment": "28 pages, 3 figures", "summary": "Probabilistic principal component analysis (PCA) and its Bayesian variant\n(BPCA) are widely used for dimension reduction in machine learning and\nstatistics. The main advantage of probabilistic PCA over the traditional\nformulation is allowing uncertainty quantification. The parameters of BPCA are\ntypically learned using mean-field variational inference, and in particular,\nthe coordinate ascent variational inference (CAVI) algorithm. So far, the\nconvergence speed of CAVI for BPCA has not been characterized. In our paper, we\nfill this gap in the literature. Firstly, we prove a precise exponential\nconvergence result in the case where the model uses a single principal\ncomponent (PC). Interestingly, this result is established through a connection\nwith the classical $\\textit{power iteration algorithm}$ and it indicates that\ntraditional PCA is retrieved as points estimates of the BPCA parameters.\nSecondly, we leverage recent tools to prove exponential convergence of CAVI for\nthe model with any number of PCs, thus leading to a more general result, but\none that is of a slightly different flavor. To prove the latter result, we\nadditionally needed to introduce a novel lower bound for the symmetric\nKullback--Leibler divergence between two multivariate normal distributions,\nwhich, we believe, is of independent interest in information theory.", "AI": {"tldr": "The paper characterizes the convergence speed of CAVI for BPCA, proving exponential convergence for single and multiple PCs, and introduces a novel lower bound for the Kullback-Leibler divergence.", "motivation": "To address the lack of understanding of the convergence speed of CAVI for BPCA, a widely used method for dimension reduction.", "method": "Proves exponential convergence for BPCA with a single PC using a connection to power iteration, and extends this to multiple PCs using new tools, including a novel lower bound for the Kullback-Leibler divergence.", "result": "Exponential convergence of CAVI for BPCA is proven, with traditional PCA retrieved as point estimates for single PC cases.", "conclusion": "The paper fills a gap in BPCA literature by characterizing CAVI convergence and introduces a useful lower bound for information theory."}}
{"id": "2401.01008", "pdf": "https://arxiv.org/pdf/2401.01008", "abs": "https://arxiv.org/abs/2401.01008", "authors": ["Rosco Hunter", "\u0141ukasz Dudziak", "Mohamed S. Abdelfattah", "Abhinav Mehrotra", "Sourav Bhattacharya", "Hongkai Wen"], "title": "Fast Sampling Through The Reuse Of Attention Maps In Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Text-to-image diffusion models have demonstrated unprecedented capabilities\nfor flexible and realistic image synthesis. Nevertheless, these models rely on\na time-consuming sampling procedure, which has motivated attempts to reduce\ntheir latency. When improving efficiency, researchers often use the original\ndiffusion model to train an additional network designed specifically for fast\nimage generation. In contrast, our approach seeks to reduce latency directly,\nwithout any retraining, fine-tuning, or knowledge distillation. In particular,\nwe find the repeated calculation of attention maps to be costly yet redundant,\nand instead suggest reusing them during sampling. Our specific reuse strategies\nare based on ODE theory, which implies that the later a map is reused, the\nsmaller the distortion in the final image. We empirically compare our reuse\nstrategies with few-step sampling procedures of comparable latency, finding\nthat reuse generates images that are closer to those produced by the original\nhigh-latency diffusion model.", "AI": {"tldr": "The paper proposes reusing attention maps in diffusion models to reduce latency without retraining, outperforming few-step sampling methods.", "motivation": "Text-to-image diffusion models are slow due to repeated attention map calculations, and existing efficiency improvements require additional training.", "method": "Reuses attention maps during sampling based on ODE theory, with strategies to minimize distortion.", "result": "Reuse strategies generate images closer to the original high-latency model compared to few-step sampling.", "conclusion": "Directly reusing attention maps is an effective way to reduce latency without compromising image quality."}}
{"id": "2409.02813", "pdf": "https://arxiv.org/pdf/2409.02813", "abs": "https://arxiv.org/abs/2409.02813", "authors": ["Xiang Yue", "Tianyu Zheng", "Yuansheng Ni", "Yubo Wang", "Kai Zhang", "Shengbang Tong", "Yuxuan Sun", "Botao Yu", "Ge Zhang", "Huan Sun", "Yu Su", "Wenhu Chen", "Graham Neubig"], "title": "MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark", "categories": ["cs.CL", "cs.CV"], "comment": "ACL 2025 Main", "summary": "This paper introduces MMMU-Pro, a robust version of the Massive\nMulti-discipline Multimodal Understanding and Reasoning (MMMU) benchmark.\nMMMU-Pro rigorously assesses multimodal models' true understanding and\nreasoning capabilities through a three-step process based on MMMU: (1)\nfiltering out questions answerable by text-only models, (2) augmenting\ncandidate options, and (3) introducing a vision-only input setting where\nquestions are embedded within images. This setting challenges AI to truly \"see\"\nand \"read\" simultaneously, testing a fundamental human cognitive skill of\nseamlessly integrating visual and textual information. Results show that model\nperformance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8%\nto 26.9% across models. We explore the impact of OCR prompts and Chain of\nThought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT\ngenerally improves performance. MMMU-Pro provides a more rigorous evaluation\ntool, closely mimicking real-world scenarios and offering valuable directions\nfor future research in multimodal AI.", "AI": {"tldr": "MMMU-Pro is an enhanced version of the MMMU benchmark, designed to rigorously test multimodal models' understanding and reasoning by filtering text-only answerable questions, augmenting options, and introducing vision-only inputs. Results show lower performance on MMMU-Pro, highlighting the need for better multimodal integration.", "motivation": "To create a more robust benchmark that accurately assesses multimodal models' ability to integrate visual and textual information, mimicking real-world cognitive tasks.", "method": "A three-step process: (1) filtering text-only answerable questions, (2) augmenting candidate options, and (3) introducing vision-only inputs where questions are embedded in images.", "result": "Model performance drops significantly (16.8% to 26.9%) on MMMU-Pro compared to MMMU. OCR prompts have minimal impact, while Chain of Thought reasoning improves performance.", "conclusion": "MMMU-Pro offers a more rigorous evaluation tool for multimodal AI, aligning with real-world scenarios and guiding future research."}}
{"id": "2505.07581", "pdf": "https://arxiv.org/pdf/2505.07581", "abs": "https://arxiv.org/abs/2505.07581", "authors": ["Lei Wang", "Heyang Gao", "Xiaohe Bo", "Xu Chen", "Ji-Rong Wen"], "title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Leveraging large language model (LLM) based agents to simulate human social\nbehaviors has recently gained significant attention. In this paper, we\nintroduce a novel social simulator called YuLan-OneSim. Compared to previous\nworks, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free\nscenario construction: Users can simply describe and refine their simulation\nscenarios through natural language interactions with our simulator. All\nsimulation code is automatically generated, significantly reducing the need for\nprogramming expertise. (2) Comprehensive default scenarios: We implement 50\ndefault simulation scenarios spanning 8 domains, including economics,\nsociology, politics, psychology, organization, demographics, law, and\ncommunication, broadening access for a diverse range of social researchers. (3)\nEvolvable simulation: Our simulator is capable of receiving external feedback\nand automatically fine-tuning the backbone LLMs, significantly enhancing the\nsimulation quality. (4) Large-scale simulation: By developing a fully\nresponsive agent framework and a distributed simulation architecture, our\nsimulator can handle up to 100,000 agents, ensuring more stable and reliable\nsimulation results. (5) AI social researcher: Leveraging the above features, we\ndevelop an AI social researcher. Users only need to propose a research topic,\nand the AI researcher will automatically analyze the input, construct\nsimulation environments, summarize results, generate technical reports, review\nand refine the reports--completing the social science research loop. To\ndemonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate\nthe quality of the automatically generated scenarios, the reliability,\nefficiency, and scalability of the simulation process, as well as the\nperformance of the AI social researcher.", "AI": {"tldr": "YuLan-OneSim is a novel LLM-based social simulator enabling code-free scenario construction, large-scale simulations, and AI-driven social research.", "motivation": "To simplify and enhance social behavior simulations by reducing programming needs and providing scalable, evolvable tools for diverse researchers.", "method": "Develops a code-free, natural language interface, 50 default scenarios, evolvable LLMs, a distributed architecture for scalability, and an AI social researcher.", "result": "Demonstrates high-quality scenario generation, reliable simulations for up to 100,000 agents, and effective AI-driven research automation.", "conclusion": "YuLan-OneSim advances social simulation by making it accessible, scalable, and automated, benefiting diverse research domains."}}
{"id": "2505.16156", "pdf": "https://arxiv.org/pdf/2505.16156", "abs": "https://arxiv.org/abs/2505.16156", "authors": ["Siu Lun Chau", "Michele Caprio", "Krikamol Muandet"], "title": "Integral Imprecise Probability Metrics", "categories": ["stat.ML", "cs.LG"], "comment": "50 pages, 2 figures", "summary": "Quantifying differences between probability distributions is fundamental to\nstatistics and machine learning, primarily for comparing statistical\nuncertainty. In contrast, epistemic uncertainty (EU) -- due to incomplete\nknowledge -- requires richer representations than those offered by classical\nprobability. Imprecise probability (IP) theory offers such models, capturing\nambiguity and partial belief. This has driven growing interest in imprecise\nprobabilistic machine learning (IPML), where inference and decision-making rely\non broader uncertainty models -- highlighting the need for metrics beyond\nclassical probability. This work introduces the Integral Imprecise Probability\nMetric (IIPM) framework, a Choquet integral-based generalisation of classical\nIntegral Probability Metric (IPM) to the setting of capacities -- a broad class\nof IP models encompassing many existing ones, including lower probabilities,\nprobability intervals, belief functions, and more. Theoretically, we establish\nconditions under which IIPM serves as a valid metric and metrises a form of\nweak convergence of capacities. Practically, IIPM not only enables comparison\nacross different IP models but also supports the quantification of epistemic\nuncertainty within a single IP model. In particular, by comparing an IP model\nwith its conjugate, IIPM gives rise to a new class of EU measures -- Maximum\nMean Imprecision -- which satisfy key axiomatic properties proposed in the\nUncertainty Quantification literature. We validate MMI through selective\nclassification experiments, demonstrating strong empirical performance against\nestablished EU measures, and outperforming them when classical methods struggle\nto scale to a large number of classes. Our work advances both theory and\npractice in IPML, offering a principled framework for comparing and quantifying\nepistemic uncertainty under imprecision.", "AI": {"tldr": "The paper introduces the Integral Imprecise Probability Metric (IIPM) framework, a generalization of classical Integral Probability Metrics for imprecise probability models, enabling comparison and quantification of epistemic uncertainty.", "motivation": "To address the limitations of classical probability in capturing epistemic uncertainty, the paper leverages imprecise probability theory to provide richer uncertainty models and introduces a metric for their comparison.", "method": "The IIPM framework is based on Choquet integrals, extending classical IPMs to capacities, a broad class of imprecise probability models. It includes theoretical validation and practical applications like Maximum Mean Imprecision (MMI) for EU quantification.", "result": "IIPM serves as a valid metric under certain conditions and supports weak convergence of capacities. MMI, derived from IIPM, outperforms established EU measures in selective classification tasks, especially in high-class scenarios.", "conclusion": "The work advances imprecise probabilistic machine learning by providing a principled framework for comparing and quantifying epistemic uncertainty, validated through empirical performance."}}
{"id": "2408.07221", "pdf": "https://arxiv.org/pdf/2408.07221", "abs": "https://arxiv.org/abs/2408.07221", "authors": ["Patrick Kage", "Jay C. Rothenberger", "Pavlos Andreadis", "Dimitrios I. Diochnos"], "title": "A Review of Pseudo-Labeling for Computer Vision", "categories": ["cs.CV", "cs.LG", "I.2.0; I.5.4; I.4.0"], "comment": "40 pages, 4 figures, 2 tables", "summary": "Deep neural models have achieved state of the art performance on a wide range\nof problems in computer science, especially in computer vision. However, deep\nneural networks often require large datasets of labeled samples to generalize\neffectively, and an important area of active research is semi-supervised\nlearning, which attempts to instead utilize large quantities of (easily\nacquired) unlabeled samples. One family of methods in this space is\npseudo-labeling, a class of algorithms that use model outputs to assign labels\nto unlabeled samples which are then used as labeled samples during training.\nSuch assigned labels, called pseudo-labels, are most commonly associated with\nthe field of semi-supervised learning. In this work we explore a broader\ninterpretation of pseudo-labels within both self-supervised and unsupervised\nmethods. By drawing the connection between these areas we identify new\ndirections when advancements in one area would likely benefit others, such as\ncurriculum learning and self-supervised regularization.", "AI": {"tldr": "The paper explores pseudo-labeling in semi-supervised, self-supervised, and unsupervised learning, identifying cross-domain benefits.", "motivation": "Deep neural networks require large labeled datasets; semi-supervised learning leverages unlabeled data, with pseudo-labeling as a key method.", "method": "The study broadens pseudo-labeling's scope to self-supervised and unsupervised methods, linking these areas.", "result": "Connections between pseudo-labeling methods reveal potential advancements like curriculum learning and self-supervised regularization.", "conclusion": "Expanding pseudo-labeling's application can drive progress across learning paradigms."}}
{"id": "2409.03327", "pdf": "https://arxiv.org/pdf/2409.03327", "abs": "https://arxiv.org/abs/2409.03327", "authors": ["A. Ram\u00edrez-de-Arellano", "F. G. C. Cabarle", "D. Orellana-Mart\u00edn", "M. J. P\u00e9rez-Jim\u00e9nez"], "title": "Normal forms in Virus Machines", "categories": ["cs.CL", "cs.FL", "68Q07 (Primary) 68Q10, 68R01 (Secondary)", "F.0; F.1.1"], "comment": "24 pages, 14 figures", "summary": "In the present work, we further study the computational power of virus\nmachines (VMs in short).VMs provide a computing paradigm inspired by the\ntransmission and replication networks of viruses.VMs consist of process units\n(called hosts) structured by a directed graph whose arcs are called channels\nand an instruction graph that controls the transmissions of virus objects among\nhosts. The present work complements our understanding of the computing power of\nVMs by introducing normal forms; these expressions restrict the features in a\ngiven computing model.Some of the features that we restrict in our normal forms\ninclude (a) the number of hosts, (b) the number of instructions, and (c) the\nnumber of virus objects in each host. After we recall some known results on the\ncomputing power of VMs we give our series of normal forms, such as the size of\nthe loops in the network, proving new characterisations of family of sets, such\nas finite sets, semilinear sets, or recursively enumerable sets (NRE).", "AI": {"tldr": "The paper explores the computational power of virus machines (VMs) by introducing normal forms that restrict features like host count, instructions, and virus objects, leading to new characterizations of sets like finite, semilinear, and recursively enumerable sets.", "motivation": "To deepen understanding of VMs' computational capabilities by defining normal forms that limit specific model features.", "method": "Introduces normal forms restricting VM features (hosts, instructions, virus objects) and analyzes their impact on computational power.", "result": "Proves new characterizations of sets (finite, semilinear, recursively enumerable) through these normal forms.", "conclusion": "Normal forms provide insights into VMs' computational limits and expand theoretical understanding of their power."}}
{"id": "2505.10819", "pdf": "https://arxiv.org/pdf/2505.10819", "abs": "https://arxiv.org/abs/2505.10819", "authors": ["Wasu Top Piriyakulkij", "Yichao Liang", "Hao Tang", "Adrian Weller", "Marta Kryven", "Kevin Ellis"], "title": "PoE-World: Compositional World Modeling with Products of Programmatic Experts", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Learning how the world works is central to building AI agents that can adapt\nto complex environments. Traditional world models based on deep learning demand\nvast amounts of training data, and do not flexibly update their knowledge from\nsparse observations. Recent advances in program synthesis using Large Language\nModels (LLMs) give an alternate approach which learns world models represented\nas source code, supporting strong generalization from little data. To date,\napplication of program-structured world models remains limited to natural\nlanguage and grid-world domains. We introduce a novel program synthesis method\nfor effectively modeling complex, non-gridworld domains by representing a world\nmodel as an exponentially-weighted product of programmatic experts (PoE-World)\nsynthesized by LLMs. We show that this approach can learn complex, stochastic\nworld models from just a few observations. We evaluate the learned world models\nby embedding them in a model-based planning agent, demonstrating efficient\nperformance and generalization to unseen levels on Atari's Pong and Montezuma's\nRevenge. We release our code and display the learned world models and videos of\nthe agent's gameplay at https://topwasu.github.io/poe-world.", "AI": {"tldr": "A novel program synthesis method (PoE-World) uses LLMs to create world models as code, enabling efficient learning from sparse data and strong generalization in complex domains like Atari games.", "motivation": "Traditional deep learning world models require extensive data and lack flexibility. Program synthesis with LLMs offers a promising alternative for adaptable, data-efficient world modeling.", "method": "The approach represents world models as exponentially-weighted products of programmatic experts (PoE-World) synthesized by LLMs, learning from few observations.", "result": "The method successfully learns complex, stochastic world models and enables efficient planning and generalization in Atari games like Pong and Montezuma's Revenge.", "conclusion": "PoE-World demonstrates the potential of program synthesis for scalable, adaptable world modeling, with applications in AI agents for complex environments."}}
{"id": "2505.16215", "pdf": "https://arxiv.org/pdf/2505.16215", "abs": "https://arxiv.org/abs/2505.16215", "authors": ["Md Ashraf Uddin", "Nam H. Chu", "Reza Rafeh", "Mutaz Barika"], "title": "A Scalable Hierarchical Intrusion Detection System for Internet of Vehicles", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Due to its nature of dynamic, mobility, and wireless data transfer, the\nInternet of Vehicles (IoV) is prone to various cyber threats, ranging from\nspoofing and Distributed Denial of Services (DDoS) attacks to malware. To\nsafeguard the IoV ecosystem from intrusions, malicious activities, policy\nviolations, intrusion detection systems (IDS) play a critical role by\ncontinuously monitoring and analyzing network traffic to identify and mitigate\npotential threats in real-time. However, most existing research has focused on\ndeveloping centralized, machine learning-based IDS systems for IoV without\naccounting for its inherently distributed nature. Due to intensive computing\nrequirements, these centralized systems often rely on the cloud to detect cyber\nthreats, increasing delay of system response. On the other hand, edge nodes\ntypically lack the necessary resources to train and deploy complex machine\nlearning algorithms. To address this issue, this paper proposes an effective\nhierarchical classification framework tailored for IoV networks. Hierarchical\nclassification allows classifiers to be trained and tested at different levels,\nenabling edge nodes to detect specific types of attacks independently. With\nthis approach, edge nodes can conduct targeted attack detection while\nleveraging cloud nodes for comprehensive threat analysis and support. Given the\nresource constraints of edge nodes, we have employed the Boruta feature\nselection method to reduce data dimensionality, optimizing processing\nefficiency. To evaluate our proposed framework, we utilize the latest IoV\nsecurity dataset CIC-IoV2024, achieving promising results that demonstrate the\nfeasibility and effectiveness of our models in securing IoV networks.", "AI": {"tldr": "Proposes a hierarchical classification framework for intrusion detection in IoV, balancing edge and cloud resources for efficient threat detection.", "motivation": "Existing centralized IDS systems for IoV are inefficient due to high latency and resource constraints at edge nodes, necessitating a distributed approach.", "method": "Uses hierarchical classification and Boruta feature selection to optimize edge node processing, with cloud support for comprehensive analysis.", "result": "Demonstrates feasibility and effectiveness using the CIC-IoV2024 dataset.", "conclusion": "The framework efficiently addresses IoV security challenges by leveraging edge-cloud collaboration."}}
{"id": "2408.15519", "pdf": "https://arxiv.org/pdf/2408.15519", "abs": "https://arxiv.org/abs/2408.15519", "authors": ["Pratik K. Mishra", "Irene Ballester", "Andrea Iaboni", "Bing Ye", "Kristine Newman", "Alex Mihailidis", "Shehroz S. Khan"], "title": "Depth-Weighted Detection of Behaviours of Risk in People with Dementia using Cameras", "categories": ["cs.CV"], "comment": null, "summary": "The behavioural and psychological symptoms of dementia, such as agitation and\naggression, present a significant health and safety risk in residential care\nsettings. Many care facilities have video cameras in place for digital\nmonitoring of public spaces, which can be leveraged to develop an automated\nbehaviours of risk detection system that can alert the staff to enable timely\nintervention and prevent the situation from escalating. However, one of the\nchallenges in our previous study was the presence of false alarms due to\ndisparate importance of events based on distance. To address this issue, we\nproposed a novel depth-weighted loss to enforce equivalent importance to the\nevents happening both near and far from the cameras; thus, helping to reduce\nfalse alarms. We further propose to utilize the training outliers to determine\nthe anomaly threshold. The data from nine dementia participants across three\ncameras in a specialized dementia unit were used for training. The proposed\napproach obtained the best area under receiver operating characteristic curve\nperformance of 0.852, 0.81 and 0.768, respectively, for the three cameras.\nAblation analysis was conducted for the individual components of the proposed\napproach and effect of frame size and frame rate. The performance of the\nproposed approach was investigated for cross-camera, participant-specific and\nsex-specific behaviours of risk detection. The proposed approach performed\nreasonably well in reducing false alarms. This motivates further research to\nmake the system more suitable for deployment in care facilities.", "AI": {"tldr": "The paper proposes a depth-weighted loss method to reduce false alarms in automated dementia behavior detection using video cameras, achieving improved performance metrics.", "motivation": "Addressing false alarms in dementia behavior monitoring due to distance disparities, aiming for timely staff intervention.", "method": "Proposed a depth-weighted loss for equal event importance and used training outliers for anomaly threshold. Tested on data from nine dementia participants.", "result": "Achieved AUC scores of 0.852, 0.81, and 0.768 for three cameras, with reduced false alarms.", "conclusion": "The approach shows promise for deployment in care facilities, warranting further research."}}
{"id": "2409.18199", "pdf": "https://arxiv.org/pdf/2409.18199", "abs": "https://arxiv.org/abs/2409.18199", "authors": ["Yihong Liu", "Haotian Ye", "Chunlan Ma", "Mingyang Wang", "Hinrich Sch\u00fctze"], "title": "LangSAMP: Language-Script Aware Multilingual Pretraining", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "Recent multilingual pretrained language models (mPLMs) often avoid using\nlanguage embeddings -- learnable vectors assigned to individual languages.\nHowever, this places a significant burden on token representations to encode\nall language-specific information, which may hinder language neutrality. To\naddress this limitation, we propose Language-Script Aware Multilingual\nPretraining (LangSAMP), a method that incorporates both language and script\nembeddings to enhance representation learning. Specifically, we integrate these\nembeddings into the output of the Transformer blocks before passing the final\nrepresentations to the language modeling head for prediction. We apply LangSAMP\nto the continual pretraining of XLM-R on a highly multilingual corpus covering\nmore than 500 languages. The resulting model consistently outperforms the\nbaseline in zero-shot crosslingual transfer across diverse downstream tasks.\nExtensive analysis reveals that language and script embeddings capture\nlanguage- and script-specific nuances, which benefits more language-neutral\nrepresentations, proven by improved pairwise cosine similarity. In our case\nstudy, we also show that language and script embeddings can be used to select\nbetter source languages for crosslingual transfer. We make our code and models\npublicly available at https://github.com/cisnlp/LangSAMP.", "AI": {"tldr": "LangSAMP enhances multilingual pretraining by incorporating language and script embeddings, improving language neutrality and crosslingual transfer performance.", "motivation": "Multilingual pretrained models often lack language embeddings, burdening token representations and hindering language neutrality.", "method": "LangSAMP integrates language and script embeddings into Transformer outputs before prediction, applied to XLM-R pretraining on 500+ languages.", "result": "LangSAMP outperforms baselines in zero-shot crosslingual transfer and improves language-neutral representations, as shown by cosine similarity.", "conclusion": "Language and script embeddings enhance representation learning and aid in selecting better source languages for transfer."}}
{"id": "2505.12822", "pdf": "https://arxiv.org/pdf/2505.12822", "abs": "https://arxiv.org/abs/2505.12822", "authors": ["Jing Liu", "Haozheng Wang", "Yueheng Li"], "title": "Emergent Specialization: Rare Token Neurons in Language Models", "categories": ["cs.AI"], "comment": "9 pages, 6 figures", "summary": "Large language models struggle with representing and generating rare tokens\ndespite their importance in specialized domains. In this study, we identify\nneuron structures with exceptionally strong influence on language model's\nprediction of rare tokens, termed as rare token neurons, and investigate the\nmechanism for their emergence and behavior. These neurons exhibit a\ncharacteristic three-phase organization (plateau, power-law, and rapid decay)\nthat emerges dynamically during training, evolving from a homogeneous initial\nstate to a functionally differentiated architecture. In the activation space,\nrare token neurons form a coordinated subnetwork that selectively co-activates\nwhile avoiding co-activation with other neurons. This functional specialization\npotentially correlates with the development of heavy-tailed weight\ndistributions, suggesting a statistical mechanical basis for emergent\nspecialization.", "AI": {"tldr": "The paper identifies rare token neurons in large language models, revealing their three-phase organization and coordinated subnetwork behavior, suggesting a statistical basis for their specialization.", "motivation": "To understand how rare tokens are represented and generated in language models, despite their challenges in specialized domains.", "method": "Identified rare token neurons, analyzed their three-phase organization during training, and investigated their activation patterns and weight distributions.", "result": "Rare token neurons form a coordinated subnetwork with selective co-activation and exhibit a dynamic three-phase structure, correlating with heavy-tailed weight distributions.", "conclusion": "The study provides insights into the emergent specialization of rare token neurons, suggesting a statistical mechanical basis for their behavior."}}
{"id": "2505.16244", "pdf": "https://arxiv.org/pdf/2505.16244", "abs": "https://arxiv.org/abs/2505.16244", "authors": ["Masanari Kimura", "Howard Bondell"], "title": "Generalized Power Priors for Improved Bayesian Inference with Historical Data", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "The power prior is a class of informative priors designed to incorporate\nhistorical data alongside current data in a Bayesian framework. It includes a\npower parameter that controls the influence of historical data, providing\nflexibility and adaptability. A key property of the power prior is that the\nresulting posterior minimizes a linear combination of KL divergences between\ntwo pseudo-posterior distributions: one ignoring historical data and the other\nfully incorporating it. We extend this framework by identifying the posterior\ndistribution as the minimizer of a linear combination of Amari's\n$\\alpha$-divergence, a generalization of KL divergence. We show that this\ngeneralization can lead to improved performance by allowing for the data to\nadapt to appropriate choices of the $\\alpha$ parameter. Theoretical properties\nof this generalized power posterior are established, including behavior as a\ngeneralized geodesic on the Riemannian manifold of probability distributions,\noffering novel insights into its geometric interpretation.", "AI": {"tldr": "The paper extends the power prior framework by generalizing the KL divergence to Amari's \u03b1-divergence, improving adaptability and performance.", "motivation": "To enhance the flexibility and performance of the power prior by incorporating a more general divergence measure.", "method": "Extends the power prior using Amari's \u03b1-divergence, analyzes theoretical properties, and explores geometric interpretations.", "result": "The generalized power posterior shows improved adaptability and offers novel geometric insights.", "conclusion": "The extension provides a more flexible and theoretically rich framework for incorporating historical data in Bayesian analysis."}}
{"id": "2408.15966", "pdf": "https://arxiv.org/pdf/2408.15966", "abs": "https://arxiv.org/abs/2408.15966", "authors": ["Yuan Tang", "Xu Han", "Xianzhi Li", "Qiao Yu", "Jinfeng Xu", "Yixue Hao", "Long Hu", "Min Chen"], "title": "More Text, Less Point: Towards 3D Data-Efficient Point-Language Understanding", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Enabling Large Language Models (LLMs) to comprehend the 3D physical world\nremains a significant challenge. Due to the lack of large-scale 3D-text pair\ndatasets, the success of LLMs has yet to be replicated in 3D understanding. In\nthis paper, we rethink this issue and propose a new task: 3D Data-Efficient\nPoint-Language Understanding. The goal is to enable LLMs to achieve robust 3D\nobject understanding with minimal 3D point cloud and text data pairs. To\naddress this task, we introduce GreenPLM, which leverages more text data to\ncompensate for the lack of 3D data. First, inspired by using CLIP to align\nimages and text, we utilize a pre-trained point cloud-text encoder to map the\n3D point cloud space to the text space. This mapping leaves us to seamlessly\nconnect the text space with LLMs. Once the point-text-LLM connection is\nestablished, we further enhance text-LLM alignment by expanding the\nintermediate text space, thereby reducing the reliance on 3D point cloud data.\nSpecifically, we generate 6M free-text descriptions of 3D objects, and design a\nthree-stage training strategy to help LLMs better explore the intrinsic\nconnections between different modalities. To achieve efficient modality\nalignment, we design a zero-parameter cross-attention module for token pooling.\nExtensive experimental results show that GreenPLM requires only 12% of the 3D\ntraining data used by existing state-of-the-art models to achieve superior 3D\nunderstanding. Remarkably, GreenPLM also achieves competitive performance using\ntext-only data. The code and weights are available at:\nhttps://github.com/TangYuan96/GreenPLM.", "AI": {"tldr": "GreenPLM enables LLMs to understand 3D objects with minimal 3D-text data by leveraging text data and a novel training strategy.", "motivation": "The challenge of enabling LLMs to comprehend 3D worlds due to limited 3D-text datasets.", "method": "Uses a pre-trained point cloud-text encoder, generates 6M text descriptions, and employs a three-stage training strategy with a zero-parameter cross-attention module.", "result": "Achieves superior 3D understanding with only 12% of the 3D data used by SOTA models and performs well with text-only data.", "conclusion": "GreenPLM effectively bridges the gap between 3D and text modalities, reducing reliance on large 3D datasets."}}
{"id": "2410.05254", "pdf": "https://arxiv.org/pdf/2410.05254", "abs": "https://arxiv.org/abs/2410.05254", "authors": ["Eilam Shapira", "Omer Madmon", "Itamar Reinman", "Samuel Joseph Amouyal", "Roi Reichart", "Moshe Tennenholtz"], "title": "GLEE: A Unified Framework and Benchmark for Language-based Economic Environments", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.GT", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) show significant potential in economic and\nstrategic interactions, where communication via natural language is often\nprevalent. This raises key questions: Do LLMs behave rationally? How do they\nperform compared to humans? Do they tend to reach an efficient and fair\noutcome? What is the role of natural language in strategic interaction? How do\ncharacteristics of the economic environment influence these dynamics? These\nquestions become crucial concerning the economic and societal implications of\nintegrating LLM-based agents into real-world data-driven systems, such as\nonline retail platforms and recommender systems. To answer these questions, we\nintroduce a benchmark for standardizing research on two-player, sequential,\nlanguage-based games. Inspired by the economic literature, we define three base\nfamilies of games with consistent parameterization, degrees of freedom and\neconomic measures to evaluate agents' performance (self-gain), as well as the\ngame outcome (efficiency and fairness). We develop an open-source framework for\ninteraction simulation and analysis, and utilize it to collect a dataset of LLM\nvs. LLM interactions across numerous game configurations and an additional\ndataset of human vs. LLM interactions. Through extensive experimentation, we\ndemonstrate how our framework and dataset can be used to: (i) compare the\nbehavior of LLM-based agents in various economic contexts; (ii) evaluate agents\nin both individual and collective performance measures; and (iii) quantify the\neffect of the economic characteristics of the environments on the behavior of\nagents. Our results suggest that the market parameters, as well as the choice\nof the LLMs, tend to have complex and interdependent effects on the economic\noutcome, which calls for careful design and analysis of the language-based\neconomic ecosystem.", "AI": {"tldr": "The paper introduces a benchmark for studying LLMs in strategic interactions, evaluating their rationality, performance, and outcomes in language-based games.", "motivation": "To understand LLMs' behavior in economic interactions and their societal implications when integrated into real-world systems.", "method": "Developed a benchmark with three game families, an open-source framework for simulation, and datasets of LLM vs. LLM and human vs. LLM interactions.", "result": "Market parameters and LLM choice have complex, interdependent effects on economic outcomes, requiring careful ecosystem design.", "conclusion": "The framework and dataset enable systematic study of LLMs in strategic contexts, highlighting the need for nuanced analysis in language-based economic systems."}}
{"id": "2505.14510", "pdf": "https://arxiv.org/pdf/2505.14510", "abs": "https://arxiv.org/abs/2505.14510", "authors": ["Haishi Bai", "Jozo Dujmovic", "Jianwu Wang"], "title": "BACON: A fully explainable AI model with graded logic for decision making problems", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As machine learning models and autonomous agents are increasingly deployed in\nhigh-stakes, real-world domains such as healthcare, security, finance, and\nrobotics, the need for transparent and trustworthy explanations has become\ncritical. To ensure end-to-end transparency of AI decisions, we need models\nthat are not only accurate but also fully explainable and human-tunable. We\nintroduce BACON, a novel framework for automatically training explainable AI\nmodels for decision making problems using graded logic. BACON achieves high\npredictive accuracy while offering full structural transparency and precise,\nlogic-based symbolic explanations, enabling effective human-AI collaboration\nand expert-guided refinement. We evaluate BACON with a diverse set of\nscenarios: classic Boolean approximation, Iris flower classification, house\npurchasing decisions and breast cancer diagnosis. In each case, BACON provides\nhigh-performance models while producing compact, human-verifiable decision\nlogic. These results demonstrate BACON's potential as a practical and\nprincipled approach for delivering crisp, trustworthy explainable AI.", "AI": {"tldr": "BACON is a framework for training explainable AI models using graded logic, achieving high accuracy and transparency for human-AI collaboration.", "motivation": "The need for transparent and trustworthy AI explanations in high-stakes domains like healthcare and finance.", "method": "BACON uses graded logic to train explainable models, ensuring structural transparency and symbolic explanations.", "result": "BACON delivers high-performance models with compact, human-verifiable decision logic across diverse scenarios.", "conclusion": "BACON is a practical and principled approach for trustworthy explainable AI."}}
{"id": "2505.16251", "pdf": "https://arxiv.org/pdf/2505.16251", "abs": "https://arxiv.org/abs/2505.16251", "authors": ["Masanari Kimura"], "title": "Graph-Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Label shift adaptation aims to recover target class priors when the labelled\nsource distribution $P$ and the unlabelled target distribution $Q$ share $P(X\n\\mid Y) = Q(X \\mid Y)$ but $P(Y) \\neq Q(Y)$. Classical black-box shift\nestimators invert an empirical confusion matrix of a frozen classifier,\nproducing a brittle point estimate that ignores sampling noise and similarity\namong classes. We present Graph-Smoothed Bayesian BBSE (GS-B$^3$SE), a fully\nprobabilistic alternative that places Laplacian-Gaussian priors on both target\nlog-priors and confusion-matrix columns, tying them together on a\nlabel-similarity graph. The resulting posterior is tractable with HMC or a fast\nblock Newton-CG scheme. We prove identifiability, $N^{-1/2}$ contraction,\nvariance bounds that shrink with the graph's algebraic connectivity, and\nrobustness to Laplacian misspecification. We also reinterpret GS-B$^3$SE\nthrough information geometry, showing that it generalizes existing shift\nestimators.", "AI": {"tldr": "GS-B$^3$SE is a probabilistic method for label shift adaptation, using graph-based priors for robust estimation.", "motivation": "Classical methods for label shift adaptation are brittle and ignore sampling noise and class similarities.", "method": "GS-B$^3$SE uses Laplacian-Gaussian priors on target log-priors and confusion-matrix columns, tied via a label-similarity graph, with tractable posterior inference.", "result": "The method ensures identifiability, $N^{-1/2}$ contraction, variance bounds, and robustness to misspecification.", "conclusion": "GS-B$^3$SE generalizes existing shift estimators and offers a robust, probabilistic alternative."}}
{"id": "2409.17045", "pdf": "https://arxiv.org/pdf/2409.17045", "abs": "https://arxiv.org/abs/2409.17045", "authors": ["Phillip Mueller", "Sebastian Mueller", "Lars Mikelsons"], "title": "GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We provide a dataset for enabling Deep Generative Models (DGMs) in\nengineering design and propose methods to automate data labeling by utilizing\nlarge-scale foundation models. GeoBiked is curated to contain 4 355 bicycle\nimages, annotated with structural and technical features and is used to\ninvestigate two automated labeling techniques: The utilization of consolidated\nlatent features (Hyperfeatures) from image-generation models to detect\ngeometric correspondences (e.g. the position of the wheel center) in structural\nimages and the generation of diverse text descriptions for structural images.\nGPT-4o, a vision-language-model (VLM), is instructed to analyze images and\nproduce diverse descriptions aligned with the system-prompt. By representing\ntechnical images as Diffusion-Hyperfeatures, drawing geometric correspondences\nbetween them is possible. The detection accuracy of geometric points in unseen\nsamples is improved by presenting multiple annotated source images. GPT-4o has\nsufficient capabilities to generate accurate descriptions of technical images.\nGrounding the generation only on images leads to diverse descriptions but\ncauses hallucinations, while grounding it on categorical labels restricts the\ndiversity. Using both as input balances creativity and accuracy. Successfully\nusing Hyperfeatures for geometric correspondence suggests that this approach\ncan be used for general point-detection and annotation tasks in technical\nimages. Labeling such images with text descriptions using VLMs is possible, but\ndependent on the models detection capabilities, careful prompt-engineering and\nthe selection of input information. Applying foundation models in engineering\ndesign is largely unexplored. We aim to bridge this gap with a dataset to\nexplore training, finetuning and conditioning DGMs in this field and suggesting\napproaches to bootstrap foundation models to process technical images.", "AI": {"tldr": "The paper introduces GeoBiked, a dataset for Deep Generative Models in engineering design, and explores automated labeling using foundation models like GPT-4o and Diffusion-Hyperfeatures.", "motivation": "To bridge the gap in applying foundation models to engineering design by providing a dataset and methods for automated data labeling.", "method": "Uses Hyperfeatures for geometric correspondences and GPT-4o for text descriptions, balancing creativity and accuracy.", "result": "Improved geometric point detection and accurate text descriptions, though hallucinations occur without grounding.", "conclusion": "Foundation models can automate labeling in engineering design, but require careful prompt-engineering and input selection."}}
{"id": "2410.08085", "pdf": "https://arxiv.org/pdf/2410.08085", "abs": "https://arxiv.org/abs/2410.08085", "authors": ["Yuan Sui", "Yufei He", "Zifeng Ding", "Bryan Hooi"], "title": "Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "This paper has been accepted by ACL 2025", "summary": "Recent works integrating Knowledge Graphs (KGs) have shown promising\nimprovements in enhancing the reasoning capabilities of Large Language Models\n(LLMs). However, existing benchmarks primarily focus on closed-ended tasks,\nleaving a gap in evaluating performance on more complex, real-world scenarios.\nThis limitation also hinders a thorough assessment of KGs' potential to reduce\nhallucinations in LLMs. To address this, we introduce OKGQA, a new benchmark\nspecifically designed to evaluate LLMs augmented with KGs in open-ended,\nreal-world question answering settings. OKGQA reflects practical complexities\nthrough diverse question types and incorporates metrics to quantify both\nhallucination rates and reasoning improvements in LLM+KG models. To consider\nthe scenarios in which KGs may contain varying levels of errors, we propose a\nbenchmark variant, OKGQA-P, to assess model performance when the semantics and\nstructure of KGs are deliberately perturbed and contaminated. In this paper, we\naims to (1) explore whether KGs can make LLMs more trustworthy in an open-ended\nsetting, and (2) conduct a comparative analysis to shed light on method design.\nWe believe this study can facilitate a more complete performance comparison and\nencourages continuous improvement in integrating KGs with LLMs to mitigate\nhallucination, and make LLMs more trustworthy. Code and data are released at\nhttps://github.com/Y-Sui/OKGQA.", "AI": {"tldr": "OKGQA is a new benchmark for evaluating LLMs augmented with KGs in open-ended, real-world QA, addressing gaps in existing benchmarks and assessing KG impact on hallucination reduction.", "motivation": "Existing benchmarks focus on closed-ended tasks, lacking evaluation in complex, real-world scenarios and thorough assessment of KGs' role in reducing LLM hallucinations.", "method": "Introduces OKGQA for open-ended QA, with diverse question types and metrics for hallucination and reasoning. Proposes OKGQA-P to test KG robustness under perturbations.", "result": "Aims to show if KGs enhance LLM trustworthiness in open-ended settings and provide insights for method design.", "conclusion": "OKGQA facilitates comprehensive performance comparison and encourages KG-LLM integration to mitigate hallucinations and improve trustworthiness."}}
{"id": "2505.14524", "pdf": "https://arxiv.org/pdf/2505.14524", "abs": "https://arxiv.org/abs/2505.14524", "authors": ["Richard \u0160l\u00e9her", "William Brach", "Tibor Sloboda", "Kristi\u00e1n Ko\u0161\u0165\u00e1l", "Lukas Galke"], "title": "Guarded Query Routing for Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Query routing, the task to route user queries to different large language\nmodel (LLM) endpoints, can be considered as a text classification problem.\nHowever, out-of-distribution queries must be handled properly, as those could\nbe questions about unrelated domains, queries in other languages, or even\ncontain unsafe text. Here, we thus study a guarded query routing problem, for\nwhich we first introduce the Guarded Query Routing Benchmark (GQR-Bench), which\ncovers three exemplary target domains (law, finance, and healthcare), and seven\ndatasets to test robustness against out-of-distribution queries. We then use\nGQR-Bench to contrast the effectiveness and efficiency of LLM-based routing\nmechanisms (GPT-4o-mini, Llama-3.2-3B, and Llama-3.1-8B), standard LLM-based\nguardrail approaches (LlamaGuard and NVIDIA NeMo Guardrails), continuous\nbag-of-words classifiers (WideMLP, fastText), and traditional machine learning\nmodels (SVM, XGBoost). Our results show that WideMLP, enhanced with\nout-of-domain detection capabilities, yields the best trade-off between\naccuracy (88%) and speed (<4ms). The embedding-based fastText excels at speed\n(<1ms) with acceptable accuracy (80%), whereas LLMs yield the highest accuracy\n(91%) but are comparatively slow (62ms for local Llama-3.1:8B and 669ms for\nremote GPT-4o-mini calls). Our findings challenge the automatic reliance on\nLLMs for (guarded) query routing and provide concrete recommendations for\npractical applications. GQR-Bench will be released as a Python package -- gqr.", "AI": {"tldr": "The paper introduces GQR-Bench for guarded query routing, comparing methods like LLMs, guardrails, and traditional models, finding WideMLP offers the best balance of accuracy and speed.", "motivation": "To address the challenge of routing queries to LLM endpoints while handling out-of-distribution queries effectively.", "method": "Introduces GQR-Bench and evaluates LLM-based routing, guardrails, and traditional models (e.g., WideMLP, fastText, SVM, XGBoost).", "result": "WideMLP with out-of-domain detection achieves 88% accuracy and <4ms speed, while LLMs are slower but more accurate (91%).", "conclusion": "LLMs aren't always optimal for query routing; practical recommendations favor WideMLP or fastText for speed-accuracy trade-offs."}}
{"id": "2505.16257", "pdf": "https://arxiv.org/pdf/2505.16257", "abs": "https://arxiv.org/abs/2505.16257", "authors": ["Masanari Kimura"], "title": "Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This study develops a higher-order asymptotic framework for test-time\nadaptation (TTA) of Batch Normalization (BN) statistics under distribution\nshift by integrating classical Edgeworth expansion and saddlepoint\napproximation techniques with a novel one-step M-estimation perspective. By\nanalyzing the statistical discrepancy between training and test distributions,\nwe derive an Edgeworth expansion for the normalized difference in BN means and\nobtain an optimal weighting parameter that minimizes the mean-squared error of\nthe adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows\nus to derive higher-order local asymptotic normality results, which incorporate\nskewness and other higher moments into the estimator's behavior. Moreover, we\nquantify the trade-offs among bias, variance, and skewness in the adaptation\nprocess and establish a corresponding generalization bound on the model risk.\nThe refined saddlepoint approximations further deliver uniformly accurate\ndensity and tail probability estimates for the BN TTA statistic. These\ntheoretical insights provide a comprehensive understanding of how higher-order\ncorrections and robust one-step updating can enhance the reliability and\nperformance of BN layers in adapting to changing data distributions.", "AI": {"tldr": "The paper introduces a higher-order asymptotic framework for test-time adaptation of Batch Normalization statistics, using Edgeworth expansion and saddlepoint approximation to improve reliability under distribution shifts.", "motivation": "To address the statistical discrepancy between training and test distributions and enhance the adaptability of BN layers.", "method": "Integrates Edgeworth expansion, saddlepoint approximation, and a one-step M-estimation perspective to analyze and optimize BN statistics adaptation.", "result": "Derives an optimal weighting parameter, higher-order asymptotic normality results, and quantifies trade-offs in bias, variance, and skewness.", "conclusion": "The framework provides theoretical insights for improving BN layer reliability and performance in adapting to distribution shifts."}}
{"id": "2410.15701", "pdf": "https://arxiv.org/pdf/2410.15701", "abs": "https://arxiv.org/abs/2410.15701", "authors": ["Yiping Ma", "Shiyu Hu", "Xuchen Li", "Yipei Wang", "Yuqing Chen", "Shiqing Liu", "Kang Hao Cheong"], "title": "When LLMs Learn to be Students: The SOEI Framework for Modeling and Evaluating Virtual Student Agents in Educational Interaction", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled intelligent\ntutoring systems, yet the development of LLM-based Virtual Student Agents\n(LVSAs) remains underexplored. Such agents are essential for teacher-facing\napplications, where simulating diverse learner traits can support adaptive\ninstruction and pedagogical skill development. However, current methods lack\nprincipled personality modeling, scalable evaluation of behavioral consistency,\nand empirical validation in interactive teaching settings. We propose the SOEI\nframework, a structured pipeline comprising Scene, Object, Evaluation, and\nInteraction, for constructing and evaluating personality-aligned LVSAs in\nclassroom scenarios. Leveraging Chinese language instruction as a cognitively\nand emotionally rich testbed, we generate five LVSAs based on Big Five traits\nthrough LoRA fine-tuning and expert-informed prompt design. Their behavioral\nrealism and personality coherence are assessed using a hybrid human & GPT-4\nevaluation and a multi-dimensional annotation protocol. Through controlled\nexperiments with real pre-service teachers, we demonstrate that LVSAs can\nelicit adaptive teaching strategies and maintain trait-consistent behavior\nacross multi-turn dialogues. Our results provide: (1) an educationally and\npsychologically grounded generation pipeline for LLM-based student agents; (2)\na hybrid, scalable evaluation framework for behavioral realism; and (3)\nempirical insights into the pedagogical utility of LVSAs in shaping\ninstructional adaptation. By embedding LVSAs into both generative modeling and\nhuman-in-the-loop teaching, SOEI bridges AI for Education (AI4Edu) and\nEducation for AI (Edu4AI), positioning classroom interaction as a rigorous\ntestbed for controllability, personality alignment, and human-likeness in large\nlanguage models.", "AI": {"tldr": "The paper introduces the SOEI framework for developing and evaluating personality-aligned Large Language Model-based Virtual Student Agents (LVSAs) in classroom settings, demonstrating their pedagogical utility.", "motivation": "To address gaps in principled personality modeling, scalable evaluation, and empirical validation of LVSAs for adaptive teaching and pedagogical skill development.", "method": "Proposes the SOEI framework (Scene, Object, Evaluation, Interaction) for constructing and evaluating LVSAs, using LoRA fine-tuning and expert-informed prompts to model Big Five traits. Hybrid human & GPT-4 evaluation assesses behavioral realism.", "result": "LVSAs elicited adaptive teaching strategies and maintained trait-consistent behavior in multi-turn dialogues, validated through controlled experiments with pre-service teachers.", "conclusion": "SOEI bridges AI for Education and Education for AI, offering a scalable pipeline for personality-aligned LVSAs and insights into their pedagogical utility."}}
{"id": "2410.09338", "pdf": "https://arxiv.org/pdf/2410.09338", "abs": "https://arxiv.org/abs/2410.09338", "authors": ["Jianhao Yan", "Futing Wang", "Yun Luo", "Yafu Li", "Yue Zhang"], "title": "Keys to Robust Edits: from Theoretical Insights to Practical Advances", "categories": ["cs.CL"], "comment": "ACL 2025 Main Conference", "summary": "Large language models (LLMs) struggle with maintaining accurate knowledge due\nto conflicting/outdated parametric memories. While locate-and-edit methods\naddress this, their reliance on models' internal representations leads to\nrobustness failures in long-context reasoning and paraphrased queries. We\nidentify a fundamental limitation of locate-and-edit methods: existing semantic\nkeys (for memory localization) cannot simultaneously satisfy robustness\n(context-invariant activation) and specificity (precise knowledge\ndiscrimination). Through theoretical error-bound analysis, we establish formal\ncriteria for effective editing. Our solution introduces \\textit{Robust Edit\nPathway (REP)}, a plug-and-play module that: (1) disentangles editing keys from\nnative model representations; (2) dynamically adjusts keys via contrastive\nlearning to achieve robustness-specificity balance. Extensive experiments\nacross various editing methods (ROME/MEMIT/R-ROME/EMMET), existing LLMs\n(LLaMA2, QWen, Mistral), and datasets (CounterFact, ZsRE) show that REP\nimproves success rate over robustness tests by up-to 66.4\\% while maintaining\nthe success rate unaffected. Our code can be found at\nhttps://github.com/ElliottYan/RobustKeyEdit .", "AI": {"tldr": "The paper introduces Robust Edit Pathway (REP), a plug-and-play module to improve the robustness and specificity of knowledge editing in large language models (LLMs).", "motivation": "LLMs struggle with maintaining accurate knowledge due to conflicting or outdated parametric memories, and existing locate-and-edit methods fail in long-context reasoning and paraphrased queries.", "method": "The authors propose REP, which disentangles editing keys from native model representations and dynamically adjusts keys via contrastive learning to balance robustness and specificity.", "result": "Experiments show REP improves success rates in robustness tests by up to 66.4% without affecting the original success rate.", "conclusion": "REP effectively addresses the limitations of locate-and-edit methods, providing a robust solution for knowledge editing in LLMs."}}
{"id": "2102.01295", "pdf": "https://arxiv.org/pdf/2102.01295", "abs": "https://arxiv.org/abs/2102.01295", "authors": ["Heecheol Kim", "Yoshiyuki Ohmura", "Yasuo Kuniyoshi"], "title": "Gaze-based dual resolution deep imitation learning for high-precision dexterous robot manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages. The supplementary video can be found at:\n  https://www.youtube.com/watch?v=ytpChcFqD5g Published in IEEE Robotics and\n  Automation Letters. Replaced to add video url in the manuscript", "summary": "A high-precision manipulation task, such as needle threading, is challenging.\nPhysiological studies have proposed connecting low-resolution peripheral vision\nand fast movement to transport the hand into the vicinity of an object, and\nusing high-resolution foveated vision to achieve the accurate homing of the\nhand to the object. The results of this study demonstrate that a deep imitation\nlearning based method, inspired by the gaze-based dual resolution visuomotor\ncontrol system in humans, can solve the needle threading task. First, we\nrecorded the gaze movements of a human operator who was teleoperating a robot.\nThen, we used only a high-resolution image around the gaze to precisely control\nthe thread position when it was close to the target. We used a low-resolution\nperipheral image to reach the vicinity of the target. The experimental results\nobtained in this study demonstrate that the proposed method enables precise\nmanipulation tasks using a general-purpose robot manipulator and improves\ncomputational efficiency. Data from this and related works are available at:\nhttps://sites.google.com/view/multi-task-fine.", "AI": {"tldr": "A deep imitation learning method, inspired by human gaze-based dual-resolution vision, successfully solves needle threading tasks by combining low-resolution peripheral vision for initial hand transport and high-resolution foveated vision for precise homing.", "motivation": "High-precision tasks like needle threading are challenging, and the study aims to replicate human visuomotor control using dual-resolution vision for robotic manipulation.", "method": "The approach records human gaze movements during teleoperation, using high-resolution images near the gaze for precise control and low-resolution peripheral images for initial positioning.", "result": "The method enables precise manipulation with a general-purpose robot, improving computational efficiency.", "conclusion": "The study demonstrates the effectiveness of dual-resolution visuomotor control in robotics for high-precision tasks."}}
{"id": "2505.16311", "pdf": "https://arxiv.org/pdf/2505.16311", "abs": "https://arxiv.org/abs/2505.16311", "authors": ["Marc Brooks", "Gabriel Durham", "Kihyuk Hong", "Ambuj Tewari"], "title": "Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "39 pages, 12 figures", "summary": "Recent advances in generative artificial intelligence (GenAI) models have\nenabled the generation of personalized content that adapts to up-to-date user\ncontext. While personalized decision systems are often modeled using bandit\nformulations, the integration of GenAI introduces new structure into otherwise\nclassical sequential learning problems. In GenAI-powered interventions, the\nagent selects a query, but the environment experiences a stochastic response\ndrawn from the generative model. Standard bandit methods do not explicitly\naccount for this structure, where actions influence rewards only through\nstochastic, observed treatments. We introduce generator-mediated\nbandit-Thompson sampling (GAMBITTS), a bandit approach designed for this\naction/treatment split, using mobile health interventions with large language\nmodel-generated text as a motivating case study. GAMBITTS explicitly models\nboth the treatment and reward generation processes, using information in the\ndelivered treatment to accelerate policy learning relative to standard methods.\nWe establish regret bounds for GAMBITTS by decomposing sources of uncertainty\nin treatment and reward, identifying conditions where it achieves stronger\nguarantees than standard bandit approaches. In simulation studies, GAMBITTS\nconsistently outperforms conventional algorithms by leveraging observed\ntreatments to more accurately estimate expected rewards.", "AI": {"tldr": "The paper introduces GAMBITTS, a bandit method for GenAI-powered interventions, improving policy learning by modeling treatment and reward processes.", "motivation": "To address the gap in standard bandit methods for GenAI-driven personalized content, where actions influence rewards through stochastic treatments.", "method": "Proposes GAMBITTS, a bandit approach that models treatment and reward generation, leveraging observed treatments for better reward estimation.", "result": "GAMBITTS outperforms conventional bandit methods in simulations and achieves stronger regret bounds under certain conditions.", "conclusion": "GAMBITTS effectively integrates GenAI into bandit problems, enhancing learning by accounting for treatment-response dynamics."}}
{"id": "2410.19552", "pdf": "https://arxiv.org/pdf/2410.19552", "abs": "https://arxiv.org/abs/2410.19552", "authors": ["Hosam Elgendy", "Ahmed Sharshar", "Ahmed Aboeitta", "Yasser Ashraf", "Mohsen Guizani"], "title": "GeoLLaVA: Efficient Fine-Tuned Vision-Language Models for Temporal Change Detection in Remote Sensing", "categories": ["cs.CV"], "comment": "14 pages, 5 figures, 3 tables", "summary": "Detecting temporal changes in geographical landscapes is critical for\napplications like environmental monitoring and urban planning. While remote\nsensing data is abundant, existing vision-language models (VLMs) often fail to\ncapture temporal dynamics effectively. This paper addresses these limitations\nby introducing an annotated dataset of video frame pairs to track evolving\ngeographical patterns over time. Using fine-tuning techniques like Low-Rank\nAdaptation (LoRA), quantized LoRA (QLoRA), and model pruning on models such as\nVideo-LLaVA and LLaVA-NeXT-Video, we significantly enhance VLM performance in\nprocessing remote sensing temporal changes. Results show significant\nimprovements, with the best performance achieving a BERT score of 0.864 and\nROUGE-1 score of 0.576, demonstrating superior accuracy in describing land-use\ntransformations.", "AI": {"tldr": "The paper introduces a dataset and fine-tuning techniques to improve vision-language models (VLMs) for detecting temporal changes in geographical landscapes, achieving high accuracy.", "motivation": "Existing VLMs struggle with temporal dynamics in remote sensing data, which is crucial for applications like environmental monitoring and urban planning.", "method": "The authors use annotated video frame pairs and fine-tuning techniques (LoRA, QLoRA, model pruning) on models like Video-LLaVA and LLaVA-NeXT-Video.", "result": "Significant improvements were achieved, with a BERT score of 0.864 and ROUGE-1 score of 0.576, showing superior accuracy in describing land-use changes.", "conclusion": "The proposed approach effectively enhances VLM performance for tracking geographical patterns over time."}}
{"id": "2410.10347", "pdf": "https://arxiv.org/pdf/2410.10347", "abs": "https://arxiv.org/abs/2410.10347", "authors": ["Jasper Dekoninck", "Maximilian Baader", "Martin Vechev"], "title": "A Unified Approach to Routing and Cascading for LLMs", "categories": ["cs.CL"], "comment": null, "summary": "The availability of a wide range of large language models (LLMs) embedded in\nvarious agentic systems has significantly increased the potential of model\nselection strategies to improve the cost-performance tradeoff. Existing\nstrategies involve either routing, where a single model is chosen per query, or\ncascading, which sequentially runs increasingly larger models until a\nsatisfactory answer is found. However, current approaches face three key\nlimitations: they (1) lack formal proofs of optimality, (2) fail to identify\nthe conditions under which these strategies are most effective to improve the\ncost-performance tradeoff, and (3) are unable to combine both paradigms for\nfurther improvements. To address these issues, we first derive a novel optimal\nstrategy for cascading and prove the optimality of an existing routing\nstrategy. Further, we propose cascade routing, a unified framework that\nintegrates routing and cascading into a theoretically optimal strategy. Through\nour analysis, we identify good quality estimators as the critical factor for\nthe success of model selection paradigms. Finally, in our experiments, we show\nthat cascade routing consistently outperforms the individual approaches by a\nlarge margin and we analyze quality estimators to determine when routing and/or\ncascading are useful paradigms for model selection.", "AI": {"tldr": "The paper introduces 'cascade routing,' a unified framework combining routing and cascading for optimal model selection in LLMs, addressing limitations of existing strategies.", "motivation": "Existing model selection strategies lack optimality proofs, fail to identify effective conditions, and cannot combine routing and cascading.", "method": "Derives an optimal cascading strategy, proves routing optimality, and proposes cascade routing, a unified framework.", "result": "Cascade routing outperforms individual approaches; quality estimators are critical for success.", "conclusion": "Cascade routing is a superior, theoretically optimal strategy for model selection in LLMs."}}
{"id": "2108.00385", "pdf": "https://arxiv.org/pdf/2108.00385", "abs": "https://arxiv.org/abs/2108.00385", "authors": ["Heecheol Kim", "Yoshiyuki Ohmura", "Yasuo Kuniyoshi"], "title": "Transformer-based deep imitation learning for dual-arm robot manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages. Accepted in 2021 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS)", "summary": "Deep imitation learning is promising for solving dexterous manipulation tasks\nbecause it does not require an environment model and pre-programmed robot\nbehavior. However, its application to dual-arm manipulation tasks remains\nchallenging. In a dual-arm manipulation setup, the increased number of state\ndimensions caused by the additional robot manipulators causes distractions and\nresults in poor performance of the neural networks. We address this issue using\na self-attention mechanism that computes dependencies between elements in a\nsequential input and focuses on important elements. A Transformer, a variant of\nself-attention architecture, is applied to deep imitation learning to solve\ndual-arm manipulation tasks in the real world. The proposed method has been\ntested on dual-arm manipulation tasks using a real robot. The experimental\nresults demonstrated that the Transformer-based deep imitation learning\narchitecture can attend to the important features among the sensory inputs,\ntherefore reducing distractions and improving manipulation performance when\ncompared with the baseline architecture without the self-attention mechanisms.\nData from this and related works are available at:\nhttps://sites.google.com/view/multi-task-fine.", "AI": {"tldr": "Transformer-based deep imitation learning improves dual-arm manipulation by reducing distractions with self-attention mechanisms.", "motivation": "Dual-arm manipulation tasks are challenging due to increased state dimensions, causing distractions and poor neural network performance.", "method": "A Transformer (self-attention architecture) is applied to deep imitation learning to focus on important sensory inputs.", "result": "The method reduces distractions and improves manipulation performance compared to baseline architectures.", "conclusion": "The Transformer-based approach effectively addresses challenges in dual-arm manipulation tasks."}}
{"id": "2505.16320", "pdf": "https://arxiv.org/pdf/2505.16320", "abs": "https://arxiv.org/abs/2505.16320", "authors": ["P. Huijse", "J. De Ridder", "L. Eyer", "L. Rimoldini", "B. Holl", "N. Chornay", "J. Roquette", "K. Nienartowicz", "G. Jevardat de Fombelle", "D. J. Fritzewski", "A. Kemp", "V. Vanlaer", "M. Vanrespaille", "H. Wang", "M. I. Carnerero", "C. M. Raiteri", "G. Marton", "M. Madar\u00e1sz", "G. Clementini", "P. Gavras", "C. Aerts"], "title": "Learning novel representations of variable sources from multi-modal $\\textit{Gaia}$ data via autoencoders", "categories": ["astro-ph.IM", "cs.LG"], "comment": "Manuscript resubmitted to Astronomy & Astrophysics after positive\n  referee report, 20 pages, 20 figures, 2 tables", "summary": "Gaia Data Release 3 (DR3) published for the first time epoch photometry,\nBP/RP (XP) low-resolution mean spectra, and supervised classification results\nfor millions of variable sources. This extensive dataset offers a unique\nopportunity to study their variability by combining multiple Gaia data\nproducts. In preparation for DR4, we propose and evaluate a machine learning\nmethodology capable of ingesting multiple Gaia data products to achieve an\nunsupervised classification of stellar and quasar variability. A dataset of 4\nmillion Gaia DR3 sources is used to train three variational autoencoders (VAE),\nwhich are artificial neural networks (ANNs) designed for data compression and\ngeneration. One VAE is trained on Gaia XP low-resolution spectra, another on a\nnovel approach based on the distribution of magnitude differences in the Gaia G\nband, and the third on folded Gaia G band light curves. Each Gaia source is\ncompressed into 15 numbers, representing the coordinates in a 15-dimensional\nlatent space generated by combining the outputs of these three models. The\nlearned latent representation produced by the ANN effectively distinguishes\nbetween the main variability classes present in Gaia DR3, as demonstrated\nthrough both supervised and unsupervised classification analysis of the latent\nspace. The results highlight a strong synergy between light curves and\nlow-resolution spectral data, emphasising the benefits of combining the\ndifferent Gaia data products. A two-dimensional projection of the latent\nvariables reveals numerous overdensities, most of which strongly correlate with\nastrophysical properties, showing the potential of this latent space for\nastrophysical discovery. We show that the properties of our novel latent\nrepresentation make it highly valuable for variability analysis tasks,\nincluding classification, clustering and outlier detection.", "AI": {"tldr": "The paper proposes a machine learning method using three VAEs to classify stellar and quasar variability in Gaia DR3 data, demonstrating effective unsupervised classification and highlighting the synergy between light curves and spectral data.", "motivation": "To leverage Gaia DR3's extensive dataset for unsupervised classification of variable sources, preparing for Gaia DR4.", "method": "Three VAEs trained on Gaia XP spectra, magnitude differences in the G band, and folded G band light curves, compressing data into a 15D latent space.", "result": "The latent space effectively distinguishes variability classes and reveals astrophysical correlations, proving useful for classification, clustering, and outlier detection.", "conclusion": "The method shows strong potential for astrophysical discovery and variability analysis tasks in Gaia data."}}
{"id": "2411.03226", "pdf": "https://arxiv.org/pdf/2411.03226", "abs": "https://arxiv.org/abs/2411.03226", "authors": ["Zakariae Belmekki", "Jun Li", "Patrick Reuter", "David Antonio G\u00f3mez J\u00e1uregui", "Karl Jenkins"], "title": "Feature Map Similarity Reduction in Convolutional Neural Networks", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "It has been observed that Convolutional Neural Networks (CNNs) suffer from\nredundancy in feature maps, leading to inefficient capacity utilization.\nEfforts to address this issue have largely focused on kernel orthogonality\nmethod. In this work, we theoretically and empirically demonstrate that kernel\northogonality does not necessarily lead to a reduction in feature map\nredundancy. Based on this analysis, we propose the Convolutional Similarity\nmethod to reduce feature map similarity, independently of the CNN's input. The\nConvolutional Similarity can be minimized as either a regularization term or an\niterative initialization method. Experimental results show that minimizing\nConvolutional Similarity not only improves classification accuracy but also\naccelerates convergence. Furthermore, our method enables the use of\nsignificantly smaller models to achieve the same level of performance,\npromoting a more efficient use of model capacity. Future work will focus on\ncoupling the iterative initialization method with the optimization momentum\nterm and examining the method's impact on generative frameworks.", "AI": {"tldr": "The paper challenges the effectiveness of kernel orthogonality in reducing feature map redundancy in CNNs and proposes the Convolutional Similarity method to address this issue, improving accuracy and efficiency.", "motivation": "CNNs suffer from feature map redundancy, and existing solutions like kernel orthogonality are ineffective. The paper aims to find a better method to reduce redundancy.", "method": "Proposes Convolutional Similarity, a method to reduce feature map similarity, usable as regularization or iterative initialization.", "result": "Minimizing Convolutional Similarity improves accuracy, speeds convergence, and allows smaller models for the same performance.", "conclusion": "The method enhances CNN efficiency and performance, with future work exploring its integration with optimization momentum and generative frameworks."}}
{"id": "2410.17477", "pdf": "https://arxiv.org/pdf/2410.17477", "abs": "https://arxiv.org/abs/2410.17477", "authors": ["Jerry Huang", "Prasanna Parthasarathi", "Mehdi Rezagholizadeh", "Boxing Chen", "Sarath Chandar"], "title": "Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to Findings of The 63rd Annual Meeting of the Association\n  for Computational Linguistics (ACL), 2025", "summary": "The growth in prominence of large language models (LLMs) in everyday life can\nbe largely attributed to their generative abilities, yet some of this is also\nowed to the risks and costs associated with their use. On one front is their\ntendency to hallucinate false or misleading information, limiting their\nreliability. On another is the increasing focus on the computational\nlimitations associated with traditional self-attention based LLMs, which has\nbrought about new alternatives, in particular recurrent models, meant to\novercome them. Yet it remains uncommon to consider these two concerns\nsimultaneously. Do changes in architecture exacerbate/alleviate existing\nconcerns about hallucinations? Do they affect how and where they occur? Through\nan extensive evaluation, we study how these architecture-based inductive biases\naffect the propensity to hallucinate. While hallucination remains a general\nphenomenon not limited to specific architectures, the situations in which they\noccur and the ease with which specific types of hallucinations can be induced\ncan significantly differ based on the model architecture. These findings\nhighlight the need for better understanding both these problems in conjunction\nwith each other, as well as consider how to design more universal techniques\nfor handling hallucinations.", "AI": {"tldr": "The paper explores how different LLM architectures (e.g., recurrent models vs. self-attention) influence hallucination tendencies, revealing architecture-specific patterns in hallucination occurrence and ease of induction.", "motivation": "To address the dual concerns of LLM hallucinations and computational limitations, and to understand how architectural changes impact hallucination risks.", "method": "An extensive evaluation of how architecture-based inductive biases affect hallucination propensity in LLMs.", "result": "Hallucination is a general phenomenon, but its occurrence and inducibility vary significantly by model architecture.", "conclusion": "The findings emphasize the need for a combined understanding of architectural and hallucination issues, and for universal techniques to mitigate hallucinations."}}
{"id": "2301.00882", "pdf": "https://arxiv.org/pdf/2301.00882", "abs": "https://arxiv.org/abs/2301.00882", "authors": ["Samaa Elnagar", "Manoj A. Thomas", "Kweku-Muata Osei-Bryson"], "title": "What is Cognitive Computing? An Architecture and State of The Art", "categories": ["cs.ET", "cs.AI", "cs.NE"], "comment": "12 pages, submitted to cognitive systems research", "summary": "Cognitive Computing (COC) aims to build highly cognitive machines with low\ncomputational resources that respond in real-time. However, scholarly\nliterature shows varying research areas and various interpretations of COC.\nThis calls for a cohesive architecture that delineates the nature of COC. We\nargue that if Herbert Simon considered the design science is the science of\nartificial, cognitive systems are the products of cognitive science or 'the\nnewest science of the artificial'. Therefore, building a conceptual basis for\nCOC is an essential step into prospective cognitive computing-based systems.\nThis paper proposes an architecture of COC through analyzing the literature on\nCOC using a myriad of statistical analysis methods. Then, we compare the\nstatistical analysis results with previous qualitative analysis results to\nconfirm our findings. The study also comprehensively surveys the recent\nresearch on COC to identify the state of the art and connect the advances in\nvaried research disciplines in COC. The study found that there are three\nunderlaying computing paradigms, Von-Neuman, Neuromorphic Engineering and\nQuantum Computing, that comprehensively complement the structure of cognitive\ncomputation. The research discuss possible applications and open research\ndirections under the COC umbrella.", "AI": {"tldr": "The paper proposes a cohesive architecture for Cognitive Computing (COC) by analyzing literature and identifying three underlying computing paradigms.", "motivation": "The varying interpretations and research areas of COC necessitate a unified architecture to define its nature and applications.", "method": "The study uses statistical analysis of COC literature, compares results with qualitative analysis, and surveys recent research to identify key paradigms.", "result": "Three computing paradigms (Von-Neuman, Neuromorphic Engineering, Quantum Computing) are found to complement COC's structure.", "conclusion": "The paper establishes a conceptual basis for COC, discusses applications, and highlights open research directions."}}
{"id": "2505.16329", "pdf": "https://arxiv.org/pdf/2505.16329", "abs": "https://arxiv.org/abs/2505.16329", "authors": ["Simone Bombari", "Inbar Seroussi", "Marco Mondelli"], "title": "Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Differentially private (DP) linear regression has received significant\nattention in the recent theoretical literature, with several works aimed at\nobtaining improved error rates. A common approach is to set the clipping\nconstant much larger than the expected norm of the per-sample gradients. While\nsimplifying the analysis, this is however in sharp contrast with what empirical\nevidence suggests to optimize performance. Our work bridges this gap between\ntheory and practice: we provide sharper rates for DP stochastic gradient\ndescent (DP-SGD) by crucially operating in a regime where clipping happens\nfrequently. Specifically, we consider the setting where the data is\nmultivariate Gaussian, the number of training samples $n$ is proportional to\nthe input dimension $d$, and the algorithm guarantees constant-order zero\nconcentrated DP. Our method relies on establishing a deterministic equivalent\nfor the trajectory of DP-SGD in terms of a family of ordinary differential\nequations (ODEs). As a consequence, the risk of DP-SGD is bounded between two\nODEs, with upper and lower bounds matching for isotropic data. By studying\nthese ODEs when $n / d$ is large enough, we demonstrate the optimality of\naggressive clipping, and we uncover the benefits of decaying learning rate and\nprivate noise scheduling.", "AI": {"tldr": "The paper bridges the gap between theory and practice in DP linear regression by analyzing DP-SGD with frequent clipping, showing optimality of aggressive clipping and benefits of learning rate decay and noise scheduling.", "motivation": "To reconcile theoretical DP linear regression approaches (which use large clipping constants) with empirical evidence suggesting smaller clipping optimizes performance.", "method": "Analyzes DP-SGD in a regime with frequent clipping, using multivariate Gaussian data and ODEs to model the algorithm's trajectory.", "result": "Demonstrates the optimality of aggressive clipping and reveals advantages of decaying learning rates and private noise scheduling.", "conclusion": "The study provides sharper error rates for DP-SGD, aligning theory with practical performance improvements."}}
{"id": "2411.08701", "pdf": "https://arxiv.org/pdf/2411.08701", "abs": "https://arxiv.org/abs/2411.08701", "authors": ["Dionysis Christopoulos", "Sotiris Spanos", "Valsamis Ntouskos", "Konstantinos Karantzalos"], "title": "TRACE: Transformer-based Risk Assessment for Clinical Evaluation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation),\na novel method for clinical risk assessment based on clinical data, leveraging\nthe self-attention mechanism for enhanced feature interaction and result\ninterpretation. Our approach is able to handle different data modalities,\nincluding continuous, categorical and multiple-choice (checkbox) attributes.\nThe proposed architecture features a shared representation of the clinical data\nobtained by integrating specialized embeddings of each data modality, enabling\nthe detection of high-risk individuals using Transformer encoder layers. To\nassess the effectiveness of the proposed method, a strong baseline based on\nnon-negative multi-layer perceptrons (MLPs) is introduced. The proposed method\noutperforms various baselines widely used in the domain of clinical risk\nassessment, while effectively handling missing values. In terms of\nexplainability, our Transformer-based method offers easily interpretable\nresults via attention weights, further enhancing the clinicians'\ndecision-making process.", "AI": {"tldr": "TRACE is a Transformer-based method for clinical risk assessment, handling diverse data modalities and outperforming baselines while offering interpretable results.", "motivation": "To improve clinical risk assessment by leveraging Transformer self-attention for better feature interaction and interpretability.", "method": "Integrates specialized embeddings for different data modalities (continuous, categorical, checkbox) and uses Transformer encoder layers for risk detection.", "result": "Outperforms non-negative MLP baselines and handles missing values effectively.", "conclusion": "TRACE enhances clinical decision-making with interpretable results via attention weights."}}
{"id": "2410.22316", "pdf": "https://arxiv.org/pdf/2410.22316", "abs": "https://arxiv.org/abs/2410.22316", "authors": ["Xinyu Zhao", "Fangcong Yin", "Greg Durrett"], "title": "Understanding Synthetic Context Extension via Retrieval Heads", "categories": ["cs.CL"], "comment": "Published at ICML 2025", "summary": "Long-context LLMs are increasingly in demand for applications such as\nretrieval-augmented generation. To defray the cost of pretraining LLMs over\nlong contexts, recent work takes an approach of synthetic context extension:\nfine-tuning LLMs with synthetically generated long-context data in a\npost-training stage. However, it remains unclear how and why this synthetic\ncontext extension imparts abilities for downstream long-context tasks. In this\npaper, we investigate fine-tuning on synthetic data for three long-context\ntasks that require retrieval and reasoning. We vary the realism of \"needle\"\nconcepts to be retrieved and diversity of the surrounding \"haystack\" context,\nfrom using LLMs to construct synthetic documents to using templated relations\nand creating symbolic datasets. We find that models trained on synthetic data\nfall short of the real data, but surprisingly, the mismatch can be interpreted\nand even predicted in terms of a special set of attention heads that are\nresponsible for retrieval over long context, retrieval heads (Wu et al., 2024).\nThe retrieval heads learned on synthetic data have high overlap with retrieval\nheads learned on real data, and there is a strong correlation between the\nrecall of heads learned and the downstream performance of a model. Furthermore,\nwith attention knockout and activation patching, we mechanistically show that\nretrieval heads are necessary and explain model performance, although they are\nnot totally sufficient. Our results shed light on how to interpret synthetic\ndata fine-tuning performance and how to approach creating better data for\nlearning real-world capabilities over long contexts.", "AI": {"tldr": "Synthetic context extension for LLMs improves long-context tasks but falls short of real data. Retrieval heads explain performance gaps.", "motivation": "To understand how synthetic data fine-tuning imparts abilities for long-context tasks and identify performance gaps.", "method": "Fine-tuning LLMs on synthetic data with varied realism and diversity, analyzing retrieval heads and their impact.", "result": "Models trained on synthetic data underperform but retrieval heads correlate with performance and explain gaps.", "conclusion": "Retrieval heads are key to interpreting synthetic data performance; insights guide better synthetic data creation."}}
{"id": "2305.06058", "pdf": "https://arxiv.org/pdf/2305.06058", "abs": "https://arxiv.org/abs/2305.06058", "authors": ["Yong Qing", "Ke Li", "Peng-Fei Zhou", "Shi-Ju Ran"], "title": "Compressing Neural Networks Using Tensor Networks with Exponentially Fewer Variational Parameters", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 5 figures, 2 tables for the main text; 6 pages for the\n  appendices", "summary": "Neural network (NN) designed for challenging machine learning tasks is in\ngeneral a highly nonlinear mapping that contains massive variational\nparameters. High complexity of NN, if unbounded or unconstrained, might\nunpredictably cause severe issues including \\R{overfitting}, loss of\ngeneralization power, and unbearable cost of hardware. In this work, we propose\na general compression scheme that significantly reduces the variational\nparameters of NN's, despite of their specific types (linear, convolutional,\n\\textit{etc}), by encoding them to deep \\R{automatically differentiable} tensor\nnetwork (ADTN) that contains exponentially-fewer free parameters. Superior\ncompression performance of our scheme is demonstrated on several\nwidely-recognized NN's (FC-2, LeNet-5, AlextNet, ZFNet and VGG-16) and datasets\n(MNIST, CIFAR-10 and CIFAR-100). For instance, we compress two linear layers in\nVGG-16 with approximately $10^{7}$ parameters to two ADTN's with just 424\nparameters, improving the testing accuracy on CIFAR-10 from $90.17\\%$ to\n$91.74\\%$. We argue that the deep structure of ADTN is an essential reason for\nthe remarkable compression performance of ADTN, compared to existing\ncompression schemes that are mainly based on tensor\ndecompositions/factorization and shallow tensor networks. Our work suggests\ndeep TN as an exceptionally efficient mathematical structure for representing\nthe variational parameters of NN's, which exhibits superior compressibility\nover the commonly-used matrices and multi-way arrays.", "AI": {"tldr": "A compression scheme using deep automatically differentiable tensor networks (ADTN) reduces NN parameters significantly, improving performance.", "motivation": "To address issues like overfitting and high hardware costs caused by the high complexity of neural networks.", "method": "Encode NN parameters into ADTN, which has exponentially fewer free parameters, and test on various NNs and datasets.", "result": "Achieved superior compression, e.g., reducing VGG-16 layers from ~10^7 to 424 parameters while improving accuracy from 90.17% to 91.74%.", "conclusion": "Deep tensor networks are highly efficient for NN parameter representation, outperforming traditional compression methods."}}
{"id": "2505.16347", "pdf": "https://arxiv.org/pdf/2505.16347", "abs": "https://arxiv.org/abs/2505.16347", "authors": ["Javad Mirzaei", "Jeebak Mitra", "Gwenael Poitau"], "title": "Graph Attention Network for Optimal User Association in Wireless Networks", "categories": ["cs.IT", "cs.LG", "cs.NI", "math.IT"], "comment": "6 pages, 7 figures", "summary": "With increased 5G deployments, network densification is higher than ever to\nsupport the exponentially high throughput requirements. However, this has meant\na significant increase in energy consumption, leading to higher operational\nexpenditure (OpEx) for network operators creating an acute need for\nimprovements in network energy savings (NES). A key determinant of operational\nefficacy in cellular networks is the user association (UA) policy, as it\naffects critical aspects like spectral efficiency, load balancing etc. and\ntherefore impacts the overall energy consumption of the network directly.\nFurthermore, with cellular network topologies lending themselves well to\ngraphical abstractions, use of graphs in network optimization has gained\nsignificant prominence. In this work, we propose and analyze a graphical\nabstraction based optimization for UA in cellular networks to improve NES by\ndetermining when energy saving features like cell switch off can be activated.\nA comparison with legacy approaches establishes the superiority of the proposed\napproach.", "AI": {"tldr": "A graphical abstraction-based optimization for user association in 5G networks improves energy savings by enabling features like cell switch-off, outperforming legacy methods.", "motivation": "The rise in 5G deployments has increased energy consumption, creating a need for better network energy savings (NES). User association policies directly impact energy use, making optimization crucial.", "method": "The paper proposes a graphical abstraction-based optimization for user association, leveraging cellular network topologies' suitability for graphs to enhance NES.", "result": "The proposed approach outperforms legacy methods in improving energy savings, particularly by enabling efficient cell switch-off.", "conclusion": "Graphical abstraction-based optimization is effective for enhancing NES in 5G networks, offering a superior alternative to traditional methods."}}
{"id": "2411.11926", "pdf": "https://arxiv.org/pdf/2411.11926", "abs": "https://arxiv.org/abs/2411.11926", "authors": ["Akansh Agrawal", "Akshan Agrawal", "Shashwat Gupta", "Priyanka Bagade"], "title": "KAN-Mamba FusionNet: Redefining Medical Image Segmentation with Non-Linear Modeling", "categories": ["cs.CV"], "comment": "11 pages, 2 figures, 4 tables", "summary": "Medical image segmentation is essential for applications like robotic\nsurgeries, disease diagnosis, and treatment planning. Recently, various\ndeep-learning models have been proposed to enhance medical image segmentation.\nOne promising approach utilizes Kolmogorov-Arnold Networks (KANs), which better\ncapture non-linearity in input data. However, they are unable to effectively\ncapture long-range dependencies, which are required to accurately segment\ncomplex medical images and, by that, improve diagnostic accuracy in clinical\nsettings. Neural networks such as Mamba can handle long-range dependencies.\nHowever, they have a limited ability to accurately capture non-linearities in\nthe images as compared to KANs. Thus, we propose a novel architecture, the\nKAN-Mamba FusionNet, which improves segmentation accuracy by effectively\ncapturing the non-linearities from input and handling long-range dependencies\nwith the newly proposed KAMBA block. We evaluated the proposed KAN-Mamba\nFusionNet on three distinct medical image segmentation datasets: BUSI,\nKvasir-Seg, and GlaS - and found it consistently outperforms state-of-the-art\nmethods in IoU and F1 scores. Further, we examined the effects of various\ncomponents and assessed their contributions to the overall model performance\nvia ablation studies. The findings highlight the effectiveness of this\nmethodology for reliable medical image segmentation, providing a unique\napproach to address intricate visual data issues in healthcare.", "AI": {"tldr": "The paper introduces KAN-Mamba FusionNet, a novel architecture combining KANs and Mamba to improve medical image segmentation by capturing non-linearities and long-range dependencies, outperforming state-of-the-art methods.", "motivation": "Existing models like KANs and Mamba have limitations in handling long-range dependencies and non-linearities, respectively, which are crucial for accurate medical image segmentation.", "method": "Proposes KAN-Mamba FusionNet with a KAMBA block to combine strengths of KANs (non-linearity) and Mamba (long-range dependencies). Evaluated on BUSI, Kvasir-Seg, and GlaS datasets.", "result": "Outperforms state-of-the-art methods in IoU and F1 scores. Ablation studies confirm the contributions of model components.", "conclusion": "KAN-Mamba FusionNet effectively addresses challenges in medical image segmentation, offering a reliable solution for healthcare applications."}}
{"id": "2410.22394", "pdf": "https://arxiv.org/pdf/2410.22394", "abs": "https://arxiv.org/abs/2410.22394", "authors": ["Renze Lou", "Hanzi Xu", "Sijia Wang", "Jiangshu Du", "Ryo Kamoi", "Xiaoxin Lu", "Jian Xie", "Yuxuan Sun", "Yusen Zhang", "Jihyun Janice Ahn", "Hongchao Fang", "Zhuoyang Zou", "Wenchao Ma", "Xi Li", "Kai Zhang", "Congying Xia", "Lifu Huang", "Wenpeng Yin"], "title": "AAAR-1.0: Assessing AI's Potential to Assist Research", "categories": ["cs.CL"], "comment": "ICML 2025. Project Webpage: https://renzelou.github.io/AAAR-1.0/", "summary": "Numerous studies have assessed the proficiency of AI systems, particularly\nlarge language models (LLMs), in facilitating everyday tasks such as email\nwriting, question answering, and creative content generation. However,\nresearchers face unique challenges and opportunities in leveraging LLMs for\ntheir own work, such as brainstorming research ideas, designing experiments,\nand writing or reviewing papers. In this study, we introduce AAAR-1.0, a\nbenchmark dataset designed to evaluate LLM performance in three fundamental,\nexpertise-intensive research tasks: (i) EquationInference, assessing the\ncorrectness of equations based on the contextual information in paper\nsubmissions; (ii) ExperimentDesign, designing experiments to validate research\nideas and solutions; (iii) PaperWeakness, identifying weaknesses in paper\nsubmissions; and (iv) REVIEWCRITIQUE, identifying each segment in human reviews\nis deficient or not. AAAR-1.0 differs from prior benchmarks in two key ways:\nfirst, it is explicitly research-oriented, with tasks requiring deep domain\nexpertise; second, it is researcher-oriented, mirroring the primary activities\nthat researchers engage in on a daily basis. An evaluation of both open-source\nand proprietary LLMs reveals their potential as well as limitations in\nconducting sophisticated research tasks. We will keep iterating AAAR-1.0 to new\nversions.", "AI": {"tldr": "AAAR-1.0 is a benchmark dataset for evaluating LLMs in research tasks like equation inference, experiment design, paper weakness identification, and review critique. It highlights LLMs' potential and limitations in expert research tasks.", "motivation": "Current benchmarks don't address the unique challenges of using LLMs for research tasks like brainstorming, experiment design, and paper review. AAAR-1.0 fills this gap by focusing on expertise-intensive research activities.", "method": "The study introduces AAAR-1.0, a dataset evaluating LLMs in four research tasks: EquationInference, ExperimentDesign, PaperWeakness, and REVIEWCRITIQUE. It tests open-source and proprietary LLMs.", "result": "Evaluation shows LLMs have potential but also limitations in handling sophisticated research tasks.", "conclusion": "AAAR-1.0 is a step toward better benchmarking LLMs for research, with plans for future iterations."}}
{"id": "2311.17815", "pdf": "https://arxiv.org/pdf/2311.17815", "abs": "https://arxiv.org/abs/2311.17815", "authors": ["Serena Curzel", "Fabrizio Ferrandi", "Leandro Fiorin", "Daniele Ielmini", "Cristina Silvano", "Francesco Conti", "Luca Bompani", "Luca Benini", "Enrico Calore", "Sebastiano Fabio Schifano", "Cristian Zambelli", "Maurizio Palesi", "Giuseppe Ascia", "Enrico Russo", "Valeria Cardellini", "Salvatore Filippone", "Francesco Lo Presti", "Stefania Perri"], "title": "A Survey on Design Methodologies for Accelerating Deep Learning on Heterogeneous Architectures", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Given their increasing size and complexity, the need for efficient execution\nof deep neural networks has become increasingly pressing in the design of\nheterogeneous High-Performance Computing (HPC) and edge platforms, leading to a\nwide variety of proposals for specialized deep learning architectures and\nhardware accelerators. The design of such architectures and accelerators\nrequires a multidisciplinary approach combining expertise from several areas,\nfrom machine learning to computer architecture, low-level hardware design, and\napproximate computing. Several methodologies and tools have been proposed to\nimprove the process of designing accelerators for deep learning, aimed at\nmaximizing parallelism and minimizing data movement to achieve high performance\nand energy efficiency. This paper critically reviews influential tools and\ndesign methodologies for Deep Learning accelerators, offering a wide\nperspective in this rapidly evolving field. This work complements surveys on\narchitectures and accelerators by covering hardware-software co-design,\nautomated synthesis, domain-specific compilers, design space exploration,\nmodeling, and simulation, providing insights into technical challenges and open\nresearch directions.", "AI": {"tldr": "A review of tools and methodologies for designing efficient deep learning accelerators, covering hardware-software co-design, automation, and simulation.", "motivation": "The growing complexity of deep neural networks necessitates efficient execution on heterogeneous HPC and edge platforms, requiring specialized architectures and accelerators.", "method": "Critically reviews influential tools and design methodologies, focusing on hardware-software co-design, automated synthesis, and simulation.", "result": "Provides insights into technical challenges and open research directions in deep learning accelerator design.", "conclusion": "The paper offers a comprehensive perspective on accelerator design, highlighting multidisciplinary approaches and future research opportunities."}}
{"id": "2411.14716", "pdf": "https://arxiv.org/pdf/2411.14716", "abs": "https://arxiv.org/abs/2411.14716", "authors": ["Haiming Zhang", "Wending Zhou", "Yiyao Zhu", "Xu Yan", "Jiantao Gao", "Dongfeng Bai", "Yingjie Cai", "Bingbing Liu", "Shuguang Cui", "Zhen Li"], "title": "VisionPAD: A Vision-Centric Pre-training Paradigm for Autonomous Driving", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "Accepted at CVPR 2025", "summary": "This paper introduces VisionPAD, a novel self-supervised pre-training\nparadigm designed for vision-centric algorithms in autonomous driving. In\ncontrast to previous approaches that employ neural rendering with explicit\ndepth supervision, VisionPAD utilizes more efficient 3D Gaussian Splatting to\nreconstruct multi-view representations using only images as supervision.\nSpecifically, we introduce a self-supervised method for voxel velocity\nestimation. By warping voxels to adjacent frames and supervising the rendered\noutputs, the model effectively learns motion cues in the sequential data.\nFurthermore, we adopt a multi-frame photometric consistency approach to enhance\ngeometric perception. It projects adjacent frames to the current frame based on\nrendered depths and relative poses, boosting the 3D geometric representation\nthrough pure image supervision. Extensive experiments on autonomous driving\ndatasets demonstrate that VisionPAD significantly improves performance in 3D\nobject detection, occupancy prediction and map segmentation, surpassing\nstate-of-the-art pre-training strategies by a considerable margin.", "AI": {"tldr": "VisionPAD is a self-supervised pre-training method for autonomous driving vision tasks, using 3D Gaussian Splatting and multi-view reconstruction without explicit depth supervision. It outperforms existing methods in 3D object detection, occupancy prediction, and map segmentation.", "motivation": "Traditional methods rely on explicit depth supervision, which is inefficient. VisionPAD aims to leverage self-supervision for better efficiency and performance in vision-centric autonomous driving tasks.", "method": "Uses 3D Gaussian Splatting for multi-view reconstruction and introduces voxel velocity estimation via self-supervision. Enhances geometric perception with multi-frame photometric consistency.", "result": "Outperforms state-of-the-art pre-training methods in 3D object detection, occupancy prediction, and map segmentation on autonomous driving datasets.", "conclusion": "VisionPAD demonstrates the effectiveness of self-supervised pre-training for vision-centric autonomous driving tasks, offering superior performance without explicit depth supervision."}}
{"id": "2411.02454", "pdf": "https://arxiv.org/pdf/2411.02454", "abs": "https://arxiv.org/abs/2411.02454", "authors": ["Yukun Li", "Sijia Wang", "Lifu Huang", "Li-Ping Liu"], "title": "Graph-based Confidence Calibration for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Reliable confidence estimation is essential for enhancing the trustworthiness\nof large language models (LLMs), especially in high-stakes scenarios. Despite\nits importance, accurately estimating confidence in LLM responses remains a\nsignificant challenge. In this work, we propose using an auxiliary learning\nmodel to assess response correctness based on the self-consistency of multiple\noutputs generated by the LLM. Our method builds a consistency graph to\nrepresent the agreement among multiple responses and uses a graph neural\nnetwork (GNN) to estimate the likelihood that each response is correct.\nExperiments demonstrate that this method has strong calibration performance on\nvarious benchmark datasets and generalizes well to out-of-domain cases.", "AI": {"tldr": "Proposes using an auxiliary model and GNN to estimate LLM response confidence via self-consistency of outputs.", "motivation": "Enhancing trustworthiness of LLMs in high-stakes scenarios by improving confidence estimation.", "method": "Builds a consistency graph from multiple LLM outputs and uses a GNN to estimate response correctness.", "result": "Strong calibration performance on benchmarks and good generalization to out-of-domain cases.", "conclusion": "The method effectively improves confidence estimation in LLMs, aiding reliability."}}
{"id": "2402.09664", "pdf": "https://arxiv.org/pdf/2402.09664", "abs": "https://arxiv.org/abs/2402.09664", "authors": ["Changshu Liu", "Yang Chen", "Reyhaneh Jabbarvand"], "title": "CodeMind: Evaluating Large Language Models for Code Reasoning", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL"], "comment": null, "summary": "Large Language Models (LLMs) have been widely used to automate programming\ntasks. Their capabilities have been evaluated by assessing the quality of\ngenerated code through tests or proofs. The extent to which they can reason\nabout code is a critical question revealing important insights about their true\ncapabilities. This paper introduces CodeMind, a framework designed to gauge the\ncode reasoning abilities of LLMs through the following explicit and implicit\ncode reasoning tasks: Independent Execution Reasoning (IER), Specification\nReasoning (SR) and Dynamic Semantics Reasoning (DSR). The first evaluates the\nabilities of LLMs to simulate the execution of given inputs to a code and\npredict the output (IER). The second assesses the abilities of LLMs to\nincorporate the simulation of test data in the specification into code\ngeneration (SR). Finally, CodeMind evaluates LLMs' abilities to understand\noverall code semantics only given a specific input/output (DSR). Our extensive\nevaluation of ten LLMs across four widely used benchmarks using CodeMind shows\nthat LLMs, depending on their size and training strategy, can reason about some\ndynamic aspects of code. However, their performance drops for code with higher\ncomplexity, non-trivial logical and arithmetic operators, non-primitive types,\nand API calls. We show that these reasoning tasks evaluate LLMs differently,\nand a comprehensive evaluation of code reasoning requires them all. Finally, we\nshow that the performance of LLMs in bug repair is not correlated with any of\nthe code reasoning tasks, and except for advanced frontier models, other LLMs\ndo not incorporate code reasoning when performing bug repair.", "AI": {"tldr": "CodeMind evaluates LLMs' code reasoning abilities through tasks like IER, SR, and DSR, revealing limitations in handling complex code and non-trivial operations. Performance in bug repair isn't strongly linked to reasoning tasks.", "motivation": "Assess the true capabilities of LLMs in reasoning about code, beyond just generating or testing it, to understand their limitations and strengths.", "method": "Introduces CodeMind, a framework with three tasks (IER, SR, DSR) to evaluate LLMs' code reasoning across ten models and four benchmarks.", "result": "LLMs show varied performance in reasoning tasks, struggling with complex code, non-trivial operations, and API calls. Bug repair performance doesn't correlate with reasoning tasks.", "conclusion": "CodeMind highlights the need for comprehensive evaluation of LLMs' reasoning abilities, as they vary by task and model. Bug repair doesn't rely heavily on reasoning, except in advanced models."}}
{"id": "2505.16471", "pdf": "https://arxiv.org/pdf/2505.16471", "abs": "https://arxiv.org/abs/2505.16471", "authors": ["Robbert Reijnen", "Yaoxin Wu", "Zaharah Bukhsh", "Yingqian Zhang"], "title": "Graph-Supported Dynamic Algorithm Configuration for Multi-Objective Combinatorial Optimization", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Deep reinforcement learning (DRL) has been widely used for dynamic algorithm\nconfiguration, particularly in evolutionary computation, which benefits from\nthe adaptive update of parameters during the algorithmic execution. However,\napplying DRL to algorithm configuration for multi-objective combinatorial\noptimization (MOCO) problems remains relatively unexplored. This paper presents\na novel graph neural network (GNN) based DRL to configure multi-objective\nevolutionary algorithms. We model the dynamic algorithm configuration as a\nMarkov decision process, representing the convergence of solutions in the\nobjective space by a graph, with their embeddings learned by a GNN to enhance\nthe state representation. Experiments on diverse MOCO challenges indicate that\nour method outperforms traditional and DRL-based algorithm configuration\nmethods in terms of efficacy and adaptability. It also exhibits advantageous\ngeneralizability across objective types and problem sizes, and applicability to\ndifferent evolutionary computation methods.", "AI": {"tldr": "A GNN-based DRL method for configuring multi-objective evolutionary algorithms outperforms traditional and DRL-based methods in efficacy, adaptability, and generalizability.", "motivation": "Applying DRL to multi-objective combinatorial optimization (MOCO) problems is underexplored, despite its success in dynamic algorithm configuration for evolutionary computation.", "method": "Model dynamic algorithm configuration as a Markov decision process, using a GNN to represent solution convergence in the objective space and enhance state representation.", "result": "Outperforms traditional and DRL-based methods in efficacy, adaptability, and generalizability across objective types and problem sizes.", "conclusion": "The GNN-based DRL method is effective, adaptable, and generalizable for configuring multi-objective evolutionary algorithms in MOCO problems."}}
{"id": "2412.02573", "pdf": "https://arxiv.org/pdf/2412.02573", "abs": "https://arxiv.org/abs/2412.02573", "authors": ["Chenyang Liu", "Jiafan Zhang", "Keyan Chen", "Man Wang", "Zhengxia Zou", "Zhenwei Shi"], "title": "Remote Sensing Spatio-Temporal Vision-Language Models: A Comprehensive Survey", "categories": ["cs.CV"], "comment": null, "summary": "The interpretation of multi-temporal remote sensing imagery is critical for\nmonitoring Earth's dynamic processes-yet previous change detection methods,\nwhich produce binary or semantic masks, fall short of providing human-readable\ninsights into changes. Recent advances in Vision-Language Models (VLMs) have\nopened a new frontier by fusing visual and linguistic modalities, enabling\nspatio-temporal vision-language understanding: models that not only capture\nspatial and temporal dependencies to recognize changes but also provide a\nricher interactive semantic analysis of temporal images (e.g., generate\ndescriptive captions and answer natural-language queries). In this survey, we\npresent the first comprehensive review of RS-STVLMs. The survey covers the\nevolution of models from early task-specific models to recent general\nfoundation models that leverage powerful large language models. We discuss\nprogress in representative tasks, such as change captioning, change question\nanswering, and change grounding. Moreover, we systematically dissect the\nfundamental components and key technologies underlying these models, and review\nthe datasets and evaluation metrics that have driven the field. By synthesizing\ntask-level insights with a deep dive into shared architectural patterns, we aim\nto illuminate current achievements and chart promising directions for future\nresearch in spatio-temporal vision-language understanding for remote sensing.\nWe will keep tracing related works at\nhttps://github.com/Chen-Yang-Liu/Awesome-RS-SpatioTemporal-VLMs", "AI": {"tldr": "A survey on Remote Sensing Spatio-Temporal Vision-Language Models (RS-STVLMs) reviewing their evolution, tasks, components, datasets, and future directions.", "motivation": "Existing change detection methods lack human-readable insights; VLMs offer richer semantic analysis of temporal images.", "method": "Comprehensive review of RS-STVLMs, covering model evolution, tasks (e.g., change captioning), components, datasets, and metrics.", "result": "Synthesis of current achievements and identification of key technologies and shared architectural patterns.", "conclusion": "Highlights future research directions for spatio-temporal vision-language understanding in remote sensing."}}
{"id": "2411.04847", "pdf": "https://arxiv.org/pdf/2411.04847", "abs": "https://arxiv.org/abs/2411.04847", "authors": ["Fujie Zhang", "Peiqi Yu", "Biao Yi", "Baolei Zhang", "Tong Li", "Zheli Liu"], "title": "Prompt-Guided Internal States for Hallucination Detection of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na variety of tasks in different domains. However, they sometimes generate\nresponses that are logically coherent but factually incorrect or misleading,\nwhich is known as LLM hallucinations. Data-driven supervised methods train\nhallucination detectors by leveraging the internal states of LLMs, but\ndetectors trained on specific domains often struggle to generalize well to\nother domains. In this paper, we aim to enhance the cross-domain performance of\nsupervised detectors with only in-domain data. We propose a novel framework,\nprompt-guided internal states for hallucination detection of LLMs, namely\nPRISM. By utilizing appropriate prompts to guide changes to the structure\nrelated to text truthfulness in LLMs' internal states, we make this structure\nmore salient and consistent across texts from different domains. We integrated\nour framework with existing hallucination detection methods and conducted\nexperiments on datasets from different domains. The experimental results\nindicate that our framework significantly enhances the cross-domain\ngeneralization of existing hallucination detection methods.", "AI": {"tldr": "PRISM improves cross-domain hallucination detection in LLMs by using prompt-guided internal states, enhancing generalization without needing out-of-domain data.", "motivation": "LLMs often produce factually incorrect responses (hallucinations), and existing detectors trained on specific domains fail to generalize well.", "method": "Proposes PRISM, a framework using prompts to modify LLM internal states, making truthfulness structures more consistent across domains.", "result": "Experiments show PRISM significantly boosts cross-domain performance of existing hallucination detectors.", "conclusion": "PRISM effectively enhances generalization of hallucination detection methods using only in-domain data."}}
{"id": "2403.15855", "pdf": "https://arxiv.org/pdf/2403.15855", "abs": "https://arxiv.org/abs/2403.15855", "authors": ["Arash Badie-Modiri", "Chiara Boldrini", "Lorenzo Valerio", "J\u00e1nos Kert\u00e9sz", "M\u00e1rton Karsai"], "title": "Initialisation and Network Effects in Decentralised Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.DC", "physics.soc-ph"], "comment": null, "summary": "Fully decentralised federated learning enables collaborative training of\nindividual machine learning models on a distributed network of communicating\ndevices while keeping the training data localised on each node. This approach\navoids central coordination, enhances data privacy and eliminates the risk of a\nsingle point of failure. Our research highlights that the effectiveness of\ndecentralised federated learning is significantly influenced by the network\ntopology of connected devices and the learning models' initial conditions. We\npropose a strategy for uncoordinated initialisation of the artificial neural\nnetworks based on the distribution of eigenvector centralities of the\nunderlying communication network, leading to a radically improved training\nefficiency. Additionally, our study explores the scaling behaviour and the\nchoice of environmental parameters under our proposed initialisation strategy.\nThis work paves the way for more efficient and scalable artificial neural\nnetwork training in a distributed and uncoordinated environment, offering a\ndeeper understanding of the intertwining roles of network structure and\nlearning dynamics.", "AI": {"tldr": "Decentralized federated learning improves privacy and avoids single points of failure, with effectiveness influenced by network topology and initial conditions. A new initialization strategy based on eigenvector centrality enhances training efficiency.", "motivation": "To improve the efficiency and scalability of decentralized federated learning by addressing the impact of network topology and initial conditions on training performance.", "method": "Proposes an uncoordinated initialization strategy for neural networks using eigenvector centrality of the communication network, and explores scaling behavior and parameter choices.", "result": "The strategy significantly improves training efficiency and provides insights into the relationship between network structure and learning dynamics.", "conclusion": "This work advances efficient and scalable neural network training in decentralized settings, highlighting the interplay between network topology and learning performance."}}
{"id": "2505.16635", "pdf": "https://arxiv.org/pdf/2505.16635", "abs": "https://arxiv.org/abs/2505.16635", "authors": ["Zhaomin Wu", "Ziyang Wang", "Bingsheng He"], "title": "WikiDBGraph: Large-Scale Database Graph of Wikidata for Collaborative Learning", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Tabular data, ubiquitous and rich in informational value, is an increasing\nfocus for deep representation learning, yet progress is hindered by studies\ncentered on single tables or isolated databases, which limits model\ncapabilities due to data scale. While collaborative learning approaches such as\nfederated learning, transfer learning, split learning, and tabular foundation\nmodels aim to learn from multiple correlated databases, they are challenged by\na scarcity of real-world interconnected tabular resources. Current data lakes\nand corpora largely consist of isolated databases lacking defined\ninter-database correlations. To overcome this, we introduce WikiDBGraph, a\nlarge-scale graph of 100,000 real-world tabular databases from WikiData,\ninterconnected by 17 million edges and characterized by 13 node and 12 edge\nproperties derived from its database schema and data distribution.\nWikiDBGraph's weighted edges identify both instance- and feature-overlapped\ndatabases. Experiments on these newly identified databases confirm that\ncollaborative learning yields superior performance, thereby offering\nconsiderable promise for structured foundation model training while also\nexposing key challenges and future directions for learning from interconnected\ntabular data.", "AI": {"tldr": "WikiDBGraph introduces a large-scale graph of interconnected tabular databases to enhance collaborative learning, outperforming isolated approaches.", "motivation": "Current tabular data learning is limited by isolated databases, lacking real-world interconnected resources.", "method": "Created WikiDBGraph, a graph of 100,000 databases with 17M edges, using schema and data distribution properties.", "result": "Collaborative learning on interconnected databases shows superior performance.", "conclusion": "WikiDBGraph enables structured foundation model training and highlights challenges for future work."}}
{"id": "2412.04030", "pdf": "https://arxiv.org/pdf/2412.04030", "abs": "https://arxiv.org/abs/2412.04030", "authors": ["Th\u00e9o Sourget", "Michelle Hestbek-M\u00f8ller", "Amelia Jim\u00e9nez-S\u00e1nchez", "Jack Junchi Xu", "Veronika Cheplygina"], "title": "Mask of truth: model sensitivity to unexpected regions of medical images", "categories": ["cs.CV"], "comment": "Updated after publication in the Journal of Imaging Informatics in\n  Medicine", "summary": "The development of larger models for medical image analysis has led to\nincreased performance. However, it also affected our ability to explain and\nvalidate model decisions. Models can use non-relevant parts of images, also\ncalled spurious correlations or shortcuts, to obtain high performance on\nbenchmark datasets but fail in real-world scenarios. In this work, we challenge\nthe capacity of convolutional neural networks (CNN) to classify chest X-rays\nand eye fundus images while masking out clinically relevant parts of the image.\nWe show that all models trained on the PadChest dataset, irrespective of the\nmasking strategy, are able to obtain an Area Under the Curve (AUC) above\nrandom. Moreover, the models trained on full images obtain good performance on\nimages without the region of interest (ROI), even superior to the one obtained\non images only containing the ROI. We also reveal a possible spurious\ncorrelation in the Chaksu dataset while the performances are more aligned with\nthe expectation of an unbiased model. We go beyond the performance analysis\nwith the usage of the explainability method SHAP and the analysis of\nembeddings. We asked a radiology resident to interpret chest X-rays under\ndifferent masking to complement our findings with clinical knowledge. Our code\nis available at https://github.com/TheoSourget/MMC_Masking and\nhttps://github.com/TheoSourget/MMC_Masking_EyeFundus", "AI": {"tldr": "CNNs can classify medical images even when clinically relevant parts are masked, revealing potential spurious correlations and raising concerns about model reliability.", "motivation": "To investigate whether CNNs rely on clinically irrelevant features (shortcuts) in medical image analysis, potentially compromising real-world applicability.", "method": "Train CNNs on masked chest X-rays and eye fundus images, evaluate performance (AUC), and use SHAP and embedding analysis for explainability. Clinical validation was done by a radiology resident.", "result": "Models perform well even without clinically relevant regions, sometimes better than with them, indicating reliance on shortcuts. A spurious correlation was found in one dataset.", "conclusion": "CNNs may exploit non-relevant features, questioning their reliability for medical diagnosis. Explainability tools and clinical input are crucial for validation."}}
{"id": "2412.01031", "pdf": "https://arxiv.org/pdf/2412.01031", "abs": "https://arxiv.org/abs/2412.01031", "authors": ["Razi Mahmood", "Pingkun Yan", "Diego Machado Reyes", "Ge Wang", "Mannudeep K. Kalra", "Parisa Kaviani", "Joy T. Wu", "Tanveer Syeda-Mahmood"], "title": "Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Several evaluation metrics have been developed recently to automatically\nassess the quality of generative AI reports for chest radiographs based only on\ntextual information using lexical, semantic, or clinical named entity\nrecognition methods. In this paper, we develop a new method of report quality\nevaluation by first extracting fine-grained finding patterns capturing the\nlocation, laterality, and severity of a large number of clinical findings. We\nthen performed phrasal grounding to localize their associated anatomical\nregions on chest radiograph images. The textual and visual measures are then\ncombined to rate the quality of the generated reports. We present results that\ncompare this evaluation metric with other textual metrics on a gold standard\ndataset derived from the MIMIC collection and show its robustness and\nsensitivity to factual errors.", "AI": {"tldr": "A new method for evaluating generative AI chest radiograph reports combines fine-grained textual findings with visual localization, outperforming text-only metrics.", "motivation": "Existing metrics for assessing AI-generated chest radiograph reports rely solely on textual information, lacking integration with visual data for comprehensive evaluation.", "method": "Extracts fine-grained finding patterns (location, laterality, severity), performs phrasal grounding to localize findings on images, and combines textual and visual measures for quality rating.", "result": "The method shows robustness and sensitivity to factual errors, outperforming text-only metrics on a MIMIC-derived dataset.", "conclusion": "Combining textual and visual measures provides a more accurate and comprehensive evaluation of AI-generated radiograph reports."}}
{"id": "2405.14273", "pdf": "https://arxiv.org/pdf/2405.14273", "abs": "https://arxiv.org/abs/2405.14273", "authors": ["Akira Kitaoka"], "title": "A fast algorithm to minimize prediction loss of the optimal solution in inverse optimization problem of MILP", "categories": ["cs.LG", "cs.AI", "math.OC", "90C90(primary), 90C25, 90C52, 90C11, 90C05, 68Q25 (secondary)"], "comment": "25 pages; comments are welcome", "summary": "We consider the inverse optimization problem of estimating the weights of the\nobjective function such that the given solution is an optimal solution for a\nmixed integer linear program (MILP). In this inverse optimization problem, the\nknown methods exhibit inefficient convergence. Specifically, if $d$ denotes the\ndimension of the weights and $k$ the number of iterations, then the error of\nthe weights is bounded by $O(k^{-1/(d-1)})$, leading to slow convergence as $d$\nincreases.We propose a projected subgradient method with a step size of\n$k^{-1/2}$ based on suboptimality loss. We theoretically show and demonstrate\nthat the proposed method efficiently learns the weights. In particular, we show\nthat there exists a constant $\\gamma > 0$ such that the distance between the\nlearned and true weights is bounded by $ O\\left(k^{-1/(1+\\gamma)}\n\\exp\\left(-\\frac{\\gamma k^{1/2}}{2+\\gamma}\\right)\\right), $ or the optimal\nsolution is exactly recovered. Furthermore, experiments demonstrate that the\nproposed method solves the inverse optimization problems of MILP using fewer\nthan $1/7$ the number of MILP calls required by known methods, and converges\nwithin a finite number of iterations.", "AI": {"tldr": "The paper proposes a projected subgradient method for inverse optimization in MILP, improving convergence efficiency and reducing computational costs compared to existing methods.", "motivation": "Existing methods for inverse optimization in MILP suffer from slow convergence as the dimension of weights increases, necessitating a more efficient approach.", "method": "A projected subgradient method with a step size of $k^{-1/2}$ based on suboptimality loss is introduced.", "result": "The method achieves faster convergence, with a theoretical bound on weight error, and reduces the number of MILP calls by over 7x.", "conclusion": "The proposed method efficiently learns weights in MILP inverse optimization, offering significant computational advantages over known methods."}}
{"id": "2505.16644", "pdf": "https://arxiv.org/pdf/2505.16644", "abs": "https://arxiv.org/abs/2505.16644", "authors": ["Stephen Y. Zhang", "Michael P H Stumpf"], "title": "Learning non-equilibrium diffusions with Schr\u00f6dinger bridges: from exactly solvable to simulation-free", "categories": ["stat.ML", "cs.LG", "math.OC", "62M45, 49N10"], "comment": "9 pages, 5 figures", "summary": "We consider the Schr\\\"odinger bridge problem which, given ensemble\nmeasurements of the initial and final configurations of a stochastic dynamical\nsystem and some prior knowledge on the dynamics, aims to reconstruct the \"most\nlikely\" evolution of the system compatible with the data. Most existing\nliterature assume Brownian reference dynamics and are implicitly limited to\npotential-driven dynamics. We depart from this regime and consider reference\nprocesses described by a multivariate Ornstein-Uhlenbeck process with generic\ndrift matrix $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$. When $\\mathbf{A}$ is\nasymmetric, this corresponds to a non-equilibrium system with non-conservative\nforces at play: this is important for applications to biological systems, which\nare naturally exist out-of-equilibrium. In the case of Gaussian marginals, we\nderive explicit expressions that characterise the solution of both the static\nand dynamic Schr\\\"odinger bridge. For general marginals, we propose mvOU-OTFM,\na simulation-free algorithm based on flow and score matching for learning the\nSchr\\\"odinger bridge. In application to a range of problems based on synthetic\nand real single cell data, we demonstrate that mvOU-OTFM achieves higher\naccuracy compared to competing methods, whilst being significantly faster to\ntrain.", "AI": {"tldr": "The paper addresses the Schr\u00f6dinger bridge problem for reconstructing stochastic system evolution, focusing on non-equilibrium dynamics with asymmetric drift matrices. It introduces mvOU-OTFM, a simulation-free algorithm for Gaussian and general marginals, showing superior accuracy and speed in synthetic and real single-cell data applications.", "motivation": "The study aims to extend the Schr\u00f6dinger bridge problem beyond Brownian dynamics, addressing non-equilibrium systems (e.g., biological systems) with non-conservative forces, which are not well-covered by existing methods.", "method": "The paper uses a multivariate Ornstein-Uhlenbeck (mvOU) process with a generic drift matrix for non-equilibrium dynamics. For Gaussian marginals, explicit solutions are derived. For general cases, the mvOU-OTFM algorithm, based on flow and score matching, is proposed.", "result": "mvOU-OTFM outperforms competing methods in accuracy and training speed, as demonstrated on synthetic and real single-cell data.", "conclusion": "The work successfully generalizes the Schr\u00f6dinger bridge problem to non-equilibrium systems and introduces an efficient algorithm, mvOU-OTFM, with practical advantages in biological applications."}}
{"id": "2412.07750", "pdf": "https://arxiv.org/pdf/2412.07750", "abs": "https://arxiv.org/abs/2412.07750", "authors": ["Yuval Atzmon", "Rinon Gal", "Yoad Tewel", "Yoni Kasten", "Gal Chechik"], "title": "Motion by Queries: Identity-Motion Trade-offs in Text-to-Video Generation", "categories": ["cs.CV"], "comment": "(1) Project page:\n  https://research.nvidia.com/labs/par/MotionByQueries/ (2) The methods and\n  results in section 5, \"Consistent multi-shot video generation\", are based on\n  the arXiv version 1 (v1) of this work. Starting version 2 (v2), we extend and\n  further analyze those findings to efficient motion transfer (3) in v3 we\n  added: results with WAN 2.1, baselines and more quality metrics", "summary": "Text-to-video diffusion models have shown remarkable progress in generating\ncoherent video clips from textual descriptions. However, the interplay between\nmotion, structure, and identity representations in these models remains\nunder-explored. Here, we investigate how self-attention query (Q) features\nsimultaneously govern motion, structure, and identity and examine the\nchallenges arising when these representations interact. Our analysis reveals\nthat Q affects not only layout, but that during denoising Q also has a strong\neffect on subject identity, making it hard to transfer motion without the\nside-effect of transferring identity. Understanding this dual role enabled us\nto control query feature injection (Q injection) and demonstrate two\napplications: (1) a zero-shot motion transfer method - implemented with\nVideoCrafter2 and WAN 2.1 - that is 10 times more efficient than existing\napproaches, and (2) a training-free technique for consistent multi-shot video\ngeneration, where characters maintain identity across multiple video shots\nwhile Q injection enhances motion fidelity.", "AI": {"tldr": "The paper explores how self-attention query (Q) features in text-to-video diffusion models influence motion, structure, and identity, revealing challenges in disentangling these effects. It proposes Q injection control for efficient motion transfer and consistent multi-shot video generation.", "motivation": "The interplay between motion, structure, and identity in text-to-video models is under-explored, prompting investigation into Q features' dual role.", "method": "Analyzes Q features' impact on layout and identity during denoising, then introduces Q injection control for motion transfer and multi-shot consistency.", "result": "Develops a zero-shot motion transfer method 10x more efficient than existing approaches and a training-free technique for identity-consistent multi-shot videos.", "conclusion": "Understanding Q features' dual role enables practical applications like motion transfer and multi-shot generation, advancing text-to-video model capabilities."}}
{"id": "2412.06272", "pdf": "https://arxiv.org/pdf/2412.06272", "abs": "https://arxiv.org/abs/2412.06272", "authors": ["Jiuzhou Han", "Paul Burgess", "Ehsan Shareghi"], "title": "Evaluating LLM-based Approaches to Legal Citation Prediction: Domain-specific Pre-training, Fine-tuning, or RAG? A Benchmark and an Australian Law Case Study", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "For code, data, and models see https://auslawbench.github.io", "summary": "Large Language Models (LLMs) have demonstrated strong potential across legal\ntasks, yet the problem of legal citation prediction remains under-explored. At\nits core, this task demands fine-grained contextual understanding and precise\nidentification of relevant legislation or precedent. We introduce the AusLaw\nCitation Benchmark, a real-world dataset comprising 55k Australian legal\ninstances and 18,677 unique citations which to the best of our knowledge is the\nfirst of its scale and scope. We then conduct a systematic benchmarking across\na range of solutions: (i) standard prompting of both general and\nlaw-specialised LLMs, (ii) retrieval-only pipelines with both generic and\ndomain-specific embeddings, (iii) supervised fine-tuning, and (iv) several\nhybrid strategies that combine LLMs with retrieval augmentation through query\nexpansion, voting ensembles, or re-ranking. Results show that neither general\nnor law-specific LLMs suffice as stand-alone solutions, with performance near\nzero. Instruction tuning (of even a generic open-source LLM) on task-specific\ndataset is among the best performing solutions. We highlight that database\ngranularity along with the type of embeddings play a critical role in\nretrieval-based approaches, with hybrid methods which utilise a trained\nre-ranker delivering the best results. Despite this, a performance gap of\nnearly 50% remains, underscoring the value of this challenging benchmark as a\nrigorous test-bed for future research in legal-domain.", "AI": {"tldr": "The paper introduces the AusLaw Citation Benchmark for legal citation prediction, evaluates various methods, and finds hybrid approaches with retrieval augmentation perform best, though a significant performance gap remains.", "motivation": "Legal citation prediction is under-explored despite LLMs' potential in legal tasks, requiring fine-grained contextual understanding.", "method": "The study benchmarks solutions including standard prompting, retrieval pipelines, supervised fine-tuning, and hybrid strategies combining LLMs with retrieval augmentation.", "result": "General and law-specific LLMs perform poorly alone; instruction tuning and hybrid methods with trained re-rankers yield the best results, but a 50% performance gap persists.", "conclusion": "The AusLaw Benchmark highlights the challenge of legal citation prediction and serves as a test-bed for future research, with hybrid methods showing promise."}}
{"id": "2406.12264", "pdf": "https://arxiv.org/pdf/2406.12264", "abs": "https://arxiv.org/abs/2406.12264", "authors": ["Emanuele Zappala"], "title": "Projection Methods for Operator Learning and Universal Approximation", "categories": ["math.NA", "cs.AI", "cs.LG", "cs.NA"], "comment": "11 pages. Comments are welcome! v2: several typos have been fixed", "summary": "We obtain a new universal approximation theorem for continuous (possibly\nnonlinear) operators on arbitrary Banach spaces using the Leray-Schauder\nmapping. Moreover, we introduce and study a method for operator learning in\nBanach spaces $L^p$ of functions with multiple variables, based on orthogonal\nprojections on polynomial bases. We derive a universal approximation result for\noperators where we learn a linear projection and a finite dimensional mapping\nunder some additional assumptions. For the case of $p=2$, we give some\nsufficient conditions for the approximation results to hold. This article\nserves as the theoretical framework for a deep learning methodology in operator\nlearning.", "AI": {"tldr": "A universal approximation theorem for operators on Banach spaces is presented, using the Leray-Schauder mapping. A method for operator learning in $L^p$ spaces via orthogonal projections on polynomial bases is introduced, with theoretical guarantees.", "motivation": "To provide a theoretical foundation for operator learning in Banach spaces, enabling deep learning methodologies for such problems.", "method": "Uses the Leray-Schauder mapping and orthogonal projections on polynomial bases to approximate operators in $L^p$ spaces.", "result": "Derives universal approximation results for operators, with specific conditions for $p=2$.", "conclusion": "The paper establishes a theoretical framework for operator learning, supporting deep learning applications in this context."}}
{"id": "2505.16713", "pdf": "https://arxiv.org/pdf/2505.16713", "abs": "https://arxiv.org/abs/2505.16713", "authors": ["Shogo Nakakita"], "title": "Sharp concentration of uniform generalization errors in binary linear classification", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "26 pages, 1 figure", "summary": "We examine the concentration of uniform generalization errors around their\nexpectation in binary linear classification problems via an isoperimetric\nargument. In particular, we establish Poincar\\'{e} and log-Sobolev inequalities\nfor the joint distribution of the output labels and the label-weighted input\nvectors, which we apply to derive concentration bounds. The derived\nconcentration bounds are sharp up to moderate multiplicative constants by those\nunder well-balanced labels. In asymptotic analysis, we also show that almost\nsure convergence of uniform generalization errors to their expectation occurs\nin very broad settings, such as proportionally high-dimensional regimes. Using\nthis convergence, we establish uniform laws of large numbers under\ndimension-free conditions.", "AI": {"tldr": "The paper analyzes uniform generalization errors in binary linear classification using isoperimetric arguments, deriving sharp concentration bounds and proving almost sure convergence in high-dimensional regimes.", "motivation": "To understand and quantify the concentration of uniform generalization errors around their expectation in binary linear classification problems.", "method": "Uses isoperimetric arguments to establish Poincar\u00e9 and log-Sobolev inequalities for joint distributions of output labels and label-weighted input vectors, deriving concentration bounds.", "result": "Sharp concentration bounds are derived, and almost sure convergence of uniform generalization errors is shown in high-dimensional settings.", "conclusion": "The results enable uniform laws of large numbers under dimension-free conditions, broadening applicability in high-dimensional regimes."}}
{"id": "2412.17038", "pdf": "https://arxiv.org/pdf/2412.17038", "abs": "https://arxiv.org/abs/2412.17038", "authors": ["Sipeng Shen", "Yunming Zhang", "Dengpan Ye", "Xiuwen Shi", "Long Tang", "Haoran Duan", "Yueyun Shang", "Zhihong Tian"], "title": "ErasableMask: A Robust and Erasable Privacy Protection Scheme against Black-box Face Recognition Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "While face recognition (FR) models have brought remarkable convenience in\nface verification and identification, they also pose substantial privacy risks\nto the public. Existing facial privacy protection schemes usually adopt\nadversarial examples to disrupt face verification of FR models. However, these\nschemes often suffer from weak transferability against black-box FR models and\npermanently damage the identifiable information that cannot fulfill the\nrequirements of authorized operations such as forensics and authentication. To\naddress these limitations, we propose ErasableMask, a robust and erasable\nprivacy protection scheme against black-box FR models. Specifically, via\nrethinking the inherent relationship between surrogate FR models, ErasableMask\nintroduces a novel meta-auxiliary attack, which boosts black-box\ntransferability by learning more general features in a stable and balancing\noptimization strategy. It also offers a perturbation erasion mechanism that\nsupports the erasion of semantic perturbations in protected face without\ndegrading image quality. To further improve performance, ErasableMask employs a\ncurriculum learning strategy to mitigate optimization conflicts between\nadversarial attack and perturbation erasion. Extensive experiments on the\nCelebA-HQ and FFHQ datasets demonstrate that ErasableMask achieves the\nstate-of-the-art performance in transferability, achieving over 72% confidence\non average in commercial FR systems. Moreover, ErasableMask also exhibits\noutstanding perturbation erasion performance, achieving over 90% erasion\nsuccess rate.", "AI": {"tldr": "ErasableMask is a privacy protection scheme for face recognition, enhancing transferability and offering perturbation erasion without degrading image quality.", "motivation": "Address weak transferability and permanent damage in existing facial privacy protection methods.", "method": "Introduces meta-auxiliary attack, perturbation erasion, and curriculum learning.", "result": "Achieves 72% confidence in commercial FR systems and 90% erasion success rate.", "conclusion": "ErasableMask is robust, erasable, and outperforms existing methods."}}
{"id": "2412.07367", "pdf": "https://arxiv.org/pdf/2412.07367", "abs": "https://arxiv.org/abs/2412.07367", "authors": ["Jian Liao", "Yu Feng", "Yujin Zheng", "Jun Zhao", "Suge Wang", "Jianxing Zheng"], "title": "My Words Imply Your Opinion: Reader Agent-based Propagation Enhancement for Personalized Implicit Emotion Analysis", "categories": ["cs.CL"], "comment": null, "summary": "The subtlety of emotional expressions makes implicit emotion analysis (IEA)\nparticularly sensitive to user-specific characteristics. Current studies\npersonalize emotion analysis by focusing on the author but neglect the impact\nof the intended reader on implicit emotional feedback. In this paper, we\nintroduce Personalized IEA (PIEA) and present the RAPPIE model, which addresses\nsubjective variability by incorporating reader feedback. In particular, (1) we\ncreate reader agents based on large language models to simulate reader\nfeedback, overcoming the issue of ``spiral of silence effect'' and data\nincompleteness of real reader reaction. (2) We develop a role-aware multi-view\ngraph learning to model the emotion interactive propagation process in\nscenarios with sparse reader information. (3) We construct two new PIEA\ndatasets covering English and Chinese social media with detailed user metadata,\naddressing the text-centric limitation of existing datasets. Extensive\nexperiments show that RAPPIE significantly outperforms state-of-the-art\nbaselines, demonstrating the value of incorporating reader feedback in PIEA.", "AI": {"tldr": "The paper introduces Personalized Implicit Emotion Analysis (PIEA) and the RAPPIE model, which incorporates reader feedback to improve emotion analysis by addressing subjective variability and data limitations.", "motivation": "Current emotion analysis studies focus on authors but neglect the impact of intended readers on implicit emotional feedback, leading to incomplete analysis.", "method": "The RAPPIE model uses reader agents based on large language models to simulate feedback, employs role-aware multi-view graph learning for sparse reader scenarios, and constructs new PIEA datasets with user metadata.", "result": "RAPPIE outperforms state-of-the-art baselines, showing the value of reader feedback in PIEA.", "conclusion": "Incorporating reader feedback significantly enhances implicit emotion analysis, addressing limitations of current approaches."}}
{"id": "2407.08112", "pdf": "https://arxiv.org/pdf/2407.08112", "abs": "https://arxiv.org/abs/2407.08112", "authors": ["Jerry Huang"], "title": "How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted to The 31st International Conference on Computational\n  Linguistics (COLING), 2025", "summary": "Long sequences occur in abundance within real-world scenarios, hence properly\nmodelling them opens numerous down-stream use-cases. Deep neural networks,\nhowever, have often struggled with these for a variety of reasons. Recent\nadvances, both in system engineering as well as model design, have enabled the\nscaling up of model that are purported to support extended context length. In\nparticular, the state-space and linear recurrent neural network families of\nmodels hypothetically can entend to infinite sequence lenth. However, is this\ntoo good to be true? We conduct an evaluation to show that while such claims\nmay be sound theoretically, there remain large practical gaps that are\nempirically observed. In particular, recurrent models still suffer in the same\nsettings as long-context LLMs with attention. We further show that different\ninductive biases have inconsistent extrapolation capabilities, highlighting the\nneed to further study such paradigms and investigate why long-context models\nseemingly fail to behave as one might expect.", "AI": {"tldr": "The paper evaluates claims about infinite sequence length support in state-space and linear recurrent neural networks, finding practical gaps despite theoretical soundness.", "motivation": "Long sequences are common in real-world scenarios, but deep neural networks struggle with them. Recent advances claim to support extended context length, but practical performance is unclear.", "method": "The study empirically evaluates state-space and linear recurrent neural networks, comparing their performance with long-context LLMs.", "result": "Recurrent models perform similarly to long-context LLMs, with inconsistent extrapolation capabilities due to varying inductive biases.", "conclusion": "Further study is needed to understand why long-context models fail to meet expectations, highlighting gaps between theory and practice."}}
{"id": "2505.16714", "pdf": "https://arxiv.org/pdf/2505.16714", "abs": "https://arxiv.org/abs/2505.16714", "authors": ["Hai-Feng Zhang", "Zhao-Yun Chen", "Peng Wang", "Liang-Liang Guo", "Tian-Le Wang", "Xiao-Yan Yang", "Ren-Ze Zhao", "Ze-An Zhao", "Sheng Zhang", "Lei Du", "Hao-Ran Tao", "Zhi-Long Jia", "Wei-Cheng Kong", "Huan-Yu Liu", "Athanasios V. Vasilakos", "Yang Yang", "Yu-Chun Wu", "Ji Guan", "Peng Duan", "Guo-Ping Guo"], "title": "Experimental robustness benchmark of quantum neural network on a superconducting quantum processor", "categories": ["quant-ph", "cs.LG"], "comment": "There are 8 pages with 5 figures in the main text and 15 pages with\n  14 figures in the supplementary information", "summary": "Quantum machine learning (QML) models, like their classical counterparts, are\nvulnerable to adversarial attacks, hindering their secure deployment. Here, we\nreport the first systematic experimental robustness benchmark for 20-qubit\nquantum neural network (QNN) classifiers executed on a superconducting\nprocessor. Our benchmarking framework features an efficient adversarial attack\nalgorithm designed for QNNs, enabling quantitative characterization of\nadversarial robustness and robustness bounds. From our analysis, we verify that\nadversarial training reduces sensitivity to targeted perturbations by\nregularizing input gradients, significantly enhancing QNN's robustness.\nAdditionally, our analysis reveals that QNNs exhibit superior adversarial\nrobustness compared to classical neural networks, an advantage attributed to\ninherent quantum noise. Furthermore, the empirical upper bound extracted from\nour attack experiments shows a minimal deviation ($3 \\times 10^{-3}$) from the\ntheoretical lower bound, providing strong experimental confirmation of the\nattack's effectiveness and the tightness of fidelity-based robustness bounds.\nThis work establishes a critical experimental framework for assessing and\nimproving quantum adversarial robustness, paving the way for secure and\nreliable QML applications.", "AI": {"tldr": "A benchmarking framework for adversarial robustness in 20-qubit QNNs shows adversarial training enhances robustness, with QNNs outperforming classical networks due to quantum noise.", "motivation": "Quantum machine learning models face adversarial threats, necessitating experimental benchmarks to ensure secure deployment.", "method": "Developed an adversarial attack algorithm for QNNs, tested on a 20-qubit superconducting processor, and analyzed robustness via adversarial training.", "result": "Adversarial training improves QNN robustness; QNNs are more robust than classical networks due to quantum noise. Empirical bounds align closely with theory.", "conclusion": "This framework advances secure QML by experimentally validating adversarial robustness and bounds."}}
{"id": "2412.17105", "pdf": "https://arxiv.org/pdf/2412.17105", "abs": "https://arxiv.org/abs/2412.17105", "authors": ["Lin Wu"], "title": "Refining CNN-based Heatmap Regression with Gradient-based Corner Points for Electrode Localization", "categories": ["cs.CV"], "comment": null, "summary": "We propose a method for detecting the electrode positions in lithium-ion\nbatteries. The process begins by identifying the region of interest (ROI) in\nthe battery's X-ray image through corner point detection. A convolutional\nneural network is then used to regress the pole positions within this ROI.\nFinally, the regressed positions are optimized and corrected using corner point\npriors, significantly mitigating the loss of localization accuracy caused by\noperations such as feature map down-sampling and padding during network\ntraining. Our findings show that combining traditional pixel gradient analysis\nwith CNN-based heatmap regression for keypoint extraction enhances both\naccuracy and efficiency, resulting in significant performance improvements.", "AI": {"tldr": "A method for detecting electrode positions in lithium-ion batteries using X-ray images, combining CNN-based regression with corner point priors for improved accuracy.", "motivation": "To enhance the accuracy and efficiency of electrode position detection in lithium-ion batteries, addressing issues like localization accuracy loss from feature map down-sampling.", "method": "Identify ROI via corner point detection, regress pole positions using CNN, and optimize with corner point priors.", "result": "Combining pixel gradient analysis with CNN-based heatmap regression improves accuracy and efficiency.", "conclusion": "The proposed method significantly enhances performance in electrode position detection."}}
{"id": "2412.12459", "pdf": "https://arxiv.org/pdf/2412.12459", "abs": "https://arxiv.org/abs/2412.12459", "authors": ["Chia-Hsuan Chang", "Jui-Tse Tsai", "Yi-Hang Tsai", "San-Yih Hwang"], "title": "LITA: An Efficient LLM-assisted Iterative Topic Augmentation Framework", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted to PAKDD 2025", "summary": "Topic modeling is widely used for uncovering thematic structures within text\ncorpora, yet traditional models often struggle with specificity and coherence\nin domain-focused applications. Guided approaches, such as SeededLDA and CorEx,\nincorporate user-provided seed words to improve relevance but remain\nlabor-intensive and static. Large language models (LLMs) offer potential for\ndynamic topic refinement and discovery, yet their application often incurs high\nAPI costs. To address these challenges, we propose the LLM-assisted Iterative\nTopic Augmentation framework (LITA), an LLM-assisted approach that integrates\nuser-provided seeds with embedding-based clustering and iterative refinement.\nLITA identifies a small number of ambiguous documents and employs an LLM to\nreassign them to existing or new topics, minimizing API costs while enhancing\ntopic quality. Experiments on two datasets across topic quality and clustering\nperformance metrics demonstrate that LITA outperforms five baseline models,\nincluding LDA, SeededLDA, CorEx, BERTopic, and PromptTopic. Our work offers an\nefficient and adaptable framework for advancing topic modeling and text\nclustering.", "AI": {"tldr": "LITA is an LLM-assisted framework for topic modeling that combines user-provided seeds with embedding-based clustering and iterative refinement, outperforming traditional models while minimizing API costs.", "motivation": "Traditional topic models lack specificity and coherence in domain-focused applications, and guided approaches are labor-intensive. LLMs offer dynamic refinement but incur high costs.", "method": "LITA integrates user-provided seeds with embedding-based clustering and iterative refinement, using LLMs to reassign ambiguous documents to improve topic quality.", "result": "LITA outperforms five baseline models (LDA, SeededLDA, CorEx, BERTopic, PromptTopic) in topic quality and clustering performance on two datasets.", "conclusion": "LITA provides an efficient and adaptable framework for enhancing topic modeling and text clustering."}}
{"id": "2407.12288", "pdf": "https://arxiv.org/pdf/2407.12288", "abs": "https://arxiv.org/abs/2407.12288", "authors": ["Hong Jun Jeon", "Benjamin Van Roy"], "title": "Information-Theoretic Foundations for Machine Learning", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "The progress of machine learning over the past decade is undeniable. In\nretrospect, it is both remarkable and unsettling that this progress was\nachievable with little to no rigorous theory to guide experimentation. Despite\nthis fact, practitioners have been able to guide their future experimentation\nvia observations from previous large-scale empirical investigations. In this\nwork, we propose a theoretical framework which attempts to provide rigor to\nexisting practices in machine learning. To the theorist, we provide a framework\nwhich is mathematically rigorous and leaves open many interesting ideas for\nfuture exploration. To the practitioner, we provide a framework whose results\nare simple, and provide intuition to guide future investigations across a wide\nrange of learning paradigms. Concretely, we provide a theoretical framework\nrooted in Bayesian statistics and Shannon's information theory which is general\nenough to unify the analysis of many phenomena in machine learning. Our\nframework characterizes the performance of an optimal Bayesian learner as it\nlearns from a stream of experience. Unlike existing analyses that weaken with\nincreasing data complexity, our theoretical tools provide accurate insights\nacross diverse machine learning settings. Throughout this work, we derive\ntheoretical results and demonstrate their generality by apply them to derive\ninsights specific to settings. These settings range from learning from data\nwhich is independently and identically distributed under an unknown\ndistribution, to data which is sequential, to data which exhibits hierarchical\nstructure amenable to meta-learning, and finally to data which is not fully\nexplainable under the learner's beliefs (misspecification). These results are\nparticularly relevant as we strive to understand and overcome increasingly\ndifficult machine learning challenges in this endlessly complex world.", "AI": {"tldr": "The paper proposes a theoretical framework rooted in Bayesian statistics and information theory to unify and rigorously analyze diverse machine learning practices, providing insights for both theorists and practitioners.", "motivation": "The lack of rigorous theory guiding machine learning progress despite empirical success motivates the need for a unifying theoretical framework.", "method": "The framework is based on Bayesian statistics and Shannon's information theory, analyzing optimal Bayesian learners across various data settings (i.i.d., sequential, hierarchical, misspecified).", "result": "The framework provides accurate insights across diverse learning paradigms, outperforming existing analyses that falter with data complexity.", "conclusion": "The work offers a versatile theoretical tool to address increasingly complex machine learning challenges, bridging theory and practice."}}
{"id": "2505.16716", "pdf": "https://arxiv.org/pdf/2505.16716", "abs": "https://arxiv.org/abs/2505.16716", "authors": ["Moritz Stargalla", "Christoph Hertrich", "Daniel Reichman"], "title": "The Computational Complexity of Counting Linear Regions in ReLU Neural Networks", "categories": ["cs.CC", "cs.DM", "cs.LG", "cs.NE", "math.CO"], "comment": "25 pages", "summary": "An established measure of the expressive power of a given ReLU neural network\nis the number of linear regions into which it partitions the input space. There\nexist many different, non-equivalent definitions of what a linear region\nactually is. We systematically assess which papers use which definitions and\ndiscuss how they relate to each other. We then analyze the computational\ncomplexity of counting the number of such regions for the various definitions.\nGenerally, this turns out to be an intractable problem. We prove NP- and\n#P-hardness results already for networks with one hidden layer and strong\nhardness of approximation results for two or more hidden layers. Finally, on\nthe algorithmic side, we demonstrate that counting linear regions can at least\nbe achieved in polynomial space for some common definitions.", "AI": {"tldr": "The paper analyzes definitions of linear regions in ReLU neural networks, their relationships, and computational complexity of counting them, proving hardness results and polynomial-space solutions.", "motivation": "To systematically assess and compare definitions of linear regions in ReLU networks and understand the computational challenges of counting them.", "method": "Systematic review of definitions, analysis of their relationships, and computational complexity proofs (NP- and #P-hardness) for counting linear regions.", "result": "Counting linear regions is intractable (NP- and #P-hard) even for simple networks; polynomial-space solutions exist for some definitions.", "conclusion": "The study highlights the computational difficulty of counting linear regions and provides insights into their definitions and relationships."}}
{"id": "2412.19125", "pdf": "https://arxiv.org/pdf/2412.19125", "abs": "https://arxiv.org/abs/2412.19125", "authors": ["Inpyo Hong", "Youngwan Jo", "Hyojeong Lee", "Sunghyun Ahn", "Sanghyun Park"], "title": "Advanced Knowledge Transfer: Refined Feature Distillation for Zero-Shot Quantization in Edge Computing", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ACM SAC 2025", "summary": "We introduce AKT (Advanced Knowledge Transfer), a novel method to enhance the\ntraining ability of low-bit quantized (Q) models in the field of zero-shot\nquantization (ZSQ). Existing research in ZSQ has focused on generating\nhigh-quality data from full-precision (FP) models. However, these approaches\nstruggle with reduced learning ability in low-bit quantization due to its\nlimited information capacity. To overcome this limitation, we propose effective\ntraining strategy compared to data generation. Particularly, we analyzed that\nrefining feature maps in the feature distillation process is an effective way\nto transfer knowledge to the Q model. Based on this analysis, AKT efficiently\ntransfer core information from the FP model to the Q model. AKT is the first\napproach to utilize both spatial and channel attention information in feature\ndistillation in ZSQ. Our method addresses the fundamental gradient exploding\nproblem in low-bit Q models. Experiments on CIFAR-10 and CIFAR-100 datasets\ndemonstrated the effectiveness of the AKT. Our method led to significant\nperformance enhancement in existing generative models. Notably, AKT achieved\nsignificant accuracy improvements in low-bit Q models, achieving\nstate-of-the-art in the 3,5bit scenarios on CIFAR-10. The code is available at\nhttps://github.com/Inpyo-Hong/AKT-Advanced-knowledge-Transfer.", "AI": {"tldr": "AKT (Advanced Knowledge Transfer) enhances low-bit quantized models in zero-shot quantization by refining feature maps and using spatial/channel attention, outperforming existing methods.", "motivation": "Existing zero-shot quantization methods struggle with low-bit models due to limited information capacity. AKT aims to improve knowledge transfer without relying on data generation.", "method": "AKT refines feature maps in feature distillation and uses spatial/channel attention to transfer core information from full-precision to quantized models.", "result": "AKT significantly improves accuracy in low-bit quantized models, achieving state-of-the-art results on CIFAR-10 and CIFAR-100 datasets.", "conclusion": "AKT effectively addresses gradient exploding in low-bit models and outperforms existing methods, demonstrating its potential for practical applications."}}
{"id": "2412.12505", "pdf": "https://arxiv.org/pdf/2412.12505", "abs": "https://arxiv.org/abs/2412.12505", "authors": ["Mingxu Chai", "Ziyu Shen", "Chong Zhang", "Yue Zhang", "Xiao Wang", "Shihan Dou", "Jihua Kang", "Jiazheng Zhang", "Qi Zhang"], "title": "DocFusion: A Unified Framework for Document Parsing Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Document parsing is essential for analyzing complex document structures and\nextracting fine-grained information, supporting numerous downstream\napplications. However, existing methods often require integrating multiple\nindependent models to handle various parsing tasks, leading to high complexity\nand maintenance overhead. To address this, we propose DocFusion, a lightweight\ngenerative model with only 0.28B parameters. It unifies task representations\nand achieves collaborative training through an improved objective function.\nExperiments reveal and leverage the mutually beneficial interaction among\nrecognition tasks, and integrating recognition data significantly enhances\ndetection performance. The final results demonstrate that DocFusion achieves\nstate-of-the-art (SOTA) performance across four key tasks.", "AI": {"tldr": "DocFusion is a lightweight generative model (0.28B parameters) unifying document parsing tasks, achieving SOTA performance by leveraging task interactions.", "motivation": "Existing methods require multiple models for document parsing, leading to complexity and high maintenance.", "method": "DocFusion uses a unified task representation and improved objective function for collaborative training.", "result": "Integrating recognition data boosts detection performance; DocFusion achieves SOTA in four key tasks.", "conclusion": "DocFusion simplifies document parsing with high performance, reducing complexity and overhead."}}
{"id": "2407.21244", "pdf": "https://arxiv.org/pdf/2407.21244", "abs": "https://arxiv.org/abs/2407.21244", "authors": ["Hamidreza Kasaei", "Mohammadreza Kasaei"], "title": "VITAL: Interactive Few-Shot Imitation Learning via Visual Human-in-the-Loop Corrections", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Imitation Learning (IL) has emerged as a powerful approach in robotics,\nallowing robots to acquire new skills by mimicking human actions. Despite its\npotential, the data collection process for IL remains a significant challenge\ndue to the logistical difficulties and high costs associated with obtaining\nhigh-quality demonstrations. To address these issues, we propose a large-scale\ndata generation from a handful of demonstrations through data augmentation in\nsimulation. Our approach leverages affordable hardware and visual processing\ntechniques to collect demonstrations, which are then augmented to create\nextensive training datasets for imitation learning. By utilizing both real and\nsimulated environments, along with human-in-the-loop corrections, we enhance\nthe generalizability and robustness of the learned policies. We evaluated our\nmethod through several rounds of experiments in both simulated and real-robot\nsettings, focusing on tasks of varying complexity, including bottle collecting,\nstacking objects, and hammering. Our experimental results validate the\neffectiveness of our approach in learning robust robot policies from simulated\ndata, significantly improved by human-in-the-loop corrections and real-world\ndata integration. Additionally, we demonstrate the framework's capability to\ngeneralize to new tasks, such as setting a drink tray, showcasing its\nadaptability and potential for handling a wide range of real-world manipulation\ntasks. A video of the experiments can be found at:\nhttps://youtu.be/YeVAMRqRe64?si=R179xDlEGc7nPu8i", "AI": {"tldr": "The paper proposes a method to generate large-scale training data for Imitation Learning (IL) by augmenting a few human demonstrations in simulation, improving policy robustness and generalizability.", "motivation": "Data collection for IL is costly and logistically challenging, limiting its scalability. The paper aims to address this by creating extensive datasets from minimal demonstrations.", "method": "The approach uses affordable hardware and visual processing to collect demonstrations, augments them in simulation, and integrates human-in-the-loop corrections for enhanced robustness.", "result": "Experiments in simulated and real-robot settings show the method's effectiveness in learning robust policies and generalizing to new tasks like setting a drink tray.", "conclusion": "The framework demonstrates adaptability and potential for diverse real-world manipulation tasks, validated by experimental results."}}
{"id": "2505.16723", "pdf": "https://arxiv.org/pdf/2505.16723", "abs": "https://arxiv.org/abs/2505.16723", "authors": ["Thibaud Gloaguen", "Robin Staab", "Nikola Jovanovi\u0107", "Martin Vechev"], "title": "Robust LLM Fingerprinting via Domain-Specific Watermarks", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "As open-source language models (OSMs) grow more capable and are widely shared\nand finetuned, ensuring model provenance, i.e., identifying the origin of a\ngiven model instance, has become an increasingly important issue. At the same\ntime, existing backdoor-based model fingerprinting techniques often fall short\nof achieving key requirements of real-world model ownership detection. In this\nwork, we build on the observation that while current open-source model\nwatermarks fail to achieve reliable content traceability, they can be\neffectively adapted to address the challenge of model provenance. To this end,\nwe introduce the concept of domain-specific watermarking for model\nfingerprinting. Rather than watermarking all generated content, we train the\nmodel to embed watermarks only within specified subdomains (e.g., particular\nlanguages or topics). This targeted approach ensures detection reliability,\nwhile improving watermark durability and quality under a range of real-world\ndeployment settings. Our evaluations show that domain-specific watermarking\nenables model fingerprinting with strong statistical guarantees, controllable\nfalse positive rates, high detection power, and preserved generation quality.\nMoreover, we find that our fingerprints are inherently stealthy and naturally\nrobust to real-world variability across deployment scenarios.", "AI": {"tldr": "Domain-specific watermarking for OSMs improves model provenance by embedding watermarks in specific subdomains, ensuring reliability, durability, and quality.", "motivation": "Ensuring model provenance for widely shared and finetuned OSMs is critical, but existing fingerprinting techniques lack reliability.", "method": "Introduces domain-specific watermarking, training models to embed watermarks only in specified subdomains (e.g., languages or topics).", "result": "Achieves strong statistical guarantees, controllable false positives, high detection power, and preserved generation quality.", "conclusion": "Domain-specific watermarking is a robust and stealthy solution for model fingerprinting in real-world deployments."}}
{"id": "2412.20157", "pdf": "https://arxiv.org/pdf/2412.20157", "abs": "https://arxiv.org/abs/2412.20157", "authors": ["Jingbo Lin", "Zhilu Zhang", "Wenbo Li", "Renjing Pei", "Hang Xu", "Hongzhi Zhang", "Wangmeng Zuo"], "title": "UniRestorer: Universal Image Restoration via Adaptively Estimating Image Degradation at Proper Granularity", "categories": ["cs.CV"], "comment": null, "summary": "Recently, considerable progress has been made in all-in-one image\nrestoration. Generally, existing methods can be degradation-agnostic or\ndegradation-aware. However, the former are limited in leveraging\ndegradation-specific restoration, and the latter suffer from the inevitable\nerror in degradation estimation. Consequently, the performance of existing\nmethods has a large gap compared to specific single-task models. In this work,\nwe make a step forward in this topic, and present our UniRestorer with improved\nrestoration performance. Specifically, we perform hierarchical clustering on\ndegradation space, and train a multi-granularity mixture-of-experts (MoE)\nrestoration model. Then, UniRestorer adopts both degradation and granularity\nestimation to adaptively select an appropriate expert for image restoration. In\ncontrast to existing degradation-agnostic and -aware methods, UniRestorer can\nleverage degradation estimation to benefit degradation specific restoration,\nand use granularity estimation to make the model robust to degradation\nestimation error. Experimental results show that our UniRestorer outperforms\nstate-of-the-art all-in-one methods by a large margin, and is promising in\nclosing the performance gap to specific single task models.", "AI": {"tldr": "UniRestorer improves all-in-one image restoration by combining hierarchical clustering and a multi-granularity MoE model, outperforming existing methods.", "motivation": "Existing methods are either degradation-agnostic (limited in specific restoration) or degradation-aware (prone to estimation errors), creating a performance gap with single-task models.", "method": "Hierarchical clustering on degradation space and training a multi-granularity MoE model, with adaptive expert selection via degradation and granularity estimation.", "result": "UniRestorer outperforms state-of-the-art all-in-one methods and narrows the gap to single-task models.", "conclusion": "UniRestorer effectively balances degradation-specific restoration and robustness to estimation errors, advancing all-in-one image restoration."}}
{"id": "2412.16555", "pdf": "https://arxiv.org/pdf/2412.16555", "abs": "https://arxiv.org/abs/2412.16555", "authors": ["Yanxu Mao", "Peipei Liu", "Tiehan Cui", "Zhaoteng Yan", "Congying Liu", "Datao You"], "title": "Divide and Conquer: A Hybrid Strategy Defeats Multimodal Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are widely applied in various fields of society\ndue to their powerful reasoning, understanding, and generation capabilities.\nHowever, the security issues associated with these models are becoming\nincreasingly severe. Jailbreaking attacks, as an important method for detecting\nvulnerabilities in LLMs, have been explored by researchers who attempt to\ninduce these models to generate harmful content through various attack methods.\nNevertheless, existing jailbreaking methods face numerous limitations, such as\nexcessive query counts, limited coverage of jailbreak modalities, low attack\nsuccess rates, and simplistic evaluation methods. To overcome these\nconstraints, this paper proposes a multimodal jailbreaking method: JMLLM. This\nmethod integrates multiple strategies to perform comprehensive jailbreak\nattacks across text, visual, and auditory modalities. Additionally, we\ncontribute a new and comprehensive dataset for multimodal jailbreaking\nresearch: TriJail, which includes jailbreak prompts for all three modalities.\nExperiments on the TriJail dataset and the benchmark dataset AdvBench,\nconducted on 13 popular LLMs, demonstrate advanced attack success rates and\nsignificant reduction in time overhead.", "AI": {"tldr": "The paper proposes JMLLM, a multimodal jailbreaking method for LLMs, addressing limitations of existing methods by integrating text, visual, and auditory attacks. It introduces the TriJail dataset and achieves high success rates with reduced time overhead.", "motivation": "Existing jailbreaking methods for LLMs have limitations like high query counts, low success rates, and simplistic evaluations. The paper aims to overcome these by proposing a multimodal approach.", "method": "JMLLM integrates multiple strategies for jailbreak attacks across text, visual, and auditory modalities. The TriJail dataset is introduced to support multimodal research.", "result": "Experiments on TriJail and AdvBench datasets show advanced attack success rates and reduced time overhead across 13 popular LLMs.", "conclusion": "JMLLM effectively addresses the limitations of existing jailbreaking methods, demonstrating superior performance in multimodal attacks."}}
{"id": "2409.01175", "pdf": "https://arxiv.org/pdf/2409.01175", "abs": "https://arxiv.org/abs/2409.01175", "authors": ["Andrija Djurisic", "Rosanne Liu", "Mladen Nikolic"], "title": "Logit Scaling for Out-of-Distribution Detection", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "The safe deployment of machine learning and AI models in open-world settings\nhinges critically on the ability to detect out-of-distribution (OOD) data\naccurately, data samples that contrast vastly from what the model was trained\nwith. Current approaches to OOD detection often require further training the\nmodel, and/or statistics about the training data which may no longer be\naccessible. Additionally, many existing OOD detection methods struggle to\nmaintain performance when transferred across different architectures. Our\nresearch tackles these issues by proposing a simple, post-hoc method that does\nnot require access to the training data distribution, keeps a trained network\nintact, and holds strong performance across a variety of architectures. Our\nmethod, Logit Scaling (LTS), as the name suggests, simply scales the logits in\na manner that effectively distinguishes between in-distribution (ID) and OOD\nsamples. We tested our method on benchmarks across various scales, including\nCIFAR-10, CIFAR-100, ImageNet and OpenOOD. The experiments cover 3 ID and 14\nOOD datasets, as well as 9 model architectures. Overall, we demonstrate\nstate-of-the-art performance, robustness and adaptability across different\narchitectures, paving the way towards a universally applicable solution for\nadvanced OOD detection.", "AI": {"tldr": "A post-hoc method called Logit Scaling (LTS) is proposed for OOD detection without needing training data or model retraining, showing strong performance across architectures.", "motivation": "Current OOD detection methods often require retraining or training data access and struggle with cross-architecture performance.", "method": "LTS scales logits to distinguish ID and OOD samples, tested on multiple datasets and architectures.", "result": "Achieves state-of-the-art performance, robustness, and adaptability across 3 ID and 14 OOD datasets and 9 architectures.", "conclusion": "LTS offers a universally applicable solution for advanced OOD detection without compromising model integrity."}}
{"id": "2505.16821", "pdf": "https://arxiv.org/pdf/2505.16821", "abs": "https://arxiv.org/abs/2505.16821", "authors": ["Ziming liu", "Bryan Liu", "Alvaro Valcarce", "Xiaoli Chu"], "title": "LLM-Based Emulation of the Radio Resource Control Layer: Towards AI-Native RAN Protocols", "categories": ["cs.NI", "cs.LG", "eess.SP"], "comment": "This work has been submitted to the IEEE for possible publication.\n  Focuses on applying LLMs to 5G RRC protocol generation; primary: cs.NI;\n  cross-list: eess.SP, cs.LG", "summary": "Integrating large AI models (LAMs) into 6G mobile networks promises to\nredefine protocol design and control-plane intelligence by enabling autonomous,\ncognitive network operations. While industry concepts, such as ETSI's\nExperiential Networked Intelligence (ENI), envision LAM-driven agents for\nadaptive network slicing and intent-based management, practical implementations\nstill face challenges in protocol literacy and real-world deployment. This\npaper presents an end-to-end demonstration of a LAM that generates\nstandards-compliant, ASN.1-encoded Radio Resource Control (RRC) messages as\npart of control-plane procedures inside a gNB. We treat RRC messaging as a\ndomain-specific language and fine-tune a decoder-only transformer model (LLaMA\nclass) using parameter-efficient Low-Rank Adaptation (LoRA) on RRC messages\nlinearized to retain their ASN.1 syntactic structure before standard byte-pair\nencoding tokenization. This enables combinatorial generalization over RRC\nprotocol states while minimizing training overhead. On 30k field-test\nrequest-response pairs, our 8 B model achieves a median cosine similarity of\n0.97 with ground-truth messages on an edge GPU -- a 61 % relative gain over a\nzero-shot LLaMA-3 8B baseline -- indicating substantially improved structural\nand semantic RRC fidelity. Overall, our results show that LAMs, when augmented\nwith Radio Access Network (RAN)-specific reasoning, can directly orchestrate\ncontrol-plane procedures, representing a stepping stone toward the AI-native\nair-interface paradigm. Beyond RRC emulation, this work lays the groundwork for\nfuture AI-native wireless standards.", "AI": {"tldr": "The paper demonstrates a large AI model (LAM) fine-tuned to generate standards-compliant RRC messages for 6G networks, achieving high fidelity and improved performance over baselines.", "motivation": "To address challenges in integrating LAMs into 6G networks, particularly in protocol literacy and real-world deployment, by enabling autonomous, cognitive network operations.", "method": "Fine-tuning a decoder-only transformer model (LLaMA class) using LoRA on linearized ASN.1-encoded RRC messages, retaining syntactic structure for combinatorial generalization.", "result": "The 8B model achieved a median cosine similarity of 0.97 with ground-truth messages, a 61% improvement over a zero-shot baseline.", "conclusion": "LAMs with RAN-specific reasoning can directly orchestrate control-plane procedures, advancing AI-native wireless standards."}}
{"id": "2501.13426", "pdf": "https://arxiv.org/pdf/2501.13426", "abs": "https://arxiv.org/abs/2501.13426", "authors": ["Jian Wang", "Xiaokang Zhang", "Xianping Ma", "Weikang Yu", "Pedram Ghamisi"], "title": "Auto-Prompting SAM for Weakly Supervised Landslide Extraction", "categories": ["cs.CV"], "comment": "5 pages, 5 figures", "summary": "Weakly supervised landslide extraction aims to identify landslide regions\nfrom remote sensing data using models trained with weak labels, particularly\nimage-level labels. However, it is often challenged by the imprecise boundaries\nof the extracted objects due to the lack of pixel-wise supervision and the\nproperties of landslide objects. To tackle these issues, we propose a simple\nyet effective method by auto-prompting the Segment Anything Model (SAM), i.e.,\nAPSAM. Instead of depending on high-quality class activation maps (CAMs) for\npseudo-labeling or fine-tuning SAM, our method directly yields fine-grained\nsegmentation masks from SAM inference through prompt engineering. Specifically,\nit adaptively generates hybrid prompts from the CAMs obtained by an object\nlocalization network. To provide sufficient information for SAM prompting, an\nadaptive prompt generation (APG) algorithm is designed to fully leverage the\nvisual patterns of CAMs, enabling the efficient generation of pseudo-masks for\nlandslide extraction. These informative prompts are able to identify the extent\nof landslide areas (box prompts) and denote the centers of landslide objects\n(point prompts), guiding SAM in landslide segmentation. Experimental results on\nhigh-resolution aerial and satellite datasets demonstrate the effectiveness of\nour method, achieving improvements of at least 3.0\\% in F1 score and 3.69\\% in\nIoU compared to other state-of-the-art methods. The source codes and datasets\nwill be available at https://github.com/zxk688.", "AI": {"tldr": "The paper proposes APSAM, a method for weakly supervised landslide extraction using the Segment Anything Model (SAM) with adaptive prompt generation, improving accuracy over existing methods.", "motivation": "Weakly supervised landslide extraction faces challenges like imprecise boundaries due to lack of pixel-wise supervision. The goal is to improve segmentation accuracy without fine-tuning SAM or relying on high-quality CAMs.", "method": "APSAM auto-prompts SAM using hybrid prompts (box and point) generated adaptively from CAMs via an APG algorithm, enabling fine-grained segmentation without fine-tuning.", "result": "APSAM outperforms state-of-the-art methods, achieving at least 3.0% higher F1 score and 3.69% higher IoU on aerial and satellite datasets.", "conclusion": "APSAM is a simple yet effective solution for weakly supervised landslide extraction, leveraging SAM's capabilities through adaptive prompt engineering."}}
{"id": "2412.17933", "pdf": "https://arxiv.org/pdf/2412.17933", "abs": "https://arxiv.org/abs/2412.17933", "authors": ["Martin Fajcik", "Martin Docekal", "Jan Dolezal", "Karel Ondrej", "Karel Bene\u0161", "Jan Kapsa", "Pavel Smrz", "Alexander Polok", "Michal Hradis", "Zuzana Neverilova", "Ales Horak", "Radoslav Sabol", "Michal Stefanik", "Adam Jirkovsky", "David Adamczyk", "Petr Hyner", "Jan Hula", "Hynek Kydlicek"], "title": "BenCzechMark : A Czech-centric Multitask and Multimetric Benchmark for Large Language Models with Duel Scoring Mechanism", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to TACL", "summary": "We present BenCzechMark (BCM), the first comprehensive Czech language\nbenchmark designed for large language models, offering diverse tasks, multiple\ntask formats, and multiple evaluation metrics. Its duel scoring system is\ngrounded in statistical significance theory and uses aggregation across tasks\ninspired by social preference theory. Our benchmark encompasses 50 challenging\ntasks, with corresponding test datasets, primarily in native Czech, with 14\nnewly collected ones. These tasks span 8 categories and cover diverse domains,\nincluding historical Czech news, essays from pupils or language learners, and\nspoken word. Furthermore, we collect and clean BUT-Large Czech Collection, the\nlargest publicly available clean Czech language corpus, and use it for (i)\ncontamination analysis and (ii) continuous pretraining of the first\nCzech-centric 7B language model with Czech-specific tokenization. We use our\nmodel as a baseline for comparison with publicly available multilingual models.\nLastly, we release and maintain a leaderboard with existing 50 model\nsubmissions, where new model submissions can be made at\nhttps://huggingface.co/spaces/CZLC/BenCzechMark.", "AI": {"tldr": "BenCzechMark (BCM) is the first Czech language benchmark for large language models, featuring 50 diverse tasks, a duel scoring system, and a new Czech-centric 7B model.", "motivation": "To address the lack of a comprehensive Czech language benchmark for evaluating large language models.", "method": "Developed a benchmark with 50 tasks across 8 categories, introduced a duel scoring system, and created a Czech-centric 7B model using the BUT-Large Czech Collection.", "result": "The benchmark includes diverse tasks and a baseline model, with a leaderboard for model submissions.", "conclusion": "BCM fills a gap in Czech language evaluation and provides tools for future research and model development."}}
{"id": "2409.04367", "pdf": "https://arxiv.org/pdf/2409.04367", "abs": "https://arxiv.org/abs/2409.04367", "authors": ["Maria-Florina Balcan", "Anh Tuan Nguyen", "Dravyansh Sharma"], "title": "Algorithm Configuration for Structured Pfaffian Settings", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted to TMLR", "summary": "Data-driven algorithm design automatically adapts algorithms to specific\napplication domains, achieving better performance. In the context of\nparameterized algorithms, this approach involves tuning the algorithm's\nhyperparameters using problem instances drawn from the problem distribution of\nthe target application domain. This can be achieved by maximizing empirical\nutilities that measure the algorithms' performance as a function of their\nhyperparameters, using problem instances. While empirical evidence supports the\neffectiveness of data-driven algorithm design, providing theoretical guarantees\nfor several parameterized families remains challenging. This is due to the\nintricate behaviors of their corresponding utility functions, which typically\nadmit piecewise discontinuous structures. In this work, we present refined\nframeworks for providing learning guarantees for parameterized data-driven\nalgorithm design problems in both distributional and online learning settings.\nFor the distributional learning setting, we introduce the \\textit{Pfaffian GJ\nframework}, an extension of the classical \\textit{GJ framework}, that is\ncapable of providing learning guarantees for function classes for which the\ncomputation involves Pfaffian functions. Unlike the GJ framework, which is\nlimited to function classes with computation characterized by rational\nfunctions, our proposed framework can deal with function classes involving\nPfaffian functions, which are much more general and widely applicable. We then\nshow that for many parameterized algorithms of interest, their utility function\npossesses a \\textit{refined piecewise structure}, which automatically\ntranslates to learning guarantees using our proposed framework.", "AI": {"tldr": "The paper introduces refined frameworks for theoretical guarantees in data-driven algorithm design, addressing challenges in parameterized algorithms by leveraging Pfaffian functions and piecewise structures.", "motivation": "To overcome the lack of theoretical guarantees for data-driven algorithm design in parameterized algorithms due to complex utility functions.", "method": "Proposes the Pfaffian GJ framework, extending the classical GJ framework to handle Pfaffian functions, and analyzes utility functions with refined piecewise structures.", "result": "The framework provides learning guarantees for parameterized algorithms in distributional and online settings, applicable to broader function classes.", "conclusion": "The refined frameworks enhance theoretical understanding and applicability of data-driven algorithm design for parameterized algorithms."}}
{"id": "2505.16879", "pdf": "https://arxiv.org/pdf/2505.16879", "abs": "https://arxiv.org/abs/2505.16879", "authors": ["Hannah Sansford", "Nick Whiteley", "Patrick Rubin-Delanchy"], "title": "How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present a generalised Hanson-Wright inequality and use it to establish new\nstatistical insights into the geometry of data point-clouds. In the setting of\na general random function model of data, we clarify the roles played by three\nnotions of dimensionality: ambient intrinsic dimension $p_{\\mathrm{int}}$,\nwhich measures total variability across orthogonal feature directions;\ncorrelation rank, which measures functional complexity across samples; and\nlatent intrinsic dimension, which is the dimension of manifold structure hidden\nin data. Our analysis shows that in order for persistence diagrams to reveal\nlatent homology and for manifold structure to emerge it is sufficient that\n$p_{\\mathrm{int}}\\gg \\log n$, where $n$ is the sample size. Informed by these\ntheoretical perspectives, we revisit the ground-breaking neuroscience discovery\nof toroidal structure in grid-cell activity made by Gardner et al. (Nature,\n2022): our findings reveal, for the first time, evidence that this structure is\nin fact isometric to physical space, meaning that grid cell activity conveys a\ngeometrically faithful representation of the real world.", "AI": {"tldr": "A generalized Hanson-Wright inequality is used to analyze data point-cloud geometry, revealing insights into dimensionality and manifold structure. The findings are applied to neuroscience, confirming toroidal structure in grid-cell activity is geometrically faithful to physical space.", "motivation": "To clarify the roles of different dimensionality notions in data geometry and apply theoretical insights to real-world neuroscience discoveries.", "method": "Uses a generalized Hanson-Wright inequality to analyze data point-clouds, focusing on ambient intrinsic dimension, correlation rank, and latent intrinsic dimension.", "result": "Shows that persistence diagrams reveal latent homology when $p_{\\mathrm{int}} \\gg \\log n$. Confirms toroidal structure in grid-cell activity is isometric to physical space.", "conclusion": "Theoretical insights into dimensionality and manifold structure are validated by real-world neuroscience data, demonstrating geometrically faithful representations in grid-cell activity."}}
{"id": "2501.15415", "pdf": "https://arxiv.org/pdf/2501.15415", "abs": "https://arxiv.org/abs/2501.15415", "authors": ["Siqi Fan", "Yuguang Xie", "Bowen Cai", "Ailin Xie", "Gaochao Liu", "Mu Qiao", "Jie Xing", "Zaiqing Nie"], "title": "OCSU: Optical Chemical Structure Understanding for Molecule-centric Scientific Discovery", "categories": ["cs.CV"], "comment": null, "summary": "Understanding the chemical structure from a graphical representation of a\nmolecule is a challenging image caption task that would greatly benefit\nmolecule-centric scientific discovery. Variations in molecular images and\ncaption subtasks pose a significant challenge in both image representation\nlearning and task modeling. Yet, existing methods only focus on a specific\ncaption task that translates a molecular image into its graph structure, i.e.,\nOCSR. In this paper, we propose the Optical Chemical Structure Understanding\n(OCSU) task, which extends low-level recognition to multilevel understanding\nand aims to translate chemical structure diagrams into readable strings for\nboth machine and chemist. To facilitate the development of OCSU technology, we\nexplore both OCSR-based and OCSR-free paradigms. We propose DoubleCheck to\nenhance OCSR performance via attentive feature enhancement for local ambiguous\natoms. It can be cascaded with existing SMILES-based molecule understanding\nmethods to achieve OCSU. Meanwhile, Mol-VL is a vision-language model\nend-to-end optimized for OCSU. We also construct Vis-CheBI20, the first\nlarge-scale OCSU dataset. Through comprehensive experiments, we demonstrate the\nproposed approaches excel at providing chemist-readable caption for chemical\nstructure diagrams, which provide solid baselines for further research. Our\ncode, model, and data are open-sourced at https://github.com/PharMolix/OCSU.", "AI": {"tldr": "The paper introduces the Optical Chemical Structure Understanding (OCSU) task, extending molecule image captioning beyond OCSR, and proposes two methods (DoubleCheck and Mol-VL) with a new dataset (Vis-CheBI20).", "motivation": "To advance molecule-centric discovery by translating chemical structure diagrams into readable strings for both machines and chemists, addressing limitations of existing OCSR methods.", "method": "Proposes OCSU task, explores OCSR-based (DoubleCheck) and OCSR-free (Mol-VL) paradigms, and introduces Vis-CheBI20 dataset.", "result": "Demonstrates superior performance in providing chemist-readable captions, establishing baselines for OCSU research.", "conclusion": "The proposed methods and dataset advance chemical structure understanding, with open-sourced resources for further research."}}
{"id": "2501.05714", "pdf": "https://arxiv.org/pdf/2501.05714", "abs": "https://arxiv.org/abs/2501.05714", "authors": ["Chen Huang", "Yang Deng", "Wenqiang Lei", "Jiancheng Lv", "Tat-Seng Chua", "Jimmy Xiangji Huang"], "title": "How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "ACL 2025 Main paper", "summary": "With the advancement of large language models (LLMs), intelligent models have\nevolved from mere tools to autonomous agents with their own goals and\nstrategies for cooperating with humans. This evolution has birthed a novel\nparadigm in NLP, i.e., human-model cooperation, that has yielded remarkable\nprogress in numerous NLP tasks in recent years. In this paper, we take the\nfirst step to present a thorough review of human-model cooperation, exploring\nits principles, formalizations, and open challenges. In particular, we\nintroduce a new taxonomy that provides a unified perspective to summarize\nexisting approaches. Also, we discuss potential frontier areas and their\ncorresponding challenges. We regard our work as an entry point, paving the way\nfor more breakthrough research in this regard.", "AI": {"tldr": "A review of human-model cooperation in NLP, introducing a taxonomy and discussing challenges.", "motivation": "To explore the evolution of LLMs into autonomous agents and their cooperation with humans, addressing gaps in the field.", "method": "Presents a thorough review, introduces a new taxonomy, and discusses principles and challenges.", "result": "A unified perspective on existing approaches and identification of frontier areas.", "conclusion": "The paper serves as an entry point for future research in human-model cooperation."}}
{"id": "2409.06280", "pdf": "https://arxiv.org/pdf/2409.06280", "abs": "https://arxiv.org/abs/2409.06280", "authors": ["Zitao Chen", "Karthik Pattabiraman"], "title": "Anonymity Unveiled: A Practical Framework for Auditing Data Use in Deep Learning Models", "categories": ["cs.CR", "cs.AI"], "comment": "A shorter version of this paper will appear in CCS'25", "summary": "The rise of deep learning (DL) has led to a surging demand for training data,\nwhich incentivizes the creators of DL models to trawl through the Internet for\ntraining materials. Meanwhile, users often have limited control over whether\ntheir data (e.g., facial images) are used to train DL models without their\nconsent, which has engendered pressing concerns.\n  This work proposes MembershipTracker, a practical data auditing tool that can\nempower ordinary users to reliably detect the unauthorized use of their data in\ntraining DL models. We view data auditing through the lens of membership\ninference (MI). MembershipTracker consists of a lightweight data marking\ncomponent to mark the target data with small and targeted changes, which can be\nstrongly memorized by the model trained on them; and a specialized MI-based\nverification process to audit whether the model exhibits strong memorization on\nthe target samples.\n  MembershipTracker only requires the users to mark a small fraction of data\n(0.005% to 0.1% in proportion to the training set), and it enables the users to\nreliably detect the unauthorized use of their data (average 0% FPR@100% TPR).\nWe show that MembershipTracker is highly effective across various settings,\nincluding industry-scale training on the full-size ImageNet-1k dataset. We\nfinally evaluate MembershipTracker under multiple classes of countermeasures.", "AI": {"tldr": "MembershipTracker is a tool for users to detect unauthorized use of their data in DL models via lightweight marking and MI-based verification.", "motivation": "Address concerns about unauthorized use of personal data in DL training without consent.", "method": "Uses a lightweight data marking component and MI-based verification to detect memorization.", "result": "Highly effective, requiring minimal user-marked data (0.005%-0.1%) with 0% FPR@100% TPR.", "conclusion": "MembershipTracker is practical and robust, even against countermeasures, for data auditing."}}
{"id": "2505.16893", "pdf": "https://arxiv.org/pdf/2505.16893", "abs": "https://arxiv.org/abs/2505.16893", "authors": ["Shuichi Nishino", "Tomohiro Shiraishi", "Teruyuki Katsuoka", "Ichiro Takeuchi"], "title": "Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have gained prominence for their ability to\nprocess graph-structured data across various domains. However, interpreting GNN\ndecisions remains a significant challenge, leading to the adoption of saliency\nmaps for identifying influential nodes and edges. Despite their utility, the\nreliability of GNN saliency maps has been questioned, particularly in terms of\ntheir robustness to noise. In this study, we propose a statistical testing\nframework to rigorously evaluate the significance of saliency maps. Our main\ncontribution lies in addressing the inflation of the Type I error rate caused\nby double-dipping of data, leveraging the framework of Selective Inference. Our\nmethod provides statistically valid $p$-values while controlling the Type I\nerror rate, ensuring that identified salient subgraphs contain meaningful\ninformation rather than random artifacts. To demonstrate the effectiveness of\nour method, we conduct experiments on both synthetic and real-world datasets,\nshowing its effectiveness in assessing the reliability of GNN interpretations.", "AI": {"tldr": "A framework for statistically validating GNN saliency maps to ensure reliability and control Type I error rates.", "motivation": "Interpreting GNN decisions is challenging, and existing saliency maps lack robustness to noise, raising reliability concerns.", "method": "Proposes a statistical testing framework using Selective Inference to evaluate saliency maps, addressing data double-dipping and controlling Type I error.", "result": "The method provides valid p-values and identifies meaningful salient subgraphs, demonstrated on synthetic and real-world datasets.", "conclusion": "The framework effectively assesses GNN saliency map reliability, ensuring interpretations are statistically significant."}}
{"id": "2501.17983", "pdf": "https://arxiv.org/pdf/2501.17983", "abs": "https://arxiv.org/abs/2501.17983", "authors": ["Xudong Wang", "Yaxin Peng", "Chaomin Shen"], "title": "Efficient Feature Fusion for UAV Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Object detection in unmanned aerial vehicle (UAV) remote sensing images poses\nsignificant challenges due to unstable image quality, small object sizes,\ncomplex backgrounds, and environmental occlusions. Small objects, in\nparticular, occupy small portions of images, making their accurate detection\nhighly difficult. Existing multi-scale feature fusion methods address these\nchallenges to some extent by aggregating features across different resolutions.\nHowever, they often fail to effectively balance the classification and\nlocalization performance for small objects, primarily due to insufficient\nfeature representation and imbalanced network information flow. In this paper,\nwe propose a novel feature fusion framework specifically designed for UAV\nobject detection tasks to enhance both localization accuracy and classification\nperformance. The proposed framework integrates hybrid upsampling and\ndownsampling modules, enabling feature maps from different network depths to be\nflexibly adjusted to arbitrary resolutions. This design facilitates cross-layer\nconnections and multi-scale feature fusion, ensuring improved representation of\nsmall objects. Our approach leverages hybrid downsampling to enhance\nfine-grained feature representation, improving spatial localization of small\ntargets, even under complex conditions. Simultaneously, the upsampling module\naggregates global contextual information, optimizing feature consistency across\nscales and enhancing classification robustness in cluttered scenes.\nExperimental results on two public UAV datasets demonstrate the effectiveness\nof the proposed framework. Integrated into the YOLO-v10 model, our method\nachieves a 2% improvement in average precision (AP) compared to the baseline\nYOLO-v10 model, while maintaining the same number of parameters. These results\nhighlight the potential of our framework for accurate and efficient UAV object\ndetection.", "AI": {"tldr": "A novel feature fusion framework improves UAV object detection by balancing classification and localization for small objects, achieving a 2% AP boost over YOLO-v10.", "motivation": "Challenges in UAV object detection include unstable image quality, small object sizes, and complex backgrounds, which existing methods struggle to address effectively.", "method": "Proposes a framework with hybrid upsampling and downsampling modules for flexible feature map adjustment, enhancing small object representation and multi-scale fusion.", "result": "Achieves a 2% AP improvement on public UAV datasets while maintaining the same parameter count as YOLO-v10.", "conclusion": "The framework shows promise for accurate and efficient UAV object detection, particularly for small objects in complex environments."}}
{"id": "2501.18101", "pdf": "https://arxiv.org/pdf/2501.18101", "abs": "https://arxiv.org/abs/2501.18101", "authors": ["Jack Lanchantin", "Angelica Chen", "Shehzaad Dhuliawala", "Ping Yu", "Jason Weston", "Sainbayar Sukhbaatar", "Ilia Kulikov"], "title": "Diverse Preference Optimization", "categories": ["cs.CL"], "comment": null, "summary": "Post-training of language models, either through reinforcement learning,\npreference optimization or supervised finetuning, tends to sharpen the output\nprobability distribution and reduce the diversity of generated responses. This\nis particularly a problem for creative generative tasks where varied responses\nare desired. In this work we introduce Diverse Preference Optimization (DivPO),\nan optimization method which learns to generate much more diverse responses\nthan standard pipelines, while maintaining the quality of the generations. In\nDivPO, preference pairs are selected by first considering a pool of responses,\nand a measure of diversity among them, and selecting chosen examples as being\nmore rare but high quality, while rejected examples are more common, but low\nquality. DivPO results in generating 45.6% more diverse persona attributes, and\na 74.6% increase in story diversity, while maintaining similar win rates as\nstandard baselines. On general instruction following, DivPO results in a 46.2%\nincrease in diversity, and a 2.4% winrate improvement compared to DPO.", "AI": {"tldr": "DivPO introduces a method to enhance response diversity in language models while maintaining quality, outperforming standard pipelines in diversity metrics.", "motivation": "Standard post-training methods reduce response diversity, which is problematic for creative tasks.", "method": "DivPO selects preference pairs based on diversity and quality, favoring rare but high-quality responses.", "result": "DivPO increases diversity by 45.6% in persona attributes and 74.6% in stories, with comparable win rates.", "conclusion": "DivPO effectively balances diversity and quality, outperforming baselines like DPO in diversity and win rates."}}
{"id": "2410.01324", "pdf": "https://arxiv.org/pdf/2410.01324", "abs": "https://arxiv.org/abs/2410.01324", "authors": ["Jaeyoung Park", "Minsu Kim", "Steven Euijong Whang"], "title": "Fair Class-Incremental Learning using Sample Weighting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Model fairness is becoming important in class-incremental learning for\nTrustworthy AI. While accuracy has been a central focus in class-incremental\nlearning, fairness has been relatively understudied. However, naively using all\nthe samples of the current task for training results in unfair catastrophic\nforgetting for certain sensitive groups including classes. We theoretically\nanalyze that forgetting occurs if the average gradient vector of the current\ntask data is in an \"opposite direction\" compared to the average gradient vector\nof a sensitive group, which means their inner products are negative. We then\npropose a fair class-incremental learning framework that adjusts the training\nweights of current task samples to change the direction of the average gradient\nvector and thus reduce the forgetting of underperforming groups and achieve\nfairness. For various group fairness measures, we formulate optimization\nproblems to minimize the overall losses of sensitive groups while minimizing\nthe disparities among them. We also show the problems can be solved with linear\nprogramming and propose an efficient Fairness-aware Sample Weighting (FSW)\nalgorithm. Experiments show that FSW achieves better accuracy-fairness tradeoff\nresults than state-of-the-art approaches on real datasets.", "AI": {"tldr": "The paper addresses fairness in class-incremental learning, proposing a framework to mitigate unfair forgetting of sensitive groups by adjusting sample weights and solving optimization problems for fairness.", "motivation": "Fairness is understudied in class-incremental learning, and naive training can lead to unfair forgetting of sensitive groups.", "method": "Theoretical analysis of gradient vector directions and a Fairness-aware Sample Weighting (FSW) algorithm to adjust training weights and solve optimization problems.", "result": "FSW achieves better accuracy-fairness tradeoff than state-of-the-art methods on real datasets.", "conclusion": "The proposed framework effectively balances fairness and accuracy in class-incremental learning."}}
{"id": "2505.16901", "pdf": "https://arxiv.org/pdf/2505.16901", "abs": "https://arxiv.org/abs/2505.16901", "authors": ["Hongyuan Tao", "Ying Zhang", "Zhenhao Tang", "Hongen Peng", "Xukun Zhu", "Bingchang Liu", "Yingguang Yang", "Ziyin Zhang", "Zhaogui Xu", "Haipeng Zhang", "Linchao Zhu", "Rui Wang", "Hang Yu", "Jianguo Li", "Peng Di"], "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "categories": ["cs.SE", "cs.LG"], "comment": "31 pages, 9 figures", "summary": "Recent advances in Large Language Models (LLMs) have shown promise in\nfunction-level code generation, yet repository-level software engineering tasks\nremain challenging. Current solutions predominantly rely on proprietary LLM\nagents, which introduce unpredictability and limit accessibility, raising\nconcerns about data privacy and model customization. This paper investigates\nwhether open-source LLMs can effectively address repository-level tasks without\nrequiring agent-based approaches. We demonstrate this is possible by enabling\nLLMs to comprehend functions and files within codebases through their semantic\ninformation and structural dependencies. To this end, we introduce Code Graph\nModels (CGMs), which integrate repository code graph structures into the LLM's\nattention mechanism and map node attributes to the LLM's input space using a\nspecialized adapter. When combined with an agentless graph RAG framework, our\napproach achieves a 43.00% resolution rate on the SWE-bench Lite benchmark\nusing the open-source Qwen2.5-72B model. This performance ranks first among\nopen weight models, second among methods with open-source systems, and eighth\noverall, surpassing the previous best open-source model-based method by 12.33%.", "AI": {"tldr": "Open-source LLMs can tackle repository-level tasks without agents by using Code Graph Models (CGMs), achieving a 43.00% resolution rate on SWE-bench Lite.", "motivation": "Proprietary LLM agents for repository-level tasks introduce unpredictability, accessibility issues, and privacy concerns. This paper explores if open-source LLMs can solve these tasks without agents.", "method": "Introduces CGMs, integrating repository code graph structures into LLMs via an adapter and a graph RAG framework.", "result": "Achieves 43.00% resolution rate on SWE-bench Lite, ranking first among open-weight models and surpassing prior open-source methods by 12.33%.", "conclusion": "Open-source LLMs with CGMs can effectively handle repository-level tasks, offering a viable alternative to proprietary agent-based solutions."}}
{"id": "2502.07203", "pdf": "https://arxiv.org/pdf/2502.07203", "abs": "https://arxiv.org/abs/2502.07203", "authors": ["Xingpei Ma", "Jiaran Cai", "Yuansheng Guan", "Shenneng Huang", "Qiang Zhang", "Shunsi Zhang"], "title": "Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Recent diffusion-based talking face generation models have demonstrated\nimpressive potential in synthesizing videos that accurately match a speech\naudio clip with a given reference identity. However, existing approaches still\nencounter significant challenges due to uncontrollable factors, such as\ninaccurate lip-sync, inappropriate head posture and the lack of fine-grained\ncontrol over facial expressions. In order to introduce more face-guided\nconditions beyond speech audio clips, a novel two-stage training framework\nPlaymate is proposed to generate more lifelike facial expressions and talking\nfaces. In the first stage, we introduce a decoupled implicit 3D representation\nalong with a meticulously designed motion-decoupled module to facilitate more\naccurate attribute disentanglement and generate expressive talking videos\ndirectly from audio cues. Then, in the second stage, we introduce an\nemotion-control module to encode emotion control information into the latent\nspace, enabling fine-grained control over emotions and thereby achieving the\nability to generate talking videos with desired emotion. Extensive experiments\ndemonstrate that Playmate not only outperforms existing state-of-the-art\nmethods in terms of video quality, but also exhibits strong competitiveness in\nlip synchronization while offering improved flexibility in controlling emotion\nand head pose. The code will be available at\nhttps://github.com/Playmate111/Playmate.", "AI": {"tldr": "Playmate is a two-stage framework for generating lifelike talking faces with improved lip-sync, head posture, and emotion control, outperforming existing methods.", "motivation": "Existing diffusion-based models struggle with inaccurate lip-sync, inappropriate head posture, and lack of fine-grained facial expression control.", "method": "A two-stage approach: (1) decoupled implicit 3D representation for accurate attribute disentanglement, (2) emotion-control module for fine-grained emotion manipulation.", "result": "Playmate achieves superior video quality, lip synchronization, and flexibility in controlling emotion and head pose.", "conclusion": "Playmate advances talking face generation by addressing key challenges and enabling expressive, controllable outputs."}}
{"id": "2502.00675", "pdf": "https://arxiv.org/pdf/2502.00675", "abs": "https://arxiv.org/abs/2502.00675", "authors": ["Minghang Deng", "Ashwin Ramachandran", "Canwen Xu", "Lanxiang Hu", "Zhewei Yao", "Anupam Datta", "Hao Zhang"], "title": "ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Consensus Enforcement, and Column Exploration", "categories": ["cs.CL", "I.2.7; I.2.0; H.2.0"], "comment": "32 pages, 2 figures", "summary": "We present ReFoRCE, a Text-to-SQL agent that tops the Spider 2.0\nleaderboard--a challenging benchmark reflecting complex, real-world Text-to-SQL\nscenarios. While Text-to-SQL systems enable natural language queries over\nstructured databases, deploying them in enterprise environments remains\ndifficult due to large, complex schemas (with over 1,000 columns), diverse SQL\ndialects (e.g., BigQuery, Snowflake), and sophisticated query requirements\n(e.g., transformations and analytics). ReFoRCE addresses these challenges\nthrough: (a) database information compression via pattern-based table grouping\nand LLM-guided schema linking to alleviate long-context issues; (b)\nself-refinement to iteratively correct syntax and semantic errors across\ndialects; (c) majority-vote consensus to select high-confidence candidates\nwhile deferring ambiguous cases arising from sophisticated queries; and (d)\niterative column exploration guided by execution feedback to resolve those\ndeferred cases. ReFoRCE achieves new state-of-the-art results, with scores of\n35.83 on Spider 2.0-Snow and 36.56 on Spider 2.0-Lite.", "AI": {"tldr": "ReFoRCE is a Text-to-SQL agent that addresses challenges in enterprise environments, achieving top performance on the Spider 2.0 benchmark.", "motivation": "Deploying Text-to-SQL systems in enterprise settings is difficult due to large schemas, diverse SQL dialects, and complex queries.", "method": "ReFoRCE uses database compression, self-refinement, majority-vote consensus, and iterative column exploration to handle these challenges.", "result": "ReFoRCE achieves state-of-the-art scores of 35.83 on Spider 2.0-Snow and 36.56 on Spider 2.0-Lite.", "conclusion": "ReFoRCE effectively tackles enterprise Text-to-SQL challenges, setting new benchmarks in performance."}}
{"id": "2410.02693", "pdf": "https://arxiv.org/pdf/2410.02693", "abs": "https://arxiv.org/abs/2410.02693", "authors": ["Thibaud Gloaguen", "Nikola Jovanovi\u0107", "Robin Staab", "Martin Vechev"], "title": "Discovering Spoofing Attempts on Language Model Watermarks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "LLM watermarks stand out as a promising way to attribute ownership of\nLLM-generated text. One threat to watermark credibility comes from spoofing\nattacks, where an unauthorized third party forges the watermark, enabling it to\nfalsely attribute arbitrary texts to a particular LLM. Despite recent work\ndemonstrating that state-of-the-art schemes are, in fact, vulnerable to\nspoofing, no prior work has focused on post-hoc methods to discover spoofing\nattempts. In this work, we for the first time propose a reliable statistical\nmethod to distinguish spoofed from genuinely watermarked text, suggesting that\ncurrent spoofing attacks are less effective than previously thought. In\nparticular, we show that regardless of their underlying approach, all current\nlearning-based spoofing methods consistently leave observable artifacts in\nspoofed texts, indicative of watermark forgery. We build upon these findings to\npropose rigorous statistical tests that reliably reveal the presence of such\nartifacts and thus demonstrate that a watermark has been spoofed. Our\nexperimental evaluation shows high test power across all learning-based\nspoofing methods, providing insights into their fundamental limitations and\nsuggesting a way to mitigate this threat. We make all our code available at\nhttps://github.com/eth-sri/watermark-spoofing-detection .", "AI": {"tldr": "A statistical method to detect spoofed LLM watermarks is proposed, revealing artifacts in forged texts and demonstrating current spoofing attacks' limitations.", "motivation": "Address the threat of spoofing attacks on LLM watermarks, which falsely attribute texts to LLMs, by developing a detection method.", "method": "Propose statistical tests to identify artifacts in spoofed texts, leveraging observable patterns left by learning-based spoofing methods.", "result": "High test power across all learning-based spoofing methods, showing their fundamental limitations and potential mitigation.", "conclusion": "The method reliably detects spoofed watermarks, suggesting current attacks are less effective and providing a mitigation strategy."}}
{"id": "2505.16923", "pdf": "https://arxiv.org/pdf/2505.16923", "abs": "https://arxiv.org/abs/2505.16923", "authors": ["Yuhui Zhang", "Dongshen Wu", "Yuichiro Wada", "Takafumi Kanamori"], "title": "TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A reliable uncertainty estimation method is the foundation of many modern\nout-of-distribution (OOD) detectors, which are critical for safe deployments of\ndeep learning models in the open world. In this work, we propose TULiP, a\ntheoretically-driven post-hoc uncertainty estimator for OOD detection. Our\napproach considers a hypothetical perturbation applied to the network before\nconvergence. Based on linearized training dynamics, we bound the effect of such\nperturbation, resulting in an uncertainty score computable by perturbing model\nparameters. Ultimately, our approach computes uncertainty from a set of sampled\npredictions. We visualize our bound on synthetic regression and classification\ndatasets. Furthermore, we demonstrate the effectiveness of TULiP using\nlarge-scale OOD detection benchmarks for image classification. Our method\nexhibits state-of-the-art performance, particularly for near-distribution\nsamples.", "AI": {"tldr": "TULiP is a post-hoc uncertainty estimator for OOD detection, leveraging theoretical bounds on perturbations to compute uncertainty scores, achieving state-of-the-art performance.", "motivation": "Reliable uncertainty estimation is crucial for safe deployment of deep learning models in open-world scenarios, especially for OOD detection.", "method": "TULiP uses linearized training dynamics to bound the effect of hypothetical perturbations on model parameters, computing uncertainty from sampled predictions.", "result": "TULiP shows state-of-the-art performance on large-scale OOD detection benchmarks, particularly for near-distribution samples.", "conclusion": "TULiP provides a robust, theoretically-driven method for uncertainty estimation in OOD detection, enhancing model safety in real-world applications."}}
{"id": "2502.11971", "pdf": "https://arxiv.org/pdf/2502.11971", "abs": "https://arxiv.org/abs/2502.11971", "authors": ["Jixiang Chen", "Jing Chen", "Kai Liu", "Haochen Chang", "Shanfeng Fu", "Jian Yang"], "title": "Robust 6DoF Pose Tracking Considering Contour and Interior Correspondence Uncertainty for AR Assembly Guidance", "categories": ["cs.CV"], "comment": "Accepted by IEEE Transactions on Instrumentation and Measurement", "summary": "Augmented reality assembly guidance is essential for intelligent\nmanufacturing and medical applications, requiring continuous measurement of the\n6DoF poses of manipulated objects. Although current tracking methods have made\nsignificant advancements in accuracy and efficiency, they still face challenges\nin robustness when dealing with cluttered backgrounds, rotationally symmetric\nobjects, and noisy sequences. In this paper, we first propose a robust\ncontour-based pose tracking method that addresses error-prone contour\ncorrespondences and improves noise tolerance. It utilizes a fan-shaped search\nstrategy to refine correspondences and models local contour shape and noise\nuncertainty as mixed probability distribution, resulting in a highly robust\ncontour energy function. Secondly, we introduce a CPU-only strategy to better\ntrack rotationally symmetric objects and assist the contour-based method in\novercoming local minima by exploring sparse interior correspondences. This is\nachieved by pre-sampling interior points from sparse viewpoint templates\noffline and using the DIS optical flow algorithm to compute their\ncorrespondences during tracking. Finally, we formulate a unified energy\nfunction to fuse contour and interior information, which is solvable using a\nre-weighted least squares algorithm. Experiments on public datasets and real\nscenarios demonstrate that our method significantly outperforms\nstate-of-the-art monocular tracking methods and can achieve more than 100 FPS\nusing only a CPU.", "AI": {"tldr": "A robust contour-based pose tracking method for augmented reality, addressing challenges like cluttered backgrounds and noisy sequences, with a CPU-only strategy for symmetric objects and high efficiency.", "motivation": "To improve robustness in 6DoF pose tracking for AR applications, especially in cluttered environments and with symmetric objects.", "method": "Uses a fan-shaped search strategy for contour correspondences, models noise uncertainty, and integrates sparse interior correspondences via DIS optical flow.", "result": "Outperforms state-of-the-art monocular tracking methods, achieving over 100 FPS on CPU.", "conclusion": "The proposed method is highly robust and efficient, suitable for real-time AR applications."}}
{"id": "2502.00761", "pdf": "https://arxiv.org/pdf/2502.00761", "abs": "https://arxiv.org/abs/2502.00761", "authors": ["Liangyu Xu", "Xuemiao Zhang", "Feiyu Duan", "Sirui Wang", "Rongxiang Weng", "Jingang Wang", "Xunliang Cai"], "title": "FIRE: Flexible Integration of Data Quality Ratings for Effective Pre-Training", "categories": ["cs.CL"], "comment": "21 pages, 11 figures", "summary": "Selecting high-quality data can improve the pretraining efficiency of large\nlanguage models (LLMs). Existing methods generally rely on heuristic techniques\nor single quality signals, limiting their ability to evaluate data quality\ncomprehensively. In this work, we propose FIRE, a flexible and scalable\nframework for integrating multiple data quality raters, which allows for a\ncomprehensive assessment of data quality across various dimensions. FIRE aligns\nmultiple quality signals into a unified space, and integrates diverse data\nquality raters to provide a comprehensive quality signal for each data point.\nFurther, we introduce a progressive data selection scheme based on FIRE that\niteratively refines the selection of high-quality data points. Extensive\nexperiments show that FIRE outperforms other data selection methods and\nsignificantly boosts pretrained model performance across a wide range of\ndownstream tasks, while requiring less than 37.5\\% of the training data needed\nby the Random baseline to reach the target performance.", "AI": {"tldr": "FIRE is a framework for comprehensive data quality assessment in LLM pretraining, outperforming heuristic methods and reducing data needs by 37.5%.", "motivation": "Existing methods for data quality assessment in LLM pretraining rely on heuristics or single signals, lacking comprehensiveness.", "method": "FIRE integrates multiple quality raters, aligns signals into a unified space, and uses a progressive selection scheme.", "result": "FIRE outperforms other methods, significantly improving model performance with less data (37.5% of Random baseline).", "conclusion": "FIRE provides a scalable, flexible solution for high-quality data selection, enhancing pretraining efficiency and downstream task performance."}}
{"id": "2410.03055", "pdf": "https://arxiv.org/pdf/2410.03055", "abs": "https://arxiv.org/abs/2410.03055", "authors": ["Shoaib Ahmed Siddiqui", "Radhika Gaonkar", "Boris K\u00f6pf", "David Krueger", "Andrew Paverd", "Ahmed Salem", "Shruti Tople", "Lukas Wutschitz", "Menglin Xia", "Santiago Zanella-B\u00e9guelin"], "title": "Permissive Information-Flow Analysis for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are rapidly becoming commodity components of\nlarger software systems. This poses natural security and privacy problems:\npoisoned data retrieved from one component can change the model's behavior and\ncompromise the entire system, including coercing the model to spread\nconfidential data to untrusted components. One promising approach is to tackle\nthis problem at the system level via dynamic information flow (aka taint)\ntracking. Unfortunately, this approach of propagating the most restrictive\ninput label to the output is too conservative for applications where LLMs\noperate on inputs retrieved from diverse sources. In this paper, we propose a\nnovel, more permissive approach to propagate information flow labels through\nLLM queries. The key idea behind our approach is to propagate only the labels\nof the samples that were influential in generating the model output and to\neliminate the labels of unnecessary inputs. We implement and investigate the\neffectiveness of two variations of this approach, based on (i) prompt-based\nretrieval augmentation, and (ii) a $k$-nearest-neighbors language model. We\ncompare these with a baseline that uses introspection to predict the output\nlabel. Our experimental results in an LLM agent setting show that the\npermissive label propagator improves over the baseline in more than 85% of the\ncases, which underscores the practicality of our approach.", "AI": {"tldr": "The paper proposes a permissive approach for dynamic information flow tracking in LLMs, focusing on propagating only influential input labels to improve security and privacy.", "motivation": "LLMs are increasingly integrated into software systems, raising security and privacy concerns due to potential data poisoning and leaks. Traditional conservative label propagation is impractical for diverse inputs.", "method": "Two variations are implemented: (1) prompt-based retrieval augmentation and (2) a $k$-nearest-neighbors language model, compared to a baseline using introspection.", "result": "The permissive label propagator outperforms the baseline in over 85% of cases in an LLM agent setting.", "conclusion": "The approach is practical and effective for securing LLMs in diverse input scenarios."}}
{"id": "2505.16946", "pdf": "https://arxiv.org/pdf/2505.16946", "abs": "https://arxiv.org/abs/2505.16946", "authors": ["Sanjana Chalavadi", "Andrei Pastor", "Terry Leitch"], "title": "NY Real Estate Racial Equity Analysis via Applied Machine Learning", "categories": ["cs.CY", "cs.LG"], "comment": null, "summary": "This study analyzes tract-level real estate ownership patterns in New York\nState (NYS) and New York City (NYC) to uncover racial disparities. We use an\nadvanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering,\nvalidated at 89.2% accuracy) to compare the predicted racial composition of\nproperty owners to the resident population from census data. We examine both a\nFull Model (statewide) and a Name-Only LSTM Model (NYC) to assess how\nincorporating geospatial context affects our predictions and disparity\nestimates. The results reveal significant inequities: White individuals hold a\ndisproportionate share of properties and property value relative to their\npopulation, while Black, Hispanic, and Asian communities are underrepresented\nas property owners. These disparities are most pronounced in minority-majority\nneighborhoods, where ownership is predominantly White despite a predominantly\nnon-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates\nthese gaps by reducing owner-occupied opportunities in urban minority\ncommunities. We provide a breakdown of ownership vs. population by race for\nmajority-White, -Black, -Hispanic, and -Asian tracts, identify those with\nextreme ownership disparities, and compare patterns in urban, suburban, and\nrural contexts. The findings underscore persistent racial inequity in property\nownership, reflecting broader historical and socio-economic forces, and\nhighlight the importance of data-driven approaches to address these issues.", "AI": {"tldr": "The study reveals racial disparities in property ownership in NYS and NYC, with White individuals owning disproportionately more properties than minority groups, especially in minority-majority neighborhoods. Corporate ownership worsens these gaps.", "motivation": "To uncover and quantify racial disparities in real estate ownership using advanced imputation models and census data.", "method": "Uses an LSTM+Geo with XGBoost filtering model (89.2% accuracy) to predict racial composition of property owners, comparing it to census data. Examines Full Model (statewide) and Name-Only LSTM Model (NYC).", "result": "White individuals own more properties and value than their population share, while Black, Hispanic, and Asian communities are underrepresented. Disparities are stark in minority-majority neighborhoods. Corporate ownership reduces owner-occupied opportunities in minority communities.", "conclusion": "Persistent racial inequity in property ownership reflects historical and socio-economic forces. Data-driven approaches are crucial to address these disparities."}}
{"id": "2502.18047", "pdf": "https://arxiv.org/pdf/2502.18047", "abs": "https://arxiv.org/abs/2502.18047", "authors": ["Huimin Yan", "Xian Yang", "Liang Bai", "Jiye Liang"], "title": "Progressive Local Alignment for Medical Multimodal Pre-training", "categories": ["cs.CV", "cs.LG"], "comment": "We are currently revising the methodology described in the manuscript\n  to improve its clarity. We have decided to withdraw the current version until\n  a more robust and complete version is ready", "summary": "Local alignment between medical images and text is essential for accurate\ndiagnosis, though it remains challenging due to the absence of natural local\npairings and the limitations of rigid region recognition methods. Traditional\napproaches rely on hard boundaries, which introduce uncertainty, whereas\nmedical imaging demands flexible soft region recognition to handle irregular\nstructures. To overcome these challenges, we propose the Progressive Local\nAlignment Network (PLAN), which designs a novel contrastive learning-based\napproach for local alignment to establish meaningful word-pixel relationships\nand introduces a progressive learning strategy to iteratively refine these\nrelationships, enhancing alignment precision and robustness. By combining these\ntechniques, PLAN effectively improves soft region recognition while suppressing\nnoise interference. Extensive experiments on multiple medical datasets\ndemonstrate that PLAN surpasses state-of-the-art methods in phrase grounding,\nimage-text retrieval, object detection, and zero-shot classification, setting a\nnew benchmark for medical image-text alignment.", "AI": {"tldr": "PLAN introduces a contrastive learning-based approach for local alignment in medical images and text, improving precision and robustness through progressive learning.", "motivation": "Local alignment in medical images and text is challenging due to lack of natural pairings and rigid region recognition methods.", "method": "PLAN uses contrastive learning for word-pixel relationships and progressive learning to refine alignment.", "result": "PLAN outperforms state-of-the-art methods in tasks like phrase grounding and image-text retrieval.", "conclusion": "PLAN sets a new benchmark for medical image-text alignment by enhancing soft region recognition and reducing noise."}}
{"id": "2502.04380", "pdf": "https://arxiv.org/pdf/2502.04380", "abs": "https://arxiv.org/abs/2502.04380", "authors": ["Zhenqing Ling", "Daoyuan Chen", "Liuyi Yao", "Qianli Shen", "Yaliang Li", "Ying Shen"], "title": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "33 pages, 20 figures, 21 tables", "summary": "Fine-tuning large language models (LLMs) using diverse datasets is crucial\nfor enhancing their overall performance across various domains. In practical\nscenarios, existing methods based on modeling the mixture proportions of data\ncomposition often struggle with data whose domain labels are missing, imprecise\nor non-normalized, while methods based on data selection usually encounter\ndifficulties in balancing multi-domain performance. To address these\nchallenges, in this work, we investigate the role of data diversity in\nenhancing the overall abilities of LLMs by empirically constructing contrastive\ndata pools and theoretically deriving explanations. Building upon the insights\ngained, we propose a new method that gives the LLM a dual identity: an output\nmodel to cognitively probe and select data based on diversity reward, as well\nas an input model to be tuned with the selected data. Extensive experiments\nshow that the proposed method notably boosts performance across\ndomain-undetermined data and a series of foundational downstream tasks when\napplied to various advanced LLMs. We release our code and hope this study can\nshed light on the understanding of data diversity and advance feedback-driven\ndata-model co-design for LLMs.", "AI": {"tldr": "The paper proposes a dual-identity method for fine-tuning LLMs, addressing challenges with missing or imprecise domain labels and balancing multi-domain performance.", "motivation": "Existing methods struggle with data lacking domain labels or balancing multi-domain performance, prompting the need for a new approach.", "method": "The method assigns LLMs a dual identity: an output model for diversity-based data selection and an input model for tuning with selected data.", "result": "Experiments show the method improves performance on domain-undetermined data and downstream tasks.", "conclusion": "The study advances understanding of data diversity and feedback-driven data-model co-design for LLMs."}}
{"id": "2410.03565", "pdf": "https://arxiv.org/pdf/2410.03565", "abs": "https://arxiv.org/abs/2410.03565", "authors": ["Max Weltevrede", "Caroline Horsch", "Matthijs T. J. Spaan", "Wendelin B\u00f6hmer"], "title": "Exploration Implies Data Augmentation: Reachability and Generalisation in Contextual MDPs", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2406.08069", "summary": "In the zero-shot policy transfer (ZSPT) setting for contextual Markov\ndecision processes (MDP), agents train on a fixed set of contexts and must\ngeneralise to new ones. Recent work has argued and demonstrated that increased\nexploration can improve this generalisation, by training on more states in the\ntraining contexts. In this paper, we demonstrate that training on more states\ncan indeed improve generalisation, but can come at a cost of reducing the\naccuracy of the learned value function which should not benefit generalisation.\nWe hypothesise and demonstrate that using exploration to increase the agent's\ncoverage while also increasing the accuracy improves generalisation even more.\nInspired by this, we propose a method Explore-Go that implements an exploration\nphase at the beginning of each episode, which can be combined with existing on-\nand off-policy RL algorithms and significantly improves generalisation even in\npartially observable MDPs. We demonstrate the effectiveness of Explore-Go when\ncombined with several popular algorithms and show an increase in generalisation\nperformance across several environments. With this, we hope to provide\npractitioners with a simple modification that can improve the generalisation of\ntheir agents.", "AI": {"tldr": "Explore-Go, a method combining exploration phases with RL algorithms, improves generalization in zero-shot policy transfer by balancing state coverage and value function accuracy.", "motivation": "To address the trade-off between increased exploration (improving generalization) and reduced value function accuracy in zero-shot policy transfer settings.", "method": "Proposes Explore-Go, an exploration phase at the start of each episode, compatible with existing RL algorithms.", "result": "Demonstrates improved generalization across environments when combined with popular RL methods.", "conclusion": "Explore-Go offers a simple, effective modification to enhance agent generalization in contextual MDPs."}}
{"id": "2505.17000", "pdf": "https://arxiv.org/pdf/2505.17000", "abs": "https://arxiv.org/abs/2505.17000", "authors": ["Simmaco Di Lillo"], "title": "Critical Points of Random Neural Networks", "categories": ["stat.ML", "cs.LG", "math.PR", "60G60, 62B10, 62M45"], "comment": null, "summary": "This work investigates the expected number of critical points of random\nneural networks with different activation functions as the depth increases in\nthe infinite-width limit. Under suitable regularity conditions, we derive\nprecise asymptotic formulas for the expected number of critical points of fixed\nindex and those exceeding a given threshold. Our analysis reveals three\ndistinct regimes depending on the value of the first derivative of the\ncovariance evaluated at 1: the expected number of critical points may converge,\ngrow polynomially, or grow exponentially with depth. The theoretical\npredictions are supported by numerical experiments. Moreover, we provide\nnumerical evidence suggesting that, when the regularity condition is not\nsatisfied (e.g. for neural networks with ReLU as activation function), the\nnumber of critical points increases as the map resolution increases, indicating\na potential divergence in the number of critical points.", "AI": {"tldr": "The paper studies the expected number of critical points in random neural networks as depth grows, revealing three regimes based on activation functions and providing theoretical and numerical support.", "motivation": "To understand how the number of critical points in random neural networks behaves with increasing depth, especially under different activation functions.", "method": "Derives asymptotic formulas for critical points under regularity conditions and validates with numerical experiments.", "result": "Identifies three regimes (convergence, polynomial growth, exponential growth) based on activation functions. Suggests divergence for non-regular cases like ReLU.", "conclusion": "The study provides insights into critical point behavior in deep networks, with implications for optimization and training dynamics."}}
{"id": "2503.01222", "pdf": "https://arxiv.org/pdf/2503.01222", "abs": "https://arxiv.org/abs/2503.01222", "authors": ["Wenbin Wang", "Yongcheng Jing", "Liang Ding", "Yingjie Wang", "Li Shen", "Yong Luo", "Bo Du", "Dacheng Tao"], "title": "Retrieval-Augmented Perception: High-Resolution Image Perception Meets Visual RAG", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "High-resolution (HR) image perception remains a key challenge in multimodal\nlarge language models (MLLMs). To overcome the limitations of existing methods,\nthis paper shifts away from prior dedicated heuristic approaches and revisits\nthe most fundamental idea to HR perception by enhancing the long-context\ncapability of MLLMs, driven by recent advances in long-context techniques like\nretrieval-augmented generation (RAG) for general LLMs. Towards this end, this\npaper presents the first study exploring the use of RAG to address HR\nperception challenges. Specifically, we propose Retrieval-Augmented Perception\n(RAP), a training-free framework that retrieves and fuses relevant image crops\nwhile preserving spatial context using the proposed Spatial-Awareness Layout.\nTo accommodate different tasks, the proposed Retrieved-Exploration Search\n(RE-Search) dynamically selects the optimal number of crops based on model\nconfidence and retrieval scores. Experimental results on HR benchmarks\ndemonstrate the significant effectiveness of RAP, with LLaVA-v1.5-13B achieving\na 43% improvement on $V^*$ Bench and 19% on HR-Bench.", "AI": {"tldr": "The paper introduces Retrieval-Augmented Perception (RAP) to enhance high-resolution image perception in MLLMs using retrieval-augmented generation, achieving significant performance improvements.", "motivation": "Existing methods for high-resolution image perception in MLLMs are limited, prompting a shift to leveraging long-context techniques like RAG.", "method": "Proposes RAP, a training-free framework that retrieves and fuses relevant image crops with spatial context using Spatial-Awareness Layout, and dynamically selects crops via RE-Search.", "result": "RAP improves LLaVA-v1.5-13B by 43% on V* Bench and 19% on HR-Bench.", "conclusion": "RAP effectively addresses HR perception challenges in MLLMs by integrating retrieval techniques, demonstrating substantial performance gains."}}
{"id": "2502.06086", "pdf": "https://arxiv.org/pdf/2502.06086", "abs": "https://arxiv.org/abs/2502.06086", "authors": ["Seokwon Song", "Taehyun Lee", "Jaewoo Ahn", "Jae Hyuk Sung", "Gunhee Kim"], "title": "Is a Peeled Apple Still Red? Evaluating LLMs' Ability for Conceptual Combination with Property Type", "categories": ["cs.CL"], "comment": "NAACL 2025 Oral", "summary": "Conceptual combination is a cognitive process that merges basic concepts,\nenabling the creation of complex expressions. During this process, the\nproperties of combination (e.g., the whiteness of a peeled apple) can be\ninherited from basic concepts, newly emerge, or be canceled. However, previous\nstudies have evaluated a limited set of properties and have not examined the\ngenerative process. To address this gap, we introduce the Conceptual\nCombination with Property Type dataset (CCPT), which consists of 12.3K\nannotated triplets of noun phrases, properties, and property types. Using CCPT,\nwe establish three types of tasks to evaluate LLMs for conceptual combination\nthoroughly. Our key findings are threefold: (1) Our automatic metric grading\nproperty emergence and cancellation closely corresponds with human judgments.\n(2) LLMs, including OpenAI's o1, struggle to generate noun phrases which\npossess given emergent properties. (3) Our proposed method, inspired by\ncognitive psychology model that explains how relationships between concepts are\nformed, improves performances in all generative tasks. The dataset and\nexperimental code are available at https://github.com/seokwon99/CCPT.git.", "AI": {"tldr": "The paper introduces the CCPT dataset to evaluate LLMs in conceptual combination, finding that LLMs struggle with emergent properties and proposing a cognitive psychology-inspired method to improve performance.", "motivation": "Previous studies on conceptual combination were limited in evaluating properties and lacked examination of the generative process.", "method": "The CCPT dataset (12.3K annotated triplets) is used to evaluate LLMs through three task types, with a proposed cognitive psychology-inspired method.", "result": "Key findings: (1) Automatic metrics align with human judgments, (2) LLMs struggle with emergent properties, (3) The proposed method improves generative tasks.", "conclusion": "The CCPT dataset and proposed method advance the evaluation and performance of LLMs in conceptual combination tasks."}}
{"id": "2410.04047", "pdf": "https://arxiv.org/pdf/2410.04047", "abs": "https://arxiv.org/abs/2410.04047", "authors": ["Wen Ye", "Wei Yang", "Defu Cao", "Yizhou Zhang", "Lumingyuan Tang", "Jie Cai", "Yan Liu"], "title": "Domain-Oriented Time Series Inference Agents for Reasoning and Automated Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world time series inference requires more than point forecasting. It\ndemands multi-step reasoning, constraint handling, domain knowledge\nincorporation, and domain-specific workflow assembly. Existing time series\nfoundation models are limited to narrow tasks and lack flexibility to\ngeneralize across diverse scenarios. On the other hand, large language models\n(LLMs) struggle with numerical precision. To address these limitations, we\nintroduce TS-Reasoner, a Domain-Oriented Time Series Agent that integrates\nnatural language reasoning with precise numerical execution. TS-Reasoner\ndecomposes natural language instructions into structured workflows composed of\nstatistical, logical, and domain-specific operators, and incorporates a\nself-refinement mechanism for adaptive execution. We evaluate its capabilities\nthrough two axes: basic time series understanding and complex multi-step\ninference, using the TimeSeriesExam benchmark and a newly constructed dataset.\nExperimental results show that TS-Reasoner significantly outperforms\ngeneral-purpose LLMs, highlighting the promise of domain-specialized agents for\nrobust and interpretable time series reasoning.", "AI": {"tldr": "TS-Reasoner is a domain-oriented time series agent combining natural language reasoning with numerical precision, outperforming general-purpose LLMs in time series tasks.", "motivation": "Existing time series models lack flexibility, while LLMs struggle with numerical precision, necessitating a specialized solution.", "method": "TS-Reasoner decomposes natural language instructions into structured workflows with statistical, logical, and domain-specific operators, and uses self-refinement for adaptive execution.", "result": "TS-Reasoner significantly outperforms general-purpose LLMs in basic and complex time series tasks.", "conclusion": "Domain-specialized agents like TS-Reasoner offer robust and interpretable time series reasoning."}}
{"id": "2505.17003", "pdf": "https://arxiv.org/pdf/2505.17003", "abs": "https://arxiv.org/abs/2505.17003", "authors": ["Nanda H. Krishna", "Colin Bredenberg", "Daniel Levenstein", "Blake A. Richards", "Guillaume Lajoie"], "title": "Sufficient conditions for offline reactivation in recurrent neural networks", "categories": ["q-bio.NC", "cs.LG", "cs.NE"], "comment": "ICLR 2024", "summary": "During periods of quiescence, such as sleep, neural activity in many brain\ncircuits resembles that observed during periods of task engagement. However,\nthe precise conditions under which task-optimized networks can autonomously\nreactivate the same network states responsible for online behavior is poorly\nunderstood. In this study, we develop a mathematical framework that outlines\nsufficient conditions for the emergence of neural reactivation in circuits that\nencode features of smoothly varying stimuli. We demonstrate mathematically that\nnoisy recurrent networks optimized to track environmental state variables using\nchange-based sensory information naturally develop denoising dynamics, which,\nin the absence of input, cause the network to revisit state configurations\nobserved during periods of online activity. We validate our findings using\nnumerical experiments on two canonical neuroscience tasks: spatial position\nestimation based on self-motion cues, and head direction estimation based on\nangular velocity cues. Overall, our work provides theoretical support for\nmodeling offline reactivation as an emergent consequence of task optimization\nin noisy neural circuits.", "AI": {"tldr": "The paper explores how task-optimized neural networks can autonomously reactivate states observed during online behavior, providing a mathematical framework and validation through neuroscience tasks.", "motivation": "Understanding the conditions for neural reactivation in quiescent states like sleep, where activity resembles task engagement.", "method": "Developed a mathematical framework for noisy recurrent networks optimized to track environmental states, validated with numerical experiments on neuroscience tasks.", "result": "Networks naturally develop denoising dynamics, leading to reactivation of states observed during online activity.", "conclusion": "Offline reactivation emerges as a consequence of task optimization in noisy neural circuits."}}
{"id": "2503.03644", "pdf": "https://arxiv.org/pdf/2503.03644", "abs": "https://arxiv.org/abs/2503.03644", "authors": ["Xiaojun Bi", "Shuo Li", "Junyao Xing", "Ziyue Wang", "Fuwen Luo", "Weizheng Qiao", "Lu Han", "Ziwei Sun", "Peng Li", "Yang Liu"], "title": "DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating Semantic Understanding of Dongba Pictograms", "categories": ["cs.CV"], "comment": "Our dataset can be obtained from:\n  https://github.com/thinklis/DongbaMIE", "summary": "Dongba pictographic is the only pictographic script still in use in the\nworld. Its pictorial ideographic features carry rich cultural and contextual\ninformation. However, due to the lack of relevant datasets, research on\nsemantic understanding of Dongba hieroglyphs has progressed slowly. To this\nend, we constructed \\textbf{DongbaMIE} - the first dataset focusing on\nmultimodal information extraction of Dongba pictographs. The dataset consists\nof images of Dongba hieroglyphic characters and their corresponding semantic\nannotations in Chinese. It contains 23,530 sentence-level and 2,539\nparagraph-level high-quality text-image pairs. The annotations cover four\nsemantic dimensions: object, action, relation and attribute. Systematic\nevaluation of mainstream multimodal large language models shows that the models\nare difficult to perform information extraction of Dongba hieroglyphs\nefficiently under zero-shot and few-shot learning. Although supervised\nfine-tuning can improve the performance, accurate extraction of complex\nsemantics is still a great challenge at present.", "AI": {"tldr": "The paper introduces DongbaMIE, the first dataset for multimodal information extraction of Dongba pictographs, addressing the lack of datasets for semantic understanding. It evaluates models' performance on this task.", "motivation": "The lack of datasets for Dongba pictographs hinders semantic understanding research. DongbaMIE aims to fill this gap.", "method": "Constructed DongbaMIE dataset with 23,530 sentence-level and 2,539 paragraph-level text-image pairs, annotated across four semantic dimensions. Evaluated mainstream multimodal models under zero-shot, few-shot, and supervised fine-tuning.", "result": "Models struggle with efficient information extraction under zero-shot and few-shot learning. Supervised fine-tuning improves performance but complex semantics remain challenging.", "conclusion": "DongbaMIE enables research on Dongba pictographs, but current models face challenges in accurately extracting complex semantics."}}
{"id": "2502.06139", "pdf": "https://arxiv.org/pdf/2502.06139", "abs": "https://arxiv.org/abs/2502.06139", "authors": ["Sumin An", "Junyoung Sung", "Wonpyo Park", "Chanjun Park", "Paul Hongsuck Seo"], "title": "LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs", "categories": ["cs.CL"], "comment": "Accepted to NAACL 2025. Project Page:\n  https://ssuminan.github.io/LCIRC/", "summary": "While large language models (LLMs) excel in generating coherent and\ncontextually rich outputs, their capacity to efficiently handle long-form\ncontexts is limited by fixed-length position embeddings. Additionally, the\ncomputational cost of processing long sequences increases quadratically, making\nit challenging to extend context length. To address these challenges, we\npropose Long-form Context Injection with Recurrent Compression (LCIRC), a\nmethod that enables the efficient processing long-form sequences beyond the\nmodel's length limit through recurrent compression without retraining the\nentire model. We further introduce query dependent context modeling, which\nselectively compresses query-relevant information, ensuring that the model\nretains the most pertinent content. Our empirical results demonstrate that\nQuery Dependent LCIRC (QD-LCIRC) significantly improves LLM's ability to manage\nextended contexts, making it well-suited for tasks that require both\ncomprehensive context understanding and query relevance.", "AI": {"tldr": "The paper introduces LCIRC and QD-LCIRC to efficiently process long-form sequences in LLMs by recurrent compression and query-dependent context modeling, improving context handling without full retraining.", "motivation": "Fixed-length position embeddings and high computational costs limit LLMs' ability to handle long-form contexts effectively.", "method": "Proposes LCIRC for recurrent compression and QD-LCIRC for query-dependent context modeling to selectively retain relevant information.", "result": "QD-LCIRC significantly enhances LLMs' ability to manage extended contexts while maintaining query relevance.", "conclusion": "The method is effective for tasks requiring comprehensive context understanding and relevance, without the need for full model retraining."}}
{"id": "2410.09795", "pdf": "https://arxiv.org/pdf/2410.09795", "abs": "https://arxiv.org/abs/2410.09795", "authors": ["Fanmeng Wang", "Minjie Cheng", "Hongteng Xu"], "title": "WGFormer: An SE(3)-Transformer Driven by Wasserstein Gradient Flows for Molecular Ground-State Conformation Prediction", "categories": ["q-bio.BM", "cs.AI", "cs.LG", "physics.chem-ph"], "comment": "Accepted by the 42nd International Conference on Machine Learning\n  (ICML 2025)", "summary": "Predicting molecular ground-state conformation (i.e., energy-minimized\nconformation) is crucial for many chemical applications such as molecular\ndocking and property prediction. Classic energy-based simulation is\ntime-consuming when solving this problem, while existing learning-based methods\nhave advantages in computational efficiency but sacrifice accuracy and\ninterpretability. In this work, we propose a novel and effective method to\nbridge the energy-based simulation and the learning-based strategy, which\ndesigns and learns a Wasserstein gradient flow-driven SE(3)-Transformer, called\nWGFormer, for ground-state conformation prediction. Specifically, our method\ntackles this task within an auto-encoding framework, which encodes low-quality\nconformations by the proposed WGFormer and decodes corresponding ground-state\nconformations by an MLP. The architecture of WGFormer corresponds to\nWasserstein gradient flows -- it optimizes conformations by minimizing an\nenergy function defined on the latent mixture models of atoms, thereby\nsignificantly improving performance and interpretability. Extensive experiments\ndemonstrate that our method consistently outperforms state-of-the-art\ncompetitors, providing a new and insightful paradigm to predict ground-state\nconformation.", "AI": {"tldr": "The paper introduces WGFormer, a Wasserstein gradient flow-driven SE(3)-Transformer, to predict molecular ground-state conformations efficiently while balancing accuracy and interpretability.", "motivation": "Classic energy-based simulations are slow, and existing learning-based methods sacrifice accuracy and interpretability. The goal is to bridge these gaps.", "method": "WGFormer uses an auto-encoding framework: it encodes low-quality conformations with the transformer and decodes ground-state conformations with an MLP, leveraging Wasserstein gradient flows for optimization.", "result": "WGFormer outperforms state-of-the-art methods, offering improved performance and interpretability.", "conclusion": "The method provides a novel, effective paradigm for ground-state conformation prediction, combining efficiency, accuracy, and interpretability."}}
{"id": "2108.05974", "pdf": "https://arxiv.org/pdf/2108.05974", "abs": "https://arxiv.org/abs/2108.05974", "authors": ["Saber Malekmohammadi", "Kiarash Shaloudegi", "Zeou Hu", "Yaoliang Yu"], "title": "An Operator Splitting View of Federated Learning", "categories": ["cs.LG"], "comment": "30 pages, 28 figures", "summary": "Over the past few years, the federated learning ($\\texttt{FL}$) community has\nwitnessed a proliferation of new $\\texttt{FL}$ algorithms. However, our\nunderstating of the theory of $\\texttt{FL}$ is still fragmented, and a\nthorough, formal comparison of these algorithms remains elusive. Motivated by\nthis gap, we show that many of the existing $\\texttt{FL}$ algorithms can be\nunderstood from an operator splitting point of view. This unification allows us\nto compare different algorithms with ease, to refine previous convergence\nresults and to uncover new algorithmic variants. In particular, our analysis\nreveals the vital role played by the step size in $\\texttt{FL}$ algorithms. The\nunification also leads to a streamlined and economic way to accelerate\n$\\texttt{FL}$ algorithms, without incurring any communication overhead. We\nperform numerical experiments on both convex and nonconvex models to validate\nour findings.", "AI": {"tldr": "The paper unifies various federated learning (FL) algorithms using an operator splitting perspective, enabling easier comparison, refined convergence results, and new variants, while highlighting the importance of step size and proposing an efficient acceleration method.", "motivation": "The motivation is to address the fragmented understanding and lack of formal comparison among existing FL algorithms.", "method": "The method involves analyzing FL algorithms from an operator splitting viewpoint, unifying them for comparison, refining convergence results, and proposing new variants.", "result": "The analysis reveals the critical role of step size in FL algorithms and introduces an efficient acceleration method without communication overhead. Numerical experiments validate the findings.", "conclusion": "The conclusion is that the operator splitting perspective provides a unified framework for understanding, comparing, and improving FL algorithms, with practical benefits demonstrated through experiments."}}
{"id": "2503.04983", "pdf": "https://arxiv.org/pdf/2503.04983", "abs": "https://arxiv.org/abs/2503.04983", "authors": ["Boris Malashenko", "Ivan Jarsky", "Valeria Efimova"], "title": "Leveraging Large Language Models For Scalable Vector Graphics Processing: A Review", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, rapid advances in computer vision have significantly\nimproved the processing and generation of raster images. However, vector\ngraphics, which is essential in digital design, due to its scalability and ease\nof editing, have been relatively understudied. Traditional vectorization\ntechniques, which are often used in vector generation, suffer from long\nprocessing times and excessive output complexity, limiting their usability in\npractical applications. The advent of large language models (LLMs) has opened\nnew possibilities for the generation, editing, and analysis of vector graphics,\nparticularly in the SVG format, which is inherently text-based and well-suited\nfor integration with LLMs.\n  This paper provides a systematic review of existing LLM-based approaches for\nSVG processing, categorizing them into three main tasks: generation, editing,\nand understanding. We observe notable models such as IconShop, StrokeNUWA, and\nStarVector, highlighting their strengths and limitations. Furthermore, we\nanalyze benchmark datasets designed for assessing SVG-related tasks, including\nSVGEditBench, VGBench, and SGP-Bench, and conduct a series of experiments to\nevaluate various LLMs in these domains. Our results demonstrate that for vector\ngraphics reasoning-enhanced models outperform standard LLMs, particularly in\ngeneration and understanding tasks. Furthermore, our findings underscore the\nneed to develop more diverse and richly annotated datasets to further improve\nLLM capabilities in vector graphics tasks.", "AI": {"tldr": "The paper reviews LLM-based approaches for SVG processing, categorizing them into generation, editing, and understanding tasks, and evaluates models and datasets, finding reasoning-enhanced LLMs outperform standard ones.", "motivation": "Vector graphics, unlike raster images, are understudied despite their scalability and ease of editing. Traditional vectorization techniques are slow and complex, prompting exploration of LLMs for SVG tasks.", "method": "The paper systematically reviews LLM-based SVG approaches, categorizes tasks, evaluates models (e.g., IconShop, StrokeNUWA), and benchmarks datasets (e.g., SVGEditBench, VGBench).", "result": "Reasoning-enhanced LLMs outperform standard LLMs in SVG generation and understanding tasks. Current datasets lack diversity and rich annotations.", "conclusion": "More diverse datasets are needed to enhance LLM capabilities in vector graphics tasks, as reasoning-enhanced models show promise in SVG processing."}}
{"id": "2502.06205", "pdf": "https://arxiv.org/pdf/2502.06205", "abs": "https://arxiv.org/abs/2502.06205", "authors": ["Guoxin Chen", "Minpeng Liao", "Peiying Yu", "Dingmin Wang", "Zile Qiao", "Chao Yang", "Xin Zhao", "Kai Fan"], "title": "C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Camera ready version for ICML 2025", "summary": "Retrieval-augmented generation (RAG) systems face a fundamental challenge in\naligning independently developed retrievers and large language models (LLMs).\nExisting approaches typically involve modifying either component or introducing\nsimple intermediate modules, resulting in practical limitations and sub-optimal\nperformance. Inspired by human search behavior -- typically involving a\nback-and-forth process of proposing search queries and reviewing documents, we\npropose C-3PO, a proxy-centric framework that facilitates communication between\nretrievers and LLMs through a lightweight multi-agent system. Our framework\nimplements three specialized agents that collaboratively optimize the entire\nRAG pipeline without altering the retriever and LLMs. These agents work\ntogether to assess the need for retrieval, generate effective queries, and\nselect information suitable for the LLMs. To enable effective multi-agent\ncoordination, we develop a tree-structured rollout approach for reward credit\nassignment in reinforcement learning. Extensive experiments in both in-domain\nand out-of-distribution scenarios demonstrate that C-3PO significantly enhances\nRAG performance while maintaining plug-and-play flexibility and superior\ngeneralization capabilities.", "AI": {"tldr": "C-3PO is a proxy-centric framework using a multi-agent system to align retrievers and LLMs in RAG systems, improving performance without modifying existing components.", "motivation": "Existing RAG systems struggle with alignment between retrievers and LLMs, leading to sub-optimal performance. Inspired by human search behavior, C-3PO aims to bridge this gap.", "method": "A lightweight multi-agent system with three specialized agents optimizes the RAG pipeline. A tree-structured rollout approach in reinforcement learning enables coordination.", "result": "C-3PO significantly enhances RAG performance in both in-domain and out-of-distribution scenarios while maintaining flexibility and generalization.", "conclusion": "C-3PO effectively aligns retrievers and LLMs, offering a plug-and-play solution with superior performance and adaptability."}}
{"id": "2410.10056", "pdf": "https://arxiv.org/pdf/2410.10056", "abs": "https://arxiv.org/abs/2410.10056", "authors": ["Qi Liu", "Wanjing Ma"], "title": "The Epochal Sawtooth Effect: Unveiling Training Loss Oscillations in Adam and Other Optimizers", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "15 pages, 21 figures", "summary": "In this paper, we identify and analyze a recurring training loss pattern,\nwhich we term the \\textit{Epochal Sawtooth Effect (ESE)}, commonly observed\nduring training with adaptive gradient-based optimizers, particularly Adam\noptimizer. This pattern is characterized by a sharp drop in loss at the\nbeginning of each epoch, followed by a gradual increase, resulting in a\nsawtooth-shaped loss curve. Through empirical observations, we demonstrate that\nwhile this effect is most pronounced with Adam, it persists, although less\nseverely, with other optimizers such as RMSProp.\n  We provide an in-depth explanation of the underlying mechanisms that lead to\nthe Epochal Sawtooth Effect. The influences of factors like $\\beta$, batch\nsize, data shuffling on this pattern have been studied. We quantify the\ninfluence of $beta_2$ on the shape of the loss curve, showing that higher\nvalues of $\\beta_2$ result in a nearly linear increase in loss, while lower\nvalues create a concave upward trend. Our analysis reveals that this behavior\nstems from the adaptive learning rate controlled by the second moment estimate,\nwith $\\beta_1$ playing a minimal role when $\\beta_2$ is large.\n  To support our analysis, we replicate this phenomenon through a controlled\nquadratic minimization task. By incrementally solving a series of quadratic\noptimization problems using Adam, we demonstrate that the Epochal Sawtooth\nEffect can emerge even in simple optimization scenarios, reinforcing the\ngenerality of this pattern. This paper provides both theoretical insights and\nquantitative analysis, offering a comprehensive understanding of this\nubiquitous phenomenon in modern optimization techniques.", "AI": {"tldr": "The paper identifies the Epochal Sawtooth Effect (ESE), a sawtooth-shaped loss curve during training with adaptive optimizers like Adam, and explains its mechanisms.", "motivation": "To understand and explain the recurring ESE pattern observed in adaptive gradient-based optimizers, particularly Adam.", "method": "Empirical analysis of ESE, studying factors like \u03b2, batch size, and data shuffling, and replicating the effect via quadratic minimization tasks.", "result": "Higher \u03b2\u2082 values lead to a linear loss increase, while lower values create a concave trend. The effect is linked to the adaptive learning rate controlled by the second moment estimate.", "conclusion": "The paper provides theoretical and quantitative insights into ESE, demonstrating its generality in optimization scenarios."}}
{"id": "2206.10032", "pdf": "https://arxiv.org/pdf/2206.10032", "abs": "https://arxiv.org/abs/2206.10032", "authors": ["Hossein Zakerinia", "Shayan Talaei", "Giorgi Nadiradze", "Dan Alistarh"], "title": "Communication-Efficient Federated Learning With Data and Client Heterogeneity", "categories": ["cs.LG"], "comment": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS), 2024", "summary": "Federated Learning (FL) enables large-scale distributed training of machine\nlearning models, while still allowing individual nodes to maintain data\nlocally. However, executing FL at scale comes with inherent practical\nchallenges: 1) heterogeneity of the local node data distributions, 2)\nheterogeneity of node computational speeds (asynchrony), but also 3)\nconstraints in the amount of communication between the clients and the server.\nIn this work, we present the first variant of the classic federated averaging\n(FedAvg) algorithm which, at the same time, supports data heterogeneity,\npartial client asynchrony, and communication compression. Our algorithm comes\nwith a novel, rigorous analysis showing that, in spite of these system\nrelaxations, it can provide similar convergence to FedAvg in interesting\nparameter regimes. Experimental results in the rigorous LEAF benchmark on\nsetups of up to 300 nodes show that our algorithm ensures fast convergence for\nstandard federated tasks, improving upon prior quantized and asynchronous\napproaches.", "AI": {"tldr": "A new FedAvg variant addresses data heterogeneity, asynchrony, and communication constraints, showing convergence comparable to FedAvg and outperforming prior methods in experiments.", "motivation": "To overcome practical challenges in Federated Learning (FL) like data heterogeneity, node asynchrony, and communication constraints.", "method": "Introduces a variant of FedAvg that supports data heterogeneity, partial client asynchrony, and communication compression, with a novel convergence analysis.", "result": "Demonstrates similar convergence to FedAvg in certain regimes and outperforms prior quantized and asynchronous approaches in experiments with up to 300 nodes.", "conclusion": "The proposed algorithm effectively addresses key FL challenges while maintaining performance, offering a practical solution for large-scale FL."}}
{"id": "2503.05122", "pdf": "https://arxiv.org/pdf/2503.05122", "abs": "https://arxiv.org/abs/2503.05122", "authors": ["Xi Li", "Tong Rao", "Cihui Pan"], "title": "EDM: Efficient Deep Feature Matching", "categories": ["cs.CV"], "comment": null, "summary": "Recent feature matching methods have achieved remarkable performance but lack\nefficiency consideration. In this paper, we revisit the mainstream\ndetector-free matching pipeline and improve all its stages considering both\naccuracy and efficiency. We propose an Efficient Deep feature Matching network,\nEDM. We first adopt a deeper CNN with fewer dimensions to extract multi-level\nfeatures. Then we present a Correlation Injection Module that conducts feature\ntransformation on high-level deep features, and progressively injects feature\ncorrelations from global to local for efficient multi-scale feature\naggregation, improving both speed and performance. In the refinement stage, a\nnovel lightweight bidirectional axis-based regression head is designed to\ndirectly predict subpixel-level correspondences from latent features, avoiding\nthe significant computational cost of explicitly locating keypoints on\nhigh-resolution local feature heatmaps. Moreover, effective selection\nstrategies are introduced to enhance matching accuracy. Extensive experiments\nshow that our EDM achieves competitive matching accuracy on various benchmarks\nand exhibits excellent efficiency, offering valuable best practices for\nreal-world applications. The code is available at\nhttps://github.com/chicleee/EDM.", "AI": {"tldr": "The paper introduces EDM, an efficient deep feature matching network, improving accuracy and speed in feature matching by optimizing feature extraction, correlation injection, and refinement stages.", "motivation": "Existing feature matching methods lack efficiency despite high performance. The paper aims to enhance both accuracy and speed in detector-free matching pipelines.", "method": "EDM uses a deeper CNN with fewer dimensions for feature extraction, a Correlation Injection Module for multi-scale feature aggregation, and a lightweight bidirectional axis-based regression head for subpixel-level correspondence prediction.", "result": "EDM achieves competitive accuracy on benchmarks while demonstrating excellent efficiency, making it suitable for real-world applications.", "conclusion": "EDM provides a balanced solution for feature matching, combining high performance with efficiency, and offers practical best practices for implementation."}}
{"id": "2502.08550", "pdf": "https://arxiv.org/pdf/2502.08550", "abs": "https://arxiv.org/abs/2502.08550", "authors": ["Lisa Alazraki", "Maximilian Mozes", "Jon Ander Campos", "Tan Yi-Chern", "Marek Rei", "Max Bartolo"], "title": "No Need for Explanations: LLMs can implicitly learn from mistakes in-context", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Showing incorrect answers to Large Language Models (LLMs) is a popular\nstrategy to improve their performance in reasoning-intensive tasks. It is\nwidely assumed that, in order to be helpful, the incorrect answers must be\naccompanied by comprehensive rationales, explicitly detailing where the\nmistakes are and how to correct them. However, in this work we present a\ncounterintuitive finding: we observe that LLMs perform better in math reasoning\ntasks when these rationales are eliminated from the context and models are left\nto infer on their own what makes an incorrect answer flawed. This approach also\nsubstantially outperforms chain-of-thought prompting in our evaluations. These\nresults are consistent across LLMs of different sizes and varying reasoning\nabilities. To gain an understanding of why LLMs learn from mistakes more\neffectively without explicit corrective rationales, we perform a thorough\nanalysis, investigating changes in context length and answer diversity between\ndifferent prompting strategies, and their effect on performance. We also\nexamine evidence of overfitting to the in-context rationales when these are\nprovided, and study the extent to which LLMs are able to autonomously infer\nhigh-quality corrective rationales given only incorrect answers as input. We\nfind evidence that, while incorrect answers are more beneficial for LLM\nlearning than additional diverse correct answers, explicit corrective\nrationales over-constrain the model, thus limiting those benefits.", "AI": {"tldr": "LLMs perform better in math reasoning tasks when incorrect answers lack explicit rationales, outperforming chain-of-thought prompting.", "motivation": "To challenge the assumption that explicit rationales are necessary for LLMs to learn from incorrect answers.", "method": "Compare LLM performance with and without corrective rationales, analyze context length, answer diversity, and overfitting.", "result": "LLMs learn more effectively without explicit rationales, as they over-constrain the model.", "conclusion": "Incorrect answers alone are more beneficial for LLM learning than explicit rationales or additional correct answers."}}
{"id": "2410.10481", "pdf": "https://arxiv.org/pdf/2410.10481", "abs": "https://arxiv.org/abs/2410.10481", "authors": ["Zhaomin Wu", "Jizhou Guo", "Junyi Hou", "Bingsheng He", "Lixin Fan", "Qiang Yang"], "title": "Model-based Large Language Model Customization as Service", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Prominent Large Language Model (LLM) services from providers like OpenAI and\nGoogle excel at general tasks but often underperform on domain-specific\napplications. Current customization services for these LLMs typically require\nusers to upload data for fine-tuning, posing significant privacy risks. While\ndifferentially private (DP) data synthesis presents a potential alternative,\nits application commonly results in low effectiveness due to the introduction\nof excessive noise on data for DP. To overcome this, we introduce Llamdex, a\nnovel framework that facilitates LLM customization as a service, where the\nclient uploads pre-trained domain-specific models rather than data. This\nclient-uploaded model, optionally protected by DP with much lower noise, is\ninserted into the base LLM via connection modules. Significantly, these\nconnecting modules are trained without requiring sensitive domain data,\nenabling clients to customize LLM services while preserving data privacy.\nExperiments demonstrate that Llamdex improves domain-specific accuracy by up to\n26\\% over state-of-the-art private data synthesis methods under identical\nprivacy constraints and, by obviating the need for users to provide domain\ncontext within queries, maintains inference efficiency comparable to the\noriginal LLM service.", "AI": {"tldr": "Llamdex is a framework for customizing LLMs without sharing sensitive data, using pre-trained domain-specific models instead, achieving better accuracy and privacy than DP data synthesis.", "motivation": "Current LLM customization requires uploading sensitive data for fine-tuning, posing privacy risks. DP data synthesis is ineffective due to excessive noise.", "method": "Llamdex allows clients to upload pre-trained domain-specific models (optionally DP-protected) into the base LLM via connection modules, trained without sensitive data.", "result": "Llamdex improves domain-specific accuracy by up to 26% over DP data synthesis under the same privacy constraints and maintains inference efficiency.", "conclusion": "Llamdex offers a privacy-preserving, effective alternative for LLM customization, outperforming existing methods in accuracy and efficiency."}}
{"id": "2305.04971", "pdf": "https://arxiv.org/pdf/2305.04971", "abs": "https://arxiv.org/abs/2305.04971", "authors": ["Peng Lu", "Ahmad Rashid", "Ivan Kobyzev", "Mehdi Rezagholizadeh", "Philippe Langlais"], "title": "LABO: Towards Learning Optimal Label Regularization via Bi-level Optimization", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted at ACL2023 (Findings)", "summary": "Regularization techniques are crucial to improving the generalization\nperformance and training efficiency of deep neural networks. Many deep learning\nalgorithms rely on weight decay, dropout, batch/layer normalization to converge\nfaster and generalize. Label Smoothing (LS) is another simple, versatile and\nefficient regularization which can be applied to various supervised\nclassification tasks. Conventional LS, however, regardless of the training\ninstance assumes that each non-target class is equally likely. In this work, we\npresent a general framework for training with label regularization, which\nincludes conventional LS but can also model instance-specific variants. Based\non this formulation, we propose an efficient way of learning LAbel\nregularization by devising a Bi-level Optimization (LABO) problem. We derive a\ndeterministic and interpretable solution of the inner loop as the optimal label\nsmoothing without the need to store the parameters or the output of a trained\nmodel. Finally, we conduct extensive experiments and demonstrate our LABO\nconsistently yields improvement over conventional label regularization on\nvarious fields, including seven machine translation and three image\nclassification tasks across various", "AI": {"tldr": "The paper introduces LABO, a bi-level optimization framework for learning instance-specific label regularization, improving upon conventional Label Smoothing (LS) by modeling non-target class probabilities dynamically.", "motivation": "Conventional LS assumes equal probability for non-target classes, ignoring instance-specific variations. The authors aim to enhance regularization by adapting LS dynamically.", "method": "Proposes LABO, a bi-level optimization framework, to learn optimal label smoothing without storing model parameters or outputs.", "result": "LABO outperforms conventional LS in seven machine translation and three image classification tasks.", "conclusion": "LABO provides a deterministic, interpretable, and efficient solution for label regularization, consistently improving performance across tasks."}}
{"id": "2503.09499", "pdf": "https://arxiv.org/pdf/2503.09499", "abs": "https://arxiv.org/abs/2503.09499", "authors": ["Zhe Xu", "Daoyuan Chen", "Zhenqing Ling", "Yaliang Li", "Ying Shen"], "title": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "22 pages, 7 tables", "summary": "Large foundation models face challenges in acquiring transferable, structured\nthinking abilities, especially when supervised with rigid templates or\ncrowd-annotated instruction datasets. Unlike prior approaches, we focus on a\nthinking-centric data synthesis paradigm that enables models to evolve through\nself-generated, cognitively guided data. We propose MindGYM, a structured and\nscalable framework for question synthesis, composed of: (1) Cognitive Thinking\nProcess Injection, which infuses high-level reasoning objectives to shape the\nmodel's synthesis behavior; (2) Seed Single-Hop Question Synthesis, generating\natomic questions from diverse semantic types to encourage broader thinking; and\n(3) Challenging Multi-Hop QA Synthesis, composing more complex multi-hop\nquestions based on QA seeds for deeper reasoning. Detailed analysis shows that\nsynthetic data generated by our method achieves 16.7% higher average quality\nand 67.91% lower quality variance compared to baseline sources, highlighting\nthat both high-quality and self-contained data are essential for effective,\nthinking-oriented fine-tuning. MindGYM improves performance on six reasoning\nbenchmarks, achieving gains of up to 16% on MathVision using only 400 data\nsamples, and generalizable improvements across different model sizes and\narchitectures. MindGYM underscores the viability of self-challenging mechanisms\nin refining large model capabilities while minimizing human intervention and\nresource demands. Code and data are released to promote data-centric research\ninto self-evolving foundation models driven by their internal reasoning\ncapabilities.", "AI": {"tldr": "MindGYM introduces a structured framework for self-generated, cognitively guided data to enhance large models' reasoning abilities, outperforming baselines in quality and performance.", "motivation": "Addressing the limitations of rigid templates and crowd-annotated datasets in fostering transferable, structured thinking in large foundation models.", "method": "MindGYM includes Cognitive Thinking Process Injection, Seed Single-Hop Question Synthesis, and Challenging Multi-Hop QA Synthesis to generate high-quality, self-contained data.", "result": "Synthetic data achieves 16.7% higher quality and 67.91% lower variance, with performance gains up to 16% on reasoning benchmarks like MathVision.", "conclusion": "MindGYM demonstrates the effectiveness of self-challenging mechanisms for refining model capabilities with minimal human intervention, promoting data-centric research."}}
{"id": "2502.09604", "pdf": "https://arxiv.org/pdf/2502.09604", "abs": "https://arxiv.org/abs/2502.09604", "authors": ["Yung-Sung Chuang", "Benjamin Cohen-Wang", "Shannon Zejiang Shen", "Zhaofeng Wu", "Hu Xu", "Xi Victoria Lin", "James Glass", "Shang-Wen Li", "Wen-tau Yih"], "title": "SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICML 2025 main conference paper. The source code is available at\n  https://github.com/facebookresearch/SelfCite", "summary": "We introduce SelfCite, a novel self-supervised approach that aligns LLMs to\ngenerate high-quality, fine-grained, sentence-level citations for the\nstatements in their generated responses. Instead of only relying on costly and\nlabor-intensive annotations, SelfCite leverages a reward signal provided by the\nLLM itself through context ablation: If a citation is necessary, removing the\ncited text from the context should prevent the same response; if sufficient,\nretaining the cited text alone should preserve the same response. This reward\ncan guide the inference-time best-of-N sampling strategy to improve citation\nquality significantly, as well as be used in preference optimization to\ndirectly fine-tune the models for generating better citations. The\neffectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3\npoints on the LongBench-Cite benchmark across five long-form question answering\ntasks. The source code is available at\nhttps://github.com/facebookresearch/SelfCite", "AI": {"tldr": "SelfCite is a self-supervised method for improving sentence-level citations in LLM-generated responses by using the model's own reward signal via context ablation.", "motivation": "Existing citation methods rely on costly annotations; SelfCite aims to automate and improve citation quality without heavy human effort.", "method": "Uses context ablation to derive a reward signal: removing cited text should prevent the same response, while retaining it should preserve the response. This guides inference-time sampling and fine-tuning.", "result": "Increases citation F1 by up to 5.3 points on the LongBench-Cite benchmark across five tasks.", "conclusion": "SelfCite effectively improves citation quality in LLM outputs, demonstrating the potential of self-supervised alignment for fine-grained tasks."}}
{"id": "2410.19643", "pdf": "https://arxiv.org/pdf/2410.19643", "abs": "https://arxiv.org/abs/2410.19643", "authors": ["Nicol\u00e1s Nieto", "Simon B. Eickhoff", "Christian Jung", "Martin Reuter", "Kersten Diers", "Malte Kelm", "Artur Lichtenberg", "Federico Raimondo", "Kaustubh R. Patil"], "title": "Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine learning (ML) models benefit from large datasets. Collecting data in\nbiomedical domains is costly and challenging, hence, combining datasets has\nbecome a common practice. However, datasets obtained under different conditions\ncould present undesired site-specific variability. Data harmonization methods\naim to remove site-specific variance while retaining biologically relevant\ninformation. This study evaluates the effectiveness of popularly used\nComBat-based methods for harmonizing data in scenarios where the class balance\nis not equal across sites. We find that these methods struggle with data\nleakage issues. To overcome this problem, we propose a novel approach\nPrettYharmonize, designed to harmonize data by pretending the target labels. We\nvalidate our approach using controlled datasets designed to benchmark the\nutility of harmonization. Finally, using real-world MRI and clinical data, we\ncompare leakage-prone methods with PrettYharmonize and show that it achieves\ncomparable performance while avoiding data leakage, particularly in\nsite-target-dependence scenarios.", "AI": {"tldr": "The paper evaluates ComBat-based data harmonization methods, identifies data leakage issues in unequal class balance scenarios, and proposes PrettYharmonize to avoid leakage while maintaining performance.", "motivation": "Combining biomedical datasets is common but introduces site-specific variability. Existing harmonization methods struggle with data leakage when class balance varies across sites.", "method": "The study evaluates ComBat-based methods and introduces PrettYharmonize, which pretends target labels to prevent leakage. It tests both controlled and real-world MRI/clinical datasets.", "result": "PrettYharmonize avoids data leakage and performs comparably to leakage-prone methods, especially in site-target-dependence cases.", "conclusion": "PrettYharmonize is effective for harmonizing biomedical data without leakage, addressing limitations of existing methods."}}
{"id": "2305.15188", "pdf": "https://arxiv.org/pdf/2305.15188", "abs": "https://arxiv.org/abs/2305.15188", "authors": ["Wenjian Hao", "Paulo C. Heredia", "Shaoshuai Mou"], "title": "Optimal Control of Nonlinear Systems with Unknown Dynamics", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper presents a data-driven method for finding a closed-loop optimal\ncontroller, which minimizes a specified infinite-horizon cost function for\nsystems with unknown dynamics given any arbitrary initial state. Suppose the\nclosed-loop optimal controller can be parameterized by a given class of\nfunctions, hereafter referred to as the policy. The proposed method introduces\na novel gradient estimation framework, which approximates the gradient of the\ncost function with respect to the policy parameters via integrating the Koopman\noperator with the classical concept of actor-critic. This enables the policy\nparameters to be tuned iteratively using gradient descent to achieve an optimal\ncontroller, leveraging the linearity of the Koopman operator. The convergence\nanalysis of the proposed framework is provided. The effectiveness of the method\nis demonstrated through comparisons with a model-free reinforcement learning\napproach, and its control performance is further evaluated through simulations\nagainst model-based optimal control methods that solve the same optimal control\nproblem utilizing the exact system dynamics.", "AI": {"tldr": "A data-driven method for finding closed-loop optimal controllers for systems with unknown dynamics, using a novel gradient estimation framework combining the Koopman operator and actor-critic concepts.", "motivation": "To address the challenge of optimizing controllers for systems with unknown dynamics without relying on exact system models.", "method": "Introduces a gradient estimation framework integrating the Koopman operator with actor-critic methods to approximate cost function gradients for policy parameter tuning via gradient descent.", "result": "Demonstrates effectiveness through comparisons with model-free reinforcement learning and outperforms model-based optimal control methods in simulations.", "conclusion": "The proposed method successfully optimizes controllers for unknown systems, leveraging the Koopman operator's linearity and gradient-based tuning."}}
{"id": "2504.10804", "pdf": "https://arxiv.org/pdf/2504.10804", "abs": "https://arxiv.org/abs/2504.10804", "authors": ["Jiani Liu", "Zhiyuan Wang", "Zeliang Zhang", "Chao Huang", "Susan Liang", "Yunlong Tang", "Chenliang Xu"], "title": "Harnessing the Computation Redundancy in ViTs to Boost Adversarial Transferability", "categories": ["cs.CV"], "comment": "15 pages. 7 figures", "summary": "Vision Transformers (ViTs) have demonstrated impressive performance across a\nrange of applications, including many safety-critical tasks. However, their\nunique architectural properties raise new challenges and opportunities in\nadversarial robustness. In particular, we observe that adversarial examples\ncrafted on ViTs exhibit higher transferability compared to those crafted on\nCNNs, suggesting that ViTs contain structural characteristics favorable for\ntransferable attacks. In this work, we investigate the role of computational\nredundancy in ViTs and its impact on adversarial transferability. Unlike prior\nstudies that aim to reduce computation for efficiency, we propose to exploit\nthis redundancy to improve the quality and transferability of adversarial\nexamples. Through a detailed analysis, we identify two forms of redundancy,\nincluding the data-level and model-level, that can be harnessed to amplify\nattack effectiveness. Building on this insight, we design a suite of\ntechniques, including attention sparsity manipulation, attention head\npermutation, clean token regularization, ghost MoE diversification, and\ntest-time adversarial training. Extensive experiments on the ImageNet-1k\ndataset validate the effectiveness of our approach, showing that our methods\nsignificantly outperform existing baselines in both transferability and\ngenerality across diverse model architectures.", "AI": {"tldr": "The paper explores how Vision Transformers (ViTs) exhibit higher adversarial transferability than CNNs due to computational redundancy, proposing techniques to exploit this for stronger attacks.", "motivation": "ViTs' unique architecture raises new challenges in adversarial robustness, with observed higher transferability of adversarial examples compared to CNNs.", "method": "Investigates computational redundancy in ViTs, identifying data-level and model-level redundancy. Proposes techniques like attention sparsity manipulation and ghost MoE diversification.", "result": "Experiments on ImageNet-1k show the proposed methods outperform baselines in transferability and generality across architectures.", "conclusion": "Exploiting ViTs' redundancy improves adversarial attack effectiveness, offering new insights for robustness research."}}
{"id": "2502.09674", "pdf": "https://arxiv.org/pdf/2502.09674", "abs": "https://arxiv.org/abs/2502.09674", "authors": ["Wenbo Pan", "Zhichao Liu", "Qiguang Chen", "Xiangyang Zhou", "Haining Yu", "Xiaohua Jia"], "title": "The Hidden Dimensions of LLM Alignment: A Multi-Dimensional Analysis of Orthogonal Safety Directions", "categories": ["cs.CL", "cs.AI"], "comment": "Code and artifacts: https://github.com/BMPixel/safety-residual-space\n  Accepted by ICML 2025", "summary": "Large Language Models' safety-aligned behaviors, such as refusing harmful\nqueries, can be represented by linear directions in activation space. Previous\nresearch modeled safety behavior with a single direction, limiting mechanistic\nunderstanding to an isolated safety feature. In this work, we discover that\nsafety-aligned behavior is jointly controlled by multi-dimensional directions.\nNamely, we study the vector space of representation shifts during safety\nfine-tuning on Llama 3 8B for refusing jailbreaks. By studying orthogonal\ndirections in the space, we first find that a dominant direction governs the\nmodel's refusal behavior, while multiple smaller directions represent distinct\nand interpretable features like hypothetical narrative and role-playing. We\nthen measure how different directions promote or suppress the dominant\ndirection, showing the important role of secondary directions in shaping the\nmodel's refusal representation. Finally, we demonstrate that removing certain\ntrigger tokens in harmful queries can mitigate these directions to bypass the\nlearned safety capability, providing new insights on understanding safety\nalignment vulnerability from a multi-dimensional perspective. Code and\nartifacts are available at https://github.com/BMPixel/safety-residual-space.", "AI": {"tldr": "Safety-aligned behaviors in LLMs are controlled by multi-dimensional directions, not just one, revealing deeper mechanistic insights and vulnerabilities.", "motivation": "To understand the multi-dimensional nature of safety-aligned behaviors in LLMs, moving beyond the single-direction model.", "method": "Studied orthogonal directions in activation space of Llama 3 8B during safety fine-tuning, analyzing refusal behavior and interpretable features.", "result": "Found a dominant refusal direction and smaller interpretable ones; secondary directions shape refusal representation, and token removal can bypass safety.", "conclusion": "Safety alignment is multi-dimensional, with secondary directions playing key roles, offering new insights into vulnerabilities."}}
{"id": "2411.13079", "pdf": "https://arxiv.org/pdf/2411.13079", "abs": "https://arxiv.org/abs/2411.13079", "authors": ["Feng Gao", "Chao Yu", "Yu Wang", "Yi Wu"], "title": "Neural Internal Model Control: Learning a Robust Control Policy via Predictive Error Feedback", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted by RA-L", "summary": "Accurate motion control in the face of disturbances within complex\nenvironments remains a major challenge in robotics. Classical model-based\napproaches often struggle with nonlinearities and unstructured disturbances,\nwhile RL-based methods can be fragile when encountering unseen scenarios. In\nthis paper, we propose a novel framework, Neural Internal Model Control, which\nintegrates model-based control with RL-based control to enhance robustness. Our\nframework streamlines the predictive model by applying Newton-Euler equations\nfor rigid-body dynamics, eliminating the need to capture complex\nhigh-dimensional nonlinearities. This internal model combines model-free RL\nalgorithms with predictive error feedback. Such a design enables a closed-loop\ncontrol structure to enhance the robustness and generalizability of the control\nsystem. We demonstrate the effectiveness of our framework on both quadrotors\nand quadrupedal robots, achieving superior performance compared to\nstate-of-the-art methods. Furthermore, real-world deployment on a quadrotor\nwith rope-suspended payloads highlights the framework's robustness in\nsim-to-real transfer. Our code is released at\nhttps://github.com/thu-uav/NeuralIMC.", "AI": {"tldr": "A novel framework, Neural Internal Model Control, combines model-based and RL-based control to enhance robustness in robotics, outperforming state-of-the-art methods.", "motivation": "Addressing challenges in motion control due to nonlinearities and disturbances, where classical and RL-based methods fall short.", "method": "Integrates Newton-Euler equations for rigid-body dynamics with RL, using predictive error feedback for closed-loop control.", "result": "Superior performance on quadrotors and quadrupedal robots, with successful sim-to-real transfer in real-world tests.", "conclusion": "The framework improves robustness and generalizability, validated by real-world deployment and code release."}}
{"id": "2305.19294", "pdf": "https://arxiv.org/pdf/2305.19294", "abs": "https://arxiv.org/abs/2305.19294", "authors": ["Camila Kolling", "Till Speicher", "Vedant Nanda", "Mariya Toneva", "Krishna P. Gummadi"], "title": "Investigating the Effects of Fairness Interventions Using Pointwise Representational Similarity", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning (ML) algorithms can often exhibit discriminatory behavior,\nnegatively affecting certain populations across protected groups. To address\nthis, numerous debiasing methods, and consequently evaluation measures, have\nbeen proposed. Current evaluation measures for debiasing methods suffer from\ntwo main limitations: (1) they primarily provide a global estimate of\nunfairness, failing to provide a more fine-grained analysis, and (2) they\npredominantly analyze the model output on a specific task, failing to\ngeneralize the findings to other tasks. In this work, we introduce Pointwise\nNormalized Kernel Alignment (PNKA), a pointwise representational similarity\nmeasure that addresses these limitations by measuring how debiasing measures\naffect the intermediate representations of individuals. On tabular data, the\nuse of PNKA reveals previously unknown insights: while group fairness\npredominantly influences a small subset of the population, maintaining high\nrepresentational similarity for the majority, individual fairness constraints\nuniformly impact representations across the entire population, altering nearly\nevery data point. We show that by evaluating representations using PNKA, we can\nreliably predict the behavior of ML models trained on these representations.\nMoreover, applying PNKA to language embeddings shows that existing debiasing\nmethods may not perform as intended, failing to remove biases from\nstereotypical words and sentences. Our findings suggest that current evaluation\nmeasures for debiasing methods are insufficient, highlighting the need for a\ndeeper understanding of the effects of debiasing methods, and show how\npointwise representational similarity metrics can help with fairness audits.", "AI": {"tldr": "The paper introduces PNKA, a pointwise representational similarity measure, to address limitations in current debiasing evaluation methods, revealing new insights about fairness in ML models.", "motivation": "Current evaluation measures for debiasing methods lack fine-grained analysis and generalizability across tasks, limiting their effectiveness.", "method": "Proposes Pointwise Normalized Kernel Alignment (PNKA) to measure debiasing effects on intermediate representations of individuals.", "result": "PNKA reveals group fairness impacts a small subset, while individual fairness uniformly affects all. It also shows debiasing methods may fail in language embeddings.", "conclusion": "Existing debiasing evaluation measures are insufficient; PNKA offers a deeper understanding and aids fairness audits."}}
{"id": "2504.14202", "pdf": "https://arxiv.org/pdf/2504.14202", "abs": "https://arxiv.org/abs/2504.14202", "authors": ["Zichuan Liu", "Liming Jiang", "Qing Yan", "Yumin Jia", "Hao Kang", "Xin Lu"], "title": "Learning Joint ID-Textual Representation for ID-Preserving Image Synthesis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose a novel framework for ID-preserving generation using a multi-modal\nencoding strategy rather than injecting identity features via adapters into\npre-trained models. Our method treats identity and text as a unified\nconditioning input. To achieve this, we introduce FaceCLIP, a multi-modal\nencoder that learns a joint embedding space for both identity and textual\nsemantics. Given a reference face and a text prompt, FaceCLIP produces a\nunified representation that encodes both identity and text, which conditions a\nbase diffusion model to generate images that are identity-consistent and\ntext-aligned. We also present a multi-modal alignment algorithm to train\nFaceCLIP, using a loss that aligns its joint representation with face, text,\nand image embedding spaces. We then build FaceCLIP-SDXL, an ID-preserving image\nsynthesis pipeline by integrating FaceCLIP with Stable Diffusion XL (SDXL).\nCompared to prior methods, FaceCLIP-SDXL enables photorealistic portrait\ngeneration with better identity preservation and textual relevance. Extensive\nexperiments demonstrate its quantitative and qualitative superiority.", "AI": {"tldr": "A novel framework, FaceCLIP, integrates identity and text into a unified conditioning input for ID-preserving image generation, outperforming prior methods in photorealistic portraits.", "motivation": "To improve identity preservation and textual alignment in image generation by unifying identity and text inputs rather than using adapters.", "method": "Introduces FaceCLIP, a multi-modal encoder for joint embedding of identity and text, and integrates it with Stable Diffusion XL (SDXL) for image synthesis.", "result": "FaceCLIP-SDXL achieves photorealistic portrait generation with superior identity preservation and textual relevance.", "conclusion": "The proposed framework demonstrates quantitative and qualitative improvements over existing methods."}}
{"id": "2502.11018", "pdf": "https://arxiv.org/pdf/2502.11018", "abs": "https://arxiv.org/abs/2502.11018", "authors": ["Shijing Hu", "Jingyang Li", "Xingyu Xie", "Zhihui Lu", "Kim-Chuan Toh", "Pan Zhou"], "title": "GRIFFIN: Effective Token Alignment for Faster Speculative Decoding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating multiple draft tokens simultaneously. However, existing methods\noften struggle with token misalignment between the training and decoding\nphases, limiting their performance. To address this, we propose GRIFFIN, a\nnovel framework that incorporates a token-alignable training strategy and a\ntoken-alignable draft model to mitigate misalignment. The training strategy\nemploys a loss masking mechanism to exclude highly misaligned tokens during\ntraining, preventing them from negatively impacting the draft model's\noptimization. The token-alignable draft model introduces input tokens to\ncorrect inconsistencies in generated features. Experiments on LLaMA, Vicuna,\nQwen and Mixtral models demonstrate that GRIFFIN achieves an average acceptance\nlength improvement of over 8% and a speedup ratio exceeding 7%, outperforming\ncurrent speculative decoding state-of-the-art methods. Our code and GRIFFIN's\ndraft models are released publicly in https://github.com/hsj576/GRIFFIN.", "AI": {"tldr": "GRIFFIN improves speculative decoding in LLMs by addressing token misalignment with a novel training strategy and draft model, achieving better performance and speed.", "motivation": "Existing speculative decoding methods suffer from token misalignment between training and decoding phases, limiting their effectiveness.", "method": "GRIFFIN introduces a token-alignable training strategy (using loss masking) and a token-alignable draft model to correct feature inconsistencies.", "result": "Experiments show GRIFFIN improves acceptance length by 8% and speed by 7%, outperforming current methods.", "conclusion": "GRIFFIN effectively mitigates token misalignment, enhancing speculative decoding performance in LLMs."}}
{"id": "2411.13865", "pdf": "https://arxiv.org/pdf/2411.13865", "abs": "https://arxiv.org/abs/2411.13865", "authors": ["Qiyao Ma", "Menglin Yang", "Mingxuan Ju", "Tong Zhao", "Neil Shah", "Rex Ying"], "title": "Breaking Information Cocoons: A Hyperbolic Graph-LLM Framework for Exploration and Exploitation in Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Modern recommender systems often create information cocoons, restricting\nusers' exposure to diverse content. A key challenge lies in balancing content\nexploration and exploitation while allowing users to adjust their\nrecommendation preferences. Intuitively, this balance can be modeled as a\ntree-structured representation, where depth search facilitates exploitation and\nbreadth search enables exploration. However, existing approaches face two\nfundamental limitations: Euclidean methods struggle to capture hierarchical\nstructures, while hyperbolic methods, despite their superior hierarchical\nmodeling, lack semantic understanding of user and item profiles and fail to\nprovide a principled mechanism for balancing exploration and exploitation. To\naddress these challenges, we propose HERec, a hyperbolic graph-LLM framework\nthat effectively balances exploration and exploitation in recommender systems.\nOur framework introduces two key innovations: (1) a semantic-enhanced\nhierarchical mechanism that aligns rich textual descriptions processed by large\nlanguage models (LLMs) with collaborative information directly in hyperbolic\nspace, allowing for more nuanced updates that respect the underlying\nhierarchical structure in user-item profiles; (2) an automatic hierarchical\nrepresentation by optimizing Dasgupta's cost, which discovers hierarchical\nstructures without requiring predefined hyperparameters, enabling\nuser-adjustable exploration-exploitation trade-offs. Extensive experiments\ndemonstrate that HERec consistently outperforms both Euclidean and hyperbolic\nbaselines, achieving up to 5.49% improvement in utility metrics and 11.39%\nincrease in diversity metrics, effectively mitigating information cocoons. We\nopen-source our model implementation at https://github.com/Martin-qyma/HERec.", "AI": {"tldr": "HERec, a hyperbolic graph-LLM framework, balances exploration and exploitation in recommender systems by leveraging semantic-enhanced hierarchical mechanisms and automatic hierarchical representation, outperforming baselines in utility and diversity metrics.", "motivation": "Modern recommender systems create information cocoons, limiting content diversity. The challenge is balancing exploration and exploitation while allowing user preference adjustments.", "method": "HERec combines hyperbolic space for hierarchical modeling with LLM-processed textual descriptions, optimizing Dasgupta's cost for automatic hierarchical representation.", "result": "HERec improves utility by 5.49% and diversity by 11.39%, mitigating information cocoons.", "conclusion": "HERec effectively balances exploration and exploitation, outperforming existing methods, and is open-sourced for further use."}}
{"id": "2306.01271", "pdf": "https://arxiv.org/pdf/2306.01271", "abs": "https://arxiv.org/abs/2306.01271", "authors": ["Binghui Li", "Yuanzhi Li"], "title": "On the Clean Generalization and Robust Overfitting in Adversarial Training from Two Theoretical Views: Representation Complexity and Training Dynamics", "categories": ["cs.LG", "stat.ML"], "comment": "Published as a conference paper at ICML 2025; 28 pages", "summary": "Similar to surprising performance in the standard deep learning, deep nets\ntrained by adversarial training also generalize well for unseen clean data\n(natural data). However, despite adversarial training can achieve low robust\ntraining error, there exists a significant robust generalization gap. We call\nthis phenomenon the Clean Generalization and Robust Overfitting (CGRO). In this\nwork, we study the CGRO phenomenon in adversarial training from two views:\nrepresentation complexity and training dynamics. Specifically, we consider a\nbinary classification setting with $N$ separated training data points. First,\nwe prove that, based on the assumption that we assume there is\n$\\operatorname{poly}(D)$-size clean classifier (where $D$ is the data\ndimension), ReLU net with only $O(N D)$ extra parameters is able to leverages\nrobust memorization to achieve the CGRO, while robust classifier still requires\nexponential representation complexity in worst case. Next, we focus on a\nstructured-data case to analyze training dynamics, where we train a two-layer\nconvolutional network with $O(N D)$ width against adversarial perturbation. We\nthen show that a three-stage phase transition occurs during learning process\nand the network provably converges to robust memorization regime, which thereby\nresults in the CGRO. Besides, we also empirically verify our theoretical\nanalysis by experiments in real-image recognition datasets.", "AI": {"tldr": "Deep nets in adversarial training generalize well for clean data but show a robust generalization gap (CGRO). This paper studies CGRO via representation complexity and training dynamics, proving and empirically validating the phenomenon.", "motivation": "To understand why adversarial training achieves good clean generalization but suffers from robust overfitting (CGRO).", "method": "Analyzes CGRO through representation complexity (proving ReLU nets can achieve CGRO with extra parameters) and training dynamics (studying a structured-data case with a two-layer convolutional network).", "result": "ReLU nets with extra parameters can achieve CGRO, while robust classifiers require exponential complexity. A three-stage phase transition in training leads to robust memorization and CGRO.", "conclusion": "The CGRO phenomenon in adversarial training is explained by representation complexity and training dynamics, supported by theoretical proofs and empirical validation."}}
{"id": "2504.14391", "pdf": "https://arxiv.org/pdf/2504.14391", "abs": "https://arxiv.org/abs/2504.14391", "authors": ["Rahul Thapa", "Andrew Li", "Qingyang Wu", "Bryan He", "Yuki Sahashi", "Christina Binder", "Angela Zhang", "Ben Athiwaratkun", "Shuaiwen Leon Song", "David Ouyang", "James Zou"], "title": "How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?", "categories": ["cs.CV"], "comment": null, "summary": "Publicly available biomedical videos, such as those on YouTube, serve as\nvaluable educational resources for medical students. Unlike standard machine\nlearning datasets, these videos are designed for human learners, often mixing\nmedical imagery with narration, explanatory diagrams, and contextual framing.\nIn this work, we investigate whether such pedagogically rich, yet\nnon-standardized and heterogeneous videos can effectively teach general-domain\nvision-language models biomedical knowledge. To this end, we introduce\nOpenBiomedVi, a biomedical video instruction tuning dataset comprising 1031\nhours of video-caption and Q/A pairs, curated through a multi-step\nhuman-in-the-loop pipeline. Diverse biomedical video datasets are rare, and\nOpenBiomedVid fills an important gap by providing instruction-style supervision\ngrounded in real-world educational content. Surprisingly, despite the informal\nand heterogeneous nature of these videos, the fine-tuned Qwen-2-VL models\nexhibit substantial performance improvements across most benchmarks. The 2B\nmodel achieves gains of 98.7% on video tasks, 71.2% on image tasks, and 0.2% on\ntext tasks. The 7B model shows improvements of 37.09% on video and 11.2% on\nimage tasks, with a slight degradation of 2.7% on text tasks compared to their\nrespective base models. To address the lack of standardized biomedical video\nevaluation datasets, we also introduce two new expert curated benchmarks,\nMIMICEchoQA and SurgeryVideoQA. On these benchmarks, the 2B model achieves\ngains of 99.1% and 98.1%, while the 7B model shows gains of 22.5% and 52.1%,\nrespectively, demonstrating the models' ability to generalize and perform\nbiomedical video understanding on cleaner and more standardized datasets than\nthose seen during training. These results suggest that educational videos\ncreated for human learning offer a surprisingly effective training signal for\nbiomedical VLMs.", "AI": {"tldr": "OpenBiomedVi, a biomedical video dataset, enhances vision-language models' performance using educational videos, achieving significant gains on benchmarks.", "motivation": "To explore if pedagogically rich but non-standardized biomedical videos can effectively teach vision-language models biomedical knowledge.", "method": "Curated OpenBiomedVi dataset (1031 hours of video-caption/Q&A pairs) and fine-tuned Qwen-2-VL models. Introduced new benchmarks (MIMICEchoQA, SurgeryVideoQA).", "result": "Substantial improvements: 2B model (98.7% video, 71.2% image, 0.2% text); 7B model (37.09% video, 11.2% image, -2.7% text). New benchmarks also showed gains.", "conclusion": "Educational videos for humans are surprisingly effective for training biomedical VLMs, even with informal content."}}
{"id": "2502.11438", "pdf": "https://arxiv.org/pdf/2502.11438", "abs": "https://arxiv.org/abs/2502.11438", "authors": ["Jimin Lee", "Ingeol Baek", "Byeongjeong Kim", "Hyunkyung Bae", "Hwanhee Lee"], "title": "SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL", "categories": ["cs.CL"], "comment": "13 pages, 5 figures, 10 tables", "summary": "Text-to-SQL aims to convert natural language questions into executable SQL\nqueries. While previous approaches, such as skeleton-masked selection, have\ndemonstrated strong performance by retrieving similar training examples to\nguide large language models (LLMs), they struggle in real-world scenarios where\nsuch examples are unavailable. To overcome this limitation, we propose\nSelf-Augmentation in-context learning with Fine-grained Example selection for\nText-to-SQL (SAFE-SQL), a novel framework that improves SQL generation by\ngenerating and filtering self-augmented examples. SAFE-SQL first prompts an LLM\nto generate multiple Text-to-SQL examples relevant to the test input. Then\nSAFE-SQL filters these examples through three relevance assessments,\nconstructing high-quality in-context learning examples. Using self-generated\nexamples, SAFE-SQL surpasses the previous zero-shot, and few-shot Text-to-SQL\nframeworks, achieving higher execution accuracy. Notably, our approach provides\nadditional performance gains in extra hard and unseen scenarios, where\nconventional methods often fail.", "AI": {"tldr": "SAFE-SQL improves Text-to-SQL by generating and filtering self-augmented examples, outperforming zero-shot and few-shot methods, especially in hard and unseen scenarios.", "motivation": "Previous methods rely on similar training examples, which are often unavailable in real-world scenarios, limiting their effectiveness.", "method": "SAFE-SQL generates multiple Text-to-SQL examples, filters them via three relevance assessments, and uses these for in-context learning.", "result": "SAFE-SQL achieves higher execution accuracy than zero-shot and few-shot frameworks, excelling in challenging scenarios.", "conclusion": "SAFE-SQL addresses the limitation of unavailable training examples, offering robust performance in real-world and unseen cases."}}
{"id": "2412.03188", "pdf": "https://arxiv.org/pdf/2412.03188", "abs": "https://arxiv.org/abs/2412.03188", "authors": ["Ivan Kralj", "Lodovico Giaretta", "Gordan Je\u017ei\u0107", "Ivana Podnar \u017darko", "\u0160ar\u016bnas Girdzijauskas"], "title": "Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "9 pages, 4 figures, 3 tables, conference", "summary": "In smart mobility, large networks of geographically distributed sensors\nproduce vast amounts of high-frequency spatio-temporal data that must be\nprocessed in real time to avoid major disruptions. Traditional centralized\napproaches are increasingly unsuitable to this task, as they struggle to scale\nwith expanding sensor networks, and reliability issues in central components\ncan easily affect the whole deployment. To address these challenges, we explore\nand adapt semi-decentralized training techniques for Spatio-Temporal Graph\nNeural Networks (ST-GNNs) in smart mobility domain. We implement a simulation\nframework where sensors are grouped by proximity into multiple cloudlets, each\nhandling a subgraph of the traffic graph, fetching node features from other\ncloudlets to train its own local ST-GNN model, and exchanging model updates\nwith other cloudlets to ensure consistency, enhancing scalability and removing\nreliance on a centralized aggregator. We perform extensive comparative\nevaluation of four different ST-GNN training setups -- centralized, traditional\nFL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the\nMETR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed\npredictions. Experimental results show that semi-decentralized setups are\ncomparable to centralized approaches in performance metrics, while offering\nadvantages in terms of scalability and fault tolerance. In addition, we\nhighlight often overlooked issues in existing literature for distributed\nST-GNNs, such as the variation in model performance across different\ngeographical areas due to region-specific traffic patterns, and the significant\ncommunication overhead and computational costs that arise from the large\nreceptive field of GNNs, leading to substantial data transfers and increased\ncomputation of partial embeddings.", "AI": {"tldr": "The paper explores semi-decentralized training for Spatio-Temporal Graph Neural Networks (ST-GNNs) in smart mobility, showing comparable performance to centralized methods with better scalability and fault tolerance.", "motivation": "Centralized approaches struggle with scalability and reliability in large sensor networks, prompting the need for decentralized solutions.", "method": "A simulation framework groups sensors into cloudlets, each training local ST-GNN models and exchanging updates, avoiding centralized aggregation.", "result": "Semi-decentralized setups match centralized performance in vehicle speed predictions while improving scalability and fault tolerance.", "conclusion": "Semi-decentralized ST-GNN training is viable for smart mobility, though challenges like region-specific performance and communication overhead remain."}}
{"id": "2311.02960", "pdf": "https://arxiv.org/pdf/2311.02960", "abs": "https://arxiv.org/abs/2311.02960", "authors": ["Peng Wang", "Xiao Li", "Can Yaras", "Zhihui Zhu", "Laura Balzano", "Wei Hu", "Qing Qu"], "title": "Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination", "categories": ["cs.LG", "cs.CV", "math.OC"], "comment": "65 pages, 17 figures", "summary": "Over the past decade, deep learning has proven to be a highly effective tool\nfor learning meaningful features from raw data. However, it remains an open\nquestion how deep networks perform hierarchical feature learning across layers.\nIn this work, we attempt to unveil this mystery by investigating the structures\nof intermediate features. Motivated by our empirical findings that linear\nlayers mimic the roles of deep layers in nonlinear networks for feature\nlearning, we explore how deep linear networks transform input data into output\nby investigating the output (i.e., features) of each layer after training in\nthe context of multi-class classification problems. Toward this goal, we first\ndefine metrics to measure within-class compression and between-class\ndiscrimination of intermediate features, respectively. Through theoretical\nanalysis of these two metrics, we show that the evolution of features follows a\nsimple and quantitative pattern from shallow to deep layers when the input data\nis nearly orthogonal and the network weights are minimum-norm, balanced, and\napproximate low-rank: Each layer of the linear network progressively compresses\nwithin-class features at a geometric rate and discriminates between-class\nfeatures at a linear rate with respect to the number of layers that data have\npassed through. To the best of our knowledge, this is the first quantitative\ncharacterization of feature evolution in hierarchical representations of deep\nlinear networks. Empirically, our extensive experiments not only validate our\ntheoretical results numerically but also reveal a similar pattern in deep\nnonlinear networks which aligns well with recent empirical studies. Moreover,\nwe demonstrate the practical implications of our results in transfer learning.\nOur code is available at https://github.com/Heimine/PNC_DLN.", "AI": {"tldr": "The paper investigates how deep linear networks hierarchically learn features, showing progressive within-class compression and between-class discrimination, with empirical validation in nonlinear networks.", "motivation": "To understand how deep networks perform hierarchical feature learning, focusing on intermediate features in linear networks.", "method": "Define metrics for within-class compression and between-class discrimination, analyze feature evolution in deep linear networks, and validate empirically.", "result": "Features compress within-class geometrically and discriminate between-class linearly, validated in nonlinear networks.", "conclusion": "First quantitative characterization of feature evolution in deep linear networks, with practical implications for transfer learning."}}
{"id": "2504.14642", "pdf": "https://arxiv.org/pdf/2504.14642", "abs": "https://arxiv.org/abs/2504.14642", "authors": ["Lin Li", "Wei Chen", "Jiahui Li", "Kwang-Ting Cheng", "Long Chen"], "title": "Relation-R1: Progressively Cognitive Chain-of-Thought Guided Reinforcement Learning for Unified Relation Comprehension", "categories": ["cs.CV"], "comment": "Ongoing project", "summary": "Recent advances in multi-modal large language models (MLLMs) have\nsignificantly improved object-level grounding and region captioning. However,\nthey remain limited in visual relation understanding, struggling even with\nbinary relation detection, let alone \\textit{N}-ary relations involving\nmultiple semantic roles. The core reason is the lack of modeling for\n\\textit{structural semantic dependencies} among multi-entities, leading to\nunreliable outputs, hallucinations, and over-reliance on language priors (\\eg,\ndefaulting to ``person drinks a milk'' if a person is merely holding it). To\nthis end, we propose Relation-R1, the \\textit{first unified} relation\ncomprehension framework that explicitly integrates cognitive chain-of-thought\n(CoT)-guided supervised fine-tuning (SFT) and group relative policy\noptimization (GRPO) within a reinforcement learning (RL) paradigm.\nSpecifically, we first establish foundational reasoning capabilities via SFT,\nenforcing structured outputs with thinking processes. Then, GRPO is utilized to\nrefine these outputs via multi-rewards optimization, prioritizing\nvisual-semantic grounding over language-induced biases, thereby improving\ngeneralization capability. Furthermore, we investigate the impact of various\nCoT strategies within this framework, demonstrating that a specific-to-general\nprogressive approach in CoT guidance further improves generalization,\nespecially in capturing synonymous \\textit{N}-ary relations. Extensive\nexperiments on widely-used PSG and SWiG datasets demonstrate that Relation-R1\nachieves state-of-the-art performance in both binary and \\textit{N}-ary\nrelation understanding.", "AI": {"tldr": "Relation-R1 is a unified framework for visual relation understanding, combining cognitive CoT-guided SFT and GRPO in RL, outperforming existing methods in binary and N-ary relations.", "motivation": "Current MLLMs lack structural semantic dependency modeling, leading to unreliable outputs and biases in visual relation understanding.", "method": "Proposes Relation-R1, integrating CoT-guided SFT for reasoning and GRPO for multi-rewards optimization to prioritize visual-semantic grounding.", "result": "Achieves state-of-the-art performance on PSG and SWiG datasets for binary and N-ary relation understanding.", "conclusion": "Relation-R1 effectively addresses limitations in visual relation understanding by combining structured reasoning and optimization, improving generalization."}}
{"id": "2502.11471", "pdf": "https://arxiv.org/pdf/2502.11471", "abs": "https://arxiv.org/abs/2502.11471", "authors": ["Kangyang Luo", "Yuzhuo Bai", "Cheng Gao", "Shuzheng Si", "Yingli Shen", "Zhu Liu", "Zhitong Wang", "Cunliang Kong", "Wenhao Li", "Yufei Huang", "Ye Tian", "Xuantang Xiong", "Lei Han", "Maosong Sun"], "title": "GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion", "categories": ["cs.CL", "cs.IR"], "comment": "Accepted by ACL2025(Findings)", "summary": "Knowledge Graph Completion (KGC), which aims to infer missing or incomplete\nfacts, is a crucial task for KGs. However, integrating the vital structural\ninformation of KGs into Large Language Models (LLMs) and outputting predictions\ndeterministically remains challenging. To address this, we propose a new method\ncalled GLTW, which encodes the structural information of KGs and merges it with\nLLMs to enhance KGC performance. Specifically, we introduce an improved Graph\nTransformer (iGT) that effectively encodes subgraphs with both local and global\nstructural information and inherits the characteristics of language model,\nbypassing training from scratch. Also, we develop a subgraph-based\nmulti-classification training objective, using all entities within KG as\nclassification objects, to boost learning efficiency.Importantly, we combine\niGT with an LLM that takes KG language prompts as input.Our extensive\nexperiments on various KG datasets show that GLTW achieves significant\nperformance gains compared to SOTA baselines.", "AI": {"tldr": "GLTW enhances Knowledge Graph Completion (KGC) by merging structural KG information with LLMs using an improved Graph Transformer (iGT) and subgraph-based training.", "motivation": "Integrating KG structural information into LLMs for deterministic KGC predictions is challenging.", "method": "Proposes GLTW with iGT for encoding subgraphs and a subgraph-based multi-classification training objective, combined with LLMs.", "result": "GLTW achieves significant performance gains over SOTA baselines in experiments.", "conclusion": "GLTW effectively merges KG structure with LLMs, improving KGC performance."}}
{"id": "2412.10255", "pdf": "https://arxiv.org/pdf/2412.10255", "abs": "https://arxiv.org/abs/2412.10255", "authors": ["Yudong Jiang", "Baohan Xu", "Siqian Yang", "Mingyu Yin", "Jing Liu", "Chao Xu", "Siqi Wang", "Yidi Wu", "Bingwen Zhu", "Xinwen Zhang", "Xingyu Zheng", "Jixuan Xu", "Yue Zhang", "Jinlong Hou", "Huyang Sun"], "title": "AniSora: Exploring the Frontiers of Animation Video Generation in the Sora Era", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "Animation has gained significant interest in the recent film and TV industry.\nDespite the success of advanced video generation models like Sora, Kling, and\nCogVideoX in generating natural videos, they lack the same effectiveness in\nhandling animation videos. Evaluating animation video generation is also a\ngreat challenge due to its unique artist styles, violating the laws of physics\nand exaggerated motions. In this paper, we present a comprehensive system,\nAniSora, designed for animation video generation, which includes a data\nprocessing pipeline, a controllable generation model, and an evaluation\nbenchmark. Supported by the data processing pipeline with over 10M high-quality\ndata, the generation model incorporates a spatiotemporal mask module to\nfacilitate key animation production functions such as image-to-video\ngeneration, frame interpolation, and localized image-guided animation. We also\ncollect an evaluation benchmark of 948 various animation videos, with\nspecifically developed metrics for animation video generation. Our entire\nproject is publicly available on\nhttps://github.com/bilibili/Index-anisora/tree/main.", "AI": {"tldr": "AniSora is a system for animation video generation, addressing challenges like unique styles and exaggerated motions, with a data pipeline, generation model, and evaluation benchmark.", "motivation": "Existing video generation models struggle with animation due to its unique styles and physics-defying motions, necessitating a specialized solution.", "method": "AniSora includes a data processing pipeline (10M+ high-quality data), a controllable generation model with a spatiotemporal mask module, and an evaluation benchmark (948 videos).", "result": "The system supports key animation functions like image-to-video generation, frame interpolation, and localized image-guided animation.", "conclusion": "AniSora provides a comprehensive solution for animation video generation, with publicly available resources for further development."}}
{"id": "2312.15889", "pdf": "https://arxiv.org/pdf/2312.15889", "abs": "https://arxiv.org/abs/2312.15889", "authors": ["Biyan Zhou", "Pao-Sheng Vincent Sun", "Arindam Basu"], "title": "Combining SNNs with Filtering for Efficient Neural Decoding in Implantable Brain-Machine Interfaces", "categories": ["cs.LG", "cs.HC", "cs.NE", "q-bio.NC"], "comment": null, "summary": "While it is important to make implantable brain-machine interfaces (iBMI)\nwireless to increase patient comfort and safety, the trend of increased channel\ncount in recent neural probes poses a challenge due to the concomitant increase\nin the data rate. Extracting information from raw data at the source by using\nedge computing is a promising solution to this problem, with integrated\nintention decoders providing the best compression ratio. Recent benchmarking\nefforts have shown recurrent neural networks to be the best solution. Spiking\nNeural Networks (SNN) emerge as a promising solution for resource efficient\nneural decoding while Long Short Term Memory (LSTM) networks achieve the best\naccuracy. In this work, we show that combining traditional signal processing\ntechniques, namely signal filtering, with SNNs improve their decoding\nperformance significantly for regression tasks, closing the gap with LSTMs, at\nlittle added cost. Results with different filters are shown with Bessel filters\nproviding best performance. Two block-bidirectional Bessel filters have been\nused--one for low latency and another for high accuracy. Adding the high\naccuracy variant of the Bessel filters to the output of ANN, SNN and variants\nprovided statistically significant benefits with maximum gains of $\\approx 5\\%$\nand $8\\%$ in $R^2$ for two SNN topologies (SNN\\_Streaming and SNN\\_3D). Our\nwork presents state of the art results for this dataset and paves the way for\ndecoder-integrated-implants of the future.", "AI": {"tldr": "Combining signal filtering with Spiking Neural Networks (SNNs) improves decoding performance for wireless brain-machine interfaces, closing the gap with LSTMs at minimal cost.", "motivation": "The challenge of high data rates in wireless brain-machine interfaces (iBMI) necessitates efficient edge computing solutions, with SNNs offering resource efficiency but lagging in accuracy.", "method": "Traditional signal processing (Bessel filters) is combined with SNNs to enhance performance. Two block-bidirectional Bessel filters (low latency and high accuracy) are tested.", "result": "The high-accuracy Bessel filter variant significantly improved SNN performance, with gains of \u22485% and 8% in R\u00b2 for two SNN topologies.", "conclusion": "This approach achieves state-of-the-art results, advancing the feasibility of decoder-integrated implants."}}
{"id": "2504.14785", "pdf": "https://arxiv.org/pdf/2504.14785", "abs": "https://arxiv.org/abs/2504.14785", "authors": ["Zhenyu Yu", "Mohd Yamani Idna Idris", "Pei Wang"], "title": "DC4CR: When Cloud Removal Meets Diffusion Control in Remote Sensing", "categories": ["cs.CV"], "comment": null, "summary": "Cloud occlusion significantly hinders remote sensing applications by\nobstructing surface information and complicating analysis. To address this, we\npropose DC4CR (Diffusion Control for Cloud Removal), a novel multimodal\ndiffusion-based framework for cloud removal in remote sensing imagery. Our\nmethod introduces prompt-driven control, allowing selective removal of thin and\nthick clouds without relying on pre-generated cloud masks, thereby enhancing\npreprocessing efficiency and model adaptability. Additionally, we integrate\nlow-rank adaptation for computational efficiency, subject-driven generation for\nimproved generalization, and grouped learning to enhance performance on small\ndatasets. Designed as a plug-and-play module, DC4CR seamlessly integrates into\nexisting cloud removal models, providing a scalable and robust solution.\nExtensive experiments on the RICE and CUHK-CR datasets demonstrate\nstate-of-the-art performance, achieving superior cloud removal across diverse\nconditions. This work presents a practical and efficient approach for remote\nsensing image processing with broad real-world applications.", "AI": {"tldr": "DC4CR is a diffusion-based framework for cloud removal in remote sensing, offering prompt-driven control, computational efficiency, and scalability without needing cloud masks.", "motivation": "Cloud occlusion obstructs surface information in remote sensing, complicating analysis. DC4CR aims to address this by enabling efficient and adaptable cloud removal.", "method": "Uses multimodal diffusion with prompt-driven control, low-rank adaptation, subject-driven generation, and grouped learning for small datasets. Designed as a plug-and-play module.", "result": "Achieves state-of-the-art performance on RICE and CUHK-CR datasets, effectively removing clouds under diverse conditions.", "conclusion": "DC4CR provides a practical, scalable solution for cloud removal in remote sensing, with broad real-world applications."}}
{"id": "2502.11811", "pdf": "https://arxiv.org/pdf/2502.11811", "abs": "https://arxiv.org/abs/2502.11811", "authors": ["Qianchi Zhang", "Hainan Zhang", "Liang Pang", "Ziwei Wang", "Hongwei Zheng", "Yongxin Tong", "Zhiming Zheng"], "title": "FineFilter: A Fine-grained Noise Filtering Mechanism for Retrieval-Augmented Large Language Models", "categories": ["cs.CL"], "comment": "18 pages, 4 figures, 18 tables, under review", "summary": "Retrieved documents containing noise will hinder Retrieval-Augmented\nGeneration (RAG) from detecting answer clues, necessitating noise filtering\nmechanisms to enhance accuracy. Existing methods use reranking or summarization\nto identify the most relevant sentences, but directly and accurately locating\nanswer clues from these large-scale and complex documents remains challenging.\nUnlike these document-level operations, we treat noise filtering as a\nsentence-level MinMax optimization problem: first identifying potential clues\nfrom multiple documents, then ranking them by relevance, and finally retaining\nthe minimum number of clues through truncation. In this paper, we propose\nFineFilter, a novel fine-grained noise filtering mechanism for RAG, consisting\nof a clue extractor, a reranker, and a truncator. We optimize each module to\ntackle complex reasoning challenges: (1) The clue extractor first uses\nsentences containing the answer and similar ones as fine-tuning targets, aiming\nto extract sufficient potential clues; (2) The reranker is trained to\nprioritize effective clues based on the real feedback from the generation\nmodule, with clues capable of generating correct answers as positive samples\nand others as negative; (3) The truncator takes the minimum number of clues\nneeded to answer the question (truncation point) as fine-tuning targets, and\nperforms truncation on the reranked clues to achieve fine-grained noise\nfiltering. Experiments on three QA datasets demonstrate that FineFilter\nsignificantly improves QA performance over baselines on both LLaMA3 and\nMistral. Further analysis confirms its effectiveness in complex reasoning,\nrobustness to unreliable retrieval, and generalization to different scenarios.", "AI": {"tldr": "FineFilter is a fine-grained noise filtering mechanism for RAG, improving QA performance by optimizing clue extraction, reranking, and truncation.", "motivation": "Noise in retrieved documents hinders RAG's accuracy, and existing methods struggle with direct answer clue identification.", "method": "FineFilter uses a clue extractor, reranker, and truncator to optimize sentence-level MinMax filtering.", "result": "FineFilter outperforms baselines on QA datasets, showing effectiveness in complex reasoning and robustness.", "conclusion": "FineFilter enhances RAG accuracy by fine-grained noise filtering and generalizes well across scenarios."}}
{"id": "2412.20798", "pdf": "https://arxiv.org/pdf/2412.20798", "abs": "https://arxiv.org/abs/2412.20798", "authors": ["Supriya Manna", "Niladri Sett"], "title": "Reconciling Privacy and Explainability in High-Stakes: A Systematic Inquiry", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": "Accepted at TMLR", "summary": "Deep learning's preponderance across scientific domains has reshaped\nhigh-stakes decision-making, making it essential to follow rigorous operational\nframeworks that include both Right-to-Privacy (RTP) and Right-to-Explanation\n(RTE). This paper examines the complexities of combining these two\nrequirements. For RTP, we focus on `Differential privacy` (DP), which is\nconsidered the current gold standard for privacy-preserving machine learning\ndue to its strong quantitative guarantee of privacy. For RTE, we focus on\npost-hoc explainers: they are the go-to option for model auditing as they\noperate independently of model training. We formally investigate DP models and\nvarious commonly-used post-hoc explainers: how to evaluate these explainers\nsubject to RTP, and analyze the intrinsic interactions between DP models and\nthese explainers. Furthermore, our work throws light on how RTP and RTE can be\neffectively combined in high-stakes applications. Our study concludes by\noutlining an industrial software pipeline, with the example of a wildly used\nuse-case, that respects both RTP and RTE requirements.", "AI": {"tldr": "The paper explores combining Right-to-Privacy (RTP) and Right-to-Explanation (RTE) in deep learning, focusing on Differential Privacy (DP) for RTP and post-hoc explainers for RTE. It evaluates their interactions and proposes a software pipeline for high-stakes applications.", "motivation": "The increasing reliance on deep learning in high-stakes decision-making necessitates frameworks that balance privacy (RTP) and explainability (RTE).", "method": "The study examines DP models and post-hoc explainers, evaluating their compatibility and interactions under RTP and RTE constraints.", "result": "The research provides insights into combining RTP and RTE effectively and proposes a practical software pipeline for such applications.", "conclusion": "The paper highlights the feasibility of integrating RTP and RTE in deep learning, demonstrated through a real-world use-case."}}
{"id": "2401.06281", "pdf": "https://arxiv.org/pdf/2401.06281", "abs": "https://arxiv.org/abs/2401.06281", "authors": ["Fabio De Sousa Ribeiro", "Ben Glocker"], "title": "Demystifying Variational Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Despite the growing interest in diffusion models, gaining a deep\nunderstanding of the model class remains an elusive endeavour, particularly for\nthe uninitiated in non-equilibrium statistical physics. Thanks to the rapid\nrate of progress in the field, most existing work on diffusion models focuses\non either applications or theoretical contributions. Unfortunately, the\ntheoretical material is often inaccessible to practitioners and new\nresearchers, leading to a risk of superficial understanding in ongoing\nresearch. Given that diffusion models are now an indispensable tool, a clear\nand consolidating perspective on the model class is needed to properly\ncontextualize recent advances in generative modelling and lower the barrier to\nentry for new researchers. To that end, we revisit predecessors to diffusion\nmodels like hierarchical latent variable models and synthesize a holistic\nperspective using only directed graphical modelling and variational inference\nprinciples. The resulting narrative is easier to follow as it imposes fewer\nprerequisites on the average reader relative to the view from non-equilibrium\nthermodynamics or stochastic differential equations.", "AI": {"tldr": "The paper aims to simplify the understanding of diffusion models by synthesizing a holistic perspective using directed graphical modeling and variational inference, making it more accessible to practitioners and new researchers.", "motivation": "The growing interest in diffusion models lacks a clear, accessible theoretical foundation, risking superficial understanding. The paper seeks to lower the barrier to entry by consolidating knowledge.", "method": "The authors revisit predecessors like hierarchical latent variable models and use directed graphical modeling and variational inference to explain diffusion models.", "result": "The proposed narrative is easier to follow, requiring fewer prerequisites compared to approaches based on non-equilibrium thermodynamics or stochastic differential equations.", "conclusion": "A clearer, more accessible perspective on diffusion models is provided, aiding practitioners and new researchers in contextualizing advances in generative modeling."}}
{"id": "2504.14933", "pdf": "https://arxiv.org/pdf/2504.14933", "abs": "https://arxiv.org/abs/2504.14933", "authors": ["Mazharul Islam Rakib", "Showrin Rahman", "Joyanta Jyoti Mondal", "Xi Xiao", "David Lewis", "Alessandra Mileo", "Meem Arafat Manab"], "title": "TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion Models", "categories": ["cs.CV", "68T07, 68U10, 68T45"], "comment": "16 pages, 9 figures, published to IFIP International Summer School on\n  Privacy and Identity Management", "summary": "In today's age of social media and marketing, copyright issues can be a major\nroadblock to the free sharing of images. Generative AI models have made it\npossible to create high-quality images, but concerns about copyright\ninfringement are a hindrance to their abundant use. As these models use data\nfrom training images to generate new ones, it is often a daunting task to\nensure they do not violate intellectual property rights. Some AI models have\neven been noted to directly copy copyrighted images, a problem often referred\nto as source copying. Traditional copyright protection measures such as\nwatermarks and metadata have also proven to be futile in this regard. To\naddress this issue, we propose a novel two-step image generation model inspired\nby the conditional diffusion model. The first step involves creating an image\nsegmentation mask for some prompt-based generated images. This mask embodies\nthe shape of the image. Thereafter, the diffusion model is asked to generate\nthe image anew while avoiding the shape in question. This approach shows a\ndecrease in structural similarity from the training image, i.e. we are able to\navoid the source copying problem using this approach without expensive\nretraining of the model or user-centered prompt generation techniques. This\nmakes our approach the most computationally inexpensive approach to avoiding\nboth copyright infringement and source copying for diffusion model-based image\ngeneration.", "AI": {"tldr": "A two-step image generation model is proposed to avoid copyright infringement and source copying in AI-generated images, using segmentation masks and diffusion models to reduce structural similarity to training images.", "motivation": "Addressing copyright concerns in AI-generated images, particularly the issue of source copying, which hinders the free use of generative models.", "method": "A novel two-step approach: first, creating a segmentation mask for prompt-based images; second, regenerating the image while avoiding the masked shape, reducing structural similarity to training data.", "result": "The method decreases structural similarity to training images, effectively avoiding source copying without costly retraining or user-centered prompts.", "conclusion": "The proposed approach is a computationally inexpensive solution to prevent copyright infringement and source copying in diffusion model-based image generation."}}
{"id": "2502.11824", "pdf": "https://arxiv.org/pdf/2502.11824", "abs": "https://arxiv.org/abs/2502.11824", "authors": ["Chengyan Wu", "Bolei Ma", "Yihong Liu", "Zheyu Zhang", "Ningyuan Deng", "Yanshu Li", "Baolan Chen", "Yi Zhang", "Yun Xue", "Barbara Plank"], "title": "M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis", "categories": ["cs.CL"], "comment": null, "summary": "Aspect-based sentiment analysis (ABSA) is a crucial task in information\nextraction and sentiment analysis, aiming to identify aspects with associated\nsentiment elements in text. However, existing ABSA datasets are predominantly\nEnglish-centric, limiting the scope for multilingual evaluation and research.\nTo bridge this gap, we present M-ABSA, a comprehensive dataset spanning 7\ndomains and 21 languages, making it the most extensive multilingual parallel\ndataset for ABSA to date. Our primary focus is on triplet extraction, which\ninvolves identifying aspect terms, aspect categories, and sentiment polarities.\nThe dataset is constructed through an automatic translation process with human\nreview to ensure quality. We perform extensive experiments using various\nbaselines to assess performance and compatibility on M-ABSA. Our empirical\nfindings highlight that the dataset enables diverse evaluation tasks, such as\nmultilingual and multi-domain transfer learning, and large language model\nevaluation, underscoring its inclusivity and its potential to drive\nadvancements in multilingual ABSA research.", "AI": {"tldr": "The paper introduces M-ABSA, a multilingual dataset for aspect-based sentiment analysis (ABSA) covering 7 domains and 21 languages, addressing the lack of non-English ABSA resources. It focuses on triplet extraction and demonstrates the dataset's utility for diverse evaluation tasks.", "motivation": "Existing ABSA datasets are mostly English-centric, limiting multilingual research. The authors aim to bridge this gap by creating a comprehensive, multilingual dataset.", "method": "M-ABSA is built via automatic translation followed by human review. Experiments with various baselines assess its performance and compatibility.", "result": "The dataset supports multilingual and multi-domain transfer learning, as well as large language model evaluation, showcasing its inclusivity and research potential.", "conclusion": "M-ABSA is a valuable resource for advancing multilingual ABSA research, enabling diverse evaluation tasks and fostering inclusivity."}}
{"id": "2501.11264", "pdf": "https://arxiv.org/pdf/2501.11264", "abs": "https://arxiv.org/abs/2501.11264", "authors": ["Wannita Takerngsaksiri", "Micheal Fu", "Chakkrit Tantithamthavorn", "Jirat Pasuksmit", "Kun Chen", "Ming Wu"], "title": "Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "11 pages, 7 figures, 8 tables, under review", "summary": "Software engineers spend a significant amount of time reading code during the\nsoftware development process. This trend is amplified by the emergence of large\nlanguage models (LLMs) that automatically generate code. However, little is\nknown about the readability of the LLM-generated code and whether it is still\nimportant from practitioners' perspectives in this new era. In this paper, we\nconduct a survey to explore the practitioners' perspectives on code readability\nin the age of LLMs and investigate the readability of our LLM-based software\ndevelopment agents framework, HULA, by comparing its generated code with\nhuman-written code in real-world scenarios. Overall, the findings underscore\nthat (1) readability remains a critical aspect of software development; (2) the\nreadability of our LLM-generated code is comparable to human-written code,\nfostering the establishment of appropriate trust and driving the broad adoption\nof our LLM-powered software development platform.", "AI": {"tldr": "The paper explores the importance of code readability in the era of LLMs, finding it remains critical and that LLM-generated code (from their HULA framework) is as readable as human-written code.", "motivation": "To understand practitioners' perspectives on code readability with the rise of LLMs and assess the readability of LLM-generated code.", "method": "Conducted a survey and compared readability of LLM-generated code (HULA framework) with human-written code in real-world scenarios.", "result": "Readability is still crucial; HULA's LLM-generated code is comparable to human-written code in readability.", "conclusion": "Readability remains vital, and LLM-generated code can match human standards, supporting trust and adoption of LLM-powered development tools."}}
{"id": "2403.12474", "pdf": "https://arxiv.org/pdf/2403.12474", "abs": "https://arxiv.org/abs/2403.12474", "authors": ["Cheng Yang", "Jixi Liu", "Yunhe Yan", "Chuan Shi"], "title": "FairSIN: Achieving Fairness in Graph Neural Networks through Sensitive Information Neutralization", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "Despite the remarkable success of graph neural networks (GNNs) in modeling\ngraph-structured data, like other machine learning models, GNNs are also\nsusceptible to making biased predictions based on sensitive attributes, such as\nrace and gender. For fairness consideration, recent state-of-the-art (SOTA)\nmethods propose to filter out sensitive information from inputs or\nrepresentations, e.g., edge dropping or feature masking. However, we argue that\nsuch filtering-based strategies may also filter out some non-sensitive feature\ninformation, leading to a sub-optimal trade-off between predictive performance\nand fairness. To address this issue, we unveil an innovative\nneutralization-based paradigm, where additional Fairness-facilitating Features\n(F3) are incorporated into node features or representations before message\npassing. The F3 are expected to statistically neutralize the sensitive bias in\nnode representations and provide additional nonsensitive information. We also\nprovide theoretical explanations for our rationale, concluding that F3 can be\nrealized by emphasizing the features of each node's heterogeneous neighbors\n(neighbors with different sensitive attributes). We name our method as FairSIN,\nand present three implementation variants from both data-centric and\nmodel-centric perspectives. Experimental results on five benchmark datasets\nwith three different GNN backbones show that FairSIN significantly improves\nfairness metrics while maintaining high prediction accuracies.", "AI": {"tldr": "FairSIN introduces a neutralization-based paradigm to improve fairness in GNNs by adding Fairness-facilitating Features (F3), avoiding the drawbacks of filtering-based methods.", "motivation": "Current filtering-based fairness methods in GNNs may remove non-sensitive information, harming predictive performance. FairSIN aims to balance fairness and accuracy.", "method": "FairSIN incorporates F3 into node features or representations before message passing, emphasizing heterogeneous neighbors' features to neutralize bias.", "result": "Experiments on five datasets with three GNN backbones show FairSIN improves fairness metrics without sacrificing accuracy.", "conclusion": "FairSIN offers a better trade-off between fairness and performance compared to filtering-based methods, validated by theoretical and empirical results."}}
{"id": "2504.16114", "pdf": "https://arxiv.org/pdf/2504.16114", "abs": "https://arxiv.org/abs/2504.16114", "authors": ["Johannes Ferner", "Stefan Huber", "Saverio Messineo", "Angel Pop", "Martin Uray"], "title": "Persistence-based Hough Transform for Line Detection", "categories": ["cs.CV"], "comment": "Accepted at iDSC'25, Salzburg, Austria", "summary": "The Hough transform is a popular and classical technique in computer vision\nfor the detection of lines (or more general objects). It maps a pixel into a\ndual space -- the Hough space: each pixel is mapped to the set of lines through\nthis pixel, which forms a curve in Hough space. The detection of lines then\nbecomes a voting process to find those lines that received many votes by\npixels. However, this voting is done by thresholding, which is susceptible to\nnoise and other artifacts.\n  In this work, we present an alternative voting technique to detect peaks in\nthe Hough space based on persistent homology, which very naturally addresses\nlimitations of simple thresholding. Experiments on synthetic data show that our\nmethod significantly outperforms the original method, while also demonstrating\nenhanced robustness.\n  This work seeks to inspire future research in two key directions. First, we\nhighlight the untapped potential of Topological Data Analysis techniques and\nadvocate for their broader integration into existing methods, including\nwell-established ones. Secondly, we initiate a discussion on the mathematical\nstability of the Hough transform, encouraging exploration of mathematically\ngrounded improvements to enhance its robustness.", "AI": {"tldr": "The paper proposes a persistent homology-based voting technique for the Hough transform, improving robustness and performance over traditional thresholding methods.", "motivation": "The Hough transform's susceptibility to noise and artifacts due to thresholding motivates the search for a more robust alternative.", "method": "The authors introduce a voting technique using persistent homology to detect peaks in Hough space, addressing thresholding limitations.", "result": "Experiments on synthetic data show the method outperforms the original Hough transform in robustness and performance.", "conclusion": "The work advocates for integrating Topological Data Analysis into existing methods and encourages further research on mathematically stable improvements to the Hough transform."}}
{"id": "2502.12464", "pdf": "https://arxiv.org/pdf/2502.12464", "abs": "https://arxiv.org/abs/2502.12464", "authors": ["Seanie Lee", "Dong Bok Lee", "Dominik Wagner", "Minki Kang", "Haebin Seong", "Tobias Bocklet", "Juho Lee", "Sung Ju Hwang"], "title": "SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models", "categories": ["cs.CL"], "comment": "ACL 2025 findings", "summary": "Deploying large language models (LLMs) in real-world applications requires\nrobust safety guard models to detect and block harmful user prompts. While\nlarge safety guard models achieve strong performance, their computational cost\nis substantial. To mitigate this, smaller distilled models are used, but they\noften underperform on \"hard\" examples where the larger model provides accurate\npredictions. We observe that many inputs can be reliably handled by the smaller\nmodel, while only a small fraction require the larger model's capacity.\nMotivated by this, we propose SafeRoute, a binary router that distinguishes\nhard examples from easy ones. Our method selectively applies the larger safety\nguard model to the data that the router considers hard, improving efficiency\nwhile maintaining accuracy compared to solely using the larger safety guard\nmodel. Experimental results on multiple benchmark datasets demonstrate that our\nadaptive model selection significantly enhances the trade-off between\ncomputational cost and safety performance, outperforming relevant baselines.", "AI": {"tldr": "SafeRoute is a binary router that selectively uses a larger safety guard model only for hard examples, improving efficiency while maintaining accuracy.", "motivation": "Large safety guard models are computationally expensive, and smaller distilled models underperform on hard examples. SafeRoute addresses this by routing only hard cases to the larger model.", "method": "Proposes SafeRoute, a binary router to distinguish hard examples from easy ones, applying the larger model selectively.", "result": "Experimental results show improved trade-off between computational cost and safety performance, outperforming baselines.", "conclusion": "SafeRoute effectively balances efficiency and accuracy in deploying safety guard models for LLMs."}}
{"id": "2501.18052", "pdf": "https://arxiv.org/pdf/2501.18052", "abs": "https://arxiv.org/abs/2501.18052", "authors": ["Bartosz Cywi\u0144ski", "Kamil Deja"], "title": "SAeUron: Interpretable Concept Unlearning in Diffusion Models with Sparse Autoencoders", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models, while powerful, can inadvertently generate harmful or\nundesirable content, raising significant ethical and safety concerns. Recent\nmachine unlearning approaches offer potential solutions but often lack\ntransparency, making it difficult to understand the changes they introduce to\nthe base model. In this work, we introduce SAeUron, a novel method leveraging\nfeatures learned by sparse autoencoders (SAEs) to remove unwanted concepts in\ntext-to-image diffusion models. First, we demonstrate that SAEs, trained in an\nunsupervised manner on activations from multiple denoising timesteps of the\ndiffusion model, capture sparse and interpretable features corresponding to\nspecific concepts. Building on this, we propose a feature selection method that\nenables precise interventions on model activations to block targeted content\nwhile preserving overall performance. Our evaluation shows that SAeUron\noutperforms existing approaches on the UnlearnCanvas benchmark for concepts and\nstyle unlearning, and effectively eliminates nudity when evaluated with I2P.\nMoreover, we show that with a single SAE, we can remove multiple concepts\nsimultaneously and that in contrast to other methods, SAeUron mitigates the\npossibility of generating unwanted content under adversarial attack. Code and\ncheckpoints are available at https://github.com/cywinski/SAeUron.", "AI": {"tldr": "SAeUron uses sparse autoencoders (SAEs) to remove unwanted concepts in text-to-image diffusion models, outperforming existing methods in unlearning tasks and blocking harmful content.", "motivation": "Diffusion models can generate harmful content, and current unlearning methods lack transparency. SAeUron aims to address this by leveraging interpretable SAE features.", "method": "SAEs are trained on diffusion model activations to capture sparse, interpretable features. A feature selection method enables precise interventions to block unwanted content.", "result": "SAeUron outperforms existing methods on UnlearnCanvas and effectively removes nudity (I2P). It can unlearn multiple concepts simultaneously and resists adversarial attacks.", "conclusion": "SAeUron provides a transparent and effective solution for unlearning unwanted concepts in diffusion models, with potential for broader applications."}}
{"id": "2407.09571", "pdf": "https://arxiv.org/pdf/2407.09571", "abs": "https://arxiv.org/abs/2407.09571", "authors": ["Emanuele Carlini", "Domenico Di Gangi", "Vinicius Monteiro de Lira", "Hanna Kavalionak", "Amilcar Soares", "Gabriel Spadon"], "title": "ImPORTance: Machine Learning-Driven Analysis of Global Port Significance and Network Dynamics for Improved Operational Efficiency", "categories": ["cs.LG"], "comment": null, "summary": "Seaports play a crucial role in the global economy, and researchers have\nsought to understand their significance through various studies. In this paper,\nwe aim to explore the common characteristics shared by important ports by\nanalyzing the network of connections formed by vessel movement among them. To\naccomplish this task, we adopt a bottom-up network construction approach that\ncombines three years' worth of AIS (Automatic Identification System) data from\naround the world, constructing a Ports Network that represents the connections\nbetween different ports. Through this representation, we utilize machine\nlearning to assess the relative significance of various port features. Our\nmodel examined such features and revealed that geographical characteristics and\nthe port's depth are indicators of a port's importance to the Ports Network.\nAccordingly, this study employs a data-driven approach and utilizes machine\nlearning to provide a comprehensive understanding of the factors contributing\nto the extent of ports. Our work aims to inform decision-making processes\nrelated to port development, resource allocation, and infrastructure planning\nwithin the industry.", "AI": {"tldr": "The paper analyzes global seaport importance using AIS data and machine learning, identifying geography and depth as key factors.", "motivation": "To understand common characteristics of important ports and inform industry decision-making.", "method": "Bottom-up network construction using three years of AIS data, combined with machine learning to assess port features.", "result": "Geographical characteristics and port depth are key indicators of a port's importance.", "conclusion": "The study provides data-driven insights for port development and infrastructure planning."}}
{"id": "2505.02567", "pdf": "https://arxiv.org/pdf/2505.02567", "abs": "https://arxiv.org/abs/2505.02567", "authors": ["Xinjie Zhang", "Jintao Guo", "Shanshan Zhao", "Minghao Fu", "Lunhao Duan", "Guo-Hua Wang", "Qing-Guo Chen", "Zhao Xu", "Weihua Luo", "Kaifu Zhang"], "title": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "categories": ["cs.CV"], "comment": "In this version, we incorporate new papers. This work is still in\n  progress; Github project:\n  https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models", "summary": "Recent years have seen remarkable progress in both multimodal understanding\nmodels and image generation models. Despite their respective successes, these\ntwo domains have evolved independently, leading to distinct architectural\nparadigms: While autoregressive-based architectures have dominated multimodal\nunderstanding, diffusion-based models have become the cornerstone of image\ngeneration. Recently, there has been growing interest in developing unified\nframeworks that integrate these tasks. The emergence of GPT-4o's new\ncapabilities exemplifies this trend, highlighting the potential for\nunification. However, the architectural differences between the two domains\npose significant challenges. To provide a clear overview of current efforts\ntoward unification, we present a comprehensive survey aimed at guiding future\nresearch. First, we introduce the foundational concepts and recent advancements\nin multimodal understanding and text-to-image generation models. Next, we\nreview existing unified models, categorizing them into three main architectural\nparadigms: diffusion-based, autoregressive-based, and hybrid approaches that\nfuse autoregressive and diffusion mechanisms. For each category, we analyze the\nstructural designs and innovations introduced by related works. Additionally,\nwe compile datasets and benchmarks tailored for unified models, offering\nresources for future exploration. Finally, we discuss the key challenges facing\nthis nascent field, including tokenization strategy, cross-modal attention, and\ndata. As this area is still in its early stages, we anticipate rapid\nadvancements and will regularly update this survey. Our goal is to inspire\nfurther research and provide a valuable reference for the community. The\nreferences associated with this survey are available on GitHub\n(https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models).", "AI": {"tldr": "A survey on unifying multimodal understanding and image generation models, covering foundational concepts, architectural paradigms, datasets, and challenges.", "motivation": "To address the gap between multimodal understanding and image generation models by exploring unified frameworks, inspired by trends like GPT-4o.", "method": "Review and categorize existing unified models into diffusion-based, autoregressive-based, and hybrid approaches, analyzing their designs and innovations.", "result": "Compiled datasets and benchmarks for unified models, identified key challenges (tokenization, cross-modal attention, data), and provided a GitHub resource.", "conclusion": "The survey aims to guide future research, inspire advancements, and serve as a reference for the community in this emerging field."}}
{"id": "2502.13028", "pdf": "https://arxiv.org/pdf/2502.13028", "abs": "https://arxiv.org/abs/2502.13028", "authors": ["Nischal Ashok Kumar", "Chau Minh Pham", "Mohit Iyyer", "Andrew Lan"], "title": "Whose story is it? Personalizing story generation by inferring author styles", "categories": ["cs.CL"], "comment": "preprint:55 pages", "summary": "Personalization is critical for improving user experience in interactive\nwriting and educational applications, yet remains understudied in story\ngeneration. We study the task of personalizing story generation, where our goal\nis to mimic an author's writing style, given other stories written by them. We\ncollect Mythos, a dataset of 3.6k stories from 112 authors, with an average of\n16 stories per author, across five distinct sources reflecting diverse\nstory-writing settings. We propose a two-stage pipeline for personalized story\ngeneration: first, we infer authors' implicit writing characteristics and\norganize them into an Author Writing Sheet, which is validated by humans to be\nof high quality; second, we simulate the author's persona using tailored\npersona descriptions and personalized story rules. We find that stories\npersonalized using the Author Writing Sheet outperform a non-personalized\nbaseline, achieving a 78% win-rate in capturing authors' past style and 59% in\nsimilarity to ground-truth author stories. Human evaluation supports these\nfindings and further highlights trends, such as Reddit stories being easier to\npersonalize, and the Creativity and Language Use aspects of stories being\neasier to personalize than the Plot.", "AI": {"tldr": "The paper introduces a method for personalized story generation by mimicking authors' writing styles using a two-stage pipeline, validated by human evaluation.", "motivation": "Personalization is understudied in story generation but crucial for enhancing user experience in writing and educational applications.", "method": "A two-stage pipeline: (1) infer authors' writing characteristics into an Author Writing Sheet, and (2) simulate the author's persona using tailored descriptions and rules.", "result": "Personalized stories outperformed non-personalized baselines, with 78% win-rate in capturing style and 59% similarity to ground-truth stories. Human evaluation confirmed trends like Reddit stories being easier to personalize.", "conclusion": "The proposed method effectively personalizes story generation, with human validation supporting its success in capturing authors' styles."}}
{"id": "2502.01218", "pdf": "https://arxiv.org/pdf/2502.01218", "abs": "https://arxiv.org/abs/2502.01218", "authors": ["Zhizhen Zhang", "Lei Zhu", "Zhen Fang", "Zi Huang", "Yadan Luo"], "title": "Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Pre-training vision-language representations on human action videos has\nemerged as a promising approach to reduce reliance on large-scale expert\ndemonstrations for training embodied agents. However, prior methods often\nemploy time contrastive learning based on goal-reaching heuristics,\nprogressively aligning language instructions from the initial to the final\nframe. This overemphasis on future frames can result in erroneous\nvision-language associations, as actions may terminate early or include\nirrelevant moments in the end. To address this issue, we propose Action\nTemporal Coherence Learning (AcTOL) to learn ordered and continuous\nvision-language representations without rigid goal-based constraint. AcTOL\ntreats a video as a continuous trajectory where it (1) contrasts semantic\ndifferences between frames to reflect their natural ordering, and (2) imposes a\nlocal Brownian bridge constraint to ensure smooth transitions across\nintermediate frames. Extensive imitation learning experiments on both simulated\nand real robots show that the pretrained features significantly enhance\ndownstream manipulation tasks with high robustness to different linguistic\nstyles of instructions, offering a viable pathway toward generalized embodied\nagents.", "AI": {"tldr": "AcTOL improves vision-language representation learning by focusing on temporal coherence and smooth transitions, avoiding rigid goal-based constraints.", "motivation": "Prior methods overemphasize future frames, leading to erroneous vision-language associations. AcTOL addresses this by treating videos as continuous trajectories.", "method": "AcTOL contrasts semantic differences between frames for natural ordering and applies a local Brownian bridge constraint for smooth transitions.", "result": "Pretrained features enhance downstream manipulation tasks, showing robustness to varied linguistic instructions.", "conclusion": "AcTOL offers a viable pathway for generalized embodied agents by improving vision-language alignment."}}
{"id": "2409.06282", "pdf": "https://arxiv.org/pdf/2409.06282", "abs": "https://arxiv.org/abs/2409.06282", "authors": ["Haochen Yuan", "Yutong Wang", "Yihong Chen", "Yunbo Wang", "Xiaokang Yang"], "title": "ReAugment: Model Zoo-Guided RL for Few-Shot Time Series Augmentation and Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting, particularly in few-shot learning scenarios, is\nchallenging due to the limited availability of high-quality training data. To\naddress this, we present a pilot study on using reinforcement learning (RL) for\ntime series data augmentation. Our method, ReAugment, tackles three critical\nquestions: which parts of the training set should be augmented, how the\naugmentation should be performed, and what advantages RL brings to the process.\nSpecifically, our approach maintains a forecasting model zoo, and by measuring\nprediction diversity across the models, we identify samples with higher\nprobabilities for overfitting and use them as the anchor points for\naugmentation. Leveraging RL, our method adaptively transforms the overfit-prone\nsamples into new data that not only enhances training set diversity but also\ndirects the augmented data to target regions where the forecasting models are\nprone to overfitting. We validate the effectiveness of ReAugment across a wide\nrange of base models, showing its advantages in both standard time series\nforecasting and few-shot learning tasks.", "AI": {"tldr": "ReAugment uses RL for time series data augmentation to address few-shot learning challenges by targeting overfit-prone samples and enhancing dataset diversity.", "motivation": "Few-shot learning in time series forecasting is difficult due to limited high-quality training data.", "method": "ReAugment identifies overfit-prone samples via a forecasting model zoo and uses RL to adaptively augment these samples, improving diversity and targeting weak model regions.", "result": "ReAugment improves performance in standard and few-shot time series forecasting tasks across various base models.", "conclusion": "RL-based data augmentation (ReAugment) effectively enhances forecasting models by addressing overfitting and data scarcity."}}
{"id": "2505.03176", "pdf": "https://arxiv.org/pdf/2505.03176", "abs": "https://arxiv.org/abs/2505.03176", "authors": ["Hafez Ghaemi", "Eilif Muller", "Shahab Bakhtiari"], "title": "seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Current self-supervised algorithms commonly rely on transformations such as\ndata augmentation and masking to learn visual representations. This is achieved\nby enforcing invariance or equivariance with respect to these transformations\nafter encoding two views of an image. This dominant two-view paradigm often\nlimits the flexibility of learned representations for downstream adaptation by\ncreating performance trade-offs between high-level invariance-demanding tasks\nsuch as image classification and more fine-grained equivariance-related tasks.\nIn this work, we proposes \\emph{seq-JEPA}, a world modeling framework that\nintroduces architectural inductive biases into joint-embedding predictive\narchitectures to resolve this trade-off. Without relying on dual equivariance\npredictors or loss terms, seq-JEPA simultaneously learns two architecturally\nsegregated representations: one equivariant to specified transformations and\nanother invariant to them. To do so, our model processes short sequences of\ndifferent views (observations) of inputs. Each encoded view is concatenated\nwith an embedding of the relative transformation (action) that produces the\nnext observation in the sequence. These view-action pairs are passed through a\ntransformer encoder that outputs an aggregate representation. A predictor head\nthen conditions this aggregate representation on the upcoming action to predict\nthe representation of the next observation. Empirically, seq-JEPA demonstrates\nstrong performance on both equivariant and invariant benchmarks without\nsacrificing one for the other. Furthermore, it excels at tasks that inherently\nrequire aggregating a sequence of observations, such as path integration across\nactions and predictive learning across eye movements.", "AI": {"tldr": "seq-JEPA introduces a world modeling framework to resolve trade-offs between invariant and equivariant representations by processing sequences of views and actions, achieving strong performance on both tasks.", "motivation": "Current self-supervised methods limit flexibility by enforcing invariance or equivariance separately, creating trade-offs for downstream tasks.", "method": "seq-JEPA processes sequences of views and actions using a transformer encoder and predictor head to learn segregated invariant and equivariant representations.", "result": "seq-JEPA performs well on both invariant and equivariant benchmarks and excels at tasks requiring sequential observation aggregation.", "conclusion": "seq-JEPA effectively resolves the trade-off between invariant and equivariant representations, offering improved flexibility for diverse tasks."}}
{"id": "2502.13487", "pdf": "https://arxiv.org/pdf/2502.13487", "abs": "https://arxiv.org/abs/2502.13487", "authors": ["Chen-An Li", "Tzu-Han Lin", "Yun-Nung Chen", "Hung-yi Lee"], "title": "Transferring Textual Preferences to Vision-Language Understanding through Model Merging", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted to ACL 2025 main", "summary": "Large vision-language models (LVLMs) perform outstandingly across various\nmultimodal tasks. However, their ability to evaluate generated content remains\nlimited, and training vision-language reward models (VLRMs) with preference\ndata is computationally expensive. This paper explores a training-free\nalternative by merging text-based reward models (RMs) with LVLMs to create\nVLRMs. Our approach shows that integrating these models leads to improved\nperformance over LVLMs' scoring and text-based RMs, offering an efficient\nmethod for incorporating textual preferences into LVLMs.", "AI": {"tldr": "A training-free method merges text-based reward models with large vision-language models to improve content evaluation without costly training.", "motivation": "Address the limitations of LVLMs in evaluating generated content and the high computational cost of training vision-language reward models.", "method": "Integrate text-based reward models with LVLMs to create vision-language reward models without additional training.", "result": "Improved performance over LVLMs' scoring and text-based reward models.", "conclusion": "The approach offers an efficient way to incorporate textual preferences into LVLMs."}}
{"id": "2502.01316", "pdf": "https://arxiv.org/pdf/2502.01316", "abs": "https://arxiv.org/abs/2502.01316", "authors": ["Zeyu Wang", "Yao-Hui Li", "Xin Li", "Hongyu Zang", "Romain Laroche", "Riashat Islam"], "title": "Learning Fused State Representations for Control from Multi-View Observations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-View Reinforcement Learning (MVRL) seeks to provide agents with\nmulti-view observations, enabling them to perceive environment with greater\neffectiveness and precision. Recent advancements in MVRL focus on extracting\nlatent representations from multiview observations and leveraging them in\ncontrol tasks. However, it is not straightforward to learn compact and\ntask-relevant representations, particularly in the presence of redundancy,\ndistracting information, or missing views. In this paper, we propose Multi-view\nFusion State for Control (MFSC), firstly incorporating bisimulation metric\nlearning into MVRL to learn task-relevant representations. Furthermore, we\npropose a multiview-based mask and latent reconstruction auxiliary task that\nexploits shared information across views and improves MFSC's robustness in\nmissing views by introducing a mask token. Extensive experimental results\ndemonstrate that our method outperforms existing approaches in MVRL tasks. Even\nin more realistic scenarios with interference or missing views, MFSC\nconsistently maintains high performance.", "AI": {"tldr": "MFSC integrates bisimulation metric learning into MVRL for task-relevant representations and uses a mask token for robustness in missing views, outperforming existing methods.", "motivation": "MVRL struggles with learning compact, task-relevant representations due to redundancy, distractions, or missing views.", "method": "Proposes MFSC with bisimulation metric learning and a mask token for latent reconstruction.", "result": "MFSC outperforms existing MVRL methods, especially in scenarios with interference or missing views.", "conclusion": "MFSC effectively enhances MVRL by improving representation learning and robustness."}}
{"id": "2410.01106", "pdf": "https://arxiv.org/pdf/2410.01106", "abs": "https://arxiv.org/abs/2410.01106", "authors": ["Hayden Helm", "Aranyak Acharyya", "Brandon Duderstadt", "Youngser Park", "Carey E. Priebe"], "title": "Statistical inference on black-box generative models in the data kernel perspective space", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Generative models are capable of producing human-expert level content across\na variety of topics and domains. As the impact of generative models grows, it\nis necessary to develop statistical methods to understand collections of\navailable models. These methods are particularly important in settings where\nthe user may not have access to information related to a model's pre-training\ndata, weights, or other relevant model-level covariates. In this paper we\nextend recent results on representations of black-box generative models to\nmodel-level statistical inference tasks. We demonstrate that the model-level\nrepresentations are effective for multiple inference tasks.", "AI": {"tldr": "The paper extends black-box generative model representations for model-level statistical inference, proving their effectiveness.", "motivation": "As generative models impact grows, understanding collections of models without access to pre-training data or weights becomes crucial.", "method": "Extends recent results on black-box generative model representations for inference tasks.", "result": "Model-level representations are effective for multiple inference tasks.", "conclusion": "The approach enables statistical inference on generative models without detailed model-level information."}}
{"id": "2505.05626", "pdf": "https://arxiv.org/pdf/2505.05626", "abs": "https://arxiv.org/abs/2505.05626", "authors": ["Aarti Ghatkesar", "Uddeshya Upadhyay", "Ganesh Venkatesh"], "title": "Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Achieving deep alignment between vision and language remains a central\nchallenge for Multimodal Large Language Models (MLLMs). These models often fail\nto fully leverage visual input, defaulting to strong language priors. Our\napproach first provides insights into how MLLMs internally build visual\nunderstanding of image regions and then introduces techniques to amplify this\ncapability. Specifically, we explore techniques designed both to deepen the\nmodel's understanding of visual content and to ensure that these visual\ninsights actively guide language generation. We demonstrate the superior\nmultimodal understanding of our resultant model through a detailed upstream\nanalysis quantifying its ability to predict visually-dependent tokens as well\nas 10 pt boost on visually challenging tasks.", "AI": {"tldr": "The paper addresses the challenge of deep alignment between vision and language in MLLMs, proposing techniques to enhance visual understanding and its influence on language generation, resulting in improved performance.", "motivation": "MLLMs often underutilize visual input, relying too heavily on language priors, which limits their multimodal capabilities.", "method": "The approach involves analyzing how MLLMs build visual understanding and introducing techniques to deepen this understanding and ensure it guides language generation.", "result": "The model shows superior multimodal understanding, with improved prediction of visually-dependent tokens and a 10-point boost on visually challenging tasks.", "conclusion": "The proposed techniques effectively enhance MLLMs' visual understanding and alignment with language, leading to better performance in multimodal tasks."}}
{"id": "2502.15132", "pdf": "https://arxiv.org/pdf/2502.15132", "abs": "https://arxiv.org/abs/2502.15132", "authors": ["Vignesh Kothapalli", "Hamed Firooz", "Maziar Sanjabi"], "title": "CoT-ICL Lab: A Synthetic Framework for Studying Chain-of-Thought Learning from In-Context Demonstrations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL Main 2025", "summary": "We introduce CoT-ICL Lab, a framework and methodology to generate synthetic\ntokenized datasets and systematically study chain-of-thought (CoT) in-context\nlearning (ICL) in language models. CoT-ICL Lab allows fine grained control over\nthe complexity of in-context examples by decoupling (1) the causal structure\ninvolved in chain token generation from (2) the underlying token processing\nfunctions. We train decoder-only transformers (up to 700M parameters) on these\ndatasets and show that CoT accelerates the accuracy transition to higher values\nacross model sizes. In particular, we find that model depth is crucial for\nleveraging CoT with limited in-context examples, while more examples help\nshallow models match deeper model performance. Additionally, limiting the\ndiversity of token processing functions throughout training improves causal\nstructure learning via ICL. We also interpret these transitions by analyzing\ntransformer embeddings and attention maps. Overall, CoT-ICL Lab serves as a\nsimple yet powerful testbed for theoretical and empirical insights into ICL and\nCoT in language models.", "AI": {"tldr": "CoT-ICL Lab is a framework for generating synthetic datasets to study chain-of-thought (CoT) in-context learning (ICL) in language models, showing CoT improves accuracy, especially with model depth and controlled token diversity.", "motivation": "To systematically study CoT in ICL by decoupling causal structure from token processing, enabling fine-grained control over dataset complexity.", "method": "Generate synthetic tokenized datasets, train decoder-only transformers (up to 700M parameters), and analyze embeddings and attention maps.", "result": "CoT accelerates accuracy transitions; model depth is key for limited examples, while shallow models benefit from more examples. Limited token diversity improves causal learning.", "conclusion": "CoT-ICL Lab is a powerful testbed for theoretical and empirical insights into ICL and CoT in language models."}}
{"id": "2502.06776", "pdf": "https://arxiv.org/pdf/2502.06776", "abs": "https://arxiv.org/abs/2502.06776", "authors": ["Brandon Trabucco", "Gunnar Sigurdsson", "Robinson Piramuthu", "Ruslan Salakhutdinov"], "title": "InSTA: Towards Internet-Scale Training For Agents", "categories": ["cs.LG", "cs.AI"], "comment": "Improved results, zero-shot transfer to Web Voyager", "summary": "The predominant approach for training web navigation agents is to gather\nhuman demonstrations for a set of popular websites and hand-written tasks, but\nit is becoming clear that human data is an inefficient resource. We develop a\npipeline to facilitate internet-scale training for agents without laborious\nhuman annotations. In the first stage, an LLM annotates 150k sites with agentic\ntasks. In the next stage, LLM agents complete tasks and produce trajectories.\nIn the final stage, an LLM filters trajectories by judging their success.\nLanguage models are powerful data curation tools, identifying harmful content\nwith an accuracy of 97%, judging successful trajectories with an accuracy of\n82.6%, and producing effective data. We train agents based on Qwen 3 1.7B that\nare competitive with frontier LLMs as web agents, while being smaller and\nfaster. Our top agent reaches a success rate of 56.9%, outperforming the data\ncollection policy Qwen 3 235B, a 235 times larger Llama 4 Maverick, and\nreaching 94.7% of the performance of Gemini 2.5 Flash. We are releasing code,\nmodels and data at: https://data-for-agents.github.io.", "AI": {"tldr": "A pipeline for training web navigation agents without human annotations uses LLMs to annotate tasks, complete trajectories, and filter data, achieving competitive performance with smaller models.", "motivation": "Human demonstrations for training web agents are inefficient; this work aims to enable internet-scale training without laborious human annotations.", "method": "A three-stage pipeline: (1) LLM annotates tasks, (2) LLM agents complete tasks, (3) LLM filters trajectories. Uses Qwen 3 1.7B for training.", "result": "Agents achieve 56.9% success rate, outperforming larger models like Qwen 3 235B and Llama 4 Maverick, and reaching 94.7% of Gemini 2.5 Flash's performance.", "conclusion": "LLMs are effective for data curation and training competitive web agents, reducing reliance on human data."}}
{"id": "2410.03450", "pdf": "https://arxiv.org/pdf/2410.03450", "abs": "https://arxiv.org/abs/2410.03450", "authors": ["Junpeng Yue", "Xinrun Xu", "B\u00f6rje F. Karlsson", "Zongqing Lu"], "title": "MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents", "categories": ["cs.LG"], "comment": "ICLR 2025", "summary": "MLLM agents demonstrate potential for complex embodied tasks by retrieving\nmultimodal task-relevant trajectory data. However, current retrieval methods\nprimarily focus on surface-level similarities of textual or visual cues in\ntrajectories, neglecting their effectiveness for the specific task at hand. To\naddress this issue, we propose a novel method, MLLM As ReTriever (MART), which\nenhances the performance of embodied agents by utilizing interaction data to\nfine-tune an MLLM retriever based on preference learning, such that the\nretriever fully considers the effectiveness of trajectories and prioritizes\nthem for unseen tasks. We also introduce Trajectory Abstraction, a mechanism\nthat leverages MLLMs' summarization capabilities to represent trajectories with\nfewer tokens while preserving key information, enabling agents to better\ncomprehend milestones in the trajectory. Experimental results across various\nenvironments demonstrate our method significantly improves task success rates\nin unseen scenes compared to baseline methods. This work presents a new\nparadigm for multimodal retrieval in embodied agents, by fine-tuning a\ngeneral-purpose MLLM as the retriever to assess trajectory effectiveness. All\nthe code for benchmark tasks, simulator modifications, and the MLLM retriever\nis available at https://github.com/PKU-RL/MART.", "AI": {"tldr": "MART improves embodied agents by fine-tuning an MLLM retriever using preference learning and trajectory abstraction, enhancing task success in unseen scenes.", "motivation": "Current retrieval methods for MLLM agents focus on surface-level similarities, ignoring trajectory effectiveness for specific tasks.", "method": "Proposes MART, which fine-tunes an MLLM retriever via preference learning and introduces Trajectory Abstraction for concise trajectory representation.", "result": "Significantly improves task success rates in unseen environments compared to baselines.", "conclusion": "MART offers a new paradigm for multimodal retrieval in embodied agents by prioritizing trajectory effectiveness."}}
{"id": "2505.07344", "pdf": "https://arxiv.org/pdf/2505.07344", "abs": "https://arxiv.org/abs/2505.07344", "authors": ["Yuan Zhang", "Jiacheng Jiang", "Guoqing Ma", "Zhiying Lu", "Haoyang Huang", "Jianlong Yuan", "Nan Duan"], "title": "Generative Pre-trained Autoregressive Diffusion Transformer", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this work, we present GPDiT, a Generative Pre-trained Autoregressive\nDiffusion Transformer that unifies the strengths of diffusion and\nautoregressive modeling for long-range video synthesis, within a continuous\nlatent space. Instead of predicting discrete tokens, GPDiT autoregressively\npredicts future latent frames using a diffusion loss, enabling natural modeling\nof motion dynamics and semantic consistency across frames. This continuous\nautoregressive framework not only enhances generation quality but also endows\nthe model with representation capabilities. Additionally, we introduce a\nlightweight causal attention variant and a parameter-free rotation-based\ntime-conditioning mechanism, improving both the training and inference\nefficiency. Extensive experiments demonstrate that GPDiT achieves strong\nperformance in video generation quality, video representation ability, and\nfew-shot learning tasks, highlighting its potential as an effective framework\nfor video modeling in continuous space.", "AI": {"tldr": "GPDiT combines diffusion and autoregressive modeling for high-quality long-range video synthesis in continuous latent space, improving motion dynamics and semantic consistency.", "motivation": "To unify diffusion and autoregressive modeling for better video synthesis, addressing motion dynamics and semantic consistency in a continuous latent space.", "method": "GPDiT autoregressively predicts future latent frames using a diffusion loss, with a lightweight causal attention variant and rotation-based time-conditioning.", "result": "GPDiT excels in video generation quality, representation ability, and few-shot learning, outperforming existing methods.", "conclusion": "GPDiT is a promising framework for continuous-space video modeling, offering enhanced generation and representation capabilities."}}
{"id": "2502.16002", "pdf": "https://arxiv.org/pdf/2502.16002", "abs": "https://arxiv.org/abs/2502.16002", "authors": ["Jingbo Yang", "Bairu Hou", "Wei Wei", "Yujia Bao", "Shiyu Chang"], "title": "KVLink: Accelerating Large Language Models via Efficient KV Cache Reuse", "categories": ["cs.CL"], "comment": null, "summary": "We describe KVLink, an approach for efficient key-value (KV) cache reuse in\nlarge language models (LLMs). In many LLM applications, different inputs can\nshare overlapping context, such as the same retrieved document appearing in\nmultiple queries. However, the LLMs still need to encode the entire context for\neach query, leading to redundant computation. In this paper, we investigate a\nnew strategy to eliminate such inefficiency, where the KV cache of each\ndocument is precomputed independently. During inference, the KV caches of\nretrieved documents are concatenated, allowing the model to reuse cached\nrepresentations instead of recomputing them. To mitigate the performance\ndegradation when using KV caches computed independently for each document,\nKVLink introduces two key techniques: adjusting positional embeddings of the KV\ncache at inference to match the global position after concatenation, and using\ntrainable special tokens to restore self-attention across independently encoded\ndocuments. Experiments across 7 datasets demonstrate that KVLink improves\nquestion answering accuracy by an average of 4% over state-of-the-art methods.\nFurthermore, by leveraging precomputed KV caches, our approach reduces\ntime-to-first-token by up to 96% compared to standard LLM inference, making it\na scalable and efficient solution for context reuse. Additionally, KVLink can\nbe combined with KV cache compression to further save cache loading and storage\noverhead while outperforming the baselines.", "AI": {"tldr": "KVLink enables efficient KV cache reuse in LLMs by precomputing and concatenating caches for overlapping contexts, improving accuracy and reducing inference time.", "motivation": "Redundant computation in LLMs due to overlapping contexts in queries motivates the need for efficient KV cache reuse.", "method": "KVLink precomputes KV caches for documents independently, concatenates them during inference, and uses adjusted positional embeddings and trainable tokens to maintain performance.", "result": "KVLink improves QA accuracy by 4% on average and reduces time-to-first-token by up to 96%.", "conclusion": "KVLink is a scalable, efficient solution for context reuse in LLMs, compatible with cache compression for further overhead reduction."}}
{"id": "2502.06846", "pdf": "https://arxiv.org/pdf/2502.06846", "abs": "https://arxiv.org/abs/2502.06846", "authors": ["Zhicong Wang", "Zicheng Ma", "Ziqiang Cao", "Changlong Zhou", "Jun Zhang", "Yiqin Gao"], "title": "Prot2Chat: Protein LLM with Early-Fusion of Text, Sequence and Structure", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": "8 pages, 3 figures", "summary": "Motivation: Proteins are of great significance in living organisms. However,\nunderstanding their functions encounters numerous challenges, such as\ninsufficient integration of multimodal information, a large number of training\nparameters, limited flexibility of classification-based methods, and the lack\nof systematic evaluation metrics for protein Q&A systems. To tackle these\nissues, we propose the Prot2Chat framework. Results: We modified ProteinMPNN to\nencode protein sequence and structural information in a unified way. We used a\nlarge language model (LLM) to encode questions into vectors and developed a\nprotein-text adapter to compress protein information into virtual tokens based\non these vectors, achieving the early fusion of text and protein information.\nFinally, the same LLM reads the virtual tokens and the questions to generate\nanswers. To optimize training efficiency, we froze the encoder and employed\nLow-Rank Adaptation (LoRA) techniques for the LLM. Experiments on two datasets\nshow that both automated metrics and expert evaluations demonstrate the\nsuperior performance of our model, and zero-shot prediction results highlight\nits generalization ability. The models and codes are available at\nhttps://github.com/ wangzc1233/Prot2Chat. Contact: zqcao@suda.edu.cn or\nwangzc025@163.com Key words: Protein Q&A, Early-Fusion, LLM", "AI": {"tldr": "Prot2Chat framework integrates protein and text data for Q&A, using ProteinMPNN and LLM with LoRA for efficiency, showing superior performance and generalization.", "motivation": "Challenges in protein function understanding include multimodal integration, training parameters, flexibility, and evaluation metrics. Prot2Chat addresses these.", "method": "Modified ProteinMPNN for unified encoding, LLM for question vectors, protein-text adapter for early fusion, LoRA for efficiency.", "result": "Outperforms on datasets, excels in zero-shot prediction, and demonstrates strong generalization.", "conclusion": "Prot2Chat effectively integrates protein and text data, offering a robust solution for protein Q&A with high performance."}}
{"id": "2410.03626", "pdf": "https://arxiv.org/pdf/2410.03626", "abs": "https://arxiv.org/abs/2410.03626", "authors": ["Udita Ghosh", "Dripta S. Raychaudhuri", "Jiachen Li", "Konstantinos Karydis", "Amit K. Roy-Chowdhury"], "title": "Robust Offline Imitation Learning from Diverse Auxiliary Data", "categories": ["cs.LG"], "comment": "Accepted at TMLR", "summary": "Offline imitation learning enables learning a policy solely from a set of\nexpert demonstrations, without any environment interaction. To alleviate the\nissue of distribution shift arising due to the small amount of expert data,\nrecent works incorporate large numbers of auxiliary demonstrations alongside\nthe expert data. However, the performance of these approaches rely on\nassumptions about the quality and composition of the auxiliary data, and they\nare rarely successful when those assumptions do not hold. To address this\nlimitation, we propose Robust Offline Imitation from Diverse Auxiliary Data\n(ROIDA). ROIDA first identifies high-quality transitions from the entire\nauxiliary dataset using a learned reward function. These high-reward samples\nare combined with the expert demonstrations for weighted behavioral cloning.\nFor lower-quality samples, ROIDA applies temporal difference learning to steer\nthe policy towards high-reward states, improving long-term returns. This\ntwo-pronged approach enables our framework to effectively leverage both high\nand low-quality data without any assumptions. Extensive experiments validate\nthat ROIDA achieves robust and consistent performance across multiple auxiliary\ndatasets with diverse ratios of expert and non-expert demonstrations. ROIDA\neffectively leverages unlabeled auxiliary data, outperforming prior methods\nreliant on specific data assumptions. Our code is available at\nhttps://github.com/uditaghosh/roida.", "AI": {"tldr": "ROIDA improves offline imitation learning by leveraging diverse auxiliary data without quality assumptions, using high-reward samples for weighted behavioral cloning and TD learning for lower-quality data.", "motivation": "Address limitations of prior methods that rely on assumptions about auxiliary data quality and composition, which often fail when assumptions don't hold.", "method": "ROIDA identifies high-quality transitions via a learned reward function for weighted behavioral cloning and applies TD learning for lower-quality samples to improve long-term returns.", "result": "ROIDA achieves robust performance across diverse auxiliary datasets, outperforming methods dependent on specific data assumptions.", "conclusion": "ROIDA effectively leverages both high and low-quality auxiliary data without assumptions, demonstrating consistent performance."}}
{"id": "2505.10049", "pdf": "https://arxiv.org/pdf/2505.10049", "abs": "https://arxiv.org/abs/2505.10049", "authors": ["Jinlong Fan", "Xuepu Zeng", "Jing Zhang", "Mingming Gong", "Yuxiang Yang", "Dacheng Tao"], "title": "Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field", "categories": ["cs.CV"], "comment": null, "summary": "Dynamic scene representation and reconstruction have undergone transformative\nadvances in recent years, catalyzed by breakthroughs in neural radiance fields\nand 3D Gaussian splatting techniques. While initially developed for static\nenvironments, these methodologies have rapidly evolved to address the\ncomplexities inherent in 4D dynamic scenes through an expansive body of\nresearch. Coupled with innovations in differentiable volumetric rendering,\nthese approaches have significantly enhanced the quality of motion\nrepresentation and dynamic scene reconstruction, thereby garnering substantial\nattention from the computer vision and graphics communities. This survey\npresents a systematic analysis of over 200 papers focused on dynamic scene\nrepresentation using radiance field, spanning the spectrum from implicit neural\nrepresentations to explicit Gaussian primitives. We categorize and evaluate\nthese works through multiple critical lenses: motion representation paradigms,\nreconstruction techniques for varied scene dynamics, auxiliary information\nintegration strategies, and regularization approaches that ensure temporal\nconsistency and physical plausibility. We organize diverse methodological\napproaches under a unified representational framework, concluding with a\ncritical examination of persistent challenges and promising research\ndirections. By providing this comprehensive overview, we aim to establish a\ndefinitive reference for researchers entering this rapidly evolving field while\noffering experienced practitioners a systematic understanding of both\nconceptual principles and practical frontiers in dynamic scene reconstruction.", "AI": {"tldr": "A survey of 200+ papers on dynamic scene representation using radiance fields, covering neural representations to Gaussian primitives, with focus on motion, reconstruction, and regularization.", "motivation": "To systematically analyze advancements in dynamic scene representation and reconstruction, addressing complexities in 4D scenes and providing a reference for researchers.", "method": "Categorizes and evaluates works through lenses like motion representation, reconstruction techniques, auxiliary data integration, and regularization.", "result": "Enhanced understanding of dynamic scene reconstruction, highlighting quality improvements and methodological diversity.", "conclusion": "Identifies challenges and future directions, offering a unified framework for researchers and practitioners."}}
{"id": "2502.17775", "pdf": "https://arxiv.org/pdf/2502.17775", "abs": "https://arxiv.org/abs/2502.17775", "authors": ["Tanawan Premsri", "Parisa Kordjamshidi"], "title": "FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks", "categories": ["cs.CL"], "comment": "9 pages", "summary": "Spatial reasoning is a fundamental aspect of human intelligence. One key\nconcept in spatial cognition is the Frame of Reference (FoR), which identifies\nthe perspective of spatial expressions. Despite its significance, FoR has\nreceived limited attention in AI models that need spatial intelligence. There\nis a lack of dedicated benchmarks and in-depth evaluation of large language\nmodels (LLMs) in this area. To address this issue, we introduce the Frame of\nReference Evaluation in Spatial Reasoning Tasks (FoREST) benchmark, designed to\nassess FoR comprehension in LLMs. We evaluate LLMs on answering questions that\nrequire FoR comprehension and layout generation in text-to-image models using\nFoREST. Our results reveal a notable performance gap across different FoR\nclasses in various LLMs, affecting their ability to generate accurate layouts\nfor text-to-image generation. This highlights critical shortcomings in FoR\ncomprehension. To improve FoR understanding, we propose Spatial-Guided\nprompting, which improves LLMs ability to extract essential spatial concepts.\nOur proposed method improves overall performance across spatial reasoning\ntasks.", "AI": {"tldr": "The paper introduces FoREST, a benchmark to evaluate Frame of Reference (FoR) comprehension in LLMs, revealing performance gaps and proposing Spatial-Guided prompting to improve spatial reasoning.", "motivation": "FoR is crucial for spatial cognition but lacks attention in AI models. There's a need for dedicated benchmarks to evaluate LLMs' FoR comprehension.", "method": "Introduces FoREST benchmark to assess FoR in LLMs, evaluates performance on FoR-related questions and text-to-image layout generation, and proposes Spatial-Guided prompting.", "result": "Identifies performance gaps in LLMs' FoR comprehension, impacting text-to-image accuracy. Spatial-Guided prompting improves spatial reasoning.", "conclusion": "FoREST highlights LLMs' shortcomings in FoR comprehension, and Spatial-Guided prompting offers a solution to enhance spatial reasoning performance."}}
{"id": "2502.07523", "pdf": "https://arxiv.org/pdf/2502.07523", "abs": "https://arxiv.org/abs/2502.07523", "authors": ["Daniel Palenicek", "Florian Vogt", "Joe Watson", "Jan Peters"], "title": "Scaling Off-Policy Reinforcement Learning with Batch and Weight Normalization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning has achieved significant milestones, but sample\nefficiency remains a bottleneck for real-world applications. Recently, CrossQ\nhas demonstrated state-of-the-art sample efficiency with a low update-to-data\n(UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with\nhigher UTD ratios. We identify challenges in the training dynamics, which are\nemphasized by higher UTD ratios. To address these, we integrate weight\nnormalization into the CrossQ framework, a solution that stabilizes training,\nhas been shown to prevent potential loss of plasticity and keeps the effective\nlearning rate constant. Our proposed approach reliably scales with increasing\nUTD ratios, achieving competitive performance across 25 challenging continuous\ncontrol tasks on the DeepMind Control Suite and Myosuite benchmarks, notably\nthe complex dog and humanoid environments. This work eliminates the need for\ndrastic interventions, such as network resets, and offers a simple yet robust\npathway for improving sample efficiency and scalability in model-free\nreinforcement learning.", "AI": {"tldr": "The paper explores scaling CrossQ's sample efficiency with higher update-to-data (UTD) ratios, identifies training challenges, and proposes weight normalization to stabilize training and improve performance.", "motivation": "Sample efficiency is a bottleneck in reinforcement learning; CrossQ shows promise but struggles with higher UTD ratios.", "method": "Integrates weight normalization into CrossQ to stabilize training dynamics and maintain effective learning rates.", "result": "Achieves competitive performance on 25 tasks, including complex environments like dog and humanoid, without drastic interventions.", "conclusion": "Weight normalization offers a simple, robust solution for improving scalability and sample efficiency in model-free RL."}}
{"id": "2410.19236", "pdf": "https://arxiv.org/pdf/2410.19236", "abs": "https://arxiv.org/abs/2410.19236", "authors": ["Darin Tsui", "Aryan Musharaf", "Yigit Efe Erginbas", "Justin Singh Kang", "Amirali Aghazadeh"], "title": "SHAP zero Explains Biological Sequence Models with Near-zero Marginal Cost for Future Queries", "categories": ["cs.LG", "cs.CE", "q-bio.GN", "stat.CO"], "comment": null, "summary": "The growing adoption of machine learning models for biological sequences has\nintensified the need for interpretable predictions, with Shapley values\nemerging as a theoretically grounded standard for model explanation. While\neffective for local explanations of individual input sequences, scaling\nShapley-based interpretability to extract global biological insights requires\nevaluating thousands of sequences--incurring exponential computational cost per\nquery. We introduce SHAP zero, a novel algorithm that amortizes the cost of\nShapley value computation across large-scale biological datasets. After a\none-time model sketching step, SHAP zero enables near-zero marginal cost for\nfuture queries by uncovering an underexplored connection between Shapley\nvalues, high-order feature interactions, and the sparse Fourier transform of\nthe model. Applied to models of guide RNA efficacy, DNA repair outcomes, and\nprotein fitness, SHAP zero explains predictions orders of magnitude faster than\nexisting methods, recovering rich combinatorial interactions previously\ninaccessible at scale. This work opens the door to principled, efficient, and\nscalable interpretability for black-box sequence models in biology.", "AI": {"tldr": "SHAP zero is a novel algorithm that reduces the computational cost of Shapley value computation for large-scale biological datasets, enabling efficient and scalable interpretability for sequence models.", "motivation": "The need for interpretable predictions in machine learning models for biological sequences has grown, with Shapley values being a standard for explanations. However, scaling Shapley-based interpretability globally is computationally expensive.", "method": "SHAP zero amortizes Shapley value computation costs by leveraging a one-time model sketching step and uncovering connections between Shapley values, high-order feature interactions, and sparse Fourier transforms.", "result": "SHAP zero explains predictions much faster than existing methods, revealing rich combinatorial interactions in models of guide RNA efficacy, DNA repair, and protein fitness.", "conclusion": "SHAP zero enables efficient, scalable, and principled interpretability for black-box sequence models in biology."}}
{"id": "2505.10250", "pdf": "https://arxiv.org/pdf/2505.10250", "abs": "https://arxiv.org/abs/2505.10250", "authors": ["Wenhao Shen", "Wanqi Yin", "Xiaofeng Yang", "Cheng Chen", "Chaoyue Song", "Zhongang Cai", "Lei Yang", "Hao Wang", "Guosheng Lin"], "title": "ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization", "categories": ["cs.CV"], "comment": "Accepted to ICML 2025. Code: https://github.com/shenwenhao01/ADHMR", "summary": "Human mesh recovery (HMR) from a single image is inherently ill-posed due to\ndepth ambiguity and occlusions. Probabilistic methods have tried to solve this\nby generating numerous plausible 3D human mesh predictions, but they often\nexhibit misalignment with 2D image observations and weak robustness to\nin-the-wild images. To address these issues, we propose ADHMR, a framework that\nAligns a Diffusion-based HMR model in a preference optimization manner. First,\nwe train a human mesh prediction assessment model, HMR-Scorer, capable of\nevaluating predictions even for in-the-wild images without 3D annotations. We\nthen use HMR-Scorer to create a preference dataset, where each input image has\na pair of winner and loser mesh predictions. This dataset is used to finetune\nthe base model using direct preference optimization. Moreover, HMR-Scorer also\nhelps improve existing HMR models by data cleaning, even with fewer training\nsamples. Extensive experiments show that ADHMR outperforms current\nstate-of-the-art methods. Code is available at:\nhttps://github.com/shenwenhao01/ADHMR.", "AI": {"tldr": "ADHMR is a framework that aligns a diffusion-based human mesh recovery model using preference optimization, improving alignment with 2D observations and robustness for in-the-wild images.", "motivation": "Existing probabilistic HMR methods often misalign with 2D observations and lack robustness for in-the-wild images.", "method": "Train an HMR-Scorer to assess predictions, create a preference dataset, and finetune the base model using direct preference optimization.", "result": "ADHMR outperforms state-of-the-art methods and improves existing models via data cleaning.", "conclusion": "ADHMR effectively addresses misalignment and robustness issues in HMR, demonstrating superior performance."}}
{"id": "2502.17956", "pdf": "https://arxiv.org/pdf/2502.17956", "abs": "https://arxiv.org/abs/2502.17956", "authors": ["Patomporn Payoungkhamdee", "Pume Tuchinda", "Jinheon Baek", "Samuel Cahyawijaya", "Can Udomcharoenchaikit", "Potsawee Manakul", "Peerat Limkonchotiwat", "Ekapol Chuangsuwanich", "Sarana Nutanong"], "title": "Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments", "categories": ["cs.CL"], "comment": null, "summary": "Multi-step reasoning is essential for large language models (LLMs), yet\nmultilingual performance remains challenging. While Chain-of-Thought (CoT)\nprompting improves reasoning, it struggles with non-English languages due to\nthe entanglement of reasoning and execution. Program-of-Thought (PoT) prompting\nseparates reasoning from execution, offering a promising alternative but\nshifting the challenge to generating programs from non-English questions. We\npropose a framework to evaluate PoT by separating multilingual reasoning from\ncode execution to examine (i) the impact of fine-tuning on question-reasoning\nalignment and (ii) how reasoning quality affects answer correctness. Our\nfindings demonstrate that PoT fine-tuning substantially enhances multilingual\nreasoning, outperforming CoT fine-tuned models. We further demonstrate a strong\ncorrelation between reasoning quality (measured through code quality) and\nanswer accuracy, highlighting its potential as a test-time performance\nimprovement heuristic.", "AI": {"tldr": "PoT prompting improves multilingual reasoning in LLMs by separating reasoning from execution, outperforming CoT. Fine-tuning enhances question-reasoning alignment, and reasoning quality strongly correlates with answer accuracy.", "motivation": "Multilingual reasoning in LLMs is challenging, especially with CoT prompting due to reasoning-execution entanglement. PoT offers a solution but introduces new challenges in program generation from non-English questions.", "method": "Proposed framework evaluates PoT by separating multilingual reasoning from code execution, examining fine-tuning's impact on question-reasoning alignment and reasoning quality's effect on answer correctness.", "result": "PoT fine-tuning significantly improves multilingual reasoning, surpassing CoT models. Reasoning quality (measured by code quality) strongly correlates with answer accuracy.", "conclusion": "PoT is a promising alternative for multilingual reasoning, with fine-tuning and reasoning quality as key factors for performance improvement."}}
{"id": "2502.07849", "pdf": "https://arxiv.org/pdf/2502.07849", "abs": "https://arxiv.org/abs/2502.07849", "authors": ["Krunoslav Lehman Pavasovic", "Jakob Verbeek", "Giulio Biroli", "Marc Mezard"], "title": "Classifier-Free Guidance: From High-Dimensional Analysis to Generalized Guidance Forms", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Classifier-Free Guidance (CFG) is a widely adopted technique in diffusion and\nflow-based generative models, enabling high-quality conditional generation. A\nkey theoretical challenge is characterizing the distribution induced by CFG,\nparticularly in high-dimensional settings relevant to real-world data. Previous\nworks have shown that CFG modifies the target distribution, steering it towards\na distribution sharper than the target one, more shifted towards the boundary\nof the class. In this work, we provide a high-dimensional analysis of CFG,\nshowing that these distortions vanish as the data dimension grows. We present a\nblessing-of-dimensionality result demonstrating that in sufficiently high and\ninfinite dimensions, CFG accurately reproduces the target distribution. Using\nour high-dimensional theory, we show that there is a large family of guidances\nenjoying this property, in particular non-linear CFG generalizations. We study\na simple non-linear power-law version, for which we demonstrate improved\nrobustness, sample fidelity and diversity. Our findings are validated with\nexperiments on class-conditional and text-to-image generation using\nstate-of-the-art diffusion and flow-matching models.", "AI": {"tldr": "CFG's distortions vanish in high dimensions, accurately reproducing the target distribution. Non-linear CFG variants show improved robustness and sample quality.", "motivation": "To theoretically analyze CFG's behavior in high dimensions and explore its practical implications for generative models.", "method": "High-dimensional analysis of CFG, introducing non-linear generalizations and validating with experiments on diffusion and flow-matching models.", "result": "CFG distortions disappear in high dimensions; non-linear variants enhance robustness, fidelity, and diversity.", "conclusion": "CFG's high-dimensional behavior ensures accurate target distribution reproduction, with non-linear extensions offering practical benefits."}}
{"id": "2411.00278", "pdf": "https://arxiv.org/pdf/2411.00278", "abs": "https://arxiv.org/abs/2411.00278", "authors": ["Quan Zhou", "Changhua Pei", "Fei Sun", "Jing Han", "Zhengwei Gao", "Dan Pei", "Haiming Zhang", "Gaogang Xie", "Jianhui Li"], "title": "KAN-AD: Time Series Anomaly Detection with Kolmogorov-Arnold Networks", "categories": ["cs.LG"], "comment": "11 pages, ICML 2025", "summary": "Time series anomaly detection (TSAD) underpins real-time monitoring in cloud\nservices and web systems, allowing rapid identification of anomalies to prevent\ncostly failures. Most TSAD methods driven by forecasting models tend to overfit\nby emphasizing minor fluctuations. Our analysis reveals that effective TSAD\nshould focus on modeling \"normal\" behavior through smooth local patterns. To\nachieve this, we reformulate time series modeling as approximating the series\nwith smooth univariate functions. The local smoothness of each univariate\nfunction ensures that the fitted time series remains resilient against local\ndisturbances. However, a direct KAN implementation proves susceptible to these\ndisturbances due to the inherently localized characteristics of B-spline\nfunctions. We thus propose KAN-AD, replacing B-splines with truncated Fourier\nexpansions and introducing a novel lightweight learning mechanism that\nemphasizes global patterns while staying robust to local disturbances. On four\npopular TSAD benchmarks, KAN-AD achieves an average 15% improvement in\ndetection accuracy (with peaks exceeding 27%) over state-of-the-art baselines.\nRemarkably, it requires fewer than 1,000 trainable parameters, resulting in a\n50% faster inference speed compared to the original KAN, demonstrating the\napproach's efficiency and practical viability.", "AI": {"tldr": "KAN-AD improves TSAD by focusing on smooth local patterns, using truncated Fourier expansions for robustness, achieving 15% better accuracy and 50% faster inference.", "motivation": "Current TSAD methods overfit minor fluctuations; effective detection requires modeling normal behavior through smooth local patterns.", "method": "Reformulates time series modeling with smooth univariate functions, replaces B-splines with truncated Fourier expansions, and introduces a lightweight learning mechanism.", "result": "15% average accuracy improvement (peaking at 27%) and 50% faster inference with fewer than 1,000 parameters.", "conclusion": "KAN-AD is efficient, practical, and outperforms state-of-the-art methods in TSAD."}}
{"id": "2505.10473", "pdf": "https://arxiv.org/pdf/2505.10473", "abs": "https://arxiv.org/abs/2505.10473", "authors": ["Fengdi Zhang", "Hongkun Cao", "Ruqi Huang"], "title": "Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting", "categories": ["cs.CV"], "comment": "16 pages, 7 figures, 7 tables. Project page available at\n  https://zhang-fengdi.github.io/ControlGS/", "summary": "To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks\nto minimize the number of Gaussians used while preserving high rendering\nquality, introducing an inherent trade-off between Gaussian quantity and\nrendering quality. Existing methods strive for better quantity-quality\nperformance, but lack the ability for users to intuitively adjust this\ntrade-off to suit practical needs such as model deployment under diverse\nhardware and communication constraints. Here, we present ControlGS, a 3DGS\noptimization method that achieves semantically meaningful and cross-scene\nconsistent quantity-quality control. Through a single training run using a\nfixed setup and a user-specified hyperparameter reflecting quantity-quality\npreference, ControlGS can automatically find desirable quantity-quality\ntrade-off points across diverse scenes, from compact objects to large outdoor\nscenes. It also outperforms baselines by achieving higher rendering quality\nwith fewer Gaussians, and supports a broad adjustment range with stepless\ncontrol over the trade-off. Project page:\nhttps://zhang-fengdi.github.io/ControlGS/", "AI": {"tldr": "ControlGS is a 3DGS optimization method enabling intuitive adjustment of the trade-off between Gaussian quantity and rendering quality, outperforming baselines with higher quality and fewer Gaussians.", "motivation": "Existing methods lack user-adjustable trade-offs for practical needs like diverse hardware constraints. ControlGS addresses this gap.", "method": "ControlGS uses a single training run with a fixed setup and user-specified hyperparameter to find optimal trade-off points across scenes.", "result": "It achieves higher rendering quality with fewer Gaussians and supports stepless control over the trade-off.", "conclusion": "ControlGS provides a flexible, high-performance solution for 3DGS optimization, suitable for diverse practical applications."}}
{"id": "2503.04598", "pdf": "https://arxiv.org/pdf/2503.04598", "abs": "https://arxiv.org/abs/2503.04598", "authors": ["Zhijian Zhuo", "Yutao Zeng", "Ya Wang", "Sijun Zhang", "Jian Yang", "Xiaoqing Li", "Xun Zhou", "Jinwen Ma"], "title": "HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Transformers have become the de facto architecture for a wide range of\nmachine learning tasks, particularly in large language models (LLMs). Despite\ntheir remarkable performance, challenges remain in training deep transformer\nnetworks, especially regarding the position of layer normalization. While\nPre-Norm structures facilitate more stable training owing to their stronger\nidentity path, they often lead to suboptimal performance compared to Post-Norm.\nIn this paper, we propose $\\textbf{HybridNorm}$, a simple yet effective hybrid\nnormalization strategy that integrates the advantages of both Pre-Norm and\nPost-Norm. Specifically, HybridNorm employs QKV normalization within the\nattention mechanism and Post-Norm in the feed-forward network (FFN) of each\ntransformer block. We provide both theoretical insights and empirical evidence\ndemonstrating that HybridNorm improves gradient flow and model robustness.\nExtensive experiments on large-scale transformer models, including both dense\nand sparse variants, show that HybridNorm consistently outperforms both\nPre-Norm and Post-Norm approaches across multiple benchmarks. These findings\nhighlight the potential of HybridNorm as a more stable and effective technique\nfor improving the training and performance of deep transformer models. Code is\navailable at https://github.com/BryceZhuo/HybridNorm.", "AI": {"tldr": "HybridNorm combines Pre-Norm and Post-Norm in transformers, improving gradient flow and performance.", "motivation": "Addressing the trade-off between training stability (Pre-Norm) and performance (Post-Norm) in deep transformer networks.", "method": "Proposes HybridNorm: QKV normalization in attention and Post-Norm in FFN.", "result": "Outperforms Pre-Norm and Post-Norm in benchmarks, enhancing gradient flow and robustness.", "conclusion": "HybridNorm is a stable and effective technique for deep transformer models."}}
{"id": "2502.11741", "pdf": "https://arxiv.org/pdf/2502.11741", "abs": "https://arxiv.org/abs/2502.11741", "authors": ["Shuai Lyu", "Haoran Luo", "Ripeng Li", "Zhonghong Ou", "Jiangfeng Sun", "Yang Qin", "Xiaoran Shang", "Meina Song", "Yifan Zhu"], "title": "SQL-o1: A Self-Reward Heuristic Dynamic Search Method for Text-to-SQL", "categories": ["cs.DB", "cs.AI"], "comment": "28 pages,12 figures", "summary": "Text-to-SQL (Text2SQL) aims to map natural language questions to executable\nSQL queries. Although large language models (LLMs) have driven significant\nprogress, current approaches struggle with poor transferability to open-source\nLLMs, limited robustness against logic and function errors in complex queries,\nand inefficiencies in structured search. We introduce SQL-o1, a\nself-reward-driven heuristic search framework built on an agent-based\narchitecture to enhance model reasoning capabilities. SQL-o1 leverages Monte\nCarlo Tree Search (MCTS) for structured, multi-step exploration, and\nincorporates a dynamic pruning strategy to accelerate inference without\nsacrificing accuracy. On the Spider and Bird benchmarks, SQL-o1 achieves a\n+10.8 execution accuracy improvement on the complex Bird dataset, surpassing\neven GPT-4-based models. Notably, it exhibits strong few-shot generalization\nand robust cross-model transferability across open-source LLMs. Our code is\navailable at:https://github.com/ShuaiLyu0110/SQL-o1.", "AI": {"tldr": "SQL-o1 is a self-reward-driven heuristic search framework for Text-to-SQL, improving reasoning, robustness, and efficiency, outperforming GPT-4 on complex datasets.", "motivation": "Address poor transferability, limited robustness, and inefficiencies in current Text-to-SQL approaches using LLMs.", "method": "Agent-based architecture with Monte Carlo Tree Search (MCTS) and dynamic pruning for structured, multi-step exploration.", "result": "+10.8 execution accuracy improvement on Bird dataset; strong few-shot generalization and cross-model transferability.", "conclusion": "SQL-o1 enhances reasoning and robustness in Text-to-SQL, outperforming state-of-the-art models."}}
{"id": "2411.01642", "pdf": "https://arxiv.org/pdf/2411.01642", "abs": "https://arxiv.org/abs/2411.01642", "authors": ["Md Abrar Jahin", "Md. Akmol Masud", "M. F. Mridha", "Nilanjan Dey", "Zeyar Aung"], "title": "Quantum Rationale-Aware Graph Contrastive Learning for Jet Discrimination", "categories": ["cs.LG", "hep-ph"], "comment": null, "summary": "In high-energy physics, particle jet tagging plays a pivotal role in\ndistinguishing quark from gluon jets using data from collider experiments.\nWhile graph-based deep learning methods have advanced this task beyond\ntraditional feature-engineered approaches, the complex data structure and\nlimited labeled samples present ongoing challenges. However, existing\ncontrastive learning (CL) frameworks struggle to leverage rationale-aware\naugmentations effectively, often lacking supervision signals that guide the\nextraction of salient features and facing computational efficiency issues such\nas high parameter counts. In this study, we demonstrate that integrating a\nquantum rationale generator (QRG) within our proposed Quantum Rationale-aware\nGraph Contrastive Learning (QRGCL) framework significantly enhances jet\ndiscrimination performance, reducing reliance on labeled data and capturing\ndiscriminative features. Evaluated on the quark-gluon jet dataset, QRGCL\nachieves an AUC score of $77.53\\%$ while maintaining a compact architecture of\nonly 45 QRG parameters, outperforming classical, quantum, and hybrid GCL and\nGNN benchmarks. These results highlight QRGCL's potential to advance jet\ntagging and other complex classification tasks in high-energy physics, where\ncomputational efficiency and feature extraction limitations persist.", "AI": {"tldr": "The paper introduces QRGCL, a quantum rationale-aware graph contrastive learning framework, to improve quark-gluon jet tagging by enhancing feature extraction and reducing labeled data dependency.", "motivation": "Existing contrastive learning frameworks for jet tagging lack effective rationale-aware augmentations and face computational inefficiencies, prompting the need for a more efficient and supervised approach.", "method": "The proposed QRGCL integrates a quantum rationale generator (QRG) to guide feature extraction and improve discriminative performance, evaluated on a quark-gluon jet dataset.", "result": "QRGCL achieves a 77.53% AUC score with only 45 QRG parameters, outperforming classical, quantum, and hybrid benchmarks.", "conclusion": "QRGCL demonstrates potential for advancing jet tagging and other complex classification tasks in high-energy physics by addressing computational and feature extraction challenges."}}
{"id": "2505.11872", "pdf": "https://arxiv.org/pdf/2505.11872", "abs": "https://arxiv.org/abs/2505.11872", "authors": ["Quoc-Huy Trinh", "Minh-Van Nguyen", "Jung Peng", "Ulas Bagci", "Debesh Jha"], "title": "PRS-Med: Position Reasoning Segmentation with Vision-Language Model in Medical Imaging", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in prompt-based medical image segmentation have enabled\nclinicians to identify tumors using simple input like bounding boxes or text\nprompts. However, existing methods face challenges when doctors need to\ninteract through natural language or when position reasoning is required -\nunderstanding spatial relationships between anatomical structures and\npathologies. We present PRS-Med, a framework that integrates vision-language\nmodels with segmentation capabilities to generate both accurate segmentation\nmasks and corresponding spatial reasoning outputs. Additionally, we introduce\nthe MMRS dataset (Multimodal Medical in Positional Reasoning Segmentation),\nwhich provides diverse, spatially-grounded question-answer pairs to address the\nlack of position reasoning data in medical imaging. PRS-Med demonstrates\nsuperior performance across six imaging modalities (CT, MRI, X-ray, ultrasound,\nendoscopy, RGB), significantly outperforming state-of-the-art methods in both\nsegmentation accuracy and position reasoning. Our approach enables intuitive\ndoctor-system interaction through natural language, facilitating more efficient\ndiagnoses. Our dataset pipeline, model, and codebase will be released to foster\nfurther research in spatially-aware multimodal reasoning for medical\napplications.", "AI": {"tldr": "PRS-Med integrates vision-language models for medical image segmentation and spatial reasoning, outperforming existing methods and introducing the MMRS dataset.", "motivation": "Addressing challenges in natural language interaction and positional reasoning in medical image segmentation.", "method": "Combines vision-language models with segmentation to generate masks and spatial reasoning outputs, using the MMRS dataset.", "result": "Superior performance in segmentation and position reasoning across six imaging modalities.", "conclusion": "PRS-Med enhances doctor-system interaction and diagnoses, with plans to release resources for further research."}}
{"id": "2503.08506", "pdf": "https://arxiv.org/pdf/2503.08506", "abs": "https://arxiv.org/abs/2503.08506", "authors": ["Xian Gao", "Jiacheng Ruan", "Jingsheng Gao", "Ting Liu", "Yuzhuo Fu"], "title": "ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews", "categories": ["cs.CL"], "comment": "Work in progress", "summary": "Academic paper review is a critical yet time-consuming task within the\nresearch community. With the increasing volume of academic publications,\nautomating the review process has become a significant challenge. The primary\nissue lies in generating comprehensive, accurate, and reasoning-consistent\nreview comments that align with human reviewers' judgments. In this paper, we\naddress this challenge by proposing ReviewAgents, a framework that leverages\nlarge language models (LLMs) to generate academic paper reviews. We first\nintroduce a novel dataset, Review-CoT, consisting of 142k review comments,\ndesigned for training LLM agents. This dataset emulates the structured\nreasoning process of human reviewers-summarizing the paper, referencing\nrelevant works, identifying strengths and weaknesses, and generating a review\nconclusion. Building upon this, we train LLM reviewer agents capable of\nstructured reasoning using a relevant-paper-aware training method. Furthermore,\nwe construct ReviewAgents, a multi-role, multi-LLM agent review framework, to\nenhance the review comment generation process. Additionally, we propose\nReviewBench, a benchmark for evaluating the review comments generated by LLMs.\nOur experimental results on ReviewBench demonstrate that while existing LLMs\nexhibit a certain degree of potential for automating the review process, there\nremains a gap when compared to human-generated reviews. Moreover, our\nReviewAgents framework further narrows this gap, outperforming advanced LLMs in\ngenerating review comments.", "AI": {"tldr": "The paper proposes ReviewAgents, a framework using LLMs to automate academic paper reviews, introduces a dataset (Review-CoT), and benchmarks performance against human reviews.", "motivation": "The increasing volume of academic publications makes manual reviews time-consuming, necessitating automation while maintaining quality.", "method": "Develops ReviewAgents, a multi-role LLM framework, trained on the Review-CoT dataset, which emulates human reviewer reasoning.", "result": "ReviewAgents outperforms existing LLMs but still lags behind human reviews, though it narrows the gap.", "conclusion": "The framework shows promise for automating reviews but requires further improvement to match human quality."}}
{"id": "2502.13767", "pdf": "https://arxiv.org/pdf/2502.13767", "abs": "https://arxiv.org/abs/2502.13767", "authors": ["Abhik Roychoudhury", "Corina Pasareanu", "Michael Pradel", "Baishakhi Ray"], "title": "Agentic AI Software Engineers: Programming with Trust", "categories": ["cs.SE", "cs.AI"], "comment": "5 pages", "summary": "Large Language Models (LLMs) have shown surprising proficiency in generating\ncode snippets, promising to automate large parts of software engineering via\nartificial intelligence (AI). We argue that successfully deploying AI software\nengineers requires a level of trust equal to or even greater than the trust\nestablished by human-driven software engineering practices. The recent trend\ntoward LLM agents offers a path toward integrating the power of LLMs to create\nnew code with the power of analysis tools to increase trust in the code. This\nopinion piece comments on whether LLM agents could dominate software\nengineering workflows in the future and whether the focus of programming will\nshift from programming at scale to programming with trust.", "AI": {"tldr": "The paper discusses the potential of LLMs to automate software engineering, emphasizing the need for trust in AI-generated code and the role of LLM agents in integrating analysis tools for reliability.", "motivation": "To explore whether LLM agents can dominate future software engineering workflows and shift the focus from large-scale programming to trust-based programming.", "method": "Opinion-based analysis of LLMs' role in code generation and the integration of analysis tools for trust.", "result": "LLM agents could revolutionize software engineering by combining code generation with trust-building tools.", "conclusion": "The future of programming may prioritize trust over scale, with LLM agents playing a central role."}}
{"id": "2411.02279", "pdf": "https://arxiv.org/pdf/2411.02279", "abs": "https://arxiv.org/abs/2411.02279", "authors": ["Jincheng Huang", "Yujie Mo", "Xiaoshuang Shi", "Lei Feng", "Xiaofeng Zhu"], "title": "Enhancing the Influence of Labels on Unlabeled Nodes in Graph Convolutional Networks", "categories": ["cs.LG"], "comment": "Accepted by ICML2025", "summary": "The message-passing mechanism of graph convolutional networks (i.e., GCNs)\nenables label information to reach more unlabeled neighbors, thereby increasing\nthe utilization of labels. However, the additional label information does not\nalways contribute positively to the GCN. To address this issue, we propose a\nnew two-step framework called ELU-GCN. In the first stage, ELU-GCN conducts\ngraph learning to learn a new graph structure (i.e., ELU-graph), which allows\nthe additional label information to positively influence the predictions of\nGCN. In the second stage, we design a new graph contrastive learning on the GCN\nframework for representation learning by exploring the consistency and mutually\nexclusive information between the learned ELU graph and the original graph.\nMoreover, we theoretically demonstrate that the proposed method can ensure the\ngeneralization ability of GCNs. Extensive experiments validate the superiority\nof our method.", "AI": {"tldr": "ELU-GCN improves GCNs by learning a new graph structure (ELU-graph) and using contrastive learning to enhance label utilization and generalization.", "motivation": "Additional label information in GCNs doesn't always help; ELU-GCN aims to ensure positive influence and better utilization.", "method": "Two-step framework: (1) learn ELU-graph for positive label influence, (2) use contrastive learning on GCN for representation.", "result": "Theoretical proof of generalization ability; experiments show ELU-GCN's superiority.", "conclusion": "ELU-GCN effectively enhances GCN performance by optimizing label utilization and representation learning."}}
{"id": "2505.11945", "pdf": "https://arxiv.org/pdf/2505.11945", "abs": "https://arxiv.org/abs/2505.11945", "authors": ["Bonan li", "Zicheng Zhang", "Songhua Liu", "Weihao Yu", "Xinchao Wang"], "title": "Top-Down Compression: Revisit Efficient Vision Token Projection for Visual Instruction Tuning", "categories": ["cs.CV"], "comment": "Under Review", "summary": "Visual instruction tuning aims to enable large language models to comprehend\nthe visual world, with a pivotal challenge lying in establishing an effective\nvision-to-language projection. However, existing methods often grapple with the\nintractable trade-off between accuracy and efficiency. In this paper, we\npresent LLaVA-Meteor, a novel approach designed to break this deadlock,\nequipped with a novel Top-Down Compression paradigm that strategically\ncompresses visual tokens without compromising core information. Specifically,\nwe construct a trainable Flash Global Fusion module based on efficient\nselective state space operators, which aligns the feature space while enabling\neach token to perceive holistic visual context and instruction preference at\nlow cost. Furthermore, a local-to-single scanning manner is employed to\neffectively capture local dependencies, thereby enhancing the model's\ncapability in vision modeling. To alleviate computational overhead, we explore\na Visual-Native Selection mechanism that independently assesses token\nsignificance by both the visual and native experts, followed by aggregation to\nretain the most critical subset. Extensive experiments show that our approach\nreduces visual tokens by 75--95% while achieving comparable or superior\nperformance across 12 benchmarks, significantly improving efficiency.", "AI": {"tldr": "LLaVA-Meteor introduces a Top-Down Compression paradigm and Flash Global Fusion module to balance accuracy and efficiency in visual instruction tuning, reducing visual tokens by 75-95% while maintaining performance.", "motivation": "Addressing the trade-off between accuracy and efficiency in vision-to-language projection for large language models.", "method": "Uses Top-Down Compression, Flash Global Fusion for feature alignment, local-to-single scanning for dependencies, and Visual-Native Selection for token reduction.", "result": "Achieves comparable or superior performance on 12 benchmarks with 75-95% fewer visual tokens.", "conclusion": "LLaVA-Meteor effectively balances efficiency and accuracy in visual instruction tuning."}}
{"id": "2503.14749", "pdf": "https://arxiv.org/pdf/2503.14749", "abs": "https://arxiv.org/abs/2503.14749", "authors": ["Sophia Hager", "David Mueller", "Kevin Duh", "Nicholas Andrews"], "title": "Uncertainty Distillation: Teaching Language Models to Express Semantic Confidence", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) are increasingly used for factual\nquestion-answering, it becomes more important for LLMs to have the capability\nto communicate the likelihood that their answer is correct. For these\nverbalized expressions of uncertainty to be meaningful, they should reflect the\nerror rates at the expressed level of confidence. However, when prompted to\nexpress confidence, the error rates of current LLMs are inconsistent with their\ncommunicated confidences, highlighting the need for uncertainty quantification\nmethods. Many prior methods calculate lexical uncertainty, estimating a model's\nconfidence in the specific string it generated. In some cases, however, it may\nbe more useful to estimate semantic uncertainty, or the model's confidence in\nthe answer regardless of how it is verbalized. We propose a simple procedure,\nuncertainty distillation, to teach an LLM to verbalize calibrated semantic\nconfidences. Using held-out data to map initial uncertainty estimates to\nmeaningful probabilities, we create examples annotated with verbalized\nprobabilities for supervised fine-tuning. We compare uncertainty distillation\nto several strong baselines, and find that our method yields verbalized\nconfidences that correlate well with observed error rates.", "AI": {"tldr": "The paper proposes 'uncertainty distillation' to teach LLMs to verbalize calibrated semantic confidences, ensuring their expressed uncertainty aligns with actual error rates.", "motivation": "LLMs often express inconsistent confidence levels, making their uncertainty unreliable for factual question-answering.", "method": "The method involves using held-out data to map initial uncertainty estimates to probabilities, creating examples for supervised fine-tuning.", "result": "Uncertainty distillation produces verbalized confidences that correlate well with observed error rates.", "conclusion": "The approach improves LLMs' ability to communicate meaningful uncertainty, enhancing their reliability in factual tasks."}}
{"id": "2502.18218", "pdf": "https://arxiv.org/pdf/2502.18218", "abs": "https://arxiv.org/abs/2502.18218", "authors": ["Bingke Zhu", "Xiaoxiao Wang", "Minghui Jia", "Yihan Tao", "Xiao Kong", "Ali Luo", "Yingying Chen", "Ming Tang", "Jinqiao Wang"], "title": "FLARE: A Framework for Stellar Flare Forecasting using Stellar Physical Properties and Historical Records", "categories": ["astro-ph.SR", "astro-ph.IM", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Stellar flare events are critical observational samples for astronomical\nresearch; however, recorded flare events remain limited. Stellar flare\nforecasting can provide additional flare event samples to support research\nefforts. Despite this potential, no specialized models for stellar flare\nforecasting have been proposed to date. In this paper, we present extensive\nexperimental evidence demonstrating that both stellar physical properties and\nhistorical flare records are valuable inputs for flare forecasting tasks. We\nthen introduce FLARE (Forecasting Light-curve-based Astronomical Records via\nfeatures Ensemble), the first-of-its-kind large model specifically designed for\nstellar flare forecasting. FLARE integrates stellar physical properties and\nhistorical flare records through a novel Soft Prompt Module and Residual Record\nFusion Module. Our experiments on the publicly available Kepler light curve\ndataset demonstrate that FLARE achieves superior performance compared to other\nmethods across all evaluation metrics. Finally, we validate the forecast\ncapability of our model through a comprehensive case study.", "AI": {"tldr": "FLARE is the first specialized model for stellar flare forecasting, combining stellar properties and historical records, outperforming other methods on the Kepler dataset.", "motivation": "Limited recorded flare events hinder astronomical research; forecasting can provide more samples, but no specialized models exist.", "method": "FLARE integrates stellar properties and historical records using a Soft Prompt Module and Residual Record Fusion Module.", "result": "FLARE outperforms other methods on the Kepler dataset across all metrics.", "conclusion": "FLARE successfully forecasts stellar flares, validated by a case study, and fills a gap in specialized models."}}
{"id": "2411.04680", "pdf": "https://arxiv.org/pdf/2411.04680", "abs": "https://arxiv.org/abs/2411.04680", "authors": ["Marlon Tobaben", "Talal Alrawajfeh", "Marcus Klasson", "Mikko Heikkil\u00e4", "Arno Solin", "Antti Honkela"], "title": "Differential Privacy in Continual Learning: Which Labels to Update?", "categories": ["cs.LG", "cs.CR"], "comment": "39 pages, 13 figures", "summary": "The goal of continual learning (CL) is to retain knowledge across tasks, but\nthis conflicts with strict privacy required for sensitive training data that\nprevents storing or memorising individual samples. To address that, we combine\nCL and differential privacy (DP). We highlight that failing to account for\nprivacy leakage through the set of labels a model can output can break the\nprivacy of otherwise valid DP algorithms. This is especially relevant in CL. We\nshow that mitigating the issue with a data-independent overly large label space\ncan have minimal negative impact on utility when fine-tuning a pre-trained\nmodel under DP, while learning the labels with a separate DP mechanism risks\nlosing small classes.", "AI": {"tldr": "Combining continual learning (CL) and differential privacy (DP) to retain knowledge while protecting sensitive data, addressing privacy leakage risks in label outputs.", "motivation": "To reconcile CL's knowledge retention with strict privacy requirements for sensitive data, avoiding storage or memorization of individual samples.", "method": "Mitigate privacy leakage by using a data-independent large label space, fine-tuning pre-trained models under DP, and learning labels separately with DP.", "result": "Overly large label spaces minimally impact utility, while separate DP mechanisms risk losing small classes.", "conclusion": "Balancing CL and DP requires careful handling of label spaces to maintain privacy without sacrificing utility."}}
{"id": "2505.12007", "pdf": "https://arxiv.org/pdf/2505.12007", "abs": "https://arxiv.org/abs/2505.12007", "authors": ["Runduo Han", "Xiuping Liu", "Shangxuan Yi", "Yi Zhang", "Hongchen Tan"], "title": "Multi-modal Collaborative Optimization and Expansion Network for Event-assisted Single-eye Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we proposed a Multi-modal Collaborative Optimization and\nExpansion Network (MCO-E Net), to use event modalities to resist challenges\nsuch as low light, high exposure, and high dynamic range in single-eye\nexpression recognition tasks. The MCO-E Net introduces two innovative designs:\nMulti-modal Collaborative Optimization Mamba (MCO-Mamba) and Heterogeneous\nCollaborative and Expansion Mixture-of-Experts (HCE-MoE). MCO-Mamba, building\nupon Mamba, leverages dual-modal information to jointly optimize the model,\nfacilitating collaborative interaction and fusion of modal semantics. This\napproach encourages the model to balance the learning of both modalities and\nharness their respective strengths. HCE-MoE, on the other hand, employs a\ndynamic routing mechanism to distribute structurally varied experts (deep,\nattention, and focal), fostering collaborative learning of complementary\nsemantics. This heterogeneous architecture systematically integrates diverse\nfeature extraction paradigms to comprehensively capture expression semantics.\nExtensive experiments demonstrate that our proposed network achieves\ncompetitive performance in the task of single-eye expression recognition,\nespecially under poor lighting conditions.", "AI": {"tldr": "The paper introduces MCO-E Net, a multi-modal network for single-eye expression recognition, addressing challenges like low light and high dynamic range. It features MCO-Mamba for dual-modal optimization and HCE-MoE for heterogeneous expert collaboration, achieving strong performance in poor lighting.", "motivation": "To overcome challenges in single-eye expression recognition, such as low light and high dynamic range, by leveraging multi-modal collaboration and heterogeneous feature extraction.", "method": "Proposes MCO-E Net with two key designs: MCO-Mamba for dual-modal optimization and HCE-MoE for dynamic expert routing, integrating deep, attention, and focal features.", "result": "The network achieves competitive performance in single-eye expression recognition, particularly under poor lighting conditions.", "conclusion": "MCO-E Net effectively addresses lighting challenges in expression recognition through multi-modal collaboration and heterogeneous feature integration."}}
{"id": "2503.15463", "pdf": "https://arxiv.org/pdf/2503.15463", "abs": "https://arxiv.org/abs/2503.15463", "authors": ["Jia-Nan Li", "Jian Guan", "Songhao Wu", "Wei Wu", "Rui Yan"], "title": "From 1,000,000 Users to Every User: Scaling Up Personalized Preference for User-level Alignment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have traditionally been aligned through\none-size-fits-all approaches that assume uniform human preferences,\nfundamentally overlooking the diversity in user values and needs. This paper\nintroduces a comprehensive framework for scalable personalized alignment of\nLLMs. We establish a systematic preference space characterizing psychological\nand behavioral dimensions, alongside diverse persona representations for robust\npreference inference in real-world scenarios. Building upon this foundation, we\nintroduce \\textsc{AlignX}, a large-scale dataset of over 1.3 million\npersonalized preference examples, and develop two complementary alignment\napproaches: \\textit{in-context alignment} directly conditioning on persona\nrepresentations and \\textit{preference-bridged alignment} modeling intermediate\npreference distributions. Extensive experiments demonstrate substantial\nimprovements over existing methods, with an average 17.06\\% accuracy gain\nacross four benchmarks while exhibiting a strong adaptation capability to novel\npreferences, robustness to limited user data, and precise preference\ncontrollability. These results validate our approach toward user-adaptive AI\nsystems.", "AI": {"tldr": "The paper introduces a scalable framework for personalized alignment of large language models (LLMs), addressing diversity in user preferences. It proposes two alignment methods and demonstrates significant improvements over existing approaches.", "motivation": "Traditional LLM alignment assumes uniform human preferences, ignoring user diversity. This work aims to address this gap by enabling personalized alignment.", "method": "The paper introduces a preference space and persona representations, alongside the AlignX dataset. Two alignment approaches are developed: in-context alignment and preference-bridged alignment.", "result": "Experiments show a 17.06% accuracy gain across benchmarks, with strong adaptation, robustness, and controllability.", "conclusion": "The framework advances user-adaptive AI systems by effectively addressing diverse preferences."}}
{"id": "2502.20900", "pdf": "https://arxiv.org/pdf/2502.20900", "abs": "https://arxiv.org/abs/2502.20900", "authors": ["Yifan Zhong", "Xuchuan Huang", "Ruochong Li", "Ceyao Zhang", "Yitao Liang", "Yaodong Yang", "Yuanpei Chen"], "title": "DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping", "categories": ["cs.RO", "cs.AI"], "comment": "26 pages, 12 figures", "summary": "Dexterous grasping remains a fundamental yet challenging problem in robotics.\nA general-purpose robot must be capable of grasping diverse objects in\narbitrary scenarios. However, existing research typically relies on restrictive\nassumptions, such as single-object settings or limited environments, leading to\nconstrained generalization. We present DexGraspVLA, a hierarchical framework\nfor general dexterous grasping in cluttered scenes based on RGB image\nperception and language instructions. It utilizes a pre-trained Vision-Language\nmodel as the high-level task planner and learns a diffusion-based policy as the\nlow-level Action controller. The key insight to achieve robust generalization\nlies in iteratively transforming diverse language and visual inputs into\ndomain-invariant representations via foundation models, where imitation\nlearning can be effectively applied due to the alleviation of domain shift.\nNotably, our method achieves a 90+% success rate under thousands of unseen\nobject, lighting, and background combinations in a \"zero-shot\" environment.\nEmpirical analysis confirms the consistency of internal model behavior across\nenvironmental variations, thereby validating our design and explaining its\ngeneralization performance. DexGraspVLA also demonstrates free-form\nlong-horizon prompt execution, robustness to adversarial objects and human\ndisturbance, and failure recovery, which are rarely achieved simultaneously in\nprior work. Extended application to nonprehensile object grasping further\nproves its generality. Code, model, and video are available at\ndexgraspvla.github.io.", "AI": {"tldr": "DexGraspVLA is a hierarchical framework for general dexterous grasping in cluttered scenes using RGB images and language instructions, achieving robust generalization with a 90+% success rate in zero-shot environments.", "motivation": "Existing grasping methods rely on restrictive assumptions (e.g., single-object settings), limiting generalization. DexGraspVLA aims to overcome this by leveraging vision-language models and domain-invariant representations.", "method": "Uses a pre-trained Vision-Language model for high-level task planning and a diffusion-based policy for low-level action control, transforming diverse inputs into domain-invariant representations.", "result": "Achieves 90+% success rate in unseen object, lighting, and background combinations, with consistent behavior across environmental variations.", "conclusion": "DexGraspVLA demonstrates robust generalization, long-horizon prompt execution, and adaptability to adversarial conditions, proving its generality in dexterous grasping."}}
{"id": "2411.10510", "pdf": "https://arxiv.org/pdf/2411.10510", "abs": "https://arxiv.org/abs/2411.10510", "authors": ["Joseph Liu", "Joshua Geddes", "Ziyu Guo", "Haomiao Jiang", "Mahesh Kumar Nandwana"], "title": "SmoothCache: A Universal Inference Acceleration Technique for Diffusion Transformers", "categories": ["cs.LG"], "comment": "Code can be found at https://github.com/Roblox/SmoothCache. Accepted\n  at CVPR eLVM workshop", "summary": "Diffusion Transformers (DiT) have emerged as powerful generative models for\nvarious tasks, including image, video, and speech synthesis. However, their\ninference process remains computationally expensive due to the repeated\nevaluation of resource-intensive attention and feed-forward modules. To address\nthis, we introduce SmoothCache, a model-agnostic inference acceleration\ntechnique for DiT architectures. SmoothCache leverages the observed high\nsimilarity between layer outputs across adjacent diffusion timesteps. By\nanalyzing layer-wise representation errors from a small calibration set,\nSmoothCache adaptively caches and reuses key features during inference. Our\nexperiments demonstrate that SmoothCache achieves 8% to 71% speed up while\nmaintaining or even improving generation quality across diverse modalities. We\nshowcase its effectiveness on DiT-XL for image generation, Open-Sora for\ntext-to-video, and Stable Audio Open for text-to-audio, highlighting its\npotential to enable real-time applications and broaden the accessibility of\npowerful DiT models.", "AI": {"tldr": "SmoothCache accelerates DiT inference by caching and reusing similar layer outputs across timesteps, achieving 8-71% speedup without quality loss.", "motivation": "DiT models are computationally expensive during inference due to repeated evaluations of attention and feed-forward modules.", "method": "SmoothCache analyzes layer-wise representation errors from a calibration set to cache and reuse key features adaptively.", "result": "Achieves 8-71% speedup while maintaining or improving generation quality across image, video, and audio tasks.", "conclusion": "SmoothCache enables real-time DiT applications and enhances accessibility of these models."}}
{"id": "2505.12081", "pdf": "https://arxiv.org/pdf/2505.12081", "abs": "https://arxiv.org/abs/2505.12081", "authors": ["Yuqi Liu", "Tianyuan Qu", "Zhisheng Zhong", "Bohao Peng", "Shu Liu", "Bei Yu", "Jiaya Jia"], "title": "VisionReasoner: Unified Visual Perception and Reasoning via Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Large vision-language models exhibit inherent capabilities to handle diverse\nvisual perception tasks. In this paper, we introduce VisionReasoner, a unified\nframework capable of reasoning and solving multiple visual perception tasks\nwithin a shared model. Specifically, by designing novel multi-object cognitive\nlearning strategies and systematic task reformulation, VisionReasoner enhances\nits reasoning capabilities to analyze visual inputs, and addresses diverse\nperception tasks in a unified framework. The model generates a structured\nreasoning process before delivering the desired outputs responding to user\nqueries. To rigorously assess unified visual perception capabilities, we\nevaluate VisionReasoner on ten diverse tasks spanning three critical domains:\ndetection, segmentation, and counting. Experimental results show that\nVisionReasoner achieves superior performance as a unified model, outperforming\nQwen2.5VL by relative margins of 29.1% on COCO (detection), 22.1% on ReasonSeg\n(segmentation), and 15.3% on CountBench (counting).", "AI": {"tldr": "VisionReasoner is a unified framework for multiple visual perception tasks, outperforming Qwen2.5VL in detection, segmentation, and counting.", "motivation": "To create a shared model capable of reasoning and solving diverse visual perception tasks efficiently.", "method": "Uses multi-object cognitive learning and task reformulation to enhance reasoning and unify tasks.", "result": "Achieves superior performance: 29.1% better on COCO, 22.1% on ReasonSeg, and 15.3% on CountBench.", "conclusion": "VisionReasoner is effective as a unified model for diverse visual perception tasks."}}
{"id": "2503.16674", "pdf": "https://arxiv.org/pdf/2503.16674", "abs": "https://arxiv.org/abs/2503.16674", "authors": ["Molly Kennedy", "Ayyoob Imani", "Timo Spinde", "Hinrich Sch\u00fctze"], "title": "Through the LLM Looking Glass: A Socratic Probing of Donkeys, Elephants, and Markets", "categories": ["cs.CL"], "comment": null, "summary": "While detecting and avoiding bias in LLM-generated text is becoming\nincreasingly important, media bias often remains subtle and subjective, making\nit particularly difficult to identify and mitigate. In this study, we assess\nmedia bias in LLM-generated content and LLMs' ability to detect subtle\nideological bias. We conduct this evaluation using two datasets, PoliGen and\nEconoLex, covering political and economic discourse, respectively. We evaluate\nseven widely used LLMs by prompting them to generate articles and analyze their\nideological preferences via Socratic probing. By using our self-contained\nSocratic approach, the study aims to directly measure the models' biases rather\nthan relying on external interpretations, thereby minimizing subjective\njudgments about media bias. Our results reveal a consistent preference of\nDemocratic over Republican positions across all models. Conversely, in economic\ntopics, biases vary among Western LLMs, while those developed in China lean\nmore strongly toward socialism.", "AI": {"tldr": "The study evaluates media bias in LLM-generated content and their ability to detect subtle ideological bias using datasets PoliGen and EconoLex. It reveals Democratic and socialist leanings in political and economic topics, respectively.", "motivation": "Detecting and mitigating subtle, subjective media bias in LLM-generated text is challenging but crucial.", "method": "Seven LLMs were prompted to generate articles, and their biases were analyzed using Socratic probing on political (PoliGen) and economic (EconoLex) datasets.", "result": "All models showed a Democratic preference in politics, while economic biases varied among Western LLMs, with Chinese models leaning toward socialism.", "conclusion": "The study highlights the need for bias-aware LLM development and suggests Socratic probing as an effective tool for direct bias measurement."}}
{"id": "2503.01450", "pdf": "https://arxiv.org/pdf/2503.01450", "abs": "https://arxiv.org/abs/2503.01450", "authors": ["Zekang Wang", "Zhe He", "Borong Zhang", "Edan Toledo", "Steven Morad"], "title": "POPGym Arcade: Parallel Pixelated POMDPs", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We present the POPGym Arcade, a collection of hardware-accelerated,\npixel-based environments with shared observation and action spaces. Each\nenvironment includes fully and partially observable variants, enabling\ncounterfactual studies on partial observability. We also introduce mathematical\ntools for analyzing policies under partial observability, which reveal how\nagents recall past information to make decisions. Our analysis shows (1) that\ncontrolling for partial observability is critical and (2) that agents with\nlong-term memory learn brittle policies that struggle to generalize. Finally,\nwe demonstrate that recurrent policies can be \"poisoned\" by old,\nout-of-distribution observations, with implications for sim-to-real transfer,\nimitation learning, and offline reinforcement learning.", "AI": {"tldr": "POPGym Arcade offers pixel-based environments with shared observation/action spaces, including partial observability variants, and introduces tools to analyze policies, revealing memory-related brittleness and poisoning risks.", "motivation": "To enable counterfactual studies on partial observability and analyze how agents use past information for decision-making.", "method": "Developed hardware-accelerated environments with fully/partially observable variants and introduced mathematical tools for policy analysis under partial observability.", "result": "Found that controlling partial observability is critical, long-term memory leads to brittle policies, and recurrent policies can be poisoned by old observations.", "conclusion": "Highlights challenges in sim-to-real transfer, imitation learning, and offline RL due to memory brittleness and poisoning risks."}}
{"id": "2412.04614", "pdf": "https://arxiv.org/pdf/2412.04614", "abs": "https://arxiv.org/abs/2412.04614", "authors": ["Jiahai Feng", "Stuart Russell", "Jacob Steinhardt"], "title": "Extractive Structures Learned in Pretraining Enable Generalization on Finetuned Facts", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Pretrained language models (LMs) can generalize to implications of facts that\nthey are finetuned on. For example, if finetuned on ``John Doe lives in Tokyo,\"\nLMs can correctly answer ``What language do the people in John Doe's city\nspeak?'' with ``Japanese''. However, little is known about the mechanisms that\nenable this generalization or how they are learned during pretraining. We\nintroduce extractive structures as a framework for describing how components in\nLMs (e.g., MLPs or attention heads) coordinate to enable this generalization.\nThe structures consist of informative components that store training facts as\nweight changes, and upstream and downstream extractive components that query\nand process the stored information to produce the correct implication. We\nhypothesize that extractive structures are learned during pretraining when\nencountering implications of previously known facts. This yields two\npredictions: a data ordering effect where extractive structures can be learned\nonly if facts precede their implications, and a weight grafting effect where\nextractive structures can be transferred to predict counterfactual\nimplications. We empirically demonstrate these phenomena in the OLMo-7b, Llama\n3-8b, Gemma 2-9b, and Qwen 2-7b models. Of independent interest, our results\nalso indicate that fact learning can occur at both early and late layers, which\nlead to different forms of generalization.", "AI": {"tldr": "Pretrained LMs generalize implications of finetuned facts via extractive structures, learned during pretraining when facts precede implications.", "motivation": "To understand how LMs generalize implications of facts and the mechanisms enabling this, focusing on extractive structures.", "method": "Introduces extractive structures (informative, upstream, downstream components) and tests hypotheses via data ordering and weight grafting effects in models like OLMo-7b, Llama 3-8b.", "result": "Empirical validation shows extractive structures enable generalization, with fact learning occurring in early/late layers, leading to different generalization forms.", "conclusion": "Extractive structures explain LM generalization, learned when facts precede implications, with implications for model design and pretraining strategies."}}
{"id": "2505.12753", "pdf": "https://arxiv.org/pdf/2505.12753", "abs": "https://arxiv.org/abs/2505.12753", "authors": ["Martha Teiko Teye", "Ori Maoz", "Matthias Rottmann"], "title": "LiDAR MOT-DETR: A LiDAR-based Two-Stage Transformer for 3D Multiple Object Tracking", "categories": ["cs.CV"], "comment": "Template change", "summary": "Multi-object tracking from LiDAR point clouds presents unique challenges due\nto the sparse and irregular nature of the data, compounded by the need for\ntemporal coherence across frames. Traditional tracking systems often rely on\nhand-crafted features and motion models, which can struggle to maintain\nconsistent object identities in crowded or fast-moving scenes. We present a\nlidar-based two-staged DETR inspired transformer; a smoother and tracker. The\nsmoother stage refines lidar object detections, from any off-the-shelf\ndetector, across a moving temporal window. The tracker stage uses a DETR-based\nattention block to maintain tracks across time by associating tracked objects\nwith the refined detections using the point cloud as context. The model is\ntrained on the datasets nuScenes and KITTI in both online and offline (forward\npeeking) modes demonstrating strong performance across metrics such as\nID-switch and multiple object tracking accuracy (MOTA). The numerical results\nindicate that the online mode outperforms the lidar-only baseline and SOTA\nmodels on the nuScenes dataset, with an aMOTA of 0.722 and an aMOTP of 0.475,\nwhile the offline mode provides an additional 3 pp aMOTP.", "AI": {"tldr": "A two-staged transformer-based approach for LiDAR multi-object tracking improves performance over traditional methods by refining detections and maintaining tracks using attention mechanisms.", "motivation": "Addressing challenges in LiDAR tracking due to sparse data and the need for temporal coherence, especially in crowded or dynamic scenes.", "method": "Uses a two-staged DETR-inspired transformer: a smoother for refining detections and a tracker for maintaining object identities using attention.", "result": "Outperforms baselines on nuScenes (aMOTA: 0.722, aMOTP: 0.475) and shows further improvement in offline mode (+3 pp aMOTP).", "conclusion": "The proposed transformer-based method effectively handles LiDAR tracking challenges, achieving state-of-the-art performance."}}
{"id": "2503.16965", "pdf": "https://arxiv.org/pdf/2503.16965", "abs": "https://arxiv.org/abs/2503.16965", "authors": ["Zhe Hu", "Jing Li", "Zhongzhu Pu", "Hou Pong Chan", "Yu Yin"], "title": "Praxis-VLM: Vision-Grounded Decision Making via Text-Driven Reinforcement Learning", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Vision Language Models exhibited immense potential for embodied AI, yet they\noften lack the sophisticated situational reasoning required for complex\ndecision-making. This paper shows that VLMs can achieve surprisingly strong\ndecision-making performance when visual scenes are represented merely as\ntext-only descriptions, suggesting foundational reasoning can be effectively\nlearned from language. Motivated by this insight, we propose Praxis-VLM, a\nreasoning VLM for vision-grounded decision-making. Praxis-VLM employs the GRPO\nalgorithm on textual scenarios to instill robust reasoning capabilities, where\nmodels learn to evaluate actions and their consequences. These reasoning\nskills, acquired purely from text, successfully transfer to multimodal\ninference with visual inputs, significantly reducing reliance on scarce paired\nimage-text training data. Experiments across diverse decision-making benchmarks\ndemonstrate that Praxis-VLM substantially outperforms standard supervised\nfine-tuning, exhibiting superior performance and generalizability. Further\nanalysis confirms that our models engage in explicit and effective reasoning,\nunderpinning their enhanced performance and adaptability.", "AI": {"tldr": "VLMs can achieve strong decision-making using text-only descriptions, leading to Praxis-VLM, a reasoning model that transfers text-learned reasoning to visual tasks, outperforming traditional methods.", "motivation": "VLMs lack sophisticated situational reasoning for complex decision-making, but text-based reasoning shows promise for improving their capabilities.", "method": "Proposes Praxis-VLM, using the GRPO algorithm on textual scenarios to teach reasoning, then transferring these skills to multimodal tasks with visual inputs.", "result": "Praxis-VLM outperforms standard supervised fine-tuning in benchmarks, showing superior performance and generalizability.", "conclusion": "Text-based reasoning can effectively enhance VLMs' decision-making, reducing reliance on paired image-text data and improving adaptability."}}
{"id": "2503.01917", "pdf": "https://arxiv.org/pdf/2503.01917", "abs": "https://arxiv.org/abs/2503.01917", "authors": ["Seongheon Park", "Xuefeng Du", "Min-Hsuan Yeh", "Haobo Wang", "Yixuan Li"], "title": "Steer LLM Latents for Hallucination Detection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ICML 2025", "summary": "Hallucinations in LLMs pose a significant concern to their safe deployment in\nreal-world applications. Recent approaches have leveraged the latent space of\nLLMs for hallucination detection, but their embeddings, optimized for\nlinguistic coherence rather than factual accuracy, often fail to clearly\nseparate truthful and hallucinated content. To this end, we propose the\nTruthfulness Separator Vector (TSV), a lightweight and flexible steering vector\nthat reshapes the LLM's representation space during inference to enhance the\nseparation between truthful and hallucinated outputs, without altering model\nparameters. Our two-stage framework first trains TSV on a small set of labeled\nexemplars to form compact and well-separated clusters. It then augments the\nexemplar set with unlabeled LLM generations, employing an optimal\ntransport-based algorithm for pseudo-labeling combined with a confidence-based\nfiltering process. Extensive experiments demonstrate that TSV achieves\nstate-of-the-art performance with minimal labeled data, exhibiting strong\ngeneralization across datasets and providing a practical solution for\nreal-world LLM applications.", "AI": {"tldr": "The paper introduces the Truthfulness Separator Vector (TSV) to detect hallucinations in LLMs by reshaping the representation space, achieving state-of-the-art performance with minimal labeled data.", "motivation": "Hallucinations in LLMs hinder safe deployment; existing methods using latent space embeddings fail to clearly separate truthful and hallucinated content.", "method": "Proposes TSV, a lightweight steering vector trained on labeled exemplars and augmented with unlabeled LLM generations using optimal transport-based pseudo-labeling and confidence filtering.", "result": "TSV achieves state-of-the-art performance, generalizes well across datasets, and requires minimal labeled data.", "conclusion": "TSV provides a practical solution for enhancing hallucination detection in real-world LLM applications without altering model parameters."}}
{"id": "2412.07067", "pdf": "https://arxiv.org/pdf/2412.07067", "abs": "https://arxiv.org/abs/2412.07067", "authors": ["Yinsicheng Jiang", "Yao Fu", "Yeqi Huang", "Ping Nie", "Zhan Lu", "Leyang Xue", "Congjie He", "Man-Kit Sit", "Jilong Xue", "Li Dong", "Ziming Miao", "Dayou Du", "Tairan Xu", "Kai Zou", "Edoardo Ponti", "Luo Mai"], "title": "MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "The sparse Mixture-of-Experts (MoE) architecture is increasingly favored for\nscaling Large Language Models (LLMs) efficiently, but it depends on\nheterogeneous compute and memory resources. These factors jointly affect system\nCost, Accuracy, and Performance (CAP), making trade-offs inevitable. Existing\nbenchmarks often fail to capture these trade-offs accurately, complicating\npractical deployment decisions. To address this, we introduce MoE-CAP, a\nbenchmark specifically designed for MoE systems. Our analysis reveals that\nachieving an optimal balance across CAP is difficult with current hardware; MoE\nsystems typically optimize two of the three dimensions at the expense of the\nthird-a dynamic we term the MoE-CAP trade-off. To visualize this, we propose\nthe CAP Radar Diagram. We further introduce sparsity-aware performance\nmetrics-Sparse Memory Bandwidth Utilization (S-MBU) and Sparse Model FLOPS\nUtilization (S-MFU)-to enable accurate performance benchmarking of MoE systems\nacross diverse hardware platforms and deployment scenarios.", "AI": {"tldr": "MoE-CAP is a benchmark for MoE systems, highlighting the trade-offs between Cost, Accuracy, and Performance (CAP) in sparse MoE architectures.", "motivation": "Existing benchmarks fail to accurately capture the trade-offs in MoE systems, complicating deployment decisions.", "method": "Introduces MoE-CAP benchmark, CAP Radar Diagram, and sparsity-aware metrics (S-MBU, S-MFU) for performance evaluation.", "result": "Optimal CAP balance is hard to achieve; MoE systems often sacrifice one dimension for the other two.", "conclusion": "MoE-CAP provides a framework for better benchmarking and understanding of MoE system trade-offs."}}
{"id": "2505.14068", "pdf": "https://arxiv.org/pdf/2505.14068", "abs": "https://arxiv.org/abs/2505.14068", "authors": ["Zhenyu Li", "Tianyi Shang", "Pengjie Xu", "Zhaojun Deng"], "title": "Place Recognition: A Comprehensive Review, Current Challenges and Future Directions", "categories": ["cs.CV"], "comment": "35 pages", "summary": "Place recognition is a cornerstone of vehicle navigation and mapping, which\nis pivotal in enabling systems to determine whether a location has been\npreviously visited. This capability is critical for tasks such as loop closure\nin Simultaneous Localization and Mapping (SLAM) and long-term navigation under\nvarying environmental conditions. In this survey, we comprehensively review\nrecent advancements in place recognition, emphasizing three representative\nmethodological paradigms: Convolutional Neural Network (CNN)-based approaches,\nTransformer-based frameworks, and cross-modal strategies. We begin by\nelucidating the significance of place recognition within the broader context of\nautonomous systems. Subsequently, we trace the evolution of CNN-based methods,\nhighlighting their contributions to robust visual descriptor learning and\nscalability in large-scale environments. We then examine the emerging class of\nTransformer-based models, which leverage self-attention mechanisms to capture\nglobal dependencies and offer improved generalization across diverse scenes.\nFurthermore, we discuss cross-modal approaches that integrate heterogeneous\ndata sources such as Lidar, vision, and text description, thereby enhancing\nresilience to viewpoint, illumination, and seasonal variations. We also\nsummarize standard datasets and evaluation metrics widely adopted in the\nliterature. Finally, we identify current research challenges and outline\nprospective directions, including domain adaptation, real-time performance, and\nlifelong learning, to inspire future advancements in this domain. The unified\nframework of leading-edge place recognition methods, i.e., code library, and\nthe results of their experimental evaluations are available at\nhttps://github.com/CV4RA/SOTA-Place-Recognitioner.", "AI": {"tldr": "A survey on place recognition methods, covering CNN-based, Transformer-based, and cross-modal approaches, with insights into datasets, challenges, and future directions.", "motivation": "Place recognition is crucial for tasks like SLAM and long-term navigation, requiring robust methods to handle varying conditions.", "method": "Review of CNN-based, Transformer-based, and cross-modal methods, analyzing their strengths and applications.", "result": "Identifies advancements in descriptor learning, global dependency capture, and multi-modal integration, with available experimental results.", "conclusion": "Highlights challenges like domain adaptation and real-time performance, suggesting future research directions."}}
{"id": "2503.17287", "pdf": "https://arxiv.org/pdf/2503.17287", "abs": "https://arxiv.org/abs/2503.17287", "authors": ["Mingyang Song", "Mao Zheng", "Zheng Li", "Wenjie Yang", "Xuan Luo", "Yue Pan", "Feng Zhang"], "title": "FastCuRL: Curriculum Reinforcement Learning with Stage-wise Context Scaling for Efficient Training R1-like Reasoning Models", "categories": ["cs.CL"], "comment": "Ongoing Work", "summary": "Improving training efficiency continues to be one of the primary challenges\nin large-scale Reinforcement Learning (RL). In this paper, we investigate how\ncontext length and the complexity of training data influence the RL scaling\ntraining process of R1-distilled small reasoning models, e.g.,\nDeepSeek-R1-Distill-Qwen-1.5B. Our experimental results reveal that: (1) simply\ncontrolling the context length and curating the training data based on the\ninput prompt length can effectively improve the training efficiency of scaling\nRL, achieving better performance with more concise CoT; (2) properly scaling\nthe context length helps mitigate entropy collapse; and (3) choosing an optimal\ncontext length can improve the efficiency of model training and incentivize the\nmodel's chain-of-thought reasoning capabilities. Inspired by these insights, we\npropose FastCuRL, a curriculum RL framework with stage-wise context scaling to\nachieve efficient training and concise CoT reasoning. Experiment results\ndemonstrate that FastCuRL-1.5B-V3 significantly outperforms state-of-the-art\nreasoning models on five competition-level benchmarks and achieves 49.6\\%\naccuracy on AIME 2024. Furthermore, FastCuRL-1.5B-Preview surpasses\nDeepScaleR-1.5B-Preview on five benchmarks while only using a single node with\n8 GPUs and a total of 50\\% of training steps. %The code, training data, and\nmodels will be publicly released.", "AI": {"tldr": "The paper explores how context length and training data complexity impact RL scaling efficiency, proposing FastCuRL, a curriculum RL framework, which outperforms state-of-the-art models on benchmarks.", "motivation": "To address the challenge of improving training efficiency in large-scale RL by investigating context length and data complexity.", "method": "Proposes FastCuRL, a curriculum RL framework with stage-wise context scaling, tested on R1-distilled models like DeepSeek-R1-Distill-Qwen-1.5B.", "result": "FastCuRL-1.5B-V3 achieves 49.6% accuracy on AIME 2024 and outperforms benchmarks with fewer resources.", "conclusion": "Optimal context length and curated data improve RL training efficiency and reasoning capabilities, demonstrated by FastCuRL's success."}}
{"id": "2503.03360", "pdf": "https://arxiv.org/pdf/2503.03360", "abs": "https://arxiv.org/abs/2503.03360", "authors": ["Afnan Sultan", "Max Rausch-Dupont", "Shahrukh Khan", "Olga Kalinina", "Dietrich Klakow", "Andrea Volkamer"], "title": "Transformers for molecular property prediction: Domain adaptation efficiently improves performance", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Over the past six years, molecular transformer models have become key tools\nin drug discovery. Most existing models are pre-trained on large, unlabeled\ndatasets such as ZINC or ChEMBL. However, the extent to which large-scale\npre-training improves molecular property prediction remains unclear. This study\nevaluates transformer models for this task while addressing their limitations.\nWe explore how pre-training dataset size and chemically informed objectives\nimpact performance. Our results show that increasing the dataset beyond\napproximately 400K to 800K molecules from large-scale unlabeled databases does\nnot enhance performance across seven datasets covering five ADME endpoints:\nlipophilicity, permeability, solubility (two datasets), microsomal stability\n(two datasets), and plasma protein binding. In contrast, domain adaptation on a\nsmall, domain-specific dataset (less than or equal 4K molecules) using\nmulti-task regression of physicochemical properties significantly boosts\nperformance (P-value less than 0.001). A model pre-trained on 400K molecules\nand adapted with domain-specific data outperforms larger models such as\nMolFormer and performs comparably to MolBERT. Benchmarks against Random Forest\n(RF) baselines using descriptors and Morgan fingerprints show that chemically\nand physically informed features consistently yield better performance across\nmodel types. While RF remains a strong baseline, we identify concrete practices\nto enhance transformer performance. Aligning pre-training and adaptation with\nchemically meaningful tasks and domain-relevant data presents a promising\ndirection for molecular property prediction. Our models are available on\nHuggingFace for easy use and adaptation.", "AI": {"tldr": "Large-scale pre-training beyond 400K-800K molecules doesn't improve molecular property prediction, but domain adaptation with small, domain-specific datasets significantly boosts performance.", "motivation": "To evaluate the impact of pre-training dataset size and chemically informed objectives on molecular property prediction performance.", "method": "Assessed transformer models using pre-training and domain adaptation, comparing performance across datasets and against Random Forest baselines.", "result": "Domain adaptation with small datasets (\u22644K molecules) significantly improves performance, outperforming larger models like MolFormer and matching MolBERT.", "conclusion": "Aligning pre-training and adaptation with chemically meaningful tasks and domain-relevant data enhances transformer performance in molecular property prediction."}}
{"id": "2501.03627", "pdf": "https://arxiv.org/pdf/2501.03627", "abs": "https://arxiv.org/abs/2501.03627", "authors": ["Ya-Wei Eileen Lin", "Ronald R. Coifman", "Gal Mishne", "Ronen Talmon"], "title": "Joint Hierarchical Representation Learning of Samples and Features via Informed Tree-Wasserstein Distance", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "High-dimensional data often exhibit hierarchical structures in both modes:\nsamples and features. Yet, most existing approaches for hierarchical\nrepresentation learning consider only one mode at a time. In this work, we\npropose an unsupervised method for jointly learning hierarchical\nrepresentations of samples and features via Tree-Wasserstein Distance (TWD).\nOur method alternates between the two data modes. It first constructs a tree\nfor one mode, then computes a TWD for the other mode based on that tree, and\nfinally uses the resulting TWD to build the second mode's tree. By repeatedly\nalternating through these steps, the method gradually refines both trees and\nthe corresponding TWDs, capturing meaningful hierarchical representations of\nthe data. We provide a theoretical analysis showing that our method converges.\nWe show that our method can be integrated into hyperbolic graph convolutional\nnetworks as a pre-processing technique, improving performance in link\nprediction and node classification tasks. In addition, our method outperforms\nbaselines in sparse approximation and unsupervised Wasserstein distance\nlearning tasks on word-document and single-cell RNA-sequencing datasets.", "AI": {"tldr": "Proposes an unsupervised method for joint hierarchical representation learning of samples and features using Tree-Wasserstein Distance (TWD), alternating between modes to refine trees and TWDs.", "motivation": "High-dimensional data often have hierarchical structures in both samples and features, but existing methods address only one mode at a time.", "method": "Alternates between constructing trees for one mode and computing TWD for the other, refining both iteratively.", "result": "Convergence is proven theoretically; method improves performance in tasks like link prediction, node classification, sparse approximation, and Wasserstein distance learning.", "conclusion": "The method effectively captures hierarchical structures in data and enhances downstream tasks, outperforming baselines."}}
{"id": "2505.14671", "pdf": "https://arxiv.org/pdf/2505.14671", "abs": "https://arxiv.org/abs/2505.14671", "authors": ["Ruichuan An", "Sihan Yang", "Renrui Zhang", "Zijun Shen", "Ming Lu", "Gaole Dai", "Hao Liang", "Ziyu Guo", "Shilin Yan", "Yulin Luo", "Bocheng Zou", "Chaoqun Yang", "Wentao Zhang"], "title": "UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens", "categories": ["cs.CV"], "comment": null, "summary": "Personalized models have demonstrated remarkable success in understanding and\ngenerating concepts provided by users. However, existing methods use separate\nconcept tokens for understanding and generation, treating these tasks in\nisolation. This may result in limitations for generating images with complex\nprompts. For example, given the concept $\\langle bo\\rangle$, generating\n\"$\\langle bo\\rangle$ wearing its hat\" without additional textual descriptions\nof its hat. We call this kind of generation personalized knowledge-driven\ngeneration. To address the limitation, we present UniCTokens, a novel framework\nthat effectively integrates personalized information into a unified vision\nlanguage model (VLM) for understanding and generation. UniCTokens trains a set\nof unified concept tokens to leverage complementary semantics, boosting two\npersonalized tasks. Moreover, we propose a progressive training strategy with\nthree stages: understanding warm-up, bootstrapping generation from\nunderstanding, and deepening understanding from generation to enhance mutual\nbenefits between both tasks. To quantitatively evaluate the unified VLM\npersonalization, we present UnifyBench, the first benchmark for assessing\nconcept understanding, concept generation, and knowledge-driven generation.\nExperimental results on UnifyBench indicate that UniCTokens shows competitive\nperformance compared to leading methods in concept understanding, concept\ngeneration, and achieving state-of-the-art results in personalized\nknowledge-driven generation. Our research demonstrates that enhanced\nunderstanding improves generation, and the generation process can yield\nvaluable insights into understanding. Our code and dataset will be released at:\n\\href{https://github.com/arctanxarc/UniCTokens}{https://github.com/arctanxarc/UniCTokens}.", "AI": {"tldr": "UniCTokens introduces a unified framework for personalized concept understanding and generation, addressing limitations of isolated tasks. It achieves state-of-the-art results in knowledge-driven generation.", "motivation": "Existing methods treat concept understanding and generation separately, limiting performance for complex prompts. UniCTokens aims to unify these tasks for better results.", "method": "UniCTokens trains unified concept tokens in a vision language model (VLM) using a progressive three-stage training strategy: understanding warm-up, bootstrapping generation, and deepening understanding.", "result": "UniCTokens outperforms leading methods in concept understanding and generation, achieving state-of-the-art in personalized knowledge-driven generation.", "conclusion": "Unifying understanding and generation enhances both tasks, with generation providing insights for understanding. The framework and benchmark (UnifyBench) are publicly available."}}
{"id": "2503.19498", "pdf": "https://arxiv.org/pdf/2503.19498", "abs": "https://arxiv.org/abs/2503.19498", "authors": ["Ling Zhong", "Yujing Lu", "Jing Yang", "Weiming Li", "Peng Wei", "Yongheng Wang", "Manni Duan", "Qing Zhang"], "title": "DomainCQA: Crafting Expert-Level QA from Domain-Specific Charts", "categories": ["cs.CL"], "comment": "87 pages, 65 figures", "summary": "Chart Question Answering (CQA) benchmarks are essential for evaluating the\ncapability of Multimodal Large Language Models (MLLMs) to interpret visual\ndata. However, current benchmarks focus primarily on the evaluation of\ngeneral-purpose CQA but fail to adequately capture domain-specific challenges.\nWe introduce DomainCQA, a systematic methodology for constructing\ndomain-specific CQA benchmarks, and demonstrate its effectiveness by developing\nAstroChart, a CQA benchmark in the field of astronomy. Our evaluation shows\nthat current MLLMs face fundamental challenges in vision-language alignment and\ndomain adaptation, highlighting a critical gap in current benchmarks. By\nproviding a scalable and rigorous framework, DomainCQA enables more precise\nassessment and improvement of MLLMs for domain-specific applications.", "AI": {"tldr": "DomainCQA introduces a method for domain-specific Chart Question Answering (CQA) benchmarks, addressing gaps in current evaluations, and demonstrates its effectiveness with AstroChart in astronomy.", "motivation": "Current CQA benchmarks lack domain-specific challenges, limiting the evaluation of Multimodal Large Language Models (MLLMs) in specialized fields.", "method": "DomainCQA provides a systematic framework for creating domain-specific CQA benchmarks, exemplified by AstroChart in astronomy.", "result": "Evaluation reveals MLLMs struggle with vision-language alignment and domain adaptation, exposing benchmark shortcomings.", "conclusion": "DomainCQA offers a scalable, rigorous framework to better assess and enhance MLLMs for domain-specific tasks."}}
{"id": "2503.03965", "pdf": "https://arxiv.org/pdf/2503.03965", "abs": "https://arxiv.org/abs/2503.03965", "authors": ["Chaitanya K. Joshi", "Xiang Fu", "Yi-Lun Liao", "Vahe Gharakhanyan", "Benjamin Kurt Miller", "Anuroop Sriram", "Zachary W. Ulissi"], "title": "All-atom Diffusion Transformers: Unified generative modelling of molecules and materials", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Diffusion models are the standard toolkit for generative modelling of 3D\natomic systems. However, for different types of atomic systems -- such as\nmolecules and materials -- the generative processes are usually highly specific\nto the target system despite the underlying physics being the same. We\nintroduce the All-atom Diffusion Transformer (ADiT), a unified latent diffusion\nframework for jointly generating both periodic materials and non-periodic\nmolecular systems using the same model: (1) An autoencoder maps a unified,\nall-atom representations of molecules and materials to a shared latent\nembedding space; and (2) A diffusion model is trained to generate new latent\nembeddings that the autoencoder can decode to sample new molecules or\nmaterials. Experiments on MP20, QM9 and GEOM-DRUGS datasets demonstrate that\njointly trained ADiT generates realistic and valid molecules as well as\nmaterials, obtaining state-of-the-art results on par with molecule and\ncrystal-specific models. ADiT uses standard Transformers with minimal inductive\nbiases for both the autoencoder and diffusion model, resulting in significant\nspeedups during training and inference compared to equivariant diffusion\nmodels. Scaling ADiT up to half a billion parameters predictably improves\nperformance, representing a step towards broadly generalizable foundation\nmodels for generative chemistry. Open source code:\nhttps://github.com/facebookresearch/all-atom-diffusion-transformer", "AI": {"tldr": "ADiT is a unified latent diffusion framework for generating both molecules and materials using the same model, achieving state-of-the-art results with standard Transformers.", "motivation": "Current diffusion models for 3D atomic systems are highly specific to target systems, despite shared underlying physics. ADiT aims to unify generative processes for molecules and materials.", "method": "ADiT combines an autoencoder for shared latent space mapping and a diffusion model for generating new latent embeddings, using standard Transformers with minimal biases.", "result": "ADiT achieves state-of-the-art performance on MP20, QM9, and GEOM-DRUGS datasets, with faster training and inference than equivariant models. Scaling improves performance predictably.", "conclusion": "ADiT represents progress toward generalizable foundation models for generative chemistry, with open-source availability."}}
{"id": "2501.16168", "pdf": "https://arxiv.org/pdf/2501.16168", "abs": "https://arxiv.org/abs/2501.16168", "authors": ["Artavazd Maranjyan", "Alexander Tyurin", "Peter Richt\u00e1rik"], "title": "Ringmaster ASGD: The First Asynchronous SGD with Optimal Time Complexity", "categories": ["cs.LG", "cs.DC", "math.OC", "stat.ML"], "comment": null, "summary": "Asynchronous Stochastic Gradient Descent (Asynchronous SGD) is a cornerstone\nmethod for parallelizing learning in distributed machine learning. However, its\nperformance suffers under arbitrarily heterogeneous computation times across\nworkers, leading to suboptimal time complexity and inefficiency as the number\nof workers scales. While several Asynchronous SGD variants have been proposed,\nrecent findings by Tyurin & Richt\\'arik (NeurIPS 2023) reveal that none achieve\noptimal time complexity, leaving a significant gap in the literature. In this\npaper, we propose Ringmaster ASGD, a novel Asynchronous SGD method designed to\naddress these limitations and tame the inherent challenges of Asynchronous SGD.\nWe establish, through rigorous theoretical analysis, that Ringmaster ASGD\nachieves optimal time complexity under arbitrarily heterogeneous and\ndynamically fluctuating worker computation times. This makes it the first\nAsynchronous SGD method to meet the theoretical lower bounds for time\ncomplexity in such scenarios.", "AI": {"tldr": "Ringmaster ASGD is a new Asynchronous SGD method achieving optimal time complexity under heterogeneous worker computation times.", "motivation": "Existing Asynchronous SGD methods fail to achieve optimal time complexity under heterogeneous computation times, creating inefficiencies as worker numbers scale.", "method": "Proposes Ringmaster ASGD, designed to handle heterogeneous and dynamically fluctuating worker computation times.", "result": "Theoretical analysis shows Ringmaster ASGD achieves optimal time complexity, meeting lower bounds for such scenarios.", "conclusion": "Ringmaster ASGD is the first Asynchronous SGD method to achieve optimal time complexity under challenging conditions."}}
{"id": "2505.14729", "pdf": "https://arxiv.org/pdf/2505.14729", "abs": "https://arxiv.org/abs/2505.14729", "authors": ["Ram Mohan Rao Kadiyala", "Siddhant Gupta", "Jebish Purbey", "Srishti Yadav", "Alejandro Salamanca", "Desmond Elliott"], "title": "Uncovering Cultural Representation Disparities in Vision-Language Models", "categories": ["cs.CV"], "comment": "28 pages, 36 figures", "summary": "Vision-Language Models (VLMs) have demonstrated impressive capabilities\nacross a range of tasks, yet concerns about their potential biases exist. This\nwork investigates the extent to which prominent VLMs exhibit cultural biases by\nevaluating their performance on an image-based country identification task at a\ncountry level. Utilizing the geographically diverse Country211 dataset, we\nprobe several large vision language models (VLMs) under various prompting\nstrategies: open-ended questions, multiple-choice questions (MCQs) including\nchallenging setups like multilingual and adversarial settings. Our analysis\naims to uncover disparities in model accuracy across different countries and\nquestion formats, providing insights into how training data distribution and\nevaluation methodologies might influence cultural biases in VLMs. The findings\nhighlight significant variations in performance, suggesting that while VLMs\npossess considerable visual understanding, they inherit biases from their\npre-training data and scale that impact their ability to generalize uniformly\nacross diverse global contexts.", "AI": {"tldr": "The paper investigates cultural biases in Vision-Language Models (VLMs) by evaluating their performance on a country identification task using the Country211 dataset, revealing disparities influenced by training data and prompting strategies.", "motivation": "To assess and uncover cultural biases in VLMs, which could impact their fairness and generalization across diverse global contexts.", "method": "Evaluated VLMs on the Country211 dataset using open-ended questions, multiple-choice questions (MCQs), and challenging setups like multilingual and adversarial settings.", "result": "Significant performance variations across countries and question formats, indicating biases inherited from pre-training data.", "conclusion": "VLMs exhibit cultural biases due to training data distribution, affecting their uniform generalization globally."}}
{"id": "2503.20083", "pdf": "https://arxiv.org/pdf/2503.20083", "abs": "https://arxiv.org/abs/2503.20083", "authors": ["Benjamin Minixhofer", "Ivan Vuli\u0107", "Edoardo Maria Ponti"], "title": "Universal Cross-Tokenizer Distillation via Approximate Likelihood Matching", "categories": ["cs.CL"], "comment": "Preprint, 21 pages", "summary": "Distillation has shown remarkable success in transferring knowledge from a\nLarge Language Model (LLM) teacher to a student LLM. However, current\ndistillation methods require similar tokenizers between the teacher and the\nstudent, restricting their applicability to only a small subset of\nteacher-student pairs. In this work, we develop a principled cross-tokenizer\ndistillation method to solve this crucial deficiency. Our method is the first\nto enable effective distillation across fundamentally different tokenizers,\nwhile also substantially outperforming prior methods in all other cases. We\nverify the efficacy of our method on three distinct use cases. First, we show\nthat viewing tokenizer transfer as self-distillation enables unprecedentedly\neffective transfer across tokenizers, including rapid transfer of subword\nmodels to the byte-level. Transferring different models to the same tokenizer\nalso enables ensembling to boost performance. Secondly, we distil a large\nmaths-specialised LLM into a small general-purpose model with a different\ntokenizer, achieving competitive maths problem-solving performance. Thirdly, we\nuse our method to train state-of-the-art embedding prediction hypernetworks for\ntraining-free tokenizer transfer. Our results unlock an expanded range of\nteacher-student pairs for distillation, enabling new ways to adapt and enhance\ninteraction between LLMs.", "AI": {"tldr": "A new cross-tokenizer distillation method enables effective knowledge transfer between LLMs with different tokenizers, outperforming prior methods and expanding applicability.", "motivation": "Current distillation methods require similar tokenizers, limiting their use. This work addresses the need for effective cross-tokenizer distillation.", "method": "Develops a principled cross-tokenizer distillation method, tested on three use cases: tokenizer transfer, model distillation, and embedding prediction hypernetworks.", "result": "Outperforms prior methods, enables effective transfer across tokenizers, and achieves competitive performance in specialized tasks.", "conclusion": "The method expands the range of teacher-student pairs for distillation, enhancing LLM interaction and adaptation."}}
{"id": "2503.04564", "pdf": "https://arxiv.org/pdf/2503.04564", "abs": "https://arxiv.org/abs/2503.04564", "authors": ["Xiang Zhang", "Zhou Li", "Kai Wan", "Hua Sun", "Mingyue Ji", "Giuseppe Caire"], "title": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association", "categories": ["cs.IT", "cs.AI", "cs.CR", "cs.DC", "math.IT"], "comment": null, "summary": "Secure aggregation is motivated by federated learning (FL) where a cloud\nserver aims to compute an averaged model (i.e., weights of deep neural\nnetworks) of the locally-trained models of numerous clients, while adhering to\ndata security requirements. Hierarchical secure aggregation (HSA) extends this\nconcept to a three-layer network, where clustered users communicate with the\nserver through an intermediate layer of relays. In HSA, beyond conventional\nserver security, relay security is also enforced to ensure that the relays\nremain oblivious to the users' inputs (an abstraction of the local models in\nFL). Existing study on HSA assumes that each user is associated with only one\nrelay, limiting opportunities for coding across inter-cluster users to achieve\nefficient communication and key generation. In this paper, we consider HSA with\na cyclic association pattern where each user is connected to $B$ consecutive\nrelays in a wrap-around manner. We propose an efficient aggregation scheme\nwhich includes a message design for the inputs inspired by gradient coding-a\nwell-known technique for efficient communication in distributed computing-along\nwith a highly nontrivial security key design. We also derive novel converse\nbounds on the minimum achievable communication and key rates using\ninformation-theoretic arguments.", "AI": {"tldr": "The paper introduces a hierarchical secure aggregation (HSA) scheme with cyclic user-relay associations, improving efficiency and security in federated learning by leveraging gradient coding and novel key designs.", "motivation": "To address limitations in existing HSA where users are restricted to single relays, hindering efficient communication and key generation across clusters.", "method": "Proposes a cyclic association pattern (each user connects to B relays) with gradient coding-inspired message design and a novel security key design.", "result": "Develops an efficient aggregation scheme and derives information-theoretic bounds on communication and key rates.", "conclusion": "The cyclic HSA scheme enhances efficiency and security in federated learning, supported by theoretical performance bounds."}}
{"id": "2501.18049", "pdf": "https://arxiv.org/pdf/2501.18049", "abs": "https://arxiv.org/abs/2501.18049", "authors": ["Jianyu Xu", "Xuan Wang", "Yu-Xiang Wang", "Jiashuo Jiang"], "title": "Joint Pricing and Resource Allocation: An Optimal Online-Learning Approach", "categories": ["cs.LG", "math.OC", "stat.ML", "91B06, 90B22, 91B24, 90B50, 90B80, 62P20", "I.2.6"], "comment": null, "summary": "We study an online learning problem on dynamic pricing and resource\nallocation, where we make joint pricing and inventory decisions to maximize the\noverall net profit. We consider the stochastic dependence of demands on the\nprice, which complicates the resource allocation process and introduces\nsignificant non-convexity and non-smoothness to the problem. To solve this\nproblem, we develop an efficient algorithm that utilizes a \"Lower-Confidence\nBound (LCB)\" meta-strategy over multiple OCO agents. Our algorithm achieves\n$\\tilde{O}(\\sqrt{Tmn})$ regret (for $m$ suppliers and $n$ consumers), which is\noptimal with respect to the time horizon $T$. Our results illustrate an\neffective integration of statistical learning methodologies with complex\noperations research problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.15222", "pdf": "https://arxiv.org/pdf/2505.15222", "abs": "https://arxiv.org/abs/2505.15222", "authors": ["Yisi Luo", "Xile Zhao", "Deyu Meng"], "title": "Continuous Representation Methods, Theories, and Applications: An Overview and Perspectives", "categories": ["cs.CV"], "comment": null, "summary": "Recently, continuous representation methods emerge as novel paradigms that\ncharacterize the intrinsic structures of real-world data through function\nrepresentations that map positional coordinates to their corresponding values\nin the continuous space. As compared with the traditional discrete framework,\nthe continuous framework demonstrates inherent superiority for data\nrepresentation and reconstruction (e.g., image restoration, novel view\nsynthesis, and waveform inversion) by offering inherent advantages including\nresolution flexibility, cross-modal adaptability, inherent smoothness, and\nparameter efficiency. In this review, we systematically examine recent\nadvancements in continuous representation frameworks, focusing on three\naspects: (i) Continuous representation method designs such as basis function\nrepresentation, statistical modeling, tensor function decomposition, and\nimplicit neural representation; (ii) Theoretical foundations of continuous\nrepresentations such as approximation error analysis, convergence property, and\nimplicit regularization; (iii) Real-world applications of continuous\nrepresentations derived from computer vision, graphics, bioinformatics, and\nremote sensing. Furthermore, we outline future directions and perspectives to\ninspire exploration and deepen insights to facilitate continuous representation\nmethods, theories, and applications. All referenced works are summarized in our\nopen-source repository:\nhttps://github.com/YisiLuo/Continuous-Representation-Zoo", "AI": {"tldr": "The paper reviews continuous representation methods, highlighting their advantages over discrete frameworks, and explores their designs, theoretical foundations, and real-world applications.", "motivation": "To systematically examine advancements in continuous representation frameworks, emphasizing their superiority in data representation and reconstruction.", "method": "The review focuses on three aspects: method designs (e.g., implicit neural representation), theoretical foundations (e.g., approximation error analysis), and applications (e.g., computer vision).", "result": "Continuous representations offer resolution flexibility, cross-modal adaptability, and parameter efficiency, with diverse applications across fields.", "conclusion": "The paper outlines future directions to inspire further exploration and development of continuous representation methods and theories."}}
{"id": "2504.09753", "pdf": "https://arxiv.org/pdf/2504.09753", "abs": "https://arxiv.org/abs/2504.09753", "authors": ["Ram Mohan Rao Kadiyala", "Siddartha Pullakhandam", "Siddhant Gupta", "Drishti Sharma", "Jebish Purbey", "Kanwal Mehreen", "Muhammad Arham", "Hamza Farooq"], "title": "Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance", "categories": ["cs.CL", "cs.AI"], "comment": "24 pages, 18 figures", "summary": "Large Language Models (LLMs) have shown remarkable capabilities, but their\ndevelopment has primarily focused on English and other high-resource languages,\nleaving many languages underserved. We present our latest Hindi-English\nbi-lingual LLM \\textbf{Mantra-14B} with ~3\\% average improvement in benchmark\nscores over both languages, outperforming models twice its size. Using a\ncurated dataset composed of English and Hindi instruction data of 485K samples,\nwe instruction tuned models such as Qwen-2.5-14B-Instruct and Phi-4 to improve\nperformance over both English and Hindi. Our experiments encompassing seven\ndifferent LLMs of varying parameter sizes and over 140 training attempts with\nvarying English-Hindi training data ratios demonstrated that it is possible to\nsignificantly improve multilingual performance without compromising native\nperformance. Further, our approach avoids resource-intensive techniques like\nvocabulary expansion or architectural modifications, thus keeping the model\nsize small. Our results indicate that modest fine-tuning with culturally and\nlocally informed data can bridge performance gaps without incurring significant\ncomputational overhead. We release our training code, datasets, and models\nunder mit and apache licenses to aid further research towards under-represented\nand low-resource languages.", "AI": {"tldr": "Mantra-14B, a Hindi-English bilingual LLM, achieves ~3% better benchmark scores than larger models by fine-tuning with curated data, avoiding resource-heavy methods.", "motivation": "Address the underrepresentation of Hindi and other low-resource languages in LLM development.", "method": "Instruction tuning of models like Qwen-2.5-14B-Instruct and Phi-4 using 485K English-Hindi samples, experimenting with data ratios.", "result": "Improved multilingual performance without compromising native performance, outperforming larger models.", "conclusion": "Modest fine-tuning with culturally informed data can bridge performance gaps efficiently; resources released for further research."}}
{"id": "2503.05066", "pdf": "https://arxiv.org/pdf/2503.05066", "abs": "https://arxiv.org/abs/2503.05066", "authors": ["Shwai He", "Weilin Cai", "Jiayi Huang", "Ang Li"], "title": "Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of Experts", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The Mixture of Experts (MoE) is an effective architecture for scaling large\nlanguage models by leveraging sparse expert activation, optimizing the\ntrade-off between performance and efficiency. However, under expert\nparallelism, MoE suffers from inference inefficiencies due to imbalanced\ntoken-to-expert assignment, where some experts are overloaded while others\nremain underutilized. This imbalance leads to poor resource utilization and\nincreased latency, as the most burdened expert dictates the overall delay, a\nphenomenon we define as the \\textbf{\\textit{Straggler Effect}}. To mitigate\nthis, we propose Capacity-Aware Inference, including two key techniques: (1)\n\\textbf{\\textit{Capacity-Aware Token Drop}}, which discards overloaded tokens\nto regulate the maximum latency of MoE, and (2) \\textbf{\\textit{Capacity-Aware\nToken Reroute}}, which reallocates overflowed tokens to underutilized experts,\nbalancing the token distribution. These techniques collectively optimize both\nhigh-load and low-load expert utilization, leading to a more efficient MoE\ninference pipeline. Extensive experiments demonstrate the effectiveness of our\nmethods, showing significant improvements in inference efficiency, e.g., 0.2\\%\naverage performance increase and a 1.94$\\times$ inference speedup on\nMixtral-8$\\times$7B-Instruct.", "AI": {"tldr": "The paper addresses the inefficiency in Mixture of Experts (MoE) inference due to imbalanced token-to-expert assignments, proposing Capacity-Aware Inference with token drop and reroute techniques to improve speed and resource utilization.", "motivation": "MoE's inference inefficiency stems from the Straggler Effect, where imbalanced token assignments cause some experts to be overloaded, leading to poor resource use and higher latency.", "method": "Proposes Capacity-Aware Inference: (1) Capacity-Aware Token Drop to discard overloaded tokens, and (2) Capacity-Aware Token Reroute to redistribute tokens to underutilized experts.", "result": "Experiments show a 0.2% performance increase and 1.94\u00d7 inference speedup on Mixtral-8\u00d77B-Instruct.", "conclusion": "The proposed techniques effectively mitigate the Straggler Effect, enhancing MoE inference efficiency."}}
{"id": "2502.00775", "pdf": "https://arxiv.org/pdf/2502.00775", "abs": "https://arxiv.org/abs/2502.00775", "authors": ["Artavazd Maranjyan", "El Mehdi Saad", "Peter Richt\u00e1rik", "Francesco Orabona"], "title": "ATA: Adaptive Task Allocation for Efficient Resource Management in Distributed Machine Learning", "categories": ["cs.LG", "cs.DC", "math.OC", "stat.ML"], "comment": null, "summary": "Asynchronous methods are fundamental for parallelizing computations in\ndistributed machine learning. They aim to accelerate training by fully\nutilizing all available resources. However, their greedy approach can lead to\ninefficiencies using more computation than required, especially when\ncomputation times vary across devices. If the computation times were known in\nadvance, training could be fast and resource-efficient by assigning more tasks\nto faster workers. The challenge lies in achieving this optimal allocation\nwithout prior knowledge of the computation time distributions. In this paper,\nwe propose ATA (Adaptive Task Allocation), a method that adapts to\nheterogeneous and random distributions of worker computation times. Through\nrigorous theoretical analysis, we show that ATA identifies the optimal task\nallocation and performs comparably to methods with prior knowledge of\ncomputation times. Experimental results further demonstrate that ATA is\nresource-efficient, significantly reducing costs compared to the greedy\napproach, which can be arbitrarily expensive depending on the number of\nworkers.", "AI": {"tldr": "ATA (Adaptive Task Allocation) optimizes task distribution in distributed machine learning by adapting to unknown worker computation times, outperforming greedy methods in efficiency and cost.", "motivation": "Asynchronous methods in distributed machine learning often waste resources due to unpredictable computation times across devices. ATA aims to optimize task allocation without prior knowledge of these times.", "method": "ATA dynamically adapts task allocation based on observed worker computation times, achieving near-optimal performance without requiring prior knowledge.", "result": "Theoretical and experimental results show ATA matches the performance of methods with prior knowledge and significantly reduces resource costs compared to greedy approaches.", "conclusion": "ATA provides an efficient, adaptive solution for task allocation in distributed learning, mitigating the inefficiencies of greedy methods."}}
{"id": "2505.15267", "pdf": "https://arxiv.org/pdf/2505.15267", "abs": "https://arxiv.org/abs/2505.15267", "authors": ["Wenmin Li", "Shunsuke Sakai", "Tatsuhito Hasegawa"], "title": "Contrastive Learning-Enhanced Trajectory Matching for Small-Scale Dataset Distillation", "categories": ["cs.CV"], "comment": "Under review", "summary": "Deploying machine learning models in resource-constrained environments, such\nas edge devices or rapid prototyping scenarios, increasingly demands\ndistillation of large datasets into significantly smaller yet informative\nsynthetic datasets. Current dataset distillation techniques, particularly\nTrajectory Matching methods, optimize synthetic data so that the model's\ntraining trajectory on synthetic samples mirrors that on real data. While\ndemonstrating efficacy on medium-scale synthetic datasets, these methods fail\nto adequately preserve semantic richness under extreme sample scarcity. To\naddress this limitation, we propose a novel dataset distillation method\nintegrating contrastive learning during image synthesis. By explicitly\nmaximizing instance-level feature discrimination, our approach produces more\ninformative and diverse synthetic samples, even when dataset sizes are\nsignificantly constrained. Experimental results demonstrate that incorporating\ncontrastive learning substantially enhances the performance of models trained\non very small-scale synthetic datasets. This integration not only guides more\neffective feature representation but also significantly improves the visual\nfidelity of the synthesized images. Experimental results demonstrate that our\nmethod achieves notable performance improvements over existing distillation\ntechniques, especially in scenarios with extremely limited synthetic data.", "AI": {"tldr": "A novel dataset distillation method integrates contrastive learning to enhance synthetic data quality under extreme sample scarcity, outperforming existing techniques.", "motivation": "Current dataset distillation methods fail to preserve semantic richness in very small datasets, limiting their effectiveness in resource-constrained environments.", "method": "The proposed method combines contrastive learning with image synthesis to maximize instance-level feature discrimination, improving diversity and informativeness of synthetic samples.", "result": "The approach significantly boosts model performance and visual fidelity on small-scale synthetic datasets, outperforming existing methods.", "conclusion": "Integrating contrastive learning in dataset distillation enhances feature representation and synthetic data quality, especially in extreme scarcity scenarios."}}
{"id": "2504.10063", "pdf": "https://arxiv.org/pdf/2504.10063", "abs": "https://arxiv.org/abs/2504.10063", "authors": ["Alexandra Bazarova", "Aleksandr Yugay", "Andrey Shulga", "Alina Ermilova", "Andrei Volodichev", "Konstantin Polev", "Julia Belikova", "Rauf Parchiev", "Dmitry Simakov", "Maxim Savchenko", "Andrey Savchenko", "Serguei Barannikov", "Alexey Zaytsev"], "title": "Hallucination Detection in LLMs with Topological Divergence on Attention Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hallucination, i.e., generating factually incorrect content, remains a\ncritical challenge for large language models (LLMs). We introduce TOHA, a\nTOpology-based HAllucination detector in the RAG setting, which leverages a\ntopological divergence metric to quantify the structural properties of graphs\ninduced by attention matrices. Examining the topological divergence between\nprompt and response subgraphs reveals consistent patterns: higher divergence\nvalues in specific attention heads correlate with hallucinated outputs,\nindependent of the dataset. Extensive experiments - including evaluation on\nquestion answering and summarization tasks - show that our approach achieves\nstate-of-the-art or competitive results on several benchmarks while requiring\nminimal annotated data and computational resources. Our findings suggest that\nanalyzing the topological structure of attention matrices can serve as an\nefficient and robust indicator of factual reliability in LLMs.", "AI": {"tldr": "TOHA detects hallucinations in LLMs using topological divergence of attention matrices, achieving competitive results with minimal resources.", "motivation": "Hallucination in LLMs generates factually incorrect content, posing a critical challenge.", "method": "TOHA uses a topological divergence metric to analyze structural properties of graphs from attention matrices, comparing prompt and response subgraphs.", "result": "Higher divergence in specific attention heads correlates with hallucinations. TOHA achieves state-of-the-art results on QA and summarization tasks.", "conclusion": "Topological analysis of attention matrices is an efficient and robust indicator of factual reliability in LLMs."}}
{"id": "2503.11617", "pdf": "https://arxiv.org/pdf/2503.11617", "abs": "https://arxiv.org/abs/2503.11617", "authors": ["Xinyi Wang", "Jiashui Wang", "Jinbo Su", "Ke Wang", "Peng Chen", "Yanming Liu", "Long Liu", "Xiang Li", "Yangdong Wang", "Qiyuan Chen", "Rongze Chen", "Chunfu Jia"], "title": "ASMA-Tune: Unlocking LLMs' Assembly Code Comprehension via Structural-Semantic Instruction Tuning", "categories": ["cs.SE", "cs.AI"], "comment": "9 pages, multiple figures", "summary": "Assembly code analysis and comprehension play critical roles in applications\nlike reverse engineering, yet they face substantial challenges due to low\ninformation density and a lack of explicit syntactic structures. While\ntraditional masked language modeling (MLM) approaches do not explicitly focus\non natural language interaction, emerging decoder-focused large language models\n(LLMs) demonstrate partial success in binary analysis yet remain underexplored\nfor holistic comprehension. We present Assembly Augmented Tuning, an end-to-end\nstructural-semantic instruction tuning framework that synergizes encoder\narchitecture with decoder-based LLMs through a projector module, where the\nassembly encoder extracts hardware-level structural features, the projector\nbridges representations with the semantic space, and the instruction-tuned LLM\npreserves natural language capabilities. Experimental results demonstrate three\nkey advantages: (1) State-of-the-art performance in assembly comprehension with\n+39.7% Recall@1 and +17.8% MRR improvements over GPT-4-Turbo, (2) Consistent\nenhancements across base models (24.6-107.4% Recall@1 and 15.2-106.3% MRR on\nQwen2.5-Coder, Deepseek-Coder and CodeLlama variants), and (3) Superior\ninstruction-following capabilities (41.5%-118% improvements) with controlled\ncode generation degradation (-8.9% to -35% across architectures).", "AI": {"tldr": "Assembly Augmented Tuning improves assembly code comprehension by combining encoder and decoder LLMs, outperforming GPT-4-Turbo and other models.", "motivation": "Addressing challenges in assembly code analysis due to low information density and lack of explicit structures, leveraging LLMs for better comprehension.", "method": "Proposes Assembly Augmented Tuning, integrating an assembly encoder, projector module, and instruction-tuned LLM to bridge structural and semantic features.", "result": "Achieves state-of-the-art performance (+39.7% Recall@1, +17.8% MRR over GPT-4-Turbo) and consistent enhancements across base models.", "conclusion": "The framework excels in assembly comprehension and instruction-following while minimizing code generation degradation."}}
{"id": "2502.01171", "pdf": "https://arxiv.org/pdf/2502.01171", "abs": "https://arxiv.org/abs/2502.01171", "authors": ["Erpai Luo", "Xinran Wei", "Lin Huang", "Yunyang Li", "Han Yang", "Zaishuo Xia", "Zun Wang", "Chang Liu", "Bin Shao", "Jia Zhang"], "title": "Efficient and Scalable Density Functional Theory Hamiltonian Prediction through Adaptive Sparsity", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Hamiltonian matrix prediction is pivotal in computational chemistry, serving\nas the foundation for determining a wide range of molecular properties. While\nSE(3) equivariant graph neural networks have achieved remarkable success in\nthis domain, their substantial computational cost--driven by high-order tensor\nproduct (TP) operations--restricts their scalability to large molecular systems\nwith extensive basis sets. To address this challenge, we introduce SPHNet, an\nefficient and scalable equivariant network, that incorporates adaptive SParsity\ninto Hamiltonian prediction. SPHNet employs two innovative sparse gates to\nselectively constrain non-critical interaction combinations, significantly\nreducing tensor product computations while maintaining accuracy. To optimize\nthe sparse representation, we develop a Three-phase Sparsity Scheduler,\nensuring stable convergence and achieving high performance at sparsity rates of\nup to 70%. Extensive evaluations on QH9 and PubchemQH datasets demonstrate that\nSPHNet achieves state-of-the-art accuracy while providing up to a 7x speedup\nover existing models. Beyond Hamiltonian prediction, the proposed\nsparsification techniques also hold significant potential for improving the\nefficiency and scalability of other SE(3) equivariant networks, further\nbroadening their applicability and impact. Our code can be found at\nhttps://github.com/microsoft/SPHNet.", "AI": {"tldr": "SPHNet introduces adaptive sparsity to reduce computational costs in SE(3) equivariant networks for Hamiltonian matrix prediction, achieving high accuracy and speedup.", "motivation": "High computational costs of SE(3) equivariant networks limit scalability for large molecular systems.", "method": "SPHNet uses sparse gates and a Three-phase Sparsity Scheduler to selectively reduce tensor product operations.", "result": "Achieves state-of-the-art accuracy with up to 7x speedup on QH9 and PubchemQH datasets.", "conclusion": "SPHNet's sparsification techniques improve efficiency and scalability of SE(3) equivariant networks, broadening their applicability."}}
{"id": "2505.15358", "pdf": "https://arxiv.org/pdf/2505.15358", "abs": "https://arxiv.org/abs/2505.15358", "authors": ["Angelique Mangubat", "Shane Gilroy"], "title": "Objective Bicycle Occlusion Level Classification using a Deformable Parts-Based Model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Road safety is a critical challenge, particularly for cyclists, who are among\nthe most vulnerable road users. This study aims to enhance road safety by\nproposing a novel benchmark for bicycle occlusion level classification using\nadvanced computer vision techniques. Utilizing a parts-based detection model,\nimages are annotated and processed through a custom image detection pipeline. A\nnovel method of bicycle occlusion level is proposed to objectively quantify the\nvisibility and occlusion level of bicycle semantic parts. The findings indicate\nthat the model robustly quantifies the visibility and occlusion level of\nbicycles, a significant improvement over the subjective methods used by the\ncurrent state of the art. Widespread use of the proposed methodology will\nfacilitate accurate performance reporting of cyclist detection algorithms for\noccluded cyclists, informing the development of more robust vulnerable road\nuser detection methods for autonomous vehicles.", "AI": {"tldr": "A novel benchmark for bicycle occlusion level classification using computer vision improves cyclist safety by objectively quantifying visibility and occlusion.", "motivation": "Enhancing road safety for cyclists, who are vulnerable road users, by addressing the challenge of occlusion in cyclist detection.", "method": "Utilizes a parts-based detection model and custom image detection pipeline to classify bicycle occlusion levels.", "result": "The model robustly quantifies bicycle visibility and occlusion, outperforming current subjective methods.", "conclusion": "The proposed methodology can improve cyclist detection algorithms, aiding autonomous vehicle safety systems."}}
{"id": "2504.11952", "pdf": "https://arxiv.org/pdf/2504.11952", "abs": "https://arxiv.org/abs/2504.11952", "authors": ["Ram Mohan Rao Kadiyala", "Siddartha Pullakhandam", "Kanwal Mehreen", "Drishti Sharma", "Siddhant Gupta", "Jebish Purbey", "Ashay Srivastava", "Subhasya TippaReddy", "Arvind Reddy Bobbili", "Suraj Telugara Chandrashekhar", "Modabbir Adeeb", "Srinadh Vura", "Hamza Farooq"], "title": "Robust and Fine-Grained Detection of AI Generated Texts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "18 pages, 6 figures", "summary": "An ideal detection system for machine generated content is supposed to work\nwell on any generator as many more advanced LLMs come into existence day by\nday. Existing systems often struggle with accurately identifying AI-generated\ncontent over shorter texts. Further, not all texts might be entirely authored\nby a human or LLM, hence we focused more over partial cases i.e human-LLM\nco-authored texts. Our paper introduces a set of models built for the task of\ntoken classification which are trained on an extensive collection of\nhuman-machine co-authored texts, which performed well over texts of unseen\ndomains, unseen generators, texts by non-native speakers and those with\nadversarial inputs. We also introduce a new dataset of over 2.4M such texts\nmostly co-authored by several popular proprietary LLMs over 23 languages. We\nalso present findings of our models' performance over each texts of each domain\nand generator. Additional findings include comparison of performance against\neach adversarial method, length of input texts and characteristics of generated\ntexts compared to the original human authored texts.", "AI": {"tldr": "A token classification model for detecting human-LLM co-authored texts, trained on a large dataset, performs well across diverse conditions including unseen domains, generators, and adversarial inputs.", "motivation": "Existing systems struggle with detecting AI-generated content in short or partially co-authored texts, necessitating a more robust solution.", "method": "Developed token classification models trained on a dataset of 2.4M human-LLM co-authored texts across 23 languages.", "result": "Models performed well on unseen domains, generators, non-native texts, and adversarial inputs. Detailed performance metrics by domain, generator, and adversarial method are provided.", "conclusion": "The introduced models and dataset offer a robust solution for detecting human-LLM co-authored texts, addressing limitations of existing systems."}}
{"id": "2503.17682", "pdf": "https://arxiv.org/pdf/2503.17682", "abs": "https://arxiv.org/abs/2503.17682", "authors": ["Jiaming Ji", "Xinyu Chen", "Rui Pan", "Conghui Zhang", "Han Zhu", "Jiahao Li", "Donghai Hong", "Boyuan Chen", "Jiayi Zhou", "Kaile Wang", "Juntao Dai", "Chi-Min Chan", "Yida Tang", "Sirui Han", "Yike Guo", "Yaodong Yang"], "title": "Safe RLHF-V: Safe Reinforcement Learning from Multi-modal Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) are essential for building\ngeneral-purpose AI assistants; however, they pose increasing safety risks. How\ncan we ensure safety alignment of MLLMs to prevent undesired behaviors? Going\nfurther, it is critical to explore how to fine-tune MLLMs to preserve\ncapabilities while meeting safety constraints. Fundamentally, this challenge\ncan be formulated as a min-max optimization problem. However, existing datasets\nhave not yet disentangled single preference signals into explicit safety\nconstraints, hindering systematic investigation in this direction. Moreover, it\nremains an open question whether such constraints can be effectively\nincorporated into the optimization process for multi-modal models. In this\nwork, we present the first exploration of the Safe RLHF-V -- the first\nmultimodal safety alignment framework. The framework consists of:\n$\\mathbf{(I)}$ BeaverTails-V, the first open-source dataset featuring dual\npreference annotations for helpfulness and safety, supplemented with\nmulti-level safety labels (minor, moderate, severe); $\\mathbf{(II)}$\nBeaver-Guard-V, a multi-level guardrail system to proactively defend against\nunsafe queries and adversarial attacks. Applying the guard model over five\nrounds of filtering and regeneration significantly enhances the precursor\nmodel's overall safety by an average of 40.9%. $\\mathbf{(III)}$ Based on dual\npreference, we initiate the first exploration of multi-modal safety alignment\nwithin a constrained optimization. Experimental results demonstrate that Safe\nRLHF effectively improves both model helpfulness and safety. Specifically, Safe\nRLHF-V enhances model safety by 34.2% and helpfulness by 34.3%.", "AI": {"tldr": "The paper introduces Safe RLHF-V, a multimodal safety alignment framework, addressing safety risks in MLLMs through a dataset (BeaverTails-V), a guardrail system (Beaver-Guard-V), and constrained optimization, improving safety and helpfulness.", "motivation": "Multimodal large language models (MLLMs) pose safety risks, necessitating alignment to prevent undesired behaviors while preserving capabilities. Existing datasets lack disentangled safety constraints, and their integration into optimization for multimodal models is unexplored.", "method": "The framework includes: (I) BeaverTails-V dataset with dual preference annotations and multi-level safety labels, (II) Beaver-Guard-V guardrail system for proactive defense, and (III) constrained optimization for multimodal safety alignment.", "result": "Safe RLHF-V improves model safety by 34.2% and helpfulness by 34.3%, with Beaver-Guard-V enhancing precursor model safety by 40.9% over five filtering rounds.", "conclusion": "Safe RLHF-V successfully addresses safety alignment in MLLMs, demonstrating significant improvements in both safety and helpfulness through a systematic framework."}}
{"id": "2502.05075", "pdf": "https://arxiv.org/pdf/2502.05075", "abs": "https://arxiv.org/abs/2502.05075", "authors": ["Yijun Dong", "Yicheng Li", "Yunai Li", "Jason D. Lee", "Qi Lei"], "title": "Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": "ICML 2025", "summary": "Weak-to-strong (W2S) generalization is a type of finetuning (FT) where a\nstrong (large) student model is trained on pseudo-labels generated by a weak\nteacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek to\nunderstand this phenomenon through the observation that FT often occurs in\nintrinsically low-dimensional spaces. Leveraging the low intrinsic\ndimensionality of FT, we analyze W2S in the ridgeless regression setting from a\nvariance reduction perspective. For a strong student-weak teacher pair with\nsufficiently expressive low-dimensional feature subspaces $\\mathcal{V}_s,\n\\mathcal{V}_w$, we provide an exact characterization of the variance that\ndominates the generalization error of W2S. This unveils a virtue of discrepancy\nbetween the strong and weak models in W2S: the variance of the weak teacher is\ninherited by the strong student in $\\mathcal{V}_s \\cap \\mathcal{V}_w$, while\nreduced by a factor of $\\dim(\\mathcal{V}_s)/N$ in the subspace of discrepancy\n$\\mathcal{V}_w \\setminus \\mathcal{V}_s$ with $N$ pseudo-labels for W2S. Our\nanalysis further casts light on the sample complexities and the scaling of\nperformance gap recovery in W2S. The analysis is supported by experiments on\nsynthetic regression problems, as well as real vision and NLP tasks.", "AI": {"tldr": "Weak-to-strong (W2S) generalization improves performance by finetuning a strong model on weak pseudo-labels, leveraging low-dimensional subspaces to reduce variance.", "motivation": "To understand why W2S finetuning outperforms the weak teacher, focusing on the role of low-dimensional feature spaces.", "method": "Analyzes W2S in ridgeless regression, characterizing variance reduction in shared and discrepant subspaces of strong and weak models.", "result": "Variance is inherited in shared subspaces but reduced in discrepant ones, with performance gap recovery scaling with sample size.", "conclusion": "W2S benefits from model discrepancy and low-dimensionality, supported by experiments on synthetic and real-world tasks."}}
{"id": "2505.15441", "pdf": "https://arxiv.org/pdf/2505.15441", "abs": "https://arxiv.org/abs/2505.15441", "authors": ["David Nordstr\u00f6m", "Johan Edstedt", "Fredrik Kahl", "Georg B\u00f6kman"], "title": "Stronger ViTs With Octic Equivariance", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent efforts at scaling computer vision models have established Vision\nTransformers (ViTs) as the leading architecture. ViTs incorporate weight\nsharing over image patches as an important inductive bias. In this work, we\nshow that ViTs benefit from incorporating equivariance under the octic group,\ni.e., reflections and 90-degree rotations, as a further inductive bias. We\ndevelop new architectures, octic ViTs, that use octic-equivariant layers and\nput them to the test on both supervised and self-supervised learning. Through\nextensive experiments on DeiT-III and DINOv2 training on ImageNet-1K, we show\nthat octic ViTs yield more computationally efficient networks while also\nimproving performance. In particular, we achieve approximately 40% reduction in\nFLOPs for ViT-H while simultaneously improving both classification and\nsegmentation results.", "AI": {"tldr": "Optic ViTs, incorporating octic-equivariant layers, improve efficiency and performance in vision tasks, reducing FLOPs by 40% for ViT-H.", "motivation": "To enhance Vision Transformers (ViTs) by integrating equivariance under the octic group (reflections and 90-degree rotations) as an inductive bias.", "method": "Develop octic ViTs with octic-equivariant layers and evaluate them on supervised and self-supervised learning tasks using DeiT-III and DINOv2 on ImageNet-1K.", "result": "40% reduction in FLOPs for ViT-H, with improved classification and segmentation performance.", "conclusion": "Optic ViTs offer a computationally efficient and high-performing alternative to traditional ViTs."}}
{"id": "2504.12816", "pdf": "https://arxiv.org/pdf/2504.12816", "abs": "https://arxiv.org/abs/2504.12816", "authors": ["Xue Wen Tan", "Stanley Kok"], "title": "SMARTe: Slot-based Method for Accountable Relational Triple extraction", "categories": ["cs.CL"], "comment": null, "summary": "Relational Triple Extraction (RTE) is a fundamental task in Natural Language\nProcessing (NLP). However, prior research has primarily focused on optimizing\nmodel performance, with limited efforts to understand the internal mechanisms\ndriving these models. Many existing methods rely on complex preprocessing to\ninduce specific interactions, often resulting in opaque systems that may not\nfully align with their theoretical foundations. To address these limitations,\nwe propose SMARTe: a Slot-based Method for Accountable Relational Triple\nextraction. SMARTe introduces intrinsic interpretability through a slot\nattention mechanism and frames the task as a set prediction problem. Slot\nattention consolidates relevant information into distinct slots, ensuring all\npredictions can be explicitly traced to learned slot representations and the\ntokens contributing to each predicted relational triple. While emphasizing\ninterpretability, SMARTe achieves performance comparable to state-of-the-art\nmodels. Evaluations on the NYT and WebNLG datasets demonstrate that adding\ninterpretability does not compromise performance. Furthermore, we conducted\nqualitative assessments to showcase the explanations provided by SMARTe, using\nattention heatmaps that map to their respective tokens. We conclude with a\ndiscussion of our findings and propose directions for future research.", "AI": {"tldr": "SMARTe is a slot-based method for relational triple extraction that emphasizes interpretability without sacrificing performance, using slot attention for traceable predictions.", "motivation": "Prior RTE research focused on performance optimization, lacking understanding of internal model mechanisms and interpretability.", "method": "SMARTe uses slot attention to consolidate information into distinct slots, framing RTE as a set prediction problem for traceable results.", "result": "SMARTe matches state-of-the-art performance on NYT and WebNLG datasets while providing interpretability via attention heatmaps.", "conclusion": "SMARTe successfully balances interpretability and performance, with qualitative assessments validating its explanations. Future research directions are proposed."}}
{"id": "2504.00485", "pdf": "https://arxiv.org/pdf/2504.00485", "abs": "https://arxiv.org/abs/2504.00485", "authors": ["Mahade Hasan", "Farhana Yasmin", "Xue Yu"], "title": "Stroke Disease Classification Using Machine Learning with Feature Selection Techniques", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Heart disease remains a leading cause of mortality and morbidity worldwide,\nnecessitating the development of accurate and reliable predictive models to\nfacilitate early detection and intervention. While state of the art work has\nfocused on various machine learning approaches for predicting heart disease,\nbut they could not able to achieve remarkable accuracy. In response to this\nneed, we applied nine machine learning algorithms XGBoost, logistic regression,\ndecision tree, random forest, k-nearest neighbors (KNN), support vector machine\n(SVM), gaussian na\\\"ive bayes (NB gaussian), adaptive boosting, and linear\nregression to predict heart disease based on a range of physiological\nindicators. Our approach involved feature selection techniques to identify the\nmost relevant predictors, aimed at refining the models to enhance both\nperformance and interpretability. The models were trained, incorporating\nprocesses such as grid search hyperparameter tuning, and cross-validation to\nminimize overfitting. Additionally, we have developed a novel voting system\nwith feature selection techniques to advance heart disease classification.\nFurthermore, we have evaluated the models using key performance metrics\nincluding accuracy, precision, recall, F1-score, and the area under the\nreceiver operating characteristic curve (ROC AUC). Among the models, XGBoost\ndemonstrated exceptional performance, achieving 99% accuracy, precision,\nF1-Score, 98% recall, and 100% ROC AUC. This study offers a promising approach\nto early heart disease diagnosis and preventive healthcare.", "AI": {"tldr": "The paper evaluates nine ML algorithms for heart disease prediction, with XGBoost achieving 99% accuracy and other high metrics.", "motivation": "Heart disease is a major global health issue, and existing ML models lack sufficient accuracy for reliable early detection.", "method": "Applied nine ML algorithms with feature selection, hyperparameter tuning, and a novel voting system. Evaluated using accuracy, precision, recall, F1-score, and ROC AUC.", "result": "XGBoost outperformed others with 99% accuracy, precision, F1-score, 98% recall, and 100% ROC AUC.", "conclusion": "The study presents a highly accurate approach for early heart disease diagnosis, enhancing preventive healthcare."}}
{"id": "2502.07480", "pdf": "https://arxiv.org/pdf/2502.07480", "abs": "https://arxiv.org/abs/2502.07480", "authors": ["Daniel Barzilai", "Guy Kornowski", "Ohad Shamir"], "title": "Beyond Benign Overfitting in Nadaraya-Watson Interpolators", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": "26 pages", "summary": "In recent years, there has been much interest in understanding the\ngeneralization behavior of interpolating predictors, which overfit on noisy\ntraining data. Whereas standard analyses are concerned with whether a method is\nconsistent or not, recent observations have shown that even inconsistent\npredictors can generalize well. In this work, we revisit the classic\ninterpolating Nadaraya-Watson (NW) estimator (also known as Shepard's method),\nand study its generalization capabilities through this modern viewpoint. In\nparticular, by varying a single bandwidth-like hyperparameter, we prove the\nexistence of multiple overfitting behaviors, ranging non-monotonically from\ncatastrophic, through benign, to tempered. Our results highlight how even\nclassical interpolating methods can exhibit intricate generalization behaviors.\nIn addition, for the purpose of tuning the hyperparameter, the results suggest\nthat over-estimating the intrinsic dimension of the data is less harmful than\nunder-estimating it. Numerical experiments complement our theory, demonstrating\nthe same phenomena.", "AI": {"tldr": "The paper revisits the Nadaraya-Watson estimator to explore its generalization behavior, revealing multiple overfitting patterns and suggesting hyperparameter tuning insights.", "motivation": "To understand the generalization behavior of interpolating predictors, particularly the Nadaraya-Watson estimator, in the context of noisy training data.", "method": "Analyzing the NW estimator by varying a bandwidth-like hyperparameter to study its generalization capabilities.", "result": "Identifies multiple overfitting behaviors (catastrophic, benign, tempered) and suggests over-estimating data's intrinsic dimension is safer for tuning.", "conclusion": "Classical interpolating methods exhibit complex generalization behaviors, with hyperparameter tuning insights for practical applications."}}
{"id": "2203.09749", "pdf": "https://arxiv.org/pdf/2203.09749", "abs": "https://arxiv.org/abs/2203.09749", "authors": ["Heecheol Kim", "Yoshiyuki Ohmura", "Yasuo Kuniyoshi"], "title": "Goal-conditioned dual-action imitation learning for dexterous dual-arm robot manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "19 pages, published in Transactions on Robotics (T-RO)", "summary": "Long-horizon dexterous robot manipulation of deformable objects, such as\nbanana peeling, is a problematic task because of the difficulties in object\nmodeling and a lack of knowledge about stable and dexterous manipulation\nskills. This paper presents a goal-conditioned dual-action (GC-DA) deep\nimitation learning (DIL) approach that can learn dexterous manipulation skills\nusing human demonstration data. Previous DIL methods map the current sensory\ninput and reactive action, which often fails because of compounding errors in\nimitation learning caused by the recurrent computation of actions. The method\npredicts reactive action only when the precise manipulation of the target\nobject is required (local action) and generates the entire trajectory when\nprecise manipulation is not required (global action). This dual-action\nformulation effectively prevents compounding error in the imitation learning\nusing the trajectory-based global action while responding to unexpected changes\nin the target object during the reactive local action. The proposed method was\ntested in a real dual-arm robot and successfully accomplished the\nbanana-peeling task. Data from this and related works are available at:\nhttps://sites.google.com/view/multi-task-fine.", "AI": {"tldr": "A goal-conditioned dual-action (GC-DA) deep imitation learning (DIL) approach is proposed to tackle long-horizon dexterous robot manipulation of deformable objects like banana peeling, addressing challenges in object modeling and manipulation skills.", "motivation": "The difficulties in modeling deformable objects and lack of stable manipulation skills for tasks like banana peeling motivate the development of a more robust learning method.", "method": "The GC-DA DIL approach uses human demonstrations to learn skills, combining reactive local actions for precise manipulation and trajectory-based global actions to avoid compounding errors.", "result": "The method was successfully tested on a dual-arm robot, accomplishing the banana-peeling task.", "conclusion": "The GC-DA DIL approach effectively prevents compounding errors and adapts to unexpected changes, demonstrating success in complex manipulation tasks."}}
{"id": "2504.15253", "pdf": "https://arxiv.org/pdf/2504.15253", "abs": "https://arxiv.org/abs/2504.15253", "authors": ["Yilun Zhou", "Austin Xu", "Peifeng Wang", "Caiming Xiong", "Shafiq Joty"], "title": "Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as Test-Time Scaling Evaluators", "categories": ["cs.CL", "cs.LG"], "comment": "ICML 2025. The first two authors contributed equally. The codebase is\n  at https://github.com/SalesforceAIResearch/jetts-benchmark", "summary": "Scaling test-time computation, or affording a generator large language model\n(LLM) extra compute during inference, typically employs the help of external\nnon-generative evaluators (i.e., reward models). Concurrently, LLM-judges,\nmodels trained to generate evaluations and critiques (explanations) in natural\nlanguage, are becoming increasingly popular in automatic evaluation. Despite\njudge empirical successes, their effectiveness as evaluators in test-time\nscaling settings is largely unknown. In this paper, we introduce the Judge\nEvaluation for Test-Time Scaling (JETTS) benchmark, which evaluates judge\nperformance in three domains (math reasoning, code generation, and instruction\nfollowing) under three task settings: response reranking, step-level beam\nsearch, and critique-based response refinement. We evaluate 10 different judge\nmodels (7B-70B parameters) for 8 different base generator models (6.7B-72B\nparameters). Our benchmark shows that while judges are competitive with outcome\nreward models in reranking, they are consistently worse than process reward\nmodels in beam search procedures. Furthermore, though unique to LLM-judges,\ntheir natural language critiques are currently ineffective in guiding the\ngenerator towards better responses.", "AI": {"tldr": "The paper introduces the JETTS benchmark to evaluate LLM-judges in test-time scaling settings, comparing them to reward models across three domains and task settings. Findings show judges are competitive in reranking but underperform in beam search and critique-based refinement.", "motivation": "To assess the effectiveness of LLM-judges as evaluators in test-time scaling settings, given their growing popularity but unclear performance compared to reward models.", "method": "The JETTS benchmark evaluates 10 judge models and 8 base generator models across math reasoning, code generation, and instruction following, under reranking, beam search, and critique-based refinement tasks.", "result": "Judges are competitive with outcome reward models in reranking but consistently worse than process reward models in beam search. Natural language critiques are ineffective for response refinement.", "conclusion": "LLM-judges show promise in reranking but require improvement for beam search and critique-based tasks to match process reward models."}}
{"id": "2504.05295", "pdf": "https://arxiv.org/pdf/2504.05295", "abs": "https://arxiv.org/abs/2504.05295", "authors": ["Kwangjun Ahn", "Byron Xu", "Natalie Abreu", "John Langford"], "title": "Dion: Distributed Orthonormalized Updates", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": "\"Version 2\" with more experimental results and algorithmic details.\n  Comments would be appreciated!", "summary": "Recent work has shown that orthonormal matrix updates speed up neural network\noptimization, improve training stability, and offer better hyperparameter\ntransfer across model sizes. Applying these updates efficiently when model\nweights and optimizer states are sharded across a large-scale distributed LLM\ntraining system remains a major challenge. We introduce Dion (DIstributed\nOrthoNormalization), a scalable and communication-efficient orthonormalizing\noptimizer. Dion leverages low-rank approximation and decoupled momentum\nbuffers, eliminating the need for full gradient synchronization while producing\nnumerically equivalent results. It is compatible with simultaneous DDP, FSDP,\nand TP parallelism, and it computes an orthonormalized update without\nunsharding a full parameter matrix on any single device. We evaluate Dion on\nlanguage models from 120M to 3B parameters and find that its benefits improve\nwith increasing model size and batch size.", "AI": {"tldr": "Dion (DIstributed OrthoNormalization) is a scalable optimizer for large-scale distributed LLM training, enabling efficient orthonormal matrix updates without full gradient synchronization.", "motivation": "Orthonormal matrix updates improve neural network optimization but are challenging to apply efficiently in distributed training systems.", "method": "Dion uses low-rank approximation and decoupled momentum buffers to avoid full gradient synchronization while maintaining numerical equivalence. It works with DDP, FSDP, and TP parallelism.", "result": "Dion's benefits scale with model and batch size, as shown in evaluations on models from 120M to 3B parameters.", "conclusion": "Dion is a practical solution for efficient orthonormal updates in distributed LLM training, with advantages growing for larger models."}}
{"id": "2502.08206", "pdf": "https://arxiv.org/pdf/2502.08206", "abs": "https://arxiv.org/abs/2502.08206", "authors": ["Abdelkrim Alahyane", "C\u00e9line Comte", "Matthieu Jonckheere", "\u00c9ric Moulines"], "title": "Optimizing Asynchronous Federated Learning: A~Delicate Trade-Off Between Model-Parameter Staleness and Update Frequency", "categories": ["cs.LG", "cs.PF", "math.OC", "math.PR"], "comment": null, "summary": "Synchronous federated learning (FL) scales poorly with the number of clients\ndue to the straggler effect. Algorithms like FedAsync and GeneralizedFedAsync\naddress this limitation by enabling asynchronous communication between clients\nand the central server. In this work, we rely on stochastic modeling and\nanalysis to better understand the impact of design choices in asynchronous FL\nalgorithms, such as the concurrency level and routing probabilities, and we\nleverage this knowledge to optimize loss. Compared to most existing studies, we\naccount for the joint impact of heterogeneous and variable service speeds and\nheterogeneous datasets at the clients. We characterize in particular a\nfundamental trade-off for optimizing asynchronous FL: minimizing gradient\nestimation errors by avoiding model parameter staleness, while also speeding up\nthe system by increasing the throughput of model updates. Our two main\ncontributions can be summarized as follows. First, we prove a discrete variant\nof Little's law to derive a closed-form expression for relative delay, a metric\nthat quantifies staleness. This allows us to efficiently minimize the average\nloss per model update, which has been the gold standard in literature to date.\nSecond, we observe that naively optimizing this metric leads us to slow down\nthe system drastically by overemphazing staleness at the detriment of\nthroughput. This motivates us to introduce an alternative metric that also\ntakes system speed into account, for which we derive a tractable upper-bound\nthat can be minimized numerically. Extensive numerical results show that these\noptimizations enhance accuracy by 10% to 30%.", "AI": {"tldr": "The paper analyzes asynchronous federated learning (FL) to address the straggler effect, optimizing design choices like concurrency and routing to balance gradient staleness and system throughput, improving accuracy by 10-30%.", "motivation": "Synchronous FL scales poorly due to stragglers; asynchronous methods like FedAsync exist but lack understanding of design impacts. This work aims to model and optimize these choices.", "method": "Uses stochastic modeling to analyze asynchronous FL, focusing on concurrency and routing. Introduces metrics for staleness and throughput, optimizing loss via closed-form expressions and numerical bounds.", "result": "Proves a discrete Little's law variant for staleness, optimizes loss per update, and introduces a new metric balancing staleness and throughput, achieving 10-30% accuracy gains.", "conclusion": "Optimizing asynchronous FL requires balancing staleness and throughput; the proposed metrics and methods significantly improve accuracy."}}
{"id": "2301.11201", "pdf": "https://arxiv.org/pdf/2301.11201", "abs": "https://arxiv.org/abs/2301.11201", "authors": ["Tom\u00e1\u0161 Dlask", "Bogdan Savchynskyy"], "title": "Relative-Interior Solution for the (Incomplete) Linear Assignment Problem with Applications to the Quadratic Assignment Problem", "categories": ["math.OC", "cs.CV"], "comment": null, "summary": "We study the set of optimal solutions of the dual linear programming\nformulation of the linear assignment problem (LAP) to propose a method for\ncomputing a solution from the relative interior of this set. Assuming that an\narbitrary dual-optimal solution and an optimal assignment are available (for\nwhich many efficient algorithms already exist), our method computes a\nrelative-interior solution in linear time. Since the LAP occurs as a subproblem\nin the linear programming (LP) relaxation of the quadratic assignment problem\n(QAP), we employ our method as a new component in the family of dual-ascent\nalgorithms that provide bounds on the optimal value of the QAP. To make our\nresults applicable to the incomplete QAP, which is of interest in practical\nuse-cases, we also provide a linear-time reduction from the incomplete LAP to\nthe complete LAP along with a mapping that preserves optimality and membership\nin the relative interior. Our experiments on publicly available benchmarks\nindicate that our approach with relative-interior solution can frequently\nprovide bounds near the optimum of the LP relaxation and its runtime is much\nlower when compared to a commercial LP solver.", "AI": {"tldr": "A method for computing a relative-interior solution of the dual LAP is proposed, leveraging existing dual-optimal solutions and assignments. Applied to QAP, it improves bounds efficiently.", "motivation": "To enhance dual-ascent algorithms for QAP by efficiently computing relative-interior solutions of the dual LAP.", "method": "Uses existing dual-optimal solutions and assignments to compute relative-interior solutions in linear time, extending to incomplete QAP via a reduction.", "result": "Provides near-optimal bounds for QAP LP relaxation with lower runtime than commercial solvers.", "conclusion": "The method is efficient and practical for improving QAP bounds, especially in incomplete cases."}}
{"id": "2504.16084", "pdf": "https://arxiv.org/pdf/2504.16084", "abs": "https://arxiv.org/abs/2504.16084", "authors": ["Yuxin Zuo", "Kaiyan Zhang", "Li Sheng", "Shang Qu", "Ganqu Cui", "Xuekai Zhu", "Haozhan Li", "Yuchen Zhang", "Xinwei Long", "Ermo Hua", "Biqing Qi", "Youbang Sun", "Zhiyuan Ma", "Lifan Yuan", "Ning Ding", "Bowen Zhou"], "title": "TTRL: Test-Time Reinforcement Learning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper investigates Reinforcement Learning (RL) on data without explicit\nlabels for reasoning tasks in Large Language Models (LLMs). The core challenge\nof the problem is reward estimation during inference while not having access to\nground-truth information. While this setting appears elusive, we find that\ncommon practices in Test-Time Scaling (TTS), such as majority voting, yield\nsurprisingly effective rewards suitable for driving RL training. In this work,\nwe introduce Test-Time Reinforcement Learning (TTRL), a novel method for\ntraining LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs\nby utilizing the priors in the pre-trained models. Our experiments demonstrate\nthat TTRL consistently improves performance across a variety of tasks and\nmodels. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by\napproximately 211% on the AIME 2024 with only unlabeled test data. Furthermore,\nalthough TTRL is only supervised by the maj@n metric, TTRL has demonstrated\nperformance to consistently surpass the upper limit of the initial model maj@n,\nand approach the performance of models trained directly on test data with\nground-truth labels. Our experimental findings validate the general\neffectiveness of TTRL across various tasks and highlight TTRL's potential for\nbroader tasks and domains. GitHub: https://github.com/PRIME-RL/TTRL", "AI": {"tldr": "TTRL is a novel RL method for training LLMs on unlabeled data, using majority voting for reward estimation, and shows significant performance improvements.", "motivation": "To address the challenge of reward estimation in RL for LLMs without ground-truth labels.", "method": "Introduces Test-Time Reinforcement Learning (TTRL), leveraging majority voting (maj@n) for reward estimation and pre-trained model priors.", "result": "TTRL improves pass@1 performance by ~211% on AIME 2024 and surpasses initial model limits.", "conclusion": "TTRL is effective for RL on unlabeled data, with potential for broader applications."}}
{"id": "2504.05585", "pdf": "https://arxiv.org/pdf/2504.05585", "abs": "https://arxiv.org/abs/2504.05585", "authors": ["Yuxuan Li", "Yicheng Gao", "Ning Yang", "Stephen Xia"], "title": "TW-CRL: Time-Weighted Contrastive Reward Learning for Efficient Inverse Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Episodic tasks in Reinforcement Learning (RL) often pose challenges due to\nsparse reward signals and high-dimensional state spaces, which hinder efficient\nlearning. Additionally, these tasks often feature hidden \"trap states\" --\nirreversible failures that prevent task completion but do not provide explicit\nnegative rewards to guide agents away from repeated errors. To address these\nissues, we propose Time-Weighted Contrastive Reward Learning (TW-CRL), an\nInverse Reinforcement Learning (IRL) framework that leverages both successful\nand failed demonstrations. By incorporating temporal information, TW-CRL learns\na dense reward function that identifies critical states associated with success\nor failure. This approach not only enables agents to avoid trap states but also\nencourages meaningful exploration beyond simple imitation of expert\ntrajectories. Empirical evaluations on navigation tasks and robotic\nmanipulation benchmarks demonstrate that TW-CRL surpasses state-of-the-art\nmethods, achieving improved efficiency and robustness.", "AI": {"tldr": "TW-CRL, an IRL framework, uses time-weighted contrastive learning to derive dense rewards from both successful and failed demonstrations, improving RL performance in episodic tasks with sparse rewards and trap states.", "motivation": "Episodic RL tasks suffer from sparse rewards and hidden trap states, making learning inefficient. Existing methods lack mechanisms to avoid irreversible failures without explicit negative rewards.", "method": "TW-CRL employs Inverse Reinforcement Learning with temporal weighting to learn dense rewards from diverse demonstrations, identifying critical states for success or failure.", "result": "TW-CRL outperforms state-of-the-art methods in navigation and robotic manipulation tasks, showing better efficiency and robustness.", "conclusion": "TW-CRL effectively addresses sparse rewards and trap states in RL, enhancing learning through dense reward signals and improved exploration."}}
{"id": "2502.12413", "pdf": "https://arxiv.org/pdf/2502.12413", "abs": "https://arxiv.org/abs/2502.12413", "authors": ["Jiaqi Wang", "Yuhang Zhou", "Zhixiong Zhang", "Qiguang Chen", "Yongqiang Chen", "James Cheng"], "title": "DivIL: Unveiling and Addressing Over-Invariance for Out-of- Distribution Generalization", "categories": ["cs.LG"], "comment": null, "summary": "Out-of-distribution generalization is a common problem that expects the model\nto perform well in the different distributions even far from the train data. A\npopular approach to addressing this issue is invariant learning (IL), in which\nthe model is compiled to focus on invariant features instead of spurious\nfeatures by adding strong constraints during training. However, there are some\npotential pitfalls of strong invariant constraints. Due to the limited number\nof diverse environments and over-regularization in the feature space, it may\nlead to a loss of important details in the invariant features while alleviating\nthe spurious correlations, namely the over-invariance, which can also degrade\nthe generalization performance. We theoretically define the over-invariance and\nobserve that this issue occurs in various classic IL methods. To alleviate this\nissue, we propose a simple approach Diverse Invariant Learning (DivIL) by\nadding the unsupervised contrastive learning and the random masking mechanism\ncompensatory for the invariant constraints, which can be applied to various IL\nmethods. Furthermore, we conduct experiments across multiple modalities across\n12 datasets and 6 classic models, verifying our over-invariance insight and the\neffectiveness of our DivIL framework. Our code is available at\nhttps://github.com/kokolerk/DivIL.", "AI": {"tldr": "The paper addresses over-invariance in invariant learning (IL) for out-of-distribution generalization, proposing DivIL to mitigate it with contrastive learning and random masking.", "motivation": "Over-invariance in IL methods can degrade generalization by losing important invariant features due to strong constraints.", "method": "Proposes Diverse Invariant Learning (DivIL), combining unsupervised contrastive learning and random masking to compensate for invariant constraints.", "result": "Experiments on 12 datasets and 6 models validate the over-invariance issue and DivIL's effectiveness.", "conclusion": "DivIL successfully mitigates over-invariance, improving generalization across diverse datasets and models."}}
{"id": "2409.10339", "pdf": "https://arxiv.org/pdf/2409.10339", "abs": "https://arxiv.org/abs/2409.10339", "authors": ["Aaron Mark Thomas", "Harry Youel", "Sharu Theresa Jose"], "title": "VAE-QWGAN: Addressing Mode Collapse in Quantum GANs via Autoencoding Priors", "categories": ["quant-ph", "cs.CV", "cs.LG"], "comment": "30 pages, 13 figures", "summary": "Recent proposals for quantum generative adversarial networks (GANs) suffer\nfrom the issue of mode collapse, analogous to classical GANs, wherein the\ndistribution learnt by the GAN fails to capture the high mode complexities of\nthe target distribution. Mode collapse can arise due to the use of uninformed\nprior distributions in the generative learning task. To alleviate the issue of\nmode collapse for quantum GANs, this work presents a novel \\textbf{hybrid\nquantum-classical generative model}, the VAE-QWGAN, which combines the\nstrengths of a classical Variational AutoEncoder (VAE) with a hybrid Quantum\nWasserstein GAN (QWGAN). The VAE-QWGAN fuses the VAE decoder and QWGAN\ngenerator into a single quantum model, and utilizes the VAE encoder for\ndata-dependant latent vector sampling during training. This in turn, enhances\nthe diversity and quality of generated images. To generate new data from the\ntrained model at inference, we sample from a Gaussian mixture model (GMM) prior\nthat is learnt on the latent vectors generated during training. We conduct\nextensive experiments for image generation QGANs on MNIST/Fashion-MNIST\ndatasets and compute a range of metrics that measure the diversity and quality\nof generated samples. We show that VAE-QWGAN demonstrates significant\nimprovement over existing QGAN approaches.", "AI": {"tldr": "A hybrid quantum-classical generative model (VAE-QWGAN) is proposed to address mode collapse in quantum GANs by combining a classical VAE with a quantum Wasserstein GAN, improving diversity and quality of generated images.", "motivation": "Mode collapse in quantum GANs, similar to classical GANs, leads to poor capture of target distribution complexities. Uninformed priors exacerbate this issue.", "method": "The VAE-QWGAN integrates a VAE decoder and QWGAN generator into a single quantum model, using the VAE encoder for data-dependent latent vector sampling. A Gaussian mixture model (GMM) prior is learned for inference.", "result": "Experiments on MNIST/Fashion-MNIST show VAE-QWGAN outperforms existing QGANs in diversity and quality metrics.", "conclusion": "VAE-QWGAN effectively mitigates mode collapse, offering a robust solution for quantum generative tasks."}}
{"id": "2504.19110", "pdf": "https://arxiv.org/pdf/2504.19110", "abs": "https://arxiv.org/abs/2504.19110", "authors": ["Huajian Xin", "Luming Li", "Xiaoran Jin", "Jacques Fleuriot", "Wenda Li"], "title": "APE-Bench I: Towards File-level Automated Proof Engineering of Formal Math Libraries", "categories": ["cs.CL"], "comment": null, "summary": "Recent progress in large language models (LLMs) has shown promise in formal\ntheorem proving, yet existing benchmarks remain limited to isolated, static\nproof tasks, failing to capture the iterative, engineering-intensive workflows\nof real-world formal mathematics libraries. Motivated by analogous advances in\nsoftware engineering, we introduce the paradigm of Automated Proof Engineering\n(APE), which aims to automate proof engineering tasks such as feature addition,\nproof refactoring, and bug fixing using LLMs. To facilitate research in this\ndirection, we present APE-Bench I, the first realistic benchmark built from\nreal-world commit histories of Mathlib4, featuring diverse file-level tasks\ndescribed in natural language and verified via a hybrid approach combining the\nLean compiler and LLM-as-a-Judge. We further develop Eleanstic, a scalable\nparallel verification infrastructure optimized for proof checking across\nmultiple versions of Mathlib. Empirical results on state-of-the-art LLMs\ndemonstrate strong performance on localized edits but substantial degradation\non handling complex proof engineering. This work lays the foundation for\ndeveloping agentic workflows in proof engineering, with future benchmarks\ntargeting multi-file coordination, project-scale verification, and autonomous\nagents capable of planning, editing, and repairing formal libraries.", "AI": {"tldr": "The paper introduces Automated Proof Engineering (APE) to automate proof tasks using LLMs, presents APE-Bench I for realistic benchmarking, and highlights challenges in complex proof engineering.", "motivation": "Existing benchmarks for LLMs in theorem proving are limited to static tasks, missing real-world iterative workflows. The goal is to automate proof engineering tasks like feature addition and bug fixing.", "method": "APE-Bench I is created from Mathlib4 commit histories, featuring file-level tasks verified via Lean compiler and LLM-as-a-Judge. Eleanstic, a parallel verification infrastructure, is developed for scalable proof checking.", "result": "State-of-the-art LLMs perform well on localized edits but struggle with complex proof engineering tasks.", "conclusion": "The work sets the foundation for agentic workflows in proof engineering, with future benchmarks targeting multi-file coordination and autonomous agents."}}
{"id": "2504.05695", "pdf": "https://arxiv.org/pdf/2504.05695", "abs": "https://arxiv.org/abs/2504.05695", "authors": ["Thomas Chen", "Chun-Kai Kevin Chien", "Patricia Mu\u00f1oz Ewald", "Andrew G. Moore"], "title": "Architecture independent generalization bounds for overparametrized deep ReLU networks", "categories": ["cs.LG", "cs.AI", "math.AP", "math.OC", "stat.ML", "57R70, 62M45"], "comment": "AMS Latex, 13 pages. Both main theorems are now in Section 1", "summary": "We prove that overparametrized neural networks are able to generalize with a\ntest error that is independent of the level of overparametrization, and\nindependent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds\nthat only depend on the metric geometry of the test and training sets, on the\nregularity properties of the activation function, and on the operator norms of\nthe weights and norms of biases. For overparametrized deep ReLU networks with a\ntraining sample size bounded by the input space dimension, we explicitly\nconstruct zero loss minimizers without use of gradient descent, and prove that\nthe generalization error is independent of the network architecture.", "AI": {"tldr": "Overparametrized neural networks generalize well, with test error independent of overparametrization and VC dimension, relying on data geometry and network properties.", "motivation": "To understand how overparametrized neural networks generalize despite high complexity and lack of dependence on VC dimension.", "method": "Explicit bounds based on metric geometry of data, activation function regularity, and weight norms. Construct zero-loss minimizers for ReLU networks without gradient descent.", "result": "Generalization error is independent of network architecture, with bounds tied to data geometry and network properties.", "conclusion": "Overparametrization in neural networks can lead to good generalization without reliance on traditional complexity measures like VC dimension."}}
{"id": "2502.16772", "pdf": "https://arxiv.org/pdf/2502.16772", "abs": "https://arxiv.org/abs/2502.16772", "authors": ["Alireza Kazemipour", "Simone Parisi", "Matthew E. Taylor", "Michael Bowling"], "title": "Model-Based Exploration in Truthful Monitored Markov Decision Processes", "categories": ["cs.LG"], "comment": null, "summary": "A tenet of reinforcement learning is that the agent always observes rewards.\nHowever, this is not true in many realistic settings, e.g., a human observer\nmay not always be available to provide rewards, sensors may be limited or\nmalfunctioning, or rewards may be inaccessible during deployment. Monitored\nMarkov decision processes (Mon-MDPs) have recently been proposed to model such\nsettings. However, existing Mon-MDP algorithms have several limitations: they\ndo not fully exploit the problem structure, cannot leverage a known monitor,\nlack worst-case guarantees for 'unsolvable' Mon-MDPs without specific\ninitialization, and offer only asymptotic convergence proofs. This paper makes\nthree contributions. First, we introduce a model-based algorithm for Mon-MDPs\nthat addresses these shortcomings. The algorithm employs two instances of\nmodel-based interval estimation: one to ensure that observable rewards are\nreliably captured, and another to learn the minimax-optimal policy. Second, we\nempirically demonstrate the advantages. We show faster convergence than prior\nalgorithms in over four dozen benchmarks, and even more dramatic improvement\nwhen the monitoring process is known. Third, we present the first finite-sample\nbound on performance. We show convergence to a minimax-optimal policy even when\nsome rewards are never observable.", "AI": {"tldr": "The paper introduces a model-based algorithm for Monitored Markov Decision Processes (Mon-MDPs) to address limitations of existing methods, offering faster convergence, leveraging known monitors, and providing finite-sample guarantees.", "motivation": "Existing Mon-MDP algorithms fail to exploit problem structure, lack worst-case guarantees, and have only asymptotic convergence proofs. This work aims to overcome these limitations.", "method": "A model-based algorithm using two instances of model-based interval estimation: one for capturing observable rewards and another for learning the minimax-optimal policy.", "result": "Faster convergence in benchmarks, especially with known monitors, and finite-sample performance bounds.", "conclusion": "The proposed algorithm improves upon prior work by addressing key limitations and providing theoretical and empirical advantages."}}
{"id": "2501.08575", "pdf": "https://arxiv.org/pdf/2501.08575", "abs": "https://arxiv.org/abs/2501.08575", "authors": ["Donghwi Jung", "Keonwoo Kim", "Seong-Woo Kim"], "title": "GOTPR: General Outdoor Text-based Place Recognition Using Scene Graph Retrieval with OpenStreetMap", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "We propose GOTPR, a robust place recognition method designed for outdoor\nenvironments where GPS signals are unavailable. Unlike existing approaches that\nuse point cloud maps, which are large and difficult to store, GOTPR leverages\nscene graphs generated from text descriptions and maps for place recognition.\nThis method improves scalability by replacing point clouds with compact data\nstructures, allowing robots to efficiently store and utilize extensive map\ndata. In addition, GOTPR eliminates the need for custom map creation by using\npublicly available OpenStreetMap data, which provides global spatial\ninformation. We evaluated its performance using the KITTI360Pose dataset with\ncorresponding OpenStreetMap data, comparing it to existing point cloud-based\nplace recognition methods. The results show that GOTPR achieves comparable\naccuracy while significantly reducing storage requirements. In city-scale\ntests, it completed processing within a few seconds, making it highly practical\nfor real-world robotics applications. More information can be found at\nhttps://donghwijung.github.io/GOTPR_page/.", "AI": {"tldr": "GOTPR is a scalable place recognition method for GPS-denied outdoor environments, using scene graphs from text and maps instead of point clouds, reducing storage needs while maintaining accuracy.", "motivation": "Existing point cloud-based methods are storage-intensive and impractical for large-scale use. GOTPR aims to address this by leveraging compact data structures and publicly available maps.", "method": "GOTPR uses scene graphs derived from text descriptions and OpenStreetMap data for place recognition, eliminating the need for custom maps.", "result": "GOTPR matches the accuracy of point cloud methods but significantly reduces storage and processing time, completing city-scale tests in seconds.", "conclusion": "GOTPR is a practical, efficient solution for outdoor place recognition, suitable for real-world robotics applications."}}
{"id": "2504.21800", "pdf": "https://arxiv.org/pdf/2504.21800", "abs": "https://arxiv.org/abs/2504.21800", "authors": ["Suhas BN", "Dominik Mattioli", "Saeed Abdullah", "Rosa I. Arriaga", "Chris W. Wiese", "Andrew M. Sherrill"], "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "68T50", "I.2.7; H.3.1"], "comment": "10 pages, 5 tables", "summary": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. Synthetic therapy dialogues closely match structural\nfeatures of real-world conversations (e.g., speaker switch ratio: 0.98 vs.\n0.99); however, they may not adequately reflect key fidelity markers (e.g.,\ndistress monitoring). We highlight gaps in existing evaluation frameworks and\nadvocate for fidelity-aware metrics that go beyond surface fluency to uncover\nclinically significant failures. Our findings clarify where synthetic data can\neffectively complement real-world datasets -- and where critical limitations\nremain.", "AI": {"tldr": "Synthetic PE therapy dialogues for PTSD are explored as a scalable alternative to real-world data, showing promise for privacy and scalability but struggling with therapeutic fidelity.", "motivation": "Address privacy concerns, limited real-world data access, and high annotation costs in healthcare by using synthetic data for clinical model training.", "method": "Compare real and synthetic dialogues using linguistic, structural, and PE-specific metrics, including turn-taking and treatment fidelity.", "result": "Synthetic data matches structural features (e.g., speaker switch ratio) but lacks fidelity in distress monitoring and other clinical markers.", "conclusion": "Synthetic data can complement real-world datasets but requires fidelity-aware metrics to address clinical limitations."}}
{"id": "2504.08859", "pdf": "https://arxiv.org/pdf/2504.08859", "abs": "https://arxiv.org/abs/2504.08859", "authors": ["Fanmeng Wang", "Wentao Guo", "Qi Ou", "Hongshuai Wang", "Haitao Lin", "Hongteng Xu", "Zhifeng Gao"], "title": "PolyConf: Unlocking Polymer Conformation Generation through Hierarchical Generative Models", "categories": ["cond-mat.soft", "cs.AI"], "comment": "Accepted by the 42nd International Conference on Machine Learning\n  (ICML 2025)", "summary": "Polymer conformation generation is a critical task that enables atomic-level\nstudies of diverse polymer materials. While significant advances have been made\nin designing conformation generation methods for small molecules and proteins,\nthese methods struggle to generate polymer conformations due to their unique\nstructural characteristics. Meanwhile, the scarcity of polymer conformation\ndatasets further limits the progress, making this important area largely\nunexplored. In this work, we propose PolyConf, a pioneering tailored polymer\nconformation generation method that leverages hierarchical generative models to\nunlock new possibilities. Specifically, we decompose the polymer conformation\ninto a series of local conformations (i.e., the conformations of its repeating\nunits), generating these local conformations through an autoregressive model,\nand then generating their orientation transformations via a diffusion model to\nassemble them into the complete polymer conformation. Moreover, we develop the\nfirst benchmark with a high-quality polymer conformation dataset derived from\nmolecular dynamics simulations to boost related research in this area. The\ncomprehensive evaluation demonstrates that PolyConf consistently outperforms\nexisting conformation generation methods, thus facilitating advancements in\npolymer modeling and simulation.", "AI": {"tldr": "PolyConf is a new method for generating polymer conformations using hierarchical generative models, outperforming existing methods and supported by a novel benchmark dataset.", "motivation": "Existing methods for small molecules and proteins fail for polymers due to their unique structures, and the lack of datasets hinders progress.", "method": "PolyConf decomposes polymers into repeating units, generates local conformations autoregressively, and assembles them using a diffusion model.", "result": "PolyConf outperforms existing methods, validated by a new high-quality dataset from molecular dynamics simulations.", "conclusion": "PolyConf advances polymer modeling by addressing key challenges in conformation generation and providing a benchmark for future research."}}
{"id": "2502.20167", "pdf": "https://arxiv.org/pdf/2502.20167", "abs": "https://arxiv.org/abs/2502.20167", "authors": ["Allen Schmaltz"], "title": "Similarity-Distance-Magnitude Universal Verification", "categories": ["cs.LG", "cs.CL"], "comment": "36 pages (1 Figure, 8 Tables, 4 Algorithms, 5 Listings)", "summary": "We address the neural network robustness problem by adding Similarity (i.e.,\ncorrectly predicted depth-matches into training)-awareness and\nDistance-to-training-distribution-awareness to the existing output Magnitude\n(i.e., decision-boundary)-awareness of the softmax function. The resulting SDM\nactivation function provides strong signals of the relative epistemic\n(reducible) predictive uncertainty. We use this novel behavior to further\naddress the complementary HCI problem of mapping the output to\nhuman-interpretable summary statistics over relevant partitions of a held-out\ncalibration set. Estimates of prediction-conditional uncertainty are obtained\nvia a parsimonious learned transform over the class-conditional empirical CDFs\nof the output of a final-layer SDM activation function. For decision-making and\nas an intrinsic model check, estimates of class-conditional accuracy are\nobtained by further partitioning the high-probability regions of this\ncalibrated output into class-conditional, region-specific CDFs. The uncertainty\nestimates from SDM calibration are remarkably robust to test-time distribution\nshifts and out-of-distribution inputs; incorporate awareness of the effective\nsample size; provide estimates of uncertainty from the learning and data\nsplitting processes; and are well-suited for selective classification and\nconditional branching for additional test-time compute based on the predictive\nuncertainty, as for selective LLM generation, routing, and composition over\nmultiple models and retrieval. Finally, we construct SDM networks, LLMs with\nuncertainty-aware verification and interpretability-by-exemplar as intrinsic\nproperties. We provide open-source software implementing these results.", "AI": {"tldr": "The paper introduces the SDM activation function to improve neural network robustness by incorporating similarity and distance-awareness, alongside existing magnitude-awareness, to better estimate predictive uncertainty. It also addresses human-interpretable uncertainty mapping and demonstrates robustness to distribution shifts.", "motivation": "To enhance neural network robustness and provide interpretable uncertainty estimates by integrating similarity, distance, and magnitude-awareness into the softmax function.", "method": "Develops the SDM activation function, which combines similarity, distance, and magnitude-awareness. Uses a learned transform over class-conditional empirical CDFs for uncertainty estimation.", "result": "SDM calibration provides robust uncertainty estimates, handles distribution shifts, and supports selective classification and conditional branching.", "conclusion": "The SDM function improves uncertainty estimation and interpretability, with applications in selective classification and LLMs, supported by open-source implementation."}}
{"id": "2502.00622", "pdf": "https://arxiv.org/pdf/2502.00622", "abs": "https://arxiv.org/abs/2502.00622", "authors": ["Han Qi", "Haocheng Yin", "Aris Zhu", "Yilun Du", "Heng Yang"], "title": "Strengthening Generative Robot Policies through Predictive World Modeling", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Website: https://computationalrobotics.seas.harvard.edu/GPC", "summary": "We present generative predictive control (GPC), a learning control framework\nthat (i) clones a generative diffusion-based policy from expert demonstrations,\n(ii) trains a predictive action-conditioned world model from both expert\ndemonstrations and random explorations, and (iii) synthesizes an online planner\nthat ranks and optimizes the action proposals from (i) by looking ahead into\nthe future using the world model from (ii). Across a variety of robotic\nmanipulation tasks, we demonstrate that GPC consistently outperforms behavior\ncloning in both state-based and vision-based settings, in simulation and in the\nreal world.", "AI": {"tldr": "GPC is a learning control framework combining generative diffusion-based policy cloning, predictive world modeling, and online planning to outperform behavior cloning in robotic tasks.", "motivation": "To improve robotic manipulation performance by integrating generative policies and predictive world models for better decision-making.", "method": "Clones a generative diffusion-based policy from expert data, trains an action-conditioned world model, and synthesizes an online planner for action optimization.", "result": "GPC consistently outperforms behavior cloning in state-based and vision-based robotic tasks in simulation and real-world settings.", "conclusion": "GPC effectively enhances robotic manipulation by leveraging generative policies and predictive planning."}}
{"id": "2505.00063", "pdf": "https://arxiv.org/pdf/2505.00063", "abs": "https://arxiv.org/abs/2505.00063", "authors": ["Siqi Li", "Yufan Shen", "Xiangnan Chen", "Jiayi Chen", "Hengwei Ju", "Haodong Duan", "Song Mao", "Hongbin Zhou", "Bo Zhang", "Bin Fu", "Pinlong Cai", "Licheng Wen", "Botian Shi", "Yong Liu", "Xinyu Cai", "Yu Qiao"], "title": "GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "The rapid advancement of multimodal large language models (MLLMs) has\nprofoundly impacted the document domain, creating a wide array of application\nscenarios. This progress highlights the need for a comprehensive benchmark to\nevaluate these models' capabilities across various document-specific tasks.\nHowever, existing benchmarks often fail to locate specific model weaknesses or\nguide systematic improvements. To bridge this gap, we introduce a General\nDocument Intelligence Benchmark (GDI-Bench), featuring 2.3k images across 9 key\nscenarios and 19 document-specific tasks. By decoupling visual complexity and\nreasoning complexity, the GDI-Bench structures graded tasks that allow\nperformance assessment by difficulty, aiding in model weakness identification\nand optimization guidance. We evaluate various open-source and closed-source\nmodels on GDI-Bench, conducting decoupled analyses in the visual and reasoning\ndomains, revealing their strengths and weaknesses. To address the diverse tasks\nand domains in the GDI-Bench, we propose a GDI-Model that mitigates\ncatastrophic forgetting during the supervised fine-tuning (SFT) process through\nan intelligence-preserving training strategy, thereby reinforcing the inherent\nweaknesses of the base model. Our model achieves state-of-the-art performance\non previous benchmarks and the GDI-Bench. Both our benchmark and models are or\nwill be open-sourced on https://huggingface.co/GDIBench.", "AI": {"tldr": "The paper introduces GDI-Bench, a benchmark for evaluating multimodal large language models (MLLMs) on document-specific tasks, and proposes GDI-Model to address weaknesses, achieving state-of-the-art performance.", "motivation": "Existing benchmarks lack the ability to pinpoint model weaknesses or guide systematic improvements in document intelligence tasks.", "method": "Developed GDI-Bench with 2.3k images across 9 scenarios and 19 tasks, decoupling visual and reasoning complexity. Proposed GDI-Model with intelligence-preserving training to mitigate catastrophic forgetting.", "result": "GDI-Model outperforms existing models on GDI-Bench and previous benchmarks.", "conclusion": "GDI-Bench and GDI-Model provide a robust framework for evaluating and improving document intelligence in MLLMs, with open-sourced resources."}}
{"id": "2504.10612", "pdf": "https://arxiv.org/pdf/2504.10612", "abs": "https://arxiv.org/abs/2504.10612", "authors": ["Michal Balcerak", "Tamaz Amiranashvili", "Antonio Terpin", "Suprosanna Shit", "Lea Bogensperger", "Sebastian Kaltenbach", "Petros Koumoutsakos", "Bjoern Menze"], "title": "Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The most widely used generative models map noise and data distributions by\nmatching flows or scores. However, they struggle to incorporate partial\nobservations and additional priors--something energy-based models (EBMs) handle\nelegantly by simply adding corresponding scalar energy terms. We address this\nissue by proposing Energy Matching, a framework that endows flow-based\napproaches with the flexibility of EBMs. Far from the data manifold, samples\nmove along curl-free, optimal transport paths from noise to data. As they\napproach the data manifold, an entropic energy term guides the system into a\nBoltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 and ImageNet generation in\nterms of fidelity, while retaining simulation-free training of transport-based\napproaches away from the data manifold. Furthermore, we leverage the method's\nflexibility to introduce an interaction energy that supports diverse mode\nexploration, which we demonstrate in a controlled protein-generation setting.\nOur approach focuses on learning a scalar potential energy--without\ntime-conditioning, auxiliary generators, or additional networks--which marks a\nsignificant departure from recent EBM methods. We believe that this simplified\nframework significantly advances EBMs capabilities and paves the way for their\nwider adoption in generative modeling across diverse domains.", "AI": {"tldr": "Energy Matching integrates flow-based models with energy-based flexibility, improving generative performance and regularization for inverse problems.", "motivation": "To address the limitations of generative models in handling partial observations and additional priors, which energy-based models (EBMs) handle well.", "method": "Proposes Energy Matching, a framework combining flow-based approaches with EBM flexibility, using a scalar field for dynamic parameterization.", "result": "Outperforms existing EBMs on CIFAR-10 and ImageNet in fidelity, supports diverse mode exploration, and simplifies EBM frameworks.", "conclusion": "Energy Matching advances EBM capabilities, enabling wider adoption in generative modeling across domains."}}
{"id": "2503.00307", "pdf": "https://arxiv.org/pdf/2503.00307", "abs": "https://arxiv.org/abs/2503.00307", "authors": ["Guanghan Wang", "Yair Schiff", "Subham Sekhar Sahoo", "Volodymyr Kuleshov"], "title": "Remasking Discrete Diffusion Models with Inference-Time Scaling", "categories": ["cs.LG", "stat.ML"], "comment": "Project page: https://remdm.github.io", "summary": "Part of the success of diffusion models stems from their ability to perform\niterative refinement, i.e., repeatedly correcting outputs during generation.\nHowever, modern masked discrete diffusion lacks this capability: when a token\nis generated, it cannot be updated again, even when it introduces an error.\nHere, we address this limitation by introducing the remasking diffusion model\n(ReMDM) sampler, a method that can be applied to pretrained masked diffusion\nmodels in a principled way and that is derived from a discrete diffusion model\nwith a custom remasking backward process. Most interestingly, ReMDM endows\ndiscrete diffusion with a form of inference-time compute scaling. By increasing\nthe number of sampling steps, ReMDM generates natural language outputs that\napproach the quality of autoregressive models, whereas when the computation\nbudget is limited, ReMDM better maintains quality. ReMDM also improves sample\nquality of masked diffusion models for discretized images, and in scientific\ndomains such as molecule design, ReMDM facilitates diffusion guidance and\npushes the Pareto frontier of controllability relative to classical masking and\nuniform noise diffusion. We provide the code along with a blog post on the\nproject page: https://remdm.github.io", "AI": {"tldr": "ReMDM introduces a remasking diffusion model sampler to enable iterative refinement in masked discrete diffusion, improving output quality and controllability.", "motivation": "Modern masked discrete diffusion lacks iterative refinement, limiting its ability to correct errors during generation.", "method": "ReMDM applies a custom remasking backward process to pretrained masked diffusion models, enabling inference-time compute scaling.", "result": "ReMDM improves output quality in natural language, discretized images, and scientific domains like molecule design, while maintaining quality under limited compute.", "conclusion": "ReMDM enhances masked diffusion models by enabling iterative refinement and improving controllability, with applications across diverse domains."}}
{"id": "2503.01161", "pdf": "https://arxiv.org/pdf/2503.01161", "abs": "https://arxiv.org/abs/2503.01161", "authors": ["Wenda Chu", "Zihui Wu", "Yifan Chen", "Yang Song", "Yisong Yue"], "title": "Split Gibbs Discrete Diffusion Posterior Sampling", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We study the problem of posterior sampling in discrete-state spaces using\ndiscrete diffusion models. While posterior sampling methods for continuous\ndiffusion models have achieved remarkable progress, analogous methods for\ndiscrete diffusion models remain challenging. In this work, we introduce a\nprincipled plug-and-play discrete diffusion posterior sampling algorithm based\non split Gibbs sampling, which we call SGDD. Our algorithm enables\nreward-guided generation and solving inverse problems in discrete-state spaces.\nWe demonstrate the convergence of SGDD to the target posterior distribution and\nverify this through controlled experiments on synthetic benchmarks. Our method\nenjoys state-of-the-art posterior sampling performance on a range of benchmarks\nfor discrete data, including DNA sequence design, discrete image inverse\nproblems, and music infilling, achieving more than 30% improved performance\ncompared to existing baselines.", "AI": {"tldr": "SGDD, a plug-and-play discrete diffusion posterior sampling algorithm, improves performance by 30% over baselines in discrete-state spaces like DNA design and music infilling.", "motivation": "Posterior sampling in discrete-state spaces using discrete diffusion models is challenging compared to continuous models.", "method": "SGDD uses split Gibbs sampling for reward-guided generation and solving inverse problems.", "result": "SGDD converges to the target posterior and outperforms baselines by 30% in benchmarks.", "conclusion": "SGDD is a state-of-the-art method for discrete posterior sampling with broad applications."}}
{"id": "2505.02156", "pdf": "https://arxiv.org/pdf/2505.02156", "abs": "https://arxiv.org/abs/2505.02156", "authors": ["Minzheng Wang", "Yongbin Li", "Haobo Wang", "Xinghua Zhang", "Nan Xu", "Bingli Wu", "Fei Huang", "Haiyang Yu", "Wenji Mao"], "title": "Adaptive Thinking via Mode Policy Optimization for Social Language Agents", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Work in Progress. The code and data are available, see\n  https://github.com/MozerWang/AMPO", "summary": "Effective social intelligence simulation requires language agents to\ndynamically adjust reasoning depth, a capability notably absent in current\nstudies. Existing methods either lack this kind of reasoning capability or\nenforce Long Chain-of-Thought reasoning uniformly across all scenarios,\nresulting in excessive token usage and inflexible social simulation. To address\nthis, we propose an $\\textbf{A}$daptive $\\textbf{M}$ode $\\textbf{L}$earning\n($\\textbf{AML}$) framework in this paper, aiming to improve the adaptive\nthinking ability of language agents in dynamic social interactions. To this\nend, we first identify hierarchical thinking modes ranging from intuitive\nresponse to deep deliberation based on the cognitive control theory. We then\ndevelop the $\\textbf{A}$daptive $\\textbf{M}$ode $\\textbf{P}$olicy\n$\\textbf{O}$ptimization ($\\textbf{AMPO}$) algorithm to optimize the\ncontext-aware mode switching and reasoning. Our framework advances existing\nresearch in three key aspects: (1) Multi-granular thinking mode design, (2)\nContext-aware mode switching across social interaction, and (3) Token-efficient\nreasoning via depth-adaptive processing. Extensive experiments on social\nintelligence benchmarks verify that AML achieves 15.6% higher task performance\nthan GPT-4o. Notably, our AMPO outperforms GRPO by 7.0% with 32.8% shorter\nreasoning chains, demonstrating the advantage of adaptive thinking mode\nselection and optimization mechanism in AMPO over GRPO's fixed-depth solution.", "AI": {"tldr": "The paper proposes an Adaptive Mode Learning (AML) framework to enhance language agents' adaptive reasoning in social interactions, outperforming GPT-4o and GRPO in task performance and efficiency.", "motivation": "Current methods lack dynamic reasoning depth adjustment in social intelligence simulation, leading to inefficiency and inflexibility.", "method": "The AML framework includes hierarchical thinking modes and the AMPO algorithm for context-aware mode switching and reasoning optimization.", "result": "AML achieves 15.6% higher task performance than GPT-4o and 7.0% better than GRPO with 32.8% shorter reasoning chains.", "conclusion": "AML's adaptive thinking mode selection and optimization significantly improve social intelligence simulation efficiency and performance."}}
{"id": "2504.18078", "pdf": "https://arxiv.org/pdf/2504.18078", "abs": "https://arxiv.org/abs/2504.18078", "authors": ["Xiaolu Chen", "Chenghao Huang", "Yanru Zhang", "Hao Wang"], "title": "Privacy-Preserving Personalized Federated Learning for Distributed Photovoltaic Disaggregation under Statistical Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages", "summary": "The rapid expansion of distributed photovoltaic (PV) installations worldwide,\nmany being behind-the-meter systems, has significantly challenged energy\nmanagement and grid operations, as unobservable PV generation further\ncomplicates the supply-demand balance. Therefore, estimating this generation\nfrom net load, known as PV disaggregation, is critical. Given privacy concerns\nand the need for large training datasets, federated learning becomes a\npromising approach, but statistical heterogeneity, arising from geographical\nand behavioral variations among prosumers, poses new challenges to PV\ndisaggregation. To overcome these challenges, a privacy-preserving distributed\nPV disaggregation framework is proposed using Personalized Federated Learning\n(PFL). The proposed method employs a two-level framework that combines local\nand global modeling. At the local level, a transformer-based PV disaggregation\nmodel is designed to generate solar irradiance embeddings for representing\nlocal PV conditions. A novel adaptive local aggregation mechanism is adopted to\nmitigate the impact of statistical heterogeneity on the local model, extracting\na portion of global information that benefits the local model. At the global\nlevel, a central server aggregates information uploaded from multiple data\ncenters, preserving privacy while enabling cross-center knowledge sharing.\nExperiments on real-world data demonstrate the effectiveness of this proposed\nframework, showing improved accuracy and robustness compared to benchmark\nmethods.", "AI": {"tldr": "A privacy-preserving distributed PV disaggregation framework using Personalized Federated Learning (PFL) is proposed to address challenges in estimating behind-the-meter PV generation, improving accuracy and robustness.", "motivation": "The rapid expansion of distributed PV installations complicates energy management due to unobservable generation, necessitating accurate PV disaggregation while addressing privacy and data heterogeneity.", "method": "A two-level PFL framework combines local transformer-based models for solar irradiance embeddings and adaptive local aggregation, with global aggregation for cross-center knowledge sharing.", "result": "Experiments on real-world data show the framework outperforms benchmarks in accuracy and robustness.", "conclusion": "The proposed PFL-based framework effectively addresses privacy and heterogeneity challenges in PV disaggregation, offering a scalable solution for grid management."}}
{"id": "2503.08245", "pdf": "https://arxiv.org/pdf/2503.08245", "abs": "https://arxiv.org/abs/2503.08245", "authors": ["Petr Ry\u0161av\u00fd", "Pavel Ryt\u00ed\u0159", "Xiaoyu He", "Georgios Korpas", "Jakub Mare\u010dek"], "title": "ExMAG: Learning of Maximally Ancestral Graphs", "categories": ["cs.LG"], "comment": null, "summary": "In mixed graphs, there are both directed and undirected edges. An extension\nof acyclicity to this mixed-graph setting is known as maximally ancestral\ngraphs. This extension is of considerable interest in causal learning in the\npresence of confounders. There, directed edges represent a clear direction of\ncausality, while undirected edges represent confounding. We propose a\nscore-based branch-and-cut algorithm for learning maximally ancestral graphs.\nThe algorithm produces more accurate results than state-of-the-art methods,\nwhile being faster to run on small and medium-sized synthetic instances.", "AI": {"tldr": "A score-based branch-and-cut algorithm for learning maximally ancestral graphs in mixed graphs, outperforming state-of-the-art methods in accuracy and speed.", "motivation": "Extending acyclicity to mixed graphs (with directed and undirected edges) is crucial for causal learning, especially with confounders.", "method": "Proposes a score-based branch-and-cut algorithm for learning maximally ancestral graphs.", "result": "The algorithm is more accurate and faster than existing methods on small and medium-sized synthetic instances.", "conclusion": "The proposed algorithm effectively improves accuracy and efficiency in learning maximally ancestral graphs."}}
{"id": "2503.09449", "pdf": "https://arxiv.org/pdf/2503.09449", "abs": "https://arxiv.org/abs/2503.09449", "authors": ["Viktor Nevelius Wernholm", "Alfred W\u00e4rns\u00e4ter", "Axel Ringh"], "title": "Fast computation of the TGOSPA metric for multiple target tracking via unbalanced optimal transport", "categories": ["math.OC", "cs.CV", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures. Revision", "summary": "In multiple target tracking, it is important to be able to evaluate the\nperformance of different tracking algorithms. The trajectory generalized\noptimal sub-pattern assignment metric (TGOSPA) is a recently proposed metric\nfor such evaluations. The TGOSPA metric is computed as the solution to an\noptimization problem, but for large tracking scenarios, solving this problem\nbecomes computationally demanding. In this paper, we present an approximation\nalgorithm for evaluating the TGOSPA metric, based on casting the TGOSPA problem\nas an unbalanced multimarginal optimal transport problem. Following recent\nadvances in computational optimal transport, we introduce an entropy\nregularization and derive an iterative scheme for solving the Lagrangian dual\nof the regularized problem. Numerical results suggest that our proposed\nalgorithm is more computationally efficient than the alternative of computing\nthe exact metric using a linear programming solver, while still providing an\nadequate approximation of the metric.", "AI": {"tldr": "An approximation algorithm for the TGOSPA metric is proposed, improving computational efficiency while maintaining accuracy.", "motivation": "Evaluating tracking algorithms with TGOSPA is computationally demanding for large scenarios.", "method": "Casts TGOSPA as an unbalanced multimarginal optimal transport problem, using entropy regularization and an iterative scheme.", "result": "The algorithm is more efficient than exact computation via linear programming, with adequate approximation.", "conclusion": "The proposed method offers a practical solution for large-scale tracking evaluations."}}
{"id": "2505.02172", "pdf": "https://arxiv.org/pdf/2505.02172", "abs": "https://arxiv.org/abs/2505.02172", "authors": ["Chuck Arvin"], "title": "Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization", "categories": ["cs.CL"], "comment": "Presented as a short paper at International Conference on Artificial\n  Intelligence and Law 2025 (Chicago, IL)", "summary": "As large language models (LLMs) continue to advance in capabilities, it is\nessential to assess how they perform on established benchmarks. In this study,\nwe present a suite of experiments to assess the performance of modern LLMs\n(ranging from 3B to 90B+ parameters) on CaseHOLD, a legal benchmark dataset for\nidentifying case holdings. Our experiments demonstrate ``scaling effects'' -\nperformance on this task improves with model size, with more capable models\nlike GPT4o and AmazonNovaPro achieving macro F1 scores of 0.744 and 0.720\nrespectively. These scores are competitive with the best published results on\nthis dataset, and do not require any technically sophisticated model training,\nfine-tuning or few-shot prompting. To ensure that these strong results are not\ndue to memorization of judicial opinions contained in the training data, we\ndevelop and utilize a novel citation anonymization test that preserves semantic\nmeaning while ensuring case names and citations are fictitious. Models maintain\nstrong performance under these conditions (macro F1 of 0.728), suggesting the\nperformance is not due to rote memorization. These findings demonstrate both\nthe promise and current limitations of LLMs for legal tasks with important\nimplications for the development and measurement of automated legal analytics\nand legal benchmarks.", "AI": {"tldr": "Modern LLMs show strong performance on legal benchmarks like CaseHOLD, improving with model size, without needing fine-tuning. A novel anonymization test confirms results aren't due to memorization.", "motivation": "Assess how advanced LLMs perform on legal benchmarks to understand their capabilities and limitations for legal tasks.", "method": "Tested LLMs (3B to 90B+ parameters) on CaseHOLD, using a citation anonymization test to check for memorization.", "result": "Larger models (e.g., GPT4o, AmazonNovaPro) achieved high F1 scores (0.744, 0.720), competitive with published results. Performance remained strong (0.728 F1) under anonymization.", "conclusion": "LLMs show promise for legal tasks but have limitations, impacting automated legal analytics and benchmark development."}}
{"id": "2505.02347", "pdf": "https://arxiv.org/pdf/2505.02347", "abs": "https://arxiv.org/abs/2505.02347", "authors": ["Nilava Metya", "Arunesh Sinha"], "title": "Temporal Robustness in Discrete Time Linear Dynamical Systems", "categories": ["math.OC", "cs.AI"], "comment": null, "summary": "Discrete time linear dynamical systems, including Markov chains, have found\nmany applications. However, in some problems, there is uncertainty about the\ntime horizon for which the system runs. This creates uncertainty about the cost\n(or reward) incurred based on the state distribution when the system stops.\nGiven past data samples of how long a system ran, we propose to theoretically\nanalyze a distributional robust cost estimation task in a Wasserstein ambiguity\nset, instead of learning a probability distribution from a few samples. Towards\nthis, we show an equivalence between a discrete time Markov Chain on a\nprobability simplex and a global asymptotic stable (GAS) discrete time linear\ndynamical system, allowing us to base our study on a GAS system only. Then, we\nprovide various polynomial time algorithms and hardness results for different\ncases in our theoretical study, including a fundamental result about\nWasserstein distance based polytope.", "AI": {"tldr": "The paper analyzes distributional robust cost estimation for uncertain time horizons in discrete time linear dynamical systems, using Wasserstein ambiguity sets and polynomial-time algorithms.", "motivation": "Uncertainty about the time horizon in dynamical systems complicates cost estimation, motivating a robust approach without relying on learned distributions.", "method": "The study leverages an equivalence between Markov chains and GAS linear systems, then provides polynomial-time algorithms and hardness results for Wasserstein-based analysis.", "result": "The paper establishes theoretical foundations and computational methods for robust cost estimation, including insights into Wasserstein distance polytopes.", "conclusion": "The work offers practical tools and theoretical insights for handling uncertainty in dynamical systems, with implications for robust optimization."}}
{"id": "2504.08364", "pdf": "https://arxiv.org/pdf/2504.08364", "abs": "https://arxiv.org/abs/2504.08364", "authors": ["Marcus R\u00fcb", "Daniel Konegen", "Patrick Selle", "Axel Sikora", "Daniel Mueller-Gritschneder"], "title": "DRIP: DRop unImportant data Points -- Enhancing Machine Learning Efficiency with Grad-CAM-Based Real-Time Data Prioritization for On-Device Training", "categories": ["cs.LG"], "comment": null, "summary": "Selecting data points for model training is critical in machine learning.\nEffective selection methods can reduce the labeling effort, optimize on-device\ntraining for embedded systems with limited data storage, and enhance the model\nperformance. This paper introduces a novel algorithm that uses Grad-CAM to make\nonline decisions about retaining or discarding data points. Optimized for\nembedded devices, the algorithm computes a unique DRIP Score to quantify the\nimportance of each data point. This enables dynamic decision-making on whether\na data point should be stored for potential retraining or discarded without\ncompromising model performance. Experimental evaluations on four benchmark\ndatasets demonstrate that our approach can match or even surpass the accuracy\nof models trained on the entire dataset, all while achieving storage savings of\nup to 39\\%. To our knowledge, this is the first algorithm that makes online\ndecisions about data point retention without requiring access to the entire\ndataset.", "AI": {"tldr": "A novel algorithm uses Grad-CAM to dynamically decide data point retention for model training, optimizing storage and performance on embedded devices.", "motivation": "Reducing labeling effort, optimizing on-device training for embedded systems, and enhancing model performance by selecting critical data points.", "method": "Introduces a DRIP Score computed via Grad-CAM to quantify data point importance, enabling dynamic retention decisions without full dataset access.", "result": "Achieves accuracy matching or surpassing full-dataset training while saving up to 39% storage on four benchmark datasets.", "conclusion": "First algorithm for online data retention decisions without full dataset access, balancing performance and storage efficiency."}}
{"id": "2504.13386", "pdf": "https://arxiv.org/pdf/2504.13386", "abs": "https://arxiv.org/abs/2504.13386", "authors": ["Radek Dan\u011b\u010dek", "Carolin Schmitt", "Senya Polikovsky", "Michael J. Black"], "title": "Supervising 3D Talking Head Avatars with Analysis-by-Audio-Synthesis", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "In order to be widely applicable, speech-driven 3D head avatars must\narticulate their lips in accordance with speech, while also conveying the\nappropriate emotions with dynamically changing facial expressions. The key\nproblem is that deterministic models produce high-quality lip-sync but without\nrich expressions, whereas stochastic models generate diverse expressions but\nwith lower lip-sync quality. To get the best of both, we seek a stochastic\nmodel with accurate lip-sync. To that end, we develop a new approach based on\nthe following observation: if a method generates realistic 3D lip motions, it\nshould be possible to infer the spoken audio from the lip motion. The inferred\nspeech should match the original input audio, and erroneous predictions create\na novel supervision signal for training 3D talking head avatars with accurate\nlip-sync. To demonstrate this effect, we propose THUNDER (Talking Heads Under\nNeural Differentiable Elocution Reconstruction), a 3D talking head avatar\nframework that introduces a novel supervision mechanism via differentiable\nsound production. First, we train a novel mesh-to-speech model that regresses\naudio from facial animation. Then, we incorporate this model into a\ndiffusion-based talking avatar framework. During training, the mesh-to-speech\nmodel takes the generated animation and produces a sound that is compared to\nthe input speech, creating a differentiable analysis-by-audio-synthesis\nsupervision loop. Our extensive qualitative and quantitative experiments\ndemonstrate that THUNDER significantly improves the quality of the lip-sync of\ntalking head avatars while still allowing for generation of diverse,\nhigh-quality, expressive facial animations. The code and models will be\navailable at https://thunder.is.tue.mpg.de/", "AI": {"tldr": "THUNDER introduces a novel supervision mechanism for 3D talking head avatars, combining accurate lip-sync with expressive facial animations by using differentiable sound production.", "motivation": "Current models either produce high-quality lip-sync without rich expressions or diverse expressions with poor lip-sync. THUNDER aims to achieve both.", "method": "A mesh-to-speech model regresses audio from facial animation, integrated into a diffusion-based framework. The inferred speech is compared to input audio for supervision.", "result": "THUNDER improves lip-sync quality while enabling diverse, expressive facial animations.", "conclusion": "The approach successfully balances lip-sync accuracy and expressive diversity, with code and models made available."}}
{"id": "2505.03563", "pdf": "https://arxiv.org/pdf/2505.03563", "abs": "https://arxiv.org/abs/2505.03563", "authors": ["Cl\u00e9a Chataigner", "Rebecca Ma", "Prakhar Ganesh", "Afaf Ta\u00efk", "Elliot Creager", "Golnoosh Farnadi"], "title": "Say It Another Way: Auditing LLMs with a User-Grounded Automated Paraphrasing Framework", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are sensitive to subtle changes in prompt\nphrasing, complicating efforts to audit them reliably. Prior approaches often\nrely on arbitrary or ungrounded prompt variations, which may miss key\nlinguistic and demographic factors in real-world usage. We introduce AUGMENT\n(Automated User-Grounded Modeling and Evaluation of Natural Language\nTransformations), a framework for systematically generating and evaluating\ncontrolled, realistic prompt paraphrases based on linguistic structure and user\ndemographics. AUGMENT ensures paraphrase quality through a combination of\nsemantic, stylistic, and instruction-following criteria. In a case study on the\nBBQ dataset, we show that user-grounded paraphrasing leads to significant\nshifts in LLM performance and bias metrics across nine models. Our findings\nhighlight the need for more representative and structured approaches to prompt\nvariation in LLM auditing.", "AI": {"tldr": "AUGMENT is a framework for generating and evaluating realistic prompt paraphrases to audit LLMs systematically, addressing biases and performance shifts.", "motivation": "LLMs are sensitive to prompt phrasing, and prior methods lack grounding in real-world linguistic and demographic factors.", "method": "AUGMENT uses semantic, stylistic, and instruction-following criteria to create controlled, realistic paraphrases.", "result": "User-grounded paraphrasing significantly affects LLM performance and bias metrics in the BBQ dataset.", "conclusion": "Structured and representative prompt variation is crucial for reliable LLM auditing."}}
{"id": "2505.02435", "pdf": "https://arxiv.org/pdf/2505.02435", "abs": "https://arxiv.org/abs/2505.02435", "authors": ["Pouria Fatemi", "Ehsan Sharifian", "Mohammad Hossein Yassaee"], "title": "A New Approach to Backtracking Counterfactual Explanations: A Unified Causal Framework for Efficient Model Interpretability", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Counterfactual explanations enhance interpretability by identifying\nalternative inputs that produce different outputs, offering localized insights\ninto model decisions. However, traditional methods often neglect causal\nrelationships, leading to unrealistic examples. While newer approaches\nintegrate causality, they are computationally expensive. To address these\nchallenges, we propose an efficient method called BRACE based on backtracking\ncounterfactuals that incorporates causal reasoning to generate actionable\nexplanations. We first examine the limitations of existing methods and then\nintroduce our novel approach and its features. We also explore the relationship\nbetween our method and previous techniques, demonstrating that it generalizes\nthem in specific scenarios. Finally, experiments show that our method provides\ndeeper insights into model outputs.", "AI": {"tldr": "BRACE is an efficient method for generating counterfactual explanations with causal reasoning, addressing limitations of traditional and newer approaches.", "motivation": "Traditional counterfactual methods lack causal relationships, while newer causal methods are computationally expensive. BRACE aims to bridge this gap.", "method": "BRACE uses backtracking counterfactuals with causal reasoning to generate actionable explanations efficiently.", "result": "Experiments show BRACE provides deeper insights into model outputs and generalizes previous techniques.", "conclusion": "BRACE offers a practical and efficient solution for interpretable counterfactual explanations with causal reasoning."}}
{"id": "2504.15771", "pdf": "https://arxiv.org/pdf/2504.15771", "abs": "https://arxiv.org/abs/2504.15771", "authors": ["Assaf Gerner", "Netta Madvil", "Nadav Barak", "Alex Zaikman", "Jonatan Liberman", "Liron Hamra", "Rotem Brazilay", "Shay Tsadok", "Yaron Friedman", "Neal Harow", "Noam Bressler", "Shir Chorev", "Philip Tannor"], "title": "ORION Grounded in Context: Retrieval-Based Method for Hallucination Detection", "categories": ["cs.LG"], "comment": null, "summary": "Despite advancements in grounded content generation, production Large\nLanguage Models (LLMs) based applications still suffer from hallucinated\nanswers. We present \"Grounded in Context\" - a member of Deepchecks' ORION\n(Output Reasoning-based InspectiON) family of lightweight evaluation models. It\nis our framework for hallucination detection, designed for production-scale\nlong-context data and tailored to diverse use cases, including summarization,\ndata extraction, and RAG. Inspired by RAG architecture, our method integrates\nretrieval and Natural Language Inference (NLI) models to predict factual\nconsistency between premises and hypotheses using an encoder-based model with\nonly a 512-token context window. Our framework identifies unsupported claims\nwith an F1 score of 0.83 in RAGTruth's response-level classification task,\nmatching methods that trained on the dataset, and outperforming all comparable\nframeworks using similar-sized models.", "AI": {"tldr": "The paper introduces 'Grounded in Context,' a framework for detecting hallucinations in LLM outputs, achieving high accuracy in factual consistency tasks.", "motivation": "Addressing the issue of hallucinated answers in LLM applications despite advancements in grounded content generation.", "method": "Integrates retrieval and NLI models within a 512-token context window to predict factual consistency between premises and hypotheses.", "result": "Achieves an F1 score of 0.83 in RAGTruth's response-level classification task, outperforming comparable frameworks.", "conclusion": "The framework is effective for hallucination detection in diverse use cases like summarization and RAG."}}
{"id": "2505.15298", "pdf": "https://arxiv.org/pdf/2505.15298", "abs": "https://arxiv.org/abs/2505.15298", "authors": ["Kangan Qian", "Sicong Jiang", "Yang Zhong", "Ziang Luo", "Zilin Huang", "Tianze Zhu", "Kun Jiang", "Mengmeng Yang", "Zheng Fu", "Jinyu Miao", "Yining Shi", "He Zhe Lim", "Li Liu", "Tianbao Zhou", "Hongyi Wang", "Huang Yu", "Yifei Hu", "Guang Li", "Guang Chen", "Hao Ye", "Lijun Sun", "Diange Yang"], "title": "AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving", "categories": ["cs.RO", "cs.CL", "cs.CV"], "comment": "18 pages, 8 figures", "summary": "Vision-Language Models (VLMs) show promise for autonomous driving, yet their\nstruggle with hallucinations, inefficient reasoning, and limited real-world\nvalidation hinders accurate perception and robust step-by-step reasoning. To\novercome this, we introduce \\textbf{AgentThink}, a pioneering unified framework\nthat, for the first time, integrates Chain-of-Thought (CoT) reasoning with\ndynamic, agent-style tool invocation for autonomous driving tasks. AgentThink's\ncore innovations include: \\textbf{(i) Structured Data Generation}, by\nestablishing an autonomous driving tool library to automatically construct\nstructured, self-verified reasoning data explicitly incorporating tool usage\nfor diverse driving scenarios; \\textbf{(ii) A Two-stage Training Pipeline},\nemploying Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization\n(GRPO) to equip VLMs with the capability for autonomous tool invocation; and\n\\textbf{(iii) Agent-style Tool-Usage Evaluation}, introducing a novel\nmulti-tool assessment protocol to rigorously evaluate the model's tool\ninvocation and utilization. Experiments on the DriveLMM-o1 benchmark\ndemonstrate AgentThink significantly boosts overall reasoning scores by\n\\textbf{53.91\\%} and enhances answer accuracy by \\textbf{33.54\\%}, while\nmarkedly improving reasoning quality and consistency. Furthermore, ablation\nstudies and robust zero-shot/few-shot generalization experiments across various\nbenchmarks underscore its powerful capabilities. These findings highlight a\npromising trajectory for developing trustworthy and tool-aware autonomous\ndriving models.", "AI": {"tldr": "AgentThink integrates CoT reasoning with dynamic tool invocation for autonomous driving, improving reasoning scores by 53.91% and accuracy by 33.54%.", "motivation": "Address hallucinations, inefficient reasoning, and limited real-world validation in VLMs for autonomous driving.", "method": "Structured data generation, two-stage training (SFT with GRPO), and agent-style tool-usage evaluation.", "result": "Significant improvements in reasoning scores (53.91%) and answer accuracy (33.54%).", "conclusion": "AgentThink shows promise for developing trustworthy, tool-aware autonomous driving models."}}
{"id": "2505.05423", "pdf": "https://arxiv.org/pdf/2505.05423", "abs": "https://arxiv.org/abs/2505.05423", "authors": ["Ran Zhang", "Wei Zhao", "Lieve Macken", "Steffen Eger"], "title": "LiTransProQA: an LLM-based Literary Translation evaluation metric with Professional Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "Updated version, with examples in the appendix", "summary": "The impact of Large Language Models (LLMs) has extended into literary\ndomains. However, existing evaluation metrics prioritize mechanical accuracy\nover artistic expression and tend to overrate machine translation as being\nsuperior to human translation from experienced professionals. In the long run,\nthis bias could result in an irreversible decline in translation quality and\ncultural authenticity. In response to the urgent need for a specialized\nliterary evaluation metric, we introduce LiTransProQA, a novel, reference-free,\nLLM-based question-answering framework designed for literary translation\nevaluation. LiTransProQA uniquely integrates insights from professional\nliterary translators and researchers, focusing on critical elements in literary\nquality assessment such as literary devices, cultural understanding, and\nauthorial voice. Our extensive evaluation shows that while literary-finetuned\nXCOMET-XL yields marginal gains, LiTransProQA substantially outperforms current\nmetrics, achieving up to 0.07 gain in correlation and surpassing the best\nstate-of-the-art metrics by over 15 points in adequacy assessments.\nIncorporating professional translator insights as weights further improves\nperformance, highlighting the value of translator inputs. Notably, LiTransProQA\nreaches human-level evaluation performance comparable to trained student\nevaluators. It shows broad applicability to open-source models like\nLLaMa3.3-70b and Qwen2.5-32b, indicating its potential as an accessible and\ntraining-free tool for evaluating literary translations that require local\nprocessing due to copyright or ethical considerations. The code and datasets\nare available under: https://github.com/zhangr2021/TransProQA.", "AI": {"tldr": "LiTransProQA is a new LLM-based framework for evaluating literary translations, outperforming existing metrics by focusing on artistic expression and cultural authenticity.", "motivation": "Existing metrics favor mechanical accuracy over artistic quality, risking a decline in translation quality and cultural authenticity.", "method": "LiTransProQA integrates insights from professional translators, assessing literary devices, cultural understanding, and authorial voice.", "result": "LiTransProQA outperforms current metrics, achieving up to 0.07 gain in correlation and surpassing state-of-the-art metrics by 15+ points.", "conclusion": "LiTransProQA matches human-level performance and is applicable to open-source models, offering a training-free tool for literary translation evaluation."}}
{"id": "2505.04404", "pdf": "https://arxiv.org/pdf/2505.04404", "abs": "https://arxiv.org/abs/2505.04404", "authors": ["Jiaqi Zhu", "Shaofeng Cai", "Yanyan Shen", "Gang Chen", "Fang Deng", "Beng Chin Ooi"], "title": "In-Context Adaptation to Concept Drift for Learned Database Operations", "categories": ["cs.DB", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Machine learning has demonstrated transformative potential for database\noperations, such as query optimization and in-database data analytics. However,\ndynamic database environments, characterized by frequent updates and evolving\ndata distributions, introduce concept drift, which leads to performance\ndegradation for learned models and limits their practical applicability.\nAddressing this challenge requires efficient frameworks capable of adapting to\nshifting concepts while minimizing the overhead of retraining or fine-tuning.\n  In this paper, we propose FLAIR, an online adaptation framework that\nintroduces a new paradigm called \\textit{in-context adaptation} for learned\ndatabase operations. FLAIR leverages the inherent property of data systems,\ni.e., immediate availability of execution results for predictions, to enable\ndynamic context construction. By formalizing adaptation as $f:(\\mathbf{x} \\,|\n\\,C_t) \\to \\mathbf{y}$, with $C_t$ representing a dynamic context memory, FLAIR\ndelivers predictions aligned with the current concept, eliminating the need for\nruntime parameter optimization. To achieve this, FLAIR integrates two key\nmodules: a Task Featurization Module for encoding task-specific features into\nstandardized representations, and a Dynamic Decision Engine, pre-trained via\nBayesian meta-training, to adapt seamlessly using contextual information at\nruntime. Extensive experiments across key database tasks demonstrate that FLAIR\noutperforms state-of-the-art baselines, achieving up to 5.2x faster adaptation\nand reducing error by 22.5% for cardinality estimation.", "AI": {"tldr": "FLAIR is an online adaptation framework for learned database operations, addressing concept drift with in-context adaptation and dynamic context memory, outperforming baselines in speed and accuracy.", "motivation": "Dynamic database environments with frequent updates cause concept drift, degrading learned model performance, necessitating efficient adaptation frameworks.", "method": "FLAIR uses in-context adaptation with dynamic context memory, integrating Task Featurization and Dynamic Decision Engine modules for runtime adaptation without parameter optimization.", "result": "FLAIR achieves up to 5.2x faster adaptation and 22.5% lower error in cardinality estimation compared to state-of-the-art baselines.", "conclusion": "FLAIR effectively addresses concept drift in learned database operations, offering superior adaptation and performance."}}
{"id": "2505.05181", "pdf": "https://arxiv.org/pdf/2505.05181", "abs": "https://arxiv.org/abs/2505.05181", "authors": ["Bojian Yin", "Federico Corradi"], "title": "Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 5 figures", "summary": "Backpropagation (BP) is the cornerstone of deep learning, but its reliance on\nglobal gradient synchronization limits scalability and imposes significant\nmemory overhead. We propose Stochastic Variational Propagation (SVP), a\nscalable alternative that reframes training as hierarchical variational\ninference. SVP treats layer activations as latent variables and optimizes local\nEvidence Lower Bounds (ELBOs), enabling independent, local updates while\npreserving global coherence. However, directly applying KL divergence in\nlayer-wise ELBOs risks inter-layer's representation collapse due to excessive\ncompression. To prevent this, SVP projects activations into low-dimensional\nspaces via fixed random matrices, ensuring information preservation and\nrepresentational diversity. Combined with a feature alignment loss for\ninter-layer consistency, SVP achieves competitive accuracy with BP across\ndiverse architectures (MLPs, CNNs, Transformers) and datasets (MNIST to\nImageNet), reduces memory usage by up to 4x, and significantly improves\nscalability. More broadly, SVP introduces a probabilistic perspective to deep\nrepresentation learning, opening pathways toward more modular and interpretable\nneural network design.", "AI": {"tldr": "SVP replaces backpropagation with hierarchical variational inference, enabling local updates and reducing memory usage while maintaining accuracy.", "motivation": "Backpropagation's scalability and memory limitations hinder deep learning efficiency.", "method": "SVP treats layer activations as latent variables, optimizes local ELBOs, uses random projections to prevent collapse, and adds feature alignment for consistency.", "result": "SVP matches BP's accuracy, reduces memory by 4x, and improves scalability across architectures and datasets.", "conclusion": "SVP offers a probabilistic, scalable alternative to BP, enhancing modularity and interpretability in neural networks."}}
{"id": "2505.15810", "pdf": "https://arxiv.org/pdf/2505.15810", "abs": "https://arxiv.org/abs/2505.15810", "authors": ["Yuqi Zhou", "Sunhao Dai", "Shuai Wang", "Kaiwen Zhou", "Qinglin Jia", "Jun Xu"], "title": "GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Recent Graphical User Interface (GUI) agents replicate the R1-Zero paradigm,\ncoupling online Reinforcement Learning (RL) with explicit chain-of-thought\nreasoning prior to object grounding and thereby achieving substantial\nperformance gains. In this paper, we first conduct extensive analysis\nexperiments of three key components of that training pipeline: input design,\noutput evaluation, and policy update-each revealing distinct challenges arising\nfrom blindly applying general-purpose RL without adapting to GUI grounding\ntasks. Input design: Current templates encourage the model to generate\nchain-of-thought reasoning, but longer chains unexpectedly lead to worse\ngrounding performance. Output evaluation: Reward functions based on hit signals\nor box area allow models to exploit box size, leading to reward hacking and\npoor localization quality. Policy update: Online RL tends to overfit easy\nexamples due to biases in length and sample difficulty, leading to\nunder-optimization on harder cases. To address these issues, we propose three\ntargeted solutions. First, we adopt a Fast Thinking Template that encourages\ndirect answer generation, reducing excessive reasoning during training. Second,\nwe incorporate a box size constraint into the reward function to mitigate\nreward hacking. Third, we revise the RL objective by adjusting length\nnormalization and adding a difficulty-aware scaling factor, enabling better\noptimization on hard samples. Our GUI-G1-3B, trained on 17K public samples with\nQwen2.5-VL-3B-Instruct, achieves 90.3% accuracy on ScreenSpot and 37.1% on\nScreenSpot-Pro. This surpasses all prior models of similar size and even\noutperforms the larger UI-TARS-7B, establishing a new state-of-the-art in GUI\nagent grounding. The project repository is available at\nhttps://github.com/Yuqi-Zhou/GUI-G1.", "AI": {"tldr": "The paper identifies challenges in GUI agent grounding tasks using RL and proposes three solutions: a Fast Thinking Template, box size constraint in rewards, and a revised RL objective. Their model, GUI-G1-3B, achieves state-of-the-art performance.", "motivation": "To address issues in GUI grounding tasks where general-purpose RL leads to poor performance due to input design, output evaluation, and policy update challenges.", "method": "Proposes three solutions: Fast Thinking Template for direct answers, box size constraint in rewards, and difficulty-aware RL objective.", "result": "GUI-G1-3B achieves 90.3% accuracy on ScreenSpot and 37.1% on ScreenSpot-Pro, outperforming larger models.", "conclusion": "The proposed solutions effectively improve GUI grounding performance, setting a new benchmark for GUI agents."}}
{"id": "2505.10736", "pdf": "https://arxiv.org/pdf/2505.10736", "abs": "https://arxiv.org/abs/2505.10736", "authors": ["Ximing Dong", "Shaowei Wang", "Dayi Lin", "Ahmed E. Hassan"], "title": "Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization", "categories": ["cs.CL"], "comment": "ACL 2025, Findings", "summary": "Optimizing Large Language Model (LLM) performance requires well-crafted\nprompts, but manual prompt engineering is labor-intensive and often\nineffective. Automated prompt optimization techniques address this challenge\nbut the majority of them rely on randomly selected evaluation subsets, which\nfail to represent the full dataset, leading to unreliable evaluations and\nsuboptimal prompts. Existing coreset selection methods, designed for LLM\nbenchmarking, are unsuitable for prompt optimization due to challenges in\nclustering similar samples, high data collection costs, and the unavailability\nof performance data for new or private datasets. To overcome these issues, we\npropose IPOMP, an Iterative evaluation data selection for effective Prompt\nOptimization using real-time Model Performance. IPOMP is a two-stage approach\nthat selects representative and diverse samples using semantic clustering and\nboundary analysis, followed by iterative refinement with real-time model\nperformance data to replace redundant samples. Evaluations on the BIG-bench\ndataset show that IPOMP improves effectiveness by 1.6% to 5.3% and stability by\nat least 57% compared with SOTA baselines, with minimal computational overhead\nbelow 1%. Furthermore, the results demonstrate that our real-time\nperformance-guided refinement approach can be universally applied to enhance\nexisting coreset selection methods.", "AI": {"tldr": "IPOMP improves prompt optimization by selecting diverse, representative samples and refining them iteratively with real-time model performance, outperforming SOTA methods.", "motivation": "Manual prompt engineering is inefficient, and existing automated methods use unreliable evaluation subsets, leading to suboptimal prompts.", "method": "IPOMP uses semantic clustering and boundary analysis for sample selection, followed by iterative refinement with real-time performance data.", "result": "IPOMP improves effectiveness by 1.6% to 5.3% and stability by 57%, with minimal computational overhead (<1%).", "conclusion": "IPOMP's real-time performance-guided refinement can universally enhance coreset selection methods for prompt optimization."}}
{"id": "2505.05784", "pdf": "https://arxiv.org/pdf/2505.05784", "abs": "https://arxiv.org/abs/2505.05784", "authors": ["Yang Li", "Zhi Chen", "Steve Yang"], "title": "FlowHFT: Imitation Learning via Flow Matching Policy for Optimal High-Frequency Trading under Diverse Market Conditions", "categories": ["q-fin.TR", "cs.AI", "cs.CE", "q-fin.CP"], "comment": "16 pages, 6 figures, 7 tables, 2 algorithms", "summary": "High-frequency trading (HFT) is an investing strategy that continuously\nmonitors market states and places bid and ask orders at millisecond speeds.\nTraditional HFT approaches fit models with historical data and assume that\nfuture market states follow similar patterns. This limits the effectiveness of\nany single model to the specific conditions it was trained for. Additionally,\nthese models achieve optimal solutions only under specific market conditions,\nsuch as assumptions about stock price's stochastic process, stable order flow,\nand the absence of sudden volatility. Real-world markets, however, are dynamic,\ndiverse, and frequently volatile. To address these challenges, we propose the\nFlowHFT, a novel imitation learning framework based on flow matching policy.\nFlowHFT simultaneously learns strategies from numerous expert models, each\nproficient in particular market scenarios. As a result, our framework can\nadaptively adjust investment decisions according to the prevailing market\nstate. Furthermore, FlowHFT incorporates a grid-search fine-tuning mechanism.\nThis allows it to refine strategies and achieve superior performance even in\ncomplex or extreme market scenarios where expert strategies may be suboptimal.\nWe test FlowHFT in multiple market environments. We first show that flow\nmatching policy is applicable in stochastic market environments, thus enabling\nFlowHFT to learn trading strategies under different market conditions. Notably,\nour single framework consistently achieves performance superior to the best\nexpert for each market condition.", "AI": {"tldr": "FlowHFT is an imitation learning framework for high-frequency trading that adapts to dynamic markets by learning from multiple expert models and fine-tuning strategies for superior performance.", "motivation": "Traditional HFT models are limited by static assumptions and fail in dynamic, volatile markets. FlowHFT addresses this by leveraging diverse expert strategies.", "method": "FlowHFT uses a flow matching policy to learn from multiple expert models and incorporates grid-search fine-tuning for adaptive decision-making.", "result": "FlowHFT outperforms the best expert models in various market conditions, demonstrating adaptability and robustness.", "conclusion": "FlowHFT offers a scalable and adaptive solution for high-frequency trading in dynamic markets, overcoming limitations of traditional approaches."}}
{"id": "2505.06108", "pdf": "https://arxiv.org/pdf/2505.06108", "abs": "https://arxiv.org/abs/2505.06108", "authors": ["Lennart Justen"], "title": "LLMs Outperform Experts on Challenging Biology Benchmarks", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "This study systematically evaluates 27 frontier Large Language Models on\neight biology benchmarks spanning molecular biology, genetics, cloning,\nvirology, and biosecurity. Models from major AI developers released between\nNovember 2022 and April 2025 were assessed through ten independent runs per\nbenchmark. The findings reveal dramatic improvements in biological\ncapabilities. Top model performance increased more than 4-fold on the\nchallenging text-only subset of the Virology Capabilities Test over the study\nperiod, with OpenAI's o3 now performing twice as well as expert virologists.\nSeveral models now match or exceed expert-level performance on other\nchallenging benchmarks, including the biology subsets of GPQA and WMDP and\nLAB-Bench CloningScenarios. Contrary to expectations, chain-of-thought did not\nsubstantially improve performance over zero-shot evaluation, while extended\nreasoning features in o3-mini and Claude 3.7 Sonnet typically improved\nperformance as predicted by inference scaling. Benchmarks such as PubMedQA and\nthe MMLU and WMDP biology subsets exhibited performance plateaus well below\n100%, suggesting benchmark saturation and errors in the underlying benchmark\ndata. The analysis highlights the need for more sophisticated evaluation\nmethodologies as AI systems continue to advance.", "AI": {"tldr": "The study evaluates 27 Large Language Models (LLMs) on eight biology benchmarks, showing significant improvements in performance, with some models surpassing expert-level capabilities. Extended reasoning features improved results, while chain-of-thought did not. Benchmark limitations were identified.", "motivation": "To systematically assess the biological capabilities of frontier LLMs and track their advancements over time.", "method": "Evaluated 27 LLMs from major AI developers on eight biology benchmarks through ten independent runs per benchmark.", "result": "Top models showed dramatic improvements, with some exceeding expert-level performance. Extended reasoning features enhanced results, but chain-of-thought did not. Benchmarks revealed saturation and data errors.", "conclusion": "The study underscores the rapid progress of LLMs in biology but calls for more sophisticated evaluation methods due to benchmark limitations."}}
{"id": "2505.10945", "pdf": "https://arxiv.org/pdf/2505.10945", "abs": "https://arxiv.org/abs/2505.10945", "authors": ["Seungyoon Lee", "Seongtae Hong", "Hyeonseok Moon", "Heuiseok Lim"], "title": "Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 Findings", "summary": "Large Language Models (LLMs) increasingly incorporate multilingual\ncapabilities, fueling the demand to transfer them into target language-specific\nmodels. However, most approaches, which blend the source model's embedding by\nreplacing the source vocabulary with the target language-specific vocabulary,\nmay constrain expressive capacity in the target language since the source model\nis predominantly trained on English data. In this paper, we propose Semantic\nAware Linear Transfer (SALT), a novel cross-lingual transfer technique that\nrecycles embeddings from target language Pre-trained Language Models (PLMs) to\ntransmit the deep representational strengths of PLM-derived embedding to LLMs.\nSALT derives unique regression lines based on the similarity in the overlap of\nthe source and target vocabularies, to handle each non-overlapping token's\nembedding space. Our extensive experiments show that SALT significantly\noutperforms other transfer methods and achieves lower loss with accelerating\nfaster convergence during language adaptation. Notably, SALT obtains remarkable\nperformance in cross-lingual understanding setups compared to other methods.\nFurthermore, we highlight the scalable use of PLMs to enhance the functionality\nof contemporary LLMs by conducting experiments with varying architectures.", "AI": {"tldr": "SALT, a cross-lingual transfer technique, recycles target language PLM embeddings to enhance LLMs, outperforming other methods in performance and convergence.", "motivation": "Address limitations of current multilingual transfer methods that constrain expressive capacity in target languages due to English-dominated source models.", "method": "Proposes Semantic Aware Linear Transfer (SALT), using regression lines based on vocabulary overlap to handle non-overlapping token embeddings.", "result": "SALT outperforms other methods, achieves lower loss, faster convergence, and remarkable cross-lingual understanding performance.", "conclusion": "SALT effectively leverages PLMs to enhance LLMs, demonstrating scalability and superior performance in cross-lingual transfer."}}
{"id": "2505.08133", "pdf": "https://arxiv.org/pdf/2505.08133", "abs": "https://arxiv.org/abs/2505.08133", "authors": ["Dan Bateyko", "Karen Levy"], "title": "One Bad NOFO? AI Governance in Federal Grantmaking", "categories": ["cs.CY", "cs.AI", "K.5.2"], "comment": "In The 2025 ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT '25), June 23---26, 2025, Athens, Greece. 13 pages", "summary": "Much scholarship considers how U.S. federal agencies govern artificial\nintelligence (AI) through rulemaking and their own internal use policies. But\nagencies have an overlooked AI governance role: setting discretionary grant\npolicy when directing billions of dollars in federal financial assistance.\nThese dollars enable state and local entities to study, create, and use AI.\nThis funding not only goes to dedicated AI programs, but also to grantees using\nAI in the course of meeting their routine grant objectives. As discretionary\ngrantmakers, agencies guide and restrict what grant winners do -- a hidden\nlever for AI governance. Agencies pull this lever by setting program\nobjectives, judging criteria, and restrictions for AI use. Using a novel\ndataset of over 40,000 non-defense federal grant notices of funding opportunity\n(NOFOs) posted to the U.S. federal grants website between 2009 and 2024, we\nanalyze how agencies regulate the use of AI by grantees. We select records\nmentioning AI and review their stated goals and requirements. We find agencies\npromoting AI in notice narratives, shaping adoption in ways other records of\ngrant policy might fail to capture. Of the grant opportunities that mention AI,\nwe find only a handful of AI-specific judging criteria or restrictions. This\nsilence holds even when agencies fund AI uses in contexts affecting people's\nrights and which, under an analogous federal procurement regime, would result\nin extra oversight. These findings recast grant notices as a site of AI\npolicymaking -- albeit one that is developing out of step with other regulatory\nefforts and incomplete in its consideration of transparency, accountability,\nand privacy protections. The paper concludes by drawing lessons from AI\nprocurement scholarship, while identifying distinct challenges in grantmaking\nthat invite further study.", "AI": {"tldr": "The paper examines how U.S. federal agencies govern AI through discretionary grant policies, revealing gaps in oversight despite significant funding influence.", "motivation": "To uncover the overlooked role of federal agencies in AI governance via grant funding, which shapes AI adoption by state and local entities.", "method": "Analysis of 40,000+ federal grant notices (2009-2024) to identify AI-related goals, judging criteria, and restrictions.", "result": "Agencies promote AI in narratives but rarely impose specific criteria or restrictions, even in rights-sensitive contexts.", "conclusion": "Grant notices are an emerging but underdeveloped AI policymaking tool, lacking alignment with broader regulatory efforts and protections."}}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields.", "AI": {"tldr": "A unified transformer-based attribution model for marketing, handling member-level and aggregate data, plus external factors, implemented at LinkedIn with significant impact.", "motivation": "To improve marketing intelligence by accurately attributing conversions using data-driven methods, addressing diverse data types and external influences.", "method": "A transformer-based approach integrating member-level, aggregate-level data, and external macro factors.", "result": "Successful large-scale implementation at LinkedIn, demonstrating significant impact.", "conclusion": "The approach offers valuable insights broadly applicable to marketing and ad tech, enhancing attribution accuracy and business outcomes."}}
{"id": "2505.11004", "pdf": "https://arxiv.org/pdf/2505.11004", "abs": "https://arxiv.org/abs/2505.11004", "authors": ["Jingcheng Niu", "Subhabrata Dutta", "Ahmed Elshabrawy", "Harish Tayyar Madabushi", "Iryna Gurevych"], "title": "Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large-scale Transformer language models (LMs) trained solely on next-token\nprediction with web-scale data can solve a wide range of tasks after seeing\njust a few examples. The mechanism behind this capability, known as in-context\nlearning (ICL), remains both controversial and poorly understood. Some studies\nargue that it is merely the result of memorizing vast amounts of data, while\nothers contend that it reflects a fundamental, symbolic algorithmic development\nin LMs. In this work, we introduce a suite of investigative tasks and a novel\nmethod to systematically investigate ICL by leveraging the full Pythia scaling\nsuite, including interim checkpoints that capture progressively larger amount\nof training data. By carefully exploring ICL performance on downstream tasks\nand simultaneously conducting a mechanistic analysis of the residual stream's\nsubspace, we demonstrate that ICL extends beyond mere \"memorization\" of the\ntraining corpus, yet does not amount to the implementation of an independent\nsymbolic algorithm. Our results also clarify several aspects of ICL, including\nthe influence of training dynamics, model capabilities, and elements of\nmechanistic interpretability. Overall, our work advances the understanding of\nICL and its implications, offering model developers insights into potential\nimprovements and providing AI security practitioners with a basis for more\ninformed guidelines.", "AI": {"tldr": "The paper investigates in-context learning (ICL) in large-scale Transformer models, showing it's not just memorization but also not a fully symbolic algorithm, while clarifying training dynamics and model capabilities.", "motivation": "To understand the mechanism behind ICL in Transformer models, which remains controversial, and determine whether it's memorization or algorithmic development.", "method": "Uses the Pythia scaling suite with interim checkpoints to explore ICL performance and analyze the residual stream's subspace.", "result": "ICL goes beyond memorization but isn't a standalone symbolic algorithm; insights into training dynamics and model capabilities are provided.", "conclusion": "Advances understanding of ICL, offering insights for model improvement and AI security guidelines."}}
{"id": "2505.09619", "pdf": "https://arxiv.org/pdf/2505.09619", "abs": "https://arxiv.org/abs/2505.09619", "authors": ["Pietro Cassieri", "Aiman Faiz", "Anna Maria De Roberto", "Claudio Pascarelli", "Gianvito Mitrano", "Gianluca Fimiani", "Marina Garofano", "Genoveffa Tortora", "Mariangela Lazoi", "Claudio Passino", "Alessia Bramanti", "Giuseppe Scanniello"], "title": "Machine Learning Solutions Integrated in an IoT Healthcare Platform for Heart Failure Risk Stratification", "categories": ["stat.OT", "cs.AI"], "comment": null, "summary": "The management of chronic Heart Failure (HF) presents significant challenges\nin modern healthcare, requiring continuous monitoring, early detection of\nexacerbations, and personalized treatment strategies. In this paper, we present\na predictive model founded on Machine Learning (ML) techniques to identify\npatients at HF risk. This model is an ensemble learning approach, a modified\nstacking technique, that uses two specialized models leveraging clinical and\nechocardiographic features and then a meta-model to combine the predictions of\nthese two models. We initially assess the model on a real dataset and the\nobtained results suggest that it performs well in the stratification of\npatients at HR risk. Specifically, we obtained high sensitivity (95\\%),\nensuring that nearly all high-risk patients are identified. As for accuracy, we\nobtained 84\\%, which can be considered moderate in some ML contexts. However,\nit is acceptable given our priority of identifying patients at risk of HF\nbecause they will be asked to participate in the telemonitoring program of the\nPrediHealth research project on which some of the authors of this paper are\nworking. The initial findings also suggest that ML-based risk stratification\nmodels can serve as valuable decision-support tools not only in the PrediHealth\nproject but also for healthcare professionals, aiding in early intervention and\npersonalized patient management. To have a better understanding of the value\nand of potentiality of our predictive model, we also contrasted its results\nwith those obtained by using three baseline models. The preliminary results\nindicate that our predictive model outperforms these baselines that flatly\nconsider features, \\ie not grouping them in clinical and echocardiographic\nfeatures.", "AI": {"tldr": "A machine learning-based predictive model for heart failure risk stratification using clinical and echocardiographic features, achieving high sensitivity (95%) and moderate accuracy (84%).", "motivation": "To address the challenges of chronic heart failure management by enabling early detection and personalized treatment through predictive modeling.", "method": "An ensemble learning approach with a modified stacking technique, combining two specialized models and a meta-model, tested on a real dataset.", "result": "High sensitivity (95%) and moderate accuracy (84%), outperforming baseline models.", "conclusion": "The model shows promise as a decision-support tool for early intervention and personalized patient management in heart failure care."}}
{"id": "2505.11356", "pdf": "https://arxiv.org/pdf/2505.11356", "abs": "https://arxiv.org/abs/2505.11356", "authors": ["Nero Z. Li", "Xuehao Zhai", "Zhichao Shi", "Boshen Shi", "Xuhui Jiang"], "title": "Fractal Graph Contrastive Learning", "categories": ["cs.LG"], "comment": null, "summary": "While Graph Contrastive Learning (GCL) has attracted considerable attention\nin the field of graph self-supervised learning, its performance heavily relies\non data augmentations that are expected to generate semantically consistent\npositive pairs. Existing strategies typically resort to random perturbations or\nlocal structure preservation, yet lack explicit control over global structural\nconsistency between augmented views. To address this limitation, we propose\nFractal Graph Contrastive Learning (FractalGCL), a theory-driven framework that\nleverages fractal self-similarity to enforce global topological coherence.\nFractalGCL introduces two key innovations: a renormalisation-based augmentation\nthat generates structurally aligned positive views via box coverings; and a\nfractal-dimension-aware contrastive loss that aligns graph embeddings according\nto their fractal dimensions. While combining the two innovations markedly\nboosts graph-representation quality, it also adds non-trivial computational\noverhead. To mitigate the computational overhead of fractal dimension\nestimation, we derive a one-shot estimator by proving that the dimension\ndiscrepancy between original and renormalised graphs converges weakly to a\ncentred Gaussian distribution. This theoretical insight enables a reduction in\ndimension computation cost by an order of magnitude, cutting overall training\ntime by approximately 61%. The experiments show that FractalGCL not only\ndelivers state-of-the-art results on standard benchmarks but also outperforms\ntraditional baselines on traffic networks by an average margin of about\nremarkably 7%. Codes are available at\n(https://anonymous.4open.science/r/FractalGCL-0511).", "AI": {"tldr": "FractalGCL introduces a theory-driven GCL framework using fractal self-similarity to ensure global structural consistency, improving performance and reducing computational costs.", "motivation": "Existing GCL methods lack explicit control over global structural consistency in data augmentations, limiting performance.", "method": "FractalGCL uses renormalisation-based augmentation and a fractal-dimension-aware contrastive loss, with a one-shot estimator to reduce computational overhead.", "result": "FractalGCL achieves state-of-the-art results, outperforming baselines by ~7% on traffic networks, and reduces training time by ~61%.", "conclusion": "FractalGCL effectively addresses global structural consistency in GCL, enhancing performance and efficiency."}}
{"id": "2505.11628", "pdf": "https://arxiv.org/pdf/2505.11628", "abs": "https://arxiv.org/abs/2505.11628", "authors": ["Berkcan Kapusuzoglu", "Supriyo Chakraborty", "Chia-Hsuan Lee", "Sambit Sahu"], "title": "Critique-Guided Distillation: Improving Supervised Fine-tuning via Better Distillation", "categories": ["cs.CL", "cs.LG"], "comment": "Submitted to NeurIPS 2025", "summary": "Supervised fine-tuning (SFT) using expert demonstrations often suffer from\nthe imitation problem, where the model learns to reproduce the correct\nresponses without understanding the underlying rationale. To address this\nlimitation, we propose Critique-Guided Distillation (CGD), a novel multi-stage\nframework that integrates teacher model generated explanatory critiques and\nrefined responses into the SFT process. A student model is then trained to map\nthe triplet of prompt, teacher critique, and its own initial response to the\ncorresponding refined teacher response, thereby learning both what to imitate\nand why. Using entropy-based analysis, we show that CGD reduces refinement\nuncertainty and can be interpreted as a Bayesian posterior update. We perform\nextensive empirical evaluation of CGD, on variety of benchmark tasks, and\ndemonstrate significant gains on both math (AMC23 +17.5%) and language\nunderstanding tasks (MMLU-Pro +6.3%), while successfully mitigating the format\ndrift issues observed in previous critique fine-tuning (CFT) techniques.", "AI": {"tldr": "CGD improves SFT by integrating teacher critiques and refined responses, reducing imitation issues and uncertainty, and outperforming benchmarks.", "motivation": "Address the imitation problem in SFT where models copy responses without understanding.", "method": "Propose CGD, a multi-stage framework using teacher critiques and refined responses to train student models.", "result": "CGD achieves significant gains on math (+17.5%) and language tasks (+6.3%), reducing format drift.", "conclusion": "CGD effectively mitigates imitation and format drift, enhancing model understanding and performance."}}
{"id": "2505.10375", "pdf": "https://arxiv.org/pdf/2505.10375", "abs": "https://arxiv.org/abs/2505.10375", "authors": ["Rui Melo", "Claudia Mamede", "Andre Catarino", "Rui Abreu", "Henrique Lopes Cardoso"], "title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "10 pages, 10 figures", "summary": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision.", "AI": {"tldr": "SAEs offer a lightweight, interpretable alternative for bug detection in Java functions, achieving up to 89% F1 score without fine-tuning LLMs.", "motivation": "Traditional vulnerability detection methods have high false positives and scalability issues, driving interest in AI-based approaches. LLMs, while powerful, lack interpretability.", "method": "Evaluated SAEs on representations from GPT-2 Small and Gemma 2B for bug detection in Java functions, without fine-tuning the LLMs.", "result": "SAEs achieved an F1 score of up to 89%, outperforming fine-tuned transformer baselines.", "conclusion": "SAEs can effectively detect software bugs from pretrained LLM representations without fine-tuning, offering a promising interpretable solution."}}
{"id": "2505.11654", "pdf": "https://arxiv.org/pdf/2505.11654", "abs": "https://arxiv.org/abs/2505.11654", "authors": ["Yuhang Liu", "Yingxue Zhang", "Xin Zhang", "Ling Tian", "Yanhua Li", "Jun Luo"], "title": "UrbanMind: Urban Dynamics Prediction with Multifaceted Spatial-Temporal Large Language Models", "categories": ["cs.LG"], "comment": "KDD 2025 accepted", "summary": "Understanding and predicting urban dynamics is crucial for managing\ntransportation systems, optimizing urban planning, and enhancing public\nservices. While neural network-based approaches have achieved success, they\noften rely on task-specific architectures and large volumes of data, limiting\ntheir ability to generalize across diverse urban scenarios. Meanwhile, Large\nLanguage Models (LLMs) offer strong reasoning and generalization capabilities,\nyet their application to spatial-temporal urban dynamics remains underexplored.\nExisting LLM-based methods struggle to effectively integrate multifaceted\nspatial-temporal data and fail to address distributional shifts between\ntraining and testing data, limiting their predictive reliability in real-world\napplications. To bridge this gap, we propose UrbanMind, a novel\nspatial-temporal LLM framework for multifaceted urban dynamics prediction that\nensures both accurate forecasting and robust generalization. At its core,\nUrbanMind introduces Muffin-MAE, a multifaceted fusion masked autoencoder with\nspecialized masking strategies that capture intricate spatial-temporal\ndependencies and intercorrelations among multifaceted urban dynamics.\nAdditionally, we design a semantic-aware prompting and fine-tuning strategy\nthat encodes spatial-temporal contextual details into prompts, enhancing LLMs'\nability to reason over spatial-temporal patterns. To further improve\ngeneralization, we introduce a test time adaptation mechanism with a test data\nreconstructor, enabling UrbanMind to dynamically adjust to unseen test data by\nreconstructing LLM-generated embeddings. Extensive experiments on real-world\nurban datasets across multiple cities demonstrate that UrbanMind consistently\noutperforms state-of-the-art baselines, achieving high accuracy and robust\ngeneralization, even in zero-shot settings.", "AI": {"tldr": "UrbanMind is a spatial-temporal LLM framework for urban dynamics prediction, combining multifaceted data fusion, semantic-aware prompting, and test-time adaptation to achieve high accuracy and robust generalization.", "motivation": "Existing neural network and LLM-based methods struggle with generalization and integrating spatial-temporal data for urban dynamics prediction.", "method": "UrbanMind uses Muffin-MAE for data fusion, semantic-aware prompting for contextual encoding, and test-time adaptation for dynamic adjustment.", "result": "UrbanMind outperforms baselines in accuracy and generalization, even in zero-shot settings.", "conclusion": "UrbanMind effectively bridges the gap in urban dynamics prediction by leveraging LLMs with specialized techniques for robust performance."}}
{"id": "2505.12075", "pdf": "https://arxiv.org/pdf/2505.12075", "abs": "https://arxiv.org/abs/2505.12075", "authors": ["Guy Davidson", "Todd M. Gureckis", "Brenden M. Lake", "Adina Williams"], "title": "Do different prompting methods yield a common task representation in language models?", "categories": ["cs.CL", "cs.LG"], "comment": "9 pages, 4 figures; under review", "summary": "Demonstrations and instructions are two primary approaches for prompting\nlanguage models to perform in-context learning (ICL) tasks. Do identical tasks\nelicited in different ways result in similar representations of the task? An\nimproved understanding of task representation mechanisms would offer\ninterpretability insights and may aid in steering models. We study this through\n\\textit{function vectors} (FVs), recently proposed as a mechanism to extract\nfew-shot ICL task representations. We generalize FVs to alternative task\npresentations, focusing on short textual instruction prompts, and successfully\nextract instruction function vectors that promote zero-shot task accuracy. We\nfind evidence that demonstration- and instruction-based function vectors\nleverage different model components, and offer several controls to dissociate\ntheir contributions to task performance. Our results suggest that different\ntask promptings forms do not induce a common task representation through FVs\nbut elicit different, partly overlapping mechanisms. Our findings offer\nprincipled support to the practice of combining instructions and task\ndemonstrations, imply challenges in universally monitoring task inference\nacross presentation forms, and encourage further examinations of LLM task\ninference mechanisms.", "AI": {"tldr": "The paper explores whether different prompting methods (demonstrations vs. instructions) for in-context learning tasks result in similar task representations in language models, using function vectors (FVs) to analyze and compare these representations.", "motivation": "To understand how task representations vary with different prompting methods, aiming to improve interpretability and control over language models.", "method": "Generalizes function vectors (FVs) to analyze task representations from both demonstration- and instruction-based prompts, focusing on zero-shot task accuracy.", "result": "Demonstration- and instruction-based FVs use different model components, suggesting no common task representation but partially overlapping mechanisms.", "conclusion": "Combining instructions and demonstrations is beneficial, but universally monitoring task inference across prompting forms is challenging. Further study of LLM task inference mechanisms is encouraged."}}
{"id": "2505.12269", "pdf": "https://arxiv.org/pdf/2505.12269", "abs": "https://arxiv.org/abs/2505.12269", "authors": ["Kerry Xiao", "Amy Zang"], "title": "Vague Knowledge: Evidence from Analyst Reports", "categories": ["econ.GN", "cs.AI", "cs.CL", "math.LO", "q-fin.EC", "q-fin.GN", "03B48, 03B65, 03E02, 03E15, 03E72, 18E45, 28A05, 62F15, 68T01,\n  68T35, 68T50, 91G30,", "F.4; I.2.3; I.2.4; I.2.7; J.1; J.4; J.5"], "comment": null, "summary": "People in the real world often possess vague knowledge of future payoffs, for\nwhich quantification is not feasible or desirable. We argue that language, with\ndiffering ability to convey vague information, plays an important but less\nknown-role in representing subjective expectations. Empirically, we find that\nin their reports, analysts include useful information in linguistic expressions\nbut not numerical forecasts. Specifically, the textual tone of analyst reports\nhas predictive power for forecast errors and subsequent revisions in numerical\nforecasts, and this relation becomes stronger when analyst's language is\nvaguer, when uncertainty is higher, and when analysts are busier. Overall, our\ntheory and evidence suggest that some useful information is vaguely known and\nonly communicated through language.", "AI": {"tldr": "Language conveys vague but useful information about future payoffs, as shown by analyst reports' textual tone predicting forecast errors and revisions.", "motivation": "To explore how language, especially vague expressions, represents subjective expectations when quantification is impractical.", "method": "Analyzed analyst reports, focusing on textual tone and its relation to forecast errors and revisions under varying conditions of vagueness, uncertainty, and analyst workload.", "result": "Textual tone in reports predicts forecast errors and revisions, with stronger effects under vaguer language, higher uncertainty, and busier analysts.", "conclusion": "Some valuable information is vaguely known and only communicated through language, highlighting its role in conveying subjective expectations."}}
{"id": "2505.12586", "pdf": "https://arxiv.org/pdf/2505.12586", "abs": "https://arxiv.org/abs/2505.12586", "authors": ["Sanggeon Yun", "Ryozo Masukawa", "Hyunwoo Oh", "Nathaniel D. Bastian", "Mohsen Imani"], "title": "A Few Large Shifts: Layer-Inconsistency Based Minimal Overhead Adversarial Example Detection", "categories": ["cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) are highly susceptible to adversarial\nexamples--subtle, imperceptible perturbations that can lead to incorrect\npredictions. While detection-based defenses offer a practical alternative to\nadversarial training, many existing methods depend on external models, complex\narchitectures, heavy augmentations, or adversarial data, limiting their\nefficiency and generalizability. We introduce a lightweight, plug-in detection\nframework that leverages internal layer-wise inconsistencies within the target\nmodel itself, requiring only benign data for calibration. Our approach is\ngrounded in the A Few Large Shifts Assumption, which posits that adversarial\nperturbations typically induce large representation shifts in a small subset of\nlayers. Building on this, we propose two complementary strategies--Recovery\nTesting (RT) and Logit-layer Testing (LT)--to expose internal disruptions\ncaused by adversaries. Evaluated on CIFAR-10, CIFAR-100, and ImageNet under\nboth standard and adaptive threat models, our method achieves state-of-the-art\ndetection performance with negligible computational overhead and no compromise\nto clean accuracy. The code is available here:\nhttps://github.com/c0510gy/AFLS-AED.", "AI": {"tldr": "A lightweight, plug-in detection framework for adversarial examples in DNNs, leveraging internal layer inconsistencies without external models or adversarial data.", "motivation": "DNNs are vulnerable to adversarial examples, and existing detection methods are inefficient or lack generalizability.", "method": "Uses the A Few Large Shifts Assumption and proposes Recovery Testing (RT) and Logit-layer Testing (LT) to detect adversarial perturbations.", "result": "Achieves state-of-the-art detection performance on CIFAR-10, CIFAR-100, and ImageNet with minimal computational overhead.", "conclusion": "The framework is efficient, generalizable, and maintains clean accuracy, offering a practical defense against adversarial attacks."}}
{"id": "2505.12082", "pdf": "https://arxiv.org/pdf/2505.12082", "abs": "https://arxiv.org/abs/2505.12082", "authors": ["Yunshui Li", "Yiyuan Ma", "Shen Yan", "Chaoyi Zhang", "Jing Liu", "Jianqiao Lu", "Ziwen Xu", "Mengzhao Chen", "Minrui Wang", "Shiyi Zhan", "Jin Ma", "Xunhao Lai", "Deyi Liu", "Yao Luo", "Xingyan Bin", "Hongbin Ren", "Mingji Han", "Wenhao Hao", "Bairen Yi", "LingJun Liu", "Bole Ma", "Xiaoying Jia", "Xun Zhou", "Siyuan Qiao", "Liang Xiang", "Yonghui Wu"], "title": "Model Merging in Pre-training of Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Model merging has emerged as a promising technique for enhancing large\nlanguage models, though its application in large-scale pre-training remains\nrelatively unexplored. In this paper, we present a comprehensive investigation\nof model merging techniques during the pre-training process. Through extensive\nexperiments with both dense and Mixture-of-Experts (MoE) architectures ranging\nfrom millions to over 100 billion parameters, we demonstrate that merging\ncheckpoints trained with constant learning rates not only achieves significant\nperformance improvements but also enables accurate prediction of annealing\nbehavior. These improvements lead to both more efficient model development and\nsignificantly lower training costs. Our detailed ablation studies on merging\nstrategies and hyperparameters provide new insights into the underlying\nmechanisms while uncovering novel applications. Through comprehensive\nexperimental analysis, we offer the open-source community practical\npre-training guidelines for effective model merging.", "AI": {"tldr": "Model merging in large-scale pre-training improves performance and reduces costs, with insights from experiments on dense and MoE architectures.", "motivation": "To explore the unexplored potential of model merging in large-scale pre-training and its benefits for efficiency and cost reduction.", "method": "Extensive experiments with dense and MoE architectures, merging checkpoints trained with constant learning rates, and ablation studies on strategies and hyperparameters.", "result": "Significant performance improvements, accurate prediction of annealing behavior, and lower training costs.", "conclusion": "Provides practical pre-training guidelines for effective model merging, benefiting the open-source community."}}
{"id": "2505.13176", "pdf": "https://arxiv.org/pdf/2505.13176", "abs": "https://arxiv.org/abs/2505.13176", "authors": ["Zihao Cheng", "Hongru Wang", "Zeming Liu", "Yuhang Guo", "Yuanfang Guo", "Yunhong Wang", "Haifeng Wang"], "title": "ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL 2025 Findings", "summary": "While integrating external tools into large language models (LLMs) enhances\ntheir ability to access real-time information and domain-specific services,\nexisting approaches focus narrowly on functional tool selection following user\ninstructions, overlooking the context-aware personalization in tool selection.\nThis oversight leads to suboptimal user satisfaction and inefficient tool\nutilization, particularly when overlapping toolsets require nuanced selection\nbased on contextual factors. To bridge this gap, we introduce ToolSpectrum, a\nbenchmark designed to evaluate LLMs' capabilities in personalized tool\nutilization. Specifically, we formalize two key dimensions of personalization,\nuser profile and environmental factors, and analyze their individual and\nsynergistic impacts on tool utilization. Through extensive experiments on\nToolSpectrum, we demonstrate that personalized tool utilization significantly\nimproves user experience across diverse scenarios. However, even\nstate-of-the-art LLMs exhibit the limited ability to reason jointly about user\nprofiles and environmental factors, often prioritizing one dimension at the\nexpense of the other. Our findings underscore the necessity of context-aware\npersonalization in tool-augmented LLMs and reveal critical limitations for\ncurrent models. Our data and code are available at\nhttps://github.com/Chengziha0/ToolSpectrum.", "AI": {"tldr": "ToolSpectrum is a benchmark for evaluating LLMs' personalized tool utilization, highlighting the need for context-aware personalization beyond functional tool selection.", "motivation": "Existing approaches overlook context-aware personalization in tool selection, leading to suboptimal user satisfaction and inefficient tool use.", "method": "ToolSpectrum formalizes user profile and environmental factors to analyze their impact on tool utilization, testing LLMs' capabilities.", "result": "Personalized tool utilization improves user experience, but current LLMs struggle to jointly reason about user profiles and environmental factors.", "conclusion": "Context-aware personalization is crucial for tool-augmented LLMs, and current models have limitations in balancing user and environmental factors."}}
{"id": "2505.13092", "pdf": "https://arxiv.org/pdf/2505.13092", "abs": "https://arxiv.org/abs/2505.13092", "authors": ["Dennis Frauen", "Valentyn Melnychuk", "Jonas Schweisthal", "Mihaela van der Schaar", "Stefan Feuerriegel"], "title": "Treatment Effect Estimation for Optimal Decision-Making", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Decision-making across various fields, such as medicine, heavily relies on\nconditional average treatment effects (CATEs). Practitioners commonly make\ndecisions by checking whether the estimated CATE is positive, even though the\ndecision-making performance of modern CATE estimators is poorly understood from\na theoretical perspective. In this paper, we study optimal decision-making\nbased on two-stage CATE estimators (e.g., DR-learner), which are considered\nstate-of-the-art and widely used in practice. We prove that, while such\nestimators may be optimal for estimating CATE, they can be suboptimal when used\nfor decision-making. Intuitively, this occurs because such estimators\nprioritize CATE accuracy in regions far away from the decision boundary, which\nis ultimately irrelevant to decision-making. As a remedy, we propose a novel\ntwo-stage learning objective that retargets the CATE to balance CATE estimation\nerror and decision performance. We then propose a neural method that optimizes\nan adaptively-smoothed approximation of our learning objective. Finally, we\nconfirm the effectiveness of our method both empirically and theoretically. In\nsum, our work is the first to show how two-stage CATE estimators can be adapted\nfor optimal decision-making.", "AI": {"tldr": "The paper reveals that two-stage CATE estimators, though optimal for estimating CATE, may underperform in decision-making due to their focus on irrelevant regions. It proposes a retargeted learning objective and a neural method to improve decision performance, validated empirically and theoretically.", "motivation": "Understanding the gap between CATE estimation and decision-making performance, especially with widely used two-stage estimators like DR-learner.", "method": "Proposes a novel two-stage learning objective to balance CATE estimation and decision performance, along with a neural method for optimization.", "result": "Shows that traditional CATE estimators can be suboptimal for decisions, while the proposed method improves performance.", "conclusion": "First work to adapt two-stage CATE estimators for optimal decision-making, bridging theory and practice."}}
{"id": "2505.12212", "pdf": "https://arxiv.org/pdf/2505.12212", "abs": "https://arxiv.org/abs/2505.12212", "authors": ["Shaobo Wang", "Xiangqi Jin", "Ziming Wang", "Jize Wang", "Jiajun Zhang", "Kaixin Li", "Zichen Wen", "Zhong Li", "Conghui He", "Xuming Hu", "Linfeng Zhang"], "title": "Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025 main, 18 pages, 8 figures, 6 tables", "summary": "Fine-tuning large language models (LLMs) on task-specific data is essential\nfor their effective deployment. As dataset sizes grow, efficiently selecting\noptimal subsets for training becomes crucial to balancing performance and\ncomputational costs. Traditional data selection methods often require\nfine-tuning a scoring model on the target dataset, which is time-consuming and\nresource-intensive, or rely on heuristics that fail to fully leverage the\nmodel's predictive capabilities. To address these challenges, we propose Data\nWhisperer, an efficient, training-free, attention-based method that leverages\nfew-shot in-context learning with the model to be fine-tuned. Comprehensive\nevaluations were conducted on both raw and synthetic datasets across diverse\ntasks and models. Notably, Data Whisperer achieves superior performance\ncompared to the full GSM8K dataset on the Llama-3-8B-Instruct model, using just\n10% of the data, and outperforms existing methods with a 3.1-point improvement\nand a 7.4$\\times$ speedup.", "AI": {"tldr": "Data Whisperer is a training-free, attention-based method for selecting optimal subsets of task-specific data for fine-tuning LLMs, outperforming traditional methods in performance and efficiency.", "motivation": "Efficiently selecting optimal subsets for training LLMs is crucial due to growing dataset sizes and computational costs. Traditional methods are either resource-intensive or heuristic-based.", "method": "Proposes Data Whisperer, leveraging few-shot in-context learning with the target model, eliminating the need for fine-tuning a scoring model.", "result": "Achieves superior performance with 10% of the GSM8K dataset on Llama-3-8B-Instruct, outperforming existing methods by 3.1 points with a 7.4x speedup.", "conclusion": "Data Whisperer offers an efficient, scalable solution for data selection in LLM fine-tuning, balancing performance and computational costs."}}
{"id": "2505.14625", "pdf": "https://arxiv.org/pdf/2505.14625", "abs": "https://arxiv.org/abs/2505.14625", "authors": ["Zhangchen Xu", "Yuetai Li", "Fengqing Jiang", "Bhaskar Ramasubramanian", "Luyao Niu", "Bill Yuchen Lin", "Radha Poovendran"], "title": "TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning (RL) has become a powerful tool for enhancing the\nreasoning abilities of large language models (LLMs) by optimizing their\npolicies with reward signals. Yet, RL's success relies on the reliability of\nrewards, which are provided by verifiers. In this paper, we expose and analyze\na widespread problem--false negatives--where verifiers wrongly reject correct\nmodel outputs. Our in-depth study of the Big-Math-RL-Verified dataset reveals\nthat over 38% of model-generated responses suffer from false negatives, where\nthe verifier fails to recognize correct answers. We show, both empirically and\ntheoretically, that these false negatives severely impair RL training by\ndepriving the model of informative gradient signals and slowing convergence. To\nmitigate this, we propose tinyV, a lightweight LLM-based verifier that augments\nexisting rule-based methods, which dynamically identifies potential false\nnegatives and recovers valid responses to produce more accurate reward\nestimates. Across multiple math-reasoning benchmarks, integrating TinyV boosts\npass rates by up to 10% and accelerates convergence relative to the baseline.\nOur findings highlight the critical importance of addressing verifier false\nnegatives and offer a practical approach to improve RL-based fine-tuning of\nLLMs. Our code is available at https://github.com/uw-nsl/TinyV.", "AI": {"tldr": "The paper identifies false negatives in RL-based LLM training, where verifiers wrongly reject correct outputs, and proposes TinyV, a lightweight verifier, to mitigate this issue.", "motivation": "To address the problem of false negatives in RL training of LLMs, which impair learning by depriving models of correct feedback.", "method": "Analyzes the Big-Math-RL-Verified dataset, introduces TinyV, a lightweight LLM-based verifier, to dynamically identify and recover false negatives.", "result": "TinyV improves pass rates by up to 10% and accelerates convergence in math-reasoning benchmarks.", "conclusion": "False negatives significantly hinder RL training; TinyV offers a practical solution to enhance LLM fine-tuning."}}
{"id": "2505.14033", "pdf": "https://arxiv.org/pdf/2505.14033", "abs": "https://arxiv.org/abs/2505.14033", "authors": ["Guoming Li", "Jian Yang", "Yifan Chen"], "title": "Partition-wise Graph Filtering: A Unified Perspective Through the Lens of Graph Coarsening", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "comment": "Accepted at the 31st ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining, KDD 2025 February Cycle", "summary": "Filtering-based graph neural networks (GNNs) constitute a distinct class of\nGNNs that employ graph filters to handle graph-structured data, achieving\nnotable success in various graph-related tasks. Conventional methods adopt a\ngraph-wise filtering paradigm, imposing a uniform filter across all nodes, yet\nrecent findings suggest that this rigid paradigm struggles with heterophilic\ngraphs. To overcome this, recent works have introduced node-wise filtering,\nwhich assigns distinct filters to individual nodes, offering enhanced\nadaptability. However, a fundamental gap remains: a comprehensive framework\nunifying these two strategies is still absent, limiting theoretical insights\ninto the filtering paradigms. Moreover, through the lens of Contextual\nStochastic Block Model, we reveal that a synthesis of graph-wise and node-wise\nfiltering provides a sufficient solution for classification on graphs\nexhibiting both homophily and heterophily, suggesting the risk of excessive\nparameterization and potential overfitting with node-wise filtering. To address\nthe limitations, this paper introduces Coarsening-guided Partition-wise\nFiltering (CPF). CPF innovates by performing filtering on node partitions. The\nmethod begins with structure-aware partition-wise filtering, which filters node\npartitions obtained via graph coarsening algorithms, and then performs\nfeature-aware partition-wise filtering, refining node embeddings via filtering\non clusters produced by $k$-means clustering over features. In-depth analysis\nis conducted for each phase of CPF, showing its superiority over other\nparadigms. Finally, benchmark node classification experiments, along with a\nreal-world graph anomaly detection application, validate CPF's efficacy and\npractical utility.", "AI": {"tldr": "The paper introduces Coarsening-guided Partition-wise Filtering (CPF), a framework unifying graph-wise and node-wise filtering for GNNs, addressing limitations in handling heterophilic graphs and avoiding overfitting.", "motivation": "The rigid uniform filtering in conventional GNNs struggles with heterophilic graphs, while node-wise filtering risks overfitting. A unified framework is needed for better adaptability and theoretical insights.", "method": "CPF performs filtering on node partitions: first structure-aware via graph coarsening, then feature-aware via k-means clustering.", "result": "CPF outperforms other paradigms in node classification and anomaly detection, demonstrating its efficacy.", "conclusion": "CPF provides a balanced solution for graphs with homophily and heterophily, avoiding excessive parameterization and overfitting."}}
{"id": "2505.14079", "pdf": "https://arxiv.org/pdf/2505.14079", "abs": "https://arxiv.org/abs/2505.14079", "authors": ["Weihong Du", "Wenrui Liao", "Binyu Yan", "Hongru Liang", "Anthony G. Cohn", "Wenqiang Lei"], "title": "BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Large language model (LLM) based agents have shown great potential in\nfollowing human instructions and automatically completing various tasks. To\ncomplete a task, the agent needs to decompose it into easily executed steps by\nplanning. Existing studies mainly conduct the planning by inferring what steps\nshould be executed next starting from the agent's initial state. However, this\nforward reasoning paradigm doesn't work well for complex tasks. We propose to\nstudy this issue in Minecraft, a virtual environment that simulates complex\ntasks based on real-world scenarios. We believe that the failure of forward\nreasoning is caused by the big perception gap between the agent's initial state\nand task goal. To this end, we leverage backward reasoning and make the\nplanning starting from the terminal state, which can directly achieve the task\ngoal in one step. Specifically, we design a BAckward Reasoning based agent\n(BAR). It is equipped with a recursive goal decomposition module, a state\nconsistency maintaining module and a stage memory module to make robust,\nconsistent, and efficient planning starting from the terminal state.\nExperimental results demonstrate the superiority of BAR over existing methods\nand the effectiveness of proposed modules.", "AI": {"tldr": "The paper proposes BAR, a backward reasoning-based agent for complex tasks in Minecraft, outperforming forward reasoning methods.", "motivation": "Forward reasoning struggles with complex tasks due to the perception gap between initial state and goal. Backward reasoning is explored as a solution.", "method": "BAR uses recursive goal decomposition, state consistency maintenance, and stage memory for robust planning from the terminal state.", "result": "BAR outperforms existing methods, demonstrating the effectiveness of its modules.", "conclusion": "Backward reasoning, implemented via BAR, is superior for complex task planning in environments like Minecraft."}}
{"id": "2505.15046", "pdf": "https://arxiv.org/pdf/2505.15046", "abs": "https://arxiv.org/abs/2505.15046", "authors": ["Yifan Wu", "Lutao Yan", "Leixian Shen", "Yinan Mei", "Jiannan Wang", "Yuyu Luo"], "title": "ChartCards: A Chart-Metadata Generation Framework for Multi-Task Chart Understanding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The emergence of Multi-modal Large Language Models (MLLMs) presents new\nopportunities for chart understanding. However, due to the fine-grained nature\nof these tasks, applying MLLMs typically requires large, high-quality datasets\nfor task-specific fine-tuning, leading to high data collection and training\ncosts. To address this, we propose ChartCards, a unified chart-metadata\ngeneration framework for multi-task chart understanding. ChartCards\nsystematically synthesizes various chart information, including data tables,\nvisualization code, visual elements, and multi-dimensional semantic captions.\nBy structuring this information into organized metadata, ChartCards enables a\nsingle chart to support multiple downstream tasks, such as text-to-chart\nretrieval, chart summarization, chart-to-table conversion, chart description,\nand chart question answering. Using ChartCards, we further construct MetaChart,\na large-scale high-quality dataset containing 10,862 data tables, 85K charts,\nand 170 K high-quality chart captions. We validate the dataset through\nqualitative crowdsourcing evaluations and quantitative fine-tuning experiments\nacross various chart understanding tasks. Fine-tuning six different models on\nMetaChart resulted in an average performance improvement of 5% across all\ntasks. The most notable improvements are seen in text-to-chart retrieval and\nchart-to-table tasks, with Long-CLIP and Llama 3.2-11B achieving improvements\nof 17% and 28%, respectively.", "AI": {"tldr": "ChartCards is a framework for generating unified chart metadata to support multi-task chart understanding, reducing the need for large datasets. MetaChart, a dataset built using ChartCards, improves model performance by 5% on average across tasks.", "motivation": "High data collection and training costs for fine-tuning MLLMs on fine-grained chart understanding tasks necessitate a more efficient solution.", "method": "Proposes ChartCards, a framework synthesizing chart information into structured metadata, and constructs MetaChart dataset for validation.", "result": "Fine-tuning on MetaChart improves performance by 5% on average, with notable gains in text-to-chart retrieval (17%) and chart-to-table tasks (28%).", "conclusion": "ChartCards and MetaChart offer an efficient, high-quality solution for multi-task chart understanding, reducing reliance on large datasets."}}
{"id": "2505.14214", "pdf": "https://arxiv.org/pdf/2505.14214", "abs": "https://arxiv.org/abs/2505.14214", "authors": ["Mattes Mollenhauer", "Nicole M\u00fccke", "Dimitri Meunier", "Arthur Gretton"], "title": "Regularized least squares learning with heavy-tailed noise is minimax optimal", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "62G08 (Primary) 62G35, 62J07 (Secondary)"], "comment": "32 pages, 1 figure", "summary": "This paper examines the performance of ridge regression in reproducing kernel\nHilbert spaces in the presence of noise that exhibits a finite number of higher\nmoments. We establish excess risk bounds consisting of subgaussian and\npolynomial terms based on the well known integral operator framework. The\ndominant subgaussian component allows to achieve convergence rates that have\npreviously only been derived under subexponential noise - a prevalent\nassumption in related work from the last two decades. These rates are optimal\nunder standard eigenvalue decay conditions, demonstrating the asymptotic\nrobustness of regularized least squares against heavy-tailed noise. Our\nderivations are based on a Fuk-Nagaev inequality for Hilbert-space valued\nrandom variables.", "AI": {"tldr": "The paper analyzes ridge regression in reproducing kernel Hilbert spaces under heavy-tailed noise, showing optimal convergence rates and robustness.", "motivation": "To extend the understanding of ridge regression performance beyond subexponential noise, addressing heavy-tailed noise with finite higher moments.", "method": "Uses the integral operator framework and a Fuk-Nagaev inequality for Hilbert-space valued random variables to derive excess risk bounds.", "result": "Achieves optimal convergence rates under standard eigenvalue decay, demonstrating robustness against heavy-tailed noise.", "conclusion": "Regularized least squares is asymptotically robust to heavy-tailed noise, with rates matching those under subexponential noise."}}
{"id": "2505.14464", "pdf": "https://arxiv.org/pdf/2505.14464", "abs": "https://arxiv.org/abs/2505.14464", "authors": ["Xiaoyu Tian", "Yunjie Ji", "Haotian Wang", "Shuaiting Chen", "Sitong Zhao", "Yiping Peng", "Han Zhao", "Xiangang Li"], "title": "Not All Correct Answers Are Equal: Why Your Distillation Source Matters", "categories": ["cs.CL"], "comment": null, "summary": "Distillation has emerged as a practical and effective approach to enhance the\nreasoning capabilities of open-source language models. In this work, we conduct\na large-scale empirical study on reasoning data distillation by collecting\nverified outputs from three state-of-the-art teacher models-AM-Thinking-v1,\nQwen3-235B-A22B, and DeepSeek-R1-on a shared corpus of 1.89 million queries. We\nconstruct three parallel datasets and analyze their distributions, revealing\nthat AM-Thinking-v1-distilled data exhibits greater token length diversity and\nlower perplexity. Student models trained on each dataset are evaluated on\nreasoning benchmarks including AIME2024, AIME2025, MATH500, and LiveCodeBench.\nThe model distilled from AM-Thinking-v1 consistently achieves the best\nperformance (e.g., 84.3 on AIME2024, 72.2 on AIME2025, 98.4 on MATH500, and\n65.9 on LiveCodeBench) and demonstrates adaptive output behavior-producing\nlonger responses for harder tasks and shorter ones for simpler tasks. These\nfindings highlight the value of high-quality, verified reasoning traces. We\nrelease the AM-Thinking-v1 and Qwen3-235B-A22B distilled datasets to support\nfuture research on open and high-performing reasoning-oriented language models.\nThe datasets are publicly available on Hugging Face\\footnote{Datasets are\navailable on Hugging Face:\n\\href{https://huggingface.co/datasets/a-m-team/AM-Thinking-v1-Distilled}{AM-Thinking-v1-Distilled},\n\\href{https://huggingface.co/datasets/a-m-team/AM-Qwen3-Distilled}{AM-Qwen3-Distilled}.}.", "AI": {"tldr": "The paper explores distillation to boost reasoning in language models, using data from three teachers. AM-Thinking-v1-distilled data shows superior diversity and performance.", "motivation": "To enhance reasoning in open-source language models through verified distillation data.", "method": "Collect outputs from three teacher models on 1.89M queries, analyze distributions, and train student models on each dataset.", "result": "AM-Thinking-v1-distilled data leads to the best student performance across benchmarks, with adaptive response lengths.", "conclusion": "High-quality, verified reasoning traces are valuable; datasets are released for future research."}}
{"id": "2505.15091", "pdf": "https://arxiv.org/pdf/2505.15091", "abs": "https://arxiv.org/abs/2505.15091", "authors": ["Qihang Yu", "Kairui Fu", "Shengyu Zhang", "Zheqi Lv", "Fan Wu", "Fei Wu"], "title": "ThinkRec: Thinking-based recommendation via LLM", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled more\nsemantic-aware recommendations through natural language generation. Existing\nLLM for recommendation (LLM4Rec) methods mostly operate in a System 1-like\nmanner, relying on superficial features to match similar items based on click\nhistory, rather than reasoning through deeper behavioral logic. This often\nleads to superficial and erroneous recommendations. Motivated by this, we\npropose ThinkRec, a thinking-based framework that shifts LLM4Rec from System 1\nto System 2 (rational system). Technically, ThinkRec introduces a thinking\nactivation mechanism that augments item metadata with keyword summarization and\ninjects synthetic reasoning traces, guiding the model to form interpretable\nreasoning chains that consist of analyzing interaction histories, identifying\nuser preferences, and making decisions based on target items. On top of this,\nwe propose an instance-wise expert fusion mechanism to reduce the reasoning\ndifficulty. By dynamically assigning weights to expert models based on users'\nlatent features, ThinkRec adapts its reasoning path to individual users,\nthereby enhancing precision and personalization. Extensive experiments on\nreal-world datasets demonstrate that ThinkRec significantly improves the\naccuracy and interpretability of recommendations. Our implementations are\navailable in anonymous Github: https://github.com/Yu-Qi-hang/ThinkRec.", "AI": {"tldr": "ThinkRec is a thinking-based framework for LLM-driven recommendations, shifting from superficial matching to deeper reasoning, improving accuracy and interpretability.", "motivation": "Existing LLM4Rec methods rely on superficial features, leading to erroneous recommendations. ThinkRec aims to enhance reasoning and personalization.", "method": "ThinkRec uses a thinking activation mechanism for keyword summarization and synthetic reasoning traces, along with an instance-wise expert fusion mechanism for dynamic reasoning paths.", "result": "Extensive experiments show ThinkRec significantly improves recommendation accuracy and interpretability.", "conclusion": "ThinkRec advances LLM4Rec by enabling deeper reasoning and personalization, with promising results."}}
{"id": "2505.15030", "pdf": "https://arxiv.org/pdf/2505.15030", "abs": "https://arxiv.org/abs/2505.15030", "authors": ["Qingyu Song", "Peiyu Liao", "Wenqian Zhao", "Yiwen Wang", "Shoubo Hu", "Hui-Ling Zhen", "Ning Jiang", "Mingxuan Yuan"], "title": "Harnessing On-Device Large Language Model: Empirical Results and Implications for AI PC", "categories": ["cs.LG"], "comment": "18 pages, 14 figures", "summary": "The increasing deployment of Large Language Models (LLMs) on edge devices,\ndriven by model advancements and hardware improvements, offers significant\nprivacy benefits. However, these on-device LLMs inherently face performance\nlimitations due to reduced model capacity and necessary compression techniques.\nTo address this, we introduce a systematic methodology -- encompassing model\ncapability, development efficiency, and system resources -- for evaluating\non-device LLMs. Our comprehensive evaluation, encompassing models from 0.5B to\n14B parameters and seven post-training quantization (PTQ) methods on commodity\nlaptops, yields several critical insights: 1) System-level metrics exhibit\nnear-linear scaling with effective bits-per-weight (BPW). 2) A practical\nthreshold exists around $\\sim$3.5 effective BPW, larger models subjected to\nlow-bit quantization consistently outperform smaller models utilizing higher\nbit-precision. 3) Quantization with low BPW incurs marginal accuracy loss but\nsignificant memory savings. 4) Determined by low-level implementation specifics\npower consumption on CPU, where computation-intensive operations spend more\npower than memory-intensive ones. These findings offer crucial insights and\npractical guidelines for the efficient deployment and optimized configuration\nof LLMs on resource-constrained edge devices. Our codebase is available at\nhttps://github.com/simmonssong/LLMOnDevice.", "AI": {"tldr": "The paper introduces a methodology for evaluating on-device LLMs, revealing insights on performance, quantization, and power consumption for efficient edge deployment.", "motivation": "To address performance limitations of on-device LLMs due to reduced capacity and compression, ensuring privacy benefits.", "method": "Systematic evaluation of models (0.5B-14B parameters) and seven PTQ methods on commodity laptops, analyzing metrics like BPW and power consumption.", "result": "Key findings include near-linear scaling with BPW, a practical threshold at ~3.5 BPW, marginal accuracy loss with low BPW, and power consumption trends.", "conclusion": "Provides guidelines for deploying and optimizing LLMs on edge devices, balancing performance and resource constraints."}}
{"id": "2505.14652", "pdf": "https://arxiv.org/pdf/2505.14652", "abs": "https://arxiv.org/abs/2505.14652", "authors": ["Xueguang Ma", "Qian Liu", "Dongfu Jiang", "Ge Zhang", "Zejun Ma", "Wenhu Chen"], "title": "General-Reasoner: Advancing LLM Reasoning Across All Domains", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) has recently demonstrated strong potential in\nenhancing the reasoning capabilities of large language models (LLMs).\nParticularly, the \"Zero\" reinforcement learning introduced by Deepseek-R1-Zero,\nenables direct RL training of base LLMs without relying on an intermediate\nsupervised fine-tuning stage. Despite these advancements, current works for LLM\nreasoning mainly focus on mathematical and coding domains, largely due to data\nabundance and the ease of answer verification. This limits the applicability\nand generalization of such models to broader domains, where questions often\nhave diverse answer representations, and data is more scarce. In this paper, we\npropose General-Reasoner, a novel training paradigm designed to enhance LLM\nreasoning capabilities across diverse domains. Our key contributions include:\n(1) constructing a large-scale, high-quality dataset of questions with\nverifiable answers curated by web crawling, covering a wide range of\ndisciplines; and (2) developing a generative model-based answer verifier, which\nreplaces traditional rule-based verification with the capability of\nchain-of-thought and context-awareness. We train a series of models and\nevaluate them on a wide range of datasets covering wide domains like physics,\nchemistry, finance, electronics etc. Our comprehensive evaluation across these\n12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC)\ndemonstrates that General-Reasoner outperforms existing baseline methods,\nachieving robust and generalizable reasoning performance while maintaining\nsuperior effectiveness in mathematical reasoning tasks.", "AI": {"tldr": "General-Reasoner enhances LLM reasoning across diverse domains by using a novel training paradigm, a large-scale dataset, and a generative model-based answer verifier, outperforming baselines.", "motivation": "Current LLM reasoning methods are limited to mathematical and coding domains due to data abundance and answer verification ease, restricting broader applicability.", "method": "Proposes General-Reasoner with a large-scale dataset from web crawling and a generative model-based answer verifier for diverse domains.", "result": "Outperforms baselines on 12 benchmarks, showing robust and generalizable reasoning across domains like physics, chemistry, and finance.", "conclusion": "General-Reasoner advances LLM reasoning beyond narrow domains, maintaining effectiveness in mathematical tasks while excelling in diverse disciplines."}}
{"id": "2505.15242", "pdf": "https://arxiv.org/pdf/2505.15242", "abs": "https://arxiv.org/abs/2505.15242", "authors": ["Zhiyuan Wei", "Jing Sun", "Zijian Zhang", "Zhe Hou", "Zixiao Zhao"], "title": "Adaptive Plan-Execute Framework for Smart Contract Security Auditing", "categories": ["cs.CR", "cs.AI"], "comment": "30 pages, 5 figures", "summary": "Large Language Models (LLMs) have shown great promise in code analysis and\nauditing; however, they still struggle with hallucinations and limited\ncontext-aware reasoning. We introduce SmartAuditFlow, a novel Plan-Execute\nframework that enhances smart contract security analysis through dynamic audit\nplanning and structured execution. Unlike conventional LLM-based auditing\napproaches that follow fixed workflows and predefined steps, SmartAuditFlow\ndynamically generates and refines audit plans based on the unique\ncharacteristics of each smart contract. It continuously adjusts its auditing\nstrategy in response to intermediate LLM outputs and newly detected\nvulnerabilities, ensuring a more adaptive and precise security assessment. The\nframework then executes these plans step by step, applying a structured\nreasoning process to enhance vulnerability detection accuracy while minimizing\nhallucinations and false positives. To further improve audit precision,\nSmartAuditFlow integrates iterative prompt optimization and external knowledge\nsources, such as static analysis tools and Retrieval-Augmented Generation\n(RAG). This ensures audit decisions are contextually informed and backed by\nreal-world security knowledge, producing comprehensive security reports.\nExtensive evaluations across multiple benchmarks demonstrate that\nSmartAuditFlow outperforms existing methods, achieving 100 percent accuracy on\ncommon and critical vulnerabilities, 41.2 percent accuracy for comprehensive\ncoverage of known smart contract weaknesses in real-world projects, and\nsuccessfully identifying all 13 tested CVEs. These results highlight\nSmartAuditFlow's scalability, cost-effectiveness, and superior adaptability\nover traditional static analysis tools and contemporary LLM-based approaches,\nestablishing it as a robust solution for automated smart contract auditing.", "AI": {"tldr": "SmartAuditFlow is a dynamic Plan-Execute framework for smart contract auditing, outperforming traditional methods with adaptive planning and structured execution.", "motivation": "LLMs struggle with hallucinations and limited context-aware reasoning in code auditing, necessitating a more adaptive and precise approach.", "method": "SmartAuditFlow dynamically generates and refines audit plans, integrates iterative prompt optimization, and uses external knowledge sources like RAG and static analysis tools.", "result": "Achieves 100% accuracy on critical vulnerabilities, 41.2% coverage of known weaknesses, and identifies all 13 tested CVEs.", "conclusion": "SmartAuditFlow is scalable, cost-effective, and superior to traditional tools, making it a robust solution for automated smart contract auditing."}}
{"id": "2505.15544", "pdf": "https://arxiv.org/pdf/2505.15544", "abs": "https://arxiv.org/abs/2505.15544", "authors": ["Haruki Settai", "Naoya Takeishi", "Takehisa Yairi"], "title": "A Temporal Difference Method for Stochastic Continuous Dynamics", "categories": ["cs.LG"], "comment": null, "summary": "For continuous systems modeled by dynamical equations such as ODEs and SDEs,\nBellman's principle of optimality takes the form of the Hamilton-Jacobi-Bellman\n(HJB) equation, which provides the theoretical target of reinforcement learning\n(RL). Although recent advances in RL successfully leverage this formulation,\nthe existing methods typically assume the underlying dynamics are known a\npriori because they need explicit access to the coefficient functions of\ndynamical equations to update the value function following the HJB equation. We\naddress this inherent limitation of HJB-based RL; we propose a model-free\napproach still targeting the HJB equation and propose the corresponding\ntemporal difference method. We demonstrate its potential advantages over\ntransition kernel-based formulations, both qualitatively and empirically. The\nproposed formulation paves the way toward bridging stochastic optimal control\nand model-free reinforcement learning.", "AI": {"tldr": "A model-free reinforcement learning approach targeting the HJB equation is proposed, overcoming the need for known dynamics in traditional methods.", "motivation": "Existing HJB-based RL methods require known dynamics, limiting their applicability. The paper aims to address this by developing a model-free approach.", "method": "The paper introduces a model-free temporal difference method that targets the HJB equation without needing explicit dynamics.", "result": "The proposed method shows qualitative and empirical advantages over transition kernel-based formulations.", "conclusion": "This work bridges stochastic optimal control and model-free RL, offering a promising direction for future research."}}
{"id": "2505.15255", "pdf": "https://arxiv.org/pdf/2505.15255", "abs": "https://arxiv.org/abs/2505.15255", "authors": ["Yuansheng Gao", "Han Bao", "Tong Zhang", "Bin Li", "Zonghui Wang", "Wenzhi Chen"], "title": "MentalMAC: Enhancing Large Language Models for Detecting Mental Manipulation via Multi-Task Anti-Curriculum Distillation", "categories": ["cs.CL"], "comment": null, "summary": "Mental manipulation is a subtle yet pervasive form of psychological abuse\nthat poses serious threats to mental health. Its covert nature and the\ncomplexity of manipulation strategies make it challenging to detect, even for\nstate-of-the-art large language models (LLMs). This concealment also hinders\nthe manual collection of large-scale, high-quality annotations essential for\ntraining effective models. Although recent efforts have sought to improve LLMs'\nperformance on this task, progress remains limited due to the scarcity of\nreal-world annotated datasets. To address these challenges, we propose\nMentalMAC, a multi-task anti-curriculum distillation method that enhances LLMs'\nability to detect mental manipulation in multi-turn dialogue. Our approach\nincludes: (i) EvoSA, an unsupervised data expansion method based on\nevolutionary operations and speech act theory; (ii) teacher model-generated\nmulti-task supervision; and (iii) progressive knowledge distillation from\ncomplex to simpler tasks. We then constructed the ReaMent dataset with 5,000\nreal-world dialogue samples, using a MentalMAC-distilled model to assist human\nannotation. Vast experiments demonstrate that our method significantly narrows\nthe gap between student and teacher models and outperforms competitive LLMs\nacross key evaluation metrics. All code, datasets, and checkpoints will be\nreleased upon paper acceptance. Warning: This paper contains content that may\nbe offensive to readers.", "AI": {"tldr": "The paper introduces MentalMAC, a method to improve LLMs' detection of mental manipulation in dialogues, using multi-task anti-curriculum distillation and unsupervised data expansion.", "motivation": "Mental manipulation is hard to detect due to its covert nature and lack of annotated datasets, limiting LLMs' effectiveness.", "method": "Proposes MentalMAC with EvoSA for data expansion, multi-task supervision, and progressive knowledge distillation. Uses the ReaMent dataset for validation.", "result": "MentalMAC significantly improves detection performance, narrowing the gap between student and teacher models.", "conclusion": "The method advances LLMs' ability to detect mental manipulation, with resources to be released publicly."}}
{"id": "2505.15553", "pdf": "https://arxiv.org/pdf/2505.15553", "abs": "https://arxiv.org/abs/2505.15553", "authors": ["Angelie Kraft", "Judith Simon", "Sonja Schimmler"], "title": "Social Bias in Popular Question-Answering Benchmarks", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Question-answering (QA) and reading comprehension (RC) benchmarks are\nessential for assessing the capabilities of large language models (LLMs) in\nretrieving and reproducing knowledge. However, we demonstrate that popular QA\nand RC benchmarks are biased and do not cover questions about different\ndemographics or regions in a representative way, potentially due to a lack of\ndiversity of those involved in their creation. We perform a qualitative content\nanalysis of 30 benchmark papers and a quantitative analysis of 20 respective\nbenchmark datasets to learn (1) who is involved in the benchmark creation, (2)\nhow social bias is addressed or prevented, and (3) whether the demographics of\nthe creators and annotators correspond to particular biases in the content.\nMost analyzed benchmark papers provided insufficient information regarding the\nstakeholders involved in benchmark creation, particularly the annotators.\nNotably, just one of the benchmark papers explicitly reported measures taken to\naddress social representation issues. Moreover, the data analysis revealed\ngender, religion, and geographic biases across a wide range of encyclopedic,\ncommonsense, and scholarly benchmarks. More transparent and bias-aware QA and\nRC benchmark creation practices are needed to facilitate better scrutiny and\nincentivize the development of fairer LLMs.", "AI": {"tldr": "The paper highlights biases in QA and RC benchmarks due to lack of diversity in their creation, calling for more transparent and bias-aware practices.", "motivation": "To assess biases in QA and RC benchmarks and advocate for fairer LLM development.", "method": "Qualitative analysis of 30 benchmark papers and quantitative analysis of 20 datasets.", "result": "Found insufficient transparency in benchmark creation and widespread biases (gender, religion, geography).", "conclusion": "Urges more transparent, bias-aware practices for fairer benchmarks and LLMs."}}
{"id": "2505.15747", "pdf": "https://arxiv.org/pdf/2505.15747", "abs": "https://arxiv.org/abs/2505.15747", "authors": ["Kanan Kiguchi", "Yunhao Tu", "Katsuhiro Ajito", "Fady Alnajjar", "Kazuyuki Murase"], "title": "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.1; H.3.1; J.3"], "comment": "38 pages, 8 figures, 4 tables", "summary": "We propose a novel framework for integrating fragmented multi-modal data in\nAlzheimer's disease (AD) research using large language models (LLMs) and\nknowledge graphs. While traditional multimodal analysis requires matched\npatient IDs across datasets, our approach demonstrates population-level\nintegration of MRI, gene expression, biomarkers, EEG, and clinical indicators\nfrom independent cohorts. Statistical analysis identified significant features\nin each modality, which were connected as nodes in a knowledge graph. LLMs then\nanalyzed the graph to extract potential correlations and generate hypotheses in\nnatural language. This approach revealed several novel relationships, including\na potential pathway linking metabolic risk factors to tau protein abnormalities\nvia neuroinflammation (r>0.6, p<0.001), and unexpected correlations between\nfrontal EEG channels and specific gene expression profiles (r=0.42-0.58,\np<0.01). Cross-validation with independent datasets confirmed the robustness of\nmajor findings, with consistent effect sizes across cohorts (variance <15%).\nThe reproducibility of these findings was further supported by expert review\n(Cohen's k=0.82) and computational validation. Our framework enables cross\nmodal integration at a conceptual level without requiring patient ID matching,\noffering new possibilities for understanding AD pathology through fragmented\ndata reuse and generating testable hypotheses for future research.", "AI": {"tldr": "A novel framework integrates fragmented multi-modal Alzheimer's disease data using LLMs and knowledge graphs, revealing new correlations without requiring patient ID matching.", "motivation": "Traditional multimodal analysis in AD research requires matched patient IDs, limiting data integration. This framework aims to overcome this by enabling population-level integration of diverse data types.", "method": "The approach combines statistical analysis of MRI, gene expression, biomarkers, EEG, and clinical data into a knowledge graph, analyzed by LLMs to extract correlations and generate hypotheses.", "result": "Identified novel relationships, such as metabolic risk factors linked to tau protein via neuroinflammation, and validated findings with cross-dataset consistency (variance <15%) and expert review (Cohen's k=0.82).", "conclusion": "The framework enables conceptual-level cross-modal integration, offering new insights into AD pathology and generating testable hypotheses for future research."}}
{"id": "2505.15431", "pdf": "https://arxiv.org/pdf/2505.15431", "abs": "https://arxiv.org/abs/2505.15431", "authors": ["Tencent Hunyuan Team", "Ao Liu", "Botong Zhou", "Can Xu", "Chayse Zhou", "ChenChen Zhang", "Chengcheng Xu", "Chenhao Wang", "Decheng Wu", "Dengpeng Wu", "Dian Jiao", "Dong Du", "Dong Wang", "Feng Zhang", "Fengzong Lian", "Guanghui Xu", "Guanwei Zhang", "Hai Wang", "Haipeng Luo", "Han Hu", "Huilin Xu", "Jiajia Wu", "Jianchen Zhu", "Jianfeng Yan", "Jiaqi Zhu", "Jihong Zhang", "Jinbao Xue", "Jun Xia", "Junqiang Zheng", "Kai Liu", "Kai Zhang", "Kai Zheng", "Kejiao Li", "Keyao Wang", "Lan Jiang", "Lixin Liu", "Lulu Wu", "Mengyuan Huang", "Peijie Yu", "Peiqi Wang", "Qian Wang", "Qianbiao Xiang", "Qibin Liu", "Qingfeng Sun", "Richard Guo", "Ruobing Xie", "Saiyong Yang", "Shaohua Chen", "Shihui Hu", "Shuai Li", "Shuaipeng Li", "Shuang Chen", "Suncong Zheng", "Tao Yang", "Tian Zhang", "Tinghao Yu", "Weidong Han", "Weijie Liu", "Weijin Zhou", "Weikang Wang", "Wesleye Chen", "Xiao Feng", "Xiaoqin Ren", "Xingwu Sun", "Xiong Kuang", "Xuemeng Huang", "Xun Cao", "Yanfeng Chen", "Yang Du", "Yang Zhen", "Yangyu Tao", "Yaping Deng", "Yi Shen", "Yigeng Hong", "Yiqi Chen", "Yiqing Huang", "Yuchi Deng", "Yue Mao", "Yulong Wang", "Yuyuan Zeng", "Zenan Xu", "Zhanhui Kang", "Zhe Zhao", "ZhenXiang Yan", "Zheng Fang", "Zhichao Hu", "Zhongzhi Chen", "Zhuoyu Li", "Zongwei Li", "Alex Yan", "Ande Liang", "Baitong Liu", "Beiping Pan", "Bin Xing", "Binghong Wu", "Bingxin Qu", "Bolin Ni", "Boyu Wu", "Chen Li", "Cheng Jiang", "Cheng Zhang", "Chengjun Liu", "Chengxu Yang", "Chengzhong Xu", "Chiyu Wang", "Chong Zha", "Daisy Yi", "Di Wang", "Fanyang Lu", "Fei Chen", "Feifei Liu", "Feng Zheng", "Guanghua Yu", "Guiyang Li", "Guohua Wang", "Haisheng Lin", "Han Liu", "Han Wang", "Hao Fei", "Hao Lu", "Haoqing Jiang", "Haoran Sun", "Haotian Zhu", "Huangjin Dai", "Huankui Chen", "Huawen Feng", "Huihui Cai", "Huxin Peng", "Jackson Lv", "Jiacheng Shi", "Jiahao Bu", "Jianbo Li", "Jianglu Hu", "Jiangtao Guan", "Jianing Xu", "Jianwei Cai", "Jiarong Zhang", "Jiawei Song", "Jie Jiang", "Jie Liu", "Jieneng Yang", "Jihong Zhang", "Jin lv", "Jing Zhao", "Jinjian Li", "Jinxing Liu", "Jun Zhao", "Juntao Guo", "Kai Wang", "Kan Wu", "Lei Fu", "Lei He", "Lei Wang", "Li Liu", "Liang Dong", "Liya Zhan", "Long Cheng", "Long Xu", "Mao Zheng", "Meng Liu", "Mengkang Hu", "Nanli Chen", "Peirui Chen", "Peng He", "Pengju Pan", "Pengzhi Wei", "Qi Yang", "Qi Yi", "Roberts Wang", "Rongpeng Chen", "Rui Sun", "Rui Yang", "Ruibin Chen", "Ruixu Zhou", "Shaofeng Zhang", "Sheng Zhang", "Shihao Xu", "Shuaishuai Chang", "Shulin Liu", "SiQi Wang", "Songjia Feng", "Songling Yuan", "Tao Zhang", "Tianjiao Lang", "Tongkai Li", "Wei Deng", "Wei Li", "Weichao Wang", "Weigang Zhang", "Weixuan Sun", "Wen Ouyang", "Wenxiang Jiao", "Wenzhi Sun", "Wenzhuo Jia", "Xiang Zhang", "Xiangyu He", "Xianshun Ren", "XiaoYing Zhu", "Xiaolong Guo", "Xiaoxue Li", "Xiaoyu Ma", "Xican Lu", "Xinhua Feng", "Xinting Huang", "Xinyu Guan", "Xirui Li", "Xu Zhang", "Xudong Gao", "Xun Luo", "Xuxiang Qi", "Yangkun Chen", "Yangyu Tao", "Yanling Xiao", "Yantao Mai", "Yanze Chen", "Yao Ding", "Yeting Yang", "YiFan Song", "Yifan Yang", "Yijiao Zhu", "Yinhe Wu", "Yixian Liu", "Yong Yang", "Yuanjun Cai", "Yuanlin Tu", "Yue Zhang", "Yufei Huang", "Yuhang Zhou", "Yuhao Jiang", "Yuhong Liu", "Yuhui Hu", "Yujin Lin", "Yun Yang", "Yunhao Wang", "Yusong Zhang", "Zekun Wu", "Zelong Zhang", "Zhan Yu", "Zhaoliang Yang", "Zhe Zhao", "Zheng Li", "Zhenyu Huang", "Zhiguang Liu", "Zhijiang Xu", "Zhiqing Kui", "Zhiyin Zeng", "Zhiyuan Xiong", "Zhuo Han", "Zifan Wu", "Zigang Geng", "Zilong Zhao", "Ziyan Tang", "Ziyuan Zhu", "Zonglei Zhu", "Zhijiang Xu"], "title": "Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought", "categories": ["cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) rapidly advance, we introduce Hunyuan-TurboS,\na novel large hybrid Transformer-Mamba Mixture of Experts (MoE) model. It\nsynergistically combines Mamba's long-sequence processing efficiency with\nTransformer's superior contextual understanding. Hunyuan-TurboS features an\nadaptive long-short chain-of-thought (CoT) mechanism, dynamically switching\nbetween rapid responses for simple queries and deep \"thinking\" modes for\ncomplex problems, optimizing computational resources. Architecturally, this 56B\nactivated (560B total) parameter model employs 128 layers (Mamba2, Attention,\nFFN) with an innovative AMF/MF block pattern. Faster Mamba2 ensures linear\ncomplexity, Grouped-Query Attention minimizes KV cache, and FFNs use an MoE\nstructure. Pre-trained on 16T high-quality tokens, it supports a 256K context\nlength and is the first industry-deployed large-scale Mamba model. Our\ncomprehensive post-training strategy enhances capabilities via Supervised\nFine-Tuning (3M instructions), a novel Adaptive Long-short CoT Fusion method,\nMulti-round Deliberation Learning for iterative improvement, and a two-stage\nLarge-scale Reinforcement Learning process targeting STEM and general\ninstruction-following. Evaluations show strong performance: overall top 7 rank\non LMSYS Chatbot Arena with a score of 1356, outperforming leading models like\nGemini-2.0-Flash-001 (1352) and o4-mini-2025-04-16 (1345). TurboS also achieves\nan average of 77.9% across 23 automated benchmarks. Hunyuan-TurboS balances\nhigh performance and efficiency, offering substantial capabilities at lower\ninference costs than many reasoning models, establishing a new paradigm for\nefficient large-scale pre-trained models.", "AI": {"tldr": "Hunyuan-TurboS is a hybrid Transformer-Mamba MoE model combining efficiency and contextual understanding, achieving top performance with optimized computational resources.", "motivation": "To create a high-performance, efficient large-scale model by synergizing Mamba's long-sequence efficiency and Transformer's contextual strengths.", "method": "Uses a 56B activated parameter model with 128 layers (Mamba2, Attention, FFN), adaptive CoT, and MoE. Pre-trained on 16T tokens, enhanced via post-training strategies.", "result": "Top 7 rank on LMSYS Chatbot Arena (1356 score), outperforms competitors, and averages 77.9% on 23 benchmarks.", "conclusion": "Hunyuan-TurboS sets a new paradigm for efficient large-scale models, balancing performance and cost."}}
{"id": "2304.06833", "pdf": "https://arxiv.org/pdf/2304.06833", "abs": "https://arxiv.org/abs/2304.06833", "authors": ["Adam N. Elmachtoub", "Henry Lam", "Haofeng Zhang", "Yunfan Zhao"], "title": "Estimate-Then-Optimize versus Integrated-Estimation-Optimization versus Sample Average Approximation: A Stochastic Dominance Perspective", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "In data-driven stochastic optimization, model parameters of the underlying\ndistribution need to be estimated from data in addition to the optimization\ntask. Recent literature considers integrating the estimation and optimization\nprocesses by selecting model parameters that lead to the best empirical\nobjective performance. This integrated approach, which we call\nintegrated-estimation-optimization (IEO), can be readily shown to outperform\nsimple estimate-then-optimize (ETO) when the model is misspecified. In this\npaper, we show that a reverse behavior appears when the model class is\nwell-specified and there is sufficient data. Specifically, for a general class\nof nonlinear stochastic optimization problems, we show that simple ETO\noutperforms IEO asymptotically when the model class covers the ground truth, in\nthe strong sense of stochastic dominance of the regret. Namely, the entire\ndistribution of the regret, not only its mean or other moments, is always\nbetter for ETO compared to IEO. Our results also apply to constrained,\ncontextual optimization problems where the decision depends on observed\nfeatures. Whenever applicable, we also demonstrate how standard sample average\napproximation (SAA) performs the worst when the model class is well-specified\nin terms of regret, and best when it is misspecified. Finally, we provide\nexperimental results to support our theoretical comparisons and illustrate when\nour insights hold in finite-sample regimes and under various degrees of\nmisspecification.", "AI": {"tldr": "The paper compares integrated-estimation-optimization (IEO) and estimate-then-optimize (ETO) in stochastic optimization, showing ETO outperforms IEO asymptotically when the model is well-specified, while IEO excels under misspecification. SAA performs worst in well-specified cases but best under misspecification.", "motivation": "To understand the performance of integrated vs. sequential estimation and optimization methods under different model specifications (well-specified vs. misspecified).", "method": "Theoretical analysis of nonlinear stochastic optimization problems, including constrained and contextual cases, supported by experimental results.", "result": "ETO dominates IEO asymptotically in well-specified models (stochastic dominance of regret), while IEO is better under misspecification. SAA performs worst in well-specified cases but best under misspecification.", "conclusion": "The choice between ETO and IEO depends on model specification; ETO is preferred for well-specified models, while IEO is better for misspecified ones. SAA's performance varies similarly."}}
{"id": "2505.15472", "pdf": "https://arxiv.org/pdf/2505.15472", "abs": "https://arxiv.org/abs/2505.15472", "authors": ["Song Dai", "Yibo Yan", "Jiamin Su", "Dongfang Zihao", "Yubo Gao", "Yonghua Hei", "Jungang Li", "Junyan Zhang", "Sicheng Tao", "Zhuoran Gao", "Xuming Hu"], "title": "PhysicsArena: The First Multimodal Physics Reasoning Benchmark Exploring Variable, Process, and Solution Dimensions", "categories": ["cs.CL", "I.2.7; I.2.10"], "comment": "Under Review", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in diverse reasoning tasks, yet their application to complex\nphysics reasoning remains underexplored. Physics reasoning presents unique\nchallenges, requiring grounding in physical conditions and the interpretation\nof multimodal information. Current physics benchmarks are limited, often\nfocusing on text-only inputs or solely on problem-solving, thereby overlooking\nthe critical intermediate steps of variable identification and process\nformulation. To address these limitations, we introduce PhysicsArena, the first\nmultimodal physics reasoning benchmark designed to holistically evaluate MLLMs\nacross three critical dimensions: variable identification, physical process\nformulation, and solution derivation. PhysicsArena aims to provide a\ncomprehensive platform for assessing and advancing the multimodal physics\nreasoning abilities of MLLMs.", "AI": {"tldr": "PhysicsArena is introduced as the first multimodal benchmark to evaluate MLLMs in physics reasoning, addressing gaps in variable identification, process formulation, and solution derivation.", "motivation": "Current physics benchmarks lack multimodal inputs and overlook intermediate reasoning steps, limiting MLLMs' application in physics.", "method": "PhysicsArena is designed to holistically assess MLLMs across variable identification, process formulation, and solution derivation.", "result": "The benchmark aims to advance MLLMs' multimodal physics reasoning capabilities.", "conclusion": "PhysicsArena provides a comprehensive platform for evaluating and improving MLLMs in physics reasoning."}}
{"id": "2309.15593", "pdf": "https://arxiv.org/pdf/2309.15593", "abs": "https://arxiv.org/abs/2309.15593", "authors": ["Yuan Wang", "Surya T. Sathujoda", "Krzysztof Sawicki", "Kanishk Gandhi", "Angelica I Aviles-Rivero", "Pavlos G. Lagoudakis"], "title": "A Fourier Neural Operator Approach for Modelling Exciton-Polariton Condensate Systems", "categories": ["cond-mat.quant-gas", "cs.LG"], "comment": "29 pages, 10 figures", "summary": "A plethora of next-generation all-optical devices based on exciton-polaritons\nhave been proposed in latest years, including prototypes of transistors,\nswitches, analogue quantum simulators and others. However, for such systems\nconsisting of multiple polariton condensates, it is still challenging to\npredict their properties in a fast and accurate manner. The condensate physics\nis conventionally described by Gross-Pitaevskii equations (GPEs). While\nGPU-based solvers currently exist, we propose a significantly more efficient\nmachine-learning-based Fourier neural operator approach to find the solution to\nthe GPE coupled with exciton rate equations, trained on both numerical and\nexperimental datasets. The proposed method predicts solutions almost three\norders of magnitude faster than CUDA-based solvers in numerical studies,\nmaintaining the high degree of accuracy. Our method not only accelerates\nsimulations but also opens the door to faster, more scalable designs for\nall-optical chips and devices, offering profound implications for quantum\ncomputing, neuromorphic systems, and beyond.", "AI": {"tldr": "A machine-learning-based Fourier neural operator is proposed to solve Gross-Pitaevskii equations (GPEs) for exciton-polariton condensates, offering faster and accurate predictions compared to GPU-based solvers.", "motivation": "The challenge of predicting properties of polariton condensates quickly and accurately for next-generation all-optical devices motivates this work.", "method": "A Fourier neural operator approach is trained on numerical and experimental datasets to solve GPEs coupled with exciton rate equations.", "result": "The method predicts solutions nearly three orders of magnitude faster than CUDA-based solvers while maintaining accuracy.", "conclusion": "This approach accelerates simulations and enables scalable designs for all-optical devices, impacting quantum computing and neuromorphic systems."}}
{"id": "2310.00443", "pdf": "https://arxiv.org/pdf/2310.00443", "abs": "https://arxiv.org/abs/2310.00443", "authors": ["Mahmud Hasan", "Mathias Muia"], "title": "Generalization error property of infoGAN for two-layer neural network", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Information Maximizing Generative Adversarial Network (infoGAN) can be\nunderstood as a minimax problem involving two neural networks: discriminators\nand generators with mutual information functions. The infoGAN incorporates\nvarious components, including latent variables, mutual information, and\nobjective function. This research demonstrates the Generalization error\nproperty of infoGAN as the discriminator and generator sample size approaches\ninfinity. This research explores the generalization error property of InfoGAN\nas the sample sizes of the discriminator and generator approach infinity. To\nestablish this property, the study considers the difference between the\nempirical and population versions of the objective function. The error bound is\nderived from the Rademacher complexity of the discriminator and generator\nfunction classes. Additionally, the bound is proven for a two-layer network,\nwhere both the discriminator and generator utilize Lipschitz and non-decreasing\nactivation functions.", "AI": {"tldr": "The paper analyzes the generalization error of infoGAN as sample sizes grow, deriving bounds using Rademacher complexity for Lipschitz and non-decreasing activation functions.", "motivation": "To understand the theoretical properties of infoGAN, specifically its generalization error as discriminator and generator sample sizes approach infinity.", "method": "Uses empirical and population objective function differences, Rademacher complexity, and focuses on two-layer networks with specific activation functions.", "result": "Derives an error bound for infoGAN's generalization error, applicable to networks with Lipschitz and non-decreasing activation functions.", "conclusion": "The study provides theoretical insights into infoGAN's generalization behavior, supporting its practical use with large sample sizes."}}
{"id": "2402.03819", "pdf": "https://arxiv.org/pdf/2402.03819", "abs": "https://arxiv.org/abs/2402.03819", "authors": ["Abdoulaye Sakho", "Emmanuel Malherbe", "Erwan Scornet"], "title": "Do we need rebalancing strategies? A theoretical and empirical study around SMOTE and its variants", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing\nstrategy for handling imbalanced tabular data sets. However, few works analyze\nSMOTE theoretically. In this paper, we derive several non-asymptotic upper\nbound on SMOTE density. From these results, we prove that SMOTE (with default\nparameter) tends to copy the original minority samples asymptotically. We\nconfirm and illustrate empirically this first theoretical behavior on a\nreal-world data-set.bFurthermore, we prove that SMOTE density vanishes near the\nboundary of the support of the minority class distribution. We then adapt SMOTE\nbased on our theoretical findings to introduce two new variants. These\nstrategies are compared on 13 tabular data sets with 10 state-of-the-art\nrebalancing procedures, including deep generative and diffusion models. One of\nour key findings is that, for most data sets, applying no rebalancing strategy\nis competitive in terms of predictive performances, would it be with LightGBM,\ntuned random forests or logistic regression. However, when the imbalance ratio\nis artificially augmented, one of our two modifications of SMOTE leads to\npromising predictive performances compared to SMOTE and other state-of-the-art\nstrategies.", "AI": {"tldr": "The paper analyzes SMOTE theoretically, proving it copies minority samples asymptotically and vanishes near boundaries. Two new SMOTE variants are introduced and tested, showing competitive performance with no rebalancing in most cases, but outperforming when imbalance is high.", "motivation": "To provide theoretical insights into SMOTE's behavior and improve its performance for imbalanced tabular data.", "method": "Derives non-asymptotic upper bounds on SMOTE density, proves asymptotic copying behavior, and introduces two new SMOTE variants. Empirical validation on real-world data and comparison with 10 state-of-the-art methods.", "result": "SMOTE copies minority samples asymptotically and vanishes near boundaries. No rebalancing is often competitive, but one new SMOTE variant outperforms in high imbalance scenarios.", "conclusion": "Theoretical analysis improves understanding of SMOTE, and new variants offer better performance in extreme imbalance cases."}}
{"id": "2503.20576", "pdf": "https://arxiv.org/pdf/2503.20576", "abs": "https://arxiv.org/abs/2503.20576", "authors": ["Siyuan Guo", "Huiwu Liu", "Xiaolong Chen", "Yuming Xie", "Liang Zhang", "Tao Han", "Hechang Chen", "Yi Chang", "Jun Wang"], "title": "Optimizing Case-Based Reasoning System for Functional Test Script Generation with Large Language Models", "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": "Accepted by KDD 2025 (ADS Track)", "summary": "In this work, we explore the potential of large language models (LLMs) for\ngenerating functional test scripts, which necessitates understanding the\ndynamically evolving code structure of the target software. To achieve this, we\npropose a case-based reasoning (CBR) system utilizing a 4R cycle (i.e.,\nretrieve, reuse, revise, and retain), which maintains and leverages a case bank\nof test intent descriptions and corresponding test scripts to facilitate LLMs\nfor test script generation. To improve user experience further, we introduce\nRe4, an optimization method for the CBR system, comprising reranking-based\nretrieval finetuning and reinforced reuse finetuning. Specifically, we first\nidentify positive examples with high semantic and script similarity, providing\nreliable pseudo-labels for finetuning the retriever model without costly\nlabeling. Then, we apply supervised finetuning, followed by a reinforcement\nlearning finetuning stage, to align LLMs with our production scenarios,\nensuring the faithful reuse of retrieved cases. Extensive experimental results\non two product development units from Huawei Datacom demonstrate the\nsuperiority of the proposed CBR+Re4. Notably, we also show that the proposed\nRe4 method can help alleviate the repetitive generation issues with LLMs.", "AI": {"tldr": "The paper proposes a case-based reasoning (CBR) system with a 4R cycle to enhance LLMs' ability to generate functional test scripts, introducing Re4 for optimization.", "motivation": "To improve the generation of functional test scripts by LLMs by leveraging dynamically evolving code structures and reducing repetitive generation issues.", "method": "A CBR system with a 4R cycle (retrieve, reuse, revise, retain) and Re4 optimization (reranking-based retrieval finetuning and reinforced reuse finetuning).", "result": "Superior performance on Huawei Datacom product units, with Re4 mitigating repetitive generation in LLMs.", "conclusion": "The CBR+Re4 approach effectively enhances LLM-based test script generation and addresses repetitive output issues."}}
{"id": "2404.02595", "pdf": "https://arxiv.org/pdf/2404.02595", "abs": "https://arxiv.org/abs/2404.02595", "authors": ["Nouhaila Innan", "Alberto Marchisio", "Mohamed Bennai", "Muhammad Shafique"], "title": "QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection", "categories": ["quant-ph", "cs.LG", "q-fin.RM"], "comment": "9 pages, 8 figures", "summary": "This study introduces the Quantum Federated Neural Network for Financial\nFraud Detection (QFNN-FFD), a cutting-edge framework merging Quantum Machine\nLearning (QML) and quantum computing with Federated Learning (FL) for financial\nfraud detection. Using quantum technologies' computational power and the robust\ndata privacy protections offered by FL, QFNN-FFD emerges as a secure and\nefficient method for identifying fraudulent transactions within the financial\nsector. Implementing a dual-phase training model across distributed clients\nenhances data integrity and enables superior performance metrics, achieving\nprecision rates consistently above 95%. Additionally, QFNN-FFD demonstrates\nexceptional resilience by maintaining an impressive 80% accuracy, highlighting\nits robustness and readiness for real-world applications. This combination of\nhigh performance, security, and robustness against noise positions QFNN-FFD as\na transformative advancement in financial technology solutions and establishes\nit as a new benchmark for privacy-focused fraud detection systems. This\nframework facilitates the broader adoption of secure, quantum-enhanced\nfinancial services and inspires future innovations that could use QML to tackle\ncomplex challenges in other areas requiring high confidentiality and accuracy.", "AI": {"tldr": "QFNN-FFD combines Quantum Machine Learning and Federated Learning for secure, high-performance financial fraud detection, achieving over 95% precision and 80% accuracy.", "motivation": "To address financial fraud detection with enhanced privacy and computational power by leveraging quantum technologies and federated learning.", "method": "A dual-phase training model implemented across distributed clients, utilizing quantum computing and federated learning for secure and efficient fraud detection.", "result": "QFNN-FFD achieves precision rates above 95% and maintains 80% accuracy, demonstrating robustness and readiness for real-world use.", "conclusion": "QFNN-FFD sets a new benchmark for privacy-focused fraud detection, enabling secure quantum-enhanced financial services and inspiring future innovations in high-confidentiality domains."}}
{"id": "2505.13862", "pdf": "https://arxiv.org/pdf/2505.13862", "abs": "https://arxiv.org/abs/2505.13862", "authors": ["Guobin Shen", "Dongcheng Zhao", "Linghao Feng", "Xiang He", "Jihang Wang", "Sicheng Shen", "Haibo Tong", "Yiting Dong", "Jindong Li", "Xiang Zheng", "Yi Zeng"], "title": "PandaGuard: Systematic Evaluation of LLM Safety against Jailbreaking Attacks", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable capabilities but remain\nvulnerable to adversarial prompts known as jailbreaks, which can bypass safety\nalignment and elicit harmful outputs. Despite growing efforts in LLM safety\nresearch, existing evaluations are often fragmented, focused on isolated attack\nor defense techniques, and lack systematic, reproducible analysis. In this\nwork, we introduce PandaGuard, a unified and modular framework that models LLM\njailbreak safety as a multi-agent system comprising attackers, defenders, and\njudges. Our framework implements 19 attack methods and 12 defense mechanisms,\nalong with multiple judgment strategies, all within a flexible plugin\narchitecture supporting diverse LLM interfaces, multiple interaction modes, and\nconfiguration-driven experimentation that enhances reproducibility and\npractical deployment. Built on this framework, we develop PandaBench, a\ncomprehensive benchmark that evaluates the interactions between these\nattack/defense methods across 49 LLMs and various judgment approaches,\nrequiring over 3 billion tokens to execute. Our extensive evaluation reveals\nkey insights into model vulnerabilities, defense cost-performance trade-offs,\nand judge consistency. We find that no single defense is optimal across all\ndimensions and that judge disagreement introduces nontrivial variance in safety\nassessments. We release the code, configurations, and evaluation results to\nsupport transparent and reproducible research in LLM safety.", "AI": {"tldr": "PandaGuard is a unified framework for evaluating LLM jailbreak safety, featuring multi-agent interactions, diverse attack/defense methods, and a benchmark (PandaBench) tested on 49 LLMs. Findings highlight vulnerabilities, defense trade-offs, and judge inconsistencies.", "motivation": "Existing LLM safety evaluations are fragmented and lack systematic analysis, prompting the need for a unified, reproducible framework.", "method": "PandaGuard models jailbreak safety as a multi-agent system (attackers, defenders, judges) with 19 attack methods, 12 defenses, and flexible configurations. PandaBench evaluates interactions across 49 LLMs.", "result": "No single defense is optimal; judge disagreement affects safety assessments. Key insights include vulnerabilities and cost-performance trade-offs.", "conclusion": "PandaGuard and PandaBench provide a transparent, reproducible approach for LLM safety research, with released code and results."}}
{"id": "2405.03526", "pdf": "https://arxiv.org/pdf/2405.03526", "abs": "https://arxiv.org/abs/2405.03526", "authors": ["Qianren Li", "Bojie Lv", "Yuncong Hong", "Rui Wang"], "title": "ReinWiFi: Application-Layer QoS Optimization of WiFi Networks with Reinforcement Learning", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "The enhanced distributed channel access (EDCA) mechanism is used in current\nwireless fidelity (WiFi) networks to support priority requirements of\nheterogeneous applications. However, the EDCA mechanism can not adapt to\nparticular quality-of-service (QoS) objective, network topology, and\ninterference level. In this paper, a novel reinforcement-learning-based\nscheduling framework is proposed and implemented to optimize the\napplication-layer quality-of-service (QoS) of a WiFi network with commercial\nadapters and unknown interference. Particularly, application-layer tasks of\nfile delivery and delay-sensitive communication are jointly scheduled by\nadjusting the contention window sizes and application-layer throughput\nlimitation, such that the throughput of the former and the round trip time of\nthe latter can be optimized. Due to the unknown interference and\nvendor-dependent implementation of the WiFi adapters, the relation between the\nscheduling policy and the system QoS is unknown. Hence, a reinforcement\nlearning method is proposed, in which a novel Q-network is trained to map from\nthe historical scheduling parameters and QoS observations to the current\nscheduling action. It is demonstrated on a testbed that the proposed framework\ncan achieve a significantly better performance than the EDCA mechanism.", "AI": {"tldr": "A reinforcement-learning-based scheduling framework is proposed to optimize QoS in WiFi networks, outperforming the traditional EDCA mechanism.", "motivation": "The EDCA mechanism lacks adaptability to specific QoS needs, network topology, and interference levels, necessitating a more dynamic solution.", "method": "A reinforcement learning approach with a novel Q-network is used to map historical scheduling parameters and QoS observations to current actions, optimizing contention window sizes and throughput limits.", "result": "The framework significantly outperforms EDCA in optimizing throughput for file delivery and round-trip time for delay-sensitive communication.", "conclusion": "The proposed reinforcement-learning-based framework effectively addresses QoS optimization in WiFi networks with unknown interference and vendor-specific implementations."}}
{"id": "2405.04715", "pdf": "https://arxiv.org/pdf/2405.04715", "abs": "https://arxiv.org/abs/2405.04715", "authors": ["Yihong Gu", "Cong Fang", "Peter B\u00fchlmann", "Jianqing Fan"], "title": "Causality Pursuit from Heterogeneous Environments via Neural Adversarial Invariance Learning", "categories": ["math.ST", "cs.LG", "stat.ME", "stat.ML", "stat.TH", "62G08"], "comment": "109 pages, 9 figures with supplemental materials", "summary": "Pursuing causality from data is a fundamental problem in scientific\ndiscovery, treatment intervention, and transfer learning. This paper introduces\na novel algorithmic method for addressing nonparametric invariance and\ncausality learning in regression models across multiple environments, where the\njoint distribution of response variables and covariates varies, but the\nconditional expectations of outcome given an unknown set of quasi-causal\nvariables are invariant. The challenge of finding such an unknown set of\nquasi-causal or invariant variables is compounded by the presence of endogenous\nvariables that have heterogeneous effects across different environments. The\nproposed Focused Adversarial Invariant Regularization (FAIR) framework utilizes\nan innovative minimax optimization approach that drives regression models\ntoward prediction-invariant solutions through adversarial testing. Leveraging\nthe representation power of neural networks, FAIR neural networks (FAIR-NN) are\nintroduced for causality pursuit. It is shown that FAIR-NN can find the\ninvariant variables and quasi-causal variables under a minimal identification\ncondition and that the resulting procedure is adaptive to low-dimensional\ncomposition structures in a non-asymptotic analysis. Under a structural causal\nmodel, variables identified by FAIR-NN represent pragmatic causality and\nprovably align with exact causal mechanisms under conditions of sufficient\nheterogeneity. Computationally, FAIR-NN employs a novel Gumbel approximation\nwith decreased temperature and a stochastic gradient descent ascent algorithm.\nThe procedures are demonstrated using simulated and real-data examples.", "AI": {"tldr": "The paper introduces FAIR-NN, a method for identifying invariant and quasi-causal variables in regression models across varying environments using adversarial testing and neural networks.", "motivation": "Addressing the challenge of finding invariant variables in nonparametric causality learning, especially with heterogeneous effects across environments.", "method": "Proposes FAIR-NN, leveraging adversarial minimax optimization and neural networks to identify invariant variables under minimal conditions.", "result": "FAIR-NN successfully identifies invariant and quasi-causal variables, aligning with exact causal mechanisms under sufficient heterogeneity.", "conclusion": "FAIR-NN provides a robust, adaptive solution for causality pursuit in complex, heterogeneous environments."}}
{"id": "2405.20825", "pdf": "https://arxiv.org/pdf/2405.20825", "abs": "https://arxiv.org/abs/2405.20825", "authors": ["Nanna E. Hartong", "Ilias Sachpazidis", "Oliver Blanck", "Lucas Etzel", "Jan C. Peeken", "Stephanie E. Combs", "Horst Urbach", "Maxim Zaitsev", "Dimos Baltas", "Ilinca Popp", "Anca-Ligia Grosu", "Tobias Fechter"], "title": "Analysis of clinical, dosimetric and radiomic features for predicting local failure after stereotactic radiotherapy of brain metastases in malignant melanoma", "categories": ["physics.med-ph", "cs.LG"], "comment": null, "summary": "Background: This study aimed to predict lesion-specific outcomes after\nstereotactic radiotherapy (SRT) in patients with brain metastases from\nmalignant melanoma (MBM), using clinical, dosimetric pretherapeutic MRI data.\nMethods: In this multicenter retrospective study, 517 MBM from 130 patients\ntreated with single-fraction or hypofractionated SRT across three centers were\nanalyzed. From contrast-enhanced T1-weighted MRI, 1576 radiomic features (RF)\nwere extracted per lesion - 788 from the gross tumor volume (GTV), 788 from a 3\nmm peritumoral margin. Clinical data, radiation dose and RF from one center\nwere used for feature selection and model development via nested\ncross-validation; external validation was performed using the other two\ncenters. Results: Local failure occurred in 72 of 517 lesions (13.9%).\nPredictive models based on clinical data (model 1), RF (model 2), or both\n(model 3) achieved c-indices of 0.60 +/- 0.15, 0.65 +/- 0.11, and 0.65 +/-\n0.12. RF-based models outperformed the clinical model, while dosimetric data\nalone were not predictive. Most predictive RF came from the peritumoral margin\n(92%) vs. GTV (76%). On the first external dataset, all models performed\nsimilarly (c-index: 0.60-0.63), but showed poor generalization on the second\n(c-index < 0.50), likely due to differences in patient characteristics and\nimaging protocols. Conclusions: Information extracted from pretherapeutic MRI,\nparticularly from the peritumoral area, can support accurate prediction of\nlesion-specific outcomes after SRT in MBM. When combined with clinical data,\nthese imaging-derived markers offer valuable prognostic insights. However,\ngeneralizability remains challenging by heterogeneity in patient populations\nand MRI protocols.", "AI": {"tldr": "The study predicts lesion-specific outcomes after SRT for brain metastases from melanoma using clinical and MRI-derived radiomic features, finding peritumoral MRI data most predictive, though generalizability is limited by variability in patient and imaging protocols.", "motivation": "To improve prediction of treatment outcomes for brain metastases from melanoma using pretherapeutic MRI and clinical data.", "method": "Multicenter retrospective analysis of 517 lesions, extracting radiomic features from MRI and combining with clinical data for model development and validation.", "result": "Radiomic features, especially from peritumoral areas, outperformed clinical data in predicting outcomes, but models struggled with external validation due to heterogeneity.", "conclusion": "Pretherapeutic MRI data, particularly peritumoral features, aids outcome prediction, but variability in patient populations and imaging protocols limits generalizability."}}
{"id": "2406.14071", "pdf": "https://arxiv.org/pdf/2406.14071", "abs": "https://arxiv.org/abs/2406.14071", "authors": ["Ziyi Huang", "Henry Lam", "Haofeng Zhang"], "title": "Bayesian Bandit Algorithms with Approximate Inference in Stochastic Linear Bandits", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Bayesian bandit algorithms with approximate Bayesian inference have been\nwidely used in real-world applications. Despite the superior practical\nperformance, their theoretical justification is less investigated in the\nliterature, especially for contextual bandit problems. To fill this gap, we\npropose a theoretical framework to analyze the impact of approximate inference\nin stochastic linear bandits and conduct frequentist regret analysis on two\nBayesian bandit algorithms, Linear Thompson Sampling (LinTS) and the extension\nof Bayesian Upper Confidence Bound, namely Linear Bayesian Upper Confidence\nBound (LinBUCB). We demonstrate that when applied in approximate inference\nsettings, LinTS and LinBUCB can universally preserve their original rates of\nregret upper bound but with a sacrifice of larger constant terms. These results\nhold for general Bayesian inference approaches, assuming the inference error\nmeasured by two different $\\alpha$-divergences is bounded. Additionally, by\nintroducing a new definition of well-behaved distributions, we show that\nLinBUCB expedites the regret rate of LinTS from $\\tilde{O}(d^{3/2}\\sqrt{T})$ to\n$\\tilde{O}(d\\sqrt{T})$, matching the minimax optimal rate. To our knowledge,\nthis work provides the first regret bounds in the setting of stochastic linear\nbandits with bounded approximate inference errors.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2407.00644", "pdf": "https://arxiv.org/pdf/2407.00644", "abs": "https://arxiv.org/abs/2407.00644", "authors": ["D. J. W. Touw", "A. Alfons", "P. J. F. Groenen", "I. Wilms"], "title": "Clusterpath Gaussian Graphical Modeling", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Graphical models serve as effective tools for visualizing conditional\ndependencies between variables. However, as the number of variables grows,\ninterpretation becomes increasingly difficult, and estimation uncertainty\nincreases due to the large number of parameters relative to the number of\nobservations. To address these challenges, we introduce the Clusterpath\nestimator of the Gaussian Graphical Model (CGGM) that encourages variable\nclustering in the graphical model in a data-driven way. Through the use of an\naggregation penalty, we group variables together, which in turn results in a\nblock-structured precision matrix whose block structure remains preserved in\nthe covariance matrix. The CGGM estimator is formulated as the solution to a\nconvex optimization problem, making it easy to incorporate other popular\npenalization schemes which we illustrate through the combination of an\naggregation and sparsity penalty. We present a computationally efficient\nimplementation of the CGGM estimator by using a cyclic block coordinate descent\nalgorithm. In simulations, we show that CGGM not only matches, but oftentimes\noutperforms other state-of-the-art methods for variable clustering in graphical\nmodels. We also demonstrate CGGM's practical advantages and versatility on a\ndiverse collection of empirical applications.", "AI": {"tldr": "The paper introduces the Clusterpath estimator for Gaussian Graphical Models (CGGM) to address challenges in interpreting and estimating large-scale graphical models by encouraging variable clustering.", "motivation": "As graphical models grow in complexity with more variables, interpretation and estimation become difficult due to high parameter uncertainty.", "method": "CGGM uses an aggregation penalty to group variables, resulting in a block-structured precision matrix. It combines this with sparsity penalties and employs a cyclic block coordinate descent algorithm for efficient computation.", "result": "Simulations show CGGM outperforms state-of-the-art methods in variable clustering and maintains versatility in empirical applications.", "conclusion": "CGGM effectively addresses scalability and interpretability issues in graphical models while offering computational efficiency and practical utility."}}
{"id": "2410.02561", "pdf": "https://arxiv.org/pdf/2410.02561", "abs": "https://arxiv.org/abs/2410.02561", "authors": ["Zhiyu Zhang", "Zhou Lu", "Heng Yang"], "title": "The Benefit of Being Bayesian in Online Conformal Prediction", "categories": ["stat.ML", "cs.LG"], "comment": "Improved writing", "summary": "Based on the framework of Conformal Prediction (CP), we study the online\nconstruction of confidence sets given a black-box machine learning model. By\nconverting the target confidence levels into quantile levels, the problem can\nbe reduced to predicting the quantiles (in hindsight) of a sequentially\nrevealed data sequence. Two very different approaches have been studied\npreviously: (i) Assuming the data sequence is iid or exchangeable, one could\nmaintain the empirical distribution of the observed data as an algorithmic\nbelief, and directly predict its quantiles. (ii) Due to the fragility of\nstatistical assumptions, a recent trend is to consider the non-distributional,\nadversarial setting and apply first-order online optimization algorithms to\nmoving quantile losses. However, it requires the oracle knowledge of the target\nquantile level, and suffers from a previously overlooked monotonicity issue due\nto the associated loss linearization.\n  This paper presents an adaptive CP algorithm that combines their strengths.\nWithout any statistical assumption, it is able to answer multiple arbitrary\nconfidence level queries with low regret, while also overcoming the\nmonotonicity issue suffered by first-order optimization baselines. Furthermore,\nif the data sequence is actually iid, then the same algorithm is automatically\nequipped with the \"correct\" coverage probability guarantee.\n  To achieve such strengths, our key technical innovation is to regularize the\naforementioned algorithmic belief (the empirical distribution) by a Bayesian\nprior, which robustifies it by simulating a non-linearized Follow the\nRegularized Leader (FTRL) algorithm on the output. Such a belief update\nbackbone is shared by prediction heads targeting different confidence levels,\nbringing practical benefits analogous to the recently proposed concept of\nU-calibration (Kleinberg et al., 2023).", "AI": {"tldr": "The paper introduces an adaptive Conformal Prediction (CP) algorithm that combines strengths of empirical distribution and adversarial approaches, addressing monotonicity issues and providing correct coverage guarantees under iid assumptions.", "motivation": "To bridge the gap between empirical distribution-based methods (relying on iid assumptions) and adversarial online optimization methods (lacking monotonicity and requiring oracle knowledge), ensuring robust confidence set construction without statistical assumptions.", "method": "The algorithm regularizes the empirical distribution with a Bayesian prior, simulating a non-linearized Follow the Regularized Leader (FTRL) approach, enabling adaptive handling of multiple confidence levels.", "result": "The method achieves low regret for arbitrary confidence levels, overcomes monotonicity issues, and guarantees correct coverage under iid conditions.", "conclusion": "The proposed adaptive CP algorithm robustly combines empirical and adversarial strengths, offering practical benefits and theoretical guarantees."}}
{"id": "2410.17464", "pdf": "https://arxiv.org/pdf/2410.17464", "abs": "https://arxiv.org/abs/2410.17464", "authors": ["Ali Azizpour", "Nicolas Zilberstein", "Santiago Segarra"], "title": "Scalable Implicit Graphon Learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Graphons are continuous models that represent the structure of graphs and\nallow the generation of graphs of varying sizes. We propose Scalable Implicit\nGraphon Learning (SIGL), a scalable method that combines implicit neural\nrepresentations (INRs) and graph neural networks (GNNs) to estimate a graphon\nfrom observed graphs. Unlike existing methods, which face important limitations\nlike fixed resolution and scalability issues, SIGL learns a continuous graphon\nat arbitrary resolutions. GNNs are used to determine the correct node ordering,\nimproving graph alignment. Furthermore, we characterize the asymptotic\nconsistency of our estimator, showing that more expressive INRs and GNNs lead\nto consistent estimators. We evaluate SIGL in synthetic and real-world graphs,\nshowing that it outperforms existing methods and scales effectively to larger\ngraphs, making it ideal for tasks like graph data augmentation.", "AI": {"tldr": "SIGL is a scalable method using implicit neural representations (INRs) and graph neural networks (GNNs) to learn continuous graphons at arbitrary resolutions, outperforming existing methods in scalability and performance.", "motivation": "Existing graphon learning methods face limitations like fixed resolution and scalability issues, motivating the need for a more flexible and scalable approach.", "method": "SIGL combines INRs and GNNs to estimate graphons, using GNNs for node ordering and alignment. It ensures continuous graphon learning at arbitrary resolutions.", "result": "SIGL outperforms existing methods in synthetic and real-world graphs, scaling effectively to larger graphs and proving useful for tasks like data augmentation.", "conclusion": "SIGL provides a consistent, scalable solution for graphon learning, with expressive INRs and GNNs leading to better performance and broader applicability."}}
{"id": "2412.04163", "pdf": "https://arxiv.org/pdf/2412.04163", "abs": "https://arxiv.org/abs/2412.04163", "authors": ["Gianluca Capozzi", "Tong Tang", "Jie Wan", "Ziqi Yang", "Daniele Cono D'Elia", "Giuseppe Antonio Di Luna", "Lorenzo Cavallaro", "Leonardo Querzoni"], "title": "On the Lack of Robustness of Binary Function Similarity Systems", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Binary function similarity, which often relies on learning-based algorithms\nto identify what functions in a pool are most similar to a given query\nfunction, is a sought-after topic in different communities, including machine\nlearning, software engineering, and security. Its importance stems from the\nimpact it has in facilitating several crucial tasks, from reverse engineering\nand malware analysis to automated vulnerability detection. Whereas recent work\ncast light around performance on this long-studied problem, the research\nlandscape remains largely lackluster in understanding the resiliency of the\nstate-of-the-art machine learning models against adversarial attacks. As\nsecurity requires to reason about adversaries, in this work we assess the\nrobustness of such models through a simple yet effective black-box greedy\nattack, which modifies the topology and the content of the control flow of the\nattacked functions. We demonstrate that this attack is successful in\ncompromising all the models, achieving average attack success rates of 57.06%\nand 95.81% depending on the problem settings (targeted and untargeted attacks).\nOur findings are insightful: top performance on clean data does not necessarily\nrelate to top robustness properties, which explicitly highlights\nperformance-robustness trade-offs one should consider when deploying such\nmodels, calling for further research.", "AI": {"tldr": "The paper evaluates the robustness of binary function similarity models against adversarial attacks, revealing vulnerabilities despite high performance on clean data.", "motivation": "Binary function similarity is critical for tasks like reverse engineering and malware analysis, but the robustness of state-of-the-art models against adversarial attacks is understudied.", "method": "A black-box greedy attack is used to modify the control flow of functions, testing model resilience.", "result": "The attack compromised all models, with success rates of 57.06% (targeted) and 95.81% (untargeted).", "conclusion": "High performance on clean data doesn't guarantee robustness, emphasizing the need for further research on performance-robustness trade-offs."}}
{"id": "2412.11764", "pdf": "https://arxiv.org/pdf/2412.11764", "abs": "https://arxiv.org/abs/2412.11764", "authors": ["Jiayu Chen", "Chao Yu", "Yuqing Xie", "Feng Gao", "Yinuo Chen", "Shu'ang Yu", "Wenhao Tang", "Shilong Ji", "Mo Mu", "Yi Wu", "Huazhong Yang", "Yu Wang"], "title": "What Matters in Learning A Zero-Shot Sim-to-Real RL Policy for Quadrotor Control? A Comprehensive Study", "categories": ["cs.RO", "cs.LG"], "comment": "The first two authors contribute equally; Accepted by RA-L", "summary": "Executing precise and agile flight maneuvers is critical for quadrotors in\nvarious applications. Traditional quadrotor control approaches are limited by\ntheir reliance on flat trajectories or time-consuming optimization, which\nrestricts their flexibility. Recently, RL-based policy has emerged as a\npromising alternative due to its ability to directly map observations to\nactions, reducing the need for detailed system knowledge and actuation\nconstraints. However, a significant challenge remains in bridging the\nsim-to-real gap, where RL-based policies often experience instability when\ndeployed in real world. In this paper, we investigate key factors for learning\nrobust RL-based control policies that are capable of zero-shot deployment in\nreal-world quadrotors. We identify five critical factors and we develop a\nPPO-based training framework named SimpleFlight, which integrates these five\ntechniques. We validate the efficacy of SimpleFlight on Crazyflie quadrotor,\ndemonstrating that it achieves more than a 50% reduction in trajectory tracking\nerror compared to state-of-the-art RL baselines. The policy derived by\nSimpleFlight consistently excels across both smooth polynominal trajectories\nand challenging infeasible zigzag trajectories on small thrust-to-weight\nquadrotors. In contrast, baseline methods struggle with high-speed or\ninfeasible trajectories. To support further research and reproducibility, we\nintegrate SimpleFlight into a GPU-based simulator Omnidrones and provide\nopen-source access to the code and model checkpoints. We hope SimpleFlight will\noffer valuable insights for advancing RL-based quadrotor control. For more\ndetails, visit our project website at\nhttps://sites.google.com/view/simpleflight/.", "AI": {"tldr": "SimpleFlight, a PPO-based RL framework, reduces quadrotor trajectory tracking errors by over 50% compared to baselines, enabling zero-shot real-world deployment.", "motivation": "Traditional quadrotor control lacks flexibility due to reliance on flat trajectories or optimization. RL offers promise but faces sim-to-real gaps.", "method": "Develops SimpleFlight, integrating five key techniques for robust RL-based control, validated on Crazyflie quadrotors.", "result": "Achieves significant error reduction and excels in both smooth and challenging trajectories, outperforming baselines.", "conclusion": "SimpleFlight advances RL-based quadrotor control, with open-source code and models provided for reproducibility."}}
{"id": "2502.03198", "pdf": "https://arxiv.org/pdf/2502.03198", "abs": "https://arxiv.org/abs/2502.03198", "authors": ["Yimu Zhang", "Dongqi Han", "Yansen Wang", "Zhenning Lv", "Yu Gu", "Dongsheng Li"], "title": "SimSort: A Data-Driven Framework for Spike Sorting by Large-Scale Electrophysiology Simulation", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Spike sorting is an essential process in neural recording, which identifies\nand separates electrical signals from individual neurons recorded by electrodes\nin the brain, enabling researchers to study how specific neurons communicate\nand process information. Although there exist a number of spike sorting methods\nwhich have contributed to significant neuroscientific breakthroughs, many are\nheuristically designed, making it challenging to verify their correctness due\nto the difficulty of obtaining ground truth labels from real-world neural\nrecordings. In this work, we explore a data-driven, deep learning-based\napproach. We begin by creating a large-scale dataset through electrophysiology\nsimulations using biologically realistic computational models. We then present\nSimSort, a pretraining framework for spike sorting. Trained solely on simulated\ndata, SimSort demonstrates zero-shot generalizability to real-world spike\nsorting tasks, yielding consistent improvements over existing methods across\nmultiple benchmarks. These results highlight the potential of simulation-driven\npretraining to enhance the robustness and scalability of spike sorting in\nexperimental neuroscience.", "AI": {"tldr": "SimSort, a deep learning-based spike sorting method, uses simulated data for pretraining and achieves zero-shot generalizability to real-world tasks, outperforming existing methods.", "motivation": "Existing spike sorting methods are heuristically designed and lack verifiability due to the absence of ground truth labels in real-world neural recordings.", "method": "A large-scale dataset is created via electrophysiology simulations using biologically realistic models. SimSort, a pretraining framework, is trained on this simulated data.", "result": "SimSort shows zero-shot generalizability to real-world tasks, consistently outperforming existing methods across benchmarks.", "conclusion": "Simulation-driven pretraining enhances the robustness and scalability of spike sorting, offering potential improvements for experimental neuroscience."}}
{"id": "2502.07993", "pdf": "https://arxiv.org/pdf/2502.07993", "abs": "https://arxiv.org/abs/2502.07993", "authors": ["Ruihan Xu", "Yiping Lu"], "title": "What is a Sketch-and-Precondition Derivation for Low-Rank Approximation? Inverse Power Error or Inverse Power Estimation?", "categories": ["math.NA", "cs.CC", "cs.LG", "cs.NA", "stat.CO", "stat.ML"], "comment": null, "summary": "Randomized sketching accelerates large-scale numerical linear algebra by\nreducing computational complexity. While the traditional sketch-and-solve\napproach reduces the problem size directly through sketching, the\nsketch-and-precondition method leverages sketching to construct a computational\nfriendly preconditioner. This preconditioner improves the convergence speed of\niterative solvers applied to the original problem, maintaining accuracy in the\nfull space. Furthermore, the convergence rate of the solver improves at least\nlinearly with the sketch size. Despite its potential, developing a\nsketch-and-precondition framework for randomized algorithms in low-rank matrix\napproximation remains an open challenge. We introduce the Error-Powered\nSketched Inverse Iteration (EPSI) Method via run sketched Newton iteration for\nthe Lagrange form as a sketch-and-precondition variant for randomized low-rank\napproximation. Our method achieves theoretical guarantees, including a\nconvergence rate that improves at least linearly with the sketch size.", "AI": {"tldr": "EPSI Method introduces a sketch-and-precondition variant for low-rank matrix approximation, improving convergence rates with theoretical guarantees.", "motivation": "Addressing the open challenge of developing a sketch-and-precondition framework for randomized low-rank matrix approximation.", "method": "Error-Powered Sketched Inverse Iteration (EPSI) Method, using sketched Newton iteration for the Lagrange form.", "result": "Achieves a convergence rate improving at least linearly with sketch size, with theoretical guarantees.", "conclusion": "EPSI Method advances randomized low-rank approximation by combining sketching and preconditioning effectively."}}
{"id": "2502.16816", "pdf": "https://arxiv.org/pdf/2502.16816", "abs": "https://arxiv.org/abs/2502.16816", "authors": ["Yang Xu", "Washim Uddin Mondal", "Vaneet Aggarwal"], "title": "Finite-Sample Analysis of Policy Evaluation for Robust Average Reward Reinforcement Learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present the first finite-sample analysis for policy evaluation in robust\naverage-reward Markov Decision Processes (MDPs). Prior works in this setting\nhave established only asymptotic convergence guarantees, leaving open the\nquestion of sample complexity. In this work, we address this gap by\nestablishing that the robust Bellman operator is a contraction under the span\nsemi-norm, and developing a stochastic approximation framework with controlled\nbias. Our approach builds upon Multi-Level Monte Carlo (MLMC) techniques to\nestimate the robust Bellman operator efficiently. To overcome the infinite\nexpected sample complexity inherent in standard MLMC, we introduce a truncation\nmechanism based on a geometric distribution, ensuring a finite constant sample\ncomplexity while maintaining a small bias that decays exponentially with the\ntruncation level. Our method achieves the order-optimal sample complexity of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ for robust policy evaluation and robust\naverage reward estimation, marking a significant advancement in robust\nreinforcement learning theory.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2502.17405", "pdf": "https://arxiv.org/pdf/2502.17405", "abs": "https://arxiv.org/abs/2502.17405", "authors": ["Edward Milsom", "Ben Anson", "Laurence Aitchison"], "title": "Function-Space Learning Rates", "categories": ["stat.ML", "cs.LG"], "comment": "ICML 2025 Camera Ready Version, 27 pages, 26 figures", "summary": "We consider layerwise function-space learning rates, which measure the\nmagnitude of the change in a neural network's output function in response to an\nupdate to a parameter tensor. This contrasts with traditional learning rates,\nwhich describe the magnitude of changes in parameter space. We develop\nefficient methods to measure and set function-space learning rates in arbitrary\nneural networks, requiring only minimal computational overhead through a few\nadditional backward passes that can be performed at the start of, or\nperiodically during, training. We demonstrate two key applications: (1)\nanalysing the dynamics of standard neural network optimisers in function space,\nrather than parameter space, and (2) introducing FLeRM (Function-space Learning\nRate Matching), a novel approach to hyperparameter transfer across model\nscales. FLeRM records function-space learning rates while training a small,\ncheap base model, then automatically adjusts parameter-space layerwise learning\nrates when training larger models to maintain consistent function-space\nupdates. FLeRM gives hyperparameter transfer across model width, depth,\ninitialisation scale, and LoRA rank in various architectures including MLPs\nwith residual connections and transformers with different layer normalisation\nschemes.", "AI": {"tldr": "The paper introduces function-space learning rates for neural networks, contrasting with traditional parameter-space learning rates. It proposes efficient methods to measure and set these rates with minimal overhead and demonstrates applications like analyzing optimizer dynamics and hyperparameter transfer via FLeRM.", "motivation": "Traditional learning rates focus on parameter-space updates, but function-space learning rates provide insights into the actual changes in the network's output, enabling better optimization and hyperparameter transfer.", "method": "The paper develops methods to measure function-space learning rates efficiently using minimal additional backward passes. It introduces FLeRM for hyperparameter transfer by matching function-space updates across model scales.", "result": "The approach works across various architectures (MLPs, transformers) and scales (width, depth, initialization, LoRA rank), showing effective hyperparameter transfer and consistent function-space updates.", "conclusion": "Function-space learning rates offer a practical and efficient way to improve optimization and enable hyperparameter transfer, demonstrated by the success of FLeRM in diverse settings."}}
{"id": "2504.21787", "pdf": "https://arxiv.org/pdf/2504.21787", "abs": "https://arxiv.org/abs/2504.21787", "authors": ["Jaouad Mourtada"], "title": "Estimation of discrete distributions in relative entropy, and the deviations of the missing mass", "categories": ["math.ST", "cs.IT", "cs.LG", "math.IT", "stat.ML", "stat.TH"], "comment": "54 pages", "summary": "We study the problem of estimating a distribution over a finite alphabet from\nan i.i.d. sample, with accuracy measured in relative entropy (Kullback-Leibler\ndivergence). While optimal expected risk bounds are known, high-probability\nguarantees remain less well-understood. First, we analyze the classical Laplace\n(add-one) estimator, obtaining matching upper and lower bounds on its\nperformance and showing its optimality among confidence-independent estimators.\nWe then characterize the minimax-optimal high-probability risk, which is\nattained via a simple confidence-dependent smoothing technique. Interestingly,\nthe optimal non-asymptotic risk exhibits an additional logarithmic factor over\nthe ideal asymptotic risk. Next, motivated by scenarios where the alphabet\nexceeds the sample size, we investigate methods that adapt to the sparsity of\nthe distribution at hand. We introduce an estimator using data-dependent\nsmoothing, for which we establish a high-probability risk bound depending on\ntwo effective sparsity parameters. As part of the analysis, we also derive a\nsharp high-probability upper bound on the missing mass.", "AI": {"tldr": "The paper studies distribution estimation over finite alphabets using relative entropy, focusing on high-probability guarantees. It analyzes the Laplace estimator, introduces a confidence-dependent smoothing method for minimax-optimal risk, and proposes a data-dependent estimator for sparse distributions.", "motivation": "To address gaps in high-probability guarantees for distribution estimation and adapt methods for scenarios where the alphabet size exceeds the sample size.", "method": "Analyzes the Laplace estimator, introduces confidence-dependent smoothing for minimax risk, and proposes a data-dependent estimator for sparse distributions.", "result": "Matching bounds for the Laplace estimator, minimax-optimal risk with a logarithmic factor, and a high-probability risk bound for sparse distributions.", "conclusion": "The paper provides theoretical insights into high-probability guarantees and adapts methods for sparse distributions, revealing a logarithmic factor in non-asymptotic risk."}}
{"id": "2505.00625", "pdf": "https://arxiv.org/pdf/2505.00625", "abs": "https://arxiv.org/abs/2505.00625", "authors": ["Junchi Liu", "Ying Tang", "Sergei Tretiak", "Wenhui Duan", "Liujiang Zhou"], "title": "SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Recent advances in machine learning have demonstrated an enormous utility of\ndeep learning approaches, particularly Graph Neural Networks (GNNs) for\nmaterials science. These methods have emerged as powerful tools for\nhigh-throughput prediction of material properties, offering a compelling\nenhancement and alternative to traditional first-principles calculations. While\nthe community has predominantly focused on developing increasingly complex and\nuniversal models to enhance predictive accuracy, such approaches often lack\nphysical interpretability and insights into materials behavior. Here, we\nintroduce a novel computational paradigm, Self-Adaptable Graph Attention\nNetworks integrated with Symbolic Regression (SA-GAT-SR), that synergistically\ncombines the predictive capability of GNNs with the interpretative power of\nsymbolic regression. Our framework employs a self-adaptable encoding algorithm\nthat automatically identifies and adjust attention weights so as to screen\ncritical features from an expansive 180-dimensional feature space while\nmaintaining O(n) computational scaling. The integrated SR module subsequently\ndistills these features into compact analytical expressions that explicitly\nreveal quantum-mechanically meaningful relationships, achieving 23 times\nacceleration compared to conventional SR implementations that heavily rely on\nfirst principle calculations-derived features as input. This work suggests a\nnew framework in computational materials science, bridging the gap between\npredictive accuracy and physical interpretability, offering valuable physical\ninsights into material behavior.", "AI": {"tldr": "A novel framework, SA-GAT-SR, combines GNNs with symbolic regression for interpretable and accurate material property predictions.", "motivation": "Address the lack of interpretability in complex GNN models for materials science while maintaining predictive accuracy.", "method": "Uses self-adaptable graph attention networks to identify critical features and symbolic regression to distill them into interpretable expressions.", "result": "Achieves 23x acceleration over conventional methods and provides quantum-mechanically meaningful insights.", "conclusion": "SA-GAT-SR bridges the gap between accuracy and interpretability in computational materials science."}}
{"id": "2505.07101", "pdf": "https://arxiv.org/pdf/2505.07101", "abs": "https://arxiv.org/abs/2505.07101", "authors": ["Haichen Hu", "David Simchi-Levi", "Navid Azizan"], "title": "Constrained Online Decision-Making: A Unified Framework", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Contextual online decision-making problems with constraints appear in a wide\nrange of real-world applications, such as adaptive experimental design under\nsafety constraints, personalized recommendation with resource limits, and\ndynamic pricing under fairness requirements. In this paper, we investigate a\ngeneral formulation of sequential decision-making with stage-wise feasibility\nconstraints, where at each round, the learner must select an action based on\nobserved context while ensuring that a problem-specific feasibility criterion\nis satisfied. We propose a unified algorithmic framework that captures many\nexisting constrained learning problems, including constrained bandits, active\nlearning with label budgets, online hypothesis testing with Type I error\ncontrol, and model calibration. Central to our approach is the concept of upper\ncounterfactual confidence bounds, which enables the design of practically\nefficient online algorithms with strong theoretical guarantees using any\noffline conditional density estimation oracle. To handle feasibility\nconstraints in complex environments, we introduce a generalized notion of the\neluder dimension, extending it from the classical setting based on square loss\nto a broader class of metric-like probability divergences. This allows us to\ncapture the complexity of various density function classes and characterize the\nutility regret incurred due to feasibility constraint uncertainty. Our result\noffers a principled foundation for constrained sequential decision-making in\nboth theory and practice.", "AI": {"tldr": "The paper presents a unified framework for constrained sequential decision-making, addressing problems like adaptive experimental design and personalized recommendation. It introduces upper counterfactual confidence bounds and extends the eluder dimension to handle feasibility constraints with theoretical guarantees.", "motivation": "To address real-world problems like adaptive experimental design and dynamic pricing, which require sequential decision-making under constraints, the paper aims to provide a general and efficient solution.", "method": "The proposed framework uses upper counterfactual confidence bounds and a generalized eluder dimension to handle feasibility constraints, leveraging offline conditional density estimation oracles.", "result": "The approach offers strong theoretical guarantees and practical efficiency, applicable to various constrained learning problems.", "conclusion": "The paper provides a principled foundation for constrained sequential decision-making, bridging theory and practice."}}
{"id": "2505.11006", "pdf": "https://arxiv.org/pdf/2505.11006", "abs": "https://arxiv.org/abs/2505.11006", "authors": ["Oskar Allerbo", "Thomas B. Sch\u00f6n"], "title": "Supervised Models Can Generalize Also When Trained on Random Labels", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The success of unsupervised learning raises the question of whether also\nsupervised models can be trained without using the information in the output\n$y$. In this paper, we demonstrate that this is indeed possible. The key step\nis to formulate the model as a smoother, i.e. on the form $\\hat{f}=Sy$, and to\nconstruct the smoother matrix $S$ independently of $y$, e.g. by training on\nrandom labels. We present a simple model selection criterion based on the\ndistribution of the out-of-sample predictions and show that, in contrast to\ncross-validation, this criterion can be used also without access to $y$. We\ndemonstrate on real and synthetic data that $y$-free trained versions of linear\nand kernel ridge regression, smoothing splines, and neural networks perform\nsimilarly to their standard, $y$-based, versions and, most importantly,\nsignificantly better than random guessing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.13947", "pdf": "https://arxiv.org/pdf/2505.13947", "abs": "https://arxiv.org/abs/2505.13947", "authors": ["Shirong Xu", "Hengzhi He", "Guang Cheng"], "title": "A Probabilistic Perspective on Model Collapse", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In recent years, model collapse has become a critical issue in language model\ntraining, making it essential to understand the underlying mechanisms driving\nthis phenomenon. In this paper, we investigate recursive parametric model\ntraining from a probabilistic perspective, aiming to characterize the\nconditions under which model collapse occurs and, crucially, how it can be\nmitigated. We conceptualize the recursive training process as a random walk of\nthe model estimate, highlighting how the sample size influences the step size\nand how the estimation procedure determines the direction and potential bias of\nthe random walk. Under mild conditions, we rigorously show that progressively\nincreasing the sample size at each training step is necessary to prevent model\ncollapse. In particular, when the estimation is unbiased, the required growth\nrate follows a superlinear pattern. This rate needs to be accelerated even\nfurther in the presence of substantial estimation bias. Building on this\nprobabilistic framework, we also investigate the probability that recursive\ntraining on synthetic data yields models that outperform those trained solely\non real data. Moreover, we extend these results to general parametric model\nfamily in an asymptotic regime. Finally, we validate our theoretical results\nthrough extensive simulations and a real-world dataset.", "AI": {"tldr": "The paper investigates model collapse in recursive parametric model training, identifying conditions for its occurrence and mitigation, emphasizing the need for increasing sample sizes and addressing estimation bias.", "motivation": "Understanding and mitigating model collapse in language model training is critical due to its growing impact.", "method": "The study uses a probabilistic framework to analyze recursive training as a random walk, examining sample size growth and estimation bias.", "result": "Increasing sample size superlinearly is necessary to prevent collapse, with faster growth needed for biased estimation. Synthetic data can outperform real data in some cases.", "conclusion": "The findings provide a theoretical foundation for mitigating model collapse, validated through simulations and real-world data."}}
{"id": "2505.14759", "pdf": "https://arxiv.org/pdf/2505.14759", "abs": "https://arxiv.org/abs/2505.14759", "authors": ["Yan Wang", "Ling Ding", "Tien N Nguyen", "Shaohua Wang", "Yanan Zheng"], "title": "LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models", "categories": ["cs.SE", "cs.LG"], "comment": "Accepted to ACL 2025 main conference", "summary": "Large Language Models for code often entail significant computational\ncomplexity, which grows significantly with the length of the input code\nsequence. We propose LeanCode for code simplification to reduce training and\nprediction time, leveraging code contexts in utilizing attention scores to\nrepresent the tokens' importance. We advocate for the selective removal of\ntokens based on the average context-aware attention scores rather than average\nscores across all inputs. LeanCode uses the attention scores of `CLS' tokens\nwithin the encoder for classification tasks, such as code search. It also\nemploys the encoder-decoder attention scores to determine token significance\nfor sequence-to-sequence tasks like code summarization. Our evaluation shows\nLeanCode's superiority over the SOTAs DietCode and Slimcode, with improvements\nof 60% and 16% for code search, and 29% and 27% for code summarization,\nrespectively.", "AI": {"tldr": "LeanCode simplifies code to reduce computational complexity by selectively removing tokens based on context-aware attention scores, outperforming SOTAs DietCode and Slimcode.", "motivation": "Large Language Models for code face high computational complexity, which grows with input length, necessitating efficient simplification methods.", "method": "LeanCode uses attention scores (from `CLS` tokens for classification and encoder-decoder for sequence tasks) to determine token importance and selectively remove tokens.", "result": "LeanCode improves code search by 60% and 16%, and code summarization by 29% and 27% over DietCode and Slimcode, respectively.", "conclusion": "LeanCode effectively reduces computational overhead while maintaining performance, making it superior to existing methods."}}
{"id": "2505.14806", "pdf": "https://arxiv.org/pdf/2505.14806", "abs": "https://arxiv.org/abs/2505.14806", "authors": ["Minglu Zhao", "Dehong Xu", "Deqian Kong", "Wen-Hao Zhang", "Ying Nian Wu"], "title": "Place Cells as Position Embeddings of Multi-Time Random Walk Transition Kernels for Path Planning", "categories": ["q-bio.NC", "cs.LG", "stat.ML"], "comment": null, "summary": "The hippocampus orchestrates spatial navigation through collective place cell\nencodings that form cognitive maps. We reconceptualize the population of place\ncells as position embeddings approximating multi-scale symmetric random walk\ntransition kernels: the inner product $\\langle h(x, t), h(y, t) \\rangle =\nq(y|x, t)$ represents normalized transition probabilities, where $h(x, t)$ is\nthe embedding at location $ x $, and $q(y|x, t)$ is the normalized symmetric\ntransition probability over time $t$. The time parameter $\\sqrt{t}$ defines a\nspatial scale hierarchy, mirroring the hippocampal dorsoventral axis. $q(y|x,\nt)$ defines spatial adjacency between $x$ and $y$ at scale or resolution\n$\\sqrt{t}$, and the pairwise adjacency relationships $(q(y|x, t), \\forall x,\ny)$ are reduced into individual embeddings $(h(x, t), \\forall x)$ that\ncollectively form a map of the environment at sale $\\sqrt{t}$. Our framework\nemploys gradient ascent on $q(y|x, t) = \\langle h(x, t), h(y, t)\\rangle$ with\nadaptive scale selection, choosing the time scale with maximal gradient at each\nstep for trap-free, smooth trajectories. Efficient matrix squaring $P_{2t} =\nP_t^2$ builds global representations from local transitions $P_1$ without\nmemorizing past trajectories, enabling hippocampal preplay-like path planning.\nThis produces robust navigation through complex environments, aligning with\nhippocampal navigation. Experimental results show that our model captures place\ncell properties -- field size distribution, adaptability, and remapping --\nwhile achieving computational efficiency. By modeling collective transition\nprobabilities rather than individual place fields, we offer a biologically\nplausible, scalable framework for spatial navigation.", "AI": {"tldr": "The paper redefines place cells in the hippocampus as position embeddings approximating multi-scale symmetric random walk transition kernels, enabling efficient and biologically plausible spatial navigation.", "motivation": "To provide a scalable and biologically plausible framework for spatial navigation by modeling collective transition probabilities of place cells rather than individual place fields.", "method": "The framework uses gradient ascent on normalized transition probabilities with adaptive scale selection and efficient matrix squaring to build global representations from local transitions.", "result": "The model captures place cell properties like field size distribution, adaptability, and remapping while achieving computational efficiency and robust navigation.", "conclusion": "The proposed framework offers a scalable and biologically plausible approach to spatial navigation, aligning with hippocampal function."}}
{"id": "2505.15793", "pdf": "https://arxiv.org/pdf/2505.15793", "abs": "https://arxiv.org/abs/2505.15793", "authors": ["Zhiwen Chen", "Bo Leng", "Zhuoren Li", "Hanming Deng", "Guizhe Jin", "Ran Yu", "Huanxi Wen"], "title": "HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Integrating Large Language Models (LLMs) with Reinforcement Learning (RL) can\nenhance autonomous driving (AD) performance in complex scenarios. However,\ncurrent LLM-Dominated RL methods over-rely on LLM outputs, which are prone to\nhallucinations. Evaluations show that state-of-the-art LLM indicates a\nnon-hallucination rate of only approximately 57.95% when assessed on essential\ndriving-related tasks. Thus, in these methods, hallucinations from the LLM can\ndirectly jeopardize the performance of driving policies. This paper argues that\nmaintaining relative independence between the LLM and the RL is vital for\nsolving the hallucinations problem. Consequently, this paper is devoted to\npropose a novel LLM-Hinted RL paradigm. The LLM is used to generate semantic\nhints for state augmentation and policy optimization to assist RL agent in\nmotion planning, while the RL agent counteracts potential erroneous semantic\nindications through policy learning to achieve excellent driving performance.\nBased on this paradigm, we propose the HCRMP (LLM-Hinted Contextual\nReinforcement Learning Motion Planner) architecture, which is designed that\nincludes Augmented Semantic Representation Module to extend state space.\nContextual Stability Anchor Module enhances the reliability of multi-critic\nweight hints by utilizing information from the knowledge base. Semantic Cache\nModule is employed to seamlessly integrate LLM low-frequency guidance with RL\nhigh-frequency control. Extensive experiments in CARLA validate HCRMP's strong\noverall driving performance. HCRMP achieves a task success rate of up to 80.3%\nunder diverse driving conditions with different traffic densities. Under\nsafety-critical driving conditions, HCRMP significantly reduces the collision\nrate by 11.4%, which effectively improves the driving performance in complex\nscenarios.", "AI": {"tldr": "The paper proposes a novel LLM-Hinted RL paradigm to address hallucinations in LLM-Dominated RL methods for autonomous driving, introducing the HCRMP architecture for improved performance.", "motivation": "Current LLM-Dominated RL methods over-rely on LLM outputs, which are prone to hallucinations, jeopardizing driving policies. Maintaining LLM-RL independence is crucial.", "method": "The paper introduces the HCRMP architecture, featuring modules for state augmentation, contextual stability, and semantic cache to integrate LLM hints with RL control.", "result": "HCRMP achieves an 80.3% task success rate and reduces collision rates by 11.4% in safety-critical conditions, validated in CARLA.", "conclusion": "The LLM-Hinted RL paradigm and HCRMP architecture effectively mitigate hallucinations and enhance autonomous driving performance in complex scenarios."}}
